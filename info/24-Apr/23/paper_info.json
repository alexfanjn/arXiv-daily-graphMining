[
  {
    "id": "arXiv:2404.13079",
    "title": "Relational Graph Convolutional Networks for Sentiment Analysis",
    "abstract": "With the growth of textual data across online platforms, sentiment analysis has become crucial for extracting insights from user-generated content. While traditional approaches and deep learning models have shown promise, they cannot often capture complex relationships between entities. In this paper, we propose leveraging Relational Graph Convolutional Networks (RGCNs) for sentiment analysis, which offer interpretability and flexibility by capturing dependencies between data points represented as nodes in a graph. We demonstrate the effectiveness of our approach by using pre-trained language models such as BERT and RoBERTa with RGCN architecture on product reviews from Amazon and Digikala datasets and evaluating the results. Our experiments highlight the effectiveness of RGCNs in capturing relational information for sentiment analysis tasks. ",
    "url": "https://arxiv.org/abs/2404.13079",
    "authors": [
      "Asal Khosravi",
      "Zahed Rahmati",
      "Ali Vefghi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13087",
    "title": "Demystifying Legalese: An Automated Approach for Summarizing and  Analyzing Overlaps in Privacy Policies and Terms of Service",
    "abstract": "The complexities of legalese in terms and policy documents can bind individuals to contracts they do not fully comprehend, potentially leading to uninformed data sharing. Our work seeks to alleviate this issue by developing language models that provide automated, accessible summaries and scores for such documents, aiming to enhance user understanding and facilitate informed decisions. We compared transformer-based and conventional models during training on our dataset, and RoBERTa performed better overall with a remarkable 0.74 F1-score. Leveraging our best-performing model, RoBERTa, we highlighted redundancies and potential guideline violations by identifying overlaps in GDPR-required documents, underscoring the necessity for stricter GDPR compliance. ",
    "url": "https://arxiv.org/abs/2404.13087",
    "authors": [
      "Shikha Soneji",
      "Mitchell Hoesing",
      "Sujay Koujalgi",
      "Jonathan Dodge"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13104",
    "title": "Multi Class Depression Detection Through Tweets using Artificial  Intelligence",
    "abstract": "Depression is a significant issue nowadays. As per the World Health Organization (WHO), in 2023, over 280 million individuals are grappling with depression. This is a huge number; if not taken seriously, these numbers will increase rapidly. About 4.89 billion individuals are social media users. People express their feelings and emotions on platforms like Twitter, Facebook, Reddit, Instagram, etc. These platforms contain valuable information which can be used for research purposes. Considerable research has been conducted across various social media platforms. However, certain limitations persist in these endeavors. Particularly, previous studies were only focused on detecting depression and the intensity of depression in tweets. Also, there existed inaccuracies in dataset labeling. In this research work, five types of depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted using tweets from the Twitter database based on lexicon labeling. Explainable AI was used to provide reasoning by highlighting the parts of tweets that represent type of depression. Bidirectional Encoder Representations from Transformers (BERT) was used for feature extraction and training. Machine learning and deep learning methodologies were used to train the model. The BERT model presented the most promising results, achieving an overall accuracy of 0.96. ",
    "url": "https://arxiv.org/abs/2404.13104",
    "authors": [
      "Muhammad Osama Nusrat",
      "Waseem Shahzad",
      "Saad Ahmed Jamal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13125",
    "title": "Towards Robust Real-Time Hardware-based Mobile Malware Detection using  Multiple Instance Learning Formulation",
    "abstract": "This study introduces RT-HMD, a Hardware-based Malware Detector (HMD) for mobile devices, that refines malware representation in segmented time-series through a Multiple Instance Learning (MIL) approach. We address the mislabeling issue in real-time HMDs, where benign segments in malware time-series incorrectly inherit malware labels, leading to increased false positives. Utilizing the proposed Malicious Discriminative Score within the MIL framework, RT-HMD effectively identifies localized malware behaviors, thereby improving the predictive accuracy. Empirical analysis, using a hardware telemetry dataset collected from a mobile platform across 723 benign and 1033 malware samples, shows a 5% precision boost while maintaining recall, outperforming baselines affected by mislabeled benign segments. ",
    "url": "https://arxiv.org/abs/2404.13125",
    "authors": [
      "Harshit Kumar",
      "Sudarshan Sharma",
      "Biswadeep Chakraborty",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13146",
    "title": "DeepFake-O-Meter v2.0: An Open Platform for DeepFake Detection",
    "abstract": "Deepfakes, as AI-generated media, have increasingly threatened media integrity and personal privacy with realistic yet fake digital content. In this work, we introduce an open-source and user-friendly online platform, DeepFake-O-Meter v2.0, that integrates state-of-the-art methods for detecting Deepfake images, videos, and audio. Built upon DeepFake-O-Meter v1.0, we have made significant upgrades and improvements in platform architecture design, including user interaction, detector integration, job balancing, and security management. The platform aims to offer everyday users a convenient service for analyzing DeepFake media using multiple state-of-the-art detection algorithms. It ensures secure and private delivery of the analysis results. Furthermore, it serves as an evaluation and benchmarking platform for researchers in digital media forensics to compare the performance of multiple algorithms on the same input. We have also conducted detailed usage analysis based on the collected data to gain deeper insights into our platform's statistics. This involves analyzing two-month trends in user activity and evaluating the processing efficiency of each detector. ",
    "url": "https://arxiv.org/abs/2404.13146",
    "authors": [
      "Shuwei Hou",
      "Yan Ju",
      "Chengzhe Sun",
      "Shan Jia",
      "Lipeng Ke",
      "Riky Zhou",
      "Anita Nikolich",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13158",
    "title": "Resource Slicing with Cross-Cell Coordination in Satellite-Terrestrial  Integrated Networks",
    "abstract": "Satellite-terrestrial integrated networks (STIN) are envisioned as a promising architecture for ubiquitous network connections to support diversified services. In this paper, we propose a novel resource slicing scheme with cross-cell coordination in STIN to satisfy distinct service delay requirements and efficient resource usage. To address the challenges posed by spatiotemporal dynamics in service demands and satellite mobility, we formulate the resource slicing problem into a long-term optimization problem and propose a distributed resource slicing (DRS) scheme for scalable and flexible resource management across different cells. Specifically, a hybrid data-model co-driven approach is developed, including an asynchronous multi-agent reinforcement learning-based algorithm to determine the optimal satellite set serving each cell and a distributed optimization-based algorithm to make the resource reservation decisions for each slice. Simulation results demonstrate that the proposed scheme outperforms benchmark methods in terms of resource usage and delay performance. ",
    "url": "https://arxiv.org/abs/2404.13158",
    "authors": [
      "Mingcheng He",
      "Huaqing Wu",
      "Conghao Zhou",
      "Xuemin",
      "Shen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.13159",
    "title": "Equivariant Imaging for Self-supervised Hyperspectral Image Inpainting",
    "abstract": "Hyperspectral imaging (HSI) is a key technology for earth observation, surveillance, medical imaging and diagnostics, astronomy and space exploration. The conventional technology for HSI in remote sensing applications is based on the push-broom scanning approach in which the camera records the spectral image of a stripe of the scene at a time, while the image is generated by the aggregation of measurements through time. In real-world airborne and spaceborne HSI instruments, some empty stripes would appear at certain locations, because platforms do not always maintain a constant programmed attitude, or have access to accurate digital elevation maps (DEM), and the travelling track is not necessarily aligned with the hyperspectral cameras at all times. This makes the enhancement of the acquired HS images from incomplete or corrupted observations an essential task. We introduce a novel HSI inpainting algorithm here, called Hyperspectral Equivariant Imaging (Hyper-EI). Hyper-EI is a self-supervised learning-based method which does not require training on extensive datasets or access to a pre-trained model. Experimental results show that the proposed method achieves state-of-the-art inpainting performance compared to the existing methods. ",
    "url": "https://arxiv.org/abs/2404.13159",
    "authors": [
      "Shuo Li",
      "Mike Davies",
      "Mehrdad Yaghoobi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2404.13182",
    "title": "Spectral Convolutional Conditional Neural Processes",
    "abstract": "Conditional Neural Processes (CNPs) constitute a family of probabilistic models that harness the flexibility of neural networks to parameterize stochastic processes. Their capability to furnish well-calibrated predictions, combined with simple maximum-likelihood training, has established them as appealing solutions for addressing various learning problems, with a particular emphasis on meta-learning. A prominent member of this family, Convolutional Conditional Neural Processes (ConvCNPs), utilizes convolution to explicitly introduce translation equivariance as an inductive bias. However, ConvCNP's reliance on local discrete kernels in its convolution layers can pose challenges in capturing long-range dependencies and complex patterns within the data, especially when dealing with limited and irregularly sampled observations from a new task. Building on the successes of Fourier neural operators (FNOs) for approximating the solution operators of parametric partial differential equations (PDEs), we propose Spectral Convolutional Conditional Neural Processes (SConvCNPs), a new addition to the NPs family that allows for more efficient representation of functions in the frequency domain. ",
    "url": "https://arxiv.org/abs/2404.13182",
    "authors": [
      "Peiman Mohseni",
      "Nick Duffield"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13192",
    "title": "Heterogeneous Subgraph Transformer for Fake News Detection",
    "abstract": "Fake news is pervasive on social media, inflicting substantial harm on public discourse and societal well-being. We investigate the explicit structural information and textual features of news pieces by constructing a heterogeneous graph concerning the relations among news topics, entities, and content. Through our study, we reveal that fake news can be effectively detected in terms of the atypical heterogeneous subgraphs centered on them, which encapsulate the essential semantics and intricate relations between news elements. However, suffering from the heterogeneity, exploring such heterogeneous subgraphs remains an open problem. To bridge the gap, this work proposes a heterogeneous subgraph transformer (HeteroSGT) to exploit subgraphs in our constructed heterogeneous graph. In HeteroSGT, we first employ a pre-trained language model to derive both word-level and sentence-level semantics. Then the random walk with restart (RWR) is applied to extract subgraphs centered on each news, which are further fed to our proposed subgraph Transformer to quantify the authenticity. Extensive experiments on five real-world datasets demonstrate the superior performance of HeteroSGT over five baselines. Further case and ablation studies validate our motivation and demonstrate that performance improvement stems from our specially designed components. ",
    "url": "https://arxiv.org/abs/2404.13192",
    "authors": [
      "Yuchen Zhang",
      "Xiaoxiao Ma",
      "Jia Wu",
      "Jian Yang",
      "Hao Fan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13194",
    "title": "Privacy-Preserving Debiasing using Data Augmentation and Machine  Unlearning",
    "abstract": "Data augmentation is widely used to mitigate data bias in the training dataset. However, data augmentation exposes machine learning models to privacy attacks, such as membership inference attacks. In this paper, we propose an effective combination of data augmentation and machine unlearning, which can reduce data bias while providing a provable defense against known attacks. Specifically, we maintain the fairness of the trained model with diffusion-based data augmentation, and then utilize multi-shard unlearning to remove identifying information of original data from the ML model for protection against privacy attacks. Experimental evaluation across diverse datasets demonstrates that our approach can achieve significant improvements in bias reduction as well as robustness against state-of-the-art privacy attacks. ",
    "url": "https://arxiv.org/abs/2404.13194",
    "authors": [
      "Zhixin Pan",
      "Emma Andrews",
      "Laura Chang",
      "Prabhat Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13216",
    "title": "Robustness and Accuracy in Pipelined Bi-Conjugate Gradient Stabilized  Method: A Comparative Study",
    "abstract": "In this article, we propose an accuracy-assuring technique for finding a solution for unsymmetric linear systems. Such problems are related to different areas such as image processing, computer vision, and computational fluid dynamics. Parallel implementation of Krylov subspace methods speeds up finding approximate solutions for linear systems. In this context, the refined approach in pipelined BiCGStab enhances scalability on distributed memory machines, yielding to substantial speed improvements compared to the standard BiCGStab method. However, it's worth noting that the pipelined BiCGStab algorithm sacrifices some accuracy, which is stabilized with the residual replacement technique. This paper aims to address this issue by employing the ExBLAS-based reproducible approach. We validate the idea on a set of matrices from the SuiteSparse Matrix Collection. ",
    "url": "https://arxiv.org/abs/2404.13216",
    "authors": [
      "Mykhailo Havdiak",
      "Jose I. Aliaga",
      "Roman Iakymchuk"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2404.13220",
    "title": "Security and Privacy Product Inclusion",
    "abstract": "In this paper, we explore the challenges of ensuring security and privacy for users from diverse demographic backgrounds. We propose a threat modeling approach to identify potential risks and countermeasures for product inclusion in security and privacy. We discuss various factors that can affect a user's ability to achieve a high level of security and privacy, including low-income demographics, poor connectivity, shared device usage, ML fairness, etc. We present results from a global security and privacy user experience survey and discuss the implications for product developers. Our work highlights the need for a more inclusive approach to security and privacy and provides a framework for researchers and practitioners to consider when designing products and services for a diverse range of users. ",
    "url": "https://arxiv.org/abs/2404.13220",
    "authors": [
      "Dave Kleidermacher",
      "Emmanuel Arriaga",
      "Eric Wang",
      "Sebastian Porst",
      "Roger Piqueras Jover"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13235",
    "title": "TrialDura: Hierarchical Attention Transformer for Interpretable Clinical  Trial Duration Prediction",
    "abstract": "The clinical trial process, also known as drug development, is an indispensable step toward the development of new treatments. The major objective of interventional clinical trials is to assess the safety and effectiveness of drug-based treatment in treating certain diseases in the human body. However, clinical trials are lengthy, labor-intensive, and costly. The duration of a clinical trial is a crucial factor that influences overall expenses. Therefore, effective management of the timeline of a clinical trial is essential for controlling the budget and maximizing the economic viability of the research. To address this issue, We propose TrialDura, a machine learning-based method that estimates the duration of clinical trials using multimodal data, including disease names, drug molecules, trial phases, and eligibility criteria. Then, we encode them into Bio-BERT embeddings specifically tuned for biomedical contexts to provide a deeper and more relevant semantic understanding of clinical trial data. Finally, the model's hierarchical attention mechanism connects all of the embeddings to capture their interactions and predict clinical trial duration. Our proposed model demonstrated superior performance with a mean absolute error (MAE) of 1.04 years and a root mean square error (RMSE) of 1.39 years compared to the other models, indicating more accurate clinical trial duration prediction. Publicly available code can be found at https://anonymous.4open.science/r/TrialDura-F196 ",
    "url": "https://arxiv.org/abs/2404.13235",
    "authors": [
      "Ling Yue",
      "Jonathan Li",
      "Md Zabirul Islam",
      "Bolun Xia",
      "Tianfan Fu",
      "Jintai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13242",
    "title": "5G-WAVE: A Core Network Framework with Decentralized Authorization for  Network Slices",
    "abstract": "5G mobile networks leverage Network Function Virtualization (NFV) to offer services in the form of network slices. Each network slice is a logically isolated fragment constructed by service chaining a set of Virtual Network Functions (VNFs). The Network Repository Function (NRF) acts as a central OpenAuthorization (OAuth) 2.0 server to secure inter-VNF communications resulting in a single point of failure. Thus, we propose 5G-WAVE, a decentralized authorization framework for the 5G core by leveraging the WAVE framework and integrating it into the OpenAirInterface (OAI) 5G core. Our design relies on Side-Car Proxies (SCPs) deployed alongside individual VNFs, allowing point-to-point authorization. Each SCP acts as a WAVE engine to create entities and attestations and verify incoming service requests. We measure the authorization latency overhead for VNF registration, 5G Authentication and Key Agreement (AKA), and data session setup and observe that WAVE verification introduces 155ms overhead to HTTP transactions for decentralizing authorization. Additionally, we evaluate the scalability of 5G-WAVE by instantiating more network slices to observe 1.4x increase in latency with 10x growth in network size. We also discuss how 5G-WAVE can significantly reduce the 5G attack surface without using OAuth 2.0 while addressing several key issues of 5G standardization. ",
    "url": "https://arxiv.org/abs/2404.13242",
    "authors": [
      "Pragya Sharma",
      "Tolga Atalay",
      "Hans-Andrew Gibbs",
      "Dragoslav Stojadinovic",
      "Angelos Stavrou",
      "Haining Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.13267",
    "title": "Demystify Adult Learning: A Social Network and Large Language Model  Assisted Approach",
    "abstract": "Adult learning is increasingly recognized as a crucial way for personal development and societal progress. It however is challenging, and adult learners face unique challenges such as balancing education with other life responsibilities. Collecting feedback from adult learners is effective in understanding their concerns and improving learning experiences, and social networks provide a rich source of real-time sentiment data from adult learners. Machine learning technologies especially large language models (LLMs) perform well in automating sentiment analysis. However, none of such models is specialized for adult learning with accurate sentiment understanding. In this paper, we present A-Learn, which enhances adult learning sentiment analysis by customizing existing general-purpose LLMs with domain-specific datasets for adult learning. We collect adult learners' comments from social networks and label the sentiment of each comment with an existing LLM to form labelled datasets tailored for adult learning. The datasets are used to customize A-Learn from several base LLMs. We conducted experimental studies and the results reveal A-Learn's competitive sentiment analysis performance, achieving up to 91.3% accuracy with 20% improvement over the base LLM. A-Learn is also employed for word cloud analysis to identify key concerns of adult learners. The research outcome of this study highlights the importance of applying machine learning with educational expertise for teaching improvement and educational innovations that benefit adult learning and adult learners. ",
    "url": "https://arxiv.org/abs/2404.13267",
    "authors": [
      "Fang Liu",
      "Bosheng Ding",
      "Chong Guan",
      "Zhang Wei",
      "Dusit Niyato",
      "Justina Tan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2404.13273",
    "title": "Multi-feature Reconstruction Network using Crossed-mask Restoration for  Unsupervised Anomaly Detection",
    "abstract": "Unsupervised anomaly detection using only normal samples is of great significance for quality inspection in industrial manufacturing. Although existing reconstruction-based methods have achieved promising results, they still face two problems: poor distinguishable information in image reconstruction and well abnormal regeneration caused by model over-generalization ability. To overcome the above issues, we convert the image reconstruction into a combination of parallel feature restorations and propose a multi-feature reconstruction network, MFRNet, using crossed-mask restoration in this paper. Specifically, a multi-scale feature aggregator is first developed to generate more discriminative hierarchical representations of the input images from a pre-trained model. Subsequently, a crossed-mask generator is adopted to randomly cover the extracted feature map, followed by a restoration network based on the transformer structure for high-quality repair of the missing regions. Finally, a hybrid loss is equipped to guide model training and anomaly estimation, which gives consideration to both the pixel and structural similarity. Extensive experiments show that our method is highly competitive with or significantly outperforms other state-of-the-arts on four public available datasets and one self-made dataset. ",
    "url": "https://arxiv.org/abs/2404.13273",
    "authors": [
      "Junpu Wang",
      "Guili Xu",
      "Chunlei Li",
      "Guangshuai Gao",
      "Yuehua Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13279",
    "title": "Backdoor Attacks and Defenses on Semantic-Symbol Reconstruction in  Semantic Communications",
    "abstract": "Semantic communication is of crucial importance for the next-generation wireless communication networks. The existing works have developed semantic communication frameworks based on deep learning. However, systems powered by deep learning are vulnerable to threats such as backdoor attacks and adversarial attacks. This paper delves into backdoor attacks targeting deep learning-enabled semantic communication systems. Since current works on backdoor attacks are not tailored for semantic communication scenarios, a new backdoor attack paradigm on semantic symbols (BASS) is introduced, based on which the corresponding defense measures are designed. Specifically, a training framework is proposed to prevent BASS. Additionally, reverse engineering-based and pruning-based defense strategies are designed to protect against backdoor attacks in semantic communication. Simulation results demonstrate the effectiveness of both the proposed attack paradigm and the defense strategies. ",
    "url": "https://arxiv.org/abs/2404.13279",
    "authors": [
      "Yuan Zhou",
      "Rose Qingyang Hu",
      "Yi Qian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.13282",
    "title": "Wills Aligner: A Robust Multi-Subject Brain Representation Learner",
    "abstract": "Decoding visual information from human brain activity has seen remarkable advancements in recent research. However, due to the significant variability in cortical parcellation and cognition patterns across subjects, current approaches personalized deep models for each subject, constraining the practicality of this technology in real-world contexts. To tackle the challenges, we introduce Wills Aligner, a robust multi-subject brain representation learner. Our Wills Aligner initially aligns different subjects' brains at the anatomical level. Subsequently, it incorporates a mixture of brain experts to learn individual cognition patterns. Additionally, it decouples the multi-subject learning task into a two-stage training, propelling the deep model and its plugin network to learn inter-subject commonality knowledge and various cognition patterns, respectively. Wills Aligner enables us to overcome anatomical differences and to efficiently leverage a single model for multi-subject brain representation learning. We meticulously evaluate the performance of our approach across coarse-grained and fine-grained visual decoding tasks. The experimental results demonstrate that our Wills Aligner achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2404.13282",
    "authors": [
      "Guangyin Bao",
      "Zixuan Gong",
      "Qi Zhang",
      "Jialei Zhou",
      "Wei Fan",
      "Kun Yi",
      "Usman Naseem",
      "Liang Hu",
      "Duoqian Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2404.13286",
    "title": "Track Role Prediction of Single-Instrumental Sequences",
    "abstract": "In the composition process, selecting appropriate single-instrumental music sequences and assigning their track-role is an indispensable task. However, manually determining the track-role for a myriad of music samples can be time-consuming and labor-intensive. This study introduces a deep learning model designed to automatically predict the track-role of single-instrumental music sequences. Our evaluations show a prediction accuracy of 87% in the symbolic domain and 84% in the audio domain. The proposed track-role prediction methods hold promise for future applications in AI music generation and analysis. ",
    "url": "https://arxiv.org/abs/2404.13286",
    "authors": [
      "Changheon Han",
      "Suhyun Lee",
      "Minsam Ko"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.13288",
    "title": "PoseINN: Realtime Visual-based Pose Regression and Localization with  Invertible Neural Networks",
    "abstract": "Estimating ego-pose from cameras is an important problem in robotics with applications ranging from mobile robotics to augmented reality. While SOTA models are becoming increasingly accurate, they can still be unwieldy due to high computational costs. In this paper, we propose to solve the problem by using invertible neural networks (INN) to find the mapping between the latent space of images and poses for a given scene. Our model achieves similar performance to the SOTA while being faster to train and only requiring offline rendering of low-resolution synthetic data. By using normalizing flows, the proposed method also provides uncertainty estimation for the output. We also demonstrated the efficiency of this method by deploying the model on a mobile robot. ",
    "url": "https://arxiv.org/abs/2404.13288",
    "authors": [
      "Zirui Zang",
      "Ahmad Amine",
      "Rahul Mangharam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13289",
    "title": "Double Mixture: Towards Continual Event Detection from Speech",
    "abstract": "Speech event detection is crucial for multimedia retrieval, involving the tagging of both semantic and acoustic events. Traditional ASR systems often overlook the interplay between these events, focusing solely on content, even though the interpretation of dialogue can vary with environmental context. This paper tackles two primary challenges in speech event detection: the continual integration of new events without forgetting previous ones, and the disentanglement of semantic from acoustic events. We introduce a new task, continual event detection from speech, for which we also provide two benchmark datasets. To address the challenges of catastrophic forgetting and effective disentanglement, we propose a novel method, 'Double Mixture.' This method merges speech expertise with robust memory mechanisms to enhance adaptability and prevent forgetting. Our comprehensive experiments show that this task presents significant challenges that are not effectively addressed by current state-of-the-art methods in either computer vision or natural language processing. Our approach achieves the lowest rates of forgetting and the highest levels of generalization, proving robust across various continual learning sequences. Our code and data are available at https://anonymous.4open.science/status/Continual-SpeechED-6461. ",
    "url": "https://arxiv.org/abs/2404.13289",
    "authors": [
      "Jingqi Kang",
      "Tongtong Wu",
      "Jinming Zhao",
      "Guitao Wang",
      "Yinwei Wei",
      "Hao Yang",
      "Guilin Qi",
      "Yuan-Fang Li",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.13308",
    "title": "ABACUS: An Impairment Aware Joint Optimal Dynamic RMLSA in Elastic  Optical Networks",
    "abstract": "The challenge of optimal Routing and Spectrum Assignment (RSA) is significant in Elastic Optical Networks. Integrating adaptive modulation formats into the RSA problem - Routing, Modulation Level, and Spectrum Assignment - broadens allocation options and increases complexity. The conventional RSA approach entails predetermining fixed paths and then allocating spectrum within them separately. However, expanding the path set for optimality may not be advisable due to the substantial increase in paths with network size expansion. This paper delves into a novel approach called RMLSA, which proposes a comprehensive solution addressing both route determination and spectrum assignment simultaneously. An objective function named ABACUS, Adaptive Balance of Average Clustering and Utilization of Spectrum, is chosen for its capability to adjust and assign significance to average clustering and spectrum utilization. Our approach involves formulating an Integer Linear Programming model with a straightforward relationship between path and spectrum constraints. The model also integrates Physical Layer Impairments to ensure end-to-end Quality of Transmission for requested connections while maintaining existing ones. We demonstrate that ILP can offer an optimal solution for a dynamic traffic scenario within a reasonable time complexity. To achieve this goal, we adopt a structured formulation approach where essential information is determined beforehand, thus minimizing the need for online computations. ",
    "url": "https://arxiv.org/abs/2404.13308",
    "authors": [
      "M Jyothi Kiran",
      "Venkatesh Chebolu",
      "Goutam Das",
      "Raja Datta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.13318",
    "title": "EHRFL: Federated Learning Framework for Heterogeneous EHRs and  Precision-guided Selection of Participating Clients",
    "abstract": "In this study, we provide solutions to two practical yet overlooked scenarios in federated learning for electronic health records (EHRs): firstly, we introduce EHRFL, a framework that facilitates federated learning across healthcare institutions with distinct medical coding systems and database schemas using text-based linearization of EHRs. Secondly, we focus on a scenario where a single healthcare institution initiates federated learning to build a model tailored for itself, in which the number of clients must be optimized in order to reduce expenses incurred by the host. For selecting participating clients, we present a novel precision-based method, leveraging data latents to identify suitable participants for the institution. Our empirical results show that EHRFL effectively enables federated learning across hospitals with different EHR systems. Furthermore, our results demonstrate the efficacy of our precision-based method in selecting reduced number of participating clients without compromising model performance, resulting in lower operational costs when constructing institution-specific models. We believe this work lays a foundation for the broader adoption of federated learning on EHRs. ",
    "url": "https://arxiv.org/abs/2404.13318",
    "authors": [
      "Jiyoun Kim",
      "Junu Kim",
      "Kyunghoon Hur",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13320",
    "title": "Pixel is a Barrier: Diffusion Models Are More Adversarially Robust Than  We Think",
    "abstract": "Adversarial examples for diffusion models are widely used as solutions for safety concerns. By adding adversarial perturbations to personal images, attackers can not edit or imitate them easily. However, it is essential to note that all these protections target the latent diffusion model (LDMs), the adversarial examples for diffusion models in the pixel space (PDMs) are largely overlooked. This may mislead us to think that the diffusion models are vulnerable to adversarial attacks like most deep models. In this paper, we show novel findings that: even though gradient-based white-box attacks can be used to attack the LDMs, they fail to attack PDMs. This finding is supported by extensive experiments of almost a wide range of attacking methods on various PDMs and LDMs with different model structures, which means diffusion models are indeed much more robust against adversarial attacks. We also find that PDMs can be used as an off-the-shelf purifier to effectively remove the adversarial patterns that were generated on LDMs to protect the images, which means that most protection methods nowadays, to some extent, cannot protect our images from malicious attacks. We hope that our insights will inspire the community to rethink the adversarial samples for diffusion models as protection methods and move forward to more effective protection. Codes are available in https://github.com/xavihart/PDM-Pure. ",
    "url": "https://arxiv.org/abs/2404.13320",
    "authors": [
      "Haotian Xue",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13322",
    "title": "MergeNet: Knowledge Migration across Heterogeneous Models, Tasks, and  Modalities",
    "abstract": "In this study, we focus on heterogeneous knowledge transfer across entirely different model architectures, tasks, and modalities. Existing knowledge transfer methods (e.g., backbone sharing, knowledge distillation) often hinge on shared elements within model structures or task-specific features/labels, limiting transfers to complex model types or tasks. To overcome these challenges, we present MergeNet, which learns to bridge the gap of parameter spaces of heterogeneous models, facilitating the direct interaction, extraction, and application of knowledge within these parameter spaces. The core mechanism of MergeNet lies in the parameter adapter, which operates by querying the source model's low-rank parameters and adeptly learning to identify and map parameters into the target model. MergeNet is learned alongside both models, allowing our framework to dynamically transfer and adapt knowledge relevant to the current stage, including the training trajectory knowledge of the source model. Extensive experiments on heterogeneous knowledge transfer demonstrate significant improvements in challenging settings, where representative approaches may falter or prove less applicable. ",
    "url": "https://arxiv.org/abs/2404.13322",
    "authors": [
      "Kunxi Li",
      "Tianyu Zhan",
      "Shengyu Zhang",
      "Kun Kuang",
      "Jiwei Li",
      "Zhou Zhao",
      "Fei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13325",
    "title": "Integrating Physics-Informed Neural Networks into Power System Dynamic  Simulations",
    "abstract": "Time-domain simulations in power systems are crucial for ensuring power system stability and avoiding critical scenarios that could lead to blackouts. The proliferation of converter-connected resources, however, adds significant additional degrees of non-linearity and complexity to these simulations. This drastically increases the computational time and the number of critical scenarios to be considered. Physics-Informed Neural Networks (PINN) have been shown to accelerate these simulations by several orders of magnitude. This paper introduces the first natural step to remove the barriers for using PINNs in time-domain simulations: it proposes the first method to integrate PINNs in conventional numerical solvers. Integrating PINNs into conventional solvers unlocks a wide range of opportunities. First, PINNs can substantially accelerate simulation time, second, the modeling of components with PINNs allows new ways to reduce privacy concerns when sharing models, and last, enhance the applicability of PINN-based surrogate modeling. We demonstrate the training, integration, and simulation framework for several combinations of PINNs and numerical solution methods, using the IEEE 9-bus system. ",
    "url": "https://arxiv.org/abs/2404.13325",
    "authors": [
      "Ignasi Ventura Nadal",
      "Jochen Stiasny",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.13337",
    "title": "Fuzzychain: An Equitable Consensus Mechanism for Blockchain Networks",
    "abstract": "Blockchain technology has become a trusted method for establishing secure and transparent transactions through a distributed, encrypted network. The operation of blockchain is governed by consensus algorithms, among which Proof of Stake (PoS) is popular yet has its drawbacks, notably the potential for centralising power in nodes with larger stakes or higher rewards. Fuzzychain, our proposed solution, introduces the use of fuzzy sets to define stake semantics, promoting decentralised and distributed processing control. This system selects validators based on their degree of membership to the stake fuzzy sets rather than just the size of their stakes. As a pioneer proposal in applying fuzzy sets to blockchain, Fuzzychain aims to rectify PoS's limitations. Our results indicate that Fuzzychain not only matches PoS in functionality but also ensures a fairer distribution of stakes among validators, leading to more inclusive validator selection and a better-distributed network. ",
    "url": "https://arxiv.org/abs/2404.13337",
    "authors": [
      "Bruno Ramos-Cruz",
      "Javier Andreu-P\u00e9rez",
      "Francisco J. Quesada",
      "Luis Mart\u00ednez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2404.13342",
    "title": "Hyperspectral Anomaly Detection with Self-Supervised Anomaly Prior",
    "abstract": "The majority of existing hyperspectral anomaly detection (HAD) methods use the low-rank representation (LRR) model to separate the background and anomaly components, where the anomaly component is optimized by handcrafted sparse priors (e.g., $\\ell_{2,1}$-norm). However, this may not be ideal since they overlook the spatial structure present in anomalies and make the detection result largely dependent on manually set sparsity. To tackle these problems, we redefine the optimization criterion for the anomaly component in the LRR model with a self-supervised network called self-supervised anomaly prior (SAP). This prior is obtained by the pretext task of self-supervised learning, which is customized to learn the characteristics of hyperspectral anomalies. Specifically, this pretext task is a classification task to distinguish the original hyperspectral image (HSI) and the pseudo-anomaly HSI, where the pseudo-anomaly is generated from the original HSI and designed as a prism with arbitrary polygon bases and arbitrary spectral bands. In addition, a dual-purified strategy is proposed to provide a more refined background representation with an enriched background dictionary, facilitating the separation of anomalies from complex backgrounds. Extensive experiments on various hyperspectral datasets demonstrate that the proposed SAP offers a more accurate and interpretable solution than other advanced HAD methods. ",
    "url": "https://arxiv.org/abs/2404.13342",
    "authors": [
      "Yidan Liu",
      "Weiying Xie",
      "Kai Jiang",
      "Jiaqing Zhang",
      "Yunsong Li",
      "Leyuan Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13343",
    "title": "UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty  and Response Time for Multiple-Choice Questions",
    "abstract": "This work explores a novel data augmentation method based on Large Language Models (LLMs) for predicting item difficulty and response time of retired USMLE Multiple-Choice Questions (MCQs) in the BEA 2024 Shared Task. Our approach is based on augmenting the dataset with answers from zero-shot LLMs (Falcon, Meditron, Mistral) and employing transformer-based models based on six alternative feature combinations. The results suggest that predicting the difficulty of questions is more challenging. Notably, our top performing methods consistently include the question text, and benefit from the variability of LLM answers, highlighting the potential of LLMs for improving automated assessment in medical licensing exams. We make our code available https://github.com/ana-rogoz/BEA-2024. ",
    "url": "https://arxiv.org/abs/2404.13343",
    "authors": [
      "Ana-Cristina Rogoz",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13344",
    "title": "GRANOLA: Adaptive Normalization for Graph Neural Networks",
    "abstract": "In recent years, significant efforts have been made to refine the design of Graph Neural Network (GNN) layers, aiming to overcome diverse challenges, such as limited expressive power and oversmoothing. Despite their widespread adoption, the incorporation of off-the-shelf normalization layers like BatchNorm or InstanceNorm within a GNN architecture may not effectively capture the unique characteristics of graph-structured data, potentially reducing the expressive power of the overall architecture. Moreover, existing graph-specific normalization layers often struggle to offer substantial and consistent benefits. In this paper, we propose GRANOLA, a novel graph-adaptive normalization layer. Unlike existing normalization layers, GRANOLA normalizes node features by adapting to the specific characteristics of the graph, particularly by generating expressive representations of its neighborhood structure, obtained by leveraging the propagation of Random Node Features (RNF) in the graph. We present theoretical results that support our design choices. Our extensive empirical evaluation of various graph benchmarks underscores the superior performance of GRANOLA over existing normalization techniques. Furthermore, GRANOLA emerges as the top-performing method among all baselines within the same time complexity of Message Passing Neural Networks (MPNNs). ",
    "url": "https://arxiv.org/abs/2404.13344",
    "authors": [
      "Moshe Eliasof",
      "Beatrice Bevilacqua",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13346",
    "title": "EC-SLAM: Real-time Dense Neural RGB-D SLAM System with Effectively  Constrained Global Bundle Adjustment",
    "abstract": "We introduce EC-SLAM, a real-time dense RGB-D simultaneous localization and mapping (SLAM) system utilizing Neural Radiance Fields (NeRF). Although recent NeRF-based SLAM systems have demonstrated encouraging outcomes, they have yet to completely leverage NeRF's capability to constrain pose optimization. By employing an effectively constrained global bundle adjustment (BA) strategy, our system makes use of NeRF's implicit loop closure correction capability. This improves the tracking accuracy by reinforcing the constraints on the keyframes that are most pertinent to the optimized current frame. In addition, by implementing a feature-based and uniform sampling strategy that minimizes the number of ineffective constraint points for pose optimization, we mitigate the effects of random sampling in NeRF. EC-SLAM utilizes sparse parametric encodings and the truncated signed distance field (TSDF) to represent the map in order to facilitate efficient fusion, resulting in reduced model parameters and accelerated convergence velocity. A comprehensive evaluation conducted on the Replica, ScanNet, and TUM datasets showcases cutting-edge performance, including enhanced reconstruction accuracy resulting from precise pose estimation, 21 Hz run time, and tracking precision improvements of up to 50\\%. The source code is available at https://github.com/Lightingooo/EC-SLAM. ",
    "url": "https://arxiv.org/abs/2404.13346",
    "authors": [
      "Guanghao Li",
      "Qi Chen",
      "YuXiang Yan",
      "Jian Pu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.13349",
    "title": "Breaking the Memory Wall for Heterogeneous Federated Learning with  Progressive Training",
    "abstract": "This paper presents ProFL, a novel progressive FL framework to effectively break the memory wall. Specifically, ProFL divides the model into different blocks based on its original architecture. Instead of updating the full model in each training round, ProFL first trains the front blocks and safely freezes them after convergence. Training of the next block is then triggered. This process iterates until the training of the whole model is completed. In this way, the memory footprint is effectively reduced for feasible deployment on heterogeneous devices. In order to preserve the feature representation of each block, we decouple the whole training process into two stages: progressive model shrinking and progressive model growing. During the progressive model shrinking stage, we meticulously design corresponding output modules to assist each block in learning the expected feature representation and obtain the initialization parameters. Then, the obtained output modules are utilized in the corresponding progressive model growing stage. Additionally, to control the training pace for each block, a novel metric from the scalar perspective is proposed to assess the learning status of each block and determines when to trigger the training of the next one. Finally, we theoretically prove the convergence of ProFL and conduct extensive experiments on representative models and datasets to evaluate the effectiveness of ProFL. The results demonstrate that ProFL effectively reduces the peak memory footprint by up to 57.4% and improves model accuracy by up to 82.4%. ",
    "url": "https://arxiv.org/abs/2404.13349",
    "authors": [
      "Yebo Wu",
      "Li Li",
      "Chunlin Tian",
      "Chengzhong Xu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13377",
    "title": "Bridging the Gap Between Theory and Practice: Benchmarking Transfer  Evolutionary Optimization",
    "abstract": "In recent years, the field of Transfer Evolutionary Optimization (TrEO) has witnessed substantial growth, fueled by the realization of its profound impact on solving complex problems. Numerous algorithms have emerged to address the challenges posed by transferring knowledge between tasks. However, the recently highlighted ``no free lunch theorem'' in transfer optimization clarifies that no single algorithm reigns supreme across diverse problem types. This paper addresses this conundrum by adopting a benchmarking approach to evaluate the performance of various TrEO algorithms in realistic scenarios. Despite the growing methodological focus on transfer optimization, existing benchmark problems often fall short due to inadequate design, predominantly featuring synthetic problems that lack real-world relevance. This paper pioneers a practical TrEO benchmark suite, integrating problems from the literature categorized based on the three essential aspects of Big Source Task-Instances: volume, variety, and velocity. Our primary objective is to provide a comprehensive analysis of existing TrEO algorithms and pave the way for the development of new approaches to tackle practical challenges. By introducing realistic benchmarks that embody the three dimensions of volume, variety, and velocity, we aim to foster a deeper understanding of algorithmic performance in the face of diverse and complex transfer scenarios. This benchmark suite is poised to serve as a valuable resource for researchers, facilitating the refinement and advancement of TrEO algorithms in the pursuit of solving real-world problems. ",
    "url": "https://arxiv.org/abs/2404.13377",
    "authors": [
      "Yaqing Hou",
      "Wenqiang Ma",
      "Abhishek Gupta",
      "Kavitesh Kumar Bali",
      "Hongwei Ge",
      "Qiang Zhang",
      "Carlos A. Coello Coello",
      "Yew-Soon Ong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2404.13378",
    "title": "Social Force Embedded Mixed Graph Convolutional Network for Multi-class  Trajectory Prediction",
    "abstract": "Accurate prediction of agent motion trajectories is crucial for autonomous driving, contributing to the reduction of collision risks in human-vehicle interactions and ensuring ample response time for other traffic participants. Current research predominantly focuses on traditional deep learning methods, including convolutional neural networks (CNNs) and recurrent neural networks (RNNs). These methods leverage relative distances to forecast the motion trajectories of a single class of agents. However, in complex traffic scenarios, the motion patterns of various types of traffic participants exhibit inherent randomness and uncertainty. Relying solely on relative distances may not adequately capture the nuanced interaction patterns between different classes of road users. In this paper, we propose a novel multi-class trajectory prediction method named the social force embedded mixed graph convolutional network (SFEM-GCN). SFEM-GCN comprises three graph topologies: the semantic graph (SG), position graph (PG), and velocity graph (VG). These graphs encode various of social force relationships among different classes of agents in complex scenes. Specifically, SG utilizes one-hot encoding of agent-class information to guide the construction of graph adjacency matrices based on semantic information. PG and VG create adjacency matrices to capture motion interaction relationships between different classes agents. These graph structures are then integrated into a mixed graph, where learning is conducted using a spatiotemporal graph convolutional neural network (ST-GCNN). To further enhance prediction performance, we adopt temporal convolutional networks (TCNs) to generate the predicted trajectory with fewer parameters. Experimental results on publicly available datasets demonstrate that SFEM-GCN surpasses state-of-the-art methods in terms of accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2404.13378",
    "authors": [
      "Quancheng Du",
      "Xiao Wang",
      "Shouguo Yin",
      "Lingxi Li",
      "Huansheng Ning"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.13381",
    "title": "DNA: Differentially private Neural Augmentation for contact tracing",
    "abstract": "The COVID19 pandemic had enormous economic and societal consequences. Contact tracing is an effective way to reduce infection rates by detecting potential virus carriers early. However, this was not generally adopted in the recent pandemic, and privacy concerns are cited as the most important reason. We substantially improve the privacy guarantees of the current state of the art in decentralized contact tracing. Whereas previous work was based on statistical inference only, we augment the inference with a learned neural network and ensure that this neural augmentation satisfies differential privacy. In a simulator for COVID19, even at epsilon=1 per message, this can significantly improve the detection of potentially infected individuals and, as a result of targeted testing, reduce infection rates. This work marks an important first step in integrating deep learning into contact tracing while maintaining essential privacy guarantees. ",
    "url": "https://arxiv.org/abs/2404.13381",
    "authors": [
      "Rob Romijnders",
      "Christos Louizos",
      "Yuki M. Asano",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2404.13402",
    "title": "Intrusion Detection at Scale with the Assistance of a Command-line  Language Model",
    "abstract": "Intrusion detection is a long standing and crucial problem in security. A system capable of detecting intrusions automatically is on great demand in enterprise security solutions. Existing solutions rely heavily on hand-crafted rules designed by security operators, which suffer from high false negative rates and poor generalization ability to new, zero-day attacks at scale. AI and machine learning offer promising solutions to address the issues, by inspecting abnormal user behaviors intelligently and automatically from data. However, existing learning-based intrusion detection systems in the literature are mostly designed for small data, and they lack the ability to leverage the power of big data in cloud environments. In this paper, we target at this problem and introduce an intrusion detection system which incorporates large-scale pre-training, so as to train a large language model based on tens of millions of command lines for AI-based intrusion detection. Experiments performed on 30 million training samples and 10 million test samples verify the effectiveness of our solution. ",
    "url": "https://arxiv.org/abs/2404.13402",
    "authors": [
      "Jiongliang Lin",
      "Yiwen Guo",
      "Hao Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.13407",
    "title": "A Framework for Managing Multifaceted Privacy Leakage While Optimizing  Utility in Continuous LBS Interactions",
    "abstract": "Privacy in Location-Based Services (LBS) has become a paramount concern with the ubiquity of mobile devices and the increasing integration of location data into various applications. In this paper, we present several novel contributions aimed at advancing the understanding and management of privacy leakage in LBS. Our contributions provides a more comprehensive framework for analyzing privacy concerns across different facets of location-based interactions. Specifically, we introduce $(\\epsilon, \\delta)$-location privacy, $(\\epsilon, \\delta, \\theta)$-trajectory privacy, and $(\\epsilon, \\delta, \\theta)$-POI privacy, which offer refined mechanisms for quantifying privacy risks associated with location, trajectory, and points of interest when continuously interacting with LBS. Furthermore, we establish fundamental connections between these privacy notions, facilitating a holistic approach to privacy preservation in LBS. Additionally, we present a lower bound analysis to evaluate the utility of the proposed privacy-preserving mechanisms, offering insights into the trade-offs between privacy protection and data utility. Finally, we instantiate our framework with the Plannar Isotopic Mechanism to demonstrate its practical applicability while ensuring optimal utility and quantifying privacy leakages across various dimensions. The conducted evaluations provide a comprehensive insight into the efficacy of our framework in capturing privacy loss on location, trajectory, and Points of Interest (POI) while facilitating quantification of the ensured accuracy. ",
    "url": "https://arxiv.org/abs/2404.13407",
    "authors": [
      "Anis Bkakria",
      "Reda Yaich"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.13417",
    "title": "Efficient and Concise Explanations for Object Detection with  Gaussian-Class Activation Mapping Explainer",
    "abstract": "To address the challenges of providing quick and plausible explanations in Explainable AI (XAI) for object detection models, we introduce the Gaussian Class Activation Mapping Explainer (G-CAME). Our method efficiently generates concise saliency maps by utilizing activation maps from selected layers and applying a Gaussian kernel to emphasize critical image regions for the predicted object. Compared with other Region-based approaches, G-CAME significantly reduces explanation time to 0.5 seconds without compromising the quality. Our evaluation of G-CAME, using Faster-RCNN and YOLOX on the MS-COCO 2017 dataset, demonstrates its ability to offer highly plausible and faithful explanations, especially in reducing the bias on tiny object detection. ",
    "url": "https://arxiv.org/abs/2404.13417",
    "authors": [
      "Quoc Khanh Nguyen",
      "Truong Thanh Hung Nguyen",
      "Vo Thanh Khang Nguyen",
      "Van Binh Truong",
      "Tuong Phan",
      "Hung Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13420",
    "title": "NeurCADRecon: Neural Representation for Reconstructing CAD Surfaces by  Enforcing Zero Gaussian Curvature",
    "abstract": "Despite recent advances in reconstructing an organic model with the neural signed distance function (SDF), the high-fidelity reconstruction of a CAD model directly from low-quality unoriented point clouds remains a significant challenge. In this paper, we address this challenge based on the prior observation that the surface of a CAD model is generally composed of piecewise surface patches, each approximately developable even around the feature line. Our approach, named NeurCADRecon, is self-supervised, and its loss includes a developability term to encourage the Gaussian curvature toward 0 while ensuring fidelity to the input points. Noticing that the Gaussian curvature is non-zero at tip points, we introduce a double-trough curve to tolerate the existence of these tip points. Furthermore, we develop a dynamic sampling strategy to deal with situations where the given points are incomplete or too sparse. Since our resulting neural SDFs can clearly manifest sharp feature points/lines, one can easily extract the feature-aligned triangle mesh from the SDF and then decompose it into smooth surface patches, greatly reducing the difficulty of recovering the parametric CAD design. A comprehensive comparison with existing state-of-the-art methods shows the significant advantage of our approach in reconstructing faithful CAD shapes. ",
    "url": "https://arxiv.org/abs/2404.13420",
    "authors": [
      "Qiujie Dong",
      "Rui Xu",
      "Pengfei Wang",
      "Shuangmin Chen",
      "Shiqing Xin",
      "Xiaohong Jia",
      "Wenping Wang",
      "Changhe Tu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13425",
    "title": "AdvLoRA: Adversarial Low-Rank Adaptation of Vision-Language Models",
    "abstract": "Vision-Language Models (VLMs) are a significant technique for Artificial General Intelligence (AGI). With the fast growth of AGI, the security problem become one of the most important challenges for VLMs. In this paper, through extensive experiments, we demonstrate the vulnerability of the conventional adaptation methods for VLMs, which may bring significant security risks. In addition, as the size of the VLMs increases, performing conventional adversarial adaptation techniques on VLMs results in high computational costs. To solve these problems, we propose a parameter-efficient \\underline{Adv}ersarial adaptation method named \\underline{AdvLoRA} by \\underline{Lo}w-\\underline{R}ank \\underline{A}daptation. At first, we investigate and reveal the intrinsic low-rank property during the adversarial adaptation for VLMs. Different from LoRA, we improve the efficiency and robustness of adversarial adaptation by designing a novel reparameterizing method based on parameter clustering and parameter alignment. In addition, an adaptive parameter update strategy is proposed to further improve the robustness. By these settings, our proposed AdvLoRA alleviates the model security and high resource waste problems. Extensive experiments demonstrate the effectiveness and efficiency of the AdvLoRA. ",
    "url": "https://arxiv.org/abs/2404.13425",
    "authors": [
      "Yuheng Ji",
      "Yue Liu",
      "Zhicheng Zhang",
      "Zhao Zhang",
      "Yuting Zhao",
      "Gang Zhou",
      "Xingwei Zhang",
      "Xinwang Liu",
      "Xiaolong Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13426",
    "title": "Data Privacy Vocabulary (DPV) -- Version 2",
    "abstract": "The Data Privacy Vocabulary (DPV), developed by the W3C Data Privacy Vocabularies and Controls Community Group (DPVCG), enables the creation of machine-readable, interoperable, and standards-based representations for describing the processing of personal data. The group has also published extensions to the DPV to describe specific applications to support legislative requirements such as the EU's GDPR. The DPV fills a crucial niche in the state of the art by providing a vocabulary that can be embedded and used alongside other existing standards such as W3C ODRL, and which can be customised and extended for adapting to specifics of use-cases or domains. This article describes the version 2 iteration of the DPV in terms of its contents, methodology, current adoptions and uses, and future potential. It also describes the relevance and role of DPV in acting as a common vocabulary to support various regulatory (e.g. EU's DGA and AI Act) and community initiatives (e.g. Solid) emerging across the globe. ",
    "url": "https://arxiv.org/abs/2404.13426",
    "authors": [
      "Harshvardhan J. Pandit",
      "Beatriz Esteves",
      "Georg P. Krog",
      "Paul Ryan",
      "Delaram Golpayegani",
      "Julian Flake"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2404.13437",
    "title": "High-fidelity Endoscopic Image Synthesis by Utilizing Depth-guided  Neural Surfaces",
    "abstract": "In surgical oncology, screening colonoscopy plays a pivotal role in providing diagnostic assistance, such as biopsy, and facilitating surgical navigation, particularly in polyp detection. Computer-assisted endoscopic surgery has recently gained attention and amalgamated various 3D computer vision techniques, including camera localization, depth estimation, surface reconstruction, etc. Neural Radiance Fields (NeRFs) and Neural Implicit Surfaces (NeuS) have emerged as promising methodologies for deriving accurate 3D surface models from sets of registered images, addressing the limitations of existing colon reconstruction approaches stemming from constrained camera movement. However, the inadequate tissue texture representation and confused scale problem in monocular colonoscopic image reconstruction still impede the progress of the final rendering results. In this paper, we introduce a novel method for colon section reconstruction by leveraging NeuS applied to endoscopic images, supplemented by a single frame of depth map. Notably, we pioneered the exploration of utilizing only one frame depth map in photorealistic reconstruction and neural rendering applications while this single depth map can be easily obtainable from other monocular depth estimation networks with an object scale. Through rigorous experimentation and validation on phantom imagery, our approach demonstrates exceptional accuracy in completely rendering colon sections, even capturing unseen portions of the surface. This breakthrough opens avenues for achieving stable and consistently scaled reconstructions, promising enhanced quality in cancer screening procedures and treatment interventions. ",
    "url": "https://arxiv.org/abs/2404.13437",
    "authors": [
      "Baoru Huang",
      "Yida Wang",
      "Anh Nguyen",
      "Daniel Elson",
      "Francisco Vasconcelos",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13443",
    "title": "FisheyeDetNet: Object Detection on Fisheye Surround View Camera Systems  for Automated Driving",
    "abstract": "Object detection is a mature problem in autonomous driving with pedestrian detection being one of the first deployed algorithms. It has been comprehensively studied in the literature. However, object detection is relatively less explored for fisheye cameras used for surround-view near field sensing. The standard bounding box representation fails in fisheye cameras due to heavy radial distortion, particularly in the periphery. To mitigate this, we explore extending the standard object detection output representation of bounding box. We design rotated bounding boxes, ellipse, generic polygon as polar arc/angle representations and define an instance segmentation mIOU metric to analyze these representations. The proposed model FisheyeDetNet with polygon outperforms others and achieves a mAP score of 49.5 % on Valeo fisheye surround-view dataset for automated driving applications. This dataset has 60K images captured from 4 surround-view cameras across Europe, North America and Asia. To the best of our knowledge, this is the first detailed study on object detection on fisheye cameras for autonomous driving scenarios. ",
    "url": "https://arxiv.org/abs/2404.13443",
    "authors": [
      "Ganesh Sistu",
      "Senthil Yogamani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.13445",
    "title": "DMesh: A Differentiable Representation for General Meshes",
    "abstract": "We present a differentiable representation, DMesh, for general 3D triangular meshes. DMesh considers both the geometry and connectivity information of a mesh. In our design, we first get a set of convex tetrahedra that compactly tessellates the domain based on Weighted Delaunay Triangulation (WDT), and formulate probability of faces to exist on our desired mesh in a differentiable manner based on the WDT. This enables DMesh to represent meshes of various topology in a differentiable way, and allows us to reconstruct the mesh under various observations, such as point cloud and multi-view images using gradient-based optimization. The source code and full paper is available at: https://sonsang.github.io/dmesh-project. ",
    "url": "https://arxiv.org/abs/2404.13445",
    "authors": [
      "Sanghyun Son",
      "Matheus Gadelha",
      "Yang Zhou",
      "Zexiang Xu",
      "Ming C. Lin",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2404.13456",
    "title": "Real-Time Safe Control of Neural Network Dynamic Models with Sound  Approximation",
    "abstract": "Safe control of neural network dynamic models (NNDMs) is important to robotics and many applications. However, it remains challenging to compute an optimal safe control in real time for NNDM. To enable real-time computation, we propose to use a sound approximation of the NNDM in the control synthesis. In particular, we propose Bernstein over-approximated neural dynamics (BOND) based on the Bernstein polynomial over-approximation (BPO) of ReLU activation functions in NNDM. To mitigate the errors introduced by the approximation and to ensure persistent feasibility of the safe control problems, we synthesize a worst-case safety index using the most unsafe approximated state within the BPO relaxation of NNDM offline. For the online real-time optimization, we formulate the first-order Taylor approximation of the nonlinear worst-case safety constraint as an additional linear layer of NNDM with the l2 bounded bias term for the higher-order remainder. Comprehensive experiments with different neural dynamics and safety constraints show that with safety guaranteed, our NNDMs with sound approximation are 10-100 times faster than the safe control baseline that uses mixed integer programming (MIP), validating the effectiveness of the worst-case safety index and scalability of the proposed BOND in real-time large-scale settings. ",
    "url": "https://arxiv.org/abs/2404.13456",
    "authors": [
      "Hanjiang Hu",
      "Jianglin Lan",
      "Changliu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.13477",
    "title": "Leveraging Adversarial Detection to Enable Scalable and Low Overhead  RowHammer Mitigations",
    "abstract": "RowHammer is a prime example of read disturbance in DRAM where repeatedly accessing (hammering) a row of DRAM cells (DRAM row) induces bitflips in other physically nearby DRAM rows. RowHammer solutions perform preventive actions (e.g., refresh neighbor rows of the hammered row) that mitigate such bitflips to preserve memory isolation, a fundamental building block of security and privacy in modern computing systems. However, preventive actions induce non-negligible memory request latency and system performance overheads as they interfere with memory requests in the memory controller. As shrinking technology node size over DRAM chip generations exacerbates RowHammer, the overheads of RowHammer solutions become prohibitively large. As a result, a malicious program can effectively hog the memory system and deny service to benign applications by causing many RowHammer preventive actions. In this work, we tackle the performance overheads of RowHammer solutions by tracking the generators of memory accesses that trigger RowHammer solutions. To this end, we propose BreakHammer. BreakHammer cooperates with existing RowHammer solutions to identify hardware threads that trigger preventive actions. To do so, BreakHammer estimates the RowHammer likelihood of a thread, based on how frequently it triggers RowHammer preventive actions. BreakHammer limits the number of on-the-fly requests a thread can inject into the memory system based on the thread's RowHammer likelihood. By doing so, BreakHammer significantly reduces the number of performed counter-measures, improves the system performance by an average (maximum) of 48.7% (105.5%), and reduces the maximum slowdown induced on a benign application by 14.6% with near-zero area overhead (e.g., 0.0002% of a highend processor's chip area). ",
    "url": "https://arxiv.org/abs/2404.13477",
    "authors": [
      "O\u011fuzhan Canpolat",
      "A. Giray Ya\u011fl\u0131k\u00e7\u0131",
      "Ataberk Olgun",
      "\u0130smail Emir Y\u00fcksel",
      "Yahya Can Tu\u011frul",
      "Konstantinos Kanellopoulos",
      "O\u011fuz Ergin",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2404.13489",
    "title": "SCHENO: Measuring Schema vs. Noise in Graphs",
    "abstract": "Real-world data is typically a noisy manifestation of a core pattern (\"schema\"), and the purpose of data mining algorithms is to uncover that pattern, thereby splitting (i.e. \"decomposing\") the data into schema and noise. We introduce SCHENO, a principled evaluation metric for the goodness of a schema-noise decomposition of a graph. SCHENO captures how schematic the schema is, how noisy the noise is, and how well the combination of the two represent the original graph data. We visually demonstrate what our metric prioritizes in small graphs, then show that if SCHENO is used as the fitness function for a simple genetic algorithm, we can uncover a wide variety of patterns. Finally, we evaluate several famous graph mining algorithms with our metric, finding that although they produce patterns, those patterns do not always represent the input data. ",
    "url": "https://arxiv.org/abs/2404.13489",
    "authors": [
      "Justus Isaiah Hibshman",
      "Adnan Hoq",
      "Tim Weninger"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2404.13504",
    "title": "IMO: Greedy Layer-Wise Sparse Representation Learning for  Out-of-Distribution Text Classification with Pre-trained Models",
    "abstract": "Machine learning models have made incredible progress, but they still struggle when applied to examples from unseen domains. This study focuses on a specific problem of domain generalization, where a model is trained on one source domain and tested on multiple target domains that are unseen during training. We propose IMO: Invariant features Masks for Out-of-Distribution text classification, to achieve OOD generalization by learning invariant features. During training, IMO would learn sparse mask layers to remove irrelevant features for prediction, where the remaining features keep invariant. Additionally, IMO has an attention module at the token level to focus on tokens that are useful for prediction. Our comprehensive experiments show that IMO substantially outperforms strong baselines in terms of various evaluation metrics and settings. ",
    "url": "https://arxiv.org/abs/2404.13504",
    "authors": [
      "Tao Feng",
      "Lizhen Qu",
      "Zhuang Li",
      "Haolan Zhan",
      "Yuncheng Hua",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.13505",
    "title": "Dynamic in Static: Hybrid Visual Correspondence for Self-Supervised  Video Object Segmentation",
    "abstract": "Conventional video object segmentation (VOS) methods usually necessitate a substantial volume of pixel-level annotated video data for fully supervised learning. In this paper, we present HVC, a \\textbf{h}ybrid static-dynamic \\textbf{v}isual \\textbf{c}orrespondence framework for self-supervised VOS. HVC extracts pseudo-dynamic signals from static images, enabling an efficient and scalable VOS model. Our approach utilizes a minimalist fully-convolutional architecture to capture static-dynamic visual correspondence in image-cropped views. To achieve this objective, we present a unified self-supervised approach to learn visual representations of static-dynamic feature similarity. Firstly, we establish static correspondence by utilizing a priori coordinate information between cropped views to guide the formation of consistent static feature representations. Subsequently, we devise a concise convolutional layer to capture the forward / backward pseudo-dynamic signals between two views, serving as cues for dynamic representations. Finally, we propose a hybrid visual correspondence loss to learn joint static and dynamic consistency representations. Our approach, without bells and whistles, necessitates only one training session using static image data, significantly reducing memory consumption ($\\sim$16GB) and training time ($\\sim$\\textbf{2h}). Moreover, HVC achieves state-of-the-art performance in several self-supervised VOS benchmarks and additional video label propagation tasks. ",
    "url": "https://arxiv.org/abs/2404.13505",
    "authors": [
      "Gensheng Pei",
      "Yazhou Yao",
      "Jianbo Jiao",
      "Wenguan Wang",
      "Liqiang Nie",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13515",
    "title": "FedTrans: Efficient Federated Learning Over Heterogeneous Clients via  Model Transformation",
    "abstract": "Federated learning (FL) aims to train machine learning (ML) models across potentially millions of edge client devices. Yet, training and customizing models for FL clients is notoriously challenging due to the heterogeneity of client data, device capabilities, and the massive scale of clients, making individualized model exploration prohibitively expensive. State-of-the-art FL solutions personalize a globally trained model or concurrently train multiple models, but they often incur suboptimal model accuracy and huge training costs. In this paper, we introduce FedTrans, a multi-model FL training framework that automatically produces and trains high-accuracy, hardware-compatible models for individual clients at scale. FedTrans begins with a basic global model, identifies accuracy bottlenecks in model architectures during training, and then employs model transformation to derive new models for heterogeneous clients on the fly. It judiciously assigns models to individual clients while performing soft aggregation on multi-model updates to minimize total training costs. Our evaluations using realistic settings show that FedTrans improves individual client model accuracy by 14% - 72% while slashing training costs by 1.6X - 20X over state-of-the-art solutions. ",
    "url": "https://arxiv.org/abs/2404.13515",
    "authors": [
      "Yuxuan Zhu",
      "Jiachen Liu",
      "Mosharaf Chowdhury",
      "Fan Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2404.13518",
    "title": "Reliable Model Watermarking: Defending Against Theft without  Compromising on Evasion",
    "abstract": "With the rise of Machine Learning as a Service (MLaaS) platforms,safeguarding the intellectual property of deep learning models is becoming paramount. Among various protective measures, trigger set watermarking has emerged as a flexible and effective strategy for preventing unauthorized model distribution. However, this paper identifies an inherent flaw in the current paradigm of trigger set watermarking: evasion adversaries can readily exploit the shortcuts created by models memorizing watermark samples that deviate from the main task distribution, significantly impairing their generalization in adversarial settings. To counteract this, we leverage diffusion models to synthesize unrestricted adversarial examples as trigger sets. By learning the model to accurately recognize them, unique watermark behaviors are promoted through knowledge injection rather than error memorization, thus avoiding exploitable shortcuts. Furthermore, we uncover that the resistance of current trigger set watermarking against removal attacks primarily relies on significantly damaging the decision boundaries during embedding, intertwining unremovability with adverse impacts. By optimizing the knowledge transfer properties of protected models, our approach conveys watermark behaviors to extraction surrogates without aggressively decision boundary perturbation. Experimental results on CIFAR-10/100 and Imagenette datasets demonstrate the effectiveness of our method, showing not only improved robustness against evasion adversaries but also superior resistance to watermark removal attacks compared to state-of-the-art solutions. ",
    "url": "https://arxiv.org/abs/2404.13518",
    "authors": [
      "Hongyu Zhu",
      "Sichu Liang",
      "Wentao Hu",
      "Fangqi Li",
      "Ju Jia",
      "Shilin Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13521",
    "title": "Graph4GUI: Graph Neural Networks for Representing Graphical User  Interfaces",
    "abstract": "Present-day graphical user interfaces (GUIs) exhibit diverse arrangements of text, graphics, and interactive elements such as buttons and menus, but representations of GUIs have not kept up. They do not encapsulate both semantic and visuo-spatial relationships among elements. To seize machine learning's potential for GUIs more efficiently, Graph4GUI exploits graph neural networks to capture individual elements' properties and their semantic-visuo-spatial constraints in a layout. The learned representation demonstrated its effectiveness in multiple tasks, especially generating designs in a challenging GUI autocompletion task, which involved predicting the positions of remaining unplaced elements in a partially completed GUI. The new model's suggestions showed alignment and visual appeal superior to the baseline method and received higher subjective ratings for preference. Furthermore, we demonstrate the practical benefits and efficiency advantages designers perceive when utilizing our model as an autocompletion plug-in. ",
    "url": "https://arxiv.org/abs/2404.13521",
    "authors": [
      "Yue Jiang",
      "Changkong Zhou",
      "Vikas Garg",
      "Antti Oulasvirta"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13527",
    "title": "On the structure of envy-free orientations on graphs",
    "abstract": "Fair division is the problem of allocating a set of items among agents in a fair manner. One of the most sought-after fairness notions is envy-freeness (EF), requiring that no agent envies another's allocation. When items are indivisible, it ceases to exist, and envy-freeness up to any good (EFX) emerged as one of its strongest relaxations. The existence of EFX allocations is arguably the biggest open question within fair division. Recently, Christodoulou, Fiat, Koutsoupias, and Sgouritsa (EC 2023) introduced showed that EFX allocations exist for the case of graphical valuations where an instance is represented by a graph: nodes are agents, edges are goods, and each agent values only her incident edges. On the other hand, they showed NP-hardness for checking the existence of EFX orientation where every edge is allocated to one of its incident vertices, and asked for a characterization of graphs that exhibit EFX orientation regardless of the assigned valuations. In this paper, we make significant progress toward answering their question. We introduce the notion of strongly EFX orientable graphs -- graphs that have EFX orientations regardless of how much agents value the edges. We show a surprising connection between this property and the chromatic number of the graph, namely $\\chi(G)$ for graph $G$. In particular, we show that graphs with $\\chi(G)\\le 2$ are strongly EFX orientable, and those with $\\chi(G)>3$ are not strongly EFX orientable. We provide examples of strongly EFX orientable and non-strongly EFX orientable graphs of $\\chi(G)=3$ to prove tightness. Finally, we give a complete characterization of strong EFX orientability when restricted to binary valuations. ",
    "url": "https://arxiv.org/abs/2404.13527",
    "authors": [
      "Jinghan A Zeng",
      "Ruta Mehta"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2404.13532",
    "title": "SpringGrasp: An optimization pipeline for robust and compliant dexterous  pre-grasp synthesis",
    "abstract": "Generating stable and robust grasps on arbitrary objects is critical for dexterous robotic hands, marking a significant step towards advanced dexterous manipulation. Previous studies have mostly focused on improving differentiable grasping metrics with the assumption of precisely known object geometry. However, shape uncertainty is ubiquitous due to noisy and partial shape observations, which introduce challenges in grasp planning. We propose, SpringGrasp planner, a planner that considers uncertain observations of the object surface for synthesizing compliant dexterous grasps. A compliant dexterous grasp could minimize the effect of unexpected contact with the object, leading to more stable grasp with shape-uncertain objects. We introduce an analytical and differentiable metric, SpringGrasp metric, that evaluates the dynamic behavior of the entire compliant grasping process. Planning with SpringGrasp planner, our method achieves a grasp success rate of 89% from two viewpoints and 84% from a single viewpoints in experiment with a real robot on 14 common objects. Compared with a force-closure based planner, our method achieves at least 18% higher grasp success rate. ",
    "url": "https://arxiv.org/abs/2404.13532",
    "authors": [
      "Sirui Chen",
      "Jeannette Bohg",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.13555",
    "title": "Cell Phone Image-Based Persian Rice Detection and Classification Using  Deep Learning Techniques",
    "abstract": "This study introduces an innovative approach to classifying various types of Persian rice using image-based deep learning techniques, highlighting the practical application of everyday technology in food categorization. Recognizing the diversity of Persian rice and its culinary significance, we leveraged the capabilities of convolutional neural networks (CNNs), specifically by fine-tuning a ResNet model for accurate identification of different rice varieties and employing a U-Net architecture for precise segmentation of rice grains in bulk images. This dual-methodology framework allows for both individual grain classification and comprehensive analysis of bulk rice samples, addressing two crucial aspects of rice quality assessment. Utilizing images captured with consumer-grade cell phones reflects a realistic scenario in which individuals can leverage this technology for assistance with grocery shopping and meal preparation. The dataset, comprising various rice types photographed under natural conditions without professional lighting or equipment, presents a challenging yet practical classification problem. Our findings demonstrate the feasibility of using non-professional images for food classification and the potential of deep learning models, like ResNet and U-Net, to adapt to the nuances of everyday objects and textures. This study contributes to the field by providing insights into the applicability of image-based deep learning in daily life, specifically for enhancing consumer experiences and knowledge in food selection. Furthermore, it opens avenues for extending this approach to other food categories and practical applications, emphasizing the role of accessible technology in bridging the gap between sophisticated computational methods and everyday tasks. ",
    "url": "https://arxiv.org/abs/2404.13555",
    "authors": [
      "Mahmood Saeedi kelishami",
      "Amin Saeidi Kelishami",
      "Sajjad Saeedi Kelishami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13556",
    "title": "ChatRetriever: Adapting Large Language Models for Generalized and Robust  Conversational Dense Retrieval",
    "abstract": "Conversational search requires accurate interpretation of user intent from complex multi-turn contexts. This paper presents ChatRetriever, which inherits the strong generalization capability of large language models to robustly represent complex conversational sessions for dense retrieval. To achieve this, we propose a simple and effective dual-learning approach that adapts LLM for retrieval via contrastive learning while enhancing the complex session understanding through masked instruction tuning on high-quality conversational instruction tuning data. Extensive experiments on five conversational search benchmarks demonstrate that ChatRetriever substantially outperforms existing conversational dense retrievers, achieving state-of-the-art performance on par with LLM-based rewriting approaches. Furthermore, ChatRetriever exhibits superior robustness in handling diverse conversational contexts. Our work highlights the potential of adapting LLMs for retrieval with complex inputs like conversational search sessions and proposes an effective approach to advance this research direction. ",
    "url": "https://arxiv.org/abs/2404.13556",
    "authors": [
      "Kelong Mao",
      "Chenlong Deng",
      "Haonan Chen",
      "Fengran Mo",
      "Zheng Liu",
      "Tetsuya Sakai",
      "Zhicheng Dou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.13569",
    "title": "Musical Word Embedding for Music Tagging and Retrieval",
    "abstract": "Word embedding has become an essential means for text-based information retrieval. Typically, word embeddings are learned from large quantities of general and unstructured text data. However, in the domain of music, the word embedding may have difficulty understanding musical contexts or recognizing music-related entities like artists and tracks. To address this issue, we propose a new approach called Musical Word Embedding (MWE), which involves learning from various types of texts, including both everyday and music-related vocabulary. We integrate MWE into an audio-word joint representation framework for tagging and retrieving music, using words like tag, artist, and track that have different levels of musical specificity. Our experiments show that using a more specific musical word like track results in better retrieval performance, while using a less specific term like tag leads to better tagging performance. To balance this compromise, we suggest multi-prototype training that uses words with different levels of musical specificity jointly. We evaluate both word embedding and audio-word joint embedding on four tasks (tag rank prediction, music tagging, query-by-tag, and query-by-track) across two datasets (Million Song Dataset and MTG-Jamendo). Our findings show that the suggested MWE is more efficient and robust than the conventional word embedding. ",
    "url": "https://arxiv.org/abs/2404.13569",
    "authors": [
      "SeungHeon Doh",
      "Jongpil Lee",
      "Dasaem Jeong",
      "Juhan Nam"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.13571",
    "title": "Test-Time Training on Graphs with Large Language Models (LLMs)",
    "abstract": "Graph Neural Networks have demonstrated great success in various fields of multimedia. However, the distribution shift between the training and test data challenges the effectiveness of GNNs. To mitigate this challenge, Test-Time Training (TTT) has been proposed as a promising approach. Traditional TTT methods require a demanding unsupervised training strategy to capture the information from test to benefit the main task. Inspired by the great annotation ability of Large Language Models (LLMs) on Text-Attributed Graphs (TAGs), we propose to enhance the test-time training on graphs with LLMs as annotators. In this paper, we design a novel Test-Time Training pipeline, LLMTTT, which conducts the test-time adaptation under the annotations by LLMs on a carefully-selected node set. Specifically, LLMTTT introduces a hybrid active node selection strategy that considers not only node diversity and representativeness, but also prediction signals from the pre-trained model. Given annotations from LLMs, a two-stage training strategy is designed to tailor the test-time model with the limited and noisy labels. A theoretical analysis ensures the validity of our method and extensive experiments demonstrate that the proposed LLMTTT can achieve a significant performance improvement compared to existing Out-of-Distribution (OOD) generalization methods. ",
    "url": "https://arxiv.org/abs/2404.13571",
    "authors": [
      "Jiaxin Zhang",
      "Yiqi Wang",
      "Xihong Yang",
      "Siwei Wang",
      "Yu Feng",
      "Yu Shi",
      "Ruicaho Ren",
      "En Zhu",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13576",
    "title": "I2CANSAY:Inter-Class Analogical Augmentation and Intra-Class  Significance Analysis for Non-Exemplar Online Task-Free Continual Learning",
    "abstract": "Online task-free continual learning (OTFCL) is a more challenging variant of continual learning which emphasizes the gradual shift of task boundaries and learns in an online mode. Existing methods rely on a memory buffer composed of old samples to prevent forgetting. However,the use of memory buffers not only raises privacy concerns but also hinders the efficient learning of new samples. To address this problem, we propose a novel framework called I2CANSAY that gets rid of the dependence on memory buffers and efficiently learns the knowledge of new data from one-shot samples. Concretely, our framework comprises two main modules. Firstly, the Inter-Class Analogical Augmentation (ICAN) module generates diverse pseudo-features for old classes based on the inter-class analogy of feature distributions for different new classes, serving as a substitute for the memory buffer. Secondly, the Intra-Class Significance Analysis (ISAY) module analyzes the significance of attributes for each class via its distribution standard deviation, and generates the importance vector as a correction bias for the linear classifier, thereby enhancing the capability of learning from new samples. We run our experiments on four popular image classification datasets: CoRe50, CIFAR-10, CIFAR-100, and CUB-200, our approach outperforms the prior state-of-the-art by a large margin. ",
    "url": "https://arxiv.org/abs/2404.13576",
    "authors": [
      "Songlin Dong",
      "Yingjie Chen",
      "Yuhang He",
      "Yuhan Jin",
      "Alex C. Kot",
      "Yihong Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13581",
    "title": "Preliminary Investigation of SSL for Complex Work Activity Recognition  in Industrial Domain via MoIL",
    "abstract": "In this study, we investigate a new self-supervised learning (SSL) approach for complex work activity recognition using wearable sensors. Owing to the cost of labeled sensor data collection, SSL methods for human activity recognition (HAR) that effectively use unlabeled data for pretraining have attracted attention. However, applying prior SSL to complex work activities such as packaging works is challenging because the observed data vary considerably depending on situations such as the number of items to pack and the size of the items in the case of packaging works. In this study, we focus on sensor data corresponding to characteristic and necessary actions (sensor data motifs) in a specific activity such as a stretching packing tape action in an assembling a box activity, and \\textcolor{black}{try} to train a neural network in self-supervised learning so that it identifies occurrences of the characteristic actions, i.e., Motif Identification Learning (MoIL). The feature extractor in the network is used in the downstream task, i.e., work activity recognition, enabling precise activity recognition containing characteristic actions with limited labeled training data. The MoIL approach was evaluated on real-world work activity data and it achieved state-of-the-art performance under limited training labels. ",
    "url": "https://arxiv.org/abs/2404.13581",
    "authors": [
      "Qingxin Xia",
      "Takuya Maekawa",
      "Jaime Morales",
      "Takahiro Hara",
      "Hirotomo Oshima",
      "Masamitsu Fukuda",
      "Yasuo Namioka"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2404.13583",
    "title": "Radial Basis Function Neural Networks for Formation Control of Unmanned  Aerial Vehicles",
    "abstract": "This paper addresses the problem of controlling multiple unmanned aerial vehicles (UAVs) cooperating in a formation to carry out a complex task such as surface inspection. We first use the virtual leader-follower model to determine the topology and trajectory of the formation. A double-loop control system combining backstepping and sliding mode control techniques is then designed for the UAVs to track the trajectory. A radial basis function neural network (RBFNN) capable of estimating external disturbances is developed to enhance the robustness of the controller. The stability of the controller is proven by using the Lyapunov theorem. A number of comparisons and software-in-the-loop (SIL) tests have been conducted to evaluate the performance of the proposed controller. The results show that our controller not only outperforms other state-of-the-art controllers but is also sufficient for complex tasks of UAVs such as collecting surface data for inspection. The source code of our controller can be found at https://github.com/duynamrcv/rbf_bsmc ",
    "url": "https://arxiv.org/abs/2404.13583",
    "authors": [
      "Duy-Nam Bui",
      "Manh Duong Phung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.13595",
    "title": "Unsupervised Social Bot Detection via Structural Information Theory",
    "abstract": "Research on social bot detection plays a crucial role in maintaining the order and reliability of information dissemination while increasing trust in social interactions. The current mainstream social bot detection models rely on black-box neural network technology, e.g., Graph Neural Network, Transformer, etc., which lacks interpretability. In this work, we present UnDBot, a novel unsupervised, interpretable, yet effective and practical framework for detecting social bots. This framework is built upon structural information theory. We begin by designing three social relationship metrics that capture various aspects of social bot behaviors: Posting Type Distribution, Posting Influence, and Follow-to-follower Ratio. Three new relationships are utilized to construct a new, unified, and weighted social multi-relational graph, aiming to model the relevance of social user behaviors and discover long-distance correlations between users. Second, we introduce a novel method for optimizing heterogeneous structural entropy. This method involves the personalized aggregation of edge information from the social multi-relational graph to generate a two-dimensional encoding tree. The heterogeneous structural entropy facilitates decoding of the substantial structure of the social bots network and enables hierarchical clustering of social bots. Thirdly, a new community labeling method is presented to distinguish social bot communities by computing the user's stationary distribution, measuring user contributions to network structure, and counting the intensity of user aggregation within the community. Compared with ten representative social bot detection approaches, comprehensive experiments demonstrate the advantages of effectiveness and interpretability of UnDBot on four real social network datasets. ",
    "url": "https://arxiv.org/abs/2404.13595",
    "authors": [
      "Hao Peng",
      "Jingyun Zhang",
      "Xiang Huang",
      "Zhifeng Hao",
      "Angsheng Li",
      "Zhengtao Yu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2404.13598",
    "title": "An Integrated Communication and Computing Scheme for Wi-Fi Networks  based on Generative AI and Reinforcement Learning",
    "abstract": "The continuous evolution of future mobile communication systems is heading towards the integration of communication and computing, with Mobile Edge Computing (MEC) emerging as a crucial means of implementing Artificial Intelligence (AI) computation. MEC could enhance the computational performance of wireless edge networks by offloading computing-intensive tasks to MEC servers. However, in edge computing scenarios, the sparse sample problem may lead to high costs of time-consuming model training. This paper proposes an MEC offloading decision and resource allocation solution that combines generative AI and deep reinforcement learning (DRL) for the communication-computing integration scenario in the 802.11ax Wi-Fi network. Initially, the optimal offloading policy is determined by the joint use of the Generative Diffusion Model (GDM) and the Twin Delayed DDPG (TD3) algorithm. Subsequently, resource allocation is accomplished by using the Hungarian algorithm. Simulation results demonstrate that the introduction of Generative AI significantly reduces model training costs, and the proposed solution exhibits significant reductions in system task processing latency and total energy consumption costs. ",
    "url": "https://arxiv.org/abs/2404.13598",
    "authors": [
      "Xinyang Du",
      "Xuming Fang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.13604",
    "title": "CKGConv: General Graph Convolution with Continuous Kernels",
    "abstract": "The existing definitions of graph convolution, either from spatial or spectral perspectives, are inflexible and not unified. Defining a general convolution operator in the graph domain is challenging due to the lack of canonical coordinates, the presence of irregular structures, and the properties of graph symmetries. In this work, we propose a novel graph convolution framework by parameterizing the kernels as continuous functions of pseudo-coordinates derived via graph positional encoding. We name this Continuous Kernel Graph Convolution (CKGConv). Theoretically, we demonstrate that CKGConv is flexible and expressive. CKGConv encompasses many existing graph convolutions, and exhibits the same expressiveness as graph transformers in terms of distinguishing non-isomorphic graphs. Empirically, we show that CKGConv-based Networks outperform existing graph convolutional networks and perform comparably to the best graph transformers across a variety of graph datasets. ",
    "url": "https://arxiv.org/abs/2404.13604",
    "authors": [
      "Liheng Ma",
      "Soumyasundar Pal",
      "Yitian Zhang",
      "Jiaming Zhou",
      "Yingxue Zhang",
      "Mark Coates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13619",
    "title": "Towards Unified Representation of Multi-Modal Pre-training for 3D  Understanding via Differentiable Rendering",
    "abstract": "State-of-the-art 3D models, which excel in recognition tasks, typically depend on large-scale datasets and well-defined category sets. Recent advances in multi-modal pre-training have demonstrated potential in learning 3D representations by aligning features from 3D shapes with their 2D RGB or depth counterparts. However, these existing frameworks often rely solely on either RGB or depth images, limiting their effectiveness in harnessing a comprehensive range of multi-modal data for 3D applications. To tackle this challenge, we present DR-Point, a tri-modal pre-training framework that learns a unified representation of RGB images, depth images, and 3D point clouds by pre-training with object triplets garnered from each modality. To address the scarcity of such triplets, DR-Point employs differentiable rendering to obtain various depth images. This approach not only augments the supply of depth images but also enhances the accuracy of reconstructed point clouds, thereby promoting the representative learning of the Transformer backbone. Subsequently, using a limited number of synthetically generated triplets, DR-Point effectively learns a 3D representation space that aligns seamlessly with the RGB-Depth image space. Our extensive experiments demonstrate that DR-Point outperforms existing self-supervised learning methods in a wide range of downstream tasks, including 3D object classification, part segmentation, point cloud completion, semantic segmentation, and detection. Additionally, our ablation studies validate the effectiveness of DR-Point in enhancing point cloud understanding. ",
    "url": "https://arxiv.org/abs/2404.13619",
    "authors": [
      "Ben Fei",
      "Yixuan Li",
      "Weidong Yang",
      "Lipeng Ma",
      "Ying He"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2404.13621",
    "title": "Attack on Scene Flow using Point Clouds",
    "abstract": "Deep neural networks have made significant advancements in accurately estimating scene flow using point clouds, which is vital for many applications like video analysis, action recognition, and navigation. Robustness of these techniques, however, remains a concern, particularly in the face of adversarial attacks that have been proven to deceive state-of-the-art deep neural networks in many domains. Surprisingly, the robustness of scene flow networks against such attacks has not been thoroughly investigated. To address this problem, the proposed approach aims to bridge this gap by introducing adversarial white-box attacks specifically tailored for scene flow networks. Experimental results show that the generated adversarial examples obtain up to 33.7 relative degradation in average end-point error on the KITTI and FlyingThings3D datasets. The study also reveals the significant impact that attacks targeting point clouds in only one dimension or color channel have on average end-point error. Analyzing the success and failure of these attacks on the scene flow networks and their 2D optical flow network variants show a higher vulnerability for the optical flow networks. ",
    "url": "https://arxiv.org/abs/2404.13621",
    "authors": [
      "Haniyeh Ehsani Oskouie",
      "Mohammad-Shahram Moin",
      "Shohreh Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2404.13634",
    "title": "Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming  Generative Adversarial Networks",
    "abstract": "Synthetic data generation offers a promising solution to enhance the usefulness of Electronic Healthcare Records (EHR) by generating realistic de-identified data. However, the existing literature primarily focuses on the quality of synthetic health data, neglecting the crucial aspect of fairness in downstream predictions. Consequently, models trained on synthetic EHR have faced criticism for producing biased outcomes in target tasks. These biases can arise from either spurious correlations between features or the failure of models to accurately represent sub-groups. To address these concerns, we present Bias-transforming Generative Adversarial Networks (Bt-GAN), a GAN-based synthetic data generator specifically designed for the healthcare domain. In order to tackle spurious correlations (i), we propose an information-constrained Data Generation Process that enables the generator to learn a fair deterministic transformation based on a well-defined notion of algorithmic fairness. To overcome the challenge of capturing exact sub-group representations (ii), we incentivize the generator to preserve sub-group densities through score-based weighted sampling. This approach compels the generator to learn from underrepresented regions of the data manifold. We conduct extensive experiments using the MIMIC-III database. Our results demonstrate that Bt-GAN achieves SOTA accuracy while significantly improving fairness and minimizing bias amplification. We also perform an in-depth explainability analysis to provide additional evidence supporting the validity of our study. In conclusion, our research introduces a novel and professional approach to addressing the limitations of synthetic data generation in the healthcare domain. By incorporating fairness considerations and leveraging advanced techniques such as GANs, we pave the way for more reliable and unbiased predictions in healthcare applications. ",
    "url": "https://arxiv.org/abs/2404.13634",
    "authors": [
      "Resmi Ramachandranpillai",
      "Md Fahim Sikder",
      "David Bergstr\u00f6m",
      "Fredrik Heintz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13639",
    "title": "Performance Analysis for Deterministic System using Time Sensitive  Network",
    "abstract": "Modern technology necessitates the use of dependable, fast, and inexpensive networks as the backbone for data transmission. Switched Ethernet coupled with the Time Sensitive Networking ",
    "url": "https://arxiv.org/abs/2404.13639",
    "authors": [
      "Md Mehedi Hasan",
      "He Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.13646",
    "title": "Physics-informed Mesh-independent Deep Compositional Operator Network",
    "abstract": "Solving parametric Partial Differential Equations (PDEs) for a broad range of parameters is a critical challenge in scientific computing. To this end, neural operators, which learn mappings from parameters to solutions, have been successfully used. However, the training of neural operators typically demands large training datasets, the acquisition of which can be prohibitively expensive. To address this challenge, physics-informed training can offer a cost-effective strategy. However, current physics-informed neural operators face limitations, either in handling irregular domain shapes or in generalization to various discretizations of PDE parameters with variable mesh sizes. In this research, we introduce a novel physics-informed model architecture which can generalize to parameter discretizations of variable size and irregular domain shapes. Particularly, inspired by deep operator neural networks, our model involves a discretization-independent learning of parameter embedding repeatedly, and this parameter embedding is integrated with the response embeddings through multiple compositional layers, for more expressivity. Numerical results demonstrate the accuracy and efficiency of the proposed method. ",
    "url": "https://arxiv.org/abs/2404.13646",
    "authors": [
      "Weiheng Zhong",
      "Hadi Meidani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13647",
    "title": "Mean Aggregator Is More Robust Than Robust Aggregators Under Label  Poisoning Attacks",
    "abstract": "Robustness to malicious attacks is of paramount importance for distributed learning. Existing works often consider the classical Byzantine attacks model, which assumes that some workers can send arbitrarily malicious messages to the server and disturb the aggregation steps of the distributed learning process. To defend against such worst-case Byzantine attacks, various robust aggregators have been proven effective and much superior to the often-used mean aggregator. In this paper, we show that robust aggregators are too conservative for a class of weak but practical malicious attacks, as known as label poisoning attacks, where the sample labels of some workers are poisoned. Surprisingly, we are able to show that the mean aggregator is more robust than the state-of-the-art robust aggregators in theory, given that the distributed data are sufficiently heterogeneous. In fact, the learning error of the mean aggregator is proven to be optimal in order. Experimental results corroborate our theoretical findings, demonstrating the superiority of the mean aggregator under label poisoning attacks. ",
    "url": "https://arxiv.org/abs/2404.13647",
    "authors": [
      "Jie Peng",
      "Weiyu Li",
      "Qing Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13655",
    "title": "SPGNN: Recognizing Salient Subgraph Patterns via Enhanced Graph  Convolution and Pooling",
    "abstract": "Graph neural networks (GNNs) have revolutionized the field of machine learning on non-Euclidean data such as graphs and networks. GNNs effectively implement node representation learning through neighborhood aggregation and achieve impressive results in many graph-related tasks. However, most neighborhood aggregation approaches are summation-based, which can be problematic as they may not be sufficiently expressive to encode informative graph structures. Furthermore, though the graph pooling module is also of vital importance for graph learning, especially for the task of graph classification, research on graph down-sampling mechanisms is rather limited. To address the above challenges, we propose a concatenation-based graph convolution mechanism that injectively updates node representations to maximize the discriminative power in distinguishing non-isomorphic subgraphs. In addition, we design a novel graph pooling module, called WL-SortPool, to learn important subgraph patterns in a deep-learning manner. WL-SortPool layer-wise sorts node representations (i.e. continuous WL colors) to separately learn the relative importance of subtrees with different depths for the purpose of classification, thus better characterizing the complex graph topology and rich information encoded in the graph. We propose a novel Subgraph Pattern GNN (SPGNN) architecture that incorporates these enhancements. We test the proposed SPGNN architecture on many graph classification benchmarks. Experimental results show that our method can achieve highly competitive results with state-of-the-art graph kernels and other GNN approaches. ",
    "url": "https://arxiv.org/abs/2404.13655",
    "authors": [
      "Zehao Dong",
      "Muhan Zhang",
      "Yixin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13660",
    "title": "Trojan Detection in Large Language Models: Insights from The Trojan  Detection Challenge",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various domains, but their vulnerability to trojan or backdoor attacks poses significant security risks. This paper explores the challenges and insights gained from the Trojan Detection Competition 2023 (TDC2023), which focused on identifying and evaluating trojan attacks on LLMs. We investigate the difficulty of distinguishing between intended and unintended triggers, as well as the feasibility of reverse engineering trojans in real-world scenarios. Our comparative analysis of various trojan detection methods reveals that achieving high Recall scores is significantly more challenging than obtaining high Reverse-Engineering Attack Success Rate (REASR) scores. The top-performing methods in the competition achieved Recall scores around 0.16, comparable to a simple baseline of randomly sampling sentences from a distribution similar to the given training prefixes. This finding raises questions about the detectability and recoverability of trojans inserted into the model, given only the harmful targets. Despite the inability to fully solve the problem, the competition has led to interesting observations about the viability of trojan detection and improved techniques for optimizing LLM input prompts. The phenomenon of unintended triggers and the difficulty in distinguishing them from intended triggers highlights the need for further research into the robustness and interpretability of LLMs. The TDC2023 has provided valuable insights into the challenges and opportunities associated with trojan detection in LLMs, laying the groundwork for future research in this area to ensure their safety and reliability in real-world applications. ",
    "url": "https://arxiv.org/abs/2404.13660",
    "authors": [
      "Narek Maloyan",
      "Ekansh Verma",
      "Bulat Nutfullin",
      "Bislan Ashinov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.13671",
    "title": "FiLo: Zero-Shot Anomaly Detection by Fine-Grained Description and  High-Quality Localization",
    "abstract": "Zero-shot anomaly detection (ZSAD) methods entail detecting anomalies directly without access to any known normal or abnormal samples within the target item categories. Existing approaches typically rely on the robust generalization capabilities of multimodal pretrained models, computing similarities between manually crafted textual features representing \"normal\" or \"abnormal\" semantics and image features to detect anomalies and localize anomalous patches. However, the generic descriptions of \"abnormal\" often fail to precisely match diverse types of anomalies across different object categories. Additionally, computing feature similarities for single patches struggles to pinpoint specific locations of anomalies with various sizes and scales. To address these issues, we propose a novel ZSAD method called FiLo, comprising two components: adaptively learned Fine-Grained Description (FG-Des) and position-enhanced High-Quality Localization (HQ-Loc). FG-Des introduces fine-grained anomaly descriptions for each category using Large Language Models (LLMs) and employs adaptively learned textual templates to enhance the accuracy and interpretability of anomaly detection. HQ-Loc, utilizing Grounding DINO for preliminary localization, position-enhanced text prompts, and Multi-scale Multi-shape Cross-modal Interaction (MMCI) module, facilitates more accurate localization of anomalies of different sizes and shapes. Experimental results on datasets like MVTec and VisA demonstrate that FiLo significantly improves the performance of ZSAD in both detection and localization, achieving state-of-the-art performance with an image-level AUC of 83.9% and a pixel-level AUC of 95.9% on the VisA dataset. ",
    "url": "https://arxiv.org/abs/2404.13671",
    "authors": [
      "Zhaopeng Gu",
      "Bingke Zhu",
      "Guibo Zhu",
      "Yingying Chen",
      "Hao Li",
      "Ming Tang",
      "Jinqiao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13676",
    "title": "Lowest-degree robust finite element schemes for inhomogeneous bi-Laplace  problems",
    "abstract": "In this paper, we study the numerical method for the bi-Laplace problems with inhomogeneous coefficients; particularly, we propose finite element schemes on rectangular grids respectively for an inhomogeneous fourth-order elliptic singular perturbation problem and for the Helmholtz transmission eigenvalue problem. The new methods use the reduced rectangle Morley (RRM for short) element space with piecewise quadratic polynomials, which are of the lowest degree possible. For the finite element space, a discrete analogue of an equality by Grisvard is proved for the stability issue and a locally-averaged interpolation operator is constructed for the approximation issue. Optimal convergence rates of the schemes are proved, and numerical experiments are given to verify the theoretical analysis. ",
    "url": "https://arxiv.org/abs/2404.13676",
    "authors": [
      "Bin Dai",
      "Huilan Zeng",
      "Chensong Zhang",
      "Shuo Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2404.13678",
    "title": "Adaptive Social Force Window Planner with Reinforcement Learning",
    "abstract": "Human-aware navigation is a complex task for mobile robots, requiring an autonomous navigation system capable of achieving efficient path planning together with socially compliant behaviors. Social planners usually add costs or constraints to the objective function, leading to intricate tuning processes or tailoring the solution to the specific social scenario. Machine Learning can enhance planners' versatility and help them learn complex social behaviors from data. This work proposes an adaptive social planner, using a Deep Reinforcement Learning agent to dynamically adjust the weighting parameters of the cost function used to evaluate trajectories. The resulting planner combines the robustness of the classic Dynamic Window Approach, integrated with a social cost based on the Social Force Model, and the flexibility of learning methods to boost the overall performance on social navigation tasks. Our extensive experimentation on different environments demonstrates the general advantage of the proposed method over static cost planners. ",
    "url": "https://arxiv.org/abs/2404.13678",
    "authors": [
      "Mauro Martini",
      "No\u00e9 P\u00e9rez-Higueras",
      "Andrea Ostuni",
      "Marcello Chiaberge",
      "Fernando Caballero",
      "Luis Merino"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.13696",
    "title": "Clio: Real-time Task-Driven Open-Set 3D Scene Graphs",
    "abstract": "Modern tools for class-agnostic image segmentation (e.g., SegmentAnything) and open-set semantic understanding (e.g., CLIP) provide unprecedented opportunities for robot perception and mapping. While traditional closed-set metric-semantic maps were restricted to tens or hundreds of semantic classes, we can now build maps with a plethora of objects and countless semantic variations. This leaves us with a fundamental question: what is the right granularity for the objects (and, more generally, for the semantic concepts) the robot has to include in its map representation? While related work implicitly chooses a level of granularity by tuning thresholds for object detection, we argue that such a choice is intrinsically task-dependent. The first contribution of this paper is to propose a task-driven 3D scene understanding problem, where the robot is given a list of tasks in natural language and has to select the granularity and the subset of objects and scene structure to retain in its map that is sufficient to complete the tasks. We show that this problem can be naturally formulated using the Information Bottleneck (IB), an established information-theoretic framework. The second contribution is an algorithm for task-driven 3D scene understanding based on an Agglomerative IB approach, that is able to cluster 3D primitives in the environment into task-relevant objects and regions and executes incrementally. The third contribution is to integrate our task-driven clustering algorithm into a real-time pipeline, named Clio, that constructs a hierarchical 3D scene graph of the environment online using only onboard compute, as the robot explores it. Our final contribution is an extensive experimental campaign showing that Clio not only allows real-time construction of compact open-set 3D scene graphs, but also improves the accuracy of task execution by limiting the map to relevant semantic concepts. ",
    "url": "https://arxiv.org/abs/2404.13696",
    "authors": [
      "Dominic Maggio",
      "Yun Chang",
      "Nathan Hughes",
      "Matthew Trang",
      "Dan Griffith",
      "Carlyn Dougherty",
      "Eric Cristofalo",
      "Lukas Schmid",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.13711",
    "title": "ArtNeRF: A Stylized Neural Field for 3D-Aware Cartoonized Face Synthesis",
    "abstract": "Recent advances in generative visual models and neural radiance fields have greatly boosted 3D-aware image synthesis and stylization tasks. However, previous NeRF-based work is limited to single scene stylization, training a model to generate 3D-aware cartoon faces with arbitrary styles remains unsolved. We propose ArtNeRF, a novel face stylization framework derived from 3D-aware GAN to tackle this problem. In this framework, we utilize an expressive generator to synthesize stylized faces and a triple-branch discriminator module to improve the visual quality and style consistency of the generated faces. Specifically, a style encoder based on contrastive learning is leveraged to extract robust low-dimensional embeddings of style images, empowering the generator with the knowledge of various styles. To smooth the training process of cross-domain transfer learning, we propose an adaptive style blending module which helps inject style information and allows users to freely tune the level of stylization. We further introduce a neural rendering module to achieve efficient real-time rendering of images with higher resolutions. Extensive experiments demonstrate that ArtNeRF is versatile in generating high-quality 3D-aware cartoon faces with arbitrary styles. ",
    "url": "https://arxiv.org/abs/2404.13711",
    "authors": [
      "Zichen Tang",
      "Hongyu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13736",
    "title": "Interval Abstractions for Robust Counterfactual Explanations",
    "abstract": "Counterfactual Explanations (CEs) have emerged as a major paradigm in explainable AI research, providing recourse recommendations for users affected by the decisions of machine learning models. However, when slight changes occur in the parameters of the underlying model, CEs found by existing methods often become invalid for the updated models. The literature lacks a way to certify deterministic robustness guarantees for CEs under model changes, in that existing methods to improve CEs' robustness are heuristic, and the robustness performances are evaluated empirically using only a limited number of retrained models. To bridge this gap, we propose a novel interval abstraction technique for parametric machine learning models, which allows us to obtain provable robustness guarantees of CEs under the possibly infinite set of plausible model changes $\\Delta$. We formalise our robustness notion as the $\\Delta$-robustness for CEs, in both binary and multi-class classification settings. We formulate procedures to verify $\\Delta$-robustness based on Mixed Integer Linear Programming, using which we further propose two algorithms to generate CEs that are $\\Delta$-robust. In an extensive empirical study, we demonstrate how our approach can be used in practice by discussing two strategies for determining the appropriate hyperparameter in our method, and we quantitatively benchmark the CEs generated by eleven methods, highlighting the effectiveness of our algorithms in finding robust CEs. ",
    "url": "https://arxiv.org/abs/2404.13736",
    "authors": [
      "Junqi Jiang",
      "Francesco Leofante",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13745",
    "title": "A Nasal Cytology Dataset for Object Detection and Deep Learning",
    "abstract": "Nasal Cytology is a new and efficient clinical technique to diagnose rhinitis and allergies that is not much widespread due to the time-consuming nature of cell counting; that is why AI-aided counting could be a turning point for the diffusion of this technique. In this article we present the first dataset of rhino-cytological field images: the NCD (Nasal Cytology Dataset), aimed to train and deploy Object Detection models to support physicians and biologists during clinical practice. The real distribution of the cytotypes, populating the nasal mucosa has been replicated, sampling images from slides of clinical patients, and manually annotating each cell found on them. The correspondent object detection task presents non'trivial issues associated with the strong class imbalancement, involving the rarest cell types. This work contributes to some of open challenges by presenting a novel machine learning-based approach to aid the automated detection and classification of nasal mucosa cells: the DETR and YOLO models shown good performance in detecting cells and classifying them correctly, revealing great potential to accelerate the work of rhinology experts. ",
    "url": "https://arxiv.org/abs/2404.13745",
    "authors": [
      "Mauro Camporeale",
      "Giovanni Dimauro",
      "Matteo Gelardi",
      "Giorgia Iacobellis",
      "Mattia Sebastiano Ladisa",
      "Sergio Latrofa",
      "Nunzia Lomonte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13752",
    "title": "Towards General Conceptual Model Editing via Adversarial Representation  Engineering",
    "abstract": "Recent research has introduced Representation Engineering (RepE) as a promising approach for understanding complex inner workings of large-scale models like Large Language Models (LLMs). However, finding practical and efficient methods to apply these representations for general and flexible model editing remains an open problem. Inspired by the Generative Adversarial Network (GAN) framework, we introduce a novel approach called Adversarial Representation Engineering (ARE). This method leverages RepE by using a representation sensor to guide the editing of LLMs, offering a unified and interpretable framework for conceptual model editing without degrading baseline performance. Our experiments on multiple conceptual editing confirm ARE's effectiveness. Code and data are available at https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering. ",
    "url": "https://arxiv.org/abs/2404.13752",
    "authors": [
      "Yihao Zhang",
      "Zeming Wei",
      "Jun Sun",
      "Meng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2404.13779",
    "title": "Automated Text Mining of Experimental Methodologies from Biomedical  Literature",
    "abstract": "Biomedical literature is a rapidly expanding field of science and technology. Classification of biomedical texts is an essential part of biomedicine research, especially in the field of biology. This work proposes the fine-tuned DistilBERT, a methodology-specific, pre-trained generative classification language model for mining biomedicine texts. The model has proven its effectiveness in linguistic understanding capabilities and has reduced the size of BERT models by 40\\% but by 60\\% faster. The main objective of this project is to improve the model and assess the performance of the model compared to the non-fine-tuned model. We used DistilBert as a support model and pre-trained on a corpus of 32,000 abstracts and complete text articles; our results were impressive and surpassed those of traditional literature classification methods by using RNN or LSTM. Our aim is to integrate this highly specialised and specific model into different research industries. ",
    "url": "https://arxiv.org/abs/2404.13779",
    "authors": [
      "Ziqing Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13788",
    "title": "AnyPattern: Towards In-context Image Copy Detection",
    "abstract": "This paper explores in-context learning for image copy detection (ICD), i.e., prompting an ICD model to identify replicated images with new tampering patterns without the need for additional training. The prompts (or the contexts) are from a small set of image-replica pairs that reflect the new patterns and are used at inference time. Such in-context ICD has good realistic value, because it requires no fine-tuning and thus facilitates fast reaction against the emergence of unseen patterns. To accommodate the \"seen $\\rightarrow$ unseen\" generalization scenario, we construct the first large-scale pattern dataset named AnyPattern, which has the largest number of tamper patterns ($90$ for training and $10$ for testing) among all the existing ones. We benchmark AnyPattern with popular ICD methods and reveal that existing methods barely generalize to novel tamper patterns. We further propose a simple in-context ICD method named ImageStacker. ImageStacker learns to select the most representative image-replica pairs and employs them as the pattern prompts in a stacking manner (rather than the popular concatenation manner). Experimental results show (1) training with our large-scale dataset substantially benefits pattern generalization ($+26.66 \\%$ $\\mu AP$), (2) the proposed ImageStacker facilitates effective in-context ICD (another round of $+16.75 \\%$ $\\mu AP$), and (3) AnyPattern enables in-context ICD, i.e. without such a large-scale dataset, in-context learning does not emerge even with our ImageStacker. The project (including the proposed dataset AnyPattern and the code for ImageStacker) is publicly available at https://anypattern.github.io under the MIT Licence. ",
    "url": "https://arxiv.org/abs/2404.13788",
    "authors": [
      "Wenhao Wang",
      "Yifan Sun",
      "Zhentao Tan",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13793",
    "title": "Lightweight Connective Detection Using Gradient Boosting",
    "abstract": "In this work, we introduce a lightweight discourse connective detection system. Employing gradient boosting trained on straightforward, low-complexity features, this proposed approach sidesteps the computational demands of the current approaches that rely on deep neural networks. Considering its simplicity, our approach achieves competitive results while offering significant gains in terms of time even on CPU. Furthermore, the stable performance across two unrelated languages suggests the robustness of our system in the multilingual scenario. The model is designed to support the annotation of discourse relations, particularly in scenarios with limited resources, while minimizing performance loss. ",
    "url": "https://arxiv.org/abs/2404.13793",
    "authors": [
      "Mustafa Erolcan Er",
      "Murathan Kurfal\u0131",
      "Deniz Zeyrek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.13798",
    "title": "Enforcing Conditional Independence for Fair Representation Learning and  Causal Image Generation",
    "abstract": "Conditional independence (CI) constraints are critical for defining and evaluating fairness in machine learning, as well as for learning unconfounded or causal representations. Traditional methods for ensuring fairness either blindly learn invariant features with respect to a protected variable (e.g., race when classifying sex from face images) or enforce CI relative to the protected attribute only on the model output (e.g., the sex label). Neither of these methods are effective in enforcing CI in high-dimensional feature spaces. In this paper, we focus on a nascent approach characterizing the CI constraint in terms of two Jensen-Shannon divergence terms, and we extend it to high-dimensional feature spaces using a novel dynamic sampling strategy. In doing so, we introduce a new training paradigm that can be applied to any encoder architecture. We are able to enforce conditional independence of the diffusion autoencoder latent representation with respect to any protected attribute under the equalized odds constraint and show that this approach enables causal image generation with controllable latent spaces. Our experimental results demonstrate that our approach can achieve high accuracy on downstream tasks while upholding equality of odds. ",
    "url": "https://arxiv.org/abs/2404.13798",
    "authors": [
      "Jensen Hwa",
      "Qingyu Zhao",
      "Aditya Lahiri",
      "Adnan Masood",
      "Babak Salimi",
      "Ehsan Adeli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13804",
    "title": "Adaptive Heterogeneous Client Sampling for Federated Learning over  Wireless Networks",
    "abstract": "Federated learning (FL) algorithms usually sample a fraction of clients in each round (partial participation) when the number of participants is large and the server's communication bandwidth is limited. Recent works on the convergence analysis of FL have focused on unbiased client sampling, e.g., sampling uniformly at random, which suffers from slow wall-clock time for convergence due to high degrees of system heterogeneity and statistical heterogeneity. This paper aims to design an adaptive client sampling algorithm for FL over wireless networks that tackles both system and statistical heterogeneity to minimize the wall-clock convergence time. We obtain a new tractable convergence bound for FL algorithms with arbitrary client sampling probability. Based on the bound, we analytically establish the relationship between the total learning time and sampling probability with an adaptive bandwidth allocation scheme, which results in a non-convex optimization problem. We design an efficient algorithm for learning the unknown parameters in the convergence bound and develop a low-complexity algorithm to approximately solve the non-convex problem. Our solution reveals the impact of system and statistical heterogeneity parameters on the optimal client sampling design. Moreover, our solution shows that as the number of sampled clients increases, the total convergence time first decreases and then increases because a larger sampling number reduces the number of rounds for convergence but results in a longer expected time per-round due to limited wireless bandwidth. Experimental results from both hardware prototype and simulation demonstrate that our proposed sampling scheme significantly reduces the convergence time compared to several baseline sampling schemes. ",
    "url": "https://arxiv.org/abs/2404.13804",
    "authors": [
      "Bing Luo",
      "Wenli Xiao",
      "Shiqiang Wang",
      "Jianwei Huang",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.13808",
    "title": "General Item Representation Learning for Cold-start Content  Recommendations",
    "abstract": "Cold-start item recommendation is a long-standing challenge in recommendation systems. A common remedy is to use a content-based approach, but rich information from raw contents in various forms has not been fully utilized. In this paper, we propose a domain/data-agnostic item representation learning framework for cold-start recommendations, naturally equipped with multimodal alignment among various features by adopting a Transformer-based architecture. Our proposed model is end-to-end trainable completely free from classification labels, not just costly to collect but suboptimal for recommendation-purpose representation learning. From extensive experiments on real-world movie and news recommendation benchmarks, we verify that our approach better preserves fine-grained user taste than state-of-the-art baselines, universally applicable to multiple domains at large scale. ",
    "url": "https://arxiv.org/abs/2404.13808",
    "authors": [
      "Jooeun Kim",
      "Jinri Kim",
      "Kwangeun Yeo",
      "Eungi Kim",
      "Kyoung-Woon On",
      "Jonghwan Mun",
      "Joonseok Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2404.13812",
    "title": "A Comparative Study on Enhancing Prediction in Social Network  Advertisement through Data Augmentation",
    "abstract": "In the ever-evolving landscape of social network advertising, the volume and accuracy of data play a critical role in the performance of predictive models. However, the development of robust predictive algorithms is often hampered by the limited size and potential bias present in real-world datasets. This study presents and explores a generative augmentation framework of social network advertising data. Our framework explores three generative models for data augmentation - Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and diversity in the context of social network advertising analytics effectiveness. By performing synthetic extensions of the feature space, we find that through data augmentation, the performance of various classifiers has been quantitatively improved. Furthermore, we compare the relative performance gains brought by each data augmentation technique, providing insights for practitioners to select appropriate techniques to enhance model performance. This paper contributes to the literature by showing that synthetic data augmentation alleviates the limitations imposed by small or imbalanced datasets in the field of social network advertising. At the same time, this article also provides a comparative perspective on the practicality of different data augmentation methods, thereby guiding practitioners to choose appropriate techniques to enhance model performance. ",
    "url": "https://arxiv.org/abs/2404.13812",
    "authors": [
      "Qikai Yang",
      "Panfeng Li",
      "Xinyu Shen",
      "Zhicheng Ding",
      "Wenjing Zhou",
      "Yi Nian",
      "Xinhe Xu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.13815",
    "title": "Improving Group Robustness on Spurious Correlation Requires Preciser  Group Inference",
    "abstract": "Standard empirical risk minimization (ERM) models may prioritize learning spurious correlations between spurious features and true labels, leading to poor accuracy on groups where these correlations do not hold. Mitigating this issue often requires expensive spurious attribute (group) labels or relies on trained ERM models to infer group labels when group information is unavailable. However, the significant performance gap in worst-group accuracy between using pseudo group labels and using oracle group labels inspires us to consider further improving group robustness through preciser group inference. Therefore, we propose GIC, a novel method that accurately infers group labels, resulting in improved worst-group performance. GIC trains a spurious attribute classifier based on two key properties of spurious correlations: (1) high correlation between spurious attributes and true labels, and (2) variability in this correlation between datasets with different group distributions. Empirical studies on multiple datasets demonstrate the effectiveness of GIC in inferring group labels, and combining GIC with various downstream invariant learning methods improves worst-group accuracy, showcasing its powerful flexibility. Additionally, through analyzing the misclassifications in GIC, we identify an interesting phenomenon called semantic consistency, which may contribute to better decoupling the association between spurious attributes and labels, thereby mitigating spurious correlation. ",
    "url": "https://arxiv.org/abs/2404.13815",
    "authors": [
      "Yujin Han",
      "Difan Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13816",
    "title": "Neural Radiance Field in Autonomous Driving: A Survey",
    "abstract": "Neural Radiance Field (NeRF) has garnered significant attention from both academia and industry due to its intrinsic advantages, particularly its implicit representation and novel view synthesis capabilities. With the rapid advancements in deep learning, a multitude of methods have emerged to explore the potential applications of NeRF in the domain of Autonomous Driving (AD). However, a conspicuous void is apparent within the current literature. To bridge this gap, this paper conducts a comprehensive survey of NeRF's applications in the context of AD. Our survey is structured to categorize NeRF's applications in Autonomous Driving (AD), specifically encompassing perception, 3D reconstruction, simultaneous localization and mapping (SLAM), and simulation. We delve into in-depth analysis and summarize the findings for each application category, and conclude by providing insights and discussions on future directions in this field. We hope this paper serves as a comprehensive reference for researchers in this domain. To the best of our knowledge, this is the first survey specifically focused on the applications of NeRF in the Autonomous Driving domain. ",
    "url": "https://arxiv.org/abs/2404.13816",
    "authors": [
      "Lei He",
      "Leheng Li",
      "Wenchao Sun",
      "Zeyu Han",
      "Yichen Liu",
      "Sifa Zheng",
      "Jianqiang Wang",
      "Keqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13820",
    "title": "Prove Symbolic Regression is NP-hard by Symbol Graph",
    "abstract": "Symbolic regression (SR) is the task of discovering a symbolic expression that fits a given data set from the space of mathematical expressions. Despite the abundance of research surrounding the SR problem, there's a scarcity of works that confirm its NP-hard nature. Therefore, this paper introduces the concept of a symbol graph as a comprehensive representation of the entire mathematical expression space, effectively illustrating the NP-hard characteristics of the SR problem. Leveraging the symbol graph, we establish a connection between the SR problem and the task of identifying an optimally fitted degree-constrained Steiner Arborescence (DCSAP). The complexity of DCSAP, which is proven to be NP-hard, directly implies the NP-hard nature of the SR problem. ",
    "url": "https://arxiv.org/abs/2404.13820",
    "authors": [
      "Jinglu Song",
      "Qiang Lu",
      "Bozhou Tian",
      "Jingwen Zhang",
      "Jake Luo",
      "Zhiguang Wang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2404.13827",
    "title": "Swap It Like Its Hot: Segmentation-based spoof attacks on eye-tracking  images",
    "abstract": "Video-based eye trackers capture the iris biometric and enable authentication to secure user identity. However, biometric authentication is susceptible to spoofing another user's identity through physical or digital manipulation. The current standard to identify physical spoofing attacks on eye-tracking sensors uses liveness detection. Liveness detection classifies gaze data as real or fake, which is sufficient to detect physical presentation attacks. However, such defenses cannot detect a spoofing attack when real eye image inputs are digitally manipulated to swap the iris pattern of another person. We propose IrisSwap as a novel attack on gaze-based liveness detection. IrisSwap allows attackers to segment and digitally swap in a victim's iris pattern to fool iris authentication. Both offline and online attacks produce gaze data that deceives the current state-of-the-art defense models at rates up to 58% and motivates the need to develop more advanced authentication methods for eye trackers. ",
    "url": "https://arxiv.org/abs/2404.13827",
    "authors": [
      "Anish S. Narkar",
      "Brendan David-John"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13838",
    "title": "C2F-SemiCD: A Coarse-to-Fine Semi-Supervised Change Detection Method  Based on Consistency Regularization in High-Resolution Remote Sensing Images",
    "abstract": "A high-precision feature extraction model is crucial for change detection (CD). In the past, many deep learning-based supervised CD methods learned to recognize change feature patterns from a large number of labelled bi-temporal images, whereas labelling bi-temporal remote sensing images is very expensive and often time-consuming; therefore, we propose a coarse-to-fine semi-supervised CD method based on consistency regularization (C2F-SemiCD), which includes a coarse-to-fine CD network with a multiscale attention mechanism (C2FNet) and a semi-supervised update method. Among them, the C2FNet network gradually completes the extraction of change features from coarse-grained to fine-grained through multiscale feature fusion, channel attention mechanism, spatial attention mechanism, global context module, feature refine module, initial aggregation module, and final aggregation module. The semi-supervised update method uses the mean teacher method. The parameters of the student model are updated to the parameters of the teacher Model by using the exponential moving average (EMA) method. Through extensive experiments on three datasets and meticulous ablation studies, including crossover experiments across datasets, we verify the significant effectiveness and efficiency of the proposed C2F-SemiCD method. The code will be open at: https://github.com/ChengxiHAN/C2F-SemiCDand-C2FNet. ",
    "url": "https://arxiv.org/abs/2404.13838",
    "authors": [
      "Chengxi Han",
      "Chen Wu",
      "Meiqi Hu",
      "Jiepan Li",
      "Hongruixuan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13842",
    "title": "On Support Relations Inference and Scene Hierarchy Graph Construction  from Point Cloud in Clustered Environments",
    "abstract": "Over the years, scene understanding has attracted a growing interest in computer vision, providing the semantic and physical scene information necessary for robots to complete some particular tasks autonomously. In 3D scenes, rich spatial geometric and topological information are often ignored by RGB-based approaches for scene understanding. In this study, we develop a bottom-up approach for scene understanding that infers support relations between objects from a point cloud. Our approach utilizes the spatial topology information of the plane pairs in the scene, consisting of three major steps. 1) Detection of pairwise spatial configuration: dividing primitive pairs into local support connection and local inner connection; 2) primitive classification: a combinatorial optimization method applied to classify primitives; and 3) support relations inference and hierarchy graph construction: bottom-up support relations inference and scene hierarchy graph construction containing primitive level and object level. Through experiments, we demonstrate that the algorithm achieves excellent performance in primitive classification and support relations inference. Additionally, we show that the scene hierarchy graph contains rich geometric and topological information of objects, and it possesses great scalability for scene understanding. ",
    "url": "https://arxiv.org/abs/2404.13842",
    "authors": [
      "Gang Ma",
      "Hui Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2404.13848",
    "title": "DSDRNet: Disentangling Representation and Reconstruct Network for Domain  Generalization",
    "abstract": "Domain generalization faces challenges due to the distribution shift between training and testing sets, and the presence of unseen target domains. Common solutions include domain alignment, meta-learning, data augmentation, or ensemble learning, all of which rely on domain labels or domain adversarial techniques. In this paper, we propose a Dual-Stream Separation and Reconstruction Network, dubbed DSDRNet. It is a disentanglement-reconstruction approach that integrates features of both inter-instance and intra-instance through dual-stream fusion. The method introduces novel supervised signals by combining inter-instance semantic distance and intra-instance similarity. Incorporating Adaptive Instance Normalization (AdaIN) into a two-stage cyclic reconstruction process enhances self-disentangled reconstruction signals to facilitate model convergence. Extensive experiments on four benchmark datasets demonstrate that DSDRNet outperforms other popular methods in terms of domain generalization capabilities. ",
    "url": "https://arxiv.org/abs/2404.13848",
    "authors": [
      "Juncheng Yang",
      "Zuchao Li",
      "Shuai Xie",
      "Wei Yu",
      "Shijun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13852",
    "title": "Toward Robust LiDAR based 3D Object Detection via Density-Aware Adaptive  Thresholding",
    "abstract": "Robust 3D object detection is a core challenge for autonomous mobile systems in field robotics. To tackle this issue, many researchers have demonstrated improvements in 3D object detection performance in datasets. However, real-world urban scenarios with unstructured and dynamic situations can still lead to numerous false positives, posing a challenge for robust 3D object detection models. This paper presents a post-processing algorithm that dynamically adjusts object detection thresholds based on the distance from the ego-vehicle. 3D object detection models usually perform well in detecting nearby objects but may exhibit suboptimal performance for distant ones. While conventional perception algorithms typically employ a single threshold in post-processing, the proposed algorithm addresses this issue by employing adaptive thresholds based on the distance from the ego-vehicle, minimizing false negatives and reducing false positives in urban scenarios. The results show performance enhancements in 3D object detection models across a range of scenarios, not only in dynamic urban road conditions but also in scenarios involving adverse weather conditions. ",
    "url": "https://arxiv.org/abs/2404.13852",
    "authors": [
      "Eunho Lee",
      "Minwoo Jung",
      "Ayoung Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.13853",
    "title": "ICST-DNET: An Interpretable Causal Spatio-Temporal Diffusion Network for  Traffic Speed Prediction",
    "abstract": "Traffic speed prediction is significant for intelligent navigation and congestion alleviation. However, making accurate predictions is challenging due to three factors: 1) traffic diffusion, i.e., the spatial and temporal causality existing between the traffic conditions of multiple neighboring roads, 2) the poor interpretability of traffic data with complicated spatio-temporal correlations, and 3) the latent pattern of traffic speed fluctuations over time, such as morning and evening rush. Jointly considering these factors, in this paper, we present a novel architecture for traffic speed prediction, called Interpretable Causal Spatio-Temporal Diffusion Network (ICST-DNET). Specifically, ICST-DENT consists of three parts, namely the Spatio-Temporal Causality Learning (STCL), Causal Graph Generation (CGG), and Speed Fluctuation Pattern Recognition (SFPR) modules. First, to model the traffic diffusion within road networks, an STCL module is proposed to capture both the temporal causality on each individual road and the spatial causality in each road pair. The CGG module is then developed based on STCL to enhance the interpretability of the traffic diffusion procedure from the temporal and spatial perspectives. Specifically, a time causality matrix is generated to explain the temporal causality between each road's historical and future traffic conditions. For spatial causality, we utilize causal graphs to visualize the diffusion process in road pairs. Finally, to adapt to traffic speed fluctuations in different scenarios, we design a personalized SFPR module to select the historical timesteps with strong influences for learning the pattern of traffic speed fluctuations. Extensive experimental results prove that ICST-DNET can outperform all existing baselines, as evidenced by the higher prediction accuracy, ability to explain causality, and adaptability to different scenarios. ",
    "url": "https://arxiv.org/abs/2404.13853",
    "authors": [
      "Yi Rong",
      "Yingchi Mao",
      "Yinqiu Liu",
      "Ling Chen",
      "Xiaoming He",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.13854",
    "title": "Self-Supervised Monocular Depth Estimation in the Dark: Towards Data  Distribution Compensation",
    "abstract": "Nighttime self-supervised monocular depth estimation has received increasing attention in recent years. However, using night images for self-supervision is unreliable because the photometric consistency assumption is usually violated in the videos taken under complex lighting conditions. Even with domain adaptation or photometric loss repair, performance is still limited by the poor supervision of night images on trainable networks. In this paper, we propose a self-supervised nighttime monocular depth estimation method that does not use any night images during training. Our framework utilizes day images as a stable source for self-supervision and applies physical priors (e.g., wave optics, reflection model and read-shot noise model) to compensate for some key day-night differences. With day-to-night data distribution compensation, our framework can be trained in an efficient one-stage self-supervised manner. Though no nighttime images are considered during training, qualitative and quantitative results demonstrate that our method achieves SoTA depth estimating results on the challenging nuScenes-Night and RobotCar-Night compared with existing methods. ",
    "url": "https://arxiv.org/abs/2404.13854",
    "authors": [
      "Haolin Yang",
      "Chaoqiang Zhao",
      "Lu Sheng",
      "Yang Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13860",
    "title": "Distributional Black-Box Model Inversion Attack with Multi-Agent  Reinforcement Learning",
    "abstract": "A Model Inversion (MI) attack based on Generative Adversarial Networks (GAN) aims to recover the private training data from complex deep learning models by searching codes in the latent space. However, they merely search a deterministic latent space such that the found latent code is usually suboptimal. In addition, the existing distributional MI schemes assume that an attacker can access the structures and parameters of the target model, which is not always viable in practice. To overcome the above shortcomings, this paper proposes a novel Distributional Black-Box Model Inversion (DBB-MI) attack by constructing the probabilistic latent space for searching the target privacy data. Specifically, DBB-MI does not need the target model parameters or specialized GAN training. Instead, it finds the latent probability distribution by combining the output of the target model with multi-agent reinforcement learning techniques. Then, it randomly chooses latent codes from the latent probability distribution for recovering the private data. As the latent probability distribution closely aligns with the target privacy data in latent space, the recovered data will leak the privacy of training samples of the target model significantly. Abundant experiments conducted on diverse datasets and networks show that the present DBB-MI has better performance than state-of-the-art in attack accuracy, K-nearest neighbor feature distance, and Peak Signal-to-Noise Ratio. ",
    "url": "https://arxiv.org/abs/2404.13860",
    "authors": [
      "Huan Bao",
      "Kaimin Wei",
      "Yongdong Wu",
      "Jin Qian",
      "Robert H. Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.13872",
    "title": "FreqBlender: Enhancing DeepFake Detection by Blending Frequency  Knowledge",
    "abstract": "Generating synthetic fake faces, known as pseudo-fake faces, is an effective way to improve the generalization of DeepFake detection. Existing methods typically generate these faces by blending real or fake faces in color space. While these methods have shown promise, they overlook the simulation of frequency distribution in pseudo-fake faces, limiting the learning of generic forgery traces in-depth. To address this, this paper introduces {\\em FreqBlender}, a new method that can generate pseudo-fake faces by blending frequency knowledge. Specifically, we investigate the major frequency components and propose a Frequency Parsing Network to adaptively partition frequency components related to forgery traces. Then we blend this frequency knowledge from fake faces into real faces to generate pseudo-fake faces. Since there is no ground truth for frequency components, we describe a dedicated training strategy by leveraging the inner correlations among different frequency knowledge to instruct the learning process. Experimental results demonstrate the effectiveness of our method in enhancing DeepFake detection, making it a potential plug-and-play strategy for other methods. ",
    "url": "https://arxiv.org/abs/2404.13872",
    "authors": [
      "Hanzhe Li",
      "Jiaran Zhou",
      "Bin Li",
      "Junyu Dong",
      "Yuezun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13873",
    "title": "Texture-aware and Shape-guided Transformer for Sequential DeepFake  Detection",
    "abstract": "Sequential DeepFake detection is an emerging task that aims to predict the manipulation sequence in order. Existing methods typically formulate it as an image-to-sequence problem, employing conventional Transformer architectures for detection. However, these methods lack dedicated design and consequently result in limited performance. In this paper, we propose a novel Texture-aware and Shape-guided Transformer to enhance detection performance. Our method features four major improvements. Firstly, we describe a texture-aware branch that effectively captures subtle manipulation traces with the Diversiform Pixel Difference Attention module. Then we introduce a Bidirectional Interaction Cross-attention module that seeks deep correlations among spatial and sequential features, enabling effective modeling of complex manipulation traces. To further enhance the cross-attention, we describe a Shape-guided Gaussian mapping strategy, providing initial priors of the manipulation shape. Finally, observing that the latter manipulation in a sequence may influence traces left in the earlier one, we intriguingly invert the prediction order from forward to backward, leading to notable gains as expected. Extensive experimental results demonstrate that our method outperforms others by a large margin, highlighting the superiority of our method. ",
    "url": "https://arxiv.org/abs/2404.13873",
    "authors": [
      "Yunfei Li",
      "Jiaran Zhou",
      "Xin Wang",
      "Junyu Dong",
      "Yuezun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13879",
    "title": "Explicit Lipschitz Value Estimation Enhances Policy Robustness Against  Perturbation",
    "abstract": "In robotic control tasks, policies trained by reinforcement learning (RL) in simulation often experience a performance drop when deployed on physical hardware, due to modeling error, measurement error, and unpredictable perturbations in the real world. Robust RL methods account for this issue by approximating a worst-case value function during training, but they can be sensitive to approximation errors in the value function and its gradient before training is complete. In this paper, we hypothesize that Lipschitz regularization can help condition the approximated value function gradients, leading to improved robustness after training. We test this hypothesis by combining Lipschitz regularization with an application of Fast Gradient Sign Method to reduce approximation errors when evaluating the value function under adversarial perturbations. Our empirical results demonstrate the benefits of this approach over prior work on a number of continuous control benchmarks. ",
    "url": "https://arxiv.org/abs/2404.13879",
    "authors": [
      "Xulin Chen",
      "Ruipeng Liu",
      "Garrett E. Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13892",
    "title": "Retrieval-Augmented Audio Deepfake Detection",
    "abstract": "With recent advances in speech synthesis including text-to-speech (TTS) and voice conversion (VC) systems enabling the generation of ultra-realistic audio deepfakes, there is growing concern about their potential misuse. However, most deepfake (DF) detection methods rely solely on the fuzzy knowledge learned by a single model, resulting in performance bottlenecks and transparency issues. Inspired by retrieval-augmented generation (RAG), we propose a retrieval-augmented detection (RAD) framework that augments test samples with similar retrieved samples for enhanced detection. We also extend the multi-fusion attentive classifier to integrate it with our proposed RAD framework. Extensive experiments show the superior performance of the proposed RAD framework over baseline methods, achieving state-of-the-art results on the ASVspoof 2021 DF set and competitive results on the 2019 and 2021 LA sets. Further sample analysis indicates that the retriever consistently retrieves samples mostly from the same speaker with acoustic characteristics highly consistent with the query audio, thereby improving detection performance. ",
    "url": "https://arxiv.org/abs/2404.13892",
    "authors": [
      "Zuheng Kang",
      "Yayun He",
      "Botao Zhao",
      "Xiaoyang Qu",
      "Junqing Peng",
      "Jing Xiao",
      "Jianzong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.13896",
    "title": "CT-NeRF: Incremental Optimizing Neural Radiance Field and Poses with  Complex Trajectory",
    "abstract": "Neural radiance field (NeRF) has achieved impressive results in high-quality 3D scene reconstruction. However, NeRF heavily relies on precise camera poses. While recent works like BARF have introduced camera pose optimization within NeRF, their applicability is limited to simple trajectory scenes. Existing methods struggle while tackling complex trajectories involving large rotations. To address this limitation, we propose CT-NeRF, an incremental reconstruction optimization pipeline using only RGB images without pose and depth input. In this pipeline, we first propose a local-global bundle adjustment under a pose graph connecting neighboring frames to enforce the consistency between poses to escape the local minima caused by only pose consistency with the scene structure. Further, we instantiate the consistency between poses as a reprojected geometric image distance constraint resulting from pixel-level correspondences between input image pairs. Through the incremental reconstruction, CT-NeRF enables the recovery of both camera poses and scene structure and is capable of handling scenes with complex trajectories. We evaluate the performance of CT-NeRF on two real-world datasets, NeRFBuster and Free-Dataset, which feature complex trajectories. Results show CT-NeRF outperforms existing methods in novel view synthesis and pose estimation accuracy. ",
    "url": "https://arxiv.org/abs/2404.13896",
    "authors": [
      "Yunlong Ran",
      "Yanxu Li",
      "Qi Ye",
      "Yuchi Huo",
      "Zechun Bai",
      "Jiahao Sun",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13904",
    "title": "Deep Regression Representation Learning with Topology",
    "abstract": "Most works studying representation learning focus only on classification and neglect regression. Yet, the learning objectives and therefore the representation topologies of the two tasks are fundamentally different: classification targets class separation, leading to disconnected representations, whereas regression requires ordinality with respect to the target, leading to continuous representations. We thus wonder how the effectiveness of a regression representation is influenced by its topology, with evaluation based on the Information Bottleneck (IB) principle. The IB principle is an important framework that provides principles for learning effectiveness representations. We establish two connections between it and the topology of regression representations. The first connection reveals that a lower intrinsic dimension of the feature space implies a reduced complexity of the representation Z. This complexity can be quantified as the conditional entropy of Z on the target space Y and serves as an upper bound on the generalization error. The second connection suggests learning a feature space that is topologically similar to the target space will better align with the IB principle. Based on these two connections, we introduce PH-Reg, a regularizer specific to regression that matches the intrinsic dimension and topology of the feature space with the target space. Experiments on synthetic and real-world regression tasks demonstrate the benefits of PH-Reg. ",
    "url": "https://arxiv.org/abs/2404.13904",
    "authors": [
      "Shihao Zhang",
      "kenji kawaguchi",
      "Angela Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13909",
    "title": "Physics-informed neural networks with curriculum training for  poroelastic flow and deformation processes",
    "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a highly active research topic across multiple disciplines in science and engineering, including computational geomechanics. PINNs offer a promising approach in different applications where faster, near real-time or real-time numerical prediction is required. Examples of such areas in geomechanics include geotechnical design optimization, digital twins of geo-structures and stability prediction of monitored slopes. But there remain challenges in training of PINNs, especially for problems with high spatial and temporal complexity. In this paper, we study how the training of PINNs can be improved by using an ideal-ized poroelasticity problem as a demonstration example. A curriculum training strat-egy is employed where the PINN model is trained gradually by dividing the training data into intervals along the temporal dimension. We find that the PINN model with curriculum training takes nearly half the time required for training compared to con-ventional training over the whole solution domain. For the particular example here, the quality of the predicted solution was found to be good in both training approach-es, but it is anticipated that the curriculum training approach has the potential to offer a better prediction capability for more complex problems, a subject for further research. ",
    "url": "https://arxiv.org/abs/2404.13909",
    "authors": [
      "Yared Worku Bekele"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2404.13921",
    "title": "NeRF-DetS: Enhancing Multi-View 3D Object Detection with  Sampling-adaptive Network of Continuous NeRF-based Representation",
    "abstract": "As a preliminary work, NeRF-Det unifies the tasks of novel view synthesis and 3D perception, demonstrating that perceptual tasks can benefit from novel view synthesis methods like NeRF, significantly improving the performance of indoor multi-view 3D object detection. Using the geometry MLP of NeRF to direct the attention of detection head to crucial parts and incorporating self-supervised loss from novel view rendering contribute to the achieved improvement. To better leverage the notable advantages of the continuous representation through neural rendering in space, we introduce a novel 3D perception network structure, NeRF-DetS. The key component of NeRF-DetS is the Multi-level Sampling-Adaptive Network, making the sampling process adaptively from coarse to fine. Also, we propose a superior multi-view information fusion method, known as Multi-head Weighted Fusion. This fusion approach efficiently addresses the challenge of losing multi-view information when using arithmetic mean, while keeping low computational costs. NeRF-DetS outperforms competitive NeRF-Det on the ScanNetV2 dataset, by achieving +5.02% and +5.92% improvement in mAP@.25 and mAP@.50, respectively. ",
    "url": "https://arxiv.org/abs/2404.13921",
    "authors": [
      "Chi Huang",
      "Xinyang Li",
      "Shengchuan Zhang",
      "Liujuan Cao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13937",
    "title": "Data-Based System Representation and Synchronization for Multiagent  Systems",
    "abstract": "This paper presents novel solutions of the data-based synchronization problem for continuous-time multiagent systems. We consider the cases of homogeneous and heterogeneous systems. First, a data-based representation of the synchronization error dynamics is obtained for homogeneous systems, using input-state data collected from the agents. Then, we show how to extend existing data-based stabilization results to the multiagent case to stabilize the obtained synchronization errors. The proposed method relies on the solution of a set of linear matrix inequalities that are shown to be feasible. Then, we solve the synchronization problem for heterogeneous systems by means of dynamic controllers. Different from existing results, we do not require model knowledge for the followers and the leader. The theoretical results are finally validated using numerical simulations. ",
    "url": "https://arxiv.org/abs/2404.13937",
    "authors": [
      "Victor G. Lopez",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.13946",
    "title": "Dual Model Replacement:invisible Multi-target Backdoor Attack based on  Federal Learning",
    "abstract": "In recent years, the neural network backdoor hidden in the parameters of the federated learning model has been proved to have great security risks. Considering the characteristics of trigger generation, data poisoning and model training in backdoor attack, this paper designs a backdoor attack method based on federated learning. Firstly, aiming at the concealment of the backdoor trigger, a TrojanGan steganography model with encoder-decoder structure is designed. The model can encode specific attack information as invisible noise and attach it to the image as a backdoor trigger, which improves the concealment and data transformations of the backdoor trigger.Secondly, aiming at the problem of single backdoor trigger mode, an image poisoning attack method called combination trigger attack is proposed. This method realizes multi-backdoor triggering by multiplexing combined triggers and improves the robustness of backdoor attacks. Finally, aiming at the problem that the local training mechanism leads to the decrease of the success rate of backdoor attack, a dual model replacement backdoor attack algorithm based on federated learning is designed. This method can improve the success rate of backdoor attack while maintaining the performance of the federated learning aggregation model. Experiments show that the attack strategy in this paper can not only achieve high backdoor concealment and diversification of trigger forms under federated learning, but also achieve good attack success rate in multi-target attacks.door concealment and diversification of trigger forms but also achieve good results in multi-target attacks. ",
    "url": "https://arxiv.org/abs/2404.13946",
    "authors": [
      "Rong Wang",
      "Guichen Zhou",
      "Mingjun Gao",
      "Yunpeng Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13948",
    "title": "Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by  Simulating Documents in the Wild via Low-level Perturbations",
    "abstract": "The robustness of recent Large Language Models (LLMs) has become increasingly crucial as their applicability expands across various domains and real-world applications. Retrieval-Augmented Generation (RAG) is a promising solution for addressing the limitations of LLMs, yet existing studies on the robustness of RAG often overlook the interconnected relationships between RAG components or the potential threats prevalent in real-world databases, such as minor textual errors. In this work, we investigate two underexplored aspects when assessing the robustness of RAG: 1) vulnerability to noisy documents through low-level perturbations and 2) a holistic evaluation of RAG robustness. Furthermore, we introduce a novel attack method, the Genetic Attack on RAG (\\textit{GARAG}), which targets these aspects. Specifically, GARAG is designed to reveal vulnerabilities within each component and test the overall system functionality against noisy documents. We validate RAG robustness by applying our \\textit{GARAG} to standard QA datasets, incorporating diverse retrievers and LLMs. The experimental results show that GARAG consistently achieves high attack success rates. Also, it significantly devastates the performance of each component and their synergy, highlighting the substantial risk that minor textual inaccuracies pose in disrupting RAG systems in the real world. ",
    "url": "https://arxiv.org/abs/2404.13948",
    "authors": [
      "Sukmin Cho",
      "Soyeong Jeong",
      "Jeongyeon Seo",
      "Taeho Hwang",
      "Jong C. Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.13974",
    "title": "A single-sided all-at-once preconditioning for linear system from a  non-local evolutionary equation with weakly singular kernels",
    "abstract": "{In [X. L. Lin, M. K. Ng, and Y. Zhi. {\\it J. Comput. Phys.}, 434 (2021), pp. 110221] and [Y. L. Zhao, J. Wu, X. M. Gu, and H. Li. {\\it Comput. Math. Appl.}, 148(2023), pp. 200--210]}, two-sided preconditioning techniques are proposed for non-local evolutionary equations, which possesses (i) mesh-size independent theoretical bound of condition number of the two-sided preconditioned matrix; (ii) small and stable iteration numbers in numerical tests. In this paper, we modify the two-sided preconditioning by multiplying the left-sided and the right-sided preconditioners together as a single-sided preconditioner. Such a single-sided preconditioner essentially derives from approximating the spatial matrix with a fast diagonalizable matrix and keeping the temporal matrix unchanged. Clearly, the matrix-vector multiplication of the single-sided preconditioning is faster to compute than that of the two-sided one, since the single-sided preconditioned matrix has a simpler structure. More importantly, we show theoretically that the single-sided preconditioned generalized minimal residual (GMRES) method has a convergence rate no worse than the two-sided preconditioned one. As a result, the one-sided preconditioned GMRES solver requires less computational time than the two-sided preconditioned GMRES solver in total. Numerical results are reported to show the efficiency of the proposed single-sided preconditioning technique. ",
    "url": "https://arxiv.org/abs/2404.13974",
    "authors": [
      "Xuelei Lin",
      "Jiamei Dong",
      "Sean Hon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2404.13982",
    "title": "Liquid-Graph Time-Constant Network for Multi-Agent Systems Control",
    "abstract": "In this paper, we propose the Liquid-Graph Time-constant (LGTC) network, a continuous graph neural network(GNN) model for control of multi-agent systems based on therecent Liquid Time Constant (LTC) network. We analyse itsstability leveraging contraction analysis and propose a closed-form model that preserves the model contraction rate and doesnot require solving an ODE at each iteration. Compared todiscrete models like Graph Gated Neural Networks (GGNNs),the higher expressivity of the proposed model guaranteesremarkable performance while reducing the large amountof communicated variables normally required by GNNs. Weevaluate our model on a distributed multi-agent control casestudy (flocking) taking into account variable communicationrange and scalability under non-instantaneous communication ",
    "url": "https://arxiv.org/abs/2404.13982",
    "authors": [
      "Antonio Marino",
      "Claudio Pacchierotti",
      "Paolo Robuffo Giordano"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2404.13983",
    "title": "Structure-Aware Human Body Reshaping with Adaptive Affinity-Graph  Network",
    "abstract": "Given a source portrait, the automatic human body reshaping task aims at editing it to an aesthetic body shape. As the technology has been widely used in media, several methods have been proposed mainly focusing on generating optical flow to warp the body shape. However, those previous works only consider the local transformation of different body parts (arms, torso, and legs), ignoring the global affinity, and limiting the capacity to ensure consistency and quality across the entire body. In this paper, we propose a novel Adaptive Affinity-Graph Network (AAGN), which extracts the global affinity between different body parts to enhance the quality of the generated optical flow. Specifically, our AAGN primarily introduces the following designs: (1) we propose an Adaptive Affinity-Graph (AAG) Block that leverages the characteristic of a fully connected graph. AAG represents different body parts as nodes in an adaptive fully connected graph and captures all the affinities between nodes to obtain a global affinity map. The design could better improve the consistency between body parts. (2) Besides, for high-frequency details are crucial for photo aesthetics, a Body Shape Discriminator (BSD) is designed to extract information from both high-frequency and spatial domain. Particularly, an SRM filter is utilized to extract high-frequency details, which are combined with spatial features as input to the BSD. With this design, BSD guides the Flow Generator (FG) to pay attention to various fine details rather than rigid pixel-level fitting. Extensive experiments conducted on the BR-5K dataset demonstrate that our framework significantly enhances the aesthetic appeal of reshaped photos, marginally surpassing all previous work to achieve state-of-the-art in all evaluation metrics. ",
    "url": "https://arxiv.org/abs/2404.13983",
    "authors": [
      "Qiwen Deng",
      "Yangcen Liu",
      "Wen Li",
      "Guoqing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13993",
    "title": "Zero-Shot Character Identification and Speaker Prediction in Comics via  Iterative Multimodal Fusion",
    "abstract": "Recognizing characters and predicting speakers of dialogue are critical for comic processing tasks, such as voice generation or translation. However, because characters vary by comic title, supervised learning approaches like training character classifiers which require specific annotations for each comic title are infeasible. This motivates us to propose a novel zero-shot approach, allowing machines to identify characters and predict speaker names based solely on unannotated comic images. In spite of their importance in real-world applications, these task have largely remained unexplored due to challenges in story comprehension and multimodal integration. Recent large language models (LLMs) have shown great capability for text understanding and reasoning, while their application to multimodal content analysis is still an open problem. To address this problem, we propose an iterative multimodal framework, the first to employ multimodal information for both character identification and speaker prediction tasks. Our experiments demonstrate the effectiveness of the proposed framework, establishing a robust baseline for these tasks. Furthermore, since our method requires no training data or annotations, it can be used as-is on any comic series. ",
    "url": "https://arxiv.org/abs/2404.13993",
    "authors": [
      "Yingxuan Li",
      "Ryota Hinami",
      "Kiyoharu Aizawa",
      "Yusuke Matsui"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14017",
    "title": "Hybrid Ensemble-Based Travel Mode Prediction",
    "abstract": "Travel mode choice (TMC) prediction, which can be formulated as a classification task, helps in understanding what makes citizens choose different modes of transport for individual trips. This is also a major step towards fostering sustainable transportation. As behaviour may evolve over time, we also face the question of detecting concept drift in the data. This necessitates using appropriate methods to address potential concept drift. In particular, it is necessary to decide whether batch or stream mining methods should be used to develop periodically updated TMC models. To address the challenge of the development of TMC models, we propose the novel Incremental Ensemble of Batch and Stream Models (IEBSM) method aimed at adapting travel mode choice classifiers to concept drift possibly occurring in the data. It relies on the combination of drift detectors with batch learning and stream mining models. We compare it against batch and incremental learners, including methods relying on active drift detection. Experiments with varied travel mode data sets representing both city and country levels show that the IEBSM method both detects drift in travel mode data and successfully adapts the models to evolving travel mode choice data. The method has a higher rank than batch and stream learners. ",
    "url": "https://arxiv.org/abs/2404.14017",
    "authors": [
      "Pawe\u0142 Golik",
      "Maciej Grzenda",
      "El\u017cbieta Sienkiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.14019",
    "title": "A Multimodal Feature Distillation with CNN-Transformer Network for Brain  Tumor Segmentation with Incomplete Modalities",
    "abstract": "Existing brain tumor segmentation methods usually utilize multiple Magnetic Resonance Imaging (MRI) modalities in brain tumor images for segmentation, which can achieve better segmentation performance. However, in clinical applications, some modalities are missing due to resource constraints, leading to severe degradation in the performance of methods applying complete modality segmentation. In this paper, we propose a Multimodal feature distillation with Convolutional Neural Network (CNN)-Transformer hybrid network (MCTSeg) for accurate brain tumor segmentation with missing modalities. We first design a Multimodal Feature Distillation (MFD) module to distill feature-level multimodal knowledge into different unimodality to extract complete modality information. We further develop a Unimodal Feature Enhancement (UFE) module to model the relationship between global and local information semantically. Finally, we build a Cross-Modal Fusion (CMF) module to explicitly align the global correlations among different modalities even when some modalities are missing. Complementary features within and across different modalities are refined via the CNN-Transformer hybrid architectures in both the UFE and CMF modules, where local and global dependencies are both captured. Our ablation study demonstrates the importance of the proposed modules with CNN-Transformer networks and the convolutional blocks in Transformer for improving the performance of brain tumor segmentation with missing modalities. Extensive experiments on the BraTS2018 and BraTS2020 datasets show that the proposed MCTSeg framework outperforms the state-of-the-art methods in missing modalities cases. Our code is available at: https://github.com/mkang315/MCTSeg. ",
    "url": "https://arxiv.org/abs/2404.14019",
    "authors": [
      "Ming Kang",
      "Fung Fung Ting",
      "Rapha\u00ebl C.-W. Phan",
      "Zongyuan Ge",
      "Chee-Ming Ting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2404.14024",
    "title": "Exploring neural oscillations during speech perception via surrogate  gradient spiking neural networks",
    "abstract": "Understanding cognitive processes in the brain demands sophisticated models capable of replicating neural dynamics at large scales. We present a physiologically inspired speech recognition architecture, compatible and scalable with deep learning frameworks, and demonstrate that end-to-end gradient descent training leads to the emergence of neural oscillations in the central spiking neural network. Significant cross-frequency couplings, indicative of these oscillations, are measured within and across network layers during speech processing, whereas no such interactions are observed when handling background noise inputs. Furthermore, our findings highlight the crucial inhibitory role of feedback mechanisms, such as spike frequency adaptation and recurrent connections, in regulating and synchronising neural activity to improve recognition performance. Overall, on top of developing our understanding of synchronisation phenomena notably observed in the human auditory pathway, our architecture exhibits dynamic and efficient information processing, with relevance to neuromorphic technology. ",
    "url": "https://arxiv.org/abs/2404.14024",
    "authors": [
      "Alexandre Bittar",
      "Philip N. Garner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2404.14025",
    "title": "DHRNet: A Dual-Path Hierarchical Relation Network for Multi-Person Pose  Estimation",
    "abstract": "Multi-person pose estimation (MPPE) presents a formidable yet crucial challenge in computer vision. Most existing methods predominantly concentrate on isolated interaction either between instances or joints, which is inadequate for scenarios demanding concurrent localization of both instances and joints. This paper introduces a novel CNN-based single-stage method, named Dual-path Hierarchical Relation Network (DHRNet), to extract instance-to-joint and joint-to-instance interactions concurrently. Specifically, we design a dual-path interaction modeling module (DIM) that strategically organizes cross-instance and cross-joint interaction modeling modules in two complementary orders, enriching interaction information by integrating merits from different correlation modeling branches. Notably, DHRNet excels in joint localization by leveraging information from other instances and joints. Extensive evaluations on challenging datasets, including COCO, CrowdPose, and OCHuman datasets, showcase DHRNet's state-of-the-art performance. The code will be released at https://github.com/YHDang/dhrnet-multi-pose-estimation. ",
    "url": "https://arxiv.org/abs/2404.14025",
    "authors": [
      "Yonghao Dang",
      "Jianqin Yin",
      "Liyuan Liu",
      "Yuan Sun",
      "Yanzhu Hu",
      "Pengxiang Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14027",
    "title": "OccFeat: Self-supervised Occupancy Feature Prediction for Pretraining  BEV Segmentation Networks",
    "abstract": "We introduce a self-supervised pretraining method, called OcFeat, for camera-only Bird's-Eye-View (BEV) segmentation networks. With OccFeat, we pretrain a BEV network via occupancy prediction and feature distillation tasks. Occupancy prediction provides a 3D geometric understanding of the scene to the model. However, the geometry learned is class-agnostic. Hence, we add semantic information to the model in the 3D space through distillation from a self-supervised pretrained image foundation model. Models pretrained with our method exhibit improved BEV semantic segmentation performance, particularly in low-data scenarios. Moreover, empirical results affirm the efficacy of integrating feature distillation with 3D occupancy prediction in our pretraining approach. ",
    "url": "https://arxiv.org/abs/2404.14027",
    "authors": [
      "Sophia Sirko-Galouchenko",
      "Alexandre Boulch",
      "Spyros Gidaris",
      "Andrei Bursuc",
      "Antonin Vobecky",
      "Patrick P\u00e9rez",
      "Renaud Marlet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.14033",
    "title": "Apodotiko: Enabling Efficient Serverless Federated Learning in  Heterogeneous Environments",
    "abstract": "Federated Learning (FL) is an emerging machine learning paradigm that enables the collaborative training of a shared global model across distributed clients while keeping the data decentralized. Recent works on designing systems for efficient FL have shown that utilizing serverless computing technologies, particularly Function-as-a-Service (FaaS) for FL, can enhance resource efficiency, reduce training costs, and alleviate the complex infrastructure management burden on data holders. However, current serverless FL systems still suffer from the presence of stragglers, i.e., slow clients that impede the collaborative training process. While strategies aimed at mitigating stragglers in these systems have been proposed, they overlook the diverse hardware resource configurations among FL clients. To this end, we present Apodotiko, a novel asynchronous training strategy designed for serverless FL. Our strategy incorporates a scoring mechanism that evaluates each client's hardware capacity and dataset size to intelligently prioritize and select clients for each training round, thereby minimizing the effects of stragglers on system performance. We comprehensively evaluate Apodotiko across diverse datasets, considering a mix of CPU and GPU clients, and compare its performance against five other FL training strategies. Results from our experiments demonstrate that Apodotiko outperforms other FL training strategies, achieving an average speedup of 2.75x and a maximum speedup of 7.03x. Furthermore, our strategy significantly reduces cold starts by a factor of four on average, demonstrating suitability in serverless environments. ",
    "url": "https://arxiv.org/abs/2404.14033",
    "authors": [
      "Mohak Chadha",
      "Alexander Jensen",
      "Jianfeng Gu",
      "Osama Abboud",
      "Michael Gerndt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.14034",
    "title": "PointDifformer: Robust Point Cloud Registration With Neural Diffusion  and Transformer",
    "abstract": "Point cloud registration is a fundamental technique in 3-D computer vision with applications in graphics, autonomous driving, and robotics. However, registration tasks under challenging conditions, under which noise or perturbations are prevalent, can be difficult. We propose a robust point cloud registration approach that leverages graph neural partial differential equations (PDEs) and heat kernel signatures. Our method first uses graph neural PDE modules to extract high dimensional features from point clouds by aggregating information from the 3-D point neighborhood, thereby enhancing the robustness of the feature representations. Then, we incorporate heat kernel signatures into an attention mechanism to efficiently obtain corresponding keypoints. Finally, a singular value decomposition (SVD) module with learnable weights is used to predict the transformation between two point clouds. Empirical experiments on a 3-D point cloud dataset demonstrate that our approach not only achieves state-of-the-art performance for point cloud registration but also exhibits better robustness to additive noise or 3-D shape perturbations. ",
    "url": "https://arxiv.org/abs/2404.14034",
    "authors": [
      "Rui She",
      "Qiyu Kang",
      "Sijie Wang",
      "Wee Peng Tay",
      "Kai Zhao",
      "Yang Song",
      "Tianyu Geng",
      "Yi Xu",
      "Diego Navarro Navarro",
      "Andreas Hartmannsgruber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14042",
    "title": "CloudFort: Enhancing Robustness of 3D Point Cloud Classification Against  Backdoor Attacks via Spatial Partitioning and Ensemble Prediction",
    "abstract": "The increasing adoption of 3D point cloud data in various applications, such as autonomous vehicles, robotics, and virtual reality, has brought about significant advancements in object recognition and scene understanding. However, this progress is accompanied by new security challenges, particularly in the form of backdoor attacks. These attacks involve inserting malicious information into the training data of machine learning models, potentially compromising the model's behavior. In this paper, we propose CloudFort, a novel defense mechanism designed to enhance the robustness of 3D point cloud classifiers against backdoor attacks. CloudFort leverages spatial partitioning and ensemble prediction techniques to effectively mitigate the impact of backdoor triggers while preserving the model's performance on clean data. We evaluate the effectiveness of CloudFort through extensive experiments, demonstrating its strong resilience against the Point Cloud Backdoor Attack (PCBA). Our results show that CloudFort significantly enhances the security of 3D point cloud classification models without compromising their accuracy on benign samples. Furthermore, we explore the limitations of CloudFort and discuss potential avenues for future research in the field of 3D point cloud security. The proposed defense mechanism represents a significant step towards ensuring the trustworthiness and reliability of point-cloud-based systems in real-world applications. ",
    "url": "https://arxiv.org/abs/2404.14042",
    "authors": [
      "Wenhao Lan",
      "Yijun Yang",
      "Haihua Shen",
      "Shan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14044",
    "title": "HashPoint: Accelerated Point Searching and Sampling for Neural Rendering",
    "abstract": "In this paper, we address the problem of efficient point searching and sampling for volume neural rendering. Within this realm, two typical approaches are employed: rasterization and ray tracing. The rasterization-based methods enable real-time rendering at the cost of increased memory and lower fidelity. In contrast, the ray-tracing-based methods yield superior quality but demand longer rendering time. We solve this problem by our HashPoint method combining these two strategies, leveraging rasterization for efficient point searching and sampling, and ray marching for rendering. Our method optimizes point searching by rasterizing points within the camera's view, organizing them in a hash table, and facilitating rapid searches. Notably, we accelerate the rendering process by adaptive sampling on the primary surface encountered by the ray. Our approach yields substantial speed-up for a range of state-of-the-art ray-tracing-based methods, maintaining equivalent or superior accuracy across synthetic and real test datasets. The code will be available at https://jiahao-ma.github.io/hashpoint/. ",
    "url": "https://arxiv.org/abs/2404.14044",
    "authors": [
      "Jiahao Ma",
      "Miaomiao Liu",
      "David Ahmedt-Aristizaba",
      "Chuong Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14070",
    "title": "No General Code of Ethics for All: Ethical Considerations in Human-bot  Psycho-counseling",
    "abstract": "The pervasive use of AI applications is increasingly influencing our everyday decisions. However, the ethical challenges associated with AI transcend conventional ethics and single-discipline approaches. In this paper, we propose aspirational ethical principles specifically tailored for human-bot psycho-counseling during an era when AI-powered mental health services are continually emerging. We examined the responses generated by EVA2.0, GPT-3.5, and GPT-4.0 in the context of psycho-counseling and mental health inquiries. Our analysis focused on standard psycho-counseling ethical codes (respect for autonomy, non-maleficence, beneficence, justice, and responsibility) as well as crisis intervention strategies (risk assessment, involvement of emergency services, and referral to human professionals). The results indicate that although there has been progress in adhering to regular ethical codes as large language models (LLMs) evolve, the models' capabilities in handling crisis situations need further improvement. Additionally, we assessed the linguistic quality of the generated responses and found that misleading responses are still produced by the models. Furthermore, the ability of LLMs to encourage individuals to introspect in the psycho-counseling setting remains underdeveloped. ",
    "url": "https://arxiv.org/abs/2404.14070",
    "authors": [
      "Lizhi Ma",
      "Tong Zhao",
      "Huachuan Qiu",
      "Zhenzhong Lan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2404.14073",
    "title": "Towards Robust Trajectory Representations: Isolating Environmental  Confounders with Causal Learning",
    "abstract": "Trajectory modeling refers to characterizing human movement behavior, serving as a pivotal step in understanding mobility patterns. Nevertheless, existing studies typically ignore the confounding effects of geospatial context, leading to the acquisition of spurious correlations and limited generalization capabilities. To bridge this gap, we initially formulate a Structural Causal Model (SCM) to decipher the trajectory representation learning process from a causal perspective. Building upon the SCM, we further present a Trajectory modeling framework (TrajCL) based on Causal Learning, which leverages the backdoor adjustment theory as an intervention tool to eliminate the spurious correlations between geospatial context and trajectories. Extensive experiments on two real-world datasets verify that TrajCL markedly enhances performance in trajectory classification tasks while showcasing superior generalization and interpretability. ",
    "url": "https://arxiv.org/abs/2404.14073",
    "authors": [
      "Kang Luo",
      "Yuanshao Zhu",
      "Wei Chen",
      "Kun Wang",
      "Zhengyang Zhou",
      "Sijie Ruan",
      "Yuxuan Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.14087",
    "title": "A Tight Subexponential-time Algorithm for Two-Page Book Embedding",
    "abstract": "A book embedding of a graph is a drawing that maps vertices onto a line and edges to simple pairwise non-crossing curves drawn into pages, which are half-planes bounded by that line. Two-page book embeddings, i.e., book embeddings into 2 pages, are of special importance as they are both NP-hard to compute and have specific applications. We obtain a 2^(O(\\sqrt{n})) algorithm for computing a book embedding of an n-vertex graph on two pages -- a result which is asymptotically tight under the Exponential Time Hypothesis. As a key tool in our approach, we obtain a single-exponential fixed-parameter algorithm for the same problem when parameterized by the treewidth of the input graph. We conclude by establishing the fixed-parameter tractability of computing minimum-page book embeddings when parameterized by the feedback edge number, settling an open question arising from previous work on the problem. ",
    "url": "https://arxiv.org/abs/2404.14087",
    "authors": [
      "Robert Ganian",
      "Haiko Mueller",
      "Sebastian Ordyniak",
      "Giacomo Paesani",
      "Mateusz Rychlicki"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2404.14095",
    "title": "Immersive Rover Control and Obstacle Detection based on Extended Reality  and Artificial Intelligence",
    "abstract": "Lunar exploration has become a key focus, driving scientific and technological advances. Ongoing missions are deploying rovers to the surface of the Moon, targeting the far side and south pole. However, these terrains pose challenges, emphasizing the need for precise obstacles and resource detection to avoid mission risks. This work proposes a novel system that integrates eXtended Reality (XR) and Artificial Intelligence (AI) to teleoperate lunar rovers. It is capable of autonomously detecting rocks and recreating an immersive 3D virtual environment of the location of the robot. This system has been validated in a lunar laboratory to observe its advantages over traditional 2D-based teleoperation approaches ",
    "url": "https://arxiv.org/abs/2404.14095",
    "authors": [
      "Sof\u00eda Coloma",
      "Alexandre Frantz",
      "Dave van der Meer",
      "Ernest Skrzypczyk",
      "Andrej Orsula",
      "Miguel Olivares-Mendez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.14100",
    "title": "A Method of Joint Angle Estimation Using Only Relative Changes in Muscle  Lengths for Tendon-driven Humanoids with Complex Musculoskeletal Structures",
    "abstract": "Tendon-driven musculoskeletal humanoids typically have complex structures similar to those of human beings, such as ball joints and the scapula, in which encoders cannot be installed. Therefore, joint angles cannot be directly obtained and need to be estimated using the changes in muscle lengths. In previous studies, methods using table-search and extended kalman filter have been developed. These methods express the joint-muscle mapping, which is the nonlinear relationship between joint angles and muscle lengths, by using a data table, polynomials, or a neural network. However, due to computational complexity, these methods cannot consider the effects of polyarticular muscles. In this study, considering the limitation of the computational cost, we reduce unnecessary degrees of freedom, divide joints and muscles into several groups, and formulate a joint angle estimation method that takes into account polyarticular muscles. Also, we extend the estimation method to propose a joint angle estimation method using only the relative changes in muscle lengths. By this extension, which does not use absolute muscle lengths, we do not need to execute a difficult calibration of muscle lengths for tendon-driven musculoskeletal humanoids. Finally, we conduct experiments in simulation and actual environments, and verify the effectiveness of this study. ",
    "url": "https://arxiv.org/abs/2404.14100",
    "authors": [
      "Kento Kawaharazuka",
      "Shogo Makino",
      "Masaya Kawamura",
      "Yuki Asano",
      "Kei Okada",
      "Masayuki Inaba"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.14112",
    "title": "Investigating child sexual abuse material availability, searches, and  users on the anonymous Tor network for a public health intervention strategy",
    "abstract": "Tor is widely used for staying anonymous online and accessing onion websites; unfortunately, Tor is popular for distributing and viewing illicit child sexual abuse material (CSAM). From 2018 to 2023, we analyse 176,683 onion domains and find that one-fifth share CSAM. We find that CSAM is easily available using 21 out of the 26 most-used Tor search engines. We analyse 110,133,715 search sessions from the Ahmia.fi search engine and discover that 11.1% seek CSAM. When searching CSAM by age, 40.5% search for 11-year-olds and younger; 11.0% for 12-year-olds; 8.2% for 13-year-olds; 11.6% for 14-year-olds; 10.9% for 15-year-olds; and 12.7% for 16-year-olds. We demonstrate accurate filtering for search engines, introduce intervention, show a questionnaire for CSAM users, and analyse 11,470 responses. 65.3% of CSAM users first saw the material when they were children themselves, and half of the respondents first saw the material accidentally, demonstrating the availability of CSAM. 48.1% want to stop using CSAM. Some seek help through Tor, and self-help websites are popular. Our survey finds commonalities between CSAM use and addiction. Help-seeking correlates with increasing viewing duration and frequency, depression, anxiety, self-harming thoughts, guilt, and shame. Yet, 73.9% of help seekers have not been able to receive it. ",
    "url": "https://arxiv.org/abs/2404.14112",
    "authors": [
      "Juha Nurmi",
      "Arttu Paju",
      "Billy Bob Brumley",
      "Tegan Insoll",
      "Anna K. Ovaska",
      "Valeriia Soloveva",
      "Nina Vaaranen-Valkonen",
      "Mikko Aaltonen",
      "David Arroyo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.14132",
    "title": "CRNet: A Detail-Preserving Network for Unified Image Restoration and  Enhancement Task",
    "abstract": "In real-world scenarios, images captured often suffer from blurring, noise, and other forms of image degradation, and due to sensor limitations, people usually can only obtain low dynamic range images. To achieve high-quality images, researchers have attempted various image restoration and enhancement operations on photographs, including denoising, deblurring, and high dynamic range imaging. However, merely performing a single type of image enhancement still cannot yield satisfactory images. In this paper, to deal with the challenge above, we propose the Composite Refinement Network (CRNet) to address this issue using multiple exposure images. By fully integrating information-rich multiple exposure inputs, CRNet can perform unified image restoration and enhancement. To improve the quality of image details, CRNet explicitly separates and strengthens high and low-frequency information through pooling layers, using specially designed Multi-Branch Blocks for effective fusion of these frequencies. To increase the receptive field and fully integrate input features, CRNet employs the High-Frequency Enhancement Module, which includes large kernel convolutions and an inverted bottleneck ConvFFN. Our model secured third place in the first track of the Bracketing Image Restoration and Enhancement Challenge, surpassing previous SOTA models in both testing metrics and visual quality. ",
    "url": "https://arxiv.org/abs/2404.14132",
    "authors": [
      "Kangzhen Yang",
      "Tao Hu",
      "Kexin Dai",
      "Genggeng Chen",
      "Yu Cao",
      "Wei Dong",
      "Peng Wu",
      "Yanning Zhang",
      "Qingsen Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2404.14134",
    "title": "A participatory design approach to using social robots for elderly care",
    "abstract": "We present our ongoing research on applying a participatory design approach to using social robots for elderly care. Our approach involves four different groups of stakeholders: the elderly, (non-professional) caregivers, medical professionals, and psychologists. We focus on card sorting and storyboarding techniques to elicit the concerns of the stakeholders towards deploying social robots for elderly care. This is followed by semi-structured interviews to assess their attitudes towards social robots individually. Then we are conducting two-stage workshops with different elderly groups to understand how to engage them with the technology and to identify the challenges in this task. ",
    "url": "https://arxiv.org/abs/2404.14134",
    "authors": [
      "Barbara Sienkiewicz",
      "Zuzanna Radosz-Knawa",
      "Bipin Indurkhya"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2404.14138",
    "title": "Offensive AI: Enhancing Directory Brute-forcing Attack with the Use of  Language Models",
    "abstract": "Web Vulnerability Assessment and Penetration Testing (Web VAPT) is a comprehensive cybersecurity process that uncovers a range of vulnerabilities which, if exploited, could compromise the integrity of web applications. In a VAPT, it is common to perform a \\textit{Directory brute-forcing Attack}, aiming at the identification of accessible directories of a target website. Current commercial solutions are inefficient as they are based on brute-forcing strategies that use wordlists, resulting in enormous quantities of trials for a small amount of success. Offensive AI is a recent paradigm that integrates AI-based technologies in cyber attacks. In this work, we explore whether AI can enhance the directory enumeration process and propose a novel Language Model-based framework. Our experiments -- conducted in a testbed consisting of 1 million URLs from different web application domains (universities, hospitals, government, companies) -- demonstrate the superiority of the LM-based attack, with an average performance increase of 969%. ",
    "url": "https://arxiv.org/abs/2404.14138",
    "authors": [
      "Alberto Castagnaro",
      "Mauro Conti",
      "Luca Pajola"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.14167",
    "title": "A multi-robot system for the detection of explosive devices",
    "abstract": "In order to clear the world of the threat posed by landmines and other explosive devices, robotic systems can play an important role. However, the development of such field robots that need to operate in hazardous conditions requires the careful consideration of multiple aspects related to the perception, mobility, and collaboration capabilities of the system. In the framework of a European challenge, the Artificial Intelligence for Detection of Explosive Devices - eXtended (AIDEDeX) project proposes to design a heterogeneous multi-robot system with advanced sensor fusion algorithms. This system is specifically designed to detect and classify improvised explosive devices, explosive ordnances, and landmines. This project integrates specialised sensors, including electromagnetic induction, ground penetrating radar, X-Ray backscatter imaging, Raman spectrometers, and multimodal cameras, to achieve comprehensive threat identification and localisation. The proposed system comprises a fleet of unmanned ground vehicles and unmanned aerial vehicles. This article details the operational phases of the AIDEDeX system, from rapid terrain exploration using unmanned aerial vehicles to specialised detection and classification by unmanned ground vehicles equipped with a robotic manipulator. Initially focusing on a centralised approach, the project will also explore the potential of a decentralised control architecture, taking inspiration from swarm robotics to provide a robust, adaptable, and scalable solution for explosive detection. ",
    "url": "https://arxiv.org/abs/2404.14167",
    "authors": [
      "Ken Hasselmann",
      "Mario Malizia",
      "Rafael Caballero",
      "Fabio Polisano",
      "Shashank Govindaraj",
      "Jakob Stigler",
      "Oleksii Ilchenko",
      "Milan Bajic",
      "Geert De Cubber"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.14183",
    "title": "SemEval-2024 Task 8: Multidomain, Multimodel and Multilingual  Machine-Generated Text Detection",
    "abstract": "We present the results and the main findings of SemEval-2024 Task 8: Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection. The task featured three subtasks. Subtask A is a binary classification task determining whether a text is written by a human or generated by a machine. This subtask has two tracks: a monolingual track focused solely on English texts and a multilingual track. Subtask B is to detect the exact source of a text, discerning whether it is written by a human or generated by a specific LLM. Subtask C aims to identify the changing point within a text, at which the authorship transitions from human to machine. The task attracted a large number of participants: subtask A monolingual (126), subtask A multilingual (59), subtask B (70), and subtask C (30). In this paper, we present the task, analyze the results, and discuss the system submissions and the methods they used. For all subtasks, the best systems used LLMs. ",
    "url": "https://arxiv.org/abs/2404.14183",
    "authors": [
      "Yuxia Wang",
      "Jonibek Mansurov",
      "Petar Ivanov",
      "Jinyan Su",
      "Artem Shelmanov",
      "Akim Tsvigun",
      "Osama Mohammed Afzal",
      "Tarek Mahmoud",
      "Giovanni Puccetti",
      "Thomas Arnold",
      "Chenxi Whitehouse",
      "Alham Fikri Aji",
      "Nizar Habash",
      "Iryna Gurevych",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.14190",
    "title": "Dismantling Common Internet Services for Ad-Malware Detection",
    "abstract": "Online advertising represents a main instrument for publishers to fund content on the World Wide Web. Unfortunately, a significant number of online advertisements often accommodates potentially malicious content, such as cryptojacking hidden in web banners - even on reputable websites. In order to protect Internet users from such online threats, the thorough detection of ad-malware campaigns plays a crucial role for a safe Web. Today, common Internet services like VirusTotal can label suspicious content based on feedback from contributors and from the entire Web community. However, it is open to which extent ad-malware is actually taken into account and whether the results of these services are consistent. In this pre-study, we evaluate who defines ad-malware on the Internet. In a first step, we crawl a vast set of websites and fetch all HTTP requests (particularly to online advertisements) within these websites. Then we query these requests both against popular filtered DNS providers and VirusTotal. The idea is to validate, how much content is labeled as a potential threat. The results show that up to 0.47% of the domains found during crawling are labeled as suspicious by DNS providers and up to 8.8% by VirusTotal. Moreover, only about 0.7% to 3.2% of these domains are categorized as ad-malware. The overall responses from the used Internet services paint a divergent picture: All considered services have different understandings to the definition of suspicious content. Thus, we outline potential research efforts to the automated detection of ad-malware. We further bring up the open question of a common definition of ad-malware to the Web community. ",
    "url": "https://arxiv.org/abs/2404.14190",
    "authors": [
      "Florian Nettersheim",
      "Stephan Arlt",
      "Michael Rademacher"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.14193",
    "title": "LLAMP: Assessing Network Latency Tolerance of HPC Applications with  Linear Programming",
    "abstract": "The shift towards high-bandwidth networks driven by AI workloads in data centers and HPC clusters has unintentionally aggravated network latency, adversely affecting the performance of communication-intensive HPC applications. As large-scale MPI applications often exhibit significant differences in their network latency tolerance, it is crucial to accurately determine the extent of network latency an application can withstand without significant performance degradation. Current approaches to assessing this metric often rely on specialized hardware or network simulators, which can be inflexible and time-consuming. In response, we introduce LLAMP, a novel toolchain that offers an efficient, analytical approach to evaluating HPC applications' network latency tolerance using the LogGPS model and linear programming. LLAMP equips software developers and network architects with essential insights for optimizing HPC infrastructures and strategically deploying applications to minimize latency impacts. Through our validation on a variety of MPI applications like MILC, LULESH, and LAMMPS, we demonstrate our tool's high accuracy, with relative prediction errors generally below 2%. Additionally, we include a case study of the ICON weather and climate model to illustrate LLAMP's broad applicability in evaluating collective algorithms and network topologies. ",
    "url": "https://arxiv.org/abs/2404.14193",
    "authors": [
      "Siyuan Shen",
      "Langwen Huang",
      "Marcin Chrapek",
      "Timo Schneider",
      "Jai Dayal",
      "Manisha Gajbe",
      "Robert Wisniewski",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2404.14199",
    "title": "Generalizable Neural Human Renderer",
    "abstract": "While recent advancements in animatable human rendering have achieved remarkable results, they require test-time optimization for each subject which can be a significant limitation for real-world applications. To address this, we tackle the challenging task of learning a Generalizable Neural Human Renderer (GNH), a novel method for rendering animatable humans from monocular video without any test-time optimization. Our core method focuses on transferring appearance information from the input video to the output image plane by utilizing explicit body priors and multi-view geometry. To render the subject in the intended pose, we utilize a straightforward CNN-based image renderer, foregoing the more common ray-sampling or rasterizing-based rendering modules. Our GNH achieves remarkable generalizable, photorealistic rendering with unseen subjects with a three-stage process. We quantitatively and qualitatively demonstrate that GNH significantly surpasses current state-of-the-art methods, notably achieving a 31.3% improvement in LPIPS. ",
    "url": "https://arxiv.org/abs/2404.14199",
    "authors": [
      "Mana Masuda",
      "Jinhyung Park",
      "Shun Iwase",
      "Rawal Khirodkar",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14228",
    "title": "A Survey of Decomposition-Based Evolutionary Multi-Objective  Optimization: Part II -- A Data Science Perspective",
    "abstract": "This paper presents the second part of the two-part survey series on decomposition-based evolutionary multi-objective optimization where we mainly focus on discussing the literature related to multi-objective evolutionary algorithms based on decomposition (MOEA/D). Complementary to the first part, here we employ a series of advanced data mining approaches to provide a comprehensive anatomy of the enormous landscape of MOEA/D research, which is far beyond the capacity of classic manual literature review protocol. In doing so, we construct a heterogeneous knowledge graph that encapsulates more than 5,400 papers, 10,000 authors, 400 venues, and 1,600 institutions for MOEA/D research. We start our analysis with basic descriptive statistics. Then we delve into prominent research/application topics pertaining to MOEA/D with state-of-the-art topic modeling techniques and interrogate their sptial-temporal and bilateral relationships. We also explored the collaboration and citation networks of MOEA/D, uncovering hidden patterns in the growth of literature as well as collaboration between researchers. Our data mining results here, combined with the expert review in Part I, together offer a holistic view of the MOEA/D research, and demonstrate the potential of an exciting new paradigm for conducting scientific surveys from a data science perspective. ",
    "url": "https://arxiv.org/abs/2404.14228",
    "authors": [
      "Mingyu Huang",
      "Ke Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2404.14232",
    "title": "Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting  and Cognitive Load on User Attention and Saliency Prediction",
    "abstract": "Visual highlighting can guide user attention in complex interfaces. However, its effectiveness under limited attentional capacities is underexplored. This paper examines the joint impact of visual highlighting (permanent and dynamic) and dual-task-induced cognitive load on gaze behaviour. Our analysis, using eye-movement data from 27 participants viewing 150 unique webpages reveals that while participants' ability to attend to UI elements decreases with increasing cognitive load, dynamic adaptations (i.e., highlighting) remain attention-grabbing. The presence of these factors significantly alters what people attend to and thus what is salient. Accordingly, we show that state-of-the-art saliency models increase their performance when accounting for different cognitive loads. Our empirical insights, along with our openly available dataset, enhance our understanding of attentional processes in UIs under varying cognitive (and perceptual) loads and open the door for new models that can predict user attention while multitasking. ",
    "url": "https://arxiv.org/abs/2404.14232",
    "authors": [
      "Anwesha Das",
      "Zekun Wu",
      "Iza \u0160krjanec",
      "Anna Maria Feit"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.14235",
    "title": "Computing the LCP Array of a Labeled Graph",
    "abstract": "The LCP array is an important tool in stringology, allowing to speed up pattern matching algorithms and enabling compact representations of the suffix tree. Recently, Conte et al. [DCC 2023] and Cotumaccio et al. [SPIRE 2023] extended the definition of this array to Wheeler DFAs and, ultimately, to arbitrary labeled graphs, proving that it can be used to efficiently solve matching statistics queries on the graph's paths. In this paper, we provide the first efficient algorithm building the LCP array of a directed labeled graph with $n$ nodes and $m$ edges labeled over an alphabet of size $\\sigma$. After arguing that the natural generalization of a compact-space LCP-construction algorithm by Beller et al. [J. Discrete Algorithms 2013] runs in time $\\Omega(n\\sigma)$, we present a new algorithm based on dynamic range stabbing building the LCP array in $O(n\\log \\sigma)$ time and $O(n\\log\\sigma)$ bits of working space. ",
    "url": "https://arxiv.org/abs/2404.14235",
    "authors": [
      "Jarno Alanko",
      "Davide Cenzato",
      "Nicola Cotumaccio",
      "Sung-Hwan Kim",
      "Giovanni Manzini",
      "Nicola Prezza"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2404.14243",
    "title": "Turbo-CF: Matrix Decomposition-Free Graph Filtering for Fast  Recommendation",
    "abstract": "A series of graph filtering (GF)-based collaborative filtering (CF) showcases state-of-the-art performance on the recommendation accuracy by using a low-pass filter (LPF) without a training process. However, conventional GF-based CF approaches mostly perform matrix decomposition on the item-item similarity graph to realize the ideal LPF, which results in a non-trivial computational cost and thus makes them less practical in scenarios where rapid recommendations are essential. In this paper, we propose Turbo-CF, a GF-based CF method that is both training-free and matrix decomposition-free. Turbo-CF employs a polynomial graph filter to circumvent the issue of expensive matrix decompositions, enabling us to make full use of modern computer hardware components (i.e., GPU). Specifically, Turbo-CF first constructs an item-item similarity graph whose edge weights are effectively regulated. Then, our own polynomial LPFs are designed to retain only low-frequency signals without explicit matrix decompositions. We demonstrate that Turbo-CF is extremely fast yet accurate, achieving a runtime of less than 1 second on real-world benchmark datasets while achieving recommendation accuracies comparable to best competitors. ",
    "url": "https://arxiv.org/abs/2404.14243",
    "authors": [
      "Jin-Duk Park",
      "Yong-Min Shin",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2404.14247",
    "title": "From Modalities to Styles: Rethinking the Domain Gap in Heterogeneous  Face Recognition",
    "abstract": "Heterogeneous Face Recognition (HFR) focuses on matching faces from different domains, for instance, thermal to visible images, making Face Recognition (FR) systems more versatile for challenging scenarios. However, the domain gap between these domains and the limited large-scale datasets in the target HFR modalities make it challenging to develop robust HFR models from scratch. In our work, we view different modalities as distinct styles and propose a method to modulate feature maps of the target modality to address the domain gap. We present a new Conditional Adaptive Instance Modulation (CAIM ) module that seamlessly fits into existing FR networks, turning them into HFR-ready systems. The CAIM block modulates intermediate feature maps, efficiently adapting to the style of the source modality and bridging the domain gap. Our method enables end-to-end training using a small set of paired samples. We extensively evaluate the proposed approach on various challenging HFR benchmarks, showing that it outperforms state-of-the-art methods. The source code and protocols for reproducing the findings will be made publicly available ",
    "url": "https://arxiv.org/abs/2404.14247",
    "authors": [
      "Anjith George",
      "Sebastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14271",
    "title": "Sparse Explanations of Neural Networks Using Pruned Layer-Wise Relevance  Propagation",
    "abstract": "Explainability is a key component in many applications involving deep neural networks (DNNs). However, current explanation methods for DNNs commonly leave it to the human observer to distinguish relevant explanations from spurious noise. This is not feasible anymore when going from easily human-accessible data such as images to more complex data such as genome sequences. To facilitate the accessibility of DNN outputs from such complex data and to increase explainability, we present a modification of the widely used explanation method layer-wise relevance propagation. Our approach enforces sparsity directly by pruning the relevance propagation for the different layers. Thereby, we achieve sparser relevance attributions for the input features as well as for the intermediate layers. As the relevance propagation is input-specific, we aim to prune the relevance propagation rather than the underlying model architecture. This allows to prune different neurons for different inputs and hence, might be more appropriate to the local nature of explanation methods. To demonstrate the efficacy of our method, we evaluate it on two types of data, images and genomic sequences. We show that our modification indeed leads to noise reduction and concentrates relevance on the most important features compared to the baseline. ",
    "url": "https://arxiv.org/abs/2404.14271",
    "authors": [
      "Paulo Yanez Sarmiento",
      "Simon Witzke",
      "Nadja Klein",
      "Bernhard Y. Renard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.14280",
    "title": "RESFM: Robust Equivariant Multiview Structure from Motion",
    "abstract": "Multiview Structure from Motion is a fundamental and challenging computer vision problem. A recent deep-based approach was proposed utilizing matrix equivariant architectures for the simultaneous recovery of camera pose and 3D scene structure from large image collections. This work however made the unrealistic assumption that the point tracks given as input are clean of outliers. Here we propose an architecture suited to dealing with outliers by adding an inlier/outlier classifying module that respects the model equivariance and by adding a robust bundle adjustment step. Experiments demonstrate that our method can be successfully applied in realistic settings that include large image collections and point tracks extracted with common heuristics and include many outliers. ",
    "url": "https://arxiv.org/abs/2404.14280",
    "authors": [
      "Fadi Khatib",
      "Yoni Kasten",
      "Dror Moran",
      "Meirav Galun",
      "Ronen Basri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14281",
    "title": "Fast and Robust Normal Estimation for Sparse LiDAR Scans",
    "abstract": "Light Detection and Ranging (LiDAR) technology has proven to be an important part of many robotics systems. Surface normals estimated from LiDAR data are commonly used for a variety of tasks in such systems. As most of the today's mechanical LiDAR sensors produce sparse data, estimating normals from a single scan in a robust manner poses difficulties. In this paper, we address the problem of estimating normals for sparse LiDAR data avoiding the typical issues of smoothing out the normals in high curvature areas. Mechanical LiDARs rotate a set of rigidly mounted lasers. One firing of such a set of lasers produces an array of points where each point's neighbor is known due to the known firing pattern of the scanner. We use this knowledge to connect these points to their neighbors and label them using the angles of the lines connecting them. When estimating normals at these points, we only consider points with the same label as neighbors. This allows us to avoid estimating normals in high curvature areas. We evaluate our approach on various data, both self-recorded and publicly available, acquired using various sparse LiDAR sensors. We show that using our method for normal estimation leads to normals that are more robust in areas with high curvature which leads to maps of higher quality. We also show that our method only incurs a constant factor runtime overhead with respect to a lightweight baseline normal estimation procedure and is therefore suited for operation in computationally demanding environments. ",
    "url": "https://arxiv.org/abs/2404.14281",
    "authors": [
      "Igor Bogoslavskyi",
      "Konstantinos Zampogiannis",
      "Raymond Phan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14282",
    "title": "Blockchain in a box: A portable blockchain network implementation on  Raspberry Pi's",
    "abstract": "In this paper we describe a prototype of a blockchain-in-a-box system which allows users to easily bootstrap the whole Ethereum Proof-of-Work (PoW) network running on multiple Raspberry Pi nodes - an inexpensive modular computers. Users are able to orchestrate the whole blockchain network using a single web based interface, for example they are able to set the topology of the peer-to-peer (P2P) connections and control the initialization parameters. Each Raspberry Pi has a screen attached which visualizes current state of local blockchain, allowing users to easily visualize the consensus of the network in real time. We show how this platform can be used to perform experiments on consensus quality while using different P2P topologies. Similar experiments can be used for demonstration purposes in a workshop or other educational settings. ",
    "url": "https://arxiv.org/abs/2404.14282",
    "authors": [
      "Matija Pi\u0161korec",
      "Anton Ivaskevich",
      "Said Haji Abukar",
      "Lundrim Azemi",
      "Md Rezuanul Haque",
      "Mostafa Chegenizadeh",
      "Claudio J. Tessone"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2404.14296",
    "title": "Does Your Neural Code Completion Model Use My Code? A Membership  Inference Approach",
    "abstract": "Recent years have witnessed significant progress in developing deep learning-based models for automated code completion. Although using source code in GitHub has been a common practice for training deep-learning-based models for code completion, it may induce some legal and ethical issues such as copyright infringement. In this paper, we investigate the legal and ethical issues of current neural code completion models by answering the following question: Is my code used to train your neural code completion model? To this end, we tailor a membership inference approach (termed CodeMI) that was originally crafted for classification tasks to a more challenging task of code completion. In particular, since the target code completion models perform as opaque black boxes, preventing access to their training data and parameters, we opt to train multiple shadow models to mimic their behavior. The acquired posteriors from these shadow models are subsequently employed to train a membership classifier. Subsequently, the membership classifier can be effectively employed to deduce the membership status of a given code sample based on the output of a target code completion model. We comprehensively evaluate the effectiveness of this adapted approach across a diverse array of neural code completion models, (i.e., LSTM-based, CodeGPT, CodeGen, and StarCoder). Experimental results reveal that the LSTM-based and CodeGPT models suffer the membership leakage issue, which can be easily detected by our proposed membership inference approach with an accuracy of 0.842, and 0.730, respectively. Interestingly, our experiments also show that the data membership of current large language models of code, e.g., CodeGen and StarCoder, is difficult to detect, leaving amper space for further improvement. Finally, we also try to explain the findings from the perspective of model memorization. ",
    "url": "https://arxiv.org/abs/2404.14296",
    "authors": [
      "Yao Wan",
      "Guanghua Wan",
      "Shijie Zhang",
      "Hongyu Zhang",
      "Yulei Sui",
      "Pan Zhou",
      "Hai Jin",
      "Lichao Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.14304",
    "title": "Explaining Arguments' Strength: Unveiling the Role of Attacks and  Supports (Technical Report)",
    "abstract": "Quantitatively explaining the strength of arguments under gradual semantics has recently received increasing attention. Specifically, several works in the literature provide quantitative explanations by computing the attribution scores of arguments. These works disregard the importance of attacks and supports, even though they play an essential role when explaining arguments' strength. In this paper, we propose a novel theory of Relation Attribution Explanations (RAEs), adapting Shapley values from game theory to offer fine-grained insights into the role of attacks and supports in quantitative bipolar argumentation towards obtaining the arguments' strength. We show that RAEs satisfy several desirable properties. We also propose a probabilistic algorithm to approximate RAEs efficiently. Finally, we show the application value of RAEs in fraud detection and large language models case studies. ",
    "url": "https://arxiv.org/abs/2404.14304",
    "authors": [
      "Xiang Yin",
      "Potyka Nico",
      "Francesca Toni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.14309",
    "title": "Towards Better Adversarial Purification via Adversarial Denoising  Diffusion Training",
    "abstract": "Recently, diffusion-based purification (DBP) has emerged as a promising approach for defending against adversarial attacks. However, previous studies have used questionable methods to evaluate the robustness of DBP models, their explanations of DBP robustness also lack experimental support. We re-examine DBP robustness using precise gradient, and discuss the impact of stochasticity on DBP robustness. To better explain DBP robustness, we assess DBP robustness under a novel attack setting, Deterministic White-box, and pinpoint stochasticity as the main factor in DBP robustness. Our results suggest that DBP models rely on stochasticity to evade the most effective attack direction, rather than directly countering adversarial perturbations. To improve the robustness of DBP models, we propose Adversarial Denoising Diffusion Training (ADDT). This technique uses Classifier-Guided Perturbation Optimization (CGPO) to generate adversarial perturbation through guidance from a pre-trained classifier, and uses Rank-Based Gaussian Mapping (RBGM) to convert adversarial pertubation into a normal Gaussian distribution. Empirical results show that ADDT improves the robustness of DBP models. Further experiments confirm that ADDT equips DBP models with the ability to directly counter adversarial perturbations. ",
    "url": "https://arxiv.org/abs/2404.14309",
    "authors": [
      "Yiming Liu",
      "Kezhao Liu",
      "Yao Xiao",
      "Ziyi Dong",
      "Xiaogang Xu",
      "Pengxu Wei",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14312",
    "title": "Structure-preserving neural networks for the regularzied entropy-based  closure of the Boltzmann moment system",
    "abstract": "The main challenge of large-scale numerical simulation of radiation transport is the high memory and computation time requirements of discretization methods for kinetic equations. In this work, we derive and investigate a neural network-based approximation to the entropy closure method to accurately compute the solution of the multi-dimensional moment system with a low memory footprint and competitive computational time. We extend methods developed for the standard entropy-based closure to the context of regularized entropy-based closures. The main idea is to interpret structure-preserving neural network approximations of the regularized entropy closure as a two-stage approximation to the original entropy closure. We conduct a numerical analysis of this approximation and investigate optimal parameter choices. Our numerical experiments demonstrate that the method has a much lower memory footprint than traditional methods with competitive computation times and simulation accuracy. The code and all trained networks are provided on GitHub\\footnote{\\url{https://github.com/ScSteffen/neuralEntropyClosures}}$^,$\\footnote{\\url{https://github.com/CSMMLab/KiT-RT}}. ",
    "url": "https://arxiv.org/abs/2404.14312",
    "authors": [
      "Steffen Schotth\u00f6fer",
      "M. Paul Laiu",
      "Martin Frank",
      "Cory D. Hauck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.14313",
    "title": "Self-Supervised Alignment with Mutual Information: Learning to Follow  Principles without Preference Labels",
    "abstract": "When prompting a language model (LM), users frequently expect the model to adhere to a set of behavioral principles across diverse tasks, such as producing insightful content while avoiding harmful or biased language. Instilling such principles into a model can be resource-intensive and technically challenging, generally requiring human preference labels or examples. We introduce SAMI, a method for teaching a pretrained LM to follow behavioral principles that does not require any preference labels or demonstrations. SAMI is an iterative algorithm that finetunes a pretrained LM to increase the conditional mutual information between constitutions and self-generated responses given queries from a datasest. On single-turn dialogue and summarization, a SAMI-trained mistral-7b outperforms the initial pretrained model, with win rates between 66% and 77%. Strikingly, it also surpasses an instruction-finetuned baseline (mistral-7b-instruct) with win rates between 55% and 57% on single-turn dialogue. SAMI requires a \"principle writer\" model; to avoid dependence on stronger models, we further evaluate aligning a strong pretrained model (mixtral-8x7b) using constitutions written by a weak instruction-finetuned model (mistral-7b-instruct). The SAMI-trained mixtral-8x7b outperforms both the initial model and the instruction-finetuned model, achieving a 65% win rate on summarization. Our results indicate that a pretrained LM can learn to follow constitutions without using preference labels, demonstrations, or human oversight. ",
    "url": "https://arxiv.org/abs/2404.14313",
    "authors": [
      "Jan-Philipp Fr\u00e4nken",
      "Eric Zelikman",
      "Rafael Rafailov",
      "Kanishk Gandhi",
      "Tobias Gerstenberg",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.14329",
    "title": "X-Ray: A Sequential 3D Representation for Generation",
    "abstract": "In this paper, we introduce X-Ray, an innovative approach to 3D generation that employs a new sequential representation, drawing inspiration from the depth-revealing capabilities of X-Ray scans to meticulously capture both the external and internal features of objects. Central to our method is the utilization of ray casting techniques originating from the camera's viewpoint, meticulously recording the geometric and textural details encountered across all intersected surfaces. This process efficiently condenses complete objects or scenes into a multi-frame format, just like videos. Such a structure ensures the 3D representation is composed solely of critical surface information. Highlighting the practicality and adaptability of our X-Ray representation, we showcase its utility in synthesizing 3D objects, employing a network architecture akin to that used in video diffusion models. The outcomes reveal our representation's superior performance in enhancing both the accuracy and efficiency of 3D synthesis, heralding new directions for ongoing research and practical implementations in the field. ",
    "url": "https://arxiv.org/abs/2404.14329",
    "authors": [
      "Tao Hu",
      "Wenhang Ge",
      "Yuyang Zhao",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14339",
    "title": "Zero-shot Cross-lingual Stance Detection via Adversarial Language  Adaptation",
    "abstract": "Stance detection has been widely studied as the task of determining if a social media post is positive, negative or neutral towards a specific issue, such as support towards vaccines. Research in stance detection has however often been limited to a single language and, where more than one language has been studied, research has focused on few-shot settings, overlooking the challenges of developing a zero-shot cross-lingual stance detection model. This paper makes the first such effort by introducing a novel approach to zero-shot cross-lingual stance detection, Multilingual Translation-Augmented BERT (MTAB), aiming to enhance the performance of a cross-lingual classifier in the absence of explicit training data for target languages. Our technique employs translation augmentation to improve zero-shot performance and pairs it with adversarial learning to further boost model efficacy. Through experiments on datasets labeled for stance towards vaccines in four languages English, German, French, Italian. We demonstrate the effectiveness of our proposed approach, showcasing improved results in comparison to a strong baseline model as well as ablated versions of our model. Our experiments demonstrate the effectiveness of model components, not least the translation-augmented data as well as the adversarial learning component, to the improved performance of the model. We have made our source code accessible on GitHub. ",
    "url": "https://arxiv.org/abs/2404.14339",
    "authors": [
      "Bharathi A",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.14343",
    "title": "Heterogeneous Face Recognition Using Domain Invariant Units",
    "abstract": "Heterogeneous Face Recognition (HFR) aims to expand the applicability of Face Recognition (FR) systems to challenging scenarios, enabling the matching of face images across different domains, such as matching thermal images to visible spectra. However, the development of HFR systems is challenging because of the significant domain gap between modalities and the lack of availability of large-scale paired multi-channel data. In this work, we leverage a pretrained face recognition model as a teacher network to learn domaininvariant network layers called Domain-Invariant Units (DIU) to reduce the domain gap. The proposed DIU can be trained effectively even with a limited amount of paired training data, in a contrastive distillation framework. This proposed approach has the potential to enhance pretrained models, making them more adaptable to a wider range of variations in data. We extensively evaluate our approach on multiple challenging benchmarks, demonstrating superior performance compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2404.14343",
    "authors": [
      "Anjith George",
      "Sebastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14357",
    "title": "A Stochastic Geo-spatiotemporal Bipartite Network to Optimize GCOOS  Sensor Placement Strategies",
    "abstract": "This paper proposes two new measures applicable in a spatial bipartite network model: coverage and coverage robustness. The bipartite network must consist of observer nodes, observable nodes, and edges that connect observer nodes to observable nodes. The coverage and coverage robustness scores evaluate the effectiveness of the observer node placements. This measure is beneficial for stochastic data as it may be coupled with Monte Carlo simulations to identify optimal placements for new observer nodes. In this paper, we construct a Geo-SpatioTemporal Bipartite Network (GSTBN) within the stochastic and dynamical environment of the Gulf of Mexico. This GSTBN consists of GCOOS sensor nodes and HYCOM Region of Interest (RoI) event nodes. The goal is to identify optimal placements to expand GCOOS to improve the forecasting outcomes by the HYCOM ocean prediction model. ",
    "url": "https://arxiv.org/abs/2404.14357",
    "authors": [
      "Ted Edward Holmberg",
      "Elias Ioup",
      "Mahdi Abdelguerfi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2404.14370",
    "title": "Assessing GPT-4-Vision's Capabilities in UML-Based Code Generation",
    "abstract": "The emergence of advanced neural networks has opened up new ways in automated code generation from conceptual models, promising to enhance software development processes. This paper presents a preliminary evaluation of GPT-4-Vision, a state-of-the-art deep learning model, and its capabilities in transforming Unified Modeling Language (UML) class diagrams into fully operating Java class files. In our study, we used exported images of 18 class diagrams comprising 10 single-class and 8 multi-class diagrams. We used 3 different prompts for each input, and we manually evaluated the results. We created a scoring system in which we scored the occurrence of elements found in the diagram within the source code. On average, the model was able to generate source code for 88% of the elements shown in the diagrams. Our results indicate that GPT-4-Vision exhibits proficiency in handling single-class UML diagrams, successfully transforming them into syntactically correct class files. However, for multi-class UML diagrams, the model's performance is weaker compared to single-class diagrams. In summary, further investigations are necessary to exploit the model's potential completely. ",
    "url": "https://arxiv.org/abs/2404.14370",
    "authors": [
      "G\u00e1bor Antal",
      "Rich\u00e1rd Voz\u00e1r",
      "Rudolf Ferenc"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2404.14372",
    "title": "Beyond Scaling: Predicting Patent Approval with Domain-specific  Fine-grained Claim Dependency Graph",
    "abstract": "Model scaling is becoming the default choice for many language tasks due to the success of large language models (LLMs). However, it can fall short in specific scenarios where simple customized methods excel. In this paper, we delve into the patent approval pre-diction task and unveil that simple domain-specific graph methods outperform enlarging the model, using the intrinsic dependencies within the patent data. Specifically, we first extend the embedding-based state-of-the-art (SOTA) by scaling up its backbone model with various sizes of open-source LLMs, then explore prompt-based methods to harness proprietary LLMs' potential, but find the best results close to random guessing, underlining the ineffectiveness of model scaling-up. Hence, we propose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulous patent data analyses, capturing the inherent dependencies across segments of the patent text. As it is model-agnostic, we apply cost-effective graph models to our FLAN Graph to obtain representations for approval prediction. Extensive experiments and detailed analyses prove that incorporating FLAN Graph via various graph models consistently outperforms all LLM baselines significantly. We hope that our observations and analyses in this paper can bring more attention to this challenging task and prompt further research into the limitations of LLMs. Our source code and dataset can be obtained from this http URL ",
    "url": "https://arxiv.org/abs/2404.14372",
    "authors": [
      "Xiaochen Kev Gao",
      "Feng Yao",
      "Kewen Zhao",
      "Beilei He",
      "Animesh Kumar",
      "Vish Krishnan",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.14389",
    "title": "Poisoning Attacks on Federated Learning-based Wireless Traffic  Prediction",
    "abstract": "Federated Learning (FL) offers a distributed framework to train a global control model across multiple base stations without compromising the privacy of their local network data. This makes it ideal for applications like wireless traffic prediction (WTP), which plays a crucial role in optimizing network resources, enabling proactive traffic flow management, and enhancing the reliability of downstream communication-aided applications, such as IoT devices, autonomous vehicles, and industrial automation systems. Despite its promise, the security aspects of FL-based distributed wireless systems, particularly in regression-based WTP problems, remain inadequately investigated. In this paper, we introduce a novel fake traffic injection (FTI) attack, designed to undermine the FL-based WTP system by injecting fabricated traffic distributions with minimal knowledge. We further propose a defense mechanism, termed global-local inconsistency detection (GLID), which strategically removes abnormal model parameters that deviate beyond a specific percentile range estimated through statistical methods in each dimension. Extensive experimental evaluations, performed on real-world wireless traffic datasets, demonstrate that both our attack and defense strategies significantly outperform existing baselines. ",
    "url": "https://arxiv.org/abs/2404.14389",
    "authors": [
      "Zifan Zhang",
      "Minghong Fang",
      "Jiayuan Huang",
      "Yuchen Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13101",
    "title": "DensePANet: An improved generative adversarial network for photoacoustic  tomography image reconstruction from sparse data",
    "abstract": "Image reconstruction is an essential step of every medical imaging method, including Photoacoustic Tomography (PAT), which is a promising modality of imaging, that unites the benefits of both ultrasound and optical imaging methods. Reconstruction of PAT images using conventional methods results in rough artifacts, especially when applied directly to sparse PAT data. In recent years, generative adversarial networks (GANs) have shown a powerful performance in image generation as well as translation, rendering them a smart choice to be applied to reconstruction tasks. In this study, we proposed an end-to-end method called DensePANet to solve the problem of PAT image reconstruction from sparse data. The proposed model employs a novel modification of UNet in its generator, called FD-UNet++, which considerably improves the reconstruction performance. We evaluated the method on various in-vivo and simulated datasets. Quantitative and qualitative results show the better performance of our model over other prevalent deep learning techniques. ",
    "url": "https://arxiv.org/abs/2404.13101",
    "authors": [
      "Hesam hakimnejad",
      "Zohreh Azimifar",
      "Narjes Goshtasbi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13103",
    "title": "ToNNO: Tomographic Reconstruction of a Neural Network's Output for  Weakly Supervised Segmentation of 3D Medical Images",
    "abstract": "Annotating lots of 3D medical images for training segmentation models is time-consuming. The goal of weakly supervised semantic segmentation is to train segmentation models without using any ground truth segmentation masks. Our work addresses the case where only image-level categorical labels, indicating the presence or absence of a particular region of interest (such as tumours or lesions), are available. Most existing methods rely on class activation mapping (CAM). We propose a novel approach, ToNNO, which is based on the Tomographic reconstruction of a Neural Network's Output. Our technique extracts stacks of slices with different angles from the input 3D volume, feeds these slices to a 2D encoder, and applies the inverse Radon transform in order to reconstruct a 3D heatmap of the encoder's predictions. This generic method allows to perform dense prediction tasks on 3D volumes using any 2D image encoder. We apply it to weakly supervised medical image segmentation by training the 2D encoder to output high values for slices containing the regions of interest. We test it on four large scale medical image datasets and outperform 2D CAM methods. We then extend ToNNO by combining tomographic reconstruction with CAM methods, proposing Averaged CAM and Tomographic CAM, which obtain even better results. ",
    "url": "https://arxiv.org/abs/2404.13103",
    "authors": [
      "Marius Schmidt-Mengin",
      "Alexis Benichoux",
      "Shibeshih Belachew",
      "Nikos Komodakis",
      "Nikos Paragios"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13106",
    "title": "Automatic Cranial Defect Reconstruction with Self-Supervised Deep  Deformable Masked Autoencoders",
    "abstract": "Thousands of people suffer from cranial injuries every year. They require personalized implants that need to be designed and manufactured before the reconstruction surgery. The manual design is expensive and time-consuming leading to searching for algorithms whose goal is to automatize the process. The problem can be formulated as volumetric shape completion and solved by deep neural networks dedicated to supervised image segmentation. However, such an approach requires annotating the ground-truth defects which is costly and time-consuming. Usually, the process is replaced with synthetic defect generation. However, even the synthetic ground-truth generation is time-consuming and limits the data heterogeneity, thus the deep models' generalizability. In our work, we propose an alternative and simple approach to use a self-supervised masked autoencoder to solve the problem. This approach by design increases the heterogeneity of the training set and can be seen as a form of data augmentation. We compare the proposed method with several state-of-the-art deep neural networks and show both the quantitative and qualitative improvement on the SkullBreak and SkullFix datasets. The proposed method can be used to efficiently reconstruct the cranial defects in real time. ",
    "url": "https://arxiv.org/abs/2404.13106",
    "authors": [
      "Marek Wodzinski",
      "Daria Hemmerling",
      "Mateusz Daniol"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13155",
    "title": "On the rectilinear crossing number of complete balanced multipartite  graphs and layered graphs",
    "abstract": "A rectilinear drawing of a graph is a drawing of the graph in the plane in which the edges are drawn as straight-line segments. The rectilinear crossing number of a graph is the minimum number of pairs of edges that cross over all rectilinear drawings of the graph. Let $n \\ge r$ be positive integers. The graph $K_n^r$, is the complete $r$-partite graph on $n$ vertices, in which every set of the partition has at least $\\lfloor n/r \\rfloor$ vertices. The layered graph, $L_n^r$, is an $r$-partite graph on $n$ vertices, in which for every $1\\le i \\le r-1$, all the vertices in the $i$-th partition are adjacent to all the vertices in the $(i+1)$-th partition. In this paper, we give upper bounds on the rectilinear crossing numbers of $K_n^r$ and~$L_n^r$. ",
    "url": "https://arxiv.org/abs/2404.13155",
    "authors": [
      "Ruy Fabila-Monroy",
      "Rosna Paul",
      "Jenifer Viafara-Chanchi",
      "Alexandra Weinberger"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2404.13185",
    "title": "Unlocking Robust Segmentation Across All Age Groups via Continual  Learning",
    "abstract": "Most deep learning models in medical imaging are trained on adult data with unclear performance on pediatric images. In this work, we aim to address this challenge in the context of automated anatomy segmentation in whole-body Computed Tomography (CT). We evaluate the performance of CT organ segmentation algorithms trained on adult data when applied to pediatric CT volumes and identify substantial age-dependent underperformance. We subsequently propose and evaluate strategies, including data augmentation and continual learning approaches, to achieve good segmentation accuracy across all age groups. Our best-performing model, trained using continual learning, achieves high segmentation accuracy on both adult and pediatric data (Dice scores of 0.90 and 0.84 respectively). ",
    "url": "https://arxiv.org/abs/2404.13185",
    "authors": [
      "Chih-Ying Liu",
      "Jeya Maria Jose Valanarasu",
      "Camila Gonzalez",
      "Curtis Langlotz",
      "Andrew Ng",
      "Sergios Gatidis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13198",
    "title": "An economically-consistent discrete choice model with flexible utility  specification based on artificial neural networks",
    "abstract": "Random utility maximisation (RUM) models are one of the cornerstones of discrete choice modelling. However, specifying the utility function of RUM models is not straightforward and has a considerable impact on the resulting interpretable outcomes and welfare measures. In this paper, we propose a new discrete choice model based on artificial neural networks (ANNs) named \"Alternative-Specific and Shared weights Neural Network (ASS-NN)\", which provides a further balance between flexible utility approximation from the data and consistency with two assumptions: RUM theory and fungibility of money (i.e., \"one euro is one euro\"). Therefore, the ASS-NN can derive economically-consistent outcomes, such as marginal utilities or willingness to pay, without explicitly specifying the utility functional form. Using a Monte Carlo experiment and empirical data from the Swissmetro dataset, we show that ASS-NN outperforms (in terms of goodness of fit) conventional multinomial logit (MNL) models under different utility specifications. Furthermore, we show how the ASS-NN is used to derive marginal utilities and willingness to pay measures. ",
    "url": "https://arxiv.org/abs/2404.13198",
    "authors": [
      "Jose Ignacio Hernandez",
      "Niek Mouter",
      "Sander van Cranenburgh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2404.13222",
    "title": "Vim4Path: Self-Supervised Vision Mamba for Histopathology Images",
    "abstract": "Representation learning from Gigapixel Whole Slide Images (WSI) poses a significant challenge in computational pathology due to the complicated nature of tissue structures and the scarcity of labeled data. Multi-instance learning methods have addressed this challenge, leveraging image patches to classify slides utilizing pretrained models using Self-Supervised Learning (SSL) approaches. The performance of both SSL and MIL methods relies on the architecture of the feature encoder. This paper proposes leveraging the Vision Mamba (Vim) architecture, inspired by state space models, within the DINO framework for representation learning in computational pathology. We evaluate the performance of Vim against Vision Transformers (ViT) on the Camelyon16 dataset for both patch-level and slide-level classification. Our findings highlight Vim's enhanced performance compared to ViT, particularly at smaller scales, where Vim achieves an 8.21 increase in ROC AUC for models of similar size. An explainability analysis further highlights Vim's capabilities, which reveals that Vim uniquely emulates the pathologist workflow-unlike ViT. This alignment with human expert analysis highlights Vim's potential in practical diagnostic settings and contributes significantly to developing effective representation-learning algorithms in computational pathology. We release the codes and pretrained weights at \\url{https://github.com/AtlasAnalyticsLab/Vim4Path}. ",
    "url": "https://arxiv.org/abs/2404.13222",
    "authors": [
      "Ali Nasiri-Sarvi",
      "Vincent Quoc-Huy Trinh",
      "Hassan Rivaz",
      "Mahdi S. Hosseini"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13240",
    "title": "Learning In Reverse Causal Strategic Environments With Ramifications on  Two Sided Markets",
    "abstract": "Motivated by equilibrium models of labor markets, we develop a formulation of causal strategic classification in which strategic agents can directly manipulate their outcomes. As an application, we compare employers that anticipate the strategic response of a labor force with employers that do not. We show through a combination of theory and experiment that employers with performatively optimal hiring policies improve employer reward, labor force skill level, and in some cases labor force equity. On the other hand, we demonstrate that performative employers harm labor force utility and fail to prevent discrimination in other cases. ",
    "url": "https://arxiv.org/abs/2404.13240",
    "authors": [
      "Seamus Somerstep",
      "Yuekai Sun",
      "Ya'acov Ritov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13277",
    "title": "Beyond Score Changes: Adversarial Attack on No-Reference Image Quality  Assessment from Two Perspectives",
    "abstract": "Deep neural networks have demonstrated impressive success in No-Reference Image Quality Assessment (NR-IQA). However, recent researches highlight the vulnerability of NR-IQA models to subtle adversarial perturbations, leading to inconsistencies between model predictions and subjective ratings. Current adversarial attacks, however, focus on perturbing predicted scores of individual images, neglecting the crucial aspect of inter-score correlation relationships within an entire image set. Meanwhile, it is important to note that the correlation, like ranking correlation, plays a significant role in NR-IQA tasks. To comprehensively explore the robustness of NR-IQA models, we introduce a new framework of correlation-error-based attacks that perturb both the correlation within an image set and score changes on individual images. Our research primarily focuses on ranking-related correlation metrics like Spearman's Rank-Order Correlation Coefficient (SROCC) and prediction error-related metrics like Mean Squared Error (MSE). As an instantiation, we propose a practical two-stage SROCC-MSE-Attack (SMA) that initially optimizes target attack scores for the entire image set and then generates adversarial examples guided by these scores. Experimental results demonstrate that our SMA method not only significantly disrupts the SROCC to negative values but also maintains a considerable change in the scores of individual images. Meanwhile, it exhibits state-of-the-art performance across metrics with different categories. Our method provides a new perspective on the robustness of NR-IQA models. ",
    "url": "https://arxiv.org/abs/2404.13277",
    "authors": [
      "Chenxi Yang",
      "Yujia Liu",
      "Dingquan Li",
      "Yan Zhong",
      "Tingting Jiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.13386",
    "title": "SSVT: Self-Supervised Vision Transformer For Eye Disease Diagnosis Based  On Fundus Images",
    "abstract": "Machine learning-based fundus image diagnosis technologies trigger worldwide interest owing to their benefits such as reducing medical resource power and providing objective evaluation results. However, current methods are commonly based on supervised methods, bringing in a heavy workload to biomedical staff and hence suffering in expanding effective databases. To address this issue, in this article, we established a label-free method, name 'SSVT',which can automatically analyze un-labeled fundus images and generate high evaluation accuracy of 97.0% of four main eye diseases based on six public datasets and two datasets collected by Beijing Tongren Hospital. The promising results showcased the effectiveness of the proposed unsupervised learning method, and the strong application potential in biomedical resource shortage regions to improve global eye health. ",
    "url": "https://arxiv.org/abs/2404.13386",
    "authors": [
      "Jiaqi Wang",
      "Mengtian Kang",
      "Yong Liu",
      "Chi Zhang",
      "Ying Liu",
      "Shiming Li",
      "Yue Qi",
      "Wenjun Xu",
      "Chenyu Tang",
      "Edoardo Occhipinti",
      "Mayinuer Yusufu",
      "Ningli Wang",
      "Weiling Bai",
      "Shuo Gao",
      "Luigi G. Occhipinti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13388",
    "title": "Diagnosis of Multiple Fundus Disorders Amidst a Scarcity of Medical  Experts Via Self-supervised Machine Learning",
    "abstract": "Fundus diseases are major causes of visual impairment and blindness worldwide, especially in underdeveloped regions, where the shortage of ophthalmologists hinders timely diagnosis. AI-assisted fundus image analysis has several advantages, such as high accuracy, reduced workload, and improved accessibility, but it requires a large amount of expert-annotated data to build reliable models. To address this dilemma, we propose a general self-supervised machine learning framework that can handle diverse fundus diseases from unlabeled fundus images. Our method's AUC surpasses existing supervised approaches by 15.7%, and even exceeds performance of a single human expert. Furthermore, our model adapts well to various datasets from different regions, races, and heterogeneous image sources or qualities from multiple cameras or devices. Our method offers a label-free general framework to diagnose fundus diseases, which could potentially benefit telehealth programs for early screening of people at risk of vision loss. ",
    "url": "https://arxiv.org/abs/2404.13388",
    "authors": [
      "Yong Liu",
      "Mengtian Kang",
      "Shuo Gao",
      "Chi Zhang",
      "Ying Liu",
      "Shiming Li",
      "Yue Qi",
      "Arokia Nathan",
      "Wenjun Xu",
      "Chenyu Tang",
      "Edoardo Occhipinti",
      "Mayinuer Yusufu",
      "Ningli Wang",
      "Weiling Bai",
      "Luigi Occhipinti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13404",
    "title": "Solution space and storage capacity of fully connected two-layer neural  networks with generic activation functions",
    "abstract": "The storage capacity of a binary classification model is the maximum number of random input-output pairs per parameter that the model can learn. It is one of the indicators of the expressive power of machine learning models and is important for comparing the performance of various models. In this study, we analyze the structure of the solution space and the storage capacity of fully connected two-layer neural networks with general activation functions using the replica method from statistical physics. Our results demonstrate that the storage capacity per parameter remains finite even with infinite width and that the weights of the network exhibit negative correlations, leading to a 'division of labor'. In addition, we find that increasing the dataset size triggers a phase transition at a certain transition point where the permutation symmetry of weights is broken, resulting in the solution space splitting into disjoint regions. We identify the dependence of this transition point and the storage capacity on the choice of activation function. These findings contribute to understanding the influence of activation functions and the number of parameters on the structure of the solution space, potentially offering insights for selecting appropriate architectures based on specific objectives. ",
    "url": "https://arxiv.org/abs/2404.13404",
    "authors": [
      "Sota Nishiyama",
      "Masayuki Ohzeki"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.13557",
    "title": "Preconditioned Neural Posterior Estimation for Likelihood-free Inference",
    "abstract": "Simulation based inference (SBI) methods enable the estimation of posterior distributions when the likelihood function is intractable, but where model simulation is feasible. Popular neural approaches to SBI are the neural posterior estimator (NPE) and its sequential version (SNPE). These methods can outperform statistical SBI approaches such as approximate Bayesian computation (ABC), particularly for relatively small numbers of model simulations. However, we show in this paper that the NPE methods are not guaranteed to be highly accurate, even on problems with low dimension. In such settings the posterior cannot be accurately trained over the prior predictive space, and even the sequential extension remains sub-optimal. To overcome this, we propose preconditioned NPE (PNPE) and its sequential version (PSNPE), which uses a short run of ABC to effectively eliminate regions of parameter space that produce large discrepancy between simulations and data and allow the posterior emulator to be more accurately trained. We present comprehensive empirical evidence that this melding of neural and statistical SBI methods improves performance over a range of examples, including a motivating example involving a complex agent-based model applied to real tumour growth data. ",
    "url": "https://arxiv.org/abs/2404.13557",
    "authors": [
      "Xiaoyu Wang",
      "Ryan P. Kelly",
      "David J. Warne",
      "Christopher Drovandi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.13693",
    "title": "PV-S3: Advancing Automatic Photovoltaic Defect Detection using  Semi-Supervised Semantic Segmentation of Electroluminescence Images",
    "abstract": "Photovoltaic (PV) systems allow us to tap into all abundant solar energy, however they require regular maintenance for high efficiency and to prevent degradation. Traditional manual health check, using Electroluminescence (EL) imaging, is expensive and logistically challenging making automated defect detection essential. Current automation approaches require extensive manual expert labeling, which is time-consuming, expensive, and prone to errors. We propose PV-S3 (Photovoltaic-Semi Supervised Segmentation), a Semi-Supervised Learning approach for semantic segmentation of defects in EL images that reduces reliance on extensive labeling. PV-S3 is a Deep learning model trained using a few labeled images along with numerous unlabeled images. We introduce a novel Semi Cross-Entropy loss function to train PV-S3 which addresses the challenges specific to automated PV defect detection, such as diverse defect types and class imbalance. We evaluate PV-S3 on multiple datasets and demonstrate its effectiveness and adaptability. With merely 20% labeled samples, we achieve an absolute improvement of 9.7% in IoU, 29.9% in Precision, 12.75% in Recall, and 20.42% in F1-Score over prior state-of-the-art supervised method (which uses 100% labeled samples) on UCF-EL dataset (largest dataset available for semantic segmentation of EL images) showing improvement in performance while reducing the annotation costs by 80%. ",
    "url": "https://arxiv.org/abs/2404.13693",
    "authors": [
      "Abhishek Jha",
      "Yogesh Rawat",
      "Shruti Vyas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.14133",
    "title": "Quantum Convolutional Neural Networks for the detection of Gamma-Ray  Bursts in the AGILE space mission data",
    "abstract": "Quantum computing represents a cutting-edge frontier in artificial intelligence. It makes use of hybrid quantum-classical computation which tries to leverage quantum mechanic principles that allow us to use a different approach to deep learning classification problems. The work presented here falls within the context of the AGILE space mission, launched in 2007 by the Italian Space Agency. We implement different Quantum Convolutional Neural Networks (QCNN) that analyze data acquired by the instruments onboard AGILE to detect Gamma-Ray Bursts from sky maps or light curves. We use several frameworks such as TensorFlow-Quantum, Qiskit and PennyLane to simulate a quantum computer. We achieved an accuracy of 95.1% on sky maps with QCNNs, while the classical counterpart achieved 98.8% on the same data, using however hundreds of thousands more parameters. ",
    "url": "https://arxiv.org/abs/2404.14133",
    "authors": [
      "A. Rizzo",
      "N. Parmiggiani",
      "A. Bulgarelli",
      "A. Macaluso",
      "V. Fioretti",
      "L. Castaldini",
      "A. Di Piano",
      "G. Panebianco",
      "C. Pittori",
      "M. Tavani",
      "C. Sartori",
      "C. Burigana",
      "V. Cardone",
      "F. Farsian",
      "M. Meneghetti",
      "G. Murante",
      "R. Scaramella",
      "F. Schillir\u00f2",
      "V. Testa",
      "T. Trombetti"
    ],
    "subjectives": [
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.14212",
    "title": "Toward Routing River Water in Land Surface Models with Recurrent Neural  Networks",
    "abstract": "Machine learning is playing an increasing role in hydrology, supplementing or replacing physics-based models. One notable example is the use of recurrent neural networks (RNNs) for forecasting streamflow given observed precipitation and geographic characteristics. Training of such a model over the continental United States has demonstrated that a single set of model parameters can be used across independent catchments, and that RNNs can outperform physics-based models. In this work, we take a next step and study the performance of RNNs for river routing in land surface models (LSMs). Instead of observed precipitation, the LSM-RNN uses instantaneous runoff calculated from physics-based models as an input. We train the model with data from river basins spanning the globe and test it in streamflow hindcasts. The model demonstrates skill at generalization across basins (predicting streamflow in unseen catchments) and across time (predicting streamflow during years not used in training). We compare the predictions from the LSM-RNN to an existing physics-based model calibrated with a similar dataset and find that the LSM-RNN outperforms the physics-based model. Our results give further evidence that RNNs are effective for global streamflow prediction from runoff inputs and motivate the development of complete routing models that can capture nested sub-basis connections. ",
    "url": "https://arxiv.org/abs/2404.14212",
    "authors": [
      "Mauricio Lima",
      "Katherine Deck",
      "Oliver R. A. Dunbar",
      "Tapio Schneider"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.14299",
    "title": "A Cross-Platform Execution Engine for the Quantum Intermediate  Representation",
    "abstract": "Hybrid languages like the Quantum Intermediate Representation (QIR) are essential for programming systems that mix quantum and conventional computing models, while execution of these programs is often deferred to a system-specific implementation. Here, we describe and demonstrate the QIR Execution Engine (QIR-EE) for parsing, interpreting, and executing QIR across multiple hardware platforms. QIR-EE uses LLVM to execute hybrid instructions specifying quantum programs and, by design, presents extension points that support customized runtime and hardware environments. We demonstrate an implementation that uses the XACC quantum hardware-accelerator library to dispatch prototypical quantum programs on different commercial quantum platforms and numerical simulators, and we validate execution of QIR-EE on the IonQ Harmony and Quantinuum H1-1 hardware. Our results highlight the efficiency of hybrid executable architectures for handling mixed instructions, managing mixed data, and integrating with quantum computing frameworks to realize cross-platform execution. ",
    "url": "https://arxiv.org/abs/2404.14299",
    "authors": [
      "Elaine Wong",
      "Vicente Leyton Ortega",
      "Daniel Claudino",
      "Seth Johnson",
      "Sharmin Afrose",
      "Meenambika Gowrishankar",
      "Anthony M. Cabrera",
      "Travis S. Humble"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2404.14322",
    "title": "A Novel Approach to Chest X-ray Lung Segmentation Using U-net and  Modified Convolutional Block Attention Module",
    "abstract": "Lung segmentation in chest X-ray images is of paramount importance as it plays a crucial role in the diagnosis and treatment of various lung diseases. This paper presents a novel approach for lung segmentation in chest X-ray images by integrating U-net with attention mechanisms. The proposed method enhances the U-net architecture by incorporating a Convolutional Block Attention Module (CBAM), which unifies three distinct attention mechanisms: channel attention, spatial attention, and pixel attention. The channel attention mechanism enables the model to concentrate on the most informative features across various channels. The spatial attention mechanism enhances the model's precision in localization by focusing on significant spatial locations. Lastly, the pixel attention mechanism empowers the model to focus on individual pixels, further refining the model's focus and thereby improving the accuracy of segmentation. The adoption of the proposed CBAM in conjunction with the U-net architecture marks a significant advancement in the field of medical imaging, with potential implications for improving diagnostic precision and patient outcomes. The efficacy of this method is validated against contemporary state-of-the-art techniques, showcasing its superiority in segmentation performance. ",
    "url": "https://arxiv.org/abs/2404.14322",
    "authors": [
      "Mohammad Ali Labbaf Khaniki",
      "Mohammad Manthouri"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.14399",
    "title": "MLQAOA: Graph Learning Accelerated Hybrid Quantum-Classical Multilevel  QAOA",
    "abstract": "Learning the problem structure at multiple levels of coarseness to inform the decomposition-based hybrid quantum-classical combinatorial optimization solvers is a promising approach to scaling up variational approaches. We introduce a multilevel algorithm reinforced with the spectral graph representation learning-based accelerator to tackle large-scale graph maximum cut instances and fused with several versions of the quantum approximate optimization algorithm (QAOA) and QAOA-inspired algorithms. The graph representation learning model utilizes the idea of QAOA variational parameters concentration and substantially improves the performance of QAOA. We demonstrate the potential of using multilevel QAOA and representation learning-based approaches on very large graphs by achieving high-quality solutions in a much faster time.\\\\ Reproducibility: Our source code and results are available at \\url{https://github.com/bachbao/MLQAOA} ",
    "url": "https://arxiv.org/abs/2404.14399",
    "authors": [
      "Bao Bach",
      "Jose Falla",
      "Ilya Safro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2404.14402",
    "title": "A mean curvature flow arising in adversarial training",
    "abstract": "We connect adversarial training for binary classification to a geometric evolution equation for the decision boundary. Relying on a perspective that recasts adversarial training as a regularization problem, we introduce a modified training scheme that constitutes a minimizing movements scheme for a nonlocal perimeter functional. We prove that the scheme is monotone and consistent as the adversarial budget vanishes and the perimeter localizes, and as a consequence we rigorously show that the scheme approximates a weighted mean curvature flow. This highlights that the efficacy of adversarial training may be due to locally minimizing the length of the decision boundary. In our analysis, we introduce a variety of tools for working with the subdifferential of a supremal-type nonlocal total variation and its regularity properties. ",
    "url": "https://arxiv.org/abs/2404.14402",
    "authors": [
      "Leon Bungert",
      "Tim Laux",
      "Kerrek Stinson"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1910.11436",
    "title": "Hierarchical Representation Learning in Graph Neural Networks with Node  Decimation Pooling",
    "abstract": " Title: Hierarchical Representation Learning in Graph Neural Networks with Node  Decimation Pooling ",
    "url": "https://arxiv.org/abs/1910.11436",
    "authors": [
      "Filippo Maria Bianchi",
      "Daniele Grattarola",
      "Lorenzo Livi",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.01809",
    "title": "What's Wrong with the Bottom-up Methods in Arbitrary-shape Scene Text  Detection",
    "abstract": " Comments: Accepted by Trans. on Multimedia ",
    "url": "https://arxiv.org/abs/2108.01809",
    "authors": [
      "Chengpei Xu",
      "Wenjing Jia",
      "Tingcheng Cui",
      "Ruomei Wang",
      "Yuan-fang Zhang",
      "Xiangjian He"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2112.04620",
    "title": "Online Calibrated and Conformal Prediction Improves Bayesian  Optimization",
    "abstract": " Title: Online Calibrated and Conformal Prediction Improves Bayesian  Optimization ",
    "url": "https://arxiv.org/abs/2112.04620",
    "authors": [
      "Shachi Deshpande",
      "Charles Marx",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03861",
    "title": "Decentralized Online Regularized Learning Over Random Time-Varying  Graphs",
    "abstract": " Title: Decentralized Online Regularized Learning Over Random Time-Varying  Graphs ",
    "url": "https://arxiv.org/abs/2206.03861",
    "authors": [
      "Xiwei Zhang",
      "Tao Li",
      "Xiaozheng Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.04045",
    "title": "Runtime Analysis for Permutation-based Evolutionary Algorithms",
    "abstract": " Comments: Journal version of our paper at GECCO 2022, appeared in Algorithmica. 52 pages. arXiv admin note: substantial text overlap with arXiv:2204.07637 ",
    "url": "https://arxiv.org/abs/2207.04045",
    "authors": [
      "Benjamin Doerr",
      "Yassine Ghannane",
      "Marouane Ibn Brahim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.13618",
    "title": "Scalable Multilevel and Memetic Signed Graph Clustering",
    "abstract": " Title: Scalable Multilevel and Memetic Signed Graph Clustering ",
    "url": "https://arxiv.org/abs/2208.13618",
    "authors": [
      "Felix Hausberger",
      "Marcelo Fonseca Faraj",
      "Christian Schulz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2212.03095",
    "title": "Interpretation of Neural Networks is Susceptible to Universal  Adversarial Perturbations",
    "abstract": " Title: Interpretation of Neural Networks is Susceptible to Universal  Adversarial Perturbations ",
    "url": "https://arxiv.org/abs/2212.03095",
    "authors": [
      "Haniyeh Ehsani Oskouie",
      "Farzan Farnia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.09412",
    "title": "Empowering Diffusion Models on the Embedding Space for Text Generation",
    "abstract": " Comments: NAACL 2024 ",
    "url": "https://arxiv.org/abs/2212.09412",
    "authors": [
      "Zhujin Gao",
      "Junliang Guo",
      "Xu Tan",
      "Yongxin Zhu",
      "Fang Zhang",
      "Jiang Bian",
      "Linli Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13389",
    "title": "Differentially Private Kernel Inducing Points using features from  ScatterNets (DP-KIP-ScatterNet) for Privacy Preserving Data Distillation",
    "abstract": " Title: Differentially Private Kernel Inducing Points using features from  ScatterNets (DP-KIP-ScatterNet) for Privacy Preserving Data Distillation ",
    "url": "https://arxiv.org/abs/2301.13389",
    "authors": [
      "Margarita Vinaroz",
      "Mi Jung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.03232",
    "title": "Linear Optimal Partial Transport Embedding",
    "abstract": " Title: Linear Optimal Partial Transport Embedding ",
    "url": "https://arxiv.org/abs/2302.03232",
    "authors": [
      "Yikun Bai",
      "Ivan Medri",
      "Rocio Diaz Martin",
      "Rana Muhammad Shahroz Khan",
      "Soheil Kolouri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.13952",
    "title": "Pressure robust SUPG-stabilized finite elements for the unsteady  Navier-Stokes equation",
    "abstract": " Title: Pressure robust SUPG-stabilized finite elements for the unsteady  Navier-Stokes equation ",
    "url": "https://arxiv.org/abs/2302.13952",
    "authors": [
      "L. Beir\u00e3o da Veiga",
      "F. Dassi",
      "G. Vacca"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.13959",
    "title": "Bridging Stereo Geometry and BEV Representation with Reliable Mutual  Interaction for Semantic Scene Completion",
    "abstract": " Comments: IJCAI2024 (this https URL) ",
    "url": "https://arxiv.org/abs/2303.13959",
    "authors": [
      "Bohan Li",
      "Yasheng Sun",
      "Zhujin Liang",
      "Dalong Du",
      "Zhuanghui Zhang",
      "Xiaofeng Wang",
      "Yunnan Wang",
      "Xin Jin",
      "Wenjun Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03535",
    "title": "CRISP: Curriculum inducing Primitive Informed Subgoal Prediction",
    "abstract": " Title: CRISP: Curriculum inducing Primitive Informed Subgoal Prediction ",
    "url": "https://arxiv.org/abs/2304.03535",
    "authors": [
      "Utsav Singh",
      "Vinay P. Namboodiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04391",
    "title": "CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised  Representation Learning on Graphs",
    "abstract": " Title: CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised  Representation Learning on Graphs ",
    "url": "https://arxiv.org/abs/2304.04391",
    "authors": [
      "Arvindh Arun",
      "Aakash Aanegola",
      "Amul Agrawal",
      "Ramasuri Narayanam",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2304.10126",
    "title": "Decouple Graph Neural Networks: Train Multiple Simple GNNs  Simultaneously Instead of One",
    "abstract": " Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence ",
    "url": "https://arxiv.org/abs/2304.10126",
    "authors": [
      "Hongyuan Zhang",
      "Yanan Zhu",
      "Xuelong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.00608",
    "title": "Differentiable Neural Networks with RePU Activation: with Applications  to Score Estimation and Isotonic Regression",
    "abstract": " Comments: 78 pages, 20 figures, and 6 tables. arXiv admin note: text overlap with arXiv:2207.10442 ",
    "url": "https://arxiv.org/abs/2305.00608",
    "authors": [
      "Guohao Shen",
      "Yuling Jiao",
      "Yuanyuan Lin",
      "Jian Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10540",
    "title": "Generalization Bounds for Neural Belief Propagation Decoders",
    "abstract": " Comments: Published in IEEE Transactions on Information Theory (2024) ",
    "url": "https://arxiv.org/abs/2305.10540",
    "authors": [
      "Sudarshan Adiga",
      "Xin Xiao",
      "Ravi Tandon",
      "Bane Vasic",
      "Tamal Bose"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13982",
    "title": "Toward stochastic neural computing",
    "abstract": " Title: Toward stochastic neural computing ",
    "url": "https://arxiv.org/abs/2305.13982",
    "authors": [
      "Yang Qi",
      "Zhichao Zhu",
      "Yiming Wei",
      "Lu Cao",
      "Zhigang Wang",
      "Jie Zhang",
      "Wenlian Lu",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Biological Physics (physics.bio-ph)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.00168",
    "title": "Measuring the Robustness of NLP Models to Domain Shifts",
    "abstract": " Title: Measuring the Robustness of NLP Models to Domain Shifts ",
    "url": "https://arxiv.org/abs/2306.00168",
    "authors": [
      "Nitay Calderon",
      "Naveh Porat",
      "Eyal Ben-David",
      "Alexander Chapanin",
      "Zorik Gekhman",
      "Nadav Oved",
      "Vitaly Shalumov",
      "Roi Reichart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.00816",
    "title": "Versatile Backdoor Attack with Visible, Semantic, Sample-Specific, and  Compatible Triggers",
    "abstract": " Title: Versatile Backdoor Attack with Visible, Semantic, Sample-Specific, and  Compatible Triggers ",
    "url": "https://arxiv.org/abs/2306.00816",
    "authors": [
      "Ruotong Wang",
      "Hongrui Chen",
      "Zihao Zhu",
      "Li Liu",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.05880",
    "title": "Time Series Continuous Modeling for Imputation and Forecasting with  Implicit Neural Representations",
    "abstract": " Title: Time Series Continuous Modeling for Imputation and Forecasting with  Implicit Neural Representations ",
    "url": "https://arxiv.org/abs/2306.05880",
    "authors": [
      "Etienne Le Naour",
      "Louis Serrano",
      "L\u00e9on Migus",
      "Yuan Yin",
      "Ghislain Agoua",
      "Nicolas Baskiotis",
      "Patrick Gallinari",
      "Vincent Guigue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06743",
    "title": "Trees versus Neural Networks for enhancing tau lepton real-time  selection in proton-proton collisions",
    "abstract": " Title: Trees versus Neural Networks for enhancing tau lepton real-time  selection in proton-proton collisions ",
    "url": "https://arxiv.org/abs/2306.06743",
    "authors": [
      "Maayan Yaary",
      "Uriel Barron",
      "Luis Pascual Dom\u00ednguez",
      "Boping Chen",
      "Liron Barak",
      "Erez Etzion",
      "Raja Giryes"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2306.13287",
    "title": "Optimal Power Flow for Integrated Primary-Secondary Distribution  Networks with Center-Tapped Service Transformers",
    "abstract": " Title: Optimal Power Flow for Integrated Primary-Secondary Distribution  Networks with Center-Tapped Service Transformers ",
    "url": "https://arxiv.org/abs/2306.13287",
    "authors": [
      "Rui Cheng",
      "Naihao Shi",
      "Zhaoyu Wang",
      "Zixiao Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.17469",
    "title": "Manga109Dialog: A Large-scale Dialogue Dataset for Comics Speaker  Detection",
    "abstract": " Comments: Accepted to ICME2024 ",
    "url": "https://arxiv.org/abs/2306.17469",
    "authors": [
      "Yingxuan Li",
      "Kiyoharu Aizawa",
      "Yusuke Matsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.16792",
    "title": "Classification with Deep Neural Networks and Logistic Loss",
    "abstract": " Title: Classification with Deep Neural Networks and Logistic Loss ",
    "url": "https://arxiv.org/abs/2307.16792",
    "authors": [
      "Zihan Zhang",
      "Lei Shi",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03279",
    "title": "Let Quantum Neural Networks Choose Their Own Frequencies",
    "abstract": " Comments: 11 pages, 7 figures. Updated with small changes for publication ",
    "url": "https://arxiv.org/abs/2309.03279",
    "authors": [
      "Ben Jaderberg",
      "Antonio A. Gentile",
      "Youssef Achari Berrada",
      "Elvira Shishenina",
      "Vincent E. Elfving"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03798",
    "title": "Managing the Uncertainty in System Dynamics Through Distributionally  Robust Stability-Constrained Optimization",
    "abstract": " Title: Managing the Uncertainty in System Dynamics Through Distributionally  Robust Stability-Constrained Optimization ",
    "url": "https://arxiv.org/abs/2309.03798",
    "authors": [
      "Zhongda Chu",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.07597",
    "title": "C-Pack: Packaged Resources To Advance General Chinese Embedding",
    "abstract": " Comments: Accepted by SIGIR 2024 ",
    "url": "https://arxiv.org/abs/2309.07597",
    "authors": [
      "Shitao Xiao",
      "Zheng Liu",
      "Peitian Zhang",
      "Niklas Muennighoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.08043",
    "title": "On Prediction Feature Assignment in the Heckman Selection Model",
    "abstract": " Comments: Full version of work accepted to IJCNN 2024 ",
    "url": "https://arxiv.org/abs/2309.08043",
    "authors": [
      "Huy Mai",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.10509",
    "title": "Polynomial-time Solver of Tridiagonal QUBO and QUDO problems with Tensor  Networks",
    "abstract": " Comments: 6 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2309.10509",
    "authors": [
      "Alejandro Mata Ali",
      "I\u00f1igo Perez Delgado",
      "Marina Ristol Roura",
      "Aitor Moreno Fdez. de Leceta"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2309.16172",
    "title": "Random and Safe Cache Architecture to Defeat Cache Timing Attacks",
    "abstract": " Title: Random and Safe Cache Architecture to Defeat Cache Timing Attacks ",
    "url": "https://arxiv.org/abs/2309.16172",
    "authors": [
      "Guangyuan Hu",
      "Ruby B. Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2310.03742",
    "title": "A High-Performance Design, Implementation, Deployment, and Evaluation of  The Slim Fly Network",
    "abstract": " Title: A High-Performance Design, Implementation, Deployment, and Evaluation of  The Slim Fly Network ",
    "url": "https://arxiv.org/abs/2310.03742",
    "authors": [
      "Nils Blach",
      "Maciej Besta",
      "Daniele De Sensi",
      "Jens Domke",
      "Hussein Harake",
      "Shigang Li",
      "Patrick Iff",
      "Marek Konieczny",
      "Kartik Lakhotia",
      "Ales Kubicek",
      "Marcel Ferrari",
      "Fabrizio Petrini",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.03991",
    "title": "SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text  Generation",
    "abstract": " Comments: Accepted to NAACL 24 Main ",
    "url": "https://arxiv.org/abs/2310.03991",
    "authors": [
      "Abe Bohan Hou",
      "Jingyu Zhang",
      "Tianxing He",
      "Yichen Wang",
      "Yung-Sung Chuang",
      "Hongwei Wang",
      "Lingfeng Shen",
      "Benjamin Van Durme",
      "Daniel Khashabi",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05108",
    "title": "Enhancing Representations through Heterogeneous Self-Supervised Learning",
    "abstract": " Title: Enhancing Representations through Heterogeneous Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2310.05108",
    "authors": [
      "Zhong-Yu Li",
      "Bo-Wen Yin",
      "Shanghua Gao",
      "Yongxiang Liu",
      "Li Liu",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.11102",
    "title": "Refining Latent Representations: A Generative SSL Approach for  Heterogeneous Graph Learning",
    "abstract": " Title: Refining Latent Representations: A Generative SSL Approach for  Heterogeneous Graph Learning ",
    "url": "https://arxiv.org/abs/2310.11102",
    "authors": [
      "Yulan Hu",
      "Zhirui Yang",
      "Sheng Ouyang",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.13253",
    "title": "Knowledge Graph Context-Enhanced Diversified Recommendation",
    "abstract": " Comments: 10 pages, 5 figures, accepted by WSDM 2024 ",
    "url": "https://arxiv.org/abs/2310.13253",
    "authors": [
      "Xiaolong Liu",
      "Liangwei Yang",
      "Zhiwei Liu",
      "Mingdai Yang",
      "Chen Wang",
      "Hao Peng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.14809",
    "title": "Learning spatio-temporal patterns with Neural Cellular Automata",
    "abstract": " Comments: For videos referenced in appendix, see: this https URL ",
    "url": "https://arxiv.org/abs/2310.14809",
    "authors": [
      "Alex D. Richardson",
      "Tibor Antal",
      "Richard A. Blythe",
      "Linus J. Schumacher"
    ],
    "subjectives": [
      "Pattern Formation and Solitons (nlin.PS)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2310.19268",
    "title": "Moral Sparks in Social Media Narratives",
    "abstract": " Title: Moral Sparks in Social Media Narratives ",
    "url": "https://arxiv.org/abs/2310.19268",
    "authors": [
      "Ruijie Xi",
      "Munindar P. Singh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.00182",
    "title": "Local Max-Cut on Sparse Graphs",
    "abstract": " Title: Local Max-Cut on Sparse Graphs ",
    "url": "https://arxiv.org/abs/2311.00182",
    "authors": [
      "Gregory Schwartzman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.02445",
    "title": "Pre-Construction of Opinion Dynamics Considering Structural Inequality:  Interdisciplinary Analysis of Complex Social Stratification, Media Influence,  and Functionalism",
    "abstract": " Comments: Discussion Paper:Theory of opinion distribution in human relations where trust and distrust mixed(2020) This paper is partially an attempt to utilize \"Generative AI\" and was written with educational intent. There are currently no plans for it to become a peer-reviewed paper ",
    "url": "https://arxiv.org/abs/2311.02445",
    "authors": [
      "Yasuko Kawahata"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.03661",
    "title": "Operational risk quantification of power grids using graph neural  network surrogates of the DC OPF",
    "abstract": " Comments: Manuscript submitted to IEEE Transactions on Power Systems ",
    "url": "https://arxiv.org/abs/2311.03661",
    "authors": [
      "Yadong Zhang",
      "Pranav M Karve",
      "Sankaran Mahadevan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.04456",
    "title": "(Social) Trouble on the Road: Understanding and Addressing Social  Discomfort in Shared Car Trips",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2311.04456",
    "authors": [
      "Alexandra Bremers",
      "Natalie Friedman",
      "Sam Lee",
      "Tong Wu",
      "Eric Laurier",
      "Malte Jung",
      "Jorge Ortiz",
      "Wendy Ju"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.07454",
    "title": "Discrete Nonparametric Causal Discovery Under Latent Class Confounding",
    "abstract": " Title: Discrete Nonparametric Causal Discovery Under Latent Class Confounding ",
    "url": "https://arxiv.org/abs/2311.07454",
    "authors": [
      "Bijan Mazaheri",
      "Spencer Gordon",
      "Yuval Rabani",
      "Leonard Schulman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2311.16198",
    "title": "Ultra-short-term multi-step wind speed prediction for wind farms based  on adaptive noise reduction technology and temporal convolutional network",
    "abstract": " Comments: Project Technical Report ",
    "url": "https://arxiv.org/abs/2311.16198",
    "authors": [
      "Haojian Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.17132",
    "title": "TransNeXt: Robust Foveal Visual Perception for Vision Transformers",
    "abstract": " Comments: CVPR 2024 Camera-ready Version. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2311.17132",
    "authors": [
      "Dai Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17241",
    "title": "End-to-End Temporal Action Detection with 1B Parameters Across 1000  Frames",
    "abstract": " Comments: Accepted to CVPR 2024. Camera-Ready Version ",
    "url": "https://arxiv.org/abs/2311.17241",
    "authors": [
      "Shuming Liu",
      "Chen-Lin Zhang",
      "Chen Zhao",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17406",
    "title": "LLM-State: Open World State Representation for Long-horizon Task  Planning with Large Language Model",
    "abstract": " Title: LLM-State: Open World State Representation for Long-horizon Task  Planning with Large Language Model ",
    "url": "https://arxiv.org/abs/2311.17406",
    "authors": [
      "Siwei Chen",
      "Anxing Xiao",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.01201",
    "title": "PAC Privacy Preserving Diffusion Models",
    "abstract": " Title: PAC Privacy Preserving Diffusion Models ",
    "url": "https://arxiv.org/abs/2312.01201",
    "authors": [
      "Qipan Xu",
      "Youlong Ding",
      "Xinxi Zhang",
      "Jie Gao",
      "Hao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.03878",
    "title": "Domain constraints improve risk prediction when outcome data is missing",
    "abstract": " Comments: Published at ICLR 2024 ",
    "url": "https://arxiv.org/abs/2312.03878",
    "authors": [
      "Sidhika Balachandar",
      "Nikhil Garg",
      "Emma Pierson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.04865",
    "title": "StructComp: Substituting propagation with Structural Compression in  Training Graph Contrastive Learning",
    "abstract": " Comments: Accepted by ICLR 2024 ",
    "url": "https://arxiv.org/abs/2312.04865",
    "authors": [
      "Shengzhong Zhang",
      "Wenjie Yang",
      "Xinyuan Cao",
      "Hongwei Zhang",
      "Zengfeng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05104",
    "title": "An Autonomous Driving Model Integrated with BEV-V2X Perception, Fusion  Prediction of Motion and Occupancy, and Driving Planning, in Complex Traffic  Intersections",
    "abstract": " Comments: The content of the paper has not received unanimous consent from all the members and requires further evaluation prior to submission ",
    "url": "https://arxiv.org/abs/2312.05104",
    "authors": [
      "Fukang Li",
      "Wenlin Ou",
      "Kunpeng Gao",
      "Yuwen Pang",
      "Yifei Li",
      "Henry Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.08083",
    "title": "Training of Neural Networks with Uncertain Data -- A Mixture of Experts  Approach",
    "abstract": " Title: Training of Neural Networks with Uncertain Data -- A Mixture of Experts  Approach ",
    "url": "https://arxiv.org/abs/2312.08083",
    "authors": [
      "Lucas Luttner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.08616",
    "title": "A Generalized Neural Diffusion Framework on Graphs",
    "abstract": " Comments: Accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2312.08616",
    "authors": [
      "Yibo Li",
      "Xiao Wang",
      "Hongrui Liu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.13328",
    "title": "NeLF-Pro: Neural Light Field Probes for Multi-Scale Novel View Synthesis",
    "abstract": " Comments: CVPR 2024 Conference Paper, Camera Ready Version ",
    "url": "https://arxiv.org/abs/2312.13328",
    "authors": [
      "Zinuo You",
      "Andreas Geiger",
      "Anpei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.14494",
    "title": "Revisiting Few-Shot Object Detection with Vision-Language Models",
    "abstract": " Title: Revisiting Few-Shot Object Detection with Vision-Language Models ",
    "url": "https://arxiv.org/abs/2312.14494",
    "authors": [
      "Anish Madan",
      "Neehar Peri",
      "Shu Kong",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01836",
    "title": "Neural Control: Concurrent System Identification and Control Learning  with Neural ODE",
    "abstract": " Comments: 9 pages, code open sourced in format of Google Colab notebooks; Resubmitted for adding missed references in the last submission ",
    "url": "https://arxiv.org/abs/2401.01836",
    "authors": [
      "Cheng Chi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.03907",
    "title": "RoboFusion: Towards Robust Multi-Modal 3D Object Detection via SAM",
    "abstract": " Title: RoboFusion: Towards Robust Multi-Modal 3D Object Detection via SAM ",
    "url": "https://arxiv.org/abs/2401.03907",
    "authors": [
      "Ziying Song",
      "Guoxing Zhang",
      "Lin Liu",
      "Lei Yang",
      "Shaoqing Xu",
      "Caiyan Jia",
      "Feiyang Jia",
      "Li Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.04727",
    "title": "Revisiting Adversarial Training at Scale",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2401.04727",
    "authors": [
      "Zeyu Wang",
      "Xianhang Li",
      "Hongru Zhu",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.08505",
    "title": "Harnessing Orthogonality to Train Low-Rank Neural Networks",
    "abstract": " Title: Harnessing Orthogonality to Train Low-Rank Neural Networks ",
    "url": "https://arxiv.org/abs/2401.08505",
    "authors": [
      "Daniel Coquelin",
      "Katharina Fl\u00fcgel",
      "Marie Weiel",
      "Nicholas Kiefer",
      "Charlotte Debus",
      "Achim Streit",
      "Markus G\u00f6tz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.09673",
    "title": "Artwork Protection Against Neural Style Transfer Using Locally Adaptive  Adversarial Color Attack",
    "abstract": " Comments: 9 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2401.09673",
    "authors": [
      "Zhongliang Guo",
      "Junhao Dong",
      "Yifei Qian",
      "Kaixuan Wang",
      "Weiye Li",
      "Ziheng Guo",
      "Yuheng Wang",
      "Yanli Li",
      "Ognjen Arandjelovi\u0107",
      "Lei Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2401.11248",
    "title": "Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense  Passage Retrieval",
    "abstract": " Comments: Accepted by SIGIR24. Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2401.11248",
    "authors": [
      "Guangyuan Ma",
      "Xing Wu",
      "Zijia Lin",
      "Songlin Hu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.11395",
    "title": "UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with  Fine-Grained Feature Representation",
    "abstract": " Comments: Accepted by IJCAI 2024 ",
    "url": "https://arxiv.org/abs/2401.11395",
    "authors": [
      "Qingdong He",
      "Jinlong Peng",
      "Zhengkai Jiang",
      "Kai Wu",
      "Xiaozhong Ji",
      "Jiangning Zhang",
      "Yabiao Wang",
      "Chengjie Wang",
      "Mingang Chen",
      "Yunsheng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.12184",
    "title": "Is Your Kettle Smarter Than a Hacker? A Scalable Tool for Assessing  Replay Attack Vulnerabilities on Consumer IoT Devices",
    "abstract": " Comments: Please use the PERCOM reference: S. Lazzaro, V. De Angelis, A. M. Mandalari and F. Buccafurri, \"Is Your Kettle Smarter Than a Hacker? A Scalable Tool for Assessing Replay Attack Vulnerabilities on Consumer IoT Devices,\" 2024 IEEE International Conference on Pervasive Computing and Communications (PerCom), Biarritz, France, 2024, pp. 114-124, doi: 10.1109/PerCom59722.2024.10494466 ",
    "url": "https://arxiv.org/abs/2401.12184",
    "authors": [
      "Sara Lazzaro",
      "Vincenzo De Angelis",
      "Anna Maria Mandalari",
      "Francesco Buccafurri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.13516",
    "title": "Delocate: Detection and Localization for Deepfake Videos with  Randomly-Located Tampered Traces",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2308.09921, arXiv:2305.05943 ",
    "url": "https://arxiv.org/abs/2401.13516",
    "authors": [
      "Juan Hu",
      "Xin Liao",
      "Difei Gao",
      "Satoshi Tsutsui",
      "Qian Wang",
      "Zheng Qin",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.15902",
    "title": "A Concise but High-performing Network for Image Guided Depth Completion  in Autonomous Driving",
    "abstract": " Title: A Concise but High-performing Network for Image Guided Depth Completion  in Autonomous Driving ",
    "url": "https://arxiv.org/abs/2401.15902",
    "authors": [
      "Moyun Liu",
      "Bing Chen",
      "Youping Chen",
      "Jingming Xie",
      "Lei Yao",
      "Yang Zhang",
      "Joey Tianyi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.17738",
    "title": "Harnessing Smartwatch Microphone Sensors for Cough Detection and  Classification",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2401.17738",
    "authors": [
      "Pranay Jaiswal",
      "Haroon R. Lone"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.01123",
    "title": "A Single Simple Patch is All You Need for AI-generated Image Detection",
    "abstract": " Title: A Single Simple Patch is All You Need for AI-generated Image Detection ",
    "url": "https://arxiv.org/abs/2402.01123",
    "authors": [
      "Jiaxuan Chen",
      "Jieteng Yao",
      "Li Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.01147",
    "title": "Efficient Reinforcement Learning for Routing Jobs in Heterogeneous  Queueing Systems",
    "abstract": " Comments: AISTATS 2024; Corrected typos ",
    "url": "https://arxiv.org/abs/2402.01147",
    "authors": [
      "Neharika Jali",
      "Guannan Qu",
      "Weina Wang",
      "Gauri Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2402.01397",
    "title": "A survey on robustness in trajectory prediction for autonomous vehicles",
    "abstract": " Comments: 8 pages, 1 figure, 1 table ",
    "url": "https://arxiv.org/abs/2402.01397",
    "authors": [
      "Jeroen Hagenus",
      "Frederik Baymler Mathiesen",
      "Julian F. Schumann",
      "Arkady Zgonnikov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.07307",
    "title": "Self-Consistent Conformal Prediction",
    "abstract": " Title: Self-Consistent Conformal Prediction ",
    "url": "https://arxiv.org/abs/2402.07307",
    "authors": [
      "Lars van der Laan",
      "Ahmed M. Alaa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2402.11461",
    "title": "FGeo-HyperGNet: Geometric Problem Solving Integrating Formal Symbolic  System and Hypergraph Neural Network",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2402.11461",
    "authors": [
      "Xiaokai Zhang",
      "Na Zhu",
      "Cheng Qin",
      "Yang Li",
      "Zhenbing Zeng",
      "Tuo Leng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.11677",
    "title": "MultiCorrupt: A Multi-Modal Robustness Dataset and Benchmark of  LiDAR-Camera Fusion for 3D Object Detection",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2402.11677",
    "authors": [
      "Till Beemelmanns",
      "Quan Zhang",
      "Christian Geller",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.11753",
    "title": "ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs",
    "abstract": " Title: ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs ",
    "url": "https://arxiv.org/abs/2402.11753",
    "authors": [
      "Fengqing Jiang",
      "Zhangchen Xu",
      "Luyao Niu",
      "Zhen Xiang",
      "Bhaskar Ramasubramanian",
      "Bo Li",
      "Radha Poovendran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12338",
    "title": "An Adversarial Approach to Evaluating the Robustness of Event  Identification Models",
    "abstract": " Title: An Adversarial Approach to Evaluating the Robustness of Event  Identification Models ",
    "url": "https://arxiv.org/abs/2402.12338",
    "authors": [
      "Obai Bahwal",
      "Oliver Kosut",
      "Lalitha Sankar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.15163",
    "title": "Studying the Impact of Stochasticity on the Evaluation of Deep Neural  Networks for Forest-Fire Prediction",
    "abstract": " Comments: Under peer review ",
    "url": "https://arxiv.org/abs/2402.15163",
    "authors": [
      "Harshit Kumar",
      "Biswadeep Chakraborty",
      "Beomseok Kang",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.17905",
    "title": "Using Graph Neural Networks to Predict Local Culture",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2402.17905",
    "authors": [
      "Thiago H Silva",
      "Daniel Silver"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.01644",
    "title": "OccFusion: A Straightforward and Effective Multi-Sensor Fusion Framework  for 3D Occupancy Prediction",
    "abstract": " Title: OccFusion: A Straightforward and Effective Multi-Sensor Fusion Framework  for 3D Occupancy Prediction ",
    "url": "https://arxiv.org/abs/2403.01644",
    "authors": [
      "Zhenxing Ming",
      "Julie Stephany Berrio",
      "Mao Shan",
      "Stewart Worrall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.04287",
    "title": "DGR: A General Graph Desmoothing Framework for Recommendation via Global  and Local Perspectives",
    "abstract": " Title: DGR: A General Graph Desmoothing Framework for Recommendation via Global  and Local Perspectives ",
    "url": "https://arxiv.org/abs/2403.04287",
    "authors": [
      "Leilei Ding",
      "Dazhong Shen",
      "Chao Wang",
      "Tianfu Wang",
      "Le Zhang",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.05817",
    "title": "SAFDNet: A Simple and Effective Network for Fully Sparse 3D Object  Detection",
    "abstract": " Comments: Accepted by CVPR 2024 (Oral) ",
    "url": "https://arxiv.org/abs/2403.05817",
    "authors": [
      "Gang Zhang",
      "Junnan Chen",
      "Guohuan Gao",
      "Jianmin Li",
      "Si Liu",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.06687",
    "title": "Advancing Graph Neural Networks with HL-HGAT: A Hodge-Laplacian and  Attention Mechanism Approach for Heterogeneous Graph-Structured Data",
    "abstract": " Title: Advancing Graph Neural Networks with HL-HGAT: A Hodge-Laplacian and  Attention Mechanism Approach for Heterogeneous Graph-Structured Data ",
    "url": "https://arxiv.org/abs/2403.06687",
    "authors": [
      "Jinghan Huang",
      "Qiufeng Chen",
      "Yijun Bian",
      "Pengli Zhu",
      "Nanguang Chen",
      "Moo K. Chung",
      "Anqi Qiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09173",
    "title": "Bridging Quantum Computing and Differential Privacy: Insights into  Quantum Computing Privacy",
    "abstract": " Comments: 12 pages (10 pages + 2 refs) ",
    "url": "https://arxiv.org/abs/2403.09173",
    "authors": [
      "Yusheng Zhao",
      "Hui Zhong",
      "Xinyue Zhang",
      "Yuqing Li",
      "Chi Zhang",
      "Miao Pan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.09450",
    "title": "Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative  Privacy Risk",
    "abstract": " Title: Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative  Privacy Risk ",
    "url": "https://arxiv.org/abs/2403.09450",
    "authors": [
      "Zhangheng Li",
      "Junyuan Hong",
      "Bo Li",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10518",
    "title": "Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation  Guided by the Characteristic Dance Primitives",
    "abstract": " Comments: Accepted by CVPR2024, Project page: this https URL ",
    "url": "https://arxiv.org/abs/2403.10518",
    "authors": [
      "Ronghui Li",
      "YuXiang Zhang",
      "Yachao Zhang",
      "Hongwen Zhang",
      "Jie Guo",
      "Yan Zhang",
      "Yebin Liu",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.14593",
    "title": "Rethinking Adversarial Inverse Reinforcement Learning: From the Angles  of Policy Imitation and Transferable Reward Recovery",
    "abstract": " Title: Rethinking Adversarial Inverse Reinforcement Learning: From the Angles  of Policy Imitation and Transferable Reward Recovery ",
    "url": "https://arxiv.org/abs/2403.14593",
    "authors": [
      "Yangchun Zhang",
      "Yirui Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.16055",
    "title": "Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from  Monetary Policy Conference Calls with LLM",
    "abstract": " Comments: Accepted by LREC Coling 2024 -FinNLP (oral) ",
    "url": "https://arxiv.org/abs/2403.16055",
    "authors": [
      "Kun Ouyang",
      "Yi Liu",
      "Shicheng Li",
      "Ruihan Bao",
      "Keiko Harimoto",
      "Xu Sun"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2403.17886",
    "title": "Neural Embedding Compression For Efficient Multi-Task Earth Observation  Modelling",
    "abstract": " Comments: Published at IGARSS 2024 ",
    "url": "https://arxiv.org/abs/2403.17886",
    "authors": [
      "Carlos Gomes",
      "Thomas Brunschwiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.18985",
    "title": "Robustness and Visual Explanation for Black Box Image, Video, and ECG  Signal Classification with Reinforcement Learning",
    "abstract": " Comments: AAAI Proceedings reference: this https URL ",
    "url": "https://arxiv.org/abs/2403.18985",
    "authors": [
      "Soumyendu Sarkar",
      "Ashwin Ramesh Babu",
      "Sajad Mousavi",
      "Vineet Gundecha",
      "Avisek Naug",
      "Sahand Ghorbanpour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2403.19852",
    "title": "A Review of Graph Neural Networks in Epidemic Modeling",
    "abstract": " Title: A Review of Graph Neural Networks in Epidemic Modeling ",
    "url": "https://arxiv.org/abs/2403.19852",
    "authors": [
      "Zewen Liu",
      "Guancheng Wan",
      "B. Aditya Prakash",
      "Max S. Y. Lau",
      "Wei Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2403.20260",
    "title": "Prototype-based Interpretable Breast Cancer Prediction Models: Analysis  and Challenges",
    "abstract": " Comments: Accepted at World Conference on Explainable Artificial Intelligence; 21 pages, 5 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2403.20260",
    "authors": [
      "Shreyasi Pathak",
      "J\u00f6rg Schl\u00f6tterer",
      "Jeroen Veltman",
      "Jeroen Geerdink",
      "Maurice van Keulen",
      "Christin Seifert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00257",
    "title": "YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel  Class Discovery",
    "abstract": " Comments: Withdrawn because it was submitted without consent of the first author. In addition, this submission has some errors ",
    "url": "https://arxiv.org/abs/2404.00257",
    "authors": [
      "Qian Wan",
      "Xiang Xiang",
      "Qinhao Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2404.01643",
    "title": "A Closer Look at Spatial-Slice Features Learning for COVID-19 Detection",
    "abstract": " Comments: Camera-ready version, accepted by DEF-AI-MIA workshop, in conjunted with CVPR2024 ",
    "url": "https://arxiv.org/abs/2404.01643",
    "authors": [
      "Chih-Chung Hsu",
      "Chia-Ming Lee",
      "Yang Fan Chiang",
      "Yi-Shiuan Chou",
      "Chih-Yu Jiang",
      "Shen-Chieh Tai",
      "Chi-Han Tsai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.02000",
    "title": "Africa-Centric Self-Supervised Pre-Training for Multilingual Speech  Representation in a Sub-Saharan Context",
    "abstract": " Comments: To appear in AfricaNLP 2024 ",
    "url": "https://arxiv.org/abs/2404.02000",
    "authors": [
      "Antoine Caubri\u00e8re",
      "Elodie Gauthier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.02937",
    "title": "Towards Responsible and Reliable Traffic Flow Prediction with Large  Language Models",
    "abstract": " Comments: 27pages, 8 figures ",
    "url": "https://arxiv.org/abs/2404.02937",
    "authors": [
      "Xusen Guo",
      "Qiming Zhang",
      "Junyue Jiang",
      "Mingxing Peng",
      "Yang",
      "Meixin Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.04438",
    "title": "Stable Blockchain Sharding under Adversarial Transaction Generation",
    "abstract": " Comments: 11 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2404.04438",
    "authors": [
      "Ramesh Adhikari",
      "Costas Busch",
      "Dariusz R. Kowalski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2404.05656",
    "title": "Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid  Framework",
    "abstract": " Title: Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid  Framework ",
    "url": "https://arxiv.org/abs/2404.05656",
    "authors": [
      "Shahidur Rahoman Sohag",
      "Sai Zhang",
      "Min Xian",
      "Shoukun Sun",
      "Fei Xu",
      "Zhegang Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.08162",
    "title": "Naively Sorting Evolving Data is Optimal and Robust",
    "abstract": " Comments: 37 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2404.08162",
    "authors": [
      "George Giakkoupis",
      "Marcos Kiwi",
      "Dimitrios Los"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2404.10296",
    "title": "Engineering software 2.0 by interpolating neural networks: unifying  training, solving, and calibration",
    "abstract": " Comments: 9 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2404.10296",
    "authors": [
      "Chanwook Park",
      "Sourav Saha",
      "Jiachen Guo",
      "Xiaoyu Xie",
      "Satyajit Mojumder",
      "Miguel A. Bessa",
      "Dong Qian",
      "Wei Chen",
      "Gregory J. Wagner",
      "Jian Cao",
      "Wing Kam Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2404.10593",
    "title": "A Longitudinal Study of Child Wellbeing Assessment via Online  Interactions with a Social Robots",
    "abstract": " Title: A Longitudinal Study of Child Wellbeing Assessment via Online  Interactions with a Social Robots ",
    "url": "https://arxiv.org/abs/2404.10593",
    "authors": [
      "Nida Itrat Abbasi",
      "Guy Laban",
      "Tamsin Ford",
      "Peter B. Jones",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.10800",
    "title": "Advancing Network Intrusion Detection: Integrating Graph Neural Networks  with Scattering Transform and Node2Vec for Enhanced Anomaly Detection",
    "abstract": " Title: Advancing Network Intrusion Detection: Integrating Graph Neural Networks  with Scattering Transform and Node2Vec for Enhanced Anomaly Detection ",
    "url": "https://arxiv.org/abs/2404.10800",
    "authors": [
      "Abdeljalil Zoubir",
      "Badr Missaoui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.10907",
    "title": "Causal Effect Estimation Using Random Hyperplane Tessellations",
    "abstract": " Comments: At CLeaR 2024 ",
    "url": "https://arxiv.org/abs/2404.10907",
    "authors": [
      "Abhishek Dalvi",
      "Neil Ashtekar",
      "Vasant Honavar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.10976",
    "title": "Group-Aware Coordination Graph for Multi-Agent Reinforcement Learning",
    "abstract": " Comments: Accepted by IJCAI 2024 ",
    "url": "https://arxiv.org/abs/2404.10976",
    "authors": [
      "Wei Duan",
      "Jie Lu",
      "Junyu Xuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2404.11422",
    "title": "Short-term wind speed forecasting model based on an attention-gated  recurrent neural network and error correction strategy",
    "abstract": " Comments: 23 pages, 11 figures, 6 tables, Technical Report ",
    "url": "https://arxiv.org/abs/2404.11422",
    "authors": [
      "Haojian Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2404.12149",
    "title": "AccidentBlip2: Accident Detection With Multi-View MotionBlip2",
    "abstract": " Title: AccidentBlip2: Accident Detection With Multi-View MotionBlip2 ",
    "url": "https://arxiv.org/abs/2404.12149",
    "authors": [
      "Yihua Shao",
      "Hongyi Cai",
      "Xinwei Long",
      "Weiyi Lang",
      "Zhe Wang",
      "Haoran Wu",
      "Yan Wang",
      "Jiayi Yin",
      "Yang Yang",
      "Zhen Lei"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.12291",
    "title": "Augmenting emotion features in irony detection with Large language  modeling",
    "abstract": " Comments: 11 pages, 3 tables, 2 figures. Accepted by the 25th Chinese Lexical Semantics Workshop ",
    "url": "https://arxiv.org/abs/2404.12291",
    "authors": [
      "Yucheng Lin",
      "Yuhan Xia",
      "Yunfei Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.12916",
    "title": "Physical Backdoor Attack can Jeopardize Driving with  Vision-Large-Language Models",
    "abstract": " Title: Physical Backdoor Attack can Jeopardize Driving with  Vision-Large-Language Models ",
    "url": "https://arxiv.org/abs/2404.12916",
    "authors": [
      "Zhenyang Ni",
      "Rui Ye",
      "Yuxi Wei",
      "Zhen Xiang",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  }
]