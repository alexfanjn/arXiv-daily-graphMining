[
  {
    "id": "arXiv:2404.00011",
    "title": "A novel interface for adversarial trivia question-writing",
    "abstract": "A critical component when developing question-answering AIs is an adversarial dataset that challenges models to adapt to the complex syntax and reasoning underlying our natural language. Present techniques for procedurally generating adversarial texts are not robust enough for training on complex tasks such as answering multi-sentence trivia questions. We instead turn to human-generated data by introducing an interface for collecting adversarial human-written trivia questions. Our interface is aimed towards question writers and players of Quiz Bowl, a buzzer-based trivia competition where paragraph-long questions consist of a sequence of clues of decreasing difficulty. To incentivize usage, a suite of machine learning-based tools in our interface assist humans in writing questions that are more challenging to answer for Quiz Bowl players and computers alike. Not only does our interface gather training data for the groundbreaking Quiz Bowl AI project QANTA, but it is also a proof-of-concept of future adversarial data collection for question-answering systems. The results of performance-testing our interface with ten originally-composed questions indicate that, despite some flaws, our interface's novel question-writing features as well as its real-time exposure of useful responses from our machine models could facilitate and enhance the collection of adversarial questions. ",
    "url": "https://arxiv.org/abs/2404.00011",
    "authors": [
      "Jason Liu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00013",
    "title": "Missing Data Imputation With Granular Semantics and AI-driven Pipeline  for Bankruptcy Prediction",
    "abstract": "This work focuses on designing a pipeline for the prediction of bankruptcy. The presence of missing values, high dimensional data, and highly class-imbalance databases are the major challenges in the said task. A new method for missing data imputation with granular semantics has been introduced here. The merits of granular computing have been explored here to define this method. The missing values have been predicted using the feature semantics and reliable observations in a low-dimensional space, in the granular space. The granules are formed around every missing entry, considering a few of the highly correlated features and most reliable closest observations to preserve the relevance and reliability, the context, of the database against the missing entries. An intergranular prediction is then carried out for the imputation within those contextual granules. That is, the contextual granules enable a small relevant fraction of the huge database to be used for imputation and overcome the need to access the entire database repetitively for each missing value. This method is then implemented and tested for the prediction of bankruptcy with the Polish Bankruptcy dataset. It provides an efficient solution for big and high-dimensional datasets even with large imputation rates. Then an AI-driven pipeline for bankruptcy prediction has been designed using the proposed granular semantic-based data filling method followed by the solutions to the issues like high dimensional dataset and high class-imbalance in the dataset. The rest of the pipeline consists of feature selection with the random forest for reducing dimensionality, data balancing with SMOTE, and prediction with six different popular classifiers including deep NN. All methods defined here have been experimentally verified with suitable comparative studies and proven to be effective on all the data sets captured over the five years. ",
    "url": "https://arxiv.org/abs/2404.00013",
    "authors": [
      "Debarati Chakraborty",
      "Ravi Ranjan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistical Finance (q-fin.ST)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2404.00018",
    "title": "Can AI Outperform Human Experts in Creating Social Media Creatives?",
    "abstract": "Artificial Intelligence has outperformed human experts in functional tasks such as chess and baduk. How about creative tasks? This paper evaluates AI's capability in the creative domain compared to human experts, which little research has been conducted so far. We propose a novel Prompt-for-Prompt to generate social media creatives via prompt augmentation by Large Language Models. We take the most popular Instagram posts (with the biggest number of like clicks) in top brands' Instagram accounts to create social media creatives. We give GPT 4 several prompt instructions with text descriptions to generate the most effective prompts for cutting-edge text-to-image generators: Midjourney, DALL E 3, and Stable Diffusion. LLM-augmented prompts can boost AI's abilities by adding objectives, engagement strategy, lighting and brand consistency for social media image creation. We conduct an extensive human evaluation experiment, and find that AI excels human experts, and Midjourney is better than the other text-to-image generators. Surprisingly, unlike conventional wisdom in the social media industry, prompt instruction including eye-catching shows much poorer performance than those including natural. Regarding the type of creatives, AI improves creatives with animals or products but less with real people. Also, AI improves creatives with short text descriptions more than with long text descriptions, because there is more room for AI to augment prompts with shorter descriptions. ",
    "url": "https://arxiv.org/abs/2404.00018",
    "authors": [
      "Eunkyung Park",
      "Raymond K. Wong",
      "Junbum Kwon"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2404.00051",
    "title": "Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal  Knowledge Graph Reasoning",
    "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the task of inferring missing facts for incomplete TKGs in complex scenarios (e.g., transductive and inductive settings), which has been gaining increasing attention. Recently, to mitigate dependence on structured connections in TKGs, text-based methods have been developed to utilize rich linguistic information from entity descriptions. However, suffering from the enormous parameters and inflexibility of pre-trained language models, existing text-based methods struggle to balance the textual knowledge and temporal information with computationally expensive purpose-built training strategies. To tap the potential of text-based models for TKGR in various complex scenarios, we propose ChapTER, a Contrastive historical modeling framework with prefix-tuning for TEmporal Reasoning. ChapTER feeds history-contextualized text into the pseudo-Siamese encoders to strike a textual-temporal balance via contrastive estimation between queries and candidates. By introducing virtual time prefix tokens, it applies a prefix-based tuning method to facilitate the frozen PLM capable for TKGR tasks under different settings. We evaluate ChapTER on four transductive and three few-shot inductive TKGR benchmarks, and experimental results demonstrate that ChapTER achieves superior performance compared to competitive baselines with only 0.17% tuned parameters. We conduct thorough analysis to verify the effectiveness, flexibility and efficiency of ChapTER. ",
    "url": "https://arxiv.org/abs/2404.00051",
    "authors": [
      "Miao Peng",
      "Ben Liu",
      "Wenjie Xu",
      "Zihao Jiang",
      "Jiahui Zhu",
      "Min Peng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00062",
    "title": "Modelling the Impact of Quantum Circuit Imperfections on Networks and  Computer Applications",
    "abstract": "Post Quantum and Quantum Cryptography schemes are feasible quantum computer applications for 7G networks. These schemes could possibly replace existing schemes. These algorithms have been compromised by advances in quantum search algorithms run on quantum computers like Shor algorithm. Shor algorithm is a quantum algorithm for finding the prime factors of an integer which is the basis of existing algorithm. This has become an available quantum computer application putting the use of ESA algorithm at risk. Our recent paper provides a detailed survey of the work on post quantum and quantum cryptography algorithms with focus on their applicability in 7G networks. Since the paper focuses on the cryptography algorithms as a follow up, in this paper, we provide a new framework for quantum network optimization and survey in detail the work on enabling technologies (quantum hardware) for the practical implementation of these algorithms including the most important segments of quantum hardware in 7G. As always in engineering practice practical solutions are a compromise between the performance and complexity of the implementation. For this reason, as the main contribution, the paper presents a network and computer applications optimization framework that includes implementation imperfections. The tools should be useful in optimizing future generation practical computer system design. After that a comprehensive survey of the existing work on quantum hardware is presented pointing out the sources of these imperfections. This enables us to make a fair assessment of how much investment into quantum hardware improvements contributes to the performance enhancement of the overall system. In this way a decision can be made on proper partitioning between the investment in hardware and system level complexity. ",
    "url": "https://arxiv.org/abs/2404.00062",
    "authors": [
      "Savo Glisic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2404.00076",
    "title": "A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping  Attacks",
    "abstract": "Audio-based machine learning systems frequently use public or third-party data, which might be inaccurate. This exposes deep neural network (DNN) models trained on such data to potential data poisoning attacks. In this type of assault, attackers can train the DNN model using poisoned data, potentially degrading its performance. Another type of data poisoning attack that is extremely relevant to our investigation is label flipping, in which the attacker manipulates the labels for a subset of data. It has been demonstrated that these assaults may drastically reduce system performance, even for attackers with minimal abilities. In this study, we propose a backdoor attack named 'DirtyFlipping', which uses dirty label techniques, \"label-on-label\", to input triggers (clapping) in the selected data patterns associated with the target class, thereby enabling a stealthy backdoor. ",
    "url": "https://arxiv.org/abs/2404.00076",
    "authors": [
      "Orson Mengara"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.00095",
    "title": "GDA: Generalized Diffusion for Robust Test-time Adaptation",
    "abstract": "Machine learning models struggle with generalization when encountering out-of-distribution (OOD) samples with unexpected distribution shifts. For vision tasks, recent studies have shown that test-time adaptation employing diffusion models can achieve state-of-the-art accuracy improvements on OOD samples by generating new samples that align with the model's domain without the need to modify the model's weights. Unfortunately, those studies have primarily focused on pixel-level corruptions, thereby lacking the generalization to adapt to a broader range of OOD types. We introduce Generalized Diffusion Adaptation (GDA), a novel diffusion-based test-time adaptation method robust against diverse OOD types. Specifically, GDA iteratively guides the diffusion by applying a marginal entropy loss derived from the model, in conjunction with style and content preservation losses during the reverse sampling process. In other words, GDA considers the model's output behavior with the semantic information of the samples as a whole, which can reduce ambiguity in downstream tasks during the generation process. Evaluation across various popular model architectures and OOD benchmarks shows that GDA consistently outperforms prior work on diffusion-driven adaptation. Notably, it achieves the highest classification accuracy improvements, ranging from 4.4\\% to 5.02\\% on ImageNet-C and 2.5\\% to 7.4\\% on Rendition, Sketch, and Stylized benchmarks. This performance highlights GDA's generalization to a broader range of OOD benchmarks. ",
    "url": "https://arxiv.org/abs/2404.00095",
    "authors": [
      "Yun-Yun Tsai",
      "Fu-Chen Chen",
      "Albert Y. C. Chen",
      "Junfeng Yang",
      "Che-Chun Su",
      "Min Sun",
      "Cheng-Hao Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00099",
    "title": "Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision  Processes",
    "abstract": "We study evaluating a policy under best- and worst-case perturbations to a Markov decision process (MDP), given transition observations from the original MDP, whether under the same or different policy. This is an important problem when there is the possibility of a shift between historical and future environments, due to e.g. unmeasured confounding, distributional shift, or an adversarial environment. We propose a perturbation model that can modify transition kernel densities up to a given multiplicative factor or its reciprocal, which extends the classic marginal sensitivity model (MSM) for single time step decision making to infinite-horizon RL. We characterize the sharp bounds on policy value under this model, that is, the tightest possible bounds given by the transition observations from the original MDP, and we study the estimation of these bounds from such transition observations. We develop an estimator with several appealing guarantees: it is semiparametrically efficient, and remains so even when certain necessary nuisance functions such as worst-case Q-functions are estimated at slow nonparametric rates. It is also asymptotically normal, enabling easy statistical inference using Wald confidence intervals. In addition, when certain nuisances are estimated inconsistently we still estimate a valid, albeit possibly not sharp bounds on the policy value. We validate these properties in numeric simulations. The combination of accounting for environment shifts from train to test (robustness), being insensitive to nuisance-function estimation (orthogonality), and accounting for having only finite samples to learn from (inference) together leads to credible and reliable policy evaluation. ",
    "url": "https://arxiv.org/abs/2404.00099",
    "authors": [
      "Andrew Bennett",
      "Nathan Kallus",
      "Miruna Oprescu",
      "Wen Sun",
      "Kaiwen Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.00103",
    "title": "PikeLPN: Mitigating Overlooked Inefficiencies of Low-Precision Neural  Networks",
    "abstract": "Low-precision quantization is recognized for its efficacy in neural network optimization. Our analysis reveals that non-quantized elementwise operations which are prevalent in layers such as parameterized activation functions, batch normalization, and quantization scaling dominate the inference cost of low-precision models. These non-quantized elementwise operations are commonly overlooked in SOTA efficiency metrics such as Arithmetic Computation Effort (ACE). In this paper, we propose ACEv2 - an extended version of ACE which offers a better alignment with the inference cost of quantized models and their energy consumption on ML hardware. Moreover, we introduce PikeLPN, a model that addresses these efficiency issues by applying quantization to both elementwise operations and multiply-accumulate operations. In particular, we present a novel quantization technique for batch normalization layers named QuantNorm which allows for quantizing the batch normalization parameters without compromising the model performance. Additionally, we propose applying Double Quantization where the quantization scaling parameters are quantized. Furthermore, we recognize and resolve the issue of distribution mismatch in Separable Convolution layers by introducing Distribution-Heterogeneous Quantization which enables quantizing them to low-precision. PikeLPN achieves Pareto-optimality in efficiency-accuracy trade-off with up to 3X efficiency improvement compared to SOTA low-precision models. ",
    "url": "https://arxiv.org/abs/2404.00103",
    "authors": [
      "Marina Neseem",
      "Conor McCullough",
      "Randy Hsin",
      "Chas Leichner",
      "Shan Li",
      "In Suk Chong",
      "Andrew G. Howard",
      "Lukasz Lew",
      "Sherief Reda",
      "Ville-Mikko Rautio",
      "Daniele Moro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00107",
    "title": "Robust Ensemble Person Re-Identification via Orthogonal Fusion with  Occlusion Handling",
    "abstract": "Occlusion remains one of the major challenges in person reidentification (ReID) as a result of the diversity of poses and the variation of appearances. Developing novel architectures to improve the robustness of occlusion-aware person Re-ID requires new insights, especially on low-resolution edge cameras. We propose a deep ensemble model that harnesses both CNN and Transformer architectures to generate robust feature representations. To achieve robust Re-ID without the need to manually label occluded regions, we propose to take an ensemble learning-based approach derived from the analogy between arbitrarily shaped occluded regions and robust feature representation. Using the orthogonality principle, our developed deep CNN model makes use of masked autoencoder (MAE) and global-local feature fusion for robust person identification. Furthermore, we present a part occlusion-aware transformer capable of learning feature space that is robust to occluded regions. Experimental results are reported on several Re-ID datasets to show the effectiveness of our developed ensemble model named orthogonal fusion with occlusion handling (OFOH). Compared to competing methods, the proposed OFOH approach has achieved competent rank-1 and mAP performance. ",
    "url": "https://arxiv.org/abs/2404.00107",
    "authors": [
      "Syeda Nyma Ferdous",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00114",
    "title": "Deepfake Sentry: Harnessing Ensemble Intelligence for Resilient  Detection and Generalisation",
    "abstract": "Recent advancements in Generative Adversarial Networks (GANs) have enabled photorealistic image generation with high quality. However, the malicious use of such generated media has raised concerns regarding visual misinformation. Although deepfake detection research has demonstrated high accuracy, it is vulnerable to advances in generation techniques and adversarial iterations on detection countermeasures. To address this, we propose a proactive and sustainable deepfake training augmentation solution that introduces artificial fingerprints into models. We achieve this by employing an ensemble learning approach that incorporates a pool of autoencoders that mimic the effect of the artefacts introduced by the deepfake generator models. Experiments on three datasets reveal that our proposed ensemble autoencoder-based data augmentation learning approach offers improvements in terms of generalisation, resistance against basic data perturbations such as noise, blurring, sharpness enhancement, and affine transforms, resilience to commonly used lossy compression algorithms such as JPEG, and enhanced resistance against adversarial attacks. ",
    "url": "https://arxiv.org/abs/2404.00114",
    "authors": [
      "Liviu-Daniel \u015etefan",
      "Dan-Cristian Stanciu",
      "Mihai Dogariu",
      "Mihai Gabriel Constantin",
      "Andrei Cosmin Jitaru",
      "Bogdan Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00123",
    "title": "SURESTEP: An Uncertainty-Aware Trajectory Optimization Framework to  Enhance Visual Tool Tracking for Robust Surgical Automation",
    "abstract": "Inaccurate tool localization is one of the main reasons for failures in automating surgical tasks. Imprecise robot kinematics and noisy observations caused by the poor visual acuity of an endoscopic camera make tool tracking challenging. Previous works in surgical automation adopt environment-specific setups or hard-coded strategies instead of explicitly considering motion and observation uncertainty of tool tracking in their policies. In this work, we present SURESTEP, an uncertainty-aware trajectory optimization framework for robust surgical automation. We model the uncertainty of tool tracking with the components motivated by the sources of noise in typical surgical scenes. Using a Gaussian assumption to propagate our uncertainty models through a given tool trajectory, SURESTEP provides a general framework that minimizes the upper bound on the entropy of the final estimated tool distribution. We compare SURESTEP with a baseline method on a real-world suture needle regrasping task under challenging environmental conditions, such as poor lighting and a moving endoscopic camera. The results over 60 regrasps on the da Vinci Research Kit (dVRK) demonstrate that our optimized trajectories significantly outperform the un-optimized baseline. ",
    "url": "https://arxiv.org/abs/2404.00123",
    "authors": [
      "Nikhil U. Shinde",
      "Zih-Yun Chiu",
      "Florian Richter",
      "Jason Lim",
      "Yuheng Zhi",
      "Sylvia Herbert",
      "Michael C. Yip"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.00149",
    "title": "VSRD: Instance-Aware Volumetric Silhouette Rendering for Weakly  Supervised 3D Object Detection",
    "abstract": "Monocular 3D object detection poses a significant challenge in 3D scene understanding due to its inherently ill-posed nature in monocular depth estimation. Existing methods heavily rely on supervised learning using abundant 3D labels, typically obtained through expensive and labor-intensive annotation on LiDAR point clouds. To tackle this problem, we propose a novel weakly supervised 3D object detection framework named VSRD (Volumetric Silhouette Rendering for Detection) to train 3D object detectors without any 3D supervision but only weak 2D supervision. VSRD consists of multi-view 3D auto-labeling and subsequent training of monocular 3D object detectors using the pseudo labels generated in the auto-labeling stage. In the auto-labeling stage, we represent the surface of each instance as a signed distance field (SDF) and render its silhouette as an instance mask through our proposed instance-aware volumetric silhouette rendering. To directly optimize the 3D bounding boxes through rendering, we decompose the SDF of each instance into the SDF of a cuboid and the residual distance field (RDF) that represents the residual from the cuboid. This mechanism enables us to optimize the 3D bounding boxes in an end-to-end manner by comparing the rendered instance masks with the ground truth instance masks. The optimized 3D bounding boxes serve as effective training data for 3D object detection. We conduct extensive experiments on the KITTI-360 dataset, demonstrating that our method outperforms the existing weakly supervised 3D object detection methods. The code is available at https://github.com/skmhrk1209/VSRD. ",
    "url": "https://arxiv.org/abs/2404.00149",
    "authors": [
      "Zihua Liu",
      "Hiroki Sakuma",
      "Masatoshi Okutomi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00152",
    "title": "On-the-fly Definition Augmentation of LLMs for Biomedical NER",
    "abstract": "Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15\\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM performance, allowing them to outperform fine-tuned language models in few-shot settings. To facilitate future research in this direction, we release our code at https://github.com/allenai/beacon. ",
    "url": "https://arxiv.org/abs/2404.00152",
    "authors": [
      "Monica Munnangi",
      "Sergey Feldman",
      "Byron C Wallace",
      "Silvio Amir",
      "Tom Hope",
      "Aakanksha Naik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00163",
    "title": "CT respiratory motion synthesis using joint supervised and adversarial  learning",
    "abstract": "Objective: Four-dimensional computed tomography (4DCT) imaging consists in reconstructing a CT acquisition into multiple phases to track internal organ and tumor motion. It is commonly used in radiotherapy treatment planning to establish planning target volumes. However, 4DCT increases protocol complexity, may not align with patient breathing during treatment, and lead to higher radiation delivery. Approach: In this study, we propose a deep synthesis method to generate pseudo respiratory CT phases from static images for motion-aware treatment planning. The model produces patient-specific deformation vector fields (DVFs) by conditioning synthesis on external patient surface-based estimation, mimicking respiratory monitoring devices. A key methodological contribution is to encourage DVF realism through supervised DVF training while using an adversarial term jointly not only on the warped image but also on the magnitude of the DVF itself. This way, we avoid excessive smoothness typically obtained through deep unsupervised learning, and encourage correlations with the respiratory amplitude. Main results: Performance is evaluated using real 4DCT acquisitions with smaller tumor volumes than previously reported. Results demonstrate for the first time that the generated pseudo-respiratory CT phases can capture organ and tumor motion with similar accuracy to repeated 4DCT scans of the same patient. Mean inter-scans tumor center-of-mass distances and Dice similarity coefficients were $1.97$mm and $0.63$, respectively, for real 4DCT phases and $2.35$mm and $0.71$ for synthetic phases, and compares favorably to a state-of-the-art technique (RMSim). ",
    "url": "https://arxiv.org/abs/2404.00163",
    "authors": [
      "Yi-Heng Cao",
      "Vincent Bourbonne",
      "Fran\u00e7ois Lucia",
      "Ulrike Schick",
      "Julien Bert",
      "Vincent Jaouen",
      "Dimitris Visvikis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00168",
    "title": "Multi-Level Neural Scene Graphs for Dynamic Urban Environments",
    "abstract": "We estimate the radiance field of large-scale dynamic areas from multiple vehicle captures under varying environmental conditions. Previous works in this domain are either restricted to static environments, do not scale to more than a single short video, or struggle to separately represent dynamic object instances. To this end, we present a novel, decomposable radiance field approach for dynamic urban environments. We propose a multi-level neural scene graph representation that scales to thousands of images from dozens of sequences with hundreds of fast-moving objects. To enable efficient training and rendering of our representation, we develop a fast composite ray sampling and rendering scheme. To test our approach in urban driving scenarios, we introduce a new, novel view synthesis benchmark. We show that our approach outperforms prior art by a significant margin on both established and our proposed benchmark while being faster in training and rendering. ",
    "url": "https://arxiv.org/abs/2404.00168",
    "authors": [
      "Tobias Fischer",
      "Lorenzo Porzi",
      "Samuel Rota Bul\u00f2",
      "Marc Pollefeys",
      "Peter Kontschieder"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00185",
    "title": "On Inherent Adversarial Robustness of Active Vision Systems",
    "abstract": "Current Deep Neural Networks are vulnerable to adversarial examples, which alter their predictions by adding carefully crafted noise. Since human eyes are robust to such inputs, it is possible that the vulnerability stems from the standard way of processing inputs in one shot by processing every pixel with the same importance. In contrast, neuroscience suggests that the human vision system can differentiate salient features by (1) switching between multiple fixation points (saccades) and (2) processing the surrounding with a non-uniform external resolution (foveation). In this work, we advocate that the integration of such active vision mechanisms into current deep learning systems can offer robustness benefits. Specifically, we empirically demonstrate the inherent robustness of two active vision methods - GFNet and FALcon - under a black box threat model. By learning and inferencing based on downsampled glimpses obtained from multiple distinct fixation points within an input, we show that these active methods achieve (2-3) times greater robustness compared to a standard passive convolutional network under state-of-the-art adversarial attacks. More importantly, we provide illustrative and interpretable visualization analysis that demonstrates how performing inference from distinct fixation points makes active vision methods less vulnerable to malicious inputs. ",
    "url": "https://arxiv.org/abs/2404.00185",
    "authors": [
      "Amitangshu Mukherjee",
      "Timur Ibrayev",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00189",
    "title": "GPTA: Generative Prompt Tuning Assistant for Synergistic Downstream  Neural Network Enhancement with LLMs",
    "abstract": "This study introduces GPTA, a Large Language Model assistance training framework, that enhances the training of downstream task models via prefix prompt. By minimizing data exposure to LLM, the framework addresses the security and legal challenges of applying LLM in downstream task model training. GPTA utilizes a new synergistic training approach, optimizing the downstream models with parameter gradients and LLMs with the novel ``dialogue gradient''. The framework not only demonstrates significant improvements in model performance across six NLP benchmark datasets, but also reduces overfitting in low-resource scenarios effectively. The detailed analyses further validate that our pioneer framework provides a cost-efficient and adaptive method for downstream task model training with LLM support. ",
    "url": "https://arxiv.org/abs/2404.00189",
    "authors": [
      "Xiao Liu",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00196",
    "title": "Combined Static Analysis and Machine Learning Prediction for Application  Debloating",
    "abstract": "Software debloating can effectively thwart certain code reuse attacks by reducing attack surfaces to break gadget chains. Approaches based on static analysis enable a reduced set of functions reachable at a callsite for execution by leveraging static properties of the callgraph. This achieves low runtime overhead, but the function set is conservatively computed, negatively affecting reduction. In contrast, approaches based on machine learning (ML) have much better precision and can sharply reduce function sets, leading to significant improvement in attack surface. Nevertheless, mispredictions occur in ML-based approaches. These cause overheads, and worse, there is no clear way to distinguish between mispredictions and actual attacks. In this work, we contend that a software debloating approach that incorporates ML-based predictions at runtime is realistic in a whole application setting, and that it can achieve significant attack surface reductions beyond the state of the art. We develop a framework, Predictive Debloat with Static Guarantees (PDSG). PDSG is fully sound and works on application source code. At runtime it predicts the dynamic callee set emanating from a callsite, and to resolve mispredictions, it employs a lightweight audit based on static invariants of call chains. We deduce the invariants offline and assert that they hold at runtime when there is a misprediction. To the best of our knowledge, it achieves the highest gadget reductions among similar techniques on SPEC CPU 2017, reducing 82.5% of the total gadgets on average. It triggers misprediction checks on only 3.8% of the total predictions invoked at runtime, and it leverages Datalog to verify dynamic call sequences conform to the static call relations. It has an overhead of 8.9%, which makes the scheme attractive for practical deployments. ",
    "url": "https://arxiv.org/abs/2404.00196",
    "authors": [
      "Chris Porter",
      "Sharjeel Khan",
      "Kangqi Ni",
      "Santosh Pande"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.00204",
    "title": "A PPO-based DRL Auto-Tuning Nonlinear PID Drone Controller for Robust  Autonomous Flights",
    "abstract": "This project aims to revolutionize drone flight control by implementing a nonlinear Deep Reinforcement Learning (DRL) agent as a replacement for traditional linear Proportional Integral Derivative (PID) controllers. The primary objective is to seamlessly transition drones between manual and autonomous modes, enhancing responsiveness and stability. We utilize the Proximal Policy Optimization (PPO) reinforcement learning strategy within the Gazebo simulator to train the DRL agent. Adding a $20,000 indoor Vicon tracking system offers <1mm positioning accuracy, which significantly improves autonomous flight precision. To navigate the drone in the shortest collision-free trajectory, we also build a 3 dimensional A* path planner and implement it into the real flight successfully. ",
    "url": "https://arxiv.org/abs/2404.00204",
    "authors": [
      "Junyang Zhang",
      "Cristian Emanuel Ocampo Rivera",
      "Kyle Tyni",
      "Steven Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.00207",
    "title": "Causal Inference for Human-Language Model Collaboration",
    "abstract": "In this paper, we examine the collaborative dynamics between humans and language models (LMs), where the interactions typically involve LMs proposing text segments and humans editing or responding to these proposals. Productive engagement with LMs in such scenarios necessitates that humans discern effective text-based interaction strategies, such as editing and response styles, from historical human-LM interactions. This objective is inherently causal, driven by the counterfactual `what-if' question: how would the outcome of collaboration change if humans employed a different text editing/refinement strategy? A key challenge in answering this causal inference question is formulating an appropriate causal estimand: the conventional average treatment effect (ATE) estimand is inapplicable to text-based treatments due to their high dimensionality. To address this concern, we introduce a new causal estimand -- Incremental Stylistic Effect (ISE) -- which characterizes the average impact of infinitesimally shifting a text towards a specific style, such as increasing formality. We establish the conditions for the non-parametric identification of ISE. Building on this, we develop CausalCollab, an algorithm designed to estimate the ISE of various interaction strategies in dynamic human-LM collaborations. Our empirical investigations across three distinct human-LM collaboration scenarios reveal that CausalCollab effectively reduces confounding and significantly improves counterfactual estimation over a set of competitive baselines. ",
    "url": "https://arxiv.org/abs/2404.00207",
    "authors": [
      "Bohan Zhang",
      "Yixin Wang",
      "Paramveer S. Dhillon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00209",
    "title": "EventGround: Narrative Reasoning by Grounding to Eventuality-centric  Knowledge Graphs",
    "abstract": "Narrative reasoning relies on the understanding of eventualities in story contexts, which requires a wealth of background world knowledge. To help machines leverage such knowledge, existing solutions can be categorized into two groups. Some focus on implicitly modeling eventuality knowledge by pretraining language models (LMs) with eventuality-aware objectives. However, this approach breaks down knowledge structures and lacks interpretability. Others explicitly collect world knowledge of eventualities into structured eventuality-centric knowledge graphs (KGs). However, existing research on leveraging these knowledge sources for free-texts is limited. In this work, we propose an initial comprehensive framework called EventGround, which aims to tackle the problem of grounding free-texts to eventuality-centric KGs for contextualized narrative reasoning. We identify two critical problems in this direction: the event representation and sparsity problems. We provide simple yet effective parsing and partial information extraction methods to tackle these problems. Experimental results demonstrate that our approach consistently outperforms baseline models when combined with graph neural network (GNN) or large language model (LLM) based graph reasoning models. Our framework, incorporating grounded knowledge, achieves state-of-the-art performance while providing interpretable evidence. ",
    "url": "https://arxiv.org/abs/2404.00209",
    "authors": [
      "Cheng Jiayang",
      "Lin Qiu",
      "Chunkit Chan",
      "Xin Liu",
      "Yangqiu Song",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00225",
    "title": "Heterogeneous Contrastive Learning for Foundation Models and Beyond",
    "abstract": "In the era of big data and Artificial Intelligence, an emerging paradigm is to utilize contrastive self-supervised learning to model large-scale heterogeneous data. Many existing foundation models benefit from the generalization capability of contrastive self-supervised learning by learning compact and high-quality representations without relying on any label information. Amidst the explosive advancements in foundation models across multiple domains, including natural language processing and computer vision, a thorough survey on heterogeneous contrastive learning for the foundation model is urgently needed. In response, this survey critically evaluates the current landscape of heterogeneous contrastive learning for foundation models, highlighting the open challenges and future trends of contrastive learning. In particular, we first present how the recent advanced contrastive learning-based methods deal with view heterogeneity and how contrastive learning is applied to train and fine-tune the multi-view foundation models. Then, we move to contrastive learning methods for task heterogeneity, including pretraining tasks and downstream tasks, and show how different tasks are combined with contrastive learning loss for different purposes. Finally, we conclude this survey by discussing the open challenges and shedding light on the future directions of contrastive learning. ",
    "url": "https://arxiv.org/abs/2404.00225",
    "authors": [
      "Lecheng Zheng",
      "Baoyu Jing",
      "Zihao Li",
      "Hanghang Tong",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00227",
    "title": "A Survey of using Large Language Models for Generating Infrastructure as  Code",
    "abstract": "Infrastructure as Code (IaC) is a revolutionary approach which has gained significant prominence in the Industry. IaC manages and provisions IT infrastructure using machine-readable code by enabling automation, consistency across the environments, reproducibility, version control, error reduction and enhancement in scalability. However, IaC orchestration is often a painstaking effort which requires specialised skills as well as a lot of manual effort. Automation of IaC is a necessity in the present conditions of the Industry and in this survey, we study the feasibility of applying Large Language Models (LLM) to address this problem. LLMs are large neural network-based models which have demonstrated significant language processing abilities and shown to be capable of following a range of instructions within a broad scope. Recently, they have also been adapted for code understanding and generation tasks successfully, which makes them a promising choice for the automatic generation of IaC configurations. In this survey, we delve into the details of IaC, usage of IaC in different platforms, their challenges, LLMs in terms of code-generation aspects and the importance of LLMs in IaC along with our own experiments. Finally, we conclude by presenting the challenges in this area and highlighting the scope for future research. ",
    "url": "https://arxiv.org/abs/2404.00227",
    "authors": [
      "Kalahasti Ganesh Srivatsa",
      "Sabyasachi Mukhopadhyay",
      "Ganesh Katrapati",
      "Manish Shrivastava"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00231",
    "title": "Attention-based Shape-Deformation Networks for Artifact-Free Geometry  Reconstruction of Lumbar Spine from MR Images",
    "abstract": "Lumbar disc degeneration, a progressive structural wear and tear of lumbar intervertebral disc, is regarded as an essential role on low back pain, a significant global health concern. Automated lumbar spine geometry reconstruction from MR images will enable fast measurement of medical parameters to evaluate the lumbar status, in order to determine a suitable treatment. Existing image segmentation-based techniques often generate erroneous segments or unstructured point clouds, unsuitable for medical parameter measurement. In this work, we present TransDeformer: a novel attention-based deep learning approach that reconstructs the contours of the lumbar spine with high spatial accuracy and mesh correspondence across patients, and we also present a variant of TransDeformer for error estimation. Specially, we devise new attention modules with a new attention formula, which integrates image features and tokenized contour features to predict the displacements of the points on a shape template without the need for image segmentation. The deformed template reveals the lumbar spine geometry in the input image. We develop a multi-stage training strategy to enhance model robustness with respect to template initialization. Experiment results show that our TransDeformer generates artifact-free geometry outputs, and its variant predicts the error of a reconstructed geometry. Our code is available at https://github.com/linchenq/TransDeformer-Mesh. ",
    "url": "https://arxiv.org/abs/2404.00231",
    "authors": [
      "Linchen Qian",
      "Jiasong Chen",
      "Linhai Ma",
      "Timur Urakov",
      "Weiyong Gu",
      "Liang Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00235",
    "title": "Information Security and Privacy in the Digital World: Some Selected  Topics",
    "abstract": "In the era of generative artificial intelligence and the Internet of Things, while there is explosive growth in the volume of data and the associated need for processing, analysis, and storage, several new challenges are faced in identifying spurious and fake information and protecting the privacy of sensitive data. This has led to an increasing demand for more robust and resilient schemes for authentication, integrity protection, encryption, non-repudiation, and privacy-preservation of data. The chapters in this book present some of the state-of-the-art research works in the field of cryptography and security in computing and communications. ",
    "url": "https://arxiv.org/abs/2404.00235",
    "authors": [
      "Jaydip Sen",
      "Joceli Mayer",
      "Subhasis Dasgupta",
      "Subrata Nandi",
      "Srinivasan Krishnaswamy",
      "Pinaki Mitra",
      "Mahendra Pratap Singh",
      "Naga Prasanthi Kundeti",
      "Chandra Sekhara Rao MVP",
      "Sudha Sree Chekuri",
      "Seshu Babu Pallapothu",
      "Preethi Nanjundan",
      "Jossy P. George",
      "Abdelhadi El Allahi",
      "Ilham Morino",
      "Salma AIT Oussous",
      "Siham Beloualid",
      "Ahmed Tamtaoui",
      "Abderrahim Bajit"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00237",
    "title": "Joint Pedestrian Trajectory Prediction through Posterior Sampling",
    "abstract": "Joint pedestrian trajectory prediction has long grappled with the inherent unpredictability of human behaviors. Recent investigations employing variants of conditional diffusion models in trajectory prediction have exhibited notable success. Nevertheless, the heavy dependence on accurate historical data results in their vulnerability to noise disturbances and data incompleteness. To improve the robustness and reliability, we introduce the Guided Full Trajectory Diffuser (GFTD), a novel diffusion model framework that captures the joint full (historical and future) trajectory distribution. By learning from the full trajectory, GFTD can recover the noisy and missing data, hence improving the robustness. In addition, GFTD can adapt to data imperfections without additional training requirements, leveraging posterior sampling for reliable prediction and controllable generation. Our approach not only simplifies the prediction process but also enhances generalizability in scenarios with noise and incomplete inputs. Through rigorous experimental evaluation, GFTD exhibits superior performance in both trajectory prediction and controllable generation. ",
    "url": "https://arxiv.org/abs/2404.00237",
    "authors": [
      "Haotian Lin",
      "Yixiao Wang",
      "Mingxiao Huo",
      "Chensheng Peng",
      "Zhiyuan Liu",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.00254",
    "title": "Clustering for Protein Representation Learning",
    "abstract": "Protein representation learning is a challenging task that aims to capture the structure and function of proteins from their amino acid sequences. Previous methods largely ignored the fact that not all amino acids are equally important for protein folding and activity. In this article, we propose a neural clustering framework that can automatically discover the critical components of a protein by considering both its primary and tertiary structure information. Our framework treats a protein as a graph, where each node represents an amino acid and each edge represents a spatial or sequential connection between amino acids. We then apply an iterative clustering strategy to group the nodes into clusters based on their 1D and 3D positions and assign scores to each cluster. We select the highest-scoring clusters and use their medoid nodes for the next iteration of clustering, until we obtain a hierarchical and informative representation of the protein. We evaluate on four protein-related tasks: protein fold classification, enzyme reaction classification, gene ontology term prediction, and enzyme commission number prediction. Experimental results demonstrate that our method achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2404.00254",
    "authors": [
      "Ruijie Quan",
      "Wenguan Wang",
      "Fan Ma",
      "Hehe Fan",
      "Yi Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2404.00257",
    "title": "YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel  Class Discovery",
    "abstract": "Because of its use in practice, open-world object detection (OWOD) has gotten a lot of attention recently. The challenge is how can a model detect novel classes and then incrementally learn them without forgetting previously known classes. Previous approaches hinge on strongly-supervised or weakly-supervised novel-class data for novel-class detection, which may not apply to real applications. We construct a new benchmark that novel classes are only encountered at the inference stage. And we propose a new OWOD detector YOLOOC, based on the YOLO architecture yet for the Open-Class setup. We introduce label smoothing to prevent the detector from over-confidently mapping novel classes to known classes and to discover novel classes. Extensive experiments conducted on our more realistic setup demonstrate the effectiveness of our method for discovering novel classes in our new benchmark. ",
    "url": "https://arxiv.org/abs/2404.00257",
    "authors": [
      "Qian Wan",
      "Xiang Xiang",
      "Qinhao Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2404.00260",
    "title": "Exploiting Self-Supervised Constraints in Image Super-Resolution",
    "abstract": "Recent advances in self-supervised learning, predominantly studied in high-level visual tasks, have been explored in low-level image processing. This paper introduces a novel self-supervised constraint for single image super-resolution, termed SSC-SR. SSC-SR uniquely addresses the divergence in image complexity by employing a dual asymmetric paradigm and a target model updated via exponential moving average to enhance stability. The proposed SSC-SR framework works as a plug-and-play paradigm and can be easily applied to existing SR models. Empirical evaluations reveal that our SSC-SR framework delivers substantial enhancements on a variety of benchmark datasets, achieving an average increase of 0.1 dB over EDSR and 0.06 dB over SwinIR. In addition, extensive ablation studies corroborate the effectiveness of each constituent in our SSC-SR framework. Codes are available at https://github.com/Aitical/SSCSR. ",
    "url": "https://arxiv.org/abs/2404.00260",
    "authors": [
      "Gang Wu",
      "Junjun Jiang",
      "Kui Jiang",
      "Xianming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2404.00268",
    "title": "A Unified Framework for Adaptive Representation Enhancement and Inversed  Learning in Cross-Domain Recommendation",
    "abstract": "Cross-domain recommendation (CDR), aiming to extract and transfer knowledge across domains, has attracted wide attention for its efficacy in addressing data sparsity and cold-start problems. Despite significant advances in representation disentanglement to capture diverse user preferences, existing methods usually neglect representation enhancement and lack rigorous decoupling constraints, thereby limiting the transfer of relevant information. To this end, we propose a Unified Framework for Adaptive Representation Enhancement and Inversed Learning in Cross-Domain Recommendation (AREIL). Specifically, we first divide user embeddings into domain-shared and domain-specific components to disentangle mixed user preferences. Then, we incorporate intra-domain and inter-domain information to adaptively enhance the ability of user representations. In particular, we propose a graph convolution module to capture high-order information, and a self-attention module to reveal inter-domain correlations and accomplish adaptive fusion. Next, we adopt domain classifiers and gradient reversal layers to achieve inversed representation learning in a unified framework. Finally, we employ a cross-entropy loss for measuring recommendation performance and jointly optimize the entire framework via multi-task learning. Extensive experiments on multiple datasets validate the substantial improvement in the recommendation performance of AREIL. Moreover, ablation studies and representation visualizations further illustrate the effectiveness of adaptive enhancement and inversed learning in CDR. ",
    "url": "https://arxiv.org/abs/2404.00268",
    "authors": [
      "Luankang Zhang",
      "Hao Wang",
      "Suojuan Zhang",
      "Mingjia Yin",
      "Yongqiang Han",
      "Jiaqing Zhang",
      "Defu Lian",
      "Enhong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2404.00270",
    "title": "Engineering A Workload-balanced Push-Relabel Algorithm for Massive  Graphs on GPUs",
    "abstract": "The push-relabel algorithm is an efficient algorithm that solves the maximum flow/ minimum cut problems of its affinity to parallelization. As the size of graphs grows exponentially, researchers have used Graphics Processing Units (GPUs) to accelerate the computation of the push-relabel algorithm further. However, prior works need to handle the significant memory consumption to represent a massive residual graph. In addition, the nature of their algorithms has inherently imbalanced workload distribution on GPUs. This paper first identifies the two challenges with the memory and computational models. Based on the analysis of these models, we propose a workload-balanced push-relabel algorithm (WBPR) with two enhanced compressed sparse representations (CSR) and a vertex-centric approach. The enhanced CSR significantly reduces memory consumption, while the vertex-centric approach alleviates the workload imbalance and improves the utilization of the GPU. In the experiment, our approach reduces the memory consumption from O(V^2) to O(V + E). Moreover, we can achieve up to 7.31x and 2.29x runtime speedup compared to the state-of-the-art on real-world graphs in maximum flow and bipartite matching tasks, respectively. Our code will be open-sourced for further research on accelerating the push-relabel algorithm. ",
    "url": "https://arxiv.org/abs/2404.00270",
    "authors": [
      "Chou-Ying Hsieh",
      "Po-Chieh Lin",
      "Sy-Yen Kuo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2404.00271",
    "title": "TG-NAS: Leveraging Zero-Cost Proxies with Transformer and Graph  Convolution Networks for Efficient Neural Architecture Search",
    "abstract": "Neural architecture search (NAS) is an effective method for discovering new convolutional neural network (CNN) architectures. However, existing approaches often require time-consuming training or intensive sampling and evaluations. Zero-shot NAS aims to create training-free proxies for architecture performance prediction. However, existing proxies have suboptimal performance, and are often outperformed by simple metrics such as model parameter counts or the number of floating-point operations. Besides, existing model-based proxies cannot be generalized to new search spaces with unseen new types of operators without golden accuracy truth. A universally optimal proxy remains elusive. We introduce TG-NAS, a novel model-based universal proxy that leverages a transformer-based operator embedding generator and a graph convolution network (GCN) to predict architecture performance. This approach guides neural architecture search across any given search space without the need of retraining. Distinct from other model-based predictor subroutines, TG-NAS itself acts as a zero-cost (ZC) proxy, guiding architecture search with advantages in terms of data independence, cost-effectiveness, and consistency across diverse search spaces. Our experiments showcase its advantages over existing proxies across various NAS benchmarks, suggesting its potential as a foundational element for efficient architecture search. TG-NAS achieves up to 300X improvements in search efficiency compared to previous SOTA ZC proxy methods. Notably, it discovers competitive models with 93.75% CIFAR-10 accuracy on the NAS-Bench-201 space and 74.5% ImageNet top-1 accuracy on the DARTS space. ",
    "url": "https://arxiv.org/abs/2404.00271",
    "authors": [
      "Ye Qiao",
      "Haocheng Xu",
      "Sitao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00285",
    "title": "Long-Tailed Recognition on Binary Networks by Calibrating A Pre-trained  Model",
    "abstract": "Deploying deep models in real-world scenarios entails a number of challenges, including computational efficiency and real-world (e.g., long-tailed) data distributions. We address the combined challenge of learning long-tailed distributions using highly resource-efficient binary neural networks as backbones. Specifically, we propose a calibrate-and-distill framework that uses off-the-shelf pretrained full-precision models trained on balanced datasets to use as teachers for distillation when learning binary networks on long-tailed datasets. To better generalize to various datasets, we further propose a novel adversarial balancing among the terms in the objective function and an efficient multiresolution learning scheme. We conducted the largest empirical study in the literature using 15 datasets, including newly derived long-tailed datasets from existing balanced datasets, and show that our proposed method outperforms prior art by large margins (>14.33% on average). ",
    "url": "https://arxiv.org/abs/2404.00285",
    "authors": [
      "Jihun Kim",
      "Dahyun Kim",
      "Hyungrok Jung",
      "Taeil Oh",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00287",
    "title": "An Empirical Study of Automated Vulnerability Localization with Large  Language Models",
    "abstract": "Recently, Automated Vulnerability Localization (AVL) has attracted much attention, aiming to facilitate diagnosis by pinpointing the lines of code responsible for discovered vulnerabilities. Large Language Models (LLMs) have shown potential in various domains, yet their effectiveness in vulnerability localization remains underexplored. In this work, we perform the first comprehensive study of LLMs for AVL. Our investigation encompasses 10+ leading LLMs suitable for code analysis, including ChatGPT and various open-source models, across three architectural types: encoder-only, encoder-decoder, and decoder-only, with model sizes ranging from 60M to 16B parameters. We explore the efficacy of these LLMs using 4 distinct paradigms: zero-shot learning, one-shot learning, discriminative fine-tuning, and generative fine-tuning. Our evaluation framework is applied to the BigVul-based dataset for C/C++, and an additional dataset comprising smart contract vulnerabilities. The results demonstrate that discriminative fine-tuning of LLMs can significantly outperform existing learning-based methods for AVL, while other paradigms prove less effective or unexpectedly ineffective for the task. We also identify challenges related to input length and unidirectional context in fine-tuning processes for encoders and decoders. We then introduce two remedial strategies: the sliding window and the right-forward embedding, both of which substantially enhance performance. Furthermore, our findings highlight certain generalization capabilities of LLMs across Common Weakness Enumerations (CWEs) and different projects, indicating a promising pathway toward their practical application in vulnerability localization. ",
    "url": "https://arxiv.org/abs/2404.00287",
    "authors": [
      "Jian Zhang",
      "Chong Wang",
      "Anran Li",
      "Weisong Sun",
      "Cen Zhang",
      "Wei Ma",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.00303",
    "title": "A Comprehensive Study on NLP Data Augmentation for Hate Speech  Detection: Legacy Methods, BERT, and LLMs",
    "abstract": "The surge of interest in data augmentation within the realm of NLP has been driven by the need to address challenges posed by hate speech domains, the dynamic nature of social media vocabulary, and the demands for large-scale neural networks requiring extensive training data. However, the prevalent use of lexical substitution in data augmentation has raised concerns, as it may inadvertently alter the intended meaning, thereby impacting the efficacy of supervised machine learning models. In pursuit of suitable data augmentation methods, this study explores both established legacy approaches and contemporary practices such as Large Language Models (LLM), including GPT in Hate Speech detection. Additionally, we propose an optimized utilization of BERT-based encoder models with contextual cosine similarity filtration, exposing significant limitations in prior synonym substitution methods. Our comparative analysis encompasses five popular augmentation techniques: WordNet and Fast-Text synonym replacement, Back-translation, BERT-mask contextual augmentation, and LLM. Our analysis across five benchmarked datasets revealed that while traditional methods like back-translation show low label alteration rates (0.3-1.5%), and BERT-based contextual synonym replacement offers sentence diversity but at the cost of higher label alteration rates (over 6%). Our proposed BERT-based contextual cosine similarity filtration markedly reduced label alteration to just 0.05%, demonstrating its efficacy in 0.7% higher F1 performance. However, augmenting data with GPT-3 not only avoided overfitting with up to sevenfold data increase but also improved embedding space coverage by 15% and classification F1 score by 1.4% over traditional methods, and by 0.8% over our method. ",
    "url": "https://arxiv.org/abs/2404.00303",
    "authors": [
      "Md Saroar Jahan",
      "Mourad Oussalah",
      "Djamila Romaissa Beddia",
      "Jhuma kabir Mim",
      "Nabil Arhab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00309",
    "title": "Model-Driven Deep Learning for Distributed Detection with Binary  Quantization",
    "abstract": "Within the realm of rapidly advancing wireless sensor networks (WSNs), distributed detection assumes a significant role in various practical applications. However, critical challenge lies in maintaining robust detection performance while operating within the constraints of limited bandwidth and energy resources. This paper introduces a novel approach that combines model-driven deep learning (DL) with binary quantization to strike a balance between communication overhead and detection performance in WSNs. We begin by establishing the lower bound of detection error probability for distributed detection using the maximum a posteriori (MAP) criterion. Furthermore, we prove the global optimality of employing identical local quantizers across sensors, thereby maximizing the corresponding Chernoff information. Subsequently, the paper derives the minimum MAP detection error probability (MAPDEP) by inplementing identical binary probabilistic quantizers across the sensors. Moreover, the paper establishes the equivalence between utilizing all quantized data and their average as input to the detector at the fusion center (FC). In particular, we derive the Kullback-Leibler (KL) divergence, which measures the difference between the true posterior probability and output of the proposed detector. Leveraging the MAPDEP and KL divergence as loss functions, the paper proposes model-driven DL method to separately train the probability controller module in the quantizer and the detector module at the FC. Numerical results validate the convergence and effectiveness of the proposed method, which achieves near-optimal performance with reduced complexity for Gaussian hypothesis testing. ",
    "url": "https://arxiv.org/abs/2404.00309",
    "authors": [
      "Wei Guo",
      "Meng He",
      "Chuan Huang",
      "Hengtao He",
      "Shenghui Song",
      "Jun Zhang",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.00318",
    "title": "Exploring Unseen Environments with Robots using Large Language and  Vision Models through a Procedurally Generated 3D Scene Representation",
    "abstract": "Recent advancements in Generative Artificial Intelligence, particularly in the realm of Large Language Models (LLMs) and Large Vision Language Models (LVLMs), have enabled the prospect of leveraging cognitive planners within robotic systems. This work focuses on solving the object goal navigation problem by mimicking human cognition to attend, perceive and store task specific information and generate plans with the same. We introduce a comprehensive framework capable of exploring an unfamiliar environment in search of an object by leveraging the capabilities of Large Language Models(LLMs) and Large Vision Language Models (LVLMs) in understanding the underlying semantics of our world. A challenging task in using LLMs to generate high level sub-goals is to efficiently represent the environment around the robot. We propose to use a 3D scene modular representation, with semantically rich descriptions of the object, to provide the LLM with task relevant information. But providing the LLM with a mass of contextual information (rich 3D scene semantic representation), can lead to redundant and inefficient plans. We propose to use an LLM based pruner that leverages the capabilities of in-context learning to prune out irrelevant goal specific information. ",
    "url": "https://arxiv.org/abs/2404.00318",
    "authors": [
      "Arjun P S",
      "Andrew Melnik",
      "Gora Chand Nandi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00322",
    "title": "Instrument-tissue Interaction Detection Framework for Surgical Video  Understanding",
    "abstract": "Instrument-tissue interaction detection task, which helps understand surgical activities, is vital for constructing computer-assisted surgery systems but with many challenges. Firstly, most models represent instrument-tissue interaction in a coarse-grained way which only focuses on classification and lacks the ability to automatically detect instruments and tissues. Secondly, existing works do not fully consider relations between intra- and inter-frame of instruments and tissues. In the paper, we propose to represent instrument-tissue interaction as <instrument class, instrument bounding box, tissue class, tissue bounding box, action class> quintuple and present an Instrument-Tissue Interaction Detection Network (ITIDNet) to detect the quintuple for surgery videos understanding. Specifically, we propose a Snippet Consecutive Feature (SCF) Layer to enhance features by modeling relationships of proposals in the current frame using global context information in the video snippet. We also propose a Spatial Corresponding Attention (SCA) Layer to incorporate features of proposals between adjacent frames through spatial encoding. To reason relationships between instruments and tissues, a Temporal Graph (TG) Layer is proposed with intra-frame connections to exploit relationships between instruments and tissues in the same frame and inter-frame connections to model the temporal information for the same instance. For evaluation, we build a cataract surgery video (PhacoQ) dataset and a cholecystectomy surgery video (CholecQ) dataset. Experimental results demonstrate the promising performance of our model, which outperforms other state-of-the-art models on both datasets. ",
    "url": "https://arxiv.org/abs/2404.00322",
    "authors": [
      "Wenjun Lin",
      "Yan Hu",
      "Huazhu Fu",
      "Mingming Yang",
      "Chin-Boon Chng",
      "Ryo Kawasaki",
      "Cheekong Chui",
      "Jiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00323",
    "title": "CLIP-driven Outliers Synthesis for few-shot OOD detection",
    "abstract": "Few-shot OOD detection focuses on recognizing out-of-distribution (OOD) images that belong to classes unseen during training, with the use of only a small number of labeled in-distribution (ID) images. Up to now, a mainstream strategy is based on large-scale vision-language models, such as CLIP. However, these methods overlook a crucial issue: the lack of reliable OOD supervision information, which can lead to biased boundaries between in-distribution (ID) and OOD. To tackle this problem, we propose CLIP-driven Outliers Synthesis~(CLIP-OS). Firstly, CLIP-OS enhances patch-level features' perception by newly proposed patch uniform convolution, and adaptively obtains the proportion of ID-relevant information by employing CLIP-surgery-discrepancy, thus achieving separation between ID-relevant and ID-irrelevant. Next, CLIP-OS synthesizes reliable OOD data by mixing up ID-relevant features from different classes to provide OOD supervision information. Afterward, CLIP-OS leverages synthetic OOD samples by unknown-aware prompt learning to enhance the separability of ID and OOD. Extensive experiments across multiple benchmarks demonstrate that CLIP-OS achieves superior few-shot OOD detection capability. ",
    "url": "https://arxiv.org/abs/2404.00323",
    "authors": [
      "Hao Sun",
      "Rundong He",
      "Zhongyi Han",
      "Zhicong Lin",
      "Yongshun Gong",
      "Yilong Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00353",
    "title": "CBF-Based STL Motion Planning for Social Navigation in Crowded  Environment",
    "abstract": "A motion planning methodology based on the combination of Control Barrier Functions (CBF) and Signal Temporal Logic (STL) is employed in this paper. This methodology allows task completion at any point within a specified time interval, considering a dynamic system subject to velocity constraints. In this work, we apply this approach into the context of Socially Responsible Navigation (SRN), introducing a rotation constraint. This constraint is designed to maintain the user within the robot's field of view (FOV), enhancing human-robot interaction with the concept of side-by-side human-robot companion. This angular constraint offers the possibility to customize social navigation to specific needs, thereby enabling safe SRN. Its validation is carried out through simulations demonstrating the system's effectiveness in adhering to spatio-temporal constraints, including those related to robot velocity, rotation, and the presence of static and dynamic obstacles. ",
    "url": "https://arxiv.org/abs/2404.00353",
    "authors": [
      "Andrea Ruo",
      "Lorenzo Sabattini",
      "Valeria Villani"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.00354",
    "title": "Follow me: an architecture for user identification and social navigation  with a mobile robot",
    "abstract": "Over the past decade, a multitude of service robots have been developed to fulfill a wide range of practical purposes. Notably, roles such as reception and robotic guidance have garnered extensive popularity. In these positions, robots are progressively assuming the responsibilities traditionally held by human staff in assisting customers. Ensuring the safe and socially acceptable operation of robots in such environments poses a fundamental challenge within the context of Socially Responsible Navigation (SRN). This article presents an architecture for user identification and social navigation with a mobile robot that employs computer vision, machine learning, and artificial intelligence algorithms to identify and guide users in a social navigation context, thereby providing an intuitive and user-friendly experience with the robot. ",
    "url": "https://arxiv.org/abs/2404.00354",
    "authors": [
      "Andrea Ruo",
      "Lorenzo Sabattini",
      "Valeria Villani"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.00361",
    "title": "Controllable and Diverse Data Augmentation with Large Language Model for  Low-Resource Open-Domain Dialogue Generation",
    "abstract": "Data augmentation (DA) is crucial to mitigate model training instability and over-fitting problems in low-resource open-domain dialogue generation. However, traditional DA methods often neglect semantic data diversity, restricting the overall quality. Recently, large language models (LLM) have been used for DA to generate diversified dialogues. However, they have limited controllability and tend to generate dialogues with a distribution shift compared to the seed dialogues. To maximize the augmentation diversity and address the controllability problem, we propose \\textbf{S}ummary-based \\textbf{D}ialogue \\textbf{A}ugmentation with LLM (SDA). Our approach enhances the controllability of LLM by using dialogue summaries as a planning tool. Based on summaries, SDA can generate high-quality and diverse dialogue data even with a small seed dataset. To evaluate the efficacy of data augmentation methods for open-domain dialogue, we designed a clustering-based metric to characterize the semantic diversity of the augmented dialogue data. The experimental results show that SDA can augment high-quality and semantically diverse dialogues given a small seed dataset and an LLM, and the augmented data can boost the performance of open-domain dialogue models. ",
    "url": "https://arxiv.org/abs/2404.00361",
    "authors": [
      "Zhenhua Liu",
      "Tong Zhu",
      "Jianxiang Xiang",
      "Wenliang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00362",
    "title": "STBA: Towards Evaluating the Robustness of DNNs for Query-Limited  Black-box Scenario",
    "abstract": "Many attack techniques have been proposed to explore the vulnerability of DNNs and further help to improve their robustness. Despite the significant progress made recently, existing black-box attack methods still suffer from unsatisfactory performance due to the vast number of queries needed to optimize desired perturbations. Besides, the other critical challenge is that adversarial examples built in a noise-adding manner are abnormal and struggle to successfully attack robust models, whose robustness is enhanced by adversarial training against small perturbations. There is no doubt that these two issues mentioned above will significantly increase the risk of exposure and result in a failure to dig deeply into the vulnerability of DNNs. Hence, it is necessary to evaluate DNNs' fragility sufficiently under query-limited settings in a non-additional way. In this paper, we propose the Spatial Transform Black-box Attack (STBA), a novel framework to craft formidable adversarial examples in the query-limited scenario. Specifically, STBA introduces a flow field to the high-frequency part of clean images to generate adversarial examples and adopts the following two processes to enhance their naturalness and significantly improve the query efficiency: a) we apply an estimated flow field to the high-frequency part of clean images to generate adversarial examples instead of introducing external noise to the benign image, and b) we leverage an efficient gradient estimation method based on a batch of samples to optimize such an ideal flow field under query-limited settings. Compared to existing score-based black-box baselines, extensive experiments indicated that STBA could effectively improve the imperceptibility of the adversarial examples and remarkably boost the attack success rate under query-limited settings. ",
    "url": "https://arxiv.org/abs/2404.00362",
    "authors": [
      "Renyang Liu",
      "Kwok-Yan Lam",
      "Wei Zhou",
      "Sixing Wu",
      "Jun Zhao",
      "Dongting Hu",
      "Mingming Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2404.00366",
    "title": "Efficient Multi-branch Segmentation Network for Situation Awareness in  Autonomous Navigation",
    "abstract": "Real-time and high-precision situational awareness technology is critical for autonomous navigation of unmanned surface vehicles (USVs). In particular, robust and fast obstacle semantic segmentation methods are essential. However, distinguishing between the sea and the sky is challenging due to the differences between port and maritime environments. In this study, we built a dataset that captured perspectives from USVs and unmanned aerial vehicles in a maritime port environment and analysed the data features. Statistical analysis revealed a high correlation between the distribution of the sea and sky and row positional information. Based on this finding, a three-branch semantic segmentation network with a row position encoding module (RPEM) was proposed to improve the prediction accuracy between the sea and the sky. The proposed RPEM highlights the effect of row coordinates on feature extraction. Compared to the baseline, the three-branch network with RPEM significantly improved the ability to distinguish between the sea and the sky without significantly reducing the computational speed. ",
    "url": "https://arxiv.org/abs/2404.00366",
    "authors": [
      "Guan-Cheng Zhou",
      "Chen Chengb",
      "Yan-zhou Chena"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00383",
    "title": "SpikingJET: Enhancing Fault Injection for Fully and Convolutional  Spiking Neural Networks",
    "abstract": "As artificial neural networks become increasingly integrated into safety-critical systems such as autonomous vehicles, devices for medical diagnosis, and industrial automation, ensuring their reliability in the face of random hardware faults becomes paramount. This paper introduces SpikingJET, a novel fault injector designed specifically for fully connected and convolutional Spiking Neural Networks (SNNs). Our work underscores the critical need to evaluate the resilience of SNNs to hardware faults, considering their growing prominence in real-world applications. SpikingJET provides a comprehensive platform for assessing the resilience of SNNs by inducing errors and injecting faults into critical components such as synaptic weights, neuron model parameters, internal states, and activation functions. This paper demonstrates the effectiveness of Spiking-JET through extensive software-level experiments on various SNN architectures, revealing insights into their vulnerability and resilience to hardware faults. Moreover, highlighting the importance of fault resilience in SNNs contributes to the ongoing effort to enhance the reliability and safety of Neural Network (NN)-powered systems in diverse domains. ",
    "url": "https://arxiv.org/abs/2404.00383",
    "authors": [
      "Anil Bayram Gogebakan",
      "Enrico Magliano",
      "Alessio Carpegna",
      "Annachiara Ruospo",
      "Alessandro Savino",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00385",
    "title": "Constrained Layout Generation with Factor Graphs",
    "abstract": "This paper addresses the challenge of object-centric layout generation under spatial constraints, seen in multiple domains including floorplan design process. The design process typically involves specifying a set of spatial constraints that include object attributes like size and inter-object relations such as relative positioning. Existing works, which typically represent objects as single nodes, lack the granularity to accurately model complex interactions between objects. For instance, often only certain parts of an object, like a room's right wall, interact with adjacent objects. To address this gap, we introduce a factor graph based approach with four latent variable nodes for each room, and a factor node for each constraint. The factor nodes represent dependencies among the variables to which they are connected, effectively capturing constraints that are potentially of a higher order. We then develop message-passing on the bipartite graph, forming a factor graph neural network that is trained to produce a floorplan that aligns with the desired requirements. Our approach is simple and generates layouts faithful to the user requirements, demonstrated by a large improvement in IOU scores over existing methods. Additionally, our approach, being inferential and accurate, is well-suited to the practical human-in-the-loop design process where specifications evolve iteratively, offering a practical and powerful tool for AI-guided design. ",
    "url": "https://arxiv.org/abs/2404.00385",
    "authors": [
      "Mohammed Haroon Dupty",
      "Yanfei Dong",
      "Sicong Leng",
      "Guoji Fu",
      "Yong Liang Goh",
      "Wei Lu",
      "Wee Sun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00391",
    "title": "Robust and structure-preserving time-discretisation and linearisation  schemes for singular and degenerate evolution systems arising in models for  biofilm growth",
    "abstract": "We propose and analyse numerical schemes for a system of quasilinear, degenerate evolution equations modelling biofilm growth as well as other processes such as flow through porous media and the spreading of wildfires. The first equation in the system is parabolic and exhibits degenerate and singular diffusion, while the second is either uniformly parabolic or an ordinary differential equation. First, we introduce a semi-implicit time discretisation that has the benefit of decoupling the equations. We prove the positivity, boundedness, and convergence of the time-discrete solutions to the time-continuous solution. Then, we introduce an iterative linearisation scheme to solve the resulting nonlinear time-discrete problems. Under weak assumptions on the time-step size, we prove that the scheme converges irrespective of the space discretisation and mesh. Moreover, if the problem is non-degenerate, the convergence becomes faster as the time-step size decreases. Finally, employing the finite element method for the spatial discretisation, we study the behaviour of the scheme, and compare its performance to other commonly used schemes. These tests confirm that the proposed scheme is robust and fast. ",
    "url": "https://arxiv.org/abs/2404.00391",
    "authors": [
      "R.K.H. Smeets",
      "K. Mitra",
      "I.S. Pop",
      "S. Sonner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2404.00394",
    "title": "Analysis of Fairness-promoting Optimization Schemes of Photovoltaic  Curtailments for Voltage Regulation in Power Distribution Networks",
    "abstract": "Active power curtailment of photovoltaic (PV) generation is commonly exercised to mitigate over-voltage issues in power distribution networks. However, fairness concerns arise as certain PV plants may experience more significant curtailments than others depending on their locations within the network. Existing literature tackles this issue through fairness-promoting/aware optimization schemes. These schemes can be broadly categorized into two types. The first type maximizes an additional fairness objective along with the main objective of curtailment minimization. The second type is formulated as a feedback controller, where fairness is accounted for by assigning different weights (as feedback) in the curtailment minimization objective for each PV plant based on previous curtailment actions. In this work, we combine these two schemes and provide extensive analyses and comparisons of these two fairness schemes. We compare the performance in terms of fairness and net curtailments for several benchmark test networks. ",
    "url": "https://arxiv.org/abs/2404.00394",
    "authors": [
      "Rahul K. Gupta",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.00397",
    "title": "An Analysis of BPE Vocabulary Trimming in Neural Machine Translation",
    "abstract": "We explore threshold vocabulary trimming in Byte-Pair Encoding subword tokenization, a postprocessing step that replaces rare subwords with their component subwords. The technique is available in popular tokenization libraries but has not been subjected to rigorous scientific scrutiny. While the removal of rare subwords is suggested as best practice in machine translation implementations, both as a means to reduce model size and for improving model performance through robustness, our experiments indicate that, across a large space of hyperparameter settings, vocabulary trimming fails to improve performance, and is even prone to incurring heavy degradation. ",
    "url": "https://arxiv.org/abs/2404.00397",
    "authors": [
      "Marco Cognetta",
      "Tatsuya Hiraoka",
      "Naoaki Okazaki",
      "Rico Sennrich",
      "Yuval Pinter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00401",
    "title": "How Robust are the Tabular QA Models for Scientific Tables? A Study  using Customized Dataset",
    "abstract": "Question-answering (QA) on hybrid scientific tabular and textual data deals with scientific information, and relies on complex numerical reasoning. In recent years, while tabular QA has seen rapid progress, understanding their robustness on scientific information is lacking due to absence of any benchmark dataset. To investigate the robustness of the existing state-of-the-art QA models on scientific hybrid tabular data, we propose a new dataset, \"SciTabQA\", consisting of 822 question-answer pairs from scientific tables and their descriptions. With the help of this dataset, we assess the state-of-the-art Tabular QA models based on their ability (i) to use heterogeneous information requiring both structured data (table) and unstructured data (text) and (ii) to perform complex scientific reasoning tasks. In essence, we check the capability of the models to interpret scientific tables and text. Our experiments show that \"SciTabQA\" is an innovative dataset to study question-answering over scientific heterogeneous data. We benchmark three state-of-the-art Tabular QA models, and find that the best F1 score is only 0.462. ",
    "url": "https://arxiv.org/abs/2404.00401",
    "authors": [
      "Akash Ghosh",
      "B Venkata Sahith",
      "Niloy Ganguly",
      "Pawan Goyal",
      "Mayank Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00415",
    "title": "CoDa: Constrained Generation based Data Augmentation for Low-Resource  NLP",
    "abstract": "We present CoDa (Constrained Generation based Data Augmentation), a controllable, effective, and training-free data augmentation technique for low-resource (data-scarce) NLP. Our approach is based on prompting off-the-shelf instruction-following Large Language Models (LLMs) for generating text that satisfies a set of constraints. Precisely, we extract a set of simple constraints from every instance in the low-resource dataset and verbalize them to prompt an LLM to generate novel and diverse training instances. Our findings reveal that synthetic data that follows simple constraints in the downstream dataset act as highly effective augmentations, and CoDa can achieve this without intricate decoding-time constrained generation techniques or fine-tuning with complex algorithms that eventually make the model biased toward the small number of training instances. Additionally, CoDa is the first framework that provides users explicit control over the augmentation generation process, thereby also allowing easy adaptation to several domains. We demonstrate the effectiveness of CoDa across 11 datasets spanning 3 tasks and 3 low-resource settings. CoDa outperforms all our baselines, qualitatively and quantitatively, with improvements of 0.12%-7.19%. Code is available here: https://github.com/Sreyan88/CoDa ",
    "url": "https://arxiv.org/abs/2404.00415",
    "authors": [
      "Chandra Kiran Reddy Evuru",
      "Sreyan Ghosh",
      "Sonal Kumar",
      "Ramaneswaran S",
      "Utkarsh Tyagi",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00416",
    "title": "Circular-arc graphs and the Helly property",
    "abstract": "In this paper we investigate some problems related to the Helly properties of circular-arc graphs, which are defined as intersection graphs of arcs of a fixed circle. As such, circular-arc graphs are among the simplest classes of intersection graphs whose models might not satisfy the Helly property. In particular, some cliques of a circular-arc graph might be Helly in some but not all arc intersection models of the graph. Our first result is an alternative proof of a theorem by Lin and Szwarcfiter which asserts that for every circular-arc graph $G$ either every normalized model of $G$ satisfies the Helly property or no normalized model of $G$ satisfies this property. Further, we study the Helly properties of a single clique of a circular-arc graph $G$. We divide the cliques of $G$ into three types: a clique $C$ of $G$ is always-Helly/always-non-Helly/ambiguous if $C$ is Helly in every/no/(some but not all) normalized model of $G$. We provide a combinatorial description for the cliques of each type, and based on it, we devise a polynomial time algorithm which determines the type of a given clique. Finally, we study the Helly Cliques problem, in which we are given an $n$-vertex circular-arc graph $G$ and some of its cliques $C_1, \\ldots, C_k$ and we ask if there is an arc intersection model of $G$ in which all the cliques $C_1, \\ldots, C_k$ satisfy the Helly property. We show that: (1) the Helly Cliques problem admits a $2^{O(k\\log{k})}n^{O(1)}$-time algorithm (that is, it is FPT when parametrized by the number of cliques given in the input), (2) assuming Exponential Time Hypothesis (ETH), the Helly Cliques problem cannot be solved in time $2^{o(k)}n^{O(1)}$, (3) the Helly Cliques problem admits a polynomial kernel of size $O(k^6)$. All our results use a data structure, called a PQM-tree, which maintains all normalized models of a circular-arc graph $G$. ",
    "url": "https://arxiv.org/abs/2404.00416",
    "authors": [
      "Jan Derbisz",
      "Tomasz Krawczyk"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2404.00458",
    "title": "Beyond One-Size-Fits-All: Multi-Domain, Multi-Task Framework for  Embedding Model Selection",
    "abstract": "This position paper proposes a systematic approach towards developing a framework to help select the most effective embedding models for natural language processing (NLP) tasks, addressing the challenge posed by the proliferation of both proprietary and open-source encoder models. ",
    "url": "https://arxiv.org/abs/2404.00458",
    "authors": [
      "Vivek Khetan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2404.00461",
    "title": "Shortcuts Arising from Contrast: Effective and Covert Clean-Label  Attacks in Prompt-Based Learning",
    "abstract": "Prompt-based learning paradigm has demonstrated remarkable efficacy in enhancing the adaptability of pretrained language models (PLMs), particularly in few-shot scenarios. However, this learning paradigm has been shown to be vulnerable to backdoor attacks. The current clean-label attack, employing a specific prompt as a trigger, can achieve success without the need for external triggers and ensure correct labeling of poisoned samples, which is more stealthy compared to the poisoned-label attack, but on the other hand, it faces significant issues with false activations and poses greater challenges, necessitating a higher rate of poisoning. Using conventional negative data augmentation methods, we discovered that it is challenging to trade off between effectiveness and stealthiness in a clean-label setting. In addressing this issue, we are inspired by the notion that a backdoor acts as a shortcut and posit that this shortcut stems from the contrast between the trigger and the data utilized for poisoning. In this study, we propose a method named Contrastive Shortcut Injection (CSI), by leveraging activation values, integrates trigger design and data selection strategies to craft stronger shortcut features. With extensive experiments on full-shot and few-shot text classification tasks, we empirically validate CSI's high effectiveness and high stealthiness at low poisoning rates. Notably, we found that the two approaches play leading roles in full-shot and few-shot settings, respectively. ",
    "url": "https://arxiv.org/abs/2404.00461",
    "authors": [
      "Xiaopeng Xie",
      "Ming Yan",
      "Xiwen Zhou",
      "Chenlong Zhao",
      "Suli Wang",
      "Yong Zhang",
      "Joey Tianyi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.00462",
    "title": "Zero-shot Safety Prediction for Autonomous Robots with Foundation World  Models",
    "abstract": "A world model creates a surrogate world to train a controller and predict safety violations by learning the internal dynamic model of systems. However, the existing world models rely solely on statistical learning of how observations change in response to actions, lacking precise quantification of how accurate the surrogate dynamics are, which poses a significant challenge in safety-critical systems. To address this challenge, we propose foundation world models that embed observations into meaningful and causally latent representations. This enables the surrogate dynamics to directly predict causal future states by leveraging a training-free large language model. In two common benchmarks, this novel model outperforms standard world models in the safety prediction task and has a performance comparable to supervised learning despite not using any data. We evaluate its performance with a more specialized and system-relevant metric by comparing estimated states instead of aggregating observation-wide error. ",
    "url": "https://arxiv.org/abs/2404.00462",
    "authors": [
      "Zhenjiang Mao",
      "Siqi Dai",
      "Yuang Geng",
      "Ivan Ruchkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.00463",
    "title": "Addressing Both Statistical and Causal Gender Fairness in NLP Models",
    "abstract": "Statistical fairness stipulates equivalent outcomes for every protected group, whereas causal fairness prescribes that a model makes the same prediction for an individual regardless of their protected characteristics. Counterfactual data augmentation (CDA) is effective for reducing bias in NLP models, yet models trained with CDA are often evaluated only on metrics that are closely tied to the causal fairness notion; similarly, sampling-based methods designed to promote statistical fairness are rarely evaluated for causal fairness. In this work, we evaluate both statistical and causal debiasing methods for gender bias in NLP models, and find that while such methods are effective at reducing bias as measured by the targeted metric, they do not necessarily improve results on other bias metrics. We demonstrate that combinations of statistical and causal debiasing techniques are able to reduce bias measured through both types of metrics. ",
    "url": "https://arxiv.org/abs/2404.00463",
    "authors": [
      "Hannah Chen",
      "Yangfeng Ji",
      "David Evans"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00469",
    "title": "SceneGraphLoc: Cross-Modal Coarse Visual Localization on 3D Scene Graphs",
    "abstract": "We introduce a novel problem, i.e., the localization of an input image within a multi-modal reference map represented by a database of 3D scene graphs. These graphs comprise multiple modalities, including object-level point clouds, images, attributes, and relationships between objects, offering a lightweight and efficient alternative to conventional methods that rely on extensive image databases. Given the available modalities, the proposed method SceneGraphLoc learns a fixed-sized embedding for each node (i.e., representing an object instance) in the scene graph, enabling effective matching with the objects visible in the input query image. This strategy significantly outperforms other cross-modal methods, even without incorporating images into the map embeddings. When images are leveraged, SceneGraphLoc achieves performance close to that of state-of-the-art techniques depending on large image databases, while requiring three orders-of-magnitude less storage and operating orders-of-magnitude faster. The code will be made public. ",
    "url": "https://arxiv.org/abs/2404.00469",
    "authors": [
      "Yang Miao",
      "Francis Engelmann",
      "Olga Vysotska",
      "Federico Tombari",
      "Marc Pollefeys",
      "D\u00e1niel B\u00e9la Bar\u00e1th"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00470",
    "title": "Classification of Short Segment Pediatric Heart Sounds Based on a  Transformer-Based Convolutional Neural Network",
    "abstract": "Congenital anomalies arising as a result of a defect in the structure of the heart and great vessels are known as congenital heart diseases or CHDs. A PCG can provide essential details about the mechanical conduction system of the heart and point out specific patterns linked to different kinds of CHD. This study aims to investigate the minimum signal duration required for the automatic classification of heart sounds. This study also investigated the optimum signal quality assessment indicator (Root Mean Square of Successive Differences) RMSSD and (Zero Crossings Rate) ZCR value. Mel-frequency cepstral coefficients (MFCCs) based feature is used as an input to build a Transformer-Based residual one-dimensional convolutional neural network, which is then used for classifying the heart sound. The study showed that 0.4 is the ideal threshold for getting suitable signals for the RMSSD and ZCR indicators. Moreover, a minimum signal length of 5s is required for effective heart sound classification. It also shows that a shorter signal (3 s heart sound) does not have enough information to categorize heart sounds accurately, and the longer signal (15 s heart sound) may contain more noise. The best accuracy, 93.69%, is obtained for the 5s signal to distinguish the heart sound. ",
    "url": "https://arxiv.org/abs/2404.00470",
    "authors": [
      "Md Hassanuzzaman",
      "Nurul Akhtar Hasan",
      "Mohammad Abdullah Al Mamun",
      "Khawza I Ahmed",
      "Ahsan H Khandoker",
      "Raqibul Mostafa"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.00473",
    "title": "Privacy Backdoors: Stealing Data with Corrupted Pretrained Models",
    "abstract": "Practitioners commonly download pretrained machine learning models from open repositories and finetune them to fit specific applications. We show that this practice introduces a new risk of privacy backdoors. By tampering with a pretrained model's weights, an attacker can fully compromise the privacy of the finetuning data. We show how to build privacy backdoors for a variety of models, including transformers, which enable an attacker to reconstruct individual finetuning samples, with a guaranteed success! We further show that backdoored models allow for tight privacy attacks on models trained with differential privacy (DP). The common optimistic practice of training DP models with loose privacy guarantees is thus insecure if the model is not trusted. Overall, our work highlights a crucial and overlooked supply chain attack on machine learning privacy. ",
    "url": "https://arxiv.org/abs/2404.00473",
    "authors": [
      "Shanglun Feng",
      "Florian Tram\u00e8r"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00477",
    "title": "DE-HNN: An effective neural model for Circuit Netlist representation",
    "abstract": "The run-time for optimization tools used in chip design has grown with the complexity of designs to the point where it can take several days to go through one design cycle which has become a bottleneck. Designers want fast tools that can quickly give feedback on a design. Using the input and output data of the tools from past designs, one can attempt to build a machine learning model that predicts the outcome of a design in significantly shorter time than running the tool. The accuracy of such models is affected by the representation of the design data, which is usually a netlist that describes the elements of the digital circuit and how they are connected. Graph representations for the netlist together with graph neural networks have been investigated for such models. However, the characteristics of netlists pose several challenges for existing graph learning frameworks, due to the large number of nodes and the importance of long-range interactions between nodes. To address these challenges, we represent the netlist as a directed hypergraph and propose a Directional Equivariant Hypergraph Neural Network (DE-HNN) for the effective learning of (directed) hypergraphs. Theoretically, we show that our DE-HNN can universally approximate any node or hyperedge based function that satisfies certain permutation equivariant and invariant properties natural for directed hypergraphs. We compare the proposed DE-HNN with several State-of-the-art (SOTA) machine learning models for (hyper)graphs and netlists, and show that the DE-HNN significantly outperforms them in predicting the outcome of optimized place-and-route tools directly from the input netlists. Our source code and the netlists data used are publicly available at https://github.com/YusuLab/chips.git ",
    "url": "https://arxiv.org/abs/2404.00477",
    "authors": [
      "Zhishang Luo",
      "Truong Son Hy",
      "Puoya Tabaghi",
      "Donghyeon Koh",
      "Michael Defferrard",
      "Elahe Rezaei",
      "Ryan Carey",
      "Rhett Davis",
      "Rajeev Jain",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2404.00489",
    "title": "PROMPT-SAW: Leveraging Relation-Aware Graphs for Textual Prompt  Compression",
    "abstract": "Large language models (LLMs) have shown exceptional abilities for multiple different natural language processing tasks. While prompting is a crucial tool for LLM inference, we observe that there is a significant cost associated with exceedingly lengthy prompts. Existing attempts to compress lengthy prompts lead to sub-standard results in terms of readability and interpretability of the compressed prompt, with a detrimental impact on prompt utility. To address this, we propose PROMPT-SAW: Prompt compresSion via Relation AWare graphs, an effective strategy for prompt compression over task-agnostic and task-aware prompts. PROMPT-SAW uses the prompt's textual information to build a graph, later extracts key information elements in the graph to come up with the compressed prompt. We also propose GSM8K-AUG, i.e., an extended version of the existing GSM8k benchmark for task-agnostic prompts in order to provide a comprehensive evaluation platform. Experimental evaluation using benchmark datasets shows that prompts compressed by PROMPT-SAW are not only better in terms of readability, but they also outperform the best-performing baseline models by up to 14.3 and 13.7 respectively for task-aware and task-agnostic settings while compressing the original prompt text by 33.0 and 56.7. ",
    "url": "https://arxiv.org/abs/2404.00489",
    "authors": [
      "Muhammad Asif Ali",
      "Zhengping Li",
      "Shu Yang",
      "Keyuan Cheng",
      "Yang Cao",
      "Tianhao Huang",
      "Lijie Hu",
      "Lu Yu",
      "Di Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00538",
    "title": "Eclipse Attack Detection on a Blockchain Network as a Non-Parametric  Change Detection Problem",
    "abstract": "This paper introduces a novel non-parametric change detection algorithm to identify eclipse attacks on a blockchain network; the non-parametric algorithm relies only on the empirical mean and variance of the dataset, making it highly adaptable. An eclipse attack occurs when malicious actors isolate blockchain users, disrupting their ability to reach consensus with the broader network, thereby distorting their local copy of the ledger. To detect an eclipse attack, we monitor changes in the Fr\\'echet mean and variance of the evolving blockchain communication network connecting blockchain users. First, we leverage the Johnson-Lindenstrauss lemma to project large-dimensional networks into a lower-dimensional space, preserving essential statistical properties. Subsequently, we employ a non-parametric change detection procedure, leading to a test statistic that converges weakly to a Brownian bridge process in the absence of an eclipse attack. This enables us to quantify the false alarm rate of the detector. Our detector can be implemented as a smart contract on the blockchain, offering a tamper-proof and reliable solution. Finally, we use numerical examples to compare the proposed eclipse attack detector with a detector based on the random forest model. ",
    "url": "https://arxiv.org/abs/2404.00538",
    "authors": [
      "Anurag Gupta",
      "Brian Sadler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2404.00539",
    "title": "Solving the QAP by Two-Stage Graph Pointer Networks and Reinforcement  Learning",
    "abstract": "Quadratic Assignment Problem (QAP) is a practical combinatorial optimization problems that has been studied for several years. Since it is NP-hard, solving large problem instances of QAP is challenging. Although heuristics can find semi-optimal solutions, the execution time significantly increases as the problem size increases. Recently, solving combinatorial optimization problems by deep learning has been attracting attention as a faster solver than heuristics. Even with deep learning, however, solving large QAP is still challenging. In this paper, we propose the deep reinforcement learning model called the two-stage graph pointer network (GPN) for solving QAP. Two-stage GPN relies on GPN, which has been proposed for Euclidean Traveling Salesman Problem (TSP). First, we extend GPN for general TSP, and then we add new algorithms to that model for solving QAP. Our experimental results show that our two-stage GPN provides semi-optimal solutions for benchmark problem instances from TSPlib and QAPLIB. ",
    "url": "https://arxiv.org/abs/2404.00539",
    "authors": [
      "Satoko Iida",
      "Ryota Yasudo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00540",
    "title": "Embodied Active Defense: Leveraging Recurrent Feedback to Counter  Adversarial Patches",
    "abstract": "The vulnerability of deep neural networks to adversarial patches has motivated numerous defense strategies for boosting model robustness. However, the prevailing defenses depend on single observation or pre-established adversary information to counter adversarial patches, often failing to be confronted with unseen or adaptive adversarial attacks and easily exhibiting unsatisfying performance in dynamic 3D environments. Inspired by active human perception and recurrent feedback mechanisms, we develop Embodied Active Defense (EAD), a proactive defensive strategy that actively contextualizes environmental information to address misaligned adversarial patches in 3D real-world settings. To achieve this, EAD develops two central recurrent sub-modules, i.e., a perception module and a policy module, to implement two critical functions of active vision. These models recurrently process a series of beliefs and observations, facilitating progressive refinement of their comprehension of the target object and enabling the development of strategic actions to counter adversarial patches in 3D environments. To optimize learning efficiency, we incorporate a differentiable approximation of environmental dynamics and deploy patches that are agnostic to the adversary strategies. Extensive experiments demonstrate that EAD substantially enhances robustness against a variety of patches within just a few steps through its action policy in safety-critical tasks (e.g., face recognition and object detection), without compromising standard accuracy. Furthermore, due to the attack-agnostic characteristic, EAD facilitates excellent generalization to unseen attacks, diminishing the averaged attack success rate by 95 percent across a range of unseen adversarial attacks. ",
    "url": "https://arxiv.org/abs/2404.00540",
    "authors": [
      "Lingxuan Wu",
      "Xiao Yang",
      "Yinpeng Dong",
      "Liuwei Xie",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00544",
    "title": "Deep Extrinsic Manifold Representation for Vision Tasks",
    "abstract": "Non-Euclidean data is frequently encountered across different fields, yet there is limited literature that addresses the fundamental challenge of training neural networks with manifold representations as outputs. We introduce the trick named Deep Extrinsic Manifold Representation (DEMR) for visual tasks in this context. DEMR incorporates extrinsic manifold embedding into deep neural networks, which helps generate manifold representations. The DEMR approach does not directly optimize the complex geodesic loss. Instead, it focuses on optimizing the computation graph within the embedded Euclidean space, allowing for adaptability to various architectural requirements. We provide empirical evidence supporting the proposed concept on two types of manifolds, $SE(3)$ and its associated quotient manifolds. This evidence offers theoretical assurances regarding feasibility, asymptotic properties, and generalization capability. The experimental results show that DEMR effectively adapts to point cloud alignment, producing outputs in $ SE(3) $, as well as in illumination subspace learning with outputs on the Grassmann manifold. ",
    "url": "https://arxiv.org/abs/2404.00544",
    "authors": [
      "Tongtong Zhang",
      "Xian Wei",
      "Yuanxiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00566",
    "title": "CodeBenchGen: Creating Scalable Execution-based Code Generation  Benchmarks",
    "abstract": "To facilitate evaluation of code generation systems across diverse scenarios, we present CodeBenchGen, a framework to create scalable execution-based benchmarks that only requires light guidance from humans. Specifically, we leverage a large language model (LLM) to convert an arbitrary piece of code into an evaluation example, including test cases for execution-based evaluation. We illustrate the usefulness of our framework by creating a dataset, Exec-CSN, which includes 1,931 examples involving 293 libraries revised from code in 367 GitHub repositories taken from the CodeSearchNet dataset. To demonstrate the complexity and solvability of examples in Exec-CSN, we present a human study demonstrating that 81.3% of the examples can be solved by humans and 61% are rated as ``requires effort to solve''. We conduct code generation experiments on open-source and proprietary models and analyze the performance of both humans and models. We will release the code of both the framework and the dataset upon acceptance. ",
    "url": "https://arxiv.org/abs/2404.00566",
    "authors": [
      "Yiqing Xie",
      "Alex Xie",
      "Divyanshu Sheth",
      "Pengfei Liu",
      "Daniel Fried",
      "Carolyn Rose"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00570",
    "title": "ParaICL: Towards Robust Parallel In-Context Learning",
    "abstract": "Large language models (LLMs) have become the norm in natural language processing (NLP), excelling in few-shot in-context learning (ICL) with their remarkable abilities. Nonetheless, the success of ICL largely hinges on the choice of few-shot demonstration examples, making the selection process increasingly crucial. Existing methods have delved into optimizing the quantity and semantic similarity of these examples to improve ICL performances. However, our preliminary experiments indicate that the effectiveness of ICL is limited by the length of the input context. Moreover, varying combinations of few-shot demonstration examples can significantly boost accuracy across different test samples. To address this, we propose a novel method named parallel in-context learning (ParaICL) that effectively utilizes all demonstration examples without exceeding the manageable input context length. ParaICL employs parallel batching to distribute demonstration examples into different batches according to the semantic similarities of the questions in the demonstrations to the test question. It then computes normalized batch semantic scores for each batch. A weighted average semantic objective, constrained by adaptive plausibility, is applied to select the most appropriate tokens. Through extensive experiments, we validate the effectiveness of ParaICL and conduct ablation studies to underscore its design rationale. We further demonstrate that ParaICL can seamlessly integrate with existing methods. ",
    "url": "https://arxiv.org/abs/2404.00570",
    "authors": [
      "Xingxuan Li",
      "Xuan-Phi Nguyen",
      "Shafiq Joty",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00576",
    "title": "Automated Bi-Fold Weighted Ensemble Algorithms and its Application to  Brain Tumor Detection and Classification",
    "abstract": "The uncontrolled and unstructured growth of brain cells is known as brain tumor, which has one of the highest mortality rates among diseases from all types of cancers. Due to limited diagnostic and treatment capabilities, they pose significant challenges, especially in third-world countries. Early diagnosis plays a vital role in effectively managing brain tumors and reducing mortality rates. However, the availability of diagnostic methods is hindered by various limitations, including high costs and lengthy result acquisition times, impeding early detection of the disease. In this study, we present two cutting-edge bi-fold weighted voting ensemble models that aim to boost the effectiveness of weighted ensemble methods. These two proposed methods combine the classification outcomes from multiple classifiers and determine the optimal result by selecting the one with the highest probability in the first approach, and the highest weighted prediction in the second technique. These approaches significantly improve the overall performance of weighted ensemble techniques. In the first proposed method, we improve the soft voting technique (SVT) by introducing a novel unsupervised weight calculating schema (UWCS) to enhance its weight assigning capability, known as the extended soft voting technique (ESVT). Secondly, we propose a novel weighted method (NWM) by using the proposed UWCS. Both of our approaches incorporate three distinct models: a custom-built CNN, VGG-16, and InceptionResNetV2 which has been trained on publicly available datasets. The effectiveness of our proposed systems is evaluated through blind testing, where exceptional results are achieved. We then establish a comparative analysis of the performance of our proposed methods with that of SVT to show their superiority and effectiveness. ",
    "url": "https://arxiv.org/abs/2404.00576",
    "authors": [
      "PoTsang B. Huang",
      "Muhammad Rizwan",
      "Mehboob Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00586",
    "title": "RLGNet: Repeating-Local-Global History Network for Temporal Knowledge  Graph Reasoning",
    "abstract": "Temporal Knowledge Graph (TKG) reasoning is based on historical information to predict the future. Therefore, parsing and mining historical information is key to predicting the future. Most existing methods fail to concurrently address and comprehend historical information from both global and local perspectives. Neglecting the global view might result in overlooking macroscopic trends and patterns, while ignoring the local view can lead to missing critical detailed information. Additionally, some methods do not focus on learning from high-frequency repeating events, which means they may not fully grasp frequently occurring historical events. To this end, we propose the \\textbf{R}epetitive-\\textbf{L}ocal-\\textbf{G}lobal History \\textbf{Net}work(RLGNet). We utilize a global history encoder to capture the overarching nature of historical information. Subsequently, the local history encoder provides information related to the query timestamp. Finally, we employ the repeating history encoder to identify and learn from frequently occurring historical events. In the evaluation on six benchmark datasets, our approach generally outperforms existing TKG reasoning models in multi-step and single-step reasoning tasks. ",
    "url": "https://arxiv.org/abs/2404.00586",
    "authors": [
      "Ao Lv",
      "Yongzhong Huang",
      "Guige Ouyang",
      "Yue Chen",
      "Haoran Xie"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00588",
    "title": "Memory-based Cross-modal Semantic Alignment Network for Radiology Report  Generation",
    "abstract": "Generating radiology reports automatically reduces the workload of radiologists and helps the diagnoses of specific diseases. Many existing methods take this task as modality transfer process. However, since the key information related to disease accounts for a small proportion in both image and report, it is hard for the model to learn the latent relation between the radiology image and its report, thus failing to generate fluent and accurate radiology reports. To tackle this problem, we propose a memory-based cross-modal semantic alignment model (MCSAM) following an encoder-decoder paradigm. MCSAM includes a well initialized long-term clinical memory bank to learn disease-related representations as well as prior knowledge for different modalities to retrieve and use the retrieved memory to perform feature consolidation. To ensure the semantic consistency of the retrieved cross modal prior knowledge, a cross-modal semantic alignment module (SAM) is proposed. SAM is also able to generate semantic visual feature embeddings which can be added to the decoder and benefits report generation. More importantly, to memorize the state and additional information while generating reports with the decoder, we use learnable memory tokens which can be seen as prompts. Extensive experiments demonstrate the promising performance of our proposed method which generates state-of-the-art performance on the MIMIC-CXR dataset. ",
    "url": "https://arxiv.org/abs/2404.00588",
    "authors": [
      "Yitian Tao",
      "Liyan Ma",
      "Jing Yu",
      "Han Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00589",
    "title": "Harnessing the Power of Large Language Model for Uncertainty Aware Graph  Processing",
    "abstract": "Handling graph data is one of the most difficult tasks. Traditional techniques, such as those based on geometry and matrix factorization, rely on assumptions about the data relations that become inadequate when handling large and complex graph data. On the other hand, deep learning approaches demonstrate promising results in handling large graph data, but they often fall short of providing interpretable explanations. To equip the graph processing with both high accuracy and explainability, we introduce a novel approach that harnesses the power of a large language model (LLM), enhanced by an uncertainty-aware module to provide a confidence score on the generated answer. We experiment with our approach on two graph processing tasks: few-shot knowledge graph completion and graph classification. Our results demonstrate that through parameter efficient fine-tuning, the LLM surpasses state-of-the-art algorithms by a substantial margin across ten diverse benchmark datasets. Moreover, to address the challenge of explainability, we propose an uncertainty estimation based on perturbation, along with a calibration scheme to quantify the confidence scores of the generated answers. Our confidence measure achieves an AUC of 0.8 or higher on seven out of the ten datasets in predicting the correctness of the answer generated by LLM. ",
    "url": "https://arxiv.org/abs/2404.00589",
    "authors": [
      "Zhenyu Qian",
      "Yiming Qian",
      "Yuting Song",
      "Fei Gao",
      "Hai Jin",
      "Chen Yu",
      "Xia Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00598",
    "title": "Robust Beamforming Design and Antenna Selection for Dynamic HRIS-aided  Massive MIMO Systems",
    "abstract": "In this paper, a dynamic hybrid active-passive reconfigurable intelligent surface (HRIS) is proposed to further enhance the massive multiple-input-multiple-output (MIMO) system, since it supports the dynamic placement of active and passive elements. Specifically, considering the impact of the hardware impairments (HWIs), we investigate the channel-aware configuration of the receive antennas at the base station (BS) and the active/passive elements at the HRIS to improve the reliability of system. To this end, we investigate the average mean-square-error (MSE) minimization problem for the HRIS-aided massive MIMO system by jointly optimizing the BS receive antenna selection matrix, the reflection phase coefficients, the reflection amplitude matrix, and the mode selection matrix of the HRIS under the power budget of the HRIS. To tackle the non-convexity and intractability of this problem, we first transform the binary and discrete variables into continuous ones, and then propose a penalty-based exact block coordinate descent (BCD) algorithm to solve these subproblems alternately. Numerical simulations demonstrate the great superiority of the proposed scheme over the conventional benchmark schemes. ",
    "url": "https://arxiv.org/abs/2404.00598",
    "authors": [
      "Jintao Wang",
      "Binggui Zhou",
      "Chengzhi Ma",
      "Shiqi Gong",
      "Guanghua Yang",
      "Shaodan Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.00599",
    "title": "EvoCodeBench: An Evolving Code Generation Benchmark Aligned with  Real-World Code Repositories",
    "abstract": "How to evaluate Large Language Models (LLMs) in code generation is an open question. Existing benchmarks demonstrate poor alignment with real-world code repositories and are insufficient to evaluate the coding abilities of LLMs. This paper proposes a new benchmark - EvoCodeBench to address the preceding problems, which has three primary advances. (1) EvoCodeBench aligns with real-world repositories in multiple dimensions, e.g., code distributions and dependency distributions. (2) EvoCodeBench offers comprehensive annotations (e.g., requirements, reference code, and reference dependencies), and robust evaluation metrics (e.g., Pass@k and Recall@k). (3) EvoCodeBench is an evolving benchmark to avoid data leakage. We build an automatic pipeline to update EvoCodeBench from the latest repositories. We release the first version - EvoCodeBench-2403, containing 275 samples from 25 real-world repositories. Based on EvoCodeBench, we propose repository-level code generation and evaluate 10 popular LLMs (e.g., gpt-4, gpt-3.5, DeepSeek Coder, StarCoder 2, CodeLLaMa, Gemma, and Qwen 1.5). Our experiments reveal the coding abilities of these LLMs in real-world repositories. For example, the highest Pass@1 of gpt-4 only is 20.73% in our experiments. We also analyze failed cases and summarize the shortcomings of existing LLMs in EvoCodeBench. We release EvoCodeBench, all prompts, and LLMs' completions for further community analysis. ",
    "url": "https://arxiv.org/abs/2404.00599",
    "authors": [
      "Jia Li",
      "Ge Li",
      "Xuanming Zhang",
      "Yihong Dong",
      "Zhi Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2404.00600",
    "title": "AI Act and Large Language Models (LLMs): When critical issues and  privacy impact require human and ethical oversight",
    "abstract": "The imposing evolution of artificial intelligence systems and, specifically, of Large Language Models (LLM) makes it necessary to carry out assessments of their level of risk and the impact they may have in the area of privacy, personal data protection and at an ethical level, especially on the weakest and most vulnerable. This contribution addresses human oversight, ethical oversight, and privacy impact assessment. ",
    "url": "https://arxiv.org/abs/2404.00600",
    "authors": [
      "Nicola Fabiano"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00611",
    "title": "Object-level Copy-Move Forgery Image Detection based on Inconsistency  Mining",
    "abstract": "In copy-move tampering operations, perpetrators often employ techniques, such as blurring, to conceal tampering traces, posing significant challenges to the detection of object-level targets with intact structures. Focus on these challenges, this paper proposes an Object-level Copy-Move Forgery Image Detection based on Inconsistency Mining (IMNet). To obtain complete object-level targets, we customize prototypes for both the source and tampered regions and dynamically update them. Additionally, we extract inconsistent regions between coarse similar regions obtained through self-correlation calculations and regions composed of prototypes. The detected inconsistent regions are used as supplements to coarse similar regions to refine pixel-level detection. We operate experiments on three public datasets which validate the effectiveness and the robustness of the proposed IMNet. ",
    "url": "https://arxiv.org/abs/2404.00611",
    "authors": [
      "Jingyu Wang",
      "Niantai Jing",
      "Ziyao Liu",
      "Jie Nie",
      "Yuxin Qi",
      "Chi-Hung Chi",
      "Kwok-Yan Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00618",
    "title": "A Multi-Branched Radial Basis Network Approach to Predicting Complex  Chaotic Behaviours",
    "abstract": "In this study, we propose a multi branched network approach to predict the dynamics of a physics attractor characterized by intricate and chaotic behavior. We introduce a unique neural network architecture comprised of Radial Basis Function (RBF) layers combined with an attention mechanism designed to effectively capture nonlinear inter-dependencies inherent in the attractor's temporal evolution. Our results demonstrate successful prediction of the attractor's trajectory across 100 predictions made using a real-world dataset of 36,700 time-series observations encompassing approximately 28 minutes of activity. To further illustrate the performance of our proposed technique, we provide comprehensive visualizations depicting the attractor's original and predicted behaviors alongside quantitative measures comparing observed versus estimated outcomes. Overall, this work showcases the potential of advanced machine learning algorithms in elucidating hidden structures in complex physical systems while offering practical applications in various domains requiring accurate short-term forecasting capabilities. ",
    "url": "https://arxiv.org/abs/2404.00618",
    "authors": [
      "Aarush Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2404.00622",
    "title": "OpenMines: A Light and Comprehensive Mining Simulation Environment for  Truck Dispatching",
    "abstract": "Mine fleet management algorithms can significantly reduce operational costs and enhance productivity in mining systems. Most current fleet management algorithms are evaluated based on self-implemented or proprietary simulation environments, posing challenges for replication and comparison. This paper models the simulation environment for mine fleet management from a complex systems perspective. Building upon previous work, we introduce probabilistic, user-defined events for random event simulation and implement various evaluation metrics and baselines, effectively reflecting the robustness of fleet management algorithms against unforeseen incidents. We present ``OpenMines'', an open-source framework encompassing the entire process of mine system modeling, algorithm development, and evaluation, facilitating future algorithm comparison and replication in the field. Code is available in https://github.com/370025263/openmines. ",
    "url": "https://arxiv.org/abs/2404.00622",
    "authors": [
      "Shi Meng",
      "Bin Tian",
      "Xiaotong Zhang",
      "Shuangying Qi",
      "Caiji Zhang",
      "Qiang Zhang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.00638",
    "title": "HypeBoy: Generative Self-Supervised Representation Learning on  Hypergraphs",
    "abstract": "Hypergraphs are marked by complex topology, expressing higher-order interactions among multiple nodes with hyperedges, and better capturing the topology is essential for effective representation learning. Recent advances in generative self-supervised learning (SSL) suggest that hypergraph neural networks learned from generative self supervision have the potential to effectively encode the complex hypergraph topology. Designing a generative SSL strategy for hypergraphs, however, is not straightforward. Questions remain with regard to its generative SSL task, connection to downstream tasks, and empirical properties of learned representations. In light of the promises and challenges, we propose a novel generative SSL strategy for hypergraphs. We first formulate a generative SSL task on hypergraphs, hyperedge filling, and highlight its theoretical connection to node classification. Based on the generative SSL task, we propose a hypergraph SSL method, HypeBoy. HypeBoy learns effective general-purpose hypergraph representations, outperforming 16 baseline methods across 11 benchmark datasets. ",
    "url": "https://arxiv.org/abs/2404.00638",
    "authors": [
      "Sunwoo Kim",
      "Shinhwan Kang",
      "Fanchen Bu",
      "Soo Yong Lee",
      "Jaemin Yoo",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00645",
    "title": "Attire-Based Anomaly Detection in Restricted Areas Using YOLOv8 for  Enhanced CCTV Security",
    "abstract": "This research introduces an innovative security enhancement approach, employing advanced image analysis and soft computing. The focus is on an intelligent surveillance system that detects unauthorized individuals in restricted areas by analyzing attire. Traditional security measures face challenges in monitoring unauthorized access. Leveraging YOLOv8, an advanced object detection algorithm, our system identifies authorized personnel based on their attire in CCTV footage. The methodology involves training the YOLOv8 model on a comprehensive dataset of uniform patterns, ensuring precise recognition in specific regions. Soft computing techniques enhance adaptability to dynamic environments and varying lighting conditions. This research contributes to image analysis and soft computing, providing a sophisticated security solution. Emphasizing uniform-based anomaly detection, it establishes a foundation for robust security systems in restricted areas. The outcomes highlight the potential of YOLOv8-based surveillance in ensuring safety in sensitive locations. ",
    "url": "https://arxiv.org/abs/2404.00645",
    "authors": [
      "Abdul Aziz A.B",
      "Aindri Bajpai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00653",
    "title": "Dual DETRs for Multi-Label Temporal Action Detection",
    "abstract": "Temporal Action Detection (TAD) aims to identify the action boundaries and the corresponding category within untrimmed videos. Inspired by the success of DETR in object detection, several methods have adapted the query-based framework to the TAD task. However, these approaches primarily followed DETR to predict actions at the instance level (i.e., identify each action by its center point), leading to sub-optimal boundary localization. To address this issue, we propose a new Dual-level query-based TAD framework, namely DualDETR, to detect actions from both instance-level and boundary-level. Decoding at different levels requires semantics of different granularity, therefore we introduce a two-branch decoding structure. This structure builds distinctive decoding processes for different levels, facilitating explicit capture of temporal cues and semantics at each level. On top of the two-branch design, we present a joint query initialization strategy to align queries from both levels. Specifically, we leverage encoder proposals to match queries from each level in a one-to-one manner. Then, the matched queries are initialized using position and content prior from the matched action proposal. The aligned dual-level queries can refine the matched proposal with complementary cues during subsequent decoding. We evaluate DualDETR on three challenging multi-label TAD benchmarks. The experimental results demonstrate the superior performance of DualDETR to the existing state-of-the-art methods, achieving a substantial improvement under det-mAP and delivering impressive results under seg-mAP. ",
    "url": "https://arxiv.org/abs/2404.00653",
    "authors": [
      "Yuhan Zhu",
      "Guozhen Zhang",
      "Jing Tan",
      "Gangshan Wu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00656",
    "title": "WavLLM: Towards Robust and Adaptive Speech Large Language Model",
    "abstract": "The recent advancements in large language models (LLMs) have revolutionized the field of natural language processing, progressively broadening their scope to multimodal perception and generation. However, effectively integrating listening capabilities into LLMs poses significant challenges, particularly with respect to generalizing across varied contexts and executing complex auditory tasks. In this work, we introduce WavLLM, a robust and adaptive speech large language model with dual encoders, and a prompt-aware LoRA weight adapter, optimized by a two-stage curriculum learning approach. Leveraging dual encoders, we decouple different types of speech information, utilizing a Whisper encoder to process the semantic content of speech, and a WavLM encoder to capture the unique characteristics of the speaker's identity. Within the curriculum learning framework, WavLLM first builds its foundational capabilities by optimizing on mixed elementary single tasks, followed by advanced multi-task training on more complex tasks such as combinations of the elementary tasks. To enhance the flexibility and adherence to different tasks and instructions, a prompt-aware LoRA weight adapter is introduced in the second advanced multi-task training stage. We validate the proposed model on universal speech benchmarks including tasks such as ASR, ST, SV, ER, and also apply it to specialized datasets like Gaokao English listening comprehension set for SQA, and speech Chain-of-Thought (CoT) evaluation set. Experiments demonstrate that the proposed model achieves state-of-the-art performance across a range of speech tasks on the same model size, exhibiting robust generalization capabilities in executing complex tasks using CoT approach. Furthermore, our model successfully completes Gaokao tasks without specialized training. The codes, models, audio, and Gaokao evaluation set can be accessed at \\url{aka.ms/wavllm}. ",
    "url": "https://arxiv.org/abs/2404.00656",
    "authors": [
      "Shujie Hu",
      "Long Zhou",
      "Shujie Liu",
      "Sanyuan Chen",
      "Hongkun Hao",
      "Jing Pan",
      "Xunying Liu",
      "Jinyu Li",
      "Sunit Sivasankaran",
      "Linquan Liu",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.00673",
    "title": "A Survey of Privacy-Preserving Model Explanations: Privacy Risks,  Attacks, and Countermeasures",
    "abstract": "As the adoption of explainable AI (XAI) continues to expand, the urgency to address its privacy implications intensifies. Despite a growing corpus of research in AI privacy and explainability, there is little attention on privacy-preserving model explanations. This article presents the first thorough survey about privacy attacks on model explanations and their countermeasures. Our contribution to this field comprises a thorough analysis of research papers with a connected taxonomy that facilitates the categorisation of privacy attacks and countermeasures based on the targeted explanations. This work also includes an initial investigation into the causes of privacy leaks. Finally, we discuss unresolved issues and prospective research directions uncovered in our analysis. This survey aims to be a valuable resource for the research community and offers clear insights for those new to this domain. To support ongoing research, we have established an online resource repository, which will be continuously updated with new and relevant findings. Interested readers are encouraged to access our repository at https://github.com/tamlhp/awesome-privex. ",
    "url": "https://arxiv.org/abs/2404.00673",
    "authors": [
      "Thanh Tam Nguyen",
      "Thanh Trung Huynh",
      "Zhao Ren",
      "Thanh Toan Nguyen",
      "Phi Le Nguyen",
      "Hongzhi Yin",
      "Quoc Viet Hung Nguyen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00679",
    "title": "Weak-to-Strong 3D Object Detection with X-Ray Distillation",
    "abstract": "This paper addresses the critical challenges of sparsity and occlusion in LiDAR-based 3D object detection. Current methods often rely on supplementary modules or specific architectural designs, potentially limiting their applicability to new and evolving architectures. To our knowledge, we are the first to propose a versatile technique that seamlessly integrates into any existing framework for 3D Object Detection, marking the first instance of Weak-to-Strong generalization in 3D computer vision. We introduce a novel framework, X-Ray Distillation with Object-Complete Frames, suitable for both supervised and semi-supervised settings, that leverages the temporal aspect of point cloud sequences. This method extracts crucial information from both previous and subsequent LiDAR frames, creating Object-Complete frames that represent objects from multiple viewpoints, thus addressing occlusion and sparsity. Given the limitation of not being able to generate Object-Complete frames during online inference, we utilize Knowledge Distillation within a Teacher-Student framework. This technique encourages the strong Student model to emulate the behavior of the weaker Teacher, which processes simple and informative Object-Complete frames, effectively offering a comprehensive view of objects as if seen through X-ray vision. Our proposed methods surpass state-of-the-art in semi-supervised learning by 1-1.5 mAP and enhance the performance of five established supervised models by 1-2 mAP on standard autonomous driving datasets, even with default hyperparameters. Code for Object-Complete frames is available here: https://github.com/sakharok13/X-Ray-Teacher-Patching-Tools. ",
    "url": "https://arxiv.org/abs/2404.00679",
    "authors": [
      "Alexander Gambashidze",
      "Aleksandr Dadukin",
      "Maksim Golyadkin",
      "Maria Razzhivina",
      "Ilya Makarov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00681",
    "title": "CoUDA: Coherence Evaluation via Unified Data Augmentation",
    "abstract": "Coherence evaluation aims to assess the organization and structure of a discourse, which remains challenging even in the era of large language models. Due to the scarcity of annotated data, data augmentation is commonly used for training coherence evaluation models. However, previous augmentations for this task primarily rely on heuristic rules, lacking designing criteria as guidance. In this paper, we take inspiration from linguistic theory of discourse structure, and propose a data augmentation framework named CoUDA. CoUDA breaks down discourse coherence into global and local aspects, and designs augmentation strategies for both aspects, respectively. Especially for local coherence, we propose a novel generative strategy for constructing augmentation samples, which involves post-pretraining a generative model and applying two controlling mechanisms to control the difficulty of generated samples. During inference, CoUDA also jointly evaluates both global and local aspects to comprehensively assess the overall coherence of a discourse. Extensive experiments in coherence evaluation show that, with only 233M parameters, CoUDA achieves state-of-the-art performance in both pointwise scoring and pairwise ranking tasks, even surpassing recent GPT-3.5 and GPT-4 based metrics. ",
    "url": "https://arxiv.org/abs/2404.00681",
    "authors": [
      "Dawei Zhu",
      "Wenhao Wu",
      "Yifan Song",
      "Fangwei Zhu",
      "Ziqiang Cao",
      "Sujian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00694",
    "title": "DMSSN: Distilled Mixed Spectral-Spatial Network for Hyperspectral  Salient Object Detection",
    "abstract": "Hyperspectral salient object detection (HSOD) has exhibited remarkable promise across various applications, particularly in intricate scenarios where conventional RGB-based approaches fall short. Despite the considerable progress in HSOD method advancements, two critical challenges require immediate attention. Firstly, existing hyperspectral data dimension reduction techniques incur a loss of spectral information, which adversely affects detection accuracy. Secondly, previous methods insufficiently harness the inherent distinctive attributes of hyperspectral images (HSIs) during the feature extraction process. To address these challenges, we propose a novel approach termed the Distilled Mixed Spectral-Spatial Network (DMSSN), comprising a Distilled Spectral Encoding process and a Mixed Spectral-Spatial Transformer (MSST) feature extraction network. The encoding process utilizes knowledge distillation to construct a lightweight autoencoder for dimension reduction, striking a balance between robust encoding capabilities and low computational costs. The MSST extracts spectral-spatial features through multiple attention head groups, collaboratively enhancing its resistance to intricate scenarios. Moreover, we have created a large-scale HSOD dataset, HSOD-BIT, to tackle the issue of data scarcity in this field and meet the fundamental data requirements of deep network training. Extensive experiments demonstrate that our proposed DMSSN achieves state-of-the-art performance on multiple datasets. We will soon make the code and dataset publicly available on https://github.com/anonymous0519/HSOD-BIT. ",
    "url": "https://arxiv.org/abs/2404.00694",
    "authors": [
      "Haolin Qin",
      "Tingfa Xu",
      "Peifu Liu",
      "Jingxuan Xu",
      "Jianan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00696",
    "title": "Privacy Re-identification Attacks on Tabular GANs",
    "abstract": "Generative models are subject to overfitting and thus may potentially leak sensitive information from the training data. In this work. we investigate the privacy risks that can potentially arise from the use of generative adversarial networks (GANs) for creating tabular synthetic datasets. For the purpose, we analyse the effects of re-identification attacks on synthetic data, i.e., attacks which aim at selecting samples that are predicted to correspond to memorised training samples based on their proximity to the nearest synthetic records. We thus consider multiple settings where different attackers might have different access levels or knowledge of the generative model and predictive, and assess which information is potentially most useful for launching more successful re-identification attacks. In doing so we also consider the situation for which re-identification attacks are formulated as reconstruction attacks, i.e., the situation where an attacker uses evolutionary multi-objective optimisation for perturbing synthetic samples closer to the training space. The results indicate that attackers can indeed pose major privacy risks by selecting synthetic samples that are likely representative of memorised training samples. In addition, we notice that privacy threats considerably increase when the attacker either has knowledge or has black-box access to the generative models. We also find that reconstruction attacks through multi-objective optimisation even increase the risk of identifying confidential samples. ",
    "url": "https://arxiv.org/abs/2404.00696",
    "authors": [
      "Abdallah Alshantti",
      "Adil Rasheed",
      "Frank Westad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00714",
    "title": "Neural Radiance Field-based Visual Rendering: A Comprehensive Review",
    "abstract": "In recent years, Neural Radiance Fields (NeRF) has made remarkable progress in the field of computer vision and graphics, providing strong technical support for solving key tasks including 3D scene understanding, new perspective synthesis, human body reconstruction, robotics, and so on, the attention of academics to this research result is growing. As a revolutionary neural implicit field representation, NeRF has caused a continuous research boom in the academic community. Therefore, the purpose of this review is to provide an in-depth analysis of the research literature on NeRF within the past two years, to provide a comprehensive academic perspective for budding researchers. In this paper, the core architecture of NeRF is first elaborated in detail, followed by a discussion of various improvement strategies for NeRF, and case studies of NeRF in diverse application scenarios, demonstrating its practical utility in different domains. In terms of datasets and evaluation metrics, This paper details the key resources needed for NeRF model training. Finally, this paper provides a prospective discussion on the future development trends and potential challenges of NeRF, aiming to provide research inspiration for researchers in the field and to promote the further development of related technologies. ",
    "url": "https://arxiv.org/abs/2404.00714",
    "authors": [
      "Mingyuan Yao",
      "Yukang Huo",
      "Yang Ran",
      "Qingbin Tian",
      "Ruifeng Wang",
      "Haihua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00724",
    "title": "Absolute-Unified Multi-Class Anomaly Detection via Class-Agnostic  Distribution Alignment",
    "abstract": "Conventional unsupervised anomaly detection (UAD) methods build separate models for each object category. Recent studies have proposed to train a unified model for multiple classes, namely model-unified UAD. However, such methods still implement the unified model separately on each class during inference with respective anomaly decision thresholds, which hinders their application when the image categories are entirely unavailable. In this work, we present a simple yet powerful method to address multi-class anomaly detection without any class information, namely \\textit{absolute-unified} UAD. We target the crux of prior works in this challenging setting: different objects have mismatched anomaly score distributions. We propose Class-Agnostic Distribution Alignment (CADA) to align the mismatched score distribution of each implicit class without knowing class information, which enables unified anomaly detection for all classes and samples. The essence of CADA is to predict each class's score distribution of normal samples given any image, normal or anomalous, of this class. As a general component, CADA can activate the potential of nearly all UAD methods under absolute-unified setting. Our approach is extensively evaluated under the proposed setting on two popular UAD benchmark datasets, MVTec AD and VisA, where we exceed previous state-of-the-art by a large margin. ",
    "url": "https://arxiv.org/abs/2404.00724",
    "authors": [
      "Jia Guo",
      "Shuai Lu",
      "Weihang Zhang",
      "Huiqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00742",
    "title": "Adapting to Length Shift: FlexiLength Network for Trajectory Prediction",
    "abstract": "Trajectory prediction plays an important role in various applications, including autonomous driving, robotics, and scene understanding. Existing approaches mainly focus on developing compact neural networks to increase prediction precision on public datasets, typically employing a standardized input duration. However, a notable issue arises when these models are evaluated with varying observation lengths, leading to a significant performance drop, a phenomenon we term the Observation Length Shift. To address this issue, we introduce a general and effective framework, the FlexiLength Network (FLN), to enhance the robustness of existing trajectory prediction techniques against varying observation periods. Specifically, FLN integrates trajectory data with diverse observation lengths, incorporates FlexiLength Calibration (FLC) to acquire temporal invariant representations, and employs FlexiLength Adaptation (FLA) to further refine these representations for more accurate future trajectory predictions. Comprehensive experiments on multiple datasets, ie, ETH/UCY, nuScenes, and Argoverse 1, demonstrate the effectiveness and flexibility of our proposed FLN framework. ",
    "url": "https://arxiv.org/abs/2404.00742",
    "authors": [
      "Yi Xu",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00746",
    "title": "Mining Weighted Sequential Patterns in Incremental Uncertain Databases",
    "abstract": "Due to the rapid development of science and technology, the importance of imprecise, noisy, and uncertain data is increasing at an exponential rate. Thus, mining patterns in uncertain databases have drawn the attention of researchers. Moreover, frequent sequences of items from these databases need to be discovered for meaningful knowledge with great impact. In many real cases, weights of items and patterns are introduced to find interesting sequences as a measure of importance. Hence, a constraint of weight needs to be handled while mining sequential patterns. Besides, due to the dynamic nature of databases, mining important information has become more challenging. Instead of mining patterns from scratch after each increment, incremental mining algorithms utilize previously mined information to update the result immediately. Several algorithms exist to mine frequent patterns and weighted sequences from incremental databases. However, these algorithms are confined to mine the precise ones. Therefore, we have developed an algorithm to mine frequent sequences in an uncertain database in this work. Furthermore, we have proposed two new techniques for mining when the database is incremental. Extensive experiments have been conducted for performance evaluation. The analysis showed the efficiency of our proposed framework. ",
    "url": "https://arxiv.org/abs/2404.00746",
    "authors": [
      "Kashob Kumar Roy",
      "Md Hasibul Haque Moon",
      "Md Mahmudur Rahman",
      "Chowdhury Farhan Ahmed",
      "Carson Kai-Sang Leung"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00756",
    "title": "Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery",
    "abstract": "Recognizing failures during task execution and implementing recovery procedures is challenging in robotics. Traditional approaches rely on the availability of extensive data or a tight set of constraints, while more recent approaches leverage large language models (LLMs) to verify task steps and replan accordingly. However, these methods often operate offline, necessitating scene resets and incurring in high costs. This paper introduces Recover, a neuro-symbolic framework for online failure identification and recovery. By integrating ontologies, logical rules, and LLM-based planners, Recover exploits symbolic information to enhance the ability of LLMs to generate recovery plans and also to decrease the associated costs. In order to demonstrate the capabilities of our method in a simulated kitchen environment, we introduce OntoThor, an ontology describing the AI2Thor simulator setting. Empirical evaluation shows that OntoThor's logical rules accurately detect all failures in the analyzed tasks, and that Recover considerably outperforms, for both failure detection and recovery, a baseline method reliant solely on LLMs. ",
    "url": "https://arxiv.org/abs/2404.00756",
    "authors": [
      "Cristina Cornelio",
      "Mohammed Diab"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.00758",
    "title": "From Robustness to Improved Generalization and Calibration in  Pre-trained Language Models",
    "abstract": "Enhancing generalization and uncertainty quantification in pre-trained language models (PLMs) is crucial for their effectiveness and reliability. Building on machine learning research that established the importance of robustness for improving generalization, we investigate the role of representation smoothness, achieved via Jacobian and Hessian regularization, in enhancing PLM performance. Although such regularization methods have proven effective in computer vision, their application in natural language processing (NLP), where PLM inputs are derived from a discrete domain, poses unique challenges. We introduce a novel two-phase regularization approach, JacHess, which minimizes the norms of the Jacobian and Hessian matrices within PLM intermediate representations relative to their inputs. Our evaluation using the GLUE benchmark demonstrates that JacHess significantly improves in-domain generalization and calibration in PLMs, outperforming unregularized fine-tuning and other similar regularization methods. ",
    "url": "https://arxiv.org/abs/2404.00758",
    "authors": [
      "Josip Juki\u0107",
      "Jan \u0160najder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00766",
    "title": "SoK: The Faults in our Graph Benchmarks",
    "abstract": "Graph-structured data is prevalent in domains such as social networks, financial transactions, brain networks, and protein interactions. As a result, the research community has produced new databases and analytics engines to process such data. Unfortunately, there is not yet widespread benchmark standardization in graph processing, and the heterogeneity of evaluations found in the literature can lead researchers astray. Evaluations frequently ignore datasets' statistical idiosyncrasies, which significantly affect system performance. Scalability studies often use datasets that fit easily in memory on a modest desktop. Some studies rely on synthetic graph generators, but these generators produce graphs with unnatural characteristics that also affect performance, producing misleading results. Currently, the community has no consistent and principled manner with which to compare systems and provide guidance to developers who wish to select the system most suited to their application. We provide three different systematizations of benchmarking practices. First, we present a 12-year literary review of graph processing benchmarking, including a summary of the prevalence of specific datasets and benchmarks used in these papers. Second, we demonstrate the impact of two statistical properties of datasets that drastically affect benchmark performance. We show how different assignments of IDs to vertices, called vertex orderings, dramatically alter benchmark performance due to the caching behavior they induce. We also show the impact of zero-degree vertices on the runtime of benchmarks such as breadth-first search and single-source shortest path. We show that these issues can cause performance to change by as much as 38% on several popular graph processing systems. Finally, we suggest best practices to account for these issues when evaluating graph systems. ",
    "url": "https://arxiv.org/abs/2404.00766",
    "authors": [
      "Puneet Mehrotra",
      "Vaastav Anand",
      "Daniel Margo",
      "Milad Rezaei Hajidehi",
      "Margo Seltzer"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2404.00769",
    "title": "An Active Perception Game for Robust Autonomous Exploration",
    "abstract": "We formulate active perception for an autonomous agent that explores an unknown environment as a two-player zero-sum game: the agent aims to maximize information gained from the environment while the environment aims to minimize the information gained by the agent. In each episode, the environment reveals a set of actions with their potentially erroneous information gain. In order to select the best action, the robot needs to recover the true information gain from the erroneous one. The robot does so by minimizing the discrepancy between its estimate of information gain and the true information gain it observes after taking the action. We propose an online convex optimization algorithm that achieves sub-linear expected regret $O(T^{3/4})$ for estimating the information gain. We also provide a bound on the regret of active perception performed by any (near-)optimal prediction and trajectory selection algorithms. We evaluate this approach using semantic neural radiance fields (NeRFs) in simulated realistic 3D environments to show that the robot can discover up to 12% more objects using the improved estimate of the information gain. On the M3ED dataset, the proposed algorithm reduced the error of information gain prediction in occupancy map by over 67%. In real-world experiments using occupancy maps on a Jackal ground robot, we show that this approach can calculate complicated trajectories that efficiently explore all occluded regions. ",
    "url": "https://arxiv.org/abs/2404.00769",
    "authors": [
      "Siming He",
      "Yuezhan Tao",
      "Igor Spasojevic",
      "Vijay Kumar",
      "Pratik Chaudhari"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.00775",
    "title": "Measuring audio prompt adherence with distribution-based embedding  distances",
    "abstract": "An increasing number of generative music models can be conditioned on an audio prompt that serves as musical context for which the model is to create an accompaniment (often further specified using a text prompt). Evaluation of how well model outputs adhere to the audio prompt is often done in a model or problem specific manner, presumably because no generic evaluation method for audio prompt adherence has emerged. Such a method could be useful both in the development and training of new models, and to make performance comparable across models. In this paper we investigate whether commonly used distribution-based distances like Fr\\'echet Audio Distance (FAD), can be used to measure audio prompt adherence. We propose a simple procedure based on a small number of constituents (an embedding model, a projection, an embedding distance, and a data fusion method), that we systematically assess using a baseline validation. In a follow-up experiment we test the sensitivity of the proposed audio adherence measure to pitch and time shift perturbations. The results show that the proposed measure is sensitive to such perturbations, even when the reference and candidate distributions are from different music collections. Although more experimentation is needed to answer unaddressed questions like the robustness of the measure to acoustic artifacts that do not affect the audio prompt adherence, the current results suggest that distribution-based embedding distances provide a viable way of measuring audio prompt adherence. An python/pytorch implementation of the proposed measure is publicly available as a github repository. ",
    "url": "https://arxiv.org/abs/2404.00775",
    "authors": [
      "Maarten Grachten"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.00785",
    "title": "Disentangling Hippocampal Shape Variations: A Study of Neurological  Disorders Using Graph Variational Autoencoder with Contrastive Learning",
    "abstract": "This paper presents a comprehensive study focused on disentangling hippocampal shape variations from diffusion tensor imaging (DTI) datasets within the context of neurological disorders. Leveraging a Graph Variational Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach aims to improve interpretability by disentangling two distinct latent variables corresponding to age and the presence of diseases. In our ablation study, we investigate a range of VAE architectures and contrastive loss functions, showcasing the enhanced disentanglement capabilities of our approach. This evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh datasets derived from the DTI hippocampal dataset. Our supervised disentanglement model outperforms several state-of-the-art (SOTA) methods like attribute and guided VAEs in terms of disentanglement scores. Our model distinguishes between age groups and disease status in patients with Multiple Sclerosis (MS) using the hippocampus data. Our Graph VAE with Supervised Contrastive Learning shows the volume changes of the hippocampus of MS populations at different ages, and the result is consistent with the current neuroimaging literature. This research provides valuable insights into the relationship between neurological disorder and hippocampal shape changes in different age groups of MS populations using a Graph VAE with Supervised Contrastive loss. ",
    "url": "https://arxiv.org/abs/2404.00785",
    "authors": [
      "Jakaria Rabbi",
      "Johannes Kiechle",
      "Christian Beaulieu",
      "Nilanjan Ray",
      "Dana Cobzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2404.00791",
    "title": "Personalized Neural Speech Codec",
    "abstract": "In this paper, we propose a personalized neural speech codec, envisioning that personalization can reduce the model complexity or improve perceptual speech quality. Despite the common usage of speech codecs where only a single talker is involved on each side of the communication, personalizing a codec for the specific user has rarely been explored in the literature. First, we assume speakers can be grouped into smaller subsets based on their perceptual similarity. Then, we also postulate that a group-specific codec can focus on the group's speech characteristics to improve its perceptual quality and computational efficiency. To this end, we first develop a Siamese network that learns the speaker embeddings from the LibriSpeech dataset, which are then grouped into underlying speaker clusters. Finally, we retrain the LPCNet-based speech codec baselines on each of the speaker clusters. Subjective listening tests show that the proposed personalization scheme introduces model compression while maintaining speech quality. In other words, with the same model complexity, personalized codecs produce better speech quality. ",
    "url": "https://arxiv.org/abs/2404.00791",
    "authors": [
      "Inseon Jang",
      "Haici Yang",
      "Wootaek Lim",
      "Seungkwon Beack",
      "Minje Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.00793",
    "title": "Learning the mechanisms of network growth",
    "abstract": "We propose a novel model-selection method for dynamic real-life networks. Our approach involves training a classifier on a large body of synthetic network data. The data is generated by simulating nine state-of-the-art random graph models for dynamic networks, with parameter range chosen to ensure exponential growth of the network size in time. We design a conceptually novel type of dynamic features that count new links received by a group of vertices in a particular time interval. The proposed features are easy to compute, analytically tractable, and interpretable. Our approach achieves a near-perfect classification of synthetic networks, exceeding the state-of-the-art by a large margin. Applying our classification method to real-world citation networks gives credibility to the claims in the literature that models with preferential attachment, fitness and aging fit real-world citation networks best, although sometimes, the predicted model does not involve vertex fitness. ",
    "url": "https://arxiv.org/abs/2404.00793",
    "authors": [
      "Lourens Touwen",
      "Doina Bucur",
      "Remco van der Hofstad",
      "Alessandro Garavaglia",
      "Nelly Litvak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.00814",
    "title": "Imposing Exact Safety Specifications in Neural Reachable Tubes",
    "abstract": "Hamilton-Jacobi (HJ) reachability analysis is a verification tool that provides safety and performance guarantees for autonomous systems. It is widely adopted because of its ability to handle nonlinear dynamical systems with bounded adversarial disturbances and constraints on states and inputs. However, it involves solving a PDE to compute a safety value function, whose computational and memory complexity scales exponentially with the state dimension, making its direct usage in large-scale systems intractable. Recently, a learning-based approach called DeepReach, has been proposed to approximate high-dimensional reachable tubes using neural networks. While DeepReach has been shown to be effective, the accuracy of the learned solution decreases with the increase in system complexity. One of the reasons for this degradation is the inexact imposition of safety constraints during the learning process, which corresponds to the PDE's boundary conditions. Specifically, DeepReach imposes boundary conditions as soft constraints in the loss function, which leaves room for error during the value function learning. Moreover, one needs to carefully adjust the relative contributions from the imposition of boundary conditions and the imposition of the PDE in the loss function. This, in turn, induces errors in the overall learned solution. In this work, we propose a variant of DeepReach that exactly imposes safety constraints during the learning process by restructuring the overall value function as a weighted sum of the boundary condition and neural network output. This eliminates the need for a boundary loss during training, thus bypassing the need for loss adjustment. We demonstrate the efficacy of the proposed approach in significantly improving the accuracy of learned solutions for challenging high-dimensional reachability tasks, such as rocket-landing and multivehicle collision-avoidance problems. ",
    "url": "https://arxiv.org/abs/2404.00814",
    "authors": [
      "Aditya Singh",
      "Zeyuan Feng",
      "Somil Bansal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.00816",
    "title": "HeteroMILE: a Multi-Level Graph Representation Learning Framework for  Heterogeneous Graphs",
    "abstract": "Heterogeneous graphs are ubiquitous in real-world applications because they can represent various relationships between different types of entities. Therefore, learning embeddings in such graphs is a critical problem in graph machine learning. However, existing solutions for this problem fail to scale to large heterogeneous graphs due to their high computational complexity. To address this issue, we propose a Multi-Level Embedding framework of nodes on a heterogeneous graph (HeteroMILE) - a generic methodology that allows contemporary graph embedding methods to scale to large graphs. HeteroMILE repeatedly coarsens the large sized graph into a smaller size while preserving the backbone structure of the graph before embedding it, effectively reducing the computational cost by avoiding time-consuming processing operations. It then refines the coarsened embedding to the original graph using a heterogeneous graph convolution neural network. We evaluate our approach using several popular heterogeneous graph datasets. The experimental results show that HeteroMILE can substantially reduce computational time (approximately 20x speedup) and generate an embedding of better quality for link prediction and node classification. ",
    "url": "https://arxiv.org/abs/2404.00816",
    "authors": [
      "Yue Zhang",
      "Yuntian He",
      "Saket Gurukar",
      "Srinivasan Parthasarathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00826",
    "title": "Extracting Social Determinants of Health from Pediatric Patient Notes  Using Large Language Models: Novel Corpus and Methods",
    "abstract": "Social determinants of health (SDoH) play a critical role in shaping health outcomes, particularly in pediatric populations where interventions can have long-term implications. SDoH are frequently studied in the Electronic Health Record (EHR), which provides a rich repository for diverse patient data. In this work, we present a novel annotated corpus, the Pediatric Social History Annotation Corpus (PedSHAC), and evaluate the automatic extraction of detailed SDoH representations using fine-tuned and in-context learning methods with Large Language Models (LLMs). PedSHAC comprises annotated social history sections from 1,260 clinical notes obtained from pediatric patients within the University of Washington (UW) hospital system. Employing an event-based annotation scheme, PedSHAC captures ten distinct health determinants to encompass living and economic stability, prior trauma, education access, substance use history, and mental health with an overall annotator agreement of 81.9 F1. Our proposed fine-tuning LLM-based extractors achieve high performance at 78.4 F1 for event arguments. In-context learning approaches with GPT-4 demonstrate promise for reliable SDoH extraction with limited annotated examples, with extraction performance at 82.3 F1 for event triggers. ",
    "url": "https://arxiv.org/abs/2404.00826",
    "authors": [
      "Yujuan Fu",
      "Giridhar Kaushik Ramachandran",
      "Nicholas J Dobbins",
      "Namu Park",
      "Michael Leu",
      "Abby R. Rosenberg",
      "Kevin Lybarger",
      "Fei Xia",
      "Ozlem Uzuner",
      "Meliha Yetisgen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00828",
    "title": "PID Control-Based Self-Healing to Improve the Robustness of Large  Language Models",
    "abstract": "Despite the effectiveness of deep neural networks in numerous natural language processing applications, recent findings have exposed the vulnerability of these language models when minor perturbations are introduced. While appearing semantically indistinguishable to humans, these perturbations can significantly reduce the performance of well-trained language models, raising concerns about the reliability of deploying them in safe-critical situations. In this work, we construct a computationally efficient self-healing process to correct undesired model behavior during online inference when perturbations are applied to input data. This is formulated as a trajectory optimization problem in which the internal states of the neural network layers are automatically corrected using a PID (Proportional-Integral-Derivative) control mechanism. The P controller targets immediate state adjustments, while the I and D controllers consider past states and future dynamical trends, respectively. We leverage the geometrical properties of the training data to design effective linear PID controllers. This approach reduces the computational cost to that of using just the P controller, instead of the full PID control. Further, we introduce an analytical method for approximating the optimal control solutions, enhancing the real-time inference capabilities of this controlled system. Moreover, we conduct a theoretical error analysis of the analytic solution in a simplified setting. The proposed PID control-based self-healing is a low cost framework that improves the robustness of pre-trained large language models, whether standard or robustly trained, against a wide range of perturbations. A detailed implementation can be found in:https://github.com/zhuotongchen/PID-Control-Based-Self-Healing-to-Improve-the-Robustness-of-Large-Language-Models. ",
    "url": "https://arxiv.org/abs/2404.00828",
    "authors": [
      "Zhuotong Chen",
      "Zihu Wang",
      "Yifan Yang",
      "Qianxiao Li",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00834",
    "title": "Towards Robust Event-guided Low-Light Image Enhancement: A Large-Scale  Real-World Event-Image Dataset and Novel Approach",
    "abstract": "Event camera has recently received much attention for low-light image enhancement (LIE) thanks to their distinct advantages, such as high dynamic range. However, current research is prohibitively restricted by the lack of large-scale, real-world, and spatial-temporally aligned event-image datasets. To this end, we propose a real-world (indoor and outdoor) dataset comprising over 30K pairs of images and events under both low and normal illumination conditions. To achieve this, we utilize a robotic arm that traces a consistent non-linear trajectory to curate the dataset with spatial alignment precision under 0.03mm. We then introduce a matching alignment strategy, rendering 90% of our dataset with errors less than 0.01s. Based on the dataset, we propose a novel event-guided LIE approach, called EvLight, towards robust performance in real-world low-light scenes. Specifically, we first design the multi-scale holistic fusion branch to extract holistic structural and textural information from both events and images. To ensure robustness against variations in the regional illumination and noise, we then introduce a Signal-to-Noise-Ratio (SNR)-guided regional feature selection to selectively fuse features of images from regions with high SNR and enhance those with low SNR by extracting regional structure information from events. Extensive experiments on our dataset and the synthetic SDSD dataset demonstrate our EvLight significantly surpasses the frame-based methods. Code and datasets are available at https://vlislab22.github.io/eg-lowlight/. ",
    "url": "https://arxiv.org/abs/2404.00834",
    "authors": [
      "Guoqiang Liang",
      "Kanghao Chen",
      "Hangyu Li",
      "Yunfan Lu",
      "Lin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00847",
    "title": "Collaborative Learning of Anomalies with Privacy (CLAP) for Unsupervised  Video Anomaly Detection: A New Baseline",
    "abstract": "Unsupervised (US) video anomaly detection (VAD) in surveillance applications is gaining more popularity recently due to its practical real-world applications. As surveillance videos are privacy sensitive and the availability of large-scale video data may enable better US-VAD systems, collaborative learning can be highly rewarding in this setting. However, due to the extremely challenging nature of the US-VAD task, where learning is carried out without any annotations, privacy-preserving collaborative learning of US-VAD systems has not been studied yet. In this paper, we propose a new baseline for anomaly detection capable of localizing anomalous events in complex surveillance videos in a fully unsupervised fashion without any labels on a privacy-preserving participant-based distributed training configuration. Additionally, we propose three new evaluation protocols to benchmark anomaly detection approaches on various scenarios of collaborations and data availability. Based on these protocols, we modify existing VAD datasets to extensively evaluate our approach as well as existing US SOTA methods on two large-scale datasets including UCF-Crime and XD-Violence. All proposed evaluation protocols, dataset splits, and codes are available here: https://github.com/AnasEmad11/CLAP ",
    "url": "https://arxiv.org/abs/2404.00847",
    "authors": [
      "Anas Al-lahham",
      "Muhammad Zaigham Zaheer",
      "Nurbek Tastan",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00850",
    "title": "Delay-Induced Watermarking for Detection of Replay Attacks in Linear  Systems",
    "abstract": "A state-feedback watermarking signal design for the detection of replay attacks in linear systems is proposed. The control input is augmented with a random time-delayed term of the system state estimate, in order to secure the system against attacks of replay type. We outline the basic analysis of the closed-loop response of the state-feedback watermarking in a LQG controlled system. Our theoretical results are applied on a temperature process control example. While the proposed secure control scheme requires very involved analysis, it, nevertheless, holds promise of being superior to conventional, feed-forward, watermarking schemes, in both its ability to detect attacks as well as the secured system performance. ",
    "url": "https://arxiv.org/abs/2404.00850",
    "authors": [
      "Christoforos Somarakis",
      "Raman Goyal",
      "Erfaun Noorani",
      "Shantanu Rane"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.00855",
    "title": "TSOM: Small Object Motion Detection Neural Network Inspired by Avian  Visual Circuit",
    "abstract": "Detecting small moving objects in complex backgrounds from an overhead perspective is a highly challenging task for machine vision systems. As an inspiration from nature, the avian visual system is capable of processing motion information in various complex aerial scenes, and its Retina-OT-Rt visual circuit is highly sensitive to capturing the motion information of small objects from high altitudes. However, more needs to be done on small object motion detection algorithms based on the avian visual system. In this paper, we conducted mathematical modeling based on extensive studies of the biological mechanisms of the Retina-OT-Rt visual circuit. Based on this, we proposed a novel tectum small object motion detection neural network (TSOM). The neural network includes the retina, SGC dendritic, SGC Soma, and Rt layers, each layer corresponding to neurons in the visual pathway. The Retina layer is responsible for accurately projecting input content, the SGC dendritic layer perceives and encodes spatial-temporal information, the SGC Soma layer computes complex motion information and extracts small objects, and the Rt layer integrates and decodes motion information from multiple directions to determine the position of small objects. Extensive experiments on pigeon neurophysiological experiments and image sequence data showed that the TSOM is biologically interpretable and effective in extracting reliable small object motion features from complex high-altitude backgrounds. ",
    "url": "https://arxiv.org/abs/2404.00855",
    "authors": [
      "Pignge Hu",
      "Xiaoteng Zhang",
      "Mengmeng Li",
      "Yingjie Zhu",
      "Li Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00856",
    "title": "Removing Speaker Information from Speech Representation using  Variable-Length Soft Pooling",
    "abstract": "Recently, there have been efforts to encode the linguistic information of speech using a self-supervised framework for speech synthesis. However, predicting representations from surrounding representations can inadvertently entangle speaker information in the speech representation. This paper aims to remove speaker information by exploiting the structured nature of speech, composed of discrete units like phonemes with clear boundaries. A neural network predicts these boundaries, enabling variable-length pooling for event-based representation extraction instead of fixed-rate methods. The boundary predictor outputs a probability for the boundary between 0 and 1, making pooling soft. The model is trained to minimize the difference with the pooled representation of the data augmented by time-stretch and pitch-shift. To confirm that the learned representation includes contents information but is independent of speaker information, the model was evaluated with libri-light's phonetic ABX task and SUPERB's speaker identification task. ",
    "url": "https://arxiv.org/abs/2404.00856",
    "authors": [
      "Injune Hwang",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.00860",
    "title": "Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text  Guidance",
    "abstract": "Large-scale contrastive vision-language pre-trained models provide the zero-shot model achieving competitive performance across a range of image classification tasks without requiring training on downstream data. Recent works have confirmed that while additional fine-tuning of the zero-shot model on the reference data results in enhanced downstream performance, it compromises the model's robustness against distribution shifts. Our investigation begins by examining the conditions required to achieve the goals of robust fine-tuning, employing descriptions based on feature distortion theory and joint energy-based models. Subsequently, we propose a novel robust fine-tuning algorithm, Lipsum-FT, that effectively utilizes the language modeling aspect of the vision-language pre-trained models. Extensive experiments conducted on distribution shift scenarios in DomainNet and ImageNet confirm the superiority of our proposed Lipsum-FT approach over existing robust fine-tuning methods. ",
    "url": "https://arxiv.org/abs/2404.00860",
    "authors": [
      "Giung Nam",
      "Byeongho Heo",
      "Juho Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00862",
    "title": "Bailong: Bilingual Transfer Learning based on QLoRA and Zip-tie  Embedding",
    "abstract": "Large language models (LLMs) have demonstrated exceptional performance in various NLP applications. However, the majority of existing open-source LLMs are pre-trained primarily on English data and little part of other languages. This deficiency in multilingual training data results in suboptimal performance when applied to languages with fewer available resources. Furthermore, enhancing the performance of LLMs on low-resource languages by full-parameter fine-tuning with additional data requires substantial computational resources, posing computational barriers for research organizations and individual researchers. Consequently, several techniques such as parameter-efficient tuning and advanced embedding initialization have been proposed to address these challenges. In this work, we combine them to facilitate cross-lingual transfer on English-dominated open-source LLM. To effectively enhance the model's proficiency in Traditional Chinese, we conduct secondary pre-training on Llama 2 7B with Traditional Chinese data by leveraging QLoRA and our proposed zip-tie embedding initialization. The resulting model called Bailong, which stands for Bilingual trAnsfer learnIng based on qLOra and zip-tie embeddiNG. We present Bailong-instruct 7B, a fine-tuned version of Bailong 7B optimized for multi-turn dialogue scenarios. Recognizing the inadequacy of benchmark datasets in Traditional Chinese, we further introduce Bailong-bench to assess the alignment of models with human preferences and the capability to follow instructions in both Traditional Chinese and English tasks. In our evaluation, Bailong-instruct 7B exhibits competitive performance on Bailong-bench and other benchmark datasets when compared to other open-source models of similar or even larger parameter sizes. Bailong-instruct 7B and Bailong-bench are publicly available with the aim of empowering the community to build upon our efforts. ",
    "url": "https://arxiv.org/abs/2404.00862",
    "authors": [
      "Lung-Chuan Chen",
      "Zong-Ru Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00880",
    "title": "Rethinking the Relationship between Recurrent and Non-Recurrent Neural  Networks: A Study in Sparsity",
    "abstract": "Neural networks (NN) can be divided into two broad categories, recurrent and non-recurrent. Both types of neural networks are popular and extensively studied, but they are often treated as distinct families of machine learning algorithms. In this position paper, we argue that there is a closer relationship between these two types of neural networks than is normally appreciated. We show that many common neural network models, such as Recurrent Neural Networks (RNN), Multi-Layer Perceptrons (MLP), and even deep multi-layer transformers, can all be represented as iterative maps. The close relationship between RNNs and other types of NNs should not be surprising. In particular, RNNs are known to be Turing complete, and therefore capable of representing any computable function (such as any other types of NNs), but herein we argue that the relationship runs deeper and is more practical than this. For example, RNNs are often thought to be more difficult to train than other types of NNs, with RNNs being plagued by issues such as vanishing or exploding gradients. However, as we demonstrate in this paper, MLPs, RNNs, and many other NNs lie on a continuum, and this perspective leads to several insights that illuminate both theoretical and practical aspects of NNs. ",
    "url": "https://arxiv.org/abs/2404.00880",
    "authors": [
      "Quincy Hershey",
      "Randy Paffenroth",
      "Harsh Pathak",
      "Simon Tavener"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00883",
    "title": "Interpretable Multi-View Clustering Based on Anchor Graph Tensor  Factorization",
    "abstract": "The clustering method based on the anchor graph has gained significant attention due to its exceptional clustering performance and ability to process large-scale data. One common approach is to learn bipartite graphs with K-connected components, helping avoid the need for post-processing. However, this method has strict parameter requirements and may not always get K-connected components. To address this issue, an alternative approach is to directly obtain the cluster label matrix by performing non-negative matrix factorization (NMF) on the anchor graph. Nevertheless, existing multi-view clustering methods based on anchor graph factorization lack adequate cluster interpretability for the decomposed matrix and often overlook the inter-view information. We address this limitation by using non-negative tensor factorization to decompose an anchor graph tensor that combines anchor graphs from multiple views. This approach allows us to consider inter-view information comprehensively. The decomposed tensors, namely the sample indicator tensor and the anchor indicator tensor, enhance the interpretability of the factorization. Extensive experiments validate the effectiveness of this method. ",
    "url": "https://arxiv.org/abs/2404.00883",
    "authors": [
      "Jing Li",
      "Quanxue Gao",
      "Cheng Deng",
      "Qianqian Wang",
      "Ming Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00893",
    "title": "An Integrating Comprehensive Trajectory Prediction with Risk Potential  Field Method for Autonomous Driving",
    "abstract": "Due to the uncertainty of traffic participants' intentions, generating safe but not overly cautious behavior in interactive driving scenarios remains a formidable challenge for autonomous driving. In this paper, we address this issue by combining a deep learning-based trajectory prediction model with risk potential field-based motion planning. In order to comprehensively predict the possible future trajectories of other vehicles, we propose a target-region based trajectory prediction model(TRTP) which considers every region a vehicle may arrive in the future. After that, we construct a risk potential field at each future time step based on the prediction results of TRTP, and integrate risk value to the objective function of Model Predictive Contouring Control(MPCC). This enables the uncertainty of other vehicles to be taken into account during the planning process. Balancing between risk and progress along the reference path can achieve both driving safety and efficiency at the same time. We also demonstrate the security and effectiveness performance of our method in the CARLA simulator. ",
    "url": "https://arxiv.org/abs/2404.00893",
    "authors": [
      "Kailu Wu",
      "Xing Liu",
      "Feiyu Bian",
      "Yizhai Zhang",
      "Panfeng Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.00898",
    "title": "CAAP: Class-Dependent Automatic Data Augmentation Based On Adaptive  Policies For Time Series",
    "abstract": "Data Augmentation is a common technique used to enhance the performance of deep learning models by expanding the training dataset. Automatic Data Augmentation (ADA) methods are getting popular because of their capacity to generate policies for various datasets. However, existing ADA methods primarily focused on overall performance improvement, neglecting the problem of class-dependent bias that leads to performance reduction in specific classes. This bias poses significant challenges when deploying models in real-world applications. Furthermore, ADA for time series remains an underexplored domain, highlighting the need for advancements in this field. In particular, applying ADA techniques to vital signals like an electrocardiogram (ECG) is a compelling example due to its potential in medical domains such as heart disease diagnostics. We propose a novel deep learning-based approach called Class-dependent Automatic Adaptive Policies (CAAP) framework to overcome the notable class-dependent bias problem while maintaining the overall improvement in time-series data augmentation. Specifically, we utilize the policy network to generate effective sample-wise policies with balanced difficulty through class and feature information extraction. Second, we design the augmentation probability regulation method to minimize class-dependent bias. Third, we introduce the information region concepts into the ADA framework to preserve essential regions in the sample. Through a series of experiments on real-world ECG datasets, we demonstrate that CAAP outperforms representative methods in achieving lower class-dependent bias combined with superior overall performance. These results highlight the reliability of CAAP as a promising ADA method for time series modeling that fits for the demands of real-world applications. ",
    "url": "https://arxiv.org/abs/2404.00898",
    "authors": [
      "Tien-Yu Chang",
      "Hao Dai",
      "Vincent S. Tseng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00899",
    "title": "TM-TREK at SemEval-2024 Task 8: Towards LLM-Based Automatic Boundary  Detection for Human-Machine Mixed Text",
    "abstract": "With the increasing prevalence of text generated by large language models (LLMs), there is a growing concern about distinguishing between LLM-generated and human-written texts in order to prevent the misuse of LLMs, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content. This paper explores LLMs' ability to identify boundaries in human-written and machine-generated mixed texts. We approach this task by transforming it into a token classification problem and regard the label turning point as the boundary. Notably, our ensemble model of LLMs achieved first place in the 'Human-Machine Mixed Text Detection' sub-task of the SemEval'24 Competition Task 8. Additionally, we investigate factors that influence the capability of LLMs in detecting boundaries within mixed texts, including the incorporation of extra layers on top of LLMs, combination of segmentation loss, and the impact of pretraining. Our findings aim to provide valuable insights for future research in this area. ",
    "url": "https://arxiv.org/abs/2404.00899",
    "authors": [
      "Xiaoyan Qu",
      "Xiangfeng Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.00904",
    "title": "A Fast Percolation-Dijkstra Routing Method for Mega-Constellation  Backbone Network",
    "abstract": "The real-time routing for satellite communication of the mega-constellations is being challenged due to the large-scale of network nodes, especially on devices with limited computation such as onboard embedded systems. In this paper, a fast routing method is proposed for mega-constellation backbone networks. Firstly, inspired by the regularity and sparse characteristics of mega-constellations, the 4-degree percolation theory is proposed to describe the node search process. Then, dynamic minimum search and mapping methods are used to narrow down the traversal range. The proposed method performs as well as the heap-optimized Dijkstra algorithm with less memory space and dynamic access. The experimental results show that the method proposed in this paper can significantly reduce routing computation time, especially on the onboard, edge-computing or other computation-limited devices. ",
    "url": "https://arxiv.org/abs/2404.00904",
    "authors": [
      "Shenshen Luan",
      "Luyuan Wang",
      "Yepeng Liu",
      "Ninghan Sun",
      "Ran Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.00906",
    "title": "From Pixels to Graphs: Open-Vocabulary Scene Graph Generation with  Vision-Language Models",
    "abstract": "Scene graph generation (SGG) aims to parse a visual scene into an intermediate graph representation for downstream reasoning tasks. Despite recent advancements, existing methods struggle to generate scene graphs with novel visual relation concepts. To address this challenge, we introduce a new open-vocabulary SGG framework based on sequence generation. Our framework leverages vision-language pre-trained models (VLM) by incorporating an image-to-graph generation paradigm. Specifically, we generate scene graph sequences via image-to-text generation with VLM and then construct scene graphs from these sequences. By doing so, we harness the strong capabilities of VLM for open-vocabulary SGG and seamlessly integrate explicit relational modeling for enhancing the VL tasks. Experimental results demonstrate that our design not only achieves superior performance with an open vocabulary but also enhances downstream vision-language task performance through explicit relation modeling knowledge. ",
    "url": "https://arxiv.org/abs/2404.00906",
    "authors": [
      "Rongjie Li",
      "Songyang Zhang",
      "Dahua Lin",
      "Kai Chen",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00916",
    "title": "Gyro-based Neural Single Image Deblurring",
    "abstract": "In this paper, we present GyroDeblurNet, a novel single image deblurring method that utilizes a gyro sensor to effectively resolve the ill-posedness of image deblurring. The gyro sensor provides valuable information about camera motion during exposure time that can significantly improve deblurring quality. However, effectively exploiting real-world gyro data is challenging due to significant errors from various sources including sensor noise, the disparity between the positions of a camera module and a gyro sensor, the absence of translational motion information, and moving objects whose motions cannot be captured by a gyro sensor. To handle gyro error, GyroDeblurNet is equipped with two novel neural network blocks: a gyro refinement block and a gyro deblurring block. The gyro refinement block refines the error-ridden gyro data using the blur information from the input image. On the other hand, the gyro deblurring block removes blur from the input image using the refined gyro data and further compensates for gyro error by leveraging the blur information from the input image. For training a neural network with erroneous gyro data, we propose a training strategy based on the curriculum learning. We also introduce a novel gyro data embedding scheme to represent real-world intricate camera shakes. Finally, we present a synthetic dataset and a real dataset for the training and evaluation of gyro-based single image deblurring. Our experiments demonstrate that our approach achieves state-of-the-art deblurring quality by effectively utilizing erroneous gyro data. ",
    "url": "https://arxiv.org/abs/2404.00916",
    "authors": [
      "Heemin Yang",
      "Jaesung Rim",
      "Seung-Hwan Baek",
      "Sunghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00924",
    "title": "BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise  Regression Tasks",
    "abstract": "Pixel-wise regression tasks (e.g., monocular depth estimation (MDE) and optical flow estimation (OFE)) have been widely involved in our daily life in applications like autonomous driving, augmented reality and video composition. Although certain applications are security-critical or bear societal significance, the adversarial robustness of such models are not sufficiently studied, especially in the black-box scenario. In this work, we introduce the first unified black-box adversarial patch attack framework against pixel-wise regression tasks, aiming to identify the vulnerabilities of these models under query-based black-box attacks. We propose a novel square-based adversarial patch optimization framework and employ probabilistic square sampling and score-based gradient estimation techniques to generate the patch effectively and efficiently, overcoming the scalability problem of previous black-box patch attacks. Our attack prototype, named BadPart, is evaluated on both MDE and OFE tasks, utilizing a total of 7 models. BadPart surpasses 3 baseline methods in terms of both attack performance and efficiency. We also apply BadPart on the Google online service for portrait depth estimation, causing 43.5% relative distance error with 50K queries. State-of-the-art (SOTA) countermeasures cannot defend our attack effectively. ",
    "url": "https://arxiv.org/abs/2404.00924",
    "authors": [
      "Zhiyuan Cheng",
      "Zhaoyi Liu",
      "Tengda Guo",
      "Shiwei Feng",
      "Dongfang Liu",
      "Mingjie Tang",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00931",
    "title": "GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields",
    "abstract": "Recent advancements in vision-language foundation models have significantly enhanced open-vocabulary 3D scene understanding. However, the generalizability of existing methods is constrained due to their framework designs and their reliance on 3D data. We address this limitation by introducing Generalizable Open-Vocabulary Neural Semantic Fields (GOV-NeSF), a novel approach offering a generalizable implicit representation of 3D scenes with open-vocabulary semantics. We aggregate the geometry-aware features using a cost volume, and propose a Multi-view Joint Fusion module to aggregate multi-view features through a cross-view attention mechanism, which effectively predicts view-specific blending weights for both colors and open-vocabulary features. Remarkably, our GOV-NeSF exhibits state-of-the-art performance in both 2D and 3D open-vocabulary semantic segmentation, eliminating the need for ground truth semantic labels or depth priors, and effectively generalize across scenes and datasets without fine-tuning. ",
    "url": "https://arxiv.org/abs/2404.00931",
    "authors": [
      "Yunsong Wang",
      "Hanlin Chen",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00942",
    "title": "Evaluating the Factuality of Large Language Models using Large-Scale  Knowledge Graphs",
    "abstract": "The advent of Large Language Models (LLMs) has significantly transformed the AI landscape, enhancing machine learning and AI capabilities. Factuality issue is a critical concern for LLMs, as they may generate factually incorrect responses. In this paper, we propose GraphEval to evaluate an LLM's performance using a substantially large test dataset. Specifically, the test dataset is retrieved from a large knowledge graph with more than 10 million facts without expensive human efforts. Unlike conventional methods that evaluate LLMs based on generated responses, GraphEval streamlines the evaluation process by creating a judge model to estimate the correctness of the answers given by the LLM. Our experiments demonstrate that the judge model's factuality assessment aligns closely with the correctness of the LLM's generated outputs, while also substantially reducing evaluation costs. Besides, our findings offer valuable insights into LLM performance across different metrics and highlight the potential for future improvements in ensuring the factual integrity of LLM outputs. The code is publicly available at https://github.com/xz-liu/GraphEval. ",
    "url": "https://arxiv.org/abs/2404.00942",
    "authors": [
      "Xiaoze Liu",
      "Feijie Wu",
      "Tianyang Xu",
      "Zhuo Chen",
      "Yichi Zhang",
      "Xiaoqian Wang",
      "Jing Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00964",
    "title": "S2RC-GCN: A Spatial-Spectral Reliable Contrastive Graph Convolutional  Network for Complex Land Cover Classification Using Hyperspectral Images",
    "abstract": "Spatial correlations between different ground objects are an important feature of mining land cover research. Graph Convolutional Networks (GCNs) can effectively capture such spatial feature representations and have demonstrated promising results in performing hyperspectral imagery (HSI) classification tasks of complex land. However, the existing GCN-based HSI classification methods are prone to interference from redundant information when extracting complex features. To classify complex scenes more effectively, this study proposes a novel spatial-spectral reliable contrastive graph convolutional classification framework named S2RC-GCN. Specifically, we fused the spectral and spatial features extracted by the 1D- and 2D-encoder, and the 2D-encoder includes an attention model to automatically extract important information. We then leveraged the fused high-level features to construct graphs and fed the resulting graphs into the GCNs to determine more effective graph representations. Furthermore, a novel reliable contrastive graph convolution was proposed for reliable contrastive learning to learn and fuse robust features. Finally, to test the performance of the model on complex object classification, we used imagery taken by Gaofen-5 in the Jiang Xia area to construct complex land cover datasets. The test results show that compared with other models, our model achieved the best results and effectively improved the classification performance of complex remote sensing imagery. ",
    "url": "https://arxiv.org/abs/2404.00964",
    "authors": [
      "Renxiang Guan",
      "Zihao Li",
      "Chujia Song",
      "Guo Yu",
      "Xianju Li",
      "Ruyi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00971",
    "title": "Exploring and Evaluating Hallucinations in LLM-Powered Code Generation",
    "abstract": "The rise of Large Language Models (LLMs) has significantly advanced many applications on software engineering tasks, particularly in code generation. Despite the promising performance, LLMs are prone to generate hallucinations, which means LLMs might produce outputs that deviate from users' intent, exhibit internal inconsistencies, or misalign with the factual knowledge, making the deployment of LLMs potentially risky in a wide range of applications. Existing work mainly focuses on investing the hallucination in the domain of natural language generation (NLG), leaving a gap in understanding the types and extent of hallucinations in the context of code generation. To bridge the gap, we conducted a thematic analysis of the LLM-generated code to summarize and categorize the hallucinations present in it. Our study established a comprehensive taxonomy of hallucinations in LLM-generated code, encompassing 5 primary categories of hallucinations depending on the conflicting objectives and varying degrees of deviation observed in code generation. Furthermore, we systematically analyzed the distribution of hallucinations, exploring variations among different LLMs and their correlation with code correctness. Based on the results, we proposed HalluCode, a benchmark for evaluating the performance of code LLMs in recognizing hallucinations. Hallucination recognition and mitigation experiments with HalluCode and HumanEval show existing LLMs face great challenges in recognizing hallucinations, particularly in identifying their types, and are hardly able to mitigate hallucinations. We believe our findings will shed light on future research about hallucination evaluation, detection, and mitigation, ultimately paving the way for building more effective and reliable code LLMs in the future. ",
    "url": "https://arxiv.org/abs/2404.00971",
    "authors": [
      "Fang Liu",
      "Yang Liu",
      "Lin Shi",
      "Houkun Huang",
      "Ruifeng Wang",
      "Zhen Yang",
      "Li Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.00992",
    "title": "SGCNeRF: Few-Shot Neural Rendering via Sparse Geometric Consistency  Guidance",
    "abstract": "Neural Radiance Field (NeRF) technology has made significant strides in creating novel viewpoints. However, its effectiveness is hampered when working with sparsely available views, often leading to performance dips due to overfitting. FreeNeRF attempts to overcome this limitation by integrating implicit geometry regularization, which incrementally improves both geometry and textures. Nonetheless, an initial low positional encoding bandwidth results in the exclusion of high-frequency elements. The quest for a holistic approach that simultaneously addresses overfitting and the preservation of high-frequency details remains ongoing. This study introduces a novel feature matching based sparse geometry regularization module. This module excels in pinpointing high-frequency keypoints, thereby safeguarding the integrity of fine details. Through progressive refinement of geometry and textures across NeRF iterations, we unveil an effective few-shot neural rendering architecture, designated as SGCNeRF, for enhanced novel view synthesis. Our experiments demonstrate that SGCNeRF not only achieves superior geometry-consistent outcomes but also surpasses FreeNeRF, with improvements of 0.7 dB and 0.6 dB in PSNR on the LLFF and DTU datasets, respectively. ",
    "url": "https://arxiv.org/abs/2404.00992",
    "authors": [
      "Yuru Xiao",
      "Xianming Liu",
      "Deming Zhai",
      "Kui Jiang",
      "Junjun Jiang",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01012",
    "title": "Query Performance Prediction using Relevance Judgments Generated by  Large Language Models",
    "abstract": "Query performance prediction (QPP) aims to estimate the retrieval quality of a search system for a query without human relevance judgments. Previous QPP methods typically return a single scalar value and do not require the predicted values to approximate a specific information retrieval (IR) evaluation measure, leading to certain drawbacks: (i) a single scalar is insufficient to accurately represent different IR evaluation measures, especially when metrics do not highly correlate, and (ii) a single scalar limits the interpretability of QPP methods because solely using a scalar is insufficient to explain QPP results. To address these issues, we propose a QPP framework using automatically generated relevance judgments (QPP-GenRE), which decomposes QPP into independent subtasks of judging the relevance of each item in a ranked list to a given query. This allows us to predict any IR evaluation measure using the generated relevance judgments as pseudo-labels; Also, this allows us to interpret predicted IR evaluation measures, and identify, track and rectify errors in generated relevance judgments to improve QPP quality. We judge relevance by leveraging a leading open-source large language model (LLM), LLaMA, to ensure scientific reproducibility. In doing so, we address two main challenges: (i) excessive computational costs of judging the entire corpus for predicting a recall-based metric, and (ii) poor performance in prompting LLaMA in a zero-/few-shot manner. We devise an approximation strategy to predict a recall-oriented IR measure and propose to fine-tune LLaMA using human-labeled relevance judgments. Experiments on the TREC 2019-2022 deep learning tracks show that QPP-GenRE achieves state-of-the-art QPP accuracy for both lexical and neural rankers in both precision- and recall-oriented metrics. ",
    "url": "https://arxiv.org/abs/2404.01012",
    "authors": [
      "Chuan Meng",
      "Negar Arabzadeh",
      "Arian Askari",
      "Mohammad Aliannejadi",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01014",
    "title": "Harnessing Large Language Models for Training-free Video Anomaly  Detection",
    "abstract": "Video anomaly detection (VAD) aims to temporally locate abnormal events in a video. Existing works mostly rely on training deep models to learn the distribution of normality with either video-level supervision, one-class supervision, or in an unsupervised setting. Training-based methods are prone to be domain-specific, thus being costly for practical deployment as any domain change will involve data collection and model training. In this paper, we radically depart from previous efforts and propose LAnguage-based VAD (LAVAD), a method tackling VAD in a novel, training-free paradigm, exploiting the capabilities of pre-trained large language models (LLMs) and existing vision-language models (VLMs). We leverage VLM-based captioning models to generate textual descriptions for each frame of any test video. With the textual scene description, we then devise a prompting mechanism to unlock the capability of LLMs in terms of temporal aggregation and anomaly score estimation, turning LLMs into an effective video anomaly detector. We further leverage modality-aligned VLMs and propose effective techniques based on cross-modal similarity for cleaning noisy captions and refining the LLM-based anomaly scores. We evaluate LAVAD on two large datasets featuring real-world surveillance scenarios (UCF-Crime and XD-Violence), showing that it outperforms both unsupervised and one-class methods without requiring any training or data collection. ",
    "url": "https://arxiv.org/abs/2404.01014",
    "authors": [
      "Luca Zanella",
      "Willi Menapace",
      "Massimiliano Mancini",
      "Yiming Wang",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01039",
    "title": "A Survey on Hypergraph Neural Networks: An In-Depth and Step-By-Step  Guide",
    "abstract": "Higher-order interactions (HOIs) are ubiquitous in real-world complex systems and applications, and thus investigation of deep learning for HOIs has become a valuable agenda for the data mining and machine learning communities. As networks of HOIs are expressed mathematically as hypergraphs, hypergraph neural networks (HNNs) have emerged as a powerful tool for representation learning on hypergraphs. Given the emerging trend, we present the first survey dedicated to HNNs, with an in-depth and step-by-step guide. Broadly, the present survey overviews HNN architectures, training strategies, and applications. First, we break existing HNNs down into four design components: (i) input features, (ii) input structures, (iii) message-passing schemes, and (iv) training strategies. Second, we examine how HNNs address and learn HOIs with each of their components. Third, we overview the recent applications of HNNs in recommendation, biological and medical science, time series analysis, and computer vision. Lastly, we conclude with a discussion on limitations and future directions. ",
    "url": "https://arxiv.org/abs/2404.01039",
    "authors": [
      "Sunwoo Kim",
      "Soo Yong Lee",
      "Yue Gao",
      "Alessia Antelmi",
      "Mirko Polato",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01051",
    "title": "Action Detection via an Image Diffusion Process",
    "abstract": "Action detection aims to localize the starting and ending points of action instances in untrimmed videos, and predict the classes of those instances. In this paper, we make the observation that the outputs of the action detection task can be formulated as images. Thus, from a novel perspective, we tackle action detection via a three-image generation process to generate starting point, ending point and action-class predictions as images via our proposed Action Detection Image Diffusion (ADI-Diff) framework. Furthermore, since our images differ from natural images and exhibit special properties, we further explore a Discrete Action-Detection Diffusion Process and a Row-Column Transformer design to better handle their processing. Our ADI-Diff framework achieves state-of-the-art results on two widely-used datasets. ",
    "url": "https://arxiv.org/abs/2404.01051",
    "authors": [
      "Lin Geng Foo",
      "Tianjiao Li",
      "Hossein Rahmani",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01058",
    "title": "A Novel Audio Representation for Music Genre Identification in MIR",
    "abstract": "For Music Information Retrieval downstream tasks, the most common audio representation is time-frequency-based, such as Mel spectrograms. In order to identify musical genres, this study explores the possibilities of a new form of audio representation one of the most usual MIR downstream tasks. Therefore, to discretely encoding music using deep vector quantization; a novel audio representation was created for the innovative generative music model i.e. Jukebox. The effectiveness of Jukebox's audio representation is compared to Mel spectrograms using a dataset that is almost equivalent to State-of-the-Art (SOTA) and an almost same transformer design. The results of this study imply that, at least when the transformers are pretrained using a very modest dataset of 20k tracks, Jukebox's audio representation is not superior to Mel spectrograms. This could be explained by the fact that Jukebox's audio representation does not sufficiently take into account the peculiarities of human hearing perception. On the other hand, Mel spectrograms are specifically created with the human auditory sense in mind. ",
    "url": "https://arxiv.org/abs/2404.01058",
    "authors": [
      "Navin Kamuni",
      "Mayank Jindal",
      "Arpita Soni",
      "Sukender Reddy Mallreddy",
      "Sharath Chandra Macha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2404.01060",
    "title": "A comparison of Single- and Double-generator formalisms for  Thermodynamics-Informed Neural Networks",
    "abstract": "The development of inductive biases has been shown to be a very effective way to increase the accuracy and robustness of neural networks, particularly when they are used to predict physical phenomena. These biases significantly increase the certainty of predictions, decrease the error made and allow considerably smaller datasets to be used. There are a multitude of methods in the literature to develop these biases. One of the most effective ways, when dealing with physical phenomena, is to introduce physical principles of recognised validity into the network architecture. The problem becomes more complex without knowledge of the physical principles governing the phenomena under study. A very interesting possibility then is to turn to the principles of thermodynamics, which are universally valid, regardless of the level of abstraction of the description sought for the phenomenon under study. To ensure compliance with the principles of thermodynamics, there are formulations that have a long tradition in many branches of science. In the field of rheology, for example, two main types of formalisms are used to ensure compliance with these principles: one-generator and two-generator formalisms. In this paper we study the advantages and disadvantages of each, using classical problems with known solutions and synthetic data. ",
    "url": "https://arxiv.org/abs/2404.01060",
    "authors": [
      "Pau Urdeitx",
      "Ic\u00edar Alfaro",
      "David Gonz\u00e1lez",
      "Francisco Chinesta",
      "El\u00edas Cueto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01064",
    "title": "Roadside Monocular 3D Detection via 2D Detection Prompting",
    "abstract": "The problem of roadside monocular 3D detection requires detecting objects of interested classes in a 2D RGB frame and predicting their 3D information such as locations in bird's-eye-view (BEV). It has broad applications in traffic control, vehicle-vehicle communication, and vehicle-infrastructure cooperative perception. To approach this problem, we present a novel and simple method by prompting the 3D detector using 2D detections. Our method builds on a key insight that, compared with 3D detectors, a 2D detector is much easier to train and performs significantly better w.r.t detections on the 2D image plane. That said, one can exploit 2D detections of a well-trained 2D detector as prompts to a 3D detector, being trained in a way of inflating such 2D detections to 3D towards 3D detection. To construct better prompts using the 2D detector, we explore three techniques: (a) concatenating both 2D and 3D detectors' features, (b) attentively fusing 2D and 3D detectors' features, and (c) encoding predicted 2D boxes x, y, width, height, label and attentively fusing such with the 3D detector's features. Surprisingly, the third performs the best. Moreover, we present a yaw tuning tactic and a class-grouping strategy that merges classes based on their functionality; these techniques improve 3D detection performance further. Comprehensive ablation studies and extensive experiments demonstrate that our method resoundingly outperforms prior works, achieving the state-of-the-art on two large-scale roadside 3D detection benchmarks. ",
    "url": "https://arxiv.org/abs/2404.01064",
    "authors": [
      "Yechi Ma",
      "Shuoquan Wei",
      "Churun Zhang",
      "Wei Hua",
      "Yanan Li",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01070",
    "title": "Advancing AI with Integrity: Ethical Challenges and Solutions in Neural  Machine Translation",
    "abstract": "This paper addresses the ethical challenges of Artificial Intelligence in Neural Machine Translation (NMT) systems, emphasizing the imperative for developers to ensure fairness and cultural sensitivity. We investigate the ethical competence of AI models in NMT, examining the Ethical considerations at each stage of NMT development, including data handling, privacy, data ownership, and consent. We identify and address ethical issues through empirical studies. These include employing Transformer models for Luganda-English translations and enhancing efficiency with sentence mini-batching. And complementary studies that refine data labeling techniques and fine-tune BERT and Longformer models for analyzing Luganda and English social media content. Our second approach is a literature review from databases such as Google Scholar and platforms like GitHub. Additionally, the paper probes the distribution of responsibility between AI systems and humans, underscoring the essential role of human oversight in upholding NMT ethical standards. Incorporating a biblical perspective, we discuss the societal impact of NMT and the broader ethical responsibilities of developers, positing them as stewards accountable for the societal repercussions of their creations. ",
    "url": "https://arxiv.org/abs/2404.01070",
    "authors": [
      "Richard Kimera",
      "Yun-Seon Kim",
      "Heeyoul Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.01074",
    "title": "Prompt Learning for Oriented Power Transmission Tower Detection in  High-Resolution SAR Images",
    "abstract": "Detecting transmission towers from synthetic aperture radar (SAR) images remains a challenging task due to the comparatively small size and side-looking geometry, with background clutter interference frequently hindering tower identification. A large number of interfering signals superimposes the return signal from the tower. We found that localizing or prompting positions of power transmission towers is beneficial to address this obstacle. Based on this revelation, this paper introduces prompt learning into the oriented object detector (P2Det) for multimodal information learning. P2Det contains the sparse prompt coding and cross-attention between the multimodal data. Specifically, the sparse prompt encoder (SPE) is proposed to represent point locations, converting prompts into sparse embeddings. The image embeddings are generated through the Transformer layers. Then a two-way fusion module (TWFM) is proposed to calculate the cross-attention of the two different embeddings. The interaction of image-level and prompt-level features is utilized to address the clutter interference. A shape-adaptive refinement module (SARM) is proposed to reduce the effect of aspect ratio. Extensive experiments demonstrated the effectiveness of the proposed model on high-resolution SAR images. P2Det provides a novel insight for multimodal object detection due to its competitive performance. ",
    "url": "https://arxiv.org/abs/2404.01074",
    "authors": [
      "Tianyang Li",
      "Chao Wang",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01094",
    "title": "HairFastGAN: Realistic and Robust Hair Transfer with a Fast  Encoder-Based Approach",
    "abstract": "Our paper addresses the complex task of transferring a hairstyle from a reference image to an input photo for virtual hair try-on. This task is challenging due to the need to adapt to various photo poses, the sensitivity of hairstyles, and the lack of objective metrics. The current state of the art hairstyle transfer methods use an optimization process for different parts of the approach, making them inexcusably slow. At the same time, faster encoder-based models are of very low quality because they either operate in StyleGAN's W+ space or use other low-dimensional image generators. Additionally, both approaches have a problem with hairstyle transfer when the source pose is very different from the target pose, because they either don't consider the pose at all or deal with it inefficiently. In our paper, we present the HairFast model, which uniquely solves these problems and achieves high resolution, near real-time performance, and superior reconstruction compared to optimization problem-based methods. Our solution includes a new architecture operating in the FS latent space of StyleGAN, an enhanced inpainting approach, and improved encoders for better alignment, color transfer, and a new encoder for post-processing. The effectiveness of our approach is demonstrated on realism metrics after random hairstyle transfer and reconstruction when the original hairstyle is transferred. In the most difficult scenario of transferring both shape and color of a hairstyle from different images, our method performs in less than a second on the Nvidia V100. Our code is available at https://github.com/AIRI-Institute/HairFastGAN. ",
    "url": "https://arxiv.org/abs/2404.01094",
    "authors": [
      "Maxim Nikolaev",
      "Mikhail Kuznetsov",
      "Dmitry Vetrov",
      "Aibek Alanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01101",
    "title": "UFID: A Unified Framework for Input-level Backdoor Detection on  Diffusion Models",
    "abstract": "Diffusion Models are vulnerable to backdoor attacks, where malicious attackers inject backdoors by poisoning some parts of the training samples during the training stage. This poses a serious threat to the downstream users, who query the diffusion models through the API or directly download them from the internet. To mitigate the threat of backdoor attacks, there have been a plethora of investigations on backdoor detections. However, none of them designed a specialized backdoor detection method for diffusion models, rendering the area much under-explored. Moreover, these prior methods mainly focus on the traditional neural networks in the classification task, which cannot be adapted to the backdoor detections on the generative task easily. Additionally, most of the prior methods require white-box access to model weights and architectures, or the probability logits as additional information, which are not always practical. In this paper, we propose a Unified Framework for Input-level backdoor Detection (UFID) on the diffusion models, which is motivated by observations in the diffusion models and further validated with a theoretical causality analysis. Extensive experiments across different datasets on both conditional and unconditional diffusion models show that our method achieves a superb performance on detection effectiveness and run-time efficiency. The code is available at https://github.com/GuanZihan/official_UFID. ",
    "url": "https://arxiv.org/abs/2404.01101",
    "authors": [
      "Zihan Guan",
      "Mengxuan Hu",
      "Sheng Li",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01104",
    "title": "SentiCSE: A Sentiment-aware Contrastive Sentence Embedding Framework  with Sentiment-guided Textual Similarity",
    "abstract": "Recently, sentiment-aware pre-trained language models (PLMs) demonstrate impressive results in downstream sentiment analysis tasks. However, they neglect to evaluate the quality of their constructed sentiment representations; they just focus on improving the fine-tuning performance, which overshadows the representation quality. We argue that without guaranteeing the representation quality, their downstream performance can be highly dependent on the supervision of the fine-tuning data rather than representation quality. This problem would make them difficult to foray into other sentiment-related domains, especially where labeled data is scarce. We first propose Sentiment-guided Textual Similarity (SgTS), a novel metric for evaluating the quality of sentiment representations, which is designed based on the degree of equivalence in sentiment polarity between two sentences. We then propose SentiCSE, a novel Sentiment-aware Contrastive Sentence Embedding framework for constructing sentiment representations via combined word-level and sentence-level objectives, whose quality is guaranteed by SgTS. Qualitative and quantitative comparison with the previous sentiment-aware PLMs shows the superiority of our work. Our code is available at: https://github.com/nayohan/SentiCSE ",
    "url": "https://arxiv.org/abs/2404.01104",
    "authors": [
      "Jaemin Kim",
      "Yohan Na",
      "Kangmin Kim",
      "Sang Rak Lee",
      "Dong-Kyu Chae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.01106",
    "title": "MagLive: Near-Field Magnetic Sensing-Based Voice Liveness Detection on  Smartphones",
    "abstract": "Voice authentication has been widely used on smartphones. However, it remains vulnerable to spoofing attacks, where the attacker replays recorded voice samples from authentic humans using loudspeakers to bypass the voice authentication system. In this paper, we present MagLive, a robust voice liveness detection scheme designed for smartphones to mitigate such spoofing attacks. MagLive leverages differences in magnetic field patterns generated by different speakers (i.e., humans or loudspeakers) when speaking for liveness detection. It uses the built-in magnetometer on smartphones to capture these magnetic field changes. Specifically, MagLive utilizes two CNN-based submodels and a self-attention-based feature fusion model to extract effective and robust features. Supervised contrastive learning is then employed to achieve user-irrelevance, device-irrelevance, and content-irrelevance. MagLive imposes no additional burdens on users and does not rely on active sensing or extra devices. We conducted comprehensive experiments with various settings to evaluate the security and robustness of MagLive. Our results demonstrate that MagLive effectively distinguishes between humans and attackers (i.e., loudspeakers), achieving a balanced accuracy of 99.01% and an equal error rate of 0.77%. ",
    "url": "https://arxiv.org/abs/2404.01106",
    "authors": [
      "Xiping Sun",
      "Jing Chen",
      "Cong Wu",
      "Kun He",
      "Haozhe Xu",
      "Yebo Feng",
      "Ruiying Du",
      "Xianhao Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.01109",
    "title": "An incremental hybrid adaptive network-based IDS in Software Defined  Networks to detect stealth attacks",
    "abstract": "Network attacks have became increasingly more sophisticated and stealthy due to the advances in technologies and the growing sophistication of attackers. Advanced Persistent Threats (APTs) are a type of attack that implement a wide range of strategies to evade detection and be under the defence radar. Software Defined Network (SDN) is a network paradigm that implements dynamic configuration by separating the control plane from the network plane. This approach improves security aspects by facilitating the employment of network intrusion detection systems. Implementing Machine Learning (ML) techniques in Intrusion Detection Systems (IDSs) is widely used to detect such attacks but has a challenge when the data distribution changes. Concept drift is a term that describes the change in the relationship between the input data and the target value (label or class). The model is expected to degrade as certain forms of change occur. In this paper, the primary form of change will be in user behaviour (particularly changes in attacker behaviour). It is essential for a model to adapt itself to deviations in data distribution. SDN can help in monitoring changes in data distribution. This paper discusses changes in stealth attacker behaviour. The work described here investigates various concept drift detection algorithms. An incremental hybrid adaptive Network Intrusion Detection System (NIDS) is proposed to tackle the issue of concept drift in SDN. It can detect known and unknown attacks. The model is evaluated over different datasets showing promising results. ",
    "url": "https://arxiv.org/abs/2404.01109",
    "authors": [
      "Abdullah H Alqahtani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.01114",
    "title": "A CRISP-DM-based Methodology for Assessing Agent-based Simulation Models  using Process Mining",
    "abstract": "Agent-based simulation (ABS) models are potent tools for analyzing complex systems. However, understanding and validating ABS models can be a significant challenge. To address this challenge, cutting-edge data-driven techniques offer sophisticated capabilities for analyzing the outcomes of ABS models. One such technique is process mining, which encompasses a range of methods for discovering, monitoring, and enhancing processes by extracting knowledge from event logs. However, applying process mining to event logs derived from ABSs is not trivial, and deriving meaningful insights from the resulting process models adds an additional layer of complexity. Although process mining is invaluable in extracting insights from ABS models, there is a lack of comprehensive methodological guidance for its application in ABS evaluation in the research landscape. In this paper, we propose a methodology, based on the CRoss-Industry Standard Process for Data Mining (CRISP-DM) methodology, to assess ABS models using process mining techniques. We incorporate process mining techniques into the stages of the CRISP-DM methodology, facilitating the analysis of ABS model behaviors and their underlying processes. We demonstrate our methodology using an established agent-based model, Schelling model of segregation. Our results show that our proposed methodology can effectively assess ABS models through produced event logs, potentially paving the way for enhanced agent-based model validity and more insightful decision-making. ",
    "url": "https://arxiv.org/abs/2404.01114",
    "authors": [
      "Rob H. Bemthuis",
      "Ruben R. Govers",
      "Amin Asadi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2404.01129",
    "title": "Structured Information Matters: Incorporating Abstract Meaning  Representation into LLMs for Improved Open-Domain Dialogue Evaluation",
    "abstract": "Automatic open-domain dialogue evaluation has attracted increasing attention. Trainable evaluation metrics are commonly trained with true positive and randomly selected negative responses, resulting in a tendency for them to assign a higher score to the responses that share higher content similarity with a given context. However, adversarial negative responses possess high content similarity with the contexts whilst being semantically different. Therefore, existing evaluation metrics are not robust enough to evaluate such responses, resulting in low correlations with human judgments. While recent studies have shown some efficacy in utilizing Large Language Models (LLMs) for open-domain dialogue evaluation, they still encounter challenges in effectively handling adversarial negative examples. In this paper, we propose a simple yet effective framework for open-domain dialogue evaluation, which combines domain-specific language models (SLMs) with LLMs. The SLMs can explicitly incorporate Abstract Meaning Representation (AMR) graph information of the dialogue through a gating mechanism for enhanced semantic representation learning. The evaluation result of SLMs and AMR graph information are plugged into the prompt of LLM, for the enhanced in-context learning performance. Experimental results on open-domain dialogue evaluation tasks demonstrate the superiority of our method compared to a wide range of state-of-the-art baselines, especially in discriminating adversarial negative responses. Our code is available at https://github.com/Bernard-Yang/SIMAMR. ",
    "url": "https://arxiv.org/abs/2404.01129",
    "authors": [
      "Bohao Yang",
      "Kun Zhao",
      "Chen Tang",
      "Liang Zhan",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.01131",
    "title": "GOV-REK: Governed Reward Engineering Kernels for Designing Robust  Multi-Agent Reinforcement Learning Systems",
    "abstract": "For multi-agent reinforcement learning systems (MARLS), the problem formulation generally involves investing massive reward engineering effort specific to a given problem. However, this effort often cannot be translated to other problems; worse, it gets wasted when system dynamics change drastically. This problem is further exacerbated in sparse reward scenarios, where a meaningful heuristic can assist in the policy convergence task. We propose GOVerned Reward Engineering Kernels (GOV-REK), which dynamically assign reward distributions to agents in MARLS during its learning stage. We also introduce governance kernels, which exploit the underlying structure in either state or joint action space for assigning meaningful agent reward distributions. During the agent learning stage, it iteratively explores different reward distribution configurations with a Hyperband-like algorithm to learn ideal agent reward models in a problem-agnostic manner. Our experiments demonstrate that our meaningful reward priors robustly jumpstart the learning process for effectively learning different MARL problems. ",
    "url": "https://arxiv.org/abs/2404.01131",
    "authors": [
      "Ashish Rana",
      "Michael Oesterle",
      "Jannik Brinkmann"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.01143",
    "title": "Condition-Aware Neural Network for Controlled Image Generation",
    "abstract": "We present Condition-Aware Neural Network (CAN), a new method for adding control to image generative models. In parallel to prior conditional control methods, CAN controls the image generation process by dynamically manipulating the weight of the neural network. This is achieved by introducing a condition-aware weight generation module that generates conditional weight for convolution/linear layers based on the input condition. We test CAN on class-conditional image generation on ImageNet and text-to-image generation on COCO. CAN consistently delivers significant improvements for diffusion transformer models, including DiT and UViT. In particular, CAN combined with EfficientViT (CaT) achieves 2.78 FID on ImageNet 512x512, surpassing DiT-XL/2 while requiring 52x fewer MACs per sampling step. ",
    "url": "https://arxiv.org/abs/2404.01143",
    "authors": [
      "Han Cai",
      "Muyang Li",
      "Zhuoyang Zhang",
      "Qinsheng Zhang",
      "Ming-Yu Liu",
      "Song Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.01148",
    "title": "Joint Beam Scheduling and Beamforming Design for Cooperative Positioning  in Multi-beam LEO Satellite Networks",
    "abstract": "Cooperative positioning with multiple low earth orbit (LEO) satellites is promising in providing location-based services and enhancing satellite-terrestrial communication. However, positioning accuracy is greatly affected by inter-beam interference and satellite-terrestrial topology geometry. To select the best combination of satellites from visible ones and suppress inter-beam interference, this paper explores the utilization of flexible beam scheduling and beamforming of multi-beam LEO satellites that can adjust beam directions toward the same earth-fixed cell to send positioning signals simultaneously. By leveraging Cram\\'{e}r-Rao lower bound (CRLB) to characterize user Time Difference of Arrival (TDOA) positioning accuracy, the concerned problem is formulated, aiming at optimizing user positioning accuracy under beam scheduling and beam transmission power constraints. To deal with the mixed-integer-nonconvex problem, we decompose it into an inner beamforming design problem and an outer beam scheduling problem. For the former, we first prove the monotonic relationship between user positioning accuracy and its perceived signal-to-interference-plus-noise ratio (SINR) to reformulate the problem, and then semidefinite relaxation (SDR) is adopted for beamforming design. For the outer problem, a heuristic low-complexity beam scheduling scheme is proposed, whose core idea is to schedule users with lower channel correlation to mitigate inter-beam interference while seeking a proper satellite-terrestrial topology geometry. Simulation results verify the superior positioning performance of our proposed positioning-oriented beamforming and beam scheduling scheme, and it is shown that average user positioning accuracy is improved by $17.1\\%$ and $55.9\\%$ when the beam transmission power is 20 dBw, compared to conventional beamforming and beam scheduling schemes, respectively. ",
    "url": "https://arxiv.org/abs/2404.01148",
    "authors": [
      "Hongtao Xv",
      "Yaohua Sun",
      "Yafei Zhao",
      "Mugen Peng",
      "Shijie Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.01154",
    "title": "Uncovering the Text Embedding in Text-to-Image Diffusion Models",
    "abstract": "The correspondence between input text and the generated image exhibits opacity, wherein minor textual modifications can induce substantial deviations in the generated image. While, text embedding, as the pivotal intermediary between text and images, remains relatively underexplored. In this paper, we address this research gap by delving into the text embedding space, unleashing its capacity for controllable image editing and explicable semantic direction attributes within a learning-free framework. Specifically, we identify two critical insights regarding the importance of per-word embedding and their contextual correlations within text embedding, providing instructive principles for learning-free image editing. Additionally, we find that text embedding inherently possesses diverse semantic potentials, and further reveal this property through the lens of singular value decomposition (SVD). These uncovered properties offer practical utility for image editing and semantic discovery. More importantly, we expect the in-depth analyses and findings of the text embedding can enhance the understanding of text-to-image diffusion models. ",
    "url": "https://arxiv.org/abs/2404.01154",
    "authors": [
      "Hu Yu",
      "Hao Luo",
      "Fan Wang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.01158",
    "title": "Dialogue with Robots: Proposals for Broadening Participation and  Research in the SLIVAR Community",
    "abstract": "The ability to interact with machines using natural human language is becoming not just commonplace, but expected. The next step is not just text interfaces, but speech interfaces and not just with computers, but with all machines including robots. In this paper, we chronicle the recent history of this growing field of spoken dialogue with robots and offer the community three proposals, the first focused on education, the second on benchmarks, and the third on the modeling of language when it comes to spoken interaction with robots. The three proposals should act as white papers for any researcher to take and build upon. ",
    "url": "https://arxiv.org/abs/2404.01158",
    "authors": [
      "Casey Kennington",
      "Malihe Alikhani",
      "Heather Pon-Barry",
      "Katherine Atwell",
      "Yonatan Bisk",
      "Daniel Fried",
      "Felix Gervits",
      "Zhao Han",
      "Mert Inan",
      "Michael Johnston",
      "Raj Korpan",
      "Diane Litman",
      "Matthew Marge",
      "Cynthia Matuszek",
      "Ross Mead",
      "Shiwali Mohan",
      "Raymond Mooney",
      "Natalie Parde",
      "Jivko Sinapov",
      "Angela Stewart",
      "Matthew Stone",
      "Stefanie Tellex",
      "Tom Williams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.01159",
    "title": "GPU-accelerated Evolutionary Multiobjective Optimization Using  Tensorized RVEA",
    "abstract": "Evolutionary multiobjective optimization has witnessed remarkable progress during the past decades. However, existing algorithms often encounter computational challenges in large-scale scenarios, primarily attributed to the absence of hardware acceleration. In response, we introduce a Tensorized Reference Vector Guided Evolutionary Algorithm (TensorRVEA) for harnessing the advancements of GPU acceleration. In TensorRVEA, the key data structures and operators are fully transformed into tensor forms for leveraging GPU-based parallel computing. In numerical benchmark tests involving large-scale populations and problem dimensions, TensorRVEA consistently demonstrates high computational performance, achieving up to over 1000$\\times$ speedups. Then, we applied TensorRVEA to the domain of multiobjective neuroevolution for addressing complex challenges in robotic control tasks. Furthermore, we assessed TensorRVEA's extensibility by altering several tensorized reproduction operators. Experimental results demonstrate promising scalability and robustness of TensorRVEA. Source codes are available at https://github.com/EMI-Group/tensorrvea. ",
    "url": "https://arxiv.org/abs/2404.01159",
    "authors": [
      "Zhenyu Liang",
      "Tao Jiang",
      "Kebin Sun",
      "Ran Cheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2404.01163",
    "title": "Capturing Shock Waves by Relaxation Neural Networks",
    "abstract": "In this paper, we put forward a neural network framework to solve the nonlinear hyperbolic systems. This framework, named relaxation neural networks(RelaxNN), is a simple and scalable extension of physics-informed neural networks(PINN). It is shown later that a typical PINN framework struggles to handle shock waves that arise in hyperbolic systems' solutions. This ultimately results in the failure of optimization that is based on gradient descent in the training process. Relaxation systems provide a smooth asymptotic to the discontinuity solution, under the expectation that macroscopic problems can be solved from a microscopic perspective. Based on relaxation systems, the RelaxNN framework alleviates the conflict of losses in the training process of the PINN framework. In addition to the remarkable results demonstrated in numerical simulations, most of the acceleration techniques and improvement strategies aimed at the standard PINN framework can also be applied to the RelaxNN framework. ",
    "url": "https://arxiv.org/abs/2404.01163",
    "authors": [
      "Nan Zhou",
      "Zheng Ma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.01177",
    "title": "Poisoning Decentralized Collaborative Recommender System and Its  Countermeasures",
    "abstract": "To make room for privacy and efficiency, the deployment of many recommender systems is experiencing a shift from central servers to personal devices, where the federated recommender systems (FedRecs) and decentralized collaborative recommender systems (DecRecs) are arguably the two most representative paradigms. While both leverage knowledge (e.g., gradients) sharing to facilitate learning local models, FedRecs rely on a central server to coordinate the optimization process, yet in DecRecs, the knowledge sharing directly happens between clients. Knowledge sharing also opens a backdoor for model poisoning attacks, where adversaries disguise themselves as benign clients and disseminate polluted knowledge to achieve malicious goals like promoting an item's exposure rate. Although research on such poisoning attacks provides valuable insights into finding security loopholes and corresponding countermeasures, existing attacks mostly focus on FedRecs, and are either inapplicable or ineffective for DecRecs. Compared with FedRecs where the tampered information can be universally distributed to all clients once uploaded to the cloud, each adversary in DecRecs can only communicate with neighbor clients of a small size, confining its impact to a limited range. To fill the gap, we present a novel attack method named Poisoning with Adaptive Malicious Neighbors (PAMN). With item promotion in top-K recommendation as the attack objective, PAMN effectively boosts target items' ranks with several adversaries that emulate benign clients and transfers adaptively crafted gradients conditioned on each adversary's neighbors. Moreover, with the vulnerabilities of DecRecs uncovered, a dedicated defensive mechanism based on user-level gradient clipping with sparsified updating is proposed. Extensive experiments demonstrate the effectiveness of the poisoning attack and the robustness of our defensive mechanism. ",
    "url": "https://arxiv.org/abs/2404.01177",
    "authors": [
      "Ruiqi Zheng",
      "Liang Qu",
      "Tong Chen",
      "Kai Zheng",
      "Yuhui Shi",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2404.01184",
    "title": "Efficient Motion Planning for Manipulators with Control Barrier  Function-Induced Neural Controller",
    "abstract": "Sampling-based motion planning methods for manipulators in crowded environments often suffer from expensive collision checking and high sampling complexity, which make them difficult to use in real time. To address this issue, we propose a new generalizable control barrier function (CBF)-based steering controller to reduce the number of samples needed in a sampling-based motion planner RRT. Our method combines the strength of CBF for real-time collision-avoidance control and RRT for long-horizon motion planning, by using CBF-induced neural controller (CBF-INC) to generate control signals that steer the system towards sampled configurations by RRT. CBF-INC is learned as Neural Networks and has two variants handling different inputs, respectively: state (signed distance) input and point-cloud input from LiDAR. In the latter case, we also study two different settings: fully and partially observed environmental information. Compared to manually crafted CBF which suffers from over-approximating robot geometry, CBF-INC can balance safety and goal-reaching better without being over-conservative. Given state-based input, our neural CBF-induced neural controller-enhanced RRT (CBF-INC-RRT) can increase the success rate by 14% while reducing the number of nodes explored by 30%, compared with vanilla RRT on hard test cases. Given LiDAR input where vanilla RRT is not directly applicable, we demonstrate that our CBF-INC-RRT can improve the success rate by 10%, compared with planning with other steering controllers. Our project page with supplementary material is at https://mit-realm.github.io/CBF-INC-RRT-website/. ",
    "url": "https://arxiv.org/abs/2404.01184",
    "authors": [
      "Mingxin Yu",
      "Chenning Yu",
      "M-Mahdi Naddaf-Sh",
      "Devesh Upadhyay",
      "Sicun Gao",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01194",
    "title": "Adaptive Query Prompting for Multi-Domain Landmark Detection",
    "abstract": "Medical landmark detection is crucial in various medical imaging modalities and procedures. Although deep learning-based methods have achieve promising performance, they are mostly designed for specific anatomical regions or tasks. In this work, we propose a universal model for multi-domain landmark detection by leveraging transformer architecture and developing a prompting component, named as Adaptive Query Prompting (AQP). Instead of embedding additional modules in the backbone network, we design a separate module to generate prompts that can be effectively extended to any other transformer network. In our proposed AQP, prompts are learnable parameters maintained in a memory space called prompt pool. The central idea is to keep the backbone frozen and then optimize prompts to instruct the model inference process. Furthermore, we employ a lightweight decoder to decode landmarks from the extracted features, namely Light-MLD. Thanks to the lightweight nature of the decoder and AQP, we can handle multiple datasets by sharing the backbone encoder and then only perform partial parameter tuning without incurring much additional cost. It has the potential to be extended to more landmark detection tasks. We conduct experiments on three widely used X-ray datasets for different medical landmark detection tasks. Our proposed Light-MLD coupled with AQP achieves SOTA performance on many metrics even without the use of elaborate structural designs or complex frameworks. ",
    "url": "https://arxiv.org/abs/2404.01194",
    "authors": [
      "Qiusen Wei",
      "Guoheng Huang",
      "Xiaochen Yuan",
      "Xuhang Chen",
      "Guo Zhong",
      "Jianwen Huang",
      "Jiajie Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01210",
    "title": "AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for  hallucination detection and analysis",
    "abstract": "In this paper, we present our team's submissions for SemEval-2024 Task-6 - SHROOM, a Shared-task on Hallucinations and Related Observable Overgeneration Mistakes. The participants were asked to perform binary classification to identify cases of fluent overgeneration hallucinations. Our experimentation included fine-tuning a pre-trained model on hallucination detection and a Natural Language Inference (NLI) model. The most successful strategy involved creating an ensemble of these models, resulting in accuracy rates of 77.8% and 79.9% on model-agnostic and model-aware datasets respectively, outperforming the organizers' baseline and achieving notable results when contrasted with the top-performing results in the competition, which reported accuracies of 84.7% and 81.3% correspondingly. ",
    "url": "https://arxiv.org/abs/2404.01210",
    "authors": [
      "Natalia Griogoriadou",
      "Maria Lymperaiou",
      "Giorgos Filandrianos",
      "Giorgos Stamou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.01216",
    "title": "Novel Node Category Detection Under Subpopulation Shift",
    "abstract": "In real-world graph data, distribution shifts can manifest in various ways, such as the emergence of new categories and changes in the relative proportions of existing categories. It is often important to detect nodes of novel categories under such distribution shifts for safety or insight discovery purposes. We introduce a new approach, Recall-Constrained Optimization with Selective Link Prediction (RECO-SLIP), to detect nodes belonging to novel categories in attributed graphs under subpopulation shifts. By integrating a recall-constrained learning framework with a sample-efficient link prediction mechanism, RECO-SLIP addresses the dual challenges of resilience against subpopulation shifts and the effective exploitation of graph structure. Our extensive empirical evaluation across multiple graph datasets demonstrates the superior performance of RECO-SLIP over existing methods. ",
    "url": "https://arxiv.org/abs/2404.01216",
    "authors": [
      "Hsing-Huan Chung",
      "Shravan Chaudhari",
      "Yoav Wald",
      "Xing Han",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.01217",
    "title": "Incorporating Domain Differential Equations into Graph Convolutional  Networks to Lower Generalization Discrepancy",
    "abstract": "Ensuring both accuracy and robustness in time series prediction is critical to many applications, ranging from urban planning to pandemic management. With sufficient training data where all spatiotemporal patterns are well-represented, existing deep-learning models can make reasonably accurate predictions. However, existing methods fail when the training data are drawn from different circumstances (e.g., traffic patterns on regular days) compared to test data (e.g., traffic patterns after a natural disaster). Such challenges are usually classified under domain generalization. In this work, we show that one way to address this challenge in the context of spatiotemporal prediction is by incorporating domain differential equations into Graph Convolutional Networks (GCNs). We theoretically derive conditions where GCNs incorporating such domain differential equations are robust to mismatched training and testing data compared to baseline domain agnostic models. To support our theory, we propose two domain-differential-equation-informed networks called Reaction-Diffusion Graph Convolutional Network (RDGCN), which incorporates differential equations for traffic speed evolution, and Susceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN), which incorporates a disease propagation model. Both RDGCN and SIRGCN are based on reliable and interpretable domain differential equations that allow the models to generalize to unseen patterns. We experimentally show that RDGCN and SIRGCN are more robust with mismatched testing data than the state-of-the-art deep learning methods. ",
    "url": "https://arxiv.org/abs/2404.01217",
    "authors": [
      "Yue Sun",
      "Chao Chen",
      "Yuesheng Xu",
      "Sihong Xie",
      "Rick S. Blum",
      "Parv Venkitasubramaniam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.01226",
    "title": "Stable Code Technical Report",
    "abstract": "We introduce Stable Code, the first in our new-generation of code language models series, which serves as a general-purpose base code language model targeting code completion, reasoning, math, and other software engineering-based tasks. Additionally, we introduce an instruction variant named Stable Code Instruct that allows conversing with the model in a natural chat interface for performing question-answering and instruction-based tasks. In this technical report, we detail the data and training procedure leading to both models. Their weights are available via Hugging Face for anyone to download and use at https://huggingface.co/stabilityai/stable-code-3b and https://huggingface.co/stabilityai/stable-code-instruct-3b. This report contains thorough evaluations of the models, including multilingual programming benchmarks, and the MT benchmark focusing on multi-turn dialogues. At the time of its release, Stable Code is the state-of-the-art open model under 3B parameters and even performs comparably to larger models of sizes 7 billion and 15 billion parameters on the popular Multi-PL benchmark. Stable Code Instruct also exhibits state-of-the-art performance on the MT-Bench coding tasks and on Multi-PL completion compared to other instruction tuned models. Given its appealing small size, we also provide throughput measurements on a number of edge devices. In addition, we open source several quantized checkpoints and provide their performance metrics compared to the original model. ",
    "url": "https://arxiv.org/abs/2404.01226",
    "authors": [
      "Nikhil Pinnaparaju",
      "Reshinth Adithyan",
      "Duy Phung",
      "Jonathan Tow",
      "James Baicoianu",
      "Ashish Datta",
      "Maksym Zhuravinskyi",
      "Dakota Mahan",
      "Marco Bellagente",
      "Carlos Riquelme",
      "Nathan Cooper"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.01231",
    "title": "Privacy Backdoors: Enhancing Membership Inference through Poisoning  Pre-trained Models",
    "abstract": "It is commonplace to produce application-specific models by fine-tuning large pre-trained models using a small bespoke dataset. The widespread availability of foundation model checkpoints on the web poses considerable risks, including the vulnerability to backdoor attacks. In this paper, we unveil a new vulnerability: the privacy backdoor attack. This black-box privacy attack aims to amplify the privacy leakage that arises when fine-tuning a model: when a victim fine-tunes a backdoored model, their training data will be leaked at a significantly higher rate than if they had fine-tuned a typical model. We conduct extensive experiments on various datasets and models, including both vision-language models (CLIP) and large language models, demonstrating the broad applicability and effectiveness of such an attack. Additionally, we carry out multiple ablation studies with different fine-tuning methods and inference strategies to thoroughly analyze this new threat. Our findings highlight a critical privacy concern within the machine learning community and call for a reevaluation of safety protocols in the use of open-source pre-trained models. ",
    "url": "https://arxiv.org/abs/2404.01231",
    "authors": [
      "Yuxin Wen",
      "Leo Marchyok",
      "Sanghyun Hong",
      "Jonas Geiping",
      "Tom Goldstein",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01240",
    "title": "AURORA: Navigating UI Tarpits via Automated Neural Screen Understanding",
    "abstract": "Nearly a decade of research in software engineering has focused on automating mobile app testing to help engineers in overcoming the unique challenges associated with the software platform. Much of this work has come in the form of Automated Input Generation tools (AIG tools) that dynamically explore app screens. However, such tools have repeatedly been demonstrated to achieve lower-than-expected code coverage - particularly on sophisticated proprietary apps. Prior work has illustrated that a primary cause of these coverage deficiencies is related to so-called tarpits, or complex screens that are difficult to navigate. In this paper, we take a critical step toward enabling AIG tools to effectively navigate tarpits during app exploration through a new form of automated semantic screen understanding. We introduce AURORA, a technique that learns from the visual and textual patterns that exist in mobile app UIs to automatically detect common screen designs and navigate them accordingly. The key idea of AURORA is that there are a finite number of mobile app screen designs, albeit with subtle variations, such that the general patterns of different categories of UI designs can be learned. As such, AURORA employs a multi-modal, neural screen classifier that is able to recognize the most common types of UI screen designs. After recognizing a given screen, it then applies a set of flexible and generalizable heuristics to properly navigate the screen. We evaluated AURORA both on a set of 12 apps with known tarpits from prior work, and on a new set of five of the most popular apps from the Google Play store. Our results indicate that AURORA is able to effectively navigate tarpit screens, outperforming prior approaches that avoid tarpits by 19.6% in terms of method coverage. The improvements can be attributed to AURORA's UI design classification and heuristic navigation techniques. ",
    "url": "https://arxiv.org/abs/2404.01240",
    "authors": [
      "Safwat Ali Khan",
      "Wenyu Wang",
      "Yiran Ren",
      "Bin Zhu",
      "Jiangfan Shi",
      "Alyssa McGowan",
      "Wing Lam",
      "Kevin Moran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2404.01243",
    "title": "A Unified and Interpretable Emotion Representation and Expression  Generation",
    "abstract": "Canonical emotions, such as happy, sad, and fearful, are easy to understand and annotate. However, emotions are often compound, e.g. happily surprised, and can be mapped to the action units (AUs) used for expressing emotions, and trivially to the canonical ones. Intuitively, emotions are continuous as represented by the arousal-valence (AV) model. An interpretable unification of these four modalities - namely, Canonical, Compound, AUs, and AV - is highly desirable, for a better representation and understanding of emotions. However, such unification remains to be unknown in the current literature. In this work, we propose an interpretable and unified emotion model, referred as C2A2. We also develop a method that leverages labels of the non-unified models to annotate the novel unified one. Finally, we modify the text-conditional diffusion models to understand continuous numbers, which are then used to generate continuous expressions using our unified emotion model. Through quantitative and qualitative experiments, we show that our generated images are rich and capture subtle expressions. Our work allows a fine-grained generation of expressions in conjunction with other textual inputs and offers a new label space for emotions at the same time. ",
    "url": "https://arxiv.org/abs/2404.01243",
    "authors": [
      "Reni Paskaleva",
      "Mykyta Holubakha",
      "Andela Ilic",
      "Saman Motamed",
      "Luc Van Gool",
      "Danda Paudel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01270",
    "title": "Decentralized Collaborative Learning Framework with External Privacy  Leakage Analysis",
    "abstract": "This paper presents two methodological advancements in decentralized multi-task learning under privacy constraints, aiming to pave the way for future developments in next-generation Blockchain platforms. First, we expand the existing framework for collaborative dictionary learning (CollabDict), which has previously been limited to Gaussian mixture models, by incorporating deep variational autoencoders (VAEs) into the framework, with a particular focus on anomaly detection. We demonstrate that the VAE-based anomaly score function shares the same mathematical structure as the non-deep model, and provide comprehensive qualitative comparison. Second, considering the widespread use of \"pre-trained models,\" we provide a mathematical analysis on data privacy leakage when models trained with CollabDict are shared externally. We show that the CollabDict approach, when applied to Gaussian mixtures, adheres to a Renyi differential privacy criterion. Additionally, we propose a practical metric for monitoring internal privacy breaches during the learning process. ",
    "url": "https://arxiv.org/abs/2404.01270",
    "authors": [
      "Tsuyoshi Id\u00e9",
      "Dzung T. Phan",
      "Rudy Raymond"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2404.01278",
    "title": "BiPer: Binary Neural Networks using a Periodic Function",
    "abstract": "Quantized neural networks employ reduced precision representations for both weights and activations. This quantization process significantly reduces the memory requirements and computational complexity of the network. Binary Neural Networks (BNNs) are the extreme quantization case, representing values with just one bit. Since the sign function is typically used to map real values to binary values, smooth approximations are introduced to mimic the gradients during error backpropagation. Thus, the mismatch between the forward and backward models corrupts the direction of the gradient, causing training inconsistency problems and performance degradation. In contrast to current BNN approaches, we propose to employ a binary periodic (BiPer) function during binarization. Specifically, we use a square wave for the forward pass to obtain the binary values and employ the trigonometric sine function with the same period of the square wave as a differentiable surrogate during the backward pass. We demonstrate that this approach can control the quantization error by using the frequency of the periodic function and improves network performance. Extensive experiments validate the effectiveness of BiPer in benchmark datasets and network architectures, with improvements of up to 1% and 0.69% with respect to state-of-the-art methods in the classification task over CIFAR-10 and ImageNet, respectively. Our code is publicly available at https://github.com/edmav4/BiPer. ",
    "url": "https://arxiv.org/abs/2404.01278",
    "authors": [
      "Edwin Vargas",
      "Claudia Correa",
      "Carlos Hinojosa",
      "Henry Arguello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01283",
    "title": "Evaluating Privacy Perceptions, Experience, and Behavior of Software  Development Teams",
    "abstract": "With the increase in the number of privacy regulations, small development teams are forced to make privacy decisions on their own. In this paper, we conduct a mixed-method survey study, including statistical and qualitative analysis, to evaluate the privacy perceptions, practices, and knowledge of members involved in various phases of software development (SDLC). Our survey includes 362 participants from 23 countries, encompassing roles such as product managers, developers, and testers. Our results show diverse definitions of privacy across SDLC roles, emphasizing the need for a holistic privacy approach throughout SDLC. We find that software teams, regardless of their region, are less familiar with privacy concepts (such as anonymization), relying on self-teaching and forums. Most participants are more familiar with GDPR and HIPAA than other regulations, with multi-jurisdictional compliance being their primary concern. Our results advocate the need for role-dependent solutions to address the privacy challenges, and we highlight research directions and educational takeaways to help improve privacy-aware software development. ",
    "url": "https://arxiv.org/abs/2404.01283",
    "authors": [
      "Maxwell Prybylo",
      "Sara Haghighi",
      "Sai Teja Peddinti",
      "Sepideh Ghanavati"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2404.01299",
    "title": "CausalChaos! Dataset for Comprehensive Causal Action Question Answering  Over Longer Causal Chains Grounded in Dynamic Visual Scenes",
    "abstract": "Causal video question answering (QA) has garnered increasing interest, yet existing datasets often lack depth in causal reasoning analysis. To address this gap, we capitalize on the unique properties of cartoons and construct CausalChaos!, a novel, challenging causal Why-QA dataset built upon the iconic \"Tom and Jerry\" cartoon series. With thoughtful questions and multi-level answers, our dataset contains much longer causal chains embedded in dynamic interactions and visuals, at the same time principles of animation allows animators to create well-defined, unambiguous causal relationships. These factors allow models to solve more challenging, yet well-defined causal relationships. We also introduce hard negative mining, including CausalConfusion version. While models perform well, there is much room for improvement, especially, on open-ended answers. We identify more advanced/explicit causal relationship modeling and joint modeling of vision and language as the immediate areas for future efforts to focus upon. Along with the other complementary datasets, our new challenging dataset will pave the way for these developments in the field. We will release our dataset, codes, and models to help future efforts in this domain. ",
    "url": "https://arxiv.org/abs/2404.01299",
    "authors": [
      "Ting En Lam",
      "Yuhan Chen",
      "Elston Tan",
      "Eric Peh",
      "Ruirui Chen",
      "Paritosh Parmar",
      "Basura Fernando"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01300",
    "title": "NeRF-MAE : Masked AutoEncoders for Self Supervised 3D representation  Learning for Neural Radiance Fields",
    "abstract": "Neural fields excel in computer vision and robotics due to their ability to understand the 3D visual world such as inferring semantics, geometry, and dynamics. Given the capabilities of neural fields in densely representing a 3D scene from 2D images, we ask the question: Can we scale their self-supervised pretraining, specifically using masked autoencoders, to generate effective 3D representations from posed RGB images. Owing to the astounding success of extending transformers to novel data modalities, we employ standard 3D Vision Transformers to suit the unique formulation of NeRFs. We leverage NeRF's volumetric grid as a dense input to the transformer, contrasting it with other 3D representations such as pointclouds where the information density can be uneven, and the representation is irregular. Due to the difficulty of applying masked autoencoders to an implicit representation, such as NeRF, we opt for extracting an explicit representation that canonicalizes scenes across domains by employing the camera trajectory for sampling. Our goal is made possible by masking random patches from NeRF's radiance and density grid and employing a standard 3D Swin Transformer to reconstruct the masked patches. In doing so, the model can learn the semantic and spatial structure of complete scenes. We pretrain this representation at scale on our proposed curated posed-RGB data, totaling over 1.6 million images. Once pretrained, the encoder is used for effective 3D transfer learning. Our novel self-supervised pretraining for NeRFs, NeRF-MAE, scales remarkably well and improves performance on various challenging 3D tasks. Utilizing unlabeled posed 2D data for pretraining, NeRF-MAE significantly outperforms self-supervised 3D pretraining and NeRF scene understanding baselines on Front3D and ScanNet datasets with an absolute performance improvement of over 20% AP50 and 8% AP25 for 3D object detection. ",
    "url": "https://arxiv.org/abs/2404.01300",
    "authors": [
      "Muhammad Zubair Irshad",
      "Sergey Zakahrov",
      "Vitor Guizilini",
      "Adrien Gaidon",
      "Zsolt Kira",
      "Rares Ambrus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00014",
    "title": "Deep Geometry Handling and Fragment-wise Molecular 3D Graph Generation",
    "abstract": "Most earlier 3D structure-based molecular generation approaches follow an atom-wise paradigm, incrementally adding atoms to a partially built molecular fragment within protein pockets. These methods, while effective in designing tightly bound ligands, often overlook other essential properties such as synthesizability. The fragment-wise generation paradigm offers a promising solution. However, a common challenge across both atom-wise and fragment-wise methods lies in their limited ability to co-design plausible chemical and geometrical structures, resulting in distorted conformations. In response to this challenge, we introduce the Deep Geometry Handling protocol, a more abstract design that extends the design focus beyond the model architecture. Through a comprehensive review of existing geometry-related models and their protocols, we propose a novel hybrid strategy, culminating in the development of FragGen - a geometry-reliable, fragment-wise molecular generation method. FragGen marks a significant leap forward in the quality of generated geometry and the synthesis accessibility of molecules. The efficacy of FragGen is further validated by its successful application in designing type II kinase inhibitors at the nanomolar level. ",
    "url": "https://arxiv.org/abs/2404.00014",
    "authors": [
      "Odin Zhang",
      "Yufei Huang",
      "Shichen Cheng",
      "Mengyao Yu",
      "Xujun Zhang",
      "Haitao Lin",
      "Yundian Zeng",
      "Mingyang Wang",
      "Zhenxing Wu",
      "Huifeng Zhao",
      "Zaixi Zhang",
      "Chenqing Hua",
      "Yu Kang",
      "Sunliang Cui",
      "Peichen Pan",
      "Chang-Yu Hsieh",
      "Tingjun Hou"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2404.00044",
    "title": "UAlign: Pushing the Limit of Template-free Retrosynthesis Prediction  with Unsupervised SMILES Alignment",
    "abstract": "Retrosynthesis planning poses a formidable challenge in the organic chemical industry, particularly in pharmaceuticals. Single-step retrosynthesis prediction, a crucial step in the planning process, has witnessed a surge in interest in recent years due to advancements in AI for science. Various deep learning-based methods have been proposed for this task in recent years, incorporating diverse levels of additional chemical knowledge dependency. This paper introduces UAlign, a template-free graph-to-sequence pipeline for retrosynthesis prediction. By combining graph neural networks and Transformers, our method can more effectively leverage the inherent graph structure of molecules. Based on the fact that the majority of molecule structures remain unchanged during a chemical reaction, we propose a simple yet effective SMILES alignment technique to facilitate the reuse of unchanged structures for reactant generation. Extensive experiments show that our method substantially outperforms state-of-the-art template-free and semi-template-based approaches. Importantly, Our template-free method achieves effectiveness comparable to, or even surpasses, established powerful template-based methods. Scientific contribution: We present a novel graph-to-sequence template-free retrosynthesis prediction pipeline that overcomes the limitations of Transformer-based methods in molecular representation learning and insufficient utilization of chemical information. We propose an unsupervised learning mechanism for establishing product-atom correspondence with reactant SMILES tokens, achieving even better results than supervised SMILES alignment methods. Extensive experiments demonstrate that UAlign significantly outperforms state-of-the-art template-free methods and rivals or surpasses template-based approaches, with up to 5\\% (top-5) and 5.4\\% (top-10) increased accuracy over the strongest baseline. ",
    "url": "https://arxiv.org/abs/2404.00044",
    "authors": [
      "Kaipeng Zeng",
      "Xin Zhao",
      "Yu Zhang",
      "Fan Nie",
      "Xiaokang Yang",
      "Yaohui Jin",
      "Yanyan Xu"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2404.00060",
    "title": "Temporal Graph Networks for Graph Anomaly Detection in Financial  Networks",
    "abstract": "This paper explores the utilization of Temporal Graph Networks (TGN) for financial anomaly detection, a pressing need in the era of fintech and digitized financial transactions. We present a comprehensive framework that leverages TGN, capable of capturing dynamic changes in edges within financial networks, for fraud detection. Our study compares TGN's performance against static Graph Neural Network (GNN) baselines, as well as cutting-edge hypergraph neural network baselines using DGraph dataset for a realistic financial context. Our results demonstrate that TGN significantly outperforms other models in terms of AUC metrics. This superior performance underlines TGN's potential as an effective tool for detecting financial fraud, showcasing its ability to adapt to the dynamic and complex nature of modern financial systems. We also experimented with various graph embedding modules within the TGN framework and compared the effectiveness of each module. In conclusion, we demonstrated that, even with variations within TGN, it is possible to achieve good performance in the anomaly detection task. ",
    "url": "https://arxiv.org/abs/2404.00060",
    "authors": [
      "Yejin Kim",
      "Youngbin Lee",
      "Minyoung Choe",
      "Sungju Oh",
      "Yongjae Lee"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00081",
    "title": "Molecular Generative Adversarial Network with Multi-Property  Optimization",
    "abstract": "Deep generative models, such as generative adversarial networks (GANs), have been employed for $de~novo$ molecular generation in drug discovery. Most prior studies have utilized reinforcement learning (RL) algorithms, particularly Monte Carlo tree search (MCTS), to handle the discrete nature of molecular representations in GANs. However, due to the inherent instability in training GANs and RL models, along with the high computational cost associated with MCTS sampling, MCTS RL-based GANs struggle to scale to large chemical databases. To tackle these challenges, this study introduces a novel GAN based on actor-critic RL with instant and global rewards, called InstGAN, to generate molecules at the token-level with multi-property optimization. Furthermore, maximized information entropy is leveraged to alleviate the mode collapse. The experimental results demonstrate that InstGAN outperforms other baselines, achieves comparable performance to state-of-the-art models, and efficiently generates molecules with multi-property optimization. The source code will be released upon acceptance of the paper. ",
    "url": "https://arxiv.org/abs/2404.00081",
    "authors": [
      "Huidong Tang",
      "Chen Li",
      "Sayaka Kamei",
      "Yoshihiro Yamanishi",
      "Yasuhiko Morimoto"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00082",
    "title": "Data-Driven Room Acoustic Modeling Via Differentiable Feedback Delay  Networks With Learnable Delay Lines",
    "abstract": "Over the past few decades, extensive research has been devoted to the design of artificial reverberation algorithms aimed at emulating the room acoustics of physical environments. Despite significant advancements, automatic parameter tuning of delay-network models remains an open challenge. We introduce a novel method for finding the parameters of a Feedback Delay Network (FDN) such that its output renders the perceptual qualities of a measured room impulse response. The proposed approach involves the implementation of a differentiable FDN with trainable delay lines, which, for the first time, allows us to simultaneously learn each and every delay-network parameter via backpropagation. The iterative optimization process seeks to minimize a time-domain loss function incorporating differentiable terms accounting for energy decay and echo density. Through experimental validation, we show that the proposed method yields time-invariant frequency-independent FDNs capable of closely matching the desired acoustical characteristics, and outperforms existing methods based on genetic algorithms and analytical filter design. ",
    "url": "https://arxiv.org/abs/2404.00082",
    "authors": [
      "Alessandro Ilic Mezza",
      "Riccardo Giampiccolo",
      "Enzo De Sena",
      "Alberto Bernardini"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2404.00218",
    "title": "Functional-Edged Network Modeling",
    "abstract": "Contrasts with existing works which all consider nodes as functions and use edges to represent the relationships between different functions. We target at network modeling whose edges are functional data and transform the adjacency matrix into a functional adjacency tensor, introducing an additional dimension dedicated to function representation. Tucker functional decomposition is used for the functional adjacency tensor, and to further consider the community between nodes, we regularize the basis matrices to be symmetrical. Furthermore, to deal with irregular observations of the functional edges, we conduct model inference to solve a tensor completion problem. It is optimized by a Riemann conjugate gradient descent method. Besides these, we also derive several theorems to show the desirable properties of the functional edged network model. Finally, we evaluate the efficacy of our proposed model using simulation data and real metro system data from Hong Kong and Singapore. ",
    "url": "https://arxiv.org/abs/2404.00218",
    "authors": [
      "Haijie Xu",
      "Chen Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00220",
    "title": "Partially-Observable Sequential Change-Point Detection for  Autocorrelated Data via Upper Confidence Region",
    "abstract": "Sequential change point detection for multivariate autocorrelated data is a very common problem in practice. However, when the sensing resources are limited, only a subset of variables from the multivariate system can be observed at each sensing time point. This raises the problem of partially observable multi-sensor sequential change point detection. For it, we propose a detection scheme called adaptive upper confidence region with state space model (AUCRSS). It models multivariate time series via a state space model (SSM), and uses an adaptive sampling policy for efficient change point detection and localization. A partially-observable Kalman filter algorithm is developed for online inference of SSM, and accordingly, a change point detection scheme based on a generalized likelihood ratio test is developed. How its detection power relates to the adaptive sampling strategy is analyzed. Meanwhile, by treating the detection power as a reward, its connection with the online combinatorial multi-armed bandit (CMAB) problem is formulated and an adaptive upper confidence region algorithm is proposed for adaptive sampling policy design. Theoretical analysis of the asymptotic average detection delay is performed, and thorough numerical studies with synthetic data and real-world data are conducted to demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2404.00220",
    "authors": [
      "Haijie Xu",
      "Xiaochen Xian",
      "Chen Zhang",
      "Kaibo Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00481",
    "title": "Convolutional Bayesian Filtering",
    "abstract": "Bayesian filtering serves as the mainstream framework of state estimation in dynamic systems. Its standard version utilizes total probability rule and Bayes' law alternatively, where how to define and compute conditional probability is critical to state distribution inference. Previously, the conditional probability is assumed to be exactly known, which represents a measure of the occurrence probability of one event, given the second event. In this paper, we find that by adding an additional event that stipulates an inequality condition, we can transform the conditional probability into a special integration that is analogous to convolution. Based on this transformation, we show that both transition probability and output probability can be generalized to convolutional forms, resulting in a more general filtering framework that we call convolutional Bayesian filtering. This new framework encompasses standard Bayesian filtering as a special case when the distance metric of the inequality condition is selected as Dirac delta function. It also allows for a more nuanced consideration of model mismatch by choosing different types of inequality conditions. For instance, when the distance metric is defined in a distributional sense, the transition probability and output probability can be approximated by simply rescaling them into fractional powers. Under this framework, a robust version of Kalman filter can be constructed by only altering the noise covariance matrix, while maintaining the conjugate nature of Gaussian distributions. Finally, we exemplify the effectiveness of our approach by reshaping classic filtering algorithms into convolutional versions, including Kalman filter, extended Kalman filter, unscented Kalman filter and particle filter. ",
    "url": "https://arxiv.org/abs/2404.00481",
    "authors": [
      "Wenhan Cao",
      "Shiqi Liu",
      "Chang Liu",
      "Zeyu He",
      "Stephen S.-T. Yau",
      "Shengbo Eben Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2404.00545",
    "title": "Unified, Verifiable Neural Simulators for Electromagnetic Wave Inverse  Problems",
    "abstract": "Simulators based on neural networks offer a path to orders-of-magnitude faster electromagnetic wave simulations. Existing models, however, only address narrowly tailored classes of problems and only scale to systems of a few dozen degrees of freedom (DoFs). Here, we demonstrate a single, unified model capable of addressing scattering simulations with thousands of DoFs, of any wavelength, any illumination wavefront, and freeform materials, within broad configurable bounds. Based on an attentional multi-conditioning strategy, our method also allows non-recurrent supervision on and prediction of intermediate physical states, which provides improved generalization with no additional data-generation cost. Using this O(1)-time intermediate prediction capability, we propose and prove a rigorous, efficiently computable upper bound on prediction error, allowing accuracy guarantees at inference time for all predictions. After training solely on randomized systems, we demonstrate the unified model across a suite of challenging multi-disciplinary inverse problems, finding strong efficacy and speed improvements up to 96% for problems in optical tomography, beam shaping through volumetric random media, and freeform photonic inverse design, with no problem-specific training. Our findings demonstrate a path to universal, verifiably accurate neural surrogates for existing scattering simulators, and our conditioning and training methods are directly applicable to any PDE admitting a time-domain iterative solver. ",
    "url": "https://arxiv.org/abs/2404.00545",
    "authors": [
      "Charles Dove",
      "Jatearoon Boondicharern",
      "Laura Waller"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2404.00549",
    "title": "Pneumonia App: a mobile application for efficient pediatric pneumonia  diagnosis using explainable convolutional neural networks (CNN)",
    "abstract": "Mycoplasma pneumoniae pneumonia (MPP) poses significant diagnostic challenges in pediatric healthcare, especially in regions like China where it's prevalent. We introduce PneumoniaAPP, a mobile application leveraging deep learning techniques for rapid MPP detection. Our approach capitalizes on convolutional neural networks (CNNs) trained on a comprehensive dataset comprising 3345 chest X-ray (CXR) images, which includes 833 CXR images revealing MPP and additionally augmented with samples from a public dataset. The CNN model achieved an accuracy of 88.20% and an AUROC of 0.9218 across all classes, with a specific accuracy of 97.64% for the mycoplasma class, as demonstrated on the testing dataset. Furthermore, we integrated explainability techniques into PneumoniaAPP to aid respiratory physicians in lung opacity localization. Our contribution extends beyond existing research by targeting pediatric MPP, emphasizing the age group of 0-12 years, and prioritizing deployment on mobile devices. This work signifies a significant advancement in pediatric pneumonia diagnosis, offering a reliable and accessible tool to alleviate diagnostic burdens in healthcare settings. ",
    "url": "https://arxiv.org/abs/2404.00549",
    "authors": [
      "Jiaming Deng",
      "Zhenglin Chen",
      "Minjiang Chen",
      "Lulu Xu",
      "Jiaqi Yang",
      "Zhendong Luo",
      "Peiwu Qin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.00726",
    "title": "MugenNet: A Novel Combined Convolution Neural Network and Transformer  Network with its Application for Colonic Polyp Image Segmentation",
    "abstract": "Biomedical image segmentation is a very important part in disease diagnosis. The term \"colonic polyps\" refers to polypoid lesions that occur on the surface of the colonic mucosa within the intestinal lumen. In clinical practice, early detection of polyps is conducted through colonoscopy examinations and biomedical image processing. Therefore, the accurate polyp image segmentation is of great significance in colonoscopy examinations. Convolutional Neural Network (CNN) is a common automatic segmentation method, but its main disadvantage is the long training time. Transformer utilizes a self-attention mechanism, which essentially assigns different importance weights to each piece of information, thus achieving high computational efficiency during segmentation. However, a potential drawback is the risk of information loss. In the study reported in this paper, based on the well-known hybridization principle, we proposed a method to combine CNN and Transformer to retain the strengths of both, and we applied this method to build a system called MugenNet for colonic polyp image segmentation. We conducted a comprehensive experiment to compare MugenNet with other CNN models on five publicly available datasets. The ablation experiment on MugentNet was conducted as well. The experimental results show that MugenNet achieves significantly higher processing speed and accuracy compared with CNN alone. The generalized implication with our work is a method to optimally combine two complimentary methods of machine learning. ",
    "url": "https://arxiv.org/abs/2404.00726",
    "authors": [
      "Chen Peng",
      "Zhiqin Qian",
      "Kunyu Wang",
      "Qi Luo",
      "Zhuming Bi",
      "Wenjun Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.00751",
    "title": "C-XGBoost: A tree boosting model for causal effect estimation",
    "abstract": "Causal effect estimation aims at estimating the Average Treatment Effect as well as the Conditional Average Treatment Effect of a treatment to an outcome from the available data. This knowledge is important in many safety-critical domains, where it often needs to be extracted from observational data. In this work, we propose a new causal inference model, named C-XGBoost, for the prediction of potential outcomes. The motivation of our approach is to exploit the superiority of tree-based models for handling tabular data together with the notable property of causal inference neural network-based models to learn representations that are useful for estimating the outcome for both the treatment and non-treatment cases. The proposed model also inherits the considerable advantages of XGBoost model such as efficiently handling features with missing values requiring minimum preprocessing effort, as well as it is equipped with regularization techniques to avoid overfitting/bias. Furthermore, we propose a new loss function for efficiently training the proposed causal inference model. The experimental analysis, which is based on the performance profiles of Dolan and Mor{\\'e} as well as on post-hoc and non-parametric statistical tests, provide strong evidence about the effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2404.00751",
    "authors": [
      "Niki Kiriakidou",
      "Ioannis E. Livieris",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2404.00954",
    "title": "Digital Twins for Supporting AI Research with Autonomous Vehicle  Networks",
    "abstract": "Digital twins (DTs), which are virtual environments that simulate, predict, and optimize the performance of their physical counterparts, are envisioned to be essential technologies for advancing next-generation wireless networks. While DTs have been studied extensively for wireless networks, their use in conjunction with autonomous vehicles with programmable mobility remains relatively under-explored. In this paper, we study DTs used as a development environment to design, deploy, and test artificial intelligence (AI) techniques that use real-time observations, e.g. radio key performance indicators, for vehicle trajectory and network optimization decisions in an autonomous vehicle networks (AVN). We first compare and contrast the use of simulation, digital twin (software in the loop (SITL)), sandbox (hardware-in-the-loop (HITL)), and physical testbed environments for their suitability in developing and testing AI algorithms for AVNs. We then review various representative use cases of DTs for AVN scenarios. Finally, we provide an example from the NSF AERPAW platform where a DT is used to develop and test AI-aided solutions for autonomous unmanned aerial vehicles for localizing a signal source based solely on link quality measurements. Our results in the physical testbed show that SITL DTs, when supplemented with data from real-world (RW) measurements and simulations, can serve as an ideal environment for developing and testing innovative AI solutions for AVNs. ",
    "url": "https://arxiv.org/abs/2404.00954",
    "authors": [
      "An\u0131l G\u00fcrses",
      "Gautham Reddy",
      "Saad Masrur",
      "\u00d6zg\u00fcr \u00d6zdemir",
      "\u0130smail G\u00fcven\u00e7",
      "Mihail L. Sichitiu",
      "Alphan \u015eahin",
      "Ahmed Alkhateeb",
      "Rudra Dutta"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2404.00977",
    "title": "Nonlinear Impulse Pattern Formulation dynamical social and political  prediction algorithm for city planning and public participation",
    "abstract": "A nonlinear-dynamical algorithm for city planning is proposed as an Impulse Pattern Formulation (IPF) for predicting relevant parameters like health, artistic freedom, or financial developments of different social or political stakeholders over the cause of a planning process. The IPF has already shown high predictive precision at low computational cost in musical instrument simulations, brain dynamics, and human-human interactions. The social and political IPF consists of three basic equations of system state developments, self-adaptation of stakeholders, two adaptive interactions, and external impact terms suitable for respective planning situations. Typical scenarios of stakeholder interactions and developments are modeled by adjusting a set of system parameters. These include stakeholder reaction to external input, enhanced system stability through self-adaptation, stakeholder convergence due to mediative interaction adaptation, as well as complex dynamics in terms of direct stakeholder impacts. A workflow for implementing the algorithm in real city planning scenarios is outlined. This workflow includes machine learning of a suitable set of parameters suggesting best-practice planning to aim at the desired development of the planning process and its output. ",
    "url": "https://arxiv.org/abs/2404.00977",
    "authors": [
      "Rolf Bader",
      "Simon Linke",
      "Stefanie Gernert"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2404.01153",
    "title": "TransFusion: Covariate-Shift Robust Transfer Learning for  High-Dimensional Regression",
    "abstract": "The main challenge that sets transfer learning apart from traditional supervised learning is the distribution shift, reflected as the shift between the source and target models and that between the marginal covariate distributions. In this work, we tackle model shifts in the presence of covariate shifts in the high-dimensional regression setting. Specifically, we propose a two-step method with a novel fused-regularizer that effectively leverages samples from source tasks to improve the learning performance on a target task with limited samples. Nonasymptotic bound is provided for the estimation error of the target model, showing the robustness of the proposed method to covariate shifts. We further establish conditions under which the estimator is minimax-optimal. Additionally, we extend the method to a distributed setting, allowing for a pretraining-finetuning strategy, requiring just one round of communication while retaining the estimation rate of the centralized version. Numerical tests validate our theory, highlighting the method's robustness to covariate shifts. ",
    "url": "https://arxiv.org/abs/2404.01153",
    "authors": [
      "Zelin He",
      "Ying Sun",
      "Jingyuan Liu",
      "Runze Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2404.01192",
    "title": "iMD4GC: Incomplete Multimodal Data Integration to Advance Precise  Treatment Response Prediction and Survival Analysis for Gastric Cancer",
    "abstract": "Gastric cancer (GC) is a prevalent malignancy worldwide, ranking as the fifth most common cancer with over 1 million new cases and 700 thousand deaths in 2020. Locally advanced gastric cancer (LAGC) accounts for approximately two-thirds of GC diagnoses, and neoadjuvant chemotherapy (NACT) has emerged as the standard treatment for LAGC. However, the effectiveness of NACT varies significantly among patients, with a considerable subset displaying treatment resistance. Ineffective NACT not only leads to adverse effects but also misses the optimal therapeutic window, resulting in lower survival rate. However, existing multimodal learning methods assume the availability of all modalities for each patient, which does not align with the reality of clinical practice. The limited availability of modalities for each patient would cause information loss, adversely affecting predictive accuracy. In this study, we propose an incomplete multimodal data integration framework for GC (iMD4GC) to address the challenges posed by incomplete multimodal data, enabling precise response prediction and survival analysis. Specifically, iMD4GC incorporates unimodal attention layers for each modality to capture intra-modal information. Subsequently, the cross-modal interaction layers explore potential inter-modal interactions and capture complementary information across modalities, thereby enabling information compensation for missing modalities. To evaluate iMD4GC, we collected three multimodal datasets for GC study: GastricRes (698 cases) for response prediction, GastricSur (801 cases) for survival analysis, and TCGA-STAD (400 cases) for survival analysis. The scale of our datasets is significantly larger than previous studies. The iMD4GC achieved impressive performance with an 80.2% AUC on GastricRes, 71.4% C-index on GastricSur, and 66.1% C-index on TCGA-STAD, significantly surpassing other compared methods. ",
    "url": "https://arxiv.org/abs/2404.01192",
    "authors": [
      "Fengtao Zhou",
      "Yingxue Xu",
      "Yanfen Cui",
      "Shenyan Zhang",
      "Yun Zhu",
      "Weiyang He",
      "Jiguang Wang",
      "Xin Wang",
      "Ronald Chan",
      "Louis Ho Shing Lau",
      "Chu Han",
      "Dafu Zhang",
      "Zhenhui Li",
      "Hao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.01200",
    "title": "Large-Scale Non-convex Stochastic Constrained Distributionally Robust  Optimization",
    "abstract": "Distributionally robust optimization (DRO) is a powerful framework for training robust models against data distribution shifts. This paper focuses on constrained DRO, which has an explicit characterization of the robustness level. Existing studies on constrained DRO mostly focus on convex loss function, and exclude the practical and challenging case with non-convex loss function, e.g., neural network. This paper develops a stochastic algorithm and its performance analysis for non-convex constrained DRO. The computational complexity of our stochastic algorithm at each iteration is independent of the overall dataset size, and thus is suitable for large-scale applications. We focus on the general Cressie-Read family divergence defined uncertainty set which includes $\\chi^2$-divergences as a special case. We prove that our algorithm finds an $\\epsilon$-stationary point with a computational complexity of $\\mathcal O(\\epsilon^{-3k_*-5})$, where $k_*$ is the parameter of the Cressie-Read divergence. The numerical results indicate that our method outperforms existing methods.} Our method also applies to the smoothed conditional value at risk (CVaR) DRO. ",
    "url": "https://arxiv.org/abs/2404.01200",
    "authors": [
      "Qi Zhang",
      "Yi Zhou",
      "Ashley Prater-Bennette",
      "Lixin Shen",
      "Shaofeng Zou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.01233",
    "title": "Optimal Ridge Regularization for Out-of-Distribution Prediction",
    "abstract": "We study the behavior of optimal ridge regularization and optimal ridge risk for out-of-distribution prediction, where the test distribution deviates arbitrarily from the train distribution. We establish general conditions that determine the sign of the optimal regularization level under covariate and regression shifts. These conditions capture the alignment between the covariance and signal structures in the train and test data and reveal stark differences compared to the in-distribution setting. For example, a negative regularization level can be optimal under covariate shift or regression shift, even when the training features are isotropic or the design is underparameterized. Furthermore, we prove that the optimally-tuned risk is monotonic in the data aspect ratio, even in the out-of-distribution setting and when optimizing over negative regularization levels. In general, our results do not make any modeling assumptions for the train or the test distributions, except for moment bounds, and allow for arbitrary shifts and the widest possible range of (negative) regularization levels. ",
    "url": "https://arxiv.org/abs/2404.01233",
    "authors": [
      "Pratik Patil",
      "Jin-Hong Du",
      "Ryan J. Tibshirani"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.01245",
    "title": "A Statistical Framework of Watermarks for Large Language Models: Pivot,  Detection Efficiency and Optimal Rules",
    "abstract": "Since ChatGPT was introduced in November 2022, embedding (nearly) unnoticeable statistical signals into text generated by large language models (LLMs), also known as watermarking, has been used as a principled approach to provable detection of LLM-generated text from its human-written counterpart. In this paper, we introduce a general and flexible framework for reasoning about the statistical efficiency of watermarks and designing powerful detection rules. Inspired by the hypothesis testing formulation of watermark detection, our framework starts by selecting a pivotal statistic of the text and a secret key -- provided by the LLM to the verifier -- to enable controlling the false positive rate (the error of mistakenly detecting human-written text as LLM-generated). Next, this framework allows one to evaluate the power of watermark detection rules by obtaining a closed-form expression of the asymptotic false negative rate (the error of incorrectly classifying LLM-generated text as human-written). Our framework further reduces the problem of determining the optimal detection rule to solving a minimax optimization program. We apply this framework to two representative watermarks -- one of which has been internally implemented at OpenAI -- and obtain several findings that can be instrumental in guiding the practice of implementing watermarks. In particular, we derive optimal detection rules for these watermarks under our framework. These theoretically derived detection rules are demonstrated to be competitive and sometimes enjoy a higher power than existing detection approaches through numerical experiments. ",
    "url": "https://arxiv.org/abs/2404.01245",
    "authors": [
      "Xiang Li",
      "Feng Ruan",
      "Huiyuan Wang",
      "Qi Long",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.01255",
    "title": "Gradient Methods for Scalable Multi-value Electricity Network Expansion  Planning",
    "abstract": "We consider multi-value expansion planning (MEP), a general bilevel optimization model in which a planner optimizes arbitrary functions of the dispatch outcome in the presence of a partially controllable, competitive electricity market. The MEP problem can be used to jointly plan various grid assets, such as transmission, generation, and battery storage capacities; examples include identifying grid investments that minimize emissions in the absence of a carbon tax, maximizing the profit of a portfolio of renewable investments and long-term energy contracts, or reducing price inequities between different grid stakeholders. The MEP problem, however, is in general nonconvex, making it difficult to solve exactly for large real-world systems. Therefore, we propose a fast stochastic implicit gradient-based heuristic method that scales well to large networks with many scenarios. We use a strong duality reformulation and the McCormick envelope to provide a lower bound on the performance of our algorithm via convex relaxation. We test the performance of our method on a large model of the U.S. Western Interconnect and demonstrate that it scales linearly with network size and number of scenarios and can be efficiently parallelized on large machines. We find that for medium-sized 16 hour cases, gradient descent on average finds a 5.3x lower objective value in 16.5x less time compared to a traditional reformulation-based approach solved with an interior point method. We conclude with a large example in which we jointly plan transmission, generation, and storage for a 768 hour case on 100 node system, showing that emissions penalization leads to additional 40.0% reduction in carbon intensity at an additional cost of $17.1/MWh. ",
    "url": "https://arxiv.org/abs/2404.01255",
    "authors": [
      "Anthony Degleris",
      "Abbas El Gamal",
      "Ram Rajagopal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2004.11131",
    "title": "Privacy at Scale: Introducing the PrivaSeer Corpus of Web Privacy  Policies",
    "abstract": " Title: Privacy at Scale: Introducing the PrivaSeer Corpus of Web Privacy  Policies ",
    "url": "https://arxiv.org/abs/2004.11131",
    "authors": [
      "Mukund Srinath",
      "Shomir Wilson",
      "C. Lee Giles"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2011.14598",
    "title": "Video Self-Stitching Graph Network for Temporal Action Localization",
    "abstract": " Title: Video Self-Stitching Graph Network for Temporal Action Localization ",
    "url": "https://arxiv.org/abs/2011.14598",
    "authors": [
      "Chen Zhao",
      "Ali Thabet",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.11866",
    "title": "GraphFM: Graph Factorization Machines for Feature Interaction Modeling",
    "abstract": " Comments: The code and data are available at this https URL ",
    "url": "https://arxiv.org/abs/2105.11866",
    "authors": [
      "Shu Wu",
      "Zekun Li",
      "Yunyue Su",
      "Zeyu Cui",
      "Xiaoyu Zhang",
      "Liang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2107.00363",
    "title": "Valid prediction intervals for regression problems",
    "abstract": " Comments: Minor correction (bibliography and typo in Fig. 3). Thanks to Dr. Mar\\'ia Moreno de Castro for spotting this typo ",
    "url": "https://arxiv.org/abs/2107.00363",
    "authors": [
      "Nicolas Dewolf",
      "Bernard De Baets",
      "Willem Waegeman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.03262",
    "title": "CGCL: Collaborative Graph Contrastive Learning without Handcrafted Graph  Data Augmentations",
    "abstract": " Comments: Accepted by DASFAA'24 ",
    "url": "https://arxiv.org/abs/2111.03262",
    "authors": [
      "Tianyu Zhang",
      "Yuxiang Ren",
      "Wenzheng Feng",
      "Weitao Du",
      "Xuecang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.13530",
    "title": "Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of  Representation Learning in Actor-Critic",
    "abstract": " Comments: 41 pages, accepted to NeurIPS 2021, add acknowledgement ",
    "url": "https://arxiv.org/abs/2112.13530",
    "authors": [
      "Yufeng Zhang",
      "Siyu Chen",
      "Zhuoran Yang",
      "Michael I. Jordan",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.14233",
    "title": "Multitask Learning and Bandits via Robust Statistics",
    "abstract": " Title: Multitask Learning and Bandits via Robust Statistics ",
    "url": "https://arxiv.org/abs/2112.14233",
    "authors": [
      "Kan Xu",
      "Hamsa Bastani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2202.03583",
    "title": "Multi-Label Classification of Thoracic Diseases using Dense  Convolutional Network on Chest Radiographs",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2202.03583",
    "authors": [
      "Dipkamal Bhusal",
      "Sanjeeb Prasad Panday"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07821",
    "title": "Detection of Small Holes by the Scale-Invariant Robust Density-Aware  Distance (RDAD) Filtration",
    "abstract": " Comments: 39 pages, 38 figs, J Appl. and Comput. Topology (2024). GitHub: [github.com/c-siu/RDAD]. Published version: [rdcu.be/dCXLa]. Diff of v2/3: added publication info, NO post-submission improvements (Cor2-3 rephrased and proven, setup of Sec4.1 explained, complexity computed in Sec6.1, Thm5 simplified, comparison with DTM in Sec1,8, streamlining), so no change in pdf. Diff of v1/2: more thms, more discussion on conformality, fewer egs ",
    "url": "https://arxiv.org/abs/2204.07821",
    "authors": [
      "Chunyin Siu",
      "Gennady Samorodnitsky",
      "Christina Lee Yu",
      "Andrey Yao"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.11143",
    "title": "Supplementing Missing Visions via Dialog for Scene Graph Generations",
    "abstract": " Comments: ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2204.11143",
    "authors": [
      "Zhenghao Zhao",
      "Ye Zhu",
      "Xiaoguang Zhu",
      "Yuzhang Shang",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10573",
    "title": "Spectral Neural Operators",
    "abstract": " Title: Spectral Neural Operators ",
    "url": "https://arxiv.org/abs/2205.10573",
    "authors": [
      "V. Fanaskov",
      "I. Oseledets"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.11566",
    "title": "Compressing the chronology of a temporal network with graph commutators",
    "abstract": " Title: Compressing the chronology of a temporal network with graph commutators ",
    "url": "https://arxiv.org/abs/2205.11566",
    "authors": [
      "Andrea J. Allen",
      "Cristopher Moore",
      "Laurent H\u00e9bert-Dufresne"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.11720",
    "title": "ENS-t-SNE: Embedding Neighborhoods Simultaneously t-SNE",
    "abstract": " Title: ENS-t-SNE: Embedding Neighborhoods Simultaneously t-SNE ",
    "url": "https://arxiv.org/abs/2205.11720",
    "authors": [
      "Jacob Miller",
      "Vahan Huroyan",
      "Raymundo Navarrete",
      "Md Iqbal Hossain",
      "Stephen Kobourov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.13476",
    "title": "Embed to Control Partially Observed Systems: Representation Learning  with Provable Sample Efficiency",
    "abstract": " Comments: Accepted by ICLR 2022 ",
    "url": "https://arxiv.org/abs/2205.13476",
    "authors": [
      "Lingxiao Wang",
      "Qi Cai",
      "Zhuoran Yang",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14375",
    "title": "WaveMix: A Resource-efficient Neural Network for Image Analysis",
    "abstract": " Comments: 20 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2205.14375",
    "authors": [
      "Pranav Jeevan",
      "Kavitha Viswanathan",
      "Anandu A S",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.02649",
    "title": "Visually Evaluating Generative Adversarial Networks Using Itself under  Multivariate Time Series",
    "abstract": " Comments: This is just a manuscript draft where the experiment is not evident, and need to be studied further ",
    "url": "https://arxiv.org/abs/2208.02649",
    "authors": [
      "Qilong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2208.14161",
    "title": "Identifiable Latent Causal Content for Domain Adaptation under Latent  Covariate Shift",
    "abstract": " Title: Identifiable Latent Causal Content for Domain Adaptation under Latent  Covariate Shift ",
    "url": "https://arxiv.org/abs/2208.14161",
    "authors": [
      "Yuhang Liu",
      "Zhen Zhang",
      "Dong Gong",
      "Mingming Gong",
      "Biwei Huang",
      "Anton van den Hengel",
      "Kun Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.07028",
    "title": "Estimating large causal polytrees from small samples",
    "abstract": " Comments: 26 pages. An R package has been developed (see link in the article), and a real data example has been added ",
    "url": "https://arxiv.org/abs/2209.07028",
    "authors": [
      "Sourav Chatterjee",
      "Mathukumalli Vidyasagar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.09404",
    "title": "Machine Learning-Augmented Optimization of Large Bilevel and Two-stage  Stochastic Programs: Application to Cycling Network Design",
    "abstract": " Title: Machine Learning-Augmented Optimization of Large Bilevel and Two-stage  Stochastic Programs: Application to Cycling Network Design ",
    "url": "https://arxiv.org/abs/2209.09404",
    "authors": [
      "Timothy C. Y. Chan",
      "Bo Lin",
      "Shoshanna Saxe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15497",
    "title": "Local dominance unveils clusters in networks",
    "abstract": " Title: Local dominance unveils clusters in networks ",
    "url": "https://arxiv.org/abs/2209.15497",
    "authors": [
      "Dingyi Shi",
      "Fan Shang",
      "Bingsheng Chen",
      "Paul Expert",
      "Linyuan L\u00fc",
      "H.Eugene Stanley",
      "Renaud Lambiotte",
      "Tim S. Evans",
      "Ruiqi Li"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.02941",
    "title": "BootAug: Boosting Text Augmentation via Hybrid Instance Filtering  Framework",
    "abstract": " Comments: Source code and examples: this https URL ",
    "url": "https://arxiv.org/abs/2210.02941",
    "authors": [
      "Heng Yang",
      "Ke Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.09846",
    "title": "G-PECNet: Towards a Generalizable Pedestrian Trajectory Prediction  System",
    "abstract": " Comments: Notable ICLR Tiny Paper 2024 ",
    "url": "https://arxiv.org/abs/2210.09846",
    "authors": [
      "Aryan Garg",
      "Renu M. Rameshan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.16863",
    "title": "Time-aware Metapath Feature Augmentation for Ponzi Detection in Ethereum",
    "abstract": " Comments: Accepted by IEEE Transactions on Network Science and Engineering ",
    "url": "https://arxiv.org/abs/2210.16863",
    "authors": [
      "Chengxiang Jin",
      "Jiajun Zhou",
      "Jie Jin",
      "Jiajing Wu",
      "Qi Xuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2301.08237",
    "title": "LoCoNet: Long-Short Context Network for Active Speaker Detection",
    "abstract": " Comments: accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2301.08237",
    "authors": [
      "Xizi Wang",
      "Feng Cheng",
      "Gedas Bertasius",
      "David Crandall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.08530",
    "title": "Self-Organization Towards $1/f$ Noise in Deep Neural Networks",
    "abstract": " Title: Self-Organization Towards $1/f$ Noise in Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2301.08530",
    "authors": [
      "Nicholas Chong Jia Le",
      "Ling Feng"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Artificial Intelligence (cs.AI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2302.03511",
    "title": "Differential Privacy with Higher Utility by Exploiting Coordinate-wise  Disparity: Laplace Mechanism can Beat Gaussian in High Dimensions",
    "abstract": " Title: Differential Privacy with Higher Utility by Exploiting Coordinate-wise  Disparity: Laplace Mechanism can Beat Gaussian in High Dimensions ",
    "url": "https://arxiv.org/abs/2302.03511",
    "authors": [
      "Gokularam Muthukrishnan",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.05043",
    "title": "A Review of Predictive and Contrastive Self-supervised Learning for  Medical Images",
    "abstract": " Comments: Article links: this https URL ",
    "url": "https://arxiv.org/abs/2302.05043",
    "authors": [
      "Wei-Chien Wang",
      "Euijoon Ahn",
      "Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.08860",
    "title": "Realizing temporal graphs from fastest travel times",
    "abstract": " Comments: 57 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2302.08860",
    "authors": [
      "Nina Klobas",
      "George B. Mertzios",
      "Hendrik Molter",
      "Paul G. Spirakis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2302.10306",
    "title": "Deep Convolutional Framelet Denoising for Panoramic by Mixed Wavelet  Integration",
    "abstract": " Title: Deep Convolutional Framelet Denoising for Panoramic by Mixed Wavelet  Integration ",
    "url": "https://arxiv.org/abs/2302.10306",
    "authors": [
      "Masoud Shahraki Mohammadi",
      "Seyed Javad Seyed Mahdavi Chabok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.11774",
    "title": "Semantic-Fused Multi-Granularity Cross-City Traffic Prediction",
    "abstract": " Title: Semantic-Fused Multi-Granularity Cross-City Traffic Prediction ",
    "url": "https://arxiv.org/abs/2302.11774",
    "authors": [
      "Kehua Chen",
      "Yuxuan Liang",
      "Jindong Han",
      "Siyuan Feng",
      "Meixin Zhu",
      "Hai Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09373",
    "title": "MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical  Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling",
    "abstract": " Comments: CVPR 2024 camera-ready (8 pages, 3 figures) with the supplemental materials (5 pages, 4 figures). Xuzhe Zhang and Yuhao Wu are co-first authors. Andrew F. Laine and Yun Wang are co-senior supervising authors ",
    "url": "https://arxiv.org/abs/2303.09373",
    "authors": [
      "Xuzhe Zhang",
      "Yuhao Wu",
      "Elsa Angelini",
      "Ang Li",
      "Jia Guo",
      "Jerod M. Rasmussen",
      "Thomas G. O'Connor",
      "Pathik D. Wadhwa",
      "Andrea Parolin Jackowski",
      "Hai Li",
      "Jonathan Posner",
      "Andrew F. Laine",
      "Yun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09383",
    "title": "Unifying Top-down and Bottom-up Scanpath Prediction Using Transformers",
    "abstract": " Comments: CVPR 2024 ",
    "url": "https://arxiv.org/abs/2303.09383",
    "authors": [
      "Zhibo Yang",
      "Sounak Mondal",
      "Seoyoung Ahn",
      "Ruoyu Xue",
      "Gregory Zelinsky",
      "Minh Hoai",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.12212",
    "title": "AeonG: An Efficient Built-in Temporal Support in Graph Databases",
    "abstract": " Comments: VLDB 2024 ",
    "url": "https://arxiv.org/abs/2304.12212",
    "authors": [
      "Jiamin Hou",
      "Zhanhao Zhao",
      "Zhouyu Wang",
      "Wei Lu",
      "Guodong Jin",
      "Dong Wen",
      "Xiaoyong Du"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2304.13061",
    "title": "iMixer: hierarchical Hopfield network implies an invertible, implicit  and iterative MLP-Mixer",
    "abstract": " Comments: 19 pages. v2: minor improvements ",
    "url": "https://arxiv.org/abs/2304.13061",
    "authors": [
      "Toshihiro Ota",
      "Masato Taki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.01157",
    "title": "Complex Logical Reasoning over Knowledge Graphs using Large Language  Models",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2305.01157",
    "authors": [
      "Nurendra Choudhary",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.04067",
    "title": "The Best Defense is Attack: Repairing Semantics in Textual Adversarial  Examples",
    "abstract": " Title: The Best Defense is Attack: Repairing Semantics in Textual Adversarial  Examples ",
    "url": "https://arxiv.org/abs/2305.04067",
    "authors": [
      "Heng Yang",
      "Ke Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.11074",
    "title": "Tram: A Token-level Retrieval-augmented Mechanism for Source Code  Summarization",
    "abstract": " Comments: NAACL 2024 Findings ",
    "url": "https://arxiv.org/abs/2305.11074",
    "authors": [
      "Tong Ye",
      "Lingfei Wu",
      "Tengfei Ma",
      "Xuhong Zhang",
      "Yangkai Du",
      "Peiyu Liu",
      "Shouling Ji",
      "Wenhai Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12599",
    "title": "Abstract Meaning Representation-Based Logic-Driven Data Augmentation for  Logical Reasoning",
    "abstract": " Comments: The short version (v2) was accepted for oral presentation at the first LLM@IJCAI 2023 non-archival symposium; the full version is under review. Update the mistake in Figure 1 ",
    "url": "https://arxiv.org/abs/2305.12599",
    "authors": [
      "Qiming Bao",
      "Alex Yuxuan Peng",
      "Zhenyun Deng",
      "Wanjun Zhong",
      "Gael Gendron",
      "Timothy Pistotti",
      "Neset Tan",
      "Nathan Young",
      "Yang Chen",
      "Yonghua Zhu",
      "Paul Denny",
      "Michael Witbrock",
      "Jiamou Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18216",
    "title": "Towards minimizing efforts for Morphing Attacks -- Deep embeddings for  morphing pair selection and improved Morphing Attack Detection",
    "abstract": " Title: Towards minimizing efforts for Morphing Attacks -- Deep embeddings for  morphing pair selection and improved Morphing Attack Detection ",
    "url": "https://arxiv.org/abs/2305.18216",
    "authors": [
      "Roman Kessler",
      "Kiran Raja",
      "Juan Tapia",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.03506",
    "title": "Subgraph Networks Based Contrastive Learning",
    "abstract": " Comments: 12 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2306.03506",
    "authors": [
      "Jinhuan Wang",
      "Jiafei Shao",
      "Zeyu Wang",
      "Shanqing Yu",
      "Qi Xuan",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.00185",
    "title": "Interpretable Constructive Algorithm for Random Weight Neural Networks",
    "abstract": " Title: Interpretable Constructive Algorithm for Random Weight Neural Networks ",
    "url": "https://arxiv.org/abs/2307.00185",
    "authors": [
      "Jing Nan",
      "Wei Dai",
      "Guan Yuan",
      "Ping Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08919",
    "title": "Systematic comparison of semi-supervised and self-supervised learning  for medical image classification",
    "abstract": " Comments: CVPR 2024 ",
    "url": "https://arxiv.org/abs/2307.08919",
    "authors": [
      "Zhe Huang",
      "Ruijie Jiang",
      "Shuchin Aeron",
      "Michael C. Hughes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.10438",
    "title": "Uncertainty Quantification for Molecular Property Predictions with Graph  Neural Architecture Search",
    "abstract": " Title: Uncertainty Quantification for Molecular Property Predictions with Graph  Neural Architecture Search ",
    "url": "https://arxiv.org/abs/2307.10438",
    "authors": [
      "Shengli Jiang",
      "Shiyi Qin",
      "Reid C. Van Lehn",
      "Prasanna Balaprakash",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2307.12872",
    "title": "Latent Code Augmentation Based on Stable Diffusion for Data-free  Substitute Attacks",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2307.12872",
    "authors": [
      "Mingwen Shao",
      "Lingzhuang Meng",
      "Yuanjian Qiao",
      "Lixu Zhang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.16120",
    "title": "Deep Unrolling Networks with Recurrent Momentum Acceleration for  Nonlinear Inverse Problems",
    "abstract": " Title: Deep Unrolling Networks with Recurrent Momentum Acceleration for  Nonlinear Inverse Problems ",
    "url": "https://arxiv.org/abs/2307.16120",
    "authors": [
      "Qingping Zhou",
      "Jiayu Qian",
      "Junqi Tang",
      "Jinglai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01813",
    "title": "Deep Neural Networks Fused with Textures for Image Classification",
    "abstract": " Comments: 14 pages, 6 figures, 4 tables, conference ",
    "url": "https://arxiv.org/abs/2308.01813",
    "authors": [
      "Asish Bera",
      "Debotosh Bhattacharjee",
      "Mita Nasipuri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.16859",
    "title": "Information Theoretically Optimal Sample Complexity of Learning  Dynamical Directed Acyclic Graphs",
    "abstract": " Comments: 21 pages. Accepted for publication in AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2308.16859",
    "authors": [
      "Mishfad Shaikh Veedu",
      "Deepjyoti Deka",
      "Murti V. Salapaka"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.06325",
    "title": "Distributed Precoding for Satellite-Terrestrial Integrated Networks  Without Sharing CSIT: A Rate-Splitting Approach",
    "abstract": " Comments: 13 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2309.06325",
    "authors": [
      "Doseon Kim",
      "Sungyoon Cho",
      "Wonjae Shin",
      "Jeonghun Park",
      "Dong Ku Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.11281",
    "title": "Language-driven Object Fusion into Neural Radiance Fields with  Pose-Conditioned Dataset Updates",
    "abstract": " Comments: CVPR 2024 ",
    "url": "https://arxiv.org/abs/2309.11281",
    "authors": [
      "Ka Chun Shum",
      "Jaeyeon Kim",
      "Binh-Son Hua",
      "Duc Thanh Nguyen",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11798",
    "title": "A Comprehensive Review of Community Detection in Graphs",
    "abstract": " Title: A Comprehensive Review of Community Detection in Graphs ",
    "url": "https://arxiv.org/abs/2309.11798",
    "authors": [
      "Jiakang Li",
      "Songning Lai",
      "Zhihao Shuai",
      "Yuan Tan",
      "Yifan Jia",
      "Mianyang Yu",
      "Zichen Song",
      "Xiaokang Peng",
      "Ziyang Xu",
      "Yongxin Ni",
      "Haifeng Qiu",
      "Jiayu Yang",
      "Yutong Liu",
      "Yonggang Lu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.12784",
    "title": "Learning to Walk and Fly with Adversarial Motion Priors",
    "abstract": " Comments: 8 pages, 8 figures, submitted to IROS 2024 ",
    "url": "https://arxiv.org/abs/2309.12784",
    "authors": [
      "Giuseppe L'Erario",
      "Drew Hanover",
      "Angel Romero",
      "Yunlong Song",
      "Gabriele Nava",
      "Paolo Maria Viceconte",
      "Daniele Pucci",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.12790",
    "title": "NTO3D: Neural Target Object 3D Reconstruction with Segment Anything",
    "abstract": " Comments: accepted by CVPR24 ",
    "url": "https://arxiv.org/abs/2309.12790",
    "authors": [
      "Xiaobao Wei",
      "Renrui Zhang",
      "Jiarui Wu",
      "Jiaming Liu",
      "Ming Lu",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15204",
    "title": "CLRmatchNet: Enhancing Curved Lane Detection with Deep Matching Process",
    "abstract": " Title: CLRmatchNet: Enhancing Curved Lane Detection with Deep Matching Process ",
    "url": "https://arxiv.org/abs/2309.15204",
    "authors": [
      "Sapir Kontente",
      "Roy Orfaig",
      "Ben-Zion Bobrovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00238",
    "title": "Feasibility-Guaranteed Safety-Critical Control with Applications to  Heterogeneous Platoons",
    "abstract": " Comments: 8 pages, 2 figures. arXiv admin note: text overlap with arXiv:2304.00372 ",
    "url": "https://arxiv.org/abs/2310.00238",
    "authors": [
      "Shuo Liu",
      "Wei Xiao",
      "Calin A. Belta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.01393",
    "title": "DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object  Detection",
    "abstract": " Title: DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object  Detection ",
    "url": "https://arxiv.org/abs/2310.01393",
    "authors": [
      "Shilin Xu",
      "Xiangtai Li",
      "Size Wu",
      "Wenwei Zhang",
      "Yunhai Tong",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06588",
    "title": "FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics",
    "abstract": " Title: FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics ",
    "url": "https://arxiv.org/abs/2310.06588",
    "authors": [
      "Yupei Du",
      "Albert Gatt",
      "Dong Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07676",
    "title": "Composite Backdoor Attacks Against Large Language Models",
    "abstract": " Comments: To Appear in Findings of the Association for Computational Linguistics: NAACL 2024, June 2024 ",
    "url": "https://arxiv.org/abs/2310.07676",
    "authors": [
      "Hai Huang",
      "Zhengyu Zhao",
      "Michael Backes",
      "Yun Shen",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07889",
    "title": "LangNav: Language as a Perceptual Representation for Navigation",
    "abstract": " Title: LangNav: Language as a Perceptual Representation for Navigation ",
    "url": "https://arxiv.org/abs/2310.07889",
    "authors": [
      "Bowen Pan",
      "Rameswar Panda",
      "SouYoung Jin",
      "Rogerio Feris",
      "Aude Oliva",
      "Phillip Isola",
      "Yoon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.09430",
    "title": "Assessing and Enhancing the Robustness of Large Language Models with  Task Structure Variations for Logical Reasoning",
    "abstract": " Comments: The short version (v3) was accepted for oral presentation at the first LLM@IJCAI 2023 non-archival symposium; the full version is under review ",
    "url": "https://arxiv.org/abs/2310.09430",
    "authors": [
      "Qiming Bao",
      "Gael Gendron",
      "Alex Yuxuan Peng",
      "Wanjun Zhong",
      "Neset Tan",
      "Yang Chen",
      "Michael Witbrock",
      "Jiamou Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09486",
    "title": "Mirage: Model-Agnostic Graph Distillation for Graph Classification",
    "abstract": " Comments: 14 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2310.09486",
    "authors": [
      "Mridul Gupta",
      "Sahil Manchanda",
      "Hariprasad Kodamana",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09892",
    "title": "Active Perception using Neural Radiance Fields",
    "abstract": " Title: Active Perception using Neural Radiance Fields ",
    "url": "https://arxiv.org/abs/2310.09892",
    "authors": [
      "Siming He",
      "Christopher D. Hsu",
      "Dexter Ong",
      "Yifei Simon Shao",
      "Pratik Chaudhari"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.17247",
    "title": "Grokking Beyond Neural Networks: An Empirical Exploration with Model  Complexity",
    "abstract": " Title: Grokking Beyond Neural Networks: An Empirical Exploration with Model  Complexity ",
    "url": "https://arxiv.org/abs/2310.17247",
    "authors": [
      "Jack Miller",
      "Charles O'Neill",
      "Thang Bui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.17584",
    "title": "A minimax optimal control approach for robust neural ODEs",
    "abstract": " Comments: 7 pages, 2 figures and 1 table. Correction of typos and improvement of Section 4 (Numerics) ",
    "url": "https://arxiv.org/abs/2310.17584",
    "authors": [
      "Cristina Cipriani",
      "Alessandro Scagliotti",
      "Tobias W\u00f6hrer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.18715",
    "title": "Robust Offline Reinforcement learning with Heavy-Tailed Rewards",
    "abstract": " Comments: 23 pages, 6 figures. Proceedings of the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024 ",
    "url": "https://arxiv.org/abs/2310.18715",
    "authors": [
      "Jin Zhu",
      "Runzhe Wan",
      "Zhengling Qi",
      "Shikai Luo",
      "Chengchun Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18964",
    "title": "LLMs and Finetuning: Benchmarking cross-domain performance for hate  speech detection",
    "abstract": " Comments: 9 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2310.18964",
    "authors": [
      "Ahmad Nasir",
      "Aadish Sharma",
      "Kokil Jaidka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.01276",
    "title": "Neural Atoms: Propagating Long-range Interaction in Molecular Graphs  through Efficient Communication Channel",
    "abstract": " Title: Neural Atoms: Propagating Long-range Interaction in Molecular Graphs  through Efficient Communication Channel ",
    "url": "https://arxiv.org/abs/2311.01276",
    "authors": [
      "Xuan Li",
      "Zhanke Zhou",
      "Jiangchao Yao",
      "Yu Rong",
      "Lu Zhang",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2311.03733",
    "title": "Improved weight initialization for deep and narrow feedforward neural  network",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2311.03733",
    "authors": [
      "Hyunwoo Lee",
      "Yunho Kim",
      "Seung Yeop Yang",
      "Hayoung Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.08118",
    "title": "Evaluating Neighbor Explainability for Graph Neural Networks",
    "abstract": " Title: Evaluating Neighbor Explainability for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2311.08118",
    "authors": [
      "Oscar Llorente",
      "Rana Fawzy",
      "Jared Keown",
      "Michal Horemuz",
      "P\u00e9ter Vaderna",
      "S\u00e1ndor Laki",
      "Roland Kotrocz\u00f3",
      "Rita Csoma",
      "J\u00e1nos M\u00e1rk Szalai-Gindl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08721",
    "title": "A Robust Semantics-based Watermark for Large Language Model against  Paraphrasing",
    "abstract": " Comments: Accepted to NAACL findings 2024 ",
    "url": "https://arxiv.org/abs/2311.08721",
    "authors": [
      "Jie Ren",
      "Han Xu",
      "Yiding Liu",
      "Yingqian Cui",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.08835",
    "title": "Correlation-guided Query-Dependency Calibration in Video Representation  Learning for Temporal Grounding",
    "abstract": " Comments: 34 pages, 16 figures, 13 tables, Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2311.08835",
    "authors": [
      "WonJun Moon",
      "Sangeek Hyun",
      "SuBeen Lee",
      "Jae-Pil Heo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09117",
    "title": "R-Spin: Efficient Speaker and Noise-invariant Representation Learning  with Acoustic Pieces",
    "abstract": " Comments: Accepted to NAACL 2024 ",
    "url": "https://arxiv.org/abs/2311.09117",
    "authors": [
      "Heng-Jui Chang",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.09174",
    "title": "AbsPyramid: Benchmarking the Abstraction Ability of Language Models with  a Unified Entailment Graph",
    "abstract": " Comments: Findings of NAACL2024 ",
    "url": "https://arxiv.org/abs/2311.09174",
    "authors": [
      "Zhaowei Wang",
      "Haochen Shi",
      "Weiqi Wang",
      "Tianqing Fang",
      "Hongming Zhang",
      "Sehyun Choi",
      "Xin Liu",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09618",
    "title": "Simulating Opinion Dynamics with Networks of LLM-based Agents",
    "abstract": " Title: Simulating Opinion Dynamics with Networks of LLM-based Agents ",
    "url": "https://arxiv.org/abs/2311.09618",
    "authors": [
      "Yun-Shiuan Chuang",
      "Agam Goyal",
      "Nikunj Harlalka",
      "Siddharth Suresh",
      "Robert Hawkins",
      "Sijia Yang",
      "Dhavan Shah",
      "Junjie Hu",
      "Timothy T. Rogers"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.10707",
    "title": "Multimodal Representation Learning by Alternating Unimodal Adaptation",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2311.10707",
    "authors": [
      "Xiaohui Zhang",
      "Jaehong Yoon",
      "Mohit Bansal",
      "Huaxiu Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12981",
    "title": "SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion",
    "abstract": " Comments: Accepted by ICLR 2024 TinyPapers ",
    "url": "https://arxiv.org/abs/2311.12981",
    "authors": [
      "Yueqian Lin",
      "Jingyang Zhang",
      "Yiran Chen",
      "Hai Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.13716",
    "title": "DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation  Networks for Remote Sensing Imagery",
    "abstract": " Title: DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation  Networks for Remote Sensing Imagery ",
    "url": "https://arxiv.org/abs/2311.13716",
    "authors": [
      "Wanli Ma",
      "Oktay Karakus",
      "Paul L. Rosin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.14218",
    "title": "A New Benchmark and Model for Challenging Image Manipulation Detection",
    "abstract": " Comments: 9 pages, 6 figures, 3 tabels. AAAI-24 ",
    "url": "https://arxiv.org/abs/2311.14218",
    "authors": [
      "Zhenfei Zhang",
      "Mingyang Li",
      "Ming-Ching Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.14496",
    "title": "RTPS Attack Dataset Description",
    "abstract": " Comments: This manuscript is written in Korean. You can download our dataset through our lab: this https URL We welcome your comments or feedback. Contact INFO: Dong Young Kim (klgh1256@korea.ac.kr), Huy Kang Kim (cenda@korea.ac.kr) ",
    "url": "https://arxiv.org/abs/2311.14496",
    "authors": [
      "Dong Young Kim",
      "Dongsung Kim",
      "Yuchan Song",
      "Gang Min Kim",
      "Min Geun Song",
      "Jeong Do Yoo",
      "Huy Kang Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.15011",
    "title": "VSCode: General Visual Salient and Camouflaged Object Detection with 2D  Prompt Learning",
    "abstract": " Title: VSCode: General Visual Salient and Camouflaged Object Detection with 2D  Prompt Learning ",
    "url": "https://arxiv.org/abs/2311.15011",
    "authors": [
      "Ziyang Luo",
      "Nian Liu",
      "Wangbo Zhao",
      "Xuguang Yang",
      "Dingwen Zhang",
      "Deng-Ping Fan",
      "Fahad Khan",
      "Junwei Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17516",
    "title": "MMA-Diffusion: MultiModal Attack on Diffusion Models",
    "abstract": " Comments: CVPR 2024. Our codes and benchmarks are available at this https URL ",
    "url": "https://arxiv.org/abs/2311.17516",
    "authors": [
      "Yijun Yang",
      "Ruiyuan Gao",
      "Xiaosen Wang",
      "Tsung-Yi Ho",
      "Nan Xu",
      "Qiang Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01196",
    "title": "Neural Parametric Gaussians for Monocular Non-Rigid Object  Reconstruction",
    "abstract": " Comments: Accepted at CVPR 2024 | Project Website: this https URL ",
    "url": "https://arxiv.org/abs/2312.01196",
    "authors": [
      "Devikalyan Das",
      "Christopher Wewer",
      "Raza Yunus",
      "Eddy Ilg",
      "Jan Eric Lenssen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.02142",
    "title": "Object Recognition as Next Token Prediction",
    "abstract": " Comments: CVPR 2024 ",
    "url": "https://arxiv.org/abs/2312.02142",
    "authors": [
      "Kaiyu Yue",
      "Bor-Chun Chen",
      "Jonas Geiping",
      "Hengduo Li",
      "Tom Goldstein",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.02224",
    "title": "Tracing Hyperparameter Dependencies for Model Parsing via Learnable  Graph Pooling Network",
    "abstract": " Comments: 24 pages, 15 figures, 17 tables ",
    "url": "https://arxiv.org/abs/2312.02224",
    "authors": [
      "Xiao Guo",
      "Vishal Asnani",
      "Sijia Liu",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.03041",
    "title": "Transformer-Based Deep Learning Model for Bored Pile Load-Deformation  Prediction in Bangkok Subsoil",
    "abstract": " Title: Transformer-Based Deep Learning Model for Bored Pile Load-Deformation  Prediction in Bangkok Subsoil ",
    "url": "https://arxiv.org/abs/2312.03041",
    "authors": [
      "Sompote Youwai",
      "Chissanupong Thongnoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2312.04551",
    "title": "Free3D: Consistent Novel View Synthesis without 3D Representation",
    "abstract": " Comments: webpage: this https URL, code: this https URL ",
    "url": "https://arxiv.org/abs/2312.04551",
    "authors": [
      "Chuanxia Zheng",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.05716",
    "title": "Initialization Matters for Adversarial Transfer Learning",
    "abstract": " Comments: CVPR 2024 ",
    "url": "https://arxiv.org/abs/2312.05716",
    "authors": [
      "Andong Hua",
      "Jindong Gu",
      "Zhiyu Xue",
      "Nicholas Carlini",
      "Eric Wong",
      "Yao Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.06226",
    "title": "Invariant Representation via Decoupling Style and Spurious Features from  Images",
    "abstract": " Comments: 10 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2312.06226",
    "authors": [
      "Ruimeng Li",
      "Yuanhao Pu",
      "Zhaoyi Li",
      "Hong Xie",
      "Defu Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08356",
    "title": "CUTTANA: Scalable Graph Partitioning for Faster Distributed Graph  Databases and Analytics",
    "abstract": " Comments: Preprint version, Under-review, Code available after reviews ",
    "url": "https://arxiv.org/abs/2312.08356",
    "authors": [
      "Milad Rezaei Hajidehi",
      "Sraavan Sridhar",
      "Margo Seltzer"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.09243",
    "title": "OccNeRF: Advancing 3D Occupancy Prediction in LiDAR-Free Environments",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2312.09243",
    "authors": [
      "Chubin Zhang",
      "Juncheng Yan",
      "Yi Wei",
      "Jiaxin Li",
      "Li Liu",
      "Yansong Tang",
      "Yueqi Duan",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.11575",
    "title": "Blind-Touch: Homomorphic Encryption-Based Distributed Neural Network  Inference for Privacy-Preserving Fingerprint Authentication",
    "abstract": " Comments: The 38th Annual AAAI Conference on Artificial Intelligence (AAAI) 2024 ",
    "url": "https://arxiv.org/abs/2312.11575",
    "authors": [
      "Hyunmin Choi",
      "Simon Woo",
      "Hyoungshick Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.14024",
    "title": "NICP: Neural ICP for 3D Human Registration at Scale",
    "abstract": " Title: NICP: Neural ICP for 3D Human Registration at Scale ",
    "url": "https://arxiv.org/abs/2312.14024",
    "authors": [
      "Riccardo Marin",
      "Enric Corona",
      "Gerard Pons-Moll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.16457",
    "title": "City-on-Web: Real-time Neural Rendering of Large-scale Scenes on the Web",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2312.16457",
    "authors": [
      "Kaiwen Song",
      "Xiaoyi Zeng",
      "Chenqu Ren",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2401.00104",
    "title": "Causal State Distillation for Explainable Reinforcement Learning",
    "abstract": " Comments: this https URL; Accepted as oral by CLeaR 2024 ",
    "url": "https://arxiv.org/abs/2401.00104",
    "authors": [
      "Wenhao Lu",
      "Xufeng Zhao",
      "Thilo Fryen",
      "Jae Hee Lee",
      "Mengdi Li",
      "Sven Magg",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2401.01482",
    "title": "Incorporating Geo-Diverse Knowledge into Prompting for Increased  Geographical Robustness in Object Recognition",
    "abstract": " Comments: To appear in IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR), 2024 ",
    "url": "https://arxiv.org/abs/2401.01482",
    "authors": [
      "Kyle Buettner",
      "Sina Malakouti",
      "Xiang Lorraine Li",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.04071",
    "title": "Fun with Flags: Robust Principal Directions via Flag Manifolds",
    "abstract": " Title: Fun with Flags: Robust Principal Directions via Flag Manifolds ",
    "url": "https://arxiv.org/abs/2401.04071",
    "authors": [
      "Nathan Mankovich",
      "Gustau Camps-Valls",
      "Tolga Birdal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.04105",
    "title": "Dr$^2$Net: Dynamic Reversible Dual-Residual Networks for  Memory-Efficient Finetuning",
    "abstract": " Title: Dr$^2$Net: Dynamic Reversible Dual-Residual Networks for  Memory-Efficient Finetuning ",
    "url": "https://arxiv.org/abs/2401.04105",
    "authors": [
      "Chen Zhao",
      "Shuming Liu",
      "Karttikeya Mangalam",
      "Guocheng Qian",
      "Fatimah Zohra",
      "Abdulmohsen Alghannam",
      "Jitendra Malik",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.05698",
    "title": "HiCMAE: Hierarchical Contrastive Masked Autoencoder for Self-Supervised  Audio-Visual Emotion Recognition",
    "abstract": " Comments: Accepted by Information Fusion. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2401.05698",
    "authors": [
      "Licai Sun",
      "Zheng Lian",
      "Bin Liu",
      "Jianhua Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2401.08409",
    "title": "Faster ISNet for Background Bias Mitigation on Deep Neural Networks",
    "abstract": " Title: Faster ISNet for Background Bias Mitigation on Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2401.08409",
    "authors": [
      "Pedro R. A. S. Bassi",
      "Sergio Decherchi",
      "Andrea Cavalli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.10171",
    "title": "SHINOBI: Shape and Illumination using Neural Object Decomposition via  BRDF Optimization In-the-wild",
    "abstract": " Comments: Accepted by IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024). Updated supplementary material and acknowledgements ",
    "url": "https://arxiv.org/abs/2401.10171",
    "authors": [
      "Andreas Engelhardt",
      "Amit Raj",
      "Mark Boss",
      "Yunzhi Zhang",
      "Abhishek Kar",
      "Yuanzhen Li",
      "Deqing Sun",
      "Ricardo Martin Brualla",
      "Jonathan T. Barron",
      "Hendrik P. A. Lensch",
      "Varun Jampani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2401.12610",
    "title": "The twin peaks of learning neural networks",
    "abstract": " Comments: 37 pages, 31 figures ",
    "url": "https://arxiv.org/abs/2401.12610",
    "authors": [
      "Elizaveta Demyanenko",
      "Christoph Feinauer",
      "Enrico M. Malatesta",
      "Luca Saglietti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2401.12987",
    "title": "TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition  in Conversation",
    "abstract": " Comments: NAACL 2024 main conference ",
    "url": "https://arxiv.org/abs/2401.12987",
    "authors": [
      "Taeyang Yun",
      "Hyunkuk Lim",
      "Jeonghwan Lee",
      "Min Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2401.13964",
    "title": "An Extensible Framework for Open Heterogeneous Collaborative Perception",
    "abstract": " Comments: Accepted by ICLR 2024. The code and data are open-sourced at this https URL ",
    "url": "https://arxiv.org/abs/2401.13964",
    "authors": [
      "Yifan Lu",
      "Yue Hu",
      "Yiqi Zhong",
      "Dequan Wang",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.14295",
    "title": "Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of  Thoughts",
    "abstract": " Title: Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of  Thoughts ",
    "url": "https://arxiv.org/abs/2401.14295",
    "authors": [
      "Maciej Besta",
      "Florim Memedi",
      "Zhenyu Zhang",
      "Robert Gerstenberger",
      "Guangyuan Piao",
      "Nils Blach",
      "Piotr Nyczyk",
      "Marcin Copik",
      "Grzegorz Kwa\u015bniewski",
      "J\u00fcrgen M\u00fcller",
      "Lukas Gianinazzi",
      "Ales Kubicek",
      "Hubert Niewiadomski",
      "Aidan O'Mahony",
      "Onur Mutlu",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.17513",
    "title": "A PNP ion channel deep learning solver with local neural network and  finite element input data",
    "abstract": " Comments: 17 pages, 4 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2401.17513",
    "authors": [
      "Hwi Lee",
      "Zhen Chao",
      "Harris Cobb",
      "Yingjie Liu",
      "Dexuan Xie"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2402.02277",
    "title": "Causal Bayesian Optimization via Exogenous Distribution Learning",
    "abstract": " Title: Causal Bayesian Optimization via Exogenous Distribution Learning ",
    "url": "https://arxiv.org/abs/2402.02277",
    "authors": [
      "Shaogang Ren",
      "Xiaoning Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.03355",
    "title": "Unlocking Criminal Hierarchies: A Survey, Experimental, and Comparative  Exploration of Techniques for Identifying Leaders within Criminal Networks",
    "abstract": " Title: Unlocking Criminal Hierarchies: A Survey, Experimental, and Comparative  Exploration of Techniques for Identifying Leaders within Criminal Networks ",
    "url": "https://arxiv.org/abs/2402.03355",
    "authors": [
      "Kamal Taha",
      "Abdulhadi Shoufan",
      "Aya Taha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.03769",
    "title": "AttackNet: Enhancing Biometric Security via Tailored Convolutional  Neural Network Architectures for Liveness Detection",
    "abstract": " Title: AttackNet: Enhancing Biometric Security via Tailored Convolutional  Neural Network Architectures for Liveness Detection ",
    "url": "https://arxiv.org/abs/2402.03769",
    "authors": [
      "Oleksandr Kuznetsov",
      "Dmytro Zakharov",
      "Emanuele Frontoni",
      "Andrea Maranesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2402.07365",
    "title": "A Deep Learning Method for Optimal Investment Under Relative Performance  Criteria Among Heterogeneous Agents",
    "abstract": " Title: A Deep Learning Method for Optimal Investment Under Relative Performance  Criteria Among Heterogeneous Agents ",
    "url": "https://arxiv.org/abs/2402.07365",
    "authors": [
      "Mathieu Lauri\u00e8re",
      "Ludovic Tangpi",
      "Xuchen Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12259",
    "title": "Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds with  Queryable Objects and Open-Set Relationships",
    "abstract": " Comments: CVPR 2024. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2402.12259",
    "authors": [
      "Sebastian Koch",
      "Narunas Vaskevicius",
      "Mirco Colosi",
      "Pedro Hermosilla",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.16774",
    "title": "Video-Based Autism Detection with Deep Learning",
    "abstract": " Comments: Poster Abstract. Accepted into 2024 IEEE Green Technologies Conference ",
    "url": "https://arxiv.org/abs/2402.16774",
    "authors": [
      "M. Serna-Aguilera",
      "X. B. Nguyen",
      "A. Singh",
      "L. Rockers",
      "S. Park",
      "L. Neely",
      "H. Seo",
      "K. Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17916",
    "title": "LLM-Resistant Math Word Problem Generation via Adversarial Attacks",
    "abstract": " Comments: Code/data: this https URL ",
    "url": "https://arxiv.org/abs/2402.17916",
    "authors": [
      "Roy Xie",
      "Chengxuan Huang",
      "Junlin Wang",
      "Bhuwan Dhingra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.18933",
    "title": "Modality-Agnostic Structural Image Representation Learning for  Deformable Multi-Modality Medical Image Registration",
    "abstract": " Comments: Accepted by CVPR2024 ",
    "url": "https://arxiv.org/abs/2402.18933",
    "authors": [
      "Tony C. W. Mok",
      "Zi Li",
      "Yunhao Bai",
      "Jianpeng Zhang",
      "Wei Liu",
      "Yan-Jie Zhou",
      "Ke Yan",
      "Dakai Jin",
      "Yu Shi",
      "Xiaoli Yin",
      "Le Lu",
      "Ling Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.19231",
    "title": "CricaVPR: Cross-image Correlation-aware Representation Learning for  Visual Place Recognition",
    "abstract": " Comments: Accepted by CVPR2024 ",
    "url": "https://arxiv.org/abs/2402.19231",
    "authors": [
      "Feng Lu",
      "Xiangyuan Lan",
      "Lijun Zhang",
      "Dongmei Jiang",
      "Yaowei Wang",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.00344",
    "title": "Robustifying a Policy in Multi-Agent RL with Diverse Cooperative  Behaviors and Adversarial Style Sampling for Assistive Tasks",
    "abstract": " Comments: 7 pages, accepted for ICRA 2024 ",
    "url": "https://arxiv.org/abs/2403.00344",
    "authors": [
      "Takayuki Osa",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.01414",
    "title": "Unsigned Orthogonal Distance Fields: An Accurate Neural Implicit  Representation for Diverse 3D Shapes",
    "abstract": " Comments: accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.01414",
    "authors": [
      "Yujie Lu",
      "Long Wan",
      "Nayu Ding",
      "Yulong Wang",
      "Shuhan Shen",
      "Shen Cai",
      "Lin Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08848",
    "title": "FocusMAE: Gallbladder Cancer Detection from Ultrasound Videos with  Focused Masked Autoencoders",
    "abstract": " Comments: To Appear at CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.08848",
    "authors": [
      "Soumen Basu",
      "Mayuna Gupta",
      "Chetan Madan",
      "Pankaj Gupta",
      "Chetan Arora"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09817",
    "title": "Impact of Objective Function on Spectral Efficiency in Integrated  HAPS-Terrestrial Networks",
    "abstract": " Comments: 6 Pages, Accepted by ICC Workshop on Emerging Technologies in Aerial and Space Networks ",
    "url": "https://arxiv.org/abs/2403.09817",
    "authors": [
      "Afsoon Alidadi Shamsabadi",
      "Animesh Yadav",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.11270",
    "title": "Bilateral Propagation Network for Depth Completion",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.11270",
    "authors": [
      "Jie Tang",
      "Fei-Peng Tian",
      "Boshi An",
      "Jian Li",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.12418",
    "title": "STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space  Model",
    "abstract": " Title: STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space  Model ",
    "url": "https://arxiv.org/abs/2403.12418",
    "authors": [
      "Lincan Li",
      "Hanchen Wang",
      "Wenjie Zhang",
      "Adelle Coster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.13362",
    "title": "Incentivizing News Consumption on Social Media Platforms Using Large  Language Models and Realistic Bot Accounts",
    "abstract": " Title: Incentivizing News Consumption on Social Media Platforms Using Large  Language Models and Realistic Bot Accounts ",
    "url": "https://arxiv.org/abs/2403.13362",
    "authors": [
      "Hadi Askari",
      "Anshuman Chhabra",
      "Bernhard Clemm von Hohenberg",
      "Michael Heseltine",
      "Magdalena Wojcieszak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.15443",
    "title": "Introducing an ensemble method for the early detection of Alzheimer's  disease through the analysis of PET scan images",
    "abstract": " Title: Introducing an ensemble method for the early detection of Alzheimer's  disease through the analysis of PET scan images ",
    "url": "https://arxiv.org/abs/2403.15443",
    "authors": [
      "Arezoo Borji",
      "Taha-Hossein Hejazi",
      "Abbas Seifi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.15638",
    "title": "Differentially Private Next-Token Prediction of Large Language Models",
    "abstract": " Title: Differentially Private Next-Token Prediction of Large Language Models ",
    "url": "https://arxiv.org/abs/2403.15638",
    "authors": [
      "James Flemings",
      "Meisam Razaviyayn",
      "Murali Annavaram"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.15918",
    "title": "An Embarrassingly Simple Defense Against Backdoor Attacks On SSL",
    "abstract": " Comments: 10 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2403.15918",
    "authors": [
      "Aryan Satpathy",
      "Nilaksh Nilaksh",
      "Dhruva Rajwade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15955",
    "title": "Finding needles in a haystack: A Black-Box Approach to Invisible  Watermark Detection",
    "abstract": " Title: Finding needles in a haystack: A Black-Box Approach to Invisible  Watermark Detection ",
    "url": "https://arxiv.org/abs/2403.15955",
    "authors": [
      "Minzhou Pan",
      "Zhenting Wang",
      "Xin Dong",
      "Vikash Sehwag",
      "Lingjuan Lyu",
      "Xue Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.16051",
    "title": "Segment Anything Model for Road Network Graph Extraction",
    "abstract": " Title: Segment Anything Model for Road Network Graph Extraction ",
    "url": "https://arxiv.org/abs/2403.16051",
    "authors": [
      "Congrui Hetang",
      "Haoru Xue",
      "Cindy Le",
      "Tianwei Yue",
      "Wenping Wang",
      "Yihui He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.16055",
    "title": "Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from  Monetary Policy Conference Calls with LLM",
    "abstract": " Comments: Accepted by LREC Coling 2024 -FinNLP ",
    "url": "https://arxiv.org/abs/2403.16055",
    "authors": [
      "Kun Ouyang",
      "Yi Liu",
      "Shicheng Li",
      "Ruihan Bao",
      "Keiko Harimoto",
      "Xu Sun"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2403.16479",
    "title": "Model-less Is the Best Model: Generating Pure Code Implementations to  Replace On-Device DL Models",
    "abstract": " Comments: Accepted by the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA2024) ",
    "url": "https://arxiv.org/abs/2403.16479",
    "authors": [
      "Mingyi Zhou",
      "Xiang Gao",
      "Pei Liu",
      "John Grundy",
      "Chunyang Chen",
      "Xiao Chen",
      "Li Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.17683",
    "title": "Solution for Emotion Prediction Competition of Workshop on Emotionally  and Culturally Intelligent AI",
    "abstract": " Title: Solution for Emotion Prediction Competition of Workshop on Emotionally  and Culturally Intelligent AI ",
    "url": "https://arxiv.org/abs/2403.17683",
    "authors": [
      "Shengdong Xu",
      "Zhouyang Chi",
      "Yang Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.18539",
    "title": "Safe and Robust Reinforcement Learning: Principles and Practice",
    "abstract": " Title: Safe and Robust Reinforcement Learning: Principles and Practice ",
    "url": "https://arxiv.org/abs/2403.18539",
    "authors": [
      "Taku Yamagata",
      "Raul Santos-Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.18710",
    "title": "Energy-Guided Data Sampling for Traffic Prediction with Mini Training  Datasets",
    "abstract": " Title: Energy-Guided Data Sampling for Traffic Prediction with Mini Training  Datasets ",
    "url": "https://arxiv.org/abs/2403.18710",
    "authors": [
      "Zhaohui Yang",
      "Kshitij Jerath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.19001",
    "title": "Cross-domain Fiber Cluster Shape Analysis for Language Performance  Cognitive Score Prediction",
    "abstract": " Comments: 2 figures, 11 pages ",
    "url": "https://arxiv.org/abs/2403.19001",
    "authors": [
      "Yui Lo",
      "Yuqian Chen",
      "Dongnan Liu",
      "Wan Liu",
      "Leo Zekelman",
      "Fan Zhang",
      "Yogesh Rathi",
      "Nikos Makris",
      "Alexandra J. Golby",
      "Weidong Cai",
      "Lauren J. O'Donnell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2403.19002",
    "title": "Robust Active Speaker Detection in Noisy Environments",
    "abstract": " Comments: 15 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2403.19002",
    "authors": [
      "Siva Sai Nagender Vasireddy",
      "Chenxu Zhang",
      "Xiaohu Guo",
      "Yapeng Tian"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.19026",
    "title": "Egocentric Scene-aware Human Trajectory Prediction",
    "abstract": " Comments: 14 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2403.19026",
    "authors": [
      "Weizhuo Wang",
      "C. Karen Liu",
      "Monroe Kennedy III"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19180",
    "title": "A Robust UWOC-assisted Multi-hop Topology for Underwater Sensor Network  Nodes",
    "abstract": " Title: A Robust UWOC-assisted Multi-hop Topology for Underwater Sensor Network  Nodes ",
    "url": "https://arxiv.org/abs/2403.19180",
    "authors": [
      "Maaz Salman",
      "Javad Bolboli",
      "Wan-Young Chung"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2403.19433",
    "title": "Puzzle game: Prediction and Classification of Wordle Solution Words",
    "abstract": " Comments: 19 pages, 19 figures, MCM/ICM 2023 Award winning Paper ",
    "url": "https://arxiv.org/abs/2403.19433",
    "authors": [
      "Haidong Xin",
      "Fang Wu",
      "Zhitong Zhou",
      "Shujuan Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.19561",
    "title": "Self-Improved Learning for Scalable Neural Combinatorial Optimization",
    "abstract": " Title: Self-Improved Learning for Scalable Neural Combinatorial Optimization ",
    "url": "https://arxiv.org/abs/2403.19561",
    "authors": [
      "Fu Luo",
      "Xi Lin",
      "Zhenkun Wang",
      "Xialiang Tong",
      "Mingxuan Yuan",
      "Qingfu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.19647",
    "title": "Sparse Feature Circuits: Discovering and Editing Interpretable Causal  Graphs in Language Models",
    "abstract": " Comments: Code and data at this https URL Demonstration at this https URL ",
    "url": "https://arxiv.org/abs/2403.19647",
    "authors": [
      "Samuel Marks",
      "Can Rager",
      "Eric J. Michaud",
      "Yonatan Belinkov",
      "David Bau",
      "Aaron Mueller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.19797",
    "title": "Efficient 3D Instance Mapping and Localization with Neural Fields",
    "abstract": " Title: Efficient 3D Instance Mapping and Localization with Neural Fields ",
    "url": "https://arxiv.org/abs/2403.19797",
    "authors": [
      "George Tang",
      "Krishna Murthy Jatavallabhula",
      "Antonio Torralba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20261",
    "title": "FABind+: Enhancing Molecular Docking through Improved Pocket Prediction  and Pose Generation",
    "abstract": " Comments: 17 pages, 14 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2403.20261",
    "authors": [
      "Kaiyuan Gao",
      "Qizhi Pei",
      "Jinhua Zhu",
      "Tao Qin",
      "Kun He",
      "Lijun Wu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]