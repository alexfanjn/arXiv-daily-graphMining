[
  {
    "id": "arXiv:2403.19721",
    "title": "Computationally and Memory-Efficient Robust Predictive Analytics Using  Big Data",
    "abstract": "In the current data-intensive era, big data has become a significant asset for Artificial Intelligence (AI), serving as a foundation for developing data-driven models and providing insight into various unknown fields. This study navigates through the challenges of data uncertainties, storage limitations, and predictive data-driven modeling using big data. We utilize Robust Principal Component Analysis (RPCA) for effective noise reduction and outlier elimination, and Optimal Sensor Placement (OSP) for efficient data compression and storage. The proposed OSP technique enables data compression without substantial information loss while simultaneously reducing storage needs. While RPCA offers an enhanced alternative to traditional Principal Component Analysis (PCA) for high-dimensional data management, the scope of this work extends its utilization, focusing on robust, data-driven modeling applicable to huge data sets in real-time. For that purpose, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network, are applied to model and predict data based on a low-dimensional subset obtained from OSP, leading to a crucial acceleration of the training phase. LSTMs are feasible for capturing long-term dependencies in time series data, making them particularly suited for predicting the future states of physical systems on historical data. All the presented algorithms are not only theorized but also simulated and validated using real thermal imaging data mapping a ship's engine. ",
    "url": "https://arxiv.org/abs/2403.19721",
    "authors": [
      "Daniel Menges",
      "Adil Rasheed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.19723",
    "title": "HGT: Leveraging Heterogeneous Graph-enhanced Large Language Models for  Few-shot Complex Table Understanding",
    "abstract": "Table understanding (TU) has achieved promising advancements, but it faces the challenges of the scarcity of manually labeled tables and the presence of complex table structures.To address these challenges, we propose HGT, a framework with a heterogeneous graph (HG)-enhanced large language model (LLM) to tackle few-shot TU tasks.It leverages the LLM by aligning the table semantics with the LLM's parametric knowledge through soft prompts and instruction turning and deals with complex tables by a multi-task pre-training scheme involving three novel multi-granularity self-supervised HG pre-training objectives.We empirically demonstrate the effectiveness of HGT, showing that it outperforms the SOTA for few-shot complex TU on several benchmarks. ",
    "url": "https://arxiv.org/abs/2403.19723",
    "authors": [
      "Rihui Jin",
      "Yu Li",
      "Guilin Qi",
      "Nan Hu",
      "Yuan-Fang Li",
      "Jiaoyan Chen",
      "Jianan Wang",
      "Yongrui Chen",
      "Dehai Min"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.19725",
    "title": "MUGC: Machine Generated versus User Generated Content Detection",
    "abstract": "As advanced modern systems like deep neural networks (DNNs) and generative AI continue to enhance their capabilities in producing convincing and realistic content, the need to distinguish between user-generated and machine generated content is becoming increasingly evident. In this research, we undertake a comparative evaluation of eight traditional machine-learning algorithms to distinguish between machine-generated and human-generated data across three diverse datasets: Poems, Abstracts, and Essays. Our results indicate that traditional methods demonstrate a high level of accuracy in identifying machine-generated data, reflecting the documented effectiveness of popular pre-trained models like RoBERT. We note that machine-generated texts tend to be shorter and exhibit less word variety compared to human-generated content. While specific domain-related keywords commonly utilized by humans, albeit disregarded by current LLMs (Large Language Models), may contribute to this high detection accuracy, we show that deeper word representations like word2vec can capture subtle semantic variances. Furthermore, readability, bias, moral, and affect comparisons reveal a discernible contrast between machine-generated and human generated content. There are variations in expression styles and potentially underlying biases in the data sources (human and machine-generated). This study provides valuable insights into the advancing capacities and challenges associated with machine-generated content across various domains. ",
    "url": "https://arxiv.org/abs/2403.19725",
    "authors": [
      "Yaqi Xie",
      "Anjali Rawal",
      "Yujing Cen",
      "Dixuan Zhao",
      "Sunil K Narang",
      "Shanu Sushmita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.19729",
    "title": "Is the edge really necessary for drone computing offloading? An  experimental assessment in carrier-grade 5G operator networks",
    "abstract": "In this article, we evaluate the first experience of computation offloading from drones to real fifth-generation (5G) operator systems, including commercial and private carrier-grade 5G networks. A follow-me drone service was implemented as a representative testbed of remote video analytics. In this application, an image of a person from a drone camera is processed at the edge, and image tracking displacements are translated into positioning commands that are sent back to the drone, so that the drone keeps the camera focused on the person at all times. The application is characterised to identify the processing and communication contributions to service delay. Then, we evaluate the latency of the application in a real non standalone 5G operator network, a standalone carrier-grade 5G private network, and, to compare these results with previous research, a Wi-Fi wireless local area network. We considered both multi-access edge computing (MEC) and cloud offloading scenarios. Onboard computing was also evaluated to assess the trade-offs with task offloading. The results determine the network configurations that are feasible for the follow-me application use case depending on the mobility of the end user, and to what extent MEC is advantageous over a state-of-the-art cloud service. ",
    "url": "https://arxiv.org/abs/2403.19729",
    "authors": [
      "David Candal-Ventureira",
      "Francisco Javier Gonz\u00e1lez-Casta\u00f1o",
      "Felipe Gil-Casti\u00f1eira",
      "Pablo Fondo-Ferreiro"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.19731",
    "title": "Quarantining Malicious IoT Devices in Intelligent Sliced Mobile Networks",
    "abstract": "The unstoppable adoption of the Internet of Things (IoT) is driven by the deployment of new services that require continuous capture of information from huge populations of sensors, or actuating over a myriad of \"smart\" objects. Accordingly, next generation networks are being designed to support such massive numbers of devices and connections. For example, the 3rd Generation Partnership Project (3GPP) is designing the different 5G releases specifically with IoT in mind. Nevertheless, from a security perspective this scenario is a potential nightmare: the attack surface becomes wider and many IoT nodes do not have enough resources to support advanced security protocols. In fact, security is rarely a priority in their design. Thus, including network-level mechanisms for preventing attacks from malware-infected IoT devices is mandatory to avert further damage. In this paper, we propose a novel Software-Defined Networking (SDN)-based architecture to identify suspicious nodes in 4G or 5G networks and redirect their traffic to a secondary network slice where traffic is analyzed in depth before allowing it reaching its destination. The architecture can be easily integrated in any existing deployment due to its interoperability. By following this approach, we can detect potential threats at an early stage and limit the damage by Distributed Denial of Service (DDoS) attacks originated in IoT devices. ",
    "url": "https://arxiv.org/abs/2403.19731",
    "authors": [
      "David Candal-Ventureira",
      "Pablo Fondo-Ferreiro",
      "Felipe Gil-Casti\u00f1eira",
      "Francisco Javier Gonz\u00e1lez-Casta\u00f1o"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.19780",
    "title": "Mitigating Motion Blur in Neural Radiance Fields with Events and Frames",
    "abstract": "Neural Radiance Fields (NeRFs) have shown great potential in novel view synthesis. However, they struggle to render sharp images when the data used for training is affected by motion blur. On the other hand, event cameras excel in dynamic scenes as they measure brightness changes with microsecond resolution and are thus only marginally affected by blur. Recent methods attempt to enhance NeRF reconstructions under camera motion by fusing frames and events. However, they face challenges in recovering accurate color content or constrain the NeRF to a set of predefined camera poses, harming reconstruction quality in challenging conditions. This paper proposes a novel formulation addressing these issues by leveraging both model- and learning-based modules. We explicitly model the blur formation process, exploiting the event double integral as an additional model-based prior. Additionally, we model the event-pixel response using an end-to-end learnable response function, allowing our method to adapt to non-idealities in the real event-camera sensor. We show, on synthetic and real data, that the proposed approach outperforms existing deblur NeRFs that use only frames as well as those that combine frames and events by +6.13dB and +2.48dB, respectively. ",
    "url": "https://arxiv.org/abs/2403.19780",
    "authors": [
      "Marco Cannici",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19782",
    "title": "ENet-21: An Optimized light CNN Structure for Lane Detection",
    "abstract": "Lane detection for autonomous vehicles is an important concept, yet it is a challenging issue of driver assistance systems in modern vehicles. The emergence of deep learning leads to significant progress in self-driving cars. Conventional deep learning-based methods handle lane detection problems as a binary segmentation task and determine whether a pixel belongs to a line. These methods rely on the assumption of a fixed number of lanes, which does not always work. This study aims to develop an optimal structure for the lane detection problem, offering a promising solution for driver assistance features in modern vehicles by utilizing a machine learning method consisting of binary segmentation and Affinity Fields that can manage varying numbers of lanes and lane change scenarios. In this approach, the Convolutional Neural Network (CNN), is selected as a feature extractor, and the final output is obtained through clustering of the semantic segmentation and Affinity Field outputs. Our method uses less complex CNN architecture than exi ",
    "url": "https://arxiv.org/abs/2403.19782",
    "authors": [
      "Seyed Rasoul Hosseini",
      "Mohammad Teshnehlab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19785",
    "title": "Integrated Communication, Localization, and Sensing in 6G D-MIMO  Networks",
    "abstract": "Future generations of mobile networks call for concurrent sensing and communication functionalities in the same hardware and/or spectrum. Compared to communication, sensing services often suffer from limited coverage, due to the high path loss of the reflected signal and the increased infrastructure requirements. To provide a more uniform quality of service, distributed multiple input multiple output (D-MIMO) systems deploy a large number of distributed nodes and efficiently control them, making distributed integrated sensing and communications (ISAC) possible. In this paper, we investigate ISAC in D-MIMO through the lens of different design architectures and deployments, revealing both conflicts and synergies. In addition, simulation and demonstration results reveal both opportunities and challenges towards the implementation of ISAC in D-MIMO. ",
    "url": "https://arxiv.org/abs/2403.19785",
    "authors": [
      "Hao Guo",
      "Henk Wymeersch",
      "Behrooz Makki",
      "Hui Chen",
      "Yibo Wu",
      "Giuseppe Durisi",
      "Musa Furkan Keskin",
      "Mohammad H. Moghaddam",
      "Charitha Madapatha",
      "Han Yu",
      "Peter Hammarberg",
      "Hyowon Kim",
      "Tommy Svensson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.19797",
    "title": "Efficient 3D Instance Mapping and Localization with Neural Fields",
    "abstract": "We tackle the problem of learning an implicit scene representation for 3D instance segmentation from a sequence of posed RGB images. Towards this, we introduce 3DIML, a novel framework that efficiently learns a label field that may be rendered from novel viewpoints to produce view-consistent instance segmentation masks. 3DIML significantly improves upon training and inference runtimes of existing implicit scene representation based methods. Opposed to prior art that optimizes a neural field in a self-supervised manner, requiring complicated training procedures and loss function design, 3DIML leverages a two-phase process. The first phase, InstanceMap, takes as input 2D segmentation masks of the image sequence generated by a frontend instance segmentation model, and associates corresponding masks across images to 3D labels. These almost view-consistent pseudolabel masks are then used in the second phase, InstanceLift, to supervise the training of a neural label field, which interpolates regions missed by InstanceMap and resolves ambiguities. Additionally, we introduce InstanceLoc, which enables near realtime localization of instance masks given a trained label field and an off-the-shelf image segmentation model by fusing outputs from both. We evaluate 3DIML on sequences from the Replica and ScanNet datasets and demonstrate 3DIML's effectiveness under mild assumptions for the image sequences. We achieve a 14-24x speedup over existing implicit scene representation methods with comparable quality, showcasing its potential to facilitate faster and more effective 3D scene understanding. ",
    "url": "https://arxiv.org/abs/2403.19797",
    "authors": [
      "George Tang",
      "Krishna Murthy Jatavallabhula",
      "Antonio Torralba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19800",
    "title": "Gegenbauer Graph Neural Networks for Time-varying Signal Reconstruction",
    "abstract": "Reconstructing time-varying graph signals (or graph time-series imputation) is a critical problem in machine learning and signal processing with broad applications, ranging from missing data imputation in sensor networks to time-series forecasting. Accurately capturing the spatio-temporal information inherent in these signals is crucial for effectively addressing these tasks. However, existing approaches relying on smoothness assumptions of temporal differences and simple convex optimization techniques have inherent limitations. To address these challenges, we propose a novel approach that incorporates a learning module to enhance the accuracy of the downstream task. To this end, we introduce the Gegenbauer-based graph convolutional (GegenConv) operator, which is a generalization of the conventional Chebyshev graph convolution by leveraging the theory of Gegenbauer polynomials. By deviating from traditional convex problems, we expand the complexity of the model and offer a more accurate solution for recovering time-varying graph signals. Building upon GegenConv, we design the Gegenbauer-based time Graph Neural Network (GegenGNN) architecture, which adopts an encoder-decoder structure. Likewise, our approach also utilizes a dedicated loss function that incorporates a mean squared error component alongside Sobolev smoothness regularization. This combination enables GegenGNN to capture both the fidelity to ground truth and the underlying smoothness properties of the signals, enhancing the reconstruction performance. We conduct extensive experiments on real datasets to evaluate the effectiveness of our proposed approach. The experimental results demonstrate that GegenGNN outperforms state-of-the-art methods, showcasing its superior capability in recovering time-varying graph signals. ",
    "url": "https://arxiv.org/abs/2403.19800",
    "authors": [
      "Jhon A. Castro-Correa",
      "Jhony H. Giraldo",
      "Mohsen Badiey",
      "Fragkiskos D. Malliaros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.19802",
    "title": "Developing Healthcare Language Model Embedding Spaces",
    "abstract": "Pre-trained Large Language Models (LLMs) often struggle on out-of-domain datasets like healthcare focused text. We explore specialized pre-training to adapt smaller LLMs to different healthcare datasets. Three methods are assessed: traditional masked language modeling, Deep Contrastive Learning for Unsupervised Textual Representations (DeCLUTR), and a novel pre-training objective utilizing metadata categories from the healthcare settings. These schemes are evaluated on downstream document classification tasks for each dataset, with additional analysis of the resultant embedding spaces. Contrastively trained models outperform other approaches on the classification tasks, delivering strong performance from limited labeled data and with fewer model parameter updates required. While metadata-based pre-training does not further improve classifications across the datasets, it yields interesting embedding cluster separability. All domain adapted LLMs outperform their publicly available general base LLM, validating the importance of domain-specialization. This research illustrates efficient approaches to instill healthcare competency in compact LLMs even under tight computational budgets, an essential capability for responsible and sustainable deployment in local healthcare settings. We provide pre-training guidelines for specialized healthcare LLMs, motivate continued inquiry into contrastive objectives, and demonstrates adaptation techniques to align small LLMs with privacy-sensitive medical tasks. ",
    "url": "https://arxiv.org/abs/2403.19802",
    "authors": [
      "Niall Taylor",
      "Dan Schofield",
      "Andrey Kormilitzin",
      "Dan W Joyce",
      "Alejo Nevado-Holgado"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.19836",
    "title": "Target Span Detection for Implicit Harmful Content",
    "abstract": "Identifying the targets of hate speech is a crucial step in grasping the nature of such speech and, ultimately, in improving the detection of offensive posts on online forums. Much harmful content on online platforms uses implicit language especially when targeting vulnerable and protected groups such as using stereotypical characteristics instead of explicit target names, making it harder to detect and mitigate the language. In this study, we focus on identifying implied targets of hate speech, essential for recognizing subtler hate speech and enhancing the detection of harmful content on digital platforms. We define a new task aimed at identifying the targets even when they are not explicitly stated. To address that task, we collect and annotate target spans in three prominent implicit hate speech datasets: SBIC, DynaHate, and IHC. We call the resulting merged collection Implicit-Target-Span. The collection is achieved using an innovative pooling method with matching scores based on human annotations and Large Language Models (LLMs). Our experiments indicate that Implicit-Target-Span provides a challenging test bed for target span detection methods. ",
    "url": "https://arxiv.org/abs/2403.19836",
    "authors": [
      "Nazanin Jafari",
      "James Allan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.19837",
    "title": "Concept-based Analysis of Neural Networks via Vision-Language Models",
    "abstract": "Formal analysis of vision-based deep neural networks (DNNs) is highly desirable but it is very challenging due to the difficulty of expressing formal specifications for vision tasks and the lack of efficient verification procedures. In this paper, we propose to leverage emerging multimodal, vision-language, foundation models (VLMs) as a lens through which we can reason about vision models. VLMs have been trained on a large body of images accompanied by their textual description, and are thus implicitly aware of high-level, human-understandable concepts describing the images. We describe a logical specification language $\\texttt{Con}_{\\texttt{spec}}$ designed to facilitate writing specifications in terms of these concepts. To define and formally check $\\texttt{Con}_{\\texttt{spec}}$ specifications, we leverage a VLM, which provides a means to encode and efficiently check natural-language properties of vision models. We demonstrate our techniques on a ResNet-based classifier trained on the RIVAL-10 dataset leveraging CLIP as the multimodal model. ",
    "url": "https://arxiv.org/abs/2403.19837",
    "authors": [
      "Ravi Mangal",
      "Nina Narodytska",
      "Divya Gopinath",
      "Boyue Caroline Hu",
      "Anirban Roy",
      "Susmit Jha",
      "Corina Pasareanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2403.19852",
    "title": "A Review of Graph Neural Networks in Epidemic Modeling",
    "abstract": "Since the onset of the COVID-19 pandemic, there has been a growing interest in studying epidemiological models. Traditional mechanistic models mathematically describe the transmission mechanisms of infectious diseases. However, they often fall short when confronted with the growing challenges of today. Consequently, Graph Neural Networks (GNNs) have emerged as a progressively popular tool in epidemic research. In this paper, we endeavor to furnish a comprehensive review of GNNs in epidemic tasks and highlight potential future directions. To accomplish this objective, we introduce hierarchical taxonomies for both epidemic tasks and methodologies, offering a trajectory of development within this domain. For epidemic tasks, we establish a taxonomy akin to those typically employed within the epidemic domain. For methodology, we categorize existing work into \\textit{Neural Models} and \\textit{Hybrid Models}. Following this, we perform an exhaustive and systematic examination of the methodologies, encompassing both the tasks and their technical details. Furthermore, we discuss the limitations of existing methods from diverse perspectives and systematically propose future research directions. This survey aims to bridge literature gaps and promote the progression of this promising field. We hope that it will facilitate synergies between the communities of GNNs and epidemiology, and contribute to their collective progress. ",
    "url": "https://arxiv.org/abs/2403.19852",
    "authors": [
      "Zewen Liu",
      "Guancheng Wan",
      "B. Aditya Prakash",
      "Max S. Y. Lau",
      "Wei Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2403.19856",
    "title": "Towards a Brazilian History Knowledge Graph",
    "abstract": "This short paper describes the first steps in a project to construct a knowledge graph for Brazilian history based on the Brazilian Dictionary of Historical Biographies (DHBB) and Wikipedia/Wikidata. We contend that large repositories of Brazilian-named entities (people, places, organizations, and political events and movements) would be beneficial for extracting information from Portuguese texts. We show that many of the terms/entities described in the DHBB do not have corresponding concepts (or Q items) in Wikidata, the largest structured database of entities associated with Wikipedia. We describe previous work on extracting information from the DHBB and outline the steps to construct a Wikidata-based historical knowledge graph. ",
    "url": "https://arxiv.org/abs/2403.19856",
    "authors": [
      "Valeria de Paiva",
      "Alexandre Rademaker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2403.19859",
    "title": "Secure Link State Routing for Mobile Ad Hoc Networks",
    "abstract": "The secure operation of the routing protocol is one of the major challenges to be met for the proliferation of the Mobile Ad hoc Networking (MANET) paradigm. Nevertheless, security enhancements have been proposed mostly for reactive MANET protocols. The proposed here Secure Link State Routing Protocol (SLSP) provides secure proactive topology discovery, which can be multiply beneficial to the network operation. SLSP can be employed as a stand-alone protocol, or fit naturally into a hybrid routing framework, when combined with a reactive protocol. SLSP is robust against individual attackers, it is capable of adjusting its scope between local and network-wide topology discovery, and it is capable of operating in networks of frequently changing topology and membership. ",
    "url": "https://arxiv.org/abs/2403.19859",
    "authors": [
      "Panagiotis Papadimitratos",
      "Zygmunt J. Haas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.19863",
    "title": "DeNetDM: Debiasing by Network Depth Modulation",
    "abstract": "When neural networks are trained on biased datasets, they tend to inadvertently learn spurious correlations, leading to challenges in achieving strong generalization and robustness. Current approaches to address such biases typically involve utilizing bias annotations, reweighting based on pseudo-bias labels, or enhancing diversity within bias-conflicting data points through augmentation techniques. We introduce DeNetDM, a novel debiasing method based on the observation that shallow neural networks prioritize learning core attributes, while deeper ones emphasize biases when tasked with acquiring distinct information. Using a training paradigm derived from Product of Experts, we create both biased and debiased branches with deep and shallow architectures and then distill knowledge to produce the target debiased model. Extensive experiments and analyses demonstrate that our approach outperforms current debiasing techniques, achieving a notable improvement of around 5% in three datasets, encompassing both synthetic and real-world data. Remarkably, DeNetDM accomplishes this without requiring annotations pertaining to bias labels or bias types, while still delivering performance on par with supervised counterparts. Furthermore, our approach effectively harnesses the diversity of bias-conflicting points within the data, surpassing previous methods and obviating the need for explicit augmentation-based methods to enhance the diversity of such bias-conflicting points. The source code will be available upon acceptance. ",
    "url": "https://arxiv.org/abs/2403.19863",
    "authors": [
      "Silpa Vadakkeeveetil Sreelatha",
      "Adarsh Kappiyath",
      "Anjan Dutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19879",
    "title": "MAC: Maximizing Algebraic Connectivity for Graph Sparsification",
    "abstract": "Simultaneous localization and mapping (SLAM) is a critical capability in autonomous navigation, but memory and computational limits make long-term application of common SLAM techniques impractical; a robot must be able to determine what information should be retained and what can safely be forgotten. In graph-based SLAM, the number of edges (measurements) in a pose graph determines both the memory requirements of storing a robot's observations and the computational expense of algorithms deployed for performing state estimation using those observations, both of which can grow unbounded during long-term navigation. Motivated by these challenges, we propose a new general purpose approach to sparsify graphs in a manner that maximizes algebraic connectivity, a key spectral property of graphs which has been shown to control the estimation error of pose graph SLAM solutions. Our algorithm, MAC (for maximizing algebraic connectivity), is simple and computationally inexpensive, and admits formal post hoc performance guarantees on the quality of the solution that it provides. In application to the problem of pose-graph SLAM, we show on several benchmark datasets that our approach quickly produces high-quality sparsification results which retain the connectivity of the graph and, in turn, the quality of corresponding SLAM solutions. ",
    "url": "https://arxiv.org/abs/2403.19879",
    "authors": [
      "Kevin Doherty",
      "Alan Papalia",
      "Yewei Huang",
      "David Rosen",
      "Brendan Englot",
      "John Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.19881",
    "title": "IME: Integrating Multi-curvature Shared and Specific Embedding for  Temporal Knowledge Graph Completion",
    "abstract": "Temporal Knowledge Graphs (TKGs) incorporate a temporal dimension, allowing for a precise capture of the evolution of knowledge and reflecting the dynamic nature of the real world. Typically, TKGs contain complex geometric structures, with various geometric structures interwoven. However, existing Temporal Knowledge Graph Completion (TKGC) methods either model TKGs in a single space or neglect the heterogeneity of different curvature spaces, thus constraining their capacity to capture these intricate geometric structures. In this paper, we propose a novel Integrating Multi-curvature shared and specific Embedding (IME) model for TKGC tasks. Concretely, IME models TKGs into multi-curvature spaces, including hyperspherical, hyperbolic, and Euclidean spaces. Subsequently, IME incorporates two key properties, namely space-shared property and space-specific property. The space-shared property facilitates the learning of commonalities across different curvature spaces and alleviates the spatial gap caused by the heterogeneous nature of multi-curvature spaces, while the space-specific property captures characteristic features. Meanwhile, IME proposes an Adjustable Multi-curvature Pooling (AMP) approach to effectively retain important information. Furthermore, IME innovatively designs similarity, difference, and structure loss functions to attain the stated objective. Experimental results clearly demonstrate the superior performance of IME over existing state-of-the-art TKGC models. ",
    "url": "https://arxiv.org/abs/2403.19881",
    "authors": [
      "Jiapu Wang",
      "Zheng Cui",
      "Boyue Wang",
      "Shirui Pan",
      "Junbin Gao",
      "Baocai Yin",
      "Wen Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.19889",
    "title": "Towards a Robust Retrieval-Based Summarization System",
    "abstract": "This paper describes an investigation of the robustness of large language models (LLMs) for retrieval augmented generation (RAG)-based summarization tasks. While LLMs provide summarization capabilities, their performance in complex, real-world scenarios remains under-explored. Our first contribution is LogicSumm, an innovative evaluation framework incorporating realistic scenarios to assess LLM robustness during RAG-based summarization. Based on limitations identified by LogiSumm, we then developed SummRAG, a comprehensive system to create training dialogues and fine-tune a model to enhance robustness within LogicSumm's scenarios. SummRAG is an example of our goal of defining structured methods to test the capabilities of an LLM, rather than addressing issues in a one-off fashion. Experimental results confirm the power of SummRAG, showcasing improved logical coherence and summarization quality. Data, corresponding model weights, and Python code are available online. ",
    "url": "https://arxiv.org/abs/2403.19889",
    "authors": [
      "Shengjie Liu",
      "Jing Wu",
      "Jingyuan Bao",
      "Wenyi Wang",
      "Naira Hovakimyan",
      "Christopher G Healey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.19902",
    "title": "Heterogeneous Network Based Contrastive Learning Method for PolSAR Land  Cover Classification",
    "abstract": "Polarimetric synthetic aperture radar (PolSAR) image interpretation is widely used in various fields. Recently, deep learning has made significant progress in PolSAR image classification. Supervised learning (SL) requires a large amount of labeled PolSAR data with high quality to achieve better performance, however, manually labeled data is insufficient. This causes the SL to fail into overfitting and degrades its generalization performance. Furthermore, the scattering confusion problem is also a significant challenge that attracts more attention. To solve these problems, this article proposes a Heterogeneous Network based Contrastive Learning method(HCLNet). It aims to learn high-level representation from unlabeled PolSAR data for few-shot classification according to multi-features and superpixels. Beyond the conventional CL, HCLNet introduces the heterogeneous architecture for the first time to utilize heterogeneous PolSAR features better. And it develops two easy-to-use plugins to narrow the domain gap between optics and PolSAR, including feature filter and superpixel-based instance discrimination, which the former is used to enhance the complementarity of multi-features, and the latter is used to increase the diversity of negative samples. Experiments demonstrate the superiority of HCLNet on three widely used PolSAR benchmark datasets compared with state-of-the-art methods. Ablation studies also verify the importance of each component. Besides, this work has implications for how to efficiently utilize the multi-features of PolSAR data to learn better high-level representation in CL and how to construct networks suitable for PolSAR data better. ",
    "url": "https://arxiv.org/abs/2403.19902",
    "authors": [
      "Jianfeng Cai",
      "Yue Ma",
      "Zhixi Feng",
      "Shuyuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19903",
    "title": "Keeping Up With the Winner! Targeted Advertisement to Communities in  Social Networks",
    "abstract": "When a new product enters a market already dominated by an existing product, will it survive along with this dominant product? Most of the existing works have shown the coexistence of two competing products spreading/being adopted on overlaid graphs with same set of users. However, when it comes to the survival of a weaker product on the same graph, it has been established that the stronger one dominates the market and wipes out the other. This paper makes a step towards narrowing this gap so that a new/weaker product can also survive along with its competitor with a positive market share. Specifically, we identify a locally optimal set of users to induce a community that is targeted with advertisement by the product launching company under a given budget constraint. To this end, we model the system as competing Susceptible-Infected-Susceptible (SIS) epidemics and employ perturbation techniques to quantify and attain a positive market share in a cost-efficient manner. Our extensive simulation results with real-world graph dataset show that with our choice of target users, a new product can establish itself with positive market share, which otherwise would be dominated and eventually wiped out of the competitive market under the same budget constraint. ",
    "url": "https://arxiv.org/abs/2403.19903",
    "authors": [
      "Shailaja Mallick",
      "Vishwaraj Doshi",
      "Do Young Eun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.19907",
    "title": "Beyond the Known: Novel Class Discovery for Open-world Graph Learning",
    "abstract": "Node classification on graphs is of great importance in many applications. Due to the limited labeling capability and evolution in real-world open scenarios, novel classes can emerge on unlabeled testing nodes. However, little attention has been paid to novel class discovery on graphs. Discovering novel classes is challenging as novel and known class nodes are correlated by edges, which makes their representations indistinguishable when applying message passing GNNs. Furthermore, the novel classes lack labeling information to guide the learning process. In this paper, we propose a novel method Open-world gRAph neuraL network (ORAL) to tackle these challenges. ORAL first detects correlations between classes through semi-supervised prototypical learning. Inter-class correlations are subsequently eliminated by the prototypical attention network, leading to distinctive representations for different classes. Furthermore, to fully explore multi-scale graph features for alleviating label deficiencies, ORAL generates pseudo-labels by aligning and ensembling label estimations from multiple stacked prototypical attention networks. Extensive experiments on several benchmark datasets show the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2403.19907",
    "authors": [
      "Yucheng Jin",
      "Yun Xiong",
      "Juncheng Fang",
      "Xixi Wu",
      "Dongxiao He",
      "Xing Jia",
      "Bingchen Zhao",
      "Philip Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.19914",
    "title": "A Comprehensive Evaluation of the Impact of ATM QoS Mechanisms on  Network Performance for Multimedia and Data Applications",
    "abstract": "The Asynchronous Transfer Mode (ATM) network is crucial due to its ability to efficiently transmit data, provide reliable connections, and support various service classes with specific Quality of Service (QoS) requirements. In this paper, we utilize the OPNET network simulation software to model an ATM network and analyze the impact of QoS classification on network performance. We investigate the effects of Constant Bit Rate (CBR), Variable Bit Rate (VBR), Available Bit Rate (ABR) and Unspecified Bit Rate (UBR) models on various network traffic types such as voice, video and data. For voice traffic, we examine key QoS parameters including Jitter, Packet Delay Variation and End-to-End Delay. For video traffic, we evaluate Packet Delay Variation and End-to-End Delay. Additionally, we analyze Download Response Time for data traffic to assess the influence of QoS on the ATM network. Our results demonstrate that CBR and VBR are preferred for real-time traffic like voice and video, providing low delay and jitter. The simulation approach enables us to test various configurations and gain insights not possible in hardware tests. Our findings can help network operators determine the optimal QoS settings and tradeoffs when deploying ATM for modern multi-service networks. ",
    "url": "https://arxiv.org/abs/2403.19914",
    "authors": [
      "Mahdi Manavi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.19924",
    "title": "SceneTracker: Long-term Scene Flow Estimation Network",
    "abstract": "Considering the complementarity of scene flow estimation in the spatial domain's focusing capability and 3D object tracking in the temporal domain's coherence, this study aims to address a comprehensive new task that can simultaneously capture fine-grained and long-term 3D motion in an online manner: long-term scene flow estimation (LSFE). We introduce SceneTracker, a novel learning-based LSFE network that adopts an iterative approach to approximate the optimal trajectory. Besides, it dynamically indexes and constructs appearance and depth correlation features simultaneously and employs the Transformer to explore and utilize long-range connections within and between trajectories. With detailed experiments, SceneTracker shows superior capabilities in handling 3D spatial occlusion and depth noise interference, highly tailored to the LSFE task's needs. The code for SceneTracker is available at https://github.com/wwsource/SceneTracker. ",
    "url": "https://arxiv.org/abs/2403.19924",
    "authors": [
      "Bo Wang",
      "Jian Li",
      "Yang Yu",
      "Li Liu",
      "Zhenping Sun",
      "Dewen Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19931",
    "title": "DHNet: A Distributed Network Architecture for Smart Home",
    "abstract": "With the increasing popularity of smart homes, more and more devices need to connect to home networks. Traditional home networks mainly rely on centralized networking, where an excessive number of devices in the centralized topology can increase the pressure on the central router, potentially leading to decreased network performance metrics such as communication latency. To address the latency performance issues brought about by centralized networks, this paper proposes a new network system called DHNet, and designs an algorithm for clustering networking and communication based on vector routing. Communication within clusters in a simulated virtual environment achieves a latency of approximately 0.7 milliseconds. Furthermore, by directly using the first non-\"lo\" network card address of a device as the protocol's network layer address, the protocol avoids the several tens of milliseconds of access latency caused by DHCP. The integration of service discovery functionality into the network layer protocol is achieved through a combination of \"server-initiated service push\" and \"client request + server reply\" methods. Compared to traditional application-layer DNS passive service discovery, the average latency is reduced by over 50%. The PVH protocol is implemented in the user space using the Go programming language, with implementation details drawn from Google's gVisor project. The code has been ported from x86\\_64 Linux computers to devices such as OpenWrt routers and Android smartphones. The PVH protocol can communicate through \"tunnels\" to provide IP compatibility, allowing existing applications based on TCP/IP to communicate using the PVH protocol without requiring modifications to their code. ",
    "url": "https://arxiv.org/abs/2403.19931",
    "authors": [
      "Chaoqi Zhou",
      "Jingpu Duan",
      "YuPeng Xiao",
      "Qing Li",
      "Dingding Chen",
      "Ruobin Zheng",
      "Shaoteng Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.19935",
    "title": "CP HDR: A feature point detection and description library for LDR and  HDR images",
    "abstract": "In computer vision, characteristics refer to image regions with unique properties, such as corners, edges, textures, or areas with high contrast. These regions can be represented through feature points (FPs). FP detection and description are fundamental steps to many computer vision tasks. Most FP detection and description methods use low dynamic range (LDR) images, sufficient for most applications involving digital images. However, LDR images may have saturated pixels in scenes with extreme light conditions, which degrade FP detection. On the other hand, high dynamic range (HDR) images usually present a greater dynamic range but FP detection algorithms do not take advantage of all the information in such images. In this study, we present a systematic review of image detection and description algorithms that use HDR images as input. We developed a library called CP_HDR that implements the Harris corner detector, SIFT detector and descriptor, and two modifications of those algorithms specialized in HDR images, called SIFT for HDR (SfHDR) and Harris for HDR (HfHDR). Previous studies investigated the use of HDR images in FP detection, but we did not find studies investigating the use of HDR images in FP description. Using uniformity, repeatability rate, mean average precision, and matching rate metrics, we compared the performance of the CP_HDR algorithms using LDR and HDR images. We observed an increase in the uniformity of the distribution of FPs among the high-light, mid-light, and low-light areas of the images. The results show that using HDR images as input to detection algorithms improves performance and that SfHDR and HfHDR enhance FP description. ",
    "url": "https://arxiv.org/abs/2403.19935",
    "authors": [
      "Artur Santos Nascimento",
      "Valter Guilherme Silva de Souza",
      "Daniel Oliveira Dantas",
      "Beatriz Trinch\u00e3o Andrade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19936",
    "title": "SLFNet: Generating Semantic Logic Forms from Natural Language Using  Semantic Probability Graphs",
    "abstract": "Building natural language interfaces typically uses a semantic parser to parse the user's natural language and convert it into structured \\textbf{S}emantic \\textbf{L}ogic \\textbf{F}orms (SLFs). The mainstream approach is to adopt a sequence-to-sequence framework, which requires that natural language commands and SLFs must be represented serially. Since a single natural language may have multiple SLFs or multiple natural language commands may have the same SLF, training a sequence-to-sequence model is sensitive to the choice among them, a phenomenon recorded as \"order matters\". To solve this problem, we propose a novel neural network, SLFNet, which firstly incorporates dependent syntactic information as prior knowledge and can capture the long-range interactions between contextual information and words. Secondly construct semantic probability graphs to obtain local dependencies between predictor variables. Finally we propose the Multi-Head SLF Attention mechanism to synthesize SLFs from natural language commands based on Sequence-to-Slots. Experiments show that SLFNet achieves state-of-the-art performance on the ChineseQCI-TS and Okapi datasets, and competitive performance on the ATIS dataset. ",
    "url": "https://arxiv.org/abs/2403.19936",
    "authors": [
      "Hao Wu",
      "Fan Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.19943",
    "title": "TDANet: A Novel Temporal Denoise Convolutional Neural Network With  Attention for Fault Diagnosis",
    "abstract": "Fault diagnosis plays a crucial role in maintaining the operational integrity of mechanical systems, preventing significant losses due to unexpected failures. As intelligent manufacturing and data-driven approaches evolve, Deep Learning (DL) has emerged as a pivotal technique in fault diagnosis research, recognized for its ability to autonomously extract complex features. However, the practical application of current fault diagnosis methods is challenged by the complexity of industrial environments. This paper proposed the Temporal Denoise Convolutional Neural Network With Attention (TDANet), designed to improve fault diagnosis performance in noise environments. This model transforms one-dimensional signals into two-dimensional tensors based on their periodic properties, employing multi-scale 2D convolution kernels to extract signal information both within and across periods. This method enables effective identification of signal characteristics that vary over multiple time scales. The TDANet incorporates a Temporal Variable Denoise (TVD) module with residual connections and a Multi-head Attention Fusion (MAF) module, enhancing the saliency of information within noisy data and maintaining effective fault diagnosis performance. Evaluation on two datasets, CWRU (single sensor) and Real aircraft sensor fault (multiple sensors), demonstrates that the TDANet model significantly outperforms existing deep learning approaches in terms of diagnostic accuracy under noisy environments. ",
    "url": "https://arxiv.org/abs/2403.19943",
    "authors": [
      "Zhongzhi Li",
      "Rong Fan",
      "Jingqi Tu",
      "Jinyi Ma",
      "Jianliang Ai",
      "Yiqun Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.19950",
    "title": "Coverage-Guaranteed Prediction Sets for Out-of-Distribution Data",
    "abstract": "Out-of-distribution (OOD) generalization has attracted increasing research attention in recent years, due to its promising experimental results in real-world applications. In this paper,we study the confidence set prediction problem in the OOD generalization setting. Split conformal prediction (SCP) is an efficient framework for handling the confidence set prediction problem. However, the validity of SCP requires the examples to be exchangeable, which is violated in the OOD setting. Empirically, we show that trivially applying SCP results in a failure to maintain the marginal coverage when the unseen target domain is different from the source domain. To address this issue, we develop a method for forming confident prediction sets in the OOD setting and theoretically prove the validity of our method. Finally, we conduct experiments on simulated data to empirically verify the correctness of our theory and the validity of our proposed method. ",
    "url": "https://arxiv.org/abs/2403.19950",
    "authors": [
      "Xin Zou",
      "Weiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.19963",
    "title": "Efficient Modulation for Vision Networks",
    "abstract": "In this work, we present efficient modulation, a novel design for efficient vision networks. We revisit the modulation mechanism, which operates input through convolutional context modeling and feature projection layers, and fuses features via element-wise multiplication and an MLP block. We demonstrate that the modulation mechanism is particularly well suited for efficient networks and further tailor the modulation design by proposing the efficient modulation (EfficientMod) block, which is considered the essential building block for our networks. Benefiting from the prominent representational ability of modulation mechanism and the proposed efficient design, our network can accomplish better trade-offs between accuracy and efficiency and set new state-of-the-art performance in the zoo of efficient networks. When integrating EfficientMod with the vanilla self-attention block, we obtain the hybrid architecture which further improves the performance without loss of efficiency. We carry out comprehensive experiments to verify EfficientMod's performance. With fewer parameters, our EfficientMod-s performs 0.6 top-1 accuracy better than EfficientFormerV2-s2 and is 25% faster on GPU, and 2.9 better than MobileViTv2-1.0 at the same GPU latency. Additionally, our method presents a notable improvement in downstream tasks, outperforming EfficientFormerV2-s by 3.6 mIoU on the ADE20K benchmark. Code and checkpoints are available at https://github.com/ma-xu/EfficientMod. ",
    "url": "https://arxiv.org/abs/2403.19963",
    "authors": [
      "Xu Ma",
      "Xiyang Dai",
      "Jianwei Yang",
      "Bin Xiao",
      "Yinpeng Chen",
      "Yun Fu",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19964",
    "title": "FairRAG: Fair Human Generation via Fair Retrieval Augmentation",
    "abstract": "Existing text-to-image generative models reflect or even amplify societal biases ingrained in their training data. This is especially concerning for human image generation where models are biased against certain demographic groups. Existing attempts to rectify this issue are hindered by the inherent limitations of the pre-trained models and fail to substantially improve demographic diversity. In this work, we introduce Fair Retrieval Augmented Generation (FairRAG), a novel framework that conditions pre-trained generative models on reference images retrieved from an external image database to improve fairness in human generation. FairRAG enables conditioning through a lightweight linear module that projects reference images into the textual space. To enhance fairness, FairRAG applies simple-yet-effective debiasing strategies, providing images from diverse demographic groups during the generative process. Extensive experiments demonstrate that FairRAG outperforms existing methods in terms of demographic diversity, image-text alignment, and image fidelity while incurring minimal computational overhead during inference. ",
    "url": "https://arxiv.org/abs/2403.19964",
    "authors": [
      "Robik Shrestha",
      "Yang Zou",
      "Qiuyu Chen",
      "Zhiheng Li",
      "Yusheng Xie",
      "Siqi Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.19980",
    "title": "A Parallel Attention Network for Cattle Face Recognition",
    "abstract": "Cattle face recognition holds paramount significance in domains such as animal husbandry and behavioral research. Despite significant progress in confined environments, applying these accomplishments in wild settings remains challenging. Thus, we create the first large-scale cattle face recognition dataset, ICRWE, for wild environments. It encompasses 483 cattle and 9,816 high-resolution image samples. Each sample undergoes annotation for face features, light conditions, and face orientation. Furthermore, we introduce a novel parallel attention network, PANet. Comprising several cascaded Transformer modules, each module incorporates two parallel Position Attention Modules (PAM) and Feature Mapping Modules (FMM). PAM focuses on local and global features at each image position through parallel channel attention, and FMM captures intricate feature patterns through non-linear mappings. Experimental results indicate that PANet achieves a recognition accuracy of 88.03% on the ICRWE dataset, establishing itself as the current state-of-the-art approach. The source code is available in the supplementary materials. ",
    "url": "https://arxiv.org/abs/2403.19980",
    "authors": [
      "Jiayu Li",
      "Xuechao Zou",
      "Shiying Wang",
      "Ben Chen",
      "Junliang Xing",
      "Pin Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.19996",
    "title": "DeepHeteroIoT: Deep Local and Global Learning over Heterogeneous IoT  Sensor Data",
    "abstract": "Internet of Things (IoT) sensor data or readings evince variations in timestamp range, sampling frequency, geographical location, unit of measurement, etc. Such presented sequence data heterogeneity makes it difficult for traditional time series classification algorithms to perform well. Therefore, addressing the heterogeneity challenge demands learning not only the sub-patterns (local features) but also the overall pattern (global feature). To address the challenge of classifying heterogeneous IoT sensor data (e.g., categorizing sensor data types like temperature and humidity), we propose a novel deep learning model that incorporates both Convolutional Neural Network and Bi-directional Gated Recurrent Unit to learn local and global features respectively, in an end-to-end manner. Through rigorous experimentation on heterogeneous IoT sensor datasets, we validate the effectiveness of our proposed model, which outperforms recent state-of-the-art classification methods as well as several machine learning and deep learning baselines. In particular, the model achieves an average absolute improvement of 3.37% in Accuracy and 2.85% in F1-Score across datasets ",
    "url": "https://arxiv.org/abs/2403.19996",
    "authors": [
      "Muhammad Sakib Khan Inan",
      "Kewen Liao",
      "Haifeng Shen",
      "Prem Prakash Jayaraman",
      "Dimitrios Georgakopoulos",
      "Ming Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.20000",
    "title": "Computational Complexity of the Recoverable Robust Shortest Path Problem  with Discrete Recourse",
    "abstract": "In this paper the recoverable robust shortest path problem is investigated. Discrete budgeted interval uncertainty representation is used to model uncertain second-stage arc costs. The known complexity results for this problem are strengthened. It is shown that it is Sigma_3^p-hard for the arc exclusion and the arc symmetric difference neighborhoods. Furthermore, it is also proven that the inner adversarial problem for these neighborhoods is Pi_2^p-hard. ",
    "url": "https://arxiv.org/abs/2403.20000",
    "authors": [
      "Marcel Jackiewicz",
      "Adam Kasperski",
      "Pawe\u0142 Zieli\u0144ski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2403.20002",
    "title": "Grounding and Enhancing Grid-based Models for Neural Fields",
    "abstract": "Many contemporary studies utilize grid-based models for neural field representation, but a systematic analysis of grid-based models is still missing, hindering the improvement of those models. Therefore, this paper introduces a theoretical framework for grid-based models. This framework points out that these models' approximation and generalization behaviors are determined by grid tangent kernels (GTK), which are intrinsic properties of grid-based models. The proposed framework facilitates a consistent and systematic analysis of diverse grid-based models. Furthermore, the introduced framework motivates the development of a novel grid-based model named the Multiplicative Fourier Adaptive Grid (MulFAGrid). The numerical analysis demonstrates that MulFAGrid exhibits a lower generalization bound than its predecessors, indicating its robust generalization performance. Empirical studies reveal that MulFAGrid achieves state-of-the-art performance in various tasks, including 2D image fitting, 3D signed distance field (SDF) reconstruction, and novel view synthesis, demonstrating superior representation ability. The project website is available at https://sites.google.com/view/cvpr24-2034-submission/home. ",
    "url": "https://arxiv.org/abs/2403.20002",
    "authors": [
      "Zelin Zhao",
      "Fenglei Fan",
      "Wenlong Liao",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20012",
    "title": "Colorful Cutout: Enhancing Image Data Augmentation with Curriculum  Learning",
    "abstract": "Data augmentation is one of the regularization strategies for the training of deep learning models, which enhances generalizability and prevents overfitting, leading to performance improvement. Although researchers have proposed various data augmentation techniques, they often lack consideration for the difficulty of augmented data. Recently, another line of research suggests incorporating the concept of curriculum learning with data augmentation in the field of natural language processing. In this study, we adopt curriculum data augmentation for image data augmentation and propose colorful cutout, which gradually increases the noise and difficulty introduced in the augmented image. Our experimental results highlight the possibility of curriculum data augmentation for image data. We publicly released our source code to improve the reproducibility of our study. ",
    "url": "https://arxiv.org/abs/2403.20012",
    "authors": [
      "Juhwan Choi",
      "YoungBin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.20015",
    "title": "Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion",
    "abstract": "In the field of text data augmentation, rule-based methods are widely adopted for real-world applications owing to their cost-efficiency. However, conventional rule-based approaches suffer from the possibility of losing the original semantics of the given text. We propose a novel text data augmentation strategy that avoids such phenomena through a straightforward deletion of adverbs, which play a subsidiary role in the sentence. Our comprehensive experiments demonstrate the efficiency and effectiveness of our proposed approach for not just single text classification, but also natural language inference that requires semantic preservation. We publicly released our source code for reproducibility. ",
    "url": "https://arxiv.org/abs/2403.20015",
    "authors": [
      "Juhwan Choi",
      "YoungBin Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.20034",
    "title": "NeSLAM: Neural Implicit Mapping and Self-Supervised Feature Tracking  With Depth Completion and Denoising",
    "abstract": "In recent years, there have been significant advancements in 3D reconstruction and dense RGB-D SLAM systems. One notable development is the application of Neural Radiance Fields (NeRF) in these systems, which utilizes implicit neural representation to encode 3D scenes. This extension of NeRF to SLAM has shown promising results. However, the depth images obtained from consumer-grade RGB-D sensors are often sparse and noisy, which poses significant challenges for 3D reconstruction and affects the accuracy of the representation of the scene geometry. Moreover, the original hierarchical feature grid with occupancy value is inaccurate for scene geometry representation. Furthermore, the existing methods select random pixels for camera tracking, which leads to inaccurate localization and is not robust in real-world indoor environments. To this end, we present NeSLAM, an advanced framework that achieves accurate and dense depth estimation, robust camera tracking, and realistic synthesis of novel views. First, a depth completion and denoising network is designed to provide dense geometry prior and guide the neural implicit representation optimization. Second, the occupancy scene representation is replaced with Signed Distance Field (SDF) hierarchical scene representation for high-quality reconstruction and view synthesis. Furthermore, we also propose a NeRF-based self-supervised feature tracking algorithm for robust real-time tracking. Experiments on various indoor datasets demonstrate the effectiveness and accuracy of the system in reconstruction, tracking quality, and novel view synthesis. ",
    "url": "https://arxiv.org/abs/2403.20034",
    "authors": [
      "Tianchen Deng",
      "Yanbo Wang",
      "Hongle Xie",
      "Hesheng Wang",
      "Jingchuan Wang",
      "Danwei Wang",
      "Weidong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.20056",
    "title": "Cross-Lingual Transfer Robustness to Lower-Resource Languages on  Adversarial Datasets",
    "abstract": "Multilingual Language Models (MLLMs) exhibit robust cross-lingual transfer capabilities, or the ability to leverage information acquired in a source language and apply it to a target language. These capabilities find practical applications in well-established Natural Language Processing (NLP) tasks such as Named Entity Recognition (NER). This study aims to investigate the effectiveness of a source language when applied to a target language, particularly in the context of perturbing the input test set. We evaluate on 13 pairs of languages, each including one high-resource language (HRL) and one low-resource language (LRL) with a geographic, genetic, or borrowing relationship. We evaluate two well-known MLLMs--MBERT and XLM-R--on these pairs, in native LRL and cross-lingual transfer settings, in two tasks, under a set of different perturbations. Our findings indicate that NER cross-lingual transfer depends largely on the overlap of entity chunks. If a source and target language have more entities in common, the transfer ability is stronger. Models using cross-lingual transfer also appear to be somewhat more robust to certain perturbations of the input, perhaps indicating an ability to leverage stronger representations derived from the HRL. Our research provides valuable insights into cross-lingual transfer and its implications for NLP applications, and underscores the need to consider linguistic nuances and potential limitations when employing MLLMs across distinct languages. ",
    "url": "https://arxiv.org/abs/2403.20056",
    "authors": [
      "Shadi Manafi",
      "Nikhil Krishnaswamy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.20075",
    "title": "Adaptive Decentralized Federated Learning in Energy and Latency  Constrained Wireless Networks",
    "abstract": "In Federated Learning (FL), with parameter aggregated by a central node, the communication overhead is a substantial concern. To circumvent this limitation and alleviate the single point of failure within the FL framework, recent studies have introduced Decentralized Federated Learning (DFL) as a viable alternative. Considering the device heterogeneity, and energy cost associated with parameter aggregation, in this paper, the problem on how to efficiently leverage the limited resources available to enhance the model performance is investigated. Specifically, we formulate a problem that minimizes the loss function of DFL while considering energy and latency constraints. The proposed solution involves optimizing the number of local training rounds across diverse devices with varying resource budgets. To make this problem tractable, we first analyze the convergence of DFL with edge devices with different rounds of local training. The derived convergence bound reveals the impact of the rounds of local training on the model performance. Then, based on the derived bound, the closed-form solutions of rounds of local training in different devices are obtained. Meanwhile, since the solutions require the energy cost of aggregation as low as possible, we modify different graph-based aggregation schemes to solve this energy consumption minimization problem, which can be applied to different communication scenarios. Finally, a DFL framework which jointly considers the optimized rounds of local training and the energy-saving aggregation scheme is proposed. Simulation results show that, the proposed algorithm achieves a better performance than the conventional schemes with fixed rounds of local training, and consumes less energy than other traditional aggregation schemes. ",
    "url": "https://arxiv.org/abs/2403.20075",
    "authors": [
      "Zhigang Yan",
      "Dong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.20078",
    "title": "Negative Label Guided OOD Detection with Pretrained Vision-Language  Models",
    "abstract": "Out-of-distribution (OOD) detection aims at identifying samples from unknown classes, playing a crucial role in trustworthy models against errors on unexpected inputs. Extensive research has been dedicated to exploring OOD detection in the vision modality. Vision-language models (VLMs) can leverage both textual and visual information for various multi-modal applications, whereas few OOD detection methods take into account information from the text modality. In this paper, we propose a novel post hoc OOD detection method, called NegLabel, which takes a vast number of negative labels from extensive corpus databases. We design a novel scheme for the OOD score collaborated with negative labels. Theoretical analysis helps to understand the mechanism of negative labels. Extensive experiments demonstrate that our method NegLabel achieves state-of-the-art performance on various OOD detection benchmarks and generalizes well on multiple VLM architectures. Furthermore, our method NegLabel exhibits remarkable robustness against diverse domain shifts. The codes are available at https://github.com/tmlr-group/NegLabel. ",
    "url": "https://arxiv.org/abs/2403.20078",
    "authors": [
      "Xue Jiang",
      "Feng Liu",
      "Zhen Fang",
      "Hong Chen",
      "Tongliang Liu",
      "Feng Zheng",
      "Bo Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.20107",
    "title": "Robust Federated Contrastive Recommender System against Model Poisoning  Attack",
    "abstract": "Federated Recommender Systems (FedRecs) have garnered increasing attention recently, thanks to their privacy-preserving benefits. However, the decentralized and open characteristics of current FedRecs present two dilemmas. First, the performance of FedRecs is compromised due to highly sparse on-device data for each client. Second, the system's robustness is undermined by the vulnerability to model poisoning attacks launched by malicious users. In this paper, we introduce a novel contrastive learning framework designed to fully leverage the client's sparse data through embedding augmentation, referred to as CL4FedRec. Unlike previous contrastive learning approaches in FedRecs that necessitate clients to share their private parameters, our CL4FedRec aligns with the basic FedRec learning protocol, ensuring compatibility with most existing FedRec implementations. We then evaluate the robustness of FedRecs equipped with CL4FedRec by subjecting it to several state-of-the-art model poisoning attacks. Surprisingly, our observations reveal that contrastive learning tends to exacerbate the vulnerability of FedRecs to these attacks. This is attributed to the enhanced embedding uniformity, making the polluted target item embedding easily proximate to popular items. Based on this insight, we propose an enhanced and robust version of CL4FedRec (rCL4FedRec) by introducing a regularizer to maintain the distance among item embeddings with different popularity levels. Extensive experiments conducted on four commonly used recommendation datasets demonstrate that CL4FedRec significantly enhances both the model's performance and the robustness of FedRecs. ",
    "url": "https://arxiv.org/abs/2403.20107",
    "authors": [
      "Wei Yuan",
      "Chaoqun Yang",
      "Liang Qu",
      "Guanhua Ye",
      "Quoc Viet Hung Nguyen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.20127",
    "title": "The Impact of Prompts on Zero-Shot Detection of AI-Generated Text",
    "abstract": "In recent years, there have been significant advancements in the development of Large Language Models (LLMs). While their practical applications are now widespread, their potential for misuse, such as generating fake news and committing plagiarism, has posed significant concerns. To address this issue, detectors have been developed to evaluate whether a given text is human-generated or AI-generated. Among others, zero-shot detectors stand out as effective approaches that do not require additional training data and are often likelihood-based. In chat-based applications, users commonly input prompts and utilize the AI-generated texts. However, zero-shot detectors typically analyze these texts in isolation, neglecting the impact of the original prompts. It is conceivable that this approach may lead to a discrepancy in likelihood assessments between the text generation phase and the detection phase. So far, there remains an unverified gap concerning how the presence or absence of prompts impacts detection accuracy for zero-shot detectors. In this paper, we introduce an evaluative framework to empirically analyze the impact of prompts on the detection accuracy of AI-generated text. We assess various zero-shot detectors using both white-box detection, which leverages the prompt, and black-box detection, which operates without prompt information. Our experiments reveal the significant influence of prompts on detection accuracy. Remarkably, compared with black-box detection without prompts, the white-box methods using prompts demonstrate an increase in AUC of at least $0.1$ across all zero-shot detectors tested. Code is available: \\url{https://github.com/kaito25atugich/Detector}. ",
    "url": "https://arxiv.org/abs/2403.20127",
    "authors": [
      "Kaito Taguchi",
      "Yujie Gu",
      "Kouichi Sakurai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.20136",
    "title": "Differentiated Security Architecture for Secure and Efficient  Infotainment Data Communication in IoV Networks",
    "abstract": "This paper aims to provide differentiated security protection for infotainment data communication in Internet-of-Vehicle (IoV) networks. The IoV is a network of vehicles that uses various sensors, software, built-in hardware, and communication technologies to enable information exchange between pedestrians, cars, and urban infrastructure. Negligence on the security of infotainment data communication in IoV networks can unintentionally open an easy access point for social engineering attacks. The attacker can spread false information about traffic conditions, mislead drivers in their directions, and interfere with traffic management. Such attacks can also cause distractions to the driver, which has a potential implication for the safety of driving. The existing literature on IoV communication and network security focuses mainly on generic solutions. In a heterogeneous communication network where different types of communication coexist, we can improve the efficiency of security solutions by considering the different security and efficiency requirements of data communications. Hence, we propose a differentiated security mechanism for protecting infotainment data communication in IoV networks. In particular, we first classify data communication in the IoV network, examine the security focus of each data communication, and then develop a differentiated security architecture to provide security protection on a file-to-file basis. Our architecture leverages Named Data Networking (NDN) so that infotainment files can be efficiently circulated throughout the network where any node can own a copy of the file, thus improving the hit ratio for user file requests. In addition, we propose a time-sensitive Key-Policy Attribute-Based Encryption (KP-ABE) scheme for sharing subscription-based infotainment data... ",
    "url": "https://arxiv.org/abs/2403.20136",
    "authors": [
      "Jiani Fan",
      "Lwin Khin Shar",
      "Jiale Guo",
      "Wenzhuo Yang",
      "Dusit Niyato",
      "Kwok-Yan Lam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.20147",
    "title": "IndiBias: A Benchmark Dataset to Measure Social Biases in Language  Models for Indian Context",
    "abstract": "The pervasive influence of social biases in language data has sparked the need for benchmark datasets that capture and evaluate these biases in Large Language Models (LLMs). Existing efforts predominantly focus on English language and the Western context, leaving a void for a reliable dataset that encapsulates India's unique socio-cultural nuances. To bridge this gap, we introduce IndiBias, a comprehensive benchmarking dataset designed specifically for evaluating social biases in the Indian context. We filter and translate the existing CrowS-Pairs dataset to create a benchmark dataset suited to the Indian context in Hindi language. Additionally, we leverage LLMs including ChatGPT and InstructGPT to augment our dataset with diverse societal biases and stereotypes prevalent in India. The included bias dimensions encompass gender, religion, caste, age, region, physical appearance, and occupation. We also build a resource to address intersectional biases along three intersectional dimensions. Our dataset contains 800 filtered sentences from the CrowS-Pairs dataset and tuples for bias measurement across different demographics. It is made available in English and Hindi languages, providing a size comparable to existing benchmark datasets. Furthermore, using IndiBias we compare ten different language models on multiple bias measurement metrics. We observed that the language models exhibit more bias across a majority of the intersectional groups. ",
    "url": "https://arxiv.org/abs/2403.20147",
    "authors": [
      "Nihar Ranjan Sahoo",
      "Pranamya Prashant Kulkarni",
      "Narjis Asad",
      "Arif Ahmad",
      "Tanu Goyal",
      "Aparna Garimella",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.20149",
    "title": "Conformal Prediction for Stochastic Decision-Making of PV Power in  Electricity Markets",
    "abstract": "This paper studies the use of conformal prediction (CP), an emerging probabilistic forecasting method, for day-ahead photovoltaic power predictions to enhance participation in electricity markets. First, machine learning models are used to construct point predictions. Thereafter, several variants of CP are implemented to quantify the uncertainty of those predictions by creating CP intervals and cumulative distribution functions. Optimal quantity bids for the electricity market are estimated using several bidding strategies under uncertainty, namely: trust-the-forecast, worst-case, Newsvendor and expected utility maximization (EUM). Results show that CP in combination with k-nearest neighbors and/or Mondrian binning outperforms its corresponding linear quantile regressors. Using CP in combination with certain bidding strategies can yield high profit with minimal energy imbalance. In concrete, using conformal predictive systems with k-nearest neighbors and Mondrian binning after random forest regression yields the best profit and imbalance regardless of the decision-making strategy. Combining this uncertainty quantification method with the EUM strategy with conditional value at risk (CVaR) can yield up to 93\\% of the potential profit with minimal energy imbalance. ",
    "url": "https://arxiv.org/abs/2403.20149",
    "authors": [
      "Yvet Renkema",
      "Nico Brinkel",
      "Tarek Alskaif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.20156",
    "title": "CAESAR: Enhancing Federated RL in Heterogeneous MDPs through  Convergence-Aware Sampling with Screening",
    "abstract": "In this study, we delve into Federated Reinforcement Learning (FedRL) in the context of value-based agents operating across diverse Markov Decision Processes (MDPs). Existing FedRL methods typically aggregate agents' learning by averaging the value functions across them to improve their performance. However, this aggregation strategy is suboptimal in heterogeneous environments where agents converge to diverse optimal value functions. To address this problem, we introduce the Convergence-AwarE SAmpling with scReening (CAESAR) aggregation scheme designed to enhance the learning of individual agents across varied MDPs. CAESAR is an aggregation strategy used by the server that combines convergence-aware sampling with a screening mechanism. By exploiting the fact that agents learning in identical MDPs are converging to the same optimal value function, CAESAR enables the selective assimilation of knowledge from more proficient counterparts, thereby significantly enhancing the overall learning efficiency. We empirically validate our hypothesis and demonstrate the effectiveness of CAESAR in enhancing the learning efficiency of agents, using both a custom-built GridWorld environment and the classical FrozenLake-v1 task, each presenting varying levels of environmental heterogeneity. ",
    "url": "https://arxiv.org/abs/2403.20156",
    "authors": [
      "Hei Yi Mak",
      "Flint Xiaofeng Fan",
      "Luca A. Lanzend\u00f6rfer",
      "Cheston Tan",
      "Wei Tsang Ooi",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.20159",
    "title": "HGS-Mapping: Online Dense Mapping Using Hybrid Gaussian Representation  in Urban Scenes",
    "abstract": "Online dense mapping of urban scenes forms a fundamental cornerstone for scene understanding and navigation of autonomous vehicles. Recent advancements in mapping methods are mainly based on NeRF, whose rendering speed is too slow to meet online requirements. 3D Gaussian Splatting (3DGS), with its rendering speed hundreds of times faster than NeRF, holds greater potential in online dense mapping. However, integrating 3DGS into a street-view dense mapping framework still faces two challenges, including incomplete reconstruction due to the absence of geometric information beyond the LiDAR coverage area and extensive computation for reconstruction in large urban scenes. To this end, we propose HGS-Mapping, an online dense mapping framework in unbounded large-scale scenes. To attain complete construction, our framework introduces Hybrid Gaussian Representation, which models different parts of the entire scene using Gaussians with distinct properties. Furthermore, we employ a hybrid Gaussian initialization mechanism and an adaptive update method to achieve high-fidelity and rapid reconstruction. To the best of our knowledge, we are the first to integrate Gaussian representation into online dense mapping of urban scenes. Our approach achieves SOTA reconstruction accuracy while only employing 66% number of Gaussians, leading to 20% faster reconstruction speed. ",
    "url": "https://arxiv.org/abs/2403.20159",
    "authors": [
      "Ke Wu",
      "Kaizhao Zhang",
      "Zhiwei Zhang",
      "Shanshuai Yuan",
      "Muer Tie",
      "Julong Wei",
      "Zijun Xu",
      "Jieru Zhao",
      "Zhongxue Gan",
      "Wenchao Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20163",
    "title": "Biologically-Plausible Topology Improved Spiking Actor Network for  Efficient Deep Reinforcement Learning",
    "abstract": "The success of Deep Reinforcement Learning (DRL) is largely attributed to utilizing Artificial Neural Networks (ANNs) as function approximators. Recent advances in neuroscience have unveiled that the human brain achieves efficient reward-based learning, at least by integrating spiking neurons with spatial-temporal dynamics and network topologies with biologically-plausible connectivity patterns. This integration process allows spiking neurons to efficiently combine information across and within layers via nonlinear dendritic trees and lateral interactions. The fusion of these two topologies enhances the network's information-processing ability, crucial for grasping intricate perceptions and guiding decision-making procedures. However, ANNs and brain networks differ significantly. ANNs lack intricate dynamical neurons and only feature inter-layer connections, typically achieved by direct linear summation, without intra-layer connections. This limitation leads to constrained network expressivity. To address this, we propose a novel alternative for function approximator, the Biologically-Plausible Topology improved Spiking Actor Network (BPT-SAN), tailored for efficient decision-making in DRL. The BPT-SAN incorporates spiking neurons with intricate spatial-temporal dynamics and introduces intra-layer connections, enhancing spatial-temporal state representation and facilitating more precise biological simulations. Diverging from the conventional direct linear weighted sum, the BPT-SAN models the local nonlinearities of dendritic trees within the inter-layer connections. For the intra-layer connections, the BPT-SAN introduces lateral interactions between adjacent neurons, integrating them into the membrane potential formula to ensure accurate spike firing. ",
    "url": "https://arxiv.org/abs/2403.20163",
    "authors": [
      "Duzhen Zhang",
      "Qingyu Wang",
      "Tielin Zhang",
      "Bo Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2403.20170",
    "title": "Recovery Sets of Subspaces from a Simplex Code",
    "abstract": "Recovery sets for vectors and subspaces are important in the construction of distributed storage system codes. These concepts are also interesting in their own right. In this paper, we consider the following very basic recovery question: what is the maximum number of possible pairwise disjoint recovery sets for each recovered element? The recovered elements in this work are d-dimensional subspaces of a $k$-dimensional vector space over GF(q). Each server stores one representative for each distinct one-dimensional subspace of the k-dimensional vector space, or equivalently a distinct point of PG(k-1,q). As column vectors, the associated vectors of the stored one-dimensional subspaces form the generator matrix of the $[(q^k -1)/(q-1),k,q^{k-1}]$ simplex code over GF(q). Lower bounds and upper bounds on the maximum number of such recovery sets are provided. It is shown that generally, these bounds are either tight or very close to being tight. ",
    "url": "https://arxiv.org/abs/2403.20170",
    "authors": [
      "Yeow Meng Chee",
      "Tuvi Etzion",
      "Han Mao Kiah",
      "Hui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2403.20173",
    "title": "MCNet: A crowd denstity estimation network based on integrating  multiscale attention module",
    "abstract": "Aiming at the metro video surveillance system has not been able to effectively solve the metro crowd density estimation problem, a Metro Crowd density estimation Network (called MCNet) is proposed to automatically classify crowd density level of passengers. Firstly, an Integrating Multi-scale Attention (IMA) module is proposed to enhance the ability of the plain classifiers to extract semantic crowd texture features to accommodate to the characteristics of the crowd texture feature. The innovation of the IMA module is to fuse the dilation convolution, multiscale feature extraction and attention mechanism to obtain multi-scale crowd feature activation from a larger receptive field with lower computational cost, and to strengthen the crowds activation state of convolutional features in top layers. Secondly, a novel lightweight crowd texture feature extraction network is proposed, which can directly process video frames and automatically extract texture features for crowd density estimation, while its faster image processing speed and fewer network parameters make it flexible to be deployed on embedded platforms with limited hardware resources. Finally, this paper integrates IMA module and the lightweight crowd texture feature extraction network to construct the MCNet, and validate the feasibility of this network on image classification dataset: Cifar10 and four crowd density datasets: PETS2009, Mall, QUT and SH_METRO to validate the MCNet whether can be a suitable solution for crowd density estimation in metro video surveillance where there are image processing challenges such as high density, high occlusion, perspective distortion and limited hardware resources. ",
    "url": "https://arxiv.org/abs/2403.20173",
    "authors": [
      "Qiang Guo",
      "Rubo Zhang",
      "Di Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20190",
    "title": "Homomorphic WiSARDs: Efficient Weightless Neural Network training over  encrypted data",
    "abstract": "The widespread application of machine learning algorithms is a matter of increasing concern for the data privacy research community, and many have sought to develop privacy-preserving techniques for it. Among existing approaches, the homomorphic evaluation of ML algorithms stands out by performing operations directly over encrypted data, enabling strong guarantees of confidentiality. The homomorphic evaluation of inference algorithms is practical even for relatively deep Convolution Neural Networks (CNNs). However, training is still a major challenge, with current solutions often resorting to lightweight algorithms that can be unfit for solving more complex problems, such as image recognition. This work introduces the homomorphic evaluation of Wilkie, Stonham, and Aleksander's Recognition Device (WiSARD) and subsequent Weightless Neural Networks (WNNs) for training and inference on encrypted data. Compared to CNNs, WNNs offer better performance with a relatively small accuracy drop. We develop a complete framework for it, including several building blocks that can be of independent interest. Our framework achieves 91.7% accuracy on the MNIST dataset after only 3.5 minutes of encrypted training (multi-threaded), going up to 93.8% in 3.5 hours. For the HAM10000 dataset, we achieve 67.9% accuracy in just 1.5 minutes, going up to 69.9% after 1 hour. Compared to the state of the art on the HE evaluation of CNN training, Glyph (Lou et al., NeurIPS 2020), these results represent a speedup of up to 1200 times with an accuracy loss of at most 5.4%. For HAM10000, we even achieved a 0.65% accuracy improvement while being 60 times faster than Glyph. We also provide solutions for small-scale encrypted training. In a single thread on a desktop machine using less than 200MB of memory, we train over 1000 MNIST images in 12 minutes or over the entire Wisconsin Breast Cancer dataset in just 11 seconds. ",
    "url": "https://arxiv.org/abs/2403.20190",
    "authors": [
      "Leonardo Neumann",
      "Antonio Guimar\u00e3es",
      "Diego F. Aranha",
      "Edson Borin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.20195",
    "title": "Enhancing Lithological Mapping with Spatially Constrained Bayesian  Network (SCB-Net): An Approach for Field Data-Constrained Predictions with  Uncertainty Evaluation",
    "abstract": "Geological maps are an extremely valuable source of information for the Earth sciences. They provide insights into mineral exploration, vulnerability to natural hazards, and many other applications. These maps are created using numerical or conceptual models that use geological observations to extrapolate data. Geostatistical techniques have traditionally been used to generate reliable predictions that take into account the spatial patterns inherent in the data. However, as the number of auxiliary variables increases, these methods become more labor-intensive. Additionally, traditional machine learning methods often struggle with spatially correlated data and extracting valuable non-linear information from geoscientific datasets. To address these limitations, a new architecture called the Spatially Constrained Bayesian Network (SCB-Net) has been developed. The SCB-Net aims to effectively exploit the information from auxiliary variables while producing spatially constrained predictions. It is made up of two parts, the first part focuses on learning underlying patterns in the auxiliary variables while the second part integrates ground-truth data and the learned embeddings from the first part. Moreover, to assess model uncertainty, a technique called Monte Carlo dropout is used as a Bayesian approximation. The SCB-Net has been applied to two selected areas in northern Quebec, Canada, and has demonstrated its potential in generating field-data-constrained lithological maps while allowing assessment of prediction uncertainty for decision-making. This study highlights the promising advancements of deep neural networks in geostatistics, particularly in handling complex spatial feature learning tasks, leading to improved spatial information techniques. ",
    "url": "https://arxiv.org/abs/2403.20195",
    "authors": [
      "Victor Silva dos Santos",
      "Erwan Gloaguen",
      "Shiva Tirdad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.20199",
    "title": "NeuraLunaDTNet: Feedforward Neural Network-Based Routing Protocol for  Delay-Tolerant Lunar Communication Networks",
    "abstract": "Space Communication poses challenges such as severe delays, hard-to-predict routes and communication disruptions. The Delay Tolerant Network architecture, having been specifically designed keeping such scenarios in mind, is suitable to address some challenges. The traditional DTN routing protocols fall short of delivering optimal performance, due to the inherent complexities of space communication. Researchers have aimed at using recent advancements in AI to mitigate some routing challenges [9]. We propose utilising a feedforward neural network to develop a novel protocol NeuraLunaDTNet, which enhances the efficiency of the PRoPHET routing protocol for lunar communication, by learning contact plans in dynamically changing spatio-temporal graph. ",
    "url": "https://arxiv.org/abs/2403.20199",
    "authors": [
      "Parth Patel",
      "Milena Radenkovic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.20221",
    "title": "Graph Neural Aggregation-diffusion with Metastability",
    "abstract": "Continuous graph neural models based on differential equations have expanded the architecture of graph neural networks (GNNs). Due to the connection between graph diffusion and message passing, diffusion-based models have been widely studied. However, diffusion naturally drives the system towards an equilibrium state, leading to issues like over-smoothing. To this end, we propose GRADE inspired by graph aggregation-diffusion equations, which includes the delicate balance between nonlinear diffusion and aggregation induced by interaction potentials. The node representations obtained through aggregation-diffusion equations exhibit metastability, indicating that features can aggregate into multiple clusters. In addition, the dynamics within these clusters can persist for long time periods, offering the potential to alleviate over-smoothing effects. This nonlinear diffusion in our model generalizes existing diffusion-based models and establishes a connection with classical GNNs. We prove that GRADE achieves competitive performance across various benchmarks and alleviates the over-smoothing issue in GNNs evidenced by the enhanced Dirichlet energy. ",
    "url": "https://arxiv.org/abs/2403.20221",
    "authors": [
      "Kaiyuan Cui",
      "Xinyan Wang",
      "Zicheng Zhang",
      "Weichen Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.20231",
    "title": "U-VAP: User-specified Visual Appearance Personalization via Decoupled  Self Augmentation",
    "abstract": "Concept personalization methods enable large text-to-image models to learn specific subjects (e.g., objects/poses/3D models) and synthesize renditions in new contexts. Given that the image references are highly biased towards visual attributes, state-of-the-art personalization models tend to overfit the whole subject and cannot disentangle visual characteristics in pixel space. In this study, we proposed a more challenging setting, namely fine-grained visual appearance personalization. Different from existing methods, we allow users to provide a sentence describing the desired attributes. A novel decoupled self-augmentation strategy is proposed to generate target-related and non-target samples to learn user-specified visual attributes. These augmented data allow for refining the model's understanding of the target attribute while mitigating the impact of unrelated attributes. At the inference stage, adjustments are conducted on semantic space through the learned target and non-target embeddings to further enhance the disentanglement of target attributes. Extensive experiments on various kinds of visual attributes with SOTA personalization methods show the ability of the proposed method to mimic target visual appearance in novel contexts, thus improving the controllability and flexibility of personalization. ",
    "url": "https://arxiv.org/abs/2403.20231",
    "authors": [
      "You Wu",
      "Kean Liu",
      "Xiaoyue Mi",
      "Fan Tang",
      "Juan Cao",
      "Jintao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20234",
    "title": "Artificial Neural Networks-based Real-time Classification of ENG Signals  for Implanted Nerve Interfaces",
    "abstract": "Neuropathies are gaining higher relevance in clinical settings, as they risk permanently jeopardizing a person's life. To support the recovery of patients, the use of fully implanted devices is emerging as one of the most promising solutions. However, these devices, even if becoming an integral part of a fully complex neural nanonetwork system, pose numerous challenges. In this article, we address one of them, which consists of the classification of motor/sensory stimuli. The task is performed by exploring four different types of artificial neural networks (ANNs) to extract various sensory stimuli from the electroneurographic (ENG) signal measured in the sciatic nerve of rats. Different sizes of the data sets are considered to analyze the feasibility of the investigated ANNs for real-time classification through a comparison of their performance in terms of accuracy, F1-score, and prediction time. The design of the ANNs takes advantage of the modelling of the ENG signal as a multiple-input multiple-output (MIMO) system to describe the measures taken by state-of-the-art implanted nerve interfaces. These are based on the use of multi-contact cuff electrodes to achieve nanoscale spatial discrimination of the nerve activity. The MIMO ENG signal model is another contribution of this paper. Our results show that some ANNs are more suitable for real-time applications, being capable of achieving accuracies over $90\\%$ for signal windows of $100$ and $200\\,$ms with a low enough processing time to be effective for pathology recovery. ",
    "url": "https://arxiv.org/abs/2403.20234",
    "authors": [
      "ntonio Coviello",
      "Francesco Linsalata",
      "Umberto Spagnolini",
      "Maurizio Magarini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.20236",
    "title": "Long-Tailed Anomaly Detection with Learnable Class Names",
    "abstract": "Anomaly detection (AD) aims to identify defective images and localize their defects (if any). Ideally, AD models should be able to detect defects over many image classes; without relying on hard-coded class names that can be uninformative or inconsistent across datasets; learn without anomaly supervision; and be robust to the long-tailed distributions of real-world applications. To address these challenges, we formulate the problem of long-tailed AD by introducing several datasets with different levels of class imbalance and metrics for performance evaluation. We then propose a novel method, LTAD, to detect defects from multiple and long-tailed classes, without relying on dataset class names. LTAD combines AD by reconstruction and semantic AD modules. AD by reconstruction is implemented with a transformer-based reconstruction module. Semantic AD is implemented with a binary classifier, which relies on learned pseudo class names and a pretrained foundation model. These modules are learned over two phases. Phase 1 learns the pseudo-class names and a variational autoencoder (VAE) for feature synthesis that augments the training data to combat long-tails. Phase 2 then learns the parameters of the reconstruction and classification modules of LTAD. Extensive experiments using the proposed long-tailed datasets show that LTAD substantially outperforms the state-of-the-art methods for most forms of dataset imbalance. The long-tailed dataset split is available at https://zenodo.org/records/10854201 . ",
    "url": "https://arxiv.org/abs/2403.20236",
    "authors": [
      "Chih-Hui Ho",
      "Kuan-Chuan Peng",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20251",
    "title": "Latent Embedding Clustering for Occlusion Robust Head Pose Estimation",
    "abstract": "Head pose estimation has become a crucial area of research in computer vision given its usefulness in a wide range of applications, including robotics, surveillance, or driver attention monitoring. One of the most difficult challenges in this field is managing head occlusions that frequently take place in real-world scenarios. In this paper, we propose a novel and efficient framework that is robust in real world head occlusion scenarios. In particular, we propose an unsupervised latent embedding clustering with regression and classification components for each pose angle. The model optimizes latent feature representations for occluded and non-occluded images through a clustering term while improving fine-grained angle predictions. Experimental evaluation on in-the-wild head pose benchmark datasets reveal competitive performance in comparison to state-of-the-art methodologies with the advantage of having a significant data reduction. We observe a substantial improvement in occluded head pose estimation. Also, an ablation study is conducted to ascertain the impact of the clustering term within our proposed framework. ",
    "url": "https://arxiv.org/abs/2403.20251",
    "authors": [
      "Jos\u00e9 Celestino",
      "Manuel Marques",
      "Jacinto C. Nascimento"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20254",
    "title": "Benchmarking the Robustness of Temporal Action Detection Models Against  Temporal Corruptions",
    "abstract": "Temporal action detection (TAD) aims to locate action positions and recognize action categories in long-term untrimmed videos. Although many methods have achieved promising results, their robustness has not been thoroughly studied. In practice, we observe that temporal information in videos can be occasionally corrupted, such as missing or blurred frames. Interestingly, existing methods often incur a significant performance drop even if only one frame is affected. To formally evaluate the robustness, we establish two temporal corruption robustness benchmarks, namely THUMOS14-C and ActivityNet-v1.3-C. In this paper, we extensively analyze the robustness of seven leading TAD methods and obtain some interesting findings: 1) Existing methods are particularly vulnerable to temporal corruptions, and end-to-end methods are often more susceptible than those with a pre-trained feature extractor; 2) Vulnerability mainly comes from localization error rather than classification error; 3) When corruptions occur in the middle of an action instance, TAD models tend to yield the largest performance drop. Besides building a benchmark, we further develop a simple but effective robust training method to defend against temporal corruptions, through the FrameDrop augmentation and Temporal-Robust Consistency loss. Remarkably, our approach not only improves robustness but also yields promising improvements on clean data. We believe that this study will serve as a benchmark for future research in robust video analysis. Source code and models are available at https://github.com/Alvin-Zeng/temporal-robustness-benchmark. ",
    "url": "https://arxiv.org/abs/2403.20254",
    "authors": [
      "Runhao Zeng",
      "Xiaoyong Chen",
      "Jiaming Liang",
      "Huisi Wu",
      "Guangzhong Cao",
      "Yong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20260",
    "title": "Prototype-based Interpretable Breast Cancer Prediction Models: Analysis  and Challenges",
    "abstract": "Deep learning models have achieved high performance in medical applications, however, their adoption in clinical practice is hindered due to their black-box nature. Self-explainable models, like prototype-based models, can be especially beneficial as they are interpretable by design. However, if the learnt prototypes are of low quality then the prototype-based models are as good as black-box. Having high quality prototypes is a pre-requisite for a truly interpretable model. In this work, we propose a prototype evaluation framework for coherence (PEF-C) for quantitatively evaluating the quality of the prototypes based on domain knowledge. We show the use of PEF-C in the context of breast cancer prediction using mammography. Existing works on prototype-based models on breast cancer prediction using mammography have focused on improving the classification performance of prototype-based models compared to black-box models and have evaluated prototype quality through anecdotal evidence. We are the first to go beyond anecdotal evidence and evaluate the quality of the mammography prototypes systematically using our PEF-C. Specifically, we apply three state-of-the-art prototype-based models, ProtoPNet, BRAIxProtoPNet++ and PIP-Net on mammography images for breast cancer prediction and evaluate these models w.r.t. i) classification performance, and ii) quality of the prototypes, on three public datasets. Our results show that prototype-based models are competitive with black-box models in terms of classification performance, and achieve a higher score in detecting ROIs. However, the quality of the prototypes are not yet sufficient and can be improved in aspects of relevance, purity and learning a variety of prototypes. We call the XAI community to systematically evaluate the quality of the prototypes to check their true usability in high stake decisions and improve such models further. ",
    "url": "https://arxiv.org/abs/2403.20260",
    "authors": [
      "Shreyasi Pathak",
      "J\u00f6rg Schl\u00f6tterer",
      "Jeroen Veltman",
      "Jeroen Geerdink",
      "Maurice van Keulen",
      "Christin Seifert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20273",
    "title": "CATSNet: a context-aware network for Height Estimation in a Forested  Area based on Pol-TomoSAR data",
    "abstract": "Tropical forests are a key component of the global carbon cycle. With plans for upcoming space-borne missions like BIOMASS to monitor forestry, several airborne missions, including TropiSAR and AfriSAR campaigns, have been successfully launched and experimented. Typical Synthetic Aperture Radar Tomography (TomoSAR) methods involve complex models with low accuracy and high computation costs. In recent years, deep learning methods have also gained attention in the TomoSAR framework, showing interesting performance. Recently, a solution based on a fully connected Tomographic Neural Network (TSNN) has demonstrated its effectiveness in accurately estimating forest and ground heights by exploiting the pixel-wise elements of the covariance matrix derived from TomoSAR data. This work instead goes beyond the pixel-wise approach to define a context-aware deep learning-based solution named CATSNet. A convolutional neural network is considered to leverage patch-based information and extract features from a neighborhood rather than focus on a single pixel. The training is conducted by considering TomoSAR data as the input and Light Detection and Ranging (LiDAR) values as the ground truth. The experimental results show striking advantages in both performance and generalization ability by leveraging context information within Multiple Baselines (MB) TomoSAR data across different polarimetric modalities, surpassing existing techniques. ",
    "url": "https://arxiv.org/abs/2403.20273",
    "authors": [
      "Wenyu Yang",
      "Sergio Vitale",
      "Hossein Aghababaei",
      "Giampaolo Ferraioli",
      "Vito Pascazio",
      "Gilda Schirinzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20298",
    "title": "Review-Based Cross-Domain Recommendation via Hyperbolic Embedding and  Hierarchy-Aware Domain Disentanglement",
    "abstract": "The issue of data sparsity poses a significant challenge to recommender systems. In response to this, algorithms that leverage side information such as review texts have been proposed. Furthermore, Cross-Domain Recommendation (CDR), which captures domain-shareable knowledge and transfers it from a richer domain (source) to a sparser one (target), has received notable attention. Nevertheless, the majority of existing methodologies assume a Euclidean embedding space, encountering difficulties in accurately representing richer text information and managing complex interactions between users and items. This paper advocates a hyperbolic CDR approach based on review texts for modeling user-item relationships. We first emphasize that conventional distance-based domain alignment techniques may cause problems because small modifications in hyperbolic geometry result in magnified perturbations, ultimately leading to the collapse of hierarchical structures. To address this challenge, we propose hierarchy-aware embedding and domain alignment schemes that adjust the scale to extract domain-shareable information without disrupting structural forms. The process involves the initial embedding of review texts in hyperbolic space, followed by feature extraction incorporating degree-based normalization and structure alignment. We conducted extensive experiments to substantiate the efficiency, robustness, and scalability of our proposed model in comparison to state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2403.20298",
    "authors": [
      "Yoonhyuk Choi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.20317",
    "title": "Convolutional Prompting meets Language Models for Continual Learning",
    "abstract": "Continual Learning (CL) enables machine learning models to learn from continuously shifting new training data in absence of data from old tasks. Recently, pretrained vision transformers combined with prompt tuning have shown promise for overcoming catastrophic forgetting in CL. These approaches rely on a pool of learnable prompts which can be inefficient in sharing knowledge across tasks leading to inferior performance. In addition, the lack of fine-grained layer specific prompts does not allow these to fully express the strength of the prompts for CL. We address these limitations by proposing ConvPrompt, a novel convolutional prompt creation mechanism that maintains layer-wise shared embeddings, enabling both layer-specific learning and better concept transfer across tasks. The intelligent use of convolution enables us to maintain a low parameter overhead without compromising performance. We further leverage Large Language Models to generate fine-grained text descriptions of each category which are used to get task similarity and dynamically decide the number of prompts to be learned. Extensive experiments demonstrate the superiority of ConvPrompt and improves SOTA by ~3% with significantly less parameter overhead. We also perform strong ablation over various modules to disentangle the importance of different components. ",
    "url": "https://arxiv.org/abs/2403.20317",
    "authors": [
      "Anurag Roy",
      "Riddhiman Moulick",
      "Vinay K. Verma",
      "Saptarshi Ghosh",
      "Abir Das"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20318",
    "title": "SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular  3D Detection of Large Objects",
    "abstract": "Monocular 3D detectors achieve remarkable performance on cars and smaller objects. However, their performance drops on larger objects, leading to fatal accidents. Some attribute the failures to training data scarcity or their receptive field requirements of large objects. In this paper, we highlight this understudied problem of generalization to large objects. We find that modern frontal detectors struggle to generalize to large objects even on nearly balanced datasets. We argue that the cause of failure is the sensitivity of depth regression losses to noise of larger objects. To bridge this gap, we comprehensively investigate regression and dice losses, examining their robustness under varying error levels and object sizes. We mathematically prove that the dice loss leads to superior noise-robustness and model convergence for large objects compared to regression losses for a simplified case. Leveraging our theoretical insights, we propose SeaBird (Segmentation in Bird's View) as the first step towards generalizing to large objects. SeaBird effectively integrates BEV segmentation on foreground objects for 3D detection, with the segmentation head trained with the dice loss. SeaBird achieves SoTA results on the KITTI-360 leaderboard and improves existing detectors on the nuScenes leaderboard, particularly for large objects. Code and models at https://github.com/abhi1kumar/SeaBird ",
    "url": "https://arxiv.org/abs/2403.20318",
    "authors": [
      "Abhinav Kumar",
      "Yuliang Guo",
      "Xinyu Huang",
      "Liu Ren",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.19736",
    "title": "Physics-Informed Neural Networks for Satellite State Estimation",
    "abstract": "The Space Domain Awareness (SDA) community routinely tracks satellites in orbit by fitting an orbital state to observations made by the Space Surveillance Network (SSN). In order to fit such orbits, an accurate model of the forces that are acting on the satellite is required. Over the past several decades, high-quality, physics-based models have been developed for satellite state estimation and propagation. These models are exceedingly good at estimating and propagating orbital states for non-maneuvering satellites; however, there are several classes of anomalous accelerations that a satellite might experience which are not well-modeled, such as satellites that use low-thrust electric propulsion to modify their orbit. Physics-Informed Neural Networks (PINNs) are a valuable tool for these classes of satellites as they combine physics models with Deep Neural Networks (DNNs), which are highly expressive and versatile function approximators. By combining a physics model with a DNN, the machine learning model need not learn astrodynamics, which results in more efficient and effective utilization of machine learning resources. This paper details the application of PINNs to estimate the orbital state and a continuous, low-amplitude anomalous acceleration profile for satellites. The PINN is trained to learn the unknown acceleration by minimizing the mean square error of observations. We evaluate the performance of pure physics models with PINNs in terms of their observation residuals and their propagation accuracy beyond the fit span of the observations. For a two-day simulation of a GEO satellite using an unmodeled acceleration profile on the order of $10^{-8} \\text{ km/s}^2$, the PINN outperformed the best-fit physics model by orders of magnitude for both observation residuals (123 arcsec vs 1.00 arcsec) as well as propagation accuracy (3860 km vs 164 km after five days). ",
    "url": "https://arxiv.org/abs/2403.19736",
    "authors": [
      "Jacob Varey",
      "Jessica D. Ruprecht",
      "Michael Tierney",
      "Ryan Sullenberger"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.19737",
    "title": "Piercing independent sets in graphs without large induced matching",
    "abstract": "Given a graph $G$, denote by $h(G)$ the smallest size of a subset of $V(G)$ which intersects every maximum independent set of $G$. We prove that any graph $G$ without induced matching of size $t$ satisfies $h(G)\\le \\omega(G)^{3t-3+o(1)}$. This resolves a conjecture of Hajebi, Li and Spirkl (Hitting all maximum stable sets in $P_{5}$-free graphs, JCTB 2024). ",
    "url": "https://arxiv.org/abs/2403.19737",
    "authors": [
      "Jiangdong Ai",
      "Hong Liu",
      "Zixiang Xu",
      "Qiang Zhou"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2403.19783",
    "title": "AlloyBERT: Alloy Property Prediction with Large Language Models",
    "abstract": "The pursuit of novel alloys tailored to specific requirements poses significant challenges for researchers in the field. This underscores the importance of developing predictive techniques for essential physical properties of alloys based on their chemical composition and processing parameters. This study introduces AlloyBERT, a transformer encoder-based model designed to predict properties such as elastic modulus and yield strength of alloys using textual inputs. Leveraging the pre-trained RoBERTa encoder model as its foundation, AlloyBERT employs self-attention mechanisms to establish meaningful relationships between words, enabling it to interpret human-readable input and predict target alloy properties. By combining a tokenizer trained on our textual data and a RoBERTa encoder pre-trained and fine-tuned for this specific task, we achieved a mean squared error (MSE) of 0.00015 on the Multi Principal Elemental Alloys (MPEA) data set and 0.00611 on the Refractory Alloy Yield Strength (RAYS) dataset. This surpasses the performance of shallow models, which achieved a best-case MSE of 0.00025 and 0.0076 on the MPEA and RAYS datasets respectively. Our results highlight the potential of language models in material science and establish a foundational framework for text-based prediction of alloy properties that does not rely on complex underlying representations, calculations, or simulations. ",
    "url": "https://arxiv.org/abs/2403.19783",
    "authors": [
      "Akshat Chaudhari",
      "Chakradhar Guntuboina",
      "Hongshuo Huang",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.19844",
    "title": "Expanding Chemical Representation with k-mers and Fragment-based  Fingerprints for Molecular Fingerprinting",
    "abstract": "This study introduces a novel approach, combining substruct counting, $k$-mers, and Daylight-like fingerprints, to expand the representation of chemical structures in SMILES strings. The integrated method generates comprehensive molecular embeddings that enhance discriminative power and information content. Experimental evaluations demonstrate its superiority over traditional Morgan fingerprinting, MACCS, and Daylight fingerprint alone, improving chemoinformatics tasks such as drug classification. The proposed method offers a more informative representation of chemical structures, advancing molecular similarity analysis and facilitating applications in molecular design and drug discovery. It presents a promising avenue for molecular structure analysis and design, with significant potential for practical implementation. ",
    "url": "https://arxiv.org/abs/2403.19844",
    "authors": [
      "Sarwan Ali",
      "Prakash Chourasia",
      "Murray Patterson"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2403.20018",
    "title": "SCINeRF: Neural Radiance Fields from a Snapshot Compressive Image",
    "abstract": "In this paper, we explore the potential of Snapshot Compressive Imaging (SCI) technique for recovering the underlying 3D scene representation from a single temporal compressed image. SCI is a cost-effective method that enables the recording of high-dimensional data, such as hyperspectral or temporal information, into a single image using low-cost 2D imaging sensors. To achieve this, a series of specially designed 2D masks are usually employed, which not only reduces storage requirements but also offers potential privacy protection. Inspired by this, to take one step further, our approach builds upon the powerful 3D scene representation capabilities of neural radiance fields (NeRF). Specifically, we formulate the physical imaging process of SCI as part of the training of NeRF, allowing us to exploit its impressive performance in capturing complex scene structures. To assess the effectiveness of our method, we conduct extensive evaluations using both synthetic data and real data captured by our SCI system. Extensive experimental results demonstrate that our proposed approach surpasses the state-of-the-art methods in terms of image reconstruction and novel view image synthesis. Moreover, our method also exhibits the ability to restore high frame-rate multi-view consistent images by leveraging SCI and the rendering capabilities of NeRF. The code is available at https://github.com/WU-CVGL/SCINeRF. ",
    "url": "https://arxiv.org/abs/2403.20018",
    "authors": [
      "Yunhao Li",
      "Xiaodong Wang",
      "Ping Wang",
      "Xin Yuan",
      "Peidong Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.20020",
    "title": "Nonparametric Bellman Mappings for Reinforcement Learning: Application  to Robust Adaptive Filtering",
    "abstract": "This paper designs novel nonparametric Bellman mappings in reproducing kernel Hilbert spaces (RKHSs) for reinforcement learning (RL). The proposed mappings benefit from the rich approximating properties of RKHSs, adopt no assumptions on the statistics of the data owing to their nonparametric nature, require no knowledge on transition probabilities of Markov decision processes, and may operate without any training data. Moreover, they allow for sampling on-the-fly via the design of trajectory samples, re-use past test data via experience replay, effect dimensionality reduction by random Fourier features, and enable computationally lightweight operations to fit into efficient online or time-adaptive learning. The paper offers also a variational framework to design the free parameters of the proposed Bellman mappings, and shows that appropriate choices of those parameters yield several popular Bellman-mapping designs. As an application, the proposed mappings are employed to offer a novel solution to the problem of countering outliers in adaptive filtering. More specifically, with no prior information on the statistics of the outliers and no training data, a policy-iteration algorithm is introduced to select online, per time instance, the ``optimal'' coefficient p in the least-mean-p-power-error method. Numerical tests on synthetic data showcase, in most of the cases, the superior performance of the proposed solution over several RL and non-RL schemes. ",
    "url": "https://arxiv.org/abs/2403.20020",
    "authors": [
      "Yuki Akiyama",
      "Minh Vu",
      "Konstantinos Slavakis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.20033",
    "title": "A novel decision fusion approach for sale price prediction using Elastic  Net and MOPSO",
    "abstract": "Price prediction algorithms propose prices for every product or service according to market trends, projected demand, and other characteristics, including government rules, international transactions, and speculation and expectation. As the dependent variable in price prediction, it is affected by several independent and correlated variables which may challenge the price prediction. To overcome this challenge, machine learning algorithms allow more accurate price prediction without explicitly modeling the relatedness between variables. However, as inputs increase, it challenges the existing machine learning approaches regarding computing efficiency and prediction effectiveness. Hence, this study introduces a novel decision level fusion approach to select informative variables in price prediction. The suggested metaheuristic algorithm balances two competitive objective functions, which are defined to improve the prediction utilized variables and reduce the error rate simultaneously. To generate Pareto optimal solutions, an Elastic net approach is employed to eliminate unrelated and redundant variables to increase the accuracy. Afterward, we propose a novel method for combining solutions and ensuring that a subset of features is optimal. Two various real datasets evaluate the proposed price prediction method. The results support the suggested superiority of the model concerning its relative root mean square error and adjusted correlation coefficient. ",
    "url": "https://arxiv.org/abs/2403.20033",
    "authors": [
      "Amir Eshaghi Chaleshtori"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.20058",
    "title": "Revolutionizing Disease Diagnosis with simultaneous functional PET/MR  and Deeply Integrated Brain Metabolic, Hemodynamic, and Perfusion Networks",
    "abstract": "Simultaneous functional PET/MR (sf-PET/MR) presents a cutting-edge multimodal neuroimaging technique. It provides an unprecedented opportunity for concurrently monitoring and integrating multifaceted brain networks built by spatiotemporally covaried metabolic activity, neural activity, and cerebral blood flow (perfusion). Albeit high scientific/clinical values, short in hardware accessibility of PET/MR hinders its applications, let alone modern AI-based PET/MR fusion models. Our objective is to develop a clinically feasible AI-based disease diagnosis model trained on comprehensive sf-PET/MR data with the power of, during inferencing, allowing single modality input (e.g., PET only) as well as enforcing multimodal-based accuracy. To this end, we propose MX-ARM, a multimodal MiXture-of-experts Alignment and Reconstruction Model. It is modality detachable and exchangeable, allocating different multi-layer perceptrons dynamically (\"mixture of experts\") through learnable weights to learn respective representations from different modalities. Such design will not sacrifice model performance in uni-modal situation. To fully exploit the inherent complex and nonlinear relation among modalities while producing fine-grained representations for uni-modal inference, we subsequently add a modal alignment module to line up a dominant modality (e.g., PET) with representations of auxiliary modalities (MR). We further adopt multimodal reconstruction to promote the quality of learned features. Experiments on precious multimodal sf-PET/MR data for Mild Cognitive Impairment diagnosis showcase the efficacy of our model toward clinically feasible precision medicine. ",
    "url": "https://arxiv.org/abs/2403.20058",
    "authors": [
      "Luoyu Wang",
      "Yitian Tao",
      "Qing Yang",
      "Yan Liang",
      "Siwei Liu",
      "Hongcheng Shi",
      "Dinggang Shen",
      "Han Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.20261",
    "title": "FABind+: Enhancing Molecular Docking through Improved Pocket Prediction  and Pose Generation",
    "abstract": "Molecular docking is a pivotal process in drug discovery. While traditional techniques rely on extensive sampling and simulation governed by physical principles, these methods are often slow and costly. The advent of deep learning-based approaches has shown significant promise, offering increases in both accuracy and efficiency. Building upon the foundational work of FABind, a model designed with a focus on speed and accuracy, we present FABind+, an enhanced iteration that largely boosts the performance of its predecessor. We identify pocket prediction as a critical bottleneck in molecular docking and propose a novel methodology that significantly refines pocket prediction, thereby streamlining the docking process. Furthermore, we introduce modifications to the docking module to enhance its pose generation capabilities. In an effort to bridge the gap with conventional sampling/generative methods, we incorporate a simple yet effective sampling technique coupled with a confidence model, requiring only minor adjustments to the regression framework of FABind. Experimental results and analysis reveal that FABind+ remarkably outperforms the original FABind, achieves competitive state-of-the-art performance, and delivers insightful modeling strategies. This demonstrates FABind+ represents a substantial step forward in molecular docking and drug discovery. Our code is in https://github.com/QizhiPei/FABind. ",
    "url": "https://arxiv.org/abs/2403.20261",
    "authors": [
      "Kaiyuan Gao",
      "Qizhi Pei",
      "Jinhua Zhu",
      "Tao Qin",
      "Kun He",
      "Tie-Yan Liu",
      "Lijun Wu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1811.09537",
    "title": "On three domination-based identification problems in block graphs",
    "abstract": " Title: On three domination-based identification problems in block graphs ",
    "url": "https://arxiv.org/abs/1811.09537",
    "authors": [
      "Dipayan Chakraborty",
      "Florent Foucaud",
      "Aline Parreau",
      "Annegret K. Wagler"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2008.10771",
    "title": "MuCo: Publishing Microdata with Privacy Preservation through Mutual  Cover",
    "abstract": " Title: MuCo: Publishing Microdata with Privacy Preservation through Mutual  Cover ",
    "url": "https://arxiv.org/abs/2008.10771",
    "authors": [
      "Boyu Li",
      "Jianfeng Ma",
      "Junhua Xi",
      "Lili Zhang",
      "Tao Xie",
      "Tongfei Shang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2010.08311",
    "title": "Formal Verification of Robustness and Resilience of Learning-Enabled  State Estimation Systems",
    "abstract": " Comments: Accepted for publication in Neurocomputing ",
    "url": "https://arxiv.org/abs/2010.08311",
    "authors": [
      "Wei Huang",
      "Yifan Zhou",
      "Gaojie Jin",
      "Youcheng Sun",
      "Jie Meng",
      "Fan Zhang",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.01818",
    "title": "QAGCN: Answering Multi-Relation Questions via Single-Step Implicit  Reasoning over Knowledge Graphs",
    "abstract": " Title: QAGCN: Answering Multi-Relation Questions via Single-Step Implicit  Reasoning over Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2206.01818",
    "authors": [
      "Ruijie Wang",
      "Luca Rossetto",
      "Michael Cochez",
      "Abraham Bernstein"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11964",
    "title": "Strong Transferable Adversarial Attacks via Ensembled Asymptotically  Normal Distribution Learning",
    "abstract": " Title: Strong Transferable Adversarial Attacks via Ensembled Asymptotically  Normal Distribution Learning ",
    "url": "https://arxiv.org/abs/2209.11964",
    "authors": [
      "Zhengwei Fang",
      "Rui Wang",
      "Tao Huang",
      "Liping Jing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06186",
    "title": "GOTCHA: Real-Time Video Deepfake Detection via Challenge-Response",
    "abstract": " Comments: 20 pages, 19 figures, Code and data released ",
    "url": "https://arxiv.org/abs/2210.06186",
    "authors": [
      "Govind Mittal",
      "Chinmay Hegde",
      "Nasir Memon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.14426",
    "title": "Restricting to the chip architecture maintains the quantum neural  network accuracy",
    "abstract": " Title: Restricting to the chip architecture maintains the quantum neural  network accuracy ",
    "url": "https://arxiv.org/abs/2212.14426",
    "authors": [
      "Lucas Friedrich",
      "Jonas Maziero"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13821",
    "title": "Complete Neural Networks for Complete Euclidean Graphs",
    "abstract": " Comments: The 38th AAAI Conference on Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2301.13821",
    "authors": [
      "Snir Hordan",
      "Tal Amir",
      "Steven J. Gortler",
      "Nadav Dym"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04181",
    "title": "Attending to Graph Transformers",
    "abstract": " Title: Attending to Graph Transformers ",
    "url": "https://arxiv.org/abs/2302.04181",
    "authors": [
      "Luis M\u00fcller",
      "Mikhail Galkin",
      "Christopher Morris",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.13417",
    "title": "Training neural networks with structured noise improves classification  and generalization",
    "abstract": " Comments: 17 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2302.13417",
    "authors": [
      "Marco Benedetti",
      "Enrico Ventura"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.00510",
    "title": "A Comparison of Speech Data Augmentation Methods Using S3PRL Toolkit",
    "abstract": " Title: A Comparison of Speech Data Augmentation Methods Using S3PRL Toolkit ",
    "url": "https://arxiv.org/abs/2303.00510",
    "authors": [
      "Mina Huh",
      "Ruchira Ray",
      "Corey Karnei"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.06471",
    "title": "Multimodal Data Integration for Oncology in the Era of Deep Neural  Networks: A Review",
    "abstract": " Title: Multimodal Data Integration for Oncology in the Era of Deep Neural  Networks: A Review ",
    "url": "https://arxiv.org/abs/2303.06471",
    "authors": [
      "Asim Waqas",
      "Aakash Tripathi",
      "Ravi P. Ramachandran",
      "Paul Stewart",
      "Ghulam Rasool"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.01705",
    "title": "Cross-modal tumor segmentation using generative blending augmentation  and self training",
    "abstract": " Title: Cross-modal tumor segmentation using generative blending augmentation  and self training ",
    "url": "https://arxiv.org/abs/2304.01705",
    "authors": [
      "Guillaume Sall\u00e9",
      "Pierre-Henri Conze",
      "Julien Bert",
      "Nicolas Boussion",
      "Dimitris Visvikis",
      "Vincent Jaouen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16674",
    "title": "Online learning for robust voltage control under uncertain grid topology",
    "abstract": " Comments: Accepted by IEEE Transactions on Smart Grid. arXiv admin note: substantial text overlap with arXiv:2206.14369 ",
    "url": "https://arxiv.org/abs/2306.16674",
    "authors": [
      "Christopher Yeh",
      "Jing Yu",
      "Yuanyuan Shi",
      "Adam Wierman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.12044",
    "title": "A multiobjective continuation method to compute the regularization path  of deep neural networks",
    "abstract": " Comments: 7 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2308.12044",
    "authors": [
      "Augustina C. Amakor",
      "Konstantin Sonntag",
      "Sebastian Peitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.16971",
    "title": "Multi-Resolution Active Learning of Fourier Neural Operators",
    "abstract": " Title: Multi-Resolution Active Learning of Fourier Neural Operators ",
    "url": "https://arxiv.org/abs/2309.16971",
    "authors": [
      "Shibo Li",
      "Xin Yu",
      "Wei Xing",
      "Mike Kirby",
      "Akil Narayan",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00648",
    "title": "PETA: Parameter-Efficient Trojan Attacks",
    "abstract": " Title: PETA: Parameter-Efficient Trojan Attacks ",
    "url": "https://arxiv.org/abs/2310.00648",
    "authors": [
      "Lauren Hong",
      "Ting Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05916",
    "title": "Interpreting CLIP's Image Representation via Text-Based Decomposition",
    "abstract": " Comments: Project page and code: this https URL ",
    "url": "https://arxiv.org/abs/2310.05916",
    "authors": [
      "Yossi Gandelsman",
      "Alexei A. Efros",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.13240",
    "title": "Transparency challenges in policy evaluation with causal machine  learning -- improving usability and accountability",
    "abstract": " Comments: 31 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2310.13240",
    "authors": [
      "Patrick Rehill",
      "Nicholas Biddle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2310.18274",
    "title": "LipSim: A Provably Robust Perceptual Similarity Metric",
    "abstract": " Title: LipSim: A Provably Robust Perceptual Similarity Metric ",
    "url": "https://arxiv.org/abs/2310.18274",
    "authors": [
      "Sara Ghazanfari",
      "Alexandre Araujo",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01025",
    "title": "Integrating Language-Derived Appearance Elements with Visual Cues in  Pedestrian Detection",
    "abstract": " Comments: 11 pages, 5 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2311.01025",
    "authors": [
      "Sungjune Park",
      "Hyunjun Kim",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.15153",
    "title": "Predicting Gradient is Better: Exploring Self-Supervised Learning for  SAR ATR with a Joint-Embedding Predictive Architecture",
    "abstract": " Comments: Our codes at this https URL ",
    "url": "https://arxiv.org/abs/2311.15153",
    "authors": [
      "Weijie Li",
      "Yang Wei",
      "Tianpeng Liu",
      "Yuenan Hou",
      "Yuxuan Li",
      "Zhen Liu",
      "Yongxiang Liu",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.17132",
    "title": "TransNeXt: Robust Foveal Visual Perception for Vision Transformers",
    "abstract": " Comments: CVPR 2024 Camera-ready Version. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2311.17132",
    "authors": [
      "Dai Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.02214",
    "title": "FlashAvatar: High-fidelity Head Avatar with Efficient Gaussian Embedding",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2312.02214",
    "authors": [
      "Jun Xiang",
      "Xuan Gao",
      "Yudong Guo",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2312.09866",
    "title": "PLGSLAM: Progressive Neural Scene Represenation with Local to Global  Bundle Adjustment",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2312.09866",
    "authors": [
      "Tianchen Deng",
      "Guole Shen",
      "Tong Qin",
      "Jianyu Wang",
      "Wentao Zhao",
      "Jingchuan Wang",
      "Danwei Wang",
      "Weidong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.13528",
    "title": "DyBluRF: Dynamic Deblurring Neural Radiance Fields for Blurry Monocular  Video",
    "abstract": " Comments: The first two authors contributed equally to this work (equal contribution). The last two authors advised equally to this work. Please visit our project page at this https URL ",
    "url": "https://arxiv.org/abs/2312.13528",
    "authors": [
      "Minh-Quan Viet Bui",
      "Jongmin Park",
      "Jihyong Oh",
      "Munchurl Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.16438",
    "title": "Visual Spatial Attention and Proprioceptive Data-Driven Reinforcement  Learning for Robust Peg-in-Hole Task Under Variable Conditions",
    "abstract": " Comments: Published in IEEE Robotics and Automation Letters on 08 February 2023 ",
    "url": "https://arxiv.org/abs/2312.16438",
    "authors": [
      "Andr\u00e9 Yuji Yasutomi",
      "Hideyuki Ichiwara",
      "Hiroshi Ito",
      "Hiroki Mori",
      "Tetsuya Ogata"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.17269",
    "title": "Conversational Question Answering with Reformulations over Knowledge  Graph",
    "abstract": " Title: Conversational Question Answering with Reformulations over Knowledge  Graph ",
    "url": "https://arxiv.org/abs/2312.17269",
    "authors": [
      "Lihui Liu",
      "Blaine Hill",
      "Boxin Du",
      "Fei Wang",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.00616",
    "title": "GD^2-NeRF: Generative Detail Compensation via GAN and Diffusion for  One-shot Generalizable Neural Radiance Fields",
    "abstract": " Comments: Submitted to Journal ",
    "url": "https://arxiv.org/abs/2401.00616",
    "authors": [
      "Xiao Pan",
      "Zongxin Yang",
      "Shuai Bai",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.13460",
    "title": "Multi-Agent Diagnostics for Robustness via Illuminated Diversity",
    "abstract": " Title: Multi-Agent Diagnostics for Robustness via Illuminated Diversity ",
    "url": "https://arxiv.org/abs/2401.13460",
    "authors": [
      "Mikayel Samvelyan",
      "Davide Paglieri",
      "Minqi Jiang",
      "Jack Parker-Holder",
      "Tim Rockt\u00e4schel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2401.15741",
    "title": "SERNet-Former: Semantic Segmentation by Efficient Residual Network with  Attention-Boosting Gates and Attention-Fusion Networks",
    "abstract": " Title: SERNet-Former: Semantic Segmentation by Efficient Residual Network with  Attention-Boosting Gates and Attention-Fusion Networks ",
    "url": "https://arxiv.org/abs/2401.15741",
    "authors": [
      "Serdar Erisen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.03646",
    "title": "Lens: A Foundation Model for Network Traffic in Cybersecurity",
    "abstract": " Title: Lens: A Foundation Model for Network Traffic in Cybersecurity ",
    "url": "https://arxiv.org/abs/2402.03646",
    "authors": [
      "Qineng Wang",
      "Chen Qian",
      "Xiaochang Li",
      "Ziyu Yao",
      "Huajie Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2402.04385",
    "title": "Locating the roots of a quadratic equation in one variable through a  Line-Circumference (LC) geometric construction in the plane of complex  numbers",
    "abstract": " Comments: 7 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2402.04385",
    "authors": [
      "Daniel Alba-Cuellar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Complex Variables (math.CV)"
    ]
  },
  {
    "id": "arXiv:2402.11677",
    "title": "MultiCorrupt: A Multi-Modal Robustness Dataset and Benchmark of  LiDAR-Camera Fusion for 3D Object Detection",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2402.11677",
    "authors": [
      "Till Beemelmanns",
      "Quan Zhang",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.12168",
    "title": "Defending Against Weight-Poisoning Backdoor Attacks for  Parameter-Efficient Fine-Tuning",
    "abstract": " Comments: NAACL Findings 2024 ",
    "url": "https://arxiv.org/abs/2402.12168",
    "authors": [
      "Shuai Zhao",
      "Leilei Gan",
      "Luu Anh Tuan",
      "Jie Fu",
      "Lingjuan Lyu",
      "Meihuizi Jia",
      "Jinming Wen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13729",
    "title": "Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet  Representation",
    "abstract": " Comments: 17 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2402.13729",
    "authors": [
      "Kihong Kim",
      "Haneol Lee",
      "Jihye Park",
      "Seyeon Kim",
      "Kwanghee Lee",
      "Seungryong Kim",
      "Jaejun Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.18825",
    "title": "Utilizing Local Hierarchy with Adversarial Training for Hierarchical  Text Classification",
    "abstract": " Comments: Accepted by LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2402.18825",
    "authors": [
      "Zihan Wang",
      "Peiyi Wang",
      "Houfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.18918",
    "title": "SNE-RoadSegV2: Advancing Heterogeneous Feature Fusion and Fallibility  Awareness for Freespace Detection",
    "abstract": " Title: SNE-RoadSegV2: Advancing Heterogeneous Feature Fusion and Fallibility  Awareness for Freespace Detection ",
    "url": "https://arxiv.org/abs/2402.18918",
    "authors": [
      "Yi Feng",
      "Yu Ma",
      "Qijun Chen",
      "Ioannis Pitas",
      "Rui Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.00579",
    "title": "NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing",
    "abstract": " Comments: 16 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2403.00579",
    "authors": [
      "Guseul Heo",
      "Sangyeop Lee",
      "Jaehong Cho",
      "Hyunmin Choi",
      "Sanghyeon Lee",
      "Hyungkyu Ham",
      "Gwangsun Kim",
      "Divya Mahajan",
      "Jongse Park"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2403.01261",
    "title": "GSL-LPA: Fast Label Propagation Algorithm (LPA) for Community Detection  with no Internally-Disconnected Communities",
    "abstract": " Comments: 12 pages, 7 figures, 1 table. arXiv admin note: text overlap with arXiv:2402.11454, arXiv:2312.08140 ",
    "url": "https://arxiv.org/abs/2403.01261",
    "authors": [
      "Subhajit Sahu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.05704",
    "title": "Non-robustness of diffusion estimates on networks with measurement error",
    "abstract": " Title: Non-robustness of diffusion estimates on networks with measurement error ",
    "url": "https://arxiv.org/abs/2403.05704",
    "authors": [
      "Arun G. Chandrasekhar",
      "Paul Goldsmith-Pinkham",
      "Tyler H. McCormick",
      "Samuel Thau",
      "Jerry Wei"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.10897",
    "title": "Rethinking Multi-view Representation Learning via Distilled  Disentangling",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.10897",
    "authors": [
      "Guanzhou Ke",
      "Bo Wang",
      "Xiaoli Wang",
      "Shengfeng He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.11624",
    "title": "Dual-Channel Multiplex Graph Neural Networks for Recommendation",
    "abstract": " Title: Dual-Channel Multiplex Graph Neural Networks for Recommendation ",
    "url": "https://arxiv.org/abs/2403.11624",
    "authors": [
      "Xiang Li",
      "Chaofan Fu",
      "Zhongying Zhao",
      "Guanjie Zheng",
      "Chao Huang",
      "Junyu Dong",
      "Yanwei Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.13199",
    "title": "DecentNeRFs: Decentralized Neural Radiance Fields from Crowdsourced  Images",
    "abstract": " Title: DecentNeRFs: Decentralized Neural Radiance Fields from Crowdsourced  Images ",
    "url": "https://arxiv.org/abs/2403.13199",
    "authors": [
      "Zaid Tasneem",
      "Akshat Dave",
      "Abhishek Singh",
      "Kushagra Tiwary",
      "Praneeth Vepakomma",
      "Ashok Veeraraghavan",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.15082",
    "title": "Cell Variational Information Bottleneck Network",
    "abstract": " Comments: Found errors in the article, therefore postponing publication for now ",
    "url": "https://arxiv.org/abs/2403.15082",
    "authors": [
      "Zhonghua Zhai",
      "Chen Ju",
      "Jinsong Lan",
      "Shuai Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15454",
    "title": "Emotion Detection with Transformers: A Comparative Study",
    "abstract": " Title: Emotion Detection with Transformers: A Comparative Study ",
    "url": "https://arxiv.org/abs/2403.15454",
    "authors": [
      "Mahdi Rezapour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2403.16460",
    "title": "FedAC: An Adaptive Clustered Federated Learning Framework for  Heterogeneous Data",
    "abstract": " Comments: 14 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2403.16460",
    "authors": [
      "Yuxin Zhang",
      "Haoyu Chen",
      "Zheng Lin",
      "Zhe Chen",
      "Jin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.16970",
    "title": "Joint chest X-ray diagnosis and clinical visual attention prediction  with multi-stage cooperative learning: enhancing interpretability",
    "abstract": " Title: Joint chest X-ray diagnosis and clinical visual attention prediction  with multi-stage cooperative learning: enhancing interpretability ",
    "url": "https://arxiv.org/abs/2403.16970",
    "authors": [
      "Zirui Qiu",
      "Hassan Rivaz",
      "Yiming Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.17165",
    "title": "Building an Open-Source Community to Enhance Autonomic Nervous System  Signal Analysis: DBDP-Autonomic",
    "abstract": " Title: Building an Open-Source Community to Enhance Autonomic Nervous System  Signal Analysis: DBDP-Autonomic ",
    "url": "https://arxiv.org/abs/2403.17165",
    "authors": [
      "Jessilyn Dunn",
      "Varun Mishra",
      "Md Mobashir Hasan Shandhi",
      "Hayoung Jeong",
      "Natasha Yamane",
      "Yuna Watanabe",
      "Bill Chen",
      "Matthew S. Goodwin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.17410",
    "title": "On permutation-invariant neural networks",
    "abstract": " Title: On permutation-invariant neural networks ",
    "url": "https://arxiv.org/abs/2403.17410",
    "authors": [
      "Masanari Kimura",
      "Ryotaro Shimizu",
      "Yuki Hirakawa",
      "Ryosuke Goto",
      "Yuki Saito"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.18869",
    "title": "Efficient Unsupervised Community Search with Pre-trained Graph  Transformer",
    "abstract": " Title: Efficient Unsupervised Community Search with Pre-trained Graph  Transformer ",
    "url": "https://arxiv.org/abs/2403.18869",
    "authors": [
      "Jianwei Wang",
      "Kai Wang",
      "Xuemin Lin",
      "Wenjie Zhang",
      "Ying Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.19080",
    "title": "MMCert: Provable Defense against Adversarial Attacks to Multi-modal  Models",
    "abstract": " Comments: To appear in CVPR'24 ",
    "url": "https://arxiv.org/abs/2403.19080",
    "authors": [
      "Yanting Wang",
      "Hongye Fu",
      "Wei Zou",
      "Jinyuan Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.19180",
    "title": "A Multi-hop Secure UWOC assisted Local Area Network for UIoT and  Underwater Monitoring",
    "abstract": " Comments: Conflict of interest with co-authors ",
    "url": "https://arxiv.org/abs/2403.19180",
    "authors": [
      "Maaz Salman",
      "Javad Bolboli",
      "Wan-Young Chung"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2403.19432",
    "title": "Uncovering Misattributed Suicide Causes through Annotation Inconsistency  Detection in Death Investigation Notes",
    "abstract": " Comments: 19 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2403.19432",
    "authors": [
      "Song Wang",
      "Yiliang Zhou",
      "Ziqiang Han",
      "Cui Tao",
      "Yunyu Xiao",
      "Ying Ding",
      "Joydeep Ghosh",
      "Yifan Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]