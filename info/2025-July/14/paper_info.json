[
  {
    "id": "arXiv:2507.08020",
    "title": "Circumventing Safety Alignment in Large Language Models Through Embedding Space Toxicity Attenuation",
    "abstract": "           Large Language Models (LLMs) have achieved remarkable success across domains such as healthcare, education, and cybersecurity. However, this openness also introduces significant security risks, particularly through embedding space poisoning, which is a subtle attack vector where adversaries manipulate the internal semantic representations of input data to bypass safety alignment mechanisms. While previous research has investigated universal perturbation methods, the dynamics of LLM safety alignment at the embedding level remain insufficiently understood. Consequently, more targeted and accurate adversarial perturbation techniques, which pose significant threats, have not been adequately studied. In this work, we propose ETTA (Embedding Transformation Toxicity Attenuation), a novel framework that identifies and attenuates toxicity-sensitive dimensions in embedding space via linear transformations. ETTA bypasses model refusal behaviors while preserving linguistic coherence, without requiring model fine-tuning or access to training data. Evaluated on five representative open-source LLMs using the AdvBench benchmark, ETTA achieves a high average attack success rate of 88.61%, outperforming the best baseline by 11.34%, and generalizes to safety-enhanced models (e.g., 77.39% ASR on instruction-tuned defenses). These results highlight a critical vulnerability in current alignment strategies and underscore the need for embedding-aware defenses.         ",
    "url": "https://arxiv.org/abs/2507.08020",
    "authors": [
      "Zhibo Zhang",
      "Yuxi Li",
      "Kailong Wang",
      "Shuai Yuan",
      "Ling Shi",
      "Haoyu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08037",
    "title": "CRISP: Complex Reasoning with Interpretable Step-based Plans",
    "abstract": "           Recent advancements in large language models (LLMs) underscore the need for stronger reasoning capabilities to solve complex problems effectively. While Chain-of-Thought (CoT) reasoning has been a step forward, it remains insufficient for many domains. A promising alternative is explicit high-level plan generation, but existing approaches largely assume that LLMs can produce effective plans through few-shot prompting alone, without additional training. In this work, we challenge this assumption and introduce CRISP (Complex Reasoning with Interpretable Step-based Plans), a multi-domain dataset of high-level plans for mathematical reasoning and code generation. The plans in CRISP are automatically generated and rigorously validated--both intrinsically, using an LLM as a judge, and extrinsically, by evaluating their impact on downstream task performance. We demonstrate that fine-tuning a small model on CRISP enables it to generate higher-quality plans than much larger models using few-shot prompting, while significantly outperforming Chain-of-Thought reasoning. Furthermore, our out-of-domain evaluation reveals that fine-tuning on one domain improves plan generation in the other, highlighting the generalizability of learned planning capabilities.         ",
    "url": "https://arxiv.org/abs/2507.08037",
    "authors": [
      "Matan Vetzler",
      "Koren Lazar",
      "Guy Uziel",
      "Eran Hirsch",
      "Ateret Anaby-Tavor",
      "Leshem Choshen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08039",
    "title": "Towards Evaluating Robustness of Prompt Adherence in Text to Image Models",
    "abstract": "           The advancements in the domain of LLMs in recent years have surprised many, showcasing their remarkable capabilities and diverse applications. Their potential applications in various real-world scenarios have led to significant research on their reliability and effectiveness. On the other hand, multimodal LLMs and Text-to-Image models have only recently gained prominence, especially when compared to text-only LLMs. Their reliability remains constrained due to insufficient research on assessing their performance and robustness. This paper aims to establish a comprehensive evaluation framework for Text-to-Image models, concentrating particularly on their adherence to prompts. We created a novel dataset that aimed to assess the robustness of these models in generating images that conform to the specified factors of variation in the input text prompts. Our evaluation studies present findings on three variants of Stable Diffusion models: Stable Diffusion 3 Medium, Stable Diffusion 3.5 Large, and Stable Diffusion 3.5 Large Turbo, and two variants of Janus models: Janus Pro 1B and Janus Pro 7B. We introduce a pipeline that leverages text descriptions generated by the gpt-4o model for our ground-truth images, which are then used to generate artificial images by passing these descriptions to the Text-to-Image models. We then pass these generated images again through gpt-4o using the same system prompt and compare the variation between the two descriptions. Our results reveal that these models struggle to create simple binary images with only two factors of variation: a simple geometric shape and its location. We also show, using pre-trained VAEs on our dataset, that they fail to generate images that follow our input dataset distribution.         ",
    "url": "https://arxiv.org/abs/2507.08039",
    "authors": [
      "Sujith Vemishetty",
      "Advitiya Arora",
      "Anupama Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08107",
    "title": "GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs",
    "abstract": "           We propose a new approach for generating SPARQL queries on RDF knowledge graphs from natural language questions or keyword queries, using a large language model. Our approach does not require fine-tuning. Instead, it uses the language model to explore the knowledge graph by strategically executing SPARQL queries and searching for relevant IRIs and literals. We evaluate our approach on a variety of benchmarks (for knowledge graphs of different kinds and sizes) and language models (of different scales and types, commercial as well as open-source) and compare it with existing approaches. On Wikidata we reach state-of-the-art results on multiple benchmarks, despite the zero-shot setting. On Freebase we come close to the best few-shot methods. On other, less commonly evaluated knowledge graphs and benchmarks our approach also performs well overall. We conduct several additional studies, like comparing different ways of searching the graphs, incorporating a feedback mechanism, or making use of few-shot examples.         ",
    "url": "https://arxiv.org/abs/2507.08107",
    "authors": [
      "Sebastian Walter",
      "Hannah Bast"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2507.08118",
    "title": "PDE-aware Optimizer for Physics-informed Neural Networks",
    "abstract": "           Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical constraints into the loss function. However, standard optimizers such as Adam often struggle to balance competing loss terms, particularly in stiff or ill-conditioned systems. In this work, we propose a PDE-aware optimizer that adapts parameter updates based on the variance of per-sample PDE residual gradients. This method addresses gradient misalignment without incurring the heavy computational costs of second-order optimizers such as SOAP. We benchmark the PDE-aware optimizer against Adam and SOAP on 1D Burgers', Allen-Cahn and Korteweg-de Vries(KdV) equations. Across both PDEs, the PDE-aware optimizer achieves smoother convergence and lower absolute errors, particularly in regions with sharp gradients. Our results demonstrate the effectiveness of PDE residual-aware adaptivity in enhancing stability in PINNs training. While promising, further scaling on larger architectures and hardware accelerators remains an important direction for future research.         ",
    "url": "https://arxiv.org/abs/2507.08118",
    "authors": [
      "Hardik Shukla",
      "Manurag Khullar",
      "Vismay Churiwala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08121",
    "title": "Quasi-Random Physics-informed Neural Networks",
    "abstract": "           Physics-informed neural networks have shown promise in solving partial differential equations (PDEs) by integrating physical constraints into neural network training, but their performance is sensitive to the sampling of points. Based on the impressive performance of quasi Monte-Carlo methods in high dimensional problems, this paper proposes Quasi-Random Physics-Informed Neural Networks (QRPINNs), which use low-discrepancy sequences for sampling instead of random points directly from the domain. Theoretically, QRPINNs have been proven to have a better convergence rate than PINNs. Empirically, experiments demonstrate that QRPINNs significantly outperform PINNs and some representative adaptive sampling methods, especially in high-dimensional PDEs. Furthermore, combining QRPINNs with adaptive sampling can further improve the performance.         ",
    "url": "https://arxiv.org/abs/2507.08121",
    "authors": [
      "Tianchi Yu",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2507.08124",
    "title": "Physics-Informed Neural Networks with Hard Nonlinear Equality and Inequality Constraints",
    "abstract": "           Traditional physics-informed neural networks (PINNs) do not guarantee strict constraint satisfaction. This is problematic in engineering systems where minor violations of governing laws can significantly degrade the reliability and consistency of model predictions. In this work, we develop KKT-Hardnet, a PINN architecture that enforces both linear and nonlinear equality and inequality constraints up to machine precision. It leverages a projection onto the feasible region through solving Karush-Kuhn-Tucker (KKT) conditions of a distance minimization problem. Furthermore, we reformulate the nonlinear KKT conditions using log-exponential transformation to construct a general sparse system with only linear and exponential terms, thereby making the projection differentiable. We apply KKT-Hardnet on both test problems and a real-world chemical process simulation. Compared to multilayer perceptrons and PINNs, KKT-Hardnet achieves higher accuracy and strict constraint satisfaction. This approach allows the integration of domain knowledge into machine learning towards reliable hybrid modeling of complex systems.         ",
    "url": "https://arxiv.org/abs/2507.08124",
    "authors": [
      "Ashfaq Iftakher",
      "Rahul Golder",
      "M. M. Faruque Hasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08149",
    "title": "Code with Me or for Me? How Increasing AI Automation Transforms Developer Workflows",
    "abstract": "           Developers now have access to a growing array of increasingly autonomous AI tools to support software development. While numerous studies have examined developer use of copilots, which can provide chat assistance or code completions, evaluations of coding agents, which can automatically write files and run code, still largely rely on static benchmarks without humans-in-the-loop. In this work, we conduct the first academic study to explore developer interactions with coding agents and characterize how more autonomous AI tools affect user productivity and experience, compared to existing copilots. We evaluate two leading copilot and agentic coding assistants, GitHub Copilot and OpenHands, recruiting participants who regularly use the former. Our results show agents have the potential to assist developers in ways that surpass copilots (e.g., completing tasks that humans might not have accomplished before) and reduce the user effort required to complete tasks. However, there are challenges involved in enabling their broader adoption, including how to ensure users have an adequate understanding of agent behaviors. Our results not only provide insights into how developer workflows change as a result of coding agents but also highlight how user interactions with agents differ from those with existing copilots, motivating a set of recommendations for researchers building new agents. Given the broad set of developers who still largely rely on copilot-like systems, our work highlights key challenges of adopting more agentic systems into developer workflows.         ",
    "url": "https://arxiv.org/abs/2507.08149",
    "authors": [
      "Valerie Chen",
      "Ameet Talwalkar",
      "Robert Brennan",
      "Graham Neubig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2507.08153",
    "title": "ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction",
    "abstract": "           Traffic accidents are rare, yet high-impact events that require long-context multimodal reasoning for accurate risk forecasting. In this paper, we introduce ALCo-FM, a unified adaptive long-context foundation model that computes a volatility pre-score to dynamically select context windows for input data and encodes and fuses these multimodal data via shallow cross attention. Following a local GAT layer and a BigBird-style sparse global transformer over H3 hexagonal grids, coupled with Monte Carlo dropout for confidence, the model yields superior, well-calibrated predictions. Trained on data from 15 US cities with a class-weighted loss to counter label imbalance, and fine-tuned with minimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and an ECE of 0.04, outperforming more than 20 state-of-the-art baselines in large-scale urban risk prediction. Code and dataset are available at: this https URL ",
    "url": "https://arxiv.org/abs/2507.08153",
    "authors": [
      "Pinaki Prasad Guha Neogi",
      "Ahmad Mohammadshirazi",
      "Rajiv Ramnath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08158",
    "title": "Beyond the Worst Case: Extending Differential Privacy Guarantees to Realistic Adversaries",
    "abstract": "           Differential Privacy (DP) is a family of definitions that bound the worst-case privacy leakage of a mechanism. One important feature of the worst-case DP guarantee is it naturally implies protections against adversaries with less prior information, more sophisticated attack goals, and complex measures of a successful attack. However, the analytical tradeoffs between the adversarial model and the privacy protections conferred by DP are not well understood thus far. To that end, this work sheds light on what the worst-case guarantee of DP implies about the success of attackers that are more representative of real-world privacy risks. In this paper, we present a single flexible framework that generalizes and extends the patchwork of bounds on DP mechanisms found in prior work. Our framework allows us to compute high-probability guarantees for DP mechanisms on a large family of natural attack settings that previous bounds do not capture. One class of such settings is the approximate reconstruction of multiple individuals' data, such as inferring nearly entire columns of a tabular data set from noisy marginals and extracting sensitive information from DP-trained language models. We conduct two empirical case studies to illustrate the versatility of our bounds and compare them to the success of state-of-the-art attacks. Specifically, we study attacks that extract non-uniform PII from a DP-trained language model, as well as multi-column reconstruction attacks where the adversary has access to some columns in the clear and attempts to reconstruct the remaining columns for each person's record. We find that the absolute privacy risk of attacking non-uniform data is highly dependent on the adversary's prior probability of success. Our high probability bounds give us a nuanced understanding of the privacy leakage of DP mechanisms in a variety of previously understudied attack settings.         ",
    "url": "https://arxiv.org/abs/2507.08158",
    "authors": [
      "Marika Swanberg",
      "Meenatchi Sundaram Muthu Selva Annamalai",
      "Jamie Hayes",
      "Borja Balle",
      "Adam Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2507.08160",
    "title": "The Impact of Generative AI on Code Expertise Models: An Exploratory Study",
    "abstract": "           Generative Artificial Intelligence (GenAI) tools for source code generation have significantly boosted productivity in software development. However, they also raise concerns, particularly the risk that developers may rely heavily on these tools, reducing their understanding of the generated code. We hypothesize that this loss of understanding may be reflected in source code knowledge models, which are used to identify developer expertise. In this work, we present an exploratory analysis of how a knowledge model and a Truck Factor algorithm built upon it can be affected by GenAI usage. To investigate this, we collected statistical data on the integration of ChatGPT-generated code into GitHub projects and simulated various scenarios by adjusting the degree of GenAI contribution. Our findings reveal that most scenarios led to measurable impacts, indicating the sensitivity of current expertise metrics. This suggests that as GenAI becomes more integrated into development workflows, the reliability of such metrics may decrease.         ",
    "url": "https://arxiv.org/abs/2507.08160",
    "authors": [
      "Ot\u00e1vio Cury",
      "Guilherme Avelino"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2507.08163",
    "title": "Adaptive Diffusion Denoised Smoothing : Certified Robustness via Randomized Smoothing with Differentially Private Guided Denoising Diffusion",
    "abstract": "           We propose Adaptive Diffusion Denoised Smoothing, a method for certifying the predictions of a vision model against adversarial examples, while adapting to the input. Our key insight is to reinterpret a guided denoising diffusion model as a long sequence of adaptive Gaussian Differentially Private (GDP) mechanisms refining a pure noise sample into an image. We show that these adaptive mechanisms can be composed through a GDP privacy filter to analyze the end-to-end robustness of the guided denoising process, yielding a provable certification that extends the adaptive randomized smoothing analysis. We demonstrate that our design, under a specific guiding strategy, can improve both certified accuracy and standard accuracy on ImageNet for an $\\ell_2$ threat model.         ",
    "url": "https://arxiv.org/abs/2507.08163",
    "authors": [
      "Frederick Shpilevskiy",
      "Saiyue Lyu",
      "Krishnamurthy Dj Dvijotham",
      "Mathias L\u00e9cuyer",
      "Pierre-Andr\u00e9 No\u00ebl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08164",
    "title": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence",
    "abstract": "           The emergence of large language models (LLMs) and agentic systems is enabling autonomous 6G networks with advanced intelligence, including self-configuration, self-optimization, and self-healing. However, the current implementation of individual intelligence tasks necessitates isolated knowledge retrieval pipelines, resulting in redundant data flows and inconsistent interpretations. Inspired by the service model unification effort in Open-RAN (to support interoperability and vendor diversity), we propose KP-A: a unified Network Knowledge Plane specifically designed for Agentic network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, KP-A streamlines development and reduces maintenance complexity for intelligence engineers. By offering an intuitive and consistent knowledge interface, KP-A also enhances interoperability for the network intelligence agents. We demonstrate KP-A in two representative intelligence tasks: live network knowledge Q&A and edge AI service orchestration. All implementation artifacts have been open-sourced to support reproducibility and future standardization efforts.         ",
    "url": "https://arxiv.org/abs/2507.08164",
    "authors": [
      "Yun Tang",
      "Mengbang Zou",
      "Zeinab Nezami",
      "Syed Ali Raza Zaidi",
      "Weisi Guo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2507.08166",
    "title": "GPUHammer: Rowhammer Attacks on GPU Memories are Practical",
    "abstract": "           Rowhammer is a read disturbance vulnerability in modern DRAM that causes bit-flips, compromising security and reliability. While extensively studied on Intel and AMD CPUs with DDR and LPDDR memories, its impact on GPUs using GDDR memories, critical for emerging machine learning applications, remains unexplored. Rowhammer attacks on GPUs face unique challenges: (1) proprietary mapping of physical memory to GDDR banks and rows, (2) high memory latency and faster refresh rates that hinder effective hammering, and (3) proprietary mitigations in GDDR memories, difficult to reverse-engineer without FPGA-based test platforms. We introduce GPUHammer, the first Rowhammer attack on NVIDIA GPUs with GDDR6 DRAM. GPUHammer proposes novel techniques to reverse-engineer GDDR DRAM row mappings, and employs GPU-specific memory access optimizations to amplify hammering intensity and bypass mitigations. Thus, we demonstrate the first successful Rowhammer attack on a discrete GPU, injecting up to 8 bit-flips across 4 DRAM banks on an NVIDIA A6000 with GDDR6 memory. We also show how an attacker can use these to tamper with ML models, causing significant accuracy drops (up to 80%).         ",
    "url": "https://arxiv.org/abs/2507.08166",
    "authors": [
      "Chris S. Lin",
      "Joyce Qu",
      "Gururaj Saileshwar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2507.08167",
    "title": "Emotion Detection in Older Adults Using Physiological Signals from Wearable Sensors",
    "abstract": "           Emotion detection in older adults is crucial for understanding their cognitive and emotional well-being, especially in hospital and assisted living environments. In this work, we investigate an edge-based, non-obtrusive approach to emotion identification that uses only physiological signals obtained via wearable sensors. Our dataset includes data from 40 older individuals. Emotional states were obtained using physiological signals from the Empatica E4 and Shimmer3 GSR+ wristband and facial expressions were recorded using camera-based emotion recognition with the iMotion's Facial Expression Analysis (FEA) module. The dataset also contains twelve emotion categories in terms of relative intensities. We aim to study how well emotion recognition can be accomplished using simply physiological sensor data, without the requirement for cameras or intrusive facial analysis. By leveraging classical machine learning models, we predict the intensity of emotional responses based on physiological signals. We achieved the highest 0.782 r2 score with the lowest 0.0006 MSE on the regression task. This method has significant implications for individuals with Alzheimer's Disease and Related Dementia (ADRD), as well as veterans coping with Post-Traumatic Stress Disorder (PTSD) or other cognitive impairments. Our results across multiple classical regression models validate the feasibility of this method, paving the way for privacy-preserving and efficient emotion recognition systems in real-world settings.         ",
    "url": "https://arxiv.org/abs/2507.08167",
    "authors": [
      "Md. Saif Hassan Onim",
      "Andrew M. Kiselica",
      "Himanshu Thapliyal"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08184",
    "title": "EP-GAT: Energy-based Parallel Graph Attention Neural Network for Stock Trend Classification",
    "abstract": "           Graph neural networks have shown remarkable performance in forecasting stock movements, which arises from learning complex inter-dependencies between stocks and intra-dynamics of stocks. Existing approaches based on graph neural networks typically rely on static or manually defined factors to model changing inter-dependencies between stocks. Furthermore, these works often struggle to preserve hierarchical features within stocks. To bridge these gaps, this work presents the Energy-based Parallel Graph Attention Neural Network, a novel approach for predicting future movements for multiple stocks. First, it generates a dynamic stock graph with the energy difference between stocks and Boltzmann distribution, capturing evolving inter-dependencies between stocks. Then, a parallel graph attention mechanism is proposed to preserve the hierarchical intra-stock dynamics. Extensive experiments on five real-world datasets are conducted to validate the proposed approach, spanning from the US stock markets (NASDAQ, NYSE, SP) and UK stock markets (FTSE, LSE). The experimental results demonstrate that EP-GAT consistently outperforms competitive five baselines on test periods across various metrics. The ablation studies and hyperparameter sensitivity analysis further validate the effectiveness of each module in the proposed method.         ",
    "url": "https://arxiv.org/abs/2507.08184",
    "authors": [
      "Zhuodong Jiang",
      "Pengju Zhang",
      "Peter Martin"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08205",
    "title": "HNOSeg-XS: Extremely Small Hartley Neural Operator for Efficient and Resolution-Robust 3D Image Segmentation",
    "abstract": "           In medical image segmentation, convolutional neural networks (CNNs) and transformers are dominant. For CNNs, given the local receptive fields of convolutional layers, long-range spatial correlations are captured through consecutive convolutions and pooling. However, as the computational cost and memory footprint can be prohibitively large, 3D models can only afford fewer layers than 2D models with reduced receptive fields and abstract levels. For transformers, although long-range correlations can be captured by multi-head attention, its quadratic complexity with respect to input size is computationally demanding. Therefore, either model may require input size reduction to allow more filters and layers for better segmentation. Nevertheless, given their discrete nature, models trained with patch-wise training or image downsampling may produce suboptimal results when applied on higher resolutions. To address this issue, here we propose the resolution-robust HNOSeg-XS architecture. We model image segmentation by learnable partial differential equations through the Fourier neural operator which has the zero-shot super-resolution property. By replacing the Fourier transform by the Hartley transform and reformulating the problem in the frequency domain, we created the HNOSeg-XS model, which is resolution robust, fast, memory efficient, and extremely parameter efficient. When tested on the BraTS'23, KiTS'23, and MVSeg'23 datasets with a Tesla V100 GPU, HNOSeg-XS showed its superior resolution robustness with fewer than 34.7k model parameters. It also achieved the overall best inference time (< 0.24 s) and memory efficiency (< 1.8 GiB) compared to the tested CNN and transformer models.         ",
    "url": "https://arxiv.org/abs/2507.08205",
    "authors": [
      "Ken C. L. Wong",
      "Hongzhi Wang",
      "Tanveer Syeda-Mahmood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08207",
    "title": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking",
    "abstract": "           As large language models (LLMs) are increasingly deployed in critical applications, the challenge of jailbreaking, where adversaries manipulate the models to bypass safety mechanisms, has become a significant concern. This paper presents a dynamic Stackelberg game framework to model the interactions between attackers and defenders in the context of LLM jailbreaking. The framework treats the prompt-response dynamics as a sequential extensive-form game, where the defender, as the leader, commits to a strategy while anticipating the attacker's optimal responses. We propose a novel agentic AI solution, the \"Purple Agent,\" which integrates adversarial exploration and defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple Agent actively simulates potential attack trajectories and intervenes proactively to prevent harmful outputs. This approach offers a principled method for analyzing adversarial dynamics and provides a foundation for mitigating the risk of jailbreaking.         ",
    "url": "https://arxiv.org/abs/2507.08207",
    "authors": [
      "Zhengye Han",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08212",
    "title": "EvA: Evolutionary Attacks on Graphs",
    "abstract": "           Even a slight perturbation in the graph structure can cause a significant drop in the accuracy of graph neural networks (GNNs). Most existing attacks leverage gradient information to perturb edges. This relaxes the attack's optimization problem from a discrete to a continuous space, resulting in solutions far from optimal. It also restricts the adaptability of the attack to non-differentiable objectives. Instead, we introduce a few simple yet effective enhancements of an evolutionary-based algorithm to solve the discrete optimization problem directly. Our Evolutionary Attack (EvA) works with any black-box model and objective, eliminating the need for a differentiable proxy loss. This allows us to design two novel attacks that reduce the effectiveness of robustness certificates and break conformal sets. The memory complexity of our attack is linear in the attack budget. Among our experiments, EvA shows $\\sim$11\\% additional drop in accuracy on average compared to the best previous attack, revealing significant untapped potential in designing attacks.         ",
    "url": "https://arxiv.org/abs/2507.08212",
    "authors": [
      "Mohammad Sadegh Akhondzadeh",
      "Soroush H. Zargarbashi",
      "Jimin Cao",
      "Aleksandar Bojchevski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08234",
    "title": "Maneuver Detection via a Confidence Dominance Maneuver Indicator",
    "abstract": "           Accurate and efficient maneuver detection is critical for ensuring the safety and predictability of spacecraft trajectories. This paper presents a novel maneuver detection approach based on comparing the confidence levels associated with the orbital state estimation and the observation likelihood. First, a confidence-dominance maneuver indicator (CDMI) is proposed by setting a confidence level for the state estimation and computing the maximum likelihood of the observation and its confidence level. The CDMI then flag a maneuver when the observation's confidence level exceeds that of the state estimation, indicating that the observation is unlikely under the no-maneuver hypothesis while maintaining consistency with the prior state estimation confidence. To efficiently compute the maximum likelihood of the observation and obtain the CDMI, a recursive polynomial optimization method is developed, taking advantage of convex optimization and polynomial approximation. In addition, an integrated CDMI approach is developed to eliminate the need to manually select the state confidence level. The integrated CDMI approach maintains high detection accuracy while simultaneously providing an indication of maneuver likelihood, thereby enhancing robustness and practical applicability. The performance of the proposed CDMI-based maneuver detection approaches is evaluated against an optimal control distance metric and two mixture-based approaches. The simulation results demonstrate that the proposed integrated CDMI approach can achieve up to 99.33\\% detection accuracy, at least 10% higher than the competing methods, while substantially reducing computational costs.         ",
    "url": "https://arxiv.org/abs/2507.08234",
    "authors": [
      "Xingyu Zhou",
      "Roberto Armellin",
      "Laura Pirovano",
      "Dong Qiao",
      "Xiangyu Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ]
  },
  {
    "id": "arXiv:2507.08235",
    "title": "InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems",
    "abstract": "           Smart buildings generate vast streams of sensor and control data, but facility managers often lack clear explanations for anomalous energy usage. We propose InsightBuild, a two-stage framework that integrates causality analysis with a fine-tuned large language model (LLM) to provide human-readable, causal explanations of energy consumption patterns. First, a lightweight causal inference module applies Granger causality tests and structural causal discovery on building telemetry (e.g., temperature, HVAC settings, occupancy) drawn from Google Smart Buildings and Berkeley Office datasets. Next, an LLM, fine-tuned on aligned pairs of sensor-level causes and textual explanations, receives as input the detected causal relations and generates concise, actionable explanations. We evaluate InsightBuild on two real-world datasets (Google: 2017-2022; Berkeley: 2018-2020), using expert-annotated ground-truth causes for a held-out set of anomalies. Our results demonstrate that combining explicit causal discovery with LLM-based natural language generation yields clear, precise explanations that assist facility managers in diagnosing and mitigating energy inefficiencies.         ",
    "url": "https://arxiv.org/abs/2507.08235",
    "authors": [
      "Pinaki Prasad Guha Neogi",
      "Ahmad Mohammadshirazi",
      "Rajiv Ramnath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08238",
    "title": "Self-Supervised Learning-Based Multimodal Prediction on Prosocial Behavior Intentions",
    "abstract": "           Human state detection and behavior prediction have seen significant advancements with the rise of machine learning and multimodal sensing technologies. However, predicting prosocial behavior intentions in mobility scenarios, such as helping others on the road, is an underexplored area. Current research faces a major limitation. There are no large, labeled datasets available for prosocial behavior, and small-scale datasets make it difficult to train deep-learning models effectively. To overcome this, we propose a self-supervised learning approach that harnesses multi-modal data from existing physiological and behavioral datasets. By pre-training our model on diverse tasks and fine-tuning it with a smaller, manually labeled prosocial behavior dataset, we significantly enhance its performance. This method addresses the data scarcity issue, providing a more effective benchmark for prosocial behavior prediction, and offering valuable insights for improving intelligent vehicle systems and human-machine interaction.         ",
    "url": "https://arxiv.org/abs/2507.08238",
    "authors": [
      "Abinay Reddy Naini",
      "Zhaobo K. Zheng",
      "Teruhisa Misu",
      "Kumar Akash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08255",
    "title": "Quantum-Accelerated Neural Imputation with Large Language Models (LLMs)",
    "abstract": "           Missing data presents a critical challenge in real-world datasets, significantly degrading the performance of machine learning models. While Large Language Models (LLMs) have recently demonstrated remarkable capabilities in tabular data imputation, exemplified by frameworks like UnIMP, their reliance on classical embedding methods often limits their ability to capture complex, non-linear correlations, particularly in mixed-type data scenarios encompassing numerical, categorical, and textual features. This paper introduces Quantum-UnIMP, a novel framework that integrates shallow quantum circuits into an LLM-based imputation architecture. Our core innovation lies in replacing conventional classical input embeddings with quantum feature maps generated by an Instantaneous Quantum Polynomial (IQP) circuit. This approach enables the model to leverage quantum phenomena such as superposition and entanglement, thereby learning richer, more expressive representations of data and enhancing the recovery of intricate missingness patterns. Our experiments on benchmark mixed-type datasets demonstrate that Quantum-UnIMP reduces imputation error by up to 15.2% for numerical features (RMSE) and improves classification accuracy by 8.7% for categorical features (F1-Score) compared to state-of-the-art classical and LLM-based methods. These compelling results underscore the profound potential of quantum-enhanced representations for complex data imputation tasks, even with near-term quantum hardware.         ",
    "url": "https://arxiv.org/abs/2507.08255",
    "authors": [
      "Hossein Jamali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08259",
    "title": "Neural Parameter-varying Data-enabled Predictive Control of Cold Atmospheric Pressure Plasma Jets",
    "abstract": "           Cold Atmospheric Pressure Plasma Jets (APPJs) show significant potential for biomedical applications, but their inherent complexity, characterized by nonlinear dynamics and strong sensitivity to operating conditions like tip-to-surface distance, presents considerable challenges for achieving robust and reliable real-time control. To address these issues, this paper presents the Neural Parameter-Varying Data-enabled Predictive Control (NPV-DeePC) framework. By integrating hyper neural networks (hypernets) into the neural Data-enabled Predictive Control (DeePC) paradigm, the proposed method adaptively captures system nonlinearities and parameter variations, updates the neural feature space accordingly, and enables efficient and accurate trajectory prediction and control. The NPV-DeePC framework is validated through extensive simulations involving surface temperature tracking and thermal dose delivery. The results highlight its ability to outperform existing controllers in terms of accuracy and adaptability. The computational efficiency of the NPV-DeePC approach makes it a viable candidate for real-time applications. These findings underscore its potential to advance the safe and precise control of APPJs and provide a scalable solution for other parameter-varying nonlinear systems.         ",
    "url": "https://arxiv.org/abs/2507.08259",
    "authors": [
      "Pegah GhafGhanbari",
      "Mircea Lazar",
      "Javad Mohammadpour Velni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2507.08260",
    "title": "Do Conversational Interfaces Limit Creativity? Exploring Visual Graph Systems for Creative Writing",
    "abstract": "           We present a graphical, node-based system through which users can visually chain generative AI models for creative tasks. Research in the area of chaining LLMs has found that while chaining provides transparency, controllability and guardrails to approach certain tasks, chaining with pre-defined LLM steps prevents free exploration. Using cognitive processes from creativity research as a basis, we create a system that addresses the inherent constraints of chat-based AI interactions. Specifically, our system aims to overcome the limiting linear structure that inhibits creative exploration and ideation. Further, our node-based approach enables the creation of reusable, shareable templates that can address different creative tasks. In a small-scale user study, we find that our graph-based system supports ideation and allows some users to better visualise and think through their writing process when compared to a similar conversational interface. We further discuss the weaknesses and limitations of our system, noting the benefits to creativity that user interfaces with higher complexity can provide for users who can effectively use them.         ",
    "url": "https://arxiv.org/abs/2507.08260",
    "authors": [
      "Abhinav Sood",
      "Maria Teresa Llano",
      "Jon McCormack"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2507.08265",
    "title": "Addressing overlapping communities in multiple-source detection: An edge clustering approach for complex networks",
    "abstract": "           The source detection problem in network analysis involves identifying the origins of diffusion processes, such as disease outbreaks or misinformation propagation. Traditional methods often focus on single sources, whereas real-world scenarios frequently involve multiple sources, complicating detection efforts. This study addresses the multiple-source detection (MSD) problem by integrating edge clustering algorithms into the community-based label propagation framework, effectively handling mixed-membership issues where nodes belong to multiple communities. The proposed approach applies the automated latent space edge clustering model to a network, partitioning infected networks into edge-based clusters to identify multiple sources. Simulation studies on ADD HEALTH social network datasets demonstrate that this method achieves superior accuracy, as measured by the F1-Measure, compared to state-of-the-art clustering algorithms. The results highlight the robustness of edge clustering in accurately detecting sources, particularly in networks with complex and overlapping source regions. This work advances the applicability of clustering-based methods to MSD problems, offering improved accuracy and adaptability for real-world network analyses.         ",
    "url": "https://arxiv.org/abs/2507.08265",
    "authors": [
      "Haomin Li",
      "Daniel K. Sewell"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2507.08284",
    "title": "Lightweight Safety Guardrails via Synthetic Data and RL-guided Adversarial Training",
    "abstract": "           We introduce a lightweight yet highly effective safety guardrail framework for language models, demonstrating that small-scale language models can achieve, and even surpass, the performance of larger counterparts in content moderation tasks. This is accomplished through high-fidelity synthetic data generation and adversarial training. The synthetic data generation process begins with human-curated seed data, which undergoes query augmentation and paraphrasing to create diverse and contextually rich examples. This augmented data is then subjected to multiple rounds of curation, ensuring high fidelity and relevance. Inspired by recent advances in the Generative Adversarial Network (GAN) architecture, our adversarial training employs reinforcement learning to guide a generator that produces challenging synthetic examples. These examples are used to fine-tune the safety classifier, enhancing its ability to detect and mitigate harmful content. Additionally, we incorporate strategies from recent research on efficient LLM training, leveraging the capabilities of smaller models to improve the performance of larger generative models. With iterative adversarial training and the generation of diverse, high-quality synthetic data, our framework enables small language models (SLMs) to serve as robust safety guardrails. This approach not only reduces computational overhead but also enhances resilience against adversarial attacks, offering a scalable and efficient solution for content moderation in AI systems.         ",
    "url": "https://arxiv.org/abs/2507.08284",
    "authors": [
      "Aleksei Ilin",
      "Gor Matevosyan",
      "Xueying Ma",
      "Vladimir Eremin",
      "Suhaa Dada",
      "Muqun Li",
      "Riyaaz Shaik",
      "Haluk Noyan Tokgozoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2507.08288",
    "title": "Invariant-based Robust Weights Watermark for Large Language Models",
    "abstract": "           Watermarking technology has gained significant attention due to the increasing importance of intellectual property (IP) rights, particularly with the growing deployment of large language models (LLMs) on billions resource-constrained edge devices. To counter the potential threats of IP theft by malicious users, this paper introduces a robust watermarking scheme without retraining or fine-tuning for transformer models. The scheme generates a unique key for each user and derives a stable watermark value by solving linear constraints constructed from model invariants. Moreover, this technology utilizes noise mechanism to hide watermark locations in multi-user scenarios against collusion attack. This paper evaluates the approach on three popular models (Llama3, Phi3, Gemma), and the experimental results confirm the strong robustness across a range of attack methods (fine-tuning, pruning, quantization, permutation, scaling, reversible matrix and collusion attacks).         ",
    "url": "https://arxiv.org/abs/2507.08288",
    "authors": [
      "Qingxiao Guo",
      "Xinjie Zhu",
      "Yilong Ma",
      "Hui Jin",
      "Yunhao Wang",
      "Weifeng Zhang",
      "Xiaobing Guo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08290",
    "title": "Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment",
    "abstract": "           In recent years, continuous improvements in SAR resolution have significantly benefited applications such as urban monitoring and target detection. However, the improvement in resolution leads to increased discrepancies in scattering characteristics, posing challenges to the generalization ability of target detection models. While domain adaptation technology is a potential solution, the inevitable discrepancies caused by resolution differences often lead to blind feature adaptation and unreliable semantic propagation, ultimately degrading the domain adaptation performance. To address these challenges, this paper proposes a novel SAR target detection method (termed CR-Net), that incorporates structure priors and evidential learning theory into the detection model, enabling reliable domain adaptation for cross-resolution detection. To be specific, CR-Net integrates Structure-induced Hierarchical Feature Adaptation (SHFA) and Reliable Structural Adjacency Alignment (RSAA). SHFA module is introduced to establish structural correlations between targets and achieve structure-aware feature adaptation, thereby enhancing the interpretability of the feature adaptation process. Afterwards, the RSAA module is proposed to enhance reliable semantic alignment, by leveraging the secure adjacency set to transfer valuable discriminative knowledge from the source domain to the target domain. This further improves the discriminability of the detection model in the target domain. Based on experimental results from different-resolution datasets,the proposed CR-Net significantly enhances cross-resolution adaptation by preserving intra-domain structures and improving discriminability. It achieves state-of-the-art (SOTA) performance in cross-resolution SAR target detection.         ",
    "url": "https://arxiv.org/abs/2507.08290",
    "authors": [
      "Jiang Qin",
      "Bin Zou",
      "Haolin Li",
      "Lamei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08303",
    "title": "Learning Robust Motion Skills via Critical Adversarial Attacks for Humanoid Robots",
    "abstract": "           Humanoid robots show significant potential in daily tasks. However, reinforcement learning-based motion policies often suffer from robustness degradation due to the sim-to-real dynamics gap, thereby affecting the agility of real robots. In this work, we propose a novel robust adversarial training paradigm designed to enhance the robustness of humanoid motion policies in real worlds. The paradigm introduces a learnable adversarial attack network that precisely identifies vulnerabilities in motion policies and applies targeted perturbations, forcing the motion policy to enhance its robustness against perturbations through dynamic adversarial training. We conduct experiments on the Unitree G1 humanoid robot for both perceptive locomotion and whole-body control tasks. The results demonstrate that our proposed method significantly enhances the robot's motion robustness in real world environments, enabling successful traversal of challenging terrains and highly agile whole-body trajectory tracking.         ",
    "url": "https://arxiv.org/abs/2507.08303",
    "authors": [
      "Yang Zhang",
      "Zhanxiang Cao",
      "Buqing Nie",
      "Haoyang Li",
      "Yue Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2507.08317",
    "title": "A Comprehensively Adaptive Architectural Optimization-Ingrained Quantum Neural Network Model for Cloud Workloads Prediction",
    "abstract": "           Accurate workload prediction and advanced resource reservation are indispensably crucial for managing dynamic cloud services. Traditional neural networks and deep learning models frequently encounter challenges with diverse, high-dimensional workloads, especially during sudden resource demand changes, leading to inefficiencies. This issue arises from their limited optimization during training, relying only on parametric (inter-connection weights) adjustments using conventional algorithms. To address this issue, this work proposes a novel Comprehensively Adaptive Architectural Optimization-based Variable Quantum Neural Network (CA-QNN), which combines the efficiency of quantum computing with complete structural and qubit vector parametric learning. The model converts workload data into qubits, processed through qubit neurons with Controlled NOT-gated activation functions for intuitive pattern recognition. In addition, a comprehensive architecture optimization algorithm for networks is introduced to facilitate the learning and propagation of the structure and parametric values in variable-sized QNNs. This algorithm incorporates quantum adaptive modulation and size-adaptive recombination during training process. The performance of CA-QNN model is thoroughly investigated against seven state-of-the-art methods across four benchmark datasets of heterogeneous cloud workloads. The proposed model demonstrates superior prediction accuracy, reducing prediction errors by up to 93.40% and 91.27% compared to existing deep learning and QNN-based approaches.         ",
    "url": "https://arxiv.org/abs/2507.08317",
    "authors": [
      "Jitendra Kumar",
      "Deepika Saxena",
      "Kishu Gupta",
      "Satyam Kumar",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08329",
    "title": "Cross-Domain Identity Representation for Skull to Face Matching with Benchmark DataSet",
    "abstract": "           Craniofacial reconstruction in forensic science is crucial for the identification of the victims of crimes and disasters. The objective is to map a given skull to its corresponding face in a corpus of faces with known identities using recent advancements in computer vision, such as deep learning. In this paper, we presented a framework for the identification of a person given the X-ray image of a skull using convolutional Siamese networks for cross-domain identity representation. Siamese networks are twin networks that share the same architecture and can be trained to discover a feature space where nearby observations that are similar are grouped and dissimilar observations are moved apart. To do this, the network is exposed to two sets of comparable and different data. The Euclidean distance is then minimized between similar pairs and maximized between dissimilar ones. Since getting pairs of skull and face images are difficult, we prepared our own dataset of 40 volunteers whose front and side skull X-ray images and optical face images were collected. Experiments were conducted on the collected cross-domain dataset to train and validate the Siamese networks. The experimental results provide satisfactory results on the identification of a person from the given skull.         ",
    "url": "https://arxiv.org/abs/2507.08329",
    "authors": [
      "Ravi Shankar Prasad",
      "Dinesh Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08343",
    "title": "Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation",
    "abstract": "           Deep hiding has been exploring the hiding capability of deep learning-based models, aiming to conceal image-level messages into cover images and reveal them from generated stego images. Existing schemes are easily detected by steganalyzers due to their large payloads and their limitation to feature extraction based solely on either pure convolution or pure transformer operators within a single range, as well as pixel-level loss constraints. To address the issue, in this paper, we introduce generation-based adversarial attacks into color JPEG image deep hiding and propose a multi-range representations-driven adversarial stego generation framework called MRAG from a steganalysis perspective. Specifically, we integrate the local-range neighbor reception characteristic of the convolution and the global-range dependency modeling of the transformer to construct MRAG. Meanwhile, we use the transformed images obtained through coarse-grained and fine-grained frequency decomposition as inputs, introducing multi-grained information. Furthermore, a features angle-norm disentanglement loss is designed to constrain the generated stegos closer to covers in the angle and norm space of the steganalyzer's classified features. Consequently, small yet effective adversarial perturbations can be injected into the process of generating stegos, ensuring that stegos maintain favorable secret restorability and imperceptibility. Extensive experiments demonstrate that MRAG can achieve state-of-the-art performance.         ",
    "url": "https://arxiv.org/abs/2507.08343",
    "authors": [
      "Junxue Yang",
      "Xin Liao",
      "Weixuan Tang",
      "Jianhua Yang",
      "Zheng Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08348",
    "title": "Content-Oblivious Leader Election in 2-Edge-Connected Networks",
    "abstract": "           Censor-Hillel, Cohen, Gelles, and Sela (PODC 2022 \\& Distributed Computing 2023) studied fully-defective asynchronous networks, where communication channels may suffer an extreme form of alteration errors, rendering messages completely corrupted. The model is equivalent to content-oblivious computation, where nodes communicate solely via pulses. They showed that if the network is 2-edge-connected, then any algorithm for a noiseless setting can be simulated in the fully-defective setting; otherwise, no non-trivial computation is possible in the fully-defective setting. However, their simulation requires a predesignated leader, which they conjectured to be necessary for any non-trivial content-oblivious task. Recently, Frei, Gelles, Ghazy, and Nolin (DISC 2024) refuted this conjecture for the special case of oriented ring topology. They designed two asynchronous content-oblivious leader election algorithms with message complexity $O(n \\cdot \\mathsf{ID}_{\\max})$, where $n$ is the number of nodes and $\\mathsf{ID}_{\\max}$ is the maximum $\\mathsf{ID}$. The first algorithm stabilizes in unoriented rings without termination detection. The second algorithm quiescently terminates in oriented rings, thus enabling the execution of the simulation algorithm after leader election. In this work, we present an asynchronous content-oblivious leader election algorithm that quiescently terminates in any 2-edge connected network with message complexity $O(m \\cdot N \\cdot \\mathsf{ID}_{\\min})$, where $m$ is the number of edges, $N$ is a known upper bound on the number of nodes, and $\\mathsf{ID}_{\\min}$ is the smallest $\\mathsf{ID}$. Combined with the previous simulation result, our finding implies that any algorithm from the noiseless setting can be simulated in the fully-defective setting without assuming a preselected leader, entirely refuting the original conjecture.         ",
    "url": "https://arxiv.org/abs/2507.08348",
    "authors": [
      "Yi-Jun Chang",
      "Lyuting Chen",
      "Haoran Zhou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2507.08352",
    "title": "Secrecy Offloading Analysis of UAV-assisted NOMA-MEC Incorporating WPT in IoT Networks",
    "abstract": "           This article studies the efficiency of secrecy data offloading for an unmanned aerial vehicle (UAV)-assisted nonorthogonal multiple access (NOMA)-integrated mobile-edge computing (MEC) incorporating wireless power transfer (WPT) within an Internet of Things (IoT) network. Specifically, this study assumes an UAV to function in dual roles: as a mobile computation platform and as an aerial power-supply station, offering substantial advantages for resource-constrained edge devices (EDs) in mitigating interference from an passive eavesdropper. To assess the system's secrecy offloading efficacy, the secrecy successful computation probability (SSCP) closed-formed formulation under Nakagami-m fading channel is derived. The theoretical results are conducted with a variety of parameters, thereby validating the precision of our analysis.         ",
    "url": "https://arxiv.org/abs/2507.08352",
    "authors": [
      "Gia-Huy Nguyen",
      "Anh-Nhat Nguyen",
      "Minh-Sang Nguyen",
      "Khai Nguyen",
      "Tung-Son Ngo",
      "Ngoc-Anh Bui",
      "Phuong-Chi Le",
      "Manh-Duc Hoang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2507.08355",
    "title": "scE$^2$TM: Toward Interpretable Single-Cell Embedding via Topic Modeling",
    "abstract": "           Recent advances in sequencing technologies have enabled researchers to explore cellular heterogeneity at single-cell resolution. Meanwhile, interpretability has gained prominence parallel to the rapid increase in the complexity and performance of deep learning models. In recent years, topic models have been widely used for interpretable single-cell embedding learning and clustering analysis, which we refer to as single-cell embedded topic models. However, previous studies evaluated the interpretability of the models mainly through qualitative analysis, and these single-cell embedded topic models suffer from the potential problem of interpretation collapse. Furthermore, their neglect of external biological knowledge constrains analytical performance. Here, we present scE2TM, an external knowledge-guided single-cell embedded topic model that provides a high-quality cell embedding and strong interpretation, contributing to comprehensive scRNA-seq data analysis. Our comprehensive evaluation across 20 scRNA-seq datasets demonstrates that scE2TM achieves significant clustering performance gains compared to 7 state-of-the-art methods. In addition, we propose a new interpretability evaluation benchmark that introduces 10 metrics to quantitatively assess the interpretability of single-cell embedded topic models. The results show that the interpretation provided by scE2TM performs encouragingly in terms of diversity and consistency with the underlying biological signals, contributing to a better revealing of the underlying biological mechanisms.         ",
    "url": "https://arxiv.org/abs/2507.08355",
    "authors": [
      "Hegang Chen",
      "Yuyin Lu",
      "Zhiming Dai",
      "Fu Lee Wang",
      "Qing Li",
      "Yanghui Rao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08362",
    "title": "Leveraging Machine Learning and Enhanced Parallelism Detection for BPMN Model Generation from Text",
    "abstract": "           Efficient planning, resource management, and consistent operations often rely on converting textual process documents into formal Business Process Model and Notation (BPMN) models. However, this conversion process remains time-intensive and costly. Existing approaches, whether rule-based or machine-learning-based, still struggle with writing styles and often fail to identify parallel structures in process descriptions. This paper introduces an automated pipeline for extracting BPMN models from text, leveraging the use of machine learning and large language models. A key contribution of this work is the introduction of a newly annotated dataset, which significantly enhances the training process. Specifically, we augment the PET dataset with 15 newly annotated documents containing 32 parallel gateways for model training, a critical feature often overlooked in existing datasets. This addition enables models to better capture parallel structures, a common but complex aspect of process descriptions. The proposed approach demonstrates adequate performance in terms of reconstruction accuracy, offering a promising foundation for organizations to accelerate BPMN model creation.         ",
    "url": "https://arxiv.org/abs/2507.08362",
    "authors": [
      "Phuong Nam L\u00ea",
      "Charlotte Schneider-Depr\u00e9",
      "Alexandre Goossens",
      "Alexander Stevens",
      "Aur\u00e9lie Leribaux",
      "Johannes De Smedt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08363",
    "title": "Machine Learning for Evolutionary Graph Theory",
    "abstract": "           The stability of communities - whether biological, social, economic, technological or ecological depends on the balance between cooperation and cheating. While cooperation strengthens communities, selfish individuals, or \"cheaters,\" exploit collective benefits without contributing. If cheaters become too prevalent, they can trigger the collapse of cooperation and of the community, often in an abrupt manner. A key challenge is determining whether the risk of such a collapse can be detected in advance. To address this, we use a combination of evolutionary graph theory and machine learning to examine how one can predict the unravel of cooperation on complex networks. By introducing few cheaters into a structured population, we employ machine learning to detect and anticipate the spreading of cheaters and cooperation collapse. Using temporal and structural data, the presented results show that prediction accuracy improves with stronger selection strength and larger observation windows, with CNN-Seq-LSTM and Seq-LSTM best performing models. Moreover, the accuracy for the predictions depends crucially on the type of game played between cooperators and cheaters (i.e., accuracy improves when it is more advantageous to defect) and on the community structure. Overall, this work introduces a machine learning approach into detecting abrupt shifts in evolutionary graph theory and offer potential strategies for anticipating and preventing cooperation collapse in complex social networks.         ",
    "url": "https://arxiv.org/abs/2507.08363",
    "authors": [
      "Guoli Yang",
      "Matteo Cavaliere",
      "Mingtao Zhang",
      "Giovanni Masala",
      "Adam Miles",
      "Mengzhu Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2507.08364",
    "title": "Towards Robust Sensor-Fusion Ground SLAM: A Comprehensive Benchmark and A Resilient Framework",
    "abstract": "           Considerable advancements have been achieved in SLAM methods tailored for structured environments, yet their robustness under challenging corner cases remains a critical limitation. Although multi-sensor fusion approaches integrating diverse sensors have shown promising performance improvements, the research community faces two key barriers: On one hand, the lack of standardized and configurable benchmarks that systematically evaluate SLAM algorithms under diverse degradation scenarios hinders comprehensive performance assessment. While on the other hand, existing SLAM frameworks primarily focus on fusing a limited set of sensor types, without effectively addressing adaptive sensor selection strategies for varying environmental conditions. To bridge these gaps, we make three key contributions: First, we introduce M3DGR dataset: a sensor-rich benchmark with systematically induced degradation patterns including visual challenge, LiDAR degeneracy, wheel slippage and GNSS denial. Second, we conduct a comprehensive evaluation of forty SLAM systems on M3DGR, providing critical insights into their robustness and limitations under challenging real-world conditions. Third, we develop a resilient modular multi-sensor fusion framework named Ground-Fusion++, which demonstrates robust performance by coupling GNSS, RGB-D, LiDAR, IMU (Inertial Measurement Unit) and wheel odometry. Codes and datasets are publicly available.         ",
    "url": "https://arxiv.org/abs/2507.08364",
    "authors": [
      "Deteng Zhang",
      "Junjie Zhang",
      "Yan Sun",
      "Tao Li",
      "Hao Yin",
      "Hongzhao Xie",
      "Jie Yin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2507.08365",
    "title": "Prediction of Lane Change Intentions of Human Drivers using an LSTM, a CNN and a Transformer",
    "abstract": "           Lane changes of preceding vehicles have a great impact on the motion planning of automated vehicles especially in complex traffic situations. Predicting them would benefit the public in terms of safety and efficiency. While many research efforts have been made in this direction, few concentrated on predicting maneuvers within a set time interval compared to predicting at a set prediction time. In addition, there exist a lack of comparisons between different architectures to try to determine the best performing one and to assess how to correctly choose the input for such models. In this paper the structure of an LSTM, a CNN and a Transformer network are described and implemented to predict the intention of human drivers to perform a lane change. We show how the data was prepared starting from a publicly available dataset (highD), which features were used, how the networks were designed and finally we compare the results of the three networks with different configurations of input data. We found that transformer networks performed better than the other networks and was less affected by overfitting. The accuracy of the method spanned from $82.79\\%$ to $96.73\\%$ for different input configurations and showed overall good performances considering also precision and recall.         ",
    "url": "https://arxiv.org/abs/2507.08365",
    "authors": [
      "Francesco De Cristofaro",
      "Felix Hofbaur",
      "Aixi Yang",
      "Arno Eichberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08384",
    "title": "Smelly, dense, and spreaded: The Object Detection for Olfactory References (ODOR) dataset",
    "abstract": "           Real-world applications of computer vision in the humanities require algorithms to be robust against artistic abstraction, peripheral objects, and subtle differences between fine-grained target classes. Existing datasets provide instance-level annotations on artworks but are generally biased towards the image centre and limited with regard to detailed object classes. The proposed ODOR dataset fills this gap, offering 38,116 object-level annotations across 4712 images, spanning an extensive set of 139 fine-grained categories. Conducting a statistical analysis, we showcase challenging dataset properties, such as a detailed set of categories, dense and overlapping objects, and spatial distribution over the whole image canvas. Furthermore, we provide an extensive baseline analysis for object detection models and highlight the challenging properties of the dataset through a set of secondary studies. Inspiring further research on artwork object detection and broader visual cultural heritage studies, the dataset challenges researchers to explore the intersection of object recognition and smell perception.         ",
    "url": "https://arxiv.org/abs/2507.08384",
    "authors": [
      "Mathias Zinnen",
      "Prathmesh Madhu",
      "Inger Leemans",
      "Peter Bell",
      "Azhar Hussian",
      "Hang Tran",
      "Ali H\u00fcrriyeto\u011flu",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08412",
    "title": "Enforcing Speech Content Privacy in Environmental Sound Recordings using Segment-wise Waveform Reversal",
    "abstract": "           Environmental sound recordings often contain intelligible speech, raising privacy concerns that limit analysis, sharing and reuse of data. In this paper, we introduce a method that renders speech unintelligible while preserving both the integrity of the acoustic scene, and the overall audio quality. Our approach involves reversing waveform segments to distort speech content. This process is enhanced through a voice activity detection and speech separation pipeline, which allows for more precise targeting of speech. In order to demonstrate the effectivness of the proposed approach, we consider a three-part evaluation protocol that assesses: 1) speech intelligibility using Word Error Rate (WER), 2) sound sources detectability using Sound source Classification Accuracy-Drop (SCAD) from a widely used pre-trained model, and 3) audio quality using the Fr\u00e9chet Audio Distance (FAD), computed with our reference dataset that contains unaltered speech. Experiments on this simulated evaluation dataset, which consists of linear mixtures of speech and environmental sound scenes, show that our method achieves satisfactory speech intelligibility reduction (97.9% WER), minimal degradation of the sound sources detectability (2.7% SCAD), and high perceptual quality (FAD of 1.40). An ablation study further highlights the contribution of each component of the pipeline. We also show that incorporating random splicing to our speech content privacy enforcement method can enhance the algorithm's robustness to attempt to recover the clean speech, at a slight cost of audio quality.         ",
    "url": "https://arxiv.org/abs/2507.08412",
    "authors": [
      "Modan Tailleur",
      "Mathieu Lagrange",
      "Pierre Aumond",
      "Vincent Tourre"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2507.08445",
    "title": "CUE-RAG: Towards Accurate and Cost-Efficient Graph-Based RAG via Multi-Partite Graph and Query-Driven Iterative Retrieval",
    "abstract": "           Despite the remarkable progress of Large Language Models (LLMs), their performance in question answering (QA) remains limited by the lack of domain-specific and up-to-date knowledge. Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating external information, often from graph-structured data. However, existing graph-based RAG methods suffer from poor graph quality due to incomplete extraction and insufficient utilization of query information during retrieval. To overcome these limitations, we propose CUE-RAG, a novel approach that introduces (1) a multi-partite graph index incorporates text Chunks, knowledge Units, and Entities to capture semantic content at multiple levels of granularity, (2) a hybrid extraction strategy that reduces LLM token usage while still producing accurate and disambiguated knowledge units, and (3) Q-Iter, a query-driven iterative retrieval strategy that enhances relevance through semantic search and constrained graph traversal. Experiments on three QA benchmarks show that CUE-RAG significantly outperforms state-of-the-art baselines, achieving up to 99.33% higher Accuracy and 113.51% higher F1 score while reducing indexing costs by 72.58%. Remarkably, CUE-RAG matches or outperforms baselines even without using an LLM for indexing. These results demonstrate the effectiveness and cost-efficiency of CUE-RAG in advancing graph-based RAG systems.         ",
    "url": "https://arxiv.org/abs/2507.08445",
    "authors": [
      "Yaodong Su",
      "Yixiang Fang",
      "Yingli Zhou",
      "Quanqing Xu",
      "Chuanhui Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08475",
    "title": "SynBridge: Bridging Reaction States via Discrete Flow for Bidirectional Reaction Prediction",
    "abstract": "           The essence of a chemical reaction lies in the redistribution and reorganization of electrons, which is often manifested through electron transfer or the migration of electron pairs. These changes are inherently discrete and abrupt in the physical world, such as alterations in the charge states of atoms or the formation and breaking of chemical bonds. To model the transition of states, we propose SynBridge, a bidirectional flow-based generative model to achieve multi-task reaction prediction. By leveraging a graph-to-graph transformer network architecture and discrete flow bridges between any two discrete distributions, SynBridge captures bidirectional chemical transformations between graphs of reactants and products through the bonds' and atoms' discrete states. We further demonstrate the effectiveness of our method through extensive experiments on three benchmark datasets (USPTO-50K, USPTO-MIT, Pistachio), achieving state-of-the-art performance in both forward and retrosynthesis tasks. Our ablation studies and noise scheduling analysis reveal the benefits of structured diffusion over discrete spaces for reaction prediction.         ",
    "url": "https://arxiv.org/abs/2507.08475",
    "authors": [
      "Haitao Lin",
      "Junjie Wang",
      "Zhifeng Gao",
      "Xiaohong Ji",
      "Rong Zhu",
      "Linfeng Zhang",
      "Guolin Ke",
      "Weinan E"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08478",
    "title": "A Robust Approach to Detect Intersections between Triangles with Different Numerical Representations",
    "abstract": "           The detection and classification of intersections between triangles are crucial tasks in a wide range of applications within Computer Graphics and Geometry Processing, including mesh Arrangements, mesh Booleans, and generic mesh processing and fixing tasks. Existing methods are hard-coded and deeply integrated into specific algorithms, and significant efforts are usually required to integrate them into new pipelines or to extend them to different numerical representations. This paper presents a versatile and exhaustive algorithm to identify and classify intersections between triangles with either floating points, rational numbers, or implicit representations. The proposed tool is implemented as a C++ templated and header-only code that is generic and easy to integrate into further algorithms requiring the triangle-triangle intersection detection step. The developed tool has been tested and compared with a state-of-the-art approach, and it is shared with the Geometry Processing community with an Open Source license.         ",
    "url": "https://arxiv.org/abs/2507.08478",
    "authors": [
      "Luca Garau",
      "Gianmarco Cherchi"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2507.08492",
    "title": "Dual Dimensions Geometric Representation Learning Based Document Dewarping",
    "abstract": "           Document image dewarping remains a challenging task in the deep learning era. While existing methods have improved by leveraging text line awareness, they typically focus only on a single horizontal dimension. In this paper, we propose a fine-grained deformation perception model that focuses on Dual Dimensions of document horizontal-vertical-lines to improve document Dewarping called D2Dewarp. It can perceive distortion trends in different directions across document details. To combine the horizontal and vertical granularity features, an effective fusion module based on X and Y coordinate is designed to facilitate interaction and constraint between the two dimensions for feature complementarity. Due to the lack of annotated line features in current public dewarping datasets, we also propose an automatic fine-grained annotation method using public document texture images and an automatic rendering engine to build a new large-scale distortion training dataset. The code and dataset will be publicly released. On public Chinese and English benchmarks, both quantitative and qualitative results show that our method achieves better rectification results compared with the state-of-the-art methods. The dataset will be publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2507.08492",
    "authors": [
      "Heng Li",
      "Qingcai Chen",
      "Xiangping Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08494",
    "title": "Unified People Tracking with Graph Neural Networks",
    "abstract": "           This work presents a unified, fully differentiable model for multi-people tracking that learns to associate detections into trajectories without relying on pre-computed tracklets. The model builds a dynamic spatiotemporal graph that aggregates spatial, contextual, and temporal information, enabling seamless information propagation across entire sequences. To improve occlusion handling, the graph can also encode scene-specific information. We also introduce a new large-scale dataset with 25 partially overlapping views, detailed scene reconstructions, and extensive occlusions. Experiments show the model achieves state-of-the-art performance on public benchmarks and the new dataset, with flexibility across diverse conditions. Both the dataset and approach will be publicly released to advance research in multi-people tracking.         ",
    "url": "https://arxiv.org/abs/2507.08494",
    "authors": [
      "Martin Engilberge",
      "Ivan Vrkic",
      "Friedrich Wilke Grosche",
      "Julien Pilet",
      "Engin Turetken",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08499",
    "title": "PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts",
    "abstract": "           This paper presents our system for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection (Track A), which focuses on multi-label emotion detection in short texts. We propose a feature-centric framework that dynamically adapts document representations and learning algorithms to optimize language-specific performance. Our study evaluates three key components: document representation, dimensionality reduction, and model training in 28 languages, highlighting five for detailed analysis. The results show that TF-IDF remains highly effective for low-resource languages, while contextual embeddings like FastText and transformer-based document representations, such as those produced by Sentence-BERT, exhibit language-specific strengths. Principal Component Analysis (PCA) reduces training time without compromising performance, particularly benefiting FastText and neural models such as Multi-Layer Perceptrons (MLP). Computational efficiency analysis underscores the trade-off between model complexity and processing cost. Our framework provides a scalable solution for multilingual emotion detection, addressing the challenges of linguistic diversity and resource constraints.         ",
    "url": "https://arxiv.org/abs/2507.08499",
    "authors": [
      "Ziyi Huang",
      "Xia Cui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08507",
    "title": "Recovery of UAV Swarm-enabled Collaborative Beamforming in Low-altitude Wireless Networks under Wind Field Disturbances",
    "abstract": "           Unmanned aerial vehicle (UAV) swarms utilizing collaborative beamforming (CB) in low-altitude wireless networks (LAWN) demonstrate significant potential for enhanced communication range, energy efficiency, and signal directivity through the formation of virtual antenna arrays (VAA). However, environmental disturbances, particularly wind fields, significantly degrade CB performance by introducing positional errors that disrupt beam patterns, thereby compromising transmission reliability. This paper investigates the critical challenge of maintaining CB performance in UAV-based VAAs operating in LAWN under wind field disturbances. We propose a comprehensive framework that models the impact of three distinct wind conditions (constant, shear, and turbulent) on UAV array performance, and formulate a long-term real-time optimization problem to maximize directivity while minimizing maximum sidelobe levels through adaptive excitation current weight adjustments. To address the inherent complexity of this problem, we propose a novel proximal policy optimization algorithm with long short-term memory (LSTM) structure and adaptive learning rate (PPO-LA), which effectively captures temporal patterns in wind field disturbances and enables real-time adaptation without requiring extensive prior training for specific wind conditions. Our simulation results demonstrate that the proposed PPO-LA algorithm successfully recovers degraded CB performance across various wind scenarios, and thus significantly outperforming benchmark algorithms.         ",
    "url": "https://arxiv.org/abs/2507.08507",
    "authors": [
      "Geng Sun",
      "Chenbang Liu",
      "Jiahui Li",
      "Guannan Qu",
      "Shuang Liang",
      "Jiacheng Wang",
      "Changyuan Zhao",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2507.08529",
    "title": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis",
    "abstract": "           Despite advances from medical large language models in healthcare, rare-disease diagnosis remains hampered by insufficient knowledge-representation depth, limited concept understanding, and constrained clinical reasoning. We propose a framework that couples multi-granularity sparse activation of medical concepts with a hierarchical knowledge graph. Four complementary matching algorithms, diversity control, and a five-level fallback strategy enable precise concept activation, while a three-layer knowledge graph (taxonomy, clinical features, instances) provides structured, up-to-date context. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09, ROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89 approaching the 0.90 clinical threshold. Expert evaluation confirms improvements in information quality, reasoning, and professional expression, suggesting our approach shortens the \"diagnostic odyssey\" for rare-disease patients.         ",
    "url": "https://arxiv.org/abs/2507.08529",
    "authors": [
      "Mingda Zhang",
      "Na Zhao",
      "Jianglong Qin",
      "Guoyu Ye",
      "Ruixiang Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2507.08530",
    "title": "MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling",
    "abstract": "           Generating expressive audio performances from music scores requires models to capture both instrument acoustics and human interpretation. Traditional music performance synthesis pipelines follow a two-stage approach, first generating expressive performance MIDI from a score, then synthesising the MIDI into audio. However, the synthesis models often struggle to generalise across diverse MIDI sources, musical styles, and recording environments. To address these challenges, we propose MIDI-VALLE, a neural codec language model adapted from the VALLE framework, which was originally designed for zero-shot personalised text-to-speech (TTS) synthesis. For performance MIDI-to-audio synthesis, we improve the architecture to condition on a reference audio performance and its corresponding MIDI. Unlike previous TTS-based systems that rely on piano rolls, MIDI-VALLE encodes both MIDI and audio as discrete tokens, facilitating a more consistent and robust modelling of piano performances. Furthermore, the model's generalisation ability is enhanced by training on an extensive and diverse piano performance dataset. Evaluation results show that MIDI-VALLE significantly outperforms a state-of-the-art baseline, achieving over 75% lower Frechet Audio Distance on the ATEPP and Maestro datasets. In the listening test, MIDI-VALLE received 202 votes compared to 58 for the baseline, demonstrating improved synthesis quality and generalisation across diverse performance MIDI inputs.         ",
    "url": "https://arxiv.org/abs/2507.08530",
    "authors": [
      "Jingjing Tang",
      "Xin Wang",
      "Zhe Zhang",
      "Junichi Yamagishi",
      "Geraint Wiggins",
      "George Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2507.08540",
    "title": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection",
    "abstract": "           The proliferation of software vulnerabilities presents a significant challenge to cybersecurity, necessitating more effective detection methodologies. We introduce White-Basilisk, a novel approach to vulnerability detection that demonstrates superior performance while challenging prevailing assumptions in AI model scaling. Utilizing an innovative architecture that integrates Mamba layers, linear self-attention, and a Mixture of Experts framework, White-Basilisk achieves state-of-the-art results in vulnerability detection tasks with a parameter count of only 200M. The model's capacity to process sequences of unprecedented length enables comprehensive analysis of extensive codebases in a single pass, surpassing the context limitations of current Large Language Models (LLMs). White-Basilisk exhibits robust performance on imbalanced, real-world datasets, while maintaining computational efficiency that facilitates deployment across diverse organizational scales. This research not only establishes new benchmarks in code security but also provides empirical evidence that compact, efficiently designed models can outperform larger counterparts in specialized tasks, potentially redefining optimization strategies in AI development for domain-specific applications.         ",
    "url": "https://arxiv.org/abs/2507.08540",
    "authors": [
      "Ioannis Lamprou",
      "Alexander Shevtsov",
      "Ioannis Arapakis",
      "Sotiris Ioannidis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08542",
    "title": "CircFormerMoE: An End-to-End Deep Learning Framework for Circular RNA Splice Site Detection and Pairing in Plant Genomes",
    "abstract": "           Circular RNAs (circRNAs) are important components of the non-coding RNA regulatory network. Previous circRNA identification primarily relies on high-throughput RNA sequencing (RNA-seq) data combined with alignment-based algorithms that detect back-splicing signals. However, these methods face several limitations: they can't predict circRNAs directly from genomic DNA sequences and relies heavily on RNA experimental data; they involve high computational costs due to complex alignment and filtering steps; and they are inefficient for large-scale or genome-wide circRNA prediction. The challenge is even greater in plants, where plant circRNA splice sites often lack the canonical GT-AG motif seen in human mRNA splicing, and no efficient deep learning model with strong generalization capability currently exists. Furthermore, the number of currently identified plant circRNAs is likely far lower than their true abundance. In this paper, we propose a deep learning framework named CircFormerMoE based on transformers and mixture-of experts for predicting circRNAs directly from plant genomic DNA. Our framework consists of two subtasks known as splicing site detection (SSD) and splicing site pairing (SSP). The model's effectiveness has been validated on gene data of 10 plant species. Trained on known circRNA instances, it is also capable of discovering previously unannotated circRNAs. In addition, we performed interpretability analyses on the trained model to investigate the sequence patterns contributing to its predictions. Our framework provides a fast and accurate computational method and tool for large-scale circRNA discovery in plants, laying a foundation for future research in plant functional genomics and non-coding RNA annotation.         ",
    "url": "https://arxiv.org/abs/2507.08542",
    "authors": [
      "Tianyou Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08549",
    "title": "Stabilizing and Optimizing Inter-Shell Routing in LEO Networks with Integrated Routing Cost",
    "abstract": "           The low Earth orbit (LEO) mega-constellation network (LMCN), which uses thousands of satellites across multi-shell architectures to deliver different services, is facing challenges in inter-shell routing stability due to dynamic network topologies and frequent inter-satellite link (ISL) switching. Existing strategies, such as the Minimum Hop Path set, prioritize minimizing hop counts to reduce latency, but ignore ISL switching costs, which leads to high instability. To overcome this, the Adaptive Path Routing Scheme introduces path similarity thresholds to reduce the ISL switching frequency between shells. However, the greedy approach of Adaptive Path Routing Scheme is often trapped in local optima, sacrificing inter-shell path distance efficiency. To address these limitations, we propose the Dynamic Programming-based Integrated Routing Cost (DP-IRC) algorithm, which is designed explicitly for inter-shell routing optimization. By formulating multi-shell paths as a multistage decision problem, DP-IRC balances hop counts and ISL stability through an Integrated Routing Cost (IRC) metric, combining inter-/intra-shell hops and switching costs. Experiments over 60 time slots with real-world Starlink and OneWeb configurations show that DP-IRC reduces inter-shell ISL switching rates by 39.1% and 22.0% compared to the Minimum Hop Path set strategy and Adaptive Path Routing Scheme, respectively, while still maintaining near-optimal end-to-end distances.         ",
    "url": "https://arxiv.org/abs/2507.08549",
    "authors": [
      "Yaojia Wang",
      "Qi Zhang",
      "Kun Qiu",
      "Yue Gao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2507.08554",
    "title": "Image Translation with Kernel Prediction Networks for Semantic Segmentation",
    "abstract": "           Semantic segmentation relies on many dense pixel-wise annotations to achieve the best performance, but owing to the difficulty of obtaining accurate annotations for real world data, practitioners train on large-scale synthetic datasets. Unpaired image translation is one method used to address the ensuing domain gap by generating more realistic training data in low-data regimes. Current methods for unpaired image translation train generative adversarial networks (GANs) to perform the translation and enforce pixel-level semantic matching through cycle consistency. These methods do not guarantee that the semantic matching holds, posing a problem for semantic segmentation where performance is sensitive to noisy pixel labels. We propose a novel image translation method, Domain Adversarial Kernel Prediction Network (DA-KPN), that guarantees semantic matching between the synthetic label and translation. DA-KPN estimates pixel-wise input transformation parameters of a lightweight and simple translation function. To ensure the pixel-wise transformation is realistic, DA-KPN uses multi-scale discriminators to distinguish between translated and target samples. We show DA-KPN outperforms previous GAN-based methods on syn2real benchmarks for semantic segmentation with limited access to real image labels and achieves comparable performance on face parsing.         ",
    "url": "https://arxiv.org/abs/2507.08554",
    "authors": [
      "Cristina Mata",
      "Michael S. Ryoo",
      "Henrik Turbell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08563",
    "title": "STRAP: Spatial-Temporal Risk-Attentive Vehicle Trajectory Prediction for Autonomous Driving",
    "abstract": "           Accurate vehicle trajectory prediction is essential for ensuring safety and efficiency in fully autonomous driving systems. While existing methods primarily focus on modeling observed motion patterns and interactions with other vehicles, they often neglect the potential risks posed by the uncertain or aggressive behaviors of surrounding vehicles. In this paper, we propose a novel spatial-temporal risk-attentive trajectory prediction framework that incorporates a risk potential field to assess perceived risks arising from behaviors of nearby vehicles. The framework leverages a spatial-temporal encoder and a risk-attentive feature fusion decoder to embed the risk potential field into the extracted spatial-temporal feature representations for trajectory prediction. A risk-scaled loss function is further designed to improve the prediction accuracy of high-risk scenarios, such as short relative spacing. Experiments on the widely used NGSIM and HighD datasets demonstrate that our method reduces average prediction errors by 4.8% and 31.2% respectively compared to state-of-the-art approaches, especially in high-risk scenarios. The proposed framework provides interpretable, risk-aware predictions, contributing to more robust decision-making for autonomous driving systems.         ",
    "url": "https://arxiv.org/abs/2507.08563",
    "authors": [
      "Xinyi Ning",
      "Zilin Bian",
      "Kaan Ozbay",
      "Semiha Ergan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08581",
    "title": "Heterogeneous Dynamic Logic: Provability Modulo Program Theories",
    "abstract": "           Formally specifying, let alone verifying, properties of systems involving multiple programming languages is inherently challenging. We introduce Heterogeneous Dynamic Logic (HDL), a framework for combining reasoning principles from distinct (dynamic) program logics in a modular and compositional way. HDL mirrors the architecture of satisfiability modulo theories (SMT): Individual dynamic logics, along with their calculi, are treated as dynamic theories that can be flexibly combined to reason about heterogeneous systems whose components are verified using different program logics. HDL provides two key operations: Lifting extends an individual dynamic theory with new program constructs (e.g., the havoc operation or regular programs) and automatically augments its calculus with sound reasoning principles for the new constructs; and Combination enables cross-language reasoning in a single modality via Heterogeneous Dynamic Theories, facilitating the reuse of existing proof infrastructure. We formalize dynamic theories, their lifting and combination in Isabelle, and prove the soundness of all proof rules. We also prove relative completeness theorems for lifting and combination: Under common assumptions, reasoning about lifted or combined theories is no harder than reasoning about the constituent dynamic theories and their common first-order structure (i.e., the \"data theory\"). We demonstrate HDL's utility by verifying an automotive case study in which a Java controller (formalized in Java dynamic logic) steers a plant model (formalized in differential dynamic logic).         ",
    "url": "https://arxiv.org/abs/2507.08581",
    "authors": [
      "Samuel Teuber",
      "Mattias Ulbrich",
      "Andr\u00e9 Platzer",
      "Bernhard Beckert"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2507.08597",
    "title": "ADAPT: A Pseudo-labeling Approach to Combat Concept Drift in Malware Detection",
    "abstract": "           Machine learning models are commonly used for malware classification; however, they suffer from performance degradation over time due to concept drift. Adapting these models to changing data distributions requires frequent updates, which rely on costly ground truth annotations. While active learning can reduce the annotation burden, leveraging unlabeled data through semi-supervised learning remains a relatively underexplored approach in the context of malware detection. In this research, we introduce \\texttt{ADAPT}, a novel pseudo-labeling semi-supervised algorithm for addressing concept drift. Our model-agnostic method can be applied to various machine learning models, including neural networks and tree-based algorithms. We conduct extensive experiments on five diverse malware detection datasets spanning Android, Windows, and PDF domains. The results demonstrate that our method consistently outperforms baseline models and competitive benchmarks. This work paves the way for more effective adaptation of machine learning models to concept drift in malware detection.         ",
    "url": "https://arxiv.org/abs/2507.08597",
    "authors": [
      "Md Tanvirul Alam",
      "Aritran Piplai",
      "Nidhi Rastogi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2507.08626",
    "title": "Phoneme-Level Analysis for Person-of-Interest Speech Deepfake Detection",
    "abstract": "           Recent advances in generative AI have made the creation of speech deepfakes widely accessible, posing serious challenges to digital trust. To counter this, various speech deepfake detection strategies have been proposed, including Person-of-Interest (POI) approaches, which focus on identifying impersonations of specific individuals by modeling and analyzing their unique vocal traits. Despite their excellent performance, the existing methods offer limited granularity and lack interpretability. In this work, we propose a POI-based speech deepfake detection method that operates at the phoneme level. Our approach decomposes reference audio into phonemes to construct a detailed speaker profile. In inference, phonemes from a test sample are individually compared against this profile, enabling fine-grained detection of synthetic artifacts. The proposed method achieves comparable accuracy to traditional approaches while offering superior robustness and interpretability, key aspects in multimedia forensics. By focusing on phoneme analysis, this work explores a novel direction for explainable, speaker-centric deepfake detection.         ",
    "url": "https://arxiv.org/abs/2507.08626",
    "authors": [
      "Davide Salvi",
      "Viola Negroni",
      "Sara Mandelli",
      "Paolo Bestagini",
      "Stefano Tubaro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2507.08627",
    "title": "NL in the Middle: Code Translation with LLMs and Intermediate Representations",
    "abstract": "           Studies show that large language models (LLMs) produce buggy code translations. One avenue to improve translation accuracy is through intermediate representations, which could provide structured insights to guide the model's understanding. We explore whether code translation using LLMs can benefit from intermediate representations via natural language (NL) and abstract syntax trees (ASTs). Since prompt engineering greatly affects LLM performance, we consider several ways to integrate these representations, from one-shot to chain-of-thought (CoT) prompting. Using Open Gpt4 8X7B and specialized StarCoder and CodeGen models on popular code translation benchmarks (CodeNet and AVATAR), we find that CoT with an intermediate NL summary performs best, with an increase of 13.8% and 6.7%, respectively, in successful translations for the best-performing model (Open Gpt4 8X7B) compared to the zero-shot prompt.         ",
    "url": "https://arxiv.org/abs/2507.08627",
    "authors": [
      "Chi-en Amy Tai",
      "Pengyu Nie",
      "Lukasz Golab",
      "Alexander Wong"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2507.08677",
    "title": "Qualitative Assessment of Low Power Wide Area Network Protocols and their Security Aspect",
    "abstract": "           There are currently many communication options in the Internet of Things, even in particular areas such as constrained and battery-powered devices, such as Low Power Wide Area Networks. Understanding the differences and characteristics of each option is a challenge, even for professionals and researchers in the field. To meet this need, this work analyses the qualitative characteristics of Low Power Wide Area Network protocols and the challenges and opportunities of using constrained devices for sparse networks based on long-life batteries. For this study, a bibliographic survey of the literature was carried out as an analysis of three protocols (LoRaWAN, NB-IoT, and Sigfox), and a detailing of the first one. As a result, there is a discussion about the chosen network protocol and its use in IoT solutions with sparse sensors.         ",
    "url": "https://arxiv.org/abs/2507.08677",
    "authors": [
      "Wesley dos Reis Bezerra",
      "Lais Machado Bezerra",
      "Carlos Becker Westphal"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2507.08685",
    "title": "Beer Path Problems in Temporal Graphs",
    "abstract": "           Computing paths in graph structures is a fundamental operation in a wide range of applications, from transportation networks to data analysis. The beer path problem, which captures the option of visiting points of interest, such as gas stations or convenience stops, prior to reaching the final destination, has been recently introduced and extensively studied in static graphs. However, existing approaches do not account for temporal information, which is often crucial in real-world scenarios. For instance, transit services may follow fixed schedules, and shops may only be accessible during certain hours. In this work, we introduce the notion of beer paths in temporal graphs, where edges are time-dependent and certain vertices (beer vertices) are active only at specific time instances. We formally define the problems of computing earliest-arrival, latest-departure, fastest, and shortest temporal beer paths and propose efficient algorithms for these problems under both edge stream and adjacency list representations. The time complexity of each of our algorithms is aligned with that of corresponding temporal pathfinding algorithms, thus preserving efficiency. Additionally, we present preprocessing techniques that enable efficient query answering under dynamic conditions, for example new openings or closings of shops. We achieve this through appropriate precomputation of selected paths or by transforming a temporal graph into an equivalent static graph.         ",
    "url": "https://arxiv.org/abs/2507.08685",
    "authors": [
      "Andrea D'Ascenzo",
      "Giuseppe F. Italiano",
      "Sotiris Kanellopoulos",
      "Anna Mpanti",
      "Aris Pagourtzis",
      "Christos Pergaminelis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2507.08698",
    "title": "To buy or not to buy: deterministic rent-or-buy problems on node-weighted graphs",
    "abstract": "           We study the rent-or-buy variant of the online Steiner forest problem on node- and edge-weighted graphs. For $n$-node graphs with at most $\\bar{n}$ non-zero node-weights, and at most $\\tilde{k}$ different arriving terminal pairs, we obtain a deterministic, $O(\\log n \\log \\bar{n})$-competitive algorithm. This improves on the previous best, $O(\\log^4 n)$-competitive algorithm obtained by the black-box reduction from (Bartal et al. 2021) combined with the previously best deterministic algorithms for the simpler 'buy-only' setting. We also obtain a deterministic, $O(\\bar{n}\\log \\tilde{k})$-competitive algorithm. This generalizes the $O(\\log \\tilde{k})$-competitive algorithm for the purely edge-weighted setting from (Umboh 2015). We also obtain a randomized, $O(\\log \\tilde{k} \\log \\bar{n})$-competitive algorithm. All previous approaches were based on the randomized, black-box reduction from~\\cite{AwerbuchAzarBartal96} that achieves a $O(\\log \\tilde{k} \\log n)$-competitive ratio when combined with an algorithm for the 'buy-only' setting. Our key technical ingredient is a novel charging scheme to an instance of \\emph{online prize-collecting set cover}. This allows us to extend the witness-technique of (Umboh 2015) to the node-weighted setting and obtain refined guarantees with respect to $\\bar{n}$, already in the much simpler 'buy-only' setting.         ",
    "url": "https://arxiv.org/abs/2507.08698",
    "authors": [
      "Sander Borst",
      "Moritz Venzin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2507.08707",
    "title": "SPLASH! Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations",
    "abstract": "           Inverse Reinforcement Learning (IRL) presents a powerful paradigm for learning complex robotic tasks from human demonstrations. However, most approaches make the assumption that expert demonstrations are available, which is often not the case. Those that allow for suboptimality in the demonstrations are not designed for long-horizon goals or adversarial tasks. Many desirable robot capabilities fall into one or both of these categories, thus highlighting a critical shortcoming in the ability of IRL to produce field-ready robotic agents. We introduce Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations (SPLASH), which advances the state-of-the-art in learning from suboptimal demonstrations to long-horizon and adversarial settings. We empirically validate SPLASH on a maritime capture-the-flag task in simulation, and demonstrate real-world applicability with sim-to-real translation experiments on autonomous unmanned surface vehicles. We show that our proposed methods allow SPLASH to significantly outperform the state-of-the-art in reward learning from suboptimal demonstrations.         ",
    "url": "https://arxiv.org/abs/2507.08707",
    "authors": [
      "Peter Crowley",
      "Zachary Serlin",
      "Tyler Paine",
      "Makai Mann",
      "Michael Benjamin",
      "Calin Belta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2507.08719",
    "title": "Multilingual Multimodal Software Developer for Code Generation",
    "abstract": "           The rapid advancement of Large Language Models (LLMs) has significantly improved code generation, yet most models remain text-only, neglecting crucial visual aids like diagrams and flowcharts used in real-world software development. To bridge this gap, we introduce MM-Coder, a Multilingual Multimodal software developer. MM-Coder integrates visual design inputs-Unified Modeling Language (UML) diagrams and flowcharts (termed Visual Workflow)-with textual instructions to enhance code generation accuracy and architectural alignment. To enable this, we developed MMc-Instruct, a diverse multimodal instruction-tuning dataset including visual-workflow-based code generation, allowing MM-Coder to synthesize textual and graphical information like human developers, distinct from prior work on narrow tasks. Furthermore, we introduce MMEval, a new benchmark for evaluating multimodal code generation, addressing existing text-only limitations. Our evaluations using MMEval highlight significant remaining challenges for models in precise visual information capture, instruction following, and advanced programming knowledge. Our work aims to revolutionize industrial programming by enabling LLMs to interpret and implement complex specifications conveyed through both text and visual designs.         ",
    "url": "https://arxiv.org/abs/2507.08719",
    "authors": [
      "Linzheng Chai",
      "Jian Yang",
      "Shukai Liu",
      "Wei Zhang",
      "Liran Wang",
      "Ke Jin",
      "Tao Sun",
      "Congnan Liu",
      "Chenchen Zhang",
      "Hualei Zhu",
      "Jiaheng Liu",
      "Xianjie Wu",
      "Ge Zhang",
      "Tianyu Liu",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2507.08738",
    "title": "Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series",
    "abstract": "           Nonlinear vector autoregression (NVAR) and reservoir computing (RC) have shown promise in forecasting chaotic dynamical systems, such as the Lorenz-63 model and El Nino-Southern Oscillation. However, their reliance on fixed nonlinearities - polynomial expansions in NVAR or random feature maps in RC - limits their adaptability to high noise or real-world data. These methods also scale poorly in high-dimensional settings due to costly matrix inversion during readout computation. We propose an adaptive NVAR model that combines delay-embedded linear inputs with features generated by a shallow, learnable multi-layer perceptron (MLP). The MLP and linear readout are jointly trained using gradient-based optimization, enabling the model to learn data-driven nonlinearities while preserving a simple readout structure. Unlike standard NVAR, our approach avoids the need for an exhaustive and sensitive grid search over ridge and delay parameters. Instead, tuning is restricted to neural network hyperparameters, improving scalability. Initial experiments on chaotic systems tested under noise-free and synthetically noisy conditions showed that the adaptive model outperformed the standard NVAR in predictive accuracy and showed robust forecasting under noisy conditions with a lower observation frequency.         ",
    "url": "https://arxiv.org/abs/2507.08738",
    "authors": [
      "Azimov Sherkhon",
      "Susana Lopez-Moreno",
      "Eric Dolores-Cuenca",
      "Sieun Lee",
      "Sangil Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2507.08743",
    "title": "Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection",
    "abstract": "           Digital Twins (DT) have the potential to transform traffic management and operations by creating dynamic, virtual representations of transportation systems that sense conditions, analyze operations, and support decision-making. A key component for DT of the transportation system is dynamic roadway geometry sensing. However, existing approaches often rely on static maps or costly sensors, limiting scalability and adaptability. Additionally, large-scale DTs that collect and analyze data from multiple sources face challenges in privacy, communication, and computational efficiency. To address these challenges, we introduce Geo-ORBIT (Geometrical Operational Roadway Blueprint with Integrated Twin), a unified framework that combines real-time lane detection, DT synchronization, and federated meta-learning. At the core of Geo-ORBIT is GeoLane, a lightweight lane detection model that learns lane geometries from vehicle trajectory data using roadside cameras. We extend this model through Meta-GeoLane, which learns to personalize detection parameters for local entities, and FedMeta-GeoLane, a federated learning strategy that ensures scalable and privacy-preserving adaptation across roadside deployments. Our system is integrated with CARLA and SUMO to create a high-fidelity DT that renders highway scenarios and captures traffic flows in real-time. Extensive experiments across diverse urban scenes show that FedMeta-GeoLane consistently outperforms baseline and meta-learning approaches, achieving lower geometric error and stronger generalization to unseen locations while drastically reducing communication overhead. This work lays the foundation for flexible, context-aware infrastructure modeling in DTs. The framework is publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2507.08743",
    "authors": [
      "Rei Tamaru",
      "Pei Li",
      "Bin Ran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.08746",
    "title": "Partitioned Hybrid Quantum Fourier Neural Operators for Scientific Quantum Machine Learning",
    "abstract": "           We introduce the Partitioned Hybrid Quantum Fourier Neural Operator (PHQFNO), a generalization of the Quantum Fourier Neural Operator (QFNO) for scientific machine learning. PHQFNO partitions the Fourier operator computation across classical and quantum resources, enabling tunable quantum-classical hybridization and distributed execution across quantum and classical devices. The method extends QFNOs to higher dimensions and incorporates a message-passing framework to distribute data across different partitions. Input data are encoded into quantum states using unary encoding, and quantum circuit parameters are optimized using a variational scheme. We implement PHQFNO using PennyLane with PyTorch integration and evaluate it on Burgers' equation, incompressible and compressible Navier-Stokes equations. We show that PHQFNO recovers classical FNO accuracy. On incompressible Navier-Stokes, PHQFNO achieves higher accuracy than its classical counterparts. Finally, we perform a sensitivity analysis under input noise, confirming improved stability of PHQFNO over classical baselines.         ",
    "url": "https://arxiv.org/abs/2507.08746",
    "authors": [
      "Paolo Marcandelli",
      "Yuanchun He",
      "Stefano Mariani",
      "Martina Siena",
      "Stefano Markidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2507.08749",
    "title": "Modeling Partially Observed Nonlinear Dynamical Systems and Efficient Data Assimilation via Discrete-Time Conditional Gaussian Koopman Network",
    "abstract": "           A discrete-time conditional Gaussian Koopman network (CGKN) is developed in this work to learn surrogate models that can perform efficient state forecast and data assimilation (DA) for high-dimensional complex dynamical systems, e.g., systems governed by nonlinear partial differential equations (PDEs). Focusing on nonlinear partially observed systems that are common in many engineering and earth science applications, this work exploits Koopman embedding to discover a proper latent representation of the unobserved system states, such that the dynamics of the latent states are conditional linear, i.e., linear with the given observed system states. The modeled system of the observed and latent states then becomes a conditional Gaussian system, for which the posterior distribution of the latent states is Gaussian and can be efficiently evaluated via analytical formulae. The analytical formulae of DA facilitate the incorporation of DA performance into the learning process of the modeled system, which leads to a framework that unifies scientific machine learning (SciML) and data assimilation. The performance of discrete-time CGKN is demonstrated on several canonical problems governed by nonlinear PDEs with intermittency and turbulent features, including the viscous Burgers' equation, the Kuramoto-Sivashinsky equation, and the 2-D Navier-Stokes equations, with which we show that the discrete-time CGKN framework achieves comparable performance as the state-of-the-art SciML methods in state forecast and provides efficient and accurate DA results. The discrete-time CGKN framework also serves as an example to illustrate unifying the development of SciML models and their other outer-loop applications such as design optimization, inverse problems, and optimal control.         ",
    "url": "https://arxiv.org/abs/2507.08749",
    "authors": [
      "Chuanqi Chen",
      "Zhongrui Wang",
      "Nan Chen",
      "Jin-Long Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08776",
    "title": "CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering",
    "abstract": "           This paper proposes a neural rendering approach that represents a scene as \"compressed light-field tokens (CLiFTs)\", retaining rich appearance and geometric information of a scene. CLiFT enables compute-efficient rendering by compressed tokens, while being capable of changing the number of tokens to represent a scene or render a novel view with one trained network. Concretely, given a set of images, multi-view encoder tokenizes the images with the camera poses. Latent-space K-means selects a reduced set of rays as cluster centroids using the tokens. The multi-view ``condenser'' compresses the information of all the tokens into the centroid tokens to construct CLiFTs. At test time, given a target view and a compute budget (i.e., the number of CLiFTs), the system collects the specified number of nearby tokens and synthesizes a novel view using a compute-adaptive renderer. Extensive experiments on RealEstate10K and DL3DV datasets quantitatively and qualitatively validate our approach, achieving significant data reduction with comparable rendering quality and the highest overall rendering score, while providing trade-offs of data size, rendering quality, and rendering speed.         ",
    "url": "https://arxiv.org/abs/2507.08776",
    "authors": [
      "Zhengqing Wang",
      "Yuefan Wu",
      "Jiacheng Chen",
      "Fuyang Zhang",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.08800",
    "title": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models",
    "abstract": "           We introduce NeuralOS, a neural framework that simulates graphical user interfaces (GUIs) of operating systems by directly predicting screen frames in response to user inputs such as mouse movements, clicks, and keyboard events. NeuralOS combines a recurrent neural network (RNN), which tracks computer state, with a diffusion-based neural renderer that generates screen images. The model is trained on a large-scale dataset of Ubuntu XFCE recordings, which include both randomly generated interactions and realistic interactions produced by AI agents. Experiments show that NeuralOS successfully renders realistic GUI sequences, accurately captures mouse interactions, and reliably predicts state transitions like application launches. Although modeling fine-grained keyboard interactions precisely remains challenging, NeuralOS offers a step toward creating fully adaptive, generative neural interfaces for future human-computer interaction systems.         ",
    "url": "https://arxiv.org/abs/2507.08800",
    "authors": [
      "Luke Rivard",
      "Sun Sun",
      "Hongyu Guo",
      "Wenhu Chen",
      "Yuntian Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08802",
    "title": "The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for Mechanistic Interpretability?",
    "abstract": "           The concept of causal abstraction got recently popularised to demystify the opaque decision-making processes of machine learning models; in short, a neural network can be abstracted as a higher-level algorithm if there exists a function which allows us to map between them. Notably, most interpretability papers implement these maps as linear functions, motivated by the linear representation hypothesis: the idea that features are encoded linearly in a model's representations. However, this linearity constraint is not required by the definition of causal abstraction. In this work, we critically examine the concept of causal abstraction by considering arbitrarily powerful alignment maps. In particular, we prove that under reasonable assumptions, any neural network can be mapped to any algorithm, rendering this unrestricted notion of causal abstraction trivial and uninformative. We complement these theoretical findings with empirical evidence, demonstrating that it is possible to perfectly map models to algorithms even when these models are incapable of solving the actual task; e.g., on an experiment using randomly initialised language models, our alignment maps reach 100% interchange-intervention accuracy on the indirect object identification task. This raises the non-linear representation dilemma: if we lift the linearity constraint imposed to alignment maps in causal abstraction analyses, we are left with no principled way to balance the inherent trade-off between these maps' complexity and accuracy. Together, these results suggest an answer to our title's question: causal abstraction is not enough for mechanistic interpretability, as it becomes vacuous without assumptions about how models encode information. Studying the connection between this information-encoding assumption and causal abstraction should lead to exciting future work.         ",
    "url": "https://arxiv.org/abs/2507.08802",
    "authors": [
      "Denis Sutter",
      "Julian Minder",
      "Thomas Hofmann",
      "Tiago Pimentel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08114",
    "title": "Exact Biclique Partition number of Split Graphs",
    "abstract": "           The biclique partition number of a graph \\(G\\), denoted \\( \\operatorname{bp}(G)\\), is the minimum number of biclique subgraphs that partition the edge set of \\(G\\). The Graham-Pollak theorem states that the complete graph on \\( n \\) vertices cannot be partitioned into fewer than \\( n-1 \\) bicliques. In this note, we show that for any split graph \\( G \\), the biclique partition number satisfies \\( \\operatorname{bp}(G) = \\operatorname{mc}(G^c) - 1 \\), where \\( \\operatorname{mc}(G^c) \\) denotes the number of maximal cliques in the complement of \\( G \\). This extends the celebrated Graham-Pollak theorem to a broader class of graphs.         ",
    "url": "https://arxiv.org/abs/2507.08114",
    "authors": [
      "Anand Babu",
      "Ashwin Jacob"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2507.08189",
    "title": "Robust Semi-Supervised CT Radiomics for Lung Cancer Prognosis: Cost-Effective Learning with Limited Labels and SHAP Interpretation",
    "abstract": "           Background: CT imaging is vital for lung cancer management, offering detailed visualization for AI-based prognosis. However, supervised learning SL models require large labeled datasets, limiting their real-world application in settings with scarce annotations. Methods: We analyzed CT scans from 977 patients across 12 datasets extracting 1218 radiomics features using Laplacian of Gaussian and wavelet filters via PyRadiomics Dimensionality reduction was applied with 56 feature selection and extraction algorithms and 27 classifiers were benchmarked A semi supervised learning SSL framework with pseudo labeling utilized 478 unlabeled and 499 labeled cases Model sensitivity was tested in three scenarios varying labeled data in SL increasing unlabeled data in SSL and scaling both from 10 percent to 100 percent SHAP analysis was used to interpret predictions Cross validation and external testing in two cohorts were performed. Results: SSL outperformed SL, improving overall survival prediction by up to 17 percent. The top SSL model, Random Forest plus XGBoost classifier, achieved 0.90 accuracy in cross-validation and 0.88 externally. SHAP analysis revealed enhanced feature discriminability in both SSL and SL, especially for Class 1 survival greater than 4 years. SSL showed strong performance with only 10 percent labeled data, with more stable results compared to SL and lower variance across external testing, highlighting SSL's robustness and cost effectiveness. Conclusion: We introduced a cost-effective, stable, and interpretable SSL framework for CT-based survival prediction in lung cancer, improving performance, generalizability, and clinical readiness by integrating SHAP explainability and leveraging unlabeled data.         ",
    "url": "https://arxiv.org/abs/2507.08189",
    "authors": [
      "Mohammad R. Salmanpour",
      "Amir Hossein Pouria",
      "Sonia Falahati",
      "Shahram Taeb",
      "Somayeh Sadat Mehrnia",
      "Ali Fathi Jouzdani",
      "Mehrdad Oveisi",
      "Ilker Hacihaliloglu",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08202",
    "title": "Quantum Properties Trojans (QuPTs) for Attacking Quantum Neural Networks",
    "abstract": "           Quantum neural networks (QNN) hold immense potential for the future of quantum machine learning (QML). However, QNN security and robustness remain largely unexplored. In this work, we proposed novel Trojan attacks based on the quantum computing properties in a QNN-based binary classifier. Our proposed Quantum Properties Trojans (QuPTs) are based on the unitary property of quantum gates to insert noise and Hadamard gates to enable superposition to develop Trojans and attack QNNs. We showed that the proposed QuPTs are significantly stealthier and heavily impact the quantum circuits' performance, specifically QNNs. The most impactful QuPT caused a deterioration of 23% accuracy of the compromised QNN under the experimental setup. To the best of our knowledge, this is the first work on the Trojan attack on a fully quantum neural network independent of any hybrid classical-quantum architecture.         ",
    "url": "https://arxiv.org/abs/2507.08202",
    "authors": [
      "Sounak Bhowmik",
      "Travis S. Humble",
      "Himanshu Thapliyal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2507.08261",
    "title": "Admissibility of Stein Shrinkage for Batch Normalization in the Presence of Adversarial Attacks",
    "abstract": "           Batch normalization (BN) is a ubiquitous operation in deep neural networks used primarily to achieve stability and regularization during network training. BN involves feature map centering and scaling using sample means and variances, respectively. Since these statistics are being estimated across the feature maps within a batch, this problem is ideally suited for the application of Stein's shrinkage estimation, which leads to a better, in the mean-squared-error sense, estimate of the mean and variance of the batch. In this paper, we prove that the Stein shrinkage estimator for the mean and variance dominates over the sample mean and variance estimators in the presence of adversarial attacks when modeling these attacks using sub-Gaussian distributions. This facilitates and justifies the application of Stein shrinkage to estimate the mean and variance parameters in BN and use it in image classification (segmentation) tasks with and without adversarial attacks. We present SOTA performance results using this Stein corrected batch norm in a standard ResNet architecture applied to the task of image classification using CIFAR-10 data, 3D CNN on PPMI (neuroimaging) data and image segmentation using HRNet on Cityscape data with and without adversarial attacks.         ",
    "url": "https://arxiv.org/abs/2507.08261",
    "authors": [
      "Sofia Ivolgina",
      "P. Thomas Fletcher",
      "Baba C. Vemuri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08280",
    "title": "MIRRAMS: Towards Training Models Robust to Missingness Distribution Shifts",
    "abstract": "           In real-world data analysis, missingness distributional shifts between training and test input datasets frequently occur, posing a significant challenge to achieving robust prediction performance. In this study, we propose a novel deep learning framework designed to address such shifts in missingness distributions. We begin by introducing a set of mutual information-based conditions, called MI robustness conditions, which guide a prediction model to extract label-relevant information while remaining invariant to diverse missingness patterns, thereby enhancing robustness to unseen missingness scenarios at test-time. To make these conditions practical, we propose simple yet effective techniques to derive loss terms corresponding to each and formulate a final objective function, termed MIRRAMS(Mutual Information Regularization for Robustness Against Missingness Shifts). As a by-product, our analysis provides a theoretical interpretation of the principles underlying consistency regularization-based semi-supervised learning methods, such as FixMatch. Extensive experiments across various benchmark datasets show that MIRRAMS consistently outperforms existing baselines and maintains stable performance across diverse missingness scenarios. Moreover, our approach achieves state-of-the-art performance even without missing data and can be naturally extended to address semi-supervised learning tasks, highlighting MIRRAMS as a powerful, off-the-shelf framework for general-purpose learning.         ",
    "url": "https://arxiv.org/abs/2507.08280",
    "authors": [
      "Jihye Lee",
      "Minseo Kang",
      "Dongha Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08402",
    "title": "SPINT: Spatial Permutation-Invariant Neural Transformer for Consistent Intracortical Motor Decoding",
    "abstract": "           Intracortical Brain-Computer Interfaces (iBCI) aim to decode behavior from neural population activity, enabling individuals with motor impairments to regain motor functions and communication abilities. A key challenge in long-term iBCI is the nonstationarity of neural recordings, where the composition and tuning profiles of the recorded populations are unstable across recording sessions. Existing methods attempt to address this issue by explicit alignment techniques; however, they rely on fixed neural identities and require test-time labels or parameter updates, limiting their generalization across sessions and imposing additional computational burden during deployment. In this work, we introduce SPINT - a Spatial Permutation-Invariant Neural Transformer framework for behavioral decoding that operates directly on unordered sets of neural units. Central to our approach is a novel context-dependent positional embedding scheme that dynamically infers unit-specific identities, enabling flexible generalization across recording sessions. SPINT supports inference on variable-size populations and allows few-shot, gradient-free adaptation using a small amount of unlabeled data from the test session. To further promote model robustness to population variability, we introduce dynamic channel dropout, a regularization method for iBCI that simulates shifts in population composition during training. We evaluate SPINT on three multi-session datasets from the FALCON Benchmark, covering continuous motor decoding tasks in human and non-human primates. SPINT demonstrates robust cross-session generalization, outperforming existing zero-shot and few-shot unsupervised baselines while eliminating the need for test-time alignment and fine-tuning. Our work contributes an initial step toward a robust and scalable neural decoding framework for long-term iBCI applications.         ",
    "url": "https://arxiv.org/abs/2507.08402",
    "authors": [
      "Trung Le",
      "Hao Fang",
      "Jingyuan Li",
      "Tung Nguyen",
      "Lu Mi",
      "Amy Orsborn",
      "Uygar S\u00fcmb\u00fcl",
      "Eli Shlizerman"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.08411",
    "title": "A Dissipativity Framework for Constructing Scaled Graphs",
    "abstract": "           Scaled relative graphs have been originally introduced in the context of convex optimization and have recently gained attention in the control systems community for the graphical analysis of nonlinear systems. Of particular interest in stability analysis of feedback systems is the scaled graph, a special case of the scaled relative graph. In many ways, scaled graphs can be seen as a generalization of the classical Nyquist plot for linear time-invariant systems, and facilitate a powerful graphical tool for analyzing nonlinear feedback systems. In their current formulation, however, scaled graphs require characterizing the input-output behaviour of a system for an uncountable number of inputs. This poses a practical bottleneck in obtaining the scaled graph of a nonlinear system, and currently limits its use. This paper presents a framework grounded in dissipativity for efficiently computing the scaled graph of several important classes of systems, including multivariable linear time-invariant systems, impulsive systems, and piecewise linear systems. The proposed approach leverages novel connections between linear matrix inequalities, integral quadratic constraints, and scaled graphs, and is shown to be exact for specific linear time-invariant systems. The results are accompanied by several examples illustrating the potential and effectiveness of the presented framework.         ",
    "url": "https://arxiv.org/abs/2507.08411",
    "authors": [
      "Timo de Groot",
      "Maurice heemels",
      "Sebastiaan van den Eijnden"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2507.08433",
    "title": "On the $(k,\\ell)$-multiset anonymity measure for social graphs",
    "abstract": "           The publication of social graphs must be preceded by a rigorous analysis of privacy threats against social graph users. When the threat comes from inside the social network itself, the threat is called an active attack, and the de-facto privacy measure used to quantify the resistance to such an attack is the $(k,\\ell)$-anonymity. The original formulation of $(k,\\ell)$-anonymity represents the adversary's knowledge as a vector of distances to the set of attacker nodes. In this article, we argue that such adversary is too strong when it comes to counteracting active attacks. We, instead, propose a new formulation where the adversary's knowledge is the multiset of distances to the set of attacker nodes. The goal of this article is to study the $(k,\\ell)$-multiset anonymity from a graph theoretical point of view, while establishing its relationship to $(k,\\ell)$-anonymity in one hand, and considering the $k$-multiset antiresolving sets as its theoretical frame, in a second one. That is, we prove properties of some graph families in relation to whether they contain a set of attacker nodes that breaks the $(k,\\ell)$-multiset anonymity. From a practical point of view, we develop a linear programming formulation of the $k$-multiset antiresolving sets that allows us to calculate the resistance of social graphs against active attacks. This is useful for analysts who wish to know the level of privacy offered by a graph.         ",
    "url": "https://arxiv.org/abs/2507.08433",
    "authors": [
      "Alejandro Estrada-Moreno",
      "Elena Fern\u00e1ndez",
      "Dorota Kuziak",
      "Manuel Mu\u00f1oz-M\u00e1rquez",
      "Rolando Trujillo-Rasua",
      "Ismael G. Yero"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2507.08483",
    "title": "Word-Representability of Split Graphs with Independent Set of Size 4",
    "abstract": "           A pair of letters $x$ and $y$ are said to alternate in a word $w$ if, after removing all letters except for the copies of $x$ and $y$ from $w$, the resulting word is of the form $xyxy\\ldots$ (of even or odd length) or $yxyx\\ldots$ (of even or odd length). A graph $G = (V (G), E(G))$ is word-representable if there exists a word $w$ over the alphabet $V(G)$, such that any two distinct vertices $x, y \\in V (G)$ are adjacent in $G$ (i.e., $xy \\in E(G)$) if and only if the letters $x$ and $y$ alternate in $w$. A split graph is a graph in which the vertices can be partitioned into a clique and an independent set. Word-representability of split graphs has been studied in a series of papers [2, 5, 7, 9] in the literature. In this work, we give a minimal forbidden induced subgraph characterization of word-representable split graphs with an independent set of size 4, which is an open problem posed by Kitaev and Pyatkin in [9]         ",
    "url": "https://arxiv.org/abs/2507.08483",
    "authors": [
      "Suchanda Roy",
      "Ramesh Hariharasubramanian"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2507.08773",
    "title": "Total/dual correlation/coherence, redundancy/synergy, complexity, and O-information for real and complex valued multivariate data",
    "abstract": "           Firstly, assuming Gaussianity, equations for the following information theory measures are presented: total correlation/coherence (TC), dual total correlation/coherence (DTC), O-information, TSE complexity, and the redundancy-synergy index (RSI). Since these measures are functions of the covariance matrix \"S\" and its inverse \"S^-1\", the associated Wishart and inverse-Wishart distributions are of note. The DTC is shown here to be the Kullback-Leibler (KL) divergence for the inverse-Wishart pair \"(S^-1)\" and its diagonal matrix \"diag(S^-1)\", shedding light on its interpretation as a measure of \"total partial correlation\", -lndetP, with test hypothesis H0: P=I, where \"P\" is the standardized inverse covariance (i.e. P=(D^-1/2)(S^-1)(D^-1/2), with D=diag(S^-1)). The second aim of this paper introduces a generalization of all these measures for structured groups of variables. For instance, consider three or more groups, each consisting of three or more variables, with predominant redundancy within each group, but with synergistic interactions between groups. O-information will miss the between group synergy (since redundancy occurs more often in the system). In contrast, the structured O-information measure presented here will correctly report predominant synergy between groups. This is a relevant generalization towards structured multivariate information measures. A third aim is the presentation of a framework for quantifying the contribution of \"connections\" between variables, to the system's TC, DTC, O-information, and TSE complexity. A fourth aim is to present a generalization of the redundancy-synergy index for quantifying the contribution of a group of variables to the system's redundancy-synergy balance. Finally, it is shown that the expressions derived here directly apply to data from several other elliptical distributions. All program codes, data files, and executables are available.         ",
    "url": "https://arxiv.org/abs/2507.08773",
    "authors": [
      "Roberto D. Pascual-Marqui",
      "Kieko Kochi",
      "Toshihiko Kinoshita"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2311.10011",
    "title": "SQLNet: Scale-Modulated Query and Localization Network for Few-Shot Class-Agnostic Counting",
    "abstract": "           The class-agnostic counting (CAC) task has recently been proposed to solve the problem of counting all objects of an arbitrary class with several exemplars given in the input image. To address this challenging task, existing leading methods all resort to density map regression, which renders them impractical for downstream tasks that require object locations and restricts their ability to well explore the scale information of exemplars for supervision. To address the limitations, we propose a novel localization-based CAC approach, termed Scale-modulated Query and Localization Network (SQLNet). It fully explores the scales of exemplars in both the query and localization stages and achieves effective counting by accurately locating each object and predicting its approximate size. Specifically, during the query stage, rich discriminative representations of the target class are acquired by the Hierarchical Exemplars Collaborative Enhancement (HECE) module from the few exemplars through multi-scale exemplar cooperation with equifrequent size prompt embedding. These representations are then fed into the Exemplars-Unified Query Correlation (EUQC) module to interact with the query features in a unified manner and produce the correlated query tensor. In the localization stage, the Scale-aware Multi-head Localization (SAML) module utilizes the query tensor to predict the confidence, location, and size of each potential object. Moreover, a scale-aware localization loss is introduced, which exploits flexible location associations and exemplar scales for supervision to optimize the model performance. Extensive experiments demonstrate that SQLNet outperforms state-of-the-art methods on popular CAC benchmarks, achieving excellent performance not only in counting accuracy but also in localization and bounding box generation. Our codes will be available at this https URL ",
    "url": "https://arxiv.org/abs/2311.10011",
    "authors": [
      "Hefeng Wu",
      "Yandong Chen",
      "Lingbo Liu",
      "Tianshui Chen",
      "Keze Wang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.08830",
    "title": "Sequence graphs realizations and ambiguity in language models",
    "abstract": "           Several popular language models represent local contexts in an input text $x$ as bags of words. Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in $x$, with edges representing the (ordered) co-occurrence of two words within a sliding window of size $w$. However, this compressed representation is not generally bijective: some may be ambiguous, admitting several realizations as a sequence, while others may not admit any realization. In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and algorithmic point of view. We consider the existence and enumeration of realizations of a sequence graph under multiple settings: window size $w$, presence/absence of graph orientation, and presence/absence of weights (multiplicities). When $w=2$, we provide polynomial time algorithms for realizability and enumeration in all cases except the undirected/weighted setting, where we show the $\\#$P-hardness of enumeration. For $w \\ge 3$, we prove the hardness of all variants, even when $w$ is considered as a constant, with the notable exception of the undirected unweighted case for which we propose XP algorithms for both problems, tight due to a corresponding $W[1]-$hardness result. We conclude with an integer program formulation to solve the realizability problem, and a dynamic programming algorithm to solve the enumeration problem in instances of moderate sizes. This work leaves open the membership to NP of both problems, a non-trivial question due to the existence of minimum realizations having size exponential on the instance encoding.         ",
    "url": "https://arxiv.org/abs/2402.08830",
    "authors": [
      "Sammy Khalife",
      "Yann Ponty",
      "Laurent Bulteau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.19002",
    "title": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction",
    "abstract": "           Predicting the future trajectories of pedestrians on the road is an important task for autonomous driving. The pedestrian trajectory prediction is affected by scene paths, pedestrian's intentions and decision-making, which is a multi-modal problem. Most recent studies use past trajectories to predict a variety of potential future trajectory distributions, which do not account for the scene context and pedestrian targets. Instead of predicting the future trajectory directly, we propose to use scene context and observed trajectory to predict the goal points first, and then reuse the goal points to predict the future trajectories. By leveraging the information from scene context and observed trajectory, the uncertainty can be limited to a few target areas, which represent the \"goals\" of the pedestrians. In this paper, we propose GoalNet, a new trajectory prediction neural network based on the goal areas of a pedestrian. Our network can predict both pedestrian's trajectories and bounding boxes. The overall model is efficient and modular, and its outputs can be changed according to the usage scenario. Experimental results show that GoalNet significantly improves the previous state-of-the-art performance by 48.7% on the JAAD and 40.8% on the PIE dataset.         ",
    "url": "https://arxiv.org/abs/2402.19002",
    "authors": [
      "Amar Fadillah",
      "Ching-Lin Lee",
      "Zhi-Xuan Wang",
      "Kuan-Ting Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.03099",
    "title": "Graph Convolutional Branch and Bound",
    "abstract": "           This article explores the integration of deep learning models into combinatorial optimization pipelines, specifically targeting NP-hard problems. Traditional exact algorithms for such problems often rely on heuristic criteria to guide the exploration of feasible solutions. In this work, we propose using neural networks to learn informative heuristics-most notably, an optimality score that estimates a solution's proximity to the optimum. This score is used to evaluate nodes within a branch-and-bound framework, enabling a more efficient traversal of the solution space. Focusing on the Traveling Salesman Problem, we describe two exact solvers-1-tree branch-and-bound and Concorde-and introduce a hybrid approach called Graph Convolutional Branch and Bound, which augments these solvers with a graph convolutional neural network along with a novel unsupervised training strategy that facilitates generalization to graphs of varying sizes without requiring labeled data. Empirical results demonstrate the effectiveness of the proposed method, showing a significant reduction in the number of explored branch-and-bound nodes and overall computational time.         ",
    "url": "https://arxiv.org/abs/2406.03099",
    "authors": [
      "Lorenzo Sciandra",
      "Roberto Esposito",
      "Andrea Cesare Grosso",
      "Laura Sacerdote",
      "Cristina Zucca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2406.14023",
    "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective",
    "abstract": "           As large language models (LLMs) become an important way of information access, there have been increasing concerns that LLMs may intensify the spread of unethical content, including implicit bias that hurts certain populations without explicit harmful words. In this paper, we conduct a rigorous evaluation of LLMs' implicit bias towards certain demographics by attacking them from a psychometric perspective to elicit agreements to biased viewpoints. Inspired by psychometric principles in cognitive and social psychology, we propose three attack approaches, i.e., Disguise, Deception, and Teaching. Incorporating the corresponding attack instructions, we built two benchmarks: (1) a bilingual dataset with biased statements covering four bias types (2.7K instances) for extensive comparative analysis, and (2) BUMBLE, a larger benchmark spanning nine common bias types (12.7K instances) for comprehensive evaluation. Extensive evaluation of popular commercial and open-source LLMs shows that our methods can elicit LLMs' inner bias more effectively than competitive baselines. Our attack methodology and benchmarks offer an effective means of assessing the ethical risks of LLMs, driving progress toward greater accountability in their development. Our code, data, and benchmarks are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.14023",
    "authors": [
      "Yuchen Wen",
      "Keping Bi",
      "Wei Chen",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2407.02624",
    "title": "Optimizing Probabilistic Propagation in Graphs by Adding Edges",
    "abstract": "           Probabilistic graphs are an abstraction that allow us to study randomized propagation in graphs. In a probabilistic graph, each edge is \"active\" with a certain probability, independent of the other edges. For two vertices $u,v$, a classic quantity of interest, that we refer to as the proximity $\\mathcal{P}_{G}(u, v)$, is the probability that there exists a path between $u$ and $v$ all of whose edges are active. For a given subset of vertices $V_s$, the reach of $V_s$ is defined as the minimum over pairs $u \\in V_s$ and $v \\in V$ of the proximity $\\mathcal{P}_{G}(u,v)$. This quantity has been studied in the context of multicast in unreliable communication networks and in social network analysis. We study the problem of improving the reach in a probabilistic graph via edge augmentation. Formally, given a budget $k$ of edge additions and a set of source vertices $V_s$, the goal of Reach Improvement is to maximize the reach of $V_s$ by adding at most $k$ new edges to the graph. The problem was introduced in earlier empirical work in the algorithmic fairness community. We provide the first approximation guarantees and hardness results for Reach Improvement. We prove that the existence of a good augmentation implies a cluster structure for the graph. We use this structural result to analyze a novel algorithm that outputs a $k$-edge augmentation with an objective value that is poly($\\beta^*$), where $\\beta^*$ is the objective value for the optimal augmentation. We also give an algorithm that adds $O(k \\log n)$ edges and yields a multiplicative approximation to $\\beta^*$. Our arguments rely on new probabilistic tools for analyzing proximity, inspired by techniques in percolation theory; these tools may be of broader interest. Finally, we show that significantly better approximations are unlikely, under known hardness assumptions related to gap variants of the classic Set Cover problem.         ",
    "url": "https://arxiv.org/abs/2407.02624",
    "authors": [
      "Aditya Bhaskara",
      "Alex Crane",
      "Shweta Jain",
      "Md Mumtahin Habib Ullah Mazumder",
      "Blair D. Sullivan",
      "Prasanth Yalamanchili"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2409.14679",
    "title": "Quantifying Context Bias in Domain Adaptation for Object Detection",
    "abstract": "           Domain adaptation for object detection (DAOD) has become essential to counter performance degradation caused by distribution shifts between training and deployment domains. However, a critical factor influencing DAOD - context bias resulting from learned foreground-background (FG-BG) associations - has remained underexplored. We address three key questions regarding FG BG associations in object detection: are FG-BG associations encoded during the training, is there a causal relationship between FG-BG associations and detection performance, and is there an effect of FG-BG association on DAOD. To examine how models capture FG BG associations, we analyze class-wise and feature-wise performance degradation using background masking and feature perturbation, measured via change in accuracies (defined as drop rate). To explore the causal role of FG-BG associations, we apply do-calculus on FG-BG pairs guided by class activation mapping (CAM). To quantify the causal influence of FG-BG associations across domains, we propose a novel metric - domain association gradient - defined as the ratio of drop rate to maximum mean discrepancy (MMD). Through systematic experiments involving background masking, feature-level perturbations, and CAM, we reveal that convolution-based object detection models encode FG-BG associations. Our results demonstrate that context bias not only exists but causally undermines the generalization capabilities of object detection models across domains. Furthermore, we validate these findings across multiple models and datasets, including state-of-the-art architectures such as ALDI++. This study highlights the necessity of addressing context bias explicitly in DAOD frameworks, providing insights that pave the way for developing more robust and generalizable object detection systems.         ",
    "url": "https://arxiv.org/abs/2409.14679",
    "authors": [
      "Hojun Son",
      "Asma Almutairi",
      "Arpan Kusari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2409.17642",
    "title": "AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure",
    "abstract": "           Large language model (LLM)-based AI delegates are increasingly utilized to act on behalf of users, assisting them with a wide range of tasks through conversational interfaces. Despite their advantages, concerns arise regarding the potential risk of privacy leaks, particularly in scenarios involving social interactions. While existing research has focused on protecting privacy by limiting the access of AI delegates to sensitive user information, many social scenarios require disclosing private details to achieve desired social goals, necessitating a balance between privacy protection and disclosure. To address this challenge, we first conduct a pilot study to investigate user perceptions of AI delegates across various social relations and task scenarios, and then propose a novel AI delegate system that enables privacy-conscious self-disclosure. Our user study demonstrates that the proposed AI delegate strategically protects privacy, pioneering its use in diverse and dynamic social interactions.         ",
    "url": "https://arxiv.org/abs/2409.17642",
    "authors": [
      "Zhiyang Zhang",
      "Xi Chen",
      "Fangkai Yang",
      "Xiaoting Qin",
      "Chao Du",
      "Xi Cheng",
      "Hangxin Liu",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2410.05401",
    "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation",
    "abstract": "           Climate change communication on social media increasingly employs microtargeting strategies to effectively reach and influence specific demographic groups. This study presents a post-hoc analysis of microtargeting practices within climate campaigns by leveraging large language models (LLMs) to examine Facebook advertisements. Our analysis focuses on two key aspects: demographic targeting and fairness. We evaluate the ability of LLMs to accurately predict the intended demographic targets, such as gender and age group, achieving an overall accuracy of 88.55%. Furthermore, we instruct the LLMs to generate explanations for their classifications, providing transparent reasoning behind each decision. These explanations reveal the specific thematic elements used to engage different demographic segments, highlighting distinct strategies tailored to various audiences. Our findings show that young adults are primarily targeted through messages emphasizing activism and environmental consciousness, while women are engaged through themes related to caregiving roles and social advocacy. In addition to evaluating the effectiveness of LLMs in detecting microtargeted messaging, we conduct a comprehensive fairness analysis to identify potential biases in model predictions. Our findings indicate that while LLMs perform well overall, certain biases exist, particularly in the classification of senior citizens and male audiences. By showcasing the efficacy of LLMs in dissecting and explaining targeted communication strategies and by highlighting fairness concerns, this study provides a valuable framework for future research aimed at enhancing transparency, accountability, and inclusivity in social media-driven climate campaigns.         ",
    "url": "https://arxiv.org/abs/2410.05401",
    "authors": [
      "Tunazzina Islam",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.08229",
    "title": "Improvement of Spiking Neural Network with Bit Planes and Color Models",
    "abstract": "           Spiking neural network (SNN) has emerged as a promising paradigm in computational neuroscience and artificial intelligence, offering advantages such as low energy consumption and small memory footprint. However, their practical adoption is constrained by several challenges, prominently among them being performance optimization. In this study, we present a novel approach to enhance the performance of SNN for images through a new coding method that exploits bit plane representation. Our proposed technique is designed to improve the accuracy of SNN without increasing model size. Also, we investigate the impacts of color models of the proposed coding process. Through extensive experimental validation, we demonstrate the effectiveness of our coding strategy in achieving performance gain across multiple datasets. To the best of our knowledge, this is the first research that considers bit planes and color models in the context of SNN. By leveraging the unique characteristics of bit planes, we hope to unlock new potentials in SNNs performance, potentially paving the way for more efficient and effective SNNs models in future researches and applications.         ",
    "url": "https://arxiv.org/abs/2410.08229",
    "authors": [
      "Nhan T. Luu",
      "Duong T. Luu",
      "Nam N. Pham",
      "Thang C. Truong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2411.01077",
    "title": "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection",
    "abstract": "           Jailbreaking techniques trick Large Language Models (LLMs) into producing restricted output, posing a potential threat. One line of defense is to use another LLM as a Judge to evaluate the harmfulness of generated text. However, we reveal that these Judge LLMs are vulnerable to token segmentation bias, an issue that arises when delimiters alter the tokenization process, splitting words into smaller sub-tokens. This alters the embeddings of the entire sequence, reducing detection accuracy and allowing harmful content to be misclassified as safe. In this paper, we introduce Emoji Attack, a novel strategy that amplifies existing jailbreak prompts by exploiting token segmentation bias. Our method leverages in-context learning to systematically insert emojis into text before it is evaluated by a Judge LLM, inducing embedding distortions that significantly lower the likelihood of detecting unsafe content. Unlike traditional delimiters, emojis also introduce semantic ambiguity, making them particularly effective in this attack. Through experiments on state-of-the-art Judge LLMs, we demonstrate that Emoji Attack substantially reduces the unsafe prediction rate, bypassing existing safeguards.         ",
    "url": "https://arxiv.org/abs/2411.01077",
    "authors": [
      "Zhipeng Wei",
      "Yuqi Liu",
      "N. Benjamin Erichson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2411.06728",
    "title": "On the Principles of ReLU Networks with One Hidden Layer",
    "abstract": "           A neural network with one hidden layer or a two-layer network (regardless of the input layer) is the simplest feedforward neural network, whose mechanism may be the basis of more general network architectures. However, even to this type of simple architecture, it is also a ``black box''; that is, it remains unclear how to interpret the mechanism of its solutions obtained by the back-propagation algorithm and how to control the training process through a deterministic way. This paper systematically studies the first problem by constructing universal function-approximation solutions. It is shown that, both theoretically and experimentally, the training solution for the one-dimensional input could be completely understood, and that for a higher-dimensional input can also be well interpreted to some extent. Those results pave the way for thoroughly revealing the black box of two-layer ReLU networks and advance the understanding of deep ReLU networks.         ",
    "url": "https://arxiv.org/abs/2411.06728",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2411.09250",
    "title": "Embedding Space Allocation with Angle-Norm Joint Classifiers for Few-Shot Class-Incremental Learning",
    "abstract": "           Few-shot class-incremental learning (FSCIL) aims to continually learn new classes from only a few samples without forgetting previous ones, requiring intelligent agents to adapt to dynamic environments. FSCIL combines the characteristics and challenges of class-incremental learning and few-shot learning: (i) Current classes occupy the entire feature space, which is detrimental to learning new classes. (ii) The small number of samples in incremental rounds is insufficient for fully training. In existing mainstream virtual class methods, for addressing the challenge (i), they attempt to use virtual classes as placeholders. However, new classes may not necessarily align with the virtual classes. For the challenge (ii), they replace trainable fully connected layers with Nearest Class Mean (NCM) classifiers based on cosine similarity, but NCM classifiers do not account for sample imbalance issues. To address these issues in previous methods, we propose the class-center guided embedding Space Allocation with Angle-Norm joint classifiers (SAAN) learning framework, which provides balanced space for all classes and leverages norm differences caused by sample imbalance to enhance classification criteria. Specifically, for challenge (i), SAAN divides the feature space into multiple subspaces and allocates a dedicated subspace for each session by guiding samples with the pre-set category centers. For challenge (ii), SAAN establishes a norm distribution for each class and generates angle-norm joint logits. Experiments demonstrate that SAAN can achieve state-of-the-art performance and it can be directly embedded into other SOTA methods as a plug-in, further enhancing their performance.         ",
    "url": "https://arxiv.org/abs/2411.09250",
    "authors": [
      "Dunwei Tu",
      "Huiyu Yi",
      "Tieyi Zhang",
      "Ruotong Li",
      "Furao Shen",
      "Jian Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2411.10715",
    "title": "EVT: Efficient View Transformation for Multi-Modal 3D Object Detection",
    "abstract": "           Multi-modal sensor fusion in Bird's Eye View (BEV) representation has become the leading approach for 3D object detection. However, existing methods often rely on depth estimators or transformer encoders to transform image features into BEV space, which reduces robustness or introduces significant computational overhead. Moreover, the insufficient geometric guidance in view transformation results in ray-directional misalignments, limiting the effectiveness of BEV representations. To address these challenges, we propose Efficient View Transformation (EVT), a novel 3D object detection framework that constructs a well-structured BEV representation, improving both accuracy and efficiency. Our approach focuses on two key aspects. First, Adaptive Sampling and Adaptive Projection (ASAP), which utilizes LiDAR guidance to generate 3D sampling points and adaptive kernels, enables more effective transformation of image features into BEV space and a refined BEV representation. Second, an improved query-based detection framework, incorporating group-wise mixed query selection and geometry-aware cross-attention, effectively captures both the common properties and the geometric structure of objects in the transformer decoder. On the nuScenes test set, EVT achieves state-of-the-art performance of 75.3% NDS with real-time inference speed.         ",
    "url": "https://arxiv.org/abs/2411.10715",
    "authors": [
      "Yongjin Lee",
      "Hyeon-Mun Jeong",
      "Yurim Jeon",
      "Sanghyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.14371",
    "title": "SEREP: Semantic Facial Expression Representation for Robust In-the-Wild Capture and Retargeting",
    "abstract": "           Monocular facial performance capture in-the-wild is challenging due to varied capture conditions, face shapes, and expressions. Most current methods rely on linear 3D Morphable Models, which represent facial expressions independently of identity at the vertex displacement level. We propose SEREP (Semantic Expression Representation), a model that disentangles expression from identity at the semantic level. We start by learning an expression representation from high-quality 3D data of unpaired facial expressions. Then, we train a model to predict expression from monocular images relying on a novel semi-supervised scheme using low quality synthetic data. In addition, we introduce MultiREX, a benchmark addressing the lack of evaluation resources for the expression capture task. Our experiments show that SEREP outperforms state-of-the-art methods, capturing challenging expressions and transferring them to new identities.         ",
    "url": "https://arxiv.org/abs/2412.14371",
    "authors": [
      "Arthur Josi",
      "Luiz Gustavo Hafemann",
      "Abdallah Dib",
      "Emeline Got",
      "Rafael M. O. Cruz",
      "Marc-Andre Carbonneau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2501.19334",
    "title": "The Value of Prediction in Identifying the Worst-Off",
    "abstract": "           Machine learning is increasingly used in government programs to identify and support the most vulnerable individuals, prioritizing assistance for those at greatest risk over optimizing aggregate outcomes. This paper examines the welfare impacts of prediction in equity-driven contexts, and how they compare to other policy levers, such as expanding bureaucratic capacity. Through mathematical models and a real-world case study on long-term unemployment amongst German residents, we develop a comprehensive understanding of the relative effectiveness of prediction in surfacing the worst-off. Our findings provide clear analytical frameworks and practical, data-driven tools that empower policymakers to make principled decisions when designing these systems.         ",
    "url": "https://arxiv.org/abs/2501.19334",
    "authors": [
      "Unai Fischer-Abaigar",
      "Christoph Kern",
      "Juan Carlos Perdomo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2502.05044",
    "title": "Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures",
    "abstract": "           This study introduces a hybrid machine learning-based scale-bridging framework for predicting the permeability of fibrous textile structures. By addressing the computational challenges inherent to multiscale modeling, the proposed approach evaluates the efficiency and accuracy of different scale-bridging methodologies combining traditional surrogate models and even integrating physics-informed neural networks (PINNs) with numerical solvers, enabling accurate permeability predictions across micro- and mesoscales. Four methodologies were evaluated: Single Scale Method (SSM), Simple Upscaling Method (SUM), Scale-Bridging Method (SBM), and Fully Resolved Model (FRM). SSM, the simplest method, neglects microscale permeability and exhibited permeability values deviating by up to 150\\% of the FRM model, which was taken as ground truth at an equivalent lower fiber volume content. SUM improved predictions by considering uniform microscale permeability, yielding closer values under similar conditions, but still lacked structural variability. The SBM method, incorporating segment-based microscale permeability assignments, showed significant enhancements, achieving almost equivalent values while maintaining computational efficiency and modeling runtimes of ~45 minutes per simulation. In contrast, FRM, which provides the highest fidelity by fully resolving microscale and mesoscale geometries, required up to 270 times more computational time than SSM, with model files exceeding 300 GB. Additionally, a hybrid dual-scale solver incorporating PINNs has been developed and shows the potential to overcome generalization errors and the problem of data scarcity of the data-driven surrogate approaches. The hybrid framework advances permeability modelling by balancing computational cost and prediction reliability, laying the foundation for further applications in fibrous composite manufacturing.         ",
    "url": "https://arxiv.org/abs/2502.05044",
    "authors": [
      "Denis Korolev",
      "Tim Schmidt",
      "Dinesh K. Natarajan",
      "Stefano Cassola",
      "David May",
      "Miro Duhovic",
      "Michael Hinterm\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.00404",
    "title": "SecRef*: Securely Sharing Mutable References Between Verified and Unverified Code in F*",
    "abstract": "           We introduce SecRef*, a secure compilation framework protecting stateful programs verified in F* against linked unverified code, with which the program dynamically shares ML-style mutable references. To ease program verification in this setting, we propose a way of tracking which references are shareable with the unverified code, and which ones are not shareable and whose contents are thus guaranteed to be unchanged after calling into unverified code. This universal property of non-shareable references is exposed in the interface on which the verified program can rely when calling into unverified code. The remaining refinement types and pre- and post-conditions that the verified code expects from the unverified code are converted into dynamic checks about the shared references by using higher-order contracts. We prove formally in F* that this strategy ensures sound and secure interoperability with unverified code. Since SecRef* is built on top of the Monotonic State effect of F*, these proofs rely on the first monadic representation for this effect, which is a contribution of our work that can be of independent interest. Finally, we use SecRef* to build a simple cooperative multi-threading scheduler that is verified and that securely interacts with unverified threads.         ",
    "url": "https://arxiv.org/abs/2503.00404",
    "authors": [
      "Cezar-Constantin Andrici",
      "Danel Ahman",
      "Catalin Hritcu",
      "Ruxandra Icleanu",
      "Guido Mart\u00ednez",
      "Exequiel Rivas",
      "Th\u00e9o Winterhalter"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.04088",
    "title": "Cloud Computing Energy Consumption Prediction Based on Kernel Extreme Learning Machine Algorithm Improved by Vector Weighted Average Algorithm",
    "abstract": "           With the rapid expansion of cloud computing infrastructure, energy consumption has become a critical challenge, driving the need for accurate and efficient prediction models. This study proposes a novel Vector Weighted Average Kernel Extreme Learning Machine (VWAA-KELM) model to enhance energy consumption prediction in cloud computing environments. By integrating a vector weighted average algorithm (VWAA) with kernel extreme learning machine (KELM), the proposed model dynamically adjusts feature weights and optimizes kernel functions, significantly improving prediction accuracy and generalization. Experimental results demonstrate the superior performance of VWAA-KELM: 94.7% of test set prediction errors fall within [0, 50] units, with only three cases exceeding 100 units, indicating strong stability. The model achieves a coefficient of determination (R2) of 0.987 in the training set (RMSE = 28.108, RPD = 8.872) and maintains excellent generalization with R2 = 0.973 in the test set (RMSE = 43.227, RPD = 6.202). Visual analysis confirms that predicted values closely align with actual energy consumption trends, avoiding overfitting while capturing nonlinear dependencies. A key innovation of this study is the introduction of adaptive feature weighting, allowing the model to dynamically assign importance to different input parameters, thereby enhancing high-dimensional data processing. This advancement provides a scalable and efficient approach for optimizing cloud data center energy consumption. Beyond cloud computing, the proposed hybrid framework has broader applications in Internet of Things (IoT) and edge computing, supporting real-time energy management and intelligent resource allocation.         ",
    "url": "https://arxiv.org/abs/2503.04088",
    "authors": [
      "Yuqing Wang",
      "Xiao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2504.01531",
    "title": "DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal Forecasting",
    "abstract": "           Accurate predictions of spatio-temporal systems are crucial for tasks such as system management, control, and crisis prevention. However, the inherent time variance of many spatio-temporal systems poses challenges to achieving accurate predictions whenever stationarity is not granted. In order to address non-stationarity, we propose a Distribution and Relation Adaptive Network (DRAN) capable of dynamically adapting to relation and distribution changes over time. While temporal normalization and de-normalization are frequently used techniques to adapt to distribution shifts, this operation is not suitable for the spatio-temporal context as temporal normalization scales the time series of nodes and possibly disrupts the spatial relations among nodes. In order to address this problem, a Spatial Factor Learner (SFL) module is developed that enables the normalization and de-normalization process. To adapt to dynamic changes in spatial relationships among sensors, we propose a Dynamic-Static Fusion Learner (DSFL) module that effectively integrates features learned from both dynamic and static relations through an adaptive fusion ratio mechanism. Furthermore, we introduce a Stochastic Learner to capture the noisy components of spatio-temporal representations. Our approach outperforms state-of-the-art methods on weather prediction and traffic flow forecasting this http URL results show that our SFL efficiently preserves spatial relationships across various temporal normalization operations. Visualizations of the learned dynamic and static relations demonstrate that DSFL can capture both local and distant relationships between nodes.         ",
    "url": "https://arxiv.org/abs/2504.01531",
    "authors": [
      "Xiaobei Zou",
      "Luolin Xiong",
      "Kexuan Zhang",
      "Cesare Alippi",
      "Yang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.10240",
    "title": "GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction",
    "abstract": "           Circuit link prediction identifying missing component connections from incomplete netlists is crucial in automating analog circuit design. However, existing methods face three main challenges: 1) Insufficient use of topological patterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to the complexity of annotations hinders model generalization; 3) Limited adaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural Networks (GNNs) based framework featuring three innovations to tackle these challenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes for Link Prediction) framework and achieve port-level accuracy in circuit link prediction. Second, we propose Netlist Babel Fish, a netlist format conversion tool leveraging retrieval-augmented generation (RAG) with a large language model (LLM) to enhance the compatibility of netlist formats. Finally, we construct SpiceNetlist, a comprehensive dataset that contains 775 annotated circuits across 10 different component classes. Experiments demonstrate accuracy improvements of 16.08% on SpiceNetlist, 11.38% on Image2Net, and 16.01% on Masala-CHAI compared to the baseline in intra-dataset evaluation, while maintaining accuracy from 92.05% to 99.07% in cross-dataset evaluation, exhibiting robust feature transfer capabilities.         ",
    "url": "https://arxiv.org/abs/2504.10240",
    "authors": [
      "Guanyuan Pan",
      "Tiansheng Zhou",
      "Bingtao Ma",
      "Yaqi Wang",
      "Jianxiang Zhao",
      "Zhi Li",
      "Yugui Lin",
      "Pietro Lio",
      "Shuai Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2504.18906",
    "title": "Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness",
    "abstract": "           Unauthorized screen capturing and dissemination pose severe security threats such as data leakage and information theft. Several studies propose robust watermarking methods to track the copyright of Screen-Camera (SC) images, facilitating post-hoc certification against infringement. These techniques typically employ heuristic mathematical modeling or supervised neural network fitting as the noise layer, to enhance watermarking robustness against SC. However, both strategies cannot fundamentally achieve an effective approximation of SC noise. Mathematical simulation suffers from biased approximations due to the incomplete decomposition of the noise and the absence of interdependence among the noise components. Supervised networks require paired data to train the noise-fitting model, and it is difficult for the model to learn all the features of the noise. To address the above issues, we propose Simulation-to-Real (S2R). Specifically, an unsupervised noise layer employs unpaired data to learn the discrepancy between the modeled simulated noise distribution and the real-world SC noise distribution, rather than directly learning the mapping from sharp images to real-world images. Learning this transformation from simulation to reality is inherently simpler, as it primarily involves bridging the gap in noise distributions, instead of the complex task of reconstructing fine-grained image details. Extensive experimental results validate the efficacy of the proposed method, demonstrating superior watermark robustness and generalization compared to state-of-the-art methods.         ",
    "url": "https://arxiv.org/abs/2504.18906",
    "authors": [
      "Yufeng Wu",
      "Xin Liao",
      "Baowei Wang",
      "Han Fang",
      "Xiaoshuai Wu",
      "Guiling Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.04165",
    "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks",
    "abstract": "           Spiking Neural Networks (SNNs) are increasingly recognized for their biological plausibility and energy efficiency, positioning them as strong alternatives to Artificial Neural Networks (ANNs) in neuromorphic computing applications. SNNs inherently process temporal information by leveraging the precise timing of spikes, but balancing temporal feature utilization with low energy consumption remains a challenge. In this work, we introduce Temporal Shift module for Spiking Neural Networks (TS-SNN), which incorporates a novel Temporal Shift (TS) module to integrate past, present, and future spike features within a single timestep via a simple yet effective shift operation. A residual combination method prevents information loss by integrating shifted and original features. The TS module is lightweight, requiring only one additional learnable parameter, and can be seamlessly integrated into existing architectures with minimal additional computational cost. TS-SNN achieves state-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100 (80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low energy consumption. This work marks a significant step forward in developing efficient and accurate SNN architectures.         ",
    "url": "https://arxiv.org/abs/2505.04165",
    "authors": [
      "Kairong Yu",
      "Tianqing Zhang",
      "Qi Xu",
      "Gang Pan",
      "Hongwei Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.06740",
    "title": "Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving",
    "abstract": "           Accurate prediction of surrounding road users' trajectories is essential for safe and efficient autonomous driving. While deep learning models have improved performance, challenges remain in preventing off-road predictions and ensuring kinematic feasibility. Existing methods incorporate road-awareness modules and enforce kinematic constraints but lack plausibility guarantees and often introduce trade-offs in complexity and flexibility. This paper proposes a novel framework that formulates trajectory prediction as a constrained regression guided by permissible driving directions and their boundaries. Using the agent's current state and an HD map, our approach defines the valid boundaries and ensures on-road predictions by training the network to learn superimposed paths between left and right boundary polylines. To guarantee feasibility, the model predicts acceleration profiles that determine the vehicle's travel distance along these paths while adhering to kinematic constraints. We evaluate our approach on the Argoverse-2 dataset against the HPTR baseline. Our approach shows a slight decrease in benchmark metrics compared to HPTR but notably improves final displacement error and eliminates infeasible trajectories. Moreover, the proposed approach has superior generalization to less prevalent maneuvers and unseen out-of-distribution scenarios, reducing the off-road rate under adversarial attacks from 66% to just 1%. These results highlight the effectiveness of our approach in generating feasible and robust predictions.         ",
    "url": "https://arxiv.org/abs/2505.06740",
    "authors": [
      "Ahmed Abouelazm",
      "Mianzhi Liu",
      "Christian Hubschneider",
      "Yin Wu",
      "Daniel Slieter",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.06743",
    "title": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility",
    "abstract": "           Trajectory prediction is crucial for autonomous driving, enabling vehicles to navigate safely by anticipating the movements of surrounding road users. However, current deep learning models often lack trustworthiness as their predictions can be physically infeasible and illogical to humans. To make predictions more trustworthy, recent research has incorporated prior knowledge, like the social force model for modeling interactions and kinematic models for physical realism. However, these approaches focus on priors that suit either vehicles or pedestrians and do not generalize to traffic with mixed agent classes. We propose incorporating interaction and kinematic priors of all agent classes--vehicles, pedestrians, and cyclists with class-specific interaction layers to capture agent behavioral differences. To improve the interpretability of the agent interactions, we introduce DG-SFM, a rule-based interaction importance score that guides the interaction layer. To ensure physically feasible predictions, we proposed suitable kinematic models for all agent classes with a novel pedestrian kinematic model. We benchmark our approach on the Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our baseline. Experiments demonstrate that our method improves interaction interpretability, revealing a correlation between incorrect predictions and divergence from our interaction prior. Even though incorporating the kinematic models causes a slight decrease in accuracy, they eliminate infeasible trajectories found in the dataset and the baseline model. Thus, our approach fosters trust in trajectory prediction as its interaction reasoning is interpretable, and its predictions adhere to physics.         ",
    "url": "https://arxiv.org/abs/2505.06743",
    "authors": [
      "Marius Baden",
      "Ahmed Abouelazm",
      "Christian Hubschneider",
      "Yin Wu",
      "Daniel Slieter",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.08264",
    "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning",
    "abstract": "           This paper addresses the challenges of training end-to-end autonomous driving agents using Reinforcement Learning (RL). RL agents are typically trained in a fixed set of scenarios and nominal behavior of surrounding road users in simulations, limiting their generalization and real-life deployment. While domain randomization offers a potential solution by randomly sampling driving scenarios, it frequently results in inefficient training and sub-optimal policies due to the high variance among training scenarios. To address these limitations, we propose an automatic curriculum learning framework that dynamically generates driving scenarios with adaptive complexity based on the agent's evolving capabilities. Unlike manually designed curricula that introduce expert bias and lack scalability, our framework incorporates a ``teacher'' that automatically generates and mutates driving scenarios based on their learning potential -- an agent-centric metric derived from the agent's current policy -- eliminating the need for expert design. The framework enhances training efficiency by excluding scenarios the agent has mastered or finds too challenging. We evaluate our framework in a reinforcement learning setting where the agent learns a driving policy from camera images. Comparative results against baseline methods, including fixed scenario training and domain randomization, demonstrate that our approach leads to enhanced generalization, achieving higher success rates: +9% in low traffic density, +21% in high traffic density, and faster convergence with fewer training steps. Our findings highlight the potential of ACL in improving the robustness and efficiency of RL-based autonomous driving agents.         ",
    "url": "https://arxiv.org/abs/2505.08264",
    "authors": [
      "Ahmed Abouelazm",
      "Tim Weinstein",
      "Tim Joseph",
      "Philip Sch\u00f6rner",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2505.08423",
    "title": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition",
    "abstract": "           Facial recognition systems have achieved remarkable success by leveraging deep neural networks, advanced loss functions, and large-scale datasets. However, their performance often deteriorates in real-world scenarios involving low-quality facial images. Such degradations, common in surveillance footage or standoff imaging include low resolution, motion blur, and various distortions, resulting in a substantial domain gap from the high-quality data typically used during training. While existing approaches attempt to address robustness by modifying network architectures or modeling global spatial transformations, they frequently overlook local, non-rigid deformations that are inherently present in real-world settings. In this work, we introduce \\textbf{DArFace}, a \\textbf{D}eformation-\\textbf{A}ware \\textbf{r}obust \\textbf{Face} recognition framework that enhances robustness to such degradations without requiring paired high- and low-quality training samples. Our method adversarially integrates both global transformations (e.g., rotation, translation) and local elastic deformations during training to simulate realistic low-quality conditions. Moreover, we introduce a contrastive objective to enforce identity consistency across different deformed views. Extensive evaluations on low-quality benchmarks including TinyFace, IJB-B, and IJB-C demonstrate that DArFace surpasses state-of-the-art methods, with significant gains attributed to the inclusion of local deformation modeling.         ",
    "url": "https://arxiv.org/abs/2505.08423",
    "authors": [
      "Sadaf Gulshad",
      "Abdullah Aldahlawi Thakaa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2505.11193",
    "title": "Reducing Sensor Requirements by Relaxing the Network Metric Dimension",
    "abstract": "           Source localization in graphs involves identifying the origin of a phenomenon or event, such as an epidemic outbreak or a misinformation source, by leveraging structural graph properties. One key concept in this context is the metric dimension, which quantifies the minimum number of strategically placed sensors needed to uniquely identify all vertices based on their distances. While powerful, the traditional metric dimension imposes a stringent requirement that every vertex must be uniquely identified, often necessitating a large number of sensors. In this work, we relax the metric dimension and allow vertices at a graph distance less than k to share identical distance profiles relative to the sensors. This relaxation reduces the number of sensors needed while maintaining sufficient resolution for practical applications like source localization and network monitoring. We provide two main theoretical contributions: an analysis of the k-relaxed metric dimension in deterministic trees, revealing the interplay between structural properties and sensor placement, and an extension to random trees generated by branching processes, offering insights into stochastic settings. We also conduct numerical experiments across a variety of graph types, including random trees, random geometric graphs, and real-world networks. The results show that the relaxed metric dimension is significantly smaller than the traditional metric dimension. Furthermore, the number of vertices indistinguishable from any given target vertex always remains small. Finally, we propose and evaluate a two-step localization strategy that balances the trade-off between resolution and the number of sensors required. This strategy identifies an optimal relaxation level that minimizes the total number of sensors across both steps, providing a practical and efficient approach to source localization.         ",
    "url": "https://arxiv.org/abs/2505.11193",
    "authors": [
      "Paula M\u00fcrmann",
      "Robin Jaccard",
      "Maximilien Dreveton",
      "Aryan Alavi Razavi Ravari",
      "Patrick Thiran"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2506.06489",
    "title": "Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks",
    "abstract": "           What features neural networks learn, and how, remains an open question. In this paper, we introduce Alternating Gradient Flows (AGF), an algorithmic framework that describes the dynamics of feature learning in two-layer networks trained from small initialization. Prior works have shown that gradient flow in this regime exhibits a staircase-like loss curve, alternating between plateaus where neurons slowly align to useful directions and sharp drops where neurons rapidly grow in norm. AGF approximates this behavior as an alternating two-step process: maximizing a utility function over dormant neurons and minimizing a cost function over active ones. AGF begins with all neurons dormant. At each round, a dormant neuron activates, triggering the acquisition of a feature and a drop in the loss. AGF quantifies the order, timing, and magnitude of these drops, matching experiments across architectures. We show that AGF unifies and extends existing saddle-to-saddle analyses in fully connected linear networks and attention-only linear transformers, where the learned features are singular modes and principal components, respectively. In diagonal linear networks, we prove AGF converges to gradient flow in the limit of vanishing initialization. Applying AGF to quadratic networks trained to perform modular addition, we give the first complete characterization of the training dynamics, revealing that networks learn Fourier features in decreasing order of coefficient magnitude. Altogether, AGF offers a promising step towards understanding feature learning in neural networks.         ",
    "url": "https://arxiv.org/abs/2506.06489",
    "authors": [
      "Daniel Kunin",
      "Giovanni Luca Marchetti",
      "Feng Chen",
      "Dhruva Karkada",
      "James B. Simon",
      "Michael R. DeWeese",
      "Surya Ganguli",
      "Nina Miolane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2506.07454",
    "title": "Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs",
    "abstract": "           In this paper, we introduce a multi-robot system that integrates mapping, localization, and task and motion planning (TAMP) enabled by 3D scene graphs to execute complex instructions expressed in natural language. Our system builds a shared 3D scene graph incorporating an open-set object-based map, which is leveraged for multi-robot 3D scene graph fusion. This representation supports real-time, view-invariant relocalization (via the object-based map) and planning (via the 3D scene graph), allowing a team of robots to reason about their surroundings and execute complex tasks. Additionally, we introduce a planning approach that translates operator intent into Planning Domain Definition Language (PDDL) goals using a Large Language Model (LLM) by leveraging context from the shared 3D scene graph and robot capabilities. We provide an experimental assessment of the performance of our system on real-world tasks in large-scale, outdoor environments. A supplementary video is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2506.07454",
    "authors": [
      "Jared Strader",
      "Aaron Ray",
      "Jacob Arkin",
      "Mason B. Peterson",
      "Yun Chang",
      "Nathan Hughes",
      "Christopher Bradley",
      "Yi Xuan Jia",
      "Carlos Nieto-Granda",
      "Rajat Talak",
      "Chuchu Fan",
      "Luca Carlone",
      "Jonathan P. How",
      "Nicholas Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2506.19703",
    "title": "Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of Damaged Power Networks Coupled with Road Transportation Networks",
    "abstract": "           The resilience of critical infrastructure networks (CINs) after disruptions, such as those caused by natural hazards, depends on both the speed of restoration and the extent to which operational functionality can be regained. Allocating resources for restoration is a combinatorial optimal planning problem that involves determining which crews will repair specific network nodes and in what order. This paper presents a novel graph-based formulation that merges two interconnected graphs, representing crew and transportation nodes and power grid nodes, into a single heterogeneous graph. To enable efficient planning, graph reinforcement learning (GRL) is integrated with bigraph matching. GRL is utilized to design the incentive function for assigning crews to repair tasks based on the graph-abstracted state of the environment, ensuring generalization across damage scenarios. Two learning techniques are employed: a graph neural network trained using Proximal Policy Optimization and another trained via Neuroevolution. The learned incentive functions inform a bipartite graph that links crews to repair tasks, enabling weighted maximum matching for crew-to-task allocations. An efficient simulation environment that pre-computes optimal node-to-node path plans is used to train the proposed restoration planning methods. An IEEE 8500-bus power distribution test network coupled with a 21 square km transportation network is used as the case study, with scenarios varying in terms of numbers of damaged nodes, depots, and crews. Results demonstrate the approach's generalizability and scalability across scenarios, with learned policies providing 3-fold better performance than random policies, while also outperforming optimization-based solutions in both computation time (by several orders of magnitude) and power restored.         ",
    "url": "https://arxiv.org/abs/2506.19703",
    "authors": [
      "Nathan Maurer",
      "Harshal Kaushik",
      "Roshni Anna Jacob",
      "Jie Zhang",
      "Souma Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.03631",
    "title": "Scientific Machine Learning of Chaotic Systems Discovers Governing Equations for Neural Populations",
    "abstract": "           Discovering governing equations that describe complex chaotic systems remains a fundamental challenge in physics and neuroscience. Here, we introduce the PEM-UDE method, which combines the prediction-error method with universal differential equations to extract interpretable mathematical expressions from chaotic dynamical systems, even with limited or noisy observations. This approach succeeds where traditional techniques fail by smoothing optimization landscapes and removing the chaotic properties during the fitting process without distorting optimal parameters. We demonstrate its efficacy by recovering hidden states in the Rossler system and reconstructing dynamics from noise-corrupted electrical circuit data, where the correct functional form of the dynamics is recovered even when one of the observed time series is corrupted by noise 5x the magnitude of the true signal. We demonstrate that this method is capable of recovering the correct dynamics, whereas direct symbolic regression methods, such as SINDy, fail to do so with the given amount of data and noise. Importantly, when applied to neural populations, our method derives novel governing equations that respect biological constraints such as network sparsity - a constraint necessary for cortical information processing yet not captured in next-generation neural mass models - while preserving microscale neuronal parameters. These equations predict an emergent relationship between connection density and both oscillation frequency and synchrony in neural circuits. We validate these predictions using three intracranial electrode recording datasets from the medial entorhinal cortex, prefrontal cortex, and orbitofrontal cortex. Our work provides a pathway to develop mechanistic, multi-scale brain models that generalize across diverse neural architectures, bridging the gap between single-neuron dynamics and macroscale brain activity.         ",
    "url": "https://arxiv.org/abs/2507.03631",
    "authors": [
      "Anthony G. Chesebro",
      "David Hofmann",
      "Vaibhav Dixit",
      "Earl K. Miller",
      "Richard H. Granger",
      "Alan Edelman",
      "Christopher V. Rackauckas",
      "Lilianne R. Mujica-Parodi",
      "Helmut H. Strey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Chaotic Dynamics (nlin.CD)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2507.05730",
    "title": "Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study",
    "abstract": "           Hyperspectral images are high-dimensional datasets comprising hundreds of contiguous spectral bands, enabling detailed analysis of materials and surfaces. Hyperspectral anomaly detection (HAD) refers to the technique of identifying and locating anomalous targets in such data without prior information about a hyperspectral scene or target spectrum. This technology has seen rapid advancements in recent years, with applications in agriculture, defence, military surveillance, and environmental monitoring. Despite this significant progress, existing HAD methods continue to face challenges such as high computational complexity, sensitivity to noise, and limited generalisation across diverse datasets. This study presents a comprehensive comparison of various HAD techniques, categorising them into statistical models, representation-based methods, classical machine learning approaches, and deep learning models. We evaluated these methods across 17 benchmarking datasets using different performance metrics, such as ROC, AUC, and separability map to analyse detection accuracy, computational efficiency, their strengths, limitations, and directions for future research. Our findings highlight that deep learning models achieved the highest detection accuracy, while statistical models demonstrated exceptional speed across all datasets. This survey aims to provide valuable insights for researchers and practitioners working to advance the field of hyperspectral anomaly detection methods.         ",
    "url": "https://arxiv.org/abs/2507.05730",
    "authors": [
      "Aayushma Pant",
      "Arbind Agrahari Baniya",
      "Tsz-Kwan Lee",
      "Sunil Aryal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.06850",
    "title": "The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover",
    "abstract": "           The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.         ",
    "url": "https://arxiv.org/abs/2507.06850",
    "authors": [
      "Matteo Lupinacci",
      "Francesco Aurelio Pironti",
      "Francesco Blefari",
      "Francesco Romeo",
      "Luigi Arena",
      "Angelo Furfaro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.07393",
    "title": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos",
    "abstract": "           We propose \\textbf{KeyRe-ID}, a keypoint-guided video-based person re-identification framework consisting of global and local branches that leverage human keypoints for enhanced spatiotemporal representation learning. The global branch captures holistic identity semantics through Transformer-based temporal aggregation, while the local branch dynamically segments body regions based on keypoints to generate fine-grained, part-aware features. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate state-of-the-art performance, achieving 91.73\\% mAP and 97.32\\% Rank-1 accuracy on MARS, and 96.00\\% Rank-1 and 100.0\\% Rank-5 accuracy on iLIDS-VID. The code for this work will be publicly available on GitHub upon publication.         ",
    "url": "https://arxiv.org/abs/2507.07393",
    "authors": [
      "Jinseong Kim",
      "Junghoon Song",
      "Gyeongseon Baek",
      "Byeongjoon Noh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.07532",
    "title": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings",
    "abstract": "           While Prover-Verifier Games (PVGs) offer a promising path toward verifiability in nonlinear classification models, they have not yet been applied to complex inputs such as high-dimensional images. Conversely, Concept Bottleneck Models (CBMs) effectively translate such data into interpretable concepts but are limited by their reliance on low-capacity linear predictors. In this work, we introduce the Neural Concept Verifier (NCV), a unified framework combining PVGs with concept encodings for interpretable, nonlinear classification in high-dimensional settings. NCV achieves this by utilizing recent minimally supervised concept discovery models to extract structured concept encodings from raw inputs. A prover then selects a subset of these encodings, which a verifier -- implemented as a nonlinear predictor -- uses exclusively for decision-making. Our evaluations show that NCV outperforms CBM and pixel-based PVG classifier baselines on high-dimensional, logically complex datasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV as a promising step toward performative, verifiable AI.         ",
    "url": "https://arxiv.org/abs/2507.07532",
    "authors": [
      "Berkant Turan",
      "Suhrab Asadulla",
      "David Steinmann",
      "Wolfgang Stammer",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2507.07620",
    "title": "ViLU: Learning Vision-Language Uncertainties for Failure Prediction",
    "abstract": "           Reliable Uncertainty Quantification (UQ) and failure prediction remain open challenges for Vision-Language Models (VLMs). We introduce ViLU, a new Vision-Language Uncertainty quantification framework that contextualizes uncertainty estimates by leveraging all task-relevant textual representations. ViLU constructs an uncertainty-aware multi-modal representation by integrating the visual embedding, the predicted textual embedding, and an image-conditioned textual representation via cross-attention. Unlike traditional UQ methods based on loss prediction, ViLU trains an uncertainty predictor as a binary classifier to distinguish correct from incorrect predictions using a weighted binary cross-entropy loss, making it loss-agnostic. In particular, our proposed approach is well-suited for post-hoc settings, where only vision and text embeddings are available without direct access to the model itself. Extensive experiments on diverse datasets show the significant gains of our method compared to state-of-the-art failure prediction methods. We apply our method to standard classification datasets, such as ImageNet-1k, as well as large-scale image-caption datasets like CC12M and LAION-400M. Ablation studies highlight the critical role of our architecture and training in achieving effective uncertainty quantification. Our code is publicly available and can be found here: this https URL.         ",
    "url": "https://arxiv.org/abs/2507.07620",
    "authors": [
      "Marc Lafon",
      "Yannis Karmim",
      "Julio Silva-Rodr\u00edguez",
      "Paul Couairon",
      "Cl\u00e9ment Rambour",
      "Rapha\u00ebl Fournier-Sniehotta",
      "Ismail Ben Ayed",
      "Jose Dolz",
      "Nicolas Thome"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.07802",
    "title": "Synergistic Prompting for Robust Visual Recognition with Missing Modalities",
    "abstract": "           Large-scale multi-modal models have demonstrated remarkable performance across various visual recognition tasks by leveraging extensive paired multi-modal training data. However, in real-world applications, the presence of missing or incomplete modality inputs often leads to significant performance degradation. Recent research has focused on prompt-based strategies to tackle this issue; however, existing methods are hindered by two major limitations: (1) static prompts lack the flexibility to adapt to varying missing-data conditions, and (2) basic prompt-tuning methods struggle to ensure reliable performance when critical modalities are this http URL address these challenges, we propose a novel Synergistic Prompting (SyP) framework for robust visual recognition with missing modalities. The proposed SyP introduces two key innovations: (I) a Dynamic Adapter, which computes adaptive scaling factors to dynamically generate prompts, replacing static parameters for flexible multi-modal adaptation, and (II) a Synergistic Prompting Strategy, which combines static and dynamic prompts to balance information across modalities, ensuring robust reasoning even when key modalities are missing. The proposed SyP achieves significant performance improvements over existing approaches across three widely-used visual recognition datasets, demonstrating robustness under diverse missing rates and conditions. Extensive experiments and ablation studies validate its effectiveness in handling missing modalities, highlighting its superior adaptability and reliability.         ",
    "url": "https://arxiv.org/abs/2507.07802",
    "authors": [
      "Zhihui Zhang",
      "Luanyuan Dai",
      "Qika Lin",
      "Yunfeng Diao",
      "Guangyin Jin",
      "Yufei Guo",
      "Jing Zhang",
      "Xiaoshuai Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2507.07994",
    "title": "Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection",
    "abstract": "           Keypoint detection, integral to modern machine perception, faces challenges in few-shot learning, particularly when source data from the same distribution as the query is unavailable. This gap is addressed by leveraging sketches, a popular form of human expression, providing a source-free alternative. However, challenges arise in mastering cross-modal embeddings and handling user-specific sketch styles. Our proposed framework overcomes these hurdles with a prototypical setup, combined with a grid-based locator and prototypical domain adaptation. We also demonstrate success in few-shot convergence across novel keypoints and classes through extensive experiments.         ",
    "url": "https://arxiv.org/abs/2507.07994",
    "authors": [
      "Subhajit Maity",
      "Ayan Kumar Bhunia",
      "Subhadeep Koley",
      "Pinaki Nath Chowdhury",
      "Aneeshan Sain",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.06445",
    "title": "Extremal minimal bipartite matching covered graphs",
    "abstract": "           A connected graph, on four or more vertices, is matching covered (aka 1-extendable) if every edge is present in some perfect matching. An ear decomposition theorem exists for bipartite matching covered graphs due to Hetyei. From the results and proofs of Lov\u00e1sz and Plummer, that rely on Hetyei's theorem, one may deduce that any minimal bipartite matching covered graph has at least $2(m-n+2)$ vertices of degree two (where minimal means that deleting any edge results in a graph that is not matching covered); such a graph is said to be extremal if it attains the stated lower bound. In this paper, we provide a complete characterization of the class of extremal minimal bipartite matching covered graphs. In particular, we prove that every such graph $G$ is obtained from two copies of a tree devoid of degree two vertices, say $T$ and $T'$, by adding edges -- each of which joins a leaf of $T$ with the corresponding leaf of $T'$. Apart from the aforementioned bound, there are four other bounds that appear in, or may be deduced from, the work of Lov\u00e1sz and Plummer. Each of these bounds leads to a notion of extremality. In this paper, we obtain a complete characterization of all of these extremal classes and also establish relationships between them. Two of our characterizations are in the same spirit as the one stated above. For the remaining two extremal classes, we reduce each of them to one of the already characterized extremal classes using standard matching theoretic operations. A connected graph is k-extendable if it has a matching of cardinality $k$ and each such matching extends to a perfect matching. We also discuss bounds proved by Lou (1999) for minimal k-extendable bipartite graphs. We conjecture stronger bounds and provide evidence for our conjectures by constructing tight examples that are straightforward generalizations of the ones that appear in the 1-extendable case.         ",
    "url": "https://arxiv.org/abs/2404.06445",
    "authors": [
      "Amit Kumar Mallik",
      "Ajit A. Diwan",
      "Nishad Kothari"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2410.15982",
    "title": "State Estimation Using Sparse DEIM and Recurrent Neural Networks",
    "abstract": "           Sparse Discrete Empirical Interpolation Method (S-DEIM) was recently proposed for state estimation in dynamical systems when only a sparse subset of the state variables can be observed. The S-DEIM estimate involves a kernel vector whose optimal value is inferred through a data assimilation algorithm. This data assimilation step suffers from two drawbacks: (i) It requires the knowledge of the governing equations of the dynamical system, and (ii) It is not generally guaranteed to converge to the optimal kernel vector. To address these issues, here we introduce an equation-free S-DEIM framework that estimates the optimal kernel vector from sparse observational time series using recurrent neural networks (RNNs). We show that the recurrent architecture is necessary since the kernel vector cannot be estimated from instantaneous observations. But RNNs, which incorporate the past history of the observations in the learning process, lead to nearly optimal estimations. We demonstrate the efficacy of our method on three numerical examples with increasing degree of spatiotemporal complexity: a conceptual model of atmospheric flow known as the Lorenz-96 system, the Kuramoto-Sivashinsky equation, and the Rayleigh-Benard convection. In each case, the resulting S-DEIM estimates are satisfactory even when a relatively simple RNN architecture, namely the reservoir computing network, is used.         ",
    "url": "https://arxiv.org/abs/2410.15982",
    "authors": [
      "Mohammad Farazmand"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2502.09832",
    "title": "Algorithmic contiguity from low-degree conjecture and applications in correlated random graphs",
    "abstract": "           In this paper, assuming a natural strengthening of the low-degree conjecture, we provide evidence of computational hardness for two problems: (1) the (partial) matching recovery problem in the sparse correlated Erd\u0151s-R\u00e9nyi graphs $\\mathcal G(n,q;\\rho)$ when the edge-density $q=n^{-1+o(1)}$ and the correlation $\\rho<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a remaining problem in \\cite{DDL23+}; (2) the detection problem between the correlated sparse stochastic block model $\\mathcal S(n,\\tfrac{\\lambda}{n};k,\\epsilon;s)$ and a pair of independent stochastic block models $\\mathcal S(n,\\tfrac{\\lambda s}{n};k,\\epsilon)$ when $\\epsilon^2 \\lambda s<1$ lies below the Kesten-Stigum (KS) threshold and $s<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a remaining problem in \\cite{CDGL24+}. One of the main ingredient in our proof is to derive certain forms of \\emph{algorithmic contiguity} between two probability measures based on bounds on their low-degree advantage. To be more precise, consider the high-dimensional hypothesis testing problem between two probability measures $\\mathbb{P}$ and $\\mathbb{Q}$ based on the sample $\\mathsf Y$. We show that if the low-degree advantage $\\mathsf{Adv}_{\\leq D} \\big( \\frac{\\mathrm{d}\\mathbb{P}}{\\mathrm{d}\\mathbb{Q}} \\big)=O(1)$, then (assuming the low-degree conjecture) there is no efficient algorithm $\\mathcal A$ such that $\\mathbb{Q}(\\mathcal A(\\mathsf Y)=0)=1-o(1)$ and $\\mathbb{P}(\\mathcal A(\\mathsf Y)=1)=\\Omega(1)$. This framework provides a useful tool for performing reductions between different inference tasks.         ",
    "url": "https://arxiv.org/abs/2502.09832",
    "authors": [
      "Zhangsong Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2503.02494",
    "title": "Enhancing Distributional Robustness in Principal Component Analysis by Wasserstein Distances",
    "abstract": "           We consider the distributionally robust optimization (DRO) model of principal component analysis (PCA) to account for uncertainty in the underlying probability distribution. The resulting formulation leads to a nonsmooth constrained min-max optimization problem, where the ambiguity set captures the distributional uncertainty by the type-$2$ Wasserstein distance. We prove that the inner maximization problem admits a closed-form optimal value. This explicit characterization equivalently reformulates the original DRO model into a minimization problem on the Stiefel manifold with intricate nonsmooth terms, a challenging formulation beyond the reach of existing algorithms. To address this issue, we devise an efficient smoothing manifold proximal gradient algorithm. Our analysis establishes Riemannian gradient consistency and global convergence of our algorithm to a stationary point of the nonsmooth minimization problem. We also provide the iteration complexity $O(\\epsilon^{-3})$ of our algorithm to achieve an $\\epsilon$-approximate stationary point. Finally, numerical experiments are conducted to validate the effectiveness and scalability of our algorithm, as well as to highlight the necessity and rationality of adopting the DRO model for PCA.         ",
    "url": "https://arxiv.org/abs/2503.02494",
    "authors": [
      "Lei Wang",
      "Xin Liu",
      "Xiaojun Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2503.17546",
    "title": "Communities in the Kuramoto Model: Dynamics and Detection via Path Signatures",
    "abstract": "           The behavior of multivariate dynamical processes is often governed by underlying structural connections that relate the components of the system. For example, brain activity, which is often measured via time series is determined by an underlying structural graph, where nodes represent neurons or brain regions and edges cortical connectivity. Existing methods for inferring structural connections from observed dynamics, such as correlation-based or spectral techniques, may fail to fully capture complex relationships in high-dimensional time series in an interpretable way. Here, we propose the use of path signatures, a mathematical framework that encodes geometric and temporal properties of continuous paths, to address this problem. Path signatures provide a reparametrization-invariant characterization of dynamical data and can be used to compute the lead matrix, which reveals lead-lag phenomena. We showcase our approach on time series from coupled oscillators in the Kuramoto model defined on a stochastic block model graph, termed the Kuramoto Stochastic Block Model (KSBM). Using mean-field theory and Gaussian approximations, we analytically derive reduced models of KSBM dynamics in different temporal regimes and theoretically characterize the lead matrix in these settings. Leveraging these insights, we propose a novel signature-based community detection algorithm, achieving exact recovery of structural communities from observed time series in multiple KSBM instances. We also explored the performance of our community detection on a stochastic variant of the KSBM as well as on real neuropixels of cortical recordings to demonstrate applicability on real-world data. Our results demonstrate that path signatures provide a novel perspective on analyzing complex neural data and other high-dimensional systems, explicitly exploiting temporal functional relationships to infer underlying structure.         ",
    "url": "https://arxiv.org/abs/2503.17546",
    "authors": [
      "T\u00e2m Johan Nguy\u00ean",
      "Darrick Lee",
      "Bernadette Jana Stolz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2506.06311",
    "title": "A Novel Shape-Aware Topological Representation for GPR Data with DNN Integration",
    "abstract": "           Ground Penetrating Radar (GPR) is a widely used Non-Destructive Testing (NDT) technique for subsurface exploration, particularly in infrastructure inspection and maintenance. However, conventional interpretation methods are often limited by noise sensitivity and a lack of structural awareness. This study presents a novel framework that enhances the detection of underground utilities, especially pipelines, by integrating shape-aware topological features derived from B-scan GPR images using Topological Data Analysis (TDA), with the spatial detection capabilities of the YOLOv5 deep neural network (DNN). We propose a novel shape-aware topological representation that amplifies structural features in the input data, thereby improving the model's responsiveness to the geometrical features of buried objects. To address the scarcity of annotated real-world data, we employ a Sim2Real strategy that generates diverse and realistic synthetic datasets, effectively bridging the gap between simulated and real-world domains. Experimental results demonstrate significant improvements in mean Average Precision (mAP), validating the robustness and efficacy of our approach. This approach underscores the potential of TDA-enhanced learning in achieving reliable, real-time subsurface object detection, with broad applications in urban planning, safety inspection, and infrastructure management.         ",
    "url": "https://arxiv.org/abs/2506.06311",
    "authors": [
      "Meiyan Kang",
      "Shizuo Kaji",
      "Sang-Yun Lee",
      "Taegon Kim",
      "Hee-Hwan Ryu",
      "Suyoung Choi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2507.05640",
    "title": "Learnable quantum spectral filters for hybrid graph neural networks",
    "abstract": "           In this paper, we describe a parameterized quantum circuit that can be considered as convolutional and pooling layers for graph neural networks. The circuit incorporates the parameterized quantum Fourier circuit where the qubit connections for the controlled gates derived from the Laplacian operator. Specifically, we show that the eigenspace of the Laplacian operator of a graph can be approximated by using QFT based circuit whose connections are determined from the adjacency matrix. For an $N\\times N$ Laplacian, this approach yields an approximate polynomial-depth circuit requiring only $n=log(N)$ qubits. These types of circuits can eliminate the expensive classical computations for approximating the learnable functions of the Laplacian through Chebyshev polynomial or Taylor expansions. Using this circuit as a convolutional layer provides an $n-$ dimensional probability vector that can be considered as the filtered and compressed graph signal. Therefore, the circuit along with the measurement can be considered a very efficient convolution plus pooling layer that transforms an $N$-dimensional signal input into $n-$dimensional signal with an exponential compression. We then apply a classical neural network prediction head to the output of the circuit to construct a complete graph neural network. Since the circuit incorporates geometric structure through its graph connection-based approach, we present graph classification results for the benchmark datasets listed in TUDataset library. Using only [1-100] learnable parameters for the quantum circuit and minimal classical layers (1000-5000 parameters) in a generic setting, the obtained results are comparable to and in some cases better than many of the baseline results, particularly for the cases when geometric structure plays a significant role.         ",
    "url": "https://arxiv.org/abs/2507.05640",
    "authors": [
      "Ammar Daskin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  }
]