[
  {
    "id": "arXiv:2308.05106",
    "title": "Balancing Accuracy and Training Time in Federated Learning for Violence  Detection in Surveillance Videos: A Study of Neural Network Architectures",
    "abstract": "This paper presents an investigation into machine learning techniques for violence detection in videos and their adaptation to a federated learning context. The study includes experiments with spatio-temporal features extracted from benchmark video datasets, comparison of different methods, and proposal of a modified version of the \"Flow-Gated\" architecture called \"Diff-Gated.\" Additionally, various machine learning techniques, including super-convergence and transfer learning, are explored, and a method for adapting centralized datasets to a federated learning context is developed. The research achieves better accuracy results compared to state-of-the-art models by training the best violence detection model in a federated learning context. ",
    "url": "https://arxiv.org/abs/2308.05106",
    "authors": [
      "Pajon Quentin",
      "Serre Swan",
      "Wissocq Hugo",
      "Rabaud L\u00e9o",
      "Haidar Siba",
      "Yaacoub Antoun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05110",
    "title": "Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A  Case Study on Hemorrhagic Stroke",
    "abstract": "Stroke is a significant cause of mortality and morbidity, necessitating early predictive strategies to minimize risks. Traditional methods for evaluating patients, such as Acute Physiology and Chronic Health Evaluation (APACHE II, IV) and Simplified Acute Physiology Score III (SAPS III), have limited accuracy and interpretability. This paper proposes a novel approach: an interpretable, attention-based transformer model for early stroke mortality prediction. This model seeks to address the limitations of previous predictive models, providing both interpretability (providing clear, understandable explanations of the model) and fidelity (giving a truthful explanation of the model's dynamics from input to output). Furthermore, the study explores and compares fidelity and interpretability scores using Shapley values and attention-based scores to improve model explainability. The research objectives include designing an interpretable attention-based transformer model, evaluating its performance compared to existing models, and providing feature importance derived from the model. ",
    "url": "https://arxiv.org/abs/2308.05110",
    "authors": [
      "Qizhang Feng",
      "Jiayi Yuan",
      "Forhan Bin Emdad",
      "Karim Hanna",
      "Xia Hu",
      "Zhe He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05112",
    "title": "Explicifying Neural Implicit Fields for Efficient Dynamic Human Avatar  Modeling via a Neural Explicit Surface",
    "abstract": "This paper proposes a technique for efficiently modeling dynamic humans by explicifying the implicit neural fields via a Neural Explicit Surface (NES). Implicit neural fields have advantages over traditional explicit representations in modeling dynamic 3D content from sparse observations and effectively representing complex geometries and appearances. Implicit neural fields defined in 3D space, however, are expensive to render due to the need for dense sampling during volumetric rendering. Moreover, their memory efficiency can be further optimized when modeling sparse 3D space. To overcome these issues, the paper proposes utilizing Neural Explicit Surface (NES) to explicitly represent implicit neural fields, facilitating memory and computational efficiency. To achieve this, the paper creates a fully differentiable conversion between the implicit neural fields and the explicit rendering interface of NES, leveraging the strengths of both implicit and explicit approaches. This conversion enables effective training of the hybrid representation using implicit methods and efficient rendering by integrating the explicit rendering interface with a newly proposed rasterization-based neural renderer that only incurs a texture color query once for the initial ray interaction with the explicit surface, resulting in improved inference efficiency. NES describes dynamic human geometries with pose-dependent neural implicit surface deformation fields and their dynamic neural textures both in 2D space, which is a more memory-efficient alternative to traditional 3D methods, reducing redundancy and computational load. The comprehensive experiments show that NES performs similarly to previous 3D approaches, with greatly improved rendering speed and reduced memory cost. ",
    "url": "https://arxiv.org/abs/2308.05112",
    "authors": [
      "Ruiqi Zhang",
      "Jie Chen",
      "Qiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.05127",
    "title": "Data-Free Model Extraction Attacks in the Context of Object Detection",
    "abstract": "A significant number of machine learning models are vulnerable to model extraction attacks, which focus on stealing the models by using specially curated queries against the target model. This task is well accomplished by using part of the training data or a surrogate dataset to train a new model that mimics a target model in a white-box environment. In pragmatic situations, however, the target models are trained on private datasets that are inaccessible to the adversary. The data-free model extraction technique replaces this problem when it comes to using queries artificially curated by a generator similar to that used in Generative Adversarial Nets. We propose for the first time, to the best of our knowledge, an adversary black box attack extending to a regression problem for predicting bounding box coordinates in object detection. As part of our study, we found that defining a loss function and using a novel generator setup is one of the key aspects in extracting the target model. We find that the proposed model extraction method achieves significant results by using reasonable queries. The discovery of this object detection vulnerability will support future prospects for securing such models. ",
    "url": "https://arxiv.org/abs/2308.05127",
    "authors": [
      "Harshit Shah",
      "Aravindhan G",
      "Pavan Kulkarni",
      "Yuvaraj Govidarajulu",
      "Manojkumar Parmar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05140",
    "title": "Robust Object Modeling for Visual Tracking",
    "abstract": "Object modeling has become a core part of recent tracking frameworks. Current popular tackers use Transformer attention to extract the template feature separately or interactively with the search region. However, separate template learning lacks communication between the template and search regions, which brings difficulty in extracting discriminative target-oriented features. On the other hand, interactive template learning produces hybrid template features, which may introduce potential distractors to the template via the cluttered search regions. To enjoy the merits of both methods, we propose a robust object modeling framework for visual tracking (ROMTrack), which simultaneously models the inherent template and the hybrid template features. As a result, harmful distractors can be suppressed by combining the inherent features of target objects with search regions' guidance. Target-related features can also be extracted using the hybrid template, thus resulting in a more robust object modeling framework. To further enhance robustness, we present novel variation tokens to depict the ever-changing appearance of target objects. Variation tokens are adaptable to object deformation and appearance variations, which can boost overall performance with negligible computation. Experiments show that our ROMTrack sets a new state-of-the-art on multiple benchmarks. ",
    "url": "https://arxiv.org/abs/2308.05140",
    "authors": [
      "Yidong Cai",
      "Jie Liu",
      "Jie Tang",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05141",
    "title": "Sound propagation in realistic interactive 3D scenes with parameterized  sources using deep neural operators",
    "abstract": "We address the challenge of sound propagation simulations in $3$D virtual rooms with moving sources, which have applications in virtual/augmented reality, game audio, and spatial computing. Solutions to the wave equation can describe wave phenomena such as diffraction and interference. However, simulating them using conventional numerical discretization methods with hundreds of source and receiver positions is intractable, making stimulating a sound field with moving sources impractical. To overcome this limitation, we propose using deep operator networks to approximate linear wave-equation operators. This enables the rapid prediction of sound propagation in realistic 3D acoustic scenes with moving sources, achieving millisecond-scale computations. By learning a compact surrogate model, we avoid the offline calculation and storage of impulse responses for all relevant source/listener pairs. Our experiments, including various complex scene geometries, show good agreement with reference solutions, with root mean squared errors ranging from 0.02 Pa to 0.10 Pa. Notably, our method signifies a paradigm shift as no prior machine learning approach has achieved precise predictions of complete wave fields within realistic domains. We anticipate that our findings will drive further exploration of deep neural operator methods, advancing research in immersive user experiences within virtual environments. ",
    "url": "https://arxiv.org/abs/2308.05141",
    "authors": [
      "Nikolas Borrel-Jensen",
      "Somdatta Goswami",
      "Allan P. Engsig-Karup",
      "George Em Karniadakis",
      "Cheol-Ho Jeong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.05170",
    "title": "FPGA Resource-aware Structured Pruning for Real-Time Neural Networks",
    "abstract": "Neural networks achieve state-of-the-art performance in image classification, speech recognition, scientific analysis and many more application areas. With the ever-increasing need for faster computation and lower power consumption, driven by real-time systems and Internet-of-Things (IoT) devices, FPGAs have emerged as suitable devices for deep learning inference. Due to the high computational complexity and memory footprint of neural networks, various compression techniques, such as pruning, quantization and knowledge distillation, have been proposed in literature. Pruning sparsifies a neural network, reducing the number of multiplications and memory. However, pruning often fails to capture properties of the underlying hardware, causing unstructured sparsity and load-balance inefficiency, thus bottlenecking resource improvements. We propose a hardware-centric formulation of pruning, by formulating it as a knapsack problem with resource-aware tensor structures. The primary emphasis is on real-time inference, with latencies in the order of 1$\\mu$s, accelerated with hls4ml, an open-source framework for deep learning inference on FPGAs. Evaluated on a range of tasks, including real-time particle classification at CERN's Large Hadron Collider and fast image classification, the proposed method achieves a reduction ranging between 55% and 92% in the utilization of digital signal processing blocks (DSP) and up to 81% in block memory (BRAM) utilization. ",
    "url": "https://arxiv.org/abs/2308.05170",
    "authors": [
      "Benjamin Ramhorst",
      "George A. Constantinides",
      "Vladimir Loncar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05187",
    "title": "Exploring the Interplay of Interference and Queues in Unlicensed  Spectrum Bands for UAV Networks",
    "abstract": "In this paper, we present an analytical framework to explore the interplay of signal interference and transmission queue management, and their impacts on the performance of unmanned aerial vehicles (UAVs) when operating in the unlicensed spectrum bands. In particular, we develop a comprehensive framework to investigate the impact of other interference links on the UAV as it communicates with the ground users. To this end, we provide closed-form expressions for packet drop probabilities in the queue due to buffer overflow or large queuing delay, which are expressed in terms of a transmission policy as a function of the channel fading threshold $\\beta$. The overall packet loss caused either by interference signals or queuing packet drop is obtained, which, in turn, yields in obtaining the expected throughput performance. Through extensive numerical results, we investigate the impact of the channel fading threshold $\\beta$, which plays an important role in balancing the trade-offs between packet loss due to queue drop or transmission error due to large interference levels. ",
    "url": "https://arxiv.org/abs/2308.05187",
    "authors": [
      "Masoud Ghazikor",
      "Keenan Roach",
      "Kenny Cheung",
      "Morteza Hashemi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.05194",
    "title": "Evaluating Pedestrian Trajectory Prediction Methods for the Application  in Autonomous Driving",
    "abstract": "In this paper, the state of the art in the field of pedestrian trajectory prediction is evaluated alongside the constant velocity model (CVM) with respect to its applicability in autonomous vehicles. The evaluation is conducted on the widely-used ETH/UCY dataset where the Average Displacement Error (ADE) and the Final Displacement Error (FDE) are reported. To align with requirements in real-world applications, modifications are made to the input features of the initially proposed models. An ablation study is conducted to examine the influence of the observed motion history on the prediction performance, thereby establishing a better understanding of its impact. Additionally, the inference time of each model is measured to evaluate the scalability of each model when confronted with varying amounts of agents. The results demonstrate that simple models remain competitive when generating single trajectories, and certain features commonly thought of as useful have little impact on the overall performance across different architectures. Based on these findings, recommendations are proposed to guide the future development of trajectory prediction algorithms. ",
    "url": "https://arxiv.org/abs/2308.05194",
    "authors": [
      "Nico Uhlemann",
      "Felix Fent",
      "Markus Lienkamp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05234",
    "title": "Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection  in Autonomous Driving",
    "abstract": "Environmental perception is a key element of autonomous driving because the information received from the perception module influences core driving decisions. An outstanding challenge in real-time perception for autonomous driving lies in finding the best trade-off between detection quality and latency. Major constraints on both computation and power have to be taken into account for real-time perception in autonomous vehicles. Larger object detection models tend to produce the best results, but are also slower at runtime. Since the most accurate detectors cannot run in real-time locally, we investigate the possibility of offloading computation to edge and cloud platforms, which are less resource-constrained. We create a synthetic dataset to train object detection models and evaluate different offloading strategies. Using real hardware and network simulations, we compare different trade-offs between prediction quality and end-to-end delay. Since sending raw frames over the network implies additional transmission delays, we also explore the use of JPEG and H.265 compression at varying qualities and measure their impact on prediction metrics. We show that models with adequate compression can be run in real-time on the cloud while outperforming local detection performance. ",
    "url": "https://arxiv.org/abs/2308.05234",
    "authors": [
      "Faisal Hawlader",
      "Fran\u00e7ois Robinet",
      "Rapha\u00ebl Frank"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.05247",
    "title": "TUBERAIDER: Attributing Coordinated Hate Attacks on YouTube Videos to  their Source Communities",
    "abstract": "Alas, coordinated hate attacks, or raids, are becoming increasingly common online. In a nutshell, these are perpetrated by a group of aggressors who organize and coordinate operations on a platform (e.g., 4chan) to target victims on another community (e.g., YouTube). In this paper, we focus on attributing raids to their source community, paving the way for moderation approaches that take the context (and potentially the motivation) of an attack into consideration. We present TUBERAIDER, an attribution system achieving over 75% accuracy in detecting and attributing coordinated hate attacks on YouTube videos. We instantiate it using links to YouTube videos shared on 4chan's /pol/ board, r/The_Donald, and 16 Incels-related subreddits. We use a peak detector to identify a rise in the comment activity of a YouTube video, which signals that an attack may be occurring. We then train a machine learning classifier based on the community language (i.e., TF-IDF scores of relevant keywords) to perform the attribution. We test TUBERAIDER in the wild and present a few case studies of actual aggression attacks identified by it to showcase its effectiveness. ",
    "url": "https://arxiv.org/abs/2308.05247",
    "authors": [
      "Mohammad Hammas Saeed",
      "Kostantinos Papadamou",
      "Jeremy Blackburn",
      "Emiliano De Cristofaro",
      "Gianluca Stringhini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.05254",
    "title": "Data-driven Intra-Autonomous Systems Graph Generator",
    "abstract": "This paper introduces a novel deep-learning based generator of synthetic graphs that represent intra-Autonomous System (AS) in the Internet, named Deep-generative graphs for the Internet (DGGI). It also presents a novel massive dataset of real intra-AS graphs extracted from the project Internet Topology Data Kit (ITDK), called Internet Graphs (IGraphs). To create IGraphs, the Filtered Recurrent Multi-level (FRM) algorithm for community extraction was developed. It is shown that DGGI creates synthetic graphs which accurately reproduce the properties of centrality, clustering, assortativity, and node degree. The DGGI generator overperforms existing Internet topology generators. On average, DGGI improves the Maximum Mean Discrepancy (MMD) metric 84.4%, 95.1%, 97.9%, and 94.7% for assortativity, betweenness, clustering, and node degree, respectively. ",
    "url": "https://arxiv.org/abs/2308.05254",
    "authors": [
      "Caio Vinicius Dadauto",
      "Nelson Luis Saldanha da Fonseca",
      "Ricardo da Silva Torres"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05256",
    "title": "Social Network Analysis and Validation of an Agent-Based Model",
    "abstract": "Agent-based models (ABMs) simulate the formation and evolution of social processes at a fundamental level by decoupling agent behavior from global observations. In the case where ABM networks evolve over time as a result of (or in conjunction with) agent states, there is a need for understanding the relationship between the dynamic processes and network structure. Social networks provide a natural set of tools for understanding the emergent relationships of these systems. This work examines the utility of a collection of network comparison methods for the purpose of tracking network changes in an ABM over time or between model parameters. Among the techniques examined is a novel graph pseudometric based on heat content asymptotics, which have been shown to distinguish many isospectral graphs which are not isomorphic. Additionally, we establish the use of observations about real-world networks from network science (e.g. fat-tailed degree distribution, small-world property) for ABM validation in the case where empirical population data is unavailable. These methods are all demonstrated on systematic perturbations of an original model simulating the formation of friendships in a population of 20,000 agents in Cincinnati, OH. ",
    "url": "https://arxiv.org/abs/2308.05256",
    "authors": [
      "Karleigh Pine",
      "Joel Klipfel",
      "Jared Bennett",
      "Nathaniel Bade",
      "Christian Manasseh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Multiagent Systems (cs.MA)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2308.05257",
    "title": "Advancing Early Detection of Virus Yellows: Developing a Hybrid  Convolutional Neural Network for Automatic Aphid Counting in Sugar Beet  Fields",
    "abstract": "Aphids are efficient vectors to transmit virus yellows in sugar beet fields. Timely monitoring and control of their populations are thus critical to prevent the large-scale outbreak of virus yellows. However, the manual counting of aphids, which is the most common practice, is labor-intensive and time-consuming. Additionally, two of the biggest challenges in aphid counting are that aphids are small objects and their density distributions are varied in different areas of the field. To address these challenges, we proposed a hybrid automatic aphid counting network architecture which integrates the detection network and the density map estimation network. When the distribution density of aphids is low, it utilizes an improved Yolov5 to count aphids. Conversely, when the distribution density of aphids is high, its witches to CSRNet to count aphids. To the best of our knowledge, this is the first framework integrating the detection network and the density map estimation network for counting tasks. Through comparison experiments of counting aphids, it verified that our proposed approach outperforms all other methods in counting aphids. It achieved the lowest MAE and RMSE values for both the standard and high-density aphid datasets: 2.93 and 4.01 (standard), and 34.19 and 38.66 (high-density), respectively. Moreover, the AP of the improved Yolov5 is 5% higher than that of the original Yolov5. Especially for extremely small aphids and densely distributed aphids, the detection performance of the improved Yolov5 is significantly better than the original Yolov5. This work provides an effective early warning for the virus yellows risk caused by aphids in sugar beet fields, offering protection for sugar beet growth and ensuring sugar beet yield. The datasets and project code are released at: https://github.com/JunfengGaolab/Counting-Aphids. ",
    "url": "https://arxiv.org/abs/2308.05257",
    "authors": [
      "Xumin Gao",
      "Wenxin Xue",
      "Callum Lennox",
      "Mark Stevens",
      "Junfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05264",
    "title": "TrainFors: A Large Benchmark Training Dataset for Image Manipulation  Detection and Localization",
    "abstract": "The evaluation datasets and metrics for image manipulation detection and localization (IMDL) research have been standardized. But the training dataset for such a task is still nonstandard. Previous researchers have used unconventional and deviating datasets to train neural networks for detecting image forgeries and localizing pixel maps of manipulated regions. For a fair comparison, the training set, test set, and evaluation metrics should be persistent. Hence, comparing the existing methods may not seem fair as the results depend heavily on the training datasets as well as the model architecture. Moreover, none of the previous works release the synthetic training dataset used for the IMDL task. We propose a standardized benchmark training dataset for image splicing, copy-move forgery, removal forgery, and image enhancement forgery. Furthermore, we identify the problems with the existing IMDL datasets and propose the required modifications. We also train the state-of-the-art IMDL methods on our proposed TrainFors1 dataset for a fair evaluation and report the actual performance of these methods under similar conditions. ",
    "url": "https://arxiv.org/abs/2308.05264",
    "authors": [
      "Soumyaroop Nandi",
      "Prem Natarajan",
      "Wael Abd-Almageed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05274",
    "title": "Local-Global Information Interaction Debiasing for Dynamic Scene Graph  Generation",
    "abstract": "The task of dynamic scene graph generation (DynSGG) aims to generate scene graphs for given videos, which involves modeling the spatial-temporal information in the video. However, due to the long-tailed distribution of samples in the dataset, previous DynSGG models fail to predict the tail predicates. We argue that this phenomenon is due to previous methods that only pay attention to the local spatial-temporal information and neglect the consistency of multiple frames. To solve this problem, we propose a novel DynSGG model based on multi-task learning, DynSGG-MTL, which introduces the local interaction information and global human-action interaction information. The interaction between objects and frame features makes the model more fully understand the visual context of the single image. Long-temporal human actions supervise the model to generate multiple scene graphs that conform to the global constraints and avoid the model being unable to learn the tail predicates. Extensive experiments on Action Genome dataset demonstrate the efficacy of our proposed framework, which not only improves the dynamic scene graph generation but also alleviates the long-tail problem. ",
    "url": "https://arxiv.org/abs/2308.05274",
    "authors": [
      "Xinyu Lyu",
      "Jingwei Liu",
      "Yuyu Guo",
      "Lianli Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05275",
    "title": "Cross-heterogeneity Graph Few-shot Learning",
    "abstract": "In recent years, heterogeneous graph few-shot learning has been proposed to address the label sparsity issue in heterogeneous graphs (HGs), which contain various types of nodes and edges. The existing methods have achieved good performance by transferring generalized knowledge extracted from rich-labeled classes in source HG(s) to few-labeled classes in a target HG. However, these methods only consider the single-heterogeneity scenario where the source and target HGs share a fixed set of node/edge types, ignoring the more general scenario of cross-heterogeneity, where each HG can have a different and non-fixed set of node/edge types. To this end, we focus on the unexplored cross-heterogeneity scenario and propose a novel model for Cross-heterogeneity Graph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns to capture heterogeneous information and propose a multi-view heterogeneous graph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose a score module to measure the informativeness of labeled samples and determine the transferability of each source HG. Finally, by integrating MHGN and the score module into a meta-learning mechanism, CGFL can effectively transfer generalized knowledge to predict new classes with few-labeled data. Extensive experiments on four real-world datasets have demonstrated the superior performance of CGFL over the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2308.05275",
    "authors": [
      "Pengfei Ding",
      "Yan Wang",
      "Guanfeng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05281",
    "title": "Investigating disaster response through social media data and the  Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S.  wildfire season",
    "abstract": "Effective disaster response is critical for affected communities. Responders and decision-makers would benefit from reliable, timely measures of the issues impacting their communities during a disaster, and social media offers a potentially rich data source. Social media can reflect public concerns and demands during a disaster, offering valuable insights for decision-makers to understand evolving situations and optimize resource allocation. We used Bidirectional Encoder Representations from Transformers (BERT) topic modeling to cluster topics from Twitter data. Then, we conducted a temporal-spatial analysis to examine the distribution of these topics across different regions during the 2020 western U.S. wildfire season. Our results show that Twitter users mainly focused on three topics:\"health impact,\" \"damage,\" and \"evacuation.\" We used the Susceptible-Infected-Recovered (SIR) theory to explore the magnitude and velocity of topic diffusion on Twitter. The results displayed a clear relationship between topic trends and wildfire propagation patterns. The estimated parameters obtained from the SIR model in selected cities revealed that residents exhibited a high level of several concerns during the wildfire. Our study details how the SIR model and topic modeling using social media data can provide decision-makers with a quantitative approach to measure disaster response and support their decision-making processes. ",
    "url": "https://arxiv.org/abs/2308.05281",
    "authors": [
      "Zihui Ma",
      "Lingyao Li",
      "Libby Hemphill",
      "Gregory B. Baecher"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05286",
    "title": "Informative Scene Graph Generation via Debiasing",
    "abstract": "Scene graph generation aims to detect visual relationship triplets, (subject, predicate, object). Due to biases in data, current models tend to predict common predicates, e.g. \"on\" and \"at\", instead of informative ones, e.g. \"standing on\" and \"looking at\". This tendency results in the loss of precise information and overall performance. If a model only uses \"stone on road\" rather than \"stone blocking road\" to describe an image, it may be a grave misunderstanding. We argue that this phenomenon is caused by two imbalances: semantic space level imbalance and training sample level imbalance. For this problem, we propose DB-SGG, an effective framework based on debiasing but not the conventional distribution fitting. It integrates two components: Semantic Debiasing (SD) and Balanced Predicate Learning (BPL), for these imbalances. SD utilizes a confusion matrix and a bipartite graph to construct predicate relationships. BPL adopts a random undersampling strategy and an ambiguity removing strategy to focus on informative predicates. Benefiting from the model-agnostic process, our method can be easily applied to SGG models and outperforms Transformer by 136.3%, 119.5%, and 122.6% on mR@20 at three SGG sub-tasks on the SGG-VG dataset. Our method is further verified on another complex SGG dataset (SGG-GQA) and two downstream tasks (sentence-to-graph retrieval and image captioning). ",
    "url": "https://arxiv.org/abs/2308.05286",
    "authors": [
      "Lianli Gao",
      "Xinyu Lyu",
      "Yuyu Guo",
      "Yuxuan Hu",
      "Yuan-Fang Li",
      "Lu Xu",
      "Heng Tao Shen",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05309",
    "title": "Homophily-enhanced Structure Learning for Graph Clustering",
    "abstract": "Graph clustering is a fundamental task in graph analysis, and recent advances in utilizing graph neural networks (GNNs) have shown impressive results. Despite the success of existing GNN-based graph clustering methods, they often overlook the quality of graph structure, which is inherent in real-world graphs due to their sparse and multifarious nature, leading to subpar performance. Graph structure learning allows refining the input graph by adding missing links and removing spurious connections. However, previous endeavors in graph structure learning have predominantly centered around supervised settings, and cannot be directly applied to our specific clustering tasks due to the absence of ground-truth labels. To bridge the gap, we propose a novel method called \\textbf{ho}mophily-enhanced structure \\textbf{le}arning for graph clustering (HoLe). Our motivation stems from the observation that subtly enhancing the degree of homophily within the graph structure can significantly improve GNNs and clustering outcomes. To realize this objective, we develop two clustering-oriented structure learning modules, i.e., hierarchical correlation estimation and cluster-aware sparsification. The former module enables a more accurate estimation of pairwise node relationships by leveraging guidance from latent and clustering spaces, while the latter one generates a sparsified structure based on the similarity matrix and clustering assignments. Additionally, we devise a joint optimization approach alternating between training the homophily-enhanced structure learning and GNN-based clustering, thereby enforcing their reciprocal effects. Extensive experiments on seven benchmark datasets of various types and scales, across a range of clustering metrics, demonstrate the superiority of HoLe against state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2308.05309",
    "authors": [
      "Ming Gu",
      "Gaoming Yang",
      "Sheng Zhou",
      "Ning Ma",
      "Jiawei Chen",
      "Qiaoyu Tan",
      "Meihan Liu",
      "Jiajun Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.05314",
    "title": "Deep Semantic Graph Matching for Large-scale Outdoor Point Clouds  Registration",
    "abstract": "The current point cloud registration methods are mainly based on geometric information and usually ignore the semantic information in the point clouds. In this paper, we treat the point cloud registration problem as semantic instance matching and registration task, and propose a deep semantic graph matching method for large-scale outdoor point cloud registration. Firstly, the semantic category labels of 3D point clouds are obtained by utilizing large-scale point cloud semantic segmentation network. The adjacent points with the same category labels are then clustered together by using Euclidean clustering algorithm to obtain the semantic instances. Secondly, the semantic adjacency graph is constructed based on the spatial adjacency relation of semantic instances. Three kinds of high-dimensional features including geometric shape features, semantic categorical features and spatial distribution features are learned through graph convolutional network, and enhanced based on attention mechanism. Thirdly, the semantic instance matching problem is modeled as an optimal transport problem, and solved through an optimal matching layer. Finally, according to the matched semantic instances, the geometric transformation matrix between two point clouds is first obtained by SVD algorithm and then refined by ICP algorithm. The experiments are cconducted on the KITTI Odometry dataset, and the average relative translation error and average relative rotation error of the proposed method are 6.6cm and 0.229{\\deg} respectively. ",
    "url": "https://arxiv.org/abs/2308.05314",
    "authors": [
      "Shaocong Liu",
      "Tao Wang",
      "Yan Zhang",
      "Ruqin Zhou",
      "Li Li",
      "Chenguang Dai",
      "Yongsheng Zhang",
      "Hanyun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05317",
    "title": "Few-Shot Data-to-Text Generation via Unified Representation and  Multi-Source Learning",
    "abstract": "We present a novel approach for structured data-to-text generation that addresses the limitations of existing methods that primarily focus on specific types of structured data. Our proposed method aims to improve performance in multi-task training, zero-shot and few-shot scenarios by providing a unified representation that can handle various forms of structured data such as tables, knowledge graph triples, and meaning representations. We demonstrate that our proposed approach can effectively adapt to new structured forms, and can improve performance in comparison to current methods. For example, our method resulted in a 66% improvement in zero-shot BLEU scores when transferring models trained on table inputs to a knowledge graph dataset. Our proposed method is an important step towards a more general data-to-text generation framework. ",
    "url": "https://arxiv.org/abs/2308.05317",
    "authors": [
      "Alexander Hanbo Li",
      "Mingyue Shang",
      "Evangelia Spiliopoulou",
      "Jie Ma",
      "Patrick Ng",
      "Zhiguo Wang",
      "Bonan Min",
      "William Wang",
      "Kathleen McKeown",
      "Vittorio Castelli",
      "Dan Roth",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.05318",
    "title": "RLSAC: Reinforcement Learning enhanced Sample Consensus for End-to-End  Robust Estimation",
    "abstract": "Robust estimation is a crucial and still challenging task, which involves estimating model parameters in noisy environments. Although conventional sampling consensus-based algorithms sample several times to achieve robustness, these algorithms cannot use data features and historical information effectively. In this paper, we propose RLSAC, a novel Reinforcement Learning enhanced SAmple Consensus framework for end-to-end robust estimation. RLSAC employs a graph neural network to utilize both data and memory features to guide exploring directions for sampling the next minimum set. The feedback of downstream tasks serves as the reward for unsupervised training. Therefore, RLSAC can avoid differentiating to learn the features and the feedback of downstream tasks for end-to-end robust estimation. In addition, RLSAC integrates a state transition module that encodes both data and memory features. Our experimental results demonstrate that RLSAC can learn from features to gradually explore a better hypothesis. Through analysis, it is apparent that RLSAC can be easily transferred to other sampling consensus-based robust estimation tasks. To the best of our knowledge, RLSAC is also the first method that uses reinforcement learning to sample consensus for end-to-end robust estimation. We release our codes at https://github.com/IRMVLab/RLSAC. ",
    "url": "https://arxiv.org/abs/2308.05318",
    "authors": [
      "Chang Nie",
      "Guangming Wang",
      "Zhe Liu",
      "Luca Cavalli",
      "Marc Pollefeys",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05320",
    "title": "Adv-Inpainting: Generating Natural and Transferable Adversarial Patch  via Attention-guided Feature Fusion",
    "abstract": "The rudimentary adversarial attacks utilize additive noise to attack facial recognition (FR) models. However, because manipulating the total face is impractical in the physical setting, most real-world FR attacks are based on adversarial patches, which limit perturbations to a small area. Previous adversarial patch attacks often resulted in unnatural patterns and clear boundaries that were easily noticeable. In this paper, we argue that generating adversarial patches with plausible content can result in stronger transferability than using additive noise or directly sampling from the latent space. To generate natural-looking and highly transferable adversarial patches, we propose an innovative two-stage coarse-to-fine attack framework called Adv-Inpainting. In the first stage, we propose an attention-guided StyleGAN (Att-StyleGAN) that adaptively combines texture and identity features based on the attention map to generate high-transferable and natural adversarial patches. In the second stage, we design a refinement network with a new boundary variance loss to further improve the coherence between the patch and its surrounding area. Experiment results demonstrate that Adv-Inpainting is stealthy and can produce adversarial patches with stronger transferability and improved visual quality than previous adversarial patch attacks. ",
    "url": "https://arxiv.org/abs/2308.05320",
    "authors": [
      "Yanjie Li",
      "Mingxing Duan",
      "Bin Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05322",
    "title": "DegUIL: Degree-aware Graph Neural Networks for Long-tailed User Identity  Linkage",
    "abstract": "User identity linkage (UIL), matching accounts of a person on different social networks, is a fundamental task in cross-network data mining. Recent works have achieved promising results by exploiting graph neural networks (GNNs) to capture network structure. However, they rarely analyze the realistic node-level bottlenecks that hinder UIL's performance. First, node degrees in a graph vary widely and are long-tailed. A significant fraction of tail nodes with small degrees are underrepresented due to limited structural information, degrading linkage performance seriously. The second bottleneck usually overlooked is super head nodes. It is commonly accepted that head nodes perform well. However, we find that some of them with super high degrees also have difficulty aligning counterparts, due to noise introduced by the randomness of following friends in real-world social graphs. In pursuit of learning ideal representations for these two groups of nodes, this paper proposes a degree-aware model named DegUIL to narrow the degree gap. To this end, our model complements missing neighborhoods for tail nodes and discards redundant structural information for super head nodes in embeddings respectively. Specifically, the neighboring bias is predicted and corrected locally by two modules, which are trained using the knowledge from structurally adequate head nodes. As a result, ideal neighborhoods are obtained for meaningful aggregation in GNNs. Extensive experiments demonstrate the superiority of our model. Our data and code can be found at https://github.com/Longmeix/DegUIL. ",
    "url": "https://arxiv.org/abs/2308.05322",
    "authors": [
      "Meixiu Long",
      "Siyuan Chen",
      "Xin Du",
      "Jiahai Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.05323",
    "title": "Universal Performance Bounds for Joint Self-Interference Cancellation  and Data Detection in Full-Duplex Communications",
    "abstract": "This paper studies the joint digital self-interference (SI) cancellation and data detection in an orthogonal-frequency-division-multiplexing (OFDM) full-duplex (FD) system, considering the effect of phase noise introduced by the oscillators at both the local transmitter and receiver. In particular, an universal iterative two-stage joint SI cancellation and data detection framework is considered and its performance bound independent of any specific estimation and detection methods is derived. First, the channel and phase noise estimation mean square error (MSE) lower bounds in each iteration are derived by analyzing the Fisher information of the received signal. Then, by substituting the derived MSE lower bound into the SINR expression, which is related to the channel and phase noise estimation MSE, the SINR upper bound in each iteration is computed. Finally, by exploiting the SINR upper bound and the transition information of the detection errors between two adjacent iterations, the universal bit error rate (BER) lower bound for data detection is derived. ",
    "url": "https://arxiv.org/abs/2308.05323",
    "authors": [
      "Meng He",
      "Chuan Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.05333",
    "title": "3D Quasiconformal Representation and Solver",
    "abstract": "The analysis of mapping relationships and distortions in multidimensional data poses a significant challenge in contemporary research. While Beltrami coefficients offer a precise description of distortions in two-dimensional mappings, current tools lack this capability in the context of three-dimensional space. This paper presents a novel approach: a 3D quasiconformal representation that captures the local dilation of 3D mappings, along with an algorithm that establishes a connection between this representation and the corresponding mapping. Experimental results showcase the algorithm's effectiveness in eliminating foldings in 3D mappings, as well as in mapping reconstruction and generation. These features bear a resemblance to the 2D Linear Beltrami Solver technique. The work presented in this paper offers a promising solution for the precise analysis and adjustment of distortions in 3D data and mappings. ",
    "url": "https://arxiv.org/abs/2308.05333",
    "authors": [
      "Qiguang Chen",
      "Lok Ming Lui"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2308.05344",
    "title": "Prostate Age Gap (PAG): An MRI surrogate marker of aging for prostate  cancer detection",
    "abstract": "Background: Prostate cancer (PC) MRI-based risk calculators are commonly based on biological (e.g. PSA), MRI markers (e.g. volume), and patient age. Whilst patient age measures the amount of years an individual has existed, biological age (BA) might better reflect the physiology of an individual. However, surrogates from prostate MRI and linkage with clinically significant PC (csPC) remain to be explored. Purpose: To obtain and evaluate Prostate Age Gap (PAG) as an MRI marker tool for csPC risk. Study type: Retrospective. Population: A total of 7243 prostate MRI slices from 468 participants who had undergone prostate biopsies. A deep learning model was trained on 3223 MRI slices cropped around the gland from 81 low-grade PC (ncsPC, Gleason score <=6) and 131 negative cases and tested on the remaining 256 participants. Assessment: Chronological age was defined as the age of the participant at the time of the visit and used to train the deep learning model to predict the age of the patient. Following, we obtained PAG, defined as the model predicted age minus the patient's chronological age. Multivariate logistic regression models were used to estimate the association through odds ratio (OR) and predictive value of PAG and compared against PSA levels and PI-RADS>=3. Statistical tests: T-test, Mann-Whitney U test, Permutation test and ROC curve analysis. Results: The multivariate adjusted model showed a significant difference in the odds of clinically significant PC (csPC, Gleason score >=7) (OR =3.78, 95% confidence interval (CI):2.32-6.16, P <.001). PAG showed a better predictive ability when compared to PI-RADS>=3 and adjusted by other risk factors, including PSA levels: AUC =0.981 vs AUC =0.704, p<.001. Conclusion: PAG was significantly associated with the risk of clinically significant PC and outperformed other well-established PC risk factors. ",
    "url": "https://arxiv.org/abs/2308.05344",
    "authors": [
      "Alvaro Fernandez-Quilez",
      "Tobias Nordstr\u00f6m",
      "Fredrik J\u00e4derling",
      "Svein Reidar Kjosavik",
      "Martin Eklund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05353",
    "title": "Preemptive Detection of Fake Accounts on Social Networks via Multi-Class  Preferential Attachment Classifiers",
    "abstract": "In this paper, we describe a new algorithm called Preferential Attachment k-class Classifier (PreAttacK) for detecting fake accounts in a social network. Recently, several algorithms have obtained high accuracy on this problem. However, they have done so by relying on information about fake accounts' friendships or the content they share with others--the very things we seek to prevent. PreAttacK represents a significant departure from these approaches. We provide some of the first detailed distributional analyses of how new fake (and real) accounts first attempt to request friends after joining a major network (Facebook). We show that even before a new account has made friends or shared content, these initial friend request behaviors evoke a natural multi-class extension of the canonical Preferential Attachment model of social network growth. We use this model to derive a new algorithm, PreAttacK. We prove that in relevant problem instances, PreAttacK near-optimally approximates the posterior probability that a new account is fake under this multi-class Preferential Attachment model of new accounts' (not-yet-answered) friend requests. These are the first provable guarantees for fake account detection that apply to new users, and that do not require strong homophily assumptions. This principled approach also makes PreAttacK the only algorithm with provable guarantees that obtains state-of-the-art performance on new users on the global Facebook network, where it converges to AUC=0.9 after new users send + receive a total of just 20 not-yet-answered friend requests. For comparison, state-of-the-art benchmarks do not obtain this AUC even after observing additional data on new users' first 100 friend requests. Thus, unlike mainstream algorithms, PreAttacK converges before the median new fake account has made a single friendship (accepted friend request) with a human. ",
    "url": "https://arxiv.org/abs/2308.05353",
    "authors": [
      "Adam Breuer",
      "Nazanin Khosravani",
      "Michael Tingley",
      "Bradford Cottel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05355",
    "title": "TCSloT: Text Guided 3D Context and Slope Aware Triple Network for Dental  Implant Position Prediction",
    "abstract": "In implant prosthesis treatment, the surgical guide of implant is used to ensure accurate implantation. However, such design heavily relies on the manual location of the implant position. When deep neural network has been proposed to assist the dentist in locating the implant position, most of them take a single slice as input, which do not fully explore 3D contextual information and ignoring the influence of implant slope. In this paper, we design a Text Guided 3D Context and Slope Aware Triple Network (TCSloT) which enables the perception of contextual information from multiple adjacent slices and awareness of variation of implant slopes. A Texture Variation Perception (TVP) module is correspondingly elaborated to process the multiple slices and capture the texture variation among slices and a Slope-Aware Loss (SAL) is proposed to dynamically assign varying weights for the regression head. Additionally, we design a conditional text guidance (CTG) module to integrate the text condition (i.e., left, middle and right) from the CLIP for assisting the implant position prediction. Extensive experiments on a dental implant dataset through five-fold cross-validation demonstrated that the proposed TCSloT achieves superior performance than existing methods. ",
    "url": "https://arxiv.org/abs/2308.05355",
    "authors": [
      "Xinquan Yang",
      "Jinheng Xie",
      "Xuechen Li",
      "Xuguang Li",
      "Linlin Shen",
      "Yongqiang Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05370",
    "title": "Co-movement Pattern Mining from Videos",
    "abstract": "Co-movement pattern mining from GPS trajectories has been an intriguing subject in spatial-temporal data mining. In this paper, we extend this research line by migrating the data source from GPS sensors to surveillance cameras, and presenting the first investigation into co-movement pattern mining from videos. We formulate the new problem, re-define the spatial-temporal proximity constraints from cameras deployed in a road network, and theoretically prove its hardness. Due to the lack of readily applicable solutions, we adapt existing techniques and propose two competitive baselines using Apriori-based enumerator and CMC algorithm, respectively. As the principal technical contributions, we introduce a novel index called temporal-cluster suffix tree (TCS-tree), which performs two-level temporal clustering within each camera and constructs a suffix tree from the resulting clusters. Moreover, we present a sequence-ahead pruning framework based on TCS-tree, which allows for the simultaneous leverage of all pattern constraints to filter candidate paths. Finally, to reduce verification cost on the candidate paths, we propose a sliding-window based co-movement pattern enumeration strategy and a hashing-based dominance eliminator, both of which are effective in avoiding redundant operations. We conduct extensive experiments for scalability and effectiveness analysis. Our results validate the efficiency of the proposed index and mining algorithm, which runs remarkably faster than the two baseline methods. Additionally, we construct a video database with 1169 cameras and perform an end-to-end pipeline analysis to study the performance gap between GPS-driven and video-driven methods. Our results demonstrate that the derived patterns from the video-driven approach are similar to those derived from groundtruth trajectories, providing evidence of its effectiveness. ",
    "url": "https://arxiv.org/abs/2308.05370",
    "authors": [
      "Dongxiang Zhang",
      "Teng Ma",
      "Junnan Hu",
      "Yijun Bei",
      "Kian-Lee Tan",
      "Gang Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2308.05379",
    "title": "Beyond Semantics: Learning a Behavior Augmented Relevance Model with  Self-supervised Learning",
    "abstract": "Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robustness of BARL-ASe by strengthening representation and logit learning. Furthermore, we discuss how to deal with the long-tail query-item matching of the mini apps search scenario of Alipay practically. Experiments on real-world industry data and online A/B testing demonstrate our proposal achieves promising performance with low latency. ",
    "url": "https://arxiv.org/abs/2308.05379",
    "authors": [
      "Zeyuan Chen",
      "Wei Chen",
      "Jia Xu",
      "Zhongyi Liu",
      "Wei Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05384",
    "title": "Beyond Deep Reinforcement Learning: A Tutorial on Generative Diffusion  Models in Network Optimization",
    "abstract": "Generative Diffusion Models (GDMs) have emerged as a transformative force in the realm of Generative Artificial Intelligence (GAI), demonstrating their versatility and efficacy across a variety of applications. The ability to model complex data distributions and generate high-quality samples has made GDMs particularly effective in tasks such as image generation and reinforcement learning. Furthermore, their iterative nature, which involves a series of noise addition and denoising steps, is a powerful and unique approach to learning and generating data. This paper serves as a comprehensive tutorial on applying GDMs in network optimization tasks. We delve into the strengths of GDMs, emphasizing their wide applicability across various domains, such as vision, text, and audio generation.We detail how GDMs can be effectively harnessed to solve complex optimization problems inherent in networks. The paper first provides a basic background of GDMs and their applications in network optimization. This is followed by a series of case studies, showcasing the integration of GDMs with Deep Reinforcement Learning (DRL), incentive mechanism design, Semantic Communications (SemCom), Internet of Vehicles (IoV) networks, etc. These case studies underscore the practicality and efficacy of GDMs in real-world scenarios, offering insights into network design. We conclude with a discussion on potential future directions for GDM research and applications, providing major insights into how they can continue to shape the future of network optimization. ",
    "url": "https://arxiv.org/abs/2308.05384",
    "authors": [
      "Hongyang Du",
      "Ruichen Zhang",
      "Yinqiu Liu",
      "Jiacheng Wang",
      "Yijing Lin",
      "Zonghang Li",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Shuguang Cui",
      "Bo Ai",
      "Haibo Zhou",
      "Dong In Kim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.05387",
    "title": "HGDNet: A Height-Hierarchy Guided Dual-Decoder Network for Single View  Building Extraction and Height Estimation",
    "abstract": "Unifying the correlative single-view satellite image building extraction and height estimation tasks indicates a promising way to share representations and acquire generalist model for large-scale urban 3D reconstruction. However, the common spatial misalignment between building footprints and stereo-reconstructed nDSM height labels incurs degraded performance on both tasks. To address this issue, we propose a Height-hierarchy Guided Dual-decoder Network (HGDNet) to estimate building height. Under the guidance of synthesized discrete height-hierarchy nDSM, auxiliary height-hierarchical building extraction branch enhance the height estimation branch with implicit constraints, yielding an accuracy improvement of more than 6% on the DFC 2023 track2 dataset. Additional two-stage cascade architecture is adopted to achieve more accurate building extraction. Experiments on the DFC 2023 Track 2 dataset shows the superiority of the proposed method in building height estimation ({\\delta}1:0.8012), instance extraction (AP50:0.7730), and the final average score 0.7871 ranks in the first place in test phase. ",
    "url": "https://arxiv.org/abs/2308.05387",
    "authors": [
      "Chaoran Lu",
      "Ningning Cao",
      "Pan Zhang",
      "Ting Liu",
      "Baochai Peng",
      "Guozhang Liu",
      "Mengke Yuan",
      "Sen Zhang",
      "Simin Huang",
      "Tao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05394",
    "title": "Robust Localization with Visual-Inertial Odometry Constraints for  Markerless Mobile AR",
    "abstract": "Visual Inertial Odometry (VIO) is an essential component of modern Augmented Reality (AR) applications. However, VIO only tracks the relative pose of the device, leading to drift over time. Absolute pose estimation methods infer the device's absolute pose, but their accuracy depends on the input quality. This paper introduces VIO-APR, a new framework for markerless mobile AR that combines an absolute pose regressor (APR) with a local VIO tracking system. VIO-APR uses VIO to assess the reliability of the APR and the APR to identify and compensate for VIO drift. This feedback loop results in more accurate positioning and more stable AR experiences. To evaluate VIO-APR, we created a dataset that combines camera images with ARKit's VIO system output for six indoor and outdoor scenes of various scales. Over this dataset, VIO-APR improves the median accuracy of popular APR by up to 36\\% in position and 29\\% in orientation, increases the percentage of frames in the high ($0.25 m, 2^{\\circ}$) accuracy level by up to 112\\% and reduces the percentage of frames predicted below the low ($5 m, 10^\\circ$) accuracy greatly. We implement VIO-APR into a mobile AR application using Unity to demonstrate its capabilities. VIO-APR results in noticeably more accurate localization and a more stable overall experience. ",
    "url": "https://arxiv.org/abs/2308.05394",
    "authors": [
      "Changkun Liu",
      "Yukun Zhao",
      "Tristan Braud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05404",
    "title": "Enhancing Low-light Light Field Images with A Deep Compensation  Unfolding Network",
    "abstract": "This paper presents a novel and interpretable end-to-end learning framework, called the deep compensation unfolding network (DCUNet), for restoring light field (LF) images captured under low-light conditions. DCUNet is designed with a multi-stage architecture that mimics the optimization process of solving an inverse imaging problem in a data-driven fashion. The framework uses the intermediate enhanced result to estimate the illumination map, which is then employed in the unfolding process to produce a new enhanced result. Additionally, DCUNet includes a content-associated deep compensation module at each optimization stage to suppress noise and illumination map estimation errors. To properly mine and leverage the unique characteristics of LF images, this paper proposes a pseudo-explicit feature interaction module that comprehensively exploits redundant information in LF images. The experimental results on both simulated and real datasets demonstrate the superiority of our DCUNet over state-of-the-art methods, both qualitatively and quantitatively. Moreover, DCUNet preserves the essential geometric structure of enhanced LF images much better. The code will be publicly available at https://github.com/lyuxianqiang/LFLL-DCU. ",
    "url": "https://arxiv.org/abs/2308.05404",
    "authors": [
      "Xianqiang Lyu",
      "Junhui Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.05410",
    "title": "SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated,  Noisy, and Decimated Point Cloud Data",
    "abstract": "This paper proposes a new method to infer keypoints from arbitrary object categories in practical scenarios where point cloud data (PCD) are noisy, down-sampled and arbitrarily rotated. Our proposed model adheres to the following principles: i) keypoints inference is fully unsupervised (no annotation given), ii) keypoints position error should be low and resilient to PCD perturbations (robustness), iii) keypoints should not change their indexes for the intra-class objects (semantic coherence), iv) keypoints should be close to or proximal to PCD surface (compactness). We achieve these desiderata by proposing a new self-supervised training strategy for keypoints estimation that does not assume any a priori knowledge of the object class, and a model architecture with coupled auxiliary losses that promotes the desired keypoints properties. We compare the keypoints estimated by the proposed approach with those of the state-of-the-art unsupervised approaches. The experiments show that our approach outperforms by estimating keypoints with improved coverage (+9.41%) while being semantically consistent (+4.66%) that best characterizes the object's 3D shape for downstream tasks. Code and data are available at: https://github.com/IITPAVIS/SC3K ",
    "url": "https://arxiv.org/abs/2308.05410",
    "authors": [
      "Mohammad Zohaib",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05416",
    "title": "Your DRM Can Watch You Too: Exploring the Privacy Implications of  Browsers (mis)Implementations of Widevine EME",
    "abstract": "Thanks to HTML5, users can now view videos on Web browsers without installing plug-ins or relying on specific devices. In 2017, W3C published Encrypted Media Extensions (EME) as the first official Web standard for Digital Rights Management (DRM), with the overarching goal of allowing seamless integration of DRM systems on browsers. EME has prompted numerous voices of dissent with respect to the inadequate protection of users. Of particular interest, privacy concerns were articulated, especially that DRM systems inherently require uniquely identifying information on users' devices to control content distribution better. Despite this anecdotal evidence, we lack a comprehensive overview of how browsers have supported EME in practice and what privacy implications are caused by their implementations. In this paper, we fill this gap by investigating privacy leakage caused by EME relying on proprietary and closed-source DRM systems. We focus on Google Widevine because of its versatility and wide adoption. We conduct empirical experiments to show that browsers diverge when complying EME privacy guidelines, which might undermine users' privacy. For instance, we find that many browsers gladly give away the identifying Widevine Client ID with no or little explicit consent from users. Moreover, we characterize the privacy risks of users tracking when browsers miss applying EME guidelines regarding privacy. Because of being closed-source, our work involves reverse engineering to dissect the contents of EME messages as instantiated by Widevine. Finally, we implement EME Track, a tool that automatically exploits bad Widevine-based implementations to break privacy. ",
    "url": "https://arxiv.org/abs/2308.05416",
    "authors": [
      "Gwendal Patat",
      "Mohamed Sabt",
      "Pierre-Alain Fouque"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.05423",
    "title": "On the Stability and Convergence of Physics Informed Neural Networks",
    "abstract": "Physics Informed Neural Networks is a numerical method which uses neural networks to approximate solutions of partial differential equations. It has received a lot of attention and is currently used in numerous physical and engineering problems. The mathematical understanding of these methods is limited, and in particular, it seems that, a consistent notion of stability is missing. Towards addressing this issue we consider model problems of partial differential equations, namely linear elliptic and parabolic PDEs. We consider problems with different stability properties, and problems with time discrete training. Motivated by tools of nonlinear calculus of variations we systematically show that coercivity of the energies and associated compactness provide the right framework for stability. For time discrete training we show that if these properties fail to hold then methods may become unstable. Furthermore, using tools of $\\Gamma-$convergence we provide new convergence results for weak solutions by only requiring that the neural network spaces are chosen to have suitable approximation properties. ",
    "url": "https://arxiv.org/abs/2308.05423",
    "authors": [
      "Dimitrios Gazoulis",
      "Ioannis Gkanis",
      "Charalambos G. Makridakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.05426",
    "title": "Adaptive Low Rank Adaptation of Segment Anything to Salient Object  Detection",
    "abstract": "Foundation models, such as OpenAI's GPT-3 and GPT-4, Meta's LLaMA, and Google's PaLM2, have revolutionized the field of artificial intelligence. A notable paradigm shift has been the advent of the Segment Anything Model (SAM), which has exhibited a remarkable capability to segment real-world objects, trained on 1 billion masks and 11 million images. Although SAM excels in general object segmentation, it lacks the intrinsic ability to detect salient objects, resulting in suboptimal performance in this domain. To address this challenge, we present the Segment Salient Object Model (SSOM), an innovative approach that adaptively fine-tunes SAM for salient object detection by harnessing the low-rank structure inherent in deep learning. Comprehensive qualitative and quantitative evaluations across five challenging RGB benchmark datasets demonstrate the superior performance of our approach, surpassing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2308.05426",
    "authors": [
      "Ruikai Cui",
      "Siyuan He",
      "Shi Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05438",
    "title": "Deep Fusion Transformer Network with Weighted Vector-Wise Keypoints  Voting for Robust 6D Object Pose Estimation",
    "abstract": "One critical challenge in 6D object pose estimation from a single RGBD image is efficient integration of two different modalities, i.e., color and depth. In this work, we tackle this problem by a novel Deep Fusion Transformer~(DFTr) block that can aggregate cross-modality features for improving pose estimation. Unlike existing fusion methods, the proposed DFTr can better model cross-modality semantic correlation by leveraging their semantic similarity, such that globally enhanced features from different modalities can be better integrated for improved information extraction. Moreover, to further improve robustness and efficiency, we introduce a novel weighted vector-wise voting algorithm that employs a non-iterative global optimization strategy for precise 3D keypoint localization while achieving near real-time inference. Extensive experiments show the effectiveness and strong generalization capability of our proposed 3D keypoint voting algorithm. Results on four widely used benchmarks also demonstrate that our method outperforms the state-of-the-art methods by large margins. ",
    "url": "https://arxiv.org/abs/2308.05438",
    "authors": [
      "Jun Zhou",
      "Kai Chen",
      "Linlin Xu",
      "Qi Dou",
      "Jing Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05443",
    "title": "Occupancy Grid Map to Pose Graph-based Map: Robust BIM-based 2D-LiDAR  Localization for Lifelong Indoor Navigation in Changing and Dynamic  Environments",
    "abstract": "Several studies rely on the de facto standard Adaptive Monte Carlo Localization (AMCL) method to localize a robot in an Occupancy Grid Map (OGM) extracted from a building information model (BIM model). However, most of these studies assume that the BIM model precisely represents the real world, which is rarely true. Discrepancies between the reference BIM model and the real world (Scan-BIM deviations) are not only due to furniture or clutter but also the usual as-planned and as-built deviations that exist with any model created in the design phase. These deviations affect the accuracy of AMCL drastically. This paper proposes an open-source method to generate appropriate Pose Graph-based maps from BIM models for robust 2D-LiDAR localization in changing and dynamic environments. First, 2D OGMs are automatically generated from complex BIM models. These OGMs only represent structural elements allowing indoor autonomous robot navigation. Then, an efficient technique converts these 2D OGMs into Pose Graph-based maps enabling more accurate robot pose tracking. Finally, we leverage the different map representations for accurate, robust localization with a combination of state-of-the-art algorithms. Moreover, we provide a quantitative comparison of various state-of-the-art localization algorithms in three simulated scenarios with varying levels of Scan-BIM deviations and dynamic agents. More precisely, we compare two Particle Filter (PF) algorithms: AMCL and General Monte Carlo Localization (GMCL); and two Graph-based Localization (GBL) methods: Google's Cartographer and SLAM Toolbox, solving the global localization and pose tracking problems. The numerous experiments demonstrate that the proposed method contributes to a robust localization with an as-designed BIM model or a sparse OGM in changing and dynamic environments, outperforming the conventional AMCL in accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2308.05443",
    "authors": [
      "Miguel Arturo Vega Torres",
      "Alexander Braun",
      "Andr\u00e9 Borrmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05444",
    "title": "How-to Augmented Lagrangian on Factor Graphs",
    "abstract": "Factor graphs are a very powerful graphical representation, used to model many problems in robotics. They are widely spread in the areas of Simultaneous Localization and Mapping (SLAM), computer vision, and localization. In this paper we describe an approach to fill the gap with other areas, such as optimal control, by presenting an extension of Factor Graph Solvers to constrained optimization. The core idea of our method is to encapsulate the Augmented Lagrangian (AL) method in factors of the graph that can be integrated straightforwardly in existing factor graph solvers. We show the generality of our approach by addressing three applications, arising from different areas: pose estimation, rotation synchronization and Model Predictive Control (MPC) of a pseudo-omnidirectional platform. We implemented our approach using C++ and ROS. Besides the generality of the approach, application results show that we can favorably compare against domain specific approaches. ",
    "url": "https://arxiv.org/abs/2308.05444",
    "authors": [
      "Barbara Bazzana",
      "Henrik Andreasson",
      "Giorgio Grisetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05459",
    "title": "KS-APR: Keyframe Selection for Robust Absolute Pose Regression",
    "abstract": "Markerless Mobile Augmented Reality (AR) aims to anchor digital content in the physical world without using specific 2D or 3D objects. Absolute Pose Regressors (APR) are end-to-end machine learning solutions that infer the device's pose from a single monocular image. Thanks to their low computation cost, they can be directly executed on the constrained hardware of mobile AR devices. However, APR methods tend to yield significant inaccuracies for input images that are too distant from the training set. This paper introduces KS-APR, a pipeline that assesses the reliability of an estimated pose with minimal overhead by combining the inference results of the APR and the prior images in the training set. Mobile AR systems tend to rely upon visual-inertial odometry to track the relative pose of the device during the experience. As such, KS-APR favours reliability over frequency, discarding unreliable poses. This pipeline can integrate most existing APR methods to improve accuracy by filtering unreliable images with their pose estimates. We implement the pipeline on three types of APR models on indoor and outdoor datasets. The median error on position and orientation is reduced for all models, and the proportion of large errors is minimized across datasets. Our method enables state-of-the-art APRs such as DFNetdm to outperform single-image and sequential APR methods. These results demonstrate the scalability and effectiveness of KS-APR for visual localization tasks that do not require one-shot decisions. ",
    "url": "https://arxiv.org/abs/2308.05459",
    "authors": [
      "Changkun Liu",
      "Yukun Zhao",
      "Tristan Braud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05463",
    "title": "$\\mathcal{G}^2Pxy$: Generative Open-Set Node Classification on Graphs  with Proxy Unknowns",
    "abstract": "Node classification is the task of predicting the labels of unlabeled nodes in a graph. State-of-the-art methods based on graph neural networks achieve excellent performance when all labels are available during training. But in real-life, models are often applied on data with new classes, which can lead to massive misclassification and thus significantly degrade performance. Hence, developing open-set classification methods is crucial to determine if a given sample belongs to a known class. Existing methods for open-set node classification generally use transductive learning with part or all of the features of real unseen class nodes to help with open-set classification. In this paper, we propose a novel generative open-set node classification method, i.e. $\\mathcal{G}^2Pxy$, which follows a stricter inductive learning setting where no information about unknown classes is available during training and validation. Two kinds of proxy unknown nodes, inter-class unknown proxies and external unknown proxies are generated via mixup to efficiently anticipate the distribution of novel classes. Using the generated proxies, a closed-set classifier can be transformed into an open-set one, by augmenting it with an extra proxy classifier. Under the constraints of both cross entropy loss and complement entropy loss, $\\mathcal{G}^2Pxy$ achieves superior effectiveness for unknown class detection and known class classification, which is validated by experiments on benchmark graph datasets. Moreover, $\\mathcal{G}^2Pxy$ does not have specific requirement on the GNN architecture and shows good generalizations. ",
    "url": "https://arxiv.org/abs/2308.05463",
    "authors": [
      "Qin Zhang",
      "Zelin Shi",
      "Xiaolin Zhang",
      "Xiaojun Chen",
      "Philippe Fournier-Viger",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05480",
    "title": "YOLO-MS: Rethinking Multi-Scale Representation Learning for Real-time  Object Detection",
    "abstract": "We aim at providing the object detection community with an efficient and performant object detector, termed YOLO-MS. The core design is based on a series of investigations on how convolutions with different kernel sizes affect the detection performance of objects at different scales. The outcome is a new strategy that can strongly enhance multi-scale feature representations of real-time object detectors. To verify the effectiveness of our strategy, we build a network architecture, termed YOLO-MS. We train our YOLO-MS on the MS COCO dataset from scratch without relying on any other large-scale datasets, like ImageNet, or pre-trained weights. Without bells and whistles, our YOLO-MS outperforms the recent state-of-the-art real-time object detectors, including YOLO-v7 and RTMDet, when using a comparable number of parameters and FLOPs. Taking the XS version of YOLO-MS as an example, with only 4.5M learnable parameters and 8.7G FLOPs, it can achieve an AP score of 43%+ on MS COCO, which is about 2%+ higher than RTMDet with the same model size. Moreover, our work can also be used as a plug-and-play module for other YOLO models. Typically, our method significantly improves the AP of YOLOv8 from 37%+ to 40%+ with even fewer parameters and FLOPs. Code is available at https://github.com/FishAndWasabi/YOLO-MS. ",
    "url": "https://arxiv.org/abs/2308.05480",
    "authors": [
      "Yuming Chen",
      "Xinbin Yuan",
      "Ruiqi Wu",
      "Jiabao Wang",
      "Qibin Hou",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05498",
    "title": "Complex Network Effects on the Robustness of Graph Convolutional  Networks",
    "abstract": "Vertex classification -- the problem of identifying the class labels of nodes in a graph -- has applicability in a wide variety of domains. Examples include classifying subject areas of papers in citation networks or roles of machines in a computer network. Vertex classification using graph convolutional networks is susceptible to targeted poisoning attacks, in which both graph structure and node attributes can be changed in an attempt to misclassify a target node. This vulnerability decreases users' confidence in the learning method and can prevent adoption in high-stakes contexts. Defenses have also been proposed, focused on filtering edges before creating the model or aggregating information from neighbors more robustly. This paper considers an alternative: we leverage network characteristics in the training data selection process to improve robustness of vertex classifiers. We propose two alternative methods of selecting training data: (1) to select the highest-degree nodes and (2) to iteratively select the node with the most neighbors minimally connected to the training set. In the datasets on which the original attack was demonstrated, we show that changing the training set can make the network much harder to attack. To maintain a given probability of attack success, the adversary must use far more perturbations; often a factor of 2--4 over the random training baseline. These training set selection methods often work in conjunction with the best recently published defenses to provide even greater robustness. While increasing the amount of randomly selected training data sometimes results in a more robust classifier, the proposed methods increase robustness substantially more. We also run a simulation study in which we demonstrate conditions under which each of the two methods outperforms the other, controlling for the graph topology, homophily of the labels, and node attributes. ",
    "url": "https://arxiv.org/abs/2308.05498",
    "authors": [
      "Benjamin A. Miller",
      "Kevin Chan",
      "Tina Eliassi-Rad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.05508",
    "title": "Multi-domain Recommendation with Embedding Disentangling and Domain  Alignment",
    "abstract": "Multi-domain recommendation (MDR) aims to provide recommendations for different domains (e.g., types of products) with overlapping users/items and is common for platforms such as Amazon, Facebook, and LinkedIn that host multiple services. Existing MDR models face two challenges: First, it is difficult to disentangle knowledge that generalizes across domains (e.g., a user likes cheap items) and knowledge specific to a single domain (e.g., a user likes blue clothing but not blue cars). Second, they have limited ability to transfer knowledge across domains with small overlaps. We propose a new MDR method named EDDA with two key components, i.e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively. In particular, the embedding disentangling recommender separates both the model and embedding for the inter-domain part and the intra-domain part, while most existing MDR methods only focus on model-level disentangling. The domain alignment leverages random walks from graph processing to identify similar user/item pairs from different domains and encourages similar user/item pairs to have similar embeddings, enhancing knowledge transfer. We compare EDDA with 12 state-of-the-art baselines on 3 real datasets. The results show that EDDA consistently outperforms the baselines on all datasets and domains. All datasets and codes are available at https://github.com/Stevenn9981/EDDA. ",
    "url": "https://arxiv.org/abs/2308.05508",
    "authors": [
      "Wentao Ning",
      "Xiao Yan",
      "Weiwen Liu",
      "Reynold Cheng",
      "Rui Zhang",
      "Bo Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05515",
    "title": "Mono-hydra: Real-time 3D scene graph construction from monocular camera  input with IMU",
    "abstract": "The ability of robots to autonomously navigate through 3D environments depends on their comprehension of spatial concepts, ranging from low-level geometry to high-level semantics, such as objects, places, and buildings. To enable such comprehension, 3D scene graphs have emerged as a robust tool for representing the environment as a layered graph of concepts and their relationships. However, building these representations using monocular vision systems in real-time remains a difficult task that has not been explored in depth. This paper puts forth a real-time spatial perception system Mono-Hydra, combining a monocular camera and an IMU sensor setup, focusing on indoor scenarios. However, the proposed approach is adaptable to outdoor applications, offering flexibility in its potential uses. The system employs a suite of deep learning algorithms to derive depth and semantics. It uses a robocentric visual-inertial odometry (VIO) algorithm based on square-root information, thereby ensuring consistent visual odometry with an IMU and a monocular camera. This system achieves sub-20 cm error in real-time processing at 15 fps, enabling real-time 3D scene graph construction using a laptop GPU (NVIDIA 3080). This enhances decision-making efficiency and effectiveness in simple camera setups, augmenting robotic system agility. We make Mono-Hydra publicly available at: https://github.com/UAV-Centre-ITC/Mono_Hydra ",
    "url": "https://arxiv.org/abs/2308.05515",
    "authors": [
      "U.V.B.L. Udugama",
      "G. Vosselman",
      "F. Nex"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05525",
    "title": "Critical Points ++: An Agile Point Cloud Importance Measure for Robust  Classification, Adversarial Defense and Explainable AI",
    "abstract": "The ability to cope accurately and fast with Out-Of-Distribution (OOD) samples is crucial in real-world safety demanding applications. In this work we first study the interplay between critical points of 3D point clouds and OOD samples. Our findings are that common corruptions and outliers are often interpreted as critical points. We generalize the notion of critical points into importance measures. We show that training a classification network based only on less important points dramatically improves robustness, at a cost of minor performance loss on the clean set. We observe that normalized entropy is highly informative for corruption analysis. An adaptive threshold based on normalized entropy is suggested for selecting the set of uncritical points. Our proposed importance measure is extremely fast to compute. We show it can be used for a variety of applications, such as Explainable AI (XAI), Outlier Removal, Uncertainty Estimation, Robust Classification and Adversarial Defense. We reach SOTA results on the two latter tasks. ",
    "url": "https://arxiv.org/abs/2308.05525",
    "authors": [
      "Meir Yossef Levi",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05542",
    "title": "Robust Asymmetric Loss for Multi-Label Long-Tailed Learning",
    "abstract": "In real medical data, training samples typically show long-tailed distributions with multiple labels. Class distribution of the medical data has a long-tailed shape, in which the incidence of different diseases is quite varied, and at the same time, it is not unusual for images taken from symptomatic patients to be multi-label diseases. Therefore, in this paper, we concurrently address these two issues by putting forth a robust asymmetric loss on the polynomial function. Since our loss tackles both long-tailed and multi-label classification problems simultaneously, it leads to a complex design of the loss function with a large number of hyper-parameters. Although a model can be highly fine-tuned due to a large number of hyper-parameters, it is difficult to optimize all hyper-parameters at the same time, and there might be a risk of overfitting a model. Therefore, we regularize the loss function using the Hill loss approach, which is beneficial to be less sensitive against the numerous hyper-parameters so that it reduces the risk of overfitting the model. For this reason, the proposed loss is a generic method that can be applied to most medical image classification tasks and does not make the training process more time-consuming. We demonstrate that the proposed robust asymmetric loss performs favorably against the long-tailed with multi-label medical image classification in addition to the various long-tailed single-label datasets. Notably, our method achieves Top-5 results on the CXR-LT dataset of the ICCV CVAMD 2023 competition. We opensource our implementation of the robust asymmetric loss in the public repository: https://github.com/kalelpark/RAL. ",
    "url": "https://arxiv.org/abs/2308.05542",
    "authors": [
      "Wongi Park",
      "Inhyuk Park",
      "Sungeun Kim",
      "Jongbin Ryu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05550",
    "title": "Cross-Domain Product Representation Learning for Rich-Content E-Commerce",
    "abstract": "The proliferation of short video and live-streaming platforms has revolutionized how consumers engage in online shopping. Instead of browsing product pages, consumers are now turning to rich-content e-commerce, where they can purchase products through dynamic and interactive media like short videos and live streams. This emerging form of online shopping has introduced technical challenges, as products may be presented differently across various media domains. Therefore, a unified product representation is essential for achieving cross-domain product recognition to ensure an optimal user search experience and effective product recommendations. Despite the urgent industrial need for a unified cross-domain product representation, previous studies have predominantly focused only on product pages without taking into account short videos and live streams. To fill the gap in the rich-content e-commerce area, in this paper, we introduce a large-scale cRoss-dOmain Product Ecognition dataset, called ROPE. ROPE covers a wide range of product categories and contains over 180,000 products, corresponding to millions of short videos and live streams. It is the first dataset to cover product pages, short videos, and live streams simultaneously, providing the basis for establishing a unified product representation across different media domains. Furthermore, we propose a Cross-dOmain Product rEpresentation framework, namely COPE, which unifies product representations in different domains through multimodal learning including text and vision. Extensive experiments on downstream tasks demonstrate the effectiveness of COPE in learning a joint feature space for all product domains. ",
    "url": "https://arxiv.org/abs/2308.05550",
    "authors": [
      "Xuehan Bai",
      "Yan Li",
      "Yanhua Cheng",
      "Wenjie Yang",
      "Quan Chen",
      "Han Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05563",
    "title": "Recent Advancements In The Field Of Deepfake Detection",
    "abstract": "A deepfake is a photo or video of a person whose image has been digitally altered or partially replaced with an image of someone else. Deepfakes have the potential to cause a variety of problems and are often used maliciously. A common usage is altering videos of prominent political figures and celebrities. These deepfakes can portray them making offensive, problematic, and/or untrue statements. Current deepfakes can be very realistic, and when used in this way, can spread panic and even influence elections and political opinions. There are many deepfake detection strategies currently in use but finding the most comprehensive and universal method is critical. So, in this survey we will address the problems of malicious deepfake creation and the lack of universal deepfake detection methods. Our objective is to survey and analyze a variety of current methods and advances in the field of deepfake detection. ",
    "url": "https://arxiv.org/abs/2308.05563",
    "authors": [
      "Natalie Krueger",
      "Dr. Mounika Vanamala",
      "Dr. Rushit Dave"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2308.05575",
    "title": "Symmetry Defense Against XGBoost Adversarial Perturbation Attacks",
    "abstract": "We examine whether symmetry can be used to defend tree-based ensemble classifiers such as gradient-boosting decision trees (GBDTs) against adversarial perturbation attacks. The idea is based on a recent symmetry defense for convolutional neural network classifiers (CNNs) that utilizes CNNs' lack of invariance with respect to symmetries. CNNs lack invariance because they can classify a symmetric sample, such as a horizontally flipped image, differently from the original sample. CNNs' lack of invariance also means that CNNs can classify symmetric adversarial samples differently from the incorrect classification of adversarial samples. Using CNNs' lack of invariance, the recent CNN symmetry defense has shown that the classification of symmetric adversarial samples reverts to the correct sample classification. In order to apply the same symmetry defense to GBDTs, we examine GBDT invariance and are the first to show that GBDTs also lack invariance with respect to symmetries. We apply and evaluate the GBDT symmetry defense for nine datasets against six perturbation attacks with a threat model that ranges from zero-knowledge to perfect-knowledge adversaries. Using the feature inversion symmetry against zero-knowledge adversaries, we achieve up to 100% accuracy on adversarial samples even when default and robust classifiers have 0% accuracy. Using the feature inversion and horizontal flip symmetries against perfect-knowledge adversaries, we achieve up to over 95% accuracy on adversarial samples for the GBDT classifier of the F-MNIST dataset even when default and robust classifiers have 0% accuracy. ",
    "url": "https://arxiv.org/abs/2308.05575",
    "authors": [
      "Blerta Lindqvist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.05591",
    "title": "Optimizing Cache Content Placement in Integrated Terrestrial and  Non-terrestrial Networks",
    "abstract": "Non-terrestrial networks (NTN) offer potential for efficient content broadcast in remote regions, thereby extending the reach of digital services. In this paper, we introduce a novel approach to optimize wireless edge content placement using NTN. Specifically, we dynamically select content for placement via NTN links based on popularity and suitability for delivery through NTN, while considering the orbital motion of LEO satellites. Our comprehensive system-level case studies, based on a practical LEO constellation, demonstrate the significant improvement in placement speed compared to existing methods that neglect network mobility. We further show that the advantages of NTN links over standalone wireless TN solutions are more pronounced in the early stages of content delivery and are amplified by higher content popularity correlation across geographical regions. ",
    "url": "https://arxiv.org/abs/2308.05591",
    "authors": [
      "Feng Wang",
      "Giovanni Geraci",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.05593",
    "title": "Robust Lifelong Indoor LiDAR Localization using the Area Graph",
    "abstract": "Lifelong indoor localization in a given map is the basis for navigation of autonomous mobile robots. In this letter, we address the problem of robust localization in cluttered indoor environments like office spaces and corridors using 3D LiDAR point clouds in a given Area Graph, which is a hierarchical, topometric semantic map representation that uses polygons to demark areas such as rooms, corridors or buildings. This representation is very compact, can represent different floors of buildings through its hierarchy and provides semantic information that helps with localization, like poses of doors and glass. In contrast to this, commonly used map representations, such as occupancy grid maps or point clouds, lack these features and require frequent updates in response to environmental changes (e.g. moved furniture), unlike our approach, which matches against lifelong architectural features such as walls and doors. For that we apply filtering to remove clutter from the 3D input point cloud and then employ further scoring and weight functions for localization. Given a broad initial guess from WiFi localization, our experiments show that our global localization and the weighted point to line ICP pose tracking perform very well, even when compared to localization and SLAM algorithms that use the current, feature-rich cluttered map for localization. ",
    "url": "https://arxiv.org/abs/2308.05593",
    "authors": [
      "Fujing Xie",
      "S\u00f6ren Schwertfeger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05595",
    "title": "Test-Time Selection for Robust Skin Lesion Analysis",
    "abstract": "Skin lesion analysis models are biased by artifacts placed during image acquisition, which influence model predictions despite carrying no clinical information. Solutions that address this problem by regularizing models to prevent learning those spurious features achieve only partial success, and existing test-time debiasing techniques are inappropriate for skin lesion analysis due to either making unrealistic assumptions on the distribution of test data or requiring laborious annotation from medical practitioners. We propose TTS (Test-Time Selection), a human-in-the-loop method that leverages positive (e.g., lesion area) and negative (e.g., artifacts) keypoints in test samples. TTS effectively steers models away from exploiting spurious artifact-related correlations without retraining, and with less annotation requirements. Our solution is robust to a varying availability of annotations, and different levels of bias. We showcase on the ISIC2019 dataset (for which we release a subset of annotated images) how our model could be deployed in the real-world for mitigating bias. ",
    "url": "https://arxiv.org/abs/2308.05595",
    "authors": [
      "Alceu Bissoto",
      "Catarina Barata",
      "Eduardo Valle",
      "Sandra Avila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05601",
    "title": "Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow  Prediction",
    "abstract": "Inter-city highway transportation is significant for urban life. As one of the key functions in intelligent transportation system (ITS), traffic evaluation always plays significant role nowadays, and daily traffic flow prediction still faces challenges at network-wide toll stations. On the one hand, the data imbalance in practice among various locations deteriorates the performance of prediction. On the other hand, complex correlative spatio-temporal factors cannot be comprehensively employed in long-term duration. In this paper, a prediction method is proposed for daily traffic flow in highway domain through spatio-temporal deep learning. In our method, data normalization strategy is used to deal with data imbalance, due to long-tail distribution of traffic flow at network-wide toll stations. And then, based on graph convolutional network, we construct networks in distinct semantics to capture spatio-temporal features. Beside that, meteorology and calendar features are used by our model in the full connection stage to extra external characteristics of traffic flow. By extensive experiments and case studies in one Chinese provincial highway, our method shows clear improvement in predictive accuracy than baselines and practical benefits in business. ",
    "url": "https://arxiv.org/abs/2308.05601",
    "authors": [
      "Weilong Ding",
      "Tianpu Zhang",
      "Jianwu Wang",
      "Zhuofeng Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05605",
    "title": "Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative  Convolution Network",
    "abstract": "Monocular depth estimation is known as an ill-posed task in which objects in a 2D image usually do not contain sufficient information to predict their depth. Thus, it acts differently from other tasks (e.g., classification and segmentation) in many ways. In this paper, we find that self-supervised monocular depth estimation shows a direction sensitivity and environmental dependency in the feature representation. But the current backbones borrowed from other tasks pay less attention to handling different types of environmental information, limiting the overall depth accuracy. To bridge this gap, we propose a new Direction-aware Cumulative Convolution Network (DaCCN), which improves the depth feature representation in two aspects. First, we propose a direction-aware module, which can learn to adjust the feature extraction in each direction, facilitating the encoding of different types of information. Secondly, we design a new cumulative convolution to improve the efficiency for aggregating important environmental information. Experiments show that our method achieves significant improvements on three widely used benchmarks, KITTI, Cityscapes, and Make3D, setting a new state-of-the-art performance on the popular benchmarks with all three types of self-supervision. ",
    "url": "https://arxiv.org/abs/2308.05605",
    "authors": [
      "Wencheng Han",
      "Junbo Yin",
      "Jianbing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05617",
    "title": "A Neural Network Based Choice Model for Assortment Optimization",
    "abstract": "Discrete-choice models are used in economics, marketing and revenue management to predict customer purchase probabilities, say as a function of prices and other features of the offered assortment. While they have been shown to be expressive, capturing customer heterogeneity and behaviour, they are also hard to estimate, often based on many unobservables like utilities; and moreover, they still fail to capture many salient features of customer behaviour. A natural question then, given their success in other contexts, is if neural networks can eliminate the necessity of carefully building a context-dependent customer behaviour model and hand-coding and tuning the estimation. It is unclear however how one would incorporate assortment effects into such a neural network, and also how one would optimize the assortment with such a black-box generative model of choice probabilities. In this paper we investigate first whether a single neural network architecture can predict purchase probabilities for datasets from various contexts and generated under various models and assumptions. Next, we develop an assortment optimization formulation that is solvable by off-the-shelf integer programming solvers. We compare against a variety of benchmark discrete-choice models on simulated as well as real-world datasets, developing training tricks along the way to make the neural network prediction and subsequent optimization robust and comparable in performance to the alternates. ",
    "url": "https://arxiv.org/abs/2308.05617",
    "authors": [
      "Hanzhao Wang",
      "Zhongze Cai",
      "Xiaocheng Li",
      "Kalyan Talluri"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05620",
    "title": "A Robust and Rapidly Deployable Waypoint Navigation Architecture for  Long-Duration Operations in GPS-Denied Environments",
    "abstract": "For long-duration operations in GPS-denied environments, accurate and repeatable waypoint navigation is an essential capability. While simultaneous localization and mapping (SLAM) works well for single-session operations, repeated, multi-session operations require robots to navigate to the same spot(s) accurately and precisely each and every time. Localization and navigation errors can build up from one session to the next if they are not accounted for. Localization using a global reference map works well, but there are no publicly available packages for quickly building maps and navigating with them. We propose a new architecture using a combination of two publicly available packages with a newly released package to create a fully functional multi-session navigation system for ground vehicles. The system takes just a few hours from the beginning of the first manual scan to perform autonomous waypoint navigation. ",
    "url": "https://arxiv.org/abs/2308.05620",
    "authors": [
      "Erik Pearson",
      "Brendan Englot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05634",
    "title": "Tracing the Influence of Predecessors on Trajectory Prediction",
    "abstract": "In real-world traffic scenarios, agents such as pedestrians and car drivers often observe neighboring agents who exhibit similar behavior as examples and then mimic their actions to some extent in their own behavior. This information can serve as prior knowledge for trajectory prediction, which is unfortunately largely overlooked in current trajectory prediction models. This paper introduces a novel Predecessor-and-Successor (PnS) method that incorporates a predecessor tracing module to model the influence of predecessors (identified from concurrent neighboring agents) on the successor (target agent) within the same scene. The method utilizes the moving patterns of these predecessors to guide the predictor in trajectory prediction. PnS effectively aligns the motion encodings of the successor with multiple potential predecessors in a probabilistic manner, facilitating the decoding process. We demonstrate the effectiveness of PnS by integrating it into a graph-based predictor for pedestrian trajectory prediction on the ETH/UCY datasets, resulting in a new state-of-the-art performance. Furthermore, we replace the HD map-based scene-context module with our PnS method in a transformer-based predictor for vehicle trajectory prediction on the nuScenes dataset, showing that the predictor maintains good prediction performance even without relying on any map information. ",
    "url": "https://arxiv.org/abs/2308.05634",
    "authors": [
      "Mengmeng Liu",
      "Hao Cheng",
      "Michael Ying Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05636",
    "title": "A Homomorphic Encryption Framework for Privacy-Preserving Spiking Neural  Networks",
    "abstract": "Machine learning (ML) is widely used today, especially through deep neural networks (DNNs), however, increasing computational load and resource requirements have led to cloud-based solutions. To address this problem, a new generation of networks called Spiking Neural Networks (SNN) has emerged, which mimic the behavior of the human brain to improve efficiency and reduce energy consumption. These networks often process large amounts of sensitive information, such as confidential data, and thus privacy issues arise. Homomorphic encryption (HE) offers a solution, allowing calculations to be performed on encrypted data without decrypting it. This research compares traditional DNNs and SNNs using the Brakerski/Fan-Vercauteren (BFV) encryption scheme. The LeNet-5 model, a widely-used convolutional architecture, is used for both DNN and SNN models based on the LeNet-5 architecture, and the networks are trained and compared using the FashionMNIST dataset. The results show that SNNs using HE achieve up to 40% higher accuracy than DNNs for low values of the plaintext modulus t, although their execution time is longer due to their time-coding nature with multiple time-steps. ",
    "url": "https://arxiv.org/abs/2308.05636",
    "authors": [
      "Farzad Nikfam",
      "Raffaele Casaburi",
      "Alberto Marchisio",
      "Maurizio Martina",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.05640",
    "title": "A Comparative Visual Analytics Framework for Evaluating Evolutionary  Processes in Multi-objective Optimization",
    "abstract": "Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems. In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions. However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes. Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms. In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms. Guided by a literature review and expert interviews, the proposed framework addresses various analytical tasks and establishes a multi-faceted visualization design to support the comparative analysis of intermediate generations in the evolution as well as solution sets. We demonstrate the effectiveness of our framework through case studies on benchmarking and real-world multi-objective optimization problems to elucidate how analysts can leverage our framework to inspect and compare diverse algorithms. ",
    "url": "https://arxiv.org/abs/2308.05640",
    "authors": [
      "Yansong Huang",
      "Zherui Zhang",
      "Ao Jiao",
      "Yuxin Ma",
      "Ran Cheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.05646",
    "title": "AST-MHSA : Code Summarization using Multi-Head Self-Attention",
    "abstract": "Code summarization aims to generate concise natural language descriptions for source code. The prevailing approaches adopt transformer-based encoder-decoder architectures, where the Abstract Syntax Tree (AST) of the source code is utilized for encoding structural information. However, ASTs are much longer than the corresponding source code, and existing methods ignore this size constraint by directly feeding the entire linearized AST into the encoders. This simplistic approach makes it challenging to extract truly valuable dependency relations from the overlong input sequence and leads to significant computational overhead due to self-attention applied to all nodes in the AST. To address this issue effectively and efficiently, we present a model, AST-MHSA that uses multi-head attention to extract the important semantic information from the AST. The model consists of two main components: an encoder and a decoder. The encoder takes as input the abstract syntax tree (AST) of the code and generates a sequence of hidden states. The decoder then takes these hidden states as input and generates a natural language summary of the code. The multi-head attention mechanism allows the model to learn different representations of the input code, which can be combined to generate a more comprehensive summary. The model is trained on a dataset of code and summaries, and the parameters of the model are optimized to minimize the loss between the generated summaries and the ground-truth summaries. ",
    "url": "https://arxiv.org/abs/2308.05646",
    "authors": [
      "Yeshwanth Nagaraj",
      "Ujjwal Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.05650",
    "title": "Asymptotic-preserving neural networks for multiscale  Vlasov-Poisson-Fokker-Planck system in the high-field regime",
    "abstract": "The Vlasov-Poisson-Fokker-Planck (VPFP) system is a fundamental model in plasma physics that describes the Brownian motion of a large ensemble of particles within a surrounding bath. Under the high-field scaling, both collision and field are dominant. This paper introduces two Asymptotic-Preserving Neural Network (APNN) methods within a physics-informed neural network (PINN) framework for solving the VPFP system in the high-field regime. These methods aim to overcome the computational challenges posed by high dimensionality and multiple scales of the system. The first APNN method leverages the micro-macro decomposition model of the original VPFP system, while the second is based on the mass conservation law. Both methods ensure that the loss function of the neural networks transitions naturally from the kinetic model to the high-field limit model, thereby preserving the correct asymptotic behavior. Through extensive numerical experiments, these APNN methods demonstrate their effectiveness in solving multiscale and high dimensional uncertain problems, as well as their broader applicability for problems with long time duration and non-equilibrium initial data. ",
    "url": "https://arxiv.org/abs/2308.05650",
    "authors": [
      "Shi Jin",
      "Zheng Ma",
      "Tian-ai Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.05681",
    "title": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action  Recognition with Skeleton-Motion-Informed Gradient",
    "abstract": "Recently, methods for skeleton-based human activity recognition have been shown to be vulnerable to adversarial attacks. However, these attack methods require either the full knowledge of the victim (i.e. white-box attacks), access to training data (i.e. transfer-based attacks) or frequent model queries (i.e. black-box attacks). All their requirements are highly restrictive, raising the question of how detrimental the vulnerability is. In this paper, we show that the vulnerability indeed exists. To this end, we consider a new attack task: the attacker has no access to the victim model or the training data or labels, where we coin the term hard no-box attack. Specifically, we first learn a motion manifold where we define an adversarial loss to compute a new gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our gradient contains information of the motion dynamics, which is different from existing gradient-based attack methods that compute the loss gradient assuming each dimension in the data is independent. The SMI gradient can augment many gradient-based attack methods, leading to a new family of no-box attack methods. Extensive evaluation and comparison show that our method imposes a real threat to existing classifiers. They also show that the SMI gradient improves the transferability and imperceptibility of adversarial samples in both no-box and transfer-based black-box settings. ",
    "url": "https://arxiv.org/abs/2308.05681",
    "authors": [
      "Zhengzhi Lu",
      "He Wang",
      "Ziyi Chang",
      "Guoan Yang",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05695",
    "title": "Masked Diffusion as Self-supervised Representation Learner",
    "abstract": "Denoising diffusion probabilistic models have recently demonstrated state-of-the-art generative performance and been used as strong pixel-level representation learners. This paper decomposes the interrelation between the generative capability and representation learning ability inherent in diffusion models. We present masked diffusion model (MDM), a scalable self-supervised representation learner that substitutes the conventional additive Gaussian noise of traditional diffusion with a masking mechanism. Our proposed approach convincingly surpasses prior benchmarks, demonstrating remarkable advancements in both medical and natural image semantic segmentation tasks, particularly within the context of few-shot scenario. ",
    "url": "https://arxiv.org/abs/2308.05695",
    "authors": [
      "Zixuan Pan",
      "Jianxu Chen",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05697",
    "title": "SSLRec: A Self-Supervised Learning Library for Recommendation",
    "abstract": "Self-supervised learning (SSL) has gained significant interest in recent years as a solution to address the challenges posed by sparse and noisy data in recommender systems. Despite the growing number of SSL algorithms designed to provide state-of-the-art performance in various recommendation scenarios (e.g., graph collaborative filtering, sequential recommendation, social recommendation, KG-enhanced recommendation), there is still a lack of unified frameworks that integrate recommendation algorithms across different domains. Such a framework could serve as the cornerstone for self-supervised recommendation algorithms, unifying the validation of existing methods and driving the design of new ones. To address this gap, we introduce SSLRec, a novel benchmark platform that provides a standardized, flexible, and comprehensive framework for evaluating various SSL-enhanced recommenders. The SSLRec library features a modular architecture that allows users to easily evaluate state-of-the-art models and a complete set of data augmentation and self-supervised toolkits to help create SSL recommendation models with specific needs. Furthermore, SSLRec simplifies the process of training and evaluating different recommendation models with consistent and fair settings. Our SSLRec platform covers a comprehensive set of state-of-the-art SSL-enhanced recommendation models across different scenarios, enabling researchers to evaluate these cutting-edge models and drive further innovation in the field. Our implemented SSLRec framework is available at the source code repository https://github.com/HKUDS/SSLRec. ",
    "url": "https://arxiv.org/abs/2308.05697",
    "authors": [
      "Xubin Ren",
      "Lianghao Xia",
      "Yuhao Yang",
      "Wei Wei",
      "Tianle Wang",
      "Xuheng Cai",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05700",
    "title": "The Privacy-Value-App Relationship and the Value-Centered Privacy  Assistant",
    "abstract": "Many of us make quick decisions that affect our data privacy on our smartphones without due consideration of our values. One such decision point is establishing whether to download a smartphone app or not. In this work, we aim to better understand the relationship between our values, our privacy preferences, and our app choices, as well as explore the effectiveness of a smartphone value-centered privacy assistant (VcPA) at promoting value-centered app selection. To do this, we conducted a mixed-methods study that involved two phases. The first was an online survey of 273 smartphone user's values and privacy preferences when considering whether to download one of two apps (Lose It! and OpenLitterMap). Our results suggest that values and privacy preferences are related in an app or context-dependent manner. The second phase was testing the VcPA with 77 users in a synthetic Mock App Store setting. We established usability of a VcPA, with the VcPA helping some users more than others with selecting apps consistent with their selected value profile. Future qualitative and context-specific explorations of user perspectives could contribute to adequately capturing the specific role of values for privacy decision-making and improving the VcPA. ",
    "url": "https://arxiv.org/abs/2308.05700",
    "authors": [
      "Sarah E. Carter",
      "Mathieu d'Aquin",
      "Dayana Spagnuelo",
      "Ilaria Tiddi",
      "Kathryn Cormican",
      "Heike Felzmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.05701",
    "title": "Exploring the Potential of World Models for Anomaly Detection in  Autonomous Driving",
    "abstract": "In recent years there have been remarkable advancements in autonomous driving. While autonomous vehicles demonstrate high performance in closed-set conditions, they encounter difficulties when confronted with unexpected situations. At the same time, world models emerged in the field of model-based reinforcement learning as a way to enable agents to predict the future depending on potential actions. This led to outstanding results in sparse reward and complex control tasks. This work provides an overview of how world models can be leveraged to perform anomaly detection in the domain of autonomous driving. We provide a characterization of world models and relate individual components to previous works in anomaly detection to facilitate further research in the field. ",
    "url": "https://arxiv.org/abs/2308.05701",
    "authors": [
      "Daniel Bogdoll",
      "Lukas Bosch",
      "Tim Joseph",
      "Helen Gremmelmaier",
      "Yitian Yang",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05707",
    "title": "Shadow Datasets, New challenging datasets for Causal Representation  Learning",
    "abstract": "Discovering causal relations among semantic factors is an emergent topic in representation learning. Most causal representation learning (CRL) methods are fully supervised, which is impractical due to costly labeling. To resolve this restriction, weakly supervised CRL methods were introduced. To evaluate CRL performance, four existing datasets, Pendulum, Flow, CelebA(BEARD) and CelebA(SMILE), are utilized. However, existing CRL datasets are limited to simple graphs with few generative factors. Thus we propose two new datasets with a larger number of diverse generative factors and more sophisticated causal graphs. In addition, current real datasets, CelebA(BEARD) and CelebA(SMILE), the originally proposed causal graphs are not aligned with the dataset distributions. Thus, we propose modifications to them. ",
    "url": "https://arxiv.org/abs/2308.05707",
    "authors": [
      "Jiageng Zhu",
      "Hanchen Xie",
      "Jianhua Wu",
      "Jiazhi Li",
      "Mahyar Khayatkhoei",
      "Mohamed E. Hussein",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05713",
    "title": "Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math  and science problems",
    "abstract": "This report describes a test of the large language model GPT-4 with the Wolfram Alpha and the Code Interpreter plug-ins on 105 original problems in science and math, at the high school and college levels, carried out in June-August 2023. Our tests suggest that the plug-ins significantly enhance GPT's ability to solve these problems. Having said that, there are still often \"interface\" failures; that is, GPT often has trouble formulating problems in a way that elicits useful answers from the plug-ins. Fixing these interface failures seems like a central challenge in making GPT a reliable tool for college-level calculation problems. ",
    "url": "https://arxiv.org/abs/2308.05713",
    "authors": [
      "Ernest Davis",
      "Scott Aaronson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "History and Overview (math.HO)",
      "Popular Physics (physics.pop-ph)"
    ]
  },
  {
    "id": "arXiv:2308.05721",
    "title": "Deformable Mixer Transformer with Gating for Multi-Task Learning of  Dense Prediction",
    "abstract": "CNNs and Transformers have their own advantages and both have been widely used for dense prediction in multi-task learning (MTL). Most of the current studies on MTL solely rely on CNN or Transformer. In this work, we present a novel MTL model by combining both merits of deformable CNN and query-based Transformer with shared gating for multi-task learning of dense prediction. This combination may offer a simple and efficient solution owing to its powerful and flexible task-specific learning and advantages of lower cost, less complexity and smaller parameters than the traditional MTL methods. We introduce deformable mixer Transformer with gating (DeMTG), a simple and effective encoder-decoder architecture up-to-date that incorporates the convolution and attention mechanism in a unified network for MTL. It is exquisitely designed to use advantages of each block, and provide deformable and comprehensive features for all tasks from local and global perspective. First, the deformable mixer encoder contains two types of operators: the channel-aware mixing operator leveraged to allow communication among different channels, and the spatial-aware deformable operator with deformable convolution applied to efficiently sample more informative spatial locations. Second, the task-aware gating transformer decoder is used to perform the task-specific predictions, in which task interaction block integrated with self-attention is applied to capture task interaction features, and the task query block integrated with gating attention is leveraged to select corresponding task-specific features. Further, the experiment results demonstrate that the proposed DeMTG uses fewer GFLOPs and significantly outperforms current Transformer-based and CNN-based competitive models on a variety of metrics on three dense prediction datasets. Our code and models are available at https://github.com/yangyangxu0/DeMTG. ",
    "url": "https://arxiv.org/abs/2308.05721",
    "authors": [
      "Yangyang Xu",
      "Yibo Yang",
      "Bernard Ghanemm",
      "Lefei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05724",
    "title": "Optimizing Performance of Feedforward and Convolutional Neural Networks  through Dynamic Activation Functions",
    "abstract": "Deep learning training training algorithms are a huge success in recent years in many fields including speech, text,image video etc. Deeper and deeper layers are proposed with huge success with resnet structures having around 152 layers. Shallow convolution neural networks(CNN's) are still an active research, where some phenomena are still unexplained. Activation functions used in the network are of utmost importance, as they provide non linearity to the networks. Relu's are the most commonly used activation function.We show a complex piece-wise linear(PWL) activation in the hidden layer. We show that these PWL activations work much better than relu activations in our networks for convolution neural networks and multilayer perceptrons. Result comparison in PyTorch for shallow and deep CNNs are given to further strengthen our case. ",
    "url": "https://arxiv.org/abs/2308.05724",
    "authors": [
      "Chinmay Rane",
      "Kanishka Tyagi",
      "Michael Manry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.05731",
    "title": "Rethinking Integration of Prediction and Planning in Deep Learning-Based  Automated Driving Systems: A Review",
    "abstract": "Automated driving has the potential to revolutionize personal, public, and freight mobility. Besides the enormous challenge of perception, i.e. accurately perceiving the environment using available sensor data, automated driving comprises planning a safe, comfortable, and efficient motion trajectory. To promote safety and progress, many works rely on modules that predict the future motion of surrounding traffic. Modular automated driving systems commonly handle prediction and planning as sequential separate tasks. While this accounts for the influence of surrounding traffic on the ego-vehicle, it fails to anticipate the reactions of traffic participants to the ego-vehicle's behavior. Recent works suggest that integrating prediction and planning in an interdependent joint step is necessary to achieve safe, efficient, and comfortable driving. While various models implement such integrated systems, a comprehensive overview and theoretical understanding of different principles are lacking. We systematically review state-of-the-art deep learning-based prediction, planning, and integrated prediction and planning models. Different facets of the integration ranging from model architecture and model design to behavioral aspects are considered and related to each other. Moreover, we discuss the implications, strengths, and limitations of different integration methods. By pointing out research gaps, describing relevant future challenges, and highlighting trends in the research field, we identify promising directions for future research. ",
    "url": "https://arxiv.org/abs/2308.05731",
    "authors": [
      "Steffen Hagedorn",
      "Marcel Hallgarten",
      "Martin Stoll",
      "Alexandru Condurache"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2308.05732",
    "title": "PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers",
    "abstract": "Time-dependent partial differential equations (PDEs) are ubiquitous in science and engineering. Recently, mostly due to the high computational cost of traditional solution techniques, deep neural network based surrogates have gained increased interest. The practical utility of such neural PDE solvers relies on their ability to provide accurate, stable predictions over long time horizons, which is a notoriously hard problem. In this work, we present a large-scale analysis of common temporal rollout strategies, identifying the neglect of non-dominant spatial frequency information, often associated with high frequencies in PDE solutions, as the primary pitfall limiting stable, accurate rollout performance. Based on these insights, we draw inspiration from recent advances in diffusion models to introduce PDE-Refiner; a novel model class that enables more accurate modeling of all frequency components via a multistep refinement process. We validate PDE-Refiner on challenging benchmarks of complex fluid dynamics, demonstrating stable and accurate rollouts that consistently outperform state-of-the-art models, including neural, numerical, and hybrid neural-numerical architectures. We further demonstrate that PDE-Refiner greatly enhances data efficiency, since the denoising objective implicitly induces a novel form of spectral data augmentation. Finally, PDE-Refiner's connection to diffusion models enables an accurate and efficient assessment of the model's predictive uncertainty, allowing us to estimate when the surrogate becomes inaccurate. ",
    "url": "https://arxiv.org/abs/2308.05732",
    "authors": [
      "Phillip Lippe",
      "Bastiaan S. Veeling",
      "Paris Perdikaris",
      "Richard E. Turner",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05734",
    "title": "AudioLDM 2: Learning Holistic Audio Generation with Self-supervised  Pretraining",
    "abstract": "Although audio generation shares commonalities across different types of audio, such as speech, music, and sound effects, designing models for each type requires careful consideration of specific objectives and biases that can significantly differ from those of other types. To bring us closer to a unified perspective of audio generation, this paper proposes a framework that utilizes the same learning method for speech, music, and sound effect generation. Our framework introduces a general representation of audio, called language of audio (LOA). Any audio can be translated into LOA based on AudioMAE, a self-supervised pre-trained representation learning model. In the generation process, we translate any modalities into LOA by using a GPT-2 model, and we perform self-supervised audio generation learning with a latent diffusion model conditioned on LOA. The proposed framework naturally brings advantages such as in-context learning abilities and reusable self-supervised pretrained AudioMAE and latent diffusion models. Experiments on the major benchmarks of text-to-audio, text-to-music, and text-to-speech demonstrate new state-of-the-art or competitive performance to previous approaches. Our demo and code are available at https://audioldm.github.io/audioldm2. ",
    "url": "https://arxiv.org/abs/2308.05734",
    "authors": [
      "Haohe Liu",
      "Qiao Tian",
      "Yi Yuan",
      "Xubo Liu",
      "Xinhao Mei",
      "Qiuqiang Kong",
      "Yuping Wang",
      "Wenwu Wang",
      "Yuxuan Wang",
      "Mark D. Plumbley"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.05741",
    "title": "Neural Progressive Meshes",
    "abstract": "The recent proliferation of 3D content that can be consumed on hand-held devices necessitates efficient tools for transmitting large geometric data, e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a challenge to storage as well as transmission bandwidth, and level-of-detail techniques are often used to transmit an asset using an appropriate bandwidth budget. It is especially desirable for these methods to transmit data progressively, improving the quality of the geometry with more data. Our key insight is that the geometric details of 3D meshes often exhibit similar local patterns even across different shapes, and thus can be effectively represented with a shared learned generative space. We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces. We further observe that additional residual features can be transmitted progressively between intermediate levels of subdivision that enable the client to control the tradeoff between bandwidth cost and quality of reconstruction, providing a neural progressive mesh representation. We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality. ",
    "url": "https://arxiv.org/abs/2308.05741",
    "authors": [
      "Yun-Chun Chen",
      "Vladimir G. Kim",
      "Noam Aigerman",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05744",
    "title": "PlankAssembly: Robust 3D Reconstruction from Three Orthographic Views  with Learnt Shape Programs",
    "abstract": "In this paper, we develop a new method to automatically convert 2D line drawings from three orthographic views into 3D CAD models. Existing methods for this problem reconstruct 3D models by back-projecting the 2D observations into 3D space while maintaining explicit correspondence between the input and output. Such methods are sensitive to errors and noises in the input, thus often fail in practice where the input drawings created by human designers are imperfect. To overcome this difficulty, we leverage the attention mechanism in a Transformer-based sequence generation model to learn flexible mappings between the input and output. Further, we design shape programs which are suitable for generating the objects of interest to boost the reconstruction accuracy and facilitate CAD modeling applications. Experiments on a new benchmark dataset show that our method significantly outperforms existing ones when the inputs are noisy or incomplete. ",
    "url": "https://arxiv.org/abs/2308.05744",
    "authors": [
      "Wentao Hu",
      "Jia Zheng",
      "Zixin Zhang",
      "Xiaojun Yuan",
      "Jian Yin",
      "Zihan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.05745",
    "title": "Iterative Reweighted Least Squares Networks With Convergence Guarantees  for Solving Inverse Imaging Problems",
    "abstract": "In this work we present a novel optimization strategy for image reconstruction tasks under analysis-based image regularization, which promotes sparse and/or low-rank solutions in some learned transform domain. We parameterize such regularizers using potential functions that correspond to weighted extensions of the $\\ell_p^p$-vector and $\\mathcal{S}_p^p$ Schatten-matrix quasi-norms with $0 < p \\le 1$. Our proposed minimization strategy extends the Iteratively Reweighted Least Squares (IRLS) method, typically used for synthesis-based $\\ell_p$ and $\\mathcal{S}_p$ norm and analysis-based $\\ell_1$ and nuclear norm regularization. We prove that under mild conditions our minimization algorithm converges linearly to a stationary point, and we provide an upper bound for its convergence rate. Further, to select the parameters of the regularizers that deliver the best results for the problem at hand, we propose to learn them from training data by formulating the supervised learning process as a stochastic bilevel optimization problem. We show that thanks to the convergence guarantees of our proposed minimization strategy, such optimization can be successfully performed with a memory-efficient implicit back-propagation scheme. We implement our learned IRLS variants as recurrent networks and assess their performance on the challenging image reconstruction tasks of non-blind deblurring, super-resolution and demosaicking. The comparisons against other existing learned reconstruction approaches demonstrate that our overall method is very competitive and in many cases outperforms existing unrolled networks, whose number of parameters is orders of magnitude higher than in our case. ",
    "url": "https://arxiv.org/abs/2308.05745",
    "authors": [
      "Iaroslav Koshelev",
      "Stamatios Lefkimmiatis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19069",
    "title": "Multi-source adversarial transfer learning for ultrasound image  segmentation with limited similarity",
    "abstract": "Lesion segmentation of ultrasound medical images based on deep learning techniques is a widely used method for diagnosing diseases. Although there is a large amount of ultrasound image data in medical centers and other places, labeled ultrasound datasets are a scarce resource, and it is likely that no datasets are available for new tissues/organs. Transfer learning provides the possibility to solve this problem, but there are too many features in natural images that are not related to the target domain. As a source domain, redundant features that are not conducive to the task will be extracted. Migration between ultrasound images can avoid this problem, but there are few types of public datasets, and it is difficult to find sufficiently similar source domains. Compared with natural images, ultrasound images have less information, and there are fewer transferable features between different ultrasound images, which may cause negative transfer. To this end, a multi-source adversarial transfer learning network for ultrasound image segmentation is proposed. Specifically, to address the lack of annotations, the idea of adversarial transfer learning is used to adaptively extract common features between a certain pair of source and target domains, which provides the possibility to utilize unlabeled ultrasound data. To alleviate the lack of knowledge in a single source domain, multi-source transfer learning is adopted to fuse knowledge from multiple source domains. In order to ensure the effectiveness of the fusion and maximize the use of precious data, a multi-source domain independent strategy is also proposed to improve the estimation of the target domain data distribution, which further increases the learning ability of the multi-source adversarial migration learning network in multiple domains. ",
    "url": "https://arxiv.org/abs/2305.19069",
    "authors": [
      "Yifu Zhang",
      "Hongru Li",
      "Tao Yang",
      "Rui Tao",
      "Zhengyuan Liu",
      "Shimeng Shi",
      "Jiansong Zhang",
      "Ning Ma",
      "Wujin Feng",
      "Zhanhu Zhang",
      "Xinyu Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05122",
    "title": "Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum  Disorder",
    "abstract": "The multifactorial etiology of autism spectrum disorder (ASD) suggests that its study would benefit greatly from multimodal approaches that combine data from widely varying platforms, e.g., neuroimaging, genetics, and clinical characterization. Prior neuroimaging-genetic analyses often apply naive feature concatenation approaches in data-driven work or use the findings from one modality to guide posthoc analysis of another, missing the opportunity to analyze the paired multimodal data in a truly unified approach. In this paper, we develop a more integrative model for combining genetic, demographic, and neuroimaging data. Inspired by the influence of genotype on phenotype, we propose using an attention-based approach where the genetic data guides attention to neuroimaging features of importance for model prediction. The genetic data is derived from copy number variation parameters, while the neuroimaging data is from functional magnetic resonance imaging. We evaluate the proposed approach on ASD classification and severity prediction tasks, using a sex-balanced dataset of 228 ASD and typically developing subjects in a 10-fold cross-validation framework. We demonstrate that our attention-based model combining genetic information, demographic data, and functional magnetic resonance imaging results in superior prediction performance compared to other multimodal approaches. ",
    "url": "https://arxiv.org/abs/2308.05122",
    "authors": [
      "Nicha C. Dvornek",
      "Catherine Sullivan",
      "James S. Duncan",
      "Abha R. Gupta"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.05125",
    "title": "Two Novel Approaches to Detect Community: A Case Study of Omicron  Lineage Variants PPI Network",
    "abstract": "The capacity to identify and analyze protein-protein interactions, along with their internal modular organization, plays a crucial role in comprehending the intricate mechanisms underlying biological processes at the molecular level. We can learn a lot about the structure and dynamics of these interactions by using network analysis. We can improve our understanding of the biological roots of disease pathogenesis by recognizing network communities. This knowledge, in turn, holds significant potential for driving advancements in drug discovery and facilitating personalized medicine approaches for disease treatment. In this study, we aimed to uncover the communities within the variant B.1.1.529 (Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four widely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label Propagation algorithm. Each of these algorithms has established prominence in the field and offers unique perspectives on identifying communities within complex networks. We also compare the networks by the global properties, statistic summary, subgraph count, graphlet and validate by the modulaity. By employing these approaches, we sought to gain deeper insights into the structural organization and interconnections present within the Omicron virus network. ",
    "url": "https://arxiv.org/abs/2308.05125",
    "authors": [
      "Mamata Das",
      "Selvakumar K.",
      "P.J.A. Alphonse"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2308.05133",
    "title": "Analyzing the Effect of Data Impurity on the Detection Performances of  Mental Disorders",
    "abstract": "The primary method for identifying mental disorders automatically has traditionally involved using binary classifiers. These classifiers are trained using behavioral data obtained from an interview setup. In this training process, data from individuals with the specific disorder under consideration are categorized as the positive class, while data from all other participants constitute the negative class. In practice, it is widely recognized that certain mental disorders share similar symptoms, causing the collected behavioral data to encompass a variety of attributes associated with multiple disorders. Consequently, attributes linked to the targeted mental disorder might also be present within the negative class. This data impurity may lead to sub-optimal training of the classifier for a mental disorder of interest. In this study, we investigate this hypothesis in the context of major depressive disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results show that upon removal of such data impurity, MDD and PTSD detection performances are significantly improved. ",
    "url": "https://arxiv.org/abs/2308.05133",
    "authors": [
      "Rohan Kumar Gupta",
      "Rohit Sinha"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.05142",
    "title": "Inconsistencies between the forces from code live load models and real  traffic on truss bridges",
    "abstract": "The forces acting on bridge structural elements caused by live loads are computed by live load models defined in design codes. In most cases, such live load models are defined by studies performed on girder bridges, where extreme values of shear forces and bending moment are intended to be predicted. This paper shows that when code live load models are applied to truss bridges, the estimated forces in some structural elements may not be representative of those caused by actual traffic. Three WIM (weigh-in-motion) databases, which are recorded on roads in Mexico, are used as real traffic data. The results suggest that current code live load models are not entirely adequate to estimate forces in structural elements of truss bridges. ",
    "url": "https://arxiv.org/abs/2308.05142",
    "authors": [
      "Alejandro Hern\u00e1ndez-Mart\u00ednez",
      "Adri\u00e1n David Garc\u00eda-Soto",
      "Hugo Hern\u00e1ndez-Barrios",
      "Jes\u00fas Gerardo Vald\u00e9s-V\u00e1zquez"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2308.05175",
    "title": "Cycles in graphs and in hypergraphs",
    "abstract": "This is an expository paper. A $1$-cycle in a graph is a set $C$ of edges such that every vertex is contained in an even number of edges from $C$. E.g., a cycle in the sense of graph theory is a $1$-cycle, but not vice versa. It is easy to check that the sum (modulo $2$) of $1$-cycles is a $1$-cycle. In this text we study the following problems: to find $\\bullet$ the number of all 1-cycles in a given graph; $\\bullet$ a small number of 1-cycles in a given graph such that any 1-cycle is the sum of some of them. We also consider generalizations (of these problems) to graphs with symmetry, and to $2$-cycles in $2$-dimensional hypergraphs. ",
    "url": "https://arxiv.org/abs/2308.05175",
    "authors": [
      "E. Alkin",
      "S. Dzhenzher",
      "O. Nikitenko",
      "A. Skopenkov",
      "A. Voropaev"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2308.05178",
    "title": "An Improved Model for Diabetic Retinopathy Detection by using Transfer  Learning and Ensemble Learning",
    "abstract": "Diabetic Retinopathy (DR) is an ocular condition caused by a sustained high level of sugar in the blood, which causes the retinal capillaries to block and bleed, causing retinal tissue damage. It usually results in blindness. Early detection can help in lowering the risk of DR and its severity. The robust and accurate prediction and detection of diabetic retinopathy is a challenging task. This paper develops a machine learning model for detecting Diabetic Retinopathy that is entirely accurate. Pre-trained models such as ResNet50, InceptionV3, Xception, DenseNet121, VGG19, NASNetMobile, MobileNetV2, DensNet169, and DenseNet201 with pooling layer, dense layer, and appropriate dropout layer at the bottom of them were carried out in transfer learning (TL) approach. Data augmentation and regularization was performed to reduce overfitting. Transfer Learning model of DenseNet121, Average and weighted ensemble of DenseNet169 and DenseNet201 TL architectures contribute individually the highest accuracy of 100%, the highest precision, recall, F-1 score of 100%, 100%, and 100%, respectively. ",
    "url": "https://arxiv.org/abs/2308.05178",
    "authors": [
      "Md. Simul Hasan Talukder",
      "Ajay Kirshno Sarkar",
      "Sharmin Akter",
      "Md. Nuhi-Alamin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05226",
    "title": "Training neural networks with end-to-end optical backpropagation",
    "abstract": "Optics is an exciting route for the next generation of computing hardware for machine learning, promising several orders of magnitude enhancement in both computational speed and energy efficiency. However, to reach the full capacity of an optical neural network it is necessary that the computing not only for the inference, but also for the training be implemented optically. The primary algorithm for training a neural network is backpropagation, in which the calculation is performed in the order opposite to the information flow for inference. While straightforward in a digital computer, optical implementation of backpropagation has so far remained elusive, particularly because of the conflicting requirements for the optical element that implements the nonlinear activation function. In this work, we address this challenge for the first time with a surprisingly simple and generic scheme. Saturable absorbers are employed for the role of the activation units, and the required properties are achieved through a pump-probe process, in which the forward propagating signal acts as the pump and backward as the probe. Our approach is adaptable to various analog platforms, materials, and network structures, and it demonstrates the possibility of constructing neural networks entirely reliant on analog optical processes for both training and inference tasks. ",
    "url": "https://arxiv.org/abs/2308.05226",
    "authors": [
      "James Spall",
      "Xianxin Guo",
      "A. I. Lvovsky"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1901.01381",
    "title": "Brain segmentation based on multi-atlas guided 3D fully convolutional  network ensembles",
    "abstract": " Title: Brain segmentation based on multi-atlas guided 3D fully convolutional  network ensembles ",
    "url": "https://arxiv.org/abs/1901.01381",
    "authors": [
      "Jiong Wu",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.11313",
    "title": "Physics-informed neural networks for one-dimensional sound field  predictions with parameterized sources and impedance boundaries",
    "abstract": " Comments: 11 pages, 5 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2109.11313",
    "authors": [
      "Nikolas Borrel-Jensen",
      "Allan P. Engsig-Karup",
      "Cheol-Ho Jeong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2112.06193",
    "title": "GUNNEL: Guided Mixup Augmentation and Multi-View Fusion for Aquatic  Animal Segmentation",
    "abstract": " Comments: The code is available at this https URL . The dataset is available at this https URL ",
    "url": "https://arxiv.org/abs/2112.06193",
    "authors": [
      "Minh-Quan Le",
      "Trung-Nghia Le",
      "Tam V. Nguyen",
      "Isao Echizen",
      "Minh-Triet Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10062",
    "title": "A sine transform based preconditioned MINRES method for all-at-once  systems from constant and variable-coefficient evolutionary PDEs",
    "abstract": " Title: A sine transform based preconditioned MINRES method for all-at-once  systems from constant and variable-coefficient evolutionary PDEs ",
    "url": "https://arxiv.org/abs/2201.10062",
    "authors": [
      "Sean Hon",
      "Po Yin Fung",
      "Jiamei Dong",
      "Stefano Serra-Capizzano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.03026",
    "title": "Context Autoencoder for Self-Supervised Representation Learning",
    "abstract": " Comments: Accepted by International Journal of Computer Vision (IJCV) ",
    "url": "https://arxiv.org/abs/2202.03026",
    "authors": [
      "Xiaokang Chen",
      "Mingyu Ding",
      "Xiaodi Wang",
      "Ying Xin",
      "Shentong Mo",
      "Yunhao Wang",
      "Shumin Han",
      "Ping Luo",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.09027",
    "title": "Trusted AI in Multi-agent Systems: An Overview of Privacy and Security  for Distributed Learning",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1907.09470, arXiv:2003.02133, arXiv:1606.05053, arXiv:1812.06415 by other authors ",
    "url": "https://arxiv.org/abs/2202.09027",
    "authors": [
      "Chuan Ma",
      "Jun Li",
      "Kang Wei",
      "Bo Liu",
      "Ming Ding",
      "Long Yuan",
      "Zhu Han",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2209.04278",
    "title": "Deep learning-based Crop Row Detection for Infield Navigation of  Agri-Robots",
    "abstract": " Comments: Published in Journal of Field Robotics: this https URL ",
    "url": "https://arxiv.org/abs/2209.04278",
    "authors": [
      "Rajitha de Silva",
      "Grzegorz Cielniak",
      "Gang Wang",
      "Junfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.07902",
    "title": "MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning",
    "abstract": " Comments: Accepted by NeurIPS 2022 as Spotlight ",
    "url": "https://arxiv.org/abs/2209.07902",
    "authors": [
      "Jiangmeng Li",
      "Wenwen Qiang",
      "Yanan Zhang",
      "Wenyi Mo",
      "Changwen Zheng",
      "Bing Su",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04087",
    "title": "Symmetry Defense Against CNN Adversarial Perturbation Attacks",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2210.04087",
    "authors": [
      "Blerta Lindqvist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13662",
    "title": "Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis  Testing: A Lesson From Fano",
    "abstract": " Title: Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis  Testing: A Lesson From Fano ",
    "url": "https://arxiv.org/abs/2210.13662",
    "authors": [
      "Chuan Guo",
      "Alexandre Sablayrolles",
      "Maziar Sanjabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.02365",
    "title": "On Robustness for the Skolem, Positivity and Ultimate Positivity  Problems",
    "abstract": " Comments: Extended version of conference paper which appeared in the proceedings of STACS'22 ",
    "url": "https://arxiv.org/abs/2211.02365",
    "authors": [
      "S. Akshay",
      "Hugo Bazille",
      "Blaise Genest",
      "Mihir Vahanwala"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2211.11475",
    "title": "Sensing-Assisted Communication in Vehicular Networks with Intelligent  Surface",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. arXiv admin note: text overlap with arXiv:2211.04200 ",
    "url": "https://arxiv.org/abs/2211.11475",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Wen Chen",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.00790",
    "title": "Online learning techniques for prediction of temporal tabular datasets  with regime changes",
    "abstract": " Title: Online learning techniques for prediction of temporal tabular datasets  with regime changes ",
    "url": "https://arxiv.org/abs/2301.00790",
    "authors": [
      "Thomas Wong",
      "Mauricio Barahona"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.03900",
    "title": "Strong SDP based bounds on the cutwidth of a graph",
    "abstract": " Title: Strong SDP based bounds on the cutwidth of a graph ",
    "url": "https://arxiv.org/abs/2301.03900",
    "authors": [
      "Elisabeth Gaar",
      "Diane Puges",
      "Angelika Wiegele"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.05869",
    "title": "Functional Neural Networks: Shift invariant models for functional data  with applications to EEG classification",
    "abstract": " Comments: 16 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2301.05869",
    "authors": [
      "Florian Heinrichs",
      "Mavin Heim",
      "Corinna Weber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.10822",
    "title": "RobustPdM: Designing Robust Predictive Maintenance against Adversarial  Attacks",
    "abstract": " Title: RobustPdM: Designing Robust Predictive Maintenance against Adversarial  Attacks ",
    "url": "https://arxiv.org/abs/2301.10822",
    "authors": [
      "Ayesha Siddique",
      "Ripan Kumar Kundu",
      "Gautam Raj Mode",
      "Khaza Anuarul Hoque"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00453",
    "title": "Width and Depth Limits Commute in Residual Networks",
    "abstract": " Comments: 24 pages, 8 figures. arXiv admin note: text overlap with arXiv:2210.00688 ",
    "url": "https://arxiv.org/abs/2302.00453",
    "authors": [
      "Soufiane Hayou",
      "Greg Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05194",
    "title": "Contrastive Model Adaptation for Cross-Condition Robustness in Semantic  Segmentation",
    "abstract": " Comments: International Conference on Computer Vision (ICCV) 2023 ",
    "url": "https://arxiv.org/abs/2303.05194",
    "authors": [
      "David Bruggemann",
      "Christos Sakaridis",
      "Tim Br\u00f6dermann",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06024",
    "title": "A hybrid deep-learning-metaheuristic framework for bi-level network  design problems",
    "abstract": " Comments: Two case studies added, intro, discussion and conclusion extended, details added to method and experiments, typos fixed, title revised, references added ",
    "url": "https://arxiv.org/abs/2303.06024",
    "authors": [
      "Bahman Madadi",
      "Goncalo Homem de Almeida Correia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.12384",
    "title": "RegFormer: An Efficient Projection-Aware Transformer Network for  Large-Scale Point Cloud Registration",
    "abstract": " Comments: Accepted by ICCV2023. Codes are released at this https URL ",
    "url": "https://arxiv.org/abs/2303.12384",
    "authors": [
      "Jiuming Liu",
      "Guangming Wang",
      "Zhe Liu",
      "Chaokang Jiang",
      "Marc Pollefeys",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.13381",
    "title": "Cosys-AirSim: A Real-Time Simulation Framework Expanded for Complex  Industrial Applications",
    "abstract": " Comments: Presented at Annual Modeling and Simulation Conference, ANNSIM 2023, this https URL ",
    "url": "https://arxiv.org/abs/2303.13381",
    "authors": [
      "Wouter Jansen",
      "Erik Verreycken",
      "Anthony Schenck",
      "Jean-Edouard Blanquart",
      "Connor Verhulst",
      "Nico Huebel",
      "Jan Steckel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.14961",
    "title": "Diffusion Denoised Smoothing for Certified and Adversarial Robust  Out-Of-Distribution Detection",
    "abstract": " Title: Diffusion Denoised Smoothing for Certified and Adversarial Robust  Out-Of-Distribution Detection ",
    "url": "https://arxiv.org/abs/2303.14961",
    "authors": [
      "Nicola Franco",
      "Daniel Korth",
      "Jeanette Miriam Lorenz",
      "Karsten Roscher",
      "Stephan Guennemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.02730",
    "title": "Fair Ordering via Streaming Social Choice Theory",
    "abstract": " Title: Fair Ordering via Streaming Social Choice Theory ",
    "url": "https://arxiv.org/abs/2304.02730",
    "authors": [
      "Geoffrey Ramseyer",
      "Ashish Goel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.05874",
    "title": "Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of  Alzheimer's Disease using EEG Data",
    "abstract": " Comments: 12 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2304.05874",
    "authors": [
      "Dominik Klepl",
      "Fei He",
      "Min Wu",
      "Daniel J. Blackburn",
      "Ptolemaios G. Sarrigiannis"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.03829",
    "title": "Improving Image-Based Precision Medicine with Uncertainty-Aware Causal  Models",
    "abstract": " Title: Improving Image-Based Precision Medicine with Uncertainty-Aware Causal  Models ",
    "url": "https://arxiv.org/abs/2305.03829",
    "authors": [
      "Joshua Durso-Finley",
      "Jean-Pierre Falet",
      "Raghav Mehta",
      "Douglas L. Arnold",
      "Nick Pawlowski",
      "Tal Arbel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12932",
    "title": "Forecasting Irregularly Sampled Time Series using Graphs",
    "abstract": " Title: Forecasting Irregularly Sampled Time Series using Graphs ",
    "url": "https://arxiv.org/abs/2305.12932",
    "authors": [
      "Vijaya Krishna Yalavarthi",
      "Kiran Madhusudhanan",
      "Randolf Sholz",
      "Nourhan Ahmed",
      "Johannes Burchert",
      "Shayan Jawed",
      "Stefan Born",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19170",
    "title": "Forward-Forward Training of an Optical Neural Network",
    "abstract": " Title: Forward-Forward Training of an Optical Neural Network ",
    "url": "https://arxiv.org/abs/2305.19170",
    "authors": [
      "Ilker Oguz",
      "Junjie Ke",
      "Qifei Wang",
      "Feng Yang",
      "Mustafa Yildirim",
      "Niyazi Ulas Dinc",
      "Jih-Liang Hsieh",
      "Christophe Moser",
      "Demetri Psaltis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2306.10608",
    "title": "STHG: Spatial-Temporal Heterogeneous Graph Learning for Advanced  Audio-Visual Diarization",
    "abstract": " Comments: Validation report for the Ego4D challenge at CVPR 2023 ",
    "url": "https://arxiv.org/abs/2306.10608",
    "authors": [
      "Kyle Min"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.00743",
    "title": "Joint Power Allocation and Beamforming for Active IRS-aided Directional  Modulation Network",
    "abstract": " Title: Joint Power Allocation and Beamforming for Active IRS-aided Directional  Modulation Network ",
    "url": "https://arxiv.org/abs/2307.00743",
    "authors": [
      "Rongen Dong",
      "Feng Shu",
      "Yongzhao Li",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2307.02279",
    "title": "From NeurODEs to AutoencODEs: a mean-field control framework for  width-varying Neural Networks",
    "abstract": " Comments: 35 pages, 11 figures. Minor adjustments and new bibliographical references ",
    "url": "https://arxiv.org/abs/2307.02279",
    "authors": [
      "Cristina Cipriani",
      "Massimo Fornasier",
      "Alessandro Scagliotti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.07944",
    "title": "Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and  Class-balanced Pseudo-Labeling",
    "abstract": " Comments: Accepted by ICCV 2023, camera-ready ",
    "url": "https://arxiv.org/abs/2307.07944",
    "authors": [
      "Zhuoxiao Chen",
      "Yadan Luo",
      "Zheng Wang",
      "Mahsa Baktashmotlagh",
      "Zi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08695",
    "title": "Neural Video Depth Stabilizer",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2307.08695",
    "authors": [
      "Yiran Wang",
      "Min Shi",
      "Jiaqi Li",
      "Zihao Huang",
      "Zhiguo Cao",
      "Jianming Zhang",
      "Ke Xian",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.16361",
    "title": "Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks  for Defending Adversarial Examples",
    "abstract": " Comments: 8 pages 6 figures ",
    "url": "https://arxiv.org/abs/2307.16361",
    "authors": [
      "Qiufan Ji",
      "Lin Wang",
      "Cong Shi",
      "Shengshan Hu",
      "Yingying Chen",
      "Lichao Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.02648",
    "title": "Privacy Preserving In-memory Computing Engine",
    "abstract": " Title: Privacy Preserving In-memory Computing Engine ",
    "url": "https://arxiv.org/abs/2308.02648",
    "authors": [
      "Haoran Geng",
      "Jianqiao Mo",
      "Dayane Reis",
      "Jonathan Takeshita",
      "Taeho Jung",
      "Brandon Reagen",
      "Michael Niemier",
      "Xiaobo Sharon Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2308.03382",
    "title": "Enhancing Nucleus Segmentation with HARU-Net: A Hybrid Attention Based  Residual U-Blocks Network",
    "abstract": " Comments: Nucleus segmentation, Deep learning, Instance segmentation, Medical imaging, Dual-Branch network ",
    "url": "https://arxiv.org/abs/2308.03382",
    "authors": [
      "Junzhou Chen",
      "Qian Huang",
      "Yulin Chen",
      "Linyi Qian",
      "Chengyuan Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.04365",
    "title": "SLEM: Machine Learning for Path Modeling and Causal Inference with Super  Learner Equation Modeling",
    "abstract": " Title: SLEM: Machine Learning for Path Modeling and Causal Inference with Super  Learner Equation Modeling ",
    "url": "https://arxiv.org/abs/2308.04365",
    "authors": [
      "Matthew J. Vowels"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2308.04438",
    "title": "Digital Healthcare in The Metaverse: Insights into Privacy and Security",
    "abstract": " Title: Digital Healthcare in The Metaverse: Insights into Privacy and Security ",
    "url": "https://arxiv.org/abs/2308.04438",
    "authors": [
      "Mehdi Letafati",
      "Safa Otoum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.04704",
    "title": "A Feature Set of Small Size for the PDF Malware Detection",
    "abstract": " Comments: Accepted for publication at the ACM SIGKDD & Annual KDD Conference workshop on Knowledge-infused Machine Learning, 2023 ",
    "url": "https://arxiv.org/abs/2308.04704",
    "authors": [
      "Ran Liu",
      "Charles Nicholas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05011",
    "title": "Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with  Distinct Inlier Categories",
    "abstract": " Comments: Accepted to ICML 2023 Workshop on Machine Learning for Astrophysics ",
    "url": "https://arxiv.org/abs/2308.05011",
    "authors": [
      "Manuel P\u00e9rez-Carrasco",
      "Guillermo Cabrera-Vives",
      "Lorena Hern\u00e1ndez-Garc\u00eda",
      "Francisco Forster",
      "Paula S\u00e1nchez-S\u00e1ez",
      "Alejandra Mu\u00f1oz Arancibia",
      "Nicol\u00e1s Astorga",
      "Franz Bauer",
      "Amelia Bayo",
      "Martina C\u00e1diz-Leyton",
      "Marcio Catelan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ]
  },
  {
    "id": "arXiv:2308.05013",
    "title": "Dual Intents Graph Modeling for User-centric Group Discovery",
    "abstract": " Comments: Accepted by CIKM'23 as Long Paper ",
    "url": "https://arxiv.org/abs/2308.05013",
    "authors": [
      "Xixi Wu",
      "Yun Xiong",
      "Yao Zhang",
      "Yizhu Jiao",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.05068",
    "title": "Geometric Learning-Based Transformer Network for Estimation of  Segmentation Errors",
    "abstract": " Comments: Accepted in MICCAI workshop on ShapeMI, 2023 ",
    "url": "https://arxiv.org/abs/2308.05068",
    "authors": [
      "Sneha Sree C",
      "Mohammad Al Fahim",
      "Keerthi Ram",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]