[
  {
    "id": "arXiv:2308.13534",
    "title": "Building Trust in Conversational AI: A Comprehensive Review and Solution  Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge  Graph",
    "abstract": "Conversational AI systems have emerged as key enablers of human-like interactions across diverse sectors. Nevertheless, the balance between linguistic nuance and factual accuracy has proven elusive. In this paper, we first introduce LLMXplorer, a comprehensive tool that provides an in-depth review of over 150 Large Language Models (LLMs), elucidating their myriad implications ranging from social and ethical to regulatory, as well as their applicability across industries. Building on this foundation, we propose a novel functional architecture that seamlessly integrates the structured dynamics of Knowledge Graphs with the linguistic capabilities of LLMs. Validated using real-world AI news data, our architecture adeptly blends linguistic sophistication with factual rigour and further strengthens data security through Role-Based Access Control. This research provides insights into the evolving landscape of conversational AI, emphasizing the imperative for systems that are efficient, transparent, and trustworthy. ",
    "url": "https://arxiv.org/abs/2308.13534",
    "authors": [
      "Ahtsham Zafar",
      "Venkatesh Balavadhani Parthasarathy",
      "Chan Le Van",
      "Saad Shahid",
      "Aafaq Iqbal khan",
      "Arsalan Shahid"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13541",
    "title": "Adversarial Collaborative Filtering for Free",
    "abstract": "Collaborative Filtering (CF) has been successfully used to help users discover the items of interest. Nevertheless, existing CF methods suffer from noisy data issue, which negatively impacts the quality of recommendation. To tackle this problem, many prior studies leverage adversarial learning to regularize the representations of users/items, which improves both generalizability and robustness. Those methods often learn adversarial perturbations and model parameters under min-max optimization framework. However, there still have two major drawbacks: 1) Existing methods lack theoretical guarantees of why adding perturbations improve the model generalizability and robustness; 2) Solving min-max optimization is time-consuming. In addition to updating the model parameters, each iteration requires additional computations to update the perturbations, making them not scalable for industry-scale datasets. In this paper, we present Sharpness-aware Collaborative Filtering (SharpCF), a simple yet effective method that conducts adversarial training without extra computational cost over the base optimizer. To achieve this goal, we first revisit the existing adversarial collaborative filtering and discuss its connection with recent Sharpness-aware Minimization. This analysis shows that adversarial training actually seeks model parameters that lie in neighborhoods around the optimal model parameters having uniformly low loss values, resulting in better generalizability. To reduce the computational overhead, SharpCF introduces a novel trajectory loss to measure the alignment between current weights and past weights. Experimental results on real-world datasets demonstrate that our SharpCF achieves superior performance with almost zero additional computational cost comparing to adversarial training. ",
    "url": "https://arxiv.org/abs/2308.13541",
    "authors": [
      "Huiyuan Chen",
      "Xiaoting Li",
      "Vivian Lai",
      "Chin-Chia Michael Yeh",
      "Yujie Fan",
      "Yan Zheng",
      "Mahashweta Das",
      "Hao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13559",
    "title": "Machine Unlearning for Causal Inference",
    "abstract": "Machine learning models play a vital role in making predictions and deriving insights from data and are being increasingly used for causal inference. To preserve user privacy, it is important to enable the model to forget some of its learning/captured information about a given user (machine unlearning). This paper introduces the concept of machine unlearning for causal inference, particularly propensity score matching and treatment effect estimation, which aims to refine and improve the performance of machine learning models for causal analysis given the above unlearning requirements. The paper presents a methodology for machine unlearning using a neural network-based propensity score model. The dataset used in the study is the Lalonde dataset, a widely used dataset for evaluating the effectiveness i.e. the treatment effect of job training programs. The methodology involves training an initial propensity score model on the original dataset and then creating forget sets by selectively removing instances, as well as matched instance pairs. based on propensity score matching. These forget sets are used to evaluate the retrained model, allowing for the elimination of unwanted associations. The actual retraining of the model is performed using the retain set. The experimental results demonstrate the effectiveness of the machine unlearning approach. The distribution and histogram analysis of propensity scores before and after unlearning provide insights into the impact of the unlearning process on the data. This study represents the first attempt to apply machine unlearning techniques to causal inference. ",
    "url": "https://arxiv.org/abs/2308.13559",
    "authors": [
      "Vikas Ramachandra",
      "Mohit Sethi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13582",
    "title": "Software Defect Prediction by Online Learning Considering Defect  Overlooking",
    "abstract": "Building defect prediction models based on online learning can enhance prediction accuracy. It continuously rebuilds a new prediction model when adding a new data point. However, predicting a module as \"non-defective\" (i.e., negative prediction) can result in fewer test cases for such modules. Therefore, defects can be overlooked during testing, even when the module is defective. The erroneous test results are used as learning data by online learning, which could negatively affect prediction accuracy. In our experiment, we demonstrate this negative influence on prediction accuracy. ",
    "url": "https://arxiv.org/abs/2308.13582",
    "authors": [
      "Yuta Yamasaki",
      "Nikolay Fedorov",
      "Masateru Tsunoda",
      "Akito Monden",
      "Amjed Tahir",
      "Kwabena Ebo Bennin",
      "Koji Toda",
      "Keitaro Nakasai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.13589",
    "title": "Implementing Snort Intrusion Prevention System (IPS) for Network  Forensic Analysis",
    "abstract": "The security trade confidentiality, integrity and availability are the main pillar of the information systems as every organization emphasize of the security. From last few decades, digital data is the main asset for every digital or non-digital organization. The proliferation of easily accessible attack software on the internet has lowered the barrier for individuals without hacking skills to engage in malicious activities. An Industrial organization operates a server that (Confluence) serves as a learning platform for newly hired employees or Management training officers, thereby making it vulnerable to potential attacks using readily available internet-based software. To mitigate this risk, it is essential to implement a security system capable of detecting and preventing attacks, as well as conducting investigations. This research project aims to develop a comprehensive security system that can detect attack attempts, initiate preventive measures, and carry out investigations by analyzing attack logs. The study adopted a survey methodology and spanned a period of four months, from March 1, 2023, to June 31, 2023. The outcome of this research is a robust security system that effectively identifies attack attempts, blocks the attacker's IP address, and employs network forensic techniques for investigation purposes. The findings indicate that deploying Snort in IPS mode on PfSense enables the detection of attacks targeting e-learning servers, triggering automatic preventive measures such as IP address blocking. The alerts generated by Snort facilitate investigative actions through network forensics, allowing for accurate reporting on the detrimental effects of the attacks. ",
    "url": "https://arxiv.org/abs/2308.13589",
    "authors": [
      "Kashif Ishaq",
      "Hafiz Ahsan Javed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.13612",
    "title": "Is Deep Learning Network Necessary for Image Generation?",
    "abstract": "Recently, images are considered samples from a high-dimensional distribution, and deep learning has become almost synonymous with image generation. However, is a deep learning network truly necessary for image generation? In this paper, we investigate the possibility of image generation without using a deep learning network, motivated by validating the assumption that images follow a high-dimensional distribution. Since images are assumed to be samples from such a distribution, we utilize the Gaussian Mixture Model (GMM) to describe it. In particular, we employ a recent distribution learning technique named as Monte-Carlo Marginalization to capture the parameters of the GMM based on image samples. Moreover, we also use the Singular Value Decomposition (SVD) for dimensionality reduction to decrease computational complexity. During our evaluation experiment, we first attempt to model the distribution of image samples directly to verify the assumption that images truly follow a distribution. We then use the SVD for dimensionality reduction. The principal components, rather than raw image data, are used for distribution learning. Compared to methods relying on deep learning networks, our approach is more explainable, and its performance is promising. Experiments show that our images have a lower FID value compared to those generated by variational auto-encoders, demonstrating the feasibility of image generation without deep learning networks. ",
    "url": "https://arxiv.org/abs/2308.13612",
    "authors": [
      "Chenqiu Zhao",
      "Guanfang Dong",
      "Anup Basu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13645",
    "title": "Active learning for fast and slow modeling attacks on Arbiter PUFs",
    "abstract": "Modeling attacks, in which an adversary uses machine learning techniques to model a hardware-based Physically Unclonable Function (PUF) pose a great threat to the viability of these hardware security primitives. In most modeling attacks, a random subset of challenge-response-pairs (CRPs) are used as the labeled data for the machine learning algorithm. Here, for the arbiter-PUF, a delay based PUF which may be viewed as a linear threshold function with random weights (due to manufacturing imperfections), we investigate the role of active learning in Support Vector Machine (SVM) learning. We focus on challenge selection to help SVM algorithm learn ``fast'' and learn ``slow''. Our methods construct challenges rather than relying on a sample pool of challenges as in prior work. Using active learning to learn ``fast'' (less CRPs revealed, higher accuracies) may help manufacturers learn the manufactured PUFs more efficiently, or may form a more powerful attack when the attacker may query the PUF for CRPs at will. Using active learning to select challenges from which learning is ``slow'' (low accuracy despite a large number of revealed CRPs) may provide a basis for slowing down attackers who are limited to overhearing CRPs. ",
    "url": "https://arxiv.org/abs/2308.13645",
    "authors": [
      "Vincent Dumoulin",
      "Wenjing Rao",
      "Natasha Devroye"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13658",
    "title": "Generating and Explaining Corner Cases Using Learnt Probabilistic Lane  Graphs",
    "abstract": "Validating the safety of Autonomous Vehicles (AVs) operating in open-ended, dynamic environments is challenging as vehicles will eventually encounter safety-critical situations for which there is not representative training data. By increasing the coverage of different road and traffic conditions and by including corner cases in simulation-based scenario testing, the safety of AVs can be improved. However, the creation of corner case scenarios including multiple agents is non-trivial. Our approach allows engineers to generate novel, realistic corner cases based on historic traffic data and to explain why situations were safety-critical. In this paper, we introduce Probabilistic Lane Graphs (PLGs) to describe a finite set of lane positions and directions in which vehicles might travel. The structure of PLGs is learnt directly from spatio-temporal traffic data. The graph model represents the actions of the drivers in response to a given state in the form of a probabilistic policy. We use reinforcement learning techniques to modify this policy and to generate realistic and explainable corner case scenarios which can be used for assessing the safety of AVs. ",
    "url": "https://arxiv.org/abs/2308.13658",
    "authors": [
      "Enrik Maci",
      "Rhys Howard",
      "Lars Kunze"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.13663",
    "title": "Network Embedding Using Sparse Approximations of Random Walks",
    "abstract": "In this paper, we propose an efficient numerical implementation of Network Embedding based on commute times, using sparse approximation of a diffusion process on the network obtained by a modified version of the diffusion wavelet algorithm. The node embeddings are computed by optimizing the cross entropy loss via the stochastic gradient descent method with sampling of low-dimensional representations of green functions. We demonstrate the efficacy of this method for data clustering and multi-label classification through several examples, and compare its performance over existing methods in terms of efficiency and accuracy. Theoretical issues justifying the scheme are also discussed. ",
    "url": "https://arxiv.org/abs/2308.13663",
    "authors": [
      "Paula Mercurio",
      "Di Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13671",
    "title": "Enhancing Landmark Detection in Cluttered Real-World Scenarios with  Vision Transformers",
    "abstract": "Visual place recognition tasks often encounter significant challenges in landmark detection due to the presence of irrelevant objects such as humans, cars, and trees, despite the remarkable progress achieved by previous models, especially in the context of transformers. To address this issue, we propose a novel method that effectively leverages the strengths of vision transformers. By employing a meticulous selection process, our approach identifies and isolates specific patches within the image that correspond to occluding objects. To evaluate the efficacy of our method, we created augmented datasets and conducted comprehensive testing. The results demonstrate the superior accuracy achieved by our proposed approach. This research contributes to the advancement of landmark detection in visual place recognition and shows the potential of leveraging vision transformers to overcome challenges posed by cluttered real-world scenarios. ",
    "url": "https://arxiv.org/abs/2308.13671",
    "authors": [
      "Mohammad Javad Rajabi",
      "Morteza Mirzai",
      "Ahmad Nickabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13676",
    "title": "Rethinking Language Models as Symbolic Knowledge Graphs",
    "abstract": "Symbolic knowledge graphs (KGs) play a pivotal role in knowledge-centric applications such as search, question answering and recommendation. As contemporary language models (LMs) trained on extensive textual data have gained prominence, researchers have extensively explored whether the parametric knowledge within these models can match up to that present in knowledge graphs. Various methodologies have indicated that enhancing the size of the model or the volume of training data enhances its capacity to retrieve symbolic knowledge, often with minimal or no human supervision. Despite these advancements, there is a void in comprehensively evaluating whether LMs can encompass the intricate topological and semantic attributes of KGs, attributes crucial for reasoning processes. In this work, we provide an exhaustive evaluation of language models of varying sizes and capabilities. We construct nine qualitative benchmarks that encompass a spectrum of attributes including symmetry, asymmetry, hierarchy, bidirectionality, compositionality, paths, entity-centricity, bias and ambiguity. Additionally, we propose novel evaluation metrics tailored for each of these attributes. Our extensive evaluation of various LMs shows that while these models exhibit considerable potential in recalling factual information, their ability to capture intricate topological and semantic traits of KGs remains significantly constrained. We note that our proposed evaluation metrics are more reliable in evaluating these abilities than the existing metrics. Lastly, some of our benchmarks challenge the common notion that larger LMs (e.g., GPT-4) universally outshine their smaller counterparts (e.g., BERT). ",
    "url": "https://arxiv.org/abs/2308.13676",
    "authors": [
      "Vishwas Mruthyunjaya",
      "Pouya Pezeshkpour",
      "Estevam Hruschka",
      "Nikita Bhutani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13680",
    "title": "ACC-UNet: A Completely Convolutional UNet model for the 2020s",
    "abstract": "This decade is marked by the introduction of Vision Transformer, a radical paradigm shift in broad computer vision. A similar trend is followed in medical imaging, UNet, one of the most influential architectures, has been redesigned with transformers. Recently, the efficacy of convolutional models in vision is being reinvestigated by seminal works such as ConvNext, which elevates a ResNet to Swin Transformer level. Deriving inspiration from this, we aim to improve a purely convolutional UNet model so that it can be on par with the transformer-based models, e.g, Swin-Unet or UCTransNet. We examined several advantages of the transformer-based UNet models, primarily long-range dependencies and cross-level skip connections. We attempted to emulate them through convolution operations and thus propose, ACC-UNet, a completely convolutional UNet model that brings the best of both worlds, the inherent inductive biases of convnets with the design decisions of transformers. ACC-UNet was evaluated on 5 different medical image segmentation benchmarks and consistently outperformed convnets, transformers, and their hybrids. Notably, ACC-UNet outperforms state-of-the-art models Swin-Unet and UCTransNet by $2.64 \\pm 2.54\\%$ and $0.45 \\pm 1.61\\%$ in terms of dice score, respectively, while using a fraction of their parameters ($59.26\\%$ and $24.24\\%$). Our codes are available at https://github.com/kiharalab/ACC-UNet. ",
    "url": "https://arxiv.org/abs/2308.13680",
    "authors": [
      "Nabil Ibtehaz",
      "Daisuke Kihara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13699",
    "title": "Party Prediction for Twitter",
    "abstract": "A large number of studies on social media compare the behaviour of users from different political parties. As a basic step, they employ a predictive model for inferring their political affiliation. The accuracy of this model can change the conclusions of a downstream analysis significantly, yet the choice between different models seems to be made arbitrarily. In this paper, we provide a comprehensive survey and an empirical comparison of the current party prediction practices and propose several new approaches which are competitive with or outperform state-of-the-art methods, yet require less computational resources. Party prediction models rely on the content generated by the users (e.g., tweet texts), the relations they have (e.g., who they follow), or their activities and interactions (e.g., which tweets they like). We examine all of these and compare their signal strength for the party prediction task. This paper lets the practitioner select from a wide range of data types that all give strong performance. Finally, we conduct extensive experiments on different aspects of these methods, such as data collection speed and transfer capabilities, which can provide further insights for both applied and methodological research. ",
    "url": "https://arxiv.org/abs/2308.13699",
    "authors": [
      "Kellin Pelrine",
      "Anne Imouza",
      "Zachary Yang",
      "Jacob-Junqi Tian",
      "Sacha L\u00e9vy",
      "Gabrielle Desrosiers-Brisebois",
      "Aarash Feizi",
      "C\u00e9cile Amadoro",
      "Andr\u00e9 Blais",
      "Jean-Fran\u00e7ois Godbout",
      "Reihaneh Rabbany"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13703",
    "title": "PAITS: Pretraining and Augmentation for Irregularly-Sampled Time Series",
    "abstract": "Real-world time series data that commonly reflect sequential human behavior are often uniquely irregularly sampled and sparse, with highly nonuniform sampling over time and entities. Yet, commonly-used pretraining and augmentation methods for time series are not specifically designed for such scenarios. In this paper, we present PAITS (Pretraining and Augmentation for Irregularly-sampled Time Series), a framework for identifying suitable pretraining strategies for sparse and irregularly sampled time series datasets. PAITS leverages a novel combination of NLP-inspired pretraining tasks and augmentations, and a random search to identify an effective strategy for a given dataset. We demonstrate that different datasets benefit from different pretraining choices. Compared with prior methods, our approach is better able to consistently improve pretraining across multiple datasets and domains. Our code is available at \\url{https://github.com/google-research/google-research/tree/master/irregular_timeseries_pretraining}. ",
    "url": "https://arxiv.org/abs/2308.13703",
    "authors": [
      "Nicasia Beebe-Wang",
      "Sayna Ebrahimi",
      "Jinsung Yoon",
      "Sercan O. Arik",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13707",
    "title": "Human-in-the-loop online just-in-time software defect prediction",
    "abstract": "Online Just-In-Time Software Defect Prediction (O-JIT-SDP) uses an online model to predict whether a new software change will introduce a bug or not. However, existing studies neglect the interaction of Software Quality Assurance (SQA) staff with the model, which may miss the opportunity to improve the prediction accuracy through the feedback from SQA staff. To tackle this problem, we propose Human-In-The-Loop (HITL) O-JIT-SDP that integrates feedback from SQA staff to enhance the prediction process. Furthermore, we introduce a performance evaluation framework that utilizes a k-fold distributed bootstrap method along with the Wilcoxon signed-rank test. This framework facilitates thorough pairwise comparisons of alternative classification algorithms using a prequential evaluation approach. Our proposal enables continuous statistical testing throughout the prequential process, empowering developers to make real-time decisions based on robust statistical evidence. Through experimentation across 10 GitHub projects, we demonstrate that our evaluation framework enhances the credibility of model evaluation, and the incorporation of HITL feedback elevates the prediction performance of online JIT-SDP models. These advancements hold the potential to significantly enhance the value of O-JIT-SDP for industrial applications. ",
    "url": "https://arxiv.org/abs/2308.13707",
    "authors": [
      "Xutong Liu",
      "Yufei Zhou",
      "Yutian Tang",
      "Junyan Qian",
      "Yuming Zhou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.13721",
    "title": "Robust Machine Learning Modeling for Predictive Control Using  Lipschitz-Constrained Neural Networks",
    "abstract": "Neural networks (NNs) have emerged as a state-of-the-art method for modeling nonlinear systems in model predictive control (MPC). However, the robustness of NNs, in terms of sensitivity to small input perturbations, remains a critical challenge for practical applications. To address this, we develop Lipschitz-Constrained Neural Networks (LCNNs) for modeling nonlinear systems and derive rigorous theoretical results to demonstrate their effectiveness in approximating Lipschitz functions, reducing input sensitivity, and preventing over-fitting. Specifically, we first prove a universal approximation theorem to show that LCNNs using SpectralDense layers can approximate any 1-Lipschitz target function. Then, we prove a probabilistic generalization error bound for LCNNs using SpectralDense layers by using their empirical Rademacher complexity. Finally, the LCNNs are incorporated into the MPC scheme, and a chemical process example is utilized to show that LCNN-based MPC outperforms MPC using conventional feedforward NNs in the presence of training data noise. ",
    "url": "https://arxiv.org/abs/2308.13721",
    "authors": [
      "Wallace Tan Gian Yion",
      "Zhe Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.13735",
    "title": "MST-compression: Compressing and Accelerating Binary Neural Networks  with Minimum Spanning Tree",
    "abstract": "Binary neural networks (BNNs) have been widely adopted to reduce the computational cost and memory storage on edge-computing devices by using one-bit representation for activations and weights. However, as neural networks become wider/deeper to improve accuracy and meet practical requirements, the computational burden remains a significant challenge even on the binary version. To address these issues, this paper proposes a novel method called Minimum Spanning Tree (MST) compression that learns to compress and accelerate BNNs. The proposed architecture leverages an observation from previous works that an output channel in a binary convolution can be computed using another output channel and XNOR operations with weights that differ from the weights of the reused channel. We first construct a fully connected graph with vertices corresponding to output channels, where the distance between two vertices is the number of different values between the weight sets used for these outputs. Then, the MST of the graph with the minimum depth is proposed to reorder output calculations, aiming to reduce computational cost and latency. Moreover, we propose a new learning algorithm to reduce the total MST distance during training. Experimental results on benchmark models demonstrate that our method achieves significant compression ratios with negligible accuracy drops, making it a promising approach for resource-constrained edge-computing devices. ",
    "url": "https://arxiv.org/abs/2308.13735",
    "authors": [
      "Quang Hieu Vo",
      "Linh-Tam Tran",
      "Sung-Ho Bae",
      "Lok-Won Kim",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13754",
    "title": "ZC3: Zero-Shot Cross-Language Code Clone Detection",
    "abstract": "Developers introduce code clones to improve programming productivity. Many existing studies have achieved impressive performance in monolingual code clone detection. However, during software development, more and more developers write semantically equivalent programs with different languages to support different platforms and help developers translate projects from one language to another. Considering that collecting cross-language parallel data, especially for low-resource languages, is expensive and time-consuming, how designing an effective cross-language model that does not rely on any parallel data is a significant problem. In this paper, we propose a novel method named ZC3 for Zero-shot Cross-language Code Clone detection. ZC3 designs the contrastive snippet prediction to form an isomorphic representation space among different programming languages. Based on this, ZC3 exploits domain-aware learning and cycle consistency learning to further constrain the model to generate representations that are aligned among different languages meanwhile are diacritical for different types of clones. To evaluate our approach, we conduct extensive experiments on four representative cross-language clone detection datasets. Experimental results show that ZC3 outperforms the state-of-the-art baselines by 67.12%, 51.39%, 14.85%, and 53.01% on the MAP score, respectively. We further investigate the representational distribution of different languages and discuss the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2308.13754",
    "authors": [
      "Jia Li",
      "Chongyang Tao",
      "Zhi Jin",
      "Fang Liu",
      "Jia Allen Li",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.13755",
    "title": "i-Align: an interpretable knowledge graph alignment model",
    "abstract": "Knowledge graphs (KGs) are becoming essential resources for many downstream applications. However, their incompleteness may limit their potential. Thus, continuous curation is needed to mitigate this problem. One of the strategies to address this problem is KG alignment, i.e., forming a more complete KG by merging two or more KGs. This paper proposes i-Align, an interpretable KG alignment model. Unlike the existing KG alignment models, i-Align provides an explanation for each alignment prediction while maintaining high alignment performance. Experts can use the explanation to check the correctness of the alignment prediction. Thus, the high quality of a KG can be maintained during the curation process (e.g., the merging process of two KGs). To this end, a novel Transformer-based Graph Encoder (Trans-GE) is proposed as a key component of i-Align for aggregating information from entities' neighbors (structures). Trans-GE uses Edge-gated Attention that combines the adjacency matrix and the self-attention matrix to learn a gating mechanism to control the information aggregation from the neighboring entities. It also uses historical embeddings, allowing Trans-GE to be trained over mini-batches, or smaller sub-graphs, to address the scalability issue when encoding a large KG. Another component of i-Align is a Transformer encoder for aggregating entities' attributes. This way, i-Align can generate explanations in the form of a set of the most influential attributes/neighbors based on attention weights. Extensive experiments are conducted to show the power of i-Align. The experiments include several aspects, such as the model's effectiveness for aligning KGs, the quality of the generated explanations, and its practicality for aligning large KGs. The results show the effectiveness of i-Align in these aspects. ",
    "url": "https://arxiv.org/abs/2308.13755",
    "authors": [
      "Bayu Distiawan Trisedya",
      "Flora D Salim",
      "Jeffrey Chan",
      "Damiano Spina",
      "Falk Scholer",
      "Mark Sanderson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13764",
    "title": "Unified Single-Stage Transformer Network for Efficient RGB-T Tracking",
    "abstract": "Most existing RGB-T tracking networks extract modality features in a separate manner, which lacks interaction and mutual guidance between modalities. This limits the network's ability to adapt to the diverse dual-modality appearances of targets and the dynamic relationships between the modalities. Additionally, the three-stage fusion tracking paradigm followed by these networks significantly restricts the tracking speed. To overcome these problems, we propose a unified single-stage Transformer RGB-T tracking network, namely USTrack, which unifies the above three stages into a single ViT (Vision Transformer) backbone with a dual embedding layer through self-attention mechanism. With this structure, the network can extract fusion features of the template and search region under the mutual interaction of modalities. Simultaneously, relation modeling is performed between these features, efficiently obtaining the search region fusion features with better target-background discriminability for prediction. Furthermore, we introduce a novel feature selection mechanism based on modality reliability to mitigate the influence of invalid modalities for prediction, further improving the tracking performance. Extensive experiments on three popular RGB-T tracking benchmarks demonstrate that our method achieves new state-of-the-art performance while maintaining the fastest inference speed 84.2FPS. In particular, MPR/MSR on the short-term and long-term subsets of VTUAV dataset increased by 11.1$\\%$/11.7$\\%$ and 11.3$\\%$/9.7$\\%$. ",
    "url": "https://arxiv.org/abs/2308.13764",
    "authors": [
      "Jianqiang Xia",
      "DianXi Shi",
      "Ke Song",
      "Linna Song",
      "XiaoLei Wang",
      "Songchang Jin",
      "Li Zhou",
      "Yu Cheng",
      "Lei Jin",
      "Zheng Zhu",
      "Jianan Li",
      "Gang Wang",
      "Junliang Xing",
      "Jian Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13768",
    "title": "Adversarial Fine-Tuning of Language Models: An Iterative Optimisation  Approach for the Generation and Detection of Problematic Content",
    "abstract": "In this paper, we tackle the emerging challenge of unintended harmful content generation in Large Language Models (LLMs) with a novel dual-stage optimisation technique using adversarial fine-tuning. Our two-pronged approach employs an adversarial model, fine-tuned to generate potentially harmful prompts, and a judge model, iteratively optimised to discern these prompts. In this adversarial cycle, the two models seek to outperform each other in the prompting phase, generating a dataset of rich examples which are then used for fine-tuning. This iterative application of prompting and fine-tuning allows continuous refinement and improved performance. The performance of our approach is evaluated through classification accuracy on a dataset consisting of problematic prompts not detected by GPT-4, as well as a selection of contentious but unproblematic prompts. We show considerable increase in classification accuracy of the judge model on this challenging dataset as it undergoes the optimisation process. Furthermore, we show that a rudimentary model \\texttt{ada} can achieve 13\\% higher accuracy on the hold-out test set than GPT-4 after only a few rounds of this process, and that this fine-tuning improves performance in parallel tasks such as toxic comment identification. ",
    "url": "https://arxiv.org/abs/2308.13768",
    "authors": [
      "Charles O'Neill",
      "Jack Miller",
      "Ioana Ciuca",
      "Yuan-Sen Ting",
      "Thang Bui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13772",
    "title": "Boosting Residual Networks with Group Knowledge",
    "abstract": "Recent research understands the residual networks from a new perspective of the implicit ensemble model. From this view, previous methods such as stochastic depth and stimulative training have further improved the performance of the residual network by sampling and training of its subnets. However, they both use the same supervision for all subnets of different capacities and neglect the valuable knowledge generated by subnets during training. In this manuscript, we mitigate the significant knowledge distillation gap caused by using the same kind of supervision and advocate leveraging the subnets to provide diverse knowledge. Based on this motivation, we propose a group knowledge based training framework for boosting the performance of residual networks. Specifically, we implicitly divide all subnets into hierarchical groups by subnet-in-subnet sampling, aggregate the knowledge of different subnets in each group during training, and exploit upper-level group knowledge to supervise lower-level subnet groups. Meanwhile, We also develop a subnet sampling strategy that naturally samples larger subnets, which are found to be more helpful than smaller subnets in boosting performance for hierarchical groups. Compared with typical subnet training and other methods, our method achieves the best efficiency and performance trade-offs on multiple datasets and network structures. The code will be released soon. ",
    "url": "https://arxiv.org/abs/2308.13772",
    "authors": [
      "Shengji Tang",
      "Peng Ye",
      "Baopu Li",
      "Weihao Lin",
      "Tao Chen",
      "Tong He",
      "Chong Yu",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13775",
    "title": "EditSum: A Retrieve-and-Edit Framework for Source Code Summarization",
    "abstract": "Existing studies show that code summaries help developers understand and maintain source code. Unfortunately, these summaries are often missing or outdated in software projects. Code summarization aims to generate natural language descriptions automatically for source code. Code summaries are highly structured and have repetitive patterns. Besides the patternized words, a code summary also contains important keywords, which are the key to reflecting the functionality of the code. However, the state-of-the-art approaches perform poorly on predicting the keywords, which leads to the generated summaries suffering a loss in informativeness. To alleviate this problem, this paper proposes a novel retrieve-and-edit approach named EditSum for code summarization. Specifically, EditSum first retrieves a similar code snippet from a pre-defined corpus and treats its summary as a prototype summary to learn the pattern. Then, EditSum edits the prototype automatically to combine the pattern in the prototype with the semantic information of input code. Our motivation is that the retrieved prototype provides a good start-point for post-generation because the summaries of similar code snippets often have the same pattern. The post-editing process further reuses the patternized words in the prototype and generates keywords based on the semantic information of input code. We conduct experiments on a large-scale Java corpus and experimental results demonstrate that EditSum outperforms the state-of-the-art approaches by a substantial margin. The human evaluation also proves the summaries generated by EditSum are more informative and useful. We also verify that EditSum performs well on predicting the patternized words and keywords. ",
    "url": "https://arxiv.org/abs/2308.13775",
    "authors": [
      "Jia Allen Li",
      "Yongmin Li",
      "Ge Li",
      "Xing Hu",
      "Xin Xia",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.13779",
    "title": "Zero-Shot Edge Detection with SCESAME: Spectral Clustering-based  Ensemble for Segment Anything Model Estimation",
    "abstract": "This paper proposes a novel zero-shot edge detection with SCESAME, which stands for Spectral Clustering-based Ensemble for Segment Anything Model Estimation, based on the recently proposed Segment Anything Model (SAM). SAM is a foundation model for segmentation tasks, and one of the interesting applications of SAM is Automatic Mask Generation (AMG), which generates zero-shot segmentation masks of an entire image. AMG can be applied to edge detection, but suffers from the problem of overdetecting edges. Edge detection with SCESAME overcomes this problem by three steps: (1) eliminating small generated masks, (2) combining masks by spectral clustering, taking into account mask positions and overlaps, and (3) removing artifacts after edge detection. We performed edge detection experiments on two datasets, BSDS500 and NYUDv2. Although our zero-shot approach is simple, the experimental results on BSDS500 showed almost identical performance to human performance and CNN-based methods from seven years ago. In the NYUDv2 experiments, it performed almost as well as recent CNN-based methods. These results indicate that our method has the potential to be a strong baseline for future zero-shot edge detection methods. Furthermore, SCESAME is not only applicable to edge detection, but also to other downstream zero-shot tasks. ",
    "url": "https://arxiv.org/abs/2308.13779",
    "authors": [
      "Hiroaki Yamagiwa",
      "Yusuke Takase",
      "Hiroyuki Kambe",
      "Ryosuke Nakamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13791",
    "title": "Handwritten image augmentation",
    "abstract": "In this paper, we introduce Handwritten augmentation, a new data augmentation for handwritten character images. This method focuses on augmenting handwritten image data by altering the shape of input characters in training. The proposed handwritten augmentation is similar to position augmentation, color augmentation for images but a deeper focus on handwritten characters. Handwritten augmentation is data-driven, easy to implement, and can be integrated with CNN-based optical character recognition models. Handwritten augmentation can be implemented along with commonly used data augmentation techniques such as cropping, rotating, and yields better performance of models for handwritten image datasets developed using optical character recognition methods. ",
    "url": "https://arxiv.org/abs/2308.13791",
    "authors": [
      "Mahendran N"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13792",
    "title": "Out-of-distribution detection using normalizing flows on the data  manifold",
    "abstract": "A common approach for out-of-distribution detection involves estimating an underlying data distribution, which assigns a lower likelihood value to out-of-distribution data. Normalizing flows are likelihood-based generative models providing a tractable density estimation via dimension-preserving invertible transformations. Conventional normalizing flows are prone to fail in out-of-distribution detection, because of the well-known curse of dimensionality problem of the likelihood-based models. According to the manifold hypothesis, real-world data often lie on a low-dimensional manifold. This study investigates the effect of manifold learning using normalizing flows on out-of-distribution detection. We proceed by estimating the density on a low-dimensional manifold, coupled with measuring the distance from the manifold, as criteria for out-of-distribution detection. However, individually, each of them is insufficient for this task. The extensive experimental results show that manifold learning improves the out-of-distribution detection ability of a class of likelihood-based models known as normalizing flows. This improvement is achieved without modifying the model structure or using auxiliary out-of-distribution data during training. ",
    "url": "https://arxiv.org/abs/2308.13792",
    "authors": [
      "Seyedeh Fatemeh Razavi",
      "Mohammad Mahdi Mehmanchi",
      "Reshad Hosseini",
      "Mostafa Tavassolipour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13793",
    "title": "Cooperative Resource Trading for Network Slicing in Industrial IoT: A  Multi-Agent DRL Approach",
    "abstract": "The industrial Internet of Things (IIoT) and network slicing (NS) paradigms have been envisioned as key enablers for flexible and intelligent manufacturing in the industry 4.0, where a myriad of interconnected machines, sensors, and devices of diversified quality of service (QoS) requirements coexist. To optimize network resource usage, stakeholders in the IIoT network are encouraged to take pragmatic steps towards resource sharing. However, resource sharing is only attractive if the entities involved are able to settle on a fair exchange of resource for remuneration in a win-win situation. In this paper, we design an economic model that analyzes the multilateral strategic trading interactions between sliced tenants in IIoT networks. We formulate the resource pricing and purchasing problem of the seller and buyer tenants as a cooperative Stackelberg game. Particularly, the cooperative game enforces collaboration among the buyer tenants by coalition formation in order to strengthen their position in resource price negotiations as opposed to acting individually, while the Stackelberg game determines the optimal policy optimization of the seller tenants and buyer tenant coalitions. To achieve a Stackelberg equilibrium (SE), a multi-agent deep reinforcement learning (MADRL) method is developed to make flexible pricing and purchasing decisions without prior knowledge of the environment. Simulation results and analysis prove that the proposed method achieves convergence and is superior to other baselines, in terms of utility maximization. ",
    "url": "https://arxiv.org/abs/2308.13793",
    "authors": [
      "Gordon Owusu Boateng",
      "Guisong Liu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2308.13794",
    "title": "SOGDet: Semantic-Occupancy Guided Multi-view 3D Object Detection",
    "abstract": "In the field of autonomous driving, accurate and comprehensive perception of the 3D environment is crucial. Bird's Eye View (BEV) based methods have emerged as a promising solution for 3D object detection using multi-view images as input. However, existing 3D object detection methods often ignore the physical context in the environment, such as sidewalk and vegetation, resulting in sub-optimal performance. In this paper, we propose a novel approach called SOGDet (Semantic-Occupancy Guided Multi-view 3D Object Detection), that leverages a 3D semantic-occupancy branch to improve the accuracy of 3D object detection. In particular, the physical context modeled by semantic occupancy helps the detector to perceive the scenes in a more holistic view. Our SOGDet is flexible to use and can be seamlessly integrated with most existing BEV-based methods. To evaluate its effectiveness, we apply this approach to several state-of-the-art baselines and conduct extensive experiments on the exclusive nuScenes dataset. Our results show that SOGDet consistently enhance the performance of three baseline methods in terms of nuScenes Detection Score (NDS) and mean Average Precision (mAP). This indicates that the combination of 3D object detection and 3D semantic occupancy leads to a more comprehensive perception of the 3D environment, thereby aiding build more robust autonomous driving systems. The codes are available at: https://github.com/zhouqiu/SOGDet. ",
    "url": "https://arxiv.org/abs/2308.13794",
    "authors": [
      "Qiu Zhou",
      "Jinming Cao",
      "Hanchao Leng",
      "Yifang Yin",
      "Yu Kun",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13801",
    "title": "Reinforcement Learning Based Multi-modal Feature Fusion Network for  Novel Class Discovery",
    "abstract": "With the development of deep learning techniques, supervised learning has achieved performances surpassing those of humans. Researchers have designed numerous corresponding models for different data modalities, achieving excellent results in supervised tasks. However, with the exponential increase of data in multiple fields, the recognition and classification of unlabeled data have gradually become a hot topic. In this paper, we employed a Reinforcement Learning framework to simulate the cognitive processes of humans for effectively addressing novel class discovery in the Open-set domain. We deployed a Member-to-Leader Multi-Agent framework to extract and fuse features from multi-modal information, aiming to acquire a more comprehensive understanding of the feature space. Furthermore, this approach facilitated the incorporation of self-supervised learning to enhance model training. We employed a clustering method with varying constraint conditions, ranging from strict to loose, allowing for the generation of dependable labels for a subset of unlabeled data during the training phase. This iterative process is similar to human exploratory learning of unknown data. These mechanisms collectively update the network parameters based on rewards received from environmental feedback. This process enables effective control over the extent of exploration learning, ensuring the accuracy of learning in unknown data categories. We demonstrate the performance of our approach in both the 3D and 2D domains by employing the OS-MN40, OS-MN40-Miss, and Cifar10 datasets. Our approach achieves competitive competitive results. ",
    "url": "https://arxiv.org/abs/2308.13801",
    "authors": [
      "Qiang Li",
      "Qiuyang Ma",
      "Weizhi Nie",
      "Anan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2308.13816",
    "title": "Homological Convolutional Neural Networks",
    "abstract": "Deep learning methods have demonstrated outstanding performances on classification and regression tasks on homogeneous data types (e.g., image, audio, and text data). However, tabular data still poses a challenge with classic machine learning approaches being often computationally cheaper and equally effective than increasingly complex deep learning architectures. The challenge arises from the fact that, in tabular data, the correlation among features is weaker than the one from spatial or semantic relationships in images or natural languages, and the dependency structures need to be modeled without any prior information. In this work, we propose a novel deep learning architecture that exploits the data structural organization through topologically constrained network representations to gain spatial information from sparse tabular data. The resulting model leverages the power of convolutions and is centered on a limited number of concepts from network topology to guarantee (i) a data-centric, deterministic building pipeline; (ii) a high level of interpretability over the inference process; and (iii) an adequate room for scalability. We test our model on 18 benchmark datasets against 5 classic machine learning and 3 deep learning models demonstrating that our approach reaches state-of-the-art performances on these challenging datasets. The code to reproduce all our experiments is provided at https://github.com/FinancialComputingUCL/HomologicalCNN. ",
    "url": "https://arxiv.org/abs/2308.13816",
    "authors": [
      "Antonio Briola",
      "Yuanrong Wang",
      "Silvia Bartolucci",
      "Tomaso Aste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2308.13833",
    "title": "A Cognitive Network Architecture for Vehicle-to-Network (V2N)  Communications over Smart Meters for URLLC",
    "abstract": "With the rapid advancement of smart city infrastructure, vehicle-to-network (V2N) communication has emerged as a crucial technology to enable intelligent transportation systems (ITS). The investigation of new methods to improve V2N communications is sparked by the growing need for high-speed and dependable communications in vehicular networks. To achieve ultra-reliable low latency communication (URLLC) for V2N scenarios, we propose a smart meter (SM)-based cognitive network (CN) architecture for V2N communications. Our scheme makes use of SMs' available underutilized time resources to let them serve as distributed access points (APs) for V2N communications to increase reliability and decrease latency. We propose and investigate two algorithms for efficiently associating vehicles with the appropriate SMs. Extensive simulations are carried out for comprehensive performance evaluation of our proposed architecture and algorithms under diverse system scenarios. Performance is investigated with particular emphasis on communication latency and reliability, which are also compared with the conventional base station (BS)-based V2N architecture for further validation. The results highlight the value of incorporating SMs into the current infrastructure and open the door for future ITSs to utilize more effective and dependable V2N communications. ",
    "url": "https://arxiv.org/abs/2308.13833",
    "authors": [
      "Shoaib Ahmed",
      "Sayonto Khan",
      "Kumudu S. Munasinghe",
      "Md. Farhad Hossain"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.13841",
    "title": "Cura: Curation at Social Media Scale",
    "abstract": "How can online communities execute a focused vision for their space? Curation offers one approach, where community leaders manually select content to share with the community. Curation enables leaders to shape a space that matches their taste, norms, and values, but the practice is often intractable at social media scale: curators cannot realistically sift through hundreds or thousands of submissions daily. In this paper, we contribute algorithmic and interface foundations enabling curation at scale, and manifest these foundations in a system called Cura. Our approach draws on the observation that, while curators' attention is limited, other community members' upvotes are plentiful and informative of curators' likely opinions. We thus contribute a transformer-based curation model that predicts whether each curator will upvote a post based on previous community upvotes. Cura applies this curation model to create a feed of content that it predicts the curator would want in the community. Evaluations demonstrate that the curation model accurately estimates opinions of diverse curators, that changing curators for a community results in clearly recognizable shifts in the community's content, and that, consequently, curation can reduce anti-social behavior by half without extra moderation effort. By sampling different types of curators, Cura lowers the threshold to genres of curated social media ranging from editorial groups to stakeholder roundtables to democracies. ",
    "url": "https://arxiv.org/abs/2308.13841",
    "authors": [
      "Wanrong He",
      "Mitchell L. Gordon",
      "Lindsay Popowski",
      "Michael S. Bernstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.13849",
    "title": "Effectively Heterogeneous Federated Learning: A Pairing and Split  Learning Based Approach",
    "abstract": "As a promising paradigm federated Learning (FL) is widely used in privacy-preserving machine learning, which allows distributed devices to collaboratively train a model while avoiding data transmission among clients. Despite its immense potential, the FL suffers from bottlenecks in training speed due to client heterogeneity, leading to escalated training latency and straggling server aggregation. To deal with this challenge, a novel split federated learning (SFL) framework that pairs clients with different computational resources is proposed, where clients are paired based on computing resources and communication rates among clients, meanwhile the neural network model is split into two parts at the logical level, and each client only computes the part assigned to it by using the SL to achieve forward inference and backward training. Moreover, to effectively deal with the client pairing problem, a heuristic greedy algorithm is proposed by reconstructing the optimization of training latency as a graph edge selection problem. Simulation results show the proposed method can significantly improve the FL training speed and achieve high performance both in independent identical distribution (IID) and Non-IID data distribution. ",
    "url": "https://arxiv.org/abs/2308.13849",
    "authors": [
      "Jinglong Shen",
      "Xiucheng Wang",
      "Nan Cheng",
      "Longfei Ma",
      "Conghao Zhou",
      "Yuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.13857",
    "title": "Joint Gaze-Location and Gaze-Object Detection",
    "abstract": "This paper proposes an efficient and effective method for joint gaze location detection (GL-D) and gaze object detection (GO-D), \\emph{i.e.}, gaze following detection. Current approaches frame GL-D and GO-D as two separate tasks, employing a multi-stage framework where human head crops must first be detected and then be fed into a subsequent GL-D sub-network, which is further followed by an additional object detector for GO-D. In contrast, we reframe the gaze following detection task as detecting human head locations and their gaze followings simultaneously, aiming at jointly detect human gaze location and gaze object in a unified and single-stage pipeline. To this end, we propose GTR, short for \\underline{G}aze following detection \\underline{TR}ansformer, streamlining the gaze following detection pipeline by eliminating all additional components, leading to the first unified paradigm that unites GL-D and GO-D in a fully end-to-end manner. GTR enables an iterative interaction between holistic semantics and human head features through a hierarchical structure, inferring the relations of salient objects and human gaze from the global image context and resulting in an impressive accuracy. Concretely, GTR achieves a 12.1 mAP gain ($\\mathbf{25.1}\\%$) on GazeFollowing and a 18.2 mAP gain ($\\mathbf{43.3\\%}$) on VideoAttentionTarget for GL-D, as well as a 19 mAP improvement ($\\mathbf{45.2\\%}$) on GOO-Real for GO-D. Meanwhile, unlike existing systems detecting gaze following sequentially due to the need for a human head as input, GTR has the flexibility to comprehend any number of people's gaze followings simultaneously, resulting in high efficiency. Specifically, GTR introduces over a $\\times 9$ improvement in FPS and the relative gap becomes more pronounced as the human number grows. ",
    "url": "https://arxiv.org/abs/2308.13857",
    "authors": [
      "Danyang Tu",
      "Wei Shen",
      "Wei Sun",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13871",
    "title": "Graph Edit Distance Learning via Different Attention",
    "abstract": "Recently, more and more research has focused on using Graph Neural Networks (GNN) to solve the Graph Similarity Computation problem (GSC), i.e., computing the Graph Edit Distance (GED) between two graphs. These methods treat GSC as an end-to-end learnable task, and the core of their architecture is the feature fusion modules to interact with the features of two graphs. Existing methods consider that graph-level embedding is difficult to capture the differences in local small structures between two graphs, and thus perform fine-grained feature fusion on node-level embedding can improve the accuracy, but leads to greater time and memory consumption in the training and inference phases. However, this paper proposes a novel graph-level fusion module Different Attention (DiffAtt), and demonstrates that graph-level fusion embeddings can substantially outperform these complex node-level fusion embeddings. We posit that the relative difference structure of the two graphs plays an important role in calculating their GED values. To this end, DiffAtt uses the difference between two graph-level embeddings as an attentional mechanism to capture the graph structural difference of the two graphs. Based on DiffAtt, a new GSC method, named Graph Edit Distance Learning via Different Attention (REDRAFT), is proposed, and experimental results demonstrate that REDRAFT achieves state-of-the-art performance in 23 out of 25 metrics in five benchmark datasets. Especially on MSE, it respectively outperforms the second best by 19.9%, 48.8%, 29.1%, 31.6%, and 2.2%. Moreover, we propose a quantitative test Remaining Subgraph Alignment Test (RESAT) to verify that among all graph-level fusion modules, the fusion embedding generated by DiffAtt can best capture the structural differences between two graphs. ",
    "url": "https://arxiv.org/abs/2308.13871",
    "authors": [
      "Jiaxi Lv",
      "Liang Zhang",
      "Yi Huang",
      "Jiancheng Huang",
      "Shifeng Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13884",
    "title": "Location Privacy and Spectrum Efficiency Enhancement in Spectrum Sharing  Systems",
    "abstract": "In this work, we investigate the benefits of secondary user (SU) network beamforming on improving primary user (PU) location privacy in spectrum sharing systems, where the beamformer in the SU network is designed to suppress the aggregate interference to improve the location privacy of PUs. We consider two problems: improving SU network communication throughput subject to the specified PU location privacy requirements, and enhancing PU location privacy given the quality of service (QoS) requirements of SU networks. In the first problem, we provide an algorithm to achieve high data rates with the constrained PU location privacy level. Numerical results show that for a given PU location privacy requirement, the proposed scheme is able to interfere/exclude only a few SU nodes from the PU band and the network throughput can be greatly improved. In the second problem, to fully explore the potential of SU network beamforming for enhancing PU location privacy, we propose a two-step scheme to decouple the beamforming and privacy zone design so that the PU location privacy can be improved while satisfying the SU network throughput requirement. According to numerical evaluations, the proposed scheme can maintain/achieve higher PU location privacy than the benchmark beamforming schemes while satisfying a QoS requirement for the SU network. ",
    "url": "https://arxiv.org/abs/2308.13884",
    "authors": [
      "Long Jiao",
      "Yao Ge",
      "Kai Zeng",
      "B.C. Hilburn"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.13888",
    "title": "Neural Implicit Morphing of Face Images",
    "abstract": "Face morphing is one of the seminal problems in computer graphics, with numerous artistic and forensic applications. It is notoriously challenging due to pose, lighting, gender, and ethnicity variations. Generally, this task consists of a warping for feature alignment and a blending for a seamless transition between the warped images. We propose to leverage coordinate-based neural networks to represent such warpings and blendings of face images. During training, we exploit the smoothness and flexibility of such networks, by combining energy functionals employed in classical approaches without discretizations. Additionally, our method is time-dependent, allowing a continuous warping, and blending of the target images. During warping inference, we need both direct and inverse transformations of the time-dependent warping. The first is responsible for morphing the target image into the source image, while the inverse is used for morphing in the opposite direction. Our neural warping stores those maps in a single network due to its inversible property, dismissing the hard task of inverting them. The results of our experiments indicate that our method is competitive with both classical and data-based neural techniques under the lens of face-morphing detection approaches. Aesthetically, the resulting images present a seamless blending of diverse faces not yet usual in the literature. ",
    "url": "https://arxiv.org/abs/2308.13888",
    "authors": [
      "Guilherme Schardong",
      "Tiago Novello",
      "Daniel Perazzo",
      "Hallison Paz",
      "Iurii Medvedev",
      "Luiz Velho",
      "Nuno Gon\u00e7alves"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13891",
    "title": "Drug Interaction Vectors Neural Network: DrIVeNN",
    "abstract": "Polypharmacy, the concurrent use of multiple drugs to treat a single condition, is common in patients managing multiple or complex conditions. However, as more drugs are added to the treatment plan, the risk of adverse drug events (ADEs) rises rapidly. Many serious ADEs associated with polypharmacy only become known after the drugs are in use. It is impractical to test every possible drug combination during clinical trials. This issue is particularly prevalent among older adults with cardiovascular disease (CVD) where polypharmacy and ADEs are commonly observed. In this research, our primary objective was to identify key drug features to build and evaluate a model for modeling polypharmacy ADEs. Our secondary objective was to assess our model on a domain-specific case study. We developed a two-layer neural network that incorporated drug features such as molecular structure, drug-protein interactions, and mono drug side effects (DrIVeNN). We assessed DrIVeNN using publicly available side effect databases and determined Principal Component Analysis (PCA) with a variance threshold of 0.95 as the most effective feature selection method. DrIVeNN performed moderately better than state-of-the-art models like RESCAL, DEDICOM, DeepWalk, Decagon, DeepDDI, KGDDI, and KGNN in terms of AUROC for the drug-drug interaction prediction task. We also conducted a domain-specific case study centered on the treatment of cardiovascular disease (CVD). When the best performing model architecture was applied to the CVD treatment cohort, there was a significant increase in performance from the general model. We observed an average AUROC for CVD drug pair prediction increasing from 0.826 (general model) to 0.975 (CVD specific model). Our findings indicate the strong potential of domain-specific models for improving the accuracy of drug-drug interaction predictions. ",
    "url": "https://arxiv.org/abs/2308.13891",
    "authors": [
      "Natalie Wang",
      "Casey Overby Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2308.13898",
    "title": "Memory-aware Scheduling for Complex Wired Networks with Iterative Graph  Optimization",
    "abstract": "Memory-aware network scheduling is becoming increasingly important for deep neural network (DNN) inference on resource-constrained devices. However, due to the complex cell-level and network-level topologies, memory-aware scheduling becomes very challenging. While previous algorithms all suffer from poor scalability, in this paper, we propose an efficient memory-aware scheduling framework based on iterative computation graph optimization. Our framework features an iterative graph fusion algorithm that simplifies the computation graph while preserving the scheduling optimality. We further propose an integer linear programming formulation together with topology-aware variable pruning to schedule the simplified graph efficiently. We evaluate our method against prior-art algorithms on different networks and demonstrate that our method outperforms existing techniques in all the benchmarks, reducing the peak memory footprint by 13.4%, and achieving better scalability for networks with complex network-level topologies. ",
    "url": "https://arxiv.org/abs/2308.13898",
    "authors": [
      "Shuzhang Zhong",
      "Meng Li",
      "Yun Liang",
      "Runsheng Wang",
      "Ru Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.13916",
    "title": "Exploring Large Language Models for Knowledge Graph Completion",
    "abstract": "Knowledge graphs play a vital role in numerous artificial intelligence tasks, yet they frequently face the issue of incompleteness. In this study, we explore utilizing Large Language Models (LLM) for knowledge graph completion. We consider triples in knowledge graphs as text sequences and introduce an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples. Our technique employs entity and relation descriptions of a triple as prompts and utilizes the response for predictions. Experiments on various benchmark knowledge graphs demonstrate that our method attains state-of-the-art performance in tasks such as triple classification and relation prediction. We also find that fine-tuning relatively smaller models (e.g., LLaMA-7B, ChatGLM-6B) outperforms recent ChatGPT and GPT-4. ",
    "url": "https://arxiv.org/abs/2308.13916",
    "authors": [
      "Liang Yao",
      "Jiazhen Peng",
      "Chengsheng Mao",
      "Yuan Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13920",
    "title": "Modeling Programmer Attention as Scanpath Prediction",
    "abstract": "This paper launches a new effort at modeling programmer attention by predicting eye movement scanpaths. Programmer attention refers to what information people intake when performing programming tasks. Models of programmer attention refer to machine prediction of what information is important to people. Models of programmer attention are important because they help researchers build better interfaces, assistive technologies, and more human-like AI. For many years, researchers in SE have built these models based on features such as mouse clicks, key logging, and IDE interactions. Yet the holy grail in this area is scanpath prediction -- the prediction of the sequence of eye fixations a person would take over a visual stimulus. A person's eye movements are considered the most concrete evidence that a person is taking in a piece of information. Scanpath prediction is a notoriously difficult problem, but we believe that the emergence of lower-cost, higher-accuracy eye tracking equipment and better large language models of source code brings a solution within grasp. We present an eye tracking experiment with 27 programmers and a prototype scanpath predictor to present preliminary results and obtain early community feedback. ",
    "url": "https://arxiv.org/abs/2308.13920",
    "authors": [
      "Aakash Bansal",
      "Chia-Yi Su",
      "Zachary Karas",
      "Yifan Zhang",
      "Yu Huang",
      "Toby Jia-Jun Li",
      "Collin McMillan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.13934",
    "title": "Patch-Grid: An Efficient and Feature-Preserving Neural Implicit Surface  Representation",
    "abstract": "Neural implicit representations are known to be more compact for depicting 3D shapes than traditional discrete representations. However, the neural representations tend to round sharp corners or edges and struggle to represent surfaces with open boundaries. Moreover, they are slow to train. We present a unified neural implicit representation, called Patch-Grid, that fits to complex shapes efficiently, preserves sharp features, and effectively models surfaces with open boundaries and thin geometric features. Our superior efficiency comes from embedding each surface patch into a local latent volume and decoding it using a shared MLP decoder, which is pretrained on various local surface geometries. With this pretrained decoder fixed, fitting novel shapes and local shape updates can be done efficiently. The faithful preservation of sharp features is enabled by adopting a novel merge grid to perform local constructive solid geometry (CSG) combinations of surface patches in the cells of an adaptive Octree, yielding better robustness than using a global CSG construction as proposed in the literature. Experiments show that our Patch-Grid method faithfully captures shapes with complex sharp features, open boundaries and thin structures, and outperforms existing learning-based methods in both efficiency and quality for surface fitting and local shape updates. ",
    "url": "https://arxiv.org/abs/2308.13934",
    "authors": [
      "Guying Lin",
      "Lei Yang",
      "Congyi Zhang",
      "Hao Pan",
      "Yuhan Ping",
      "Guodong Wei",
      "Taku Komura",
      "John Keyser",
      "Wenping Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.13943",
    "title": "Robust Control Barrier Functions for Safe Control Under Uncertainty  Using Extended State Observer and Output Measurement",
    "abstract": "Control barrier functions-based quadratic programming (CBF-QP) is gaining popularity as an effective controller synthesis tool for safe control. However, the provable safety is established on an accurate dynamic model and access to all states. To address such a limitation, this paper proposes a novel design combining an extended state observer (ESO) with a CBF for safe control of a system with model uncertainty and external disturbances only using output measurement. Our approach provides a less conservative estimation error bound than other disturbance observer-based CBFs. Moreover, only output measurements are needed to estimate the disturbances instead of access to the full state. The bounds of state estimation error and disturbance estimation error are obtained in a unified manner and then used for robust safe control under uncertainty. We validate our approach's efficacy in simulations of an adaptive cruise control system and a Segway self-balancing scooter. ",
    "url": "https://arxiv.org/abs/2308.13943",
    "authors": [
      "Jinfeng Chen",
      "Zhiqiang Gao",
      "Qin Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.13946",
    "title": "SOK: Privacy Definitions and Classical Mechanisms in the Local Setting",
    "abstract": "This paper delves into the intricate landscape of privacy notions, specifically honed in on the local setting. Central to our discussion is the juxtaposition of point-wise protection and average-case protection, offering a comparative analysis that highlights the strengths and trade-offs inherent to each approach. Beyond this, we delineate between context-aware and context-free notions, examining the implications of both in diverse application scenarios. The study further differentiates between the interactive and non-interactive models, illuminating the complexities and nuances each model introduces. By systematically navigating these core themes, our goal is to provide a cohesive framework that aids researchers and practitioners in discerning the most suitable privacy notions for their specific requirements in the local setting. ",
    "url": "https://arxiv.org/abs/2308.13946",
    "authors": [
      "Nan Wang",
      "Likun Qin",
      "Tianshuo Qiu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.13968",
    "title": "Multivariate time series classification with dual attention network",
    "abstract": "One of the topics in machine learning that is becoming more and more relevant is multivariate time series classification. Current techniques concentrate on identifying the local important sequence segments or establishing the global long-range dependencies. They frequently disregard the merged data from both global and local features, though. Using dual attention, we explore a novel network (DA-Net) in this research to extract local and global features for multivariate time series classification. The two distinct layers that make up DA-Net are the Squeeze-Excitation Window Attention (SEWA) layer and the Sparse Self-Attention within Windows (SSAW) layer. DA- Net can mine essential local sequence fragments that are necessary for establishing global long-range dependencies based on the two expanded layers. ",
    "url": "https://arxiv.org/abs/2308.13968",
    "authors": [
      "Mojtaba A. Farahani",
      "Tara Eslaminokandeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13982",
    "title": "Universal Graph Continual Learning",
    "abstract": "We address catastrophic forgetting issues in graph learning as incoming data transits from one to another graph distribution. Whereas prior studies primarily tackle one setting of graph continual learning such as incremental node classification, we focus on a universal approach wherein each data point in a task can be a node or a graph, and the task varies from node to graph classification. We propose a novel method that enables graph neural networks to excel in this universal setting. Our approach perseveres knowledge about past tasks through a rehearsal mechanism that maintains local and global structure consistency across the graphs. We benchmark our method against various continual learning baselines in real-world graph datasets and achieve significant improvement in average performance and forgetting across tasks. ",
    "url": "https://arxiv.org/abs/2308.13982",
    "authors": [
      "Thanh Duc Hoang",
      "Do Viet Tung",
      "Duy-Hung Nguyen",
      "Bao-Sinh Nguyen",
      "Huy Hoang Nguyen",
      "Hung Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13996",
    "title": "Improve in-situ life prediction and classification performance by  capturing both the present state and evolution rate of battery aging",
    "abstract": "This study develops a methodology by capturing both the battery aging state and degradation rate for improved life prediction performance. The aging state is indicated by six physical features of an equivalent circuit model that are extracted from the voltage relaxation data. And the degradation rate is captured by two features extracted from the differences between the voltage relaxation curves within a moving window (for life prediction), or the differences between the capacity vs. voltage curves at different cycles (for life classification). Two machine learning models, which are constructed based on Gaussian Processes, are used to describe the relationships between these physical features and battery lifetimes for the life prediction and classification, respectively. The methodology is validated with the aging data of 74 battery cells of three different types. Experimental results show that based on only 3-12 minutes' sampling data, the method with novel features predicts accurate battery lifetimes, with the prediction accuracy improved by up to 67.09% compared with the benchmark method. And the batteries are classified into three groups (long, medium, and short) with an overall accuracy larger than 90% based on only two adjacent cycles' information, enabling the highly efficient regrouping of retired batteries. ",
    "url": "https://arxiv.org/abs/2308.13996",
    "authors": [
      "Mingyuan Zhao",
      "Yongzhi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.14009",
    "title": "Towards Fast and Accurate Image-Text Retrieval with Self-Supervised  Fine-Grained Alignment",
    "abstract": "Image-text retrieval requires the system to bridge the heterogenous gap between vision and language for accurate retrieval while keeping the network lightweight-enough for efficient retrieval. Existing trade-off solutions mainly study from the view of incorporating cross-modal interactions with the independent-embedding framework or leveraging stronger pretrained encoders, which still demand time-consuming similarity measurement or heavyweight model structure in the retrieval stage. In this work, we propose an image-text alignment module SelfAlign on top of the independent-embedding framework, which improves the retrieval accuracy while maintains the retrieval efficiency without extra supervision. SelfAlign contains two collaborative sub-modules that force image-text alignment at both concept level and context level by self-supervised contrastive learning. It does not require cross-modal embedding interactions during training while maintaining independent image and text encoders during retrieval. With comparable time cost, SelfAlign consistently boosts the accuracy of state-of-the-art non-pretraining independent-embedding models respectively by 9.1%, 4.2% and 6.6% in terms of R@sum score on Flickr30K, MSCOCO 1K and MS-COCO 5K datasets. The retrieval accuracy also outperforms most existing interactive-embedding models with orders of magnitude decrease in retrieval time. The source code is available at: https://github.com/Zjamie813/SelfAlign. ",
    "url": "https://arxiv.org/abs/2308.14009",
    "authors": [
      "Jiamin Zhuang",
      "Jing Yu",
      "Yang Ding",
      "Xiangyan Qu",
      "Yue Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14012",
    "title": "Neural Influence Estimator: Towards Real-time Solutions to Influence  Blocking Maximization",
    "abstract": "Real-time solutions to the influence blocking maximization (IBM) problems are crucial for promptly containing the spread of misinformation. However, achieving this goal is non-trivial, mainly because assessing the blocked influence of an IBM problem solution typically requires plenty of expensive Monte Carlo simulations (MCSs). Although several approaches have been proposed to enhance efficiency, they still fail to achieve real-time solutions to IBM problems of practical scales. This work presents a novel approach that enables solving IBM problems with hundreds of thousands of nodes and edges in seconds. The key idea is to construct a fast-to-evaluate surrogate model, called neural influence estimator (NIE), as a substitute for the time-intensive MCSs. To this end, a learning problem is formulated to build the NIE that takes the false-and-true information instance as input, extracts features describing the topology and inter-relationship between two seed sets, and predicts the blocked influence. A well-trained NIE can generalize across different IBM problems defined on a social network, and can be readily combined with existing IBM optimization algorithms such as the greedy algorithm. The experiments on 25 IBM problems with up to millions of edges show that the NIE-based optimization method can be up to four orders of magnitude faster than MCSs-based optimization method to achieve the same solution quality. Moreover, given a real-time constraint of one minute, the NIE-based method can solve IBM problems with up to hundreds of thousands of nodes, which is at least one order of magnitude larger than what can be solved by existing methods. ",
    "url": "https://arxiv.org/abs/2308.14012",
    "authors": [
      "Wenjie Chen",
      "Shengcai Liu",
      "Yew-Soon Ong",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14020",
    "title": "A Comparison of Neural Networks for Wireless Channel Prediction",
    "abstract": "The performance of modern wireless communications systems depends critically on the quality of the available channel state information (CSI) at the transmitter and receiver. Several previous works have proposed concepts and algorithms that help maintain high quality CSI even in the presence of high mobility and channel aging, such as temporal prediction schemes that employ neural networks. However, it is still unclear which neural network-based scheme provides the best performance in terms of prediction quality, training complexity and practical feasibility. To investigate such a question, this paper first provides an overview of state-of-the-art neural networks applicable to channel prediction and compares their performance in terms of prediction quality. Next, a new comparative analysis is proposed for four promising neural networks with different prediction horizons. The well-known tapped delay channel model recommended by the Third Generation Partnership Program is used for a standardized comparison among the neural networks. Based on this comparative evaluation, the advantages and disadvantages of each neural network are discussed and guidelines for selecting the best-suited neural network in channel prediction applications are given. ",
    "url": "https://arxiv.org/abs/2308.14020",
    "authors": [
      "Oscar Stenhammar",
      "Gabor Fodor",
      "Carlo Fischione"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.14024",
    "title": "Balanced Representation Learning for Long-tailed Skeleton-based Action  Recognition",
    "abstract": "Skeleton-based action recognition has recently made significant progress. However, data imbalance is still a great challenge in real-world scenarios. The performance of current action recognition algorithms declines sharply when training data suffers from heavy class imbalance. The imbalanced data actually degrades the representations learned by these methods and becomes the bottleneck for action recognition. How to learn unbiased representations from imbalanced action data is the key to long-tailed action recognition. In this paper, we propose a novel balanced representation learning method to address the long-tailed problem in action recognition. Firstly, a spatial-temporal action exploration strategy is presented to expand the sample space effectively, generating more valuable samples in a rebalanced manner. Secondly, we design a detached action-aware learning schedule to further mitigate the bias in the representation space. The schedule detaches the representation learning of tail classes from training and proposes an action-aware loss to impose more effective constraints. Additionally, a skip-modal representation is proposed to provide complementary structural information. The proposed method is validated on four skeleton datasets, NTU RGB+D 60, NTU RGB+D 120, NW-UCLA, and Kinetics. It not only achieves consistently large improvement compared to the state-of-the-art (SOTA) methods, but also demonstrates a superior generalization capacity through extensive experiments. Our code is available at https://github.com/firework8/BRL. ",
    "url": "https://arxiv.org/abs/2308.14024",
    "authors": [
      "Hongda Liu",
      "Yunlong Wang",
      "Min Ren",
      "Junxing Hu",
      "Zhengquan Luo",
      "Guangqi Hou",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14030",
    "title": "Forensic Histopathological Recognition via a Context-Aware MIL Network  Powered by Self-Supervised Contrastive Learning",
    "abstract": "Forensic pathology is critical in analyzing death manner and time from the microscopic aspect to assist in the establishment of reliable factual bases for criminal investigation. In practice, even the manual differentiation between different postmortem organ tissues is challenging and relies on expertise, considering that changes like putrefaction and autolysis could significantly change typical histopathological appearance. Developing AI-based computational pathology techniques to assist forensic pathologists is practically meaningful, which requires reliable discriminative representation learning to capture tissues' fine-grained postmortem patterns. To this end, we propose a framework called FPath, in which a dedicated self-supervised contrastive learning strategy and a context-aware multiple-instance learning (MIL) block are designed to learn discriminative representations from postmortem histopathological images acquired at varying magnification scales. Our self-supervised learning step leverages multiple complementary contrastive losses and regularization terms to train a double-tier backbone for fine-grained and informative patch/instance embedding. Thereafter, the context-aware MIL adaptively distills from the local instances a holistic bag/image-level representation for the recognition task. On a large-scale database of $19,607$ experimental rat postmortem images and $3,378$ real-world human decedent images, our FPath led to state-of-the-art accuracy and promising cross-domain generalization in recognizing seven different postmortem tissues. The source code will be released on \\href{https://github.com/ladderlab-xjtu/forensic_pathology}{https://github.com/ladderlab-xjtu/forensic\\_pathology}. ",
    "url": "https://arxiv.org/abs/2308.14030",
    "authors": [
      "Chen Shen",
      "Jun Zhang",
      "Xinggong Liang",
      "Zeyi Hao",
      "Kehan Li",
      "Fan Wang",
      "Zhenyuan Wang",
      "Chunfeng Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14059",
    "title": "Multi-Subdomain Adversarial Network for Cross-Subject EEG-based Emotion  Recognition",
    "abstract": "The individual difference between subjects is significant in EEG-based emotion recognition, resulting in the difficulty of sharing the model across subjects. Previous studies use domain adaptation algorithms to minimize the global domain discrepancy while ignoring the class information, which may cause misalignment of subdomains and reduce model performance. This paper proposes a multi-subdomain adversarial network (MSAN) for cross-subject EEG-based emotion recognition. MSAN uses adversarial training to model the discrepancy in the global domain and subdomain to reduce the intra-class distance and enlarge the inter-class distance. In addition, MSAN initializes parameters through a pre-trained autoencoder to ensure the stability and convertibility of the model. The experimental results show that the accuracy of MSAN is improved by 30.02\\% on the SEED dataset comparing with the nontransfer method. ",
    "url": "https://arxiv.org/abs/2308.14059",
    "authors": [
      "Guang Lin",
      "Jianhai Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.14061",
    "title": "Hierarchical Contrastive Learning for Pattern-Generalizable Image  Corruption Detection",
    "abstract": "Effective image restoration with large-size corruptions, such as blind image inpainting, entails precise detection of corruption region masks which remains extremely challenging due to diverse shapes and patterns of corruptions. In this work, we present a novel method for automatic corruption detection, which allows for blind corruption restoration without known corruption masks. Specifically, we develop a hierarchical contrastive learning framework to detect corrupted regions by capturing the intrinsic semantic distinctions between corrupted and uncorrupted regions. In particular, our model detects the corrupted mask in a coarse-to-fine manner by first predicting a coarse mask by contrastive learning in low-resolution feature space and then refines the uncertain area of the mask by high-resolution contrastive learning. A specialized hierarchical interaction mechanism is designed to facilitate the knowledge propagation of contrastive learning in different scales, boosting the modeling performance substantially. The detected multi-scale corruption masks are then leveraged to guide the corruption restoration. Detecting corrupted regions by learning the contrastive distinctions rather than the semantic patterns of corruptions, our model has well generalization ability across different corruption patterns. Extensive experiments demonstrate following merits of our model: 1) the superior performance over other methods on both corruption detection and various image restoration tasks including blind inpainting and watermark removal, and 2) strong generalization across different corruption patterns such as graffiti, random noise or other image content. Codes and trained weights are available at https://github.com/xyfJASON/HCL . ",
    "url": "https://arxiv.org/abs/2308.14061",
    "authors": [
      "Xin Feng",
      "Yifeng Xu",
      "Guangming Lu",
      "Wenjie Pei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14063",
    "title": "Anomalous Sound Detection Using Self-Attention-Based Frequency Pattern  Analysis of Machine Sounds",
    "abstract": "Different machines can exhibit diverse frequency patterns in their emitted sound. This feature has been recently explored in anomaly sound detection and reached state-of-the-art performance. However, existing methods rely on the manual or empirical determination of the frequency filter by observing the effective frequency range in the training data, which may be impractical for general application. This paper proposes an anomalous sound detection method using self-attention-based frequency pattern analysis and spectral-temporal information fusion. Our experiments demonstrate that the self-attention module automatically and adaptively analyses the effective frequencies of a machine sound and enhances that information in the spectral feature representation. With spectral-temporal information fusion, the obtained audio feature eventually improves the anomaly detection performance on the DCASE 2020 Challenge Task 2 dataset. ",
    "url": "https://arxiv.org/abs/2308.14063",
    "authors": [
      "Hejing Zhang",
      "Jian Guan",
      "Qiaoxi Zhu",
      "Feiyang Xiao",
      "Youde Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.14070",
    "title": "DETDet: Dual Ensemble Teeth Detection",
    "abstract": "The field of dentistry is in the era of digital transformation. Particularly, artificial intelligence is anticipated to play a significant role in digital dentistry. AI holds the potential to significantly assist dental practitioners and elevate diagnostic accuracy. In alignment with this vision, the 2023 MICCAI DENTEX challenge aims to enhance the performance of dental panoramic X-ray diagnosis and enumeration through technological advancement. In response, we introduce DETDet, a Dual Ensemble Teeth Detection network. DETDet encompasses two distinct modules dedicated to enumeration and diagnosis. Leveraging the advantages of teeth mask data, we employ Mask-RCNN for the enumeration module. For the diagnosis module, we adopt an ensemble model comprising DiffusionDet and DINO. To further enhance precision scores, we integrate a complementary module to harness the potential of unlabeled data. The code for our approach will be made accessible at https://github.com/Bestever-choi/Evident ",
    "url": "https://arxiv.org/abs/2308.14070",
    "authors": [
      "Kyoungyeon Choi",
      "Jaewon Shin",
      "Eunyi Lyou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14071",
    "title": "Supporting Passive Users in mmWave Networks",
    "abstract": "The interference from active to passive users is a well-recognized challenge in millimeter-wave (mmWave) communications. We propose a method that enables to limit the interference on passive users (whose presence may not be detected since they do not transmit) with a small penalty to the throughput of active users. Our approach abstracts away (in a simple, yet informative way) the physical layer component and it leverages the directivity of mmWave links and the available network path diversity. We provide linear programming formulations, lower bounds on active users rates, numerical evaluations, and we establish a connection with the problem of (information theoretically) secure communication over mmWave networks. ",
    "url": "https://arxiv.org/abs/2308.14071",
    "authors": [
      "Mine Gokce Dogan",
      "Martina Cardone",
      "Christina Fragouli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.14084",
    "title": "Practical Edge Detection via Robust Collaborative Learning",
    "abstract": "Edge detection, as a core component in a wide range of visionoriented tasks, is to identify object boundaries and prominent edges in natural images. An edge detector is desired to be both efficient and accurate for practical use. To achieve the goal, two key issues should be concerned: 1) How to liberate deep edge models from inefficient pre-trained backbones that are leveraged by most existing deep learning methods, for saving the computational cost and cutting the model size; and 2) How to mitigate the negative influence from noisy or even wrong labels in training data, which widely exist in edge detection due to the subjectivity and ambiguity of annotators, for the robustness and accuracy. In this paper, we attempt to simultaneously address the above problems via developing a collaborative learning based model, termed PEdger. The principle behind our PEdger is that, the information learned from different training moments and heterogeneous (recurrent and non recurrent in this work) architectures, can be assembled to explore robust knowledge against noisy annotations, even without the help of pre-training on extra data. Extensive ablation studies together with quantitative and qualitative experimental comparisons on the BSDS500 and NYUD datasets are conducted to verify the effectiveness of our design, and demonstrate its superiority over other competitors in terms of accuracy, speed, and model size. Codes can be found at https://github.co/ForawardStar/PEdger. ",
    "url": "https://arxiv.org/abs/2308.14084",
    "authors": [
      "Yuanbin Fu",
      "Xiaojie Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14087",
    "title": "A comprehensive review on Plant Leaf Disease detection using Deep  learning",
    "abstract": "Leaf disease is a common fatal disease for plants. Early diagnosis and detection is necessary in order to improve the prognosis of leaf diseases affecting plant. For predicting leaf disease, several automated systems have already been developed using different plant pathology imaging modalities. This paper provides a systematic review of the literature on leaf disease-based models for the diagnosis of various plant leaf diseases via deep learning. The advantages and limitations of different deep learning models including Vision Transformer (ViT), Deep convolutional neural network (DCNN), Convolutional neural network (CNN), Residual Skip Network-based Super-Resolution for Leaf Disease Detection (RSNSR-LDD), Disease Detection Network (DDN), and YOLO (You only look once) are described in this review. The review also shows that the studies related to leaf disease detection applied different deep learning models to a number of publicly available datasets. For comparing the performance of the models, different metrics such as accuracy, precision, recall, etc. were used in the existing studies. ",
    "url": "https://arxiv.org/abs/2308.14087",
    "authors": [
      "Sumaya Mustofa",
      "Md Mehedi Hasan Munna",
      "Yousuf Rayhan Emon",
      "Golam Rabbany",
      "Md Taimur Ahad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14093",
    "title": "The inverse problem for neural networks",
    "abstract": "We study the problem of computing the preimage of a set under a neural network with piecewise-affine activation functions. We recall an old result that the preimage of a polyhedral set is again a union of polyhedral sets and can be effectively computed. We show several applications of computing the preimage for analysis and interpretability of neural networks. ",
    "url": "https://arxiv.org/abs/2308.14093",
    "authors": [
      "Marcelo Forets",
      "Christian Schilling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2308.14101",
    "title": "Superpixels algorithms through network community detection",
    "abstract": "Community detection is a powerful tool from complex networks analysis that finds applications in various research areas. Several image segmentation methods rely for instance on community detection algorithms as a black box in order to compute undersegmentations, i.e. a small number of regions that represent areas of interest of the image. However, to the best of our knowledge, the efficiency of such an approach w.r.t. superpixels, that aim at representing the image at a smaller level while preserving as much as possible original information, has been neglected so far. The only related work seems to be the one by Liu et. al. (IET Image Processing, 2022) that developed a superpixels algorithm using a so-called modularity maximization approach, leading to relevant results. We follow this line of research by studying the efficiency of superpixels computed by state-of-the-art community detection algorithms on a 4-connected pixel graph, so-called pixel-grid. We first detect communities on such a graph and then apply a simple merging procedure that allows to obtain the desired number of superpixels. As we shall see, such methods result in the computation of relevant superpixels as emphasized by both qualitative and quantitative experiments, according to different widely-used metrics based on ground-truth comparison or on superpixels only. We observe that the choice of the community detection algorithm has a great impact on the number of communities and hence on the merging procedure. Similarly, small variations on the pixel-grid may provide different results from both qualitative and quantitative viewpoints. For the sake of completeness, we compare our results with those of several state-of-the-art superpixels algorithms as computed by Stutz et al. (Computer Vision and Image Understanding, 2018). ",
    "url": "https://arxiv.org/abs/2308.14101",
    "authors": [
      "Anthony Perez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14104",
    "title": "Towards Generalizable Neural Solvers for Vehicle Routing Problems via  Ensemble with Transferrable Local Policy",
    "abstract": "Machine learning has been adapted to help solve NP-hard combinatorial optimization problems. One prevalent way is learning to construct solutions by deep neural networks, which has been receiving more and more attention due to the high efficiency and less requirement for expert knowledge. However, many neural construction methods for Vehicle Routing Problems (VRPs) focus on synthetic problem instances with limited scales and specified node distributions, leading to poor performance on real-world problems which usually involve large scales together with complex and unknown node distributions. To make neural VRP solvers more practical in real-world scenarios, we design an auxiliary policy that learns from the local transferable topological features, named local policy, and integrate it with a typical constructive policy (which learns from the global information of VRP instances) to form an ensemble policy. With joint training, the aggregated policies perform cooperatively and complementarily to boost generalization. The experimental results on two well-known benchmarks, TSPLIB and CVRPLIB, of travelling salesman problem and capacitated VRP show that the ensemble policy consistently achieves better generalization than state-of-the-art construction methods and even works well on real-world problems with several thousand nodes. ",
    "url": "https://arxiv.org/abs/2308.14104",
    "authors": [
      "Chengrui Gao",
      "Haopu Shang",
      "Ke Xue",
      "Dong Li",
      "Chao Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14105",
    "title": "Unified and Dynamic Graph for Temporal Character Grouping in Long Videos",
    "abstract": "Video temporal character grouping locates appearing moments of major characters within a video according to their identities. To this end, recent works have evolved from unsupervised clustering to graph-based supervised clustering. However, graph methods are built upon the premise of fixed affinity graphs, bringing many inexact connections. Besides, they extract multi-modal features with kinds of models, which are unfriendly to deployment. In this paper, we present a unified and dynamic graph (UniDG) framework for temporal character grouping. This is accomplished firstly by a unified representation network that learns representations of multiple modalities within the same space and still preserves the modality's uniqueness simultaneously. Secondly, we present a dynamic graph clustering where the neighbors of different quantities are dynamically constructed for each node via a cyclic matching strategy, leading to a more reliable affinity graph. Thirdly, a progressive association method is introduced to exploit spatial and temporal contexts among different modalities, allowing multi-modal clustering results to be well fused. As current datasets only provide pre-extracted features, we evaluate our UniDG method on a collected dataset named MTCG, which contains each character's appearing clips of face and body and speaking voice tracks. We also evaluate our key components on existing clustering and retrieval datasets to verify the generalization ability. Experimental results manifest that our method can achieve promising results and outperform several state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2308.14105",
    "authors": [
      "Xiujun Shu",
      "Wei Wen",
      "Liangsheng Xu",
      "Mingbao Lin",
      "Ruizhi Qiao",
      "Taian Guo",
      "Hanjun Li",
      "Bei Gan",
      "Xiao Wang",
      "Xing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14113",
    "title": "Semantic-aware Consistency Network for Cloth-changing Person  Re-Identification",
    "abstract": "Cloth-changing Person Re-Identification (CC-ReID) is a challenging task that aims to retrieve the target person across multiple surveillance cameras when clothing changes might happen. Despite recent progress in CC-ReID, existing approaches are still hindered by the interference of clothing variations since they lack effective constraints to keep the model consistently focused on clothing-irrelevant regions. To address this issue, we present a Semantic-aware Consistency Network (SCNet) to learn identity-related semantic features by proposing effective consistency constraints. Specifically, we generate the black-clothing image by erasing pixels in the clothing area, which explicitly mitigates the interference from clothing variations. In addition, to fully exploit the fine-grained identity information, a head-enhanced attention module is introduced, which learns soft attention maps by utilizing the proposed part-based matching loss to highlight head information. We further design a semantic consistency loss to facilitate the learning of high-level identity-related semantic features, forcing the model to focus on semantically consistent cloth-irrelevant regions. By using the consistency constraint, our model does not require any extra auxiliary segmentation module to generate the black-clothing image or locate the head region during the inference stage. Extensive experiments on four cloth-changing person Re-ID datasets (LTCC, PRCC, Vc-Clothes, and DeepChange) demonstrate that our proposed SCNet makes significant improvements over prior state-of-the-art approaches. Our code is available at: https://github.com/Gpn-star/SCNet. ",
    "url": "https://arxiv.org/abs/2308.14113",
    "authors": [
      "Peini Guo",
      "Hong Liu",
      "Jianbing Wu",
      "Guoquan Wang",
      "Tao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14114",
    "title": "Hybrid Transformer-RNN Architecture for Household Occupancy Detection  Using Low-Resolution Smart Meter Data",
    "abstract": "Residential occupancy detection has become an enabling technology in today's urbanized world for various smart home applications, such as building automation, energy management, and improved security and comfort. Digitalization of the energy system provides smart meter data that can be used for occupancy detection in a non-intrusive manner without causing concerns regarding privacy and data security. In particular, deep learning techniques make it possible to infer occupancy from low-resolution smart meter data, such that the need for accurate occupancy detection with privacy preservation can be achieved. Our work is thus motivated to develop a privacy-aware and effective model for residential occupancy detection in contemporary living environments. Our model aims to leverage the advantages of both recurrent neural networks (RNNs), which are adept at capturing local temporal dependencies, and transformers, which are effective at handling global temporal dependencies. Our designed hybrid transformer-RNN model detects residential occupancy using hourly smart meter data, achieving an accuracy of nearly 92\\% across households with diverse profiles. We validate the effectiveness of our method using a publicly accessible dataset and demonstrate its performance by comparing it with state-of-the-art models, including attention-based occupancy detection methods. ",
    "url": "https://arxiv.org/abs/2308.14114",
    "authors": [
      "Xinyu Liang",
      "Hao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14129",
    "title": "SPEED: Streaming Partition and Parallel Acceleration for Temporal  Interaction Graph Embedding",
    "abstract": "Temporal Interaction Graphs (TIGs) are widely employed to model intricate real-world systems such as financial systems and social networks. To capture the dynamism and interdependencies of nodes, existing TIG embedding models need to process edges sequentially and chronologically. However, this requirement prevents it from being processed in parallel and struggle to accommodate burgeoning data volumes to GPU. Consequently, many large-scale temporal interaction graphs are confined to CPU processing. Furthermore, a generalized GPU scaling and acceleration approach remains unavailable. To facilitate large-scale TIGs' implementation on GPUs for acceleration, we introduce a novel training approach namely Streaming Edge Partitioning and Parallel Acceleration for Temporal Interaction Graph Embedding (SPEED). The SPEED is comprised of a Streaming Edge Partitioning Component (SEP) which addresses space overhead issue by assigning fewer nodes to each GPU, and a Parallel Acceleration Component (PAC) which enables simultaneous training of different sub-graphs, addressing time overhead issue. Our method can achieve a good balance in computing resources, computing time, and downstream task performance. Empirical validation across 7 real-world datasets demonstrates the potential to expedite training speeds by a factor of up to 19.29x. Simultaneously, resource consumption of a single-GPU can be diminished by up to 69%, thus enabling the multiple GPU-based training and acceleration encompassing millions of nodes and billions of edges. Furthermore, our approach also maintains its competitiveness in downstream tasks. ",
    "url": "https://arxiv.org/abs/2308.14129",
    "authors": [
      "Xi Chen",
      "Yongxiang Liao",
      "Yun Xiong",
      "Yao Zhang",
      "Siwei Zhang",
      "Jiawei Zhang",
      "Yiheng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14132",
    "title": "Detecting Language Model Attacks with Perplexity",
    "abstract": "A novel hack involving Large Language Models (LLMs) has emerged, leveraging adversarial suffixes to trick models into generating perilous responses. This method has garnered considerable attention from reputable media outlets such as the New York Times and Wired, thereby influencing public perception regarding the security and safety of LLMs. In this study, we advocate the utilization of perplexity as one of the means to recognize such potential attacks. The underlying concept behind these hacks revolves around appending an unusually constructed string of text to a harmful query that would otherwise be blocked. This maneuver confuses the protective mechanisms and tricks the model into generating a forbidden response. Such scenarios could result in providing detailed instructions to a malicious user for constructing explosives or orchestrating a bank heist. Our investigation demonstrates the feasibility of employing perplexity, a prevalent natural language processing metric, to detect these adversarial tactics before generating a forbidden response. By evaluating the perplexity of queries with and without such adversarial suffixes using an open-source LLM, we discovered that nearly 90 percent were above a perplexity of 1000. This contrast underscores the efficacy of perplexity for detecting this type of exploit. ",
    "url": "https://arxiv.org/abs/2308.14132",
    "authors": [
      "Gabriel Alon",
      "Michael Kamfonas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14152",
    "title": "Unaligned 2D to 3D Translation with Conditional Vector-Quantized Code  Diffusion using Transformers",
    "abstract": "Generating 3D images of complex objects conditionally from a few 2D views is a difficult synthesis problem, compounded by issues such as domain gap and geometric misalignment. For instance, a unified framework such as Generative Adversarial Networks cannot achieve this unless they explicitly define both a domain-invariant and geometric-invariant joint latent distribution, whereas Neural Radiance Fields are generally unable to handle both issues as they optimize at the pixel level. By contrast, we propose a simple and novel 2D to 3D synthesis approach based on conditional diffusion with vector-quantized codes. Operating in an information-rich code space enables high-resolution 3D synthesis via full-coverage attention across the views. Specifically, we generate the 3D codes (e.g. for CT images) conditional on previously generated 3D codes and the entire codebook of two 2D views (e.g. 2D X-rays). Qualitative and quantitative results demonstrate state-of-the-art performance over specialized methods across varied evaluation criteria, including fidelity metrics such as density, coverage, and distortion metrics for two complex volumetric imagery datasets from in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2308.14152",
    "authors": [
      "Abril Corona-Figueroa",
      "Sam Bond-Taylor",
      "Neelanjan Bhowmik",
      "Yona Falinie A. Gaus",
      "Toby P. Breckon",
      "Hubert P. H. Shum",
      "Chris G. Willcocks"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14160",
    "title": "A Unified Transformer-based Network for multimodal Emotion Recognition",
    "abstract": "The development of transformer-based models has resulted in significant advances in addressing various vision and NLP-based research challenges. However, the progress made in transformer-based methods has not been effectively applied to biosensing research. This paper presents a novel Unified Biosensor-Vision Multi-modal Transformer-based (UBVMT) method to classify emotions in an arousal-valence space by combining a 2D representation of an ECG/PPG signal with the face information. To achieve this goal, we first investigate and compare the unimodal emotion recognition performance of three image-based representations of the ECG/PPG signal. We then present our UBVMT network which is trained to perform emotion recognition by combining the 2D image-based representation of the ECG/PPG signal and the facial expression features. Our unified transformer model consists of homogeneous transformer blocks that take as an input the 2D representation of the ECG/PPG signal and the corresponding face frame for emotion representation learning with minimal modality-specific design. Our UBVMT model is trained by reconstructing masked patches of video frames and 2D images of ECG/PPG signals, and contrastive modeling to align face and ECG/PPG data. Extensive experiments on the MAHNOB-HCI and DEAP datasets show that our Unified UBVMT-based model produces comparable results to the state-of-the-art techniques. ",
    "url": "https://arxiv.org/abs/2308.14160",
    "authors": [
      "Kamran Ali",
      "Charles E. Hughes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14161",
    "title": "Intergrated Segmentation and Detection Models for Dentex Challenge 2023",
    "abstract": "Dental panoramic x-rays are commonly used in dental diagnosing. With the development of deep learning, auto detection of diseases from dental panoramic x-rays can help dentists to diagnose diseases more efficiently.The Dentex Challenge 2023 is a competition for automatic detection of abnormal teeth along with their enumeration ids from dental panoramic x-rays. In this paper, we propose a method integrating segmentation and detection models to detect abnormal teeth as well as obtain their enumeration ids.Our codes are available at https://github.com/xyzlancehe/DentexSegAndDet. ",
    "url": "https://arxiv.org/abs/2308.14161",
    "authors": [
      "Lanshan He",
      "Yusheng Liu",
      "Lisheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14175",
    "title": "Leveraging Linear Independence of Component Classifiers: Optimizing Size  and Prediction Accuracy for Online Ensembles",
    "abstract": "Ensembles, which employ a set of classifiers to enhance classification accuracy collectively, are crucial in the era of big data. However, although there is general agreement that the relation between ensemble size and its prediction accuracy, the exact nature of this relationship is still unknown. We introduce a novel perspective, rooted in the linear independence of classifier's votes, to analyze the interplay between ensemble size and prediction accuracy. This framework reveals a theoretical link, consequently proposing an ensemble size based on this relationship. Our study builds upon a geometric framework and develops a series of theorems. These theorems clarify the role of linear dependency in crafting ensembles. We present a method to determine the minimum ensemble size required to ensure a target probability of linearly independent votes among component classifiers. Incorporating real and synthetic datasets, our empirical results demonstrate a trend: increasing the number of classifiers enhances accuracy, as predicted by our theoretical insights. However, we also identify a point of diminishing returns, beyond which additional classifiers provide diminishing improvements in accuracy. Surprisingly, the calculated ideal ensemble size deviates from empirical results for certain datasets, emphasizing the influence of other factors. This study opens avenues for deeper investigations into the complex dynamics governing ensemble design and offers guidance for constructing efficient and effective ensembles in practical scenarios. ",
    "url": "https://arxiv.org/abs/2308.14175",
    "authors": [
      "Enes Bektas",
      "Fazli Can"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14179",
    "title": "Towards Vision-Language Mechanistic Interpretability: A Causal Tracing  Tool for BLIP",
    "abstract": "Mechanistic interpretability seeks to understand the neural mechanisms that enable specific behaviors in Large Language Models (LLMs) by leveraging causality-based methods. While these approaches have identified neural circuits that copy spans of text, capture factual knowledge, and more, they remain unusable for multimodal models since adapting these tools to the vision-language domain requires considerable architectural changes. In this work, we adapt a unimodal causal tracing tool to BLIP to enable the study of the neural mechanisms underlying image-conditioned text generation. We demonstrate our approach on a visual question answering dataset, highlighting the causal relevance of later layer representations for all tokens. Furthermore, we release our BLIP causal tracing tool as open source to enable further experimentation in vision-language mechanistic interpretability by the community. Our code is available at https://github.com/vedantpalit/Towards-Vision-Language-Mechanistic-Interpretability. ",
    "url": "https://arxiv.org/abs/2308.14179",
    "authors": [
      "Vedant Palit",
      "Rohan Pandey",
      "Aryaman Arora",
      "Paul Pu Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14181",
    "title": "Topological Augmentation for Class-Imbalanced Node Classification",
    "abstract": "Class imbalance is prevalent in real-world node classification tasks and often biases graph learning models toward majority classes. Most existing studies root from a node-centric perspective and aim to address the class imbalance in training data by node/class-wise reweighting or resampling. In this paper, we approach the source of the class-imbalance bias from an under-explored topology-centric perspective. Our investigation reveals that beyond the inherently skewed training class distribution, the graph topology also plays an important role in the formation of predictive bias: we identify two fundamental challenges, namely ambivalent and distant message-passing, that can exacerbate the bias by aggravating majority-class over-generalization and minority-class misclassification. In light of these findings, we devise a lightweight topological augmentation method ToBA to dynamically rectify the nodes influenced by ambivalent/distant message-passing during graph learning, so as to mitigate the class-imbalance bias. We highlight that ToBA is a model-agnostic, efficient, and versatile solution that can be seamlessly combined with and further boost other imbalance-handling techniques. Systematic experiments validate the superior performance of ToBA in both promoting imbalanced node classification and mitigating the prediction bias between different classes. ",
    "url": "https://arxiv.org/abs/2308.14181",
    "authors": [
      "Zhining Liu",
      "Zhichen Zeng",
      "Ruizhong Qiu",
      "Hyunsik Yoo",
      "David Zhou",
      "Zhe Xu",
      "Yada Zhu",
      "Kommy Weldemariam",
      "Jingrui He",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14185",
    "title": "Semi-static Conditions in Low-latency C++ for High Frequency Trading:  Better than Branch Prediction Hints",
    "abstract": "Conditional branches pose a challenge for code optimisation, particularly in low latency settings. For better performance, processors leverage dedicated hardware to predict the outcome of a branch and execute the following instructions speculatively, a powerful optimisation. Modern branch predictors employ sophisticated algorithms and heuristics that utilise historical data and patterns to make predictions, and often, are extremely effective at doing so. Consequently, programmers may inadvertently underestimate the cost of misprediction when benchmarking code with synthetic data that is either too short or too predictable. While eliminating branches may not always be feasible, C++20 introduced the [[likely]] and [[unlikely]] attributes that enable the compiler to perform spot optimisations on assembly code associated with likely execution paths. Can we do better than this? This work presents the development of a novel language construct, referred to as a semi-static condition, which enables programmers to dynamically modify the direction of a branch at run-time by modifying the assembly code within the underlying executable. Subsequently, we explore scenarios where the use of semi-static conditions outperforms traditional conditional branching, highlighting their potential applications in real-time machine learning and high-frequency trading. Throughout the development process, key considerations of performance, portability, syntax, and security were taken into account. ",
    "url": "https://arxiv.org/abs/2308.14185",
    "authors": [
      "Paul Alexander Bilokon",
      "Maximilian Lucuta",
      "Erez Shermer"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2308.14206",
    "title": "Using Knowledge Representation and Task Planning for Robot-agnostic  Skills on the Example of Contact-Rich Wiping Tasks",
    "abstract": "The transition to agile manufacturing, Industry 4.0, and high-mix-low-volume tasks require robot programming solutions that are flexible. However, most deployed robot solutions are still statically programmed and use stiff position control, which limit their usefulness. In this paper, we show how a single robot skill that utilizes knowledge representation, task planning, and automatic selection of skill implementations based on the input parameters can be executed in different contexts. We demonstrate how the skill-based control platform enables this with contact-rich wiping tasks on different robot systems. To achieve that in this case study, our approach needs to address different kinematics, gripper types, vendors, and fundamentally different control interfaces. We conducted the experiments with a mobile platform that has a Universal Robots UR5e 6 degree-of-freedom robot arm with position control and a 7 degree-of-freedom KUKA iiwa with torque control. ",
    "url": "https://arxiv.org/abs/2308.14206",
    "authors": [
      "Matthias Mayr",
      "Faseeh Ahmad",
      "Alexander Duerr",
      "Volker Krueger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14222",
    "title": "Accurate complex Jacobi rotations",
    "abstract": "This note shows how to compute, to high relative accuracy under mild assumptions, complex Jacobi rotations for diagonalization of Hermitian matrices of order two, using the correctly rounded functions $\\mathtt{cr\\_hypot}$ and $\\mathtt{cr\\_rsqrt}$, proposed for standardization in the C programming language as recommended by the IEEE-754 floating-point standard. The rounding to nearest (ties to even) and the non-stop arithmetic are assumed. The numerical examples compare the observed with theoretical bounds on the relative errors in the rotations' elements, and show that the maximal observed departure of the rotations' determinants from unity is smaller than that of the transformations computed by LAPACK. ",
    "url": "https://arxiv.org/abs/2308.14222",
    "authors": [
      "Vedran Novakovi\u0107"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.14228",
    "title": "Broadcast Channels with Heterogeneous Arrival and Decoding Deadlines:  Second-Order Achievability",
    "abstract": "A standard assumption in the design of ultra-reliable low-latency communication systems is that the duration between message arrivals is larger than the number of channel uses before the decoding deadline. Nevertheless, this assumption fails when messages arrive rapidly and reliability constraints require that the number of channel uses exceed the time between arrivals. In this paper, we consider a broadcast setting in which a transmitter wishes to send two different messages to two receivers over Gaussian channels. Messages have different arrival times and decoding deadlines such that their transmission windows overlap. For this setting, we propose a coding scheme that exploits Marton's coding strategy. We derive rigorous bounds on the achievable rate regions. Those bounds can be easily employed in point-to-point settings with one or multiple parallel channels. In the point-to-point setting with one or multiple parallel channels, the proposed achievability scheme outperforms the Normal Approximation, especially when the number of channel uses is smaller than $200$. In the broadcast setting, our scheme agrees with Marton's strategy for sufficiently large numbers of channel uses and shows significant performance improvements over standard approaches based on time sharing for transmission of short packets. ",
    "url": "https://arxiv.org/abs/2308.14228",
    "authors": [
      "Homa Nikbakht",
      "Malcolm Egan",
      "Jean-Marie Gorce",
      "H.Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.14231",
    "title": "Efficient Reconstruction of Neural Mass Dynamics Modeled by  Linear-Threshold Networks",
    "abstract": "This paper studies the data-driven reconstruction of firing rate dynamics of brain activity described by linear-threshold network models. Identifying the system parameters directly leads to a large number of variables and a highly non-convex objective function. Instead, our approach introduces a novel reformulation that incorporates biological organizational features and turns the identification problem into a scalar variable optimization of a discontinuous, non-convex objective function. We prove that the minimizer of the objective function is unique and establish that the solution of the optimization problem leads to the identification of all the desired system parameters. These results are the basis to introduce an algorithm to find the optimizer by searching the different regions corresponding to the domain of definition of the objective function. To deal with measurement noise in sampled data, we propose a modification of the original algorithm whose identification error is linearly bounded by the magnitude of the measurement noise. We demonstrate the effectiveness of the proposed algorithms through simulations on synthetic and experimental data. ",
    "url": "https://arxiv.org/abs/2308.14231",
    "authors": [
      "Xuan Wang",
      "Jorge Cortes"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.14250",
    "title": "Rule-Based Error Detection and Correction to Operationalize Movement  Trajectory Classification",
    "abstract": "Classification of movement trajectories has many applications in transportation. Supervised neural models represent the current state-of-the-art. Recent security applications require this task to be rapidly employed in environments that may differ from the data used to train such models for which there is little training data. We provide a neuro-symbolic rule-based framework to conduct error correction and detection of these models to support eventual deployment in security applications. We provide a suite of experiments on several recent and state-of-the-art models and show an accuracy improvement of 1.7% over the SOTA model in the case where all classes are present in training and when 40% of classes are omitted from training, we obtain a 5.2% improvement (zero-shot) and 23.9% (few-shot) improvement over the SOTA model without resorting to retraining of the base model. ",
    "url": "https://arxiv.org/abs/2308.14250",
    "authors": [
      "Bowen Xi",
      "Kevin Scaria",
      "Paulo Shakarian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2308.14258",
    "title": "Breaking Boundaries: Distributed Domain Decomposition with Scalable  Physics-Informed Neural PDE Solvers",
    "abstract": "Mosaic Flow is a novel domain decomposition method designed to scale physics-informed neural PDE solvers to large domains. Its unique approach leverages pre-trained networks on small domains to solve partial differential equations on large domains purely through inference, resulting in high reusability. This paper presents an end-to-end parallelization of Mosaic Flow, combining data parallel training and domain parallelism for inference on large-scale problems. By optimizing the network architecture and data parallel training, we significantly reduce the training time for learning the Laplacian operator to minutes on 32 GPUs. Moreover, our distributed domain decomposition algorithm enables scalable inferences for solving the Laplace equation on domains 4096 times larger than the training domain, demonstrating strong scaling while maintaining accuracy on 32 GPUs. The reusability of Mosaic Flow, combined with the improved performance achieved through the distributed-memory algorithms, makes it a promising tool for modeling complex physical phenomena and accelerating scientific discovery. ",
    "url": "https://arxiv.org/abs/2308.14258",
    "authors": [
      "Arthur Feeney",
      "Zitong Li",
      "Ramin Bostanabad",
      "Aparna Chandramowlishwaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.14267",
    "title": "Unleash Model Potential: Bootstrapped Meta Self-supervised Learning",
    "abstract": "The long-term goal of machine learning is to learn general visual representations from a small amount of data without supervision, mimicking three advantages of human cognition: i) no need for labels, ii) robustness to data scarcity, and iii) learning from experience. Self-supervised learning and meta-learning are two promising techniques to achieve this goal, but they both only partially capture the advantages and fail to address all the problems. Self-supervised learning struggles to overcome the drawbacks of data scarcity, while ignoring prior knowledge that can facilitate learning and generalization. Meta-learning relies on supervised information and suffers from a bottleneck of insufficient learning. To address these issues, we propose a novel Bootstrapped Meta Self-Supervised Learning (BMSSL) framework that aims to simulate the human learning process. We first analyze the close relationship between meta-learning and self-supervised learning. Based on this insight, we reconstruct tasks to leverage the strengths of both paradigms, achieving advantages i and ii. Moreover, we employ a bi-level optimization framework that alternates between solving specific tasks with a learned ability (first level) and improving this ability (second level), attaining advantage iii. To fully harness its power, we introduce a bootstrapped target based on meta-gradient to make the model its own teacher. We validate the effectiveness of our approach with comprehensive theoretical and empirical study. ",
    "url": "https://arxiv.org/abs/2308.14267",
    "authors": [
      "Jingyao Wang",
      "Zeen Song",
      "Wenwen Qiang",
      "Changwen Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14279",
    "title": "Sampling unknown large networks restricted by low sampling rates",
    "abstract": "Graph sampling plays an important role in data mining for large networks. Specifically, larger networks often correspond to lower sampling rates. Under the situation, traditional traversal-based samplings for large networks usually have an excessive preference for densely-connected network core nodes. Aim at this issue, this paper proposes a sampling method for unknown networks at low sampling rates, called SLSR, which first adopts a random node sampling to evaluate a degree threshold, utilized to distinguish the core from periphery, and the average degree in unknown networks, and then runs a double-layer sampling strategy on the core and periphery. SLSR is simple and has a high time efficiency, but experimental evaluation confirms that the proposed method can accurately preserve many critical structures of unknown large networks at sampling rates not exceeding 10%. ",
    "url": "https://arxiv.org/abs/2308.14279",
    "authors": [
      "Bo Jiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.14286",
    "title": "Bridging Cross-task Protocol Inconsistency for Distillation in Dense  Object Detection",
    "abstract": "Knowledge distillation (KD) has shown potential for learning compact models in dense object detection. However, the commonly used softmax-based distillation ignores the absolute classification scores for individual categories. Thus, the optimum of the distillation loss does not necessarily lead to the optimal student classification scores for dense object detectors. This cross-task protocol inconsistency is critical, especially for dense object detectors, since the foreground categories are extremely imbalanced. To address the issue of protocol differences between distillation and classification, we propose a novel distillation method with cross-task consistent protocols, tailored for the dense object detection. For classification distillation, we address the cross-task protocol inconsistency problem by formulating the classification logit maps in both teacher and student models as multiple binary-classification maps and applying a binary-classification distillation loss to each map. For localization distillation, we design an IoU-based Localization Distillation Loss that is free from specific network structures and can be compared with existing localization distillation losses. Our proposed method is simple but effective, and experimental results demonstrate its superiority over existing methods. Code is available at https://github.com/TinyTigerPan/BCKD. ",
    "url": "https://arxiv.org/abs/2308.14286",
    "authors": [
      "Longrong Yang",
      "Xianpan Zhou",
      "Xuewei Li",
      "Liang Qiao",
      "Zheyang Li",
      "Ziwei Yang",
      "Gaoang Wang",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14306",
    "title": "Evaluating the Robustness to Instructions of Large Language Models",
    "abstract": "Recently, Instruction fine-tuning has risen to prominence as a potential method for enhancing the zero-shot capabilities of Large Language Models (LLMs) on novel tasks. This technique has shown an exceptional ability to boost the performance of moderately sized LLMs, sometimes even reaching performance levels comparable to those of much larger model variants. The focus is on the robustness of instruction-tuned LLMs to seen and unseen tasks. We conducted an exploration of six models including Alpaca, Vicuna, WizardLM, and Traditional Task-oriented Models(Flan-T5-XL/XXL, T0++) using real-world relation extraction datasets as case studies. We carried out a comprehensive evaluation of these instruction-following LLMs which have been tuned based on open-domain instructions and task-oriented instructions. The main discussion is their performance and robustness towards instructions. We have observed that in most cases, the model's performance in dealing with unfamiliar instructions tends to worsen significantly, and the robustness of the model for RE instructions deteriorates compared to QA. Further, we discovered that up until a certain parameter size threshold (3B), the performance of the FLAN-T5 model improves as the parameter count increases. The robustness of different scales of FLAN-T5 models to RE instruction is worse than the robustness to QA instruction. ",
    "url": "https://arxiv.org/abs/2308.14306",
    "authors": [
      "Yuansheng Ni",
      "Sichao Jiang",
      "Xinyu wu",
      "Hui Shen",
      "Yuli Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14311",
    "title": "Spread Control Method on Unknown Networks Based on Hierarchical  Reinforcement Learning",
    "abstract": "The spread of infectious diseases, rumors, and harmful speech in networks can result in substantial losses, underscoring the significance of studying how to suppress such hazardous events. However, previous studies often assume full knowledge of the network structure, which is often not the case in real-world scenarios. In this paper, we address the challenge of controlling the propagation of hazardous events by removing nodes when the network structure is unknown. To tackle this problem, we propose a hierarchical reinforcement learning method that drastically reduces the action space, making the problem feasible to solve. Simulation experiments demonstrate the superiority of our method over the baseline methods. Remarkably, even though the baseline methods possess extensive knowledge of the network structure, while our method has no prior information about it, our approach still achieves better results. ",
    "url": "https://arxiv.org/abs/2308.14311",
    "authors": [
      "Wenxiang Dong",
      "H.Vicky Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14321",
    "title": "Leveraging A Medical Knowledge Graph into Large Language Models for  Diagnosis Prediction",
    "abstract": "Electronic Health Records (EHRs) and routine documentation practices play a vital role in patients' daily care, providing a holistic record of health, diagnoses, and treatment. However, complex and verbose EHR narratives overload healthcare providers, risking diagnostic inaccuracies. While Large Language Models (LLMs) have showcased their potential in diverse language tasks, their application in the healthcare arena needs to ensure the minimization of diagnostic errors and the prevention of patient harm. In this paper, we outline an innovative approach for augmenting the proficiency of LLMs in the realm of automated diagnosis generation, achieved through the incorporation of a medical knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the clinical diagnostic reasoning process. We derive the KG from the National Library of Medicine's Unified Medical Language System (UMLS), a robust repository of biomedical knowledge. Our method negates the need for pre-training and instead leverages the KG as an auxiliary instrument aiding in the interpretation and summarization of complex medical concepts. Using real-world hospital datasets, our experimental results demonstrate that the proposed approach of combining LLMs with KG has the potential to improve the accuracy of automated diagnosis generation. More importantly, our approach offers an explainable diagnostic pathway, edging us closer to the realization of AI-augmented diagnostic decision support systems. ",
    "url": "https://arxiv.org/abs/2308.14321",
    "authors": [
      "Yanjun Gao",
      "Ruizhe Li",
      "John Caskey",
      "Dmitriy Dligach",
      "Timothy Miller",
      "Matthew M. Churpek",
      "Majid Afshar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14322",
    "title": "Machine Unlearning Methodology base on Stochastic Teacher Network",
    "abstract": "The rise of the phenomenon of the \"right to be forgotten\" has prompted research on machine unlearning, which grants data owners the right to actively withdraw data that has been used for model training, and requires the elimination of the contribution of that data to the model. A simple method to achieve this is to use the remaining data to retrain the model, but this is not acceptable for other data owners who continue to participate in training. Existing machine unlearning methods have been found to be ineffective in quickly removing knowledge from deep learning models. This paper proposes using a stochastic network as a teacher to expedite the mitigation of the influence caused by forgotten data on the model. We performed experiments on three datasets, and the findings demonstrate that our approach can efficiently mitigate the influence of target data on the model within a single epoch. This allows for one-time erasure and reconstruction of the model, and the reconstruction model achieves the same performance as the retrained model. ",
    "url": "https://arxiv.org/abs/2308.14322",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Yifu Sun",
      "Chuanyao Zhang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14326",
    "title": "Towards solving ontological dissonance using network graphs",
    "abstract": "Data Spaces are an emerging concept for the trusted implementation of data-based applications and business models, offering a high degree of flexibility and sovereignty to all stakeholders. As Data Spaces are currently emerging in different domains such as mobility, health or food, semantic interfaces need to be identified and implemented to ensure the technical interoperability of these Data Spaces. This paper consolidates data models from 13 different domains and analyzes the ontological dissonance of these domains. Using a network graph, central data models and ontology attributes are identified, while the semantic heterogeneity of these domains is described qualitatively. The research outlook describes how these results help to connect different Data Spaces across domains. ",
    "url": "https://arxiv.org/abs/2308.14326",
    "authors": [
      "Maximilian Staebler",
      "Frank Koester",
      "Christoph Schlueter-Langdon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14329",
    "title": "End-to-End Driving via Self-Supervised Imitation Learning Using Camera  and LiDAR Data",
    "abstract": "In autonomous driving, the end-to-end (E2E) driving approach that predicts vehicle control signals directly from sensor data is rapidly gaining attention. To learn a safe E2E driving system, one needs an extensive amount of driving data and human intervention. Vehicle control data is constructed by many hours of human driving, and it is challenging to construct large vehicle control datasets. Often, publicly available driving datasets are collected with limited driving scenes, and collecting vehicle control data is only available by vehicle manufacturers. To address these challenges, this paper proposes the first self-supervised learning framework, self-supervised imitation learning (SSIL), that can learn E2E driving networks without using driving command data. To construct pseudo steering angle data, proposed SSIL predicts a pseudo target from the vehicle's poses at the current and previous time points that are estimated with light detection and ranging sensors. Our numerical experiments demonstrate that the proposed SSIL framework achieves comparable E2E driving accuracy with the supervised learning counterpart. In addition, our qualitative analyses using a conventional visual explanation tool show that trained NNs by proposed SSIL and the supervision counterpart attend similar objects in making predictions. ",
    "url": "https://arxiv.org/abs/2308.14329",
    "authors": [
      "Jin Bok Park",
      "Jinkyu Lee",
      "Muhyun Back",
      "Hyunmin Han",
      "David T. Ma",
      "Sang Min Won",
      "Sung Soo Hwang",
      "Il Yong Chun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14333",
    "title": "DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local  Smoothing",
    "abstract": "Diffusion models have been leveraged to perform adversarial purification and thus provide both empirical and certified robustness for a standard model. On the other hand, different robustly trained smoothed models have been studied to improve the certified robustness. Thus, it raises a natural question: Can diffusion model be used to achieve improved certified robustness on those robustly trained smoothed models? In this work, we first theoretically show that recovered instances by diffusion models are in the bounded neighborhood of the original instance with high probability; and the \"one-shot\" denoising diffusion probabilistic models (DDPM) can approximate the mean of the generated distribution of a continuous-time diffusion model, which approximates the original instance under mild conditions. Inspired by our analysis, we propose a certifiably robust pipeline DiffSmooth, which first performs adversarial purification via diffusion models and then maps the purified instances to a common region via a simple yet effective local smoothing strategy. We conduct extensive experiments on different datasets and show that DiffSmooth achieves SOTA-certified robustness compared with eight baselines. For instance, DiffSmooth improves the SOTA-certified accuracy from $36.0\\%$ to $53.0\\%$ under $\\ell_2$ radius $1.5$ on ImageNet. The code is available at [https://github.com/javyduck/DiffSmooth]. ",
    "url": "https://arxiv.org/abs/2308.14333",
    "authors": [
      "Jiawei Zhang",
      "Zhongzhu Chen",
      "Huan Zhang",
      "Chaowei Xiao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14340",
    "title": "HRGCN: Heterogeneous Graph-level Anomaly Detection with Hierarchical  Relation-augmented Graph Neural Networks",
    "abstract": "This work considers the problem of heterogeneous graph-level anomaly detection. Heterogeneous graphs are commonly used to represent behaviours between different types of entities in complex industrial systems for capturing as much information about the system operations as possible. Detecting anomalous heterogeneous graphs from a large set of system behaviour graphs is crucial for many real-world applications like online web/mobile service and cloud access control. To address the problem, we propose HRGCN, an unsupervised deep heterogeneous graph neural network, to model complex heterogeneous relations between different entities in the system for effectively identifying these anomalous behaviour graphs. HRGCN trains a hierarchical relation-augmented Heterogeneous Graph Neural Network (HetGNN), which learns better graph representations by modelling the interactions among all the system entities and considering both source-to-destination entity (node) types and their relation (edge) types. Extensive evaluation on two real-world application datasets shows that HRGCN outperforms state-of-the-art competing anomaly detection approaches. We further present a real-world industrial case study to justify the effectiveness of HRGCN in detecting anomalous (e.g., congested) network devices in a mobile communication service. HRGCN is available at https://github.com/jiaxililearn/HRGCN. ",
    "url": "https://arxiv.org/abs/2308.14340",
    "authors": [
      "Jiaxi Li",
      "Guansong Pang",
      "Ling Chen",
      "Mohammad-Reza Namazi-Rad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14348",
    "title": "Label-free Deep Learning Driven Secure Access Selection in  Space-Air-Ground Integrated Networks",
    "abstract": "In Space-air-ground integrated networks (SAGIN), the inherent openness and extensive broadcast coverage expose these networks to significant eavesdropping threats. Considering the inherent co-channel interference due to spectrum sharing among multi-tier access networks in SAGIN, it can be leveraged to assist the physical layer security among heterogeneous transmissions. However, it is challenging to conduct a secrecy-oriented access strategy due to both heterogeneous resources and different eavesdropping models. In this paper, we explore secure access selection for a scenario involving multi-mode users capable of accessing satellites, unmanned aerial vehicles, or base stations in the presence of eavesdroppers. Particularly, we propose a Q-network approximation based deep learning approach for selecting the optimal access strategy for maximizing the sum secrecy rate. Meanwhile, the power optimization is also carried out by an unsupervised learning approach to improve the secrecy performance. Remarkably, two neural networks are trained by unsupervised learning and Q-network approximation which are both label-free methods without knowing the optimal solution as labels. Numerical results verify the efficiency of our proposed power optimization approach and access strategy, leading to enhanced secure transmission performance. ",
    "url": "https://arxiv.org/abs/2308.14348",
    "authors": [
      "Zhaowei Wang",
      "Zhisheng Yin",
      "Xiucheng Wang",
      "Nan Cheng",
      "Yuan Zhang",
      "Tom H. Luan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14355",
    "title": "Can Transformer and GNN Help Each Other?",
    "abstract": "Although Transformer has achieved great success in natural language process and computer vision, it has difficulty generalizing to medium and large-scale graph data for two important reasons: (i) High complexity. (ii) Failing to capture the complex and entangled structure information. In graph representation learning, Graph Neural Networks(GNNs) can fuse the graph structure and node attributes but have limited receptive fields. Therefore, we question whether can we combine Transformers and GNNs to help each other. In this paper, we propose a new model named TransGNN where the Transformer layer and GNN layer are used alternately to improve each other. Specifically, to expand the receptive field and disentangle the information aggregation from edges, we propose using Transformer to aggregate more relevant nodes' information to improve the message passing of GNNs. Besides, to capture the graph structure information, we utilize positional encoding and make use of the GNN layer to fuse the structure into node attributes, which improves the Transformer in graph data. We also propose to sample the most relevant nodes for Transformer and two efficient samples update strategies to lower the complexity. At last, we theoretically prove that TransGNN is more expressive than GNNs only with extra linear complexity. The experiments on eight datasets corroborate the effectiveness of TransGNN on node and graph classification tasks. ",
    "url": "https://arxiv.org/abs/2308.14355",
    "authors": [
      "Peiyan Zhang",
      "Yuchen Yan",
      "Chaozhuo Li",
      "Senzhang Wang",
      "Xing Xie",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.14359",
    "title": "Effect of Attention and Self-Supervised Speech Embeddings on  Non-Semantic Speech Tasks",
    "abstract": "Human emotion understanding is pivotal in making conversational technology mainstream. We view speech emotion understanding as a perception task which is a more realistic setting. With varying contexts (languages, demographics, etc.) different share of people perceive the same speech segment as a non-unanimous emotion. As part of the ACM Multimedia 2023 Computational Paralinguistics ChallengE (ComParE) in the EMotion Share track, we leverage their rich dataset of multilingual speakers and multi-label regression target of 'emotion share' or perception of that emotion. We demonstrate that the training scheme of different foundation models dictates their effectiveness for tasks beyond speech recognition, especially for non-semantic speech tasks like emotion understanding. This is a very complex task due to multilingual speakers, variability in the target labels, and inherent imbalance in the regression dataset. Our results show that HuBERT-Large with a self-attention-based light-weight sequence model provides 4.6% improvement over the reported baseline. ",
    "url": "https://arxiv.org/abs/2308.14359",
    "authors": [
      "Payal Mohapatra",
      "Akash Pandey",
      "Yueyuan Sui",
      "Qi Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.14367",
    "title": "A Comprehensive Overview of Backdoor Attacks in Large Language Models  within Communication Networks",
    "abstract": "The Large Language Models (LLMs) are becoming an integral part of modern communication networks due to their superior proficiency in language comprehension and generation. In the context of these networks, where limited data and computing resources often necessitate the use of third-party data and computing resources, the risk of backdoor attacks becomes highly significant. Such strategies may expose the model within the network to maliciously manipulated training data and processing, providing an opportunity for attackers to embed a hidden backdoor into the model, termed a backdoor attack. Backdoor attack in LLMs refers to embedding a hidden backdoor in LLMs that causes the model to perform normally on benign samples but exhibit degraded performance on poisoned ones. This issue is particularly concerning within communication networks where reliability and security are paramount. Despite the extensive research on backdoor attacks, there remains a lack of in-depth exploration specifically within the context of LLMs employed in communication networks, and a systematic review of such attacks is currently absent. In this survey, we systematically propose a taxonomy of backdoor attacks in LLMs as used in communication networks, dividing them into four major categories: input-triggered, prompt-triggered, instruction-triggered, and demonstration-triggered attacks. Furthermore, we conduct a comprehensive analysis of the benchmark datasets within the network domain. Finally, we identify potential problems and open challenges, offering valuable insights into future research directions for enhancing the security and integrity of LLMs in communication networks. ",
    "url": "https://arxiv.org/abs/2308.14367",
    "authors": [
      "Haomiao Yang",
      "Kunlan Xiang",
      "Hongwei Li",
      "Rongxing Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.14371",
    "title": "SuperUDF: Self-supervised UDF Estimation for Surface Reconstruction",
    "abstract": "Learning-based surface reconstruction based on unsigned distance functions (UDF) has many advantages such as handling open surfaces. We propose SuperUDF, a self-supervised UDF learning which exploits a learned geometry prior for efficient training and a novel regularization for robustness to sparse sampling. The core idea of SuperUDF draws inspiration from the classical surface approximation operator of locally optimal projection (LOP). The key insight is that if the UDF is estimated correctly, the 3D points should be locally projected onto the underlying surface following the gradient of the UDF. Based on that, a number of inductive biases on UDF geometry and a pre-learned geometry prior are devised to learn UDF estimation efficiently. A novel regularization loss is proposed to make SuperUDF robust to sparse sampling. Furthermore, we also contribute a learning-based mesh extraction from the estimated UDFs. Extensive evaluations demonstrate that SuperUDF outperforms the state of the arts on several public datasets in terms of both quality and efficiency. Code will be released after accteptance. ",
    "url": "https://arxiv.org/abs/2308.14371",
    "authors": [
      "Hui Tian",
      "Chenyang Zhu",
      "Yifei Shi",
      "Kai Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14376",
    "title": "Are Existing Out-Of-Distribution Techniques Suitable for Network  Intrusion Detection?",
    "abstract": "Machine learning (ML) has become increasingly popular in network intrusion detection. However, ML-based solutions always respond regardless of whether the input data reflects known patterns, a common issue across safety-critical applications. While several proposals exist for detecting Out-Of-Distribution (OOD) in other fields, it remains unclear whether these approaches can effectively identify new forms of intrusions for network security. New attacks, not necessarily affecting overall distributions, are not guaranteed to be clearly OOD as instead, images depicting new classes are in computer vision. In this work, we investigate whether existing OOD detectors from other fields allow the identification of unknown malicious traffic. We also explore whether more discriminative and semantically richer embedding spaces within models, such as those created with contrastive learning and multi-class tasks, benefit detection. Our investigation covers a set of six OOD techniques that employ different detection strategies. These techniques are applied to models trained in various ways and subsequently exposed to unknown malicious traffic from the same and different datasets (network environments). Our findings suggest that existing detectors can identify a consistent portion of new malicious traffic, and that improved embedding spaces enhance detection. We also demonstrate that simple combinations of certain detectors can identify almost 100% of malicious traffic in our tested scenarios. ",
    "url": "https://arxiv.org/abs/2308.14376",
    "authors": [
      "Andrea Corsini",
      "Shanchieh Jay Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.14377",
    "title": "Meta Attentive Graph Convolutional Recurrent Network for Traffic  Forecasting",
    "abstract": "Traffic forecasting is a fundamental problem in intelligent transportation systems. Existing traffic predictors are limited by their expressive power to model the complex spatial-temporal dependencies in traffic data, mainly due to the following limitations. Firstly, most approaches are primarily designed to model the local shared patterns, which makes them insufficient to capture the specific patterns associated with each node globally. Hence, they fail to learn each node's unique properties and diversified patterns. Secondly, most existing approaches struggle to accurately model both short- and long-term dependencies simultaneously. In this paper, we propose a novel traffic predictor, named Meta Attentive Graph Convolutional Recurrent Network (MAGCRN). MAGCRN utilizes a Graph Convolutional Recurrent Network (GCRN) as a core module to model local dependencies and improves its operation with two novel modules: 1) a Node-Specific Meta Pattern Learning (NMPL) module to capture node-specific patterns globally and 2) a Node Attention Weight Generation Module (NAWG) module to capture short- and long-term dependencies by connecting the node-specific features with the ones learned initially at each time step during GCRN operation. Experiments on six real-world traffic datasets demonstrate that NMPL and NAWG together enable MAGCRN to outperform state-of-the-art baselines on both short- and long-term predictions. ",
    "url": "https://arxiv.org/abs/2308.14377",
    "authors": [
      "Adnan Zeb",
      "Yongchao Ye",
      "Shiyao Zhang",
      "James J. Q. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14378",
    "title": "GKGNet: Group K-Nearest Neighbor based Graph Convolutional Network for  Multi-Label Image Recognition",
    "abstract": "Multi-Label Image Recognition (MLIR) is a challenging task that aims to predict multiple object labels in a single image while modeling the complex relationships between labels and image regions. Although convolutional neural networks and vision transformers have succeeded in processing images as regular grids of pixels or patches, these representations are sub-optimal for capturing irregular and discontinuous regions of interest. In this work, we present the first fully graph convolutional model, Group K-nearest neighbor based Graph convolutional Network (GKGNet), which models the connections between semantic label embeddings and image patches in a flexible and unified graph structure. To address the scale variance of different objects and to capture information from multiple perspectives, we propose the Group KGCN module for dynamic graph construction and message passing. Our experiments demonstrate that GKGNet achieves state-of-the-art performance with significantly lower computational costs on the challenging multi-label datasets, \\ie MS-COCO and VOC2007 datasets. We will release the code and models to facilitate future research in this area. ",
    "url": "https://arxiv.org/abs/2308.14378",
    "authors": [
      "Ruijie Yao",
      "Sheng Jin",
      "Lumin Xu",
      "Wang Zeng",
      "Wentao Liu",
      "Chen Qian",
      "Ping Luo",
      "Ji Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14383",
    "title": "Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a  Light-Weight ToF Sensor",
    "abstract": "Light-weight time-of-flight (ToF) depth sensors are compact and cost-efficient, and thus widely used on mobile devices for tasks such as autofocus and obstacle detection. However, due to the sparse and noisy depth measurements, these sensors have rarely been considered for dense geometry reconstruction. In this work, we present the first dense SLAM system with a monocular camera and a light-weight ToF sensor. Specifically, we propose a multi-modal implicit scene representation that supports rendering both the signals from the RGB camera and light-weight ToF sensor which drives the optimization by comparing with the raw sensor inputs. Moreover, in order to guarantee successful pose tracking and reconstruction, we exploit a predicted depth as an intermediate supervision and develop a coarse-to-fine optimization strategy for efficient learning of the implicit representation. At last, the temporal information is explicitly exploited to deal with the noisy signals from light-weight ToF sensors to improve the accuracy and robustness of the system. Experiments demonstrate that our system well exploits the signals of light-weight ToF sensors and achieves competitive results both on camera tracking and dense scene reconstruction. Project page: \\url{https://zju3dv.github.io/tof_slam/}. ",
    "url": "https://arxiv.org/abs/2308.14383",
    "authors": [
      "Xinyang Liu",
      "Yijin Li",
      "Yanbin Teng",
      "Hujun Bao",
      "Guofeng Zhang",
      "Yinda Zhang",
      "Zhaopeng Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14397",
    "title": "Ensemble of Anchor-Free Models for Robust Bangla Document Layout  Segmentation",
    "abstract": "In this research paper, we introduce a novel approach designed for the purpose of segmenting the layout of Bangla documents. Our methodology involves the utilization of a sophisticated ensemble of YOLOv8 models, which were trained for the DL Sprint 2.0 - BUET CSE Fest 2023 Competition focused on Bangla document layout segmentation. Our primary emphasis lies in enhancing various aspects of the task, including techniques such as image augmentation, model architecture, and the incorporation of model ensembles. We deliberately reduce the quality of a subset of document images to enhance the resilience of model training, thereby resulting in an improvement in our cross-validation score. By employing Bayesian optimization, we determine the optimal confidence and Intersection over Union (IoU) thresholds for our model ensemble. Through our approach, we successfully demonstrate the effectiveness of anchor-free models in achieving robust layout segmentation in Bangla documents. ",
    "url": "https://arxiv.org/abs/2308.14397",
    "authors": [
      "U Mong Sain Chak",
      "Md. Asib Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14400",
    "title": "Semi-Supervised Semantic Depth Estimation using Symbiotic Transformer  and NearFarMix Augmentation",
    "abstract": "In computer vision, depth estimation is crucial for domains like robotics, autonomous vehicles, augmented reality, and virtual reality. Integrating semantics with depth enhances scene understanding through reciprocal information sharing. However, the scarcity of semantic information in datasets poses challenges. Existing convolutional approaches with limited local receptive fields hinder the full utilization of the symbiotic potential between depth and semantics. This paper introduces a dataset-invariant semi-supervised strategy to address the scarcity of semantic information. It proposes the Depth Semantics Symbiosis module, leveraging the Symbiotic Transformer for achieving comprehensive mutual awareness by information exchange within both local and global contexts. Additionally, a novel augmentation, NearFarMix is introduced to combat overfitting and compensate both depth-semantic tasks by strategically merging regions from two images, generating diverse and structurally consistent samples with enhanced control. Extensive experiments on NYU-Depth-V2 and KITTI datasets demonstrate the superiority of our proposed techniques in indoor and outdoor environments. ",
    "url": "https://arxiv.org/abs/2308.14400",
    "authors": [
      "Md Awsafur Rahman",
      "Shaikh Anowarul Fattah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14401",
    "title": "CodeMark: Imperceptible Watermarking for Code Datasets against Neural  Code Completion Models",
    "abstract": "Code datasets are of immense value for training neural-network-based code completion models, where companies or organizations have made substantial investments to establish and process these datasets. Unluckily, these datasets, either built for proprietary or public usage, face the high risk of unauthorized exploits, resulting from data leakages, license violations, etc. Even worse, the ``black-box'' nature of neural models sets a high barrier for externals to audit their training datasets, which further connives these unauthorized usages. Currently, watermarking methods have been proposed to prohibit inappropriate usage of image and natural language datasets. However, due to domain specificity, they are not directly applicable to code datasets, leaving the copyright protection of this emerging and important field of code data still exposed to threats. To fill this gap, we propose a method, named CodeMark, to embed user-defined imperceptible watermarks into code datasets to trace their usage in training neural code completion models. CodeMark is based on adaptive semantic-preserving transformations, which preserve the exact functionality of the code data and keep the changes covert against rule-breakers. We implement CodeMark in a toolkit and conduct an extensive evaluation of code completion models. CodeMark is validated to fulfill all desired properties of practical watermarks, including harmlessness to model accuracy, verifiability, robustness, and imperceptibility. ",
    "url": "https://arxiv.org/abs/2308.14401",
    "authors": [
      "Zhensu Sun",
      "Xiaoning Du",
      "Fu Song",
      "Li Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14411",
    "title": "Community College Articulation Agreement Websites: Students' Suggestions  for New Academic Advising Software Features",
    "abstract": "Purpose: Community college counselors and students use articulation agreement websites to (a) learn how community college courses will transfer and fulfill university requirements and (b) develop an academic plan to prepare to transfer. Compared to universities that do not have them, universities that do have articulation agreements provide more transparency about course transfer. However, the literature displays conflicting results on whether articulation agreements improve transfer-related outcomes; perhaps one contributor to these conflicting research results is the subpar user experience of articulation agreement reports and the websites that host them. Approach: Accordingly, we surveyed and interviewed California community college transfer students to gather their suggestions for new academic-advising-related software features for the ASSIST website. ASSIST is California's official centralized repository of articulation agreement reports between public California community colleges and universities. We analyzed the open-ended survey and interview data using structural coding and thematic analysis. Findings: We identified four themes around students' software feature suggestions for ASSIST: (a) features that automate laborious academic advising tasks, (b) features to reduce ambiguity with articulation agreements, (c) features to mitigate mistakes in term-by-term course planning, and (d) features to facilitate online advising from counselors and student peers. Originality: Our research builds on the scant literature on incorporating education technology into articulation agreements. Furthermore, some of the suggested academic-advising-related software features (and their underlying pain points) are novel and have not been discussed before in prior research. ",
    "url": "https://arxiv.org/abs/2308.14411",
    "authors": [
      "David V. Nguyen",
      "Shayan Doroudi",
      "Daniel A. Epstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.14414",
    "title": "INF: Implicit Neural Fusion for LiDAR and Camera",
    "abstract": "Sensor fusion has become a popular topic in robotics. However, conventional fusion methods encounter many difficulties, such as data representation differences, sensor variations, and extrinsic calibration. For example, the calibration methods used for LiDAR-camera fusion often require manual operation and auxiliary calibration targets. Implicit neural representations (INRs) have been developed for 3D scenes, and the volume density distribution involved in an INR unifies the scene information obtained by different types of sensors. Therefore, we propose implicit neural fusion (INF) for LiDAR and camera. INF first trains a neural density field of the target scene using LiDAR frames. Then, a separate neural color field is trained using camera images and the trained neural density field. Along with the training process, INF both estimates LiDAR poses and optimizes extrinsic parameters. Our experiments demonstrate the high accuracy and stable performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2308.14414",
    "authors": [
      "Shuyi Zhou",
      "Shuxiang Xie",
      "Ryoichi Ishikawa",
      "Ken Sakurada",
      "Masaki Onishi",
      "Takeshi Oishi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14415",
    "title": "Eleven Years of Gender Data Visualization: A Step Towards More Inclusive  Gender Representation",
    "abstract": "We present an analysis of the representation of gender as a data dimension in data visualizations and propose a set of considerations around visual variables and annotations for gender-related data. Gender is a common demographic dimension of data collected from study or survey participants, passengers, or customers, as well as across academic studies, especially in certain disciplines like sociology. Our work contributes to multiple ongoing discussions on the ethical implications of data visualizations. By choosing specific data, visual variables, and text labels, visualization designers may, inadvertently or not, perpetuate stereotypes and biases. Here, our goal is to start an evolving discussion on how to represent data on gender in data visualizations and raise awareness of the subtleties of choosing visual variables and words in gender visualizations. In order to ground this discussion, we collected and coded gender visualizations and their captions from five different scientific communities (Biology, Politics, Social Studies, Visualisation, and Human-Computer Interaction), in addition to images from Tableau Public and the Information Is Beautiful awards showcase. Overall we found that representation types are community-specific, color hue is the dominant visual channel for gender data, and nonconforming gender is under-represented. We end our paper with a discussion of considerations for gender visualization derived from our coding and the literature and recommendations for large data collection bodies. A free copy of this paper and all supplemental materials are available at https://osf.io/v9ams/ ",
    "url": "https://arxiv.org/abs/2308.14415",
    "authors": [
      "Florent Cabric",
      "Margr\u00e9t Vilborg Bjarnad\u00f3ttir",
      "Meng Ling",
      "Gu\u00f0bj\u00f6rg Linda Rafnsd\u00f3ttir",
      "Petra Isenberg"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.14422",
    "title": "Complex coalitions: political alliances across relational contexts",
    "abstract": "Coalitions are central to politics, including government formation, international relations, and public policy. Coalitions emerge when actors engage one another across multiple relational contexts, but existing literature often approaches coalitions in singular contexts. We introduce complex coalitions, a theoretical-methodological framework that emphasises the relevance of multiple contexts and cross-context dependencies in coalition politics. We also implement tools to statistically infer such coalition structures using multilayer networks. To demonstrate the usefulness of our approach, we compare coalitions among Finnish organisations engaging in climate politics across three con-texts: resource coordination, legacy media discourse, and social media communication. We show that considering coalitions as complex and accounting for cross-context dependencies improves the empirical validity of coalition studies. In our case study, the three contexts represent complementary, but not congruent, channels for enacting coalitions. In conclusion, we argue that the complex coalitions approach is useful for advancing understanding of coalitions in different political realms. ",
    "url": "https://arxiv.org/abs/2308.14422",
    "authors": [
      "Arttu Malkam\u00e4ki",
      "Ted Hsuan Yun Chen",
      "Antti Gronow",
      "Mikko Kivel\u00e4",
      "Juho Vesa",
      "Tuomas Yl\u00e4-Anttila"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14461",
    "title": "Spatio-Temporal Analysis of Patient-Derived Organoid Videos Using Deep  Learning for the Prediction of Drug Efficacy",
    "abstract": "Over the last ten years, Patient-Derived Organoids (PDOs) emerged as the most reliable technology to generate ex-vivo tumor avatars. PDOs retain the main characteristics of their original tumor, making them a system of choice for pre-clinical and clinical studies. In particular, PDOs are attracting interest in the field of Functional Precision Medicine (FPM), which is based upon an ex-vivo drug test in which living tumor cells (such as PDOs) from a specific patient are exposed to a panel of anti-cancer drugs. Currently, the Adenosine Triphosphate (ATP) based cell viability assay is the gold standard test to assess the sensitivity of PDOs to drugs. The readout is measured at the end of the assay from a global PDO population and therefore does not capture single PDO responses and does not provide time resolution of drug effect. To this end, in this study, we explore for the first time the use of powerful large foundation models for the automatic processing of PDO data. In particular, we propose a novel imaging-based high-throughput screening method to assess real-time drug efficacy from a time-lapse microscopy video of PDOs. The recently proposed SAM algorithm for segmentation and DINOv2 model are adapted in a comprehensive pipeline for processing PDO microscopy frames. Moreover, an attention mechanism is proposed for fusing temporal and spatial features in a multiple instance learning setting to predict ATP. We report better results than other non-time-resolved methods, indicating that the temporality of data is an important factor for the prediction of ATP. Extensive ablations shed light on optimizing the experimental setting and automating the prediction both in real-time and for forecasting. ",
    "url": "https://arxiv.org/abs/2308.14461",
    "authors": [
      "Leo Fillioux",
      "Emilie Gontran",
      "J\u00e9r\u00f4me Cartry",
      "Jacques RR Mathieu",
      "Sabrina Bedja",
      "Alice Boil\u00e8ve",
      "Paul-Henry Courn\u00e8de",
      "Fanny Jaulin",
      "Stergios Christodoulidis",
      "Maria Vakalopoulou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14466",
    "title": "Improving the performance of object detection by preserving label  distribution",
    "abstract": "Object detection is a task that performs position identification and label classification of objects in images or videos. The information obtained through this process plays an essential role in various tasks in the field of computer vision. In object detection, the data utilized for training and validation typically originate from public datasets that are well-balanced in terms of the number of objects ascribed to each class in an image. However, in real-world scenarios, handling datasets with much greater class imbalance, i.e., very different numbers of objects for each class , is much more common, and this imbalance may reduce the performance of object detection when predicting unseen test images. In our study, thus, we propose a method that evenly distributes the classes in an image for training and validation, solving the class imbalance problem in object detection. Our proposed method aims to maintain a uniform class distribution through multi-label stratification. We tested our proposed method not only on public datasets that typically exhibit balanced class distribution but also on custom datasets that may have imbalanced class distribution. We found that our proposed method was more effective on datasets containing severe imbalance and less data. Our findings indicate that the proposed method can be effectively used on datasets with substantially imbalanced class distribution. ",
    "url": "https://arxiv.org/abs/2308.14466",
    "authors": [
      "Heewon Lee",
      "Sangtae Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14481",
    "title": "Group Regression for Query Based Object Detection and Tracking",
    "abstract": "Group regression is commonly used in 3D object detection to predict box parameters of similar classes in a joint head, aiming to benefit from similarities while separating highly dissimilar classes. For query-based perception methods, this has, so far, not been feasible. We close this gap and present a method to incorporate multi-class group regression, especially designed for the 3D domain in the context of autonomous driving, into existing attention and query-based perception approaches. We enhance a transformer based joint object detection and tracking model with this approach, and thoroughly evaluate its behavior and performance. For group regression, the classes of the nuScenes dataset are divided into six groups of similar shape and prevalence, each being regressed by a dedicated head. We show that the proposed method is applicable to many existing transformer based perception approaches and can bring potential benefits. The behavior of query group regression is thoroughly analyzed in comparison to a unified regression head, e.g. in terms of class-switching behavior and distribution of the output parameters. The proposed method offers many possibilities for further research, such as in the direction of deep multi-hypotheses tracking. ",
    "url": "https://arxiv.org/abs/2308.14481",
    "authors": [
      "Felicia Ruppel",
      "Florian Faion",
      "Claudius Gl\u00e4ser",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14484",
    "title": "Multimodal Detection of Social Spambots in Twitter using Transformers",
    "abstract": "Although not all bots are malicious, the vast majority of them are responsible for spreading misinformation and manipulating the public opinion about several issues, i.e., elections and many more. Therefore, the early detection of social spambots is crucial. Although there have been proposed methods for detecting bots in social media, there are still substantial limitations. For instance, existing research initiatives still extract a large number of features and train traditional machine learning algorithms or use GloVe embeddings and train LSTMs. However, feature extraction is a tedious procedure demanding domain expertise. Also, language models based on transformers have been proved to be better than LSTMs. Other approaches create large graphs and train graph neural networks requiring in this way many hours for training and access to computational resources. To tackle these limitations, this is the first study employing only the user description field and images of three channels denoting the type and content of tweets posted by the users. Firstly, we create digital DNA sequences, transform them to 3d images, and apply pretrained models of the vision domain, including EfficientNet, AlexNet, VGG16, etc. Next, we propose a multimodal approach, where we use TwHIN-BERT for getting the textual representation of the user description field and employ VGG16 for acquiring the visual representation for the image modality. We propose three different fusion methods, namely concatenation, gated multimodal unit, and crossmodal attention, for fusing the different modalities and compare their performances. Extensive experiments conducted on the Cresci '17 dataset demonstrate valuable advantages of our introduced approaches over state-of-the-art ones reaching Accuracy up to 99.98%. ",
    "url": "https://arxiv.org/abs/2308.14484",
    "authors": [
      "Loukas Ilias",
      "Ioannis Michail Kazelidis",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.14486",
    "title": "Rebalancing Social Feed to Minimize Polarization and Disagreement",
    "abstract": "Social media have great potential for enabling public discourse on important societal issues. However, adverse effects, such as polarization and echo chambers, greatly impact the benefits of social media and call for algorithms that mitigate these effects. In this paper, we propose a novel problem formulation aimed at slightly nudging users' social feeds in order to strike a balance between relevance and diversity, thus mitigating the emergence of polarization, without lowering the quality of the feed. Our approach is based on re-weighting the relative importance of the accounts that a user follows, so as to calibrate the frequency with which the content produced by various accounts is shown to the user. We analyze the convexity properties of the problem, demonstrating the non-matrix convexity of the objective function and the convexity of the feasible set. To efficiently address the problem, we develop a scalable algorithm based on projected gradient descent. We also prove that our problem statement is a proper generalization of the undirected-case problem so that our method can also be adopted for undirected social networks. As a baseline for comparison in the undirected case, we develop a semidefinite programming approach, which provides the optimal solution. Through extensive experiments on synthetic and real-world datasets, we validate the effectiveness of our approach, which outperforms non-trivial baselines, underscoring its ability to foster healthier and more cohesive online communities. ",
    "url": "https://arxiv.org/abs/2308.14486",
    "authors": [
      "Federico Cinus",
      "Aristides Gionis",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14491",
    "title": "Closeness of Some Line Graphs",
    "abstract": "Closeness is an important characteristic of networks. In this article we will calculate the closeness of line graphs of some basic graphs and the closeness of line graphs of connected by a bridge two basic graphs. ",
    "url": "https://arxiv.org/abs/2308.14491",
    "authors": [
      "Chavdar Dangalchev"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2308.14499",
    "title": "Efficient and Accurate Tree Detection from 3D Point Clouds through Paid  Crowdsourcing",
    "abstract": "Accurate tree detection is of growing importance in applications such as urban planning, forest inventory, and environmental monitoring. In this article, we present an approach to creating tree maps by annotating them in 3D point clouds. Point cloud representations allow the precise identification of tree positions, particularly stem locations, and their heights. Our method leverages human computational power through paid crowdsourcing, employing a web tool designed to enable even non-experts to effectively tackle the task. The primary focus of this paper is to discuss the web tool's development and strategies to ensure high-quality tree annotations despite encountering noise in the crowdsourced data. Following our methodology, we achieve quality measures surpassing 90% for various challenging test sets of diverse complexities. We emphasize that our tree map creation process, including initial point cloud collection, can be completed within 1-2 days. ",
    "url": "https://arxiv.org/abs/2308.14499",
    "authors": [
      "Michael K\u00f6lle",
      "Volker Walter",
      "Ivan Shiller",
      "Uwe Soergel"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.14516",
    "title": "Prediction of Tourism Flow with Sparse Geolocation Data",
    "abstract": "Modern tourism in the 21st century is facing numerous challenges. Among these the rapidly growing number of tourists visiting space-limited regions like historical cities, museums and bottlenecks such as bridges is one of the biggest. In this context, a proper and accurate prediction of tourism volume and tourism flow within a certain area is important and critical for visitor management tasks such as sustainable treatment of the environment and prevention of overcrowding. Static flow control methods like conventional low-level controllers or limiting access to overcrowded venues could not solve the problem yet. In this paper, we empirically evaluate the performance of state-of-the-art deep-learning methods such as RNNs, GNNs, and Transformers as well as the classic statistical ARIMA method. Granular limited data supplied by a tourism region is extended by exogenous data such as geolocation trajectories of individual tourists, weather and holidays. In the field of visitor flow prediction with sparse data, we are thereby capable of increasing the accuracy of our predictions, incorporating modern input feature handling as well as mapping geolocation data on top of discrete POI data. ",
    "url": "https://arxiv.org/abs/2308.14516",
    "authors": [
      "Julian Lemmel",
      "Zahra Babaiee",
      "Marvin Kleinlehner",
      "Ivan Majic",
      "Philipp Neubauer",
      "Johannes Scholz",
      "Radu Grosu",
      "Sophie A. Neubauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2308.14522",
    "title": "Large Graph Models: A Perspective",
    "abstract": "Large models have emerged as the most recent groundbreaking achievements in artificial intelligence, and particularly machine learning. However, when it comes to graphs, large models have not achieved the same level of success as in other fields, such as natural language processing and computer vision. In order to promote applying large models for graphs forward, we present a perspective paper to discuss the challenges and opportunities associated with developing large graph models. First, we discuss the desired characteristics of large graph models. Then, we present detailed discussions from three key perspectives: representation basis, graph data, and graph models. In each category, we provide a brief overview of recent advances and highlight the remaining challenges together with our visions. Finally, we discuss valuable applications of large graph models. We believe this perspective paper is able to encourage further investigations into large graph models, ultimately pushing us one step closer towards artificial general intelligence (AGI). ",
    "url": "https://arxiv.org/abs/2308.14522",
    "authors": [
      "Ziwei Zhang",
      "Haoyang Li",
      "Zeyang Zhang",
      "Yijian Qin",
      "Xin Wang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14523",
    "title": "Deep Reinforcement Learning for Uplink Scheduling in NOMA-URLLC Networks",
    "abstract": "This article addresses the problem of Ultra Reliable Low Latency Communications (URLLC) in wireless networks, a framework with particularly stringent constraints imposed by many Internet of Things (IoT) applications from diverse sectors. We propose a novel Deep Reinforcement Learning (DRL) scheduling algorithm, named NOMA-PPO, to solve the Non-Orthogonal Multiple Access (NOMA) uplink URLLC scheduling problem involving strict deadlines. The challenge of addressing uplink URLLC requirements in NOMA systems is related to the combinatorial complexity of the action space due to the possibility to schedule multiple devices, and to the partial observability constraint that we impose to our algorithm in order to meet the IoT communication constraints and be scalable. Our approach involves 1) formulating the NOMA-URLLC problem as a Partially Observable Markov Decision Process (POMDP) and the introduction of an agent state, serving as a sufficient statistic of past observations and actions, enabling a transformation of the POMDP into a Markov Decision Process (MDP); 2) adapting the Proximal Policy Optimization (PPO) algorithm to handle the combinatorial action space; 3) incorporating prior knowledge into the learning agent with the introduction of a Bayesian policy. Numerical results reveal that not only does our approach outperform traditional multiple access protocols and DRL benchmarks on 3GPP scenarios, but also proves to be robust under various channel and traffic configurations, efficiently exploiting inherent time correlations. ",
    "url": "https://arxiv.org/abs/2308.14523",
    "authors": [
      "Beno\u00eet-Marie Robaglia",
      "Marceau Coupechoux",
      "Dimitrios Tsilimantos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14537",
    "title": "Solving parametric elliptic interface problems via interfaced operator  network",
    "abstract": "Learning operator mapping between infinite-dimensional Banach spaces via neural networks has attracted a considerable amount of attention in recent years. In this work, we propose an interfaced operator network (IONet) to solve parametric elliptic interface PDEs, where different coefficients, source terms and boundary conditions are considered as input features. To capture the discontinuities of both input functions and output solutions across the interface, IONet divides the entire domain into several separate sub-domains according to the interface, and leverages multiple branch networks and truck networks. Each branch network extracts latent representations of input functions at a fixed number of sensors on a specific sub-domain, and each truck network is responsible for output solutions on one sub-domain. In addition, tailored physics-informed loss of IONet is proposed to ensure physical consistency, which greatly reduces the requirement for training datasets and makes IONet effective without any paired input-output observations in the interior of the computational domain. Extensive numerical studies show that IONet outperforms existing state-of-the-art deep operator networks in terms of accuracy, efficiency, and versatility. ",
    "url": "https://arxiv.org/abs/2308.14537",
    "authors": [
      "Sidi Wu",
      "Aiqing Zhu",
      "Yifa Tang",
      "Benzhuo Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.14541",
    "title": "Multilayer Multiset Neuronal Networks -- MMNNs",
    "abstract": "The coincidence similarity index, based on a combination of the Jaccard and overlap similarity indices, has noticeable properties in comparing and classifying data, including enhanced selectivity and sensitivity, intrinsic normalization, and robustness to data perturbations and outliers. These features allow multiset neurons, which are based on the coincidence similarity operation, to perform effective pattern recognition applications, including the challenging task of image segmentation. A few prototype points have been used in previous related approaches to represent each pattern to be identified, each of them being associated with respective multiset neurons. The segmentation of the regions can then proceed by taking into account the outputs of these neurons. The present work describes multilayer multiset neuronal networks incorporating two or more layers of coincidence similarity neurons. In addition, as a means to improve performance, this work also explores the utilization of counter-prototype points, which are assigned to the image regions to be avoided. This approach is shown to allow effective segmentation of complex regions despite considering only one prototype and one counter-prototype point. As reported here, the balanced accuracy landscapes to be optimized in order to identify the weight of the neurons in subsequent layers have been found to be relatively smooth, while typically involving more than one attraction basin. The use of a simple gradient-based optimization methodology has been demonstrated to effectively train the considered neural networks with several architectures, at least for the given data type, configuration of parameters, and network architecture. ",
    "url": "https://arxiv.org/abs/2308.14541",
    "authors": [
      "Alexandre Benatti",
      "Luciano da Fontoura Costa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.14551",
    "title": "Face Presentation Attack Detection by Excavating Causal Clues and  Adapting Embedding Statistics",
    "abstract": "Recent face presentation attack detection (PAD) leverages domain adaptation (DA) and domain generalization (DG) techniques to address performance degradation on unknown domains. However, DA-based PAD methods require access to unlabeled target data, while most DG-based PAD solutions rely on a priori, i.e., known domain labels. Moreover, most DA-/DG-based methods are computationally intensive, demanding complex model architectures and/or multi-stage training processes. This paper proposes to model face PAD as a compound DG task from a causal perspective, linking it to model optimization. We excavate the causal factors hidden in the high-level representation via counterfactual intervention. Moreover, we introduce a class-guided MixStyle to enrich feature-level data distribution within classes instead of focusing on domain information. Both class-guided MixStyle and counterfactual intervention components introduce no extra trainable parameters and negligible computational resources. Extensive cross-dataset and analytic experiments demonstrate the effectiveness and efficiency of our method compared to state-of-the-art PADs. The implementation and the trained weights are publicly available. ",
    "url": "https://arxiv.org/abs/2308.14551",
    "authors": [
      "Meiling Fang",
      "Naser Damer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14555",
    "title": "Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data  Sequences",
    "abstract": "Mathematical methods are developed to characterize the asymptotics of recurrent neural networks (RNN) as the number of hidden units, data samples in the sequence, hidden state updates, and training steps simultaneously grow to infinity. In the case of an RNN with a simplified weight matrix, we prove the convergence of the RNN to the solution of an infinite-dimensional ODE coupled with the fixed point of a random algebraic equation. The analysis requires addressing several challenges which are unique to RNNs. In typical mean-field applications (e.g., feedforward neural networks), discrete updates are of magnitude $\\mathcal{O}(\\frac{1}{N})$ and the number of updates is $\\mathcal{O}(N)$. Therefore, the system can be represented as an Euler approximation of an appropriate ODE/PDE, which it will converge to as $N \\rightarrow \\infty$. However, the RNN hidden layer updates are $\\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization of an ODE/PDE and standard mean-field techniques cannot be applied. Instead, we develop a fixed point analysis for the evolution of the RNN memory states, with convergence estimates in terms of the number of update steps and the number of hidden units. The RNN hidden layer is studied as a function in a Sobolev space, whose evolution is governed by the data sequence (a Markov chain), the parameter updates, and its dependence on the RNN hidden layer at the previous time step. Due to the strong correlation between updates, a Poisson equation must be used to bound the fluctuations of the RNN around its limit equation. These mathematical methods give rise to the neural tangent kernel (NTK) limits for RNNs trained on data sequences as the number of data samples and size of the neural network grow to infinity. ",
    "url": "https://arxiv.org/abs/2308.14555",
    "authors": [
      "Samuel Chun-Hei Lam",
      "Justin Sirignano",
      "Konstantinos Spiliopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.14570",
    "title": "SAAN: Similarity-aware attention flow network for change detection with  VHR remote sensing images",
    "abstract": "Change detection (CD) is a fundamental and important task for monitoring the land surface dynamics in the earth observation field. Existing deep learning-based CD methods typically extract bi-temporal image features using a weight-sharing Siamese encoder network and identify change regions using a decoder network. These CD methods, however, still perform far from satisfactorily as we observe that 1) deep encoder layers focus on irrelevant background regions and 2) the models' confidence in the change regions is inconsistent at different decoder stages. The first problem is because deep encoder layers cannot effectively learn from imbalanced change categories using the sole output supervision, while the second problem is attributed to the lack of explicit semantic consistency preservation. To address these issues, we design a novel similarity-aware attention flow network (SAAN). SAAN incorporates a similarity-guided attention flow module with deeply supervised similarity optimization to achieve effective change detection. Specifically, we counter the first issue by explicitly guiding deep encoder layers to discover semantic relations from bi-temporal input images using deeply supervised similarity optimization. The extracted features are optimized to be semantically similar in the unchanged regions and dissimilar in the changing regions. The second drawback can be alleviated by the proposed similarity-guided attention flow module, which incorporates similarity-guided attention modules and attention flow mechanisms to guide the model to focus on discriminative channels and regions. We evaluated the effectiveness and generalization ability of the proposed method by conducting experiments on a wide range of CD tasks. The experimental results demonstrate that our method achieves excellent performance on several CD tasks, with discriminative features and semantic consistency preserved. ",
    "url": "https://arxiv.org/abs/2308.14570",
    "authors": [
      "Haonan Guo",
      "Xin Su",
      "Chen Wu",
      "Bo Du",
      "Liangpei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14593",
    "title": "Skip, Skip, Skip, Accept!!!: A Study on the Usability of Smartphone  Manufacturer Provided Default Features and User Privacy",
    "abstract": "Smartphone manufacturer provided default features (e.g., default location services, iCloud, Google Assistant, ad tracking) enhance the usability and extend the functionality of these devices. Prior studies have highlighted smartphone vulnerabilities and how users' data can be harvested without their knowledge. However, little is known about manufacturer provided default features in this regard -- their usability concerning configuring them during usage, and how users perceive them with regards to privacy. To bridge this gap, we conducted a task-based study with 27 Android and iOS smartphone users in order to learn about their perceptions, concerns and practices, and to understand the usability of these features with regards to privacy. We explored the following: users' awareness of these features, why and when do they change the settings of these features, the challenges they face while configuring these features, and finally the mitigation strategies they adopt. Our findings reveal that users of both platforms have limited awareness of these features and their privacy implications. Awareness of these features does not imply that a user can easily locate and adjust them when needed. Furthermore, users attribute their failure to configure default features to hidden controls and insufficient knowledge on how to configure them. To cope with difficulties of finding controls, users employ various coping strategies, some of which are platform specific but most often applicable to both platforms. However, some of these coping strategies leave users vulnerable. ",
    "url": "https://arxiv.org/abs/2308.14593",
    "authors": [
      "Kopo M. Ramokapane",
      "Anthony C. Mazeli",
      "Awais Rashid"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.14595",
    "title": "Neural Network Training Strategy to Enhance Anomaly Detection  Performance: A Perspective on Reconstruction Loss Amplification",
    "abstract": "Unsupervised anomaly detection (UAD) is a widely adopted approach in industry due to rare anomaly occurrences and data imbalance. A desirable characteristic of an UAD model is contained generalization ability which excels in the reconstruction of seen normal patterns but struggles with unseen anomalies. Recent studies have pursued to contain the generalization capability of their UAD models in reconstruction from different perspectives, such as design of neural network (NN) structure and training strategy. In contrast, we note that containing of generalization ability in reconstruction can also be obtained simply from steep-shaped loss landscape. Motivated by this, we propose a loss landscape sharpening method by amplifying the reconstruction loss, dubbed Loss AMPlification (LAMP). LAMP deforms the loss landscape into a steep shape so the reconstruction error on unseen anomalies becomes greater. Accordingly, the anomaly detection performance is improved without any change of the NN architecture. Our findings suggest that LAMP can be easily applied to any reconstruction error metrics in UAD settings where the reconstruction model is trained with anomaly-free samples only. ",
    "url": "https://arxiv.org/abs/2308.14595",
    "authors": [
      "YeongHyeon Park",
      "Sungho Kang",
      "Myung Jin Kim",
      "Hyeonho Jeong",
      "Hyunkyu Park",
      "Hyeong Seok Kim",
      "Juneho Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.14597",
    "title": "Adversarial Attacks on Foundational Vision Models",
    "abstract": "Rapid progress is being made in developing large, pretrained, task-agnostic foundational vision models such as CLIP, ALIGN, DINOv2, etc. In fact, we are approaching the point where these models do not have to be finetuned downstream, and can simply be used in zero-shot or with a lightweight probing head. Critically, given the complexity of working at this scale, there is a bottleneck where relatively few organizations in the world are executing the training then sharing the models on centralized platforms such as HuggingFace and torch.hub. The goal of this work is to identify several key adversarial vulnerabilities of these models in an effort to make future designs more robust. Intuitively, our attacks manipulate deep feature representations to fool an out-of-distribution (OOD) detector which will be required when using these open-world-aware models to solve closed-set downstream tasks. Our methods reliably make in-distribution (ID) images (w.r.t. a downstream task) be predicted as OOD and vice versa while existing in extremely low-knowledge-assumption threat models. We show our attacks to be potent in whitebox and blackbox settings, as well as when transferred across foundational model types (e.g., attack DINOv2 with CLIP)! This work is only just the beginning of a long journey towards adversarially robust foundational vision models. ",
    "url": "https://arxiv.org/abs/2308.14597",
    "authors": [
      "Nathan Inkawhich",
      "Gwendolyn McDonald",
      "Ryan Luley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14606",
    "title": "On the Tradeoff between Privacy Preservation and Byzantine-Robustness in  Decentralized Learning",
    "abstract": "This paper jointly considers privacy preservation and Byzantine-robustness in decentralized learning. In a decentralized network, honest-but-curious agents faithfully follow the prescribed algorithm, but expect to infer their neighbors' private data from messages received during the learning process, while dishonest-and-Byzantine agents disobey the prescribed algorithm, and deliberately disseminate wrong messages to their neighbors so as to bias the learning process. For this novel setting, we investigate a generic privacy-preserving and Byzantine-robust decentralized stochastic gradient descent (SGD) framework, in which Gaussian noise is injected to preserve privacy and robust aggregation rules are adopted to counteract Byzantine attacks. We analyze its learning error and privacy guarantee, discovering an essential tradeoff between privacy preservation and Byzantine-robustness in decentralized learning -- the learning error caused by defending against Byzantine attacks is exacerbated by the Gaussian noise added to preserve privacy. Numerical experiments are conducted and corroborate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2308.14606",
    "authors": [
      "Haoxiang Ye",
      "Heng Zhu",
      "Qing Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.14613",
    "title": "MS-Net: A Multi-modal Self-supervised Network for Fine-Grained  Classification of Aircraft in SAR Images",
    "abstract": "Synthetic aperture radar (SAR) imaging technology is commonly used to provide 24-hour all-weather earth observation. However, it still has some drawbacks in SAR target classification, especially in fine-grained classification of aircraft: aircrafts in SAR images have large intra-class diversity and inter-class similarity; the number of effective samples is insufficient and it's hard to annotate. To address these issues, this article proposes a novel multi-modal self-supervised network (MS-Net) for fine-grained classification of aircraft. Firstly, in order to entirely exploit the potential of multi-modal information, a two-sided path feature extraction network (TSFE-N) is constructed to enhance the image feature of the target and obtain the domain knowledge feature of text mode. Secondly, a contrastive self-supervised learning (CSSL) framework is employed to effectively learn useful label-independent feature from unbalanced data, a similarity per-ception loss (SPloss) is proposed to avoid network overfitting. Finally, TSFE-N is used as the encoder of CSSL to obtain the classification results. Through a large number of experiments, our MS-Net can effectively reduce the difficulty of classifying similar types of aircrafts. In the case of no label, the proposed algorithm achieves an accuracy of 88.46% for 17 types of air-craft classification task, which has pioneering significance in the field of fine-grained classification of aircraft in SAR images. ",
    "url": "https://arxiv.org/abs/2308.14613",
    "authors": [
      "Bingying Yue",
      "Jianhao Li",
      "Hao Shi",
      "Yupei Wang",
      "Honghu Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14627",
    "title": "Zip to Zip-it: Compression to Achieve Local Differential Privacy",
    "abstract": "Local differential privacy techniques for numerical data typically transform a dataset to ensure a bound on the likelihood that, given a query, a malicious user could infer information on the original samples. Queries are often solely based on users and their requirements, limiting the design of the perturbation to processes that, while privatizing the results, do not jeopardize their usefulness. In this paper, we propose a privatization technique called Zeal, where perturbator and aggregator are designed as a unit, resulting in a locally differentially private mechanism that, by-design, improves the compressibility of the perturbed dataset compared to the original, saves on transmitted bits for data collection and protects against a privacy vulnerabilities due to floating point arithmetic that affect other state-of-the-art schemes. We prove that the utility error on querying the average is invariant to the bias introduced by Zeal in a wide range of conditions, and that under the same circumstances, Zeal also guarantee protection against the aforementioned vulnerability. Our numerical results show up to 94% improvements in compression and up to 95% more efficient data transmissions, while keeping utility errors within 2%. ",
    "url": "https://arxiv.org/abs/2308.14627",
    "authors": [
      "Francesco Taurone",
      "Daniel Lucani",
      "Qi Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.14637",
    "title": "Joint Active User Detection, Channel Estimation, and Data Detection for  Massive Grant-Free Transmission in Cell-Free Systems",
    "abstract": "Cell-free communication has the potential to significantly improve grant-free transmission in massive machine-type communication, wherein multiple access points jointly serve a large number of user equipments to improve coverage and spectral efficiency. In this paper, we propose a novel framework for joint active user detection (AUD), channel estimation (CE), and data detection (DD) for massive grant-free transmission in cell-free systems. We formulate an optimization problem for joint AUD, CE, and DD by considering both the sparsity of the data matrix, which arises from intermittent user activity, and the sparsity of the effective channel matrix, which arises from intermittent user activity and large-scale fading. We approximately solve this optimization problem with a box-constrained forward-backward splitting algorithm, which significantly improves AUD, CE, and DD performance. We demonstrate the effectiveness of the proposed framework through simulation experiments. ",
    "url": "https://arxiv.org/abs/2308.14637",
    "authors": [
      "Gangle Sun",
      "Mengyao Cao",
      "Wenjin Wang",
      "Wei Xu",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.14649",
    "title": "Composition in Differential Privacy for General Granularity Notions  (Long Version)",
    "abstract": "The composition theorems of differential privacy (DP) allow data curators to combine different algorithms to obtain a new algorithm that continues to satisfy DP. However, new granularity notions (i.e., neighborhood definitions), data domains, and composition settings have appeared in the literature that the classical composition theorems do not cover. For instance, the parallel composition theorem does not apply to general granularity notions. This complicates the opportunity of composing DP mechanisms in new settings and obtaining accurate estimates of the incurred privacy loss after composition. To overcome these limitations, we study the composability of DP in a general framework and for any kind of data domain or neighborhood definition. We give a general composition theorem in both independent and adaptive versions and we provide analogous composition results for approximate, zero-concentrated, and Gaussian DP. Besides, we study the hypothesis needed to obtain the best composition bounds. Our theorems cover both parallel and sequential composition settings. Importantly, they also cover every setting in between, allowing us to compute the final privacy loss of a composition with greatly improved accuracy. ",
    "url": "https://arxiv.org/abs/2308.14649",
    "authors": [
      "Patricia Guerra-Balboa",
      "\u00c0lex Miranda-Pascual",
      "Javier Parra-Arnau",
      "Thorsten Strufe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.14654",
    "title": "Joint Multiple Intent Detection and Slot Filling with Supervised  Contrastive Learning and Self-Distillation",
    "abstract": "Multiple intent detection and slot filling are two fundamental and crucial tasks in spoken language understanding. Motivated by the fact that the two tasks are closely related, joint models that can detect intents and extract slots simultaneously are preferred to individual models that perform each task independently. The accuracy of a joint model depends heavily on the ability of the model to transfer information between the two tasks so that the result of one task can correct the result of the other. In addition, since a joint model has multiple outputs, how to train the model effectively is also challenging. In this paper, we present a method for multiple intent detection and slot filling by addressing these challenges. First, we propose a bidirectional joint model that explicitly employs intent information to recognize slots and slot features to detect intents. Second, we introduce a novel method for training the proposed joint model using supervised contrastive learning and self-distillation. Experimental results on two benchmark datasets MixATIS and MixSNIPS show that our method outperforms state-of-the-art models in both tasks. The results also demonstrate the contributions of both bidirectional design and the training method to the accuracy improvement. Our source code is available at https://github.com/anhtunguyen98/BiSLU ",
    "url": "https://arxiv.org/abs/2308.14654",
    "authors": [
      "Nguyen Anh Tu",
      "Hoang Thi Thu Uyen",
      "Tu Minh Phuong",
      "Ngo Xuan Bach"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.14657",
    "title": "DeepHealthNet: Adolescent Obesity Prediction System Based on a Deep  Learning Framework",
    "abstract": "Childhood and adolescent obesity rates are a global concern because obesity is associated with chronic diseases and long-term health risks. Artificial intelligence technology has emerged as a promising solution to accurately predict obesity rates and provide personalized feedback to adolescents. This study emphasizes the importance of early identification and prevention of obesity-related health issues. Factors such as height, weight, waist circumference, calorie intake, physical activity levels, and other relevant health information need to be considered for developing robust algorithms for obesity rate prediction and delivering personalized feedback. Hence, by collecting health datasets from 321 adolescents, we proposed an adolescent obesity prediction system that provides personalized predictions and assists individuals in making informed health decisions. Our proposed deep learning framework, DeepHealthNet, effectively trains the model using data augmentation techniques, even when daily health data are limited, resulting in improved prediction accuracy (acc: 0.8842). Additionally, the study revealed variations in the prediction of the obesity rate between boys (acc: 0.9320) and girls (acc: 0.9163), allowing the identification of disparities and the determination of the optimal time to provide feedback. The proposed system shows significant potential in effectively addressing childhood and adolescent obesity. ",
    "url": "https://arxiv.org/abs/2308.14657",
    "authors": [
      "Ji-Hoon Jeong",
      "In-Gyu Lee",
      "Sung-Kyung Kim",
      "Tae-Eui Kam",
      "Seong-Whan Lee",
      "Euijong Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.14658",
    "title": "Adversarial Predictions of Data Distributions Across Federated  Internet-of-Things Devices",
    "abstract": "Federated learning (FL) is increasingly becoming the default approach for training machine learning models across decentralized Internet-of-Things (IoT) devices. A key advantage of FL is that no raw data are communicated across the network, providing an immediate layer of privacy. Despite this, recent works have demonstrated that data reconstruction can be done with the locally trained model updates which are communicated across the network. However, many of these works have limitations with regard to how the gradients are computed in backpropagation. In this work, we demonstrate that the model weights shared in FL can expose revealing information about the local data distributions of IoT devices. This leakage could expose sensitive information to malicious actors in a distributed system. We further discuss results which show that injecting noise into model weights is ineffective at preventing data leakage without seriously harming the global model accuracy. ",
    "url": "https://arxiv.org/abs/2308.14658",
    "authors": [
      "Samir Rajani",
      "Dario Dematties",
      "Nathaniel Hudson",
      "Kyle Chard",
      "Nicola Ferrier",
      "Rajesh Sankaran",
      "Peter Beckman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.14659",
    "title": "RESTORE: Graph Embedding Assessment Through Reconstruction",
    "abstract": "Following the success of Word2Vec embeddings, graph embeddings (GEs) have gained substantial traction. GEs are commonly generated and evaluated extrinsically on downstream applications, but intrinsic evaluations of the original graph properties in terms of topological structure and semantic information have been lacking. Understanding these will help identify the deficiency of the various families of GE methods when vectorizing graphs in terms of preserving the relevant knowledge or learning incorrect knowledge. To address this, we propose RESTORE, a framework for intrinsic GEs assessment through graph reconstruction. We show that reconstructing the original graph from the underlying GEs yields insights into the relative amount of information preserved in a given vector form. We first introduce the graph reconstruction task. We generate GEs from three GE families based on factorization methods, random walks, and deep learning (with representative algorithms from each family) on the CommonSense Knowledge Graph (CSKG). We analyze their effectiveness in preserving the (a) topological structure of node-level graph reconstruction with an increasing number of hops and (b) semantic information on various word semantic and analogy tests. Our evaluations show deep learning-based GE algorithm (SDNE) is overall better at preserving (a) with a mean average precision (mAP) of 0.54 and 0.35 for 2 and 3-hop reconstruction respectively, while the factorization-based algorithm (HOPE) is better at encapsulating (b) with an average Euclidean distance of 0.14, 0.17, and 0.11 for 1, 2, and 3-hop reconstruction respectively. The modest performance of these GEs leaves room for further research avenues on better graph representation learning. ",
    "url": "https://arxiv.org/abs/2308.14659",
    "authors": [
      "Hong Yung Yip",
      "Chidaksh Ravuru",
      "Neelabha Banerjee",
      "Shashwat Jha",
      "Amit Sheth",
      "Aman Chadha",
      "Amitava Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14667",
    "title": "Neural Network-Based Histologic Remission Prediction In Ulcerative  Colitis",
    "abstract": "BACKGROUND & AIMS: Histological remission (HR) is advocated and considered as a new therapeutic target in ulcerative colitis (UC). Diagnosis of histologic remission currently relies on biopsy; during this process, patients are at risk for bleeding, infection, and post-biopsy fibrosis. In addition, histologic response scoring is complex and time-consuming, and there is heterogeneity among pathologists. Endocytoscopy (EC) is a novel ultra-high magnification endoscopic technique that can provide excellent in vivo assessment of glands. Based on the EC technique, we propose a neural network model that can assess histological disease activity in UC using EC images to address the above issues. The experiment results demonstrate that the proposed method can assist patients in precise treatment and prognostic assessment. METHODS: We construct a neural network model for UC evaluation. A total of 5105 images of 154 intestinal segments from 87 patients undergoing EC treatment at a center in China between March 2022 and March 2023 are scored according to the Geboes score. Subsequently, 103 intestinal segments are used as the training set, 16 intestinal segments are used as the validation set for neural network training, and the remaining 35 intestinal segments are used as the test set to measure the model performance together with the validation set. RESULTS: By treating HR as a negative category and histologic activity as a positive category, the proposed neural network model can achieve an accuracy of 0.9, a specificity of 0.95, a sensitivity of 0.75, and an area under the curve (AUC) of 0.81. CONCLUSION: We develop a specific neural network model that can distinguish histologic remission/activity in EC images of UC, which helps to accelerate clinical histological diagnosis. keywords: ulcerative colitis; Endocytoscopy; Geboes score; neural network. ",
    "url": "https://arxiv.org/abs/2308.14667",
    "authors": [
      "Yemin li",
      "Zhongcheng Liu",
      "Xiaoying Lou",
      "Mirigual Kurban",
      "Miao Li",
      "Jie Yang",
      "Kaiwei Che",
      "Jiankun Wang",
      "Max Q.-H Meng",
      "Yan Huang",
      "Qin Guo",
      "Pinjin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14687",
    "title": "MELT: Mining Effective Lightweight Transformations from Pull Requests",
    "abstract": "Software developers often struggle to update APIs, leading to manual, time-consuming, and error-prone processes. We introduce MELT, a new approach that generates lightweight API migration rules directly from pull requests in popular library repositories. Our key insight is that pull requests merged into open-source libraries are a rich source of information sufficient to mine API migration rules. By leveraging code examples mined from the library source and automatically generated code examples based on the pull requests, we infer transformation rules in \\comby, a language for structural code search and replace. Since inferred rules from single code examples may be too specific, we propose a generalization procedure to make the rules more applicable to client projects. MELT rules are syntax-driven, interpretable, and easily adaptable. Moreover, unlike previous work, our approach enables rule inference to seamlessly integrate into the library workflow, removing the need to wait for client code migrations. We evaluated MELT on pull requests from four popular libraries, successfully mining 461 migration rules from code examples in pull requests and 114 rules from auto-generated code examples. Our generalization procedure increases the number of matches for mined rules by 9x. We applied these rules to client projects and ran their tests, which led to an overall decrease in the number of warnings and fixing some test cases demonstrating MELT's effectiveness in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2308.14687",
    "authors": [
      "Daniel Ramos",
      "Hailie Mitchell",
      "In\u00eas Lynce",
      "Vasco Manquinho",
      "Ruben Martins",
      "Claire Le Goues"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14708",
    "title": "Heterogeneous Drone Small Cells: Optimal 3D Placement for Downlink Power  Efficiency and Rate Satisfaction",
    "abstract": "In this paper, we consider a heterogeneous repository of drone-enabled aerial base stations with varying transmit powers that provide downlink wireless coverage for ground users. One particular challenge is optimal selection and deployment of a subset of available drone base stations (DBSs) to satisfy the downlink data rate requirements while minimizing the overall power consumption. In order to address this challenge, we formulate an optimization problem to select the best subset of available DBSs so as to guarantee wireless coverage with some acceptable transmission rate in the downlink path. In addition to the selection of DBSs, we determine their 3D position so as to minimize their overall power consumption. Moreover, assuming that the DBSs operate in the same frequency band, we develop a novel and computationally efficient beamforming method to alleviate the inter-cell interference impact on the downlink. We propose a Kalai-Smorodinsky bargaining solution to determine the optimal beamforming strategy in the downlink path to compensate for the impairment caused by the interference. Simulation results demonstrate the effectiveness of the proposed solution and provide valuable insights into the performance of the heterogeneous drone-based small cell networks. ",
    "url": "https://arxiv.org/abs/2308.14708",
    "authors": [
      "Nima Namvar",
      "Fatemeh Afghah",
      "Ismail Guvenc"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.14711",
    "title": "Fast Feedforward Networks",
    "abstract": "We break the linear link between the layer size and its inference cost by introducing the fast feedforward (FFF) architecture, a logarithmic-time alternative to feedforward networks. We show that FFFs give comparable performance to feedforward networks at an exponential fraction of their inference cost, are quicker to deliver performance compared to mixture-of-expert networks, and can readily take the place of either in transformers. Pushing FFFs to the absolute limit, we train a vision transformer to perform single-neuron inferences at the cost of only 5.8% performance decrease against the full-width variant. Our implementation is available as a Python package; just use \"pip install fastfeedforward\". ",
    "url": "https://arxiv.org/abs/2308.14711",
    "authors": [
      "Peter Belcak",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2308.14714",
    "title": "A Stochastic Surveillance Stackelberg Game: Co-Optimizing Defense  Placement and Patrol Strategy",
    "abstract": "Stochastic patrol routing is known to be advantageous in adversarial settings; however, the optimal choice of stochastic routing strategy is dependent on a model of the adversary. Duan et al. formulated a Stackelberg game for the worst-case scenario, i.e., a surveillance agent confronted with an omniscient attacker [IEEE TCNS, 8(2), 769-80, 2021]. In this article, we extend their formulation to accommodate heterogeneous defenses at the various nodes of the graph. We derive an upper bound on the value of the game. We identify methods for computing effective patrol strategies for certain classes of graphs. Finally, we leverage the heterogeneous defense formulation to develop novel defense placement algorithms that complement the patrol strategies. ",
    "url": "https://arxiv.org/abs/2308.14714",
    "authors": [
      "Yohan John",
      "Gilberto Diaz-Garcia",
      "Xiaoming Duan",
      "Jason R. Marden",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.14727",
    "title": "Faster Min-Cost Flow on Bounded Treewidth Graphs",
    "abstract": "We present a $\\widetilde{O}(m\\sqrt{\\tau}+n\\tau)$ time algorithm for finding a minimum-cost flow in graphs with $n$ vertices and $m$ edges, given a tree decomposition of width $\\tau$ and polynomially bounded integer costs and capacities. This improves upon the current best algorithms for general linear programs bounded by treewidth which run in $\\widetilde{O}(m \\tau^{(\\omega+1)/2})$ time by [Dong-Lee-Ye,21] and [Gu-Song,22], where $\\omega \\approx 2.37$ is the matrix multiplication exponent. Our approach leverages recent advances in structured linear program solvers and robust interior point methods. As a corollary, for any graph $G$ with $n$ vertices, $m$ edges, and treewidth $\\tau$, we obtain a $\\widetilde{O}(\\tau^3 \\cdot m)$ time algorithm to compute a tree decomposition of $G$ with width $O(\\tau \\cdot \\log n)$. ",
    "url": "https://arxiv.org/abs/2308.14727",
    "authors": [
      "Sally Dong",
      "Guanghao Ye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.14731",
    "title": "Distilled GPT for Source Code Summarization",
    "abstract": "A code summary is a brief natural language description of source code. Summaries are usually only a single sentence long, and yet form the backbone of developer documentation. A short descriptions such as \"changes all visible polygons to the color blue\" can give a programmer a high-level idea of what code does without the effort of reading the code itself. Recently, products based on Large Language Models such as ChatGPT have demonstrated a strong ability to write these descriptions automatically. However, to use these tools, programmers must send their code to untrusted third parties for processing (e.g., via an API call). This loss of custody is not acceptable to many organizations. In this paper, we present an alternative: we train an open source model using sample output generated by GPT-3.5 in a process related to knowledge distillation. Our model is small enough (350m parameters) to be run on a single 16gb GPU, yet we show in our evaluation that it is large enough to mimic GPT-3.5 on this task. ",
    "url": "https://arxiv.org/abs/2308.14731",
    "authors": [
      "Chia-Yi Su",
      "Collin McMillan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13546",
    "title": "Functional Graph Contrastive Learning of Hyperscanning EEG Reveals  Emotional Contagion Evoked by Stereotype-Based Stressors",
    "abstract": "This study delves into the intricacies of emotional contagion and its impact on performance within dyadic interactions. Specifically, it focuses on the context of stereotype-based stress (SBS) during collaborative problem-solving tasks among female pairs. Through an exploration of emotional contagion, the research seeks to unveil its underlying mechanisms and effects. Leveraging EEG-based hyperscanning technology, the study introduces an innovative approach known as functional Graph Contrastive Learning (fGCL), which extracts subject-invariant representations of neural activity patterns. These representations are further subjected to analysis using the Dynamic Graph Classification (DGC) model, aimed at dissecting the process of emotional contagion. By scrutinizing brain synchronization and connectivity, the study reveals the intricate interplay between emotional contagion and cognitive functioning. The results underscore the substantial role of emotional contagion in shaping the trajectories of participants' performance during collaborative tasks in the presence of SBS conditions. Overall, this research contributes invaluable insights into the neural underpinnings of emotional contagion, thereby enriching our comprehension of the complexities underlying social interactions and emotional dynamics. ",
    "url": "https://arxiv.org/abs/2308.13546",
    "authors": [
      "Jingyun Huang",
      "Mengting Liu",
      "Chad E. Forbes"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13700",
    "title": "Multipartite Entanglement in Quantum Networks using Subgraph  Complementations",
    "abstract": "Quantum networks are important for quantum communication and consist of entangled states that are essential for many tasks such as quantum teleportation, quantum key distribution, quantum sensing and quantum error correction. Graph states are a specific class of multipartite entangled states that can be represented by graphs. We propose a novel approach for distributing graph states across a quantum network. We show that the distribution of graph states can be characterised by a system of subgraph complementations, which we also relate to the minimum rank of the underlying graph and the degree of entanglement quantified by the Schmidt-rank of the quantum state. We analyse resource usage for our algorithm and show it to match or be improved in the number of qubits, bits for classical communication and EPR pairs utilised, as compared to prior work. The number of local operations is efficient, and the resource consumption for our approach scales linearly in the number of vertices. This presents a quadratic improvement in completion time for several classes of graph states represented by dense graphs, and implies a potential for improved fidelity in the presence of noise. Common classes of graph states are classified along with the optimal time for their distribution using subgraph complementations. We also provide a framework to similarly find the optimal sequence of operations to distribute an arbitrary graph state, and prove upper bounds along with providing approximate greedy algorithms. ",
    "url": "https://arxiv.org/abs/2308.13700",
    "authors": [
      "Aniruddha Sen",
      "Kenneth Goodenough",
      "Don Towsley"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.13777",
    "title": "Self-Supervised Scalable Deep Compressed Sensing",
    "abstract": "Compressed sensing (CS) is a promising tool for reducing sampling costs. Current deep neural network (NN)-based CS methods face challenges in collecting labeled measurement-ground truth (GT) data and generalizing to real applications. This paper proposes a novel $\\mathbf{S}$elf-supervised s$\\mathbf{C}$alable deep CS method, comprising a $\\mathbf{L}$earning scheme called $\\mathbf{SCL}$ and a family of $\\mathbf{Net}$works named $\\mathbf{SCNet}$, which does not require GT and can handle arbitrary sampling ratios and matrices once trained on a partial measurement set. Our SCL contains a dual-domain loss and a four-stage recovery strategy. The former encourages a cross-consistency on two measurement parts and a sampling-reconstruction cycle-consistency regarding arbitrary ratios and matrices to maximize data/information utilization. The latter can progressively leverage common signal prior in external measurements and internal characteristics of test samples and learned NNs to improve accuracy. SCNet combines the explicit guidance from optimization algorithms with implicit regularization from advanced NN blocks to learn a collaborative signal representation. Our theoretical analyses and experiments on simulated and real captured data, covering 1-/2-/3-D natural and scientific signals, demonstrate the effectiveness, superior performance, flexibility, and generalization ability of our method over existing self-supervised methods and its significant potential in competing against state-of-the-art supervised methods. ",
    "url": "https://arxiv.org/abs/2308.13777",
    "authors": [
      "Bin Chen",
      "Xuanyu Zhang",
      "Shuai Liu",
      "Yongbing Zhang",
      "Jian Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13790",
    "title": "FFPN: Fourier Feature Pyramid Network for Ultrasound Image Segmentation",
    "abstract": "Ultrasound (US) image segmentation is an active research area that requires real-time and highly accurate analysis in many scenarios. The detect-to-segment (DTS) frameworks have been recently proposed to balance accuracy and efficiency. However, existing approaches may suffer from inadequate contour encoding or fail to effectively leverage the encoded results. In this paper, we introduce a novel Fourier-anchor-based DTS framework called Fourier Feature Pyramid Network (FFPN) to address the aforementioned issues. The contributions of this paper are two fold. First, the FFPN utilizes Fourier Descriptors to adequately encode contours. Specifically, it maps Fourier series with similar amplitudes and frequencies into the same layer of the feature map, thereby effectively utilizing the encoded Fourier information. Second, we propose a Contour Sampling Refinement (CSR) module based on the contour proposals and refined features produced by the FFPN. This module extracts rich features around the predicted contours to further capture detailed information and refine the contours. Extensive experimental results on three large and challenging datasets demonstrate that our method outperforms other DTS methods in terms of accuracy and efficiency. Furthermore, our framework can generalize well to other detection or segmentation tasks. ",
    "url": "https://arxiv.org/abs/2308.13790",
    "authors": [
      "Chaoyu Chen",
      "Xin Yang",
      "Rusi Chen",
      "Junxuan Yu",
      "Liwei Du",
      "Jian Wang",
      "Xindi Hu",
      "Yan Cao",
      "Yingying Liu",
      "Dong Ni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.13861",
    "title": "Bias in Unsupervised Anomaly Detection in Brain MRI",
    "abstract": "Unsupervised anomaly detection methods offer a promising and flexible alternative to supervised approaches, holding the potential to revolutionize medical scan analysis and enhance diagnostic performance. In the current landscape, it is commonly assumed that differences between a test case and the training distribution are attributed solely to pathological conditions, implying that any disparity indicates an anomaly. However, the presence of other potential sources of distributional shift, including scanner, age, sex, or race, is frequently overlooked. These shifts can significantly impact the accuracy of the anomaly detection task. Prominent instances of such failures have sparked concerns regarding the bias, credibility, and fairness of anomaly detection. This work presents a novel analysis of biases in unsupervised anomaly detection. By examining potential non-pathological distributional shifts between the training and testing distributions, we shed light on the extent of these biases and their influence on anomaly detection results. Moreover, this study examines the algorithmic limitations that arise due to biases, providing valuable insights into the challenges encountered by anomaly detection algorithms in accurately learning and capturing the entire range of variability present in the normative distribution. Through this analysis, we aim to enhance the understanding of these biases and pave the way for future improvements in the field. Here, we specifically investigate Alzheimer's disease detection from brain MR imaging as a case study, revealing significant biases related to sex, race, and scanner variations that substantially impact the results. These findings align with the broader goal of improving the reliability, fairness, and effectiveness of anomaly detection in medical imaging. ",
    "url": "https://arxiv.org/abs/2308.13861",
    "authors": [
      "Cosmin I. Bercea",
      "Esther Puyol-Ant\u00f3n",
      "Benedikt Wiestler",
      "Daniel Rueckert",
      "Julia A. Schnabel",
      "Andrew P. King"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13870",
    "title": "Brain-like representational straightening of natural movies in robust  feedforward neural networks",
    "abstract": "Representational straightening refers to a decrease in curvature of visual feature representations of a sequence of frames taken from natural movies. Prior work established straightening in neural representations of the primate primary visual cortex (V1) and perceptual straightening in human behavior as a hallmark of biological vision in contrast to artificial feedforward neural networks which did not demonstrate this phenomenon as they were not explicitly optimized to produce temporally predictable movie representations. Here, we show robustness to noise in the input image can produce representational straightening in feedforward neural networks. Both adversarial training (AT) and base classifiers for Random Smoothing (RS) induced remarkably straightened feature codes. Demonstrating their utility within the domain of natural movies, these codes could be inverted to generate intervening movie frames by linear interpolation in the feature space even though they were not trained on these trajectories. Demonstrating their biological utility, we found that AT and RS training improved predictions of neural data in primate V1 over baseline models providing a parsimonious, bio-plausible mechanism -- noise in the sensory input stages -- for generating representations in early visual cortex. Finally, we compared the geometric properties of frame representations in these networks to better understand how they produced representations that mimicked the straightening phenomenon from biology. Overall, this work elucidating emergent properties of robust neural networks demonstrates that it is not necessary to utilize predictive objectives or train directly on natural movie statistics to achieve models supporting straightened movie representations similar to human perception that also predict V1 neural responses. ",
    "url": "https://arxiv.org/abs/2308.13870",
    "authors": [
      "Tahereh Toosi",
      "Elias B. Issa"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13906",
    "title": "A Two-Dimensional Deep Network for RF-based Drone Detection and  Identification Towards Secure Coverage Extension",
    "abstract": "As drones become increasingly prevalent in human life, they also raises security concerns such as unauthorized access and control, as well as collisions and interference with manned aircraft. Therefore, ensuring the ability to accurately detect and identify between different drones holds significant implications for coverage extension. Assisted by machine learning, radio frequency (RF) detection can recognize the type and flight mode of drones based on the sampled drone signals. In this paper, we first utilize Short-Time Fourier. Transform (STFT) to extract two-dimensional features from the raw signals, which contain both time-domain and frequency-domain information. Then, we employ a Convolutional Neural Network (CNN) built with ResNet structure to achieve multi-class classifications. Our experimental results show that the proposed ResNet-STFT can achieve higher accuracy and faster convergence on the extended dataset. Additionally, it exhibits balanced performance compared to other baselines on the raw dataset. ",
    "url": "https://arxiv.org/abs/2308.13906",
    "authors": [
      "Zixiao Zhao",
      "Qinghe Du",
      "Xiang Yao",
      "Lei Lu",
      "Shijiao Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13944",
    "title": "Deep learning assisted robust detection techniques for a chipless RFID  sensor tag",
    "abstract": "In this paper, we present a new approach for robust reading of identification and sensor data from chipless RFID sensor tags. For the first time, Machine Learning (ML) and Deep Learning (DL) regression modelling techniques are applied to a dataset of measured Radar Cross Section (RCS) data that has been derived from large-scale robotic measurements of custom-designed, 3-bit chipless RFID sensor tags. The robotic system is implemented using the first-of-its-kind automated data acquisition method using an ur16e industry-standard robot. A large data set of 9,600 Electromagnetic (EM) RCS signatures collected using the automated system is used to train and validate four ML models and four 1-dimensional Convolutional Neural Network (1D CNN) architectures. For the first time, we report an end-to-end design and implementation methodology for robust detection of identification (ID) and sensing data using ML/DL models. Also, we report, for the first time, the effect of varying tag surface shapes, tilt angles, and read ranges that were incorporated into the training of models for robust detection of ID and sensing values. The results show that all the models were able to generalise well on the given data. However, the 1D CNN models outperformed the conventional ML models in the detection of ID and sensing values. The best 1D CNN model architectures performed well with a low Root Mean Square Error (RSME) of 0.061 (0.87%) for tag ID and 0.0241 (3.44%) error for the capacitive sensing. ",
    "url": "https://arxiv.org/abs/2308.13944",
    "authors": [
      "Nadeem Rather",
      "Roy B. V. B. Simorangkir",
      "John L. Buckley",
      "Brendan O'Flynn",
      "Salvatore Tedesco"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2308.14000",
    "title": "High-risk Factor Prediction in Lung Cancer Using Thin CT Scans: An  Attention-Enhanced Graph Convolutional Network Approach",
    "abstract": "Lung cancer, particularly in its advanced stages, remains a leading cause of death globally. Though early detection via low-dose computed tomography (CT) is promising, the identification of high-risk factors crucial for surgical mode selection remains a challenge. Addressing this, our study introduces an Attention-Enhanced Graph Convolutional Network (AE-GCN) model to classify whether there are high-risk factors in stage I lung cancer based on the preoperative CT images. This will aid surgeons in determining the optimal surgical method before the operation. Unlike previous studies that relied on 3D patch techniques to represent nodule spatial features, our method employs a GCN model to capture the spatial characteristics of pulmonary nodules. Specifically, we regard each slice of the nodule as a graph vertex, and the inherent spatial relationships between slices form the edges. Then, to enhance the expression of nodule features, we integrated both channel and spatial attention mechanisms with a pre-trained VGG model for adaptive feature extraction from pulmonary nodules. Lastly, the effectiveness of the proposed method is demonstrated using real-world data collected from the hospitals, thereby emphasizing its potential utility in the clinical practice. ",
    "url": "https://arxiv.org/abs/2308.14000",
    "authors": [
      "Xiaotong Fu",
      "Xiangyu Meng",
      "Jing Zhou",
      "Ying Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14015",
    "title": "Slimmed optical neural networks with multiplexed neuron sets and a  corresponding backpropagation training algorithm",
    "abstract": "Due to their intrinsic capabilities on parallel signal processing, optical neural networks (ONNs) have attracted extensive interests recently as a potential alternative to electronic artificial neural networks (ANNs) with reduced power consumption and low latency. Preliminary confirmation of the parallelism in optical computing has been widely done by applying the technology of wavelength division multiplexing (WDM) in the linear transformation part of neural networks. However, inter-channel crosstalk has obstructed WDM technologies to be deployed in nonlinear activation in ONNs. Here, we propose a universal WDM structure called multiplexed neuron sets (MNS) which apply WDM technologies to optical neurons and enable ONNs to be further compressed. A corresponding back-propagation (BP) training algorithm is proposed to alleviate or even cancel the influence of inter-channel crosstalk on MNS-based WDM-ONNs. For simplicity, semiconductor optical amplifiers (SOAs) are employed as an example of MNS to construct a WDM-ONN trained with the new algorithm. The result shows that the combination of MNS and the corresponding BP training algorithm significantly downsize the system and improve the energy efficiency to tens of times while giving similar performance to traditional ONNs. ",
    "url": "https://arxiv.org/abs/2308.14015",
    "authors": [
      "Yi-Feng Liu",
      "Rui-Yao Ren",
      "Dai-Bao Hou",
      "Hai-Zhong Weng",
      "Bo-Wen Wang",
      "Ke-Jie Huang",
      "Xing Lin",
      "Feng Liu",
      "Chen-Hui Li",
      "Chao-Yuan Jin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2308.14048",
    "title": "A Bayesian Non-parametric Approach to Generative Models: Integrating  Variational Autoencoder and Generative Adversarial Networks using Wasserstein  and Maximum Mean Discrepancy",
    "abstract": "Generative models have emerged as a promising technique for producing high-quality images that are indistinguishable from real images. Generative adversarial networks (GANs) and variational autoencoders (VAEs) are two of the most prominent and widely studied generative models. GANs have demonstrated excellent performance in generating sharp realistic images and VAEs have shown strong abilities to generate diverse images. However, GANs suffer from ignoring a large portion of the possible output space which does not represent the full diversity of the target distribution, and VAEs tend to produce blurry images. To fully capitalize on the strengths of both models while mitigating their weaknesses, we employ a Bayesian non-parametric (BNP) approach to merge GANs and VAEs. Our procedure incorporates both Wasserstein and maximum mean discrepancy (MMD) measures in the loss function to enable effective learning of the latent space and generate diverse and high-quality samples. By fusing the discriminative power of GANs with the reconstruction capabilities of VAEs, our novel model achieves superior performance in various generative tasks, such as anomaly detection and data augmentation. Furthermore, we enhance the model's capability by employing an extra generator in the code space, which enables us to explore areas of the code space that the VAE might have overlooked. With a BNP perspective, we can model the data distribution using an infinite-dimensional space, which provides greater flexibility in the model and reduces the risk of overfitting. By utilizing this framework, we can enhance the performance of both GANs and VAEs to create a more robust generative model suitable for various applications. ",
    "url": "https://arxiv.org/abs/2308.14048",
    "authors": [
      "Forough Fazeli-Asl",
      "Michael Minyi Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2308.14049",
    "title": "Fairness and Privacy in Voice Biometrics:A Study of Gender Influences  Using wav2vec 2.0",
    "abstract": "This study investigates the impact of gender information on utility, privacy, and fairness in voice biometric systems, guided by the General Data Protection Regulation (GDPR) mandates, which underscore the need for minimizing the processing and storage of private and sensitive data, and ensuring fairness in automated decision-making systems. We adopt an approach that involves the fine-tuning of the wav2vec 2.0 model for speaker verification tasks, evaluating potential gender-related privacy vulnerabilities in the process. Gender influences during the fine-tuning process were employed to enhance fairness and privacy in order to emphasise or obscure gender information within the speakers' embeddings. Results from VoxCeleb datasets indicate our adversarial model increases privacy against uninformed attacks, yet slightly diminishes speaker verification performance compared to the non-adversarial model. However, the model's efficacy reduces against informed attacks. Analysis of system performance was conducted to identify potential gender biases, thus highlighting the need for further research to understand and improve the delicate interplay between utility, privacy, and equity in voice biometric systems. ",
    "url": "https://arxiv.org/abs/2308.14049",
    "authors": [
      "Oubaida Chouchane",
      "Michele Panariello",
      "Chiara Galdi",
      "Massimiliano Todisco",
      "Nicholas Evans"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2308.14066",
    "title": "Bi-Modality Medical Image Synthesis Using Semi-Supervised Sequential  Generative Adversarial Networks",
    "abstract": "In this paper, we propose a bi-modality medical image synthesis approach based on sequential generative adversarial network (GAN) and semi-supervised learning. Our approach consists of two generative modules that synthesize images of the two modalities in a sequential order. A method for measuring the synthesis complexity is proposed to automatically determine the synthesis order in our sequential GAN. Images of the modality with a lower complexity are synthesized first, and the counterparts with a higher complexity are generated later. Our sequential GAN is trained end-to-end in a semi-supervised manner. In supervised training, the joint distribution of bi-modality images are learned from real paired images of the two modalities by explicitly minimizing the reconstruction losses between the real and synthetic images. To avoid overfitting limited training images, in unsupervised training, the marginal distribution of each modality is learned based on unpaired images by minimizing the Wasserstein distance between the distributions of real and fake images. We comprehensively evaluate the proposed model using two synthesis tasks based on three types of evaluate metrics and user studies. Visual and quantitative results demonstrate the superiority of our method to the state-of-the-art methods, and reasonable visual quality and clinical significance. Code is made publicly available at https://github.com/hustlinyi/Multimodal-Medical-Image-Synthesis. ",
    "url": "https://arxiv.org/abs/2308.14066",
    "authors": [
      "Xin Yang",
      "Yi Lin",
      "Zhiwei Wang",
      "Xin Li",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14081",
    "title": "U-SEANNet: A Simple, Efficient and Applied U-Shaped Network for  Diagnosing Nasal Diseases from Nasal Endoscopic Images",
    "abstract": "Utilizing deep learning (DL) models to improve the early diagnosis of nasal diseases from nasal endoscopic images holds paramount importance. However, the lack of available datasets stymies advancements in this field. Furthermore, existing models fail to strike a good trade-off between model diagnosis performance, model complexity and parameter size, rendering them unsuitable for practical application. To bridge these gaps, we created the first large-scale nasal endoscopy dataset, named 7-NasEID, comprising 11,352 images that span six nasal diseases and normal samples. Building on this, we proposed U-SEANNet, an innovative architecture, underpinned by depth-wise separable convolutions. Additionally, to augment its discernment capabilities for subtle variations in input images, we further proposed the Global-Local Channel Feature Fusion Module, enabling the U-SEANNet to focus salient channel features from both global and local contexts. Notably, U-SEANNet's parameter size and GFLOPs are only 0.78M and 0.21, respectively. Employing the 7-NasalEID, we conducted the five-fold cross-validation on U-SEANNet, juxtaposing its performance against seventeen renowned architectures. The experimental results suggest U-SEANNet as the state-of-the-art (SOTA) model, achieves an accuracy of 93.58%, sensitivity of 90.17%, and specificity of 91.27%. These findings demonstrate U-SEANNet's prodigious potential for diagnosing nasal diseases in practical use, providing the development of efficacy nasal diseases diagnosis tools with a new insight. ",
    "url": "https://arxiv.org/abs/2308.14081",
    "authors": [
      "Yubiao Yue",
      "Jun Xue",
      "Haihua Liang",
      "Zhenzhang Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14085",
    "title": "Sampling with flows, diffusion and autoregressive neural networks: A  spin-glass perspective",
    "abstract": "Recent years witnessed the development of powerful generative models based on flows, diffusion or autoregressive neural networks, achieving remarkable success in generating data from examples with applications in a broad range of areas. A theoretical analysis of the performance and understanding of the limitations of these methods remain, however, challenging. In this paper, we undertake a step in this direction by analysing the efficiency of sampling by these methods on a class of problems with a known probability distribution and comparing it with the sampling performance of more traditional methods such as the Monte Carlo Markov chain and Langevin dynamics. We focus on a class of probability distribution widely studied in the statistical physics of disordered systems that relate to spin glasses, statistical inference and constraint satisfaction problems. We leverage the fact that sampling via flow-based, diffusion-based or autoregressive networks methods can be equivalently mapped to the analysis of a Bayes optimal denoising of a modified probability measure. Our findings demonstrate that these methods encounter difficulties in sampling stemming from the presence of a first-order phase transition along the algorithm's denoising path. Our conclusions go both ways: we identify regions of parameters where these methods are unable to sample efficiently, while that is possible using standard Monte Carlo or Langevin approaches. We also identify regions where the opposite happens: standard approaches are inefficient while the discussed generative methods work well. ",
    "url": "https://arxiv.org/abs/2308.14085",
    "authors": [
      "Davide Ghio",
      "Yatin Dandi",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14178",
    "title": "Data-Driven Robust Control Using Prediction Error Bounds Based on  Perturbation Analysis",
    "abstract": "For linear systems, many data-driven control methods rely on the behavioral framework, using historical data of the system to predict the future trajectories. However, measurement noise introduces errors in predictions. When the noise is bounded, we propose a method for designing historical experiments that enable the computation of an upper bound on the prediction error. This approach allows us to formulate a minimax control problem where robust constraint satisfaction is enforced. We derive an upper bound on the suboptimality gap of the resulting control input sequence compared to optimal control utilizing accurate measurements. As demonstrated in numerical experiments, the solution derived by our method can achieve constraint satisfaction and a small suboptimality gap despite the measurement noise. ",
    "url": "https://arxiv.org/abs/2308.14178",
    "authors": [
      "Baiwei Guo",
      "Yuning Jiang",
      "Colin N. Jones",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.14189",
    "title": "Topology and dynamics of higher-order multiplex networks",
    "abstract": "Higher-order networks are gaining growing attention as they encode for the many-body interactions present in complex systems. However, higher-order networks have the limitation that they only capture many-body interactions of the same type. To tackle this challenge, here we provide a mathematical framework to capture the topology of higher-order multiplex networks and the interplay between their topology and higher-order dynamics. In particular we focus on diffusion of topological signals sustained not only by the nodes, but also by the links, and the higher-dimensional simplices of multiplex simplicial complexes. We exploit the ubiquitous presence of the overlap of the simplices for coupling the dynamics among the multiplex layers providing a definition of multiplex Hodge Laplacians and Dirac operators. The spectral properties of these operators are shown to determine the higher-order diffusion on the higher-order multiplex networks, and encode for the multiplex Betti numbers. Finally, our numerical investigation of the spectral properties of synthetic and real (connectome and microbiome) multiplex simplicial complexes shows evidence that the coupling between the layers can either speed up or slow down the higher-order diffusion of topological signals. This mathematical framework is very general and can be applied to study generic higher-order systems with interactions of multiple types. In particular, these results might find applications in brain networks which are understood to be both multilayer and higher-order. ",
    "url": "https://arxiv.org/abs/2308.14189",
    "authors": [
      "Sanjukta Krishnagopal",
      "Ginestra Bianconi"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2308.14213",
    "title": "Post-Hoc Explainability of BI-RADS Descriptors in a Multi-task Framework  for Breast Cancer Detection and Segmentation",
    "abstract": "Despite recent medical advancements, breast cancer remains one of the most prevalent and deadly diseases among women. Although machine learning-based Computer-Aided Diagnosis (CAD) systems have shown potential to assist radiologists in analyzing medical images, the opaque nature of the best-performing CAD systems has raised concerns about their trustworthiness and interpretability. This paper proposes MT-BI-RADS, a novel explainable deep learning approach for tumor detection in Breast Ultrasound (BUS) images. The approach offers three levels of explanations to enable radiologists to comprehend the decision-making process in predicting tumor malignancy. Firstly, the proposed model outputs the BI-RADS categories used for BUS image analysis by radiologists. Secondly, the model employs multi-task learning to concurrently segment regions in images that correspond to tumors. Thirdly, the proposed approach outputs quantified contributions of each BI-RADS descriptor toward predicting the benign or malignant class using post-hoc explanations with Shapley Values. ",
    "url": "https://arxiv.org/abs/2308.14213",
    "authors": [
      "Mohammad Karimzadeh",
      "Aleksandar Vakanski",
      "Min Xian",
      "Boyu Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14443",
    "title": "Mutual visibility in hypercube-like graphs",
    "abstract": "Let $G$ be a graph and $X\\subseteq V(G)$. Then, vertices $x$ and $y$ of $G$ are $X$-visible if there exists a shortest $u,v$-path where no internal vertices belong to $X$. The set $X$ is a mutual-visibility set of $G$ if every two vertices of $X$ are $X$-visible, while $X$ is a total mutual-visibility set if any two vertices from $V(G)$ are $X$-visible. The cardinality of a largest mutual-visibility set (resp. total mutual-visibility set) is the mutual-visibility number (resp. total mutual-visibility number) $\\mu(G)$ (resp. $\\mu_t(G)$) of $G$. It is known that computing $\\mu(G)$ is an NP-complete problem, as well as $\\mu_t(G)$. In this paper, we study the (total) mutual-visibility in hypercube-like networks (namely, hypercubes, cube-connected cycles, and butterflies). Concerning computing $\\mu(G)$, we provide approximation algorithms for both hypercubes and cube-connected cycles, while we give an exact formula for butterflies. Concerning computing $\\mu_t(G)$ (in the literature, already studied in hypercubes), we provide exact formulae for both cube-connected cycles and butterflies. ",
    "url": "https://arxiv.org/abs/2308.14443",
    "authors": [
      "Serafino Cicerone",
      "Alessia Di Fonso",
      "Gabriele Di Stefano",
      "Alfredo Navarra",
      "Francesco Piselli"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.14456",
    "title": "Speech Self-Supervised Representations Benchmarking: a Case for Larger  Probing Heads",
    "abstract": "Self-supervised learning (SSL) leverages large datasets of unlabeled speech to reach impressive performance with reduced amounts of annotated data. The high number of proposed approaches fostered the emergence of comprehensive benchmarks that evaluate their performance on a set of downstream tasks exploring various aspects of the speech signal. However, while the number of considered tasks has been growing, most proposals rely upon a single downstream architecture that maps the frozen SSL representations to the task labels. This study examines how benchmarking results are affected by changes in the probing head architecture. Interestingly, we found that altering the downstream architecture structure leads to significant fluctuations in the performance ranking of the evaluated models. Against common practices in speech SSL benchmarking, we evaluate larger-capacity probing heads, showing their impact on performance, inference costs, generalization and multi-level feature exploitation. ",
    "url": "https://arxiv.org/abs/2308.14456",
    "authors": [
      "Salah Zaiem",
      "Youcef Kemiche",
      "Titouan Parcollet",
      "Slim Essid",
      "Mirco Ravanelli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.14478",
    "title": "Some issues in robust clustering",
    "abstract": "Some key issues in robust clustering are discussed with focus on Gaussian mixture model based clustering, namely the formal definition of outliers, ambiguity between groups of outliers and clusters, the interaction between robust clustering and the estimation of the number of clusters, the essential dependence of (not only) robust clustering on tuning decisions, and shortcomings of existing measurements of cluster stability when it comes to outliers. ",
    "url": "https://arxiv.org/abs/2308.14478",
    "authors": [
      "Christian Hennig"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2308.14553",
    "title": "Rep2wav: Noise Robust text-to-speech Using self-supervised  representations",
    "abstract": "Benefiting from the development of deep learning, text-to-speech (TTS) techniques using clean speech have achieved significant performance improvements. The data collected from real scenes often contain noise and generally needs to be denoised by speech enhancement models. Noise-robust TTS models are often trained using the enhanced speech, which thus suffer from speech distortion and background noise that affect the quality of the synthesized speech. Meanwhile, it was shown that self-supervised pre-trained models exhibit excellent noise robustness on many speech tasks, implying that the learned representation has a better tolerance for noise perturbations. In this work, we therefore explore pre-trained models to improve the noise robustness of TTS models. Based on HIFI-GAN we first propose a representation-to-waveform vocoder, which aims to learn to map the representation of pre-trained models to the waveform. We then propose a text-to-representation Fastspeech2 model, which aims to learn to map text to pre-trained model representations. Experimental results on the LJSpeech and LibriTTS datasets show that our method outperforms those using speech enhancement methods in both subjective and objective metrics. Audio samples are available at: https://zqs01.github.io/rep2wav/. ",
    "url": "https://arxiv.org/abs/2308.14553",
    "authors": [
      "Qiushi Zhu",
      "Yu Gu",
      "Chao Weng",
      "Yuchen Hu",
      "Lirong Dai",
      "Jie Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2308.14610",
    "title": "A Transformer-Conditioned Neural Fields Pipeline with Polar Coordinate  Representation for Astronomical Radio Interferometric Data Reconstruction",
    "abstract": "In radio astronomy, visibility data, which are measurements of wave signals from radio telescopes, are transformed into images for observation of distant celestial objects. However, these resultant images usually contain both real sources and artifacts, due to signal sparsity and other factors. One way to obtain cleaner images is to reconstruct samples into dense forms before imaging. Unfortunately, existing visibility reconstruction methods may miss some components of the frequency data, so blurred object edges and persistent artifacts remain in the images. Furthermore, the computation overhead is high on irregular visibility samples due to the data skew. To address these problems, we propose PolarRec, a reconstruction method for interferometric visibility data, which consists of a transformer-conditioned neural fields pipeline with a polar coordinate representation. This representation matches the way in which telescopes observe a celestial area as the Earth rotates. We further propose Radial Frequency Loss function, using radial coordinates in the polar coordinate system to correlate with the frequency information, to help reconstruct complete visibility. We also group visibility sample points by angular coordinates in the polar coordinate system, and use groups as the granularity for subsequent encoding with a Transformer encoder. Consequently, our method can capture the inherent characteristics of visibility data effectively and efficiently. Our experiments demonstrate that PolarRec markedly improves imaging results by faithfully reconstructing all frequency components in the visibility domain while significantly reducing the computation cost. ",
    "url": "https://arxiv.org/abs/2308.14610",
    "authors": [
      "Ruoqi Wang",
      "Qiong Luo",
      "Feng Wang"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14693",
    "title": "Hybrid PLS-ML Authentication Scheme for V2I Communication Networks",
    "abstract": "Vehicular communication networks are rapidly emerging as vehicles become smarter. However, these networks are increasingly susceptible to various attacks. The situation is exacerbated by the rise in automated vehicles complicates, emphasizing the need for security and authentication measures to ensure safe and effective traffic management. In this paper, we propose a novel hybrid physical layer security (PLS)-machine learning (ML) authentication scheme by exploiting the position of the transmitter vehicle as a device fingerprint. We use a time-of-arrival (ToA) based localization mechanism where the ToA is estimated at roadside units (RSUs), and the coordinates of the transmitter vehicle are extracted at the base station (BS).Furthermore, to track the mobility of the moving legitimate vehicle, we use ML model trained on several system parameters. We try two ML models for this purpose, i.e., support vector regression and decision tree. To evaluate our scheme, we conduct binary hypothesis testing on the estimated positions with the help of the ground truths provided by the ML model, which classifies the transmitter node as legitimate or malicious. Moreover, we consider the probability of false alarm and the probability of missed detection as performance metrics resulting from the binary hypothesis testing, and mean absolute error (MAE), mean square error (MSE), and coefficient of determination $\\text{R}^2$ to further evaluate the ML models. We also compare our scheme with a baseline scheme that exploits the angle of arrival at RSUs for authentication. We observe that our proposed position-based mechanism outperforms the baseline scheme significantly in terms of missed detections. ",
    "url": "https://arxiv.org/abs/2308.14693",
    "authors": [
      "Hala Amin",
      "Jawaher Kaldari",
      "Nora Mohamed",
      "Waqas Aman",
      "Saif Al-Kuwari"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14705",
    "title": "Diversified Ensemble of Independent Sub-Networks for Robust  Self-Supervised Representation Learning",
    "abstract": "Ensembling a neural network is a widely recognized approach to enhance model performance, estimate uncertainty, and improve robustness in deep supervised learning. However, deep ensembles often come with high computational costs and memory demands. In addition, the efficiency of a deep ensemble is related to diversity among the ensemble members which is challenging for large, over-parameterized deep neural networks. Moreover, ensemble learning has not yet seen such widespread adoption, and it remains a challenging endeavor for self-supervised or unsupervised representation learning. Motivated by these challenges, we present a novel self-supervised training regime that leverages an ensemble of independent sub-networks, complemented by a new loss function designed to encourage diversity. Our method efficiently builds a sub-model ensemble with high diversity, leading to well-calibrated estimates of model uncertainty, all achieved with minimal computational overhead compared to traditional deep self-supervised ensembles. To evaluate the effectiveness of our approach, we conducted extensive experiments across various tasks, including in-distribution generalization, out-of-distribution detection, dataset corruption, and semi-supervised settings. The results demonstrate that our method significantly improves prediction reliability. Our approach not only achieves excellent accuracy but also enhances calibration, surpassing baseline performance across a wide range of self-supervised architectures in computer vision, natural language processing, and genomics data. ",
    "url": "https://arxiv.org/abs/2308.14705",
    "authors": [
      "Amirhossein Vahidi",
      "Lisa Wimmer",
      "H\u00fcseyin Anil G\u00fcnd\u00fcz",
      "Bernd Bischl",
      "Eyke H\u00fcllermeier",
      "Mina Rezaei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2003.01436",
    "title": "Learning to Generate Time Series Conditioned Graphs with Generative  Adversarial Nets",
    "abstract": " Title: Learning to Generate Time Series Conditioned Graphs with Generative  Adversarial Nets ",
    "url": "https://arxiv.org/abs/2003.01436",
    "authors": [
      "Shanchao Yang",
      "Jing Liu",
      "Kai Wu",
      "Mingming Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.08915",
    "title": "Maximizing Social Welfare Subject to Network Externalities: A Unifying  Submodular Optimization Approach",
    "abstract": " Title: Maximizing Social Welfare Subject to Network Externalities: A Unifying  Submodular Optimization Approach ",
    "url": "https://arxiv.org/abs/2102.08915",
    "authors": [
      "S. Rasoul Etesami"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2102.09683",
    "title": "Community Structure Recovery and Interaction Probability Estimation for  Gossip Opinion Dynamics",
    "abstract": " Title: Community Structure Recovery and Interaction Probability Estimation for  Gossip Opinion Dynamics ",
    "url": "https://arxiv.org/abs/2102.09683",
    "authors": [
      "Yu Xing",
      "Xingkang He",
      "Haitao Fang",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2108.09976",
    "title": "Revealing the Distributional Vulnerability of Discriminators by Implicit  Generators",
    "abstract": " Title: Revealing the Distributional Vulnerability of Discriminators by Implicit  Generators ",
    "url": "https://arxiv.org/abs/2108.09976",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Kun-Yu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.05090",
    "title": "Enhancing Self-Disclosure In Neural Dialog Models By Candidate  Re-ranking",
    "abstract": " Comments: 10 pages, 3 figures, 2 table ",
    "url": "https://arxiv.org/abs/2109.05090",
    "authors": [
      "Mayank Soni",
      "Benjamin Cowan",
      "Vincent Wade"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.01729",
    "title": "Multilevel orthogonal Bochner function subspaces with applications to  robust machine learning",
    "abstract": " Title: Multilevel orthogonal Bochner function subspaces with applications to  robust machine learning ",
    "url": "https://arxiv.org/abs/2110.01729",
    "authors": [
      "Julio Enrique Castrillon-Candas",
      "Dingning Liu",
      "Sicheng Yang",
      "Mark Kon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.11011",
    "title": "CDistNet: Perceiving Multi-Domain Character Distance for Robust Text  Recognition",
    "abstract": " Comments: Paper accepted for publication at IJCV 2023 ",
    "url": "https://arxiv.org/abs/2111.11011",
    "authors": [
      "Tianlun Zheng",
      "Zhineng Chen",
      "Shancheng Fang",
      "Hongtao Xie",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.00785",
    "title": "Implicit Autoencoder for Point-Cloud Self-Supervised Representation  Learning",
    "abstract": " Comments: Published in ICCV 2023. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2201.00785",
    "authors": [
      "Siming Yan",
      "Zhenpei Yang",
      "Haoxiang Li",
      "Chen Song",
      "Li Guan",
      "Hao Kang",
      "Gang Hua",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04620",
    "title": "SparseDet: Improving Sparsely Annotated Object Detection with  Pseudo-positive Mining",
    "abstract": " Comments: Accepted at ICCV2023. Project webpage: this https URL The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2201.04620",
    "authors": [
      "Saksham Suri",
      "Sai Saketh Rambhatla",
      "Rama Chellappa",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.13799",
    "title": "One-shot Ultra-high-Resolution Generative Adversarial Network That  Synthesizes 16K Images On A Single GPU",
    "abstract": " Comments: 36 pages, 26 figures ",
    "url": "https://arxiv.org/abs/2202.13799",
    "authors": [
      "Junseok Oh",
      "Donghwee Yoon",
      "Injung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.02172",
    "title": "Adversarial Learning of Intermediate Acoustic Feature for End-to-End  Lightweight Text-to-Speech",
    "abstract": " Comments: INTERSPEECH 2023 ",
    "url": "https://arxiv.org/abs/2204.02172",
    "authors": [
      "Hyungchan Yoon",
      "Seyun Um",
      "Changwhan Kim",
      "Hong-Goo Kang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.05905",
    "title": "Few-shot Forgery Detection via Guided Adversarial Interpolation",
    "abstract": " Title: Few-shot Forgery Detection via Guided Adversarial Interpolation ",
    "url": "https://arxiv.org/abs/2204.05905",
    "authors": [
      "Haonan Qiu",
      "Siyu Chen",
      "Bei Gan",
      "Kun Wang",
      "Huafeng Shi",
      "Jing Shao",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.10348",
    "title": "Simulate Time-integrated Coarse-grained Molecular Dynamics with  Multi-Scale Graph Networks",
    "abstract": " Comments: 27 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2204.10348",
    "authors": [
      "Xiang Fu",
      "Tian Xie",
      "Nathan J. Rebello",
      "Bradley D. Olsen",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2204.14224",
    "title": "Enhancing Core Image Classification Using Generative Adversarial  Networks (GANs)",
    "abstract": " Title: Enhancing Core Image Classification Using Generative Adversarial  Networks (GANs) ",
    "url": "https://arxiv.org/abs/2204.14224",
    "authors": [
      "Galymzhan Abdimanap",
      "Kairat Bostanbekov",
      "Abdelrahman Abdallah",
      "Anel Alimova",
      "Darkhan Kurmangaliyev",
      "Daniyar Nurseitov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.13700",
    "title": "ES-GNN: Generalizing Graph Neural Networks Beyond Homophily with Edge  Splitting",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2205.13700",
    "authors": [
      "Jingwei Guo",
      "Kaizhu Huang",
      "Rui Zhang",
      "Xinping Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04678",
    "title": "ReCo: A Dataset for Residential Community Layout Planning",
    "abstract": " Comments: 9 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2206.04678",
    "authors": [
      "Xi Chen",
      "Yun Xiong",
      "Siqi Wang",
      "Haofen Wang",
      "Tao Sheng",
      "Yao Zhang",
      "Yu Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07150",
    "title": "Attacks on Perception-Based Control Systems: Modeling and Fundamental  Limits",
    "abstract": " Title: Attacks on Perception-Based Control Systems: Modeling and Fundamental  Limits ",
    "url": "https://arxiv.org/abs/2206.07150",
    "authors": [
      "Amir Khazraei",
      "Henry Pfister",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.09385",
    "title": "Out-of-distribution Detection by Cross-class Vicinity Distribution of  In-distribution Data",
    "abstract": " Title: Out-of-distribution Detection by Cross-class Vicinity Distribution of  In-distribution Data ",
    "url": "https://arxiv.org/abs/2206.09385",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Kun-Yu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09387",
    "title": "Dual Representation Learning for Out-of-Distribution Detection",
    "abstract": " Title: Dual Representation Learning for Out-of-Distribution Detection ",
    "url": "https://arxiv.org/abs/2206.09387",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14996",
    "title": "Cross-domain Federated Object Detection",
    "abstract": " Comments: ICME 2023 ",
    "url": "https://arxiv.org/abs/2206.14996",
    "authors": [
      "Shangchao Su",
      "Bin Li",
      "Chengzhi Zhang",
      "Mingzhao Yang",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.06767",
    "title": "Parameter-Efficient Finetuning for Robust Continual Multilingual  Learning",
    "abstract": " Comments: Published at ACL Findings 2023 ",
    "url": "https://arxiv.org/abs/2209.06767",
    "authors": [
      "Kartikeya Badola",
      "Shachi Dave",
      "Partha Talukdar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.14013",
    "title": "On the Robustness of Random Forest Against Untargeted Data Poisoning: An  Ensemble-Based Approach",
    "abstract": " Comments: Accepted in IEEE Transactions on Sustainable Computing; 15 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2209.14013",
    "authors": [
      "Marco Anisetti",
      "Claudio A. Ardagna",
      "Alessandro Balestrucci",
      "Nicola Bena",
      "Ernesto Damiani",
      "Chan Yeob Yeun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15304",
    "title": "Hiding Visual Information via Obfuscating Adversarial Perturbations",
    "abstract": " Title: Hiding Visual Information via Obfuscating Adversarial Perturbations ",
    "url": "https://arxiv.org/abs/2209.15304",
    "authors": [
      "Zhigang Su",
      "Dawei Zhou",
      "Nannan Wangu",
      "Decheng Li",
      "Zhen Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08423",
    "title": "TransVisDrone: Spatio-Temporal Transformer for Vision-based  Drone-to-Drone Detection in Aerial Videos",
    "abstract": " Comments: ICRA 2023 ",
    "url": "https://arxiv.org/abs/2210.08423",
    "authors": [
      "Tushar Sangam",
      "Ishan Rajendrakumar Dave",
      "Waqas Sultani",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08596",
    "title": "Logical Zonotopes: A Set Representation for the Formal Verification of  Boolean Functions",
    "abstract": " Comments: This paper is accepted at the 62nd IEEE Conference on Decision and Control (CDC 2023) ",
    "url": "https://arxiv.org/abs/2210.08596",
    "authors": [
      "Amr Alanwar",
      "Frank J. Jiang",
      "Samy Amin",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.14843",
    "title": "TuneUp: A Simple Improved Training Strategy for Graph Neural Networks",
    "abstract": " Title: TuneUp: A Simple Improved Training Strategy for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2210.14843",
    "authors": [
      "Weihua Hu",
      "Kaidi Cao",
      "Kexin Huang",
      "Edward W Huang",
      "Karthik Subbian",
      "Kenji Kawaguchi",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00945",
    "title": "CarDD: A New Dataset for Vision-based Car Damage Detection",
    "abstract": " Comments: 13 pages, 10 figures, full-length paper for Transactions on Intelligent Transportation Systems (2023) ",
    "url": "https://arxiv.org/abs/2211.00945",
    "authors": [
      "Xinkuang Wang",
      "Wenjing Li",
      "Zhongcheng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08244",
    "title": "Artificial Intelligence for Automatic Detection and Classification  Disease on the X-Ray Images",
    "abstract": " Title: Artificial Intelligence for Automatic Detection and Classification  Disease on the X-Ray Images ",
    "url": "https://arxiv.org/abs/2211.08244",
    "authors": [
      "Liora Mayats-Alpay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16098",
    "title": "Three-stage binarization of color document images based on discrete  wavelet transform and generative adversarial networks",
    "abstract": " Title: Three-stage binarization of color document images based on discrete  wavelet transform and generative adversarial networks ",
    "url": "https://arxiv.org/abs/2211.16098",
    "authors": [
      "Yu-Shian Lin",
      "Rui-Yang Ju",
      "Chih-Chia Chen",
      "Chun-Tse Chien",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.12191",
    "title": "Deep Unfolding-based Weighted Averaging for Federated Learning in  Heterogeneous Environments",
    "abstract": " Title: Deep Unfolding-based Weighted Averaging for Federated Learning in  Heterogeneous Environments ",
    "url": "https://arxiv.org/abs/2212.12191",
    "authors": [
      "Ayano Nakai-Kasai",
      "Tadashi Wadayama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.01917",
    "title": "Flying Bird Object Detection Algorithm in Surveillance Video Based on  Motion Information",
    "abstract": " Title: Flying Bird Object Detection Algorithm in Surveillance Video Based on  Motion Information ",
    "url": "https://arxiv.org/abs/2301.01917",
    "authors": [
      "Ziwei Sun",
      "Zexi Hua",
      "Hengcao Li",
      "Haiyan Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.03196",
    "title": "Near-optimal stochastic MIMO signal detection with a mixture of  t-distribution prior",
    "abstract": " Comments: to be published in the 2023 IEEE Global Communications Conference (GLOBECOM) ",
    "url": "https://arxiv.org/abs/2301.03196",
    "authors": [
      "Junichiro Hagiwara",
      "Kazushi Matsumura",
      "Hiroki Asumi",
      "Yukiko Kasuga",
      "Toshihiko Nishimura",
      "Takanori Sato",
      "Yasutaka Ogawa",
      "Takeo Ohgane"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.08859",
    "title": "Logical Message Passing Networks with One-hop Inference on Atomic  Formulas",
    "abstract": " Comments: Accepted by ICLR 2023. 20 pages, 4 figures, and 9 tables. Our implementation can be found at this https URL . update v4: more accurate comparison about the computational cost between LMPNN and GNN-QE. update v3: typo fix. update v2: add code repository ",
    "url": "https://arxiv.org/abs/2301.08859",
    "authors": [
      "Zihao Wang",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2302.02092",
    "title": "Interpolation for Robust Learning: Data Augmentation on Wasserstein  Geodesics",
    "abstract": " Comments: 34 pages, 3 figures, 18 tables ",
    "url": "https://arxiv.org/abs/2302.02092",
    "authors": [
      "Jiacheng Zhu",
      "Jielin Qiu",
      "Aritra Guha",
      "Zhuolin Yang",
      "Xuanlong Nguyen",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.05968",
    "title": "Self-supervised pseudo-colorizing of masked cells",
    "abstract": " Comments: 14 pages, 3 figures; Published in PLOS ONE ",
    "url": "https://arxiv.org/abs/2302.05968",
    "authors": [
      "Royden Wagner",
      "Carlos Fernandez Lopez",
      "Christoph Stiller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.06039",
    "title": "Predicting Class Distribution Shift for Reliable Domain Adaptive Object  Detection",
    "abstract": " Title: Predicting Class Distribution Shift for Reliable Domain Adaptive Object  Detection ",
    "url": "https://arxiv.org/abs/2302.06039",
    "authors": [
      "Nicolas Harvey Chapman",
      "Feras Dayoub",
      "Will Browne",
      "Christopher Lehnert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.08204",
    "title": "Counterfactual Reasoning for Bias Evaluation and Detection in a Fairness  under Unawareness setting",
    "abstract": " Title: Counterfactual Reasoning for Bias Evaluation and Detection in a Fairness  under Unawareness setting ",
    "url": "https://arxiv.org/abs/2302.08204",
    "authors": [
      "Giandomenico Cornacchia",
      "Vito Walter Anelli",
      "Fedelucio Narducci",
      "Azzurra Ragone",
      "Eugenio Di Sciascio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2302.10425",
    "title": "Instance-incremental Scene Graph Generation from Real-world Point Clouds  via Normalizing Flows",
    "abstract": " Comments: Accepted by IEEE TCSVT. The supplementary material is available in the media column of the journal version of the article ",
    "url": "https://arxiv.org/abs/2302.10425",
    "authors": [
      "Chao Qi",
      "Jianqin Yin",
      "Jinghang Xu",
      "Pengxiang Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10809",
    "title": "Causal Explanations for Sequential Decision-Making in Multi-Agent  Systems",
    "abstract": " Title: Causal Explanations for Sequential Decision-Making in Multi-Agent  Systems ",
    "url": "https://arxiv.org/abs/2302.10809",
    "authors": [
      "Balint Gyevnar",
      "Cheng Wang",
      "Christopher G. Lucas",
      "Shay B. Cohen",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.14353",
    "title": "A semantic backdoor attack against Graph Convolutional Networks",
    "abstract": " Title: A semantic backdoor attack against Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2302.14353",
    "authors": [
      "Jiazhu Dai",
      "Zhipeng Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02602",
    "title": "DPA-P2PNet: Deformable Proposal-aware P2PNet for Accurate Point-based  Cell Detection",
    "abstract": " Title: DPA-P2PNet: Deformable Proposal-aware P2PNet for Accurate Point-based  Cell Detection ",
    "url": "https://arxiv.org/abs/2303.02602",
    "authors": [
      "Zhongyi Shui",
      "Sunyi Zheng",
      "Chenglu Zhu",
      "Shichuan Zhang",
      "Xiaoxuan Yu",
      "Honglin Li",
      "Jingxiong Li",
      "Pingyi Chen",
      "Lin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09551",
    "title": "SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving",
    "abstract": " Comments: Accepted to ICCV 2023. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.09551",
    "authors": [
      "Yi Wei",
      "Linqing Zhao",
      "Wenzhao Zheng",
      "Zheng Zhu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10058",
    "title": "No Fear of Classifier Biases: Neural Collapse Inspired Federated  Learning with Synthetic and Fixed Classifier",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2303.10058",
    "authors": [
      "Zexi Li",
      "Xinyi Shang",
      "Rui He",
      "Tao Lin",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11917",
    "title": "Efficient Decision-based Black-box Patch Attacks on Video Recognition",
    "abstract": " Title: Efficient Decision-based Black-box Patch Attacks on Video Recognition ",
    "url": "https://arxiv.org/abs/2303.11917",
    "authors": [
      "Kaixun Jiang",
      "Zhaoyu Chen",
      "Hao Huang",
      "Jiafeng Wang",
      "Dingkang Yang",
      "Bo Li",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12149",
    "title": "SPARTAN: Self-supervised Spatiotemporal Transformers Approach to Group  Activity Recognition",
    "abstract": " Comments: Accepted to CVPRW 2023; 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2303.12149",
    "authors": [
      "Naga VS Raviteja Chappa",
      "Pha Nguyen",
      "Alexander H Nelson",
      "Han-Seok Seo",
      "Xin Li",
      "Page Daniel Dobbs",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15699",
    "title": "Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images",
    "abstract": " Comments: MICCAI 2023 accepted ",
    "url": "https://arxiv.org/abs/2303.15699",
    "authors": [
      "Hyeonsoo Lee",
      "Junha Kim",
      "Eunkyung Park",
      "Minjeong Kim",
      "Taesoo Kim",
      "Thijs Kooi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.00194",
    "title": "Safe Perception-Based Control under Stochastic Sensor Uncertainty using  Conformal Prediction",
    "abstract": " Comments: This paper is accepted by IEEE CDC 2023 ",
    "url": "https://arxiv.org/abs/2304.00194",
    "authors": [
      "Shuo Yang",
      "George J. Pappas",
      "Rahul Mangharam",
      "Lars Lindemann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.01343",
    "title": "A study of distributionally robust mixed-integer programming with  Wasserstein metric: on the value of incomplete data",
    "abstract": " Title: A study of distributionally robust mixed-integer programming with  Wasserstein metric: on the value of incomplete data ",
    "url": "https://arxiv.org/abs/2304.01343",
    "authors": [
      "Sergey S. Ketkov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.02163",
    "title": "GINA-3D: Learning to Generate Implicit Neural Assets in the Wild",
    "abstract": " Comments: Accepted by CVPR 2023; Our WOD-ObjectAsset can be accessed through waymo.com/open ",
    "url": "https://arxiv.org/abs/2304.02163",
    "authors": [
      "Bokui Shen",
      "Xinchen Yan",
      "Charles R. Qi",
      "Mahyar Najibi",
      "Boyang Deng",
      "Leonidas Guibas",
      "Yin Zhou",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.04688",
    "title": "Interaction-Aware Prompting for Zero-Shot Spatio-Temporal Action  Detection",
    "abstract": " Comments: Accepted by ICCVW 2023 (What is Next in Multimodal Foundation Models?) ",
    "url": "https://arxiv.org/abs/2304.04688",
    "authors": [
      "Wei-Jhe Huang",
      "Jheng-Hsien Yeh",
      "Min-Hung Chen",
      "Gueter Josmy Faure",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.05387",
    "title": "MOST: Multiple Object localization with Self-supervised Transformers for  object discovery",
    "abstract": " Comments: Accepted to ICCV2023 as an Oral. Project webpage: this https URL ",
    "url": "https://arxiv.org/abs/2304.05387",
    "authors": [
      "Sai Saketh Rambhatla",
      "Ishan Misra",
      "Rama Chellappa",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.07920",
    "title": "Causal Decision Transformer for Recommender Systems via Offline  Reinforcement Learning",
    "abstract": " Comments: Accepted by SIGIR'23, please check the camera-ready version for more details such as the implementation ",
    "url": "https://arxiv.org/abs/2304.07920",
    "authors": [
      "Siyu Wang",
      "Xiaocong Chen",
      "Dietmar Jannach",
      "Lina Yao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.08451",
    "title": "Efficient Video Action Detection with Token Dropout and Context  Refinement",
    "abstract": " Comments: technical report ",
    "url": "https://arxiv.org/abs/2304.08451",
    "authors": [
      "Lei Chen",
      "Zhan Tong",
      "Yibing Song",
      "Gangshan Wu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09720",
    "title": "Genetic Algorithm Based Combinatorial Optimization for the Optimal  Design of Water Distribution Network of Gurudeniya Service Zone, Sri Lanka",
    "abstract": " Comments: Submitted to the journal ENGINEER - IESL Sri Lanka. 20 pages. arXiv admin note: text overlap with arXiv:2209.11993 ",
    "url": "https://arxiv.org/abs/2304.09720",
    "authors": [
      "K. H. M. R. N. Senavirathna",
      "C. K. Walgampaya"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.12685",
    "title": "Exploring the Mutual Influence between Self-Supervised Single-Frame and  Multi-Frame Depth Estimation",
    "abstract": " Comments: Accepted for publication in the IEEE Robotics and Automation Letters (RA-L). 8 pages, 3figures ",
    "url": "https://arxiv.org/abs/2304.12685",
    "authors": [
      "Jie Xiang",
      "Yun Wang",
      "Lifeng An",
      "Haiyang Liu",
      "Jian Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.14706",
    "title": "A Twitter network and discourse analysis of the Rana Plaza collapse",
    "abstract": " Title: A Twitter network and discourse analysis of the Rana Plaza collapse ",
    "url": "https://arxiv.org/abs/2304.14706",
    "authors": [
      "Kai Bergermann",
      "Margitta Wolter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.00760",
    "title": "Breaks and Code Quality: Investigating the Impact of Forgetting on  Software Development. A Registered Report",
    "abstract": " Title: Breaks and Code Quality: Investigating the Impact of Forgetting on  Software Development. A Registered Report ",
    "url": "https://arxiv.org/abs/2305.00760",
    "authors": [
      "Dario Amoroso d'Aragona",
      "Luca Pascarella",
      "Andrea Janes",
      "Valentina Lenarduzzi",
      "Rafael Penaloza",
      "Davide Taibi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.05105",
    "title": "TinyML Design Contest for Life-Threatening Ventricular Arrhythmia  Detection",
    "abstract": " Comments: The paper is about the first TinyML design contest for healthcare ",
    "url": "https://arxiv.org/abs/2305.05105",
    "authors": [
      "Zhenge Jia",
      "Dawei Li",
      "Cong Liu",
      "Liqi Liao",
      "Xiaowei Xu",
      "Lichuan Ping",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06310",
    "title": "SoGAR: Self-supervised Spatiotemporal Attention-based Social Group  Activity Recognition",
    "abstract": " Comments: Under review for PR journal; 32 pages, 7 figures. arXiv admin note: text overlap with arXiv:2303.12149 ",
    "url": "https://arxiv.org/abs/2305.06310",
    "authors": [
      "Naga VS Raviteja Chappa",
      "Pha Nguyen",
      "Alexander H Nelson",
      "Han-Seok Seo",
      "Xin Li",
      "Page Daniel Dobbs",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07011",
    "title": "Region-Aware Pretraining for Open-Vocabulary Object Detection with  Vision Transformers",
    "abstract": " Comments: CVPR 2023 Highlight - this https URL ; adds LAION-2B result ",
    "url": "https://arxiv.org/abs/2305.07011",
    "authors": [
      "Dahun Kim",
      "Anelia Angelova",
      "Weicheng Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.09065",
    "title": "Robust Auction Design with Support Information",
    "abstract": " Comments: An abstract of this work appeared in Proceedings of the 24th ACM Conference on Economics and Computation (EC'23) ",
    "url": "https://arxiv.org/abs/2305.09065",
    "authors": [
      "Jerry Anunrojwong",
      "Santiago R. Balseiro",
      "Omar Besbes"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2306.04802",
    "title": "A Survey on Knowledge Graphs for Healthcare: Resources, Applications,  and Promises",
    "abstract": " Title: A Survey on Knowledge Graphs for Healthcare: Resources, Applications,  and Promises ",
    "url": "https://arxiv.org/abs/2306.04802",
    "authors": [
      "Hejie Cui",
      "Jiaying Lu",
      "Shiyu Wang",
      "Ran Xu",
      "Wenjing Ma",
      "Shaojun Yu",
      "Yue Yu",
      "Xuan Kan",
      "Chen Ling",
      "Liang Zhao",
      "Joyce Ho",
      "Fei Wang",
      "Carl Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.12926",
    "title": "Decentralized Multi-Agent Reinforcement Learning with Global State  Prediction",
    "abstract": " Title: Decentralized Multi-Agent Reinforcement Learning with Global State  Prediction ",
    "url": "https://arxiv.org/abs/2306.12926",
    "authors": [
      "Joshua Bloom",
      "Pranjal Paliwal",
      "Apratim Mukherjee",
      "Carlo Pinciroli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2306.14009",
    "title": "Boosting Multitask Learning on Graphs through Higher-Order Task  Affinities",
    "abstract": " Comments: 15 pages, 6 figures, 7 tables. Published in SIGKDD Conference on Knowledge Discovery and Data Mining, 2023 ",
    "url": "https://arxiv.org/abs/2306.14009",
    "authors": [
      "Dongyue Li",
      "Haotian Ju",
      "Aneesh Sharma",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.17426",
    "title": "Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal  Labeling Framework",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2306.17426",
    "authors": [
      "Yang Zhang",
      "Yimeng Bai",
      "Jianxin Chang",
      "Xiaoxue Zang",
      "Song Lu",
      "Jing Lu",
      "Fuli Feng",
      "Yanan Niu",
      "Yang Song"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.00724",
    "title": "LXL: LiDAR Excluded Lean 3D Object Detection with 4D Imaging Radar and  Camera Fusion",
    "abstract": " Title: LXL: LiDAR Excluded Lean 3D Object Detection with 4D Imaging Radar and  Camera Fusion ",
    "url": "https://arxiv.org/abs/2307.00724",
    "authors": [
      "Weiyi Xiong",
      "Jianan Liu",
      "Tao Huang",
      "Qing-Long Han",
      "Yuxuan Xia",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.02054",
    "title": "Emoji Prediction in Tweets using BERT",
    "abstract": " Comments: This paper is focused on predicting emojis corresponding to tweets using BERT ",
    "url": "https://arxiv.org/abs/2307.02054",
    "authors": [
      "Muhammad Osama Nusrat",
      "Zeeshan Habib",
      "Mehreen Alam",
      "Saad Ahmed Jamal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.02758",
    "title": "Exploring Linguistic Style Matching in Online Communities: The Role of  Social Context and Conversation Dynamics",
    "abstract": " Comments: Equal contributions from authors 1-9 (AA, HC, JY, KA, JP, AS, LD, MC, BL) ",
    "url": "https://arxiv.org/abs/2307.02758",
    "authors": [
      "Aparna Ananthasubramaniam",
      "Hong Chen",
      "Jason Yan",
      "Kenan Alkiek",
      "Jiaxin Pei",
      "Agrima Seth",
      "Lavinia Dunagan",
      "Minje Choi",
      "Benjamin Litterer",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.03854",
    "title": "inTformer: A Time-Embedded Attention-Based Transformer for Crash  Likelihood Prediction at Intersections Using Connected Vehicle Data",
    "abstract": " Comments: 29 pages, 10 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2307.03854",
    "authors": [
      "B M Tazbiul Hassan Anik",
      "Zubayer Islam",
      "Mohamed Abdel-Aty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.03898",
    "title": "StyleGAN3: Generative Networks for Improving the Equivariance of  Translation and Rotation",
    "abstract": " Comments: But now we feel we haven't fully studied our work and have found some new great results. So after careful consideration, we're going to rework this manuscript and try to give a more accurate model ",
    "url": "https://arxiv.org/abs/2307.03898",
    "authors": [
      "Tianlei Zhu",
      "Junqi Chen",
      "Renzhe Zhu",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.04298",
    "title": "Edge Storage Management Recipe with Zero-Shot Data Compression for Road  Anomaly Detection",
    "abstract": " Comments: 5 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2307.04298",
    "authors": [
      "YeongHyeon Park",
      "Uju Gim",
      "Myung Jin Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.07205",
    "title": "Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video  Anomaly Detection",
    "abstract": " Comments: Accepted at ICCV2023 ",
    "url": "https://arxiv.org/abs/2307.07205",
    "authors": [
      "Alessandro Flaborea",
      "Luca Collorone",
      "Guido D'Amely",
      "Stefano D'Arrigo",
      "Bardh Prenkaj",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07957",
    "title": "Generalizable and explainable prediction of potential miRNA-disease  associations based on heterogeneous graph learning",
    "abstract": " Title: Generalizable and explainable prediction of potential miRNA-disease  associations based on heterogeneous graph learning ",
    "url": "https://arxiv.org/abs/2307.07957",
    "authors": [
      "Yi Zhou",
      "Meixuan Wu",
      "Chengzhou Ouyang",
      "Min Zhu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2307.08487",
    "title": "Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output  Robustness of Large Language Models",
    "abstract": " Comments: Code and data are available at this https URL ",
    "url": "https://arxiv.org/abs/2307.08487",
    "authors": [
      "Huachuan Qiu",
      "Shuai Zhang",
      "Anqi Li",
      "Hongliang He",
      "Zhenzhong Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.10266",
    "title": "A DPLL(T) Framework for Verifying Deep Neural Networks",
    "abstract": " Comments: 27 pages, 8 figures. NeuralSAT is avaliable from: this https URL ",
    "url": "https://arxiv.org/abs/2307.10266",
    "authors": [
      "Hai Duong",
      "Linhan Li",
      "ThanhVu Nguyen",
      "Matthew Dwyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.15131",
    "title": "Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields",
    "abstract": " Comments: Accepted by ICCV2023. Project Page: this https URL Code: this https URL ",
    "url": "https://arxiv.org/abs/2307.15131",
    "authors": [
      "Xiangyu Wang",
      "Jingsen Zhu",
      "Qi Ye",
      "Yuchi Huo",
      "Yunlong Ran",
      "Zhihua Zhong",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2307.16109",
    "title": "A Message Passing Detection based Affine Frequency Division Multiplexing  Communication System",
    "abstract": " Comments: 19 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2307.16109",
    "authors": [
      "Lifan Wu",
      "Shan Luo",
      "Dongxiao Song",
      "Fan Yang",
      "Rongping Lin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.00247",
    "title": "Unleashing the Power of Self-Supervised Image Denoising: A Comprehensive  Review",
    "abstract": " Comments: 24 pages ",
    "url": "https://arxiv.org/abs/2308.00247",
    "authors": [
      "Dan Zhang",
      "Fangfang Zhou",
      "Xiao Yang",
      "Yuan Gu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.02332",
    "title": "Novel Online-Offline MA2C-DDPG for Efficient Spectrum Allocation and  Trajectory Optimization in Dynamic Spectrum Sharing UAV Networks",
    "abstract": " Comments: Some technical errors occured in the manuscript ",
    "url": "https://arxiv.org/abs/2308.02332",
    "authors": [
      "Rui Ding",
      "Fuhui Zhou",
      "Yuben Qu",
      "Chao Dong",
      "Qihui Wu",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.03312",
    "title": "Symmetry-Preserving Program Representations for Learning Code Semantics",
    "abstract": " Title: Symmetry-Preserving Program Representations for Learning Code Semantics ",
    "url": "https://arxiv.org/abs/2308.03312",
    "authors": [
      "Kexin Pei",
      "Weichen Li",
      "Qirui Jin",
      "Shuyang Liu",
      "Scott Geng",
      "Lorenzo Cavallaro",
      "Junfeng Yang",
      "Suman Jana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2308.03434",
    "title": "Tyshkevich's Graph Decomposition and the Distinguishing Numbers of  Unigraphs",
    "abstract": " Comments: 22 pages plus an appendix with 8 pages ",
    "url": "https://arxiv.org/abs/2308.03434",
    "authors": [
      "Christine T. Cheng"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2308.05695",
    "title": "Masked Diffusion as Self-supervised Representation Learner",
    "abstract": " Title: Masked Diffusion as Self-supervised Representation Learner ",
    "url": "https://arxiv.org/abs/2308.05695",
    "authors": [
      "Zixuan Pan",
      "Jianxu Chen",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05987",
    "title": "Advancing the study of Large-Scale Learning in Overlapped Speech  Detection",
    "abstract": " Title: Advancing the study of Large-Scale Learning in Overlapped Speech  Detection ",
    "url": "https://arxiv.org/abs/2308.05987",
    "authors": [
      "Zhaohui Yin",
      "Jingguang Tian",
      "Xinhui Hu",
      "Xinkang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.08086",
    "title": "Safety Filter Design for Neural Network Systems via Convex Optimization",
    "abstract": " Comments: This paper has been accepted to the 2023 62nd IEEE Conference on Decision and Control (CDC) ",
    "url": "https://arxiv.org/abs/2308.08086",
    "authors": [
      "Shaoru Chen",
      "Kong Yao Chee",
      "Nikolai Matni",
      "M. Ani Hsieh",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.09729",
    "title": "MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large  Language Models",
    "abstract": " Comments: 7 pages, 8 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2308.09729",
    "authors": [
      "Yilin Wen",
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10022",
    "title": "Cupid: Leveraging ChatGPT for More Accurate Duplicate Bug Report  Detection",
    "abstract": " Comments: Recently submitted to TOSEM ",
    "url": "https://arxiv.org/abs/2308.10022",
    "authors": [
      "Ting Zhang",
      "Ivana Clairine Irsan",
      "Ferdian Thung",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.10187",
    "title": "Spiking-Diffusion: Vector Quantized Discrete Diffusion Model with  Spiking Neural Networks",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2308.10187",
    "authors": [
      "Mingxuan Liu",
      "Rui Wen",
      "Hong Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10335",
    "title": "A Study on Robustness and Reliability of Large Language Model Code  Generation",
    "abstract": " Title: A Study on Robustness and Reliability of Large Language Model Code  Generation ",
    "url": "https://arxiv.org/abs/2308.10335",
    "authors": [
      "Li Zhong",
      "Zilong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.10425",
    "title": "STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer  SOTA for Traffic Forecasting",
    "abstract": " Comments: Accepted as CIKM2023 Short Paper ",
    "url": "https://arxiv.org/abs/2308.10425",
    "authors": [
      "Hangchen Liu",
      "Zheng Dong",
      "Renhe Jiang",
      "Jiewen Deng",
      "Jinliang Deng",
      "Quanjun Chen",
      "Xuan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11402",
    "title": "A Partially Observable Deep Multi-Agent Active Inference Framework for  Resource Allocation in 6G and Beyond Wireless Communications Networks",
    "abstract": " Comments: Some technical errors occured in the manuscript ",
    "url": "https://arxiv.org/abs/2308.11402",
    "authors": [
      "Fuhui Zhou",
      "Rui Ding",
      "Qihui Wu",
      "Derrick Wing Kwan Ng",
      "Kai-Kit Wong",
      "Naofal Al-Dhahir"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.12143",
    "title": "A Probabilistic Fluctuation based Membership Inference Attack for  Diffusion Models",
    "abstract": " Title: A Probabilistic Fluctuation based Membership Inference Attack for  Diffusion Models ",
    "url": "https://arxiv.org/abs/2308.12143",
    "authors": [
      "Wenjie Fu",
      "Huandong Wang",
      "Chen Gao",
      "Guanghua Liu",
      "Yong Li",
      "Tao Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12508",
    "title": "FFEINR: Flow Feature-Enhanced Implicit Neural Representation for  Spatio-temporal Super-Resolution",
    "abstract": " Comments: This paper has been accepted and published by ChinaVis 2023(2023.7.21-24) ",
    "url": "https://arxiv.org/abs/2308.12508",
    "authors": [
      "Chenyue Jiao",
      "Chongke Bi",
      "Lu Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.12570",
    "title": "StreamMapNet: Streaming Mapping Network for Vectorized Online HD Map  Construction",
    "abstract": " Title: StreamMapNet: Streaming Mapping Network for Vectorized Online HD Map  Construction ",
    "url": "https://arxiv.org/abs/2308.12570",
    "authors": [
      "Tianyuan Yuan",
      "Yicheng Liu",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12902",
    "title": "CDAN: Convolutional Dense Attention-guided Network for Low-light Image  Enhancement",
    "abstract": " Comments: 20 Pages, 13 Figures ",
    "url": "https://arxiv.org/abs/2308.12902",
    "authors": [
      "Hossein Shakibania",
      "Sina Raoufi",
      "Hassan Khotanlou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13269",
    "title": "Heterogeneous Decentralized Machine Unlearning with Seed Model  Distillation",
    "abstract": " Title: Heterogeneous Decentralized Machine Unlearning with Seed Model  Distillation ",
    "url": "https://arxiv.org/abs/2308.13269",
    "authors": [
      "Guanhua Ye",
      "Tong Chen",
      "Quoc Viet Hung Nguyen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13276",
    "title": "Knowledge-Based Version Incompatibility Detection for Deep Learning",
    "abstract": " Comments: 12 pages, FSE 2023 ",
    "url": "https://arxiv.org/abs/2308.13276",
    "authors": [
      "Zhongkai Zhao",
      "Bonan Kou",
      "Mohamed Yilmaz Ibrahim",
      "Muhao Chen",
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.13420",
    "title": "Reinforcement Learning-assisted Evolutionary Algorithm: A Survey and  Research Opportunities",
    "abstract": " Comments: 26 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2308.13420",
    "authors": [
      "Yanjie Song",
      "Yutong Wu",
      "Yangyang Guo",
      "Ran Yan",
      "P. N. Suganthan",
      "Yue Zhang",
      "Witold Pedrycz",
      "Yingwu Chen",
      "Swagatam Das",
      "Rammohan Mallipeddi",
      "Oladayo Solomon Ajani"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]