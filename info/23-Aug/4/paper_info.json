[
  {
    "id": "arXiv:2308.01327",
    "title": "Careful Whisper -- leveraging advances in automatic speech recognition  for robust and interpretable aphasia subtype classification",
    "abstract": "This paper presents a fully automated approach for identifying speech anomalies from voice recordings to aid in the assessment of speech impairments. By combining Connectionist Temporal Classification (CTC) and encoder-decoder-based automatic speech recognition models, we generate rich acoustic and clean transcripts. We then apply several natural language processing methods to extract features from these transcripts to produce prototypes of healthy speech. Basic distance measures from these prototypes serve as input features for standard machine learning classifiers, yielding human-level accuracy for the distinction between recordings of people with aphasia and a healthy control group. Furthermore, the most frequently occurring aphasia types can be distinguished with 90% accuracy. The pipeline is directly applicable to other diseases and languages, showing promise for robustly extracting diagnostic speech biomarkers. ",
    "url": "https://arxiv.org/abs/2308.01327",
    "authors": [
      "Laurin Wagner",
      "Mario Zusag",
      "Theresa Bloder"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.01329",
    "title": "EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding",
    "abstract": "Embedding learning transforms discrete data entities into continuous numerical representations, encoding features/properties of the entities. Despite the outstanding performance reported from different embedding learning algorithms, few efforts were devoted to structurally interpreting how features are encoded in the learned embedding space. This work proposes EmbeddingTree, a hierarchical embedding exploration algorithm that relates the semantics of entity features with the less-interpretable embedding vectors. An interactive visualization tool is also developed based on EmbeddingTree to explore high-dimensional embeddings. The tool helps users discover nuance features of data entities, perform feature denoising/injecting in embedding training, and generate embeddings for unseen entities. We demonstrate the efficacy of EmbeddingTree and our visualization tool through embeddings generated for industry-scale merchant data and the public 30Music listening/playlists dataset. ",
    "url": "https://arxiv.org/abs/2308.01329",
    "authors": [
      "Yan Zheng",
      "Junpeng Wang",
      "Chin-Chia Michael Yeh",
      "Yujie Fan",
      "Huiyuan Chen",
      "Liang Wang",
      "Wei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01369",
    "title": "An enhanced motion planning approach by integrating driving  heterogeneity and long-term trajectory prediction for automated driving  systems",
    "abstract": "Navigating automated driving systems (ADSs) through complex driving environments is difficult. Predicting the driving behavior of surrounding human-driven vehicles (HDVs) is a critical component of an ADS. This paper proposes an enhanced motion-planning approach for an ADS in a highway-merging scenario. The proposed enhanced approach utilizes the results of two aspects: the driving behavior and long-term trajectory of surrounding HDVs, which are coupled using a hierarchical model that is used for the motion planning of an ADS to improve driving safety. ",
    "url": "https://arxiv.org/abs/2308.01369",
    "authors": [
      "Ni Dong",
      "Shuming Chen",
      "Yina Wu",
      "Yiheng Feng",
      "Xiaobo Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01375",
    "title": "CausalOps -- Towards an Industrial Lifecycle for Causal Probabilistic  Graphical Models",
    "abstract": "Causal probabilistic graph-based models have gained widespread utility, enabling the modeling of cause-and-effect relationships across diverse domains. With their rising adoption in new areas, such as automotive system safety and machine learning, the need for an integrated lifecycle framework akin to DevOps and MLOps has emerged. Currently, a process reference for organizations interested in employing causal engineering is missing. To address this gap and foster widespread industrial adoption, we propose CausalOps, a novel lifecycle framework for causal model development and application. By defining key entities, dependencies, and intermediate artifacts generated during causal engineering, we establish a consistent vocabulary and workflow model. This work contextualizes causal model usage across different stages and stakeholders, outlining a holistic view of creating and maintaining them. CausalOps' aim is to drive the adoption of causal methods in practical applications within interested organizations and the causality community. ",
    "url": "https://arxiv.org/abs/2308.01375",
    "authors": [
      "Robert Maier",
      "Andreas Schlattl",
      "Thomas Guess",
      "J\u00fcrgen Mottok"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01389",
    "title": "Follow the Soldiers with Optimized Single-Shot Multibox Detection and  Reinforcement Learning",
    "abstract": "Nowadays, autonomous cars are gaining traction due to their numerous potential applications on battlefields and in resolving a variety of other real-world challenges. The main goal of our project is to build an autonomous system using DeepRacer which will follow a specific person (for our project, a soldier) when they will be moving in any direction. Two main components to accomplish this project is an optimized Single-Shot Multibox Detection (SSD) object detection model and a Reinforcement Learning (RL) model. We accomplished the task using SSD Lite instead of SSD and at the end, compared the results among SSD, SSD with Neural Computing Stick (NCS), and SSD Lite. Experimental results show that SSD Lite gives better performance among these three techniques and exhibits a considerable boost in inference speed (~2-3 times) without compromising accuracy. ",
    "url": "https://arxiv.org/abs/2308.01389",
    "authors": [
      "Jumman Hossain",
      "Maliha Momtaz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01398",
    "title": "A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks  with Onboard Real-Time Object Detection and Visual Odometry",
    "abstract": "This paper introduces a novel, small form-factor, aerial vehicle research platform for agile object detection, classification, tracking, and interaction tasks. General-purpose hardware components were designed to augment a given aerial vehicle and enable it to perform safe and reliable grasping. These components include a custom collision tolerant cage and low-cost Gripper Extension Package, which we call GREP, for object grasping. Small vehicles enable applications in highly constrained environments, but are often limited by computational resources. This work evaluates the challenges of pick-and-place tasks, with entirely onboard computation of object pose and visual odometry based state estimation on a small platform, and demonstrates experiments with enough accuracy to reliably grasp objects. In a total of 70 trials across challenging cases such as cluttered environments, obstructed targets, and multiple instances of the same target, we demonstrated successfully grasping the target in 93% of trials. Both the hardware component designs and software framework are released as open-source, since our intention is to enable easy reproduction and application on a wide range of small vehicles. ",
    "url": "https://arxiv.org/abs/2308.01398",
    "authors": [
      "Cora A. Dimmig",
      "Anna Goodridge",
      "Gabriel Baraban",
      "Pupei Zhu",
      "Joyraj Bhowmick",
      "Marin Kobilarov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01408",
    "title": "UPB at IberLEF-2023 AuTexTification: Detection of Machine-Generated Text  using Transformer Ensembles",
    "abstract": "This paper describes the solutions submitted by the UPB team to the AuTexTification shared task, featured as part of IberLEF-2023. Our team participated in the first subtask, identifying text documents produced by large language models instead of humans. The organizers provided a bilingual dataset for this subtask, comprising English and Spanish texts covering multiple domains, such as legal texts, social media posts, and how-to articles. We experimented mostly with deep learning models based on Transformers, as well as training techniques such as multi-task learning and virtual adversarial training to obtain better results. We submitted three runs, two of which consisted of ensemble models. Our best-performing model achieved macro F1-scores of 66.63% on the English dataset and 67.10% on the Spanish dataset. ",
    "url": "https://arxiv.org/abs/2308.01408",
    "authors": [
      "Andrei-Alexandru Preda",
      "Dumitru-Clementin Cercel",
      "Traian Rebedea",
      "Costin-Gabriel Chiru"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.01412",
    "title": "Harder synthetic anomalies to improve OoD detection in Medical Images",
    "abstract": "Our method builds upon previous Medical Out-of-Distribution (MOOD) challenge winners that empirically show that synthetic local anomalies generated copying / interpolating foreign patches are useful to train segmentation networks able to generalize to unseen types of anomalies. In terms of the synthetic anomaly generation process, our contributions makes synthetic anomalies more heterogeneous and challenging by 1) using random shapes instead of squares and 2) smoothing the interpolation edge of anomalies so networks cannot rely on the high gradient between image - foreign patch to identify anomalies. Our experiments using the validation set of 2020 MOOD winners show that both contributions improved substantially the method performance. We used a standard 3D U-Net architecture as segmentation network, trained patch-wise in both brain and abdominal datasets. Our final challenge submission consisted of 10 U-Nets trained across 5 data folds with different configurations of the anomaly generation process. Our method achieved first position in both sample-wise and pixel-wise tasks in the 2022 edition of the Medical Out-of-Distribution held at MICCAI. ",
    "url": "https://arxiv.org/abs/2308.01412",
    "authors": [
      "Sergio Naval Marimont",
      "Giacomo Tarroni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01424",
    "title": "LiDAR View Synthesis for Robust Vehicle Navigation Without Expert Labels",
    "abstract": "Deep learning models for self-driving cars require a diverse training dataset to safely manage critical driving scenarios on public roads. This includes having data from divergent trajectories such as the oncoming traffic lane or sidewalks. Such data would be too dangerous to collect in the real world. Data augmentation approaches have been proposed to tackle this issue using RGB images. However, solutions based on LiDAR sensors are scarce. We therefore propose an approach to synthesize additional LiDAR point clouds from novel viewpoints without having the need to physically drive at dangerous positions. The LiDAR view synthesis is done using mesh reconstruction and ray casting. We train a deep learning model, which takes a LiDAR scan as input and predicts the future trajectory as output. A waypoint controller is then applied on this predicted trajectory to determine the throttle and steering labels of the ego-vehicle. Our method neither requires expert driving labels for the original nor for the synthesized LiDAR sequence. Instead, we infer labels from LiDAR odometry. We demonstrate the effectiveness of our approach in a comprehensive online evaluation and with a comparison to concurrent work. Our results show the importance of synthesizing additional LiDAR point clouds, particularly in terms of model robustness. Code and supplementary visualizations are available at https://jonathsch.github.io/lidar-synthesis/ . ",
    "url": "https://arxiv.org/abs/2308.01424",
    "authors": [
      "Jonathan Schmidt",
      "Qadeer Khan",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01440",
    "title": "Optimizing Cellular Networks for UAV Corridors via Quantization Theory",
    "abstract": "We present a new framework based on quantization theory to design cellular networks optimized for both legacy ground users and uncrewed aerial vehicle (UAV) corridors, dedicated aerial highways for safe UAV flights. Our framework leverages antenna tilts and transmit power at each base station to enhance coverage and quality of service among users. We develop a comprehensive mathematical analysis and optimization algorithms for multiple system-level performance metrics, including received signal strength and signal-to-interference-plus-noise ratio. Realistic antenna radiation patterns and propagation channel models are considered, alongside a generic 3D user distribution that allows for performance prioritization on the ground, along UAV corridors, or a desired tradeoff between the two. We demonstrate the efficacy of the proposed framework through case studies, showcasing the non-trivial combinations of antenna tilts and power levels that improve coverage and signal quality along UAV corridors while incurring only a marginal impact on the ground user performance compared to scenarios without UAVs. ",
    "url": "https://arxiv.org/abs/2308.01440",
    "authors": [
      "Saeed Karimi-Bidhendi",
      "Giovanni Geraci",
      "Hamid Jafarkhani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.01463",
    "title": "SemDiff: Binary Similarity Detection by Diffing Key-Semantics Graphs",
    "abstract": "Binary similarity detection is a critical technique that has been applied in many real-world scenarios where source code is not available, e.g., bug search, malware analysis, and code plagiarism detection. Existing works are ineffective in detecting similar binaries in cases where different compiling optimizations, compilers, source code versions, or obfuscation are deployed. We observe that all the cases do not change a binary's key code behaviors although they significantly modify its syntax and structure. With this key observation, we extract a set of key instructions from a binary to capture its key code behaviors. By detecting the similarity between two binaries' key instructions, we can address well the ineffectiveness limitation of existing works. Specifically, we translate each extracted key instruction into a self-defined key expression, generating a key-semantics graph based on the binary's control flow. Each node in the key-semantics graph denotes a key instruction, and the node attribute is the key expression. To quantify the similarity between two given key-semantics graphs, we first serialize each graph into a sequence of key expressions by topological sort. Then, we tokenize and concatenate key expressions to generate token lists. We calculate the locality-sensitive hash value for all token lists and quantify their similarity. %We implement a prototype, called SemDiff, consisting of two modules: graph generation and graph diffing. The first module generates a pair of key-semantics graphs and the second module diffs the graphs. Our evaluation results show that overall, SemDiff outperforms state-of-the-art tools when detecting the similarity of binaries generated from different optimization levels, compilers, and obfuscations. SemDiff is also effective for library version search and finding similar vulnerabilities in firmware. ",
    "url": "https://arxiv.org/abs/2308.01463",
    "authors": [
      "Zian Liu",
      "Zhi Zhang",
      "Siqi Ma",
      "Dongxi Liu",
      "Jun Zhang",
      "Chao Chen",
      "Shigang Liu",
      "Muhammad Ejaz Ahmed",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.01469",
    "title": "VertexSerum: Poisoning Graph Neural Networks for Link Inference",
    "abstract": "Graph neural networks (GNNs) have brought superb performance to various applications utilizing graph structural data, such as social analysis and fraud detection. The graph links, e.g., social relationships and transaction history, are sensitive and valuable information, which raises privacy concerns when using GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel graph poisoning attack that increases the effectiveness of graph link stealing by amplifying the link connectivity leakage. To infer node adjacency more accurately, we propose an attention mechanism that can be embedded into the link detection network. Our experiments demonstrate that VertexSerum significantly outperforms the SOTA link inference attack, improving the AUC scores by an average of $9.8\\%$ across four real-world datasets and three different GNN structures. Furthermore, our experiments reveal the effectiveness of VertexSerum in both black-box and online learning settings, further validating its applicability in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2308.01469",
    "authors": [
      "Ruyi Ding",
      "Shijin Duan",
      "Xiaolin Xu",
      "Yunsi Fei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.01471",
    "title": "Implicit Occupancy Flow Fields for Perception and Prediction in  Self-Driving",
    "abstract": "A self-driving vehicle (SDV) must be able to perceive its surroundings and predict the future behavior of other traffic participants. Existing works either perform object detection followed by trajectory forecasting of the detected objects, or predict dense occupancy and flow grids for the whole scene. The former poses a safety concern as the number of detections needs to be kept low for efficiency reasons, sacrificing object recall. The latter is computationally expensive due to the high-dimensionality of the output grid, and suffers from the limited receptive field inherent to fully convolutional networks. Furthermore, both approaches employ many computational resources predicting areas or objects that might never be queried by the motion planner. This motivates our unified approach to perception and future prediction that implicitly represents occupancy and flow over time with a single neural network. Our method avoids unnecessary computation, as it can be directly queried by the motion planner at continuous spatio-temporal locations. Moreover, we design an architecture that overcomes the limited receptive field of previous explicit occupancy prediction methods by adding an efficient yet effective global attention mechanism. Through extensive experiments in both urban and highway settings, we demonstrate that our implicit model outperforms the current state-of-the-art. For more information, visit the project website: https://waabi.ai/research/implicito. ",
    "url": "https://arxiv.org/abs/2308.01471",
    "authors": [
      "Ben Agro",
      "Quinlan Sykora",
      "Sergio Casas",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01474",
    "title": "Decentralized Translator of Trust: Supporting Heterogeneous TEE for  Critical Infrastructure Protection",
    "abstract": "Trusted execution environment (TEE) technology has found many applications in mitigating various security risks in an efficient manner, which is attractive for critical infrastructure protection. First, the natural of critical infrastructure requires it to be well protected from various cyber attacks. Second, performance is usually important for critical infrastructure and it cannot afford an expensive protection mechanism. While a large number of TEE-based critical infrastructure protection systems have been proposed to address various security challenges (e.g., secure sensing and reliable control), most existing works ignore one important feature, i.e., devices comprised the critical infrastructure may be equipped with multiple incompatible TEE technologies and belongs to different owners. This feature makes it hard for these devices to establish mutual trust and form a unified TEE environment. To address these challenges and fully unleash the potential of TEE technology for critical infrastructure protection, we propose DHTee, a decentralized coordination mechanism. DHTee uses blockchain technology to support key TEE functions in a heterogeneous TEE environment, especially the attestation service. A Device equipped with one TEE can interact securely with the blockchain to verify whether another potential collaborating device claiming to have a different TEE meets the security requirements. DHTee is also flexible and can support new TEE schemes without affecting devices using existing TEEs that have been supported by the system. ",
    "url": "https://arxiv.org/abs/2308.01474",
    "authors": [
      "Rabimba Karanjai",
      "Rowan Collier",
      "Zhimin Gao",
      "Lin Chen",
      "Xinxin Fan",
      "Taeweon Suh",
      "Weidong Shi",
      "Lei Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2308.01483",
    "title": "Efficient neural supersampling on a novel gaming dataset",
    "abstract": "Real-time rendering for video games has become increasingly challenging due to the need for higher resolutions, framerates and photorealism. Supersampling has emerged as an effective solution to address this challenge. Our work introduces a novel neural algorithm for supersampling rendered content that is 4 times more efficient than existing methods while maintaining the same level of accuracy. Additionally, we introduce a new dataset which provides auxiliary modalities such as motion vectors and depth generated using graphics rendering features like viewport jittering and mipmap biasing at different resolutions. We believe that this dataset fills a gap in the current dataset landscape and can serve as a valuable resource to help measure progress in the field and advance the state-of-the-art in super-resolution techniques for gaming content. ",
    "url": "https://arxiv.org/abs/2308.01483",
    "authors": [
      "Antoine Mercier",
      "Ruan Erasmus",
      "Yashesh Savani",
      "Manik Dhingra",
      "Fatih Porikli",
      "Guillaume Berger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01487",
    "title": "Data-Driven Nonlinear TDOA for Accurate Source Localization in Complex  Signal Dynamics",
    "abstract": "The complex and dynamic propagation of oscillations and waves is often triggered by sources at unknown locations. Accurate source localization enables the elimination of the rotor core in atrial fibrillation (AFib) as an effective treatment for such severe cardiac disorder; it also finds potential use in locating the spreading source in natural disasters such as forest fires and tsunamis. However, existing approaches such as time of arrival (TOA) and time difference of arrival (TDOA) do not yield accurate localization results since they tacitly assume a constant signal propagation speed whereas realistic propagation is often non-static and heterogeneous. In this paper, we develop a nonlinear TDOA (NTDOA) approach which utilizes observational data from various positions to jointly learn the propagation speed at different angles and distances as well as the location of the source itself. Through examples of simulating the complex dynamics of electrical signals along the surface of the heart and satellite imagery from forest fires and tsunamis, we show that with a small handful of measurements, NTDOA, as a data-driven approach, can successfully locate the spreading source, leading also to better forecasting of the speed and direction of subsequent propagation. ",
    "url": "https://arxiv.org/abs/2308.01487",
    "authors": [
      "Chinmay Sahu",
      "Mahesh Banavar",
      "Jie Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.01496",
    "title": "Target-point Attention Transformer: A novel trajectory predict network  for end-to-end autonomous driving",
    "abstract": "In the field of autonomous driving, there have been many excellent perception models for object detection, semantic segmentation, and other tasks, but how can we effectively use the perception models for vehicle planning? Traditional autonomous vehicle trajectory prediction methods not only need to obey traffic rules to avoid collisions, but also need to follow the prescribed route to reach the destination. In this paper, we propose a Transformer-based trajectory prediction network for end-to-end autonomous driving without rules called Target-point Attention Transformer network (TAT). We use the attention mechanism to realize the interaction between the predicted trajectory and the perception features as well as target-points. We demonstrate that our proposed method outperforms existing conditional imitation learning and GRU-based methods, significantly reducing the occurrence of accidents and improving route completion. We evaluate our approach in complex closed loop driving scenarios in cities using the CARLA simulator and achieve state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2308.01496",
    "authors": [
      "Jingyu Du",
      "Yang Zhao",
      "Hong Cheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01512",
    "title": "Erase and Repair: An Efficient Box-Free Removal Attack on High-Capacity  Deep Hiding",
    "abstract": "Deep hiding, embedding images with others using deep neural networks, has demonstrated impressive efficacy in increasing the message capacity and robustness of secret sharing. In this paper, we challenge the robustness of existing deep hiding schemes by preventing the recovery of secret images, building on our in-depth study of state-of-the-art deep hiding schemes and their vulnerabilities. Leveraging our analysis, we first propose a simple box-free removal attack on deep hiding that does not require any prior knowledge of the deep hiding schemes. To improve the removal performance on the deep hiding schemes that may be enhanced by adversarial training, we further design a more powerful removal attack, efficient box-free removal attack (EBRA), which employs image inpainting techniques to remove secret images from container images. In addition, to ensure the effectiveness of our attack and preserve the fidelity of the processed container images, we design an erasing phase based on the locality of deep hiding to remove secret information and then make full use of the visual information of container images to repair the erased visual content. Extensive evaluations show our method can completely remove secret images from container images with negligible impact on the quality of container images. ",
    "url": "https://arxiv.org/abs/2308.01512",
    "authors": [
      "Hangcheng Liu",
      "Tao Xiang",
      "Shangwei Guo",
      "Han Li",
      "Tianwei Zhang",
      "Xiaofeng Liao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.01520",
    "title": "Contrastive Multi-FaceForensics: An End-to-end Bi-grained Contrastive  Learning Approach for Multi-face Forgery Detection",
    "abstract": "DeepFakes have raised serious societal concerns, leading to a great surge in detection-based forensics methods in recent years. Face forgery recognition is the conventional detection method that usually follows a two-phase pipeline: it extracts the face first and then determines its authenticity by classification. Since DeepFakes in the wild usually contain multiple faces, using face forgery detection methods is merely practical as they have to process faces in a sequel, i.e., only one face is processed at the same time. One straightforward way to address this issue is to integrate face extraction and forgery detection in an end-to-end fashion by adapting advanced object detection architectures. However, as these object detection architectures are designed to capture the semantic information of different object categories rather than the subtle forgery traces among the faces, the direct adaptation is far from optimal. In this paper, we describe a new end-to-end framework, Contrastive Multi-FaceForensics (COMICS), to enhance multi-face forgery detection. The core of the proposed framework is a novel bi-grained contrastive learning approach that explores effective face forgery traces at both the coarse- and fine-grained levels. Specifically, the coarse-grained level contrastive learning captures the discriminative features among positive and negative proposal pairs in multiple scales with the instruction of the proposal generator, and the fine-grained level contrastive learning captures the pixel-wise discrepancy between the forged and original areas of the same face and the pixel-wise content inconsistency between different faces. Extensive experiments on the OpenForensics dataset demonstrate our method outperforms other counterparts by a large margin (~18.5%) and shows great potential for integration into various architectures. ",
    "url": "https://arxiv.org/abs/2308.01520",
    "authors": [
      "Cong Zhang",
      "Honggang Qi",
      "Yuezun Li",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01526",
    "title": "Data Augmentation for Human Behavior Analysis in Multi-Person  Conversations",
    "abstract": "In this paper, we present the solution of our team HFUT-VUT for the MultiMediate Grand Challenge 2023 at ACM Multimedia 2023. The solution covers three sub-challenges: bodily behavior recognition, eye contact detection, and next speaker prediction. We select Swin Transformer as the baseline and exploit data augmentation strategies to address the above three tasks. Specifically, we crop the raw video to remove the noise from other parts. At the same time, we utilize data augmentation to improve the generalization of the model. As a result, our solution achieves the best results of 0.6262 for bodily behavior recognition in terms of mean average precision and the accuracy of 0.7771 for eye contact detection on the corresponding test set. In addition, our approach also achieves comparable results of 0.5281 for the next speaker prediction in terms of unweighted average recall. ",
    "url": "https://arxiv.org/abs/2308.01526",
    "authors": [
      "Kun Li",
      "Dan Guo",
      "Guoliang Chen",
      "Feiyang Liu",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01529",
    "title": "Towards Fair and Privacy Preserving Federated Learning for the  Healthcare Domain",
    "abstract": "Federated learning enables data sharing in healthcare contexts where it might otherwise be difficult due to data-use-ordinances or security and communication constraints. Distributed and shared data models allow models to become generalizable and learn from heterogeneous clients. While addressing data security, privacy, and vulnerability considerations, data itself is not shared across nodes in a given learning network. On the other hand, FL models often struggle with variable client data distributions and operate on an assumption of independent and identically distributed data. As the field has grown, the notion of fairness-aware federated learning mechanisms has also been introduced and is of distinct significance to the healthcare domain where many sensitive groups and protected classes exist. In this paper, we create a benchmark methodology for FAFL mechanisms under various heterogeneous conditions on datasets in the healthcare domain typically outside the scope of current federated learning benchmarks, such as medical imaging and waveform data formats. Our results indicate considerable variation in how various FAFL schemes respond to high levels of data heterogeneity. Additionally, doing so under privacy-preserving conditions can create significant increases in network communication cost and latency compared to the typical federated learning scheme. ",
    "url": "https://arxiv.org/abs/2308.01529",
    "authors": [
      "Navya Annapareddy",
      "Yingzheng Liu",
      "Judy Fox"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.01537",
    "title": "Learning Causality-inspired Representation Consistency for Video Anomaly  Detection",
    "abstract": "Video anomaly detection is an essential yet challenging task in the multimedia community, with promising applications in smart cities and secure communities. Existing methods attempt to learn abstract representations of regular events with statistical dependence to model the endogenous normality, which discriminates anomalies by measuring the deviations to the learned distribution. However, conventional representation learning is only a crude description of video normality and lacks an exploration of its underlying causality. The learned statistical dependence is unreliable for diverse regular events in the real world and may cause high false alarms due to overgeneralization. Inspired by causal representation learning, we think that there exists a causal variable capable of adequately representing the general patterns of regular events in which anomalies will present significant variations. Therefore, we design a causality-inspired representation consistency (CRC) framework to implicitly learn the unobservable causal variables of normality directly from available normal videos and detect abnormal events with the learned representation consistency. Extensive experiments show that the causality-inspired normality is robust to regular events with label-independent shifts, and the proposed CRC framework can quickly and accurately detect various complicated anomalies from real-world surveillance videos. ",
    "url": "https://arxiv.org/abs/2308.01537",
    "authors": [
      "Yang Liu",
      "Zhaoyang Xia",
      "Mengyang Zhao",
      "Donglai Wei",
      "Yuzheng Wang",
      "Liu Siao",
      "Bobo Ju",
      "Gaoyun Fang",
      "Jing Liu",
      "Liang Song"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2308.01547",
    "title": "Get the Best of Both Worlds: Improving Accuracy and Transferability by  Grassmann Class Representation",
    "abstract": "We generalize the class vectors found in neural networks to linear subspaces (i.e.~points in the Grassmann manifold) and show that the Grassmann Class Representation (GCR) enables the simultaneous improvement in accuracy and feature transferability. In GCR, each class is a subspace and the logit is defined as the norm of the projection of a feature onto the class subspace. We integrate Riemannian SGD into deep learning frameworks such that class subspaces in a Grassmannian are jointly optimized with the rest model parameters. Compared to the vector form, the representative capability of subspaces is more powerful. We show that on ImageNet-1K, the top-1 error of ResNet50-D, ResNeXt50, Swin-T and Deit3-S are reduced by 5.6%, 4.5%, 3.0% and 3.5%, respectively. Subspaces also provide freedom for features to vary and we observed that the intra-class feature variability grows when the subspace dimension increases. Consequently, we found the quality of GCR features is better for downstream tasks. For ResNet50-D, the average linear transfer accuracy across 6 datasets improves from 77.98% to 79.70% compared to the strong baseline of vanilla softmax. For Swin-T, it improves from 81.5% to 83.4% and for Deit3, it improves from 73.8% to 81.4%. With these encouraging results, we believe that more applications could benefit from the Grassmann class representation. Code is released at https://github.com/innerlee/GCR. ",
    "url": "https://arxiv.org/abs/2308.01547",
    "authors": [
      "Haoqi Wang",
      "Zhizhong Li",
      "Wayne Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01556",
    "title": "A Global Transport Capacity Risk Prediction Method for Rail Transit  Based on Gaussian Bayesian Network",
    "abstract": "Aiming at the prediction problem of transport capacity risk caused by the mismatch between the carrying capacity of rail transit network and passenger flow demand, this paper proposes an explainable prediction method of rail transit network transport capacity risk based on linear Gaussian Bayesian network. This method obtains the training data of the prediction model based on the simulation model of the rail transit system with a three-layer structure including rail transit network, train flow and passenger flow. A Bayesian network structure construction method based on the topology of the rail transit network is proposed, and the MLE (Maximum Likelihood Estimation) method is used to realize the parameter learning of the Bayesian network. Finally, the effectiveness of the proposed method is verified by simulation examples. ",
    "url": "https://arxiv.org/abs/2308.01556",
    "authors": [
      "Zhang Zhengyang",
      "Dong Wei",
      "Liu jun",
      "Sun Xinya",
      "Ji Yindong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01573",
    "title": "Adversarial Training of Denoising Diffusion Model Using Dual  Discriminators for High-Fidelity Multi-Speaker TTS",
    "abstract": "The diffusion model is capable of generating high-quality data through a probabilistic approach. However, it suffers from the drawback of slow generation speed due to the requirement of a large number of time steps. To address this limitation, recent models such as denoising diffusion implicit models (DDIM) focus on generating samples without directly modeling the probability distribution, while models like denoising diffusion generative adversarial networks (GAN) combine diffusion processes with GANs. In the field of speech synthesis, a recent diffusion speech synthesis model called DiffGAN-TTS, utilizing the structure of GANs, has been introduced and demonstrates superior performance in both speech quality and generation speed. In this paper, to further enhance the performance of DiffGAN-TTS, we propose a speech synthesis model with two discriminators: a diffusion discriminator for learning the distribution of the reverse process and a spectrogram discriminator for learning the distribution of the generated data. Objective metrics such as structural similarity index measure (SSIM), mel-cepstral distortion (MCD), F0 root mean squared error (F0 RMSE), short-time objective intelligibility (STOI), perceptual evaluation of speech quality (PESQ), as well as subjective metrics like mean opinion score (MOS), are used to evaluate the performance of the proposed model. The evaluation results show that the proposed model outperforms recent state-of-the-art models such as FastSpeech2 and DiffGAN-TTS in various metrics. Our implementation and audio samples are located on GitHub. ",
    "url": "https://arxiv.org/abs/2308.01573",
    "authors": [
      "Myeongjin Ko",
      "Yong-Hoon Choi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.01574",
    "title": "Another Hamiltonian Cycle in Bipartite Pfaffian Graphs",
    "abstract": "We present a linear-time algorithm that, given as input (i) a bipartite Pfaffian graph $G$ of minimum degree three, (ii) a Hamiltonian cycle $H$ in $G$, and (iii) an edge $e$ in $H$, outputs at least three other Hamiltonian cycles through the edge $e$ in $G$. This linear-time complexity of finding another Hamiltonian cycle given one is in sharp contrast to the problem of deciding the existence of a Hamiltonian cycle, which is NP-complete already for cubic bipartite planar graphs; such graphs are Pfaffian. Also, without the degree requirement, we show that it is NP-hard to find another Hamiltonian cycle in a bipartite Pfaffian graph. We present further improved algorithms for finding optimal traveling salesperson tours and counting Hamiltonian cycles in bipartite planar graphs with running times that are not known to hold in general planar graphs. We prove our results by a new structural technique that efficiently witnesses each Hamiltonian cycle $H$ through an arbitrary fixed anchor edge $e$ in a bipartite Pfaffian graph using a two-coloring of the vertices as advice that is unique to $H$. Previous techniques -- the Cut&Count technique of Cygan et al. [FOCS'11, TALG'22] in particular -- were able to reduce the Hamiltonian cycle problem only to essentially counting problems; our results show that counting can be avoided by leveraging properties of bipartite Pfaffian graphs. Our technique also has purely graph-theoretical consequences; for example, we show that every cubic bipartite Pfaffian graph has either zero or at least six distinct Hamiltonian cycles; the latter case is tight for the cube graph. ",
    "url": "https://arxiv.org/abs/2308.01574",
    "authors": [
      "Andreas Bj\u00f6rklund",
      "Petteri Kaski",
      "Jesper Nederlof"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.01578",
    "title": "Unsupervised Representation Learning for Time Series: A Review",
    "abstract": "Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field. ",
    "url": "https://arxiv.org/abs/2308.01578",
    "authors": [
      "Qianwen Meng",
      "Hangwei Qian",
      "Yong Liu",
      "Yonghui Xu",
      "Zhiqi Shen",
      "Lizhen Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01602",
    "title": "Deep Learning-based surrogate models for parametrized PDEs: handling  geometric variability through graph neural networks",
    "abstract": "Mesh-based simulations play a key role when modeling complex physical systems that, in many disciplines across science and engineering, require the solution of parametrized time-dependent nonlinear partial differential equations (PDEs). In this context, full order models (FOMs), such as those relying on the finite element method, can reach high levels of accuracy, however often yielding intensive simulations to run. For this reason, surrogate models are developed to replace computationally expensive solvers with more efficient ones, which can strike favorable trade-offs between accuracy and efficiency. This work explores the potential usage of graph neural networks (GNNs) for the simulation of time-dependent PDEs in the presence of geometrical variability. In particular, we propose a systematic strategy to build surrogate models based on a data-driven time-stepping scheme where a GNN architecture is used to efficiently evolve the system. With respect to the majority of surrogate models, the proposed approach stands out for its ability of tackling problems with parameter dependent spatial domains, while simultaneously generalizing to different geometries and mesh resolutions. We assess the effectiveness of the proposed approach through a series of numerical experiments, involving both two- and three-dimensional problems, showing that GNNs can provide a valid alternative to traditional surrogate models in terms of computational efficiency and generalization to new scenarios. We also assess, from a numerical standpoint, the importance of using GNNs, rather than classical dense deep neural networks, for the proposed framework. ",
    "url": "https://arxiv.org/abs/2308.01602",
    "authors": [
      "Nicola Rares Franco",
      "Stefania Fresca",
      "Filippo Tombari",
      "Andrea Manzoni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01606",
    "title": "Unsupervised Multiplex Graph Learning with Complementary and Consistent  Information",
    "abstract": "Unsupervised multiplex graph learning (UMGL) has been shown to achieve significant effectiveness for different downstream tasks by exploring both complementary information and consistent information among multiple graphs. However, previous methods usually overlook the issues in practical applications, i.e., the out-of-sample issue and the noise issue. To address the above issues, in this paper, we propose an effective and efficient UMGL method to explore both complementary and consistent information. To do this, our method employs multiple MLP encoders rather than graph convolutional network (GCN) to conduct representation learning with two constraints, i.e., preserving the local graph structure among nodes to handle the out-of-sample issue, and maximizing the correlation of multiple node representations to handle the noise issue. Comprehensive experiments demonstrate that our proposed method achieves superior effectiveness and efficiency over the comparison methods and effectively tackles those two issues. Code is available at https://github.com/LarryUESTC/CoCoMG. ",
    "url": "https://arxiv.org/abs/2308.01606",
    "authors": [
      "Liang Peng",
      "Xin Wang",
      "Xiaofeng Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01613",
    "title": "Real-time Light Estimation and Neural Soft Shadows for AR Indoor  Scenarios",
    "abstract": "We present a pipeline for realistic embedding of virtual objects into footage of indoor scenes with focus on real-time AR applications. Our pipeline consists of two main components: A light estimator and a neural soft shadow texture generator. Our light estimation is based on deep neural nets and determines the main light direction, light color, ambient color and an opacity parameter for the shadow texture. Our neural soft shadow method encodes object-based realistic soft shadows as light direction dependent textures in a small MLP. We show that our pipeline can be used to integrate objects into AR scenes in a new level of realism in real-time. Our models are small enough to run on current mobile devices. We achieve runtimes of 9ms for light estimation and 5ms for neural shadows on an iPhone 11 Pro. ",
    "url": "https://arxiv.org/abs/2308.01613",
    "authors": [
      "Alexander Sommer",
      "Ulrich Schwanecke",
      "Elmar Sch\u00f6mer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.01618",
    "title": "A Survey on Deep Learning-based Spatio-temporal Action Detection",
    "abstract": "Spatio-temporal action detection (STAD) aims to classify the actions present in a video and localize them in space and time. It has become a particularly active area of research in computer vision because of its explosively emerging real-world applications, such as autonomous driving, visual surveillance, entertainment, etc. Many efforts have been devoted in recent years to building a robust and effective framework for STAD. This paper provides a comprehensive review of the state-of-the-art deep learning-based methods for STAD. Firstly, a taxonomy is developed to organize these methods. Next, the linking algorithms, which aim to associate the frame- or clip-level detection results together to form action tubes, are reviewed. Then, the commonly used benchmark datasets and evaluation metrics are introduced, and the performance of state-of-the-art models is compared. At last, this paper is concluded, and a set of potential research directions of STAD are discussed. ",
    "url": "https://arxiv.org/abs/2308.01618",
    "authors": [
      "Peng Wang",
      "Fanwei Zeng",
      "Yuntao Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01621",
    "title": "A Novel Convolutional Neural Network Architecture with a Continuous  Symmetry",
    "abstract": "This paper introduces a new Convolutional Neural Network (ConvNet) architecture inspired by a class of partial differential equations (PDEs) called quasi-linear hyperbolic systems. With comparable performance on image classification task, it allows for the modification of the weights via a continuous group of symmetry. This is a significant shift from traditional models where the architecture and weights are essentially fixed. We wish to promote the (internal) symmetry as a new desirable property for a neural network, and to draw attention to the PDE perspective in analyzing and interpreting ConvNets in the broader Deep Learning community. ",
    "url": "https://arxiv.org/abs/2308.01621",
    "authors": [
      "Yao Liu",
      "Hang Shao",
      "Bing Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.01626",
    "title": "Interleaving GANs with knowledge graphs to support design creativity for  book covers",
    "abstract": "An attractive book cover is important for the success of a book. In this paper, we apply Generative Adversarial Networks (GANs) to the book covers domain, using different methods for training in order to obtain better generated images. We interleave GANs with knowledge graphs to alter the input title to obtain multiple possible options for any given title, which are then used as an augmented input to the generator. Finally, we use the discriminator obtained during the training phase to select the best images generated with new titles. Our method performed better at generating book covers than previous attempts, and the knowledge graph gives better options to the book author or editor compared to using GANs alone. ",
    "url": "https://arxiv.org/abs/2308.01626",
    "authors": [
      "Alexandru Motogna",
      "Adrian Groza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01630",
    "title": "Erasure-based Interaction Network for RGBT Video Object Detection and A  Unified Benchmark",
    "abstract": "Recently, many breakthroughs are made in the field of Video Object Detection (VOD), but the performance is still limited due to the imaging limitations of RGB sensors in adverse illumination conditions. To alleviate this issue, this work introduces a new computer vision task called RGB-thermal (RGBT) VOD by introducing the thermal modality that is insensitive to adverse illumination conditions. To promote the research and development of RGBT VOD, we design a novel Erasure-based Interaction Network (EINet) and establish a comprehensive benchmark dataset (VT-VOD50) for this task. Traditional VOD methods often leverage temporal information by using many auxiliary frames, and thus have large computational burden. Considering that thermal images exhibit less noise than RGB ones, we develop a negative activation function that is used to erase the noise of RGB features with the help of thermal image features. Furthermore, with the benefits from thermal images, we rely only on a small temporal window to model the spatio-temporal information to greatly improve efficiency while maintaining detection accuracy. VT-VOD50 dataset consists of 50 pairs of challenging RGBT video sequences with complex backgrounds, various objects and different illuminations, which are collected in real traffic scenarios. Extensive experiments on VT-VOD50 dataset demonstrate the effectiveness and efficiency of our proposed method against existing mainstream VOD methods. The code of EINet and the dataset will be released to the public for free academic usage. ",
    "url": "https://arxiv.org/abs/2308.01630",
    "authors": [
      "Zhengzheng Tu",
      "Qishun Wang",
      "Hongshun Wang",
      "Kunpeng Wang",
      "Chenglong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01639",
    "title": "Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly  Detection",
    "abstract": "Electrocardiogram (ECG) is a widely used diagnostic tool for detecting heart conditions. Rare cardiac diseases may be underdiagnosed using traditional ECG analysis, considering that no training dataset can exhaust all possible cardiac disorders. This paper proposes using anomaly detection to identify any unhealthy status, with normal ECGs solely for training. However, detecting anomalies in ECG can be challenging due to significant inter-individual differences and anomalies present in both global rhythm and local morphology. To address this challenge, this paper introduces a novel multi-scale cross-restoration framework for ECG anomaly detection and localization that considers both local and global ECG characteristics. The proposed framework employs a two-branch autoencoder to facilitate multi-scale feature learning through a masking and restoration process, with one branch focusing on global features from the entire ECG and the other on local features from heartbeat-level details, mimicking the diagnostic process of cardiologists. Anomalies are identified by their high restoration errors. To evaluate the performance on a large number of individuals, this paper introduces a new challenging benchmark with signal point-level ground truths annotated by experienced cardiologists. The proposed method demonstrates state-of-the-art performance on this benchmark and two other well-known ECG datasets. The benchmark dataset and source code are available at: \\url{https://github.com/MediaBrain-SJTU/ECGAD} ",
    "url": "https://arxiv.org/abs/2308.01639",
    "authors": [
      "Aofan Jiang",
      "Chaoqin Huang",
      "Qing Cao",
      "Shuang Wu",
      "Zi Zeng",
      "Kang Chen",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01650",
    "title": "UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node  Classification",
    "abstract": "Graph and hypergraph representation learning has attracted increasing attention from various research fields. Despite the decent performance and fruitful applications of Graph Neural Networks (GNNs), Hypergraph Neural Networks (HGNNs), and their well-designed variants, on some commonly used benchmark graphs and hypergraphs, they are outperformed by even a simple Multi-Layer Perceptron. This observation motivates a reexamination of the design paradigm of the current GNNs and HGNNs and poses challenges of extracting graph features effectively. In this work, a universal feature encoder for both graph and hypergraph representation learning is designed, called UniG-Encoder. The architecture starts with a forward transformation of the topological relationships of connected nodes into edge or hyperedge features via a normalized projection matrix. The resulting edge/hyperedge features, together with the original node features, are fed into a neural network. The encoded node embeddings are then derived from the reversed transformation, described by the transpose of the projection matrix, of the network's output, which can be further used for tasks such as node classification. The proposed architecture, in contrast to the traditional spectral-based and/or message passing approaches, simultaneously and comprehensively exploits the node features and graph/hypergraph topologies in an efficient and unified manner, covering both heterophilic and homophilic graphs. The designed projection matrix, encoding the graph features, is intuitive and interpretable. Extensive experiments are conducted and demonstrate the superior performance of the proposed framework on twelve representative hypergraph datasets and six real-world graph datasets, compared to the state-of-the-art methods. Our implementation is available online at https://github.com/MinhZou/UniG-Encoder. ",
    "url": "https://arxiv.org/abs/2308.01650",
    "authors": [
      "Minhao Zou",
      "Zhongxue Gan",
      "Yutong Wang",
      "Junheng Zhang",
      "Dongyan Sui",
      "Chun Guan",
      "Siyang Leng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01651",
    "title": "lifex-ep: a robust and efficient software for cardiac electrophysiology  simulations",
    "abstract": "Simulating the cardiac function requires the numerical solution of multi-physics and multi-scale mathematical models. This underscores the need for streamlined, accurate, and high-performance computational tools. Despite the dedicated endeavors of various research teams, comprehensive and user-friendly software programs for cardiac simulations are still in the process of achieving full maturity within the scientific community. This work introduces lifex-ep, a publicly available software for numerical simulations of the electrophysiology activity of the cardiac muscle, under both physiological and pathological conditions. lifex-ep employs the monodomain equation to model the heart's electrical activity. It incorporates both phenomenological and second-generation ionic models. These models are discretized using the Finite Element method on tetrahedral or hexahedral meshes. Additionally, lifex-ep integrates the generation of myocardial fibers based on Laplace-Dirichlet Rule-Based Methods, previously released in Africa et al., 2023, within lifex-fiber. This paper provides a concise overview of the mathematical models and numerical methods underlying lifex-ep, along with comprehensive implementation details and instructions for users. lifex-ep features exceptional parallel speedup, scaling efficiently when using up to thousands of cores, and its implementation has been verified against an established benchmark problem for computational electrophysiology. We showcase the key features of lifex-ep through various idealized and realistic simulations. lifex-ep offers a user-friendly and flexible interface. lifex-ep provides easy access to cardiac electrophysiology simulations for a wide user community. It offers a computational tool that integrates models and accurate methods for simulating cardiac electrophysiology within a high-performance framework, while maintaining a user-friendly interface. ",
    "url": "https://arxiv.org/abs/2308.01651",
    "authors": [
      "Pasquale C. Africa",
      "Roberto Piersanti",
      "Francesco Regazzoni",
      "Michele Bucelli",
      "Matteo Salvador",
      "Marco Fedele",
      "Stefano Pagani",
      "Luca Dede'",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.01682",
    "title": "Evaluating Link Prediction Explanations for Graph Neural Networks",
    "abstract": "Graph Machine Learning (GML) has numerous applications, such as node/graph classification and link prediction, in real-world domains. Providing human-understandable explanations for GML models is a challenging yet fundamental task to foster their adoption, but validating explanations for link prediction models has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations. ",
    "url": "https://arxiv.org/abs/2308.01682",
    "authors": [
      "Claudio Borile",
      "Alan Perotti",
      "Andr\u00e9 Panisson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01707",
    "title": "Joint Out-of-Distribution Detection and Uncertainty Estimation for  Trajectory Predictio",
    "abstract": "Despite the significant research efforts on trajectory prediction for automated driving, limited work exists on assessing the prediction reliability. To address this limitation we propose an approach that covers two sources of error, namely novel situations with out-of-distribution (OOD) detection and the complexity in in-distribution (ID) situations with uncertainty estimation. We introduce two modules next to an encoder-decoder network for trajectory prediction. Firstly, a Gaussian mixture model learns the probability density function of the ID encoder features during training, and then it is used to detect the OOD samples in regions of the feature space with low likelihood. Secondly, an error regression network is applied to the encoder, which learns to estimate the trajectory prediction error in supervised training. During inference, the estimated prediction error is used as the uncertainty. In our experiments, the combination of both modules outperforms the prior work in OOD detection and uncertainty estimation, on the Shifts robust trajectory prediction dataset by $2.8 \\%$ and $10.1 \\%$, respectively. The code is publicly available. ",
    "url": "https://arxiv.org/abs/2308.01707",
    "authors": [
      "Julian Wiederer",
      "Julian Schmidt",
      "Ulrich Kressel",
      "Klaus Dietmayer",
      "Vasileios Belagiannis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01722",
    "title": "Relational hyperevent models for the coevolution of coauthoring and  citation networks",
    "abstract": "Interest in the network analysis of bibliographic data has increased significantly in recent years. Yet, appropriate statistical models for examining the full dynamics of scientific citation networks, connecting authors to the papers they write and papers to other papers they cite, are not available. Very few studies exist that have examined how the social network between co-authors and the citation network among the papers shape one another and co-evolve. In consequence, our understanding of scientific citation networks remains incomplete. In this paper we extend recently derived relational hyperevent models (RHEM) to the analysis of scientific networks, providing a general framework to model the multiple dependencies involved in the relation linking multiple authors to the papers they write, and papers to the multiple references they cite. We demonstrate the empirical value of our model in an analysis of publicly available data on a scientific network comprising millions of authors and papers and assess the relative strength of various effects explaining scientific production. We outline the implications of the model for the evaluation of scientific research. ",
    "url": "https://arxiv.org/abs/2308.01722",
    "authors": [
      "J\u00fcrgen Lerner",
      "Marian-Gabriel H\u00e2ncean",
      "Alessandro Lomi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2308.01725",
    "title": "NeuroSwarm: Multi-Agent Neural 3D Scene Reconstruction and Segmentation  with UAV for Optimal Navigation of Quadruped Robot",
    "abstract": "Quadruped robots have the distinct ability to adapt their body and step height to navigate through cluttered environments. Nonetheless, for these robots to utilize their full potential in real-world scenarios, they require awareness of their environment and obstacle geometry. We propose a novel multi-agent robotic system that incorporates cutting-edge technologies. The proposed solution features a 3D neural reconstruction algorithm that enables navigation of a quadruped robot in both static and semi-static environments. The prior areas of the environment are also segmented according to the quadruped robots' abilities to pass them. Moreover, we have developed an adaptive neural field optimal motion planner (ANFOMP) that considers both collision probability and obstacle height in 2D space.Our new navigation and mapping approach enables quadruped robots to adjust their height and behavior to navigate under arches and push through obstacles with smaller dimensions. The multi-agent mapping operation has proven to be highly accurate, with an obstacle reconstruction precision of 82%. Moreover, the quadruped robot can navigate with 3D obstacle information and the ANFOMP system, resulting in a 33.3% reduction in path length and a 70% reduction in navigation time. ",
    "url": "https://arxiv.org/abs/2308.01725",
    "authors": [
      "Iana Zhura",
      "Denis Davletshin",
      "Nipun Dhananjaya Weerakkodi Mudalige",
      "Aleksey Fedoseev",
      "Robinroy Peter",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01727",
    "title": "Local Large Language Models for Complex Structured Medical Tasks",
    "abstract": "This paper introduces an approach that combines the language reasoning capabilities of large language models (LLMs) with the benefits of local training to tackle complex, domain-specific tasks. Specifically, the authors demonstrate their approach by extracting structured condition codes from pathology reports. The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs. The authors collected a dataset of over 150k uncurated surgical pathology reports, containing gross descriptions, final diagnoses, and condition codes. They trained different model architectures, including LLaMA, BERT and LongFormer and evaluated their performance. The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, even with extremely reduced precision. The LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-label tasks. Overall, this work presents an effective approach for utilizing LLMs to perform domain-specific tasks using accessible hardware, with potential applications in the medical domain, where complex data extraction and classification are required. ",
    "url": "https://arxiv.org/abs/2308.01727",
    "authors": [
      "V. K. Cody Bumgardner",
      "Aaron Mullen",
      "Sam Armstrong",
      "Caylin Hickey",
      "Jeff Talbert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01734",
    "title": "Ambient Adventures: Teaching ChatGPT on Developing Complex Stories",
    "abstract": "Imaginative play is an area of creativity that could allow robots to engage with the world around them in a much more personified way. Imaginary play can be seen as taking real objects and locations and using them as imaginary objects and locations in virtual scenarios. We adopted the story generation capability of large language models (LLMs) to obtain the stories used for imaginary play with human-written prompts. Those generated stories will be simplified and mapped into action sequences that can guide the agent in imaginary play. To evaluate whether the agent can successfully finish the imaginary play, we also designed a text adventure game to simulate a house as the playground for the agent to interact. ",
    "url": "https://arxiv.org/abs/2308.01734",
    "authors": [
      "Zexin Chen",
      "Eric Zhou",
      "Kenneth Eaton",
      "Xiangyu Peng",
      "Mark Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.01737",
    "title": "MAP: A Model-agnostic Pretraining Framework for Click-through Rate  Prediction",
    "abstract": "With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume. The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations. However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary. To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining. Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction. ",
    "url": "https://arxiv.org/abs/2308.01737",
    "authors": [
      "Jianghao Lin",
      "Yanru Qu",
      "Wei Guo",
      "Xinyi Dai",
      "Ruiming Tang",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01746",
    "title": "Neural Collapse Terminus: A Unified Solution for Class Incremental  Learning and Its Variants",
    "abstract": "How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning. Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting. Existing methods are specifically proposed for one of the three tasks. In this paper, we offer a unified solution to the misalignment dilemma in the three tasks. Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space. It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally. For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly. Our method also works for FSCIL with only minor adaptations. Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity. We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method. Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case. ",
    "url": "https://arxiv.org/abs/2308.01746",
    "authors": [
      "Yibo Yang",
      "Haobo Yuan",
      "Xiangtai Li",
      "Jianlong Wu",
      "Lefei Zhang",
      "Zhouchen Lin",
      "Philip Torr",
      "Dacheng Tao",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01750",
    "title": "Entropy-based detection of Twitter echo chambers",
    "abstract": "The presence of echo chambers, i.e. clusters of users exposed to news or opinions in line with their previous beliefs, was observed in many online debates on social platforms. Users form an echo chamber when two different phenomena appear at the same time: 1. users interact with ones sharing similar opinions; 2. users with similar opinions refer to the same pieces of news. We propose a completely unbiased entropy-based procedure to spot echo chambers. Remarkably, the method is completely agnostic about the nature of the data. In the Italian Twitter debate about Covid-19 vaccination, we find a limited presence of users in echo chambers (around 0.35% of all users), due to the limited number of validated users who are exposed to the same news. Nevertheless, their impact on the formation of a common discourse is strong, since echo chambers are responsible for nearly one-third of retweets of their discursive communities. ",
    "url": "https://arxiv.org/abs/2308.01750",
    "authors": [
      "Manuel Pratelli",
      "Fabio Saracco",
      "Marinella Petrocchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2308.01766",
    "title": "PoissonNet: Resolution-Agnostic 3D Shape Reconstruction using Fourier  Neural Operators",
    "abstract": "We introduce PoissonNet, an architecture for shape reconstruction that addresses the challenge of recovering 3D shapes from points. Traditional deep neural networks face challenges with common 3D shape discretization techniques due to their computational complexity at higher resolutions. To overcome this, we leverage Fourier Neural Operators (FNOs) to solve the Poisson equation and reconstruct a mesh from oriented point cloud measurements. PoissonNet exhibits two main advantages. First, it enables efficient training on low-resolution data while achieving comparable performance at high-resolution evaluation, thanks to the resolution-agnostic nature of FNOs. This feature allows for one-shot super-resolution. Second, our method surpasses existing approaches in reconstruction quality while being differentiable. Overall, our proposed method not only improves upon the limitations of classical deep neural networks in shape reconstruction but also achieves superior results in terms of reconstruction quality, running time, and resolution flexibility. Furthermore, we demonstrate that the Poisson surface reconstruction problem is well-posed in the limit case by showing a universal approximation theorem for the solution operator of the Poisson equation with distributional data utilizing the Fourier Neuronal Operator, which provides a theoretical foundation for our numerical results. The code to reproduce the experiments is available on: \\url{https://github.com/arsenal9971/PoissonNet}. ",
    "url": "https://arxiv.org/abs/2308.01766",
    "authors": [
      "Hector Andrade-Loarca",
      "Aras Bacho",
      "Julius Hege",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2308.01771",
    "title": "Deep Learning-based Prediction of Stress and Strain Maps in Arterial  Walls for Improved Cardiovascular Risk Assessment",
    "abstract": "This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall. We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections. Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations. On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps. Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps. The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set. Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain. Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set. Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions. ",
    "url": "https://arxiv.org/abs/2308.01771",
    "authors": [
      "Yasin Shokrollahi1",
      "Pengfei Dong1",
      "Xianqi Li",
      "Linxia Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.01813",
    "title": "Deep Neural Networks Fused with Textures for Image Classification",
    "abstract": "Fine-grained image classification (FGIC) is a challenging task in computer vision for due to small visual differences among inter-subcategories, but, large intra-class variations. Deep learning methods have achieved remarkable success in solving FGIC. In this paper, we propose a fusion approach to address FGIC by combining global texture with local patch-based information. The first pipeline extracts deep features from various fixed-size non-overlapping patches and encodes features by sequential modelling using the long short-term memory (LSTM). Another path computes image-level textures at multiple scales using the local binary patterns (LBP). The advantages of both streams are integrated to represent an efficient feature vector for image classification. The method is tested on eight datasets representing the human faces, skin lesions, food dishes, marine lives, etc. using four standard backbone CNNs. Our method has attained better classification accuracy over existing methods with notable margins. ",
    "url": "https://arxiv.org/abs/2308.01813",
    "authors": [
      "Asish Bera",
      "Debotosh Bhattacharjee",
      "Mita Nasipuri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01823",
    "title": "Hard Adversarial Example Mining for Improving Robust Fairness",
    "abstract": "Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE). Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2308.01823",
    "authors": [
      "Chenhao Lin",
      "Xiang Ji",
      "Yulong Yang",
      "Qian Li",
      "Chao Shen",
      "Run Wang",
      "Liming Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2308.01831",
    "title": "Many-to-Many Spoken Language Translation via Unified Speech and Text  Representation Learning with Unit-to-Unit Translation",
    "abstract": "In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis. We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model. Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text. Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data. Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting. Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages. A single pre-trained model with UTUT can be employed for diverse multilingual speech- and text-related tasks, such as Speech-to-Speech Translation (STS), multilingual Text-to-Speech Synthesis (TTS), and Text-to-Speech Translation (TTST). By conducting comprehensive experiments encompassing various languages, we validate the efficacy of the proposed method across diverse multilingual tasks. Moreover, we show UTUT can perform many-to-many language STS, which has not been previously explored in the literature. Samples are available on https://choijeongsoo.github.io/utut. ",
    "url": "https://arxiv.org/abs/2308.01831",
    "authors": [
      "Minsu Kim",
      "Jeongsoo Choi",
      "Dahun Kim",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.01833",
    "title": "Sim-to-Real Vision-depth Fusion CNNs for Robust Pose Estimation Aboard  Autonomous Nano-quadcopter",
    "abstract": "Nano-quadcopters are versatile platforms attracting the interest of both academia and industry. Their tiny form factor, i.e., $\\,$10 cm diameter, makes them particularly useful in narrow scenarios and harmless in human proximity. However, these advantages come at the price of ultra-constrained onboard computational and sensorial resources for autonomous operations. This work addresses the task of estimating human pose aboard nano-drones by fusing depth and images in a novel CNN exclusively trained in simulation yet capable of robust predictions in the real world. We extend a commercial off-the-shelf (COTS) Crazyflie nano-drone -- equipped with a 320$\\times$240 px camera and an ultra-low-power System-on-Chip -- with a novel multi-zone (8$\\times$8) depth sensor. We design and compare different deep-learning models that fuse depth and image inputs. Our models are trained exclusively on simulated data for both inputs, and transfer well to the real world: field testing shows an improvement of 58% and 51% of our depth+camera system w.r.t. a camera-only State-of-the-Art baseline on the horizontal and angular mean pose errors, respectively. Our prototype is based on COTS components, which facilitates reproducibility and adoption of this novel class of systems. ",
    "url": "https://arxiv.org/abs/2308.01833",
    "authors": [
      "Luca Crupi",
      "Elia Cereda",
      "Alessandro Giusti",
      "Daniele Palossi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01840",
    "title": "URET: Universal Robustness Evaluation Toolkit (for Evasion)",
    "abstract": "Machine learning models are known to be vulnerable to adversarial evasion attacks as illustrated by image classification models. Thoroughly understanding such attacks is critical in order to ensure the safety and robustness of critical AI tasks. However, most evasion attacks are difficult to deploy against a majority of AI systems because they have focused on image domain with only few constraints. An image is composed of homogeneous, numerical, continuous, and independent features, unlike many other input types to AI systems used in practice. Furthermore, some input types include additional semantic and functional constraints that must be observed to generate realistic adversarial inputs. In this work, we propose a new framework to enable the generation of adversarial inputs irrespective of the input type and task domain. Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input. We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations. We also show the importance of generating adversarial examples as they enable the deployment of mitigation techniques. ",
    "url": "https://arxiv.org/abs/2308.01840",
    "authors": [
      "Kevin Eykholt",
      "Taesung Lee",
      "Douglas Schales",
      "Jiyong Jang",
      "Ian Molloy",
      "Masha Zorin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.01861",
    "title": "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on  Class-level Code Generation",
    "abstract": "In this work, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e. class-level code generation. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on it, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we have the following main findings. First, we find that all existing LLMs show much worse performance on class-level code generation compared to on standalone method-level code generation benchmarks like HumanEval; and the method-level coding ability cannot equivalently reflect the class-level coding ability among LLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior than other LLMs on class-level code generation, and the second-tier models includes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very similar performance. Third, we find that generating the entire class all at once (i.e. holistic generation strategy) is the best generation strategy only for GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and compositional) is better strategies for the other models with limited ability of understanding long instructions and utilizing the middle information. Lastly, we find the limited model ability of generating method-dependent code and discuss the frequent error types in generated classes. Our benchmark is available at https://github.com/FudanSELab/ClassEval. ",
    "url": "https://arxiv.org/abs/2308.01861",
    "authors": [
      "Xueying Du",
      "Mingwei Liu",
      "Kaixin Wang",
      "Hanlin Wang",
      "Junwei Liu",
      "Yixuan Chen",
      "Jiayi Feng",
      "Chaofeng Sha",
      "Xin Peng",
      "Yiling Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01862",
    "title": "Wider and Deeper LLM Networks are Fairer LLM Evaluators",
    "abstract": "Measuring the quality of responses generated by LLMs is a challenging task, particularly when it comes to evaluating whether the response is aligned with human preference. A novel approach involves using the LLM itself to make evaluation and stabilizing the results through multiple independent evaluations, similar to a single-layer narrow LLM network. This network consists of a fixed number of neurons, with each neuron being the same LLM. In this paper, we draw upon the extensive research on deep neural networks to explore whether deeper and wider networks can lead to fairer evaluations. Specifically, inspired by the observation that different neurons in a neural network are responsible for detecting different concepts, we first adaptively generate as many neuron roles as possible for each evaluation sample. Each perspective corresponds to the role of a specific LLM neuron in the first layer. In subsequent layers, we follow the idea that higher layers in deep networks are responsible for more comprehensive features, each layer receives representations from all neurons in the previous layer, integrating the locally learned evaluation information to obtain a more comprehensive evaluation result. Interestingly, this network design resembles the process of academic paper reviewing. To validate the effectiveness of our method, we construct the largest and most diverse English evaluation benchmark LLMEval$^2$ for LLM evaluators, comprising 15 tasks, 8 abilities, and 2,553 samples. Experimental results demonstrate that a wider network (involving many reviewers) with 2 layers (one round of discussion) performs the best, improving kappa correlation coefficient from 0.28 to 0.34. We also leverage WideDeep to aid in the assessment of Chinese LLMs, which has accelerated the evaluation time by 4.6 times, resulting in a 60% cost saving. WideDeep achieves a remarkable 93% agreement level among humans. ",
    "url": "https://arxiv.org/abs/2308.01862",
    "authors": [
      "Xinghua Zhang",
      "Bowen Yu",
      "Haiyang Yu",
      "Yangyu Lv",
      "Tingwen Liu",
      "Fei Huang",
      "Hongbo Xu",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.01863",
    "title": "Tag Prediction of Competitive Programming Problems using Deep Learning  Techniques",
    "abstract": "In the past decade, the amount of research being done in the fields of machine learning and deep learning, predominantly in the area of natural language processing (NLP), has risen dramatically. A well-liked method for developing programming abilities like logic building and problem solving is competitive programming. It can be tough for novices and even veteran programmers to traverse the wide collection of questions due to the massive number of accessible questions and the variety of themes, levels of difficulty, and questions offered. In order to help programmers find questions that are appropriate for their knowledge and interests, there is a need for an automated method. This can be done using automated tagging of the questions using Text Classification. Text classification is one of the important tasks widely researched in the field of Natural Language Processing. In this paper, we present a way to use text classification techniques to determine the domain of a competitive programming problem. A variety of models, including are implemented LSTM, GRU, and MLP. The dataset has been scraped from Codeforces, a major competitive programming website. A total of 2400 problems were scraped and preprocessed, which we used as a dataset for our training and testing of models. The maximum accuracy reached using our model is 78.0% by MLP(Multi Layer Perceptron). ",
    "url": "https://arxiv.org/abs/2308.01863",
    "authors": [
      "Taha Lokat",
      "Divyam Prajapati",
      "Shubhada Labde"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.01888",
    "title": "FROD: Robust Object Detection for Free",
    "abstract": "Object detection is a vital task in computer vision and has become an integral component of numerous critical systems. However, state-of-the-art object detectors, similar to their classification counterparts, are susceptible to small adversarial perturbations that can significantly alter their normal behavior. Unlike classification, the robustness of object detectors has not been thoroughly explored. In this work, we take the initial step towards bridging the gap between the robustness of classification and object detection by leveraging adversarially trained classification models. Merely utilizing adversarially trained models as backbones for object detection does not result in robustness. We propose effective modifications to the classification-based backbone to instill robustness in object detection without incurring any computational overhead. To further enhance the robustness achieved by the proposed modified backbone, we introduce two lightweight components: imitation loss and delayed adversarial training. Extensive experiments on the MS-COCO and Pascal VOC datasets are conducted to demonstrate the effectiveness of our proposed approach. ",
    "url": "https://arxiv.org/abs/2308.01888",
    "authors": [
      "Muhammad",
      "Awais",
      "Weiming",
      "Zhuang",
      "Lingjuan",
      "Sung-Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01898",
    "title": "UniSim: A Neural Closed-Loop Sensor Simulator",
    "abstract": "Rigorously testing autonomy systems is essential for making safe self-driving vehicles (SDV) a reality. It requires one to generate safety critical scenarios beyond what can be collected safely in the world, as many scenarios happen rarely on public roads. To accurately evaluate performance, we need to test the SDV on these scenarios in closed-loop, where the SDV and other actors interact with each other at each timestep. Previously recorded driving logs provide a rich resource to build these new scenarios from, but for closed loop evaluation, we need to modify the sensor data based on the new scene configuration and the SDV's decisions, as actors might be added or removed and the trajectories of existing actors and the SDV will differ from the original log. In this paper, we present UniSim, a neural sensor simulator that takes a single recorded log captured by a sensor-equipped vehicle and converts it into a realistic closed-loop multi-sensor simulation. UniSim builds neural feature grids to reconstruct both the static background and dynamic actors in the scene, and composites them together to simulate LiDAR and camera data at new viewpoints, with actors added or removed and at new placements. To better handle extrapolated views, we incorporate learnable priors for dynamic objects, and leverage a convolutional network to complete unseen regions. Our experiments show UniSim can simulate realistic sensor data with small domain gap on downstream tasks. With UniSim, we demonstrate closed-loop evaluation of an autonomy system on safety-critical scenarios as if it were in the real world. ",
    "url": "https://arxiv.org/abs/2308.01898",
    "authors": [
      "Ze Yang",
      "Yun Chen",
      "Jingkang Wang",
      "Sivabalan Manivasagam",
      "Wei-Chiu Ma",
      "Anqi Joyce Yang",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01318",
    "title": "Framing image registration as a landmark detection problem for better  representation of clinical relevance",
    "abstract": "Nowadays, registration methods are typically evaluated based on sub-resolution tracking error differences. In an effort to reinfuse this evaluation process with clinical relevance, we propose to reframe image registration as a landmark detection problem. Ideally, landmark-specific detection thresholds are derived from an inter-rater analysis. To approximate this costly process, we propose to compute hit rate curves based on the distribution of errors of a sub-sample inter-rater analysis. Therefore, we suggest deriving thresholds from the error distribution using the formula: median + delta * median absolute deviation. The method promises differentiation of previously indistinguishable registration algorithms and further enables assessing the clinical significance in algorithm development. ",
    "url": "https://arxiv.org/abs/2308.01318",
    "authors": [
      "Diana Waldmannstetter",
      "Benedikt Wiestler",
      "Julian Schwarting",
      "Ivan Ezhov",
      "Marie Metz",
      "Spyridon Bakas",
      "Bhakti Baheti",
      "Satrajit Chakrabarty",
      "Jan S. Kirschke",
      "Rolf A. Heckemann",
      "Marie Piraud",
      "Florian Kofler",
      "Bjoern H. Menze"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2308.01362",
    "title": "Explainable Deep Learning for Tumor Dynamic Modeling and Overall  Survival Prediction using Neural-ODE",
    "abstract": "While tumor dynamic modeling has been widely applied to support the development of oncology drugs, there remains a need to increase predictivity, enable personalized therapy, and improve decision-making. We propose the use of Tumor Dynamic Neural-ODE (TDNODE) as a pharmacology-informed neural network to enable model discovery from longitudinal tumor size data. We show that TDNODE overcomes a key limitation of existing models in its ability to make unbiased predictions from truncated data. The encoder-decoder architecture is designed to express an underlying dynamical law which possesses the fundamental property of generalized homogeneity with respect to time. Thus, the modeling formalism enables the encoder output to be interpreted as kinetic rate metrics, with inverse time as the physical unit. We show that the generated metrics can be used to predict patients' overall survival (OS) with high accuracy. The proposed modeling formalism provides a principled way to integrate multimodal dynamical datasets in oncology disease modeling. ",
    "url": "https://arxiv.org/abs/2308.01362",
    "authors": [
      "Mark Laurie",
      "James Lu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01419",
    "title": "Graph Neural Networks for Forecasting Multivariate Realized Volatility  with Spillover Effects",
    "abstract": "We present a novel methodology for modeling and forecasting multivariate realized volatilities using customized graph neural networks to incorporate spillover effects across stocks. The proposed model offers the benefits of incorporating spillover effects from multi-hop neighbors, capturing nonlinear relationships, and flexible training with different loss functions. Our empirical findings provide compelling evidence that incorporating spillover effects from multi-hop neighbors alone does not yield a clear advantage in terms of predictive accuracy. However, modeling nonlinear spillover effects enhances the forecasting accuracy of realized volatilities, particularly for short-term horizons of up to one week. Moreover, our results consistently indicate that training with the Quasi-likelihood loss leads to substantial improvements in model performance compared to the commonly-used mean squared error. A comprehensive series of empirical evaluations in alternative settings confirm the robustness of our results. ",
    "url": "https://arxiv.org/abs/2308.01419",
    "authors": [
      "Chao Zhang",
      "Xingyue Pu",
      "Mihai Cucuringu",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2308.01467",
    "title": "EDMD for expanding circle maps and their complex perturbations",
    "abstract": "We show that spectral data of the Koopman operator arising from an analytic expanding circle map $\\tau$ can be effectively calculated using an EDMD-type algorithm combining a collocation method of order m with a Galerkin method of order n. The main result is that if $m \\geq \\delta n$, where $\\delta$ is an explicitly given positive number quantifying by how much $\\tau$ expands concentric annuli containing the unit circle, then the method converges and approximates the spectrum of the Koopman operator, taken to be acting on a space of analytic hyperfunctions, exponentially fast in n. Additionally, these results extend to more general expansive maps on suitable annuli containing the unit circle. ",
    "url": "https://arxiv.org/abs/2308.01467",
    "authors": [
      "Oscar F. Bandtlow",
      "Wolfram Just",
      "Julia Slipantschuk"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.01538",
    "title": "Non-equilibrium physics: from spin glasses to machine and neural  learning",
    "abstract": "Disordered many-body systems exhibit a wide range of emergent phenomena across different scales. These complex behaviors can be utilized for various information processing tasks such as error correction, learning, and optimization. Despite the empirical success of utilizing these systems for intelligent tasks, the underlying principles that govern their emergent intelligent behaviors remain largely unknown. In this thesis, we aim to characterize such emergent intelligence in disordered systems through statistical physics. We chart a roadmap for our efforts in this thesis based on two axes: learning mechanisms (long-term memory vs. working memory) and learning dynamics (artificial vs. natural). Throughout our journey, we uncover relationships between learning mechanisms and physical dynamics that could serve as guiding principles for designing intelligent systems. We hope that our investigation into the emergent intelligence of seemingly disparate learning systems can expand our current understanding of intelligence beyond neural systems and uncover a wider range of computational substrates suitable for AI applications. ",
    "url": "https://arxiv.org/abs/2308.01538",
    "authors": [
      "Weishun Zhong"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.01729",
    "title": "Telematics Combined Actuarial Neural Networks for Cross-Sectional and  Longitudinal Claim Count Data",
    "abstract": "We present novel cross-sectional and longitudinal claim count models for vehicle insurance built upon the Combined Actuarial Neural Network (CANN) framework proposed by Mario W\\\"uthrich and Michael Merz. The CANN approach combines a classical actuarial model, such as a generalized linear model, with a neural network. This blending of models results in a two-component model comprising a classical regression model and a neural network part. The CANN model leverages the strengths of both components, providing a solid foundation and interpretability from the classical model while harnessing the flexibility and capacity to capture intricate relationships and interactions offered by the neural network. In our proposed models, we use well-known log-linear claim count regression models for the classical regression part and a multilayer perceptron (MLP) for the neural network part. The MLP part is used to process telematics car driving data given as a vector characterizing the driving behavior of each insured driver. In addition to the Poisson and negative binomial distributions for cross-sectional data, we propose a procedure for training our CANN model with a multivariate negative binomial (MVNB) specification. By doing so, we introduce a longitudinal model that accounts for the dependence between contracts from the same insured. Our results reveal that the CANN models exhibit superior performance compared to log-linear models that rely on manually engineered telematics features. ",
    "url": "https://arxiv.org/abs/2308.01729",
    "authors": [
      "Francis Duval",
      "Jean-Philippe Boucher",
      "Mathieu Pigeon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.03110",
    "title": "Successor Feature Neural Episodic Control",
    "abstract": " Title: Successor Feature Neural Episodic Control ",
    "url": "https://arxiv.org/abs/2111.03110",
    "authors": [
      "David Emukpere",
      "Xavier Alameda-Pineda",
      "Chris Reinke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.07901",
    "title": "Auxiliary Cross-Modal Representation Learning with Triplet Loss  Functions for Online Handwriting Recognition",
    "abstract": " Title: Auxiliary Cross-Modal Representation Learning with Triplet Loss  Functions for Online Handwriting Recognition ",
    "url": "https://arxiv.org/abs/2202.07901",
    "authors": [
      "Felix Ott",
      "David R\u00fcgamer",
      "Lucas Heublein",
      "Bernd Bischl",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.10903",
    "title": "Confident Neural Network Regression with Bootstrapped Deep Ensembles",
    "abstract": " Comments: 20 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2202.10903",
    "authors": [
      "Laurens Sluijterman",
      "Eric Cator",
      "Tom Heskes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04177",
    "title": "ProxMaP: Proximal Occupancy Map Prediction for Efficient Indoor Robot  Navigation",
    "abstract": " Comments: Accepted at IROS 2023 ",
    "url": "https://arxiv.org/abs/2203.04177",
    "authors": [
      "Vishnu Dutt Sharma",
      "Jingxi Chen",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.10984",
    "title": "Brooks' Theorem in Graph Streams: A Single-Pass Semi-Streaming Algorithm  for $\u0394$-Coloring",
    "abstract": " Comments: Journal version in TheoretiCS. An extended abstract appeared in STOC 2022. 66 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2203.10984",
    "authors": [
      "Sepehr Assadi",
      "Pankaj Kumar",
      "Parth Mittal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.05492",
    "title": "The performance of the amplitude-based model for complex phase retrieval",
    "abstract": " Comments: Some proofs need improvement ",
    "url": "https://arxiv.org/abs/2204.05492",
    "authors": [
      "Yu Xia",
      "Zhiqiang Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.13904",
    "title": "A Contribution to the Defense of Liquid Democracy",
    "abstract": " Title: A Contribution to the Defense of Liquid Democracy ",
    "url": "https://arxiv.org/abs/2206.13904",
    "authors": [
      "Gregory Butterworth",
      "Richard Booth"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.01352",
    "title": "Terrorist attacks sharpen the binary perception of \"Us\" vs. \"Them\"",
    "abstract": " Comments: Peer-reviewed; Published ",
    "url": "https://arxiv.org/abs/2207.01352",
    "authors": [
      "Milan Jovi\u0107",
      "Lovro \u0160ubelj",
      "Tea Golob",
      "Matej Makarovi\u010d",
      "Taha Yasseri",
      "Danijela Boberi\u0107 Krsti\u0107ev",
      "Srdjan \u0160krbi\u0107",
      "Zoran Levnaji\u0107"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2208.00874",
    "title": "S$^2$Contact: Graph-based Network for 3D Hand-Object Contact Estimation  with Semi-Supervised Learning",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2208.00874",
    "authors": [
      "Tze Ho Elden Tse",
      "Zhongqun Zhang",
      "Kwang In Kim",
      "Ales Leonardis",
      "Feng Zheng",
      "Hyung Jin Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.07898",
    "title": "Collaborative causal inference on distributed data",
    "abstract": " Comments: 14 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2208.07898",
    "authors": [
      "Yuji Kawamata",
      "Ryoki Motai",
      "Yukihiko Okada",
      "Akira Imakura",
      "Tetsuya Sakurai"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.02144",
    "title": "No Agreement Without Loss: Learning and Social Choice in Peer Review",
    "abstract": " Comments: accepted for ECAI 2023 ",
    "url": "https://arxiv.org/abs/2211.02144",
    "authors": [
      "Pablo Barcel\u00f3",
      "Mauricio Duarte",
      "Crist\u00f3bal Rojas",
      "Tomasz Steifer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.04168",
    "title": "Pushing the limits of self-supervised speaker verification using  regularized distillation framework",
    "abstract": " Title: Pushing the limits of self-supervised speaker verification using  regularized distillation framework ",
    "url": "https://arxiv.org/abs/2211.04168",
    "authors": [
      "Yafeng Chen",
      "Siqi Zheng",
      "Hui Wang",
      "Luyao Cheng",
      "Qian Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.13755",
    "title": "TemporalStereo: Efficient Spatial-Temporal Stereo Matching Network",
    "abstract": " Comments: Accepted by IROS 2023, Project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.13755",
    "authors": [
      "Youmin Zhang",
      "Matteo Poggi",
      "Stefano Mattoccia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14512",
    "title": "Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection  in Semantic Segmentation",
    "abstract": " Comments: 16 pages, 11 figures and it is a preprint version ",
    "url": "https://arxiv.org/abs/2211.14512",
    "authors": [
      "Yuyuan Liu",
      "Choubo Ding",
      "Yu Tian",
      "Guansong Pang",
      "Vasileios Belagiannis",
      "Ian Reid",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08583",
    "title": "Semi-Siamese Network for Robust Change Detection Across Different  Domains with Applications to 3D Printing",
    "abstract": " Title: Semi-Siamese Network for Robust Change Detection Across Different  Domains with Applications to 3D Printing ",
    "url": "https://arxiv.org/abs/2212.08583",
    "authors": [
      "Yushuo Niu",
      "Ethan Chadwick",
      "Anson W. K. Ma",
      "Qian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08736",
    "title": "A Neural Network Warm-Start Approach for the Inverse Acoustic Obstacle  Scattering Problem",
    "abstract": " Title: A Neural Network Warm-Start Approach for the Inverse Acoustic Obstacle  Scattering Problem ",
    "url": "https://arxiv.org/abs/2212.08736",
    "authors": [
      "Mo Zhou",
      "Jiequn Han",
      "Manas Rachh",
      "Carlos Borges"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2212.13726",
    "title": "A Clustering-guided Contrastive Fusion for Multi-view Representation  Learning",
    "abstract": " Comments: 13 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2212.13726",
    "authors": [
      "Guanzhou Ke",
      "Guoqing Chao",
      "Xiaoli Wang",
      "Chenyang Xu",
      "Yongqi Zhu",
      "Yang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05549",
    "title": "Balancing Approach for Causal Inference at Scale",
    "abstract": " Comments: KDD '23: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining ",
    "url": "https://arxiv.org/abs/2302.05549",
    "authors": [
      "Sicheng Lin",
      "Meng Xu",
      "Xi Zhang",
      "Shih-Kang Chao",
      "Ying-Kai Huang",
      "Xiaolin Shi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.08875",
    "title": "Optimal Training of Mean Variance Estimation Neural Networks",
    "abstract": " Comments: 11 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2302.08875",
    "authors": [
      "Laurens Sluijterman",
      "Eric Cator",
      "Tom Heskes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10051",
    "title": "Normative framework for deriving neural networks with  multi-compartmental neurons and non-Hebbian plasticity",
    "abstract": " Comments: Added: Figure 1, sections 2, 3 ",
    "url": "https://arxiv.org/abs/2302.10051",
    "authors": [
      "David Lipshutz",
      "Yanis Bahroun",
      "Siavash Golkar",
      "Anirvan M. Sengupta",
      "Dmitri B. Chklovskii"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.06388",
    "title": "FAC: 3D Representation Learning via Foreground Aware Feature Contrast",
    "abstract": " Comments: IEEE/CVF Conference on Computer Vision and Pattern Recognition 2023 (CVPR 2023), 11 pages, the work is mainly supported by the Natural Science Foundation Project of Fujian Province (2020J01826) ",
    "url": "https://arxiv.org/abs/2303.06388",
    "authors": [
      "Kangcheng Liu",
      "Aoran Xiao",
      "Xiaoqin Zhang",
      "Shijian Lu",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06689",
    "title": "Self-planning Code Generation with Large Language Models",
    "abstract": " Title: Self-planning Code Generation with Large Language Models ",
    "url": "https://arxiv.org/abs/2303.06689",
    "authors": [
      "Xue Jiang",
      "Yihong Dong",
      "Lecheng Wang",
      "Zheng Fang",
      "Qiwei Shang",
      "Ge Li",
      "Zhi Jin",
      "Wenpin Jiao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.10112",
    "title": "Causal Discovery from Temporal Data: An Overview and New Perspectives",
    "abstract": " Comments: 54 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2303.10112",
    "authors": [
      "Chang Gong",
      "Di Yao",
      "Chuzhe Zhang",
      "Wenbin Li",
      "Jingping Bi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.10236",
    "title": "Prevalence of Code Smells in Reinforcement Learning Projects",
    "abstract": " Comments: Paper preprint for the 2nd International Conference on AI Engineering Software Engineering for AI CAIN2023 ",
    "url": "https://arxiv.org/abs/2303.10236",
    "authors": [
      "Nicol\u00e1s Cardozo",
      "Ivana Dusparic",
      "Christian Cabrera"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.11966",
    "title": "Multi-Robot Planning on Dynamic Topological Graphs using Mixed-Integer  Programming",
    "abstract": " Comments: \\copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2303.11966",
    "authors": [
      "Cora A. Dimmig",
      "Kevin C. Wolfe",
      "Joseph Moore"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.16500",
    "title": "AirLine: Efficient Learnable Line Detection with Local Edge Voting",
    "abstract": " Title: AirLine: Efficient Learnable Line Detection with Local Edge Voting ",
    "url": "https://arxiv.org/abs/2303.16500",
    "authors": [
      "Xiao Lin",
      "Chen Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.06120",
    "title": "Sensing the Pulse of the Pandemic: Geovisualizing the Demographic  Disparities of Public Sentiment toward COVID-19 through Social Media",
    "abstract": " Title: Sensing the Pulse of the Pandemic: Geovisualizing the Demographic  Disparities of Public Sentiment toward COVID-19 through Social Media ",
    "url": "https://arxiv.org/abs/2304.06120",
    "authors": [
      "Binbin Lina",
      "Lei Zoua",
      "Bo Zhao",
      "Xiao Huang",
      "Heng Cai",
      "Mingzheng Yang",
      "Bing Zhou"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2305.14079",
    "title": "Masked Modeling Duo for Speech: Specializing General-Purpose Audio  Representation to Speech using Denoising Distillation",
    "abstract": " Comments: Interspeech 2023; 5+2 pages, 2 figures, 6+6 tables, Code: this https URL ",
    "url": "https://arxiv.org/abs/2305.14079",
    "authors": [
      "Daisuke Niizumi",
      "Daiki Takeuchi",
      "Yasunori Ohishi",
      "Noboru Harada",
      "Kunio Kashino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.14579",
    "title": "Real-Time Idling Vehicles Detection using Combined Audio-Visual Deep  Learning",
    "abstract": " Title: Real-Time Idling Vehicles Detection using Combined Audio-Visual Deep  Learning ",
    "url": "https://arxiv.org/abs/2305.14579",
    "authors": [
      "Xiwen Li",
      "Tristalee Mangin",
      "Surojit Saha",
      "Evan Blanchard",
      "Dillon Tang",
      "Henry Poppe",
      "Nathan Searle",
      "Ouk Choi",
      "Kerry Kelly",
      "Ross Whitaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16174",
    "title": "From Latent Graph to Latent Topology Inference: Differentiable Cell  Complex Module",
    "abstract": " Comments: Under review. 17 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2305.16174",
    "authors": [
      "Claudio Battiloro",
      "Indro Spinelli",
      "Lev Telyatnikov",
      "Michael Bronstein",
      "Simone Scardapane",
      "Paolo Di Lorenzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.04643",
    "title": "Abnormal Trading Detection in the NFT Market",
    "abstract": " Comments: The Undergraduate Consortium at KDD 2023 (KDD-UC) ",
    "url": "https://arxiv.org/abs/2306.04643",
    "authors": [
      "Mingxiao Song",
      "Yunsong Liu",
      "Agam Shah",
      "Sudheer Chava"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2307.10803",
    "title": "Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies, and  Opportunities",
    "abstract": " Title: Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies, and  Opportunities ",
    "url": "https://arxiv.org/abs/2307.10803",
    "authors": [
      "Hanchen Yang",
      "Wengen Li",
      "Shuyu Wang",
      "Hui Li",
      "Jihong Guan",
      "Shuigeng Zhou",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2307.14701",
    "title": "MIM-OOD: Generative Masked Image Modelling for Out-of-Distribution  Detection in Medical Images",
    "abstract": " Comments: 12 pages, 5 figures. Accepted in DGM4MICCAI workshop @ MICCAI 2023 ",
    "url": "https://arxiv.org/abs/2307.14701",
    "authors": [
      "Sergio Naval Marimont",
      "Vasilis Siomos",
      "Giacomo Tarroni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.16149",
    "title": "An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting  in Smart Grid",
    "abstract": " Title: An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting  in Smart Grid ",
    "url": "https://arxiv.org/abs/2307.16149",
    "authors": [
      "Xun Yuan",
      "Yang Yang",
      "Arwa Alromih",
      "Prosanta Gope",
      "Biplab Sikdar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.16173",
    "title": "Data-Driven Modeling with Experimental Augmentation for the Modulation  Strategy of the Dual-Active-Bridge Converter",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2307.16173",
    "authors": [
      "Xinze Li",
      "Josep Pou",
      "Jiaxin Dong",
      "Fanfan Lin",
      "Changyun Wen",
      "Suvajit Mukherjee",
      "Xin Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.16387",
    "title": "Relation-Oriented: Toward Knowledge-Aligned Causal AI",
    "abstract": " Title: Relation-Oriented: Toward Knowledge-Aligned Causal AI ",
    "url": "https://arxiv.org/abs/2307.16387",
    "authors": [
      "Jia Li",
      "Xiang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.00579",
    "title": "Epistemic Planning for Heterogeneous Robotic Systems",
    "abstract": " Title: Epistemic Planning for Heterogeneous Robotic Systems ",
    "url": "https://arxiv.org/abs/2308.00579",
    "authors": [
      "Lauren Bramblett",
      "Nicola Bezzo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.00958",
    "title": "Isolation and Induction: Training Robust Deep Neural Networks against  Model Stealing Attacks",
    "abstract": " Comments: Accepted by ACM Multimedia 2023 ",
    "url": "https://arxiv.org/abs/2308.00958",
    "authors": [
      "Jun Guo",
      "Aishan Liu",
      "Xingyu Zheng",
      "Siyuan Liang",
      "Yisong Xiao",
      "Yichao Wu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01006",
    "title": "FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of  Autonomous Driving",
    "abstract": " Title: FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of  Autonomous Driving ",
    "url": "https://arxiv.org/abs/2308.01006",
    "authors": [
      "Tengju Ye",
      "Wei Jing",
      "Chunyong Hu",
      "Shikun Huang",
      "Lingping Gao",
      "Fangzhen Li",
      "Jingke Wang",
      "Ke Guo",
      "Wencong Xiao",
      "Weibo Mao",
      "Hang Zheng",
      "Kun Li",
      "Junbo Chen",
      "Kaicheng Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01040",
    "title": "Inaudible Adversarial Perturbation: Manipulating the Recognition of User  Speech in Real Time",
    "abstract": " Comments: Accepted by NDSS Symposium 2024 ",
    "url": "https://arxiv.org/abs/2308.01040",
    "authors": [
      "Xinfeng Li",
      "Chen Yan",
      "Xuancun Lu",
      "Zihan Zeng",
      "Xiaoyu Ji",
      "Wenyuan Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.01191",
    "title": "Towards Understanding the Capability of Large Language Models on Code  Clone Detection: A Survey",
    "abstract": " Comments: 13 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2308.01191",
    "authors": [
      "Shihan Dou",
      "Junjie Shan",
      "Haoxiang Jia",
      "Wenhao Deng",
      "Zhiheng Xi",
      "Wei He",
      "Yueming Wu",
      "Tao Gui",
      "Yang Liu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.01201",
    "title": "A Real-Time Robust Ecological-Adaptive Cruise Control Strategy for  Battery Electric Vehicles",
    "abstract": " Comments: 15 pages and 12 figures ",
    "url": "https://arxiv.org/abs/2308.01201",
    "authors": [
      "Sheng Yu",
      "Xiao Pan",
      "Anastasis Georgiou",
      "Boli Chen",
      "Imad M. Jaimoukha",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.01239",
    "title": "CMUNeXt: An Efficient Medical Image Segmentation Network based on Large  Kernel and Skip Fusion",
    "abstract": " Comments: 8 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2308.01239",
    "authors": [
      "Fenghe Tang",
      "Jianrui Ding",
      "Lingtao Wang",
      "Chunping Ning",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]