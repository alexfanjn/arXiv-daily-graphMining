[
  {
    "id": "arXiv:2308.09722",
    "title": "A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on  Social Media Using Synthetic Data",
    "abstract": "Social media cyberbullying has a detrimental effect on human life. As online social networking grows daily, the amount of hate speech also increases. Such terrible content can cause depression and actions related to suicide. This paper proposes a trustable LSTM-Autoencoder Network for cyberbullying detection on social media using synthetic data. We have demonstrated a cutting-edge method to address data availability difficulties by producing machine-translated data. However, several languages such as Hindi and Bangla still lack adequate investigations due to a lack of datasets. We carried out experimental identification of aggressive comments on Hindi, Bangla, and English datasets using the proposed model and traditional models, including Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM), LSTM-Autoencoder, Word2vec, Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformer 2 (GPT-2) models. We employed evaluation metrics such as f1-score, accuracy, precision, and recall to assess the models performance. Our proposed model outperformed all the models on all datasets, achieving the highest accuracy of 95%. Our model achieves state-of-the-art results among all the previous works on the dataset we used in this paper. ",
    "url": "https://arxiv.org/abs/2308.09722",
    "authors": [
      "Mst Shapna Akter",
      "Hossain Shahriar",
      "Alfredo Cuzzocrea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.09729",
    "title": "MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large  Language Models",
    "abstract": "LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, prompting a GPT-3.5 with MindMap yields an overwhelming performance over GPT-4 consistently. We also demonstrate that with structured facts retrieved from KG, MindMap can outperform a series of prompting-with-document-retrieval methods, benefiting from more accurate, concise, and comprehensive knowledge from KGs. ",
    "url": "https://arxiv.org/abs/2308.09729",
    "authors": [
      "Yilin Wen",
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09734",
    "title": "A Robust Policy Bootstrapping Algorithm for Multi-objective  Reinforcement Learning in Non-stationary Environments",
    "abstract": "Multi-objective Markov decision processes are a special kind of multi-objective optimization problem that involves sequential decision making while satisfying the Markov property of stochastic processes. Multi-objective reinforcement learning methods address this problem by fusing the reinforcement learning paradigm with multi-objective optimization techniques. One major drawback of these methods is the lack of adaptability to non-stationary dynamics in the environment. This is because they adopt optimization procedures that assume stationarity to evolve a coverage set of policies that can solve the problem. This paper introduces a developmental optimization approach that can evolve the policy coverage set while exploring the preference space over the defined objectives in an online manner. We propose a novel multi-objective reinforcement learning algorithm that can robustly evolve a convex coverage set of policies in an online manner in non-stationary environments. We compare the proposed algorithm with two state-of-the-art multi-objective reinforcement learning algorithms in stationary and non-stationary environments. Results showed that the proposed algorithm significantly outperforms the existing algorithms in non-stationary environments while achieving comparable results in stationary environments. ",
    "url": "https://arxiv.org/abs/2308.09734",
    "authors": [
      "Sherif Abdelfattah",
      "Kathryn Kasmarik",
      "Jiankun Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.09735",
    "title": "Causal Interpretable Progression Trajectory Analysis of Chronic Disease",
    "abstract": "Chronic disease is the leading cause of death, emphasizing the need for accurate prediction of disease progression trajectories and informed clinical decision-making. Machine learning (ML) models have shown promise in this domain by capturing non-linear patterns within patient features. However, existing ML-based models lack the ability to provide causal interpretable predictions and estimate treatment effects, limiting their decision-assisting perspective. In this study, we propose a novel model called causal trajectory prediction (CTP) to tackle the limitation. The CTP model combines trajectory prediction and causal discovery to enable accurate prediction of disease progression trajectories and uncovering causal relationships between features. By incorporating a causal graph into the prediction process, CTP ensures that ancestor features are not influenced by treatment on descendant features, thereby enhancing the interpretability of the model. By estimating the bounds of treatment effects, even in the presence of unmeasured confounders, the CTP provides valuable insights for clinical decision-making. We evaluate the performance of the CTP using simulated and real medical datasets. Experimental results demonstrate that our model achieves satisfactory performance, highlighting its potential to assist clinical decisions. ",
    "url": "https://arxiv.org/abs/2308.09735",
    "authors": [
      "Zhoujian Sun",
      "Wenzhuo Zhang",
      "Zhengxing Huang",
      "Nai Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09764",
    "title": "The Impact of Background Removal on Performance of Neural Networks for  Fashion Image Classification and Segmentation",
    "abstract": "Fashion understanding is a hot topic in computer vision, with many applications having great business value in the market. Fashion understanding remains a difficult challenge for computer vision due to the immense diversity of garments and various scenes and backgrounds. In this work, we try removing the background from fashion images to boost data quality and increase model performance. Having fashion images of evident persons in fully visible garments, we can utilize Salient Object Detection to achieve the background removal of fashion data to our expectations. A fashion image with the background removed is claimed as the \"rembg\" image, contrasting with the original one in the fashion dataset. We conducted extensive comparative experiments with these two types of images on multiple aspects of model training, including model architectures, model initialization, compatibility with other training tricks and data augmentations, and target task types. Our experiments show that background removal can effectively work for fashion data in simple and shallow networks that are not susceptible to overfitting. It can improve model accuracy by up to 5% in the classification on the FashionStyle14 dataset when training models from scratch. However, background removal does not perform well in deep neural networks due to incompatibility with other regularization techniques like batch normalization, pre-trained initialization, and data augmentations introducing randomness. The loss of background pixels invalidates many existing training tricks in the model training, adding the risk of overfitting for deep models. ",
    "url": "https://arxiv.org/abs/2308.09764",
    "authors": [
      "Junhui Liang",
      "Ying Liu",
      "Vladimir Vlassov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09780",
    "title": "Event-based Dynamic Graph Representation Learning for Patent Application  Trend Prediction",
    "abstract": "Accurate prediction of what types of patents that companies will apply for in the next period of time can figure out their development strategies and help them discover potential partners or competitors in advance. Although important, this problem has been rarely studied in previous research due to the challenges in modelling companies' continuously evolving preferences and capturing the semantic correlations of classification codes. To fill in this gap, we propose an event-based dynamic graph learning framework for patent application trend prediction. In particular, our method is founded on the memorable representations of both companies and patent classification codes. When a new patent is observed, the representations of the related companies and classification codes are updated according to the historical memories and the currently encoded messages. Moreover, a hierarchical message passing mechanism is provided to capture the semantic proximities of patent classification codes by updating their representations along the hierarchical taxonomy. Finally, the patent application trend is predicted by aggregating the representations of the target company and classification codes from static, dynamic, and hierarchical perspectives. Experiments on real-world data demonstrate the effectiveness of our approach under various experimental conditions, and also reveal the abilities of our method in learning semantics of classification codes and tracking technology developing trajectories of companies. ",
    "url": "https://arxiv.org/abs/2308.09780",
    "authors": [
      "Tao Zou",
      "Le Yu",
      "Leilei Sun",
      "Bowen Du",
      "Deqing Wang",
      "Fuzhen Zhuang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09798",
    "title": "Unveiling the Collaborative Patterns of Artificial Intelligence  Applications in Human Resource Management: A Social Network Analysis Approach",
    "abstract": "The integration of artificial intelligence (AI) into human resource management (HRM) strategies has become increasingly common due to technological advancements. This has spurred a new field of research focused on evaluating the impact of AI adoption on business and individual outcomes, as well as how to evaluate AI-enabled HRM practices. However, there is limited cross-disciplinary research in this area, causing a fragmented body of knowledge. To address this issue, social network analysis has been recognized as a tool for analyzing and researching large-scale social phenomena in HRM. The study of scientific co-authorship networks is one application of social network analysis that can help identify the main components and trends in this field. Using social network analysis indicators, the current study examined the AI&HRM co-authorship network, which consists of 43,789 members and 81,891 scientific collaborations. The study analyzed articles related to AI&HRM published between 2000 and 2023 extracted from the WOS citation database. Through centrality measures, the most important members of the \"AI&HRM\" co-authorship network were identified using the TOPSIS method, which identified twenty prominent researchers in this field. The study also examined the keywords \"AI&HRM\" and the scientific cooperation network of nations, universities, and communities. Overall, this study highlights the importance of cross-disciplinary research and social network analysis in understanding the implications of AI adoption in HRM. ",
    "url": "https://arxiv.org/abs/2308.09798",
    "authors": [
      "Mehrdad Maghsoudi",
      "Motahareh Kamrani Shahri",
      "Mehrdad Agha Mohammad Ali Kermani",
      "Rahim Khanizad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.09809",
    "title": "Adaptive Timers and Buffer Optimization for Layer-2 Protocols in 5G  Non-Terrestrial Networks",
    "abstract": "Interest in the integration of Terrestrial Networks (TN) and Non-Terrestrial Networks (NTN); primarily satellites; has been rekindled due to the potential of NTN to provide ubiquitous coverage. Especially with the peculiar and flexible physical layer properties of 5G-NR, now direct access to 5G services through satellites could become possible. However, the large Round-Trip Delays (RTD) in NTNs require a re-evaluation of the design of RLC and PDCP layers timers ( and associated buffers), in particular for the regenerative payload satellites which have limited computational resources, and hence need to be optimally utilized. Our aim in this work is to initiate a new line of research for emerging NTNs with limited resources from a higher-layer perspective. To this end, we propose a novel and efficient method for optimally designing the RLC and PDCP layers' buffers and timers without the need for intensive computations. This approach is relevant for low-cost satellites, which have limited computational and energy resources. The simulation results show that the proposed methods can significantly improve the performance in terms of resource utilization and delays. ",
    "url": "https://arxiv.org/abs/2308.09809",
    "authors": [
      "Chandan Kumar Sheemar",
      "Sumit Kumar",
      "Jorge Querol",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.09812",
    "title": "Reliability and Delay Analysis of 3-Dimensional Networks with  Multi-Connectivity: Satellite, HAPs, and Cellular Communications",
    "abstract": "Aerial vehicles (AVs) such as electric vertical take-off and landing (eVTOL) aircraft make aerial passenger transportation a reality in urban environments. However, their communication connectivity is still under research to realize their safe and full-scale operation. This paper envisages a multi-connectivity (MC) enabled aerial network to provide ubiquitous and reliable service to AVs. Vertical heterogeneous networks with direct air-to-ground (DA2G) and air-to-air (A2A) communication, high altitude platforms (HAPs), and low Earth orbit (LEO) satellites are considered. We evaluate the end-to-end (E2E) multi-hop reliability and network availability of the downlink of AVs for remote piloting scenarios, and control/telemetry traffic. Command and control (C2) connectivity service requires ultra-reliable and low-latency communication (URLLC), therefore we analyse E2E reliability and latency under the finite blocklength (FBL) regime. We explore how different MC options satisfy the demanding E2E connectivity requirements taking into account antenna radiation patterns and unreliable backhaul links. Since providing seamless connectivity to AVs is very challenging due to the line-of-sight (LoS) interference and reduced gains of downtilt ground base station (BS) antennas, we use coordinated multi-point (CoMP) among ground BSs to alleviate the inter-cell interference. Furthermore, we solve an optimization problem to select the best MC path under the quality of service (QoS) constraints. We maximize spectral efficiency (SE) to specify the optimum MC path with the minimum number of required links. Based on the simulation results, we find out that even with very efficient interference mitigation, MC is the key enabler for safe remote piloting operations. ",
    "url": "https://arxiv.org/abs/2308.09812",
    "authors": [
      "Fateme Salehi",
      "Mustafa Ozger",
      "Cicek Cavdar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.09829",
    "title": "Learning from A Single Graph is All You Need for Near-Shortest Path  Routing in Wireless Networks",
    "abstract": "We propose a learning algorithm for local routing policies that needs only a few data samples obtained from a single graph while generalizing to all random graphs in a standard model of wireless networks. We thus solve the all-pairs near-shortest path problem by training deep neural networks (DNNs) that efficiently and scalably learn routing policies that are local, i.e., they only consider node states and the states of neighboring nodes. Remarkably, one of these DNNs we train learns a policy that exactly matches the performance of greedy forwarding; another generally outperforms greedy forwarding. Our algorithm design exploits network domain knowledge in several ways: First, in the selection of input features and, second, in the selection of a ``seed graph'' and subsamples from its shortest paths. The leverage of domain knowledge provides theoretical explainability of why the seed graph and node subsampling suffice for learning that is efficient, scalable, and generalizable. Simulation-based results on uniform random graphs with diverse sizes and densities empirically corroborate that using samples generated from a few routing paths in a modest-sized seed graph quickly learns a model that is generalizable across (almost) all random graphs in the wireless network model. ",
    "url": "https://arxiv.org/abs/2308.09829",
    "authors": [
      "Yung-Fu Chen",
      "Sen Lin",
      "Anish Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.09830",
    "title": "Synergistic Integration of Large Language Models and Cognitive  Architectures for Robust AI: An Exploratory Analysis",
    "abstract": "This paper explores alternatives for integrating two subdisciplines of AI in the construction of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). Guided by theoretical models and supported by preliminary empirical data, we hypothesize how diverse synergistic approaches can mutually compensate for their respective weaknesses and limitations, ultimately fostering more robust and sophisticated artificial intelligence systems. Additionally, we discuss the tradeoffs and challenges associated with each approach. ",
    "url": "https://arxiv.org/abs/2308.09830",
    "authors": [
      "Oscar J. Romero",
      "John Zimmerman",
      "Aaron Steinfeld",
      "Anthony Tomasic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09842",
    "title": "Enumerating Safe Regions in Deep Neural Networks with Provable  Probabilistic Guarantees",
    "abstract": "Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called epsilon-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs. ",
    "url": "https://arxiv.org/abs/2308.09842",
    "authors": [
      "Luca Marzari",
      "Davide Corsi",
      "Enrico Marchesini",
      "Alessandro Farinelli",
      "Ferdinando Cicalese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09847",
    "title": "Enhancing End-to-End Determinism and Reliability in 6TiSCH networks with  disjoint leaf-based MPLS-like tunnels",
    "abstract": "Industrial multi-hop Internet of Things (IIoT) have strict reliability requirements and they are expected to have deterministic behavior. Reliability is associated with the network's ability to provide the best goodput possible to the destination from the source application, while deterministic behavior implies that the packets must also arrive at the destination before the maximum allowable deadline defined by the application expires. Although a relevant number of proposals have arisen in recent years, none of them achieve both restrictions simultaneously. In this work, we propose a cross-layer approach to solve this problem, by combining three strategies: (i) the use of the preferred parents (PP) and alternative parents (AP) together with the PRE (Packet Replication and Elimination) technique at the routing level; (ii) the use of MPLS tunnels from the leafNode, improving the Data Plane, to control the energy consumption and (iii) the use of the BDPC (Bounded Delay Packet Control) algorithm. The combination of the former strategies show that the behavior of the packet flows improves the end-to-end Packet Delivery Rate of the packets arriving before the deadline by 2.04 times with respect to standard Minimum Scheduling Function reference network while simultaneously increasing the minimum average network lifetime by 1.5 times, with respect to the hop by hop uncontrolled usage of PRE. ",
    "url": "https://arxiv.org/abs/2308.09847",
    "authors": [
      "Lucas Aimaretto",
      "Diego Dujovne"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.09850",
    "title": "Backdoor Mitigation by Correcting the Distribution of Neural Activations",
    "abstract": "Backdoor (Trojan) attacks are an important type of adversarial exploit against deep neural networks (DNNs), wherein a test instance is (mis)classified to the attacker's target class whenever the attacker's backdoor trigger is present. In this paper, we reveal and analyze an important property of backdoor attacks: a successful attack causes an alteration in the distribution of internal layer activations for backdoor-trigger instances, compared to that for clean instances. Even more importantly, we find that instances with the backdoor trigger will be correctly classified to their original source classes if this distribution alteration is corrected. Based on our observations, we propose an efficient and effective method that achieves post-training backdoor mitigation by correcting the distribution alteration using reverse-engineered triggers. Notably, our method does not change any trainable parameters of the DNN, but achieves generally better mitigation performance than existing methods that do require intensive DNN parameter tuning. It also efficiently detects test instances with the trigger, which may help to catch adversarial entities in the act of exploiting the backdoor. ",
    "url": "https://arxiv.org/abs/2308.09850",
    "authors": [
      "Xi Li",
      "Zhen Xiang",
      "David J. Miller",
      "George Kesidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.09858",
    "title": "Tensor-Compressed Back-Propagation-Free Training for (Physics-Informed)  Neural Networks",
    "abstract": "Backward propagation (BP) is widely used to compute the gradients in neural network training. However, it is hard to implement BP on edge devices due to the lack of hardware and software resources to support automatic differentiation. This has tremendously increased the design complexity and time-to-market of on-device training accelerators. This paper presents a completely BP-free framework that only requires forward propagation to train realistic neural networks. Our technical contributions are three-fold. Firstly, we present a tensor-compressed variance reduction approach to greatly improve the scalability of zeroth-order (ZO) optimization, making it feasible to handle a network size that is beyond the capability of previous ZO approaches. Secondly, we present a hybrid gradient evaluation approach to improve the efficiency of ZO training. Finally, we extend our BP-free training framework to physics-informed neural networks (PINNs) by proposing a sparse-grid approach to estimate the derivatives in the loss function without using BP. Our BP-free training only loses little accuracy on the MNIST dataset compared with standard first-order training. We also demonstrate successful results in training a PINN for solving a 20-dim Hamiltonian-Jacobi-Bellman PDE. This memory-efficient and BP-free approach may serve as a foundation for the near-future on-device training on many resource-constraint platforms (e.g., FPGA, ASIC, micro-controllers, and photonic chips). ",
    "url": "https://arxiv.org/abs/2308.09858",
    "authors": [
      "Yequan Zhao",
      "Xinling Yu",
      "Zhixiong Chen",
      "Ziyue Liu",
      "Sijia Liu",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09861",
    "title": "Black-box Adversarial Attacks against Dense Retrieval Models: A  Multi-view Contrastive Learning Method",
    "abstract": "Neural ranking models (NRMs) and dense retrieval (DR) models have given rise to substantial improvements in overall retrieval performance. In addition to their effectiveness, and motivated by the proven lack of robustness of deep learning-based approaches in other areas, there is growing interest in the robustness of deep learning-based approaches to the core retrieval problem. Adversarial attack methods that have so far been developed mainly focus on attacking NRMs, with very little attention being paid to the robustness of DR models. In this paper, we introduce the adversarial retrieval attack (AREA) task. The AREA task is meant to trick DR models into retrieving a target document that is outside the initial set of candidate documents retrieved by the DR model in response to a query. We consider the decision-based black-box adversarial setting, which is realistic in real-world search engines. To address the AREA task, we first employ existing adversarial attack methods designed for NRMs. We find that the promising results that have previously been reported on attacking NRMs, do not generalize to DR models: these methods underperform a simple term spamming method. We attribute the observed lack of generalizability to the interaction-focused architecture of NRMs, which emphasizes fine-grained relevance matching. DR models follow a different representation-focused architecture that prioritizes coarse-grained representations. We propose to formalize attacks on DR models as a contrastive learning problem in a multi-view representation space. The core idea is to encourage the consistency between each view representation of the target document and its corresponding viewer via view-wise supervision signals. Experimental results demonstrate that the proposed method can significantly outperform existing attack strategies in misleading the DR model with small indiscernible text perturbations. ",
    "url": "https://arxiv.org/abs/2308.09861",
    "authors": [
      "Yu-An Liu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Maarten de Rijke",
      "Wei Chen",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.09863",
    "title": "StROL: Stabilized and Robust Online Learning from Humans",
    "abstract": "Today's robots can learn the human's reward function online, during the current interaction. This real-time learning requires fast but approximate learning rules; when the human's behavior is noisy or suboptimal, today's approximations can result in unstable robot learning. Accordingly, in this paper we seek to enhance the robustness and convergence properties of gradient descent learning rules when inferring the human's reward parameters. We model the robot's learning algorithm as a dynamical system over the human preference parameters, where the human's true (but unknown) preferences are the equilibrium point. This enables us to perform Lyapunov stability analysis to derive the conditions under which the robot's learning dynamics converge. Our proposed algorithm (StROL) takes advantage of these stability conditions offline to modify the original learning dynamics: we introduce a corrective term that expands the basins of attraction around likely human rewards. In practice, our modified learning rule can correctly infer what the human is trying to convey, even when the human is noisy, biased, and suboptimal. Across simulations and a user study we find that StROL results in a more accurate estimate and less regret than state-of-the-art approaches for online reward learning. See videos here: https://youtu.be/uDGpkvJnY8g ",
    "url": "https://arxiv.org/abs/2308.09863",
    "authors": [
      "Shaunak A. Mehta",
      "Forrest Meng",
      "Andrea Bajcsy",
      "Dylan P. Losey"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.09881",
    "title": "Generative Adversarial Networks Unlearning",
    "abstract": "As machine learning continues to develop, and data misuse scandals become more prevalent, individuals are becoming increasingly concerned about their personal information and are advocating for the right to remove their data. Machine unlearning has emerged as a solution to erase training data from trained machine learning models. Despite its success in classifiers, research on Generative Adversarial Networks (GANs) is limited due to their unique architecture, including a generator and a discriminator. One challenge pertains to generator unlearning, as the process could potentially disrupt the continuity and completeness of the latent space. This disruption might consequently diminish the model's effectiveness after unlearning. Another challenge is how to define a criterion that the discriminator should perform for the unlearning images. In this paper, we introduce a substitution mechanism and define a fake label to effectively mitigate these challenges. Based on the substitution mechanism and fake label, we propose a cascaded unlearning approach for both item and class unlearning within GAN models, in which the unlearning and learning processes run in a cascaded manner. We conducted a comprehensive evaluation of the cascaded unlearning technique using the MNIST and CIFAR-10 datasets. Experimental results demonstrate that this approach achieves significantly improved item and class unlearning efficiency, reducing the required time by up to 185x and 284x for the MNIST and CIFAR-10 datasets, respectively, in comparison to retraining from scratch. Notably, although the model's performance experiences minor degradation after unlearning, this reduction is negligible when dealing with a minimal number of images (e.g., 64) and has no adverse effects on downstream tasks such as classification. ",
    "url": "https://arxiv.org/abs/2308.09881",
    "authors": [
      "Hui Sun",
      "Tianqing Zhu",
      "Wenhan Chang",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.09882",
    "title": "Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with  Masked Autoencoders",
    "abstract": "This study explores the application of self-supervised learning (SSL) to the task of motion forecasting, an area that has not yet been extensively investigated despite the widespread success of SSL in computer vision and natural language processing. To address this gap, we introduce Forecast-MAE, an extension of the mask autoencoders framework that is specifically designed for self-supervised learning of the motion forecasting task. Our approach includes a novel masking strategy that leverages the strong interconnections between agents' trajectories and road networks, involving complementary masking of agents' future or history trajectories and random masking of lane segments. Our experiments on the challenging Argoverse 2 motion forecasting benchmark show that Forecast-MAE, which utilizes standard Transformer blocks with minimal inductive bias, achieves competitive performance compared to state-of-the-art methods that rely on supervised learning and sophisticated designs. Moreover, it outperforms the previous self-supervised learning method by a significant margin. Code is available at https://github.com/jchengai/forecast-mae. ",
    "url": "https://arxiv.org/abs/2308.09882",
    "authors": [
      "Jie Cheng",
      "Xiaodong Mei",
      "Ming Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09884",
    "title": "A Transformer-based Framework For Multi-variate Time Series: A Remaining  Useful Life Prediction Use Case",
    "abstract": "In recent times, Large Language Models (LLMs) have captured a global spotlight and revolutionized the field of Natural Language Processing. One of the factors attributed to the effectiveness of LLMs is the model architecture used for training, transformers. Transformer models excel at capturing contextual features in sequential data since time series data are sequential, transformer models can be leveraged for more efficient time series data prediction. The field of prognostics is vital to system health management and proper maintenance planning. A reliable estimation of the remaining useful life (RUL) of machines holds the potential for substantial cost savings. This includes avoiding abrupt machine failures, maximizing equipment usage, and serving as a decision support system (DSS). This work proposed an encoder-transformer architecture-based framework for multivariate time series prediction for a prognostics use case. We validated the effectiveness of the proposed framework on all four sets of the C-MAPPS benchmark dataset for the remaining useful life prediction task. To effectively transfer the knowledge and application of transformers from the natural language domain to time series, three model-specific experiments were conducted. Also, to enable the model awareness of the initial stages of the machine life and its degradation path, a novel expanding window method was proposed for the first time in this work, it was compared with the sliding window method, and it led to a large improvement in the performance of the encoder transformer model. Finally, the performance of the proposed encoder-transformer model was evaluated on the test dataset and compared with the results from 13 other state-of-the-art (SOTA) models in the literature and it outperformed them all with an average performance increase of 137.65% over the next best model across all the datasets. ",
    "url": "https://arxiv.org/abs/2308.09884",
    "authors": [
      "Oluwaseyi Ogunfowora",
      "Homayoun Najjaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.09889",
    "title": "DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion  Customization",
    "abstract": "Stable Diffusion (SD) customization approaches enable users to personalize SD model outputs, greatly enhancing the flexibility and diversity of AI art. However, they also allow individuals to plagiarize specific styles or subjects from copyrighted images, which raises significant concerns about potential copyright infringement. To address this issue, we propose an invisible data-free universal adversarial watermark (DUAW), aiming to protect a myriad of copyrighted images from different customization approaches across various versions of SD models. First, DUAW is designed to disrupt the variational autoencoder during SD customization. Second, DUAW operates in a data-free context, where it is trained on synthetic images produced by a Large Language Model (LLM) and a pretrained SD model. This approach circumvents the necessity of directly handling copyrighted images, thereby preserving their confidentiality. Once crafted, DUAW can be imperceptibly integrated into massive copyrighted images, serving as a protective measure by inducing significant distortions in the images generated by customized SD models. Experimental results demonstrate that DUAW can effectively distort the outputs of fine-tuned SD models, rendering them discernible to both human observers and a simple classifier. ",
    "url": "https://arxiv.org/abs/2308.09889",
    "authors": [
      "Xiaoyu Ye",
      "Hao Huang",
      "Jiaqi An",
      "Yongtao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09890",
    "title": "Inductive-bias Learning: Generating Code Models with Large Language  Model",
    "abstract": "Large Language Models(LLMs) have been attracting attention due to a ability called in-context learning(ICL). ICL, without updating the parameters of a LLM, it is possible to achieve highly accurate inference based on rules ``in the context'' by merely inputting a training data into the prompt. Although ICL is a developing field with many unanswered questions, LLMs themselves serves as a inference model, seemingly realizing inference without explicitly indicate ``inductive bias''. On the other hand, a code generation is also a highlighted application of LLMs. The accuracy of code generation has dramatically improved, enabling even non-engineers to generate code to perform the desired tasks by crafting appropriate prompts. In this paper, we propose a novel ``learning'' method called an ``Inductive-Bias Learning (IBL)'', which combines the techniques of ICL and code generation. An idea of IBL is straightforward. Like ICL, IBL inputs a training data into the prompt and outputs a code with a necessary structure for inference (we referred to as ``Code Model'') from a ``contextual understanding''. Despite being a seemingly simple approach, IBL encompasses both a ``property of inference without explicit inductive bias'' inherent in ICL and a ``readability and explainability'' of the code generation. Surprisingly, generated Code Models have been found to achieve predictive accuracy comparable to, and in some cases surpassing, ICL and representative machine learning models. Our IBL code is open source: https://github.com/fuyu-quant/IBLM ",
    "url": "https://arxiv.org/abs/2308.09890",
    "authors": [
      "Toma Tanaka",
      "Naofumi Emoto",
      "Tsukasa Yumibayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.09891",
    "title": "SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin  Transformer and LSTM",
    "abstract": "Integrating CNNs and RNNs to capture spatiotemporal dependencies is a prevalent strategy for spatiotemporal prediction tasks. However, the property of CNNs to learn local spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotemporal prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and KTH datasets. In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental results demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotemporal dependencies. We hope that SwinLSTM can serve as a solid baseline to promote the advancement of spatiotemporal prediction accuracy. The codes are publicly available at https://github.com/SongTang-x/SwinLSTM. ",
    "url": "https://arxiv.org/abs/2308.09891",
    "authors": [
      "Song Tang",
      "Chuang Li",
      "Pu Zhang",
      "RongNian Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09894",
    "title": "Semantic-Human: Neural Rendering of Humans from Monocular Video with  Human Parsing",
    "abstract": "The neural rendering of humans is a topic of great research significance. However, previous works mostly focus on achieving photorealistic details, neglecting the exploration of human parsing. Additionally, classical semantic work are all limited in their ability to efficiently represent fine results in complex motions. Human parsing is inherently related to radiance reconstruction, as similar appearance and geometry often correspond to similar semantic part. Furthermore, previous works often design a motion field that maps from the observation space to the canonical space, while it tends to exhibit either underfitting or overfitting, resulting in limited generalization. In this paper, we present Semantic-Human, a novel method that achieves both photorealistic details and viewpoint-consistent human parsing for the neural rendering of humans. Specifically, we extend neural radiance fields (NeRF) to jointly encode semantics, appearance and geometry to achieve accurate 2D semantic labels using noisy pseudo-label supervision. Leveraging the inherent consistency and smoothness properties of NeRF, Semantic-Human achieves consistent human parsing in both continuous and novel views. We also introduce constraints derived from the SMPL surface for the motion field and regularization for the recovered volumetric geometry. We have evaluated the model using the ZJU-MoCap dataset, and the obtained highly competitive results demonstrate the effectiveness of our proposed Semantic-Human. We also showcase various compelling applications, including label denoising, label synthesis and image editing, and empirically validate its advantageous properties. ",
    "url": "https://arxiv.org/abs/2308.09894",
    "authors": [
      "Jie Zhang",
      "Pengcheng Shi",
      "Zaiwang Gu",
      "Yiyang Zhou",
      "Zhi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09895",
    "title": "Knowledge Transfer from High-Resource to Low-Resource Programming  Languages for Code LLMs",
    "abstract": "Over the past few years, Large Language Models of Code (Code LLMs) have started to have a significant impact on programming practice. Code LLMs are also emerging as a building block for research in programming languages and software engineering. However, the quality of code produced by a Code LLM varies significantly by programming languages. Code LLMs produce impressive results on programming languages that are well represented in their training data (e.g., Java, Python, or JavaScript), but struggle with low-resource languages, like OCaml and Racket. This paper presents an effective approach for boosting the performance of Code LLMs on low-resource languages using semi-synthetic data. Our approach generates high-quality datasets for low-resource languages, which can then be used to fine-tune any pretrained Code LLM. Our approach, called MultiPL-T, translates training data from high-resource languages into training data for low-resource languages. We apply our approach to generate tens of thousands of new, validated training items for Racket, OCaml, and Lua from Python. Moreover, we use an open dataset (The Stack) and model (StarCoderBase), which allow us to decontaminate benchmarks and train models on this data without violating the model license. With MultiPL-T generated data, we present fine-tuned versions of StarCoderBase that achieve state-of-the-art performance for Racket, OCaml, and Lua on benchmark problems. For Lua, our fine-tuned model achieves the same performance as StarCoderBase as Python -- a very high-resource language -- on the MultiPL-E benchmarks. For Racket and OCaml, we double their performance on MultiPL-E, bringing their performance close to higher-resource languages such as Ruby and C#. ",
    "url": "https://arxiv.org/abs/2308.09895",
    "authors": [
      "Federico Cassano",
      "John Gouwar",
      "Francesca Lucchetti",
      "Claire Schlesinger",
      "Carolyn Jane Anderson",
      "Michael Greenberg",
      "Abhinav Jangda",
      "Arjun Guha"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09896",
    "title": "Contrastive Learning-based Imputation-Prediction Networks for  In-hospital Mortality Risk Modeling using EHRs",
    "abstract": "Predicting the risk of in-hospital mortality from electronic health records (EHRs) has received considerable attention. Such predictions will provide early warning of a patient's health condition to healthcare professionals so that timely interventions can be taken. This prediction task is challenging since EHR data are intrinsically irregular, with not only many missing values but also varying time intervals between medical records. Existing approaches focus on exploiting the variable correlations in patient medical records to impute missing values and establishing time-decay mechanisms to deal with such irregularity. This paper presents a novel contrastive learning-based imputation-prediction network for predicting in-hospital mortality risks using EHR data. Our approach introduces graph analysis-based patient stratification modeling in the imputation process to group similar patients. This allows information of similar patients only to be used, in addition to personal contextual information, for missing value imputation. Moreover, our approach can integrate contrastive learning into the proposed network architecture to enhance patient representation learning and predictive performance on the classification task. Experiments on two real-world EHR datasets show that our approach outperforms the state-of-the-art approaches in both imputation and prediction tasks. ",
    "url": "https://arxiv.org/abs/2308.09896",
    "authors": [
      "Yuxi Liu",
      "Zhenhao Zhang",
      "Shaowen Qin",
      "Flora D. Salim",
      "Antonio Jimeno Yepes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09897",
    "title": "Spatial-Temporal Alignment Network for Action Recognition",
    "abstract": "This paper studies introducing viewpoint invariant feature representations in existing action recognition architecture. Despite significant progress in action recognition, efficiently handling geometric variations in large-scale datasets remains challenging. To tackle this problem, we propose a novel Spatial-Temporal Alignment Network (STAN), which explicitly learns geometric invariant representations for action recognition. Notably, the STAN model is light-weighted and generic, which could be plugged into existing action recognition models (e.g., MViTv2) with a low extra computational cost. We test our STAN model on widely-used datasets like UCF101 and HMDB51. The experimental results show that the STAN model can consistently improve the state-of-the-art models in action recognition tasks in trained-from-scratch settings. ",
    "url": "https://arxiv.org/abs/2308.09897",
    "authors": [
      "Jinhui Ye",
      "Junwei Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09899",
    "title": "Towards a High-Performance Object Detector: Insights from Drone  Detection Using ViT and CNN-based Deep Learning Models",
    "abstract": "Accurate drone detection is strongly desired in drone collision avoidance, drone defense and autonomous Unmanned Aerial Vehicle (UAV) self-landing. With the recent emergence of the Vision Transformer (ViT), this critical task is reassessed in this paper using a UAV dataset composed of 1359 drone photos. We construct various CNN and ViT-based models, demonstrating that for single-drone detection, a basic ViT can achieve performance 4.6 times more robust than our best CNN-based transfer learning models. By implementing the state-of-the-art You Only Look Once (YOLO v7, 200 epochs) and the experimental ViT-based You Only Look At One Sequence (YOLOS, 20 epochs) in multi-drone detection, we attain impressive 98% and 96% mAP values, respectively. We find that ViT outperforms CNN at the same epoch, but also requires more training data, computational power, and sophisticated, performance-oriented designs to fully surpass the capabilities of cutting-edge CNN detectors. We summarize the distinct characteristics of ViT and CNN models to aid future researchers in developing more efficient deep learning models. ",
    "url": "https://arxiv.org/abs/2308.09899",
    "authors": [
      "Junyang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.09907",
    "title": "Imputing Brain Measurements Across Data Sets via Graph Neural Networks",
    "abstract": "Publicly available data sets of structural MRIs might not contain specific measurements of brain Regions of Interests (ROIs) that are important for training machine learning models. For example, the curvature scores computed by Freesurfer are not released by the Adolescent Brain Cognitive Development (ABCD) Study. One can address this issue by simply reapplying Freesurfer to the data set. However, this approach is generally computationally and labor intensive (e.g., requiring quality control). An alternative is to impute the missing measurements via a deep learning approach. However, the state-of-the-art is designed to estimate randomly missing values rather than entire measurements. We therefore propose to re-frame the imputation problem as a prediction task on another (public) data set that contains the missing measurements and shares some ROI measurements with the data sets of interest. A deep learning model is then trained to predict the missing measurements from the shared ones and afterwards is applied to the other data sets. Our proposed algorithm models the dependencies between ROI measurements via a graph neural network (GNN) and accounts for demographic differences in brain measurements (e.g. sex) by feeding the graph encoding into a parallel architecture. The architecture simultaneously optimizes a graph decoder to impute values and a classifier in predicting demographic factors. We test the approach, called Demographic Aware Graph-based Imputation (DAGI), on imputing those missing Freesurfer measurements of ABCD (N=3760) by training the predictor on those publicly released by the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA, N=540)... ",
    "url": "https://arxiv.org/abs/2308.09907",
    "authors": [
      "Yixin Wang",
      "Wei Peng",
      "Susan F. Tapert",
      "Qingyu Zhao",
      "Kilian M. Pohl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09915",
    "title": "EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot  Learning",
    "abstract": "Zero-shot learning (ZSL) aims to recognize the novel classes which cannot be collected for training a prediction model. Accordingly, generative models (e.g., generative adversarial network (GAN)) are typically used to synthesize the visual samples conditioned by the class semantic vectors and achieve remarkable progress for ZSL. However, existing GAN-based generative ZSL methods are based on hand-crafted models, which cannot adapt to various datasets/scenarios and fails to model instability. To alleviate these challenges, we propose evolutionary generative adversarial network search (termed EGANS) to automatically design the generative network with good adaptation and stability, enabling reliable visual feature sample synthesis for advancing ZSL. Specifically, we adopt cooperative dual evolution to conduct a neural architecture search for both generator and discriminator under a unified evolutionary adversarial framework. EGANS is learned by two stages: evolution generator architecture search and evolution discriminator architecture search. During the evolution generator architecture search, we adopt a many-to-one adversarial training strategy to evolutionarily search for the optimal generator. Then the optimal generator is further applied to search for the optimal discriminator in the evolution discriminator architecture search with a similar evolution search algorithm. Once the optimal generator and discriminator are searched, we entail them into various generative ZSL baselines for ZSL classification. Extensive experiments show that EGANS consistently improve existing generative ZSL methods on the standard CUB, SUN, AWA2 and FLO datasets. The significant performance gains indicate that the evolutionary neural architecture search explores a virgin field in ZSL. ",
    "url": "https://arxiv.org/abs/2308.09915",
    "authors": [
      "Shiming Chen",
      "Shihuang Chen",
      "Wenjin Hou",
      "Weiping Ding",
      "Xinge You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09917",
    "title": "Learning Multiscale Consistency for Self-supervised Electron Microscopy  Instance Segmentation",
    "abstract": "Instance segmentation in electron microscopy (EM) volumes poses a significant challenge due to the complex morphology of instances and insufficient annotations. Self-supervised learning has recently emerged as a promising solution, enabling the acquisition of prior knowledge of cellular tissue structures that are essential for EM instance segmentation. However, existing pretraining methods often lack the ability to capture complex visual patterns and relationships between voxels, which results in the acquired prior knowledge being insufficient for downstream EM analysis tasks. In this paper, we propose a novel pretraining framework that leverages multiscale visual representations to capture both voxel-level and feature-level consistency in EM volumes. Specifically, our framework enforces voxel-level consistency between the outputs of a Siamese network by a reconstruction function, and incorporates a cross-attention mechanism for soft feature matching to achieve fine-grained feature-level consistency. Moreover, we propose a contrastive learning scheme on the feature pyramid to extract discriminative features across multiple scales. We extensively pretrain our method on four large-scale EM datasets, achieving promising performance improvements in representative tasks of neuron and mitochondria instance segmentation. ",
    "url": "https://arxiv.org/abs/2308.09917",
    "authors": [
      "Yinda Chen",
      "Wei Huang",
      "Xiaoyu Liu",
      "Qi Chen",
      "Zhiwei Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09920",
    "title": "Graph4J -- A computationally efficient Java library for graph algorithms",
    "abstract": "Graph algorithms play an important role in many computer science areas. In order to solve problems that can be modeled using graphs, it is necessary to use a data structure that can represent those graphs in an efficient manner. On top of this, an infrastructure should be build that will assist in implementing common algorithms or developing specialized ones. Here, a new Java library is introduced, called Graph4J, that uses a different approach when compared to existing, well-known Java libraries such as JGraphT, JUNG and Guava Graph. Instead of using object-oriented data structures for graph representation, a lower-level model based on arrays of primitive values is utilized, that drastically reduces the required memory and the running times of the algorithm implementations. The design of the library, the space complexity of the graph structures and the time complexity of the most common graph operations are presented in detail, along with an experimental study that evaluates its performance, when compared to the other libraries. Emphasis is given to infrastructure related aspects, that is graph creation, inspection, alteration and traversal. The improvements obtained for other implemented algorithms are also analyzed and it is shown that the proposed library significantly outperforms the existing ones. ",
    "url": "https://arxiv.org/abs/2308.09920",
    "authors": [
      "Cristian Fr\u0103sinaru",
      "Emanuel Florentin Olariu"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.09926",
    "title": "Robust Train-to-Train Transmission Scheduling in mmWave Band for High  Speed Train Communication Systems",
    "abstract": "Demands for data traffic in high-speed railway (HSR) has increased drastically. The increasing entertainment needs of passengers, safety control information exchanges of trains, etc., make train-to-train (T2T) communications face the challenge of achieving high-capacity and high-quality data transmissions. In order to greatly increase the communication capacity, it is urgent to introduce millimeter wave (mmWave) technology. Faced with the problem that mmWave link is easy to be blocked, this paper leverages the existing equipment to assist relay, and proposes an effective transmission scheduling scheme to improve the robustness of T2T communication systems. First of all, we formulate a mixed integer nonlinear programming (MINLP) optimization problem the transmission scheduling in T2T communication systems where mobile relays (MRs) are all working in the full-duplex (FD) mode. Then we propose a low complexity heuristic algorithm to solve the optimization problem, which consists of three components: relay selection, transmission mode selection, and transmission scheduling. The simulation results show that the proposed algorithm can greatly improve the number of completed flows and system throughput. Finally, we analyze the influence of different design parameters on the system performance. The results show that the proposed algorithm can achieve more data flows and system throughput within a reasonable communication distance threshold in T2T communication with obstacles in different orbits. It can balance the computational complexity and system performance to achieve an efficient and robust data transmission. ",
    "url": "https://arxiv.org/abs/2308.09926",
    "authors": [
      "Yunhan Ma",
      "Yong Niu",
      "Shiwen Mao",
      "Zhu Han",
      "Ruisi He",
      "Zhangdui Zhong",
      "Ning Wang",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.09932",
    "title": "What Do Code Models Memorize? An Empirical Study on Large Language  Models of Code",
    "abstract": "The availability of large-scale datasets, advanced architectures, and powerful computational resources have led to effective code models that automate diverse software engineering activities. The datasets usually consist of billions of lines of code from both open-source and private repositories. A code model memorizes and produces source code verbatim, which potentially contains vulnerabilities, sensitive information, or code with strict licenses, leading to potential security and privacy issues. This paper investigates an important problem: to what extent do code models memorize their training data? We conduct an empirical study to explore memorization in large pre-trained code models. Our study highlights that simply extracting 20,000 outputs (each having 512 tokens) from a code model can produce over 40,125 code snippets that are memorized from the training data. To provide a better understanding, we build a taxonomy of memorized contents with 3 categories and 14 subcategories. The results show that the prompts sent to the code models affect the distribution of memorized contents. We identify several key factors of memorization. Specifically, given the same architecture, larger models suffer more from memorization problems. A code model produces more memorization when it is allowed to generate longer outputs. We also find a strong positive correlation between the number of an output's occurrences in the training data and that in the generated outputs, which indicates that a potential way to reduce memorization is to remove duplicates in the training data. We then identify effective metrics that infer whether an output contains memorization accurately. We also make some suggestions regarding dealing with memorization in code models. ",
    "url": "https://arxiv.org/abs/2308.09932",
    "authors": [
      "Zhou Yang",
      "Zhipeng Zhao",
      "Chenyu Wang",
      "Jieke Shi",
      "Dongsun Kim",
      "DongGyun Han",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.09934",
    "title": "Joint User Association and Transmission Scheduling in Integrated mmWave  Access and Terahertz Backhaul Networks",
    "abstract": "Terahertz wireless backhaul is expected to meet the high-speed backhaul requirements of future ultra-dense networks using millimeter-wave (mmWave) base stations (BSs). In order to achieve higher network capacity with limited resources and meet the quality of service (QoS) requirements of more users in the integrated mmWave access and terahertz backhaul network, this paper formulates a problem of maximizing the number of users successfully served in both the access and backhaul links. Since the problem is a non-linear integer optimization problem, a minimum rate ratio user association and transmission scheduling algorithm is proposed to obtain a suboptimal solution. The proposed algorithm takes the minimum rate ratio as the user association criterion and schedules first the users with fewer backhaul transmission slots. In addition, the algorithm will update the number of access transmission slots allocated to users and the access scheduling results after the backhaul scheduling phase. Numerical results show that the proposed algorithm outperforms several benchmark algorithms in terms of the number of served users and system throughput, and it can cope with a large number of bursty user requests. ",
    "url": "https://arxiv.org/abs/2308.09934",
    "authors": [
      "Lei Wang",
      "Bo Ai",
      "Yong Niu",
      "Haiyan Jiang",
      "Shiwen Mao",
      "Zhangdui Zhong",
      "Ning Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.09937",
    "title": "Practical Anomaly Detection over Multivariate Monitoring Metrics for  Online Services",
    "abstract": "As modern software systems continue to grow in terms of complexity and volume, anomaly detection on multivariate monitoring metrics, which profile systems' health status, becomes more and more critical and challenging. In particular, the dependency between different metrics and their historical patterns plays a critical role in pursuing prompt and accurate anomaly detection. Existing approaches fall short of industrial needs for being unable to capture such information efficiently. To fill this significant gap, in this paper, we propose CMAnomaly, an anomaly detection framework on multivariate monitoring metrics based on collaborative machine. The proposed collaborative machine is a mechanism to capture the pairwise interactions along with feature and temporal dimensions with linear time complexity. Cost-effective models can then be employed to leverage both the dependency between monitoring metrics and their historical patterns for anomaly detection. The proposed framework is extensively evaluated with both public data and industrial data collected from a large-scale online service system of Huawei Cloud. The experimental results demonstrate that compared with state-of-the-art baseline models, CMAnomaly achieves an average F1 score of 0.9494, outperforming baselines by 6.77% to 10.68%, and runs 10X to 20X faster. Furthermore, we also share our experience of deploying CMAnomaly in Huawei Cloud. ",
    "url": "https://arxiv.org/abs/2308.09937",
    "authors": [
      "Jinyang Liu",
      "Tianyi Yang",
      "Zhuangbin Chen",
      "Yuxin Su",
      "Cong Feng",
      "Zengyin Yang",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09942",
    "title": "On the Robustness of Open-World Test-Time Training: Self-Training with  Dynamic Prototype Expansion",
    "abstract": "Generalizing deep learning models to unknown target domain distribution with low latency has motivated research into test-time training/adaptation (TTT/TTA). Existing approaches often focus on improving test-time training performance under well-curated target domain data. As figured out in this work, many state-of-the-art methods fail to maintain the performance when the target domain is contaminated with strong out-of-distribution (OOD) data, a.k.a. open-world test-time training (OWTTT). The failure is mainly due to the inability to distinguish strong OOD samples from regular weak OOD samples. To improve the robustness of OWTTT we first develop an adaptive strong OOD pruning which improves the efficacy of the self-training TTT method. We further propose a way to dynamically expand the prototypes to represent strong OOD samples for an improved weak/strong OOD data separation. Finally, we regularize self-training with distribution alignment and the combination yields the state-of-the-art performance on 5 OWTTT benchmarks. The code is available at https://github.com/Yushu-Li/OWTTT. ",
    "url": "https://arxiv.org/abs/2308.09942",
    "authors": [
      "Yushu Li",
      "Xun Xu",
      "Yongyi Su",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09943",
    "title": "printf: Preference Modeling Based on User Reviews with Item Images and  Textual Information via Graph Learning",
    "abstract": "Nowadays, modern recommender systems usually leverage textual and visual contents as auxiliary information to predict user preference. For textual information, review texts are one of the most popular contents to model user behaviors. Nevertheless, reviews usually lose their shine when it comes to top-N recommender systems because those that solely utilize textual reviews as features struggle to adequately capture the interaction relationships between users and items. For visual one, it is usually modeled with naive convolutional networks and also hard to capture high-order relationships between users and items. Moreover, previous works did not collaboratively use both texts and images in a proper way. In this paper, we propose printf, preference modeling based on user reviews with item images and textual information via graph learning, to address the above challenges. Specifically, the dimension-based attention mechanism directs relations between user reviews and interacted items, allowing each dimension to contribute different importance weights to derive user representations. Extensive experiments are conducted on three publicly available datasets. The experimental results demonstrate that our proposed printf consistently outperforms baseline methods with the relative improvements for NDCG@5 of 26.80%, 48.65%, and 25.74% on Amazon-Grocery, Amazon-Tools, and Amazon-Electronics datasets, respectively. The in-depth analysis also indicates the dimensions of review representations definitely have different topics and aspects, assisting the validity of our model design. ",
    "url": "https://arxiv.org/abs/2308.09943",
    "authors": [
      "Hao-Lun Lin",
      "Jyun-Yu Jiang",
      "Ming-Hao Juan",
      "Pu-Jen Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.09944",
    "title": "Spatial Reconstructed Local Attention Res2Net with F0 Subband for Fake  Speech Detection",
    "abstract": "The rhythm of synthetic speech is usually too smooth, which causes that the fundamental frequency (F0) of synthetic speech is significantly different from that of real speech. It is expected that the F0 feature contains the discriminative information for the fake speech detection (FSD) task. In this paper, we propose a novel F0 subband for FSD. In addition, to effectively model the F0 subband so as to improve the performance of FSD, the spatial reconstructed local attention Res2Net (SR-LA Res2Net) is proposed. Specifically, Res2Net is used as a backbone network to obtain multiscale information, and enhanced with a spatial reconstruction mechanism to avoid losing important information when the channel group is constantly superimposed. In addition, local attention is designed to make the model focus on the local information of the F0 subband. Experimental results on the ASVspoof 2019 LA dataset show that our proposed method obtains an equal error rate (EER) of 0.47% and a minimum tandem detection cost function (min t-DCF) of 0.0159, achieving the state-of-the-art performance among all of the single systems. ",
    "url": "https://arxiv.org/abs/2308.09944",
    "authors": [
      "Cunhang Fan",
      "Jun Xue",
      "Jianhua Tao",
      "Jiangyan Yi",
      "Chenglong Wang",
      "Chengshi Zheng",
      "Zhao Lv"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.09951",
    "title": "Semantics Meets Temporal Correspondence: Self-supervised Object-centric  Learning in Videos",
    "abstract": "Self-supervised methods have shown remarkable progress in learning high-level semantics and low-level temporal correspondence. Building on these results, we take one step further and explore the possibility of integrating these two features to enhance object-centric representations. Our preliminary experiments indicate that query slot attention can extract different semantic components from the RGB feature map, while random sampling based slot attention can exploit temporal correspondence cues between frames to assist instance identification. Motivated by this, we propose a novel semantic-aware masked slot attention on top of the fused semantic features and correspondence maps. It comprises two slot attention stages with a set of shared learnable Gaussian distributions. In the first stage, we use the mean vectors as slot initialization to decompose potential semantics and generate semantic segmentation masks through iterative attention. In the second stage, for each semantics, we randomly sample slots from the corresponding Gaussian distribution and perform masked feature aggregation within the semantic area to exploit temporal correspondence patterns for instance identification. We adopt semantic- and instance-level temporal consistency as self-supervision to encourage temporally coherent object-centric representations. Our model effectively identifies multiple object instances with semantic structure, reaching promising results on unsupervised video object discovery. Furthermore, we achieve state-of-the-art performance on dense label propagation tasks, demonstrating the potential for object-centric analysis. The code is released at https://github.com/shvdiwnkozbw/SMTC. ",
    "url": "https://arxiv.org/abs/2308.09951",
    "authors": [
      "Rui Qian",
      "Shuangrui Ding",
      "Xian Liu",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09955",
    "title": "To prune or not to prune : A chaos-causality approach to principled  pruning of dense neural networks",
    "abstract": "Reducing the size of a neural network (pruning) by removing weights without impacting its performance is an important problem for resource-constrained devices. In the past, pruning was typically accomplished by ranking or penalizing weights based on criteria like magnitude and removing low-ranked weights before retraining the remaining ones. Pruning strategies may also involve removing neurons from the network in order to achieve the desired reduction in network size. We formulate pruning as an optimization problem with the objective of minimizing misclassifications by selecting specific weights. To accomplish this, we have introduced the concept of chaos in learning (Lyapunov exponents) via weight updates and exploiting causality to identify the causal weights responsible for misclassification. Such a pruned network maintains the original performance and retains feature explainability. ",
    "url": "https://arxiv.org/abs/2308.09955",
    "authors": [
      "Rajan Sahu",
      "Shivam Chadha",
      "Nithin Nagaraj",
      "Archana Mathur",
      "Snehanshu Saha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09958",
    "title": "A Comparison of Adversarial Learning Techniques for Malware Detection",
    "abstract": "Machine learning has proven to be a useful tool for automated malware detection, but machine learning models have also been shown to be vulnerable to adversarial attacks. This article addresses the problem of generating adversarial malware samples, specifically malicious Windows Portable Executable files. We summarize and compare work that has focused on adversarial machine learning for malware detection. We use gradient-based, evolutionary algorithm-based, and reinforcement-based methods to generate adversarial samples, and then test the generated samples against selected antivirus products. We compare the selected methods in terms of accuracy and practical applicability. The results show that applying optimized modifications to previously detected malware can lead to incorrect classification of the file as benign. It is also known that generated malware samples can be successfully used against detection models other than those used to generate them and that using combinations of generators can create new samples that evade detection. Experiments show that the Gym-malware generator, which uses a reinforcement learning approach, has the greatest practical potential. This generator achieved an average sample generation time of 5.73 seconds and the highest average evasion rate of 44.11%. Using the Gym-malware generator in combination with itself improved the evasion rate to 58.35%. ",
    "url": "https://arxiv.org/abs/2308.09958",
    "authors": [
      "Pavla Louth\u00e1nov\u00e1",
      "Matou\u0161 Koz\u00e1k",
      "Martin Jure\u010dek",
      "Mark Stamp"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09965",
    "title": "Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation",
    "abstract": "Within the context of autonomous driving, encountering unknown objects becomes inevitable during deployment in the open world. Therefore, it is crucial to equip standard semantic segmentation models with anomaly awareness. Many previous approaches have utilized synthetic out-of-distribution (OoD) data augmentation to tackle this problem. In this work, we advance the OoD synthesis process by reducing the domain gap between the OoD data and driving scenes, effectively mitigating the style difference that might otherwise act as an obvious shortcut during training. Additionally, we propose a simple fine-tuning loss that effectively induces a pre-trained semantic segmentation model to generate a ``none of the given classes\" prediction, leveraging per-pixel OoD scores for anomaly segmentation. With minimal fine-tuning effort, our pipeline enables the use of pre-trained models for anomaly segmentation while maintaining the performance on the original task. ",
    "url": "https://arxiv.org/abs/2308.09965",
    "authors": [
      "Dan Zhang",
      "Kaspar Sakmann",
      "William Beluch",
      "Robin Hutmacher",
      "Yumeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09966",
    "title": "Time-aligned Exposure-enhanced Model for Click-Through Rate Prediction",
    "abstract": "Click-Through Rate (CTR) prediction, crucial in applications like recommender systems and online advertising, involves ranking items based on the likelihood of user clicks. User behavior sequence modeling has marked progress in CTR prediction, which extracts users' latent interests from their historical behavior sequences to facilitate accurate CTR prediction. Recent research explores using implicit feedback sequences, like unclicked records, to extract diverse user interests. However, these methods encounter key challenges: 1) temporal misalignment due to disparate sequence time ranges and 2) the lack of fine-grained interaction among feedback sequences. To address these challenges, we propose a novel framework called TEM4CTR, which ensures temporal alignment among sequences while leveraging auxiliary feedback information to enhance click behavior at the item level through a representation projection mechanism. Moreover, this projection-based information transfer module can effectively alleviate the negative impact of irrelevant or even potentially detrimental components of the auxiliary feedback information on the learning process of click behavior. Comprehensive experiments on public and industrial datasets confirm the superiority and effectiveness of TEM4CTR, showcasing the significance of temporal alignment in multi-feedback modeling. ",
    "url": "https://arxiv.org/abs/2308.09966",
    "authors": [
      "Hengyu Zhang",
      "Chang Meng",
      "Wei Guo",
      "Huifeng Guo",
      "Jieming Zhu",
      "Guangpeng Zhao",
      "Ruiming Tang",
      "Xiu Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.09969",
    "title": "On-the-fly Improving Performance of Deep Code Models via Input Denoising",
    "abstract": "Deep learning has been widely adopted to tackle various code-based tasks by building deep code models based on a large amount of code snippets. While these deep code models have achieved great success, even state-of-the-art models suffer from noise present in inputs leading to erroneous predictions. While it is possible to enhance models through retraining/fine-tuning, this is not a once-and-for-all approach and incurs significant overhead. In particular, these techniques cannot on-the-fly improve performance of (deployed) models. There are currently some techniques for input denoising in other domains (such as image processing), but since code input is discrete and must strictly abide by complex syntactic and semantic constraints, input denoising techniques in other fields are almost not applicable. In this work, we propose the first input denoising technique (i.e., CodeDenoise) for deep code models. Its key idea is to localize noisy identifiers in (likely) mispredicted inputs, and denoise such inputs by cleansing the located identifiers. It does not need to retrain or reconstruct the model, but only needs to cleanse inputs on-the-fly to improve performance. Our experiments on 18 deep code models (i.e., three pre-trained models with six code-based datasets) demonstrate the effectiveness and efficiency of CodeDenoise. For example, on average, CodeDenoise successfully denoises 21.91% of mispredicted inputs and improves the original models by 2.04% in terms of the model accuracy across all the subjects in an average of 0.48 second spent on each input, substantially outperforming the widely-used fine-tuning strategy. ",
    "url": "https://arxiv.org/abs/2308.09969",
    "authors": [
      "Zhao Tian",
      "Junjie Chen",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.09976",
    "title": "Explicit Time Embedding Based Cascade Attention Network for Information  Popularity Prediction",
    "abstract": "Predicting information cascade popularity is a fundamental problem in social networks. Capturing temporal attributes and cascade role information (e.g., cascade graphs and cascade sequences) is necessary for understanding the information cascade. Current methods rarely focus on unifying this information for popularity predictions, which prevents them from effectively modeling the full properties of cascades to achieve satisfactory prediction performances. In this paper, we propose an explicit Time embedding based Cascade Attention Network (TCAN) as a novel popularity prediction architecture for large-scale information networks. TCAN integrates temporal attributes (i.e., periodicity, linearity, and non-linear scaling) into node features via a general time embedding approach (TE), and then employs a cascade graph attention encoder (CGAT) and a cascade sequence attention encoder (CSAT) to fully learn the representation of cascade graphs and cascade sequences. We use two real-world datasets (i.e., Weibo and APS) with tens of thousands of cascade samples to validate our methods. Experimental results show that TCAN obtains mean logarithm squared errors of 2.007 and 1.201 and running times of 1.76 hours and 0.15 hours on both datasets, respectively. Furthermore, TCAN outperforms other representative baselines by 10.4%, 3.8%, and 10.4% in terms of MSLE, MAE, and R-squared on average while maintaining good interpretability. ",
    "url": "https://arxiv.org/abs/2308.09976",
    "authors": [
      "Xigang Sun",
      "Jingya Zhou",
      "Ling Liu",
      "Wenqi Wei"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.09985",
    "title": "HICL: Hashtag-Driven In-Context Learning for Social Media Natural  Language Understanding",
    "abstract": "Natural language understanding (NLU) is integral to various social media applications. However, existing NLU models rely heavily on context for semantic learning, resulting in compromised performance when faced with short and noisy social media content. To address this issue, we leverage in-context learning (ICL), wherein language models learn to make inferences by conditioning on a handful of demonstrations to enrich the context and propose a novel hashtag-driven in-context learning (HICL) framework. Concretely, we pre-train a model #Encoder, which employs #hashtags (user-annotated topic labels) to drive BERT-based pre-training through contrastive learning. Our objective here is to enable #Encoder to gain the ability to incorporate topic-related semantic information, which allows it to retrieve topic-related posts to enrich contexts and enhance social media NLU with noisy contexts. To further integrate the retrieved context with the source text, we employ a gradient-based method to identify trigger terms useful in fusing information from both sources. For empirical studies, we collected 45M tweets to set up an in-context NLU benchmark, and the experimental results on seven downstream tasks show that HICL substantially advances the previous state-of-the-art results. Furthermore, we conducted extensive analyzes and found that: (1) combining source input with a top-retrieved post from #Encoder is more effective than using semantically similar posts; (2) trigger words can largely benefit in merging context from the source and retrieved posts. ",
    "url": "https://arxiv.org/abs/2308.09985",
    "authors": [
      "Hanzhuo Tan",
      "Chunpu Xu",
      "Jing Li",
      "Yuqun Zhang",
      "Zeyang Fang",
      "Zeyu Chen",
      "Baohua Lai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.09993",
    "title": "TTPOINT: A Tensorized Point Cloud Network for Lightweight Action  Recognition with Event Cameras",
    "abstract": "Event cameras have gained popularity in computer vision due to their data sparsity, high dynamic range, and low latency. As a bio-inspired sensor, event cameras generate sparse and asynchronous data, which is inherently incompatible with the traditional frame-based method. Alternatively, the point-based method can avoid additional modality transformation and naturally adapt to the sparsity of events. Still, it typically cannot reach a comparable accuracy as the frame-based method. We propose a lightweight and generalized point cloud network called TTPOINT which achieves competitive results even compared to the state-of-the-art (SOTA) frame-based method in action recognition tasks while only using 1.5 % of the computational resources. The model is adept at abstracting local and global geometry by hierarchy structure. By leveraging tensor-train compressed feature extractors, TTPOINT can be designed with minimal parameters and computational complexity. Additionally, we developed a straightforward downsampling algorithm to maintain the spatio-temporal feature. In the experiment, TTPOINT emerged as the SOTA method on three datasets while also attaining SOTA among point cloud methods on all five datasets. Moreover, by using the tensor-train decomposition method, the accuracy of the proposed TTPOINT is almost unaffected while compressing the parameter size by 55 % in all five datasets. ",
    "url": "https://arxiv.org/abs/2308.09993",
    "authors": [
      "Hongwei Ren",
      "Yue Zhou",
      "Haotian Fu",
      "Yulong Huang",
      "Renjing Xu",
      "Bojun Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10001",
    "title": "AltNeRF: Learning Robust Neural Radiance Field via Alternating  Depth-Pose Optimization",
    "abstract": "Neural Radiance Fields (NeRF) have shown promise in generating realistic novel views from sparse scene images. However, existing NeRF approaches often encounter challenges due to the lack of explicit 3D supervision and imprecise camera poses, resulting in suboptimal outcomes. To tackle these issues, we propose AltNeRF -- a novel framework designed to create resilient NeRF representations using self-supervised monocular depth estimation (SMDE) from monocular videos, without relying on known camera poses. SMDE in AltNeRF masterfully learns depth and pose priors to regulate NeRF training. The depth prior enriches NeRF's capacity for precise scene geometry depiction, while the pose prior provides a robust starting point for subsequent pose refinement. Moreover, we introduce an alternating algorithm that harmoniously melds NeRF outputs into SMDE through a consistence-driven mechanism, thus enhancing the integrity of depth priors. This alternation empowers AltNeRF to progressively refine NeRF representations, yielding the synthesis of realistic novel views. Additionally, we curate a distinctive dataset comprising indoor videos captured via mobile devices. Extensive experiments showcase the compelling capabilities of AltNeRF in generating high-fidelity and robust novel views that closely resemble reality. ",
    "url": "https://arxiv.org/abs/2308.10001",
    "authors": [
      "Kun Wang",
      "Zhiqiang Yan",
      "Huang Tian",
      "Zhenyu Zhang",
      "Xiang Li",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10008",
    "title": "What is the Impact of Releasing Code with Publications? Statistics from  the Machine Learning, Robotics, and Control Communities",
    "abstract": "Open-sourcing research publications is a key enabler for the reproducibility of studies and the collective scientific progress of a research community. As all fields of science develop more advanced algorithms, we become more dependent on complex computational toolboxes -- sharing research ideas solely through equations and proofs is no longer sufficient to communicate scientific developments. Over the past years, several efforts have highlighted the importance and challenges of transparent and reproducible research; code sharing is one of the key necessities in such efforts. In this article, we study the impact of code release on scientific research and present statistics from three research communities: machine learning, robotics, and control. We found that, over a six-year period (2016-2021), the percentages of papers with code at major machine learning, robotics, and control conferences have at least doubled. Moreover, high-impact papers were generally supported by open-source codes. As an example, the top 1% of most cited papers at the Conference on Neural Information Processing Systems (NeurIPS) consistently included open-source codes. In addition, our analysis shows that popular code repositories generally come with high paper citations, which further highlights the coupling between code sharing and the impact of scientific research. While the trends are encouraging, we would like to continue to promote and increase our efforts toward transparent, reproducible research that accelerates innovation -- releasing code with our papers is a clear first step. ",
    "url": "https://arxiv.org/abs/2308.10008",
    "authors": [
      "Siqi Zhou",
      "Lukas Brunke",
      "Allen Tao",
      "Adam W. Hall",
      "Federico Pizarro Bejarano",
      "Jacopo Panerati",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.10015",
    "title": "DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for  Fingerprint Presentation Attack Detection",
    "abstract": "Automatic fingerprint recognition systems suffer from the threat of presentation attacks due to their wide range of applications in areas including national borders and commercial applications. Presentation attacks can be performed by fabricating the fake fingerprint of a user with or without the intention of the subject. This paper presents a dynamic ensemble of deep learning and handcrafted features to detect presentation attacks in known-material and unknown-material protocols. The proposed model is a dynamic ensemble of deep CNN and handcrafted features empowered deep neural networks both of which learn their parameters together. The proposed presentation attack detection model, in this way, utilizes the capabilities of both classification techniques and exhibits better performance than their individual results. The proposed model's performance is validated using benchmark LivDet 2015, 2017, and 2019 databases, with an overall accuracy of 96.10\\%, 96.49\\%, and 95.99\\% attained on them, respectively. The proposed model outperforms state-of-the-art methods in benchmark protocols of presentation attack detection in terms of classification accuracy. ",
    "url": "https://arxiv.org/abs/2308.10015",
    "authors": [
      "Anuj Rai",
      "Parsheel Kumar Tiwari",
      "Jyotishna Baishya",
      "Ram Prakash Sharma",
      "Somnath Dey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10016",
    "title": "Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation",
    "abstract": "Most self-supervised 6D object pose estimation methods can only work with additional depth information or rely on the accurate annotation of 2D segmentation masks, limiting their application range. In this paper, we propose a 6D object pose estimation method that can be trained with pure RGB images without any auxiliary information. We first obtain a rough pose initialization from networks trained on synthetic images rendered from the target's 3D mesh. Then, we introduce a refinement strategy leveraging the geometry constraint in synthetic-to-real image pairs from multiple different views. We formulate this geometry constraint as pixel-level flow consistency between the training images with dynamically generated pseudo labels. We evaluate our method on three challenging datasets and demonstrate that it outperforms state-of-the-art self-supervised methods significantly, with neither 2D annotations nor additional depth images. ",
    "url": "https://arxiv.org/abs/2308.10016",
    "authors": [
      "Yang Hai",
      "Rui Song",
      "Jiaojiao Li",
      "David Ferstl",
      "Yinlin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10022",
    "title": "Cupid: Leveraging ChatGPT for More Accurate Duplicate Bug Report  Detection",
    "abstract": "Duplicate bug report detection (DBRD) is a long-standing challenge in both academia and industry. Over the past decades, researchers have proposed various approaches to detect duplicate bug reports more accurately. With the recent advancement of deep learning, researchers have also proposed several approaches that leverage deep learning models to detect duplicate bug reports. A recent benchmarking study on DBRD also reveals that the performance of deep learning-based approaches is not always better than the traditional approaches. However, traditional approaches have limitations, e.g., they are usually based on the bag-of-words model, which cannot capture the semantics of bug reports. To address these aforementioned challenges, we seek to leverage state-of-the-art large language model to improve the performance of the traditional DBRD approach. In this paper, we propose an approach called Cupid, which combines the best-performing traditional DBRD approach REP with the state-of-the-art large language model ChatGPT. Specifically, we first leverage ChatGPT under the zero-shot setting to get essential information on bug reports. We then use the essential information as the input of REP to detect duplicate bug reports. We conducted an evaluation on comparing Cupid with three existing approaches on three datasets. The experimental results show that Cupid achieves new state-of-the-art results, reaching Recall Rate@10 scores ranging from 0.59 to 0.67 across all the datasets analyzed. Our work highlights the potential of combining large language models to improve the performance of software engineering tasks. ",
    "url": "https://arxiv.org/abs/2308.10022",
    "authors": [
      "Ting Zhang",
      "Ivana Clairine Irsan",
      "Ferdian Thung",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.10028",
    "title": "Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural  Networks",
    "abstract": "Voucher abuse detection is an important anomaly detection problem in E-commerce. While many GNN-based solutions have emerged, the supervised paradigm depends on a large quantity of labeled data. A popular alternative is to adopt self-supervised pre-training using label-free data, and further fine-tune on a downstream task with limited labels. Nevertheless, the \"pre-train, fine-tune\" paradigm is often plagued by the objective gap between pre-training and downstream tasks. Hence, we propose VPGNN, a prompt-based fine-tuning framework on GNNs for voucher abuse detection. We design a novel graph prompting function to reformulate the downstream task into a similar template as the pretext task in pre-training, thereby narrowing the objective gap. Extensive experiments on both proprietary and public datasets demonstrate the strength of VPGNN in both few-shot and semi-supervised scenarios. Moreover, an online deployment of VPGNN in a production environment shows a 23.4% improvement over two existing deployed models. ",
    "url": "https://arxiv.org/abs/2308.10028",
    "authors": [
      "Zhihao Wen",
      "Yuan Fang",
      "Yihan Liu",
      "Yang Guo",
      "Shuji Hao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.10036",
    "title": "Semi-Supervised Anomaly Detection for the Determination of Vehicle  Hijacking Tweets",
    "abstract": "In South Africa, there is an ever-growing issue of vehicle hijackings. This leads to travellers constantly being in fear of becoming a victim to such an incident. This work presents a new semi-supervised approach to using tweets to identify hijacking incidents by using unsupervised anomaly detection algorithms. Tweets consisting of the keyword \"hijacking\" are obtained, stored, and processed using the term frequency-inverse document frequency (TF-IDF) and further analyzed by using two anomaly detection algorithms: 1) K-Nearest Neighbour (KNN); 2) Cluster Based Outlier Factor (CBLOF). The comparative evaluation showed that the KNN method produced an accuracy of 89%, whereas the CBLOF produced an accuracy of 90%. The CBLOF method was also able to obtain a F1-Score of 0.8, whereas the KNN produced a 0.78. Therefore, there is a slight difference between the two approaches, in favour of CBLOF, which has been selected as a preferred unsupervised method for the determination of relevant hijacking tweets. In future, a comparison will be done between supervised learning methods and the unsupervised methods presented in this work on larger dataset. Optimisation mechanisms will also be employed in order to increase the overall performance. ",
    "url": "https://arxiv.org/abs/2308.10036",
    "authors": [
      "Taahir Aiyoob Patel",
      "Clement N. Nyirenda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10047",
    "title": "Towards Probabilistic Causal Discovery, Inference & Explanations for  Autonomous Drones in Mine Surveying Tasks",
    "abstract": "Causal modelling offers great potential to provide autonomous agents the ability to understand the data-generation process that governs their interactions with the world. Such models capture formal knowledge as well as probabilistic representations of noise and uncertainty typically encountered by autonomous robots in real-world environments. Thus, causality can aid autonomous agents in making decisions and explaining outcomes, but deploying causality in such a manner introduces new challenges. Here we identify challenges relating to causality in the context of a drone system operating in a salt mine. Such environments are challenging for autonomous agents because of the presence of confounders, non-stationarity, and a difficulty in building complete causal models ahead of time. To address these issues, we propose a probabilistic causal framework consisting of: causally-informed POMDP planning, online SCM adaptation, and post-hoc counterfactual explanations. Further, we outline planned experimentation to evaluate the framework integrated with a drone system in simulated mine environments and on a real-world mine dataset. ",
    "url": "https://arxiv.org/abs/2308.10047",
    "authors": [
      "Ricardo Cannizzaro",
      "Rhys Howard",
      "Paulina Lewinska",
      "Lars Kunze"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10051",
    "title": "The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive  field",
    "abstract": "Despite Graph Neural Networks demonstrating considerable promise in graph representation learning tasks, GNNs predominantly face significant issues with over-fitting and over-smoothing as they go deeper as models of computer vision realm. In this work, we conduct a systematic study of deeper GNN research trajectories. Our findings indicate that the current success of deep GNNs primarily stems from (I) the adoption of innovations from CNNs, such as residual/skip connections, or (II) the tailor-made aggregation algorithms like DropEdge. However, these algorithms often lack intrinsic interpretability and indiscriminately treat all nodes within a given layer in a similar manner, thereby failing to capture the nuanced differences among various nodes. To this end, we introduce the Snowflake Hypothesis -- a novel paradigm underpinning the concept of ``one node, one receptive field''. The hypothesis draws inspiration from the unique and individualistic patterns of each snowflake, proposing a corresponding uniqueness in the receptive fields of nodes in the GNNs. We employ the simplest gradient and node-level cosine distance as guiding principles to regulate the aggregation depth for each node, and conduct comprehensive experiments including: (1) different training schemes; (2) various shallow and deep GNN backbones, and (3) various numbers of layers (8, 16, 32, 64) on multiple benchmarks (six graphs including dense graphs with millions of nodes); (4) compare with different aggregation strategies. The observational results demonstrate that our hypothesis can serve as a universal operator for a range of tasks, and it displays tremendous potential on deep GNNs. It can be applied to various GNN frameworks, enhancing its effectiveness when operating in-depth, and guiding the selection of the optimal network depth in an explainable and generalizable way. ",
    "url": "https://arxiv.org/abs/2308.10051",
    "authors": [
      "Kun Wang",
      "Guohao Li",
      "Shilong Wang",
      "Guibin Zhang",
      "Kai Wang",
      "Yang You",
      "Xiaojiang Peng",
      "Yuxuan Liang",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10055",
    "title": "Robust Fraud Detection via Supervised Contrastive Learning",
    "abstract": "Deep learning models have recently become popular for detecting malicious user activity sessions in computing platforms. In many real-world scenarios, only a few labeled malicious and a large amount of normal sessions are available. These few labeled malicious sessions usually do not cover the entire diversity of all possible malicious sessions. In many scenarios, possible malicious sessions can be highly diverse. As a consequence, learned session representations of deep learning models can become ineffective in achieving a good generalization performance for unseen malicious sessions. To tackle this open-set fraud detection challenge, we propose a robust supervised contrastive learning based framework called ConRo, which specifically operates in the scenario where only a few malicious sessions having limited diversity is available. ConRo applies an effective data augmentation strategy to generate diverse potential malicious sessions. By employing these generated and available training set sessions, ConRo derives separable representations w.r.t open-set fraud detection task by leveraging supervised contrastive learning. We empirically evaluate our ConRo framework and other state-of-the-art baselines on benchmark datasets. Our ConRo framework demonstrates noticeable performance improvement over state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2308.10055",
    "authors": [
      "Vinay M.S.",
      "Shuhan Yuan",
      "Xintao Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10064",
    "title": "Efficient Representation Learning for Healthcare with  Cross-Architectural Self-Supervision",
    "abstract": "In healthcare and biomedical applications, extreme computational requirements pose a significant barrier to adopting representation learning. Representation learning can enhance the performance of deep learning architectures by learning useful priors from limited medical data. However, state-of-the-art self-supervised techniques suffer from reduced performance when using smaller batch sizes or shorter pretraining epochs, which are more practical in clinical settings. We present Cross Architectural - Self Supervision (CASS) in response to this challenge. This novel siamese self-supervised learning approach synergistically leverages Transformer and Convolutional Neural Networks (CNN) for efficient learning. Our empirical evaluation demonstrates that CASS-trained CNNs and Transformers outperform existing self-supervised learning methods across four diverse healthcare datasets. With only 1% labeled data for finetuning, CASS achieves a 3.8% average improvement; with 10% labeled data, it gains 5.9%; and with 100% labeled data, it reaches a remarkable 10.13% enhancement. Notably, CASS reduces pretraining time by 69% compared to state-of-the-art methods, making it more amenable to clinical implementation. We also demonstrate that CASS is considerably more robust to variations in batch size and pretraining epochs, making it a suitable candidate for machine learning in healthcare applications. ",
    "url": "https://arxiv.org/abs/2308.10064",
    "authors": [
      "Pranav Singh",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10077",
    "title": "Contrastive Learning for Non-Local Graphs with Multi-Resolution  Structural Views",
    "abstract": "Learning node-level representations of heterophilic graphs is crucial for various applications, including fraudster detection and protein function prediction. In such graphs, nodes share structural similarity identified by the equivalence of their connectivity which is implicitly encoded in the form of higher-order hierarchical information in the graphs. The contrastive methods are popular choices for learning the representation of nodes in a graph. However, existing contrastive methods struggle to capture higher-order graph structures. To address this limitation, we propose a novel multiview contrastive learning approach that integrates diffusion filters on graphs. By incorporating multiple graph views as augmentations, our method captures the structural equivalence in heterophilic graphs, enabling the discovery of hidden relationships and similarities not apparent in traditional node representations. Our approach outperforms baselines on synthetic and real structural datasets, surpassing the best baseline by $16.06\\%$ on Cornell, $3.27\\%$ on Texas, and $8.04\\%$ on Wisconsin. Additionally, it consistently achieves superior performance on proximal tasks, demonstrating its effectiveness in uncovering structural information and improving downstream applications. ",
    "url": "https://arxiv.org/abs/2308.10077",
    "authors": [
      "Asif Khan",
      "Amos Storkey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10078",
    "title": "Repeated Builds During Code Review: An Empirical Study of the OpenStack  Community",
    "abstract": "Code review is a popular practice where developers critique each others' changes. Since automated builds can identify low-level issues (e.g., syntactic errors, regression bugs), it is not uncommon for software organizations to incorporate automated builds in the code review process. In such code review deployment scenarios, submitted change sets must be approved for integration by both peer code reviewers and automated build bots. Since automated builds may produce an unreliable signal of the status of a change set (e.g., due to ``flaky'' or non-deterministic execution behaviour), code review tools, such as Gerrit, allow developers to request a ``recheck'', which repeats the build process without updating the change set. We conjecture that an unconstrained recheck command will waste time and resources if it is not applied judiciously. To explore how the recheck command is applied in a practical setting, in this paper, we conduct an empirical study of 66,932 code reviews from the OpenStack community. We quantitatively analyze (i) how often build failures are rechecked; (ii) the extent to which invoking recheck changes build failure outcomes; and (iii) how much waste is generated by invoking recheck. We observe that (i) 55% of code reviews invoke the recheck command after a failing build is reported; (ii) invoking the recheck command only changes the outcome of a failing build in 42% of the cases; and (iii) invoking the recheck command increases review waiting time by an average of 2,200% and equates to 187.4 compute years of waste -- enough compute resources to compete with the oldest land living animal on earth. ",
    "url": "https://arxiv.org/abs/2308.10078",
    "authors": [
      "Rungroj Maipradit",
      "Dong Wang",
      "Patanamon Thongtanunam",
      "Raula Gaikovina Kula",
      "Yasutaka Kamei",
      "Shane McIntosh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.10086",
    "title": "Connecting the Dots: Leveraging Social Network Analysis to Understand  and Optimize Collaborative Dynamics Within the Global Film Production Network",
    "abstract": "In recent years, the global film industry has observed a notable surge in international cooperation and cross-border investments. However, a comprehensive overview of these collaborative investments within the industry is lacking. This study employs social network analysis to delve into the possibilities that lie in collaborative efforts and joint investments within the film sector. The research constructs a network of 150 countries based on shared creative elements in their film productions, comprising over 7800 interconnected links. Employing measures of centrality, certain pivotal nations such as the United States, China, and England emerge as influential nodes, showcasing a strong potential to steer industry growth through collaborative engagement. Through a more detailed exploration involving community identification, distinct clusters centered around thematic commonalities that have converged through joint creative endeavors become evident. For example, the \"Global Thrill Seekers\" community focuses on action films, whereas the \"Cultural-Social Cinema Group\" addresses worldwide cultural and social issues. Each of these communities presents distinctive perspectives for international cooperation and the collaborative creation of content. This analysis significantly enhances our understanding of the global film network's structure and dynamics, while concurrently highlighting promising pathways for future investment and collaborative initiatives. The research underscores the critical role of leveraging social network analysis methodologies to optimize informed decision-making concerning collaborative investments, thereby paving the way for anticipatory outcomes. This study not only contributes insights but also serves as a model for investigating data-centric participation within the creative industries. ",
    "url": "https://arxiv.org/abs/2308.10086",
    "authors": [
      "Mehrdad Maghsoudi",
      "Saeid Aliakbar",
      "Sajjad HabibiPour"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.10087",
    "title": "GNNPipe: Accelerating Distributed Full-Graph GNN Training with Pipelined  Model Parallelism",
    "abstract": "Current distributed full-graph GNN training methods adopt a variant of data parallelism, namely graph parallelism, in which the whole graph is divided into multiple partitions (subgraphs) and each GPU processes one of them. This incurs high communication overhead because of the inter-partition message passing at each layer. To this end, we proposed a new training method named GNNPipe that adopts model parallelism instead, which has a lower worst-case asymptotic communication complexity than graph parallelism. To ensure high GPU utilization, we proposed to combine model parallelism with a chunk-based pipelined training method, in which each GPU processes a different chunk of graph data at different layers concurrently. We further proposed hybrid parallelism that combines model and graph parallelism when the model-level parallelism is insufficient. We also introduced several tricks to ensure convergence speed and model accuracies to accommodate embedding staleness introduced by pipelining. Extensive experiments show that our method reduces the per-epoch training time by up to 2.45x (on average 2.03x) and reduces the communication volume and overhead by up to 22.51x and 27.21x (on average 10.27x and 14.96x), respectively, while achieving a comparable level of model accuracy and convergence speed compared to graph parallelism. ",
    "url": "https://arxiv.org/abs/2308.10087",
    "authors": [
      "Jingji Chen",
      "Zhuoming Chen",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10099",
    "title": "Geometric instability of graph neural networks on large graphs",
    "abstract": "We analyse the geometric instability of embeddings produced by graph neural networks (GNNs). Existing methods are only applicable for small graphs and lack context in the graph domain. We propose a simple, efficient and graph-native Graph Gram Index (GGI) to measure such instability which is invariant to permutation, orthogonal transformation, translation and order of evaluation. This allows us to study the varying instability behaviour of GNN embeddings on large graphs for both node classification and link prediction. ",
    "url": "https://arxiv.org/abs/2308.10099",
    "authors": [
      "Emily Morris",
      "Haotian Shen",
      "Weiling Du",
      "Muhammad Hamza Sajjad",
      "Borun Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.10103",
    "title": "ASPIRE: Language-Guided Augmentation for Robust Image Classification",
    "abstract": "Neural image classifiers can often learn to make predictions by overly relying on non-predictive features that are spuriously correlated with the class labels in the training data. This leads to poor performance in real-world atypical scenarios where such features are absent. Supplementing the training dataset with images without such spurious features can aid robust learning against spurious correlations via better generalization. This paper presents ASPIRE (Language-guided data Augmentation for SPurIous correlation REmoval), a simple yet effective solution for expanding the training dataset with synthetic images without spurious features. ASPIRE, guided by language, generates these images without requiring any form of additional supervision or existing examples. Precisely, we employ LLMs to first extract foreground and background features from textual descriptions of an image, followed by advanced language-guided image editing to discover the features that are spuriously correlated with the class label. Finally, we personalize a text-to-image generation model to generate diverse in-domain images without spurious features. We demonstrate the effectiveness of ASPIRE on 4 datasets, including the very challenging Hard ImageNet dataset, and 9 baselines and show that ASPIRE improves the classification accuracy of prior methods by 1% - 38%. Code soon at: https://github.com/Sreyan88/ASPIRE. ",
    "url": "https://arxiv.org/abs/2308.10103",
    "authors": [
      "Sreyan Ghosh",
      "Chandra Kiran Reddy Evuru",
      "Sonal Kumar",
      "Utkarsh Tyagi",
      "Sakshi Singh",
      "Sanjoy Chowdhury",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.10107",
    "title": "Bayes Risk Transducer: Transducer with Controllable Alignment Prediction",
    "abstract": "Automatic speech recognition (ASR) based on transducers is widely used. In training, a transducer maximizes the summed posteriors of all paths. The path with the highest posterior is commonly defined as the predicted alignment between the speech and the transcription. While the vanilla transducer does not have a prior preference for any of the valid paths, this work intends to enforce the preferred paths and achieve controllable alignment prediction. Specifically, this work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties. We further demonstrate that these predicted alignments with intentionally designed properties can provide practical advantages over the vanilla transducer. Experimentally, the proposed BRT saves inference cost by up to 46% for non-streaming ASR and reduces overall system latency by 41% for streaming ASR. ",
    "url": "https://arxiv.org/abs/2308.10107",
    "authors": [
      "Jinchuan Tian",
      "Jianwei Yu",
      "Hangting Chen",
      "Brian Yan",
      "Chao Weng",
      "Dong Yu",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.10109",
    "title": "Unbiased Library of k-regular, n-sized, Connected, Small Graphs",
    "abstract": "The past decade highlighted the usefulness of social network simulations that run on k-regular, n-size, connected graphs. These can be seen as small-scale models of human social networks of large societies. By narrowing down onto k-regular graphs, the degree variation can be eliminated from the research question, which allows a focus on the isolated impact by other variables, for instance, by the clustering coefficient or the size of the network. This paper describes the generation of a random graph library that uses a random walk graph creation algorithm that starts from the \"chain of caves\", which is the structure in which the clustering coefficient is at its maximum. This method finds mid and high clustering coefficient graphs, while Wolfram`s RandomGraph was useful for finding low ones. The merge of the two samples proved to be somewhat biased. After eliminating a host of network measures, the paper focused on mean graph distance as a further variable and created an unbiased subsample for each size and clustering coefficient bin. ",
    "url": "https://arxiv.org/abs/2308.10109",
    "authors": [
      "Tamas David-Barrett"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.10110",
    "title": "Robust Mixture-of-Expert Training for Convolutional Neural Networks",
    "abstract": "Sparsely-gated Mixture of Expert (MoE), an emerging deep model architecture, has demonstrated a great promise to enable high-accuracy and ultra-efficient model inference. Despite the growing popularity of MoE, little work investigated its potential to advance convolutional neural networks (CNNs), especially in the plane of adversarial robustness. Since the lack of robustness has become one of the main hurdles for CNNs, in this paper we ask: How to adversarially robustify a CNN-based MoE model? Can we robustly train it like an ordinary CNN model? Our pilot study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) no longer remains effective to robustify an MoE-CNN. To better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: Robustness of routers (i.e., gating functions to select data-specific experts) and robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). Our analyses show that routers and experts are hard to adapt to each other in the vanilla AT. Thus, we propose a new router-expert alternating Adversarial training framework for MoE, termed AdvMoE. The effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. We find that AdvMoE achieves 1% ~ 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. Codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN. ",
    "url": "https://arxiv.org/abs/2308.10110",
    "authors": [
      "Yihua Zhang",
      "Ruisi Cai",
      "Tianlong Chen",
      "Guanhua Zhang",
      "Huan Zhang",
      "Pin-Yu Chen",
      "Shiyu Chang",
      "Zhangyang Wang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10119",
    "title": "Error Probability Bounds for Invariant Causal Prediction via Multiple  Access Channels",
    "abstract": "We consider the problem of lower bounding the error probability under the invariant causal prediction (ICP) framework. To this end, we examine and draw connections between ICP and the zero-rate Gaussian multiple access channel by first proposing a variant of the original invariant prediction assumption, and then considering a special case of the Gaussian multiple access channel where a codebook is shared between an unknown number of senders. This connection allows us to develop three types of lower bounds on the error probability, each with different assumptions and constraints, leveraging techniques for multiple access channels. The proposed bounds are evaluated with respect to existing causal discovery methods as well as a proposed heuristic method based on minimum distance decoding. ",
    "url": "https://arxiv.org/abs/2308.10119",
    "authors": [
      "Austin Goddard",
      "Yu Xiang",
      "Ilya Soloveychik"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2308.10120",
    "title": "Deep Generative Modeling-based Data Augmentation with Demonstration  using the BFBT Benchmark Void Fraction Datasets",
    "abstract": "Deep learning (DL) has achieved remarkable successes in many disciplines such as computer vision and natural language processing due to the availability of ``big data''. However, such success cannot be easily replicated in many nuclear engineering problems because of the limited amount of training data, especially when the data comes from high-cost experiments. To overcome such a data scarcity issue, this paper explores the applications of deep generative models (DGMs) that have been widely used for image data generation to scientific data augmentation. DGMs, such as generative adversarial networks (GANs), normalizing flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can be trained to learn the underlying probabilistic distribution of the training dataset. Once trained, they can be used to generate synthetic data that are similar to the training data and significantly expand the dataset size. By employing DGMs to augment TRACE simulated data of the steady-state void fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have comparable generative performance with similar errors in the synthetic data, with CVAEs achieving the smallest errors. The findings shows that DGMs have a great potential to augment scientific data in nuclear engineering, which proves effective for expanding the training dataset and enabling other DL models to be trained more accurately. ",
    "url": "https://arxiv.org/abs/2308.10120",
    "authors": [
      "Farah Alsafadi",
      "Xu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10123",
    "title": "3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose  Estimation",
    "abstract": "Regression-based methods for 3D human pose estimation directly predict the 3D pose parameters from a 2D image using deep networks. While achieving state-of-the-art performance on standard benchmarks, their performance degrades under occlusion. In contrast, optimization-based methods fit a parametric body model to 2D features in an iterative manner. The localized reconstruction loss can potentially make them robust to occlusion, but they suffer from the 2D-3D ambiguity. Motivated by the recent success of generative models in rigid object pose estimation, we propose 3D-aware Neural Body Fitting (3DNBF) - an approximate analysis-by-synthesis approach to 3D human pose estimation with SOTA performance and occlusion robustness. In particular, we propose a generative model of deep features based on a volumetric human representation with Gaussian ellipsoidal kernels emitting 3D pose-dependent feature vectors. The neural features are trained with contrastive learning to become 3D-aware and hence to overcome the 2D-3D ambiguity. Experiments show that 3DNBF outperforms other approaches on both occluded and standard benchmarks. Code is available at https://github.com/edz-o/3DNBF ",
    "url": "https://arxiv.org/abs/2308.10123",
    "authors": [
      "Yi Zhang",
      "Pengliang Ji",
      "Angtian Wang",
      "Jieru Mei",
      "Adam Kortylewski",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10134",
    "title": "AutoReP: Automatic ReLU Replacement for Fast Private Network Inference",
    "abstract": "The growth of the Machine-Learning-As-A-Service (MLaaS) market has highlighted clients' data privacy and security issues. Private inference (PI) techniques using cryptographic primitives offer a solution but often have high computation and communication costs, particularly with non-linear operators like ReLU. Many attempts to reduce ReLU operations exist, but they may need heuristic threshold selection or cause substantial accuracy loss. This work introduces AutoReP, a gradient-based approach to lessen non-linear operators and alleviate these issues. It automates the selection of ReLU and polynomial functions to speed up PI applications and introduces distribution-aware polynomial approximation (DaPa) to maintain model expressivity while accurately approximating ReLUs. Our experimental results demonstrate significant accuracy improvements of 6.12% (94.31%, 12.9K ReLU budget, CIFAR-10), 8.39% (74.92%, 12.9K ReLU budget, CIFAR-100), and 9.45% (63.69%, 55K ReLU budget, Tiny-ImageNet) over current state-of-the-art methods, e.g., SNL. Morever, AutoReP is applied to EfficientNet-B2 on ImageNet dataset, and achieved 75.55% accuracy with 176.1 times ReLU budget reduction. ",
    "url": "https://arxiv.org/abs/2308.10134",
    "authors": [
      "Hongwu Peng",
      "Shaoyi Huang",
      "Tong Zhou",
      "Yukui Luo",
      "Chenghong Wang",
      "Zigeng Wang",
      "Jiahui Zhao",
      "Xi Xie",
      "Ang Li",
      "Tony Geng",
      "Kaleel Mahmood",
      "Wujie Wen",
      "Xiaolin Xu",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10148",
    "title": "Privacy Perceptions and Behaviors of Google Personal Account Holders in  Saudi Arabia",
    "abstract": "While privacy perceptions and behaviors have been investigated in Western societies, little is known about these issues in non-Western societies. To bridge this gap, we interviewed 30 Google personal account holders in Saudi Arabia about their privacy perceptions (awareness, attitudes, preferences, and concerns) regarding the activity data that Google saves about them, as well as any steps they take to control Google's collection or use of this data. Our study focuses on Google's Activity Controls, which enable users to control whether, and how, Google saves their Web & App Activity, Location History, and YouTube History. Our results show that although most participants have some level of awareness about Google's data practices and the Activity Controls, many have only vague awareness, and the majority have not used the available controls. When participants viewed their saved activity data, many were surprised by what had been saved. While many participants find Google's use of their data to improve the services provided to them acceptable, the majority find the use of their data for ad purposes unacceptable. We observe that our Saudi participants exhibit similar trends and patterns in privacy awareness, attitudes, preferences, concerns, and behaviors to what has been found in studies in the US. However, our study is not a replication of any of the US studies, and further research is needed to directly compare US and Saudi participants. Our results emphasize the need for: (1) improved techniques to inform users about privacy settings during account sign-up, to remind users about their settings, and to raise awareness about privacy settings; (2) improved privacy setting interfaces to reduce the costs that deter many users from changing the settings; and (3) further research to explore privacy concerns in non-Western cultures. ",
    "url": "https://arxiv.org/abs/2308.10148",
    "authors": [
      "Eman Alashwali",
      "Lorrie Faith Cranor"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.10155",
    "title": "Unilaterally Aggregated Contrastive Learning with Hierarchical  Augmentation for Anomaly Detection",
    "abstract": "Anomaly detection (AD), aiming to find samples that deviate from the training distribution, is essential in safety-critical applications. Though recent self-supervised learning based attempts achieve promising results by creating virtual outliers, their training objectives are less faithful to AD which requires a concentrated inlier distribution as well as a dispersive outlier distribution. In this paper, we propose Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation (UniCon-HA), taking into account both the requirements above. Specifically, we explicitly encourage the concentration of inliers and the dispersion of virtual outliers via supervised and unsupervised contrastive losses, respectively. Considering that standard contrastive data augmentation for generating positive views may induce outliers, we additionally introduce a soft mechanism to re-weight each augmented inlier according to its deviation from the inlier distribution, to ensure a purified concentration. Moreover, to prompt a higher concentration, inspired by curriculum learning, we adopt an easy-to-hard hierarchical augmentation strategy and perform contrastive aggregation at different depths of the network based on the strengths of data augmentation. Our method is evaluated under three AD settings including unlabeled one-class, unlabeled multi-class, and labeled multi-class, demonstrating its consistent superiority over other competitors. ",
    "url": "https://arxiv.org/abs/2308.10155",
    "authors": [
      "Guodong Wang",
      "Yunhong Wang",
      "Jie Qin",
      "Dongming Zhang",
      "Xiuguo Bao",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10158",
    "title": "HODN: Disentangling Human-Object Feature for HOI Detection",
    "abstract": "The task of Human-Object Interaction (HOI) detection is to detect humans and their interactions with surrounding objects, where transformer-based methods show dominant advances currently. However, these methods ignore the relationship among humans, objects, and interactions: 1) human features are more contributive than object ones to interaction prediction; 2) interactive information disturbs the detection of objects but helps human detection. In this paper, we propose a Human and Object Disentangling Network (HODN) to model the HOI relationships explicitly, where humans and objects are first detected by two disentangling decoders independently and then processed by an interaction decoder. Considering that human features are more contributive to interaction, we propose a Human-Guide Linking method to make sure the interaction decoder focuses on the human-centric regions with human features as the positional embeddings. To handle the opposite influences of interactions on humans and objects, we propose a Stop-Gradient Mechanism to stop interaction gradients from optimizing the object detection but to allow them to optimize the human detection. Our proposed method achieves competitive performance on both the V-COCO and the HICO-Det datasets. It can be combined with existing methods easily for state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2308.10158",
    "authors": [
      "Shuman Fang",
      "Zhiwen Lin",
      "Ke Yan",
      "Jie Li",
      "Xianming Lin",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10161",
    "title": "ThermRad: A Multi-modal Dataset for Robust 3D Object Detection under  Challenging Conditions",
    "abstract": "Robust 3D object detection in extreme weather and illumination conditions is a challenging task. While radars and thermal cameras are known for their resilience to these conditions, few studies have been conducted on radar-thermal fusion due to the lack of corresponding datasets. To address this gap, we first present a new multi-modal dataset called ThermRad, which includes a 3D LiDAR, a 4D radar, an RGB camera and a thermal camera. This dataset is unique because it includes data from all four sensors in extreme weather conditions, providing a valuable resource for future research in this area. To validate the robustness of 4D radars and thermal cameras for 3D object detection in challenging weather conditions, we propose a new multi-modal fusion method called RTDF-RCNN, which leverages the complementary strengths of 4D radars and thermal cameras to boost object detection performance. To further prove the effectiveness of our proposed framework, we re-implement state-of-the-art (SOTA) 3D detectors on our dataset as benchmarks for evaluation. Our method achieves significant enhancements in detecting cars, pedestrians, and cyclists, with improvements of over 7.98%, 24.27%, and 27.15%, respectively, while achieving comparable results to LiDAR-based approaches. Our contributions in both the ThermRad dataset and the new multi-modal fusion method provide a new approach to robust 3D object detection in adverse weather and illumination conditions. The ThermRad dataset will be released. ",
    "url": "https://arxiv.org/abs/2308.10161",
    "authors": [
      "Qiao Yan",
      "Yihan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10173",
    "title": "FoodGPT: A Large Language Model in Food Testing Domain with Incremental  Pre-training and Knowledge Graph Prompt",
    "abstract": "Currently, the construction of large language models in specific domains is done by fine-tuning on a base model. Some models also incorporate knowledge bases without the need for pre-training. This is because the base model already contains domain-specific knowledge during the pre-training process. We build a large language model for food testing. Unlike the above approach, a significant amount of data in this domain exists in Scanning format for domain standard documents. In addition, there is a large amount of untrained structured knowledge. Therefore, we introduce an incremental pre-training step to inject this knowledge into a large language model. In this paper, we propose a method for handling structured knowledge and scanned documents in incremental pre-training. To overcome the problem of machine hallucination, we constructe a knowledge graph to serve as an external knowledge base for supporting retrieval in the large language model. It is worth mentioning that this paper is a technical report of our pre-release version, and we will report our specific experimental data in future versions. ",
    "url": "https://arxiv.org/abs/2308.10173",
    "authors": [
      "Zhixiao Qi",
      "Yijiong Yu",
      "Meiqi Tu",
      "Junyi Tan",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.10174",
    "title": "Neural Interactive Keypoint Detection",
    "abstract": "This work proposes an end-to-end neural interactive keypoint detection framework named Click-Pose, which can significantly reduce more than 10 times labeling costs of 2D keypoint annotation compared with manual-only annotation. Click-Pose explores how user feedback can cooperate with a neural keypoint detector to correct the predicted keypoints in an interactive way for a faster and more effective annotation process. Specifically, we design the pose error modeling strategy that inputs the ground truth pose combined with four typical pose errors into the decoder and trains the model to reconstruct the correct poses, which enhances the self-correction ability of the model. Then, we attach an interactive human-feedback loop that allows receiving users' clicks to correct one or several predicted keypoints and iteratively utilizes the decoder to update all other keypoints with a minimum number of clicks (NoC) for efficient annotation. We validate Click-Pose in in-domain, out-of-domain scenes, and a new task of keypoint adaptation. For annotation, Click-Pose only needs 1.97 and 6.45 NoC@95 (at precision 95%) on COCO and Human-Art, reducing 31.4% and 36.3% efforts than the SOTA model (ViTPose) with manual correction, respectively. Besides, without user clicks, Click-Pose surpasses the previous end-to-end model by 1.4 AP on COCO and 3.0 AP on Human-Art. The code is available at https://github.com/IDEA-Research/Click-Pose. ",
    "url": "https://arxiv.org/abs/2308.10174",
    "authors": [
      "Jie Yang",
      "Ailing Zeng",
      "Feng Li",
      "Shilong Liu",
      "Ruimao Zhang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10180",
    "title": "An IoT Architecture Leveraging Digital Twins: Compromised Node Detection  Scenario",
    "abstract": "Modern IoT (Internet of Things) environments with thousands of low-end and diverse IoT nodes with complex interactions among them and often deployed in remote and/or wild locations present some unique challenges that make traditional node compromise detection services less effective. This paper presents the design, implementation and evaluation of a fog-based architecture that utilizes the concept of a digital-twin to detect compromised IoT nodes exhibiting malicious behaviors by either producing erroneous data and/or being used to launch network intrusion attacks to hijack other nodes eventually causing service disruption. By defining a digital twin of an IoT infrastructure at a fog server, the architecture is focused on monitoring relevant information to save energy and storage space. The paper presents a prototype implementation for the architecture utilizing malicious behavior datasets to perform misbehaving node classification. An extensive accuracy and system performance evaluation was conducted based on this prototype. Results show good accuracy and negligible overhead especially when employing deep learning techniques such as MLP (multilayer perceptron). ",
    "url": "https://arxiv.org/abs/2308.10180",
    "authors": [
      "Khaled Alanezi",
      "Shivakant Mishra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10181",
    "title": "Stochastic Optimization of Coupled Power Distribution-Urban  Transportation Network Operations with Autonomous Mobility on Demand Systems",
    "abstract": "Autonomous mobility on demand systems (AMoDS) will significantly affect the operation of coupled power distribution-urban transportation networks (PTNs) by the optimal dispatch of electric vehicles (EVs). This paper proposes an uncertainty method to analyze the operational states of PTNs with AMoDS. First, a PTN operation framework is designed considering the controllable EVs dispatched by AMoDS as well as the uncontrollable driving behaviors of other vehicle users. Then, a bi-level power-traffic flow (PTF) model is proposed to characterize the interaction of power distribution networks (PDNs) and urban transportation networks (UTNs). In the upper level, a social optimum model is established to minimize the operating cost of PDNs and UTNs embedded with controllable EVs. In the lower level, a stochastic user equilibrium (SUE) model is established to minimize the operating cost of uncontrollable EVs and gasoline vehicles (GVs) in UTNs. Finally, a probabilistic PTF analysis method is developed to evaluate PTN operations under environmental and human uncertainties. A regional sensitivity analysis method is proposed to identify the critical uncertainties and quantify the impacts of their distribution ranges on PTN operations. The effectiveness of the proposed method is verified by the PTN consisting of a 21-bus PDN and a 20-node UTN. ",
    "url": "https://arxiv.org/abs/2308.10181",
    "authors": [
      "Han Wang",
      "Xiaoyuan Xu",
      "Yue Chen",
      "Zheng Yan",
      "Mohammad Shahidehpour",
      "Jiaqi Li",
      "Shaolun Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.10187",
    "title": "Spiking-Diffusion: Vector Quantized Discrete Diffusion Model with  Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) have tremendous potential for energy-efficient neuromorphic chips due to their binary and event-driven architecture. SNNs have been primarily used in classification tasks, but limited exploration on image generation tasks. To fill the gap, we propose a Spiking-Diffusion model, which is based on the vector quantized discrete diffusion model. First, we develop a vector quantized variational autoencoder with SNNs (VQ-SVAE) to learn a discrete latent space for images. With VQ-SVAE, image features are encoded using both the spike firing rate and postsynaptic potential, and an adaptive spike generator is designed to restore embedding features in the form of spike trains. Next, we perform absorbing state diffusion in the discrete latent space and construct a diffusion image decoder with SNNs to denoise the image. Our work is the first to build the diffusion model entirely from SNN layers. Experimental results on MNIST, FMNIST, KMNIST, and Letters demonstrate that Spiking-Diffusion outperforms the existing SNN-based generation model. We achieve FIDs of 37.50, 91.98, 59.23 and 67.41 on the above datasets respectively, with reductions of 58.60\\%, 18.75\\%, 64.51\\%, and 29.75\\% in FIDs compared with the state-of-art work. ",
    "url": "https://arxiv.org/abs/2308.10187",
    "authors": [
      "Mingxuan Liu",
      "Rui Wen",
      "Hong Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10193",
    "title": "ProSpire: Proactive Spatial Prediction of Radio Environment Using Deep  Learning",
    "abstract": "Spatial prediction of the radio propagation environment of a transmitter can assist and improve various aspects of wireless networks. The majority of research in this domain can be categorized as 'reactive' spatial prediction, where the predictions are made based on a small set of measurements from an active transmitter whose radio environment is to be predicted. Emerging spectrum-sharing paradigms would benefit from 'proactive' spatial prediction of the radio environment, where the spatial predictions must be done for a transmitter for which no measurement has been collected. This paper proposes a novel, supervised deep learning-based framework, ProSpire, that enables spectrum sharing by leveraging the idea of proactive spatial prediction. We carefully address several challenges in ProSpire, such as designing a framework that conveniently collects training data for learning, performing the predictions in a fast manner, enabling operations without an area map, and ensuring that the predictions do not lead to undesired interference. ProSpire relies on the crowdsourcing of transmitters and receivers during their normal operations to address some of the aforementioned challenges. The core component of ProSpire is a deep learning-based image-to-image translation method, which we call RSSu-net. We generate several diverse datasets using ray tracing software and numerically evaluate ProSpire. Our evaluations show that RSSu-net performs reasonably well in terms of signal strength prediction, 5 dB mean absolute error, which is comparable to the average error of other relevant methods. Importantly, due to the merits of RSSu-net, ProSpire creates proactive boundaries around transmitters such that they can be activated with 97% probability of not causing interference. In this regard, the performance of RSSu-net is 19% better than that of other comparable methods. ",
    "url": "https://arxiv.org/abs/2308.10193",
    "authors": [
      "Shamik Sarkar",
      "Dongning Guo",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.10201",
    "title": "Hiding Backdoors within Event Sequence Data via Poisoning Attacks",
    "abstract": "The financial industry relies on deep learning models for making important decisions. This adoption brings new danger, as deep black-box models are known to be vulnerable to adversarial attacks. In computer vision, one can shape the output during inference by performing an adversarial attack called poisoning via introducing a backdoor into the model during training. For sequences of financial transactions of a customer, insertion of a backdoor is harder to perform, as models operate over a more complex discrete space of sequences, and systematic checks for insecurities occur. We provide a method to introduce concealed backdoors, creating vulnerabilities without altering their functionality for uncontaminated data. To achieve this, we replace a clean model with a poisoned one that is aware of the availability of a backdoor and utilize this knowledge. Our most difficult for uncovering attacks include either additional supervised detection step of poisoned data activated during the test or well-hidden model weight modifications. The experimental study provides insights into how these effects vary across different datasets, architectures, and model components. Alternative methods and baselines, such as distillation-type regularization, are also explored but found to be less efficient. Conducted on three open transaction datasets and architectures, including LSTM, CNN, and Transformer, our findings not only illuminate the vulnerabilities in contemporary models but also can drive the construction of more robust systems. ",
    "url": "https://arxiv.org/abs/2308.10201",
    "authors": [
      "Elizaveta Kovtun",
      "Alina Ermilova",
      "Dmitry Berestnev",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10209",
    "title": "Fairness-aware Competitive Bidding Influence Maximization in Social  Networks",
    "abstract": "Competitive Influence Maximization (CIM) has been studied for years due to its wide application in many domains. Most current studies primarily focus on the micro-level optimization by designing policies for one competitor to defeat its opponents. Furthermore, current studies ignore the fact that many influential nodes have their own starting prices, which may lead to inefficient budget allocation. In this paper, we propose a novel Competitive Bidding Influence Maximization (CBIM) problem, where the competitors allocate budgets to bid for the seeds attributed to the platform during multiple bidding rounds. To solve the CBIM problem, we propose a Fairness-aware Multi-agent Competitive Bidding Influence Maximization (FMCBIM) framework. In this framework, we present a Multi-agent Bidding Particle Environment (MBE) to model the competitors' interactions, and design a starting price adjustment mechanism to model the dynamic bidding environment. Moreover, we put forward a novel Multi-agent Competitive Bidding Influence Maximization (MCBIM) algorithm to optimize competitors' bidding policies. Extensive experiments on five datasets show that our work has good efficiency and effectiveness. ",
    "url": "https://arxiv.org/abs/2308.10209",
    "authors": [
      "Congcong Zhang",
      "Jingya Zhou",
      "Jin Wang",
      "Jianxi Fan",
      "Yingdan Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.10236",
    "title": "FedSIS: Federated Split Learning with Intermediate Representation  Sampling for Privacy-preserving Generalized Face Presentation Attack  Detection",
    "abstract": "Lack of generalization to unseen domains/attacks is the Achilles heel of most face presentation attack detection (FacePAD) algorithms. Existing attempts to enhance the generalizability of FacePAD solutions assume that data from multiple source domains are available with a single entity to enable centralized training. In practice, data from different source domains may be collected by diverse entities, who are often unable to share their data due to legal and privacy constraints. While collaborative learning paradigms such as federated learning (FL) can overcome this problem, standard FL methods are ill-suited for domain generalization because they struggle to surmount the twin challenges of handling non-iid client data distributions during training and generalizing to unseen domains during inference. In this work, a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS) is introduced for privacy-preserving domain generalization. In FedSIS, a hybrid Vision Transformer (ViT) architecture is learned using a combination of FL and split learning to achieve robustness against statistical heterogeneity in the client data distributions without any sharing of raw data (thereby preserving privacy). To further improve generalization to unseen domains, a novel feature augmentation strategy called intermediate representation sampling is employed, and discriminative information from intermediate blocks of a ViT is distilled using a shared adapter network. The FedSIS approach has been evaluated on two well-known benchmarks for cross-domain FacePAD to demonstrate that it is possible to achieve state-of-the-art generalization performance without data sharing. Code: https://github.com/Naiftt/FedSIS ",
    "url": "https://arxiv.org/abs/2308.10236",
    "authors": [
      "Naif Alkhunaizi",
      "Koushik Srivatsan",
      "Faris Almalik",
      "Ibrahim Almakky",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10239",
    "title": "From Global to Local: Multi-scale Out-of-distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection aims to detect \"unknown\" data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD. ",
    "url": "https://arxiv.org/abs/2308.10239",
    "authors": [
      "Ji Zhang",
      "Lianli Gao",
      "Bingguang Hao",
      "Hao Huang",
      "Jingkuan Song",
      "Hengtao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10262",
    "title": "Learning Disentangled Representation with Mutual Information  Maximization for Real-Time UAV Tracking",
    "abstract": "Efficiency has been a critical problem in UAV tracking due to limitations in computation resources, battery capacity, and unmanned aerial vehicle maximum load. Although discriminative correlation filters (DCF)-based trackers prevail in this field for their favorable efficiency, some recently proposed lightweight deep learning (DL)-based trackers using model compression demonstrated quite remarkable CPU efficiency as well as precision. Unfortunately, the model compression methods utilized by these works, though simple, are still unable to achieve satisfying tracking precision with higher compression rates. This paper aims to exploit disentangled representation learning with mutual information maximization (DR-MIM) to further improve DL-based trackers' precision and efficiency for UAV tracking. The proposed disentangled representation separates the feature into an identity-related and an identity-unrelated features. Only the latter is used, which enhances the effectiveness of the feature representation for subsequent classification and regression tasks. Extensive experiments on four UAV benchmarks, including UAV123@10fps, DTB70, UAVDT and VisDrone2018, show that our DR-MIM tracker significantly outperforms state-of-the-art UAV tracking methods. ",
    "url": "https://arxiv.org/abs/2308.10262",
    "authors": [
      "Xucheng Wang",
      "Xiangyang Yang",
      "Hengzhou Ye",
      "Shuiwang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10268",
    "title": "False Data Injection Attacks in Smart Grids: State of the Art and Way  Forward",
    "abstract": "In the recent years cyberattacks to smart grids are becoming more frequent Among the many malicious activities that can be launched against smart grids False Data Injection FDI attacks have raised significant concerns from both academia and industry FDI attacks can affect the internal state estimation processcritical for smart grid monitoring and controlthus being able to bypass conventional Bad Data Detection BDD methods Hence prompt detection and precise localization of FDI attacks is becomming of paramount importance to ensure smart grids security and safety Several papers recently started to study and analyze this topic from different perspectives and address existing challenges Datadriven techniques and mathematical modelings are the major ingredients of the proposed approaches The primary objective of this work is to provide a systematic review and insights into FDI attacks joint detection and localization approaches considering that other surveys mainly concentrated on the detection aspects without detailed coverage of localization aspects For this purpose we select and inspect more than forty major research contributions while conducting a detailed analysis of their methodology and objectives in relation to the FDI attacks detection and localization We provide our key findings of the identified papers according to different criteria such as employed FDI attacks localization techniques utilized evaluation scenarios investigated FDI attack types application scenarios adopted methodologies and the use of additional data Finally we discuss open issues and future research directions ",
    "url": "https://arxiv.org/abs/2308.10268",
    "authors": [
      "Muhammad Irfan",
      "Alireza Sadighian",
      "Adeen Tanveer",
      "Shaikha J. Al-Naimi",
      "Gabriele Oligeri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.10273",
    "title": "Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing  Continuous Conditional Generative Adversarial Networks",
    "abstract": "Continuous Conditional Generative Adversarial Networks (CcGANs) enable generative modeling conditional on continuous scalar variables (termed regression labels). However, they can produce subpar fake images due to limited training data. Although Negative Data Augmentation (NDA) effectively enhances unconditional and class-conditional GANs by introducing anomalies into real training images, guiding the GANs away from low-quality outputs, its impact on CcGANs is limited, as it fails to replicate negative samples that may occur during the CcGAN sampling. We present a novel NDA approach called Dual-NDA specifically tailored for CcGANs to address this problem. Dual-NDA employs two types of negative samples: visually unrealistic images generated from a pre-trained CcGAN and label-inconsistent images created by manipulating real images' labels. Leveraging these negative samples, we introduce a novel discriminator objective alongside a modified CcGAN training algorithm. Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA consistently enhances the visual fidelity and label consistency of fake images generated by CcGANs, exhibiting a substantial performance gain over the vanilla NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable advancement beyond the capabilities of state-of-the-art conditional GANs and diffusion models, establishing a new pinnacle of performance. ",
    "url": "https://arxiv.org/abs/2308.10273",
    "authors": [
      "Xin Ding",
      "Yongwei Wang",
      "Zuheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10278",
    "title": "CharacterChat: Learning towards Conversational AI with Personalized  Social Support",
    "abstract": "In our modern, fast-paced, and interconnected world, the importance of mental well-being has grown into a matter of great urgency. However, traditional methods such as Emotional Support Conversations (ESC) face challenges in effectively addressing a diverse range of individual personalities. In response, we introduce the Social Support Conversation (S2Conv) framework. It comprises a series of support agents and the interpersonal matching mechanism, linking individuals with persona-compatible virtual supporters. Utilizing persona decomposition based on the MBTI (Myers-Briggs Type Indicator), we have created the MBTI-1024 Bank, a group that of virtual characters with distinct profiles. Through improved role-playing prompts with behavior preset and dynamic memory, we facilitate the development of the MBTI-S2Conv dataset, which contains conversations between the characters in the MBTI-1024 Bank. Building upon these foundations, we present CharacterChat, a comprehensive S2Conv system, which includes a conversational model driven by personas and memories, along with an interpersonal matching plugin model that dispatches the optimal supporters from the MBTI-1024 Bank for individuals with specific personas. Empirical results indicate the remarkable efficacy of CharacterChat in providing personalized social support and highlight the substantial advantages derived from interpersonal matching. The source code is available in \\url{https://github.com/morecry/CharacterChat}. ",
    "url": "https://arxiv.org/abs/2308.10278",
    "authors": [
      "Quan Tu",
      "Chuanqi Chen",
      "Jinpeng Li",
      "Yanran Li",
      "Shuo Shang",
      "Dongyan Zhao",
      "Ran Wang",
      "Rui Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.10280",
    "title": "MacFormer: Map-Agent Coupled Transformer for Real-time and Robust  Trajectory Prediction",
    "abstract": "Predicting the future behavior of agents is a fundamental task in autonomous vehicle domains. Accurate prediction relies on comprehending the surrounding map, which significantly regularizes agent behaviors. However, existing methods have limitations in exploiting the map and exhibit a strong dependence on historical trajectories, which yield unsatisfactory prediction performance and robustness. Additionally, their heavy network architectures impede real-time applications. To tackle these problems, we propose Map-Agent Coupled Transformer (MacFormer) for real-time and robust trajectory prediction. Our framework explicitly incorporates map constraints into the network via two carefully designed modules named coupled map and reference extractor. A novel multi-task optimization strategy (MTOS) is presented to enhance learning of topology and rule constraints. We also devise bilateral query scheme in context fusion for a more efficient and lightweight network. We evaluated our approach on Argoverse 1, Argoverse 2, and nuScenes real-world benchmarks, where it all achieved state-of-the-art performance with the lowest inference latency and smallest model size. Experiments also demonstrate that our framework is resilient to imperfect tracklet inputs. Furthermore, we show that by combining with our proposed strategies, classical models outperform their baselines, further validating the versatility of our framework. ",
    "url": "https://arxiv.org/abs/2308.10280",
    "authors": [
      "Chen Feng",
      "Hangning Zhou",
      "Huadong Lin",
      "Zhigang Zhang",
      "Ziyao Xu",
      "Chi Zhang",
      "Boyu Zhou",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.10282",
    "title": "Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity  Analysis",
    "abstract": "Traffic prediction is one of the key elements to ensure the safety and convenience of citizens. Existing traffic prediction models primarily focus on deep learning architectures to capture spatial and temporal correlation. They often overlook the underlying nature of traffic. Specifically, the sensor networks in most traffic datasets do not accurately represent the actual road network exploited by vehicles, failing to provide insights into the traffic patterns in urban activities. To overcome these limitations, we propose an improved traffic prediction method based on graph convolution deep learning algorithms. We leverage human activity frequency data from National Household Travel Survey to enhance the inference capability of a causal relationship between activity and traffic patterns. Despite making minimal modifications to the conventional graph convolutional recurrent networks and graph convolutional transformer architectures, our approach achieves state-of-the-art performance without introducing excessive computational overhead. ",
    "url": "https://arxiv.org/abs/2308.10282",
    "authors": [
      "Sumin Han",
      "Youngjun Park",
      "Minji Lee",
      "Jisun An",
      "Dongman Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10287",
    "title": "Efficient-VRNet: An Exquisite Fusion Network for Riverway Panoptic  Perception based on Asymmetric Fair Fusion of Vision and 4D mmWave Radar",
    "abstract": "Panoptic perception is essential to unmanned surface vehicles (USVs) for autonomous navigation. The current panoptic perception scheme is mainly based on vision only, that is, object detection and semantic segmentation are performed simultaneously based on camera sensors. Nevertheless, the fusion of camera and radar sensors is regarded as a promising method which could substitute pure vision methods, but almost all works focus on object detection only. Therefore, how to maximize and subtly fuse the features of vision and radar to improve both detection and segmentation is a challenge. In this paper, we focus on riverway panoptic perception based on USVs, which is a considerably unexplored field compared with road panoptic perception. We propose Efficient-VRNet, a model based on Contextual Clustering (CoC) and the asymmetric fusion of vision and 4D mmWave radar, which treats both vision and radar modalities fairly. Efficient-VRNet can simultaneously perform detection and segmentation of riverway objects and drivable area segmentation. Furthermore, we adopt an uncertainty-based panoptic perception training strategy to train Efficient-VRNet. In the experiments, our Efficient-VRNet achieves better performances on our collected dataset than other uni-modal models, especially in adverse weather and environment with poor lighting conditions. Our code and models are available at \\url{https://github.com/GuanRunwei/Efficient-VRNet}. ",
    "url": "https://arxiv.org/abs/2308.10287",
    "authors": [
      "Runwei Guan",
      "Shanliang Yao",
      "Xiaohui Zhu",
      "Ka Lok Man",
      "Yong Yue",
      "Jeremy Smith",
      "Eng Gee Lim",
      "Yutao Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.10294",
    "title": "A review of SolarWinds attack on Orion platform using persistent threat  agents anf techniques for gaining unauthorized access",
    "abstract": "This paper of work examines the SolarWinds attack, designed on Orion Platform security incident. It analyses the persistent threats agents and potential technical attack techniques to gain unauthorized access. In 2020 SolarWinds attack indicates an initial breach disclosure on Orion Platform software by malware distribution on IT and government organizations such as Homeland Security, Microsoft and Intel associated with supply chains leaks consequences from small loopholes in security systems. Hackers increased the number of infected company and businesses networks during the supply-chain attack, hackers were capable to propagate the attack by using a VMware exploit. On the special way they started to target command injections, privilege escalations, and use after free platforms of VMware. In this way, they gained access to Virtual Machines and in the east way pivot other servers. This literature review aim to analyze the security gap regarding to SolarWinds incident on Orion Platform, the impact on industry and financial sectors involving the elements of incident response plan. Therefore, this research paper ensures specifications of proper solutions for possible defense security systems by analyzing a SolarWinds attack case study via system evaluation and monitoring. It concludes with necessary remediation actions on cyber hygiene countermeasures, common vulnerabilities and exposure analysis and solutions. ",
    "url": "https://arxiv.org/abs/2308.10294",
    "authors": [
      "Antigoni Kruti",
      "Usman Butt",
      "Rejwan Sulaiman"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10299",
    "title": "Boosting Adversarial Transferability by Block Shuffle and Rotation",
    "abstract": "Adversarial examples mislead deep neural networks with imperceptible perturbations and have brought significant threats to deep learning. An important aspect is their transferability, which refers to their ability to deceive other models, thus enabling attacks in the black-box setting. Though various methods have been proposed to boost transferability, the performance still falls short compared with white-box attacks. In this work, we observe that existing input transformation based attacks, one of the mainstream transfer-based attacks, result in different attention heatmaps on various models, which might limit the transferability. We also find that breaking the intrinsic relation of the image can disrupt the attention heatmap of the original image. Based on this finding, we propose a novel input transformation based attack called block shuffle and rotation (BSR). Specifically, BSR splits the input image into several blocks, then randomly shuffles and rotates these blocks to construct a set of new images for gradient calculation. Empirical evaluations on the ImageNet dataset demonstrate that BSR could achieve significantly better transferability than the existing input transformation based methods under single-model and ensemble-model settings. Combining BSR with the current input transformation method can further improve the transferability, which significantly outperforms the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2308.10299",
    "authors": [
      "Kunyu Wang",
      "Xuanran He",
      "Wenxuan Wang",
      "Xiaosen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.10304",
    "title": "Economic Policy Uncertainty: A Review on Applications and Measurement  Methods with Focus on Text Mining Methods",
    "abstract": "Economic Policy Uncertainty (EPU) represents the uncertainty realized by the investors during economic policy alterations. EPU is a critical indicator in economic studies to predict future investments, the unemployment rate, and recessions. EPU values can be estimated based on financial parameters directly or implied uncertainty indirectly using the text mining methods. Although EPU is a well-studied topic within the economy, the methods utilized to measure it are understudied. In this article, we define the EPU briefly and review the methods used to measure the EPU, and survey the areas influenced by the changes in EPU level. We divide the EPU measurement methods into three major groups with respect to their input data. Examples of each group of methods are enlisted, and the pros and cons of the groups are discussed. Among the EPU measures, text mining-based ones are dominantly studied. These methods measure the realized uncertainty by taking into account the uncertainty represented in the news and publicly available sources of financial information. Finally, we survey the research areas that rely on measuring the EPU index with the hope that studying the impacts of uncertainty would attract further attention of researchers from various research fields. In addition, we propose a list of future research approaches focusing on measuring EPU using textual material. ",
    "url": "https://arxiv.org/abs/2308.10304",
    "authors": [
      "Fatemeh Kaveh-Yazdy",
      "Sajjad Zarifzadeh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.10308",
    "title": "Representation Disparity-aware Distillation for 3D Object Detection",
    "abstract": "In this paper, we focus on developing knowledge distillation (KD) for compact 3D detectors. We observe that off-the-shelf KD methods manifest their efficacy only when the teacher model and student counterpart share similar intermediate feature representations. This might explain why they are less effective in building extreme-compact 3D detectors where significant representation disparity arises due primarily to the intrinsic sparsity and irregularity in 3D point clouds. This paper presents a novel representation disparity-aware distillation (RDD) method to address the representation disparity issue and reduce performance gap between compact students and over-parameterized teachers. This is accomplished by building our RDD from an innovative perspective of information bottleneck (IB), which can effectively minimize the disparity of proposal region pairs from student and teacher in features and logits. Extensive experiments are performed to demonstrate the superiority of our RDD over existing KD methods. For example, our RDD increases mAP of CP-Voxel-S to 57.1% on nuScenes dataset, which even surpasses teacher performance while taking up only 42% FLOPs. ",
    "url": "https://arxiv.org/abs/2308.10308",
    "authors": [
      "Yanjing Li",
      "Sheng Xu",
      "Mingbao Lin",
      "Jihao Yin",
      "Baochang Zhang",
      "Xianbin Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10311",
    "title": "I/O Burst Prediction for HPC Clusters using Darshan Logs",
    "abstract": "Understanding cluster-wide I/O patterns of large-scale HPC clusters is essential to minimize the occurrence and impact of I/O interference. Yet, most previous work in this area focused on monitoring and predicting task and node-level I/O burst events. This paper analyzes Darshan reports from three supercomputers to extract system-level read and write I/O rates in five minutes intervals. We observe significant (over 100x) fluctuations in read and write I/O rates in all three clusters. We then train machine learning models to estimate the occurrence of system-level I/O bursts 5 - 120 minutes ahead. Evaluation results show that we can predict I/O bursts with more than 90% accuracy (F-1 score) five minutes ahead and more than 87% accuracy two hours ahead. We also show that the ML models attain more than 70% accuracy when estimating the degree of the I/O burst. We believe that high-accuracy predictions of I/O bursts can be used in multiple ways, such as postponing delay-tolerant I/O operations (e.g., checkpointing), pausing nonessential applications (e.g., file system scrubbers), and devising I/O-aware job scheduling methods. To validate this claim, we simulated a burst-aware job scheduler that can postpone the start time of applications to avoid I/O bursts. We show that the burst-aware job scheduling can lead to an up to 5x decrease in application runtime. ",
    "url": "https://arxiv.org/abs/2308.10311",
    "authors": [
      "Ehsan Saeedizade",
      "Roya Taheri",
      "Engin Arslan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.10312",
    "title": "Demystifying the Performance of Data Transfers in High-Performance  Research Networks",
    "abstract": "High-speed research networks are built to meet the ever-increasing needs of data-intensive distributed workflows. However, data transfers in these networks often fail to attain the promised transfer rates for several reasons, including I/O and network interference, server misconfigurations, and network anomalies. Although understanding the root causes of performance issues is critical to mitigating them and increasing the utilization of expensive network infrastructures, there is currently no available mechanism to monitor data transfers in these networks. In this paper, we present a scalable, end-to-end monitoring framework to gather and store key performance metrics for file transfers to shed light on the performance of transfers. The evaluation results show that the proposed framework can monitor up to 400 transfers per host and more than 40, 000 transfers in total while collecting performance statistics at one-second precision. We also introduce a heuristic method to automatically process the gathered performance metrics and identify the root causes of performance anomalies with an F-score of 87 - 98%. ",
    "url": "https://arxiv.org/abs/2308.10312",
    "authors": [
      "Ehsan Saeedizade",
      "Bing Zhang",
      "Engin Arslan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.10315",
    "title": "Improving Adversarial Robustness of Masked Autoencoders via Test-time  Frequency-domain Prompting",
    "abstract": "In this paper, we investigate the adversarial robustness of vision transformers that are equipped with BERT pretraining (\\eg, BEiT, MAE). A surprising observation is that MAE has significantly worse adversarial robustness than other BERT pretraining methods. This observation drives us to rethink the basic differences between these BERT pretraining methods and how these differences affect the robustness against adversarial perturbations. Our empirical analysis reveals that the adversarial robustness of BERT pretraining is highly related to the reconstruction target, \\ie, predicting the raw pixels of masked image patches will degrade more adversarial robustness of the model than predicting the semantic context, since it guides the model to concentrate more on medium-/high-frequency components of images. Based on our analysis, we provide a simple yet effective way to boost the adversarial robustness of MAE. The basic idea is using the dataset-extracted domain knowledge to occupy the medium-/high-frequency of images, thus narrowing the optimization space of adversarial perturbations. Specifically, we group the distribution of pretraining data and optimize a set of cluster-specific visual prompts on frequency domain. These prompts are incorporated with input images through prototype-based prompt selection during test period. Extensive evaluation shows that our method clearly boost MAE's adversarial robustness while maintaining its clean performance on ImageNet-1k classification. Our code is available at: \\href{https://github.com/shikiw/RobustMAE}{https://github.com/shikiw/RobustMAE}. ",
    "url": "https://arxiv.org/abs/2308.10315",
    "authors": [
      "Qidong Huang",
      "Xiaoyi Dong",
      "Dongdong Chen",
      "Yinpeng Chen",
      "Lu Yuan",
      "Gang Hua",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10320",
    "title": "Hyper Association Graph Matching with Uncertainty Quantification for  Coronary Artery Semantic Labeling",
    "abstract": "Coronary artery disease (CAD) is one of the primary causes leading to death worldwide. Accurate extraction of individual arterial branches on invasive coronary angiograms (ICA) is important for stenosis detection and CAD diagnosis. However, deep learning-based models face challenges in generating semantic segmentation for coronary arteries due to the morphological similarity among different types of coronary arteries. To address this challenge, we propose an innovative approach using the hyper association graph-matching neural network with uncertainty quantification (HAGMN-UQ) for coronary artery semantic labeling on ICAs. The graph-matching procedure maps the arterial branches between two individual graphs, so that the unlabeled arterial segments are classified by the labeled segments, and the coronary artery semantic labeling is achieved. By incorporating the anatomical structural loss and uncertainty, our model achieved an accuracy of 0.9345 for coronary artery semantic labeling with a fast inference speed, leading to an effective and efficient prediction in real-time clinical decision-making scenarios. ",
    "url": "https://arxiv.org/abs/2308.10320",
    "authors": [
      "Chen Zhao",
      "Michele Esposito",
      "Zhihui Xu",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10335",
    "title": "A Study on Robustness and Reliability of Large Language Model Code  Generation",
    "abstract": "Recently, the large language models (LLMs) have shown extraordinary ability in understanding natural language and generating programming code. It has been a common practice of software engineers to consult LLMs when encountering coding questions. Although efforts have been made to avoid syntax errors and align the code with the intended semantics, the reliability and robustness of the code generationfrom LLMs have not yet been thoroughly studied. The executable code is not equivalent to the reliable and robust code, especially in the context of real-world software development.The misuse of APIs in the generated code could lead to severe problem, such as resource leaks, program crashes, etc.To make things worse, the users of LLM code generation services are actually the developers that are most vulnerable to these code that seems right -- They are always novice developers that are not familiar with the APIs that LLMs generate code for them. Therefore, they could hardly tell the misuse in the code generated by LLMs, which further facilitates the incorrect code applied in real-world software. Existing code evaluation benchmark and datasets focus on crafting small tasks such as programming questions in coding interviews, which however deviates from the problem that developers would ask LLM for real-world coding help. To fill the missing piece, in this work, we propose a dataset RobustAPI for evaluating the reliability and robustness of code generated by LLMs. We collect 1208 coding questions from StackOverflow on 24 representative Java APIs. We summarize thecommon misuse patterns of these APIs and evaluate them oncurrent popular LLMs. The evaluation results show that evenfor GPT-4, 62% of the generated code contains API misuses,which would cause unexpected consequences if the code isintroduced into real-world software. ",
    "url": "https://arxiv.org/abs/2308.10335",
    "authors": [
      "Li Zhong",
      "Zilong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.10337",
    "title": "Strata-NeRF : Neural Radiance Fields for Stratified Scenes",
    "abstract": "Neural Radiance Field (NeRF) approaches learn the underlying 3D representation of a scene and generate photo-realistic novel views with high fidelity. However, most proposed settings concentrate on modelling a single object or a single level of a scene. However, in the real world, we may capture a scene at multiple levels, resulting in a layered capture. For example, tourists usually capture a monument's exterior structure before capturing the inner structure. Modelling such scenes in 3D with seamless switching between levels can drastically improve immersive experiences. However, most existing techniques struggle in modelling such scenes. We propose Strata-NeRF, a single neural radiance field that implicitly captures a scene with multiple levels. Strata-NeRF achieves this by conditioning the NeRFs on Vector Quantized (VQ) latent representations which allow sudden changes in scene structure. We evaluate the effectiveness of our approach in multi-layered synthetic dataset comprising diverse scenes and then further validate its generalization on the real-world RealEstate10K dataset. We find that Strata-NeRF effectively captures stratified scenes, minimizes artifacts, and synthesizes high-fidelity views compared to existing approaches. ",
    "url": "https://arxiv.org/abs/2308.10337",
    "authors": [
      "Ankit Dhiman",
      "Srinath R",
      "Harsh Rangwani",
      "Rishubh Parihar",
      "Lokesh R Boregowda",
      "Srinath Sridhar",
      "R Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10347",
    "title": "Enhancing Transformers without Self-supervised Learning: A Loss  Landscape Perspective in Sequential Recommendation",
    "abstract": "Transformer and its variants are a powerful class of architectures for sequential recommendation, owing to their ability of capturing a user's dynamic interests from their past interactions. Despite their success, Transformer-based models often require the optimization of a large number of parameters, making them difficult to train from sparse data in sequential recommendation. To address the problem of data sparsity, previous studies have utilized self-supervised learning to enhance Transformers, such as pre-training embeddings from item attributes or contrastive data augmentations. However, these approaches encounter several training issues, including initialization sensitivity, manual data augmentations, and large batch-size memory bottlenecks. In this work, we investigate Transformers from the perspective of loss geometry, aiming to enhance the models' data efficiency and generalization in sequential recommendation. We observe that Transformers (e.g., SASRec) can converge to extremely sharp local minima if not adequately regularized. Inspired by the recent Sharpness-Aware Minimization (SAM), we propose SAMRec, which significantly improves the accuracy and robustness of sequential recommendation. SAMRec performs comparably to state-of-the-art self-supervised Transformers, such as S$^3$Rec and CL4SRec, without the need for pre-training or strong data augmentations. ",
    "url": "https://arxiv.org/abs/2308.10347",
    "authors": [
      "Vivian Lai",
      "Huiyuan Chen",
      "Chin-Chia Michael Yeh",
      "Minghua Xu",
      "Yiwei Cai",
      "Hao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.10370",
    "title": "cantnlp@LT-EDI@RANLP-2023: Homophobia/Transphobia Detection in Social  Media Comments using Spatio-Temporally Retrained Language Models",
    "abstract": "This paper describes our multiclass classification system developed as part of the LTEDI@RANLP-2023 shared task. We used a BERT-based language model to detect homophobic and transphobic content in social media comments across five language conditions: English, Spanish, Hindi, Malayalam, and Tamil. We retrained a transformer-based crosslanguage pretrained language model, XLMRoBERTa, with spatially and temporally relevant social media language data. We also retrained a subset of models with simulated script-mixed social media language data with varied performance. We developed the best performing seven-label classification system for Malayalam based on weighted macro averaged F1 score (ranked first out of six) with variable performance for other language and class-label conditions. We found the inclusion of this spatio-temporal data improved the classification performance for all language and task conditions when compared with the baseline. The results suggests that transformer-based language classification systems are sensitive to register-specific and language-specific retraining. ",
    "url": "https://arxiv.org/abs/2308.10370",
    "authors": [
      "Sidney G.-J. Wong",
      "Matthew Durward",
      "Benjamin Adams",
      "Jonathan Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.10373",
    "title": "HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with  Adaptive Firing Thresholds",
    "abstract": "Spiking neural networks (SNNs) offer promise for efficient and powerful neurally inspired computation. Common to other types of neural networks, however, SNNs face the severe issue of vulnerability to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to develop a bio-inspired solution that counters the susceptibilities of SNNs to adversarial onslaughts. At the heart of our approach is a novel threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model, which we adopt to construct the proposed adversarially robust homeostatic SNN (HoSNN). Distinct from traditional LIF models, our TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, curtailing adversarial noise propagation and safeguarding the robustness of HoSNNs in an unsupervised manner. Theoretical analysis is presented to shed light on the stability and convergence properties of the TA-LIF neurons, underscoring their superior dynamic robustness under input distributional shifts over traditional LIF neurons. Remarkably, without explicit adversarial training, our HoSNNs demonstrate inherent robustness on CIFAR-10, with accuracy improvements to 72.6% and 54.19% against FGSM and PGD attacks, up from 20.97% and 0.6%, respectively. Furthermore, with minimal FGSM adversarial training, our HoSNNs surpass previous models by 29.99% under FGSM and 47.83% under PGD attacks on CIFAR-10. Our findings offer a new perspective on harnessing biological principles for bolstering SNNs adversarial robustness and defense, paving the way to more resilient neuromorphic computing. ",
    "url": "https://arxiv.org/abs/2308.10373",
    "authors": [
      "Hejia Geng",
      "Peng Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10388",
    "title": "Neural Architectures Learning Fourier Transforms, Signal Processing and  Much More....",
    "abstract": "This report will explore and answer fundamental questions about taking Fourier Transforms and tying it with recent advances in AI and neural architecture. One interpretation of the Fourier Transform is decomposing a signal into its constituent components by projecting them onto complex exponentials. Variants exist, such as discrete cosine transform that does not operate on the complex domain and projects an input signal to only cosine functions oscillating at different frequencies. However, this is a fundamental limitation, and it needs to be more suboptimal. The first one is that all kernels are sinusoidal: What if we could have some kernels adapted or learned according to the problem? What if we can use neural architectures for this? We show how one can learn these kernels from scratch for audio signal processing applications. We find that the neural architecture not only learns sinusoidal kernel shapes but discovers all kinds of incredible signal-processing properties. E.g., windowing functions, onset detectors, high pass filters, low pass filters, modulations, etc. Further, upon analysis of the filters, we find that the neural architecture has a comb filter-like structure on top of the learned kernels. Comb filters that allow harmonic frequencies to pass through are one of the core building blocks/types of filters similar to high-pass, low-pass, and band-pass filters of various traditional signal processing algorithms. Further, we can also use the convolution operation with a signal to be learned from scratch, and we will explore papers in the literature that uses this with that robust Transformer architectures. Further, we would also explore making the learned kernel's content adaptive, i.e., learning different kernels for different inputs. ",
    "url": "https://arxiv.org/abs/2308.10388",
    "authors": [
      "Prateek Verma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.10392",
    "title": "Towards Generalizable Morph Attack Detection with Consistency  Regularization",
    "abstract": "Though recent studies have made significant progress in morph attack detection by virtue of deep neural networks, they often fail to generalize well to unseen morph attacks. With numerous morph attacks emerging frequently, generalizable morph attack detection has gained significant attention. This paper focuses on enhancing the generalization capability of morph attack detection from the perspective of consistency regularization. Consistency regularization operates under the premise that generalizable morph attack detection should output consistent predictions irrespective of the possible variations that may occur in the input space. In this work, to reach this objective, two simple yet effective morph-wise augmentations are proposed to explore a wide space of realistic morph transformations in our consistency regularization. Then, the model is regularized to learn consistently at the logit as well as embedding levels across a wide range of morph-wise augmented images. The proposed consistency regularization aligns the abstraction in the hidden layers of our model across the morph attack images which are generated from diverse domains in the wild. Experimental results demonstrate the superior generalization and robustness performance of our proposed method compared to the state-of-the-art studies. ",
    "url": "https://arxiv.org/abs/2308.10392",
    "authors": [
      "Hossein Kashiani",
      "Niloufar Alipour Talemi",
      "Mohammad Saeed Ebrahimi Saadabadi",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10421",
    "title": "UniM$^2$AE: Multi-modal Masked Autoencoders with Unified 3D  Representation for 3D Perception in Autonomous Driving",
    "abstract": "Masked Autoencoders (MAE) play a pivotal role in learning potent representations, delivering outstanding results across various 3D perception tasks essential for autonomous driving. In real-world driving scenarios, it's commonplace to deploy multiple sensors for comprehensive environment perception. While integrating multi-modal features from these sensors can produce rich and powerful features, there is a noticeable gap in MAE methods addressing this integration. This research delves into multi-modal Masked Autoencoders tailored for a unified representation space in autonomous driving, aiming to pioneer a more efficient fusion of two distinct modalities. To intricately marry the semantics inherent in images with the geometric intricacies of LiDAR point clouds, the UniM$^2$AE is proposed. This model stands as a potent yet straightforward, multi-modal self-supervised pre-training framework, mainly consisting of two designs. First, it projects the features from both modalities into a cohesive 3D volume space, ingeniously expanded from the bird's eye view (BEV) to include the height dimension. The extension makes it possible to back-project the informative features, obtained by fusing features from both modalities, into their native modalities to reconstruct the multiple masked inputs. Second, the Multi-modal 3D Interactive Module (MMIM) is invoked to facilitate the efficient inter-modal interaction during the interaction process. Extensive experiments conducted on the nuScenes Dataset attest to the efficacy of UniM$^2$AE, indicating enhancements in 3D object detection and BEV map segmentation by 1.2\\%(NDS) and 6.5\\% (mIoU), respectively. Code is available at https://github.com/hollow-503/UniM2AE. ",
    "url": "https://arxiv.org/abs/2308.10421",
    "authors": [
      "Jian Zou",
      "Tianyu Huang",
      "Guanglei Yang",
      "Zhenhua Guo",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10425",
    "title": "Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for  Traffic Forecasting",
    "abstract": "With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge. The key bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In recent years, numerous neural networks with complicated architectures have been proposed to address this issue. However, the advancements in network architectures have encountered diminishing performance gains. In this study, we present a novel component called spatio-temporal adaptive embedding that can yield outstanding results with vanilla transformers. Our proposed Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves state-of-the-art performance on five real-world traffic forecasting datasets. Further experiments demonstrate that spatio-temporal adaptive embedding plays a crucial role in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series. ",
    "url": "https://arxiv.org/abs/2308.10425",
    "authors": [
      "Hangchen Liu",
      "Zheng Dong",
      "Renhe Jiang",
      "Jiewen Deng",
      "Jinliang Deng",
      "Quanjun Chen",
      "Xuan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10427",
    "title": "Federated Learning Robust to Byzantine Attacks: Achieving Zero  Optimality Gap",
    "abstract": "In this paper, we propose a robust aggregation method for federated learning (FL) that can effectively tackle malicious Byzantine attacks. At each user, model parameter is firstly updated by multiple steps, which is adjustable over iterations, and then pushed to the aggregation center directly. This decreases the number of interactions between the aggregation center and users, allows each user to set training parameter in a flexible way, and reduces computation burden compared with existing works that need to combine multiple historical model parameters. At the aggregation center, geometric median is leveraged to combine the received model parameters from each user. Rigorous proof shows that zero optimality gap is achieved by our proposed method with linear convergence, as long as the fraction of Byzantine attackers is below half. Numerical results verify the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2308.10427",
    "authors": [
      "Shiyuan Zuo",
      "Rongfei Fan",
      "Han Hu",
      "Ning Zhang",
      "Shimin Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.10438",
    "title": "Efficient Joint Optimization of Layer-Adaptive Weight Pruning in Deep  Neural Networks",
    "abstract": "In this paper, we propose a novel layer-adaptive weight-pruning approach for Deep Neural Networks (DNNs) that addresses the challenge of optimizing the output distortion minimization while adhering to a target pruning ratio constraint. Our approach takes into account the collective influence of all layers to design a layer-adaptive pruning scheme. We discover and utilize a very important additivity property of output distortion caused by pruning weights on multiple layers. This property enables us to formulate the pruning as a combinatorial optimization problem and efficiently solve it through dynamic programming. By decomposing the problem into sub-problems, we achieve linear time complexity, making our optimization algorithm fast and feasible to run on CPUs. Our extensive experiments demonstrate the superiority of our approach over existing methods on the ImageNet and CIFAR-10 datasets. On CIFAR-10, our method achieves remarkable improvements, outperforming others by up to 1.0% for ResNet-32, 0.5% for VGG-16, and 0.7% for DenseNet-121 in terms of top-1 accuracy. On ImageNet, we achieve up to 4.7% and 4.6% higher top-1 accuracy compared to other methods for VGG-16 and ResNet-50, respectively. These results highlight the effectiveness and practicality of our approach for enhancing DNN performance through layer-adaptive weight pruning. Code will be available on https://github.com/Akimoto-Cris/RD_VIT_PRUNE. ",
    "url": "https://arxiv.org/abs/2308.10438",
    "authors": [
      "Kaixin Xu",
      "Zhe Wang",
      "Xue Geng",
      "Min Wu",
      "Xiaoli Li",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10442",
    "title": "DySuse: Susceptibility Estimation in Dynamic Social Networks",
    "abstract": "Influence estimation aims to predict the total influence spread in social networks and has received surged attention in recent years. Most current studies focus on estimating the total number of influenced users in a social network, and neglect susceptibility estimation that aims to predict the probability of each user being influenced from the individual perspective. As a more fine-grained estimation task, susceptibility estimation is full of attractiveness and practical value. Based on the significance of susceptibility estimation and dynamic properties of social networks, we propose a task, called susceptibility estimation in dynamic social networks, which is even more realistic and valuable in real-world applications. Susceptibility estimation in dynamic networks has yet to be explored so far and is computationally intractable to naively adopt Monte Carlo simulation to obtain the results. To this end, we propose a novel end-to-end framework DySuse based on dynamic graph embedding technology. Specifically, we leverage a structural feature module to independently capture the structural information of influence diffusion on each single graph snapshot. Besides, {we propose the progressive mechanism according to the property of influence diffusion,} to couple the structural and temporal information during diffusion tightly. Moreover, a self-attention block {is designed to} further capture temporal dependency by flexibly weighting historical timestamps. Experimental results show that our framework is superior to the existing dynamic graph embedding models and has satisfactory prediction performance in multiple influence diffusion models. ",
    "url": "https://arxiv.org/abs/2308.10442",
    "authors": [
      "Yingdan Shi",
      "Jingya Zhou",
      "Congcong Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10452",
    "title": "Comparing Measures of Linguistic Diversity Across Social Media Language  Data and Census Data at Subnational Geographic Areas",
    "abstract": "This paper describes a preliminary study on the comparative linguistic ecology of online spaces (i.e., social media language data) and real-world spaces in Aotearoa New Zealand (i.e., subnational administrative areas). We compare measures of linguistic diversity between these different spaces and discuss how social media users align with real-world populations. The results from the current study suggests that there is potential to use online social media language data to observe spatial and temporal changes in linguistic diversity at subnational geographic areas; however, further work is required to understand how well social media represents real-world behaviour. ",
    "url": "https://arxiv.org/abs/2308.10452",
    "authors": [
      "Sidney G.-J. Wong",
      "Jonathan Dunn",
      "Benjamin Adams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.10457",
    "title": "Adaptive Local Steps Federated Learning with Differential Privacy Driven  by Convergence Analysis",
    "abstract": "Federated Learning (FL) is a distributed machine learning technique that allows model training among multiple devices or organizations without sharing data. However, while FL ensures that the raw data is not directly accessible to external adversaries, adversaries can still obtain some statistical information about the data through differential attacks. Differential Privacy (DP) has been proposed, which adds noise to the model or gradients to prevent adversaries from inferring private information from the transmitted parameters. We reconsider the framework of differential privacy federated learning in resource-constrained scenarios (privacy budget and communication resources). We analyze the convergence of federated learning with differential privacy (DPFL) on resource-constrained scenarios and propose an Adaptive Local Steps Differential Privacy Federated Learning (ALS-DPFL) algorithm. We experiment our algorithm on the FashionMNIST and Cifar-10 datasets and achieve quite good performance relative to previous work. ",
    "url": "https://arxiv.org/abs/2308.10457",
    "authors": [
      "Xinpeng Ling",
      "Jie Fu",
      "Zhili Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10458",
    "title": "Unraveling Low-Dimensional Network Dynamics: A Fusion of Sparse  Identification and Proper Orthogonal Decomposition",
    "abstract": "This study addresses the challenge of predicting network dynamics, such as forecasting disease spread in social networks or estimating species populations in predator-prey networks. Accurate predictions in large networks are difficult due to the increasing number of network dynamics parameters that grow with the size of the network population (e.g., each individual having its own contact and recovery rates in an epidemic process), and because the network topology is unknown or cannot be observed accurately. Inspired by the low-dimensionality inherent in network dynamics, we propose a two-step method. First, we decompose the network dynamics into a composite of principal components, each weighted by time-dependent coefficients. Subsequently, we learn the governing differential equations for these time-dependent coefficients using sparse regression over a function library capable of describing the dynamics. We illustrate the effectiveness of our proposed approach using simulated network dynamics datasets. The results provide compelling evidence of our method's potential to enhance predictions in complex networks. ",
    "url": "https://arxiv.org/abs/2308.10458",
    "authors": [
      "Rui Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2308.10462",
    "title": "Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation  with Large Language Models",
    "abstract": "Large Language Models (LLMs) possess impressive capabilities to generate meaningful code snippets given natural language intents in zero-shot, i.e., without the need for specific fine-tuning. In the perspective of unleashing their full potential, prior work has demonstrated the benefits of fine-tuning the models to task-specific data. However, fine-tuning process demands heavy computational costs and is intractable when resources are scarce, especially for models with billions of parameters. In light of these challenges, previous studies explored In-Context Learning (ICL) as an effective strategy to generate contextually appropriate code without fine-tuning. However, it operates at inference time and does not involve learning task-specific parameters, potentially limiting the model's performance on downstream tasks. In this context, we foresee that Parameter-Efficient Fine-Tuning (PEFT) techniques carry a high potential for efficiently specializing LLMs to task-specific data. In this paper, we deliver a comprehensive study of LLMs with the impact of PEFT techniques under the automated code generation scenario. Our experimental results reveal the superiority and potential of such techniques over ICL on a wide range of LLMs in reducing the computational burden and improving performance. Therefore, the study opens opportunities for broader applications of PEFT in software engineering scenarios. ",
    "url": "https://arxiv.org/abs/2308.10462",
    "authors": [
      "Martin Weyssow",
      "Xin Zhou",
      "Kisub Kim",
      "David Lo",
      "Houari Sahraoui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10467",
    "title": "Single-User Injection for Invisible Shilling Attack against Recommender  Systems",
    "abstract": "Recommendation systems (RS) are crucial for alleviating the information overload problem. Due to its pivotal role in guiding users to make decisions, unscrupulous parties are lured to launch attacks against RS to affect the decisions of normal users and gain illegal profits. Among various types of attacks, shilling attack is one of the most subsistent and profitable attacks. In shilling attack, an adversarial party injects a number of well-designed fake user profiles into the system to mislead RS so that the attack goal can be achieved. Although existing shilling attack methods have achieved promising results, they all adopt the attack paradigm of multi-user injection, where some fake user profiles are required. This paper provides the first study of shilling attack in an extremely limited scenario: only one fake user profile is injected into the victim RS to launch shilling attacks (i.e., single-user injection). We propose a novel single-user injection method SUI-Attack for invisible shilling attack. SUI-Attack is a graph based attack method that models shilling attack as a node generation task over the user-item bipartite graph of the victim RS, and it constructs the fake user profile by generating user features and edges that link the fake user to items. Extensive experiments demonstrate that SUI-Attack can achieve promising attack results in single-user injection. In addition to its attack power, SUI-Attack increases the stealthiness of shilling attack and reduces the risk of being detected. We provide our implementation at: https://github.com/KDEGroup/SUI-Attack. ",
    "url": "https://arxiv.org/abs/2308.10467",
    "authors": [
      "Chengzhi Huang",
      "Hui Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10481",
    "title": "ADNet: Lane Shape Prediction via Anchor Decomposition",
    "abstract": "In this paper, we revisit the limitations of anchor-based lane detection methods, which have predominantly focused on fixed anchors that stem from the edges of the image, disregarding their versatility and quality. To overcome the inflexibility of anchors, we decompose them into learning the heat map of starting points and their associated directions. This decomposition removes the limitations on the starting point of anchors, making our algorithm adaptable to different lane types in various datasets. To enhance the quality of anchors, we introduce the Large Kernel Attention (LKA) for Feature Pyramid Network (FPN). This significantly increases the receptive field, which is crucial in capturing the sufficient context as lane lines typically run throughout the entire image. We have named our proposed system the Anchor Decomposition Network (ADNet). Additionally, we propose the General Lane IoU (GLIoU) loss, which significantly improves the performance of ADNet in complex scenarios. Experimental results on three widely used lane detection benchmarks, VIL-100, CULane, and TuSimple, demonstrate that our approach outperforms the state-of-the-art methods on VIL-100 and exhibits competitive accuracy on CULane and TuSimple. Code and models will be released on https://github.com/ Sephirex-X/ADNet. ",
    "url": "https://arxiv.org/abs/2308.10481",
    "authors": [
      "Lingyu Xiao",
      "Xiang Li",
      "Sen Yang",
      "Wankou Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10482",
    "title": "An Effective Method using Phrase Mechanism in Neural Machine Translation",
    "abstract": "Machine Translation is one of the essential tasks in Natural Language Processing (NLP), which has massive applications in real life as well as contributing to other tasks in the NLP research community. Recently, Transformer -based methods have attracted numerous researchers in this domain and achieved state-of-the-art results in most of the pair languages. In this paper, we report an effective method using a phrase mechanism, PhraseTransformer, to improve the strong baseline model Transformer in constructing a Neural Machine Translation (NMT) system for parallel corpora Vietnamese-Chinese. Our experiments on the MT dataset of the VLSP 2022 competition achieved the BLEU score of 35.3 on Vietnamese to Chinese and 33.2 BLEU scores on Chinese to Vietnamese data. Our code is available at https://github.com/phuongnm94/PhraseTransformer. ",
    "url": "https://arxiv.org/abs/2308.10482",
    "authors": [
      "Phuong Minh Nguyen",
      "Le Minh Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10483",
    "title": "Aggregate Model of District Heating Network for Integrated Energy  Dispatch: A Physically Informed Data-Driven Approach",
    "abstract": "The district heating network (DHN) is essential in enhancing the operational flexibility of integrated energy systems (IES). Yet, it is hard to obtain an accurate and concise DHN model for the operation owing to complicated network features and imperfect measurement. Considering this, this paper proposes a physically informed data-driven aggregate model (AGM) for DHN, providing a concise description of the source-load relationship of DHN without exposing network details. First, we derive the analytical relationship between the state variables of the source and load nodes of DHN, offering a physical fundament for the AGM. Second, we propose a physics-informed estimator for AGM that is robust to low-quality measurement, in which the physical constraints associated with the parameter normalization and sparsity are embedded to improve the accuracy and robustness. Finally, we propose a physics-enhanced algorithm to solve the nonlinear estimator with non-closed constraints efficiently. Simulation results verify the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2308.10483",
    "authors": [
      "Shuai Lu",
      "Zihang Gao",
      "Yong Sun",
      "Suhan Zhang",
      "Baoju Li",
      "Chengliang Hao",
      "Yijun Xu",
      "Wei Gu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.10493",
    "title": "Semantic Graph Representation Learning for Handwritten Mathematical  Expression Recognition",
    "abstract": "Handwritten mathematical expression recognition (HMER) has attracted extensive attention recently. However, current methods cannot explicitly study the interactions between different symbols, which may fail when faced similar symbols. To alleviate this issue, we propose a simple but efficient method to enhance semantic interaction learning (SIL). Specifically, we firstly construct a semantic graph based on the statistical symbol co-occurrence probabilities. Then we design a semantic aware module (SAM), which projects the visual and classification feature into semantic space. The cosine distance between different projected vectors indicates the correlation between symbols. And jointly optimizing HMER and SIL can explicitly enhances the model's understanding of symbol relationships. In addition, SAM can be easily plugged into existing attention-based models for HMER and consistently bring improvement. Extensive experiments on public benchmark datasets demonstrate that our proposed module can effectively enhance the recognition performance. Our method achieves better recognition performance than prior arts on both CROHME and HME100K datasets. ",
    "url": "https://arxiv.org/abs/2308.10493",
    "authors": [
      "Zhuang Liu",
      "Ye Yuan",
      "Zhilong Ji",
      "Jingfeng Bai",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10504",
    "title": "Adaptive Thresholding Heuristic for KPI Anomaly Detection",
    "abstract": "A plethora of outlier detectors have been explored in the time series domain, however, in a business sense, not all outliers are anomalies of interest. Existing anomaly detection solutions are confined to certain outlier detectors limiting their applicability to broader anomaly detection use cases. Network KPIs (Key Performance Indicators) tend to exhibit stochastic behaviour producing statistical outliers, most of which do not adversely affect business operations. Thus, a heuristic is required to capture the business definition of an anomaly for time series KPI. This article proposes an Adaptive Thresholding Heuristic (ATH) to dynamically adjust the detection threshold based on the local properties of the data distribution and adapt to changes in time series patterns. The heuristic derives the threshold based on the expected periodicity and the observed proportion of anomalies minimizing false positives and addressing concept drift. ATH can be used in conjunction with any underlying seasonality decomposition method and an outlier detector that yields an outlier score. This method has been tested on EON1-Cell-U, a labeled KPI anomaly dataset produced by Ericsson, to validate our hypothesis. Experimental results show that ATH is computationally efficient making it scalable for near real time anomaly detection and flexible with multiple forecasters and outlier detectors. ",
    "url": "https://arxiv.org/abs/2308.10504",
    "authors": [
      "Ebenezer R.H.P. Isaac",
      "Akshat Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.10515",
    "title": "QD-BEV : Quantization-aware View-guided Distillation for Multi-view 3D  Object Detection",
    "abstract": "Multi-view 3D detection based on BEV (bird-eye-view) has recently achieved significant improvements. However, the huge memory consumption of state-of-the-art models makes it hard to deploy them on vehicles, and the non-trivial latency will affect the real-time perception of streaming applications. Despite the wide application of quantization to lighten models, we show in our paper that directly applying quantization in BEV tasks will 1) make the training unstable, and 2) lead to intolerable performance degradation. To solve these issues, our method QD-BEV enables a novel view-guided distillation (VGD) objective, which can stabilize the quantization-aware training (QAT) while enhancing the model performance by leveraging both image features and BEV features. Our experiments show that QD-BEV achieves similar or even better accuracy than previous methods with significant efficiency gains. On the nuScenes datasets, the 4-bit weight and 6-bit activation quantized QD-BEV-Tiny model achieves 37.2% NDS with only 15.8 MB model size, outperforming BevFormer-Tiny by 1.8% with an 8x model compression. On the Small and Base variants, QD-BEV models also perform superbly and achieve 47.9% NDS (28.2 MB) and 50.9% NDS (32.9 MB), respectively. ",
    "url": "https://arxiv.org/abs/2308.10515",
    "authors": [
      "Yifan Zhang",
      "Zhen Dong",
      "Huanrui Yang",
      "Ming Lu",
      "Cheng-Ching Tseng",
      "Yuan Du",
      "Kurt Keutzer",
      "Li Du",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10521",
    "title": "PHE-SICH-CT-IDS: A Benchmark CT Image Dataset for Evaluation Semantic  Segmentation, Object Detection and Radiomic Feature Extraction of  Perihematomal Edema in Spontaneous Intracerebral Hemorrhage",
    "abstract": "Intracerebral hemorrhage is one of the diseases with the highest mortality and poorest prognosis worldwide. Spontaneous intracerebral hemorrhage (SICH) typically presents acutely, prompt and expedited radiological examination is crucial for diagnosis, localization, and quantification of the hemorrhage. Early detection and accurate segmentation of perihematomal edema (PHE) play a critical role in guiding appropriate clinical intervention and enhancing patient prognosis. However, the progress and assessment of computer-aided diagnostic methods for PHE segmentation and detection face challenges due to the scarcity of publicly accessible brain CT image datasets. This study establishes a publicly available CT dataset named PHE-SICH-CT-IDS for perihematomal edema in spontaneous intracerebral hemorrhage. The dataset comprises 120 brain CT scans and 7,022 CT images, along with corresponding medical information of the patients. To demonstrate its effectiveness, classical algorithms for semantic segmentation, object detection, and radiomic feature extraction are evaluated. The experimental results confirm the suitability of PHE-SICH-CT-IDS for assessing the performance of segmentation, detection and radiomic feature extraction methods. To the best of our knowledge, this is the first publicly available dataset for PHE in SICH, comprising various data formats suitable for applications across diverse medical scenarios. We believe that PHE-SICH-CT-IDS will allure researchers to explore novel algorithms, providing valuable support for clinicians and patients in the clinical setting. PHE-SICH-CT-IDS is freely published for non-commercial purpose at: https://figshare.com/articles/dataset/PHE-SICH-CT-IDS/23957937. ",
    "url": "https://arxiv.org/abs/2308.10521",
    "authors": [
      "Deguo Ma",
      "Chen Li",
      "Lin Qiao",
      "Tianming Du",
      "Dechao Tang",
      "Zhiyu Ma",
      "Marcin Grzegorzek Hongzan",
      "Hongzan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10523",
    "title": "When Less is Enough: Positive and Unlabeled Learning Model for  Vulnerability Detection",
    "abstract": "Automated code vulnerability detection has gained increasing attention in recent years. The deep learning (DL)-based methods, which implicitly learn vulnerable code patterns, have proven effective in vulnerability detection. The performance of DL-based methods usually relies on the quantity and quality of labeled data. However, the current labeled data are generally automatically collected, such as crawled from human-generated commits, making it hard to ensure the quality of the labels. Prior studies have demonstrated that the non-vulnerable code (i.e., negative labels) tends to be unreliable in commonly-used datasets, while vulnerable code (i.e., positive labels) is more determined. Considering the large numbers of unlabeled data in practice, it is necessary and worth exploring to leverage the positive data and large numbers of unlabeled data for more accurate vulnerability detection. In this paper, we focus on the Positive and Unlabeled (PU) learning problem for vulnerability detection and propose a novel model named PILOT, i.e., PositIve and unlabeled Learning mOdel for vulnerability deTection. PILOT only learns from positive and unlabeled data for vulnerability detection. It mainly contains two modules: (1) A distance-aware label selection module, aiming at generating pseudo-labels for selected unlabeled data, which involves the inter-class distance prototype and progressive fine-tuning; (2) A mixed-supervision representation learning module to further alleviate the influence of noise and enhance the discrimination of representations. ",
    "url": "https://arxiv.org/abs/2308.10523",
    "authors": [
      "Xin-Cheng Wen",
      "Xinchen Wang",
      "Cuiyun Gao",
      "Shaohua Wang",
      "Yang Liu",
      "Zhaoquan Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10527",
    "title": "DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant  Recommendations",
    "abstract": "In e-commerce platforms, the relevant recommendation is a unique scenario providing related items for a trigger item that users are interested in. However, users' preferences for the similarity and diversity of recommendation results are dynamic and vary under different conditions. Moreover, individual item-level diversity is too coarse-grained since all recommended items are related to the trigger item. Thus, the two main challenges are to learn fine-grained representations of similarity and diversity and capture users' dynamic preferences for them under different conditions. To address these challenges, we propose a novel method called the Dynamic Preference-based and Attribute-aware Network (DPAN) for predicting Click-Through Rate (CTR) in relevant recommendations. Specifically, based on Attribute-aware Activation Values Generation (AAVG), Bi-dimensional Compression-based Re-expression (BCR) is designed to obtain similarity and diversity representations of user interests and item information. Then Shallow and Deep Union-based Fusion (SDUF) is proposed to capture users' dynamic preferences for the diverse degree of recommendation results according to various conditions. DPAN has demonstrated its effectiveness through extensive offline experiments and online A/B testing, resulting in a significant 7.62% improvement in CTR. Currently, DPAN has been successfully deployed on our e-commerce platform serving the primary traffic for relevant recommendations. The code of DPAN has been made publicly available. ",
    "url": "https://arxiv.org/abs/2308.10527",
    "authors": [
      "Wei Dai",
      "Yingmin Su",
      "Xiaofeng Pan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10531",
    "title": "SRFormer: Empowering Regression-Based Text Detection Transformer with  Segmentation",
    "abstract": "Existing techniques for text detection can be broadly classified into two primary groups: segmentation-based methods and regression-based methods. Segmentation models offer enhanced robustness to font variations but require intricate post-processing, leading to high computational overhead. Regression-based methods undertake instance-aware prediction but face limitations in robustness and data efficiency due to their reliance on high-level representations. In our academic pursuit, we propose SRFormer, a unified DETR-based model with amalgamated Segmentation and Regression, aiming at the synergistic harnessing of the inherent robustness in segmentation representations, along with the straightforward post-processing of instance-level regression. Our empirical analysis indicates that favorable segmentation predictions can be obtained at the initial decoder layers. In light of this, we constrain the incorporation of segmentation branches to the first few decoder layers and employ progressive regression refinement in subsequent layers, achieving performance gains while minimizing additional computational load from the mask. Furthermore, we propose a Mask-informed Query Enhancement module. We take the segmentation result as a natural soft-ROI to pool and extract robust pixel representations, which are then employed to enhance and diversify instance queries. Extensive experimentation across multiple benchmarks has yielded compelling findings, highlighting our method's exceptional robustness, superior training and data efficiency, as well as its state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2308.10531",
    "authors": [
      "Qingwen Bu",
      "Sungrae Park",
      "Minsoo Khang",
      "Yichuan Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10537",
    "title": "KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks",
    "abstract": "In recent years, countless research papers have addressed the topics of knowledge graph creation, extension, or completion in order to create knowledge graphs that are larger, more correct, or more diverse. This research is typically motivated by the argumentation that using such enhanced knowledge graphs to solve downstream tasks will improve performance. Nonetheless, this is hardly ever evaluated. Instead, the predominant evaluation metrics - aiming at correctness and completeness - are undoubtedly valuable but fail to capture the complete picture, i.e., how useful the created or enhanced knowledge graph actually is. Further, the accessibility of such a knowledge graph is rarely considered (e.g., whether it contains expressive labels, descriptions, and sufficient context information to link textual mentions to the entities of the knowledge graph). To better judge how well knowledge graphs perform on actual tasks, we present KGrEaT - a framework to estimate the quality of knowledge graphs via actual downstream tasks like classification, clustering, or recommendation. Instead of comparing different methods of processing knowledge graphs with respect to a single task, the purpose of KGrEaT is to compare various knowledge graphs as such by evaluating them on a fixed task setup. The framework takes a knowledge graph as input, automatically maps it to the datasets to be evaluated on, and computes performance metrics for the defined tasks. It is built in a modular way to be easily extendable with additional tasks and datasets. ",
    "url": "https://arxiv.org/abs/2308.10537",
    "authors": [
      "Nicolas Heist",
      "Sven Hertling",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10561",
    "title": "Spatial Transform Decoupling for Oriented Object Detection",
    "abstract": "Vision Transformers (ViTs) have achieved remarkable success in computer vision tasks. However, their potential in rotation-sensitive scenarios has not been fully explored, and this limitation may be inherently attributed to the lack of spatial invariance in the data-forwarding process. In this study, we present a novel approach, termed Spatial Transform Decoupling (STD), providing a simple-yet-effective solution for oriented object detection with ViTs. Built upon stacked ViT blocks, STD utilizes separate network branches to predict the position, size, and angle of bounding boxes, effectively harnessing the spatial transform potential of ViTs in a divide-and-conquer fashion. Moreover, by aggregating cascaded activation masks (CAMs) computed upon the regressed parameters, STD gradually enhances features within regions of interest (RoIs), which complements the self-attention mechanism. Without bells and whistles, STD achieves state-of-the-art performance on the benchmark datasets including DOTA-v1.0 (82.24% mAP) and HRSC2016 (98.55% mAP), which demonstrates the effectiveness of the proposed method. Source code is available at https://github.com/yuhongtian17/Spatial-Transform-Decoupling. ",
    "url": "https://arxiv.org/abs/2308.10561",
    "authors": [
      "Hongtian Yu",
      "Yunjie Tian",
      "Qixiang Ye",
      "Yunfan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10570",
    "title": "Self-Feedback DETR for Temporal Action Detection",
    "abstract": "Temporal Action Detection (TAD) is challenging but fundamental for real-world video applications. Recently, DETR-based models have been devised for TAD but have not performed well yet. In this paper, we point out the problem in the self-attention of DETR for TAD; the attention modules focus on a few key elements, called temporal collapse problem. It degrades the capability of the encoder and decoder since their self-attention modules play no role. To solve the problem, we propose a novel framework, Self-DETR, which utilizes cross-attention maps of the decoder to reactivate self-attention modules. We recover the relationship between encoder features by simple matrix multiplication of the cross-attention map and its transpose. Likewise, we also get the information within decoder queries. By guiding collapsed self-attention maps with the guidance map calculated, we settle down the temporal collapse of self-attention modules in the encoder and decoder. Our extensive experiments demonstrate that Self-DETR resolves the temporal collapse problem by keeping high diversity of attention over all layers. ",
    "url": "https://arxiv.org/abs/2308.10570",
    "authors": [
      "Jihwan Kim",
      "Miso Lee",
      "Jae-Pil Heo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10579",
    "title": "Demand-Aware Network Design with Steiner Nodes and a Connection to  Virtual Network Embedding",
    "abstract": "Emerging optical and virtualization technologies enable the design of more flexible and demand-aware networked systems, in which resources can be optimized toward the actual workload they serve. For example, in a demand-aware datacenter network, frequently communicating nodes (e.g., two virtual machines or a pair of racks in a datacenter) can be placed topologically closer, reducing communication costs and hence improving the overall network performance. This paper revisits the bounded-degree network design problem underlying such demand-aware networks. Namely, given a distribution over communicating server pairs, we want to design a network with bounded maximum degree that minimizes expected communication distance. In addition to this known problem, we introduce and study a variant where we allow Steiner nodes (i.e., additional routers) to be added to augment the network. We improve the understanding of this problem domain in several ways. First, we shed light on the complexity and hardness of the aforementioned problems, and study a connection between them and the virtual networking embedding problem. We then provide a constant-factor approximation algorithm for the Steiner node version of the problem, and use it to improve over prior state-of-the-art algorithms for the original version of the problem with sparse communication distributions. Finally, we investigate various heuristic approaches to bounded-degree network design problem, in particular providing a reliable heuristic algorithm with good experimental performance. We report on an extensive empirical evaluation, using several real-world traffic traces from datacenters, and find that our approach results in improved demand-aware network designs. ",
    "url": "https://arxiv.org/abs/2308.10579",
    "authors": [
      "Aleksander Figiel",
      "Janne H. Korhonen",
      "Neil Olver",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.10584",
    "title": "RADIANCE: Radio-Frequency Adversarial Deep-learning Inference for  Automated Network Coverage Estimation",
    "abstract": "Radio-frequency coverage maps (RF maps) are extensively utilized in wireless networks for capacity planning, placement of access points and base stations, localization, and coverage estimation. Conducting site surveys to obtain RF maps is labor-intensive and sometimes not feasible. In this paper, we propose radio-frequency adversarial deep-learning inference for automated network coverage estimation (RADIANCE), a generative adversarial network (GAN) based approach for synthesizing RF maps in indoor scenarios. RADIANCE utilizes a semantic map, a high-level representation of the indoor environment to encode spatial relationships and attributes of objects within the environment and guide the RF map generation process. We introduce a new gradient-based loss function that computes the magnitude and direction of change in received signal strength (RSS) values from a point within the environment. RADIANCE incorporates this loss function along with the antenna pattern to capture signal propagation within a given indoor configuration and generate new patterns under new configuration, antenna (beam) pattern, and center frequency. Extensive simulations are conducted to compare RADIANCE with ray-tracing simulations of RF maps. Our results show that RADIANCE achieves a mean average error (MAE) of 0.09, root-mean-squared error (RMSE) of 0.29, peak signal-to-noise ratio (PSNR) of 10.78, and multi-scale structural similarity index (MS-SSIM) of 0.80. ",
    "url": "https://arxiv.org/abs/2308.10584",
    "authors": [
      "Sopan Sarkar",
      "Mohammad Hossein Manshaei",
      "Marwan Krunz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.10585",
    "title": "Exploring Equation as a Better Intermediate Meaning Representation for  Numerical Reasoning",
    "abstract": "Numerical reasoning is vital for natural language processing models to understand and process numerical information in real-world scenarios. Most current methods first generate the Intermediate Meaning Representations (IMRs) of questions and then generate answers. Current SOTA methods generate programs as IMRs with large language models (LLMs). Intuitively, equations have fewer restrictions and closer semantics to the question than programs, leading to higher generation accuracy. However, current LLMs generate equations worse than programs, where we assume that the equation data is rare in pre-training data compared to programs. So in this paper, we try to use equations as IMRs to solve the numerical reasoning task by addressing two problems: (1) Theoretically, how to prove that the equation is an IMR with higher generation accuracy than programs; (2) Empirically, how to improve the generation accuracy of equations with LLMs. For the first problem, we propose and prove a proposition to theoretically compare the generation accuracy of different IMRs. For the second problem, we present a method called Boosting Numerical Reason\\textbfing by Decomposing the Generation of Equations (Bridge), which can improve the accuracy of LLMs in generating equations as IMRs by reducing the tendency of generating constant expressions and programs. Our method improves the performance by 2.2%, 0.9%, and 1.7% on GSM8K, SVAMP, and Algebra datasets compared to the previous state-of-the-art methods under the single reasoning path setting. Our codes and prompts are released in https://github.com/zirui-HIT/Bridge_for_Numerical_Reasoning. ",
    "url": "https://arxiv.org/abs/2308.10585",
    "authors": [
      "Dingzirui Wang",
      "Longxu Dou",
      "Wenbin Zhang",
      "Junyu Zeng",
      "Wanxiang Che"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.10600",
    "title": "Fixed-Parameter Algorithms for Computing RAC Drawings of Graphs",
    "abstract": "In a right-angle crossing (RAC) drawing of a graph, each edge is represented as a polyline and edge crossings must occur at an angle of exactly $90^\\circ$, where the number of bends on such polylines is typically restricted in some way. While structural and topological properties of RAC drawings have been the focus of extensive research, little was known about the boundaries of tractability for computing such drawings. In this paper, we initiate the study of RAC drawings from the viewpoint of parameterized complexity. In particular, we establish that computing a RAC drawing of an input graph $G$ with at most $b$ bends (or determining that none exists) is fixed-parameter tractable parameterized by either the feedback edge number of $G$, or $b$ plus the vertex cover number of $G$. ",
    "url": "https://arxiv.org/abs/2308.10600",
    "authors": [
      "Cornelius Brand",
      "Robert Ganian",
      "Sebastian R\u00f6der",
      "Florian Schager"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.10601",
    "title": "Improving the Transferability of Adversarial Examples with Arbitrary  Style Transfer",
    "abstract": "Deep neural networks are vulnerable to adversarial examples crafted by applying human-imperceptible perturbations on clean inputs. Although many attack methods can achieve high success rates in the white-box setting, they also exhibit weak transferability in the black-box setting. Recently, various methods have been proposed to improve adversarial transferability, in which the input transformation is one of the most effective methods. In this work, we notice that existing input transformation-based works mainly adopt the transformed data in the same domain for augmentation. Inspired by domain generalization, we aim to further improve the transferability using the data augmented from different domains. Specifically, a style transfer network can alter the distribution of low-level visual features in an image while preserving semantic content for humans. Hence, we propose a novel attack method named Style Transfer Method (STM) that utilizes a proposed arbitrary style transfer network to transform the images into different domains. To avoid inconsistent semantic information of stylized images for the classification network, we fine-tune the style transfer network and mix up the generated images added by random noise with the original images to maintain semantic consistency and boost input diversity. Extensive experimental results on the ImageNet-compatible dataset show that our proposed method can significantly improve the adversarial transferability on either normally trained models or adversarially trained models than state-of-the-art input transformation-based attacks. Code is available at: https://github.com/Zhijin-Ge/STM. ",
    "url": "https://arxiv.org/abs/2308.10601",
    "authors": [
      "Zhijin Ge",
      "Fanhua Shang",
      "Hongying Liu",
      "Yuanyuan Liu",
      "Liang Wan",
      "Wei Feng",
      "Xiaosen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.10604",
    "title": "BackTrack: Robust template update via Backward Tracking of candidate  template",
    "abstract": "Variations of target appearance such as deformations, illumination variance, occlusion, etc., are the major challenges of visual object tracking that negatively impact the performance of a tracker. An effective method to tackle these challenges is template update, which updates the template to reflect the change of appearance in the target object during tracking. However, with template updates, inadequate quality of new templates or inappropriate timing of updates may induce a model drift problem, which severely degrades the tracking performance. Here, we propose BackTrack, a robust and reliable method to quantify the confidence of the candidate template by backward tracking it on the past frames. Based on the confidence score of candidates from BackTrack, we can update the template with a reliable candidate at the right time while rejecting unreliable candidates. BackTrack is a generic template update scheme and is applicable to any template-based trackers. Extensive experiments on various tracking benchmarks verify the effectiveness of BackTrack over existing template update algorithms, as it achieves SOTA performance on various tracking benchmarks. ",
    "url": "https://arxiv.org/abs/2308.10604",
    "authors": [
      "Dongwook Lee",
      "Wonjun Choi",
      "Seohyung Lee",
      "ByungIn Yoo",
      "Eunho Yang",
      "Seongju Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10613",
    "title": "Static Application Security Testing of Consensus-Critical Code in the  Cosmos Network",
    "abstract": "Blockchains require deterministic execution in order to reach consensus. This is often guaranteed in languages designed to write smart contracts, such as Solidity. Application-specific blockchains or ``appchains'' allow the blockchain application logic to be written using general-purpose programming languages, giving developers more flexibility but also additional responsibilities. In particular, developers must ensure that their blockchain application logic does not contain any sources of non-determinism. Any source of non-determinism may be a potential source of vulnerabilities. This paper focuses on the use of Static Application Security Testing (SAST) tools to detect such sources of non-determinism at development time. We focus on Cosmos, a prominent open-source project that lets developers build interconnected networks of application-specific blockchains. Cosmos provides a Software Development Kit (SDK) that allows these chains to be implemented in the Go programming language. We create a corpus of 11 representative Cosmos-based appchains to analyze for sources of non-determinism in Go. As part of our study, we identified cosmos-sdk-codeql, a set of CodeQL code analysis rules for Cosmos applications. We find that these rules generate many false positives and propose a refactored set of rules that more precisely detects sources of non-determinism only in code that runs as part of the blockchain logic. We demonstrate a significant increase in the precision of the rules, making the SAST tool more effective and hence potentially contributing to enhanced security for Cosmos-based blockchains. ",
    "url": "https://arxiv.org/abs/2308.10613",
    "authors": [
      "Jasper Surmont",
      "Weihong Wang",
      "Tom Van Cutsem"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.10632",
    "title": "Foundation Model-oriented Robustness: Robust Image Model Evaluation with  Pretrained Models",
    "abstract": "Machine learning has demonstrated remarkable performance over finite datasets, yet whether the scores over the fixed benchmarks can sufficiently indicate the model's performance in the real world is still in discussion. In reality, an ideal robust model will probably behave similarly to the oracle (e.g., the human users), thus a good evaluation protocol is probably to evaluate the models' behaviors in comparison to the oracle. In this paper, we introduce a new robustness measurement that directly measures the image classification model's performance compared with a surrogate oracle (i.e., a foundation model). Besides, we design a simple method that can accomplish the evaluation beyond the scope of the benchmarks. Our method extends the image datasets with new samples that are sufficiently perturbed to be distinct from the ones in the original sets, but are still bounded within the same image-label structure the original test image represents, constrained by a foundation model pretrained with a large amount of samples. As a result, our new method will offer us a new way to evaluate the models' robustness performance, free of limitations of fixed benchmarks or constrained perturbations, although scoped by the power of the oracle. In addition to the evaluation results, we also leverage our generated data to understand the behaviors of the model and our new evaluation strategies. ",
    "url": "https://arxiv.org/abs/2308.10632",
    "authors": [
      "Peiyan Zhang",
      "Haoyang Liu",
      "Chaozhuo Li",
      "Xing Xie",
      "Sunghun Kim",
      "Haohan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10637",
    "title": "Metro Access Network with Convergence of Coherent and Analog RoF Data  Services",
    "abstract": "Efficient use of spectral resources will be an important aspect of converged access network deployment. This work analyzes the performance of variable bandwidth Analog Radio-over-Fiber signals transmitted in the unfilled spectral spaces of telecom-grade ROADM channels dedicated for coherent signals transmission over the OpenIreland testbed. ",
    "url": "https://arxiv.org/abs/2308.10637",
    "authors": [
      "Amol Delmade",
      "Frank Slyne",
      "Colm Browning",
      "Daniel Kilper Liam Barry",
      "Marco Ruffini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.10644",
    "title": "Faster Training of Neural ODEs Using Gau\u00df-Legendre Quadrature",
    "abstract": "Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gau{\\ss}-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models. ",
    "url": "https://arxiv.org/abs/2308.10644",
    "authors": [
      "Alexander Norcliffe",
      "Marc Peter Deisenroth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.10652",
    "title": "Proofs about Network Communication: For Humans and Machines",
    "abstract": "Many concurrent and distributed systems are safety-critical and therefore have to provide a high degree of assurance. Important properties of such systems are frequently proved on the specification level, but implementations typically deviate from specifications for practical reasons. Machine-checked proofs of bisimilarity statements are often useful for guaranteeing that properties of specifications carry over to implementations. In this paper, we present a way of conducting such proofs with a focus on network communication. The proofs resulting from our approach are not just machine-checked but also intelligible for humans. ",
    "url": "https://arxiv.org/abs/2308.10652",
    "authors": [
      "Wolfgang Jeltsch",
      "Javier D\u00edaz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.10658",
    "title": "Learning Clothing and Pose Invariant 3D Shape Representation for  Long-Term Person Re-Identification",
    "abstract": "Long-Term Person Re-Identification (LT-ReID) has become increasingly crucial in computer vision and biometrics. In this work, we aim to extend LT-ReID beyond pedestrian recognition to include a wider range of real-world human activities while still accounting for cloth-changing scenarios over large time gaps. This setting poses additional challenges due to the geometric misalignment and appearance ambiguity caused by the diversity of human pose and clothing. To address these challenges, we propose a new approach 3DInvarReID for (i) disentangling identity from non-identity components (pose, clothing shape, and texture) of 3D clothed humans, and (ii) reconstructing accurate 3D clothed body shapes and learning discriminative features of naked body shapes for person ReID in a joint manner. To better evaluate our study of LT-ReID, we collect a real-world dataset called CCDA, which contains a wide variety of human activities and clothing changes. Experimentally, we show the superior performance of our approach for person ReID. ",
    "url": "https://arxiv.org/abs/2308.10658",
    "authors": [
      "Feng Liu",
      "Minchul Kim",
      "ZiAng Gu",
      "Anil Jian",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10664",
    "title": "A Safe Deep Reinforcement Learning Approach for Energy Efficient  Federated Learning in Wireless Communication Networks",
    "abstract": "Progressing towards a new era of Artificial Intelligence (AI) - enabled wireless networks, concerns regarding the environmental impact of AI have been raised both in industry and academia. Federated Learning (FL) has emerged as a key privacy preserving decentralized AI technique. Despite efforts currently being made in FL, its environmental impact is still an open problem. Targeting the minimization of the overall energy consumption of an FL process, we propose the orchestration of computational and communication resources of the involved devices to minimize the total energy required, while guaranteeing a certain performance of the model. To this end, we propose a Soft Actor Critic Deep Reinforcement Learning (DRL) solution, where a penalty function is introduced during training, penalizing the strategies that violate the constraints of the environment, and ensuring a safe RL process. A device level synchronization method, along with a computationally cost effective FL environment are proposed, with the goal of further reducing the energy consumption and communication overhead. Evaluation results show the effectiveness of the proposed scheme compared to four state-of-the-art baseline solutions in both static and dynamic environments, achieving a decrease of up to 94% in the total energy consumption. ",
    "url": "https://arxiv.org/abs/2308.10664",
    "authors": [
      "Nikolaos Koursioumpas",
      "Lina Magoula",
      "Nikolaos Petropouleas",
      "Alexandros-Ioannis Thanopoulos",
      "Theodora Panagea",
      "Nancy Alonistioti",
      "M. A. Gutierrez-Estevez",
      "Ramin Khalili"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10671",
    "title": "Reducing Object Detection Uncertainty from RGB and Thermal Data for UAV  Outdoor Surveillance",
    "abstract": "Recent advances in Unmanned Aerial Vehicles (UAVs) have resulted in their quick adoption for wide a range of civilian applications, including precision agriculture, biosecurity, disaster monitoring and surveillance. UAVs offer low-cost platforms with flexible hardware configurations, as well as an increasing number of autonomous capabilities, including take-off, landing, object tracking and obstacle avoidance. However, little attention has been paid to how UAVs deal with object detection uncertainties caused by false readings from vision-based detectors, data noise, vibrations, and occlusion. In most situations, the relevance and understanding of these detections are delegated to human operators, as many UAVs have limited cognition power to interact autonomously with the environment. This paper presents a framework for autonomous navigation under uncertainty in outdoor scenarios for small UAVs using a probabilistic-based motion planner. The framework is evaluated with real flight tests using a sub 2 kg quadrotor UAV and illustrated in victim finding Search and Rescue (SAR) case study in a forest/bushland. The navigation problem is modelled using a Partially Observable Markov Decision Process (POMDP), and solved in real time onboard the small UAV using Augmented Belief Trees (ABT) and the TAPIR toolkit. Results from experiments using colour and thermal imagery show that the proposed motion planner provides accurate victim localisation coordinates, as the UAV has the flexibility to interact with the environment and obtain clearer visualisations of any potential victims compared to the baseline motion planner. Incorporating this system allows optimised UAV surveillance operations by diminishing false positive readings from vision-based object detectors. ",
    "url": "https://arxiv.org/abs/2308.10671",
    "authors": [
      "Juan Sandino",
      "Peter A. Caccetta",
      "Conrad Sanderson",
      "Frederic Maire",
      "Felipe Gonzalez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.10680",
    "title": "Co-Speech Gesture Detection through Multi-phase Sequence Labeling",
    "abstract": "Gestures are integral components of face-to-face communication. They unfold over time, often following predictable movement phases of preparation, stroke, and retraction. Yet, the prevalent approach to automatic gesture detection treats the problem as binary classification, classifying a segment as either containing a gesture or not, thus failing to capture its inherently sequential and contextual nature. To address this, we introduce a novel framework that reframes the task as a multi-phase sequence labeling problem rather than binary classification. Our model processes sequences of skeletal movements over time windows, uses Transformer encoders to learn contextual embeddings, and leverages Conditional Random Fields to perform sequence labeling. We evaluate our proposal on a large dataset of diverse co-speech gestures in task-oriented face-to-face dialogues. The results consistently demonstrate that our method significantly outperforms strong baseline models in detecting gesture strokes. Furthermore, applying Transformer encoders to learn contextual embeddings from movement sequences substantially improves gesture unit detection. These results highlight our framework's capacity to capture the fine-grained dynamics of co-speech gesture phases, paving the way for more nuanced and accurate gesture detection and analysis. ",
    "url": "https://arxiv.org/abs/2308.10680",
    "authors": [
      "Esam Ghaleb",
      "Ilya Burenko",
      "Marlou Rasenberg",
      "Wim Pouw",
      "Peter Uhrig",
      "Judith Holler",
      "Ivan Toni",
      "Asl\u0131 \u00d6zy\u00fcrek",
      "Raquel Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10685",
    "title": "Contrastive Graph Prompt-tuning for Cross-domain Recommendation",
    "abstract": "Recommender systems are frequently challenged by the data sparsity problem. One approach to mitigate this issue is through cross-domain recommendation techniques. In a cross-domain context, sharing knowledge between domains can enhance the effectiveness in the target domain. Recent cross-domain methods have employed a pre-training approach, but we argue that these methods often result in suboptimal fine-tuning, especially with large neural models. Modern language models utilize prompts for efficient model tuning. Such prompts act as a tunable latent vector, allowing for the freezing of the main model parameters. In our research, we introduce the Personalised Graph Prompt-based Recommendation (PGPRec) framework. This leverages the advantages of prompt-tuning. Within this framework, we formulate personalized graph prompts item-wise, rooted in items that a user has previously engaged with. Specifically, we employ Contrastive Learning (CL) to produce pre-trained embeddings that offer greater generalizability in the pre-training phase, ensuring robust training during the tuning phase. Our evaluation of PGPRec in cross-domain scenarios involves comprehensive testing with the top-k recommendation tasks and a cold-start analysis. Our empirical findings, based on four Amazon Review datasets, reveal that the PGPRec framework can decrease the tuned parameters by as much as 74%, maintaining competitive performance. Remarkably, there's an 11.41% enhancement in performance against the leading baseline in cold-start situations. ",
    "url": "https://arxiv.org/abs/2308.10685",
    "authors": [
      "Zixuan Yi",
      "Iadh Ounis",
      "Craig Macdonald"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.10692",
    "title": "Exploring Fine-Grained Representation and Recomposition for  Cloth-Changing Person Re-Identification",
    "abstract": "Cloth-changing person Re-IDentification (Re-ID) is a particularly challenging task, suffering from two limitations of inferior identity-relevant features and limited training samples. Existing methods mainly leverage auxiliary information to facilitate discriminative feature learning, including soft-biometrics features of shapes and gaits, and additional labels of clothing. However, these information may be unavailable in real-world applications. In this paper, we propose a novel FIne-grained Representation and Recomposition (FIRe$^{2}$) framework to tackle both limitations without any auxiliary information. Specifically, we first design a Fine-grained Feature Mining (FFM) module to separately cluster images of each person. Images with similar so-called fine-grained attributes (e.g., clothes and viewpoints) are encouraged to cluster together. An attribute-aware classification loss is introduced to perform fine-grained learning based on cluster labels, which are not shared among different people, promoting the model to learn identity-relevant features. Furthermore, by taking full advantage of the clustered fine-grained attributes, we present a Fine-grained Attribute Recomposition (FAR) module to recompose image features with different attributes in the latent space. It can significantly enhance representations for robust feature learning. Extensive experiments demonstrate that FIRe$^{2}$ can achieve state-of-the-art performance on five widely-used cloth-changing person Re-ID benchmarks. ",
    "url": "https://arxiv.org/abs/2308.10692",
    "authors": [
      "Qizao Wang",
      "Xuelin Qian",
      "Bin Li",
      "Ying Fu",
      "Yanwei Fu",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10696",
    "title": "SCC5G: A PQC-based Architecture for Highly Secure Critical Communication  over Cellular Network in Zero-Trust Environment",
    "abstract": "5G made a significant jump in cellular network security by offering enhanced subscriber identity protection and a user-network mutual authentication implementation. However, it still does not fully follow the zero-trust (ZT) requirements, as users need to trust the network, 5G network is not necessarily authenticated in each communication instance, and there is no mutual authentication between end users. When critical communications need to use commercial networks, but the environment is ZT, specific security architecture is needed to provide security services that do not rely on any 5G network trusted authority. In this paper, we propose SCC5G Secure Critical-mission Communication over a 5G network in ZT setting. SCC5G is a post-quantum cryptography (PQC) security solution that loads an embedded hardware root of authentication (HRA), such as physically unclonable functions (PUF), into the users' devices, to achieve tamper-resistant and unclonability features for authentication and key agreement. We evaluate the performance of the proposed architecture through an exhaustive simulation of a 5G network in an ns-3 network simulator. Results verify the scalability and efficiency of SCC5G by showing that it poses only a few kilobytes of traffic overhead and adds only an order of $O(0.1)$ second of latency under the normal traffic load. ",
    "url": "https://arxiv.org/abs/2308.10696",
    "authors": [
      "Mohammed Gharib",
      "Fatemeh Afghah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.10708",
    "title": "Measuring the Effect of Causal Disentanglement on the Adversarial  Robustness of Neural Network Models",
    "abstract": "Causal Neural Network models have shown high levels of robustness to adversarial attacks as well as an increased capacity for generalisation tasks such as few-shot learning and rare-context classification compared to traditional Neural Networks. This robustness is argued to stem from the disentanglement of causal and confounder input signals. However, no quantitative study has yet measured the level of disentanglement achieved by these types of causal models or assessed how this relates to their adversarial robustness. Existing causal disentanglement metrics are not applicable to deterministic models trained on real-world datasets. We, therefore, utilise metrics of content/style disentanglement from the field of Computer Vision to measure different aspects of the causal disentanglement for four state-of-the-art causal Neural Network models. By re-implementing these models with a common ResNet18 architecture we are able to fairly measure their adversarial robustness on three standard image classification benchmarking datasets under seven common white-box attacks. We find a strong association (r=0.820, p=0.001) between the degree to which models decorrelate causal and confounder signals and their adversarial robustness. Additionally, we find a moderate negative association between the pixel-level information content of the confounder signal and adversarial robustness (r=-0.597, p=0.040). ",
    "url": "https://arxiv.org/abs/2308.10708",
    "authors": [
      "Preben M. Ness",
      "Dusica Marijan",
      "Sunanda Bose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10720",
    "title": "On the accuracy of interpolation based on single-layer artificial neural  networks",
    "abstract": "In the present paper, we consider one-hidden layer ANNs with a feedforward architecture, also referred to as shallow or two-layer networks, so that the structure is determined by the number and types of neurons. The determination of the parameters that define the function, called training, is done via the resolution of the approximation problem, so by imposing the interpolation through a set of specific nodes. We present the case where the parameters are trained using a procedure that is referred to as Extreme Learning Machine (ELM) that leads to a linear interpolation problem. In such hypotheses, the existence of an ANN interpolating function is guaranteed. The focus is then on the accuracy of the interpolation outside of the given sampling interpolation nodes when they are the equispaced, the Chebychev, and the randomly selected ones. The study is motivated by the well-known bell-shaped Runge example, which makes it clear that the construction of a global interpolating polynomial is accurate only if trained on suitably chosen nodes, ad example the Chebychev ones. In order to evaluate the behavior when growing the number of interpolation nodes, we raise the number of neurons in our network and compare it with the interpolating polynomial. We test using Runge's function and other well-known examples with different regularities. As expected, the accuracy of the approximation with a global polynomial increases only if the Chebychev nodes are considered. Instead, the error for the ANN interpolating function always decays and in most cases we observe that the convergence follows what is observed in the polynomial case on Chebychev nodes, despite the set of nodes used for training. ",
    "url": "https://arxiv.org/abs/2308.10720",
    "authors": [
      "Ferdinando Auricchio",
      "Maria Roberta Belardo",
      "Francesco Calabr\u00f2",
      "Ariel F. Pascaner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10735",
    "title": "Different Types of Isomorphisms of Drawings of Complete Multipartite  Graphs",
    "abstract": "Simple drawings are drawings of graphs in which any two edges intersect at most once (either at a common endpoint or a proper crossing), and no edge intersects itself. We analyze several characteristics of simple drawings of complete multipartite graphs: which pairs of edges cross, in which order they cross, and the cyclic order around vertices and crossings, respectively. We consider all possible combinations of how two drawings can share some characteristics and determine which other characteristics they imply and which they do not imply. Our main results are that for simple drawings of complete multipartite graphs, the orders in which edges cross determine all other considered characteristics. Further, if all partition classes have at least three vertices, then the pairs of edges that cross determine the rotation system and the rotation around the crossings determine the extended rotation system. We also show that most other implications -- including the ones that hold for complete graphs -- do not hold for complete multipartite graphs. Using this analysis, we establish which types of isomorphisms are meaningful for simple drawings of complete multipartite graphs. ",
    "url": "https://arxiv.org/abs/2308.10735",
    "authors": [
      "Oswin Aichholzer",
      "Birgit Vogtenhuber",
      "Alexandra Weinberger"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2308.10737",
    "title": "UGSL: A Unified Framework for Benchmarking Graph Structure Learning",
    "abstract": "Graph neural networks (GNNs) demonstrate outstanding performance in a broad range of applications. While the majority of GNN applications assume that a graph structure is given, some recent methods substantially expanded the applicability of GNNs by showing that they may be effective even when no graph structure is explicitly provided. The GNN parameters and a graph structure are jointly learned. Previous studies adopt different experimentation setups, making it difficult to compare their merits. In this paper, we propose a benchmarking strategy for graph structure learning using a unified framework. Our framework, called Unified Graph Structure Learning (UGSL), reformulates existing models into a single model. We implement a wide range of existing models in our framework and conduct extensive analyses of the effectiveness of different components in the framework. Our results provide a clear and concise understanding of the different methods in this area as well as their strengths and weaknesses. The benchmark code is available at https://github.com/google-research/google-research/tree/master/ugsl. ",
    "url": "https://arxiv.org/abs/2308.10737",
    "authors": [
      "Bahare Fatemi",
      "Sami Abu-El-Haija",
      "Anton Tsitsulin",
      "Mehran Kazemi",
      "Dustin Zelle",
      "Neslihan Bulut",
      "Jonathan Halcrow",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10741",
    "title": "On the Adversarial Robustness of Multi-Modal Foundation Models",
    "abstract": "Multi-modal foundation models combining vision and language models such as Flamingo or GPT-4 have recently gained enormous interest. Alignment of foundation models is used to prevent models from providing toxic or harmful output. While malicious users have successfully tried to jailbreak foundation models, an equally important question is if honest users could be harmed by malicious third-party content. In this paper we show that imperceivable attacks on images in order to change the caption output of a multi-modal foundation model can be used by malicious content providers to harm honest users e.g. by guiding them to malicious websites or broadcast fake information. This indicates that countermeasures to adversarial attacks should be used by any deployed multi-modal foundation model. ",
    "url": "https://arxiv.org/abs/2308.10741",
    "authors": [
      "Christian Schlarmann",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10743",
    "title": "Boosting Adversarial Attack with Similar Target",
    "abstract": "Deep neural networks are vulnerable to adversarial examples, posing a threat to the models' applications and raising security concerns. An intriguing property of adversarial examples is their strong transferability. Several methods have been proposed to enhance transferability, including ensemble attacks which have demonstrated their efficacy. However, prior approaches simply average logits, probabilities, or losses for model ensembling, lacking a comprehensive analysis of how and why model ensembling significantly improves transferability. In this paper, we propose a similar targeted attack method named Similar Target~(ST). By promoting cosine similarity between the gradients of each model, our method regularizes the optimization direction to simultaneously attack all surrogate models. This strategy has been proven to enhance generalization ability. Experimental results on ImageNet validate the effectiveness of our approach in improving adversarial transferability. Our method outperforms state-of-the-art attackers on 18 discriminative classifiers and adversarially trained models. ",
    "url": "https://arxiv.org/abs/2308.10743",
    "authors": [
      "Shuo Zhang",
      "Ziruo Wang",
      "Zikai Zhou",
      "Huanran Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10757",
    "title": "To Whom are You Talking? A Deep Learning Model to Endow Social Robots  with Addressee Estimation Skills",
    "abstract": "Communicating shapes our social word. For a robot to be considered social and being consequently integrated in our social environment it is fundamental to understand some of the dynamics that rule human-human communication. In this work, we tackle the problem of Addressee Estimation, the ability to understand an utterance's addressee, by interpreting and exploiting non-verbal bodily cues from the speaker. We do so by implementing an hybrid deep learning model composed of convolutional layers and LSTM cells taking as input images portraying the face of the speaker and 2D vectors of the speaker's body posture. Our implementation choices were guided by the aim to develop a model that could be deployed on social robots and be efficient in ecological scenarios. We demonstrate that our model is able to solve the Addressee Estimation problem in terms of addressee localisation in space, from a robot ego-centric point of view. ",
    "url": "https://arxiv.org/abs/2308.10757",
    "authors": [
      "Carlo Mazzola",
      "Marta Romeo",
      "Francesco Rea",
      "Alessandra Sciutti",
      "Angelo Cangelosi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.10759",
    "title": "EALink: An Efficient and Accurate Pre-trained Framework for Issue-Commit  Link Recovery",
    "abstract": "Issue-commit links, as a type of software traceability links, play a vital role in various software development and maintenance tasks. However, they are typically deficient, as developers often forget or fail to create tags when making commits. Existing studies have deployed deep learning techniques, including pretrained models, to improve automatic issue-commit link recovery.Despite their promising performance, we argue that previous approaches have four main problems, hindering them from recovering links in large software projects. To overcome these problems, we propose an efficient and accurate pre-trained framework called EALink for issue-commit link recovery. EALink requires much fewer model parameters than existing pre-trained methods, bringing efficient training and recovery. Moreover, we design various techniques to improve the recovery accuracy of EALink. We construct a large-scale dataset and conduct extensive experiments to demonstrate the power of EALink. Results show that EALink outperforms the state-of-the-art methods by a large margin (15.23%-408.65%) on various evaluation metrics. Meanwhile, its training and inference overhead is orders of magnitude lower than existing methods. ",
    "url": "https://arxiv.org/abs/2308.10759",
    "authors": [
      "Chenyuan Zhang",
      "Yanlin Wang",
      "Zhao Wei",
      "Yong Xu",
      "Juhong Wang",
      "Hui Li",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.10776",
    "title": "A Modular and Adaptive System for Business Email Compromise Detection",
    "abstract": "The growing sophistication of Business Email Compromise (BEC) and spear phishing attacks poses significant challenges to organizations worldwide. The techniques featured in traditional spam and phishing detection are insufficient due to the tailored nature of modern BEC attacks as they often blend in with the regular benign traffic. Recent advances in machine learning, particularly in Natural Language Understanding (NLU), offer a promising avenue for combating such attacks but in a practical system, due to limitations such as data availability, operational costs, verdict explainability requirements or a need to robustly evolve the system, it is essential to combine multiple approaches together. We present CAPE, a comprehensive and efficient system for BEC detection that has been proven in a production environment for a period of over two years. Rather than being a single model, CAPE is a system that combines independent ML models and algorithms detecting BEC-related behaviors across various email modalities such as text, images, metadata and the email's communication context. This decomposition makes CAPE's verdicts naturally explainable. In the paper, we describe the design principles and constraints behind its architecture, as well as the challenges of model design, evaluation and adapting the system continuously through a Bayesian approach that combines limited data with domain knowledge. Furthermore, we elaborate on several specific behavioral detectors, such as those based on Transformer neural architectures. ",
    "url": "https://arxiv.org/abs/2308.10776",
    "authors": [
      "Jan Brabec",
      "Filip \u0160rajer",
      "Radek Starosta",
      "Tom\u00e1\u0161 Sixta",
      "Marc Dupont",
      "Milo\u0161 Lenoch",
      "Ji\u0159\u00ed Men\u0161\u00edk",
      "Florian Becker",
      "Jakub Boros",
      "Tom\u00e1\u0161 Pop",
      "Pavel Nov\u00e1k"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10778",
    "title": "A Topology-aware Analysis of Graph Collaborative Filtering",
    "abstract": "The successful integration of graph neural networks into recommender systems (RSs) has led to a novel paradigm in collaborative filtering (CF), graph collaborative filtering (graph CF). By representing user-item data as an undirected, bipartite graph, graph CF utilizes short- and long-range connections to extract collaborative signals that yield more accurate user preferences than traditional CF methods. Although the recent literature highlights the efficacy of various algorithmic strategies in graph CF, the impact of datasets and their topological features on recommendation performance is yet to be studied. To fill this gap, we propose a topology-aware analysis of graph CF. In this study, we (i) take some widely-adopted recommendation datasets and use them to generate a large set of synthetic sub-datasets through two state-of-the-art graph sampling methods, (ii) measure eleven of their classical and topological characteristics, and (iii) estimate the accuracy calculated on the generated sub-datasets considering four popular and recent graph-based RSs (i.e., LightGCN, DGCF, UltraGCN, and SVD-GCN). Finally, the investigation presents an explanatory framework that reveals the linear relationships between characteristics and accuracy measures. The results, statistically validated under different graph sampling settings, confirm the existence of solid dependencies between topological characteristics and accuracy in the graph-based recommendation, offering a new perspective on how to interpret graph CF. ",
    "url": "https://arxiv.org/abs/2308.10778",
    "authors": [
      "Daniele Malitesta",
      "Claudio Pomo",
      "Vito Walter Anelli",
      "Alberto Carlo Maria Mancino",
      "Eugenio Di Sciascio",
      "Tommaso Di Noia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.10779",
    "title": "Spear and Shield: Adversarial Attacks and Defense Methods for  Model-Based Link Prediction on Continuous-Time Dynamic Graphs",
    "abstract": "Real-world graphs are dynamic, constantly evolving with new interactions, such as financial transactions in financial networks. Temporal Graph Neural Networks (TGNNs) have been developed to effectively capture the evolving patterns in dynamic graphs. While these models have demonstrated their superiority, being widely adopted in various important fields, their vulnerabilities against adversarial attacks remain largely unexplored. In this paper, we propose T-SPEAR, a simple and effective adversarial attack method for link prediction on continuous-time dynamic graphs, focusing on investigating the vulnerabilities of TGNNs. Specifically, before the training procedure of a victim model, which is a TGNN for link prediction, we inject edge perturbations to the data that are unnoticeable in terms of the four constraints we propose, and yet effective enough to cause malfunction of the victim model. Moreover, we propose a robust training approach T-SHIELD to mitigate the impact of adversarial attacks. By using edge filtering and enforcing temporal smoothness to node embeddings, we enhance the robustness of the victim model. Our experimental study shows that T-SPEAR significantly degrades the victim model's performance on link prediction tasks, and even more, our attacks are transferable to other TGNNs, which differ from the victim model assumed by the attacker. Moreover, we demonstrate that T-SHIELD effectively filters out adversarial edges and exhibits robustness against adversarial attacks, surpassing the link prediction performance of the naive TGNN by up to 11.2% under T-SPEAR. ",
    "url": "https://arxiv.org/abs/2308.10779",
    "authors": [
      "Dongjin Lee",
      "Juho Lee",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.10788",
    "title": "Effectiveness of Reconfigurable Intelligent Surfaces to Enhance  Connectivity in UAV Networks",
    "abstract": "Reconfigurable intelligent surfaces (RISs) are expected to make future 6G networks more connected and resilient against node failures, due to their ability to introduce controllable phase-shifts onto impinging electromagnetic waves and impose link redundancy. Meanwhile, unmanned aerial vehicles (UAVs) are prone to failure due to limited energy, random failures, or targeted failures, which causes network disintegration that results in information delivery loss. In this paper, we show that the integration between UAVs and RISs for improving network connectivity is crucial. We utilize RISs to provide path diversity and alternative connectivity options for information flow from user equipments (UEs) to less critical UAVs by adding more links to the network, thereby making the network more resilient and connected. To that end, we first define the criticality of UAV nodes, which reflects the importance of some nodes over other nodes. We then employ the algebraic connectivity metric, which is adjusted by the reflected links of the RISs and their criticality weights, to formulate the problem of maximizing the network connectivity. Such problem is a computationally expensive combinatorial optimization. To tackle this problem, we propose a relaxation method such that the discrete scheduling constraint of the problem is relaxed and becomes continuous. Leveraging this, we propose two efficient solutions, namely semi-definite programming (SDP) optimization and perturbation heuristic, which both solve the problem in polynomial time. For the perturbation heuristic, we derive the lower and upper bounds of the algebraic connectivity obtained by adding new links to the network. Finally, we corroborate the effectiveness of the proposed solutions through extensive simulation experiments. ",
    "url": "https://arxiv.org/abs/2308.10788",
    "authors": [
      "Mohammed S. Al-Abiad",
      "Mohammad Javad-Kalbasi",
      "Shahrokh Valaee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.10801",
    "title": "LSCPM: communities in massive real-world Link Streams by Clique  Percolation Method",
    "abstract": "Community detection is a popular approach to understand the organization of interactions in static networks. For that purpose, the Clique Percolation Method (CPM), which involves the percolation of k-cliques, is a well-studied technique that offers several advantages. Besides, studying interactions that occur over time is useful in various contexts, which can be modeled by the link stream formalism. The Dynamic Clique Percolation Method (DCPM) has been proposed for extending CPM to temporal networks. However, existing implementations are unable to handle massive datasets. We present a novel algorithm that adapts CPM to link streams, which has the advantage that it allows us to speed up the computation time with respect to the existing DCPM method. We evaluate it experimentally on real datasets and show that it scales to massive link streams. For example, it allows to obtain a complete set of communities in under twenty-five minutes for a dataset with thirty million links, what the state of the art fails to achieve even after a week of computation. We further show that our method provides communities similar to DCPM, but slightly more aggregated. We exhibit the relevance of the obtained communities in real world cases, and show that they provide information on the importance of vertices in the link streams. ",
    "url": "https://arxiv.org/abs/2308.10801",
    "authors": [
      "Alexis Baudin",
      "Lionel Tabourier",
      "Cl\u00e9mence Magnien"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.10808",
    "title": "Graph Neural Bandits",
    "abstract": "Contextual bandits algorithms aim to choose the optimal arm with the highest reward out of a set of candidates based on the contextual information. Various bandit algorithms have been applied to real-world applications due to their ability of tackling the exploitation-exploration dilemma. Motivated by online recommendation scenarios, in this paper, we propose a framework named Graph Neural Bandits (GNB) to leverage the collaborative nature among users empowered by graph neural networks (GNNs). Instead of estimating rigid user clusters as in existing works, we model the \"fine-grained\" collaborative effects through estimated user graphs in terms of exploitation and exploration respectively. Then, to refine the recommendation strategy, we utilize separate GNN-based models on estimated user graphs for exploitation and adaptive exploration. Theoretical analysis and experimental results on multiple real data sets in comparison with state-of-the-art baselines are provided to demonstrate the effectiveness of our proposed framework. ",
    "url": "https://arxiv.org/abs/2308.10808",
    "authors": [
      "Yunzhe Qi",
      "Yikun Ban",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10819",
    "title": "Do you really follow me? Adversarial Instructions for Evaluating the  Robustness of Large Language Models",
    "abstract": "Large Language Models (LLMs) have shown remarkable proficiency in following instructions, making them valuable in customer-facing applications. However, their impressive capabilities also raise concerns about the amplification of risks posed by adversarial instructions, which can be injected into the model input by third-party attackers to manipulate LLMs' original instructions and prompt unintended actions and content. Therefore, it is crucial to understand LLMs' ability to accurately discern which instructions to follow to ensure their safe deployment in real-world scenarios. In this paper, we propose a pioneering benchmark for automatically evaluating the robustness of LLMs against adversarial instructions. The objective of this benchmark is to quantify the extent to which LLMs are influenced by injected adversarial instructions and assess their ability to differentiate between these adversarial instructions and original user instructions. Through experiments conducted with state-of-the-art instruction-following LLMs, we uncover significant limitations in their robustness against adversarial instruction attacks. Furthermore, our findings indicate that prevalent instruction-tuned models are prone to being overfitted to follow any instruction phrase in the prompt without truly understanding which instructions should be followed. This highlights the need to address the challenge of training models to comprehend prompts instead of merely following instruction phrases and completing the text. ",
    "url": "https://arxiv.org/abs/2308.10819",
    "authors": [
      "Zekun Li",
      "Baolin Peng",
      "Pengcheng He",
      "Xifeng Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10821",
    "title": "Neural Networks Optimizations Against Concept and Data Drift in Malware  Detection",
    "abstract": "Despite the promising results of machine learning models in malware detection, they face the problem of concept drift due to malware constant evolution. This leads to a decline in performance over time, as the data distribution of the new files differs from the training one, requiring regular model update. In this work, we propose a model-agnostic protocol to improve a baseline neural network to handle with the drift problem. We show the importance of feature reduction and training with the most recent validation set possible, and propose a loss function named Drift-Resilient Binary Cross-Entropy, an improvement to the classical Binary Cross-Entropy more effective against drift. We train our model on the EMBER dataset (2018) and evaluate it on a dataset of recent malicious files, collected between 2020 and 2023. Our improved model shows promising results, detecting 15.2% more malware than a baseline model. ",
    "url": "https://arxiv.org/abs/2308.10821",
    "authors": [
      "William Maillet",
      "Benjamin Marais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10832",
    "title": "EigenPlaces: Training Viewpoint Robust Models for Visual Place  Recognition",
    "abstract": "Visual Place Recognition is a task that aims to predict the place of an image (called query) based solely on its visual features. This is typically done through image retrieval, where the query is matched to the most similar images from a large database of geotagged photos, using learned global descriptors. A major challenge in this task is recognizing places seen from different viewpoints. To overcome this limitation, we propose a new method, called EigenPlaces, to train our neural network on images from different point of views, which embeds viewpoint robustness into the learned global descriptors. The underlying idea is to cluster the training data so as to explicitly present the model with different views of the same points of interest. The selection of this points of interest is done without the need for extra supervision. We then present experiments on the most comprehensive set of datasets in literature, finding that EigenPlaces is able to outperform previous state of the art on the majority of datasets, while requiring 60\\% less GPU memory for training and using 50\\% smaller descriptors. The code and trained models for EigenPlaces are available at {\\small{\\url{https://github.com/gmberton/EigenPlaces}}}, while results with any other baseline can be computed with the codebase at {\\small{\\url{https://github.com/gmberton/auto_VPR}}}. ",
    "url": "https://arxiv.org/abs/2308.10832",
    "authors": [
      "Gabriele Berton",
      "Gabriele Trivigno",
      "Barbara Caputo",
      "Carlo Masone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10835",
    "title": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs",
    "abstract": "Recommendation systems aim to provide users with relevant suggestions, but often lack interpretability and fail to capture higher-level semantic relationships between user behaviors and profiles. In this paper, we propose a novel approach that leverages large language models (LLMs) to construct personalized reasoning graphs. These graphs link a user's profile and behavioral sequences through causal and logical inferences, representing the user's interests in an interpretable way. Our approach, LLM reasoning graphs (LLMRG), has four components: chained graph reasoning, divergent extension, self-verification and scoring, and knowledge base self-improvement. The resulting reasoning graph is encoded using graph neural networks, which serves as additional input to improve conventional recommender systems, without requiring extra user or item information. Our approach demonstrates how LLMs can enable more logical and interpretable recommender systems through personalized reasoning graphs. LLMRG allows recommendations to benefit from both engineered recommendation systems and LLM-derived reasoning graphs. We demonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios in enhancing base recommendation models. ",
    "url": "https://arxiv.org/abs/2308.10835",
    "authors": [
      "Yan Wang",
      "Zhixuan Chu",
      "Xin Ouyang",
      "Simeng Wang",
      "Hongyan Hao",
      "Yue Shen",
      "Jinjie Gu",
      "Siqiao Xue",
      "James Y Zhang",
      "Qing Cui",
      "Longfei Li",
      "Jun Zhou",
      "Sheng Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.10838",
    "title": "An impossibility result for Markov Chain Monte Carlo sampling from  micro-canonical bipartite graph ensembles",
    "abstract": "Markov Chain Monte Carlo (MCMC) algorithms are commonly used to sample from graph ensembles. Two graphs are neighbors in the state space if one can be obtained from the other with only a few modifications, e.g., edge rewirings. For many common ensembles, e.g., those preserving the degree sequences of bipartite graphs, rewiring operations involving two edges are sufficient to create a fully-connected state space, and they can be performed efficiently. We show that, for ensembles of bipartite graphs with fixed degree sequences and number of butterflies (k2,2 bi-cliques), there is no universal constant c such that a rewiring of at most c edges at every step is sufficient for any such ensemble to be fully connected. Our proof relies on an explicit construction of a family of pairs of graphs with the same degree sequences and number of butterflies, with each pair indexed by a natural c, and such that any sequence of rewiring operations transforming one graph into the other must include at least one rewiring operation involving at least c edges. Whether rewiring these many edges is sufficient to guarantee the full connectivity of the state space of any such ensemble remains an open question. Our result implies the impossibility of developing efficient, graph-agnostic, MCMC algorithms for these ensembles, as the necessity to rewire an impractically large number of edges may hinder taking a step on the state space. ",
    "url": "https://arxiv.org/abs/2308.10838",
    "authors": [
      "Giulia Preti",
      "Gianmarco De Francisci Morales",
      "Matteo Riondato"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2308.10845",
    "title": "Election Manipulation in Social Networks with Single-Peaked Agents",
    "abstract": "Several elections run in the last years have been characterized by attempts to manipulate the result of the election through the diffusion of fake or malicious news over social networks. This problem has been recognized as a critical issue for the robustness of our democracy. Analyzing and understanding how such manipulations may occur is crucial to the design of effective countermeasures to these practices. Many studies have observed that, in general, to design an optimal manipulation is usually a computationally hard task. Nevertheless, literature on bribery in voting and election manipulation has frequently observed that most hardness results melt down when one focuses on the setting of (nearly) single-peaked agents, i.e., when each voter has a preferred candidate (usually, the one closer to her own belief) and preferences of remaining candidates are inversely proportional to the distance between the candidate position and the voter's belief. Unfortunately, no such analysis has been done for election manipulations run in social networks. In this work, we try to close this gap: specifically, we consider a setting for election manipulation that naturally raises (nearly) single-peaked preferences, and we evaluate the complexity of election manipulation problem in this setting: while most of the hardness and approximation results still hold, we will show that single-peaked preferences allow to design simple, efficient and effective heuristics for election manipulation. ",
    "url": "https://arxiv.org/abs/2308.10845",
    "authors": [
      "Vincenzo Auletta",
      "Francesco Carbone",
      "Diodato Ferraioli"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.10874",
    "title": "Analyzing Transformer Dynamics as Movement through Embedding Space",
    "abstract": "Transformer language models exhibit intelligent behaviors such as understanding natural language, recognizing patterns, acquiring knowledge, reasoning, planning, reflecting and using tools. This paper explores how their underlying mechanics give rise to intelligent behaviors. We adopt a systems approach to analyze Transformers in detail and develop a mathematical framework that frames their dynamics as movement through embedding space. This novel perspective provides a principled way of thinking about the problem and reveals important insights related to the emergence of intelligence: 1. At its core the Transformer is a Embedding Space walker, mapping intelligent behavior to trajectories in this vector space. 2. At each step of the walk, it composes context into a single composite vector whose location in Embedding Space defines the next step. 3. No learning actually occurs during decoding; in-context learning and generalization are simply the result of different contexts composing into different vectors. 4. Ultimately the knowledge, intelligence and skills exhibited by the model are embodied in the organization of vectors in Embedding Space rather than in specific neurons or layers. These abilities are properties of this organization. 5. Attention's contribution boils down to the association-bias it lends to vector composition and which influences the aforementioned organization. However, more investigation is needed to ascertain its significance. 6. The entire model is composed from two principal operations: data independent filtering and data dependent aggregation. This generalization unifies Transformers with other sequence models and across modalities. Building upon this foundation we formalize and test a semantic space theory which posits that embedding vectors represent semantic concepts and find some evidence of its validity. ",
    "url": "https://arxiv.org/abs/2308.10874",
    "authors": [
      "Sumeet S. Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.10892",
    "title": "Bayesian polynomial neural networks and polynomial neural ordinary  differential equations",
    "abstract": "Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) are two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs. ",
    "url": "https://arxiv.org/abs/2308.10892",
    "authors": [
      "Colby Fronk",
      "Jaewoong Yun",
      "Prashant Singh",
      "Linda Petzold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2308.10893",
    "title": "Online Transition-Based Feature Generation for Anomaly Detection in  Concurrent Data Streams",
    "abstract": "In this paper, we introduce the transition-based feature generator (TFGen) technique, which reads general activity data with attributes and generates step-by-step generated data. The activity data may consist of network activity from packets, system calls from processes or classified activity from surveillance cameras. TFGen processes data online and will generate data with encoded historical data for each incoming activity with high computational efficiency. The input activities may concurrently originate from distinct traces or channels. The technique aims to address issues such as domain-independent applicability, the ability to discover global process structures, the encoding of time-series data, and online processing capability. ",
    "url": "https://arxiv.org/abs/2308.10893",
    "authors": [
      "Yinzheng Zhong",
      "Alexei Lisitsa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2308.10902",
    "title": "CamP: Camera Preconditioning for Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) can be optimized to obtain high-fidelity 3D scene reconstructions of objects and large-scale scenes. However, NeRFs require accurate camera parameters as input -- inaccurate camera parameters result in blurry renderings. Extrinsic and intrinsic camera parameters are usually estimated using Structure-from-Motion (SfM) methods as a pre-processing step to NeRF, but these techniques rarely yield perfect estimates. Thus, prior works have proposed jointly optimizing camera parameters alongside a NeRF, but these methods are prone to local minima in challenging settings. In this work, we analyze how different camera parameterizations affect this joint optimization problem, and observe that standard parameterizations exhibit large differences in magnitude with respect to small perturbations, which can lead to an ill-conditioned optimization problem. We propose using a proxy problem to compute a whitening transform that eliminates the correlation between camera parameters and normalizes their effects, and we propose to use this transform as a preconditioner for the camera parameters during joint optimization. Our preconditioned camera optimization significantly improves reconstruction quality on scenes from the Mip-NeRF 360 dataset: we reduce error rates (RMSE) by 67% compared to state-of-the-art NeRF approaches that do not optimize for cameras like Zip-NeRF, and by 29% relative to state-of-the-art joint optimization approaches using the camera parameterization of SCNeRF. Our approach is easy to implement, does not significantly increase runtime, can be applied to a wide variety of camera parameterizations, and can straightforwardly be incorporated into other NeRF-like models. ",
    "url": "https://arxiv.org/abs/2308.10902",
    "authors": [
      "Keunhong Park",
      "Philipp Henzler",
      "Ben Mildenhall",
      "Jonathan T. Barron",
      "Ricardo Martin-Brualla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.09751",
    "title": "Data Compression and Inference in Cosmology with Self-Supervised Machine  Learning",
    "abstract": "The influx of massive amounts of data from current and upcoming cosmological surveys necessitates compression schemes that can efficiently summarize the data with minimal loss of information. We introduce a method that leverages the paradigm of self-supervised machine learning in a novel manner to construct representative summaries of massive datasets using simulation-based augmentations. Deploying the method on hydrodynamical cosmological simulations, we show that it can deliver highly informative summaries, which can be used for a variety of downstream tasks, including precise and accurate parameter inference. We demonstrate how this paradigm can be used to construct summary representations that are insensitive to prescribed systematic effects, such as the influence of baryonic physics. Our results indicate that self-supervised machine learning techniques offer a promising new approach for compression of cosmological data as well its analysis. ",
    "url": "https://arxiv.org/abs/2308.09751",
    "authors": [
      "Aizhan Akhmetzhanova",
      "Siddharth Mishra-Sharma",
      "Cora Dvorkin"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09790",
    "title": "A Two-Part Machine Learning Approach to Characterizing Network  Interference in A/B Testing",
    "abstract": "The reliability of controlled experiments, or \"A/B tests,\" can often be compromised due to the phenomenon of network interference, wherein the outcome for one unit is influenced by other units. To tackle this challenge, we propose a machine learning-based method to identify and characterize heterogeneous network interference. Our approach accounts for latent complex network structures and automates the task of \"exposure mapping'' determination, which addresses the two major limitations in the existing literature. We introduce \"causal network motifs'' and employ transparent machine learning models to establish the most suitable exposure mapping that reflects underlying network interference patterns. Our method's efficacy has been validated through simulations on two synthetic experiments and a real-world, large-scale test involving 1-2 million Instagram users, outperforming conventional methods such as design-based cluster randomization and analysis-based neighborhood exposure mapping. Overall, our approach not only offers a comprehensive, automated solution for managing network interference and improving the precision of A/B testing results, but it also sheds light on users' mutual influence and aids in the refinement of marketing strategies. ",
    "url": "https://arxiv.org/abs/2308.09790",
    "authors": [
      "Yuan Yuan",
      "Kristen M. Altenburger"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.09831",
    "title": "Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung  Cancer (NSCLC) Patient Survival Prediction",
    "abstract": "Cancer prognosis and survival outcome predictions are crucial for therapeutic response estimation and for stratifying patients into various treatment groups. Medical domains concerned with cancer prognosis are abundant with multiple modalities, including pathological image data and non-image data such as genomic information. To date, multimodal learning has shown potential to enhance clinical prediction model performance by extracting and aggregating information from different modalities of the same subject. This approach could outperform single modality learning, thus improving computer-aided diagnosis and prognosis in numerous medical applications. In this work, we propose a cross-modality attention-based multimodal fusion pipeline designed to integrate modality-specific knowledge for patient survival prediction in non-small cell lung cancer (NSCLC). Instead of merely concatenating or summing up the features from different modalities, our method gauges the importance of each modality for feature fusion with cross-modality relationship when infusing the multimodal features. Compared with single modality, which achieved c-index of 0.5772 and 0.5885 using solely tissue image data or RNA-seq data, respectively, the proposed fusion approach achieved c-index 0.6587 in our experiment, showcasing the capability of assimilating modality-specific knowledge from varied modalities. ",
    "url": "https://arxiv.org/abs/2308.09831",
    "authors": [
      "Ruining Deng",
      "Nazim Shaikh",
      "Gareth Shannon",
      "Yao Nie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09945",
    "title": "Dual Branch Deep Learning Network for Detection and Stage Grading of  Diabetic Retinopathy",
    "abstract": "Diabetic retinopathy is a severe complication of diabetes that can lead to permanent blindness if not treated promptly. Early and accurate diagnosis of the disease is essential for successful treatment. This paper introduces a deep learning method for the detection and stage grading of diabetic retinopathy, using a single fundus retinal image. Our model utilizes transfer learning, employing two state-of-the-art pre-trained models as feature extractors and fine-tuning them on a new dataset. The proposed model is trained on a large multi-center dataset, including the APTOS 2019 dataset, obtained from publicly available sources. It achieves remarkable performance in diabetic retinopathy detection and stage classification on the APTOS 2019, outperforming the established literature. For binary classification, the proposed approach achieves an accuracy of 98.50%, a sensitivity of 99.46%, and a specificity of 97.51%. In stage grading, it achieves a quadratic weighted kappa of 93.00%, an accuracy of 89.60%, a sensitivity of 89.60%, and a specificity of 97.72%. The proposed approach serves as a reliable screening and stage grading tool for diabetic retinopathy, offering significant potential to enhance clinical decision-making and patient care. ",
    "url": "https://arxiv.org/abs/2308.09945",
    "authors": [
      "Hossein Shakibania",
      "Sina Raoufi",
      "Behnam Pourafkham",
      "Hassan Khotanlou",
      "Muharram Mansoorizadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09952",
    "title": "Finding emergence in data: causal emergence inspired dynamics learning",
    "abstract": "Modelling complex dynamical systems in a data-driven manner is challenging due to the presence of emergent behaviors and properties that cannot be directly captured by micro-level observational data. Therefore, it is crucial to develop a model that can effectively capture emergent dynamics at the macro-level and quantify emergence based on the available data. Drawing inspiration from the theory of causal emergence, this paper introduces a machine learning framework aimed at learning macro-dynamics within an emergent latent space. The framework achieves this by maximizing the effective information (EI) to obtain a macro-dynamics model with stronger causal effects. Experimental results on both simulated and real data demonstrate the effectiveness of the proposed framework. Not only does it successfully capture emergent patterns, but it also learns the coarse-graining strategy and quantifies the degree of causal emergence in the data. Furthermore, experiments conducted on environments different from the training dataset highlight the superior generalization ability of our model. ",
    "url": "https://arxiv.org/abs/2308.09952",
    "authors": [
      "Mingzhe Yang",
      "Zhipeng Wang",
      "Kaiwei Liu",
      "Yingqi Rong",
      "Bing Yuan",
      "Jiang Zhang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10021",
    "title": "Effects of Convolutional Autoencoder Bottleneck Width on StarGAN-based  Singing Technique Conversion",
    "abstract": "Singing technique conversion (STC) refers to the task of converting from one voice technique to another while leaving the original singer identity, melody, and linguistic components intact. Previous STC studies, as well as singing voice conversion research in general, have utilized convolutional autoencoders (CAEs) for conversion, but how the bottleneck width of the CAE affects the synthesis quality has not been thoroughly evaluated. To this end, we constructed a GAN-based multi-domain STC system which took advantage of the WORLD vocoder representation and the CAE architecture. We varied the bottleneck width of the CAE, and evaluated the conversion results subjectively. The model was trained on a Mandarin dataset which features four singers and four singing techniques: the chest voice, the falsetto, the raspy voice, and the whistle voice. The results show that a wider bottleneck corresponds to better articulation clarity but does not necessarily lead to higher likeness to the target technique. Among the four techniques, we also found that the whistle voice is the easiest target for conversion, while the other three techniques as a source produce more convincing conversion results than the whistle. ",
    "url": "https://arxiv.org/abs/2308.10021",
    "authors": [
      "Tung-Cheng Su",
      "Yung-Chuan Chang",
      "Yi-Wen Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2308.10044",
    "title": "A branch connection rule of one-way rail network",
    "abstract": "We deal with network inspired by toy train, which is constructed by connecting Y-shaped branches. A train passes a branch through either of splitted rails and not allowed to go backward. Under these assumptions, we consider unidirectionality of a rail network, that is, there is a orientation of the rail network such that any trail of a train starting with the direction does not contradict to the orientation. We find that a rail network is one-way if and only if a digraph derived from the rail network is disconnected, which is also equal to no existence of cycle which contains odd number of tracks connecting the same side of branches. ",
    "url": "https://arxiv.org/abs/2308.10044",
    "authors": [
      "Dai Akita",
      "Daniel Thorsten Schenz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2308.10066",
    "title": "Vulnerability of democratic electoral systems",
    "abstract": "The two most common types of electoral systems (ES) used in electing national legislatures are proportional representation and plurality voting. When they are evaluated, most often the arguments come from social choice theory and political sciences. The former overall uses an axiomatic approach including a list of mathematical criteria a system should fulfill. The latter predominantly focuses on the trade-off between proportionality of apportionment and governability. However, there is no consensus on the best ES, nor on the set of indexes and measures that would be the most important in such assessment. Moreover, the ongoing debate about the fairness of national elections neglects the study of their vulnerabilities. Here we address this research gap with a framework that can measure electoral systems' vulnerability to different means of influence. Using in silico analysis we show that plurality voting systems are less stable than proportional representation. They are also more susceptible to political agitators and media propaganda. A review of real-world ES reveals possible improvements in their design leading to lower susceptibility. Additionally, our simulation framework allows computation of popular indexes, as the Gallagher index or the effective number of parties, in different scenarios. Our work provides a new tool for dealing with modern threats to democracy that could destabilize voting processes. Furthermore, our results add an important argument in a long-standing discussion on evaluation of ES. ",
    "url": "https://arxiv.org/abs/2308.10066",
    "authors": [
      "Tomasz Raducha",
      "Jaros\u0142aw Klamut",
      "Roger Cremades",
      "Paul Bouman",
      "Mateusz Wili\u0144ski"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.10113",
    "title": "Modeling Random Networks with Heterogeneous Reciprocity",
    "abstract": "Reciprocity, or the tendency of individuals to mirror behavior, is a key measure that describes information exchange in a social network. Users in social networks tend to engage in different levels of reciprocal behavior. Differences in such behavior may indicate the existence of communities that reciprocate links at varying rates. In this paper, we develop methodology to model the diverse reciprocal behavior in growing social networks. In particular, we present a preferential attachment model with heterogeneous reciprocity that imitates the attraction users have for popular users, plus the heterogeneous nature by which they reciprocate links. We compare Bayesian and frequentist model fitting techniques for large networks, as well as computationally efficient variational alternatives. Cases where the number of communities are known and unknown are both considered. We apply the presented methods to the analysis of a Facebook wallpost network where users have non-uniform reciprocal behavior patterns. The fitted model captures the heavy-tailed nature of the empirical degree distributions in the Facebook data and identifies multiple groups of users that differ in their tendency to reply to and receive responses to wallposts. ",
    "url": "https://arxiv.org/abs/2308.10113",
    "authors": [
      "Daniel Cirkovic",
      "Tiandong Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2308.10142",
    "title": "Polymerized Feature-based Domain Adaptation for Cervical Cancer Dose Map  Prediction",
    "abstract": "Recently, deep learning (DL) has automated and accelerated the clinical radiation therapy (RT) planning significantly by predicting accurate dose maps. However, most DL-based dose map prediction methods are data-driven and not applicable for cervical cancer where only a small amount of data is available. To address this problem, this paper proposes to transfer the rich knowledge learned from another cancer, i.e., rectum cancer, which has the same scanning area and more clinically available data, to improve the dose map prediction performance for cervical cancer through domain adaptation. In order to close the congenital domain gap between the source (i.e., rectum cancer) and the target (i.e., cervical cancer) domains, we develop an effective Transformer-based polymerized feature module (PFM), which can generate an optimal polymerized feature distribution to smoothly align the two input distributions. Experimental results on two in-house clinical datasets demonstrate the superiority of the proposed method compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2308.10142",
    "authors": [
      "Jie Zeng",
      "Zeyu Han",
      "Xingchen Peng",
      "Jianghong Xiao",
      "Peng Wang",
      "Yan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10192",
    "title": "EDDense-Net: Fully Dense Encoder Decoder Network for Joint Segmentation  of Optic Cup and Disc",
    "abstract": "Glaucoma is an eye disease that causes damage to the optic nerve, which can lead to visual loss and permanent blindness. Early glaucoma detection is therefore critical in order to avoid permanent blindness. The estimation of the cup-to-disc ratio (CDR) during an examination of the optical disc (OD) is used for the diagnosis of glaucoma. In this paper, we present the EDDense-Net segmentation network for the joint segmentation of OC and OD. The encoder and decoder in this network are made up of dense blocks with a grouped convolutional layer in each block, allowing the network to acquire and convey spatial information from the image while simultaneously reducing the network's complexity. To reduce spatial information loss, the optimal number of filters in all convolution layers were utilised. In semantic segmentation, dice pixel classification is employed in the decoder to alleviate the problem of class imbalance. The proposed network was evaluated on two publicly available datasets where it outperformed existing state-of-the-art methods in terms of accuracy and efficiency. For the diagnosis and analysis of glaucoma, this method can be used as a second opinion system to assist medical ophthalmologists. ",
    "url": "https://arxiv.org/abs/2308.10192",
    "authors": [
      "Mehwish Mehmood",
      "Khuram Naveed",
      "Haroon Ahmed Khan",
      "Syed S. Naqvi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10230",
    "title": "Karma: Adaptive Video Streaming via Causal Sequence Modeling",
    "abstract": "Optimal adaptive bitrate (ABR) decision depends on a comprehensive characterization of state transitions that involve interrelated modalities over time including environmental observations, returns, and actions. However, state-of-the-art learning-based ABR algorithms solely rely on past observations to decide the next action. This paradigm tends to cause a chain of deviations from optimal action when encountering unfamiliar observations, which consequently undermines the model generalization. This paper presents Karma, an ABR algorithm that utilizes causal sequence modeling to improve generalization by comprehending the interrelated causality among past observations, returns, and actions and timely refining action when deviation occurs. Unlike direct observation-to-action mapping, Karma recurrently maintains a multi-dimensional time series of observations, returns, and actions as input and employs causal sequence modeling via a decision transformer to determine the next action. In the input sequence, Karma uses the maximum cumulative future quality of experience (QoE) (a.k.a, QoE-to-go) as an extended return signal, which is periodically estimated based on current network conditions and playback status. We evaluate Karma through trace-driven simulations and real-world field tests, demonstrating superior performance compared to existing state-of-the-art ABR algorithms, with an average QoE improvement ranging from 10.8% to 18.7% across diverse network conditions. Furthermore, Karma exhibits strong generalization capabilities, showing leading performance under unseen networks in both simulations and real-world tests. ",
    "url": "https://arxiv.org/abs/2308.10230",
    "authors": [
      "Bowei Xu",
      "Hao Chen",
      "Zhan Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10302",
    "title": "Preserving Specificity in Federated Graph Learning for fMRI-based  Neurological Disorder Identification",
    "abstract": "Resting-state functional magnetic resonance imaging (rs-fMRI) offers a non-invasive approach to examining abnormal brain connectivity associated with brain disorders. Graph neural network (GNN) gains popularity in fMRI representation learning and brain disorder analysis with powerful graph representation capabilities. Training a general GNN often necessitates a large-scale dataset from multiple imaging centers/sites, but centralizing multi-site data generally faces inherent challenges related to data privacy, security, and storage burden. Federated Learning (FL) enables collaborative model training without centralized multi-site fMRI data. Unfortunately, previous FL approaches for fMRI analysis often ignore site-specificity, including demographic factors such as age, gender, and education level. To this end, we propose a specificity-aware federated graph learning (SFGL) framework for rs-fMRI analysis and automated brain disorder identification, with a server and multiple clients/sites for federated model aggregation and prediction. At each client, our model consists of a shared and a personalized branch, where parameters of the shared branch are sent to the server while those of the personalized branch remain local. This can facilitate knowledge sharing among sites and also helps preserve site specificity. In the shared branch, we employ a spatio-temporal attention graph isomorphism network to learn dynamic fMRI representations. In the personalized branch, we integrate vectorized demographic information (i.e., age, gender, and education years) and functional connectivity networks to preserve site-specific characteristics. Representations generated by the two branches are then fused for classification. Experimental results on two fMRI datasets with a total of 1,218 subjects suggest that SFGL outperforms several state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2308.10302",
    "authors": [
      "Junhao Zhang",
      "Qianqian Wang",
      "Xiaochuan Wang",
      "Lishan Qiao",
      "Mingxia Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.10368",
    "title": "Prediction of Pneumonia and COVID-19 Using Deep Neural Networks",
    "abstract": "Pneumonia, caused by bacteria and viruses, is a rapidly spreading viral infection with global implications. Prompt identification of infected individuals is crucial for containing its transmission. This study explores the potential of medical image analysis to address this challenge. We propose machine-learning techniques for predicting Pneumonia from chest X-ray images. Chest X-ray imaging is vital for Pneumonia diagnosis due to its accessibility and cost-effectiveness. However, interpreting X-rays for Pneumonia detection can be complex, as radiographic features can overlap with other respiratory conditions. We evaluate the performance of different machine learning models, including DenseNet121, Inception Resnet-v2, Inception Resnet-v3, Resnet50, and Xception, using chest X-ray images of pneumonia patients. Performance measures and confusion matrices are employed to assess and compare the models. The findings reveal that DenseNet121 outperforms other models, achieving an accuracy rate of 99.58%. This study underscores the significance of machine learning in the accurate detection of Pneumonia, leveraging chest X-ray images. Our study offers insights into the potential of technology to mitigate the spread of pneumonia through precise diagnostics. ",
    "url": "https://arxiv.org/abs/2308.10368",
    "authors": [
      "M. S. Haque",
      "M. S. Taluckder",
      "S. B. Shawkat",
      "M. A. Shahriyar",
      "M. A. Sayed",
      "C. Modak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10418",
    "title": "Quantum Query Lower Bounds for Key Recovery Attacks on the Even-Mansour  Cipher",
    "abstract": "The Even-Mansour (EM) cipher is one of the famous constructions for a block cipher. Kuwakado and Morii demonstrated that a quantum adversary can recover its $n$-bit secret keys only with $O(n)$ nonadaptive quantum queries. While the security of the EM cipher and its variants is well-understood for classical adversaries, very little is currently known of their quantum security. Towards a better understanding of the quantum security, or the limits of quantum adversaries for the EM cipher, we study the quantum query complexity for the key recovery of the EM cipher and prove every quantum algorithm requires $\\Omega(n)$ quantum queries for the key recovery even if it is allowed to make adaptive queries. Therefore, the quantum attack of Kuwakado and Morii has the optimal query complexity up to a constant factor, and we cannot asymptotically improve it even with adaptive quantum queries. ",
    "url": "https://arxiv.org/abs/2308.10418",
    "authors": [
      "Akinori Kawachi",
      "Yuki Naito"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.10436",
    "title": "Approximately Equivariant Graph Networks",
    "abstract": "Graph neural networks (GNNs) are commonly described as being permutation equivariant with respect to node relabeling in the graph. This symmetry of GNNs is often compared to the translation equivariance symmetry of Euclidean convolution neural networks (CNNs). However, these two symmetries are fundamentally different: The translation equivariance of CNNs corresponds to symmetries of the fixed domain acting on the image signal (sometimes known as active symmetries), whereas in GNNs any permutation acts on both the graph signals and the graph domain (sometimes described as passive symmetries). In this work, we focus on the active symmetries of GNNs, by considering a learning setting where signals are supported on a fixed graph. In this case, the natural symmetries of GNNs are the automorphisms of the graph. Since real-world graphs tend to be asymmetric, we relax the notion of symmetries by formalizing approximate symmetries via graph coarsening. We present a bias-variance formula that quantifies the tradeoff between the loss in expressivity and the gain in the regularity of the learned estimator, depending on the chosen symmetry group. To illustrate our approach, we conduct extensive experiments on image inpainting, traffic flow prediction, and human pose estimation with different choices of symmetries. We show theoretically and empirically that the best generalization performance can be achieved by choosing a suitably larger group than the graph automorphism group, but smaller than the full permutation group. ",
    "url": "https://arxiv.org/abs/2308.10436",
    "authors": [
      "Ningyuan Huang",
      "Ron Levie",
      "Soledad Villar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10470",
    "title": "Implicit Self-supervised Language Representation for Spoken Language  Diarization",
    "abstract": "In a code-switched (CS) scenario, the use of spoken language diarization (LD) as a pre-possessing system is essential. Further, the use of implicit frameworks is preferable over the explicit framework, as it can be easily adapted to deal with low/zero resource languages. Inspired by speaker diarization (SD) literature, three frameworks based on (1) fixed segmentation, (2) change point-based segmentation and (3) E2E are proposed to perform LD. The initial exploration with synthetic TTSF-LD dataset shows, using x-vector as implicit language representation with appropriate analysis window length ($N$) can able to achieve at per performance with explicit LD. The best implicit LD performance of $6.38$ in terms of Jaccard error rate (JER) is achieved by using the E2E framework. However, considering the E2E framework the performance of implicit LD degrades to $60.4$ while using with practical Microsoft CS (MSCS) dataset. The difference in performance is mostly due to the distributional difference between the monolingual segment duration of secondary language in the MSCS and TTSF-LD datasets. Moreover, to avoid segment smoothing, the smaller duration of the monolingual segment suggests the use of a small value of $N$. At the same time with small $N$, the x-vector representation is unable to capture the required language discrimination due to the acoustic similarity, as the same speaker is speaking both languages. Therefore, to resolve the issue a self-supervised implicit language representation is proposed in this study. In comparison with the x-vector representation, the proposed representation provides a relative improvement of $63.9\\%$ and achieved a JER of $21.8$ using the E2E framework. ",
    "url": "https://arxiv.org/abs/2308.10470",
    "authors": [
      "Jagabandhu Mishra",
      "S. R. Mahadeva Prasanna"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2308.10606",
    "title": "Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian  Networks",
    "abstract": "Interacting systems of events may exhibit cascading behavior where events tend to be temporally clustered. While the cascades themselves may be obvious from the data, it is important to understand which states of the system trigger them. For this purpose, we propose a modeling framework based on continuous-time Bayesian networks (CTBNs) to analyze cascading behavior in complex systems. This framework allows us to describe how events propagate through the system and to identify likely sentry states, that is, system states that may lead to imminent cascading behavior. Moreover, CTBNs have a simple graphical representation and provide interpretable outputs, both of which are important when communicating with domain experts. We also develop new methods for knowledge extraction from CTBNs and we apply the proposed methodology to a data set of alarms in a large industrial system. ",
    "url": "https://arxiv.org/abs/2308.10606",
    "authors": [
      "Alessandro Bregoli",
      "Karin Rathsman",
      "Marco Scutari",
      "Fabio Stella",
      "S\u00f8ren Wengel Mogensen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2308.10818",
    "title": "Interpretable Ensemble Learning for Materials Property Prediction with  Classical Interatomic Potentials: Carbon as an Example",
    "abstract": "Machine learning (ML) is widely used to explore crystal materials and predict their properties. However, the training is time-consuming for deep-learning models, and the regression process is a black box that is hard to interpret. Also, the preprocess to transfer a crystal structure into the input of ML, called descriptor, needs to be designed carefully. To efficiently predict important properties of materials, we propose an approach based on ensemble learning consisting of regression trees to predict formation energy and elastic constants based on small-size datasets of carbon allotropes as an example. Without using any descriptor, the inputs are the properties calculated by molecular dynamics with 9 different classical interatomic potentials. Overall, the results from ensemble learning are more accurate than those from classical interatomic potentials, and ensemble learning can capture the relatively accurate properties from the 9 classical potentials as criteria for predicting the final properties. ",
    "url": "https://arxiv.org/abs/2308.10818",
    "authors": [
      "Xinyu Jiang",
      "Haofan Sun",
      "Kamal Choudhary",
      "Houlong Zhuang",
      "Qiong Nian"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.08786",
    "title": "Walking Out of the Weisfeiler Leman Hierarchy: Graph Learning Beyond  Message Passing",
    "abstract": " Title: Walking Out of the Weisfeiler Leman Hierarchy: Graph Learning Beyond  Message Passing ",
    "url": "https://arxiv.org/abs/2102.08786",
    "authors": [
      "Jan T\u00f6nshoff",
      "Martin Ritzert",
      "Hinrikus Wolf",
      "Martin Grohe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2109.04269",
    "title": "Asynchronous Federated Learning on Heterogeneous Devices: A Survey",
    "abstract": " Title: Asynchronous Federated Learning on Heterogeneous Devices: A Survey ",
    "url": "https://arxiv.org/abs/2109.04269",
    "authors": [
      "Chenhao Xu",
      "Youyang Qu",
      "Yong Xiang",
      "Longxiang Gao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2109.12727",
    "title": "Anomalous Edge Detection in Edge Exchangeable Social Network Models",
    "abstract": " Title: Anomalous Edge Detection in Edge Exchangeable Social Network Models ",
    "url": "https://arxiv.org/abs/2109.12727",
    "authors": [
      "Rui Luo",
      "Buddhika Nettasinghe",
      "Vikram Krishnamurthy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.07000",
    "title": "Mixed-integer linear programming approaches for tree partitioning of  power networks",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2110.07000",
    "authors": [
      "Leon Lan",
      "Alessandro Zocca"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.13939",
    "title": "CausalAF: Causal Autoregressive Flow for Safety-Critical Driving  Scenario Generation",
    "abstract": " Comments: Acceptted to CoRL 2022 ",
    "url": "https://arxiv.org/abs/2110.13939",
    "authors": [
      "Wenhao Ding",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.14422",
    "title": "Agent-Centric Relation Graph for Object Visual Navigation",
    "abstract": " Comments: 16 pages, 13 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2111.14422",
    "authors": [
      "Xiaobo Hu",
      "Youfang Lin",
      "Shuo Wang",
      "Zhihao Wu",
      "Kai Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.09636",
    "title": "Neural Implicit Surface Evolution",
    "abstract": " Title: Neural Implicit Surface Evolution ",
    "url": "https://arxiv.org/abs/2201.09636",
    "authors": [
      "Tiago Novello",
      "Vinicius da Silva",
      "Guilherme Schardong",
      "Luiz Schirmer",
      "Helio Lopes",
      "Luiz Velho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2202.06533",
    "title": "An Introduction to Neural Data Compression",
    "abstract": " Comments: Published in Foundations and Trends in Computer Graphics and Vision: Vol. 15, No. 2, pp 113-200. this https URL ",
    "url": "https://arxiv.org/abs/2202.06533",
    "authors": [
      "Yibo Yang",
      "Stephan Mandt",
      "Lucas Theis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.11885",
    "title": "A Partition-and-Merge Algorithm for Solving the Steiner Tree Problem in  Large Graphs",
    "abstract": " Comments: The problem and techniques of our paper have been studied long ago, so it is currently meaningless. Therefore, we are preparing to withdraw the manuscript ",
    "url": "https://arxiv.org/abs/2202.11885",
    "authors": [
      "Xinyu Wu",
      "Yi Zhou",
      "Jin-Kao Hao",
      "Zhang-Hua Fu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.05186",
    "title": "Suspected Object Matters: Rethinking Model's Prediction for One-stage  Visual Grounding",
    "abstract": " Comments: Accepted to ACM MM 23 ",
    "url": "https://arxiv.org/abs/2203.05186",
    "authors": [
      "Yang Jiao",
      "Zequn Jie",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01203",
    "title": "Towards Robust Referring Video Object Segmentation with Cyclic  Relational Consensus",
    "abstract": " Comments: iccv 2023, this https URL ",
    "url": "https://arxiv.org/abs/2207.01203",
    "authors": [
      "Xiang Li",
      "Jinglu Wang",
      "Xiaohao Xu",
      "Xiao Li",
      "Bhiksha Raj",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10425",
    "title": "KD-MVS: Knowledge Distillation Based Self-supervised Learning for  Multi-view Stereo",
    "abstract": " Title: KD-MVS: Knowledge Distillation Based Self-supervised Learning for  Multi-view Stereo ",
    "url": "https://arxiv.org/abs/2207.10425",
    "authors": [
      "Yikang Ding",
      "Qingtian Zhu",
      "Xiangyue Liu",
      "Wentao Yuan",
      "Haotian Zhang",
      "Chi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11437",
    "title": "The prediction of the quality of results in Logic Synthesis using  Transformer and Graph Neural Networks",
    "abstract": " Title: The prediction of the quality of results in Logic Synthesis using  Transformer and Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2207.11437",
    "authors": [
      "Chenghao Yang",
      "Zhongda Wang",
      "Yinshui Xia",
      "Zhufei Chu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11836",
    "title": "Mitigating the Performance Sacrifice in DP-Satisfied Federated Settings  through Graph Contrastive Learning",
    "abstract": " Comments: Accepted by Information Sciences ",
    "url": "https://arxiv.org/abs/2207.11836",
    "authors": [
      "Haoran Yang",
      "Xiangyu Zhao",
      "Muyang Li",
      "Hongxu Chen",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.05110",
    "title": "Collaborative Propagation on Multiple Instance Graphs for 3D Instance  Segmentation with Single-point Supervision",
    "abstract": " Title: Collaborative Propagation on Multiple Instance Graphs for 3D Instance  Segmentation with Single-point Supervision ",
    "url": "https://arxiv.org/abs/2208.05110",
    "authors": [
      "Shichao Dong",
      "Ruibo Li",
      "Jiacheng Wei",
      "Fayao Liu",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.06681",
    "title": "Modeling biological face recognition with deep convolutional neural  networks",
    "abstract": " Comments: 41 pages, 2 figures, 1 table ",
    "url": "https://arxiv.org/abs/2208.06681",
    "authors": [
      "Leonard E. van Dyck",
      "Walter R. Gruber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.09495",
    "title": "Topical: Learning Repository Embeddings from Source Code using Attention",
    "abstract": " Comments: Pre-print, under review ",
    "url": "https://arxiv.org/abs/2208.09495",
    "authors": [
      "Agathe Lherondelle",
      "Varun Babbar",
      "Yash Satsangi",
      "Fran Silavong",
      "Shaltiel Eloul",
      "Sean Moran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.10531",
    "title": "RAIN: RegulArization on Input and Network for Black-Box Domain  Adaptation",
    "abstract": " Comments: Accepted by IJCAI 2023 ",
    "url": "https://arxiv.org/abs/2208.10531",
    "authors": [
      "Qucheng Peng",
      "Zhengming Ding",
      "Lingjuan Lyu",
      "Lichao Sun",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.05016",
    "title": "FiBiNet++: Reducing Model Size by Low Rank Feature Interaction Layer for  CTR Prediction",
    "abstract": " Title: FiBiNet++: Reducing Model Size by Low Rank Feature Interaction Layer for  CTR Prediction ",
    "url": "https://arxiv.org/abs/2209.05016",
    "authors": [
      "Pengtao Zhang",
      "Zheng Zheng",
      "Junlin Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04845",
    "title": "FS-DETR: Few-Shot DEtection TRansformer with prompting and without  re-training",
    "abstract": " Comments: Accepted at ICCV 2023 ",
    "url": "https://arxiv.org/abs/2210.04845",
    "authors": [
      "Adrian Bulat",
      "Ricardo Guerrero",
      "Brais Martinez",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.02641",
    "title": "Graph Neural Networks on SPD Manifolds for Motor Imagery Classification:  A Perspective from the Time-Frequency Analysis",
    "abstract": " Comments: 15 pages, 5 figures, 6 Tables; This work has been accepted by the IEEE Transactions on Neural Networks and Learning Systems, 2023. Copyright will be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2211.02641",
    "authors": [
      "Ce Ju",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09788",
    "title": "DiffusionDet: Diffusion Model for Object Detection",
    "abstract": " Comments: ICCV2023 (Oral), Camera-ready ",
    "url": "https://arxiv.org/abs/2211.09788",
    "authors": [
      "Shoufa Chen",
      "Peize Sun",
      "Yibing Song",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13955",
    "title": "MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision  Transformer with Heterogeneous Attention",
    "abstract": " Comments: Accepted by ICCV 2023 conference ",
    "url": "https://arxiv.org/abs/2211.13955",
    "authors": [
      "Wenxuan Zeng",
      "Meng Li",
      "Wenjie Xiong",
      "Tong Tong",
      "Wen-jie Lu",
      "Jin Tan",
      "Runsheng Wang",
      "Ru Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14512",
    "title": "Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection  in Semantic Segmentation",
    "abstract": " Comments: The paper contains 16 pages and it is accepted by ICCV'23 ",
    "url": "https://arxiv.org/abs/2211.14512",
    "authors": [
      "Yuyuan Liu",
      "Choubo Ding",
      "Yu Tian",
      "Guansong Pang",
      "Vasileios Belagiannis",
      "Ian Reid",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14963",
    "title": "Neural Architecture for Online Ensemble Continual Learning",
    "abstract": " Title: Neural Architecture for Online Ensemble Continual Learning ",
    "url": "https://arxiv.org/abs/2211.14963",
    "authors": [
      "Mateusz W\u00f3jcik",
      "Witold Ko\u015bciukiewicz",
      "Tomasz Kajdanowicz",
      "Adam Gonczarek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15046",
    "title": "PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial  Networks for Radar-Based Precipitation Nowcasting",
    "abstract": " Comments: CIKM 2023 ",
    "url": "https://arxiv.org/abs/2211.15046",
    "authors": [
      "Jaeho Choi",
      "Yura Kim",
      "Kwang-Ho Kim",
      "Sung-Hwa Jung",
      "Ikhyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01953",
    "title": "Context-aware multi-head self-attentional neural network model for next  location prediction",
    "abstract": " Comments: updated Discussion section; accepted by Transportation Research Part C ",
    "url": "https://arxiv.org/abs/2212.01953",
    "authors": [
      "Ye Hong",
      "Yatao Zhang",
      "Konrad Schindler",
      "Martin Raubal"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05231",
    "title": "NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-view  Reconstruction",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2212.05231",
    "authors": [
      "Yiming Wang",
      "Qin Han",
      "Marc Habermann",
      "Kostas Daniilidis",
      "Christian Theobalt",
      "Lingjie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.05853",
    "title": "DeepCut: Unsupervised Segmentation using Graph Neural Networks  Clustering",
    "abstract": " Title: DeepCut: Unsupervised Segmentation using Graph Neural Networks  Clustering ",
    "url": "https://arxiv.org/abs/2212.05853",
    "authors": [
      "Amit Aflalo",
      "Shai Bagon",
      "Tamar Kashti",
      "Yonina Eldar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.08781",
    "title": "Multi-Scale Relational Graph Convolutional Network for Multiple Instance  Learning in Histopathology Images",
    "abstract": " Title: Multi-Scale Relational Graph Convolutional Network for Multiple Instance  Learning in Histopathology Images ",
    "url": "https://arxiv.org/abs/2212.08781",
    "authors": [
      "Roozbeh Bazargani",
      "Ladan Fazli",
      "Larry Goldenberg",
      "Martin Gleave",
      "Ali Bashashati",
      "Septimiu Salcudean"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.13939",
    "title": "Data Augmentation using Transformers and Similarity Measures for  Improving Arabic Text Classification",
    "abstract": " Comments: 15 pages, 16 Figures, this work has been submitted to the IEEE Access Journal for possible publication ",
    "url": "https://arxiv.org/abs/2212.13939",
    "authors": [
      "Dania Refai",
      "Saleh Abo-Soud",
      "Mohammad Abdel-Rahman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.02009",
    "title": "Learning by Sorting: Self-supervised Learning with Group Ordering  Constraints",
    "abstract": " Comments: Published at ICCV 2023, Code @ this https URL ",
    "url": "https://arxiv.org/abs/2301.02009",
    "authors": [
      "Nina Shvetsova",
      "Felix Petersen",
      "Anna Kukleva",
      "Bernt Schiele",
      "Hilde Kuehne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02412",
    "title": "Code Difference Guided Adversarial Example Generation for Deep Code  Models",
    "abstract": " Comments: Accepted by ASE 2023 ",
    "url": "https://arxiv.org/abs/2301.02412",
    "authors": [
      "Zhao Tian",
      "Junjie Chen",
      "Zhi Jin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.05712",
    "title": "A Survey of Self-supervised Learning from Multiple Perspectives:  Algorithms, Applications and Future Trends",
    "abstract": " Title: A Survey of Self-supervised Learning from Multiple Perspectives:  Algorithms, Applications and Future Trends ",
    "url": "https://arxiv.org/abs/2301.05712",
    "authors": [
      "Jie Gui",
      "Tuo Chen",
      "Jing Zhang",
      "Qiong Cao",
      "Zhenan Sun",
      "Hao Luo",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.09253",
    "title": "CircNet: Meshing 3D Point Clouds with Circumcenter Detection",
    "abstract": " Comments: accepted to ICLR2023 ",
    "url": "https://arxiv.org/abs/2301.09253",
    "authors": [
      "Huan Lei",
      "Ruitao Leng",
      "Liang Zheng",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11530",
    "title": "Cost-aware Defense for Parallel Server Systems against Reliability and  Security Failures",
    "abstract": " Comments: Major Revision in Automatica ",
    "url": "https://arxiv.org/abs/2301.11530",
    "authors": [
      "Qian Xie",
      "Jiayi Wang",
      "Li Jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.07672",
    "title": "LiveHand: Real-time and Photorealistic Neural Hand Rendering",
    "abstract": " Comments: Project page: this https URL | Accepted at ICCV '23 | 11 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2302.07672",
    "authors": [
      "Akshay Mundra",
      "Mallikarjun B R",
      "Jiayi Wang",
      "Marc Habermann",
      "Christian Theobalt",
      "Mohamed Elgharib"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2302.09200",
    "title": "Brainomaly: Unsupervised Neurologic Disease Detection Utilizing  Unannotated T1-weighted Brain MR Images",
    "abstract": " Comments: Accepted in WACV 2024 ",
    "url": "https://arxiv.org/abs/2302.09200",
    "authors": [
      "Md Mahfuzur Rahman Siddiquee",
      "Jay Shah",
      "Teresa Wu",
      "Catherine Chong",
      "Todd J. Schwedt",
      "Gina Dumkrieger",
      "Simona Nikolova",
      "Baoxin Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.09582",
    "title": "Language-Specific Representation of Emotion-Concept Knowledge Causally  Supports Emotion Inference",
    "abstract": " Comments: 39 pages, 13 figures, 2 tables, fix formatting errors ",
    "url": "https://arxiv.org/abs/2302.09582",
    "authors": [
      "Ming Li",
      "Yusheng Su",
      "Hsiu-Yuan Huang",
      "Jiali Cheng",
      "Xin Hu",
      "Xinmiao Zhang",
      "Huadong Wang",
      "Yujia Qin",
      "Xiaozhi Wang",
      "Zhiyuan Liu",
      "Dan Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.10899",
    "title": "Feature Affinity Assisted Knowledge Distillation and Quantization of  Deep Neural Networks on Label-Free Data",
    "abstract": " Title: Feature Affinity Assisted Knowledge Distillation and Quantization of  Deep Neural Networks on Label-Free Data ",
    "url": "https://arxiv.org/abs/2302.10899",
    "authors": [
      "Zhijian Li",
      "Biao Yang",
      "Penghang Yin",
      "Yingyong Qi",
      "Jack Xin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.11068",
    "title": "Low Rank Matrix Completion via Robust Alternating Minimization in Nearly  Linear Time",
    "abstract": " Comments: Improve the runtime from $O(mnk)$ to $O|\\Omega| k)$ ",
    "url": "https://arxiv.org/abs/2302.11068",
    "authors": [
      "Yuzhou Gu",
      "Zhao Song",
      "Junze Yin",
      "Lichen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.01860",
    "title": "Rule-based Out-Of-Distribution Detection",
    "abstract": " Title: Rule-based Out-Of-Distribution Detection ",
    "url": "https://arxiv.org/abs/2303.01860",
    "authors": [
      "Giacomo De Bernardi",
      "Sara Narteni",
      "Enrico Cambiaso",
      "Maurizio Mongelli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08983",
    "title": "Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness  with Dataset Reinforcement",
    "abstract": " Comments: Accepted at International Conference on Computer Vision (ICCV) 2023. Camera-ready version with new Tables 9 and 10 ",
    "url": "https://arxiv.org/abs/2303.08983",
    "authors": [
      "Fartash Faghri",
      "Hadi Pouransari",
      "Sachin Mehta",
      "Mehrdad Farajtabar",
      "Ali Farhadi",
      "Mohammad Rastegari",
      "Oncel Tuzel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08998",
    "title": "Unified Visual Relationship Detection with Vision and Language Models",
    "abstract": " Comments: Accepted to ICCV 2023. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.08998",
    "authors": [
      "Long Zhao",
      "Liangzhe Yuan",
      "Boqing Gong",
      "Yin Cui",
      "Florian Schroff",
      "Ming-Hsuan Yang",
      "Hartwig Adam",
      "Ting Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09769",
    "title": "Denoising Diffusion Autoencoders are Unified Self-supervised Learners",
    "abstract": " Comments: ICCV 2023 Oral ",
    "url": "https://arxiv.org/abs/2303.09769",
    "authors": [
      "Weilai Xiang",
      "Hongyu Yang",
      "Di Huang",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11722",
    "title": "Implicit Neural Representation for Cooperative Low-light Image  Enhancement",
    "abstract": " Title: Implicit Neural Representation for Cooperative Low-light Image  Enhancement ",
    "url": "https://arxiv.org/abs/2303.11722",
    "authors": [
      "Shuzhou Yang",
      "Moxuan Ding",
      "Yanmin Wu",
      "Zihan Li",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.13233",
    "title": "Visually-Prompted Language Model for Fine-Grained Scene Graph Generation  in an Open World",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2303.13233",
    "authors": [
      "Qifan Yu",
      "Juncheng Li",
      "Yu Wu",
      "Siliang Tang",
      "Wei Ji",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.13505",
    "title": "A Large-scale Study of Spatiotemporal Representation Learning with a New  Benchmark on Action Recognition",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2303.13505",
    "authors": [
      "Andong Deng",
      "Taojiannan Yang",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16053",
    "title": "Real-time Multi-person Eyeblink Detection in the Wild for Untrimmed  Video",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.16053",
    "authors": [
      "Wenzheng Zeng",
      "Yang Xiao",
      "Sicheng Wei",
      "Jinfang Gan",
      "Xintao Zhang",
      "Zhiguo Cao",
      "Zhiwen Fang",
      "Joey Tianyi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17606",
    "title": "AvatarCraft: Transforming Text into Neural Human Avatars with  Parameterized Shape and Pose Control",
    "abstract": " Comments: ICCV 2023 Camera Ready ",
    "url": "https://arxiv.org/abs/2303.17606",
    "authors": [
      "Ruixiang Jiang",
      "Can Wang",
      "Jingbo Zhang",
      "Menglei Chai",
      "Mingming He",
      "Dongdong Chen",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.01480",
    "title": "FineRecon: Depth-aware Feed-forward Network for Detailed 3D  Reconstruction",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2304.01480",
    "authors": [
      "Noah Stier",
      "Anurag Ranjan",
      "Alex Colburn",
      "Yajie Yan",
      "Liang Yang",
      "Fangchang Ma",
      "Baptiste Angles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04521",
    "title": "Zero-Shot In-Distribution Detection in Multi-Object Settings Using  Vision-Language Foundation Models",
    "abstract": " Title: Zero-Shot In-Distribution Detection in Multi-Object Settings Using  Vision-Language Foundation Models ",
    "url": "https://arxiv.org/abs/2304.04521",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.05127",
    "title": "Balancing Privacy and Performance for Private Federated Learning  Algorithms",
    "abstract": " Title: Balancing Privacy and Performance for Private Federated Learning  Algorithms ",
    "url": "https://arxiv.org/abs/2304.05127",
    "authors": [
      "Xiangjian Hou",
      "Sarit Khirirat",
      "Mohammad Yaqub",
      "Samuel Horvath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.09987",
    "title": "Tetra-NeRF: Representing Neural Radiance Fields Using Tetrahedra",
    "abstract": " Comments: ICCV 2023, Web: this https URL ",
    "url": "https://arxiv.org/abs/2304.09987",
    "authors": [
      "Jonas Kulhanek",
      "Torsten Sattler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.10031",
    "title": "Architectures of Topological Deep Learning: A Survey on Topological  Neural Networks",
    "abstract": " Title: Architectures of Topological Deep Learning: A Survey on Topological  Neural Networks ",
    "url": "https://arxiv.org/abs/2304.10031",
    "authors": [
      "Mathilde Papillon",
      "Sophia Sanborn",
      "Mustafa Hajij",
      "Nina Miolane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11963",
    "title": "Optimal Design of Neural Network Structure for Power System Frequency  Security Constraints",
    "abstract": " Title: Optimal Design of Neural Network Structure for Power System Frequency  Security Constraints ",
    "url": "https://arxiv.org/abs/2304.11963",
    "authors": [
      "Zhuoxuan Li",
      "Zhongda Chu",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.00795",
    "title": "SelfDocSeg: A Self-Supervised vision-based Approach towards Document  Segmentation",
    "abstract": " Comments: Accepted at The 17th International Conference on Document Analysis and Recognition (ICDAR 2023) ",
    "url": "https://arxiv.org/abs/2305.00795",
    "authors": [
      "Subhajit Maity",
      "Sanket Biswas",
      "Siladittya Manna",
      "Ayan Banerjee",
      "Josep Llad\u00f3s",
      "Saumik Bhattacharya",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.03807",
    "title": "Evading Watermark based Detection of AI-Generated Content",
    "abstract": " Comments: To appear in ACM Conference on Computer and Communications Security (CCS), 2023 ",
    "url": "https://arxiv.org/abs/2305.03807",
    "authors": [
      "Zhengyuan Jiang",
      "Jinghuai Zhang",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11284",
    "title": "Federated learning for secure development of AI models for Parkinson's  disease detection using speech from different languages",
    "abstract": " Comments: INTERSPEECH 2023, pp. 5003--5007, Dublin, Ireland ",
    "url": "https://arxiv.org/abs/2305.11284",
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Cristian David Rios-Urrego",
      "Elmar Noeth",
      "Andreas Maier",
      "Seung Hee Yang",
      "Jan Rusz",
      "Juan Rafael Orozco-Arroyave"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11377",
    "title": "GraphFC: Customs Fraud Detection with Label Scarcity",
    "abstract": " Title: GraphFC: Customs Fraud Detection with Label Scarcity ",
    "url": "https://arxiv.org/abs/2305.11377",
    "authors": [
      "Karandeep Singh",
      "Yu-Che Tsai",
      "Cheng-Te Li",
      "Meeyoung Cha",
      "Shou-De Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.15121",
    "title": "Beyond Individual Input for Deep Anomaly Detection on Tabular Data",
    "abstract": " Title: Beyond Individual Input for Deep Anomaly Detection on Tabular Data ",
    "url": "https://arxiv.org/abs/2305.15121",
    "authors": [
      "Hugo Thimonier",
      "Fabrice Popineau",
      "Arpad Rimmel",
      "Bich-Li\u00ean Doan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15914",
    "title": "Reliable Detection and Quantification of Selective Forces in Language  Change",
    "abstract": " Title: Reliable Detection and Quantification of Selective Forces in Language  Change ",
    "url": "https://arxiv.org/abs/2305.15914",
    "authors": [
      "Juan Guerrero Montero",
      "Andres Karjus",
      "Kenny Smith",
      "Richard A. Blythe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19190",
    "title": "Inverse Approximation Theory for Nonlinear Recurrent Neural Networks",
    "abstract": " Title: Inverse Approximation Theory for Nonlinear Recurrent Neural Networks ",
    "url": "https://arxiv.org/abs/2305.19190",
    "authors": [
      "Shida Wang",
      "Zhong Li",
      "Qianxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2306.00658",
    "title": "NeuroGF: A Neural Representation for Fast Geodesic Distance and Path  Queries",
    "abstract": " Title: NeuroGF: A Neural Representation for Fast Geodesic Distance and Path  Queries ",
    "url": "https://arxiv.org/abs/2306.00658",
    "authors": [
      "Qijian Zhang",
      "Junhui Hou",
      "Yohanes Yudhi Adikusuma",
      "Wenping Wang",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01792",
    "title": "Task Relation-aware Continual User Representation Learning",
    "abstract": " Comments: KDD 2023 ",
    "url": "https://arxiv.org/abs/2306.01792",
    "authors": [
      "Sein Kim",
      "Namkyeong Lee",
      "Donghyun Kim",
      "Minchul Yang",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.03528",
    "title": "Adversarial Attacks and Defenses for Semantic Communication in Vehicular  Metaverses",
    "abstract": " Title: Adversarial Attacks and Defenses for Semantic Communication in Vehicular  Metaverses ",
    "url": "https://arxiv.org/abs/2306.03528",
    "authors": [
      "Jiawen Kang",
      "Jiayi He",
      "Hongyang Du",
      "Zehui Xiong",
      "Zhaohui Yang",
      "Xumin Huang",
      "Shengli Xie"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.05281",
    "title": "A Graph Reconstruction by Dynamic Signal Coefficient for Fault  Classification",
    "abstract": " Title: A Graph Reconstruction by Dynamic Signal Coefficient for Fault  Classification ",
    "url": "https://arxiv.org/abs/2306.05281",
    "authors": [
      "Wenbin He",
      "Jianxu Mao",
      "Yaonan Wang",
      "Zhe Li",
      "Qiu Fang",
      "Haotian Wu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.06236",
    "title": "iPLAN: Intent-Aware Planning in Heterogeneous Traffic via Distributed  Multi-Agent Reinforcement Learning",
    "abstract": " Title: iPLAN: Intent-Aware Planning in Heterogeneous Traffic via Distributed  Multi-Agent Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2306.06236",
    "authors": [
      "Xiyang Wu",
      "Rohan Chandra",
      "Tianrui Guan",
      "Amrit Singh Bedi",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.12235",
    "title": "CompMix: A Benchmark for Heterogeneous Question Answering",
    "abstract": " Title: CompMix: A Benchmark for Heterogeneous Question Answering ",
    "url": "https://arxiv.org/abs/2306.12235",
    "authors": [
      "Philipp Christmann",
      "Rishiraj Saha Roy",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.14161",
    "title": "BiFF: Bi-level Future Fusion with Polyline-based Coordinate for  Interactive Trajectory Prediction",
    "abstract": " Comments: 18 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2306.14161",
    "authors": [
      "Yiyao Zhu",
      "Di Luan",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.14834",
    "title": "Scalable Neural Contextual Bandit for Recommender Systems",
    "abstract": " Title: Scalable Neural Contextual Bandit for Recommender Systems ",
    "url": "https://arxiv.org/abs/2306.14834",
    "authors": [
      "Zheqing Zhu",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16699",
    "title": "Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural  Representation",
    "abstract": " Comments: Accepted by ICCAD 2023 ",
    "url": "https://arxiv.org/abs/2306.16699",
    "authors": [
      "Hanqiu Chen",
      "Hang Yang",
      "Stephen Fitzmeyer",
      "Cong Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.00562",
    "title": "A MIL Approach for Anomaly Detection in Surveillance Videos from  Multiple Camera Views",
    "abstract": " Comments: 8 Pages, 4 Figures ",
    "url": "https://arxiv.org/abs/2307.00562",
    "authors": [
      "Silas Santiago Lopes Pereira",
      "Jos\u00e9 Everardo Bessa Maia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.00750",
    "title": "Feasibility of Universal Anomaly Detection without Knowing the  Abnormality in Medical Images",
    "abstract": " Title: Feasibility of Universal Anomaly Detection without Knowing the  Abnormality in Medical Images ",
    "url": "https://arxiv.org/abs/2307.00750",
    "authors": [
      "Can Cui",
      "Yaohong Wang",
      "Shunxing Bao",
      "Yucheng Tang",
      "Ruining Deng",
      "Lucas W. Remedios",
      "Zuhayr Asad",
      "Joseph T. Roland",
      "Ken S. Lau",
      "Qi Liu",
      "Lori A. Coburn",
      "Keith T. Wilson",
      "Bennett A. Landman",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.04937",
    "title": "Towards Fair Graph Neural Networks via Graph Counterfactual",
    "abstract": " Title: Towards Fair Graph Neural Networks via Graph Counterfactual ",
    "url": "https://arxiv.org/abs/2307.04937",
    "authors": [
      "Zhimeng Guo",
      "Jialiang Li",
      "Teng Xiao",
      "Yao Ma",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.05182",
    "title": "CAT-ViL: Co-Attention Gated Vision-Language Embedding for Visual  Question Localized-Answering in Robotic Surgery",
    "abstract": " Comments: To appear in MICCAI 2023. Code availability: this https URL ",
    "url": "https://arxiv.org/abs/2307.05182",
    "authors": [
      "Long Bai",
      "Mobarakol Islam",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.07205",
    "title": "Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video  Anomaly Detection",
    "abstract": " Comments: Accepted at ICCV2023 ",
    "url": "https://arxiv.org/abs/2307.07205",
    "authors": [
      "Alessandro Flaborea",
      "Luca Collorone",
      "Guido D'Amely",
      "Stefano D'Arrigo",
      "Bardh Prenkaj",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07742",
    "title": "SINC: Self-Supervised In-Context Learning for Vision-Language Tasks",
    "abstract": " Comments: Accepted by ICCV 2023; Camera Ready Version ",
    "url": "https://arxiv.org/abs/2307.07742",
    "authors": [
      "Yi-Syuan Chen",
      "Yun-Zhu Song",
      "Cheng Yu Yeo",
      "Bei Liu",
      "Jianlong Fu",
      "Hong-Han Shuai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08652",
    "title": "Search Me Knot, Render Me Knot: Embedding Search and Differentiable  Rendering of Knots in 3D",
    "abstract": " Title: Search Me Knot, Render Me Knot: Embedding Search and Differentiable  Rendering of Knots in 3D ",
    "url": "https://arxiv.org/abs/2307.08652",
    "authors": [
      "Aalok Gangopadhyay",
      "Paras Gupta",
      "Tarun Sharma",
      "Prajwal Singh",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2307.11629",
    "title": "Scalable Multi-agent Covering Option Discovery based on Kronecker Graphs",
    "abstract": " Comments: Accepted to NeurIPS 2022. arXiv admin note: substantial text overlap with arXiv:2201.08227 ",
    "url": "https://arxiv.org/abs/2307.11629",
    "authors": [
      "Jiayu Chen",
      "Jingdi Chen",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2307.12510",
    "title": "An Empirical Evaluation of Temporal Graph Benchmark",
    "abstract": " Comments: preprint, in progress, add more results ",
    "url": "https://arxiv.org/abs/2307.12510",
    "authors": [
      "Le Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.13755",
    "title": "Training-based Model Refinement and Representation Disagreement for  Semi-Supervised Object Detection",
    "abstract": " Title: Training-based Model Refinement and Representation Disagreement for  Semi-Supervised Object Detection ",
    "url": "https://arxiv.org/abs/2307.13755",
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14751",
    "title": "FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal  Adversarial Masks",
    "abstract": " Comments: Will appear in the proceedings of ACSAC 2023; 13 pages, 5 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2307.14751",
    "authors": [
      "Buse G. A. Tekgul",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.16075",
    "title": "Redesigning Large-Scale Multimodal Transit Networks with Shared  Autonomous Mobility Services",
    "abstract": " Comments: 44 pages, 15 figures, under review for the 25th International Symposium on Transportation and Traffic Theory (ISTTT25) ",
    "url": "https://arxiv.org/abs/2307.16075",
    "authors": [
      "Max T.M. Ng",
      "Hani S. Mahmassani",
      "\u00d6mer Verbas",
      "Taner Cokyasar",
      "Roman Engelhardt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.16572",
    "title": "Transferable Attack for Semantic Segmentation",
    "abstract": " Comments: Source code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2307.16572",
    "authors": [
      "Mengqi He",
      "Jing Zhang",
      "Zhaoyuan Yang",
      "Mingyi He",
      "Nick Barnes",
      "Yuchao Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.02442",
    "title": "Adaptive Preferential Attached kNN Graph with Distribution-Awareness",
    "abstract": " Title: Adaptive Preferential Attached kNN Graph with Distribution-Awareness ",
    "url": "https://arxiv.org/abs/2308.02442",
    "authors": [
      "Shaojie Min",
      "Ji Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.02751",
    "title": "NeRFs: The Search for the Best 3D Representation",
    "abstract": " Comments: Updated based on feedback in-person and via e-mail at SIGGRAPH 2023. In particular, I have added references and discussion of seminal SIGGRAPH image-based rendering papers, and better put the recent Kerbl et al. work in context, with more references ",
    "url": "https://arxiv.org/abs/2308.02751",
    "authors": [
      "Ravi Ramamoorthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.02774",
    "title": "Self-Distillation Network with Ensemble Prototypes: Learning Robust  Speaker Representations without Supervision",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2211.04168 ",
    "url": "https://arxiv.org/abs/2308.02774",
    "authors": [
      "Yafeng Chen",
      "Siqi Zheng",
      "Qian Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2308.03272",
    "title": "Feature-Suppressed Contrast for Self-Supervised Food Pre-training",
    "abstract": " Comments: Accepted by ACM MM 2023 ",
    "url": "https://arxiv.org/abs/2308.03272",
    "authors": [
      "Xinda Liu",
      "Yaohui Zhu",
      "Linhu Liu",
      "Jiang Tian",
      "Lili Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.03282",
    "title": "Environment-Invariant Curriculum Relation Learning for Fine-Grained  Scene Graph Generation",
    "abstract": " Comments: ICCV2023. arXiv admin note: text overlap with arXiv:2203.11654 by other authors ",
    "url": "https://arxiv.org/abs/2308.03282",
    "authors": [
      "Yukuan Min",
      "Aming Wu",
      "Cheng Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.04439",
    "title": "Global Differential Privacy for Distributed Metaverse Healthcare Systems",
    "abstract": " Title: Global Differential Privacy for Distributed Metaverse Healthcare Systems ",
    "url": "https://arxiv.org/abs/2308.04439",
    "authors": [
      "Mehdi Letafati",
      "Safa Otoum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.04583",
    "title": "LATR: 3D Lane Detection from Monocular Images with Transformer",
    "abstract": " Comments: Accepted by ICCV2023 (Oral) ",
    "url": "https://arxiv.org/abs/2308.04583",
    "authors": [
      "Yueru Luo",
      "Chaoda Zheng",
      "Xu Yan",
      "Tang Kun",
      "Chao Zheng",
      "Shuguang Cui",
      "Zhen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.04589",
    "title": "Temporal DINO: A Self-supervised Video Strategy to Enhance Action  Prediction",
    "abstract": " Title: Temporal DINO: A Self-supervised Video Strategy to Enhance Action  Prediction ",
    "url": "https://arxiv.org/abs/2308.04589",
    "authors": [
      "Izzeddin Teeti",
      "Rongali Sai Bhargav",
      "Vivek Singh",
      "Andrew Bradley",
      "Biplab Banerjee",
      "Fabio Cuzzolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06058",
    "title": "Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence  and Variance Reduction",
    "abstract": " Title: Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence  and Variance Reduction ",
    "url": "https://arxiv.org/abs/2308.06058",
    "authors": [
      "Xiaowen Jiang",
      "Sebastian U. Stich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.06300",
    "title": "Automatic Classification of Blood Cell Images Using Convolutional Neural  Network",
    "abstract": " Comments: 15 ",
    "url": "https://arxiv.org/abs/2308.06300",
    "authors": [
      "Rabia Asghar",
      "Sanjay Kumar",
      "Paul Hynds",
      "Abeera Mahfooz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07134",
    "title": "Natural Language is All a Graph Needs",
    "abstract": " Comments: 21 pages, 2 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2308.07134",
    "authors": [
      "Ruosong Ye",
      "Caiqi Zhang",
      "Runhui Wang",
      "Shuyuan Xu",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07575",
    "title": "Story Visualization by Online Text Augmentation with Context Memory",
    "abstract": " Comments: ICCV 2023, Project page: this https URL ",
    "url": "https://arxiv.org/abs/2308.07575",
    "authors": [
      "Daechul Ahn",
      "Daneul Kim",
      "Gwangmo Song",
      "Seung Hwan Kim",
      "Honglak Lee",
      "Dongyeop Kang",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07615",
    "title": "Self-supervised Hypergraphs for Learning Multiple World Interpretations",
    "abstract": " Comments: Accepted in ICCV 2023 Workshops ",
    "url": "https://arxiv.org/abs/2308.07615",
    "authors": [
      "Alina Marcu",
      "Mihai Pirvu",
      "Dragos Costea",
      "Emanuela Haller",
      "Emil Slusanschi",
      "Ahmed Nabil Belbachir",
      "Rahul Sukthankar",
      "Marius Leordeanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.08242",
    "title": "Contrastive Learning for Lane Detection via Cross-Similarity",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2308.08242",
    "authors": [
      "Ali Zoljodi",
      "Sadegh Abadijou",
      "Mina Alibeigi",
      "Masoud Daneshtalab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.08463",
    "title": "Learning to Distill Global Representation for Sparse-View CT",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2308.08463",
    "authors": [
      "Zilong Li",
      "Chenglong Ma",
      "Jie Chen",
      "Junping Zhang",
      "Hongming Shan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.08917",
    "title": "Unfolding for Joint Channel Estimation and Symbol Detection in MIMO  Communication Systems",
    "abstract": " Comments: 14 pages, 19 figures, submitted to IEEE Transactions on Signal Processing ",
    "url": "https://arxiv.org/abs/2308.08917",
    "authors": [
      "Swati Bhattacharya",
      "K.V.S. Hari",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.09308",
    "title": "Differentiable Retrieval Augmentation via Generative Language Modeling  for E-commerce Query Intent Classification",
    "abstract": " Comments: 5 pages, 2 figures; accepted by CIKM2023 ",
    "url": "https://arxiv.org/abs/2308.09308",
    "authors": [
      "Chenyu Zhao",
      "Yunjiang Jiang",
      "Yiming Qiu",
      "Han Zhang",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.09357",
    "title": "Multi-scale Target-Aware Framework for Constrained Image Splicing  Detection and Localization",
    "abstract": " Comments: accepted by ACMMM2023 ",
    "url": "https://arxiv.org/abs/2308.09357",
    "authors": [
      "Yuxuan Tan",
      "Yuanman Li",
      "Limin Zeng",
      "Jiaxiong Ye",
      "Wei wang",
      "Xia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2308.09436",
    "title": "Transformer-based Detection of Microorganisms on High-Resolution Petri  Dish Images",
    "abstract": " Comments: This paper has been accepted at IEEE International Conference on Computer Vision Workshops (ICCV workshop), 2023 ",
    "url": "https://arxiv.org/abs/2308.09436",
    "authors": [
      "Nikolas Ebert",
      "Didier Stricker",
      "Oliver Wasenm\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09487",
    "title": "Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High  Attack Success Rate in the Absence of Training Data",
    "abstract": " Title: Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High  Attack Success Rate in the Absence of Training Data ",
    "url": "https://arxiv.org/abs/2308.09487",
    "authors": [
      "Binhao Ma",
      "Jiahui Wang",
      "Dejun Wang",
      "Bo Meng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09687",
    "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
    "abstract": " Title: Graph of Thoughts: Solving Elaborate Problems with Large Language Models ",
    "url": "https://arxiv.org/abs/2308.09687",
    "authors": [
      "Maciej Besta",
      "Nils Blach",
      "Ales Kubicek",
      "Robert Gerstenberger",
      "Lukas Gianinazzi",
      "Joanna Gajda",
      "Tomasz Lehmann",
      "Michal Podstawski",
      "Hubert Niewiadomski",
      "Piotr Nyczyk",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09690",
    "title": "Random Walks, Conductance, and Resistance for the Connection Graph  Laplacian",
    "abstract": " Title: Random Walks, Conductance, and Resistance for the Connection Graph  Laplacian ",
    "url": "https://arxiv.org/abs/2308.09690",
    "authors": [
      "Alexander Cloninger",
      "Gal Mishne",
      "Andreas Oslandsbotn",
      "Sawyer Jack Robertson",
      "Zhengchao Wan",
      "Yusu Wang"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  }
]