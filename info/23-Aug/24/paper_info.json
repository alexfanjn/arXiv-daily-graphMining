[
  {
    "id": "arXiv:2308.11624",
    "title": "Revolutionizing TCAD Simulations with Universal Device Encoding and  Graph Attention Networks",
    "abstract": "An innovative methodology that leverages artificial intelligence (AI) and graph representation for semiconductor device encoding in TCAD device simulation is proposed. A graph-based universal encoding scheme is presented that not only considers material-level and device-level embeddings, but also introduces a novel spatial relationship embedding inspired by interpolation operations typically used in finite element meshing. Universal physical laws from device simulations are leveraged for comprehensive data-driven modeling, which encompasses surrogate Poisson emulation and current-voltage (IV) prediction based on drift-diffusion model. Both are achieved using a novel graph attention network, referred to as RelGAT. Comprehensive technical details based on the device simulator Sentaurus TCAD are presented, empowering researchers to adopt the proposed AI-driven Electronic Design Automation (EDA) solution at the device level. ",
    "url": "https://arxiv.org/abs/2308.11624",
    "authors": [
      "Guangxi Fan",
      "Kain Lu Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2308.11646",
    "title": "Joint Local Relational Augmentation and Global Nash Equilibrium for  Federated Learning with Non-IID Data",
    "abstract": "Federated learning (FL) is a distributed machine learning paradigm that needs collaboration between a server and a series of clients with decentralized data. To make FL effective in real-world applications, existing work devotes to improving the modeling of decentralized data with non-independent and identical distributions (non-IID). In non-IID settings, there are intra-client inconsistency that comes from the imbalanced data modeling, and inter-client inconsistency among heterogeneous client distributions, which not only hinders sufficient representation of the minority data, but also brings discrepant model deviations. However, previous work overlooks to tackle the above two coupling inconsistencies together. In this work, we propose FedRANE, which consists of two main modules, i.e., local relational augmentation (LRA) and global Nash equilibrium (GNE), to resolve intra- and inter-client inconsistency simultaneously. Specifically, in each client, LRA mines the similarity relations among different data samples and enhances the minority sample representations with their neighbors using attentive message passing. In server, GNE reaches an agreement among inconsistent and discrepant model deviations from clients to server, which encourages the global model to update in the direction of global optimum without breaking down the clients optimization toward their local optimums. We conduct extensive experiments on four benchmark datasets to show the superiority of FedRANE in enhancing the performance of FL with non-IID data. ",
    "url": "https://arxiv.org/abs/2308.11646",
    "authors": [
      "Xinting Liao",
      "Chaochao Chen",
      "Weiming Liu",
      "Pengyang Zhou",
      "Huabin Zhu",
      "Shuheng Shen",
      "Weiqiang Wang",
      "Mengling Hu",
      "Yanchao Tan",
      "Xiaolin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2308.11659",
    "title": "An engine to simulate insurance fraud network data",
    "abstract": "Traditionally, the detection of fraudulent insurance claims relies on business rules and expert judgement which makes it a time-consuming and expensive process (\\'Oskarsd\\'ottir et al., 2022). Consequently, researchers have been examining ways to develop efficient and accurate analytic strategies to flag suspicious claims. Feeding learning methods with features engineered from the social network of parties involved in a claim is a particularly promising strategy (see for example Van Vlasselaer et al. (2016); Tumminello et al. (2023)). When developing a fraud detection model, however, we are confronted with several challenges. The uncommon nature of fraud, for example, creates a high class imbalance which complicates the development of well performing analytic classification models. In addition, only a small number of claims are investigated and get a label, which results in a large corpus of unlabeled data. Yet another challenge is the lack of publicly available data. This hinders not only the development of new methods, but also the validation of existing techniques. We therefore design a simulation machine that is engineered to create synthetic data with a network structure and available covariates similar to the real life insurance fraud data set analyzed in \\'Oskarsd\\'ottir et al. (2022). Further, the user has control over several data-generating mechanisms. We can specify the total number of policyholders and parties, the desired level of imbalance and the (effect size of the) features in the fraud generating model. As such, the simulation engine enables researchers and practitioners to examine several methodological challenges as well as to test their (development strategy of) insurance fraud detection models in a range of different settings. Moreover, large synthetic data sets can be generated to evaluate the predictive performance of (advanced) machine learning techniques. ",
    "url": "https://arxiv.org/abs/2308.11659",
    "authors": [
      "Bavo D.C. Campo",
      "Katrien Antonio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2308.11669",
    "title": "Class Label-aware Graph Anomaly Detection",
    "abstract": "Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a node is anomalous or not. One common observation we made from previous unsupervised methods is that they not only assume the absence of such anomaly labels, but also the absence of class labels (the class a node belongs to used in a general node classification task). In this work, we study the utility of class labels for unsupervised GAD; in particular, how they enhance the detection of structural anomalies. To this end, we propose a Class Label-aware Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of labeled nodes to enhance the performance of unsupervised GAD. Extensive experiments on ten datasets demonstrate the superior performance of CLAD in comparison to existing unsupervised GAD methods, even in the absence of ground-truth class label information. The source code for CLAD is available at \\url{https://github.com/jhkim611/CLAD}. ",
    "url": "https://arxiv.org/abs/2308.11669",
    "authors": [
      "Junghoon Kim",
      "Yeonjun In",
      "Kanghoon Yoon",
      "Junmo Lee",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11681",
    "title": "VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video  Anomaly Detection",
    "abstract": "The recent contrastive language-image pre-training (CLIP) model has shown great success in a wide range of image-level tasks, revealing remarkable ability for learning powerful visual representations with rich semantics. An open and worthwhile problem is efficiently adapting such a strong model to the video domain and designing a robust video anomaly detector. In this work, we propose VadCLIP, a new paradigm for weakly supervised video anomaly detection (WSVAD) by leveraging the frozen CLIP model directly without any pre-training and fine-tuning process. Unlike current works that directly feed extracted features into the weakly supervised classifier for frame-level binary classification, VadCLIP makes full use of fine-grained associations between vision and language on the strength of CLIP and involves dual branch. One branch simply utilizes visual features for coarse-grained binary classification, while the other fully leverages the fine-grained language-image alignment. With the benefit of dual branch, VadCLIP achieves both coarse-grained and fine-grained video anomaly detection by transferring pre-trained knowledge from CLIP to WSVAD task. We conduct extensive experiments on two commonly-used benchmarks, demonstrating that VadCLIP achieves the best performance on both coarse-grained and fine-grained WSVAD, surpassing the state-of-the-art methods by a large margin. Specifically, VadCLIP achieves 84.51% AP and 88.02% AUC on XD-Violence and UCF-Crime, respectively. Code and features will be released to facilitate future VAD research. ",
    "url": "https://arxiv.org/abs/2308.11681",
    "authors": [
      "Peng Wu",
      "Xuerong Zhou",
      "Guansong Pang",
      "Lingru Zhou",
      "Qingsen Yan",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2308.11684",
    "title": "User Identity Linkage in Social Media Using Linguistic and Social  Interaction Features",
    "abstract": "Social media users often hold several accounts in their effort to multiply the spread of their thoughts, ideas, and viewpoints. In the particular case of objectionable content, users tend to create multiple accounts to bypass the combating measures enforced by social media platforms and thus retain their online identity even if some of their accounts are suspended. User identity linkage aims to reveal social media accounts likely to belong to the same natural person so as to prevent the spread of abusive/illegal activities. To this end, this work proposes a machine learning-based detection model, which uses multiple attributes of users' online activity in order to identify whether two or more virtual identities belong to the same real natural person. The models efficacy is demonstrated on two cases on abusive and terrorism-related Twitter content. ",
    "url": "https://arxiv.org/abs/2308.11684",
    "authors": [
      "Despoina Chatzakou",
      "Juan Soler-Company",
      "Theodora Tsikrika",
      "Leo Wanner",
      "Stefanos Vrochidis",
      "Ioannis Kompatsiaris"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.11728",
    "title": "Invariant representation learning for sequential recommendation",
    "abstract": "Sequential recommendation involves automatically recommending the next item to users based on their historical item sequence. While most prior research employs RNN or transformer methods to glean information from the item sequence-generating probabilities for each user-item pair and recommending the top items, these approaches often overlook the challenge posed by spurious relationships. This paper specifically addresses these spurious relations. We introduce a novel sequential recommendation framework named Irl4Rec. This framework harnesses invariant learning and employs a new objective that factors in the relationship between spurious variables and adjustment variables during model training. This approach aids in identifying spurious relations. Comparative analyses reveal that our framework outperforms three typical methods, underscoring the effectiveness of our model. Moreover, an ablation study further demonstrates the critical role our model plays in detecting spurious relations. ",
    "url": "https://arxiv.org/abs/2308.11728",
    "authors": [
      "Xiaofan Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.11730",
    "title": "Knowledge Graph Prompting for Multi-Document Question Answering",
    "abstract": "The 'pre-train, prompt, predict' paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in the scenario of multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of different documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or intra-document structural relations. For graph traversal, we design an LM-guided graph traverser that navigates across nodes and gathers supporting passages assisting LLMs in MD-QA. The constructed graph serves as the global ruler that regulates the transitional space among passages and reduces retrieval latency. Concurrently, the LM-guided traverser acts as a local navigator that gathers pertinent context to progressively approach the question and guarantee retrieval quality. Extensive experiments underscore the efficacy of KGP for MD-QA, signifying the potential of leveraging graphs in enhancing the prompt design for LLMs. Our code is at https://github.com/YuWVandy/KG-LLM-MDQA. ",
    "url": "https://arxiv.org/abs/2308.11730",
    "authors": [
      "Yu Wang",
      "Nedim Lipka",
      "Ryan A. Rossi",
      "Alexa Siu",
      "Ruiyi Zhang",
      "Tyler Derr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11754",
    "title": "Multi-Instance Adversarial Attack on GNN-Based Malicious Domain  Detection",
    "abstract": "Malicious domain detection (MDD) is an open security challenge that aims to detect if an Internet domain is associated with cyber-attacks. Among many approaches to this problem, graph neural networks (GNNs) are deemed highly effective. GNN-based MDD uses DNS logs to represent Internet domains as nodes in a maliciousness graph (DMG) and trains a GNN to infer their maliciousness by leveraging identified malicious domains. Since this method relies on accessible DNS logs to construct DMGs, it exposes a vulnerability for adversaries to manipulate their domain nodes' features and connections within DMGs. Existing research mainly concentrates on threat models that manipulate individual attacker nodes. However, adversaries commonly generate multiple domains to achieve their goals economically and avoid detection. Their objective is to evade discovery across as many domains as feasible. In this work, we call the attack that manipulates several nodes in the DMG concurrently a multi-instance evasion attack. We present theoretical and empirical evidence that the existing single-instance evasion techniques for are inadequate to launch multi-instance evasion attacks against GNN-based MDDs. Therefore, we introduce MintA, an inference-time multi-instance adversarial attack on GNN-based MDDs. MintA enhances node and neighborhood evasiveness through optimized perturbations and operates successfully with only black-box access to the target model, eliminating the need for knowledge about the model's specifics or non-adversary nodes. We formulate an optimization challenge for MintA, achieving an approximate solution. Evaluating MintA on a leading GNN-based MDD technique with real-world data showcases an attack success rate exceeding 80%. These findings act as a warning for security experts, underscoring GNN-based MDDs' susceptibility to practical attacks that can undermine their effectiveness and benefits. ",
    "url": "https://arxiv.org/abs/2308.11754",
    "authors": [
      "Mahmoud Nazzal",
      "Issa Khalil",
      "Abdallah Khreishah",
      "NhatHai Phan",
      "Yao Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.11767",
    "title": "Improving Detection of ChatGPT-Generated Fake Science Using Real  Publication Text: Introducing xFakeBibs a Supervised-Learning Network  Algorithm",
    "abstract": "ChatGPT is becoming a new reality. In this paper, we show how to distinguish ChatGPT-generated publications from counterparts produced by scientists. Using a newly designed supervised Machine Learning algorithm, we demonstrate how to detect machine-generated publications from those produced by scientists. The algorithm was trained using 100 real publication abstracts, followed by a 10-fold calibration approach to establish a lower-upper bound range of acceptance. In the comparison with ChatGPT content, it was evident that ChatGPT contributed merely 23\\% of the bigram content, which is less than 50\\% of any of the other 10 calibrating folds. This analysis highlights a significant disparity in technical terms where ChatGPT fell short of matching real science. When categorizing the individual articles, the xFakeBibs algorithm accurately identified 98 out of 100 publications as fake, with 2 articles incorrectly classified as real publications. Though this work introduced an algorithmic approach that detected the ChatGPT-generated fake science with a high degree of accuracy, it remains challenging to detect all fake records. This work is indeed a step in the right direction to counter fake science and misinformation. ",
    "url": "https://arxiv.org/abs/2308.11767",
    "authors": [
      "Ahmed Abdeen Hamed",
      "Xindong Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.11771",
    "title": "3ET: Efficient Event-based Eye Tracking using a Change-Based ConvLSTM  Network",
    "abstract": "This paper presents a sparse Change-Based Convolutional Long Short-Term Memory (CB-ConvLSTM) model for event-based eye tracking, key for next-generation wearable healthcare technology such as AR/VR headsets. We leverage the benefits of retina-inspired event cameras, namely their low-latency response and sparse output event stream, over traditional frame-based cameras. Our CB-ConvLSTM architecture efficiently extracts spatio-temporal features for pupil tracking from the event stream, outperforming conventional CNN structures. Utilizing a delta-encoded recurrent path enhancing activation sparsity, CB-ConvLSTM reduces arithmetic operations by approximately 4.7$\\times$ without losing accuracy when tested on a \\texttt{v2e}-generated event dataset of labeled pupils. This increase in efficiency makes it ideal for real-time eye tracking in resource-constrained devices. The project code and dataset are openly available at \\url{https://github.com/qinche106/cb-convlstm-eyetracking}. ",
    "url": "https://arxiv.org/abs/2308.11771",
    "authors": [
      "Qinyu Chen",
      "Zuowen Wang",
      "Shih-Chii Liu",
      "Chang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11774",
    "title": "SAMSNeRF: Segment Anything Model (SAM) Guides Dynamic Surgical Scene  Reconstruction by Neural Radiance Field (NeRF)",
    "abstract": "The accurate reconstruction of surgical scenes from surgical videos is critical for various applications, including intraoperative navigation and image-guided robotic surgery automation. However, previous approaches, mainly relying on depth estimation, have limited effectiveness in reconstructing surgical scenes with moving surgical tools. To address this limitation and provide accurate 3D position prediction for surgical tools in all frames, we propose a novel approach called SAMSNeRF that combines Segment Anything Model (SAM) and Neural Radiance Field (NeRF) techniques. Our approach generates accurate segmentation masks of surgical tools using SAM, which guides the refinement of the dynamic surgical scene reconstruction by NeRF. Our experimental results on public endoscopy surgical videos demonstrate that our approach successfully reconstructs high-fidelity dynamic surgical scenes and accurately reflects the spatial information of surgical tools. Our proposed approach can significantly enhance surgical navigation and automation by providing surgeons with accurate 3D position information of surgical tools during surgery.The source code will be released soon. ",
    "url": "https://arxiv.org/abs/2308.11774",
    "authors": [
      "Ange Lou",
      "Yamin Li",
      "Xing Yao",
      "Yike Zhang",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11776",
    "title": "WS-SfMLearner: Self-supervised Monocular Depth and Ego-motion Estimation  on Surgical Videos with Unknown Camera Parameters",
    "abstract": "Depth estimation in surgical video plays a crucial role in many image-guided surgery procedures. However, it is difficult and time consuming to create depth map ground truth datasets in surgical videos due in part to inconsistent brightness and noise in the surgical scene. Therefore, building an accurate and robust self-supervised depth and camera ego-motion estimation system is gaining more attention from the computer vision community. Although several self-supervision methods alleviate the need for ground truth depth maps and poses, they still need known camera intrinsic parameters, which are often missing or not recorded. Moreover, the camera intrinsic prediction methods in existing works depend heavily on the quality of datasets. In this work, we aimed to build a self-supervised depth and ego-motion estimation system which can predict not only accurate depth maps and camera pose, but also camera intrinsic parameters. We proposed a cost-volume-based supervision manner to give the system auxiliary supervision for camera parameters prediction. The experimental results showed that the proposed method improved the accuracy of estimated camera parameters, ego-motion, and depth estimation. ",
    "url": "https://arxiv.org/abs/2308.11776",
    "authors": [
      "Ange Lou",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.11780",
    "title": "Few-shot Anomaly Detection in Text with Deviation Learning",
    "abstract": "Most current methods for detecting anomalies in text concentrate on constructing models solely relying on unlabeled data. These models operate on the presumption that no labeled anomalous examples are available, which prevents them from utilizing prior knowledge of anomalies that are typically present in small numbers in many real-world applications. Furthermore, these models prioritize learning feature embeddings rather than optimizing anomaly scores directly, which could lead to suboptimal anomaly scoring and inefficient use of data during the learning process. In this paper, we introduce FATE, a deep few-shot learning-based framework that leverages limited anomaly examples and learns anomaly scores explicitly in an end-to-end method using deviation learning. In this approach, the anomaly scores of normal examples are adjusted to closely resemble reference scores obtained from a prior distribution. Conversely, anomaly samples are forced to have anomalous scores that considerably deviate from the reference score in the upper tail of the prior. Additionally, our model is optimized to learn the distinct behavior of anomalies by utilizing a multi-head self-attention layer and multiple instance learning approaches. Comprehensive experiments on several benchmark datasets demonstrate that our proposed approach attains a new level of state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2308.11780",
    "authors": [
      "Anindya Sundar Das",
      "Aravind Ajay",
      "Sriparna Saha",
      "Monowar Bhuyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.11781",
    "title": "Addressing Dynamic and Sparse Qualitative Data: A Hilbert Space  Embedding of Categorical Variables",
    "abstract": "We propose a novel framework for incorporating qualitative data into quantitative models for causal estimation. Previous methods use categorical variables derived from qualitative data to build quantitative models. However, this approach can lead to data-sparse categories and yield inconsistent (asymptotically biased) and imprecise (finite sample biased) estimates if the qualitative information is dynamic and intricate. We use functional analysis to create a more nuanced and flexible framework. We embed the observed categories into a latent Baire space and introduce a continuous linear map -- a Hilbert space embedding -- from the Baire space of categories to a Reproducing Kernel Hilbert Space (RKHS) of representation functions. Through the Riesz representation theorem, we establish that the canonical treatment of categorical variables in causal models can be transformed into an identified structure in the RKHS. Transfer learning acts as a catalyst to streamline estimation -- embeddings from traditional models are paired with the kernel trick to form the Hilbert space embedding. We validate our model through comprehensive simulation evidence and demonstrate its relevance in a real-world study that contrasts theoretical predictions from economics and psychology in an e-commerce marketplace. The results confirm the superior performance of our model, particularly in scenarios where qualitative information is nuanced and complex. ",
    "url": "https://arxiv.org/abs/2308.11781",
    "authors": [
      "Anirban Mukherjee",
      "Hannah H. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11782",
    "title": "Resource Allocation in Cloud Computing Using Genetic Algorithm and  Neural Network",
    "abstract": "Cloud computing is one of the most used distributed systems for data processing and data storage. Due to the continuous increase in the size of the data processed by cloud computing, scheduling multiple tasks to maintain efficiency while reducing idle becomes more and more challenging. Efficient cloud-based scheduling is also highly sought by modern transportation systems to improve their security. In this paper, we propose a hybrid algorithm that leverages genetic algorithms and neural networks to improve scheduling. Our method classifies tasks with the Neural Network Task Classification (N2TC) and sends the selected tasks to the Genetic Algorithm Task Assignment (GATA) to allocate resources. It is fairness aware to prevent starvation and considers the execution time, response time, cost, and system efficiency. Evaluations show that our approach outperforms the state-of-the-art method by 3.2% at execution time, 13.3% in costs, and 12.1% at response time. ",
    "url": "https://arxiv.org/abs/2308.11782",
    "authors": [
      "Mahdi Manavi",
      "Yunpeng Zhang",
      "Guoning Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.11785",
    "title": "Towards Safe Automated Refactoring of Imperative Deep Learning Programs  to Graph Execution",
    "abstract": "Efficiency is essential to support responsiveness w.r.t. ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code -- supporting symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development tends to produce code that is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, less error-prone imperative DL frameworks encouraging eager execution have emerged at the expense of run-time performance. Though hybrid approaches aim for the \"best of both worlds,\" using them effectively requires subtle considerations to make code amenable to safe, accurate, and efficient graph execution -- avoiding performance bottlenecks and semantically inequivalent results. We present our ongoing work on an automated refactoring approach that assists developers in specifying whether and how their otherwise eagerly-executed imperative DL code could be reliably and efficiently executed as graphs at run-time in a semantics-preserving fashion. The approach, based on a novel tensor analysis specifically for imperative DL code, consists of refactoring preconditions for automatically determining when it is safe and potentially advantageous to migrate imperative DL code to graph execution and modifying decorator parameters or eagerly executing code already running as graphs. The approach is being implemented as a PyDev Eclipse IDE plug-in and uses the WALA Ariadne analysis framework. We discuss our ongoing work towards optimizing imperative DL code to its full potential. ",
    "url": "https://arxiv.org/abs/2308.11785",
    "authors": [
      "Raffi Khatchadourian",
      "Tatiana Castro V\u00e9lez",
      "Mehdi Bagherzadeh",
      "Nan Jia",
      "Anita Raja"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2308.11788",
    "title": "An extensible point-based method for data chart value detection",
    "abstract": "We present an extensible method for identifying semantic points to reverse engineer (i.e. extract the values of) data charts, particularly those in scientific articles. Our method uses a point proposal network (akin to region proposal networks for object detection) to directly predict the position of points of interest in a chart, and it is readily extensible to multiple chart types and chart elements. We focus on complex bar charts in the scientific literature, on which our model is able to detect salient points with an accuracy of 0.8705 F1 (@1.5-cell max deviation); it achieves 0.9810 F1 on synthetically-generated charts similar to those used in prior works. We also explore training exclusively on synthetic data with novel augmentations, reaching surprisingly competent performance in this way (0.6621 F1) on real charts with widely varying appearance, and we further demonstrate our unchanged method applied directly to synthetic pie charts (0.8343 F1). Datasets, trained models, and evaluation code are available at https://github.com/BNLNLP/PPN_model. ",
    "url": "https://arxiv.org/abs/2308.11788",
    "authors": [
      "Carlos Soto",
      "Shinjae Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11796",
    "title": "Time Does Tell: Self-Supervised Time-Tuning of Dense Image  Representations",
    "abstract": "Spatially dense self-supervised learning is a rapidly growing problem domain with promising applications for unsupervised segmentation and pretraining for dense downstream tasks. Despite the abundance of temporal data in the form of videos, this information-rich source has been largely overlooked. Our paper aims to address this gap by proposing a novel approach that incorporates temporal consistency in dense self-supervised learning. While methods designed solely for images face difficulties in achieving even the same performance on videos, our method improves not only the representation quality for videos-but also images. Our approach, which we call time-tuning, starts from image-pretrained models and fine-tunes them with a novel self-supervised temporal-alignment clustering loss on unlabeled videos. This effectively facilitates the transfer of high-level information from videos to image representations. Time-tuning improves the state-of-the-art by 8-10% for unsupervised semantic segmentation on videos and matches it for images. We believe this method paves the way for further self-supervised scaling by leveraging the abundant availability of videos. The implementation can be found here : https://github.com/SMSD75/Timetuning ",
    "url": "https://arxiv.org/abs/2308.11796",
    "authors": [
      "Mohammadreza Salehi",
      "Efstratios Gavves",
      "Cees G. M. Snoek",
      "Yuki M. Asano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11800",
    "title": "Complex-valued neural networks for voice anti-spoofing",
    "abstract": "Current anti-spoofing and audio deepfake detection systems use either magnitude spectrogram-based features (such as CQT or Melspectrograms) or raw audio processed through convolution or sinc-layers. Both methods have drawbacks: magnitude spectrograms discard phase information, which affects audio naturalness, and raw-feature-based models cannot use traditional explainable AI methods. This paper proposes a new approach that combines the benefits of both methods by using complex-valued neural networks to process the complex-valued, CQT frequency-domain representation of the input audio. This method retains phase information and allows for explainable AI methods. Results show that this approach outperforms previous methods on the \"In-the-Wild\" anti-spoofing dataset and enables interpretation of the results through explainable AI. Ablation studies confirm that the model has learned to use phase information to detect voice spoofing. ",
    "url": "https://arxiv.org/abs/2308.11800",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Philip Sperl",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.11804",
    "title": "Ceci n'est pas une pomme: Adversarial Illusions in Multi-Modal  Embeddings",
    "abstract": "Multi-modal encoders map images, sounds, texts, videos, etc. into a single embedding space, aligning representations across modalities (e.g., associate an image of a dog with a barking sound). We show that multi-modal embeddings can be vulnerable to an attack we call \"adversarial illusions.\" Given an input in any modality, an adversary can perturb it so as to make its embedding close to that of an arbitrary, adversary-chosen input in another modality. Illusions thus enable the adversary to align any image with any text, any text with any sound, etc. Adversarial illusions exploit proximity in the embedding space and are thus agnostic to downstream tasks. Using ImageBind embeddings, we demonstrate how adversarially aligned inputs, generated without knowledge of specific downstream tasks, mislead image generation, text generation, and zero-shot classification. ",
    "url": "https://arxiv.org/abs/2308.11804",
    "authors": [
      "Eugene Bagdasaryan",
      "Vitaly Shmatikov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11814",
    "title": "Evaluation of Deep Neural Operator Models toward Ocean Forecasting",
    "abstract": "Data-driven, deep-learning modeling frameworks have been recently developed for forecasting time series data. Such machine learning models may be useful in multiple domains including the atmospheric and oceanic ones, and in general, the larger fluids community. The present work investigates the possible effectiveness of such deep neural operator models for reproducing and predicting classic fluid flows and simulations of realistic ocean dynamics. We first briefly evaluate the capabilities of such deep neural operator models when trained on a simulated two-dimensional fluid flow past a cylinder. We then investigate their application to forecasting ocean surface circulation in the Middle Atlantic Bight and Massachusetts Bay, learning from high-resolution data-assimilative simulations employed for real sea experiments. We confirm that trained deep neural operator models are capable of predicting idealized periodic eddy shedding. For realistic ocean surface flows and our preliminary study, they can predict several of the features and show some skill, providing potential for future research and applications. ",
    "url": "https://arxiv.org/abs/2308.11814",
    "authors": [
      "Ellery Rajagopal",
      "Anantha N.S. Babu",
      "Tony Ryu",
      "Patrick J. Haley Jr.",
      "Chris Mirabito",
      "Pierre F.J. Lermusiaux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2308.11818",
    "title": "Incorporating Nonlocal Traffic Flow Model in Physics-informed Neural  Networks",
    "abstract": "This research contributes to the advancement of traffic state estimation methods by leveraging the benefits of the nonlocal LWR model within a physics-informed deep learning framework. The classical LWR model, while useful, falls short of accurately representing real-world traffic flows. The nonlocal LWR model addresses this limitation by considering the speed as a weighted mean of the downstream traffic density. In this paper, we propose a novel PIDL framework that incorporates the nonlocal LWR model. We introduce both fixed-length and variable-length kernels and develop the required mathematics. The proposed PIDL framework undergoes a comprehensive evaluation, including various convolutional kernels and look-ahead windows, using data from the NGSIM and CitySim datasets. The results demonstrate improvements over the baseline PIDL approach using the local LWR model. The findings highlight the potential of the proposed approach to enhance the accuracy and reliability of traffic state estimation, enabling more effective traffic management strategies. ",
    "url": "https://arxiv.org/abs/2308.11818",
    "authors": [
      "Archie J. Huang",
      "Animesh Biswas",
      "Shaurya Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2308.11822",
    "title": "PatchBackdoor: Backdoor Attack against Deep Neural Networks without  Model Modification",
    "abstract": "Backdoor attack is a major threat to deep learning systems in safety-critical scenarios, which aims to trigger misbehavior of neural network models under attacker-controlled conditions. However, most backdoor attacks have to modify the neural network models through training with poisoned data and/or direct model editing, which leads to a common but false belief that backdoor attack can be easily avoided by properly protecting the model. In this paper, we show that backdoor attacks can be achieved without any model modification. Instead of injecting backdoor logic into the training data or the model, we propose to place a carefully-designed patch (namely backdoor patch) in front of the camera, which is fed into the model together with the input images. The patch can be trained to behave normally at most of the time, while producing wrong prediction when the input image contains an attacker-controlled trigger object. Our main techniques include an effective training method to generate the backdoor patch and a digital-physical transformation modeling method to enhance the feasibility of the patch in real deployments. Extensive experiments show that PatchBackdoor can be applied to common deep learning models (VGG, MobileNet, ResNet) with an attack success rate of 93% to 99% on classification tasks. Moreover, we implement PatchBackdoor in real-world scenarios and show that the attack is still threatening. ",
    "url": "https://arxiv.org/abs/2308.11822",
    "authors": [
      "Yizhen Yuan",
      "Rui Kong",
      "Shenghao Xie",
      "Yuanchun Li",
      "Yunxin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11825",
    "title": "Accel-GCN: High-Performance GPU Accelerator Design for Graph Convolution  Networks",
    "abstract": "Graph Convolutional Networks (GCNs) are pivotal in extracting latent information from graph data across various domains, yet their acceleration on mainstream GPUs is challenged by workload imbalance and memory access irregularity. To address these challenges, we present Accel-GCN, a GPU accelerator architecture for GCNs. The design of Accel-GCN encompasses: (i) a lightweight degree sorting stage to group nodes with similar degree; (ii) a block-level partition strategy that dynamically adjusts warp workload sizes, enhancing shared memory locality and workload balance, and reducing metadata overhead compared to designs like GNNAdvisor; (iii) a combined warp strategy that improves memory coalescing and computational parallelism in the column dimension of dense matrices. Utilizing these principles, we formulated a kernel for sparse matrix multiplication (SpMM) in GCNs that employs block-level partitioning and combined warp strategy. This approach augments performance and multi-level memory efficiency and optimizes memory bandwidth by exploiting memory coalescing and alignment. Evaluation of Accel-GCN across 18 benchmark graphs reveals that it outperforms cuSPARSE, GNNAdvisor, and graph-BLAST by factors of 1.17 times, 1.86 times, and 2.94 times respectively. The results underscore Accel-GCN as an effective solution for enhancing GCN computational efficiency. ",
    "url": "https://arxiv.org/abs/2308.11825",
    "authors": [
      "Xi Xie",
      "Hongwu Peng",
      "Amit Hasan",
      "Shaoyi Huang",
      "Jiahui Zhao",
      "Haowen Fang",
      "Wei Zhang",
      "Tong Geng",
      "Omer Khan",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11834",
    "title": "Performance Comparison and Implementation of Bayesian Variants for  Network Intrusion Detection",
    "abstract": "Bayesian classifiers perform well when each of the features is completely independent of the other which is not always valid in real world application. The aim of this study is to implement and compare the performances of each variant of Bayesian classifier (Multinomial, Bernoulli, and Gaussian) on anomaly detection in network intrusion, and to investigate whether there is any association between each variant assumption and their performance. Our investigation showed that each variant of Bayesian algorithm blindly follows its assumption regardless of feature property, and that the assumption is the single most important factor that influences their accuracy. Experimental results show that Bernoulli has accuracy of 69.9% test (71% train), Multinomial has accuracy of 31.2% test (31.2% train), while Gaussian has accuracy of 81.69% test (82.84% train). Going deeper, we investigated and found that each Naive Bayes variants performances and accuracy is largely due to each classifier assumption, Gaussian classifier performed best on anomaly detection due to its assumption that features follow normal distributions which are continuous, while multinomial classifier have a dismal performance as it simply assumes discreet and multinomial distribution. ",
    "url": "https://arxiv.org/abs/2308.11834",
    "authors": [
      "Tosin Ige",
      "Christopher Kiekintveld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.11845",
    "title": "SEA: Shareable and Explainable Attribution for Query-based Black-box  Attacks",
    "abstract": "Machine Learning (ML) systems are vulnerable to adversarial examples, particularly those from query-based black-box attacks. Despite various efforts to detect and prevent such attacks, there is a need for a more comprehensive approach to logging, analyzing, and sharing evidence of attacks. While classic security benefits from well-established forensics and intelligence sharing, Machine Learning is yet to find a way to profile its attackers and share information about them. In response, this paper introduces SEA, a novel ML security system to characterize black-box attacks on ML systems for forensic purposes and to facilitate human-explainable intelligence sharing. SEA leverages the Hidden Markov Models framework to attribute the observed query sequence to known attacks. It thus understands the attack's progression rather than just focusing on the final adversarial examples. Our evaluations reveal that SEA is effective at attack attribution, even on their second occurrence, and is robust to adaptive strategies designed to evade forensics analysis. Interestingly, SEA's explanations of the attack behavior allow us even to fingerprint specific minor implementation bugs in attack libraries. For example, we discover that the SignOPT and Square attacks implementation in ART v1.14 sends over 50% specific zero difference queries. We thoroughly evaluate SEA on a variety of settings and demonstrate that it can recognize the same attack's second occurrence with 90+% Top-1 and 95+% Top-3 accuracy. ",
    "url": "https://arxiv.org/abs/2308.11845",
    "authors": [
      "Yue Gao",
      "Ilia Shumailov",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.11870",
    "title": "Multi-object Detection, Tracking and Prediction in Rugged Dynamic  Environments",
    "abstract": "Multi-object tracking (MOT) has important applications in monitoring, logistics, and other fields. This paper develops a real-time multi-object tracking and prediction system in rugged environments. A 3D object detection algorithm based on Lidar-camera fusion is designed to detect the target objects. Based on the Hungarian algorithm, this paper designs a 3D multi-object tracking algorithm with an adaptive threshold to realize the stable matching and tracking of the objects. We combine Memory Augmented Neural Networks (MANN) and Kalman filter to achieve 3D trajectory prediction on rugged terrains. Besides, we realize a new dynamic SLAM by using the results of multi-object tracking to remove dynamic points for better SLAM performance and static map. To verify the effectiveness of the proposed multi-object tracking and prediction system, several simulations and physical experiments are conducted. The results show that the proposed system can track dynamic objects and provide future trajectory and a more clean static map in real-time. ",
    "url": "https://arxiv.org/abs/2308.11870",
    "authors": [
      "Shixing Huang",
      "Zhihao Wang",
      "Junyuan Ouyang",
      "Haoyao Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.11881",
    "title": "Adversarial Training Using Feedback Loops",
    "abstract": "Deep neural networks (DNN) have found wide applicability in numerous fields due to their ability to accurately learn very complex input-output relations. Despite their accuracy and extensive use, DNNs are highly susceptible to adversarial attacks due to limited generalizability. For future progress in the field, it is essential to build DNNs that are robust to any kind of perturbations to the data points. In the past, many techniques have been proposed to robustify DNNs using first-order derivative information of the network. This paper proposes a new robustification approach based on control theory. A neural network architecture that incorporates feedback control, named Feedback Neural Networks, is proposed. The controller is itself a neural network, which is trained using regular and adversarial data such as to stabilize the system outputs. The novel adversarial training approach based on the feedback control architecture is called Feedback Looped Adversarial Training (FLAT). Numerical results on standard test problems empirically show that our FLAT method is more effective than the state-of-the-art to guard against adversarial attacks. ",
    "url": "https://arxiv.org/abs/2308.11881",
    "authors": [
      "Ali Haisam Muhammad Rafid",
      "Adrian Sandu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.11894",
    "title": "Does Physical Adversarial Example Really Matter to Autonomous Driving?  Towards System-Level Effect of Adversarial Object Evasion Attack",
    "abstract": "In autonomous driving (AD), accurate perception is indispensable to achieving safe and secure driving. Due to its safety-criticality, the security of AD perception has been widely studied. Among different attacks on AD perception, the physical adversarial object evasion attacks are especially severe. However, we find that all existing literature only evaluates their attack effect at the targeted AI component level but not at the system level, i.e., with the entire system semantics and context such as the full AD pipeline. Thereby, this raises a critical research question: can these existing researches effectively achieve system-level attack effects (e.g., traffic rule violations) in the real-world AD context? In this work, we conduct the first measurement study on whether and how effectively the existing designs can lead to system-level effects, especially for the STOP sign-evasion attacks due to their popularity and severity. Our evaluation results show that all the representative prior works cannot achieve any system-level effects. We observe two design limitations in the prior works: 1) physical model-inconsistent object size distribution in pixel sampling and 2) lack of vehicle plant model and AD system model consideration. Then, we propose SysAdv, a novel system-driven attack design in the AD context and our evaluation results show that the system-level effects can be significantly improved, i.e., the violation rate increases by around 70%. ",
    "url": "https://arxiv.org/abs/2308.11894",
    "authors": [
      "Ningfei Wang",
      "Yunpeng Luo",
      "Takami Sato",
      "Kaidi Xu",
      "Qi Alfred Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11896",
    "title": "Age Prediction From Face Images Via Contrastive Learning",
    "abstract": "This paper presents a novel approach for accurately estimating age from face images, which overcomes the challenge of collecting a large dataset of individuals with the same identity at different ages. Instead, we leverage readily available face datasets of different people at different ages and aim to extract age-related features using contrastive learning. Our method emphasizes these relevant features while suppressing identity-related features using a combination of cosine similarity and triplet margin losses. We demonstrate the effectiveness of our proposed approach by achieving state-of-the-art performance on two public datasets, FG-NET and MORPH-II. ",
    "url": "https://arxiv.org/abs/2308.11896",
    "authors": [
      "Yeongnam Chae",
      "Poulami Raha",
      "Mijung Kim",
      "Bjorn Stenger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11898",
    "title": "Exploring the Optimization Objective of One-Class Classification for  Anomaly Detection",
    "abstract": "One-class classification (OCC) is a longstanding method for anomaly detection. With the powerful representation capability of the pre-trained backbone, OCC methods have witnessed significant performance improvements. Typically, most of these OCC methods employ transfer learning to enhance the discriminative nature of the pre-trained backbone's features, thus achieving remarkable efficacy. While most current approaches emphasize feature transfer strategies, we argue that the optimization objective space within OCC methods could also be an underlying critical factor influencing performance. In this work, we conducted a thorough investigation into the optimization objective of OCC. Through rigorous theoretical analysis and derivation, we unveil a key insights: any space with the suitable norm can serve as an equivalent substitute for the hypersphere center, without relying on the distribution assumption of training samples. Further, we provide guidelines for determining the feasible domain of norms for the OCC optimization objective. This novel insight sparks a simple and data-agnostic deep one-class classification method. Our method is straightforward, with a single 1x1 convolutional layer as a trainable projector and any space with suitable norm as the optimization objective. Extensive experiments validate the reliability and efficacy of our findings and the corresponding methodology, resulting in state-of-the-art performance in both one-class classification and industrial vision anomaly detection and segmentation tasks. ",
    "url": "https://arxiv.org/abs/2308.11898",
    "authors": [
      "Han Gao",
      "Huiyuan Luo",
      "Fei Shen",
      "Zhengtao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.11900",
    "title": "HashReID: Dynamic Network with Binary Codes for Efficient Person  Re-identification",
    "abstract": "Biometric applications, such as person re-identification (ReID), are often deployed on energy constrained devices. While recent ReID methods prioritize high retrieval performance, they often come with large computational costs and high search time, rendering them less practical in real-world settings. In this work, we propose an input-adaptive network with multiple exit blocks, that can terminate computation early if the retrieval is straightforward or noisy, saving a lot of computation. To assess the complexity of the input, we introduce a temporal-based classifier driven by a new training strategy. Furthermore, we adopt a binary hash code generation approach instead of relying on continuous-valued features, which significantly improves the search process by a factor of 20. To ensure similarity preservation, we utilize a new ranking regularizer that bridges the gap between continuous and binary features. Extensive analysis of our proposed method is conducted on three datasets: Market1501, MSMT17 (Multi-Scene Multi-Time), and the BGC1 (BRIAR Government Collection). Using our approach, more than 70% of the samples with compact hash codes exit early on the Market1501 dataset, saving 80% of the networks computational cost and improving over other hash-based methods by 60%. These results demonstrate a significant improvement over dynamic networks and showcase comparable accuracy performance to conventional ReID methods. Code will be made available. ",
    "url": "https://arxiv.org/abs/2308.11900",
    "authors": [
      "Kshitij Nikhal",
      "Yujunrong Ma",
      "Shuvra S. Bhattacharyya",
      "Benjamin S. Riggan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11901",
    "title": "Camera-Driven Representation Learning for Unsupervised Domain Adaptive  Person Re-identification",
    "abstract": "We present a novel unsupervised domain adaption method for person re-identification (reID) that generalizes a model trained on a labeled source domain to an unlabeled target domain. We introduce a camera-driven curriculum learning (CaCL) framework that leverages camera labels of person images to transfer knowledge from source to target domains progressively. To this end, we divide target domain dataset into multiple subsets based on the camera labels, and initially train our model with a single subset (i.e., images captured by a single camera). We then gradually exploit more subsets for training, according to a curriculum sequence obtained with a camera-driven scheduling rule. The scheduler considers maximum mean discrepancies (MMD) between each subset and the source domain dataset, such that the subset closer to the source domain is exploited earlier within the curriculum. For each curriculum sequence, we generate pseudo labels of person images in a target domain to train a reID model in a supervised way. We have observed that the pseudo labels are highly biased toward cameras, suggesting that person images obtained from the same camera are likely to have the same pseudo labels, even for different IDs. To address the camera bias problem, we also introduce a camera-diversity (CD) loss encouraging person images of the same pseudo label, but captured across various cameras, to involve more for discriminative feature learning, providing person representations robust to inter-camera variations. Experimental results on standard benchmarks, including real-to-real and synthetic-to-real scenarios, demonstrate the effectiveness of our framework. ",
    "url": "https://arxiv.org/abs/2308.11901",
    "authors": [
      "Geon Lee",
      "Sanghoon Lee",
      "Dohyung Kim",
      "Younghoon Shin",
      "Yongsang Yoon",
      "Bumsub Ham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11909",
    "title": "Edge-aware Hard Clustering Graph Pooling for Brain Imaging Data",
    "abstract": "Graph Convolutional Networks (GCNs) can capture non-Euclidean spatial dependence between different brain regions, and the graph pooling operator in GCNs is key to enhancing the representation learning capability and acquiring abnormal brain maps. However, the majority of existing research designs graph pooling operators only from the perspective of nodes while disregarding the original edge features, in a way that not only confines graph pooling application scenarios, but also diminishes its ability to capture critical substructures. In this study, a clustering graph pooling method that first supports multidimensional edge features, called Edge-aware hard clustering graph pooling (EHCPool), is developed. EHCPool proposes the first 'Edge-to-node' score evaluation criterion based on edge features to assess node feature significance. To more effectively capture the critical subgraphs, a novel Iteration n-top strategy is further designed to adaptively learn sparse hard clustering assignments for graphs. Subsequently, an innovative N-E Aggregation strategy is presented to aggregate node and edge feature information in each independent subgraph. The proposed model was evaluated on multi-site brain imaging public datasets and yielded state-of-the-art performance. We believe this method is the first deep learning tool with the potential to probe different types of abnormal functional brain networks from data-driven perspective. ",
    "url": "https://arxiv.org/abs/2308.11909",
    "authors": [
      "Cheng Zhu",
      "Jiayi Zhu",
      "Lijuan Zhang",
      "Xi Wu",
      "Shuqi Yang",
      "Ping Liang",
      "Honghan Chen",
      "Ying Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.11911",
    "title": "ACLS: Adaptive and Conditional Label Smoothing for Network Calibration",
    "abstract": "We address the problem of network calibration adjusting miscalibrated confidences of deep neural networks. Many approaches to network calibration adopt a regularization-based method that exploits a regularization term to smooth the miscalibrated confidences. Although these approaches have shown the effectiveness on calibrating the networks, there is still a lack of understanding on the underlying principles of regularization in terms of network calibration. We present in this paper an in-depth analysis of existing regularization-based methods, providing a better understanding on how they affect to network calibration. Specifically, we have observed that 1) the regularization-based methods can be interpreted as variants of label smoothing, and 2) they do not always behave desirably. Based on the analysis, we introduce a novel loss function, dubbed ACLS, that unifies the merits of existing regularization methods, while avoiding the limitations. We show extensive experimental results for image classification and semantic segmentation on standard benchmarks, including CIFAR10, Tiny-ImageNet, ImageNet, and PASCAL VOC, demonstrating the effectiveness of our loss function. ",
    "url": "https://arxiv.org/abs/2308.11911",
    "authors": [
      "Hyekang Park",
      "Jongyoun Noh",
      "Youngmin Oh",
      "Donghyeon Baek",
      "Bumsub Ham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11914",
    "title": "Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge  Reasoning via Promoting Causal Consistency in LLMs",
    "abstract": "Despite advancements in LLMs, knowledge-based reasoning remains a longstanding issue due to the fragility of knowledge recall and inference. Existing methods primarily encourage LLMs to autonomously plan and solve problems or to extensively sample reasoning chains without addressing the conceptual and inferential fallacies. Attempting to alleviate inferential fallacies and drawing inspiration from multi-agent collaboration, we present a framework to increase faithfulness and causality for knowledge-based reasoning. Specifically, we propose to employ multiple intelligent agents (i.e., reasoner and causal evaluator) to work collaboratively in a reasoning-and-consensus paradigm for elevated reasoning faithfulness. The reasoners focus on providing solutions with human-like causality to solve open-domain problems. On the other hand, the causal evaluator agent scrutinizes if the answer in a solution is causally deducible from the question and vice versa, with a counterfactual answer replacing the original. According to the extensive and comprehensive evaluations on a variety of knowledge reasoning tasks (e.g., science question answering and commonsense reasoning), our framework outperforms all compared state-of-the-art approaches by large margins. ",
    "url": "https://arxiv.org/abs/2308.11914",
    "authors": [
      "Ziyi Tang",
      "Ruilin Wang",
      "Weixing Chen",
      "Keze Wang",
      "Yang Liu",
      "Tianshui Chen",
      "Liang Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2308.11918",
    "title": "AMSP-UOD: When Vortex Convolution and Stochastic Perturbation Meet  Underwater Object Detection",
    "abstract": "In this paper, we present a novel Amplitude-Modulated Stochastic Perturbation and Vortex Convolutional Network, AMSP-UOD, designed for underwater object detection. AMSP-UOD specifically addresses the impact of non-ideal imaging factors on detection accuracy in complex underwater environments. To mitigate the influence of noise on object detection performance, we propose AMSP Vortex Convolution (AMSP-VConv) to disrupt the noise distribution, enhance feature extraction capabilities, effectively reduce parameters, and improve network robustness. We design the Feature Association Decoupling Cross Stage Partial (FAD-CSP) module, which strengthens the association of long and short-range features, improving the network performance in complex underwater environments. Additionally, our sophisticated post-processing method, based on non-maximum suppression with aspect-ratio similarity thresholds, optimizes detection in dense scenes, such as waterweed and schools of fish, improving object detection accuracy. Extensive experiments on the URPC and RUOD datasets demonstrate that our method outperforms existing state-of-the-art methods in terms of accuracy and noise immunity. AMSP-UOD proposes an innovative solution with the potential for real-world applications. Code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2308.11918",
    "authors": [
      "Jingchun Zhou",
      "Zongxin He",
      "Kin-Man Lam",
      "Yudong Wang",
      "Weishi Zhang",
      "ChunLe Guo",
      "Chongyi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11934",
    "title": "An EEP-based robust beamforming approach for superdirective antenna  arrays and experimental validations",
    "abstract": "A superdirective antenna array has the potential to achieve an array gain proportional to the square of the number of antennas, making it of great value for future wireless communications. However, designing the superdirective beamformer while considering the complicated mutual-coupling effect is a practical challenge. Moreover, the superdirective antenna array is highly sensitive to excitation errors, especially when the number of antennas is large or the antenna spacing is very small, necessitating demanding and precise control over excitations. To address these problems, we first propose a novel superdirective beamforming approach based on the embedded element pattern (EEP), which contains the coupling information. The closed-form solution to the beamforming vector and the corresponding directivity factor are derived. This method relies on the beam coupling factors (BCFs) between the antennas, which are provided in closed form. To address the high sensitivity problem, we formulate a constrained optimization problem and propose an EEP-aided orthogonal complement-based robust beamforming (EEP-OCRB) algorithm. Full-wave simulation results validate our proposed methods. Finally, we build a prototype of a 5-dipole superdirective antenna array and conduct real-world experiments. The measurement results demonstrate the realization of the superdirectivity with our EEP-based method, as well as the robustness of the proposed EEP-OCRB algorithm to excitation errors. ",
    "url": "https://arxiv.org/abs/2308.11934",
    "authors": [
      "Mengying Gao",
      "Haifan Yin",
      "Liangcheng Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.11946",
    "title": "Multi-scale Transformer Pyramid Networks for Multivariate Time Series  Forecasting",
    "abstract": "Multivariate Time Series (MTS) forecasting involves modeling temporal dependencies within historical records. Transformers have demonstrated remarkable performance in MTS forecasting due to their capability to capture long-term dependencies. However, prior work has been confined to modeling temporal dependencies at either a fixed scale or multiple scales that exponentially increase (most with base 2). This limitation hinders their effectiveness in capturing diverse seasonalities, such as hourly and daily patterns. In this paper, we introduce a dimension invariant embedding technique that captures short-term temporal dependencies and projects MTS data into a higher-dimensional space, while preserving the dimensions of time steps and variables in MTS data. Furthermore, we present a novel Multi-scale Transformer Pyramid Network (MTPNet), specifically designed to effectively capture temporal dependencies at multiple unconstrained scales. The predictions are inferred from multi-scale latent representations obtained from transformers at various scales. Extensive experiments on nine benchmark datasets demonstrate that the proposed MTPNet outperforms recent state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2308.11946",
    "authors": [
      "Yifan Zhang",
      "Rui Wu",
      "Sergiu M. Dascalu",
      "Frederick C. Harris Jr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11948",
    "title": "Efficient Transfer Learning in Diffusion Models via Adversarial Noise",
    "abstract": "Diffusion Probabilistic Models (DPMs) have demonstrated substantial promise in image generation tasks but heavily rely on the availability of large amounts of training data. Previous works, like GANs, have tackled the limited data problem by transferring pre-trained models learned with sufficient data. However, those methods are hard to be utilized in DPMs since the distinct differences between DPM-based and GAN-based methods, showing in the unique iterative denoising process integral and the need for many timesteps with no-targeted noise in DPMs. In this paper, we propose a novel DPMs-based transfer learning method, TAN, to address the limited data problem. It includes two strategies: similarity-guided training, which boosts transfer with a classifier, and adversarial noise selection which adaptive chooses targeted noise based on the input image. Extensive experiments in the context of few-shot image generation tasks demonstrate that our method is not only efficient but also excels in terms of image quality and diversity when compared to existing GAN-based and DDPM-based methods. ",
    "url": "https://arxiv.org/abs/2308.11948",
    "authors": [
      "Xiyu Wang",
      "Baijiong Lin",
      "Daochang Liu",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11970",
    "title": "Compressing CFI Graphs and Lower Bounds for the Weisfeiler-Leman  Refinements",
    "abstract": "The $k$-dimensional Weisfeiler-Leman ($k$-WL) algorithm is a simple combinatorial algorithm that was originally designed as a graph isomorphism heuristic. It naturally finds applications in Babai's quasipolynomial time isomorphism algorithm, practical isomorphism solvers, and algebraic graph theory. However, it also has surprising connections to other areas such as logic, proof complexity, combinatorial optimization, and machine learning. The algorithm iteratively computes a coloring of the $k$-tuples of vertices of a graph. Since F\\\"urer's linear lower bound [ICALP 2001], it has been an open question whether there is a super-linear lower bound for the iteration number for $k$-WL on graphs. We answer this question affirmatively, establishing an $\\Omega(n^{k/2})$-lower bound for all $k$. ",
    "url": "https://arxiv.org/abs/2308.11970",
    "authors": [
      "Martin Grohe",
      "Moritz Lichter",
      "Daniel Neuen",
      "Pascal Schweitzer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2308.11971",
    "title": "EVE: Efficient Vision-Language Pre-training with Masked Prediction and  Modality-Aware MoE",
    "abstract": "Building scalable vision-language models to learn from diverse, multimodal data remains an open challenge. In this paper, we introduce an Efficient Vision-languagE foundation model, namely EVE, which is one unified multimodal Transformer pre-trained solely by one unified pre-training task. Specifically, EVE encodes both vision and language within a shared Transformer network integrated with modality-aware sparse Mixture-of-Experts (MoE) modules, which capture modality-specific information by selectively switching to different experts. To unify pre-training tasks of vision and language, EVE performs masked signal modeling on image-text pairs to reconstruct masked signals, i.e., image pixels and text tokens, given visible signals. This simple yet effective pre-training objective accelerates training by 3.5x compared to the model pre-trained with Image-Text Contrastive and Image-Text Matching losses. Owing to the combination of the unified architecture and pre-training task, EVE is easy to scale up, enabling better downstream performance with fewer resources and faster training speed. Despite its simplicity, EVE achieves state-of-the-art performance on various vision-language downstream tasks, including visual question answering, visual reasoning, and image-text retrieval. ",
    "url": "https://arxiv.org/abs/2308.11971",
    "authors": [
      "Junyi Chen",
      "Longteng Guo",
      "Jia Sun",
      "Shuai Shao",
      "Zehuan Yuan",
      "Liang Lin",
      "Dongyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2308.11974",
    "title": "Blending-NeRF: Text-Driven Localized Editing in Neural Radiance Fields",
    "abstract": "Text-driven localized editing of 3D objects is particularly difficult as locally mixing the original 3D object with the intended new object and style effects without distorting the object's form is not a straightforward process. To address this issue, we propose a novel NeRF-based model, Blending-NeRF, which consists of two NeRF networks: pretrained NeRF and editable NeRF. Additionally, we introduce new blending operations that allow Blending-NeRF to properly edit target regions which are localized by text. By using a pretrained vision-language aligned model, CLIP, we guide Blending-NeRF to add new objects with varying colors and densities, modify textures, and remove parts of the original object. Our extensive experiments demonstrate that Blending-NeRF produces naturally and locally edited 3D objects from various text prompts. ",
    "url": "https://arxiv.org/abs/2308.11974",
    "authors": [
      "Hyeonseop Song",
      "Seokhun Choi",
      "Hoseok Do",
      "Chul Lee",
      "Taehyeong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.11977",
    "title": "ESTA: An Efficient Spatial-Temporal Range Aggregation Query Processing  Algorithm for UAV Networks",
    "abstract": "Unmanned Aerial Vehicle (UAV) networks have been widely used in both military and civilian scenarios. When users are interested in the statistical information of the historical sensory data in a certain region during a certain time period, they will send an aggregation query request with a spatial-temporal constraint to target UAVs which store the qualified data. Then, the target UAVs will return the query results to users. Meanwhile, the query results can be aggregated within the network during transmission to save energy and bandwidth resources, which are typically scarce in UAV networks. However, due to the unique characteristics of UAV networks, it is difficult to perform efficient in-network aggregation of query results without the sacrifice of the user query delay. To the best of our knowledge, there is no research on spatial-temporal range aggregation query in UAV networks. In this paper, we propose an Efficient Spatial-Temporal range Aggregation query processing (ESTA) algorithm for UAV networks. First, a topology change graph is constructed based on the pre-planned trajectory information. Meanwhile, an efficient shortest path algorithm is proposed to obtain the user query delay. Then, on the basis of ensuring the user query delay, ESTA transforms the aggregation processing of query results into recursively solving the set cover problem, thereby constructing a spatial-temporal aggregation tree (STAT), based on which an efficient in-network aggregation routing path for query results can be found. Through extensive simulation, we demonstrate that ESTA can save more than 50% of the energy consumption compared with the baseline algorithm. ",
    "url": "https://arxiv.org/abs/2308.11977",
    "authors": [
      "Wenbin Zhai",
      "Xin Li",
      "Liang Liu",
      "Youwei Ding",
      "Wanying Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.11978",
    "title": "Will More Expressive Graph Neural Networks do Better on Generative  Tasks?",
    "abstract": "Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZINC-250k dataset. Through our extensive experiments, we demonstrate that advanced GNNs can indeed improve the performance of GCPN and GraphAF on molecular generation tasks, but GNN expressiveness is not a necessary condition for a good GNN-based generative model. Moreover, we show that GCPN and GraphAF with advanced GNNs can achieve state-of-the-art results across 17 other non-GNN-based graph generative approaches, such as variational autoencoders and Bayesian optimisation models, on the proposed molecular generative objectives (DRD2, Median1, Median2), which are important metrics for de-novo molecular design. ",
    "url": "https://arxiv.org/abs/2308.11978",
    "authors": [
      "Xiandong Zou",
      "Xiangyu Zhao",
      "Pietro Li\u00f2",
      "Yiren Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.11979",
    "title": "Rotation-Invariant Completion Network",
    "abstract": "Real-world point clouds usually suffer from incompleteness and display different poses. While current point cloud completion methods excel in reproducing complete point clouds with consistent poses as seen in the training set, their performance tends to be unsatisfactory when handling point clouds with diverse poses. We propose a network named Rotation-Invariant Completion Network (RICNet), which consists of two parts: a Dual Pipeline Completion Network (DPCNet) and an enhancing module. Firstly, DPCNet generates a coarse complete point cloud. The feature extraction module of DPCNet can extract consistent features, no matter if the input point cloud has undergone rotation or translation. Subsequently, the enhancing module refines the fine-grained details of the final generated point cloud. RICNet achieves better rotation invariance in feature extraction and incorporates structural relationships in man-made objects. To assess the performance of RICNet and existing methods on point clouds with various poses, we applied random transformations to the point clouds in the MVP dataset and conducted experiments on them. Our experiments demonstrate that RICNet exhibits superior completion performance compared to existing methods. ",
    "url": "https://arxiv.org/abs/2308.11979",
    "authors": [
      "Yu Chen",
      "Pengcheng Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11981",
    "title": "Federated Semi-Supervised and Semi-Asynchronous Learning for Anomaly  Detection in IoT Networks",
    "abstract": "Existing FL-based approaches are based on the unrealistic assumption that the data on the client-side is fully annotated with ground truths. Furthermore, it is a great challenge how to improve the training efficiency while ensuring the detection accuracy in the highly heterogeneous and resource-constrained IoT networks. Meanwhile, the communication cost between clients and the server is also a problem that can not be ignored. Therefore, in this paper, we propose a Federated Semi-Supervised and Semi-Asynchronous (FedS3A) learning for anomaly detection in IoT networks. First, we consider a more realistic assumption that labeled data is only available at the server, and pseudo-labeling is utilized to implement federated semi-supervised learning, in which a dynamic weight of supervised learning is exploited to balance the supervised learning at the server and unsupervised learning at clients. Then, we propose a semi-asynchronous model update and staleness tolerant distribution scheme to achieve a trade-off between the round efficiency and detection accuracy. Meanwhile, the staleness of local models and the participation frequency of clients are considered to adjust their contributions to the global model. In addition, a group-based aggregation function is proposed to deal with the non-IID distribution of the data. Finally, the difference transmission based on the sparse matrix is adopted to reduce the communication cost. Extensive experimental results show that FedS3A can achieve greater than 98% accuracy even when the data is non-IID and is superior to the classic FL-based algorithms in terms of both detection performance and round efficiency, achieving a win-win situation. Meanwhile, FedS3A successfully reduces the communication cost by higher than 50%. ",
    "url": "https://arxiv.org/abs/2308.11981",
    "authors": [
      "Wenbin Zhai",
      "Feng Wang",
      "Liang Liu",
      "Youwei Ding",
      "Wanying Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.11990",
    "title": "RankMixup: Ranking-Based Mixup Training for Network Calibration",
    "abstract": "Network calibration aims to accurately estimate the level of confidences, which is particularly important for employing deep neural networks in real-world systems. Recent approaches leverage mixup to calibrate the network's predictions during training. However, they do not consider the problem that mixtures of labels in mixup may not accurately represent the actual distribution of augmented samples. In this paper, we present RankMixup, a novel mixup-based framework alleviating the problem of the mixture of labels for network calibration. To this end, we propose to use an ordinal ranking relationship between raw and mixup-augmented samples as an alternative supervisory signal to the label mixtures for network calibration. We hypothesize that the network should estimate a higher level of confidence for the raw samples than the augmented ones (Fig.1). To implement this idea, we introduce a mixup-based ranking loss (MRL) that encourages lower confidences for augmented samples compared to raw ones, maintaining the ranking relationship. We also propose to leverage the ranking relationship among multiple mixup-augmented samples to further improve the calibration capability. Augmented samples with larger mixing coefficients are expected to have higher confidences and vice versa (Fig.1). That is, the order of confidences should be aligned with that of mixing coefficients. To this end, we introduce a novel loss, M-NDCG, in order to reduce the number of misaligned pairs of the coefficients and confidences. Extensive experimental results on standard benchmarks for network calibration demonstrate the effectiveness of RankMixup. ",
    "url": "https://arxiv.org/abs/2308.11990",
    "authors": [
      "Jongyoun Noh",
      "Hyekang Park",
      "Junghyup Lee",
      "Bumsub Ham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11994",
    "title": "Progressive Feature Mining and External Knowledge-Assisted  Text-Pedestrian Image Retrieval",
    "abstract": "Text-Pedestrian Image Retrieval aims to use the text describing pedestrian appearance to retrieve the corresponding pedestrian image. This task involves not only modality discrepancy, but also the challenge of the textual diversity of pedestrians with the same identity. At present, although existing research progress has been made in text-pedestrian image retrieval, these methods do not comprehensively consider the above-mentioned problems. Considering these, this paper proposes a progressive feature mining and external knowledge-assisted feature purification method. Specifically, we use a progressive mining mode to enable the model to mine discriminative features from neglected information, thereby avoiding the loss of discriminative information and improving the expression ability of features. In addition, to further reduce the negative impact of modal discrepancy and text diversity on cross-modal matching, we propose to use other sample knowledge of the same modality, i.e., external knowledge to enhance identity-consistent features and weaken identity-inconsistent features. This process purifies features and alleviates the interference caused by textual diversity and negative sample correlation features of the same modal. Extensive experiments on three challenging datasets demonstrate the effectiveness and superiority of the proposed method, and the retrieval performance even surpasses that of the large-scale model-based method on large-scale datasets. ",
    "url": "https://arxiv.org/abs/2308.11994",
    "authors": [
      "Huafeng Li",
      "Shedan Yang",
      "Yafei Zhang",
      "Dapeng Tao",
      "Zhengtao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12002",
    "title": "Neural oscillators for magnetic hysteresis modeling",
    "abstract": "Hysteresis is a ubiquitous phenomenon in science and engineering; its modeling and identification are crucial for understanding and optimizing the behavior of various systems. We develop an ordinary differential equation-based recurrent neural network (RNN) approach to model and quantify the hysteresis, which manifests itself in sequentiality and history-dependence. Our neural oscillator, HystRNN, draws inspiration from coupled-oscillatory RNN and phenomenological hysteresis models to update the hidden states. The performance of HystRNN is evaluated to predict generalized scenarios, involving first-order reversal curves and minor loops. The findings show the ability of HystRNN to generalize its behavior to previously untrained regions, an essential feature that hysteresis models must have. This research highlights the advantage of neural oscillators over the traditional RNN-based methods in capturing complex hysteresis patterns in magnetic materials, where traditional rate-dependent methods are inadequate to capture intrinsic nonlinearity. ",
    "url": "https://arxiv.org/abs/2308.12002",
    "authors": [
      "Abhishek Chandra",
      "Taniya Kapoor",
      "Bram Daniels",
      "Mitrofan Curti",
      "Koen Tiels",
      "Daniel M. Tartakovsky",
      "Elena A. Lomonova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2308.12006",
    "title": "Multi-stage Factorized Spatio-Temporal Representation for RGB-D Action  and Gesture Recognition",
    "abstract": "RGB-D action and gesture recognition remain an interesting topic in human-centered scene understanding, primarily due to the multiple granularities and large variation in human motion. Although many RGB-D based action and gesture recognition approaches have demonstrated remarkable results by utilizing highly integrated spatio-temporal representations across multiple modalities (i.e., RGB and depth data), they still encounter several challenges. Firstly, vanilla 3D convolution makes it hard to capture fine-grained motion differences between local clips under different modalities. Secondly, the intricate nature of highly integrated spatio-temporal modeling can lead to optimization difficulties. Thirdly, duplicate and unnecessary information can add complexity and complicate entangled spatio-temporal modeling. To address the above issues, we propose an innovative heuristic architecture called Multi-stage Factorized Spatio-Temporal (MFST) for RGB-D action and gesture recognition. The proposed MFST model comprises a 3D Central Difference Convolution Stem (CDC-Stem) module and multiple factorized spatio-temporal stages. The CDC-Stem enriches fine-grained temporal perception, and the multiple hierarchical spatio-temporal stages construct dimension-independent higher-order semantic primitives. Specifically, the CDC-Stem module captures bottom-level spatio-temporal features and passes them successively to the following spatio-temporal factored stages to capture the hierarchical spatial and temporal features through the Multi- Scale Convolution and Transformer (MSC-Trans) hybrid block and Weight-shared Multi-Scale Transformer (WMS-Trans) block. The seamless integration of these innovative designs results in a robust spatio-temporal representation that outperforms state-of-the-art approaches on RGB-D action and gesture recognition datasets. ",
    "url": "https://arxiv.org/abs/2308.12006",
    "authors": [
      "Yujun Ma",
      "Benjia Zhou",
      "Ruili Wang",
      "Pichao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12009",
    "title": "StofNet: Super-resolution Time of Flight Network",
    "abstract": "Time of Flight (ToF) is a prevalent depth sensing technology in the fields of robotics, medical imaging, and non-destructive testing. Yet, ToF sensing faces challenges from complex ambient conditions making an inverse modelling from the sparse temporal information intractable. This paper highlights the potential of modern super-resolution techniques to learn varying surroundings for a reliable and accurate ToF detection. Unlike existing models, we tailor an architecture for sub-sample precise semi-global signal localization by combining super-resolution with an efficient residual contraction block to balance between fine signal details and large scale contextual information. We consolidate research on ToF by conducting a benchmark comparison against six state-of-the-art methods for which we employ two publicly available datasets. This includes the release of our SToF-Chirp dataset captured by an airborne ultrasound transducer. Results showcase the superior performance of our proposed StofNet in terms of precision, reliability and model complexity. Our code is available at https://github.com/hahnec/stofnet. ",
    "url": "https://arxiv.org/abs/2308.12009",
    "authors": [
      "Christopher Hahne",
      "Michel Hayoz",
      "Raphael Sznitman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2308.12017",
    "title": "Distribution-Aware Calibration for Object Detection with Noisy Bounding  Boxes",
    "abstract": "Large-scale well-annotated datasets are of great importance for training an effective object detector. However, obtaining accurate bounding box annotations is laborious and demanding. Unfortunately, the resultant noisy bounding boxes could cause corrupt supervision signals and thus diminish detection performance. Motivated by the observation that the real ground-truth is usually situated in the aggregation region of the proposals assigned to a noisy ground-truth, we propose DIStribution-aware CalibratiOn (DISCO) to model the spatial distribution of proposals for calibrating supervision signals. In DISCO, spatial distribution modeling is performed to statistically extract the potential locations of objects. Based on the modeled distribution, three distribution-aware techniques, i.e., distribution-aware proposal augmentation (DA-Aug), distribution-aware box refinement (DA-Ref), and distribution-aware confidence estimation (DA-Est), are developed to improve classification, localization, and interpretability, respectively. Extensive experiments on large-scale noisy image datasets (i.e., Pascal VOC and MS-COCO) demonstrate that DISCO can achieve state-of-the-art detection performance, especially at high noise levels. ",
    "url": "https://arxiv.org/abs/2308.12017",
    "authors": [
      "Donghao Zhou",
      "Jialin Li",
      "Jinpeng Li",
      "Jiancheng Huang",
      "Qiang Nie",
      "Yong Liu",
      "Bin-Bin Gao",
      "Qiong Wang",
      "Pheng-Ann Heng",
      "Guangyong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12022",
    "title": "Reranking Passages with Coarse-to-Fine Neural Retriever using  List-Context Information",
    "abstract": "Passage reranking is a crucial task in many applications, particularly when dealing with large-scale documents. Traditional neural architectures are limited in retrieving the best passage for a question because they usually match the question to each passage separately, seldom considering contextual information in other passages that can provide comparison and reference information. This paper presents a list-context attention mechanism to augment the passage representation by incorporating the list-context information from other candidates. The proposed coarse-to-fine (C2F) neural retriever addresses the out-of-memory limitation of the passage attention mechanism by dividing the list-context modeling process into two sub-processes, allowing for efficient encoding of context information from a large number of candidate answers. This method can be generally used to encode context information from any number of candidate answers in one pass. Different from most multi-stage information retrieval architectures, this model integrates the coarse and fine rankers into the joint optimization process, allowing for feedback between the two layers to update the model simultaneously. Experiments demonstrate the effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2308.12022",
    "authors": [
      "Hongyin Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.12044",
    "title": "A multiobjective continuation method to compute the regularization path  of deep neural networks",
    "abstract": "Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto front for the above-mentioned objectives in a very efficient manner. We present numerical examples using both deterministic and stochastic gradients. We furthermore demonstrate that knowledge of the regularization path allows for a well-generalizing network parametrization. ",
    "url": "https://arxiv.org/abs/2308.12044",
    "authors": [
      "Augustina C. Amakor",
      "Konstantin Sontag",
      "Sebastian Peitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.12048",
    "title": "Head-Tail Cooperative Learning Network for Unbiased Scene Graph  Generation",
    "abstract": "Scene Graph Generation (SGG) as a critical task in image understanding, facing the challenge of head-biased prediction caused by the long-tail distribution of predicates. However, current unbiased SGG methods can easily prioritize improving the prediction of tail predicates while ignoring the substantial sacrifice in the prediction of head predicates, leading to a shift from head bias to tail bias. To address this issue, we propose a model-agnostic Head-Tail Collaborative Learning (HTCL) network that includes head-prefer and tail-prefer feature representation branches that collaborate to achieve accurate recognition of both head and tail predicates. We also propose a self-supervised learning approach to enhance the prediction ability of the tail-prefer feature representation branch by constraining tail-prefer predicate features. Specifically, self-supervised learning converges head predicate features to their class centers while dispersing tail predicate features as much as possible through contrast learning and head center loss. We demonstrate the effectiveness of our HTCL by applying it to various SGG models on VG150, Open Images V6 and GQA200 datasets. The results show that our method achieves higher mean Recall with a minimal sacrifice in Recall and achieves a new state-of-the-art overall performance. Our code is available at https://github.com/wanglei0618/HTCL. ",
    "url": "https://arxiv.org/abs/2308.12048",
    "authors": [
      "Lei Wang",
      "Zejian Yuan",
      "Yao Lu",
      "Badong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12049",
    "title": "Towards Privacy-Supporting Fall Detection via Deep Unsupervised  RGB2Depth Adaptation",
    "abstract": "Fall detection is a vital task in health monitoring, as it allows the system to trigger an alert and therefore enabling faster interventions when a person experiences a fall. Although most previous approaches rely on standard RGB video data, such detailed appearance-aware monitoring poses significant privacy concerns. Depth sensors, on the other hand, are better at preserving privacy as they merely capture the distance of objects from the sensor or camera, omitting color and texture information. In this paper, we introduce a privacy-supporting solution that makes the RGB-trained model applicable in depth domain and utilizes depth data at test time for fall detection. To achieve cross-modal fall detection, we present an unsupervised RGB to Depth (RGB2Depth) cross-modal domain adaptation approach that leverages labelled RGB data and unlabelled depth data during training. Our proposed pipeline incorporates an intermediate domain module for feature bridging, modality adversarial loss for modality discrimination, classification loss for pseudo-labeled depth data and labeled source data, triplet loss that considers both source and target domains, and a novel adaptive loss weight adjustment method for improved coordination among various losses. Our approach achieves state-of-the-art results in the unsupervised RGB2Depth domain adaptation task for fall detection. Code is available at https://github.com/1015206533/privacy_supporting_fall_detection. ",
    "url": "https://arxiv.org/abs/2308.12049",
    "authors": [
      "Hejun Xiao",
      "Kunyu Peng",
      "Xiangsheng Huang",
      "Alina Roitberg1",
      "Hao Li",
      "Zhaohui Wang",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.12054",
    "title": "Sample Complexity of Robust Learning against Evasion Attacks",
    "abstract": "It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. One of the fundamental problems in adversarial machine learning is to quantify how much training data is needed in the presence of evasion attacks, where data is corrupted at test time. In this thesis, we work with the exact-in-the-ball notion of robustness and study the feasibility of adversarially robust learning from the perspective of learning theory, considering sample complexity. We first explore the setting where the learner has access to random examples only, and show that distributional assumptions are essential. We then focus on learning problems with distributions on the input data that satisfy a Lipschitz condition and show that robustly learning monotone conjunctions has sample complexity at least exponential in the adversary's budget (the maximum number of bits it can perturb on each input). However, if the adversary is restricted to perturbing $O(\\log n)$ bits, then one can robustly learn conjunctions and decision lists w.r.t. log-Lipschitz distributions. We then study learning models where the learner is given more power. We first consider local membership queries, where the learner can query the label of points near the training sample. We show that, under the uniform distribution, the exponential dependence on the adversary's budget to robustly learn conjunctions remains inevitable. We then introduce a local equivalence query oracle, which returns whether the hypothesis and target concept agree in a given region around a point in the training sample, and a counterexample if it exists. We show that if the query radius is equal to the adversary's budget, we can develop robust empirical risk minimization algorithms in the distribution-free setting. We give general query complexity upper and lower bounds, as well as for concrete concept classes. ",
    "url": "https://arxiv.org/abs/2308.12054",
    "authors": [
      "Pascale Gourdeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.12063",
    "title": "Metaplasticity: Unifying Learning and Homeostatic Plasticity in Spiking  Neural Networks",
    "abstract": "The natural evolution of the human brain has given rise to multiple forms of synaptic plasticity, allowing for dynamic changes to adapt to an ever-evolving world. The evolutionary development of synaptic plasticity has spurred our exploration of biologically plausible optimization and learning algorithms for Spiking Neural Networks (SNNs). Present neural networks rely on the direct training of synaptic weights, which ultimately leads to fixed connections and hampers their ability to adapt to dynamic real-world environments. To address this challenge, we introduce the application of metaplasticity -- a sophisticated mechanism involving the learning of plasticity rules rather than direct modifications of synaptic weights. Metaplasticity dynamically combines different plasticity rules, effectively enhancing working memory, multitask generalization, and adaptability while uncovering potential associations between various forms of plasticity and cognitive functions. By integrating metaplasticity into SNNs, we demonstrate the enhanced adaptability and cognitive capabilities within artificial intelligence systems. This computational perspective unveils the learning mechanisms of the brain, marking a significant step in the profound intersection of neuroscience and artificial intelligence. ",
    "url": "https://arxiv.org/abs/2308.12063",
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Yiting Dong",
      "Yang Li",
      "Feifei Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.12083",
    "title": "Counterfactual Graph Augmentation for Consumer Unfairness Mitigation in  Recommender Systems",
    "abstract": "In recommendation literature, explainability and fairness are becoming two prominent perspectives to consider. However, prior works have mostly addressed them separately, for instance by explaining to consumers why a certain item was recommended or mitigating disparate impacts in recommendation utility. None of them has leveraged explainability techniques to inform unfairness mitigation. In this paper, we propose an approach that relies on counterfactual explanations to augment the set of user-item interactions, such that using them while inferring recommendations leads to fairer outcomes. Modeling user-item interactions as a bipartite graph, our approach augments the latter by identifying new user-item edges that not only can explain the original unfairness by design, but can also mitigate it. Experiments on two public data sets show that our approach effectively leads to a better trade-off between fairness and recommendation utility compared with state-of-the-art mitigation procedures. We further analyze the characteristics of added edges to highlight key unfairness patterns. Source code available at https://github.com/jackmedda/RS-BGExplainer/tree/cikm2023. ",
    "url": "https://arxiv.org/abs/2308.12083",
    "authors": [
      "Ludovico Boratto",
      "Francesco Fabbri",
      "Gianni Fenu",
      "Mirko Marras",
      "Giacomo Medda"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.12093",
    "title": "Cached Operator Reordering: A Unified View for Fast GNN Training",
    "abstract": "Graph Neural Networks (GNNs) are a powerful tool for handling structured graph data and addressing tasks such as node classification, graph classification, and clustering. However, the sparse nature of GNN computation poses new challenges for performance optimization compared to traditional deep neural networks. We address these challenges by providing a unified view of GNN computation, I/O, and memory. By analyzing the computational graphs of the Graph Convolutional Network (GCN) and Graph Attention (GAT) layers -- two widely used GNN layers -- we propose alternative computation strategies. We present adaptive operator reordering with caching, which achieves a speedup of up to 2.43x for GCN compared to the current state-of-the-art. Furthermore, an exploration of different caching schemes for GAT yields a speedup of up to 1.94x. The proposed optimizations save memory, are easily implemented across various hardware platforms, and have the potential to alleviate performance bottlenecks in training large-scale GNN models. ",
    "url": "https://arxiv.org/abs/2308.12093",
    "authors": [
      "Julia Bazinska",
      "Andrei Ivanov",
      "Tal Ben-Nun",
      "Nikoli Dryden",
      "Maciej Besta",
      "Siyuan Shen",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2308.12111",
    "title": "Cross-Modality Proposal-guided Feature Mining for Unregistered  RGB-Thermal Pedestrian Detection",
    "abstract": "RGB-Thermal (RGB-T) pedestrian detection aims to locate the pedestrians in RGB-T image pairs to exploit the complementation between the two modalities for improving detection robustness in extreme conditions. Most existing algorithms assume that the RGB-T image pairs are well registered, while in the real world they are not aligned ideally due to parallax or different field-of-view of the cameras. The pedestrians in misaligned image pairs may locate at different positions in two images, which results in two challenges: 1) how to achieve inter-modality complementation using spatially misaligned RGB-T pedestrian patches, and 2) how to recognize the unpaired pedestrians at the boundary. To deal with these issues, we propose a new paradigm for unregistered RGB-T pedestrian detection, which predicts two separate pedestrian locations in the RGB and thermal images, respectively. Specifically, we propose a cross-modality proposal-guided feature mining (CPFM) mechanism to extract the two precise fusion features for representing the pedestrian in the two modalities, even if the RGB-T image pair is unaligned. It enables us to effectively exploit the complementation between the two modalities. With the CPFM mechanism, we build a two-stream dense detector; it predicts the two pedestrian locations in the two modalities based on the corresponding fusion feature mined by the CPFM mechanism. Besides, we design a data augmentation method, named Homography, to simulate the discrepancy in scales and views between images. We also investigate two non-maximum suppression (NMS) methods for post-processing. Favorable experimental results demonstrate the effectiveness and robustness of our method in dealing with unregistered pedestrians with different shifts. ",
    "url": "https://arxiv.org/abs/2308.12111",
    "authors": [
      "Chao Tian",
      "Zikun Zhou",
      "Yuqing Huang",
      "Gaojun Li",
      "Zhenyu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12113",
    "title": "Advancements in Point Cloud Data Augmentation for Deep Learning: A  Survey",
    "abstract": "Point cloud has a wide range of applications in areas such as autonomous driving, mapping, navigation, scene reconstruction, and medical imaging. Due to its great potentials in these applications, point cloud processing has gained great attention in the field of computer vision. Among various point cloud processing techniques, deep learning (DL) has become one of the mainstream and effective methods for tasks such as detection, segmentation and classification. To reduce overfitting during training DL models and improve model performance especially when the amount and/or diversity of training data are limited, augmentation is often crucial. Although various point cloud data augmentation methods have been widely used in different point cloud processing tasks, there are currently no published systematic surveys or reviews of these methods. Therefore, this article surveys and discusses these methods and categorizes them into a taxonomy framework. Through the comprehensive evaluation and comparison of the augmentation methods, this article identifies their potentials and limitations and suggests possible future research directions. This work helps researchers gain a holistic understanding of the current status of point cloud data augmentation and promotes its wider application and development. ",
    "url": "https://arxiv.org/abs/2308.12113",
    "authors": [
      "Qinfeng Zhu",
      "Lei Fan",
      "Ningxin Weng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12131",
    "title": "Semantic Change Detection for the Romanian Language",
    "abstract": "Automatic semantic change methods try to identify the changes that appear over time in the meaning of words by analyzing their usage in diachronic corpora. In this paper, we analyze different strategies to create static and contextual word embedding models, i.e., Word2Vec and ELMo, on real-world English and Romanian datasets. To test our pipeline and determine the performance of our models, we first evaluate both word embedding models on an English dataset (SEMEVAL-CCOHA). Afterward, we focus our experiments on a Romanian dataset, and we underline different aspects of semantic changes in this low-resource language, such as meaning acquisition and loss. The experimental results show that, depending on the corpus, the most important factors to consider are the choice of model and the distance to calculate a score for detecting semantic change. ",
    "url": "https://arxiv.org/abs/2308.12131",
    "authors": [
      "Ciprian-Octavian Truic\u0103",
      "Victor Tudose",
      "Elena-Simona Apostol"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.12133",
    "title": "Lite-HRNet Plus: Fast and Accurate Facial Landmark Detection",
    "abstract": "Facial landmark detection is an essential technology for driver status tracking and has been in demand for real-time estimations. As a landmark coordinate prediction, heatmap-based methods are known to achieve a high accuracy, and Lite-HRNet can achieve a fast estimation. However, with Lite-HRNet, the problem of a heavy computational cost of the fusion block, which connects feature maps with different resolutions, has yet to be solved. In addition, the strong output module used in HRNetV2 is not applied to Lite-HRNet. Given these problems, we propose a novel architecture called Lite-HRNet Plus. Lite-HRNet Plus achieves two improvements: a novel fusion block based on a channel attention and a novel output module with less computational intensity using multi-resolution feature maps. Through experiments conducted on two facial landmark datasets, we confirmed that Lite-HRNet Plus further improved the accuracy in comparison with conventional methods, and achieved a state-of-the-art accuracy with a computational complexity with the range of 10M FLOPs. ",
    "url": "https://arxiv.org/abs/2308.12133",
    "authors": [
      "Sota Kato",
      "Kazuhiro Hotta",
      "Yuhki Hatakeyama",
      "Yoshinori Konishi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12143",
    "title": "A Probabilistic Fluctuation based Membership Inference Attack for  Generative Models",
    "abstract": "Membership Inference Attack (MIA) identifies whether a record exists in a machine learning model's training set by querying the model. MIAs on the classic classification models have been well-studied, and recent works have started to explore how to transplant MIA onto generative models. Our investigation indicates that existing MIAs designed for generative models mainly depend on the overfitting in target models. However, overfitting can be avoided by employing various regularization techniques, whereas existing MIAs demonstrate poor performance in practice. Unlike overfitting, memorization is essential for deep learning models to attain optimal performance, making it a more prevalent phenomenon. Memorization in generative models leads to an increasing trend in the probability distribution of generating records around the member record. Therefore, we propose a Probabilistic Fluctuation Assessing Membership Inference Attack (PFAMI), a black-box MIA that infers memberships by detecting these trends via analyzing the overall probabilistic fluctuations around given records. We conduct extensive experiments across multiple generative models and datasets, which demonstrate PFAMI can improve the attack success rate (ASR) by about 27.9% when compared with the best baseline. ",
    "url": "https://arxiv.org/abs/2308.12143",
    "authors": [
      "Wenjie Fu",
      "Huandong Wang",
      "Chen Gao",
      "Guanghua Liu",
      "Yong Li",
      "Tao Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12164",
    "title": "A robust family of exponential attractors for a linear time  discretization of the Cahn-Hilliard equation with a source term",
    "abstract": "We consider a linear implicit-explicit (IMEX) time discretization of the Cahn-Hilliard equation with a source term, endowed with Dirichlet boundary conditions. For every time step small enough, we build an exponential attractor of the discrete-in-time dynamical system associated to the discretization. We prove that, as the time step tends to 0, this attractor converges for the symmmetric Hausdorff distance to an exponential attractor of the continuous-in-time dynamical system associated with the PDE. We also prove that the fractal dimension of the exponential attractor (and consequently, of the global attractor) is bounded by a constant independent of the time step. The results also apply to the classical Cahn-Hilliard equation with Neumann boundary conditions. ",
    "url": "https://arxiv.org/abs/2308.12164",
    "authors": [
      "Dieunel Dor",
      "Morgan Pierre"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.12175",
    "title": "Unsupervised anomalies detection in IIoT edge devices networks using  federated learning",
    "abstract": "In a connection of many IoT devices that each collect data, normally training a machine learning model would involve transmitting the data to a central server which requires strict privacy rules. However, some owners are reluctant of availing their data out of the company due to data security concerns. Federated learning(FL) as a distributed machine learning approach performs training of a machine learning model on the device that gathered the data itself. In this scenario, data is not share over the network for training purpose. Fedavg as one of FL algorithms permits a model to be copied to participating devices during a training session. The devices could be chosen at random, and a device can be aborted. The resulting models are sent to the coordinating server and then average models from the devices that finished training. The process is repeated until a desired model accuracy is achieved. By doing this, FL approach solves the privacy problem for IoT/ IIoT devices that held sensitive data for the owners. In this paper, we leverage the benefits of FL and implemented Fedavg algorithm on a recent dataset that represent the modern IoT/ IIoT device networks. The results were almost the same as the centralized machine learning approach. We also evaluated some shortcomings of Fedavg such as unfairness that happens during the training when struggling devices do not participate for every stage of training. This inefficient training of local or global model could lead in a high number of false alarms in intrusion detection systems for IoT/IIoT gadgets developed using Fedavg. Hence, after evaluating the FedAv deep auto encoder with centralized deep auto encoder ML, we further proposed and designed a Fair Fedavg algorithm that will be evaluated in the future work. ",
    "url": "https://arxiv.org/abs/2308.12175",
    "authors": [
      "Niyomukiza Thamar",
      "Hossam Samy Elsaid Sharara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.12192",
    "title": "Robustness Analysis of Continuous-Depth Models with Lagrangian  Techniques",
    "abstract": "This paper presents, in a unified fashion, deterministic as well as statistical Lagrangian-verification techniques. They formally quantify the behavioral robustness of any time-continuous process, formulated as a continuous-depth model. To this end, we review LRT-NG, SLR, and GoTube, algorithms for constructing a tight reachtube, that is, an over-approximation of the set of states reachable within a given time-horizon, and provide guarantees for the reachtube bounds. We compare the usage of the variational equations, associated to the system equations, the mean value theorem, and the Lipschitz constants, in achieving deterministic and statistical guarantees. In LRT-NG, the Lipschitz constant is used as a bloating factor of the initial perturbation, to compute the radius of an ellipsoid in an optimal metric, which over-approximates the set of reachable states. In SLR and GoTube, we get statistical guarantees, by using the Lipschitz constants to compute local balls around samples. These are needed to calculate the probability of having found an upper bound, of the true maximum perturbation at every timestep. Our experiments demonstrate the superior performance of Lagrangian techniques, when compared to LRT, Flow*, and CAPD, and illustrate their use in the robustness analysis of various continuous-depth models. ",
    "url": "https://arxiv.org/abs/2308.12192",
    "authors": [
      "Sophie A. Neubauer",
      "Radu Grosu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.12210",
    "title": "ULDP-FL: Federated Learning with Across Silo User-Level Differential  Privacy",
    "abstract": "Differentially Private Federated Learning (DP-FL) has garnered attention as a collaborative machine learning approach that ensures formal privacy. Most DP-FL approaches ensure DP at the record-level within each silo for cross-silo FL. However, a single user's data may extend across multiple silos, and the desired user-level DP guarantee for such a setting remains unknown. In this study, we present ULDP-FL, a novel FL framework designed to guarantee user-level DP in cross-silo FL where a single user's data may belong to multiple silos. Our proposed algorithm directly ensures user-level DP through per-user weighted clipping, departing from group-privacy approaches. We provide a theoretical analysis of the algorithm's privacy and utility. Additionally, we enhance the algorithm's utility and showcase its private implementation using cryptographic building blocks. Empirical experiments on real-world datasets show substantial improvements in our methods in privacy-utility trade-offs under user-level DP compared to baseline methods. To the best of our knowledge, our work is the first FL framework that effectively provides user-level DP in the general cross-silo FL setting. ",
    "url": "https://arxiv.org/abs/2308.12210",
    "authors": [
      "Fumiyuki Kato",
      "Li Xiong",
      "Shun Takagi",
      "Yang Cao",
      "Masatoshi Yoshikawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.12215",
    "title": "The Challenges of Machine Learning for Trust and Safety: A Case Study on  Misinformation Detection",
    "abstract": "We examine the disconnect between scholarship and practice in applying machine learning to trust and safety problems, using misinformation detection as a case study. We systematize literature on automated detection of misinformation across a corpus of 270 well-cited papers in the field. We then examine subsets of papers for data and code availability, design missteps, reproducibility, and generalizability. We find significant shortcomings in the literature that call into question claimed performance and practicality. Detection tasks are often meaningfully distinct from the challenges that online services actually face. Datasets and model evaluation are often non-representative of real-world contexts, and evaluation frequently is not independent of model training. Data and code availability is poor. Models do not generalize well to out-of-domain data. Based on these results, we offer recommendations for evaluating machine learning applications to trust and safety problems. Our aim is for future work to avoid the pitfalls that we identify. ",
    "url": "https://arxiv.org/abs/2308.12215",
    "authors": [
      "Madelyne Xiao",
      "Jonathan Mayer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2308.12218",
    "title": "CIParsing: Unifying Causality Properties into Multiple Human Parsing",
    "abstract": "Existing methods of multiple human parsing (MHP) apply statistical models to acquire underlying associations between images and labeled body parts. However, acquired associations often contain many spurious correlations that degrade model generalization, leading statistical models to be vulnerable to visually contextual variations in images (e.g., unseen image styles/external interventions). To tackle this, we present a causality inspired parsing paradigm termed CIParsing, which follows fundamental causal principles involving two causal properties for human parsing (i.e., the causal diversity and the causal invariance). Specifically, we assume that an input image is constructed by a mix of causal factors (the characteristics of body parts) and non-causal factors (external contexts), where only the former ones cause the generation process of human parsing.Since causal/non-causal factors are unobservable, a human parser in proposed CIParsing is required to construct latent representations of causal factors and learns to enforce representations to satisfy the causal properties. In this way, the human parser is able to rely on causal factors w.r.t relevant evidence rather than non-causal factors w.r.t spurious correlations, thus alleviating model degradation and yielding improved parsing ability. Notably, the CIParsing is designed in a plug-and-play fashion and can be integrated into any existing MHP models. Extensive experiments conducted on two widely used benchmarks demonstrate the effectiveness and generalizability of our method. ",
    "url": "https://arxiv.org/abs/2308.12218",
    "authors": [
      "Xiaojia Chen",
      "Xuanhan Wang",
      "Lianli Gao",
      "Beitao Chen",
      "Jingkuan Song",
      "HenTao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.12221",
    "title": "Critical Learning Periods Emerge Even in Deep Linear Networks",
    "abstract": "Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. Despite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology. Yet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show analytically and in simulations that the learning of features is tied to competition between sources. Finally, we extend our analysis to multi-task learning to show that pre-training on certain tasks can damage the transfer performance on new tasks, and show how this depends on the relationship between tasks and the duration of the pre-training stage. To the best of our knowledge, our work provides the first analytically tractable model that sheds light into why critical learning periods emerge in biological and artificial networks. ",
    "url": "https://arxiv.org/abs/2308.12221",
    "authors": [
      "Michael Kleinman",
      "Alessandro Achille",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.12243",
    "title": "Multi-Objective Optimization for Sparse Deep Neural Network Training",
    "abstract": "Different conflicting optimization criteria arise naturally in various Deep Learning scenarios. These can address different main tasks (i.e., in the setting of Multi-Task Learning), but also main and secondary tasks such as loss minimization versus sparsity. The usual approach is a simple weighting of the criteria, which formally only works in the convex setting. In this paper, we present a Multi-Objective Optimization algorithm using a modified Weighted Chebyshev scalarization for training Deep Neural Networks (DNNs) with respect to several tasks. By employing this scalarization technique, the algorithm can identify all optimal solutions of the original problem while reducing its complexity to a sequence of single-objective problems. The simplified problems are then solved using an Augmented Lagrangian method, enabling the use of popular optimization techniques such as Adam and Stochastic Gradient Descent, while efficaciously handling constraints. Our work aims to address the (economical and also ecological) sustainability issue of DNN models, with a particular focus on Deep Multi-Task models, which are typically designed with a very large number of weights to perform equally well on multiple tasks. Through experiments conducted on two Machine Learning datasets, we demonstrate the possibility of adaptively sparsifying the model during training without significantly impacting its performance, if we are willing to apply task-specific adaptations to the network weights. Code is available at https://github.com/salomonhotegni/MDMTN. ",
    "url": "https://arxiv.org/abs/2308.12243",
    "authors": [
      "S. S. Hotegni",
      "S. Peitz",
      "M. Berkemeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.12252",
    "title": "How Safe Am I Given What I See? Calibrated Prediction of Safety Chances  for Image-Controlled Autonomy",
    "abstract": "End-to-end learning has emerged as a major paradigm for developing autonomous systems. Unfortunately, with its performance and convenience comes an even greater challenge of safety assurance. A key factor of this challenge is the absence of the notion of a low-dimensional and interpretable dynamical state, around which traditional assurance methods revolve. Focusing on the online safety prediction problem, this paper proposes a configurable family of learning pipelines based on generative world models, which do not require low-dimensional states. To implement these pipelines, we overcome the challenges of learning safety-informed latent representations and missing safety labels under prediction-induced distribution shift. These pipelines come with statistical calibration guarantees on their safety chance predictions based on conformal prediction. We perform an extensive evaluation of the proposed learning pipelines on two case studies of image-controlled systems: a racing car and a cartpole. ",
    "url": "https://arxiv.org/abs/2308.12252",
    "authors": [
      "Zhenjiang Mao",
      "Carson Sobolewski",
      "Ivan Ruchkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.12265",
    "title": "Network Navigation with Online Delays is PSPACE-complete",
    "abstract": "In public transport networks disruptions may occur and lead to travel delays. It is thus interesting to determine whether a traveler can be resilient to delays that occur unexpectedly, ensuring that they can reach their destination in time regardless. We model this as a game between the traveler and a delay-introducing adversary. We study the computational complexity of the problem of deciding whether the traveler has a winning strategy in this game. Our main result is that this problem is PSPACE-complete. ",
    "url": "https://arxiv.org/abs/2308.12265",
    "authors": [
      "Thomas Depian",
      "Christoph Kern",
      "Sebastian R\u00f6der",
      "Soeren Terziadis",
      "Markus Wallinger"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2308.12267",
    "title": "Bugsplainer: Leveraging Code Structures to Explain Software Bugs with  Neural Machine Translation",
    "abstract": "Software bugs cost the global economy billions of dollars each year and take up ~50% of the development time. Once a bug is reported, the assigned developer attempts to identify and understand the source code responsible for the bug and then corrects the code. Over the last five decades, there has been significant research on automatically finding or correcting software bugs. However, there has been little research on automatically explaining the bugs to the developers, which is essential but a highly challenging task. In this paper, we propose Bugsplainer, a novel web-based debugging solution that generates natural language explanations for software bugs by learning from a large corpus of bug-fix commits. Bugsplainer leverages code structures to reason about a bug and employs the fine-tuned version of a text generation model, CodeT5, to generate the explanations. Tool video: https://youtu.be/xga-ScvULpk ",
    "url": "https://arxiv.org/abs/2308.12267",
    "authors": [
      "Parvez Mahbub",
      "Mohammad Masudur Rahman",
      "Ohiduzzaman Shuvo",
      "Avinash Gopal"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.11633",
    "title": "Advances in Self-Supervised Learning for Synthetic Aperture Sonar Data  Processing, Classification, and Pattern Recognition",
    "abstract": "Synthetic Aperture Sonar (SAS) imaging has become a crucial technology for underwater exploration because of its unique ability to maintain resolution at increasing ranges, a characteristic absent in conventional sonar techniques. However, the effective application of deep learning to SAS data processing is often limited due to the scarcity of labeled data. To address this challenge, this paper proposes MoCo-SAS that leverages self-supervised learning (SSL) for SAS data processing, classification, and pattern recognition. The experimental results demonstrate that MoCo-SAS significantly outperforms traditional supervised learning methods, as evidenced by significant improvements observed in terms of the F1-score. These findings highlight the potential of SSL in advancing the state-of-the-art in SAS data processing, offering promising avenues for enhanced underwater object detection and classification. ",
    "url": "https://arxiv.org/abs/2308.11633",
    "authors": [
      "Brandon Sheffield",
      "Frank E. Bobe III",
      "Bradley Marchand",
      "Matthew S. Emigh"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11635",
    "title": "Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive  Learning for Cross-Subject EEG-based Emotion Recognition",
    "abstract": "Electroencephalography (EEG) is an objective tool for emotion recognition with promising applications. However, the scarcity of labeled data remains a major challenge in this field, limiting the widespread use of EEG-based emotion recognition. In this paper, a semi-supervised Dual-stream Self-Attentive Adversarial Graph Contrastive learning framework (termed as DS-AGC) is proposed to tackle the challenge of limited labeled data in cross-subject EEG-based emotion recognition. The DS-AGC framework includes two parallel streams for extracting non-structural and structural EEG features. The non-structural stream incorporates a semi-supervised multi-domain adaptation method to alleviate distribution discrepancy among labeled source domain, unlabeled source domain, and unknown target domain. The structural stream develops a graph contrastive learning method to extract effective graph-based feature representation from multiple EEG channels in a semi-supervised manner. Further, a self-attentive fusion module is developed for feature fusion, sample selection, and emotion recognition, which highlights EEG features more relevant to emotions and data samples in the labeled source domain that are closer to the target domain. Extensive experiments conducted on two benchmark databases (SEED and SEED-IV) using a semi-supervised cross-subject leave-one-subject-out cross-validation evaluation scheme show that the proposed model outperforms existing methods under different incomplete label conditions (with an average improvement of 5.83% on SEED and 6.99% on SEED-IV), demonstrating its effectiveness in addressing the label scarcity problem in cross-subject EEG-based emotion recognition. ",
    "url": "https://arxiv.org/abs/2308.11635",
    "authors": [
      "Weishan Ye",
      "Zhiguo Zhang",
      "Min Zhang",
      "Fei Teng",
      "Li Zhang",
      "Linling Li",
      "Gan Huang",
      "Jianhong Wang",
      "Dong Ni",
      "Zhen Liang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11651",
    "title": "Distributionally Robust Cross Subject EEG Decoding",
    "abstract": "Recently, deep learning has shown to be effective for Electroencephalography (EEG) decoding tasks. Yet, its performance can be negatively influenced by two key factors: 1) the high variance and different types of corruption that are inherent in the signal, 2) the EEG datasets are usually relatively small given the acquisition cost, annotation cost and amount of effort needed. Data augmentation approaches for alleviation of this problem have been empirically studied, with augmentation operations on spatial domain, time domain or frequency domain handcrafted based on expertise of domain knowledge. In this work, we propose a principled approach to perform dynamic evolution on the data for improvement of decoding robustness. The approach is based on distributionally robust optimization and achieves robustness by optimizing on a family of evolved data distributions instead of the single training data distribution. We derived a general data evolution framework based on Wasserstein gradient flow (WGF) and provides two different forms of evolution within the framework. Intuitively, the evolution process helps the EEG decoder to learn more robust and diverse features. It is worth mentioning that the proposed approach can be readily integrated with other data augmentation approaches for further improvements. We performed extensive experiments on the proposed approach and tested its performance on different types of corrupted EEG signals. The model significantly outperforms competitive baselines on challenging decoding scenarios. ",
    "url": "https://arxiv.org/abs/2308.11651",
    "authors": [
      "Tiehang Duan",
      "Zhenyi Wang",
      "Gianfranco Doretto",
      "Fang Li",
      "Cui Tao",
      "Donald Adjeroh"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11666",
    "title": "Generalized dimension reduction approach for heterogeneous networked  systems with time-delay",
    "abstract": "Networks of interconnected agents are essential to study complex networked systems' state evolution, stability, resilience, and control. Nevertheless, the high dimensionality and nonlinear dynamics are vital factors preventing us from theoretically analyzing them. Recently, the dimension-reduction approaches reduced the system's size by mapping the original system to a one-dimensional system such that only one effective representative can capture its macroscopic dynamics. However, the approaches dramatically fail as the network becomes heterogeneous and has multiple community structures. Here, we bridge the gap by developing a generalized dimension reduction approach, which enables us to map the original system to a $m$-dimensional system that consists of $m$ interacting components. Notably, by validating it on various dynamical models, this approach accurately predicts the original system state and the tipping point, if any. Furthermore, the numerical results demonstrate that this approach approximates the system evolution and identifies the critical points for complex networks with time delay. ",
    "url": "https://arxiv.org/abs/2308.11666",
    "authors": [
      "Cheng Ma",
      "Gyorgy Korniss",
      "Boleslaw K. Szymanski",
      "Jianxi Gao"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Computational Physics (physics.comp-ph)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2308.11809",
    "title": "Expressive probabilistic sampling in recurrent neural networks",
    "abstract": "In sampling-based Bayesian models of brain function, neural activities are assumed to be samples from probability distributions that the brain uses for probabilistic computation. However, a comprehensive understanding of how mechanistic models of neural dynamics can sample from arbitrary distributions is still lacking. We use tools from functional analysis and stochastic differential equations to explore the minimum architectural requirements for $\\textit{recurrent}$ neural circuits to sample from complex distributions. We first consider the traditional sampling model consisting of a network of neurons whose outputs directly represent the samples (sampler-only network). We argue that synaptic current and firing-rate dynamics in the traditional model have limited capacity to sample from a complex probability distribution. We show that the firing rate dynamics of a recurrent neural circuit with a separate set of output units can sample from an arbitrary probability distribution. We call such circuits reservoir-sampler networks (RSNs). We propose an efficient training procedure based on denoising score matching that finds recurrent and output weights such that the RSN implements Langevin sampling. We empirically demonstrate our model's ability to sample from several complex data distributions using the proposed neural dynamics and discuss its applicability to developing the next generation of sampling-based brain models. ",
    "url": "https://arxiv.org/abs/2308.11809",
    "authors": [
      "Shirui Chen",
      "Linxin Preston Jiang",
      "Rajesh P. N. Rao",
      "Eric Shea-Brown"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.11925",
    "title": "Solving Elliptic Optimal Control Problems using Physics Informed Neural  Networks",
    "abstract": "In this work, we present and analyze a numerical solver for optimal control problems (without / with box constraint) for linear and semilinear second-order elliptic problems. The approach is based on a coupled system derived from the first-order optimality system of the optimal control problem, and applies physics informed neural networks (PINNs) to solve the coupled system. We present an error analysis of the numerical scheme, and provide $L^2(\\Omega)$ error bounds on the state, control and adjoint state in terms of deep neural network parameters (e.g., depth, width, and parameter bounds) and the number of sampling points in the domain and on the boundary. The main tools in the analysis include offset Rademacher complexity and boundedness and Lipschitz continuity of neural network functions. We present several numerical examples to illustrate the approach and compare it with three existing approaches. ",
    "url": "https://arxiv.org/abs/2308.11925",
    "authors": [
      "Bangti Jin",
      "Ramesh Sau",
      "Luowei Yin",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.11969",
    "title": "Anisotropic Hybrid Networks for liver tumor segmentation with  uncertainty quantification",
    "abstract": "The burden of liver tumors is important, ranking as the fourth leading cause of cancer mortality. In case of hepatocellular carcinoma (HCC), the delineation of liver and tumor on contrast-enhanced magnetic resonance imaging (CE-MRI) is performed to guide the treatment strategy. As this task is time-consuming, needs high expertise and could be subject to inter-observer variability there is a strong need for automatic tools. However, challenges arise from the lack of available training data, as well as the high variability in terms of image resolution and MRI sequence. In this work we propose to compare two different pipelines based on anisotropic models to obtain the segmentation of the liver and tumors. The first pipeline corresponds to a baseline multi-class model that performs the simultaneous segmentation of the liver and tumor classes. In the second approach, we train two distinct binary models, one segmenting the liver only and the other the tumors. Our results show that both pipelines exhibit different strengths and weaknesses. Moreover we propose an uncertainty quantification strategy allowing the identification of potential false positive tumor lesions. Both solutions were submitted to the MICCAI 2023 Atlas challenge regarding liver and tumor segmentation. ",
    "url": "https://arxiv.org/abs/2308.11969",
    "authors": [
      "Benjamin Lambert",
      "Pauline Roca",
      "Florence Forbes",
      "Senan Doyle",
      "Michel Dojat"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2308.11980",
    "title": "Joint Prediction of Audio Event and Annoyance Rating in an Urban  Soundscape by Hierarchical Graph Representation Learning",
    "abstract": "Sound events in daily life carry rich information about the objective world. The composition of these sounds affects the mood of people in a soundscape. Most previous approaches only focus on classifying and detecting audio events and scenes, but may ignore their perceptual quality that may impact humans' listening mood for the environment, e.g. annoyance. To this end, this paper proposes a novel hierarchical graph representation learning (HGRL) approach which links objective audio events (AE) with subjective annoyance ratings (AR) of the soundscape perceived by humans. The hierarchical graph consists of fine-grained event (fAE) embeddings with single-class event semantics, coarse-grained event (cAE) embeddings with multi-class event semantics, and AR embeddings. Experiments show the proposed HGRL successfully integrates AE with AR for AEC and ARP tasks, while coordinating the relations between cAE and fAE and further aligning the two different grains of AE information with the AR. ",
    "url": "https://arxiv.org/abs/2308.11980",
    "authors": [
      "Yuanbo Hou",
      "Siyang Song",
      "Cheng Luo",
      "Andrew Mitchell",
      "Qiaoqiao Ren",
      "Weicheng Xie",
      "Jian Kang",
      "Wenwu Wang",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2308.12193",
    "title": "Self-Supervised Knowledge-Driven Deep Learning for 3D Magnetic Inversion",
    "abstract": "The magnetic inversion method is one of the non-destructive geophysical methods, which aims to estimate the subsurface susceptibility distribution from surface magnetic anomaly data. Recently, supervised deep learning methods have been widely utilized in lots of geophysical fields including magnetic inversion. However, these methods rely heavily on synthetic training data, whose performance is limited since the synthetic data is not independently and identically distributed with the field data. Thus, we proposed to realize magnetic inversion by self-supervised deep learning. The proposed self-supervised knowledge-driven 3D magnetic inversion method (SSKMI) learns on the target field data by a closed loop of the inversion and forward models. Given that the parameters of the forward model are preset, SSKMI can optimize the inversion model by minimizing the mean absolute error between observed and re-estimated surface magnetic anomalies. Besides, there is a knowledge-driven module in the proposed inversion model, which makes the deep learning method more explicable. Meanwhile, comparative experiments demonstrate that the knowledge-driven module can accelerate the training of the proposed method and achieve better results. Since magnetic inversion is an ill-pose task, SSKMI proposed to constrain the inversion model by a guideline in the auxiliary loop. The experimental results demonstrate that the proposed method is a reliable magnetic inversion method with outstanding performance. ",
    "url": "https://arxiv.org/abs/2308.12193",
    "authors": [
      "Yinshuo Li",
      "Zhuo Jia",
      "Wenkai Lu",
      "Cao Song"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.12212",
    "title": "Learning to Learn Financial Networks for Optimising Momentum Strategies",
    "abstract": "Network momentum provides a novel type of risk premium, which exploits the interconnections among assets in a financial network to predict future returns. However, the current process of constructing financial networks relies heavily on expensive databases and financial expertise, limiting accessibility for small-sized and academic institutions. Furthermore, the traditional approach treats network construction and portfolio optimisation as separate tasks, potentially hindering optimal portfolio performance. To address these challenges, we propose L2GMOM, an end-to-end machine learning framework that simultaneously learns financial networks and optimises trading signals for network momentum strategies. The model of L2GMOM is a neural network with a highly interpretable forward propagation architecture, which is derived from algorithm unrolling. The L2GMOM is flexible and can be trained with diverse loss functions for portfolio performance, e.g. the negative Sharpe ratio. Backtesting on 64 continuous future contracts demonstrates a significant improvement in portfolio profitability and risk control, with a Sharpe ratio of 1.74 across a 20-year period. ",
    "url": "https://arxiv.org/abs/2308.12212",
    "authors": [
      "Xingyue",
      "Stefan Zohren",
      "Stephen Roberts",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.12224",
    "title": "Enhancing cardiovascular risk prediction through AI-enabled  calcium-omics",
    "abstract": "Background. Coronary artery calcium (CAC) is a powerful predictor of major adverse cardiovascular events (MACE). Traditional Agatston score simply sums the calcium, albeit in a non-linear way, leaving room for improved calcification assessments that will more fully capture the extent of disease. Objective. To determine if AI methods using detailed calcification features (i.e., calcium-omics) can improve MACE prediction. Methods. We investigated additional features of calcification including assessment of mass, volume, density, spatial distribution, territory, etc. We used a Cox model with elastic-net regularization on 2457 CT calcium score (CTCS) enriched for MACE events obtained from a large no-cost CLARIFY program (ClinicalTri-als.gov Identifier: NCT04075162). We employed sampling techniques to enhance model training. We also investigated Cox models with selected features to identify explainable high-risk characteristics. Results. Our proposed calcium-omics model with modified synthetic down sampling and up sampling gave C-index (80.5%/71.6%) and two-year AUC (82.4%/74.8%) for (80:20, training/testing), respectively (sampling was applied to the training set only). Results compared favorably to Agatston which gave C-index (71.3%/70.3%) and AUC (71.8%/68.8%), respectively. Among calcium-omics features, numbers of calcifications, LAD mass, and diffusivity (a measure of spatial distribution) were important determinants of increased risk, with dense calcification (>1000HU) associated with lower risk. The calcium-omics model reclassified 63% of MACE patients to the high risk group in a held-out test. The categorical net-reclassification index was NRI=0.153. Conclusions. AI analysis of coronary calcification can lead to improved results as compared to Agatston scoring. Our findings suggest the utility of calcium-omics in improved prediction of risk. ",
    "url": "https://arxiv.org/abs/2308.12224",
    "authors": [
      "Ammar Hoori",
      "Sadeer Al-Kindi",
      "Tao Hu",
      "Yingnan Song",
      "Hao Wu",
      "Juhwan Lee",
      "Nour Tashtish",
      "Pingfu Fu",
      "Robert Gilkeson",
      "Sanjay Rajagopalan",
      "David L. Wilson"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.12231",
    "title": "SPPNet: A Single-Point Prompt Network for Nuclei Image Segmentation",
    "abstract": "Image segmentation plays an essential role in nuclei image analysis. Recently, the segment anything model has made a significant breakthrough in such tasks. However, the current model exists two major issues for cell segmentation: (1) the image encoder of the segment anything model involves a large number of parameters. Retraining or even fine-tuning the model still requires expensive computational resources. (2) in point prompt mode, points are sampled from the center of the ground truth and more than one set of points is expected to achieve reliable performance, which is not efficient for practical applications. In this paper, a single-point prompt network is proposed for nuclei image segmentation, called SPPNet. We replace the original image encoder with a lightweight vision transformer. Also, an effective convolutional block is added in parallel to extract the low-level semantic information from the image and compensate for the performance degradation due to the small image encoder. We propose a new point-sampling method based on the Gaussian kernel. The proposed model is evaluated on the MoNuSeg-2018 dataset. The result demonstrated that SPPNet outperforms existing U-shape architectures and shows faster convergence in training. Compared to the segment anything model, SPPNet shows roughly 20 times faster inference, with 1/70 parameters and computational cost. Particularly, only one set of points is required in both the training and inference phases, which is more reasonable for clinical applications. The code for our work and more technical details can be found at https://github.com/xq141839/SPPNet. ",
    "url": "https://arxiv.org/abs/2308.12231",
    "authors": [
      "Qing Xu",
      "Wenwei Kuang",
      "Zeyu Zhang",
      "Xueyao Bao",
      "Haoran Chen",
      "Wenting Duan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.06714",
    "title": "AdaTerm: Adaptive T-Distribution Estimated Robust Moments for  Noise-Robust Stochastic Gradient Optimization",
    "abstract": " Comments: 27 pages; Final version accepted by Elsevier Neurocomputing Journal (2023-08; this https URL) ",
    "url": "https://arxiv.org/abs/2201.06714",
    "authors": [
      "Wendyam Eric Lionel Ilboudo",
      "Taisuke Kobayashi",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04311",
    "title": "Identifying Backdoor Attacks in Federated Learning via Anomaly Detection",
    "abstract": " Comments: APWeb-WAIM 2023 ",
    "url": "https://arxiv.org/abs/2202.04311",
    "authors": [
      "Yuxi Mi",
      "Yiheng Sun",
      "Jihong Guan",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00309",
    "title": "Label-Efficient Online Continual Object Detection in Streaming Video",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2206.00309",
    "authors": [
      "Jay Zhangjie Wu",
      "David Junhao Zhang",
      "Wynne Hsu",
      "Mengmi Zhang",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.05184",
    "title": "SERE: Exploring Feature Self-relation for Self-supervised Transformer",
    "abstract": " Title: SERE: Exploring Feature Self-relation for Self-supervised Transformer ",
    "url": "https://arxiv.org/abs/2206.05184",
    "authors": [
      "Zhong-Yu Li",
      "Shanghua Gao",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.03678",
    "title": "Stability of Aggregation Graph Neural Networks",
    "abstract": " Title: Stability of Aggregation Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2207.03678",
    "authors": [
      "Alejandro Parada-Mayorga",
      "Zhiyang Wang",
      "Fernando Gama",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.05776",
    "title": "Neural Networks for Scalar Input and Functional Output",
    "abstract": " Title: Neural Networks for Scalar Input and Functional Output ",
    "url": "https://arxiv.org/abs/2208.05776",
    "authors": [
      "Sidi Wu",
      "C\u00e9dric Beaulac",
      "Jiguo Cao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2208.13930",
    "title": "SAFE: Sensitivity-Aware Features for Out-of-Distribution Object  Detection",
    "abstract": " Title: SAFE: Sensitivity-Aware Features for Out-of-Distribution Object  Detection ",
    "url": "https://arxiv.org/abs/2208.13930",
    "authors": [
      "Samuel Wilson",
      "Tobias Fischer",
      "Feras Dayoub",
      "Dimity Miller",
      "Niko S\u00fcnderhauf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.08996",
    "title": "EDO-Net: Learning Elastic Properties of Deformable Objects from Graph  Dynamics",
    "abstract": " Title: EDO-Net: Learning Elastic Properties of Deformable Objects from Graph  Dynamics ",
    "url": "https://arxiv.org/abs/2209.08996",
    "authors": [
      "Alberta Longhini",
      "Marco Moletta",
      "Alfredo Reichlin",
      "Michael C. Welle",
      "David Held",
      "Zackory Erickson",
      "Danica Kragic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.09245",
    "title": "Interpreting the Mechanism of Synergism for Drug Combinations Using  Attention-Based Hierarchical Graph Pooling",
    "abstract": " Title: Interpreting the Mechanism of Synergism for Drug Combinations Using  Attention-Based Hierarchical Graph Pooling ",
    "url": "https://arxiv.org/abs/2209.09245",
    "authors": [
      "Zehao Dong",
      "Heming Zhang",
      "Yixin Chen",
      "Philip R.O. Payne",
      "Fuhai Li"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12244",
    "title": "Multimodal Channel-Mixing: Channel and Spatial Masked AutoEncoder on  Facial Action Unit Detection",
    "abstract": " Title: Multimodal Channel-Mixing: Channel and Spatial Masked AutoEncoder on  Facial Action Unit Detection ",
    "url": "https://arxiv.org/abs/2209.12244",
    "authors": [
      "Xiang Zhang",
      "Huiyuan Yang",
      "Taoyue Wang",
      "Xiaotian Li",
      "Lijun Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.06924",
    "title": "A Tale of Two Graphs: Freezing and Denoising Graph Structures for  Multimodal Recommendation",
    "abstract": " Comments: Accepted to ACM Multimedia (MM) 2023 ",
    "url": "https://arxiv.org/abs/2211.06924",
    "authors": [
      "Xin Zhou",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.15498",
    "title": "Physics-informed neural networks with unknown measurement noise",
    "abstract": " Title: Physics-informed neural networks with unknown measurement noise ",
    "url": "https://arxiv.org/abs/2211.15498",
    "authors": [
      "Philipp Pilar",
      "Niklas Wahlstr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04871",
    "title": "Spurious Features Everywhere -- Large-Scale Detection of Harmful  Spurious Features in ImageNet",
    "abstract": " Comments: accepted to ICCV 2023 ",
    "url": "https://arxiv.org/abs/2212.04871",
    "authors": [
      "Yannic Neuhaus",
      "Maximilian Augustin",
      "Valentyn Boreiko",
      "Matthias Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.07771",
    "title": "Temporal Saliency Detection Towards Explainable Transformer-based  Timeseries Forecasting",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2212.07771",
    "authors": [
      "Nghia Duong-Trung",
      "Duc-Manh Nguyen",
      "Danh Le-Phuoc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.08171",
    "title": "Graphon Pooling for Reducing Dimensionality of Signals and Convolutional  Operators on Graphs",
    "abstract": " Title: Graphon Pooling for Reducing Dimensionality of Signals and Convolutional  Operators on Graphs ",
    "url": "https://arxiv.org/abs/2212.08171",
    "authors": [
      "Alejandro Parada-Mayorga",
      "Zhiyang Wang",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.08663",
    "title": "Randomized Quantization: A Generic Augmentation for Data Agnostic  Self-supervised Learning",
    "abstract": " Comments: Accepted by ICCV 2023. The code is available at https: //github.com/microsoft/random_quantize ",
    "url": "https://arxiv.org/abs/2212.08663",
    "authors": [
      "Huimin Wu",
      "Chenyang Lei",
      "Xiao Sun",
      "Peng-Shuai Wang",
      "Qifeng Chen",
      "Kwang-Ting Cheng",
      "Stephen Lin",
      "Zhirong Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.04785",
    "title": "Phase-shifted Adversarial Training",
    "abstract": " Comments: Conference on Uncertainty in Artificial Intelligence, 2023 (UAI 2023) ",
    "url": "https://arxiv.org/abs/2301.04785",
    "authors": [
      "Yeachan Kim",
      "Seongyeon Kim",
      "Ihyeok Seo",
      "Bonggun Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.07524",
    "title": "Towards Causal Analysis of Empirical Software Engineering Data: The  Impact of Programming Languages on Coding Competitions",
    "abstract": " Comments: Fixed some typos ",
    "url": "https://arxiv.org/abs/2301.07524",
    "authors": [
      "Carlo A. Furia",
      "Richard Torkar",
      "Robert Feldt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.11004",
    "title": "NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental  Health on Social Media",
    "abstract": " Title: NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental  Health on Social Media ",
    "url": "https://arxiv.org/abs/2301.11004",
    "authors": [
      "Muskan Garg",
      "Chandni Saxena",
      "Usman Naseem",
      "Bonnie J Dorr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.05601",
    "title": "Pruning Deep Neural Networks from a Sparsity Perspective",
    "abstract": " Comments: ICLR 2023 ",
    "url": "https://arxiv.org/abs/2302.05601",
    "authors": [
      "Enmao Diao",
      "Ganghua Wang",
      "Jiawei Zhan",
      "Yuhong Yang",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06912",
    "title": "Regret-Based Optimization for Robust Reinforcement Learning",
    "abstract": " Title: Regret-Based Optimization for Robust Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2302.06912",
    "authors": [
      "Roman Belaire",
      "Pradeep Varakantham",
      "Thanh Nguyen",
      "David Lo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.08835",
    "title": "h-analysis and data-parallel physics-informed neural networks",
    "abstract": " Title: h-analysis and data-parallel physics-informed neural networks ",
    "url": "https://arxiv.org/abs/2302.08835",
    "authors": [
      "Paul Escapil-Inchausp\u00e9",
      "Gonzalo A. Ruz"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.13991",
    "title": "Learning to Generalize towards Unseen Domains via a Content-Aware Style  Invariant Model for Disease Detection from Chest X-rays",
    "abstract": " Title: Learning to Generalize towards Unseen Domains via a Content-Aware Style  Invariant Model for Disease Detection from Chest X-rays ",
    "url": "https://arxiv.org/abs/2302.13991",
    "authors": [
      "Mohammad Zunaed",
      "Md. Aynal Haque",
      "Taufiq Hasan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.02206",
    "title": "Domain Specific Question Answering Over Knowledge Graphs Using Logical  Programming and Large Language Models",
    "abstract": " Title: Domain Specific Question Answering Over Knowledge Graphs Using Logical  Programming and Large Language Models ",
    "url": "https://arxiv.org/abs/2303.02206",
    "authors": [
      "Navid Madani",
      "Rohini K. Srihari",
      "Kenneth Joseph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.06980",
    "title": "Self-supervised learning based general laboratory progress pretrained  model for cardiovascular event detection",
    "abstract": " Comments: published in IEEE Journal of Translational Engineering in Health & Medicine ",
    "url": "https://arxiv.org/abs/2303.06980",
    "authors": [
      "Li-Chin Chen",
      "Kuo-Hsuan Hung",
      "Yi-Ju Tseng",
      "Hsin-Yao Wang",
      "Tse-Min Lu",
      "Wei-Chieh Huang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10762",
    "title": "Deep Image Fingerprint: Towards Low Budget Synthetic Image Detection and  Model Lineage Analysis",
    "abstract": " Title: Deep Image Fingerprint: Towards Low Budget Synthetic Image Detection and  Model Lineage Analysis ",
    "url": "https://arxiv.org/abs/2303.10762",
    "authors": [
      "Sergey Sinitsa",
      "Ohad Fried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11702",
    "title": "On the link between generative semi-supervised learning and generative  open-set recognition",
    "abstract": " Title: On the link between generative semi-supervised learning and generative  open-set recognition ",
    "url": "https://arxiv.org/abs/2303.11702",
    "authors": [
      "Emile Reyn Engelbrecht",
      "Johan du Preez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17806",
    "title": "Neural Microfacet Fields for Inverse Rendering",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2303.17806",
    "authors": [
      "Alexander Mai",
      "Dor Verbin",
      "Falko Kuester",
      "Sara Fridovich-Keil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2304.04521",
    "title": "Zero-Shot In-Distribution Detection in Multi-Object Settings Using  Vision-Language Foundation Models",
    "abstract": " Comments: v3: I fixed some typos from v2 ",
    "url": "https://arxiv.org/abs/2304.04521",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.10410",
    "title": "Radar-Camera Fusion for Object Detection and Semantic Segmentation in  Autonomous Driving: A Comprehensive Review",
    "abstract": " Comments: Accepted by IEEE Transactions on Intelligent Vehicles (T-IV) ",
    "url": "https://arxiv.org/abs/2304.10410",
    "authors": [
      "Shanliang Yao",
      "Runwei Guan",
      "Xiaoyu Huang",
      "Zhuoxiao Li",
      "Xiangyu Sha",
      "Yong Yue",
      "Eng Gee Lim",
      "Hyungjoon Seo",
      "Ka Lok Man",
      "Xiaohui Zhu",
      "Yutao Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.01792",
    "title": "Task Relation-aware Continual User Representation Learning",
    "abstract": " Comments: KDD 2023 ",
    "url": "https://arxiv.org/abs/2306.01792",
    "authors": [
      "Sein Kim",
      "Namkyeong Lee",
      "Donghyun Kim",
      "Minchul Yang",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06304",
    "title": "Finite element interpolated neural networks for solving forward and  inverse problems",
    "abstract": " Title: Finite element interpolated neural networks for solving forward and  inverse problems ",
    "url": "https://arxiv.org/abs/2306.06304",
    "authors": [
      "Santiago Badia",
      "Wei Li",
      "Alberto F. Mart\u00edn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.02237",
    "title": "MSECNet: Accurate and Robust Normal Estimation for 3D Point Clouds by  Multi-Scale Edge Conditioning",
    "abstract": " Comments: Accepted for ACM MM 2023 ",
    "url": "https://arxiv.org/abs/2308.02237",
    "authors": [
      "Haoyi Xiu",
      "Xin Liu",
      "Weimin Wang",
      "Kyoung-Sook Kim",
      "Masashi Matsuoka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.08210",
    "title": "Neural Spherical Harmonics for structurally coherent continuous  representation of diffusion MRI signal",
    "abstract": " Comments: 12 pages, 6 figures, accepted for cdMRI workshop at MICCAI 2023 Updated to fix typo in author name (Villanova -&gt; Vilanova) ",
    "url": "https://arxiv.org/abs/2308.08210",
    "authors": [
      "Tom Hendriks",
      "Anna Vilanova",
      "Maxime Chamberland"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09917",
    "title": "Learning Multiscale Consistency for Self-supervised Electron Microscopy  Instance Segmentation",
    "abstract": " Title: Learning Multiscale Consistency for Self-supervised Electron Microscopy  Instance Segmentation ",
    "url": "https://arxiv.org/abs/2308.09917",
    "authors": [
      "Yinda Chen",
      "Wei Huang",
      "Xiaoyu Liu",
      "Qi Chen",
      "Zhiwei Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10600",
    "title": "Fixed-Parameter Algorithms for Computing RAC Drawings of Graphs",
    "abstract": " Comments: Accepted at GD 2023 ",
    "url": "https://arxiv.org/abs/2308.10600",
    "authors": [
      "Cornelius Brand",
      "Robert Ganian",
      "Sebastian R\u00f6der",
      "Florian Schager"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.10632",
    "title": "Foundation Model-oriented Robustness: Robust Image Model Evaluation with  Pretrained Models",
    "abstract": " Title: Foundation Model-oriented Robustness: Robust Image Model Evaluation with  Pretrained Models ",
    "url": "https://arxiv.org/abs/2308.10632",
    "authors": [
      "Peiyan Zhang",
      "Haoyang Liu",
      "Chaozhuo Li",
      "Xing Xie",
      "Sunghun Kim",
      "Haohan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11406",
    "title": "Designing an attack-defense game: how to increase robustness of  financial transaction models via a competition",
    "abstract": " Title: Designing an attack-defense game: how to increase robustness of  financial transaction models via a competition ",
    "url": "https://arxiv.org/abs/2308.11406",
    "authors": [
      "Alexey Zaytsev",
      "Alex Natekin",
      "Evgeni Vorsin",
      "Valerii Smirnov",
      "Georgii Smirnov",
      "Oleg Sidorshin",
      "Alexander Senin",
      "Alexander Dudin",
      "Dmitry Berestnev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistical Finance (q-fin.ST)"
    ]
  }
]