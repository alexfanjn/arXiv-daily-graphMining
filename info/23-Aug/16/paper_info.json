[
  {
    "id": "arXiv:2308.07346",
    "title": "Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for  Tetrad Causal Search",
    "abstract": "We give novel Python and R interfaces for the (Java) Tetrad project for causal modeling, search, and estimation. The Tetrad project is a mainstay in the literature, having been under consistent development for over 30 years. Some of its algorithms are now classics, like PC and FCI; others are recent developments. It is increasingly the case, however, that researchers need to access the underlying Java code from Python or R. Existing methods for doing this are inadequate. We provide new, up-to-date methods using the JPype Python-Java interface and the Reticulate Python-R interface, directly solving these issues. With the addition of some simple tools and the provision of working examples for both Python and R, using JPype and Reticulate to interface Python and R with Tetrad is straightforward and intuitive. ",
    "url": "https://arxiv.org/abs/2308.07346",
    "authors": [
      "Joseph D. Ramsey",
      "Bryan Andrews"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2308.07350",
    "title": "Efficient Neural PDE-Solvers using Quantization Aware Training",
    "abstract": "In the past years, the application of neural networks as an alternative to classical numerical methods to solve Partial Differential Equations has emerged as a potential paradigm shift in this century-old mathematical field. However, in terms of practical applicability, computational cost remains a substantial bottleneck. Classical approaches try to mitigate this challenge by limiting the spatial resolution on which the PDEs are defined. For neural PDE solvers, we can do better: Here, we investigate the potential of state-of-the-art quantization methods on reducing computational costs. We show that quantizing the network weights and activations can successfully lower the computational cost of inference while maintaining performance. Our results on four standard PDE datasets and three network architectures show that quantization-aware training works across settings and three orders of FLOPs magnitudes. Finally, we empirically demonstrate that Pareto-optimality of computational cost vs performance is almost always achieved only by incorporating quantization. ",
    "url": "https://arxiv.org/abs/2308.07350",
    "authors": [
      "Winfried van den Dool",
      "Tijmen Blankevoort",
      "Max Welling",
      "Yuki M. Asano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07352",
    "title": "Bayesian Physics-Informed Neural Network for the Forward and Inverse  Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer",
    "abstract": "Globally, there are many polluted groundwater sites that need an active remediation plan for the restoration of local ecosystem and environment. Engineered nanoparticles (ENPs) have proven to be an effective reactive agent for the in-situ degradation of pollutants in groundwater. While the performance of these ENPs has been highly promising on the laboratory scale, their application in real field case conditions is still limited. The complex transport and retention mechanisms of ENPs hinder the development of an efficient remediation strategy. Therefore, a predictive tool to comprehend the transport and retention behavior of ENPs is highly required. The existing tools in the literature are dominated with numerical simulators, which have limited flexibility and accuracy in the presence of sparse datasets and the aquifer heterogeneity. This work uses a Bayesian Physics-Informed Neural Network (B-PINN) framework to model the nano-particles mobility within an aquifer. The result from the forward model demonstrates the effective capability of B-PINN in accurately predicting the ENPs mobility and quantifying the uncertainty. The inverse model output is then used to predict the governing parameters for the ENPs mobility in a small-scale aquifer. The research demonstrates the capability of the tool to provide predictive insights for developing an efficient groundwater remediation strategy. ",
    "url": "https://arxiv.org/abs/2308.07352",
    "authors": [
      "Shikhar Nilabh",
      "Fidel Grandia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2308.07358",
    "title": "Conformal Predictions Enhanced Expert-guided Meshing with Graph Neural  Networks",
    "abstract": "Computational Fluid Dynamics (CFD) is widely used in different engineering fields, but accurate simulations are dependent upon proper meshing of the simulation domain. While highly refined meshes may ensure precision, they come with high computational costs. Similarly, adaptive remeshing techniques require multiple simulations and come at a great computational cost. This means that the meshing process is reliant upon expert knowledge and years of experience. Automating mesh generation can save significant time and effort and lead to a faster and more efficient design process. This paper presents a machine learning-based scheme that utilizes Graph Neural Networks (GNN) and expert guidance to automatically generate CFD meshes for aircraft models. In this work, we introduce a new 3D segmentation algorithm that outperforms two state-of-the-art models, PointNet++ and PointMLP, for surface classification. We also present a novel approach to project predictions from 3D mesh segmentation models to CAD surfaces using the conformal predictions method, which provides marginal statistical guarantees and robust uncertainty quantification and handling. We demonstrate that the addition of conformal predictions effectively enables the model to avoid under-refinement, hence failure, in CFD meshing even for weak and less accurate models. Finally, we demonstrate the efficacy of our approach through a real-world case study that demonstrates that our automatically generated mesh is comparable in quality to expert-generated meshes and enables the solver to converge and produce accurate results. Furthermore, we compare our approach to the alternative of adaptive remeshing in the same case study and find that our method is 5 times faster in the overall process of simulation. The code and data for this project are made publicly available at https://github.com/ahnobari/AutoSurf. ",
    "url": "https://arxiv.org/abs/2308.07358",
    "authors": [
      "Amin Heyrani Nobari",
      "Justin Rey",
      "Suhas Kodali",
      "Matthew Jones",
      "Faez Ahmed"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07387",
    "title": "DISBELIEVE: Distance Between Client Models is Very Essential for  Effective Local Model Poisoning Attacks",
    "abstract": "Federated learning is a promising direction to tackle the privacy issues related to sharing patients' sensitive data. Often, federated systems in the medical image analysis domain assume that the participating local clients are \\textit{honest}. Several studies report mechanisms through which a set of malicious clients can be introduced that can poison the federated setup, hampering the performance of the global model. To overcome this, robust aggregation methods have been proposed that defend against those attacks. We observe that most of the state-of-the-art robust aggregation methods are heavily dependent on the distance between the parameters or gradients of malicious clients and benign clients, which makes them prone to local model poisoning attacks when the parameters or gradients of malicious and benign clients are close. Leveraging this, we introduce DISBELIEVE, a local model poisoning attack that creates malicious parameters or gradients such that their distance to benign clients' parameters or gradients is low respectively but at the same time their adverse effect on the global model's performance is high. Experiments on three publicly available medical image datasets demonstrate the efficacy of the proposed DISBELIEVE attack as it significantly lowers the performance of the state-of-the-art \\textit{robust aggregation} methods for medical image analysis. Furthermore, compared to state-of-the-art local model poisoning attacks, DISBELIEVE attack is also effective on natural images where we observe a severe drop in classification performance of the global model for multi-class classification on benchmark dataset CIFAR-10. ",
    "url": "https://arxiv.org/abs/2308.07387",
    "authors": [
      "Indu Joshi",
      "Priyank Upadhya",
      "Gaurav Kumar Nayak",
      "Peter Sch\u00fcffler",
      "Nassir Navab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.07395",
    "title": "Text Injection for Capitalization and Turn-Taking Prediction in Speech  Models",
    "abstract": "Text injection for automatic speech recognition (ASR), wherein unpaired text-only data is used to supplement paired audio-text data, has shown promising improvements for word error rate. This study examines the use of text injection for auxiliary tasks, which are the non-ASR tasks often performed by an E2E model. In this work, we use joint end-to-end and internal language model training (JEIT) as our text injection algorithm to train an ASR model which performs two auxiliary tasks. The first is capitalization, which is a de-normalization task. The second is turn-taking prediction, which attempts to identify whether a user has completed their conversation turn in a digital assistant interaction. We show results demonstrating that our text injection method boosts capitalization performance for long-tail data, and improves turn-taking detection recall. ",
    "url": "https://arxiv.org/abs/2308.07395",
    "authors": [
      "Shaan Bijwadia",
      "Shuo-yiin Chang",
      "Weiran Wang",
      "Zhong Meng",
      "Hao Zhang",
      "Tara N. Sainath"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.07403",
    "title": "A fast algorithm for All-Pairs-Shortest-Paths suitable for neural  networks",
    "abstract": "Given a directed graph of nodes and edges connecting them, a common problem is to find the shortest path between any two nodes. Here I show that the shortest path distances can be found by a simple matrix inversion: If the edges are given by the adjacency matrix $A_{ij}$ then with a suitably small value of $\\gamma$ the shortest path distances are $$ D_{ij} = \\operatorname{ceil} \\left( {\\frac{\\log {\\left[ {\\left({\\mathbf{1}}-\\gamma {\\mathbf{A}}\\right)^{-1}} \\right]}_{ij}}{\\log \\gamma}} \\right)$$ I derive some bounds on $\\gamma$ useful for a practical application. Even when the distance function is not globally accurate across the entire graph, it still works locally to instruct pursuit of the shortest path. In this mode, it also extends to weighted graphs with positive edge weights. For a wide range of dense graphs this distance function is computationally faster than the best available alternative. Finally I show that this method leads naturally to a neural network solution of the all-pairs-shortest-path problem. ",
    "url": "https://arxiv.org/abs/2308.07403",
    "authors": [
      "Markus Meister"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2308.07426",
    "title": "A Survey on Point-of-Interest Recommendations Leveraging Heterogeneous  Data",
    "abstract": "Tourism is an important application domain for recommender systems. In this domain, recommender systems are for example tasked with providing personalized recommendations for transportation, accommodation, points-of-interest (POIs), or tourism services. Among these tasks, in particular the problem of recommending POIs that are of likely interest to individual tourists has gained growing attention in recent years. Providing POI recommendations to tourists \\emph{during their trip} can however be especially challenging due to the variability of the users' context. With the rapid development of the Web and today's multitude of online services, vast amounts of data from various sources have become available, and these heterogeneous data sources represent a huge potential to better address the challenges of in-trip POI recommendation problems. In this work, we provide a comprehensive survey of published research on POI recommendation between 2017 and 2022 from the perspective of heterogeneous data sources. Specifically, we investigate which types of data are used in the literature and which technical approaches and evaluation methods are predominant. Among other aspects, we find that today's research works often focus on a narrow range of data sources, leaving great potential for future works that better utilize heterogeneous data sources and diverse data types for improved in-trip recommendations. ",
    "url": "https://arxiv.org/abs/2308.07426",
    "authors": [
      "Zehui Wang",
      "Wolfram H\u00f6pken",
      "Dietmar Jannach"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.07429",
    "title": "Semantic Similarity Loss for Neural Source Code Summarization",
    "abstract": "This paper presents an improved loss function for neural source code summarization. Code summarization is the task of writing natural language descriptions of source code. Neural code summarization refers to automated techniques for generating these descriptions using neural networks. Almost all current approaches involve neural networks as either standalone models or as part of a pretrained large language models e.g., GPT, Codex, LLaMA. Yet almost all also use a categorical cross-entropy (CCE) loss function for network optimization. Two problems with CCE are that 1) it computes loss over each word prediction one-at-a-time, rather than evaluating a whole sentence, and 2) it requires a perfect prediction, leaving no room for partial credit for synonyms. We propose and evaluate a loss function to alleviate this problem. In essence, we propose to use a semantic similarity metric to calculate loss over the whole output sentence prediction per training batch, rather than just loss for each word. We also propose to combine our loss with traditional CCE for each word, which streamlines the training process compared to baselines. We evaluate our approach over several baselines and report an improvement in the vast majority of conditions. ",
    "url": "https://arxiv.org/abs/2308.07429",
    "authors": [
      "Chia-Yi Su",
      "Collin McMillan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07433",
    "title": "White-Box Adversarial Attacks on Deep Learning-Based Radio Frequency  Fingerprint Identification",
    "abstract": "Radio frequency fingerprint identification (RFFI) is an emerging technique for the lightweight authentication of wireless Internet of things (IoT) devices. RFFI exploits unique hardware impairments as device identifiers, and deep learning is widely deployed as the feature extractor and classifier for RFFI. However, deep learning is vulnerable to adversarial attacks, where adversarial examples are generated by adding perturbation to clean data for causing the classifier to make wrong predictions. Deep learning-based RFFI has been shown to be vulnerable to such attacks, however, there is currently no exploration of effective adversarial attacks against a diversity of RFFI classifiers. In this paper, we report on investigations into white-box attacks (non-targeted and targeted) using two approaches, namely the fast gradient sign method (FGSM) and projected gradient descent (PGD). A LoRa testbed was built and real datasets were collected. These adversarial examples have been experimentally demonstrated to be effective against convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and gated recurrent units (GRU). ",
    "url": "https://arxiv.org/abs/2308.07433",
    "authors": [
      "Jie Ma",
      "Junqing Zhang",
      "Guanxiong Shen",
      "Alan Marshall",
      "Chip-Hong Chang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.07439",
    "title": "Interaction-Aware Personalized Vehicle Trajectory Prediction Using  Temporal Graph Neural Networks",
    "abstract": "Accurate prediction of vehicle trajectories is vital for advanced driver assistance systems and autonomous vehicles. Existing methods mainly rely on generic trajectory predictions derived from large datasets, overlooking the personalized driving patterns of individual drivers. To address this gap, we propose an approach for interaction-aware personalized vehicle trajectory prediction that incorporates temporal graph neural networks. Our method utilizes Graph Convolution Networks (GCN) and Long Short-Term Memory (LSTM) to model the spatio-temporal interactions between target vehicles and their surrounding traffic. To personalize the predictions, we establish a pipeline that leverages transfer learning: the model is initially pre-trained on a large-scale trajectory dataset and then fine-tuned for each driver using their specific driving data. We employ human-in-the-loop simulation to collect personalized naturalistic driving trajectories and corresponding surrounding vehicle trajectories. Experimental results demonstrate the superior performance of our personalized GCN-LSTM model, particularly for longer prediction horizons, compared to its generic counterpart. Moreover, the personalized model outperforms individual models created without pre-training, emphasizing the significance of pre-training on a large dataset to avoid overfitting. By incorporating personalization, our approach enhances trajectory prediction accuracy. ",
    "url": "https://arxiv.org/abs/2308.07439",
    "authors": [
      "Amr Abdelraouf",
      "Rohit Gupta",
      "Kyungtae Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.07441",
    "title": "Physics-Informed Deep Learning to Reduce the Bias in Joint Prediction of  Nitrogen Oxides",
    "abstract": "Atmospheric nitrogen oxides (NOx) primarily from fuel combustion have recognized acute and chronic health and environmental effects. Machine learning (ML) methods have significantly enhanced our capacity to predict NOx concentrations at ground-level with high spatiotemporal resolution but may suffer from high estimation bias since they lack physical and chemical knowledge about air pollution dynamics. Chemical transport models (CTMs) leverage this knowledge; however, accurate predictions of ground-level concentrations typically necessitate extensive post-calibration. Here, we present a physics-informed deep learning framework that encodes advection-diffusion mechanisms and fluid dynamics constraints to jointly predict NO2 and NOx and reduce ML model bias by 21-42%. Our approach captures fine-scale transport of NO2 and NOx, generates robust spatial extrapolation, and provides explicit uncertainty estimation. The framework fuses knowledge-driven physicochemical principles of CTMs with the predictive power of ML for air quality exposure, health, and policy applications. Our approach offers significant improvements over purely data-driven ML methods and has unprecedented bias reduction in joint NO2 and NOx prediction. ",
    "url": "https://arxiv.org/abs/2308.07441",
    "authors": [
      "Lianfa Li",
      "Roxana Khalili",
      "Frederick Lurmann",
      "Nathan Pavlovic",
      "Jun Wu",
      "Yan Xu",
      "Yisi Liu",
      "Karl O'Sharkey",
      "Beate Ritz",
      "Luke Oman",
      "Meredith Franklin",
      "Theresa Bastain",
      "Shohreh F. Farzan",
      "Carrie Breton",
      "Rima Habre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07452",
    "title": "GRU-D-Weibull: A Novel Real-Time Individualized Endpoint Prediction",
    "abstract": "Accurate prediction models for individual-level endpoints and time-to-endpoints are crucial in clinical practice. In this study, we propose a novel approach, GRU-D-Weibull, which combines gated recurrent units with decay (GRU-D) to model the Weibull distribution. Our method enables real-time individualized endpoint prediction and population-level risk management. Using a cohort of 6,879 patients with stage 4 chronic kidney disease (CKD4), we evaluated the performance of GRU-D-Weibull in endpoint prediction. The C-index of GRU-D-Weibull was ~0.7 at the index date and increased to ~0.77 after 4.3 years of follow-up, similar to random survival forest. Our approach achieved an absolute L1-loss of ~1.1 years (SD 0.95) at the CKD4 index date and a minimum of ~0.45 years (SD0.3) at 4 years of follow-up, outperforming competing methods significantly. GRU-D-Weibull consistently constrained the predicted survival probability at the time of an event within a smaller and more fixed range compared to other models throughout the follow-up period. We observed significant correlations between the error in point estimates and missing proportions of input features at the index date (correlations from ~0.1 to ~0.3), which diminished within 1 year as more data became available. By post-training recalibration, we successfully aligned the predicted and observed survival probabilities across multiple prediction horizons at different time points during follow-up. Our findings demonstrate the considerable potential of GRU-D-Weibull as the next-generation architecture for endpoint risk management, capable of generating various endpoint estimates for real-time monitoring using clinical data. ",
    "url": "https://arxiv.org/abs/2308.07452",
    "authors": [
      "Xiaoyang Ruan",
      "Liwei Wang",
      "Charat Thongprayoon",
      "Wisit Cheungpasitporn",
      "Hongfang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07480",
    "title": "OCDaf: Ordered Causal Discovery with Autoregressive Flows",
    "abstract": "We propose OCDaf, a novel order-based method for learning causal graphs from observational data. We establish the identifiability of causal graphs within multivariate heteroscedastic noise models, a generalization of additive noise models that allow for non-constant noise variances. Drawing upon the structural similarities between these models and affine autoregressive normalizing flows, we introduce a continuous search algorithm to find causal structures. Our experiments demonstrate state-of-the-art performance across the Sachs and SynTReN benchmarks in Structural Hamming Distance (SHD) and Structural Intervention Distance (SID). Furthermore, we validate our identifiability theory across various parametric and nonparametric synthetic datasets and showcase superior performance compared to existing baselines. ",
    "url": "https://arxiv.org/abs/2308.07480",
    "authors": [
      "Hamidreza Kamkari",
      "Vahid Zehtab",
      "Vahid Balazadeh",
      "Rahul G. Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2308.07504",
    "title": "ICAFusion: Iterative Cross-Attention Guided Feature Fusion for  Multispectral Object Detection",
    "abstract": "Effective feature fusion of multispectral images plays a crucial role in multi-spectral object detection. Previous studies have demonstrated the effectiveness of feature fusion using convolutional neural networks, but these methods are sensitive to image misalignment due to the inherent deffciency in local-range feature interaction resulting in the performance degradation. To address this issue, a novel feature fusion framework of dual cross-attention transformers is proposed to model global feature interaction and capture complementary information across modalities simultaneously. This framework enhances the discriminability of object features through the query-guided cross-attention mechanism, leading to improved performance. However, stacking multiple transformer blocks for feature enhancement incurs a large number of parameters and high spatial complexity. To handle this, inspired by the human process of reviewing knowledge, an iterative interaction mechanism is proposed to share parameters among block-wise multimodal transformers, reducing model complexity and computation cost. The proposed method is general and effective to be integrated into different detection frameworks and used with different backbones. Experimental results on KAIST, FLIR, and VEDAI datasets show that the proposed method achieves superior performance and faster inference, making it suitable for various practical scenarios. Code will be available at https://github.com/chanchanchan97/ICAFusion. ",
    "url": "https://arxiv.org/abs/2308.07504",
    "authors": [
      "Jifeng Shen",
      "Yifei Chen",
      "Yue Liu",
      "Xin Zuo",
      "Heng Fan",
      "Wankou Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07505",
    "title": "Data Race Detection Using Large Language Models",
    "abstract": "Large language models (LLMs) are demonstrating significant promise as an alternate strategy to facilitate analyses and optimizations of high-performance computing programs, circumventing the need for resource-intensive manual tool creation. In this paper, we explore a novel LLM-based data race detection approach combining prompting engineering and fine-tuning techniques. We create a dedicated dataset named DRB-ML, which is derived from DataRaceBench, with fine-grain labels showing the presence of data race pairs and their associated variables, line numbers, and read/write information. DRB-ML is then used to evaluate representative LLMs and fine-tune open-source ones. Our experiment shows that LLMs can be a viable approach to data race detection. However, they still cannot compete with traditional data race detection tools when we need detailed information about variable pairs causing data races. ",
    "url": "https://arxiv.org/abs/2308.07505",
    "authors": [
      "Le Chen",
      "Xianzhong Ding",
      "Murali Emani",
      "Tristan Vanderbruggen",
      "Pei-hung Lin",
      "Chuanhua Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.07511",
    "title": "Distilling Knowledge from Resource Management Algorithms to Neural  Networks: A Unified Training Assistance Approach",
    "abstract": "As a fundamental problem, numerous methods are dedicated to the optimization of signal-to-interference-plus-noise ratio (SINR), in a multi-user setting. Although traditional model-based optimization methods achieve strong performance, the high complexity raises the research of neural network (NN) based approaches to trade-off the performance and complexity. To fully leverage the high performance of traditional model-based methods and the low complexity of the NN-based method, a knowledge distillation (KD) based algorithm distillation (AD) method is proposed in this paper to improve the performance and convergence speed of the NN-based method, where traditional SINR optimization methods are employed as ``teachers\" to assist the training of NNs, which are ``students\", thus enhancing the performance of unsupervised and reinforcement learning techniques. This approach aims to alleviate common issues encountered in each of these training paradigms, including the infeasibility of obtaining optimal solutions as labels and overfitting in supervised learning, ensuring higher convergence performance in unsupervised learning, and improving training efficiency in reinforcement learning. Simulation results demonstrate the enhanced performance of the proposed AD-based methods compared to traditional learning methods. Remarkably, this research paves the way for the integration of traditional optimization insights and emerging NN techniques in wireless communication system optimization. ",
    "url": "https://arxiv.org/abs/2308.07511",
    "authors": [
      "Longfei Ma",
      "Nan Cheng",
      "Xiucheng Wang",
      "Zhisheng Yin",
      "Haibo Zhou",
      "Wei Quan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.07526",
    "title": "Protecting the Future Grid: An Electric Vehicle Robust Mitigation Scheme  Against Load Altering Attacks on Power Grids",
    "abstract": "Due to the growing threat of climate change, the worlds governments have been encouraging the adoption of Electric Vehicles (EVs). As a result, EV numbers have been growing exponentially which will introduce a large EV charging load into the power grid. On this basis, we present a scheme to utilize EVs as a defense mechanism to mitigate Load-Altering (LA) attacks against the grid. The developed scheme relies on robust control theory and Linear Matrix Inequalities (LMIs). Our EV-based defense mechanism is formulated as a feedback controller synthesized using H-2 and H-infinity control techniques to eliminate the impact of unknown LA attacks. The controller synthesis considers the grid topology and the uncertainties of the EV connection to the grid. To demonstrate the effectiveness of the proposed mitigation scheme, it is tested against three types of LA attacks on the New England 39-bus grid. We test our mitigation scheme against 800 MW static, switching, and dynamic attacks in the presence of multiple sources of uncertainty that can affect the EV load during deployment. The results demonstrate how the grid remains stable under the LA attacks that would otherwise lead to serious instabilities. ",
    "url": "https://arxiv.org/abs/2308.07526",
    "authors": [
      "Mohammad Ali Sayed",
      "Mohsen Ghafouri",
      "Ribal Atallah",
      "Mourad Debbabi",
      "Chadi Assi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.07535",
    "title": "Improved Region Proposal Network for Enhanced Few-Shot Object Detection",
    "abstract": "Despite significant success of deep learning in object detection tasks, the standard training of deep neural networks requires access to a substantial quantity of annotated images across all classes. Data annotation is an arduous and time-consuming endeavor, particularly when dealing with infrequent objects. Few-shot object detection (FSOD) methods have emerged as a solution to the limitations of classic object detection approaches based on deep learning. FSOD methods demonstrate remarkable performance by achieving robust object detection using a significantly smaller amount of training data. A challenge for FSOD is that instances from novel classes that do not belong to the fixed set of training classes appear in the background and the base model may pick them up as potential objects. These objects behave similarly to label noise because they are classified as one of the training dataset classes, leading to FSOD performance degradation. We develop a semi-supervised algorithm to detect and then utilize these unlabeled novel objects as positive samples during the FSOD training stage to improve FSOD performance. Specifically, we develop a hierarchical ternary classification region proposal network (HTRPN) to localize the potential unlabeled novel objects and assign them new objectness labels to distinguish these objects from the base training dataset classes. Our improved hierarchical sampling strategy for the region proposal network (RPN) also boosts the perception ability of the object detection model for large objects. We test our approach and COCO and PASCAL VOC baselines that are commonly used in FSOD literature. Our experimental results indicate that our method is effective and outperforms the existing state-of-the-art (SOTA) FSOD methods. Our implementation is provided as a supplement to support reproducibility of the results. ",
    "url": "https://arxiv.org/abs/2308.07535",
    "authors": [
      "Zeyu Shangguan",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07546",
    "title": "3DHacker: Spectrum-based Decision Boundary Generation for Hard-label 3D  Point Cloud Attack",
    "abstract": "With the maturity of depth sensors, the vulnerability of 3D point cloud models has received increasing attention in various applications such as autonomous driving and robot navigation. Previous 3D adversarial attackers either follow the white-box setting to iteratively update the coordinate perturbations based on gradients, or utilize the output model logits to estimate noisy gradients in the black-box setting. However, these attack methods are hard to be deployed in real-world scenarios since realistic 3D applications will not share any model details to users. Therefore, we explore a more challenging yet practical 3D attack setting, \\textit{i.e.}, attacking point clouds with black-box hard labels, in which the attacker can only have access to the prediction label of the input. To tackle this setting, we propose a novel 3D attack method, termed \\textbf{3D} \\textbf{H}ard-label att\\textbf{acker} (\\textbf{3DHacker}), based on the developed decision boundary algorithm to generate adversarial samples solely with the knowledge of class labels. Specifically, to construct the class-aware model decision boundary, 3DHacker first randomly fuses two point clouds of different classes in the spectral domain to craft their intermediate sample with high imperceptibility, then projects it onto the decision boundary via binary search. To restrict the final perturbation size, 3DHacker further introduces an iterative optimization strategy to move the intermediate sample along the decision boundary for generating adversarial point clouds with smallest trivial perturbations. Extensive evaluations show that, even in the challenging hard-label setting, 3DHacker still competitively outperforms existing 3D attacks regarding the attack performance as well as adversary quality. ",
    "url": "https://arxiv.org/abs/2308.07546",
    "authors": [
      "Yunbo Tao",
      "Daizong Liu",
      "Pan Zhou",
      "Yulai Xie",
      "Wei Du",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07553",
    "title": "Enhancing the Antidote: Improved Pointwise Certifications against  Poisoning Attacks",
    "abstract": "Poisoning attacks can disproportionately influence model behaviour by making small changes to the training corpus. While defences against specific poisoning attacks do exist, they in general do not provide any guarantees, leaving them potentially countered by novel attacks. In contrast, by examining worst-case behaviours Certified Defences make it possible to provide guarantees of the robustness of a sample against adversarial attacks modifying a finite number of training samples, known as pointwise certification. We achieve this by exploiting both Differential Privacy and the Sampled Gaussian Mechanism to ensure the invariance of prediction for each testing instance against finite numbers of poisoned examples. In doing so, our model provides guarantees of adversarial robustness that are more than twice as large as those provided by prior certifications. ",
    "url": "https://arxiv.org/abs/2308.07553",
    "authors": [
      "Shijie Liu",
      "Andrew C. Cullen",
      "Paul Montague",
      "Sarah M. Erfani",
      "Benjamin I. P. Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.07555",
    "title": "SST: A Simplified Swin Transformer-based Model for Taxi Destination  Prediction based on Existing Trajectory",
    "abstract": "Accurately predicting the destination of taxi trajectories can have various benefits for intelligent location-based services. One potential method to accomplish this prediction is by converting the taxi trajectory into a two-dimensional grid and using computer vision techniques. While the Swin Transformer is an innovative computer vision architecture with demonstrated success in vision downstream tasks, it is not commonly used to solve real-world trajectory problems. In this paper, we propose a simplified Swin Transformer (SST) structure that does not use the shifted window idea in the traditional Swin Transformer, as trajectory data is consecutive in nature. Our comprehensive experiments, based on real trajectory data, demonstrate that SST can achieve higher accuracy compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2308.07555",
    "authors": [
      "Zepu Wang",
      "Yifei Sun",
      "Zhiyu Lei",
      "Xincheng Zhu",
      "Peng Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2308.07558",
    "title": "Action Class Relation Detection and Classification Across Multiple Video  Datasets",
    "abstract": "The Meta Video Dataset (MetaVD) provides annotated relations between action classes in major datasets for human action recognition in videos. Although these annotated relations enable dataset augmentation, it is only applicable to those covered by MetaVD. For an external dataset to enjoy the same benefit, the relations between its action classes and those in MetaVD need to be determined. To address this issue, we consider two new machine learning tasks: action class relation detection and classification. We propose a unified model to predict relations between action classes, using language and visual information associated with classes. Experimental results show that (i) pre-trained recent neural network models for texts and videos contribute to high predictive performance, (ii) the relation prediction based on action label texts is more accurate than based on videos, and (iii) a blending approach that combines predictions by both modalities can further improve the predictive performance in some cases. ",
    "url": "https://arxiv.org/abs/2308.07558",
    "authors": [
      "Yuya Yoshikawa",
      "Yutaro Shigeto",
      "Masashi Shimbo",
      "Akikazu Takeuchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07571",
    "title": "Ske2Grid: Skeleton-to-Grid Representation Learning for Action  Recognition",
    "abstract": "This paper presents Ske2Grid, a new representation learning framework for improved skeleton-based action recognition. In Ske2Grid, we define a regular convolution operation upon a novel grid representation of human skeleton, which is a compact image-like grid patch constructed and learned through three novel designs. Specifically, we propose a graph-node index transform (GIT) to construct a regular grid patch through assigning the nodes in the skeleton graph one by one to the desired grid cells. To ensure that GIT is a bijection and enrich the expressiveness of the grid representation, an up-sampling transform (UPT) is learned to interpolate the skeleton graph nodes for filling the grid patch to the full. To resolve the problem when the one-step UPT is aggressive and further exploit the representation capability of the grid patch with increasing spatial size, a progressive learning strategy (PLS) is proposed which decouples the UPT into multiple steps and aligns them to multiple paired GITs through a compact cascaded design learned progressively. We construct networks upon prevailing graph convolution networks and conduct experiments on six mainstream skeleton-based action recognition datasets. Experiments show that our Ske2Grid significantly outperforms existing GCN-based solutions under different benchmark settings, without bells and whistles. Code and models are available at https://github.com/OSVAI/Ske2Grid ",
    "url": "https://arxiv.org/abs/2308.07571",
    "authors": [
      "Dongqi Cai",
      "Yangyuxuan Kang",
      "Anbang Yao",
      "Yurong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07575",
    "title": "Story Visualization by Online Text Augmentation with Context Memory",
    "abstract": "Story visualization (SV) is a challenging text-to-image generation task for the difficulty of not only rendering visual details from the text descriptions but also encoding a long-term context across multiple sentences. While prior efforts mostly focus on generating a semantically relevant image for each sentence, encoding a context spread across the given paragraph to generate contextually convincing images (e.g., with a correct character or with a proper background of the scene) remains a challenge. To this end, we propose a novel memory architecture for the Bi-directional Transformers with an online text augmentation that generates multiple pseudo-descriptions as supplementary supervision during training, for better generalization to the language variation at inference. In extensive experiments on the two popular SV benchmarks, i.e., the Pororo-SV and Flintstones-SV, the proposed method significantly outperforms the state of the arts in various evaluation metrics including FID, character F1, frame accuracy, BLEU-2/3, and R-precision with similar or less computational complexity. ",
    "url": "https://arxiv.org/abs/2308.07575",
    "authors": [
      "Daechul Ahn",
      "Daneul Kim",
      "Gwangmo Song",
      "Seung Hwan Kim",
      "Honglak Lee",
      "Dongyeop Kang",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07578",
    "title": "Understanding User Behavior in Volumetric Video Watching: Dataset,  Analysis and Prediction",
    "abstract": "Volumetric video emerges as a new attractive video paradigm in recent years since it provides an immersive and interactive 3D viewing experience with six degree-of-freedom (DoF). Unlike traditional 2D or panoramic videos, volumetric videos require dense point clouds, voxels, meshes, or huge neural models to depict volumetric scenes, which results in a prohibitively high bandwidth burden for video delivery. Users' behavior analysis, especially the viewport and gaze analysis, then plays a significant role in prioritizing the content streaming within users' viewport and degrading the remaining content to maximize user QoE with limited bandwidth. Although understanding user behavior is crucial, to the best of our best knowledge, there are no available 3D volumetric video viewing datasets containing fine-grained user interactivity features, not to mention further analysis and behavior prediction. In this paper, we for the first time release a volumetric video viewing behavior dataset, with a large scale, multiple dimensions, and diverse conditions. We conduct an in-depth analysis to understand user behaviors when viewing volumetric videos. Interesting findings on user viewport, gaze, and motion preference related to different videos and users are revealed. We finally design a transformer-based viewport prediction model that fuses the features of both gaze and motion, which is able to achieve high accuracy at various conditions. Our prediction model is expected to further benefit volumetric video streaming optimization. Our dataset, along with the corresponding visualization tools is accessible at https://cuhksz-inml.github.io/user-behavior-in-vv-watching/ ",
    "url": "https://arxiv.org/abs/2308.07578",
    "authors": [
      "Kaiyuan Hu",
      "Haowen Yang",
      "Yili Jin",
      "Junhua Liu",
      "Yongting Chen",
      "Miao Zhang",
      "Fangxin Wang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2308.07592",
    "title": "Graph-Segmenter: Graph Transformer with Boundary-aware Attention for  Semantic Segmentation",
    "abstract": "The transformer-based semantic segmentation approaches, which divide the image into different regions by sliding windows and model the relation inside each window, have achieved outstanding success. However, since the relation modeling between windows was not the primary emphasis of previous work, it was not fully utilized. To address this issue, we propose a Graph-Segmenter, including a Graph Transformer and a Boundary-aware Attention module, which is an effective network for simultaneously modeling the more profound relation between windows in a global view and various pixels inside each window as a local one, and for substantial low-cost boundary adjustment. Specifically, we treat every window and pixel inside the window as nodes to construct graphs for both views and devise the Graph Transformer. The introduced boundary-aware attention module optimizes the edge information of the target objects by modeling the relationship between the pixel on the object's edge. Extensive experiments on three widely used semantic segmentation datasets (Cityscapes, ADE-20k and PASCAL Context) demonstrate that our proposed network, a Graph Transformer with Boundary-aware Attention, can achieve state-of-the-art segmentation performance. ",
    "url": "https://arxiv.org/abs/2308.07592",
    "authors": [
      "Zizhang Wu",
      "Yuanzhu Gan",
      "Tianhao Xu",
      "Fan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07598",
    "title": "Generating Personas for Games with Multimodal Adversarial Imitation  Learning",
    "abstract": "Reinforcement learning has been widely successful in producing agents capable of playing games at a human level. However, this requires complex reward engineering, and the agent's resulting policy is often unpredictable. Going beyond reinforcement learning is necessary to model a wide range of human playstyles, which can be difficult to represent with a reward function. This paper presents a novel imitation learning approach to generate multiple persona policies for playtesting. Multimodal Generative Adversarial Imitation Learning (MultiGAIL) uses an auxiliary input parameter to learn distinct personas using a single-agent model. MultiGAIL is based on generative adversarial imitation learning and uses multiple discriminators as reward models, inferring the environment reward by comparing the agent and distinct expert policies. The reward from each discriminator is weighted according to the auxiliary input. Our experimental analysis demonstrates the effectiveness of our technique in two environments with continuous and discrete action spaces. ",
    "url": "https://arxiv.org/abs/2308.07598",
    "authors": [
      "William Ahlberg",
      "Alessandro Sestini",
      "Konrad Tollmar",
      "Linus Gissl\u00e9n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07615",
    "title": "Self-supervised Hypergraphs for Learning Multiple World Interpretations",
    "abstract": "We present a method for learning multiple scene representations given a small labeled set, by exploiting the relationships between such representations in the form of a multi-task hypergraph. We also show how we can use the hypergraph to improve a powerful pretrained VisTransformer model without any additional labeled data. In our hypergraph, each node is an interpretation layer (e.g., depth or segmentation) of the scene. Within each hyperedge, one or several input nodes predict the layer at the output node. Thus, each node could be an input node in some hyperedges and an output node in others. In this way, multiple paths can reach the same node, to form ensembles from which we obtain robust pseudolabels, which allow self-supervised learning in the hypergraph. We test different ensemble models and different types of hyperedges and show superior performance to other multi-task graph models in the field. We also introduce Dronescapes, a large video dataset captured with UAVs in different complex real-world scenes, with multiple representations, suitable for multi-task learning. ",
    "url": "https://arxiv.org/abs/2308.07615",
    "authors": [
      "Alina Marcu",
      "Mihai Pirvu",
      "Dragos Costea",
      "Emanuela Haller",
      "Emil Slusanschi",
      "Ahmed Nabil Belbachir",
      "Rahul Sukthankar",
      "Marius Leordeanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07625",
    "title": "Backpropagation Path Search On Adversarial Transferability",
    "abstract": "Deep neural networks are vulnerable to adversarial examples, dictating the imperativeness to test the model's robustness before deployment. Transfer-based attackers craft adversarial examples against surrogate models and transfer them to victim models deployed in the black-box situation. To enhance the adversarial transferability, structure-based attackers adjust the backpropagation path to avoid the attack from overfitting the surrogate model. However, existing structure-based attackers fail to explore the convolution module in CNNs and modify the backpropagation graph heuristically, leading to limited effectiveness. In this paper, we propose backPropagation pAth Search (PAS), solving the aforementioned two problems. We first propose SkipConv to adjust the backpropagation path of convolution by structural reparameterization. To overcome the drawback of heuristically designed backpropagation paths, we further construct a DAG-based search space, utilize one-step approximation for path evaluation and employ Bayesian Optimization to search for the optimal path. We conduct comprehensive experiments in a wide range of transfer settings, showing that PAS improves the attack success rate by a huge margin for both normally trained and defense models. ",
    "url": "https://arxiv.org/abs/2308.07625",
    "authors": [
      "Zhuoer Xu",
      "Zhangxuan Gu",
      "Jianping Zhang",
      "Shiwen Cui",
      "Changhua Meng",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07629",
    "title": "Learning from All Sides: Diversified Positive Augmentation via  Self-distillation in Recommendation",
    "abstract": "Personalized recommendation relies on user historical behaviors to provide user-interested items, and thus seriously struggles with the data sparsity issue. A powerful positive item augmentation is beneficial to address the sparsity issue, while few works could jointly consider both the accuracy and diversity of these augmented training labels. In this work, we propose a novel model-agnostic Diversified self-distillation guided positive augmentation (DivSPA) for accurate and diverse positive item augmentations. Specifically, DivSPA first conducts three types of retrieval strategies to collect high-quality and diverse positive item candidates according to users' overall interests, short-term intentions, and similar users. Next, a self-distillation module is conducted to double-check and rerank these candidates as the final positive augmentations. Extensive offline and online evaluations verify the effectiveness of our proposed DivSPA on both accuracy and diversity. DivSPA is simple and effective, which could be conveniently adapted to other base models and systems. Currently, DivSPA has been deployed on multiple widely-used real-world recommender systems. ",
    "url": "https://arxiv.org/abs/2308.07629",
    "authors": [
      "Chong Liu",
      "Xiaoyang Liu",
      "Ruobing Xie",
      "Lixin Zhang",
      "Feng Xia",
      "Leyu Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.07650",
    "title": "EQ-Net: Elastic Quantization Neural Networks",
    "abstract": "Current model quantization methods have shown their promising capability in reducing storage space and computation complexity. However, due to the diversity of quantization forms supported by different hardware, one limitation of existing solutions is that usually require repeated optimization for different scenarios. How to construct a model with flexible quantization forms has been less studied. In this paper, we explore a one-shot network quantization regime, named Elastic Quantization Neural Networks (EQ-Net), which aims to train a robust weight-sharing quantization supernet. First of all, we propose an elastic quantization space (including elastic bit-width, granularity, and symmetry) to adapt to various mainstream quantitative forms. Secondly, we propose the Weight Distribution Regularization Loss (WDR-Loss) and Group Progressive Guidance Loss (GPG-Loss) to bridge the inconsistency of the distribution for weights and output logits in the elastic quantization space gap. Lastly, we incorporate genetic algorithms and the proposed Conditional Quantization-Aware Accuracy Predictor (CQAP) as an estimator to quickly search mixed-precision quantized neural networks in supernet. Extensive experiments demonstrate that our EQ-Net is close to or even better than its static counterparts as well as state-of-the-art robust bit-width methods. Code can be available at \\href{https://github.com/xuke225/EQ-Net.git}{https://github.com/xuke225/EQ-Net}. ",
    "url": "https://arxiv.org/abs/2308.07650",
    "authors": [
      "Ke Xu",
      "Lei Han",
      "Ye Tian",
      "Shangshang Yang",
      "Xingyi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07673",
    "title": "A Review of Adversarial Attacks in Computer Vision",
    "abstract": "Deep neural networks have been widely used in various downstream tasks, especially those safety-critical scenario such as autonomous driving, but deep networks are often threatened by adversarial samples. Such adversarial attacks can be invisible to human eyes, but can lead to DNN misclassification, and often exhibits transferability between deep learning and machine learning models and real-world achievability. Adversarial attacks can be divided into white-box attacks, for which the attacker knows the parameters and gradient of the model, and black-box attacks, for the latter, the attacker can only obtain the input and output of the model. In terms of the attacker's purpose, it can be divided into targeted attacks and non-targeted attacks, which means that the attacker wants the model to misclassify the original sample into the specified class, which is more practical, while the non-targeted attack just needs to make the model misclassify the sample. The black box setting is a scenario we will encounter in practice. ",
    "url": "https://arxiv.org/abs/2308.07673",
    "authors": [
      "Yutong Zhang",
      "Yao Li",
      "Yin Li",
      "Zhichang Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.07681",
    "title": "SCTBEM: A scaled coordinate transformation boundary element method with  99-line MATLAB code",
    "abstract": "This paper introduces the Scaled Coordinate Transformation Boundary Element Method (SCTBEM), a novel boundary-type method for solving 3D potential problems. To address the challenges of applying the Boundary Element Method (BEM) to complex problems, it is common practice to use the fundamental solution corresponding to the partial governing equation operator to establish the integral equation. However, this approach introduces domain integral, which may jeopardize the dimensionality reduction advantages of BEM. To preserve the benefits of dimensionality reduction, this paper proposes a novel domain integral transformation method known as the Scaled Coordinate Transformation (SCT). The SCT is purely a mathematical operation that does not rely on particular solution of operators, which requires only discretization on the structure's surface while remaining analytical in the radial direction. An even better novelty is that the lower-order singularity can be eliminated by coordinate translation technique. To facilitate the wider adoption of BEM, the authors present 99-line MATLAB code. Numerical results confirm that the SCTBEM exhibits high numerical accuracy even when dealing with complex model. ",
    "url": "https://arxiv.org/abs/2308.07681",
    "authors": [
      "Bo Yu",
      "Ruijiang Jing"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.07687",
    "title": "DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using  Pre-trained Diffusion Models",
    "abstract": "Given a classifier, the inherent property of semantic Out-of-Distribution (OOD) samples is that their contents differ from all legal classes in terms of semantics, namely semantic mismatch. There is a recent work that directly applies it to OOD detection, which employs a conditional Generative Adversarial Network (cGAN) to enlarge semantic mismatch in the image space. While achieving remarkable OOD detection performance on small datasets, it is not applicable to ImageNet-scale datasets due to the difficulty in training cGANs with both input images and labels as conditions. As diffusion models are much easier to train and amenable to various conditions compared to cGANs, in this work, we propose to directly use pre-trained diffusion models for semantic mismatch-guided OOD detection, named DiffGuard. Specifically, given an OOD input image and the predicted label from the classifier, we try to enlarge the semantic difference between the reconstructed OOD image under these conditions and the original input image. We also present several test-time techniques to further strengthen such differences. Experimental results show that DiffGuard is effective on both Cifar-10 and hard cases of the large-scale ImageNet, and it can be easily combined with existing OOD detection techniques to achieve state-of-the-art OOD detection results. ",
    "url": "https://arxiv.org/abs/2308.07687",
    "authors": [
      "Ruiyuan Gao",
      "Chenchen Zhao",
      "Lanqing Hong",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07728",
    "title": "Domain-Aware Fine-Tuning: Enhancing Neural Network Adaptability",
    "abstract": "Fine-tuning pre-trained neural network models has become a widely adopted approach across various domains. However, it can lead to the distortion of pre-trained feature extractors that already possess strong generalization capabilities. Mitigating feature distortion during adaptation to new target domains is crucial. Recent studies have shown promising results in handling feature distortion by aligning the head layer on in-distribution datasets before performing fine-tuning. Nonetheless, a significant limitation arises from the treatment of batch normalization layers during fine-tuning, leading to suboptimal performance. In this paper, we propose Domain-Aware Fine-Tuning (DAFT), a novel approach that incorporates batch normalization conversion and the integration of linear probing and fine-tuning. Our batch normalization conversion method effectively mitigates feature distortion by reducing modifications to the neural network during fine-tuning. Additionally, we introduce the integration of linear probing and fine-tuning to optimize the head layer with gradual adaptation of the feature extractor. By leveraging batch normalization layers and integrating linear probing and fine-tuning, our DAFT significantly mitigates feature distortion and achieves improved model performance on both in-distribution and out-of-distribution datasets. Extensive experiments demonstrate that our method outperforms other baseline methods, demonstrating its effectiveness in not only improving performance but also mitigating feature distortion. ",
    "url": "https://arxiv.org/abs/2308.07728",
    "authors": [
      "Seokhyeon Ha",
      "Sunbeom Jung",
      "Jungwoo Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07732",
    "title": "UniTR: A Unified and Efficient Multi-Modal Transformer for  Bird's-Eye-View Representation",
    "abstract": "Jointly processing information from multiple sensors is crucial to achieving accurate and robust perception for reliable autonomous driving systems. However, current 3D perception research follows a modality-specific paradigm, leading to additional computation overheads and inefficient collaboration between different sensor data. In this paper, we present an efficient multi-modal backbone for outdoor 3D perception named UniTR, which processes a variety of modalities with unified modeling and shared parameters. Unlike previous works, UniTR introduces a modality-agnostic transformer encoder to handle these view-discrepant sensor data for parallel modal-wise representation learning and automatic cross-modal interaction without additional fusion steps. More importantly, to make full use of these complementary sensor types, we present a novel multi-modal integration strategy by both considering semantic-abundant 2D perspective and geometry-aware 3D sparse neighborhood relations. UniTR is also a fundamentally task-agnostic backbone that naturally supports different 3D perception tasks. It sets a new state-of-the-art performance on the nuScenes benchmark, achieving +1.1 NDS higher for 3D object detection and +12.0 higher mIoU for BEV map segmentation with lower inference latency. Code will be available at https://github.com/Haiyang-W/UniTR . ",
    "url": "https://arxiv.org/abs/2308.07732",
    "authors": [
      "Haiyang Wang",
      "Hao Tang",
      "Shaoshuai Shi",
      "Aoxue Li",
      "Zhenguo Li",
      "Bernt Schiele",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07737",
    "title": "Identity-Consistent Aggregation for Video Object Detection",
    "abstract": "In Video Object Detection (VID), a common practice is to leverage the rich temporal contexts from the video to enhance the object representations in each frame. Existing methods treat the temporal contexts obtained from different objects indiscriminately and ignore their different identities. While intuitively, aggregating local views of the same object in different frames may facilitate a better understanding of the object. Thus, in this paper, we aim to enable the model to focus on the identity-consistent temporal contexts of each object to obtain more comprehensive object representations and handle the rapid object appearance variations such as occlusion, motion blur, etc. However, realizing this goal on top of existing VID models faces low-efficiency problems due to their redundant region proposals and nonparallel frame-wise prediction manner. To aid this, we propose ClipVID, a VID model equipped with Identity-Consistent Aggregation (ICA) layers specifically designed for mining fine-grained and identity-consistent temporal contexts. It effectively reduces the redundancies through the set prediction strategy, making the ICA layers very efficient and further allowing us to design an architecture that makes parallel clip-wise predictions for the whole video clip. Extensive experimental results demonstrate the superiority of our method: a state-of-the-art (SOTA) performance (84.7% mAP) on the ImageNet VID dataset while running at a speed about 7x faster (39.3 fps) than previous SOTAs. ",
    "url": "https://arxiv.org/abs/2308.07737",
    "authors": [
      "Chaorui Deng",
      "Da Chen",
      "Qi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07743",
    "title": "ChartDETR: A Multi-shape Detection Network for Visual Chart Recognition",
    "abstract": "Visual chart recognition systems are gaining increasing attention due to the growing demand for automatically identifying table headers and values from chart images. Current methods rely on keypoint detection to estimate data element shapes in charts but suffer from grouping errors in post-processing. To address this issue, we propose ChartDETR, a transformer-based multi-shape detector that localizes keypoints at the corners of regular shapes to reconstruct multiple data elements in a single chart image. Our method predicts all data element shapes at once by introducing query groups in set prediction, eliminating the need for further postprocessing. This property allows ChartDETR to serve as a unified framework capable of representing various chart types without altering the network architecture, effectively detecting data elements of diverse shapes. We evaluated ChartDETR on three datasets, achieving competitive results across all chart types without any additional enhancements. For example, ChartDETR achieved an F1 score of 0.98 on Adobe Synthetic, significantly outperforming the previous best model with a 0.71 F1 score. Additionally, we obtained a new state-of-the-art result of 0.97 on ExcelChart400k. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2308.07743",
    "authors": [
      "Wenyuan Xue",
      "Dapeng Chen",
      "Baosheng Yu",
      "Yifei Chen",
      "Sai Zhou",
      "Wei Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07748",
    "title": "Exploiting Sparsity in Automotive Radar Object Detection Networks",
    "abstract": "Having precise perception of the environment is crucial for ensuring the secure and reliable functioning of autonomous driving systems. Radar object detection networks are one fundamental part of such systems. CNN-based object detectors showed good performance in this context, but they require large compute resources. This paper investigates sparse convolutional object detection networks, which combine powerful grid-based detection with low compute resources. We investigate radar specific challenges and propose sparse kernel point pillars (SKPP) and dual voxel point convolutions (DVPC) as remedies for the grid rendering and sparse backbone architectures. We evaluate our SKPP-DPVCN architecture on nuScenes, which outperforms the baseline by 5.89% and the previous state of the art by 4.19% in Car AP4.0. Moreover, SKPP-DPVCN reduces the average scale error (ASE) by 21.41% over the baseline. ",
    "url": "https://arxiv.org/abs/2308.07748",
    "authors": [
      "Marius Lippke",
      "Maurice Quach",
      "Sascha Braun",
      "Daniel K\u00f6hler",
      "Michael Ulrich",
      "Bastian Bischoff",
      "Wei Yap Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.07751",
    "title": "CASPNet++: Joint Multi-Agent Motion Prediction",
    "abstract": "The prediction of road users' future motion is a critical task in supporting advanced driver-assistance systems (ADAS). It plays an even more crucial role for autonomous driving (AD) in enabling the planning and execution of safe driving maneuvers. Based on our previous work, Context-Aware Scene Prediction Network (CASPNet), an improved system, CASPNet++, is proposed. In this work, we focus on further enhancing the interaction modeling and scene understanding to support the joint prediction of all road users in a scene using spatiotemporal grids to model future occupancy. Moreover, an instance-based output head is introduced to provide multi-modal trajectories for agents of interest. In extensive quantitative and qualitative analysis, we demonstrate the scalability of CASPNet++ in utilizing and fusing diverse environmental input sources such as HD maps, Radar detection, and Lidar segmentation. Tested on the urban-focused prediction dataset nuScenes, CASPNet++ reaches state-of-the-art performance. The model has been deployed in a testing vehicle, running in real-time with moderate computational resources. ",
    "url": "https://arxiv.org/abs/2308.07751",
    "authors": [
      "Maximilian Sch\u00e4fer",
      "Kun Zhao",
      "Anton Kummert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07752",
    "title": "Self-Supervised Dynamic Hypergraph Recommendation based on  Hyper-Relational Knowledge Graph",
    "abstract": "Knowledge graphs (KGs) are commonly used as side information to enhance collaborative signals and improve recommendation quality. In the context of knowledge-aware recommendation (KGR), graph neural networks (GNNs) have emerged as promising solutions for modeling factual and semantic information in KGs. However, the long-tail distribution of entities leads to sparsity in supervision signals, which weakens the quality of item representation when utilizing KG enhancement. Additionally, the binary relation representation of KGs simplifies hyper-relational facts, making it challenging to model complex real-world information. Furthermore, the over-smoothing phenomenon results in indistinguishable representations and information loss. To address these challenges, we propose the SDK (Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph) framework. This framework establishes a cross-view hypergraph self-supervised learning mechanism for KG enhancement. Specifically, we model hyper-relational facts in KGs to capture interdependencies between entities under complete semantic conditions. With the refined representation, a hypergraph is dynamically constructed to preserve features in the deep vector space, thereby alleviating the over-smoothing problem. Furthermore, we mine external supervision signals from both the global perspective of the hypergraph and the local perspective of collaborative filtering (CF) to guide the model prediction process. Extensive experiments conducted on different datasets demonstrate the superiority of the SDK framework over state-of-the-art models. The results showcase its ability to alleviate the effects of over-smoothing and supervision signal sparsity. ",
    "url": "https://arxiv.org/abs/2308.07752",
    "authors": [
      "Yi Liu",
      "Hongrui Xuan",
      "Bohan Li",
      "Meng Wang",
      "Tong Chen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.07760",
    "title": "Dynamic Embedding Size Search with Minimum Regret for Streaming  Recommender System",
    "abstract": "With the continuous increase of users and items, conventional recommender systems trained on static datasets can hardly adapt to changing environments. The high-throughput data requires the model to be updated in a timely manner for capturing the user interest dynamics, which leads to the emergence of streaming recommender systems. Due to the prevalence of deep learning-based recommender systems, the embedding layer is widely adopted to represent the characteristics of users, items, and other features in low-dimensional vectors. However, it has been proved that setting an identical and static embedding size is sub-optimal in terms of recommendation performance and memory cost, especially for streaming recommendations. To tackle this problem, we first rethink the streaming model update process and model the dynamic embedding size search as a bandit problem. Then, we analyze and quantify the factors that influence the optimal embedding sizes from the statistics perspective. Based on this, we propose the \\textbf{D}ynamic \\textbf{E}mbedding \\textbf{S}ize \\textbf{S}earch (\\textbf{DESS}) method to minimize the embedding size selection regret on both user and item sides in a non-stationary manner. Theoretically, we obtain a sublinear regret upper bound superior to previous methods. Empirical results across two recommendation tasks on four public datasets also demonstrate that our approach can achieve better streaming recommendation performance with lower memory cost and higher time efficiency. ",
    "url": "https://arxiv.org/abs/2308.07760",
    "authors": [
      "Bowei He",
      "Xu He",
      "Renrui Zhang",
      "Yingxue Zhang",
      "Ruiming Tang",
      "Chen Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07761",
    "title": "NeFL: Nested Federated Learning for Heterogeneous Clients",
    "abstract": "Federated learning (FL) is a promising approach in distributed learning keeping privacy. However, during the training pipeline of FL, slow or incapable clients (i.e., stragglers) slow down the total training time and degrade performance. System heterogeneity, including heterogeneous computing and network bandwidth, has been addressed to mitigate the impact of stragglers. Previous studies split models to tackle the issue, but with less degree-of-freedom in terms of model architecture. We propose nested federated learning (NeFL), a generalized framework that efficiently divides a model into submodels using both depthwise and widthwise scaling. NeFL is implemented by interpreting models as solving ordinary differential equations (ODEs) with adaptive step sizes. To address the inconsistency that arises when training multiple submodels with different architecture, we decouple a few parameters. NeFL enables resource-constrained clients to effectively join the FL pipeline and the model to be trained with a larger amount of data. Through a series of experiments, we demonstrate that NeFL leads to significant gains, especially for the worst-case submodel (e.g., 8.33 improvement on CIFAR-10). Furthermore, we demonstrate NeFL aligns with recent studies in FL. ",
    "url": "https://arxiv.org/abs/2308.07761",
    "authors": [
      "Honggu Kang",
      "Seohyeon Cha",
      "Jinwoo Shin",
      "Jongmyeong Lee",
      "Joonhyuk Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07766",
    "title": "Whale Detection Enhancement through Synthetic Satellite Images",
    "abstract": "With a number of marine populations in rapid decline, collecting and analyzing data about marine populations has become increasingly important to develop effective conservation policies for a wide range of marine animals, including whales. Modern computer vision algorithms allow us to detect whales in images in a wide range of domains, further speeding up and enhancing the monitoring process. However, these algorithms heavily rely on large training datasets, which are challenging and time-consuming to collect particularly in marine or aquatic environments. Recent advances in AI however have made it possible to synthetically create datasets for training machine learning algorithms, thus enabling new solutions that were not possible before. In this work, we present a solution - SeaDroneSim2 benchmark suite, which addresses this challenge by generating aerial, and satellite synthetic image datasets to improve the detection of whales and reduce the effort required for training data collection. We show that we can achieve a 15% performance boost on whale detection compared to using the real data alone for training, by augmenting a 10% real data. We open source both the code of the simulation platform SeaDroneSim2 and the dataset generated through it. ",
    "url": "https://arxiv.org/abs/2308.07766",
    "authors": [
      "Akshaj Gaur",
      "Cheng Liu",
      "Xiaomin Lin",
      "Nare Karapetyan",
      "Yiannis Aloimonos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.07770",
    "title": "Multi-scale Promoted Self-adjusting Correlation Learning for Facial  Action Unit Detection",
    "abstract": "Facial Action Unit (AU) detection is a crucial task in affective computing and social robotics as it helps to identify emotions expressed through facial expressions. Anatomically, there are innumerable correlations between AUs, which contain rich information and are vital for AU detection. Previous methods used fixed AU correlations based on expert experience or statistical rules on specific benchmarks, but it is challenging to comprehensively reflect complex correlations between AUs via hand-crafted settings. There are alternative methods that employ a fully connected graph to learn these dependencies exhaustively. However, these approaches can result in a computational explosion and high dependency with a large dataset. To address these challenges, this paper proposes a novel self-adjusting AU-correlation learning (SACL) method with less computation for AU detection. This method adaptively learns and updates AU correlation graphs by efficiently leveraging the characteristics of different levels of AU motion and emotion representation information extracted in different stages of the network. Moreover, this paper explores the role of multi-scale learning in correlation information extraction, and design a simple yet effective multi-scale feature learning (MSFL) method to promote better performance in AU detection. By integrating AU correlation information with multi-scale features, the proposed method obtains a more robust feature representation for the final AU detection. Extensive experiments show that the proposed method outperforms the state-of-the-art methods on widely used AU detection benchmark datasets, with only 28.7\\% and 12.0\\% of the parameters and FLOPs of the best method, respectively. The code for this method is available at \\url{https://github.com/linuxsino/Self-adjusting-AU}. ",
    "url": "https://arxiv.org/abs/2308.07770",
    "authors": [
      "Xin Liu",
      "Kaishen Yuan",
      "Xuesong Niu",
      "Jingang Shi",
      "Zitong Yu",
      "Huanjing Yue",
      "Jingyu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07774",
    "title": "A Graph Encoder-Decoder Network for Unsupervised Anomaly Detection",
    "abstract": "A key component of many graph neural networks (GNNs) is the pooling operation, which seeks to reduce the size of a graph while preserving important structural information. However, most existing graph pooling strategies rely on an assignment matrix obtained by employing a GNN layer, which is characterized by trainable parameters, often leading to significant computational complexity and a lack of interpretability in the pooling process. In this paper, we propose an unsupervised graph encoder-decoder model to detect abnormal nodes from graphs by learning an anomaly scoring function to rank nodes based on their degree of abnormality. In the encoding stage, we design a novel pooling mechanism, named LCPool, which leverages locality-constrained linear coding for feature encoding to find a cluster assignment matrix by solving a least-squares optimization problem with a locality regularization term. By enforcing locality constraints during the coding process, LCPool is designed to be free from learnable parameters, capable of efficiently handling large graphs, and can effectively generate a coarser graph representation while retaining the most significant structural characteristics of the graph. In the decoding stage, we propose an unpooling operation, called LCUnpool, to reconstruct both the structure and nodal features of the original graph. We conduct empirical evaluations of our method on six benchmark datasets using several evaluation metrics, and the results demonstrate its superiority over state-of-the-art anomaly detection approaches. ",
    "url": "https://arxiv.org/abs/2308.07774",
    "authors": [
      "Mahsa Mesgaran",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07781",
    "title": "Learning Image Deraining Transformer Network with Dynamic Dual  Self-Attention",
    "abstract": "Recently, Transformer-based architecture has been introduced into single image deraining task due to its advantage in modeling non-local information. However, existing approaches tend to integrate global features based on a dense self-attention strategy since it tend to uses all similarities of the tokens between the queries and keys. In fact, this strategy leads to ignoring the most relevant information and inducing blurry effect by the irrelevant representations during the feature aggregation. To this end, this paper proposes an effective image deraining Transformer with dynamic dual self-attention (DDSA), which combines both dense and sparse attention strategies to better facilitate clear image reconstruction. Specifically, we only select the most useful similarity values based on top-k approximate calculation to achieve sparse attention. In addition, we also develop a novel spatial-enhanced feed-forward network (SEFN) to further obtain a more accurate representation for achieving high-quality derained results. Extensive experiments on benchmark datasets demonstrate the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2308.07781",
    "authors": [
      "Zhentao Fan",
      "Hongming Chen",
      "Yufeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07783",
    "title": "Future Video Prediction from a Single Frame for Video Anomaly Detection",
    "abstract": "Video anomaly detection (VAD) is an important but challenging task in computer vision. The main challenge rises due to the rarity of training samples to model all anomaly cases. Hence, semi-supervised anomaly detection methods have gotten more attention, since they focus on modeling normals and they detect anomalies by measuring the deviations from normal patterns. Despite impressive advances of these methods in modeling normal motion and appearance, long-term motion modeling has not been effectively explored so far. Inspired by the abilities of the future frame prediction proxy-task, we introduce the task of future video prediction from a single frame, as a novel proxy-task for video anomaly detection. This proxy-task alleviates the challenges of previous methods in learning longer motion patterns. Moreover, we replace the initial and future raw frames with their corresponding semantic segmentation map, which not only makes the method aware of object class but also makes the prediction task less complex for the model. Extensive experiments on the benchmark datasets (ShanghaiTech, UCSD-Ped1, and UCSD-Ped2) show the effectiveness of the method and the superiority of its performance compared to SOTA prediction-based VAD methods. ",
    "url": "https://arxiv.org/abs/2308.07783",
    "authors": [
      "Mohammad Baradaran",
      "Robert Bergevin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07787",
    "title": "DiffV2S: Diffusion-based Video-to-Speech Synthesis with Vision-guided  Speaker Embedding",
    "abstract": "Recent research has demonstrated impressive results in video-to-speech synthesis which involves reconstructing speech solely from visual input. However, previous works have struggled to accurately synthesize speech due to a lack of sufficient guidance for the model to infer the correct content with the appropriate sound. To resolve the issue, they have adopted an extra speaker embedding as a speaking style guidance from a reference auditory information. Nevertheless, it is not always possible to obtain the audio information from the corresponding video input, especially during the inference time. In this paper, we present a novel vision-guided speaker embedding extractor using a self-supervised pre-trained model and prompt tuning technique. In doing so, the rich speaker embedding information can be produced solely from input visual information, and the extra audio information is not necessary during the inference time. Using the extracted vision-guided speaker embedding representations, we further develop a diffusion-based video-to-speech synthesis model, so called DiffV2S, conditioned on those speaker embeddings and the visual representation extracted from the input video. The proposed DiffV2S not only maintains phoneme details contained in the input video frames, but also creates a highly intelligible mel-spectrogram in which the speaker identities of the multiple speakers are all preserved. Our experimental results show that DiffV2S achieves the state-of-the-art performance compared to the previous video-to-speech synthesis technique. ",
    "url": "https://arxiv.org/abs/2308.07787",
    "authors": [
      "Jeongsoo Choi",
      "Joanna Hong",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.07793",
    "title": "Robust Indexing for the Sliced Channel: Almost Optimal Codes for  Substitutions and Deletions",
    "abstract": "Encoding data as a set of unordered strings is receiving great attention as it captures one of the basic features of DNA storage systems. However, the challenge of constructing optimal redundancy codes for this channel remained elusive. In this paper, we address this problem and present an order-wise optimal construction of codes that are capable of correcting multiple substitution, deletion, and insertion errors for this channel model. The key ingredient in the code construction is a technique we call robust indexing: simultaneously assigning indices to unordered strings (hence, creating order) and also embedding information in these indices. The encoded indices are resilient to substitution, deletion, and insertion errors, and therefore, so is the entire code. ",
    "url": "https://arxiv.org/abs/2308.07793",
    "authors": [
      "Jin Sima",
      "Netanel Raviv",
      "Jehoshua Bruck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.07802",
    "title": "Neuromorphic Seatbelt State Detection for In-Cabin Monitoring with Event  Cameras",
    "abstract": "Neuromorphic vision sensors, or event cameras, differ from conventional cameras in that they do not capture images at a specified rate. Instead, they asynchronously log local brightness changes at each pixel. As a result, event cameras only record changes in a given scene, and do so with very high temporal resolution, high dynamic range, and low power requirements. Recent research has demonstrated how these characteristics make event cameras extremely practical sensors in driver monitoring systems (DMS), enabling the tracking of high-speed eye motion and blinks. This research provides a proof of concept to expand event-based DMS techniques to include seatbelt state detection. Using an event simulator, a dataset of 108,691 synthetic neuromorphic frames of car occupants was generated from a near-infrared (NIR) dataset, and split into training, validation, and test sets for a seatbelt state detection algorithm based on a recurrent convolutional neural network (CNN). In addition, a smaller set of real event data was collected and reserved for testing. In a binary classification task, the fastened/unfastened frames were identified with an F1 score of 0.989 and 0.944 on the simulated and real test sets respectively. When the problem extended to also classify the action of fastening/unfastening the seatbelt, respective F1 scores of 0.964 and 0.846 were achieved. ",
    "url": "https://arxiv.org/abs/2308.07802",
    "authors": [
      "Paul Kielty",
      "Cian Ryan",
      "Mehdi Sefidgar Dilmaghani",
      "Waseem Shariff",
      "Joe Lemley",
      "Peter Corcoran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07805",
    "title": "Fairness and Privacy in Federated Learning and Their Implications in  Healthcare",
    "abstract": "Currently, many contexts exist where distributed learning is difficult or otherwise constrained by security and communication limitations. One common domain where this is a consideration is in Healthcare where data is often governed by data-use-ordinances like HIPAA. On the other hand, larger sample sizes and shared data models are necessary to allow models to better generalize on account of the potential for more variability and balancing underrepresented classes. Federated learning is a type of distributed learning model that allows data to be trained in a decentralized manner. This, in turn, addresses data security, privacy, and vulnerability considerations as data itself is not shared across a given learning network nodes. Three main challenges to federated learning include node data is not independent and identically distributed (iid), clients requiring high levels of communication overhead between peers, and there is the heterogeneity of different clients within a network with respect to dataset bias and size. As the field has grown, the notion of fairness in federated learning has also been introduced through novel implementations. Fairness approaches differ from the standard form of federated learning and also have distinct challenges and considerations for the healthcare domain. This paper endeavors to outline the typical lifecycle of fair federated learning in research as well as provide an updated taxonomy to account for the current state of fairness in implementations. Lastly, this paper provides added insight into the implications and challenges of implementing and supporting fairness in federated learning in the healthcare domain. ",
    "url": "https://arxiv.org/abs/2308.07805",
    "authors": [
      "Navya Annapareddy",
      "Jade Preston",
      "Judy Fox"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07824",
    "title": "Cerberus: A Deep Learning Hybrid Model for Lithium-Ion Battery Aging  Estimation and Prediction Based on Relaxation Voltage Curves",
    "abstract": "The degradation process of lithium-ion batteries is intricately linked to their entire lifecycle as power sources and energy storage devices, encompassing aspects such as performance delivery and cycling utilization. Consequently, the accurate and expedient estimation or prediction of the aging state of lithium-ion batteries has garnered extensive attention. Nonetheless, prevailing research predominantly concentrates on either aging estimation or prediction, neglecting the dynamic fusion of both facets. This paper proposes a hybrid model for capacity aging estimation and prediction based on deep learning, wherein salient features highly pertinent to aging are extracted from charge and discharge relaxation processes. By amalgamating historical capacity decay data, the model dynamically furnishes estimations of the present capacity and forecasts of future capacity for lithium-ion batteries. Our approach is validated against a novel dataset involving charge and discharge cycles at varying rates. Specifically, under a charging condition of 0.25C, a mean absolute percentage error (MAPE) of 0.29% is achieved. This outcome underscores the model's adeptness in harnessing relaxation processes commonly encountered in the real world and synergizing with historical capacity records within battery management systems (BMS), thereby affording estimations and prognostications of capacity decline with heightened precision. ",
    "url": "https://arxiv.org/abs/2308.07824",
    "authors": [
      "Yue Xiang",
      "Bo Jiang",
      "Haifeng Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07834",
    "title": "Simple and Efficient Partial Graph Adversarial Attack: A New Perspective",
    "abstract": "As the study of graph neural networks becomes more intensive and comprehensive, their robustness and security have received great research interest. The existing global attack methods treat all nodes in the graph as their attack targets. Although existing methods have achieved excellent results, there is still considerable space for improvement. The key problem is that the current approaches rigidly follow the definition of global attacks. They ignore an important issue, i.e., different nodes have different robustness and are not equally resilient to attacks. From a global attacker's view, we should arrange the attack budget wisely, rather than wasting them on highly robust nodes. To this end, we propose a totally new method named partial graph attack (PGA), which selects the vulnerable nodes as attack targets. First, to select the vulnerable items, we propose a hierarchical target selection policy, which allows attackers to only focus on easy-to-attack nodes. Then, we propose a cost-effective anchor-picking policy to pick the most promising anchors for adding or removing edges, and a more aggressive iterative greedy-based attack method to perform more efficient attacks. Extensive experimental results demonstrate that PGA can achieve significant improvements in both attack effect and attack efficiency compared to other existing graph global attack methods. ",
    "url": "https://arxiv.org/abs/2308.07834",
    "authors": [
      "Guanghui Zhu",
      "Mengyu Chen",
      "Chunfeng Yuan",
      "Yihua Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.07847",
    "title": "Robustness Over Time: Understanding Adversarial Examples' Effectiveness  on Longitudinal Versions of Large Language Models",
    "abstract": "Large Language Models (LLMs) have led to significant improvements in many tasks across various domains, such as code interpretation, response generation, and ambiguity handling. These LLMs, however, when upgrading, primarily prioritize enhancing user experience while neglecting security, privacy, and safety implications. Consequently, unintended vulnerabilities or biases can be introduced. Previous studies have predominantly focused on specific versions of the models and disregard the potential emergence of new attack vectors targeting the updated versions. Through the lens of adversarial examples within the in-context learning framework, this longitudinal study addresses this gap by conducting a comprehensive assessment of the robustness of successive versions of LLMs, vis-\\`a-vis GPT-3.5. We conduct extensive experiments to analyze and understand the impact of the robustness in two distinct learning categories: zero-shot learning and few-shot learning. Our findings indicate that, in comparison to earlier versions of LLMs, the updated versions do not exhibit the anticipated level of robustness against adversarial attacks. In addition, our study emphasizes the increased effectiveness of synergized adversarial queries in most zero-shot learning and few-shot learning cases. We hope that our study can lead to a more refined assessment of the robustness of LLMs over time and provide valuable insights of these models for both developers and users. ",
    "url": "https://arxiv.org/abs/2308.07847",
    "authors": [
      "Yugeng Liu",
      "Tianshuo Cong",
      "Zhengyu Zhao",
      "Michael Backes",
      "Yun Shen",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.07868",
    "title": "ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces",
    "abstract": "In recent years, neural implicit surface reconstruction has emerged as a popular paradigm for multi-view 3D reconstruction. Unlike traditional multi-view stereo approaches, the neural implicit surface-based methods leverage neural networks to represent 3D scenes as signed distance functions (SDFs). However, they tend to disregard the reconstruction of individual objects within the scene, which limits their performance and practical applications. To address this issue, previous work ObjectSDF introduced a nice framework of object-composition neural implicit surfaces, which utilizes 2D instance masks to supervise individual object SDFs. In this paper, we propose a new framework called ObjectSDF++ to overcome the limitations of ObjectSDF. First, in contrast to ObjectSDF whose performance is primarily restricted by its converted semantic field, the core component of our model is an occlusion-aware object opacity rendering formulation that directly volume-renders object opacity to be supervised with instance masks. Second, we design a novel regularization term for object distinction, which can effectively mitigate the issue that ObjectSDF may result in unexpected reconstruction in invisible regions due to the lack of constraint to prevent collisions. Our extensive experiments demonstrate that our novel framework not only produces superior object reconstruction results but also significantly improves the quality of scene reconstruction. Code and more resources can be found in \\url{https://qianyiwu.github.io/objectsdf++} ",
    "url": "https://arxiv.org/abs/2308.07868",
    "authors": [
      "Qianyi Wu",
      "Kaisiyuan Wang",
      "Kejie Li",
      "Jianmin Zheng",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07871",
    "title": "Emotion Embeddings $\\unicode{x2014}$ Learning Stable and Homogeneous  Abstractions from Heterogeneous Affective Datasets",
    "abstract": "Human emotion is expressed in many communication modalities and media formats and so their computational study is equally diversified into natural language processing, audio signal analysis, computer vision, etc. Similarly, the large variety of representation formats used in previous research to describe emotions (polarity scales, basic emotion categories, dimensional approaches, appraisal theory, etc.) have led to an ever proliferating diversity of datasets, predictive models, and software tools for emotion analysis. Because of these two distinct types of heterogeneity, at the expressional and representational level, there is a dire need to unify previous work on increasingly diverging data and label types. This article presents such a unifying computational model. We propose a training procedure that learns a shared latent representation for emotions, so-called emotion embeddings, independent of different natural languages, communication modalities, media or representation label formats, and even disparate model architectures. Experiments on a wide range of heterogeneous affective datasets indicate that this approach yields the desired interoperability for the sake of reusability, interpretability and flexibility, without penalizing prediction quality. Code and data are archived under https://doi.org/10.5281/zenodo.7405327 . ",
    "url": "https://arxiv.org/abs/2308.07871",
    "authors": [
      "Sven Buechel",
      "Udo Hahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07874",
    "title": "SEDA: Self-Ensembling ViT with Defensive Distillation and Adversarial  Training for robust Chest X-rays Classification",
    "abstract": "Deep Learning methods have recently seen increased adoption in medical imaging applications. However, elevated vulnerabilities have been explored in recent Deep Learning solutions, which can hinder future adoption. Particularly, the vulnerability of Vision Transformer (ViT) to adversarial, privacy, and confidentiality attacks raise serious concerns about their reliability in medical settings. This work aims to enhance the robustness of self-ensembling ViTs for the tuberculosis chest x-ray classification task. We propose Self-Ensembling ViT with defensive Distillation and Adversarial training (SEDA). SEDA utilizes efficient CNN blocks to learn spatial features with various levels of abstraction from feature representations extracted from intermediate ViT blocks, that are largely unaffected by adversarial perturbations. Furthermore, SEDA leverages adversarial training in combination with defensive distillation for improved robustness against adversaries. Training using adversarial examples leads to better model generalizability and improves its ability to handle perturbations. Distillation using soft probabilities introduces uncertainty and variation into the output probabilities, making it more difficult for adversarial and privacy attacks. Extensive experiments performed with the proposed architecture and training paradigm on publicly available Tuberculosis x-ray dataset shows SOTA efficacy of SEDA compared to SEViT in terms of computational efficiency with 70x times lighter framework and enhanced robustness of +9%. ",
    "url": "https://arxiv.org/abs/2308.07874",
    "authors": [
      "Raza Imam",
      "Ibrahim Almakky",
      "Salma Alrashdi",
      "Baketah Alrashdi",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07889",
    "title": "A Comprehensive Study on Knowledge Graph Embedding over Relational  Patterns Based on Rule Learning",
    "abstract": "Knowledge Graph Embedding (KGE) has proven to be an effective approach to solving the Knowledge Graph Completion (KGC) task. Relational patterns which refer to relations with specific semantics exhibiting graph patterns are an important factor in the performance of KGE models. Though KGE models' capabilities are analyzed over different relational patterns in theory and a rough connection between better relational patterns modeling and better performance of KGC has been built, a comprehensive quantitative analysis on KGE models over relational patterns remains absent so it is uncertain how the theoretical support of KGE to a relational pattern contributes to the performance of triples associated to such a relational pattern. To address this challenge, we evaluate the performance of 7 KGE models over 4 common relational patterns on 2 benchmarks, then conduct an analysis in theory, entity frequency, and part-to-whole three aspects and get some counterintuitive conclusions. Finally, we introduce a training-free method Score-based Patterns Adaptation (SPA) to enhance KGE models' performance over various relational patterns. This approach is simple yet effective and can be applied to KGE models without additional training. Our experimental results demonstrate that our method generally enhances performance over specific relational patterns. Our source code is available from GitHub at https://github.com/zjukg/Comprehensive-Study-over-Relational-Patterns. ",
    "url": "https://arxiv.org/abs/2308.07889",
    "authors": [
      "Long Jin",
      "Zhen Yao",
      "Mingyang Chen",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.07895",
    "title": "Roses Have Thorns: Understanding the Downside of Oncological Care  Delivery Through Visual Analytics and Sequential Rule Mining",
    "abstract": "Personalized head and neck cancer therapeutics have greatly improved survival rates for patients, but are often leading to understudied long-lasting symptoms which affect quality of life. Sequential rule mining (SRM) is a promising unsupervised machine learning method for predicting longitudinal patterns in temporal data which, however, can output many repetitive patterns that are difficult to interpret without the assistance of visual analytics. We present a data-driven, human-machine analysis visual system developed in collaboration with SRM model builders in cancer symptom research, which facilitates mechanistic knowledge discovery in large scale, multivariate cohort symptom data. Our system supports multivariate predictive modeling of post-treatment symptoms based on during-treatment symptoms. It supports this goal through an SRM, clustering, and aggregation back end, and a custom front end to help develop and tune the predictive models. The system also explains the resulting predictions in the context of therapeutic decisions typical in personalized care delivery. We evaluate the resulting models and system with an interdisciplinary group of modelers and head and neck oncology researchers. The results demonstrate that our system effectively supports clinical and symptom research. ",
    "url": "https://arxiv.org/abs/2308.07895",
    "authors": [
      "Carla Floricel",
      "Andrew Wentzel",
      "Abdallah Mohamed",
      "C.David Fuller",
      "Guadalupe Canahuate",
      "G. Elisabeta Marai"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.07903",
    "title": "Relightable and Animatable Neural Avatar from Sparse-View Video",
    "abstract": "This paper tackles the challenge of creating relightable and animatable neural avatars from sparse-view (or even monocular) videos of dynamic humans under unknown illumination. Compared to studio environments, this setting is more practical and accessible but poses an extremely challenging ill-posed problem. Previous neural human reconstruction methods are able to reconstruct animatable avatars from sparse views using deformed Signed Distance Fields (SDF) but cannot recover material parameters for relighting. While differentiable inverse rendering-based methods have succeeded in material recovery of static objects, it is not straightforward to extend them to dynamic humans as it is computationally intensive to compute pixel-surface intersection and light visibility on deformed SDFs for inverse rendering. To solve this challenge, we propose a Hierarchical Distance Query (HDQ) algorithm to approximate the world space distances under arbitrary human poses. Specifically, we estimate coarse distances based on a parametric human model and compute fine distances by exploiting the local deformation invariance of SDF. Based on the HDQ algorithm, we leverage sphere tracing to efficiently estimate the surface intersection and light visibility. This allows us to develop the first system to recover animatable and relightable neural avatars from sparse view (or monocular) inputs. Experiments demonstrate that our approach is able to produce superior results compared to state-of-the-art methods. Our code will be released for reproducibility. ",
    "url": "https://arxiv.org/abs/2308.07903",
    "authors": [
      "Zhen Xu",
      "Sida Peng",
      "Chen Geng",
      "Linzhan Mou",
      "Zihan Yan",
      "Jiaming Sun",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.07921",
    "title": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with  Code-based Self-Verification",
    "abstract": "Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has brought significant advancements in addressing math reasoning problems. In particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter, shows remarkable performance on challenging math datasets. In this paper, we explore the effect of code on enhancing LLMs' reasoning capability by introducing different constraints on the \\textit{Code Usage Frequency} of GPT-4 Code Interpreter. We found that its success can be largely attributed to its powerful skills in generating and executing code, evaluating the output of code execution, and rectifying its solution when receiving unreasonable outputs. Based on this insight, we propose a novel and effective prompting method, explicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further boost the mathematical reasoning potential of GPT-4 Code Interpreter. This method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to use code to self-verify its answers. In instances where the verification state registers as ``False'', the model shall automatically amend its solution, analogous to our approach of rectifying errors during a mathematics examination. Furthermore, we recognize that the states of the verification result indicate the confidence of a solution, which can improve the effectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we achieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$ 84.3\\%)}. ",
    "url": "https://arxiv.org/abs/2308.07921",
    "authors": [
      "Aojun Zhou",
      "Ke Wang",
      "Zimu Lu",
      "Weikang Shi",
      "Sichun Luo",
      "Zipeng Qin",
      "Shaoqing Lu",
      "Anya Jia",
      "Linqi Song",
      "Mingjie Zhan",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07925",
    "title": "Domain-Adaptive Device Fingerprints for Network Access Authentication  Through Multifractal Dimension Representation",
    "abstract": "RF data-driven device fingerprinting through the use of deep learning has recently surfaced as a potential solution for automated network access authentication. Traditional approaches are commonly susceptible to the domain adaptation problem where a model trained on data from one domain performs badly when tested on data from a different domain. Some examples of a domain change include varying the device location or environment and varying the time or day of data collection. In this work, we propose using multifractal analysis and the variance fractal dimension trajectory (VFDT) as a data representation input to the deep neural network to extract device fingerprints that are domain generalizable. We analyze the effectiveness of the proposed VFDT representation in detecting device-specific signatures from hardware-impaired IQ signals, and evaluate its robustness in real-world settings, using an experimental testbed of 30 WiFi-enabled Pycom devices under different locations and at different scales. Our results show that the VFDT representation improves the scalability, robustness and generalizability of the deep learning models significantly compared to when using raw IQ data. ",
    "url": "https://arxiv.org/abs/2308.07925",
    "authors": [
      "Benjamin Johnson",
      "Bechir Hamdaoui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.07324",
    "title": "Redesigning Out-of-Distribution Detection on 3D Medical Images",
    "abstract": "Detecting out-of-distribution (OOD) samples for trusted medical image segmentation remains a significant challenge. The critical issue here is the lack of a strict definition of abnormal data, which often results in artificial problem settings without measurable clinical impact. In this paper, we redesign the OOD detection problem according to the specifics of volumetric medical imaging and related downstream tasks (e.g., segmentation). We propose using the downstream model's performance as a pseudometric between images to define abnormal samples. This approach enables us to weigh different samples based on their performance impact without an explicit ID/OOD distinction. We incorporate this weighting in a new metric called Expected Performance Drop (EPD). EPD is our core contribution to the new problem design, allowing us to rank methods based on their clinical impact. We demonstrate the effectiveness of EPD-based evaluation in 11 CT and MRI OOD detection challenges. ",
    "url": "https://arxiv.org/abs/2308.07324",
    "authors": [
      "Anton Vasiliuk",
      "Daria Frolova",
      "Mikhail Belyaev",
      "Boris Shirokikh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07520",
    "title": "Nonlinearity, Feedback and Uniform Consistency in Causal Structural  Learning",
    "abstract": "The goal of Causal Discovery is to find automated search methods for learning causal structures from observational data. In some cases all variables of the interested causal mechanism are measured, and the task is to predict the effects one measured variable has on another. In contrast, sometimes the variables of primary interest are not directly observable but instead inferred from their manifestations in the data. These are referred to as latent variables. One commonly known example is the psychological construct of intelligence, which cannot directly measured so researchers try to assess through various indicators such as IQ tests. In this case, casual discovery algorithms can uncover underlying patterns and structures to reveal the causal connections between the latent variables and between the latent and observed variables. This thesis focuses on two questions in causal discovery: providing an alternative definition of k-Triangle Faithfulness that (i) is weaker than strong faithfulness when applied to the Gaussian family of distributions, (ii) can be applied to non-Gaussian families of distributions, and (iii) under the assumption that the modified version of Strong Faithfulness holds, can be used to show the uniform consistency of a modified causal discovery algorithm; relaxing the sufficiency assumption to learn causal structures with latent variables. Given the importance of inferring cause-and-effect relationships for understanding and forecasting complex systems, the work in this thesis of relaxing various simplification assumptions is expected to extend the causal discovery method to be applicable in a wider range with diversified causal mechanism and statistical phenomena. ",
    "url": "https://arxiv.org/abs/2308.07520",
    "authors": [
      "Shuyan Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07523",
    "title": "Potential of Deep Operator Networks in Digital Twin-enabling Technology  for Nuclear System",
    "abstract": "This research introduces the Deep Operator Network (DeepONet) as a robust surrogate modeling method within the context of digital twin (DT) systems for nuclear engineering. With the increasing importance of nuclear energy as a carbon-neutral solution, adopting DT technology has become crucial to enhancing operational efficiencies, safety, and predictive capabilities in nuclear engineering applications. DeepONet exhibits remarkable prediction accuracy, outperforming traditional ML methods. Through extensive benchmarking and evaluation, this study showcases the scalability and computational efficiency of DeepONet in solving a challenging particle transport problem. By taking functions as input data and constructing the operator $G$ from training data, DeepONet can handle diverse and complex scenarios effectively. However, the application of DeepONet also reveals challenges related to optimal sensor placement and model evaluation, critical aspects of real-world implementation. Addressing these challenges will further enhance the method's practicality and reliability. Overall, DeepONet presents a promising and transformative tool for nuclear engineering research and applications. Its accurate prediction and computational efficiency capabilities can revolutionize DT systems, advancing nuclear engineering research. This study marks an important step towards harnessing the power of surrogate modeling techniques in critical engineering domains. ",
    "url": "https://arxiv.org/abs/2308.07523",
    "authors": [
      "Kazuma Kobayashi",
      "Syed Bahauddin Alam"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2308.07573",
    "title": "Synthetic data generation method for hybrid image-tabular data using two  generative adversarial networks",
    "abstract": "The generation of synthetic medical records using generative adversarial networks (GANs) has become increasingly important for addressing privacy concerns and promoting data sharing in the medical field. In this paper, we propose a novel method for generating synthetic hybrid medical records consisting of chest X-ray images (CXRs) and structured tabular data (including anthropometric data and laboratory tests) using an auto-encoding GAN ({\\alpha}GAN) and a conditional tabular GAN (CTGAN). Our approach involves training a {\\alpha}GAN model on a large public database (pDB) to reduce the dimensionality of CXRs. We then applied the trained encoder of the GAN model to the images in original database (oDB) to obtain the latent vectors. These latent vectors were combined with tabular data in oDB, and these joint data were used to train the CTGAN model. We successfully generated diverse synthetic records of hybrid CXR and tabular data, maintaining correspondence between them. We evaluated this synthetic database (sDB) through visual assessment, distribution of interrecord distances, and classification tasks. Our evaluation results showed that the sDB captured the features of the oDB while maintaining the correspondence between the images and tabular data. Although our approach relies on the availability of a large-scale pDB containing a substantial number of images with the same modality and imaging region as those in the oDB, this method has the potential for the public release of synthetic datasets without compromising the secondary use of data. ",
    "url": "https://arxiv.org/abs/2308.07573",
    "authors": [
      "Tomohiro Kikuchi",
      "Shouhei Hanaoka",
      "Takahiro Nakao",
      "Tomomi Takenaga",
      "Yukihiro Nomura",
      "Harushi Mori",
      "Takeharu Yoshikawa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07604",
    "title": "Searching for Novel Chemistry in Exoplanetary Atmospheres using Machine  Learning for Anomaly Detection",
    "abstract": "The next generation of telescopes will yield a substantial increase in the availability of high-resolution spectroscopic data for thousands of exoplanets. The sheer volume of data and number of planets to be analyzed greatly motivate the development of new, fast and efficient methods for flagging interesting planets for reobservation and detailed analysis. We advocate the application of machine learning (ML) techniques for anomaly (novelty) detection to exoplanet transit spectra, with the goal of identifying planets with unusual chemical composition and even searching for unknown biosignatures. We successfully demonstrate the feasibility of two popular anomaly detection methods (Local Outlier Factor and One Class Support Vector Machine) on a large public database of synthetic spectra. We consider several test cases, each with different levels of instrumental noise. In each case, we use ROC curves to quantify and compare the performance of the two ML techniques. ",
    "url": "https://arxiv.org/abs/2308.07604",
    "authors": [
      "Roy T. Forestano",
      "Konstantin T. Matchev",
      "Katia Matcheva",
      "Eyup B. Unlu"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2308.07688",
    "title": "Enhancing Network Initialization for Medical AI Models Using  Large-Scale, Unlabeled Natural Images",
    "abstract": "Pre-training datasets, like ImageNet, have become the gold standard in medical image analysis. However, the emergence of self-supervised learning (SSL), which leverages unlabeled data to learn robust features, presents an opportunity to bypass the intensive labeling process. In this study, we explored if SSL for pre-training on non-medical images can be applied to chest radiographs and how it compares to supervised pre-training on non-medical images and on medical images. We utilized a vision transformer and initialized its weights based on (i) SSL pre-training on natural images (DINOv2), (ii) SL pre-training on natural images (ImageNet dataset), and (iii) SL pre-training on chest radiographs from the MIMIC-CXR database. We tested our approach on over 800,000 chest radiographs from six large global datasets, diagnosing more than 20 different imaging findings. Our SSL pre-training on curated images not only outperformed ImageNet-based pre-training (P<0.001 for all datasets) but, in certain cases, also exceeded SL on the MIMIC-CXR dataset. Our findings suggest that selecting the right pre-training strategy, especially with SSL, can be pivotal for improving artificial intelligence (AI)'s diagnostic accuracy in medical imaging. By demonstrating the promise of SSL in chest radiograph analysis, we underline a transformative shift towards more efficient and accurate AI models in medical imaging. ",
    "url": "https://arxiv.org/abs/2308.07688",
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Leo Misera",
      "Jakob Nikolas Kather",
      "Daniel Truhn",
      "Sven Nebelung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07733",
    "title": "Dynamic Low-Rank Instance Adaptation for Universal Neural Image  Compression",
    "abstract": "The latest advancements in neural image compression show great potential in surpassing the rate-distortion performance of conventional standard codecs. Nevertheless, there exists an indelible domain gap between the datasets utilized for training (i.e., natural images) and those utilized for inference (e.g., artistic images). Our proposal involves a low-rank adaptation approach aimed at addressing the rate-distortion drop observed in out-of-domain datasets. Specifically, we perform low-rank matrix decomposition to update certain adaptation parameters of the client's decoder. These updated parameters, along with image latents, are encoded into a bitstream and transmitted to the decoder in practical scenarios. Due to the low-rank constraint imposed on the adaptation parameters, the resulting bit rate overhead is small. Furthermore, the bit rate allocation of low-rank adaptation is \\emph{non-trivial}, considering the diverse inputs require varying adaptation bitstreams. We thus introduce a dynamic gating network on top of the low-rank adaptation method, in order to decide which decoder layer should employ adaptation. The dynamic adaptation network is optimized end-to-end using rate-distortion loss. Our proposed method exhibits universality across diverse image datasets. Extensive results demonstrate that this paradigm significantly mitigates the domain gap, surpassing non-adaptive methods with an average BD-rate improvement of approximately $19\\%$ across out-of-domain images. Furthermore, it outperforms the most advanced instance adaptive methods by roughly $5\\%$ BD-rate. Ablation studies confirm our method's ability to universally enhance various image compression architectures. ",
    "url": "https://arxiv.org/abs/2308.07733",
    "authors": [
      "Yue Lv",
      "Jinxi Xiang",
      "Jun Zhang",
      "Wenming Yang",
      "Xiao Han",
      "Wei Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2007.06066",
    "title": "The linear arboricity conjecture for graphs of low degeneracy",
    "abstract": " Comments: 20 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2007.06066",
    "authors": [
      "Manu Basavaraju",
      "Arijit Bishnu",
      "Mathew Francis",
      "Drimit Pattanayak"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2106.03107",
    "title": "Approximation Algorithms for Min-max-min Robust Optimization and  K-Adaptability under Objective Uncertainty",
    "abstract": " Comments: This is a completely revised version of my previous preprint \"New complexity results and algorithms for min-max-min robust combinatorial optimization\". Some results were removed while several new results were added ",
    "url": "https://arxiv.org/abs/2106.03107",
    "authors": [
      "Jannis Kurtz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2106.14136",
    "title": "Text-to-Audio based Event Detection Towards Intelligent Vehicle Road  Cooperation",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2106.14136",
    "authors": [
      "Haoyu Tang",
      "Yunxiao Wang",
      "Jihua Zhu",
      "Shuaike Zhang",
      "Mingzhu Xu",
      "Yupeng Hu",
      "Qinghai Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2109.01303",
    "title": "Self-supervised Pseudo Multi-class Pre-training for Unsupervised Anomaly  Detection and Segmentation in Medical Images",
    "abstract": " Comments: Accepted to Medical Image Analysis ",
    "url": "https://arxiv.org/abs/2109.01303",
    "authors": [
      "Yu Tian",
      "Fengbei Liu",
      "Guansong Pang",
      "Yuanhong Chen",
      "Yuyuan Liu",
      "Johan W. Verjans",
      "Rajvinder Singh",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.04513",
    "title": "Clustering and Structural Robustness in Causal Diagrams",
    "abstract": " Comments: This is the version published in JMLR ",
    "url": "https://arxiv.org/abs/2111.04513",
    "authors": [
      "Santtu Tikka",
      "Jouni Helske",
      "Juha Karvanen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.10066",
    "title": "Multi-task Representation Learning with Stochastic Linear Bandits",
    "abstract": " Title: Multi-task Representation Learning with Stochastic Linear Bandits ",
    "url": "https://arxiv.org/abs/2202.10066",
    "authors": [
      "Leonardo Cella",
      "Karim Lounici",
      "Gr\u00e9goire Pacreau",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12391",
    "title": "SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and  Boosting Segmentation Robustness",
    "abstract": " Title: SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and  Boosting Segmentation Robustness ",
    "url": "https://arxiv.org/abs/2207.12391",
    "authors": [
      "Jindong Gu",
      "Hengshuang Zhao",
      "Volker Tresp",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.00992",
    "title": "Feature Embedding by Template Matching as a ResNet Block",
    "abstract": " Comments: Accepted at the British Machine Vision Conference 2022 (BMVC 2022) ",
    "url": "https://arxiv.org/abs/2210.00992",
    "authors": [
      "Ada Gorgun",
      "Yeti Z. Gurbuz",
      "A. Aydin Alatan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.11317",
    "title": "End-to-end AI framework for interpretable prediction of molecular and  crystal properties",
    "abstract": " Comments: 20 pages, 10 images, 6 tables; v2: accepted to Machine Learning: Science and Technology ",
    "url": "https://arxiv.org/abs/2212.11317",
    "authors": [
      "Hyun Park",
      "Ruijie Zhu",
      "E. A. Huerta",
      "Santanu Chaudhuri",
      "Emad Tajkhorshid",
      "Donny Cooper"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.11944",
    "title": "Bridge Girth: A Unifying Notion in Network Design",
    "abstract": " Title: Bridge Girth: A Unifying Notion in Network Design ",
    "url": "https://arxiv.org/abs/2212.11944",
    "authors": [
      "Greg Bodwin",
      "Gary Hoppenworth",
      "Ohad Trabelsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2301.04900",
    "title": "A Recipe for Well-behaved Graph Neural Approximations of Complex  Dynamics",
    "abstract": " Title: A Recipe for Well-behaved Graph Neural Approximations of Complex  Dynamics ",
    "url": "https://arxiv.org/abs/2301.04900",
    "authors": [
      "Vaiva Vasiliauskaite",
      "Nino Antulov-Fantulin"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.00988",
    "title": "HaMuCo: Hand Pose Estimation via Multiview Collaborative Self-Supervised  Learning",
    "abstract": " Comments: Accepted to ICCV 2023. Won first place in the HANDS22 Challenge Task 2. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2302.00988",
    "authors": [
      "Xiaozheng Zheng",
      "Chao Wen",
      "Zhou Xue",
      "Pengfei Ren",
      "Jingyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03224",
    "title": "Undersampling and Cumulative Class Re-decision Methods to Improve  Detection of Agitation in People with Dementia",
    "abstract": " Comments: 19 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2302.03224",
    "authors": [
      "Zhidong Meng",
      "Andrea Iaboni",
      "Bing Ye",
      "Kristine Newman",
      "Alex Mihailidis",
      "Zhihong Deng",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.06433",
    "title": "Label-efficient Time Series Representation Learning: A Review",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2302.06433",
    "authors": [
      "Emadeldeen Eldele",
      "Mohamed Ragab",
      "Zhenghua Chen",
      "Min Wu",
      "Chee-Keong Kwoh",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.08612",
    "title": "Robust expected improvement for Bayesian optimization",
    "abstract": " Comments: 27 pages, 17 figures, 1 table ",
    "url": "https://arxiv.org/abs/2302.08612",
    "authors": [
      "Ryan B. Christianson",
      "Robert B. Gramacy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.12449",
    "title": "SGL-PT: A Strong Graph Learner with Graph Prompt Tuning",
    "abstract": " Title: SGL-PT: A Strong Graph Learner with Graph Prompt Tuning ",
    "url": "https://arxiv.org/abs/2302.12449",
    "authors": [
      "Yun Zhu",
      "Jianhao Guo",
      "Siliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.14061",
    "title": "Semantic-aware Node Synthesis for Imbalanced Heterogeneous Information  Networks",
    "abstract": " Title: Semantic-aware Node Synthesis for Imbalanced Heterogeneous Information  Networks ",
    "url": "https://arxiv.org/abs/2302.14061",
    "authors": [
      "Xinyi Gao",
      "Wentao Zhang",
      "Tong Chen",
      "Junliang Yu",
      "Hung Quoc Viet Nguyen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03048",
    "title": "Graph-based View Motion Planning for Fruit Detection",
    "abstract": " Comments: 7 pages, 10 figures, accepted at IROS 2023 ",
    "url": "https://arxiv.org/abs/2303.03048",
    "authors": [
      "Tobias Zaenker",
      "Julius R\u00fcckin",
      "Rohit Menon",
      "Marija Popovi\u0107",
      "Maren Bennewitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05408",
    "title": "Fast algorithms for Vizing's theorem on bounded degree graphs",
    "abstract": " Comments: 42 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2303.05408",
    "authors": [
      "Anton Bernshteyn",
      "Abhishek Dhawan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.10625",
    "title": "Finite element discretization of a biological network formation system:  a preliminary study",
    "abstract": " Comments: 11 pages, 3 figures, 18 plots, 2 tables ",
    "url": "https://arxiv.org/abs/2303.10625",
    "authors": [
      "Clarissa Astuto",
      "Daniele Boffi",
      "Fabio Credali"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.12398",
    "title": "Multiscale Attention via Wavelet Neural Operators for Vision  Transformers",
    "abstract": " Title: Multiscale Attention via Wavelet Neural Operators for Vision  Transformers ",
    "url": "https://arxiv.org/abs/2303.12398",
    "authors": [
      "Anahita Nekoozadeh",
      "Mohammad Reza Ahmadzadeh",
      "Zahra Mardani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11463",
    "title": "OmniLabel: A Challenging Benchmark for Language-Based Object Detection",
    "abstract": " Comments: ICCV 2023 Oral - Visit our project website at this https URL ",
    "url": "https://arxiv.org/abs/2304.11463",
    "authors": [
      "Samuel Schulter",
      "Vijay Kumar B G",
      "Yumin Suh",
      "Konstantinos M. Dafnis",
      "Zhixing Zhang",
      "Shiyu Zhao",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10704",
    "title": "Attention-based Encoder-Decoder Network for End-to-End Neural Speaker  Diarization with Target Speaker Attractor",
    "abstract": " Comments: Accepted by InterSpeech 2023 ",
    "url": "https://arxiv.org/abs/2305.10704",
    "authors": [
      "Zhengyang Chen",
      "Bing Han",
      "Shuai Wang",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.00316",
    "title": "Using Genetic Programming to Build Self-Adaptivity into Software-Defined  Networks",
    "abstract": " Comments: Accepted for publication by ACM Transactions on Autonomous and Adaptive Systems (TAAS) (in Aug 2023). arXiv admin note: substantial text overlap with arXiv:2205.04352 ",
    "url": "https://arxiv.org/abs/2306.00316",
    "authors": [
      "Jia Li",
      "Shiva Nejati",
      "Mehrdad Sabetzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.01991",
    "title": "A Bio-Inspired Chaos Sensor Model Based on the Perceptron Neural  Network: Machine Learning Concept and Application for Computational  Neuro-Science",
    "abstract": " Comments: 28 pages, 15 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2306.01991",
    "authors": [
      "Andrei Velichko",
      "Petr Boriskov",
      "Maksim Belyaev",
      "Vadim Putrolaynen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2306.02822",
    "title": "Discovering Dynamic Causal Space for DAG Structure Learning",
    "abstract": " Comments: Accepted by KDD 2023. Our codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2306.02822",
    "authors": [
      "Fangfu Liu",
      "Wenchang Ma",
      "An Zhang",
      "Xiang Wang",
      "Yueqi Duan",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.05694",
    "title": "Explainable Representation Learning of Small Quantum States",
    "abstract": " Title: Explainable Representation Learning of Small Quantum States ",
    "url": "https://arxiv.org/abs/2306.05694",
    "authors": [
      "Felix Frohnert",
      "Evert van Nieuwenburg"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07699",
    "title": "Time-aware Graph Structure Learning via Sequence Prediction on Temporal  Graphs",
    "abstract": " Comments: Accepted by CIKM 2023. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2306.07699",
    "authors": [
      "Haozhen Zhang",
      "Xueting Han",
      "Xi Xiao",
      "Jing Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.13050",
    "title": "Data augmentation and refinement for recommender system: A  semi-supervised approach using maximum margin matrix factorization",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2306.13050",
    "authors": [
      "Shamal Shaikh",
      "Venkateswara Rao Kagita",
      "Vikas Kumar",
      "Arun K Pujari"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16740",
    "title": "Principles and Guidelines for Evaluating Social Robot Navigation  Algorithms",
    "abstract": " Comments: 42 pages, 11 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2306.16740",
    "authors": [
      "Anthony Francis",
      "Claudia Perez-D'Arpino",
      "Chengshu Li",
      "Fei Xia",
      "Alexandre Alahi",
      "Rachid Alami",
      "Aniket Bera",
      "Abhijat Biswas",
      "Joydeep Biswas",
      "Rohan Chandra",
      "Hao-Tien Lewis Chiang",
      "Michael Everett",
      "Sehoon Ha",
      "Justin Hart",
      "Jonathan P. How",
      "Haresh Karnan",
      "Tsang-Wei Edward Lee",
      "Luis J. Manso",
      "Reuth Mirksy",
      "Soeren Pirk",
      "Phani Teja Singamaneni",
      "Peter Stone",
      "Ada V. Taylor",
      "Peter Trautman",
      "Nathan Tsoi",
      "Marynel Vazquez",
      "Xuesu Xiao",
      "Peng Xu",
      "Naoki Yokoyama",
      "Alexander Toshev",
      "Roberto Martin-Martin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07893",
    "title": "Anomaly Detection in Automated Fibre Placement: Learning with Data  Limitations",
    "abstract": " Title: Anomaly Detection in Automated Fibre Placement: Learning with Data  Limitations ",
    "url": "https://arxiv.org/abs/2307.07893",
    "authors": [
      "Assef Ghamisi",
      "Todd Charter",
      "Li Ji",
      "Maxime Rivard",
      "Gil Lund",
      "Homayoun Najjaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.08093",
    "title": "Cross-Ray Neural Radiance Fields for Novel-view Synthesis from  Unconstrained Image Collections",
    "abstract": " Comments: ICCV 2023 Oral ",
    "url": "https://arxiv.org/abs/2307.08093",
    "authors": [
      "Yifan Yang",
      "Shuhai Zhang",
      "Zixiong Huang",
      "Yubing Zhang",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12101",
    "title": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding  Boxes",
    "abstract": " Comments: accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2307.12101",
    "authors": [
      "Di Wu",
      "Pengfei Chen",
      "Xuehui Yu",
      "Guorong Li",
      "Zhenjun Han",
      "Jianbin Jiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01201",
    "title": "A Real-Time Robust Ecological-Adaptive Cruise Control Strategy for  Battery Electric Vehicles",
    "abstract": " Comments: 15 pages, 12 figures and 2 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2308.01201",
    "authors": [
      "Sheng Yu",
      "Xiao Pan",
      "Anastasis Georgiou",
      "Boli Chen",
      "Imad M. Jaimoukha",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.02158",
    "title": "CTP-Net: Character Texture Perception Network for Document Image Forgery  Localization",
    "abstract": " Title: CTP-Net: Character Texture Perception Network for Document Image Forgery  Localization ",
    "url": "https://arxiv.org/abs/2308.02158",
    "authors": [
      "Xin Liao",
      "Siliang Chen",
      "Jiaxin Chen",
      "Tianyi Wang",
      "Xiehua Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.02804",
    "title": "MiAMix: Enhancing Image Classification through a Multi-stage Augmented  Mixed Sample Data Augmentation Method",
    "abstract": " Title: MiAMix: Enhancing Image Classification through a Multi-stage Augmented  Mixed Sample Data Augmentation Method ",
    "url": "https://arxiv.org/abs/2308.02804",
    "authors": [
      "Wen Liang",
      "Youzhi Liang",
      "Jianguo Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.03669",
    "title": "Diffusion Model in Causal Inference with Unmeasured Confounders",
    "abstract": " Comments: 6 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2308.03669",
    "authors": [
      "Tatsuhiro Shimizu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.05040",
    "title": "Neural Field Movement Primitives for Joint Modelling of Scenes and  Motions",
    "abstract": " Comments: Accepted to IROS 2023. 8 pages, 7 figures, 2 tables. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2308.05040",
    "authors": [
      "Ahmet Tekden",
      "Marc Peter Deisenroth",
      "Yasemin Bekiroglu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.05370",
    "title": "Co-movement Pattern Mining from Videos",
    "abstract": " Title: Co-movement Pattern Mining from Videos ",
    "url": "https://arxiv.org/abs/2308.05370",
    "authors": [
      "Dongxiang Zhang",
      "Teng Ma",
      "Junnan Hu",
      "Yijun Bei",
      "Kian-Lee Tan",
      "Gang Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2308.05713",
    "title": "Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math  and science problems",
    "abstract": " Title: Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math  and science problems ",
    "url": "https://arxiv.org/abs/2308.05713",
    "authors": [
      "Ernest Davis",
      "Scott Aaronson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "History and Overview (math.HO)",
      "Popular Physics (physics.pop-ph)"
    ]
  },
  {
    "id": "arXiv:2308.05943",
    "title": "On Some Closure Properties of nc-eNCE Graph Grammars",
    "abstract": " Comments: 14 pages,9 figures, to be submitted to Theory of Computing ",
    "url": "https://arxiv.org/abs/2308.05943",
    "authors": [
      "Jayakrishna Vijayakumar",
      "Lisa Mathew"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2308.06452",
    "title": "Improved YOLOv8 Detection Algorithm in Security Inspection Image",
    "abstract": " Comments: 23 pages,23 figures ",
    "url": "https://arxiv.org/abs/2308.06452",
    "authors": [
      "Liyao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06769",
    "title": "Fr\u00e9chet Statistics Based Change Point Detection in Multivariate Hawkes  Process",
    "abstract": " Title: Fr\u00e9chet Statistics Based Change Point Detection in Multivariate Hawkes  Process ",
    "url": "https://arxiv.org/abs/2308.06769",
    "authors": [
      "Rui Luo",
      "Vikram Krishnamurthy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.06801",
    "title": "SAILOR: Structural Augmentation Based Tail Node Representation Learning",
    "abstract": " Comments: Accepted by CIKM 2023; Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2308.06801",
    "authors": [
      "Jie Liao",
      "Jintang Li",
      "Liang Chen",
      "Bingzhe Wu",
      "Yatao Bian",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]