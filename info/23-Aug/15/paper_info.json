[
  {
    "id": "arXiv:2308.06277",
    "title": "Descriptive complexity for neural networks via Boolean networks",
    "abstract": "We investigate the descriptive complexity of a class of neural networks with unrestricted topologies and piecewise polynomial activation functions. We consider the general scenario where the running time is unlimited and floating-point numbers are used for simulating reals. We characterize a class of these neural networks with a rule-based logic for Boolean networks. In particular, we show that the sizes of the neural networks and the corresponding Boolean rule formulae are polynomially related. In fact, in the direction from Boolean rules to neural networks, the blow-up is only linear. We also analyze the delays in running times due to the translations. In the translation from neural networks to Boolean rules, the time delay is polylogarithmic in the neural network size and linear in time. In the converse translation, the time delay is linear in both factors. ",
    "url": "https://arxiv.org/abs/2308.06277",
    "authors": [
      "Veeti Ahvonen",
      "Damian Heiman",
      "Antti Kuusisto"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2308.06299",
    "title": "Defensive Perception: Estimation and Monitoring of Neural Network  Performance under Deployment",
    "abstract": "In this paper, we propose a method for addressing the issue of unnoticed catastrophic deployment and domain shift in neural networks for semantic segmentation in autonomous driving. Our approach is based on the idea that deep learning-based perception for autonomous driving is uncertain and best represented as a probability distribution. As autonomous vehicles' safety is paramount, it is crucial for perception systems to recognize when the vehicle is leaving its operational design domain, anticipate hazardous uncertainty, and reduce the performance of the perception system. To address this, we propose to encapsulate the neural network under deployment within an uncertainty estimation envelope that is based on the epistemic uncertainty estimation through the Monte Carlo Dropout approach. This approach does not require modification of the deployed neural network and guarantees expected model performance. Our defensive perception envelope has the capability to estimate a neural network's performance, enabling monitoring and notification of entering domains of reduced neural network performance under deployment. Furthermore, our envelope is extended by novel methods to improve the application in deployment settings, including reducing compute expenses and confining estimation noise. Finally, we demonstrate the applicability of our method for multiple different potential deployment shifts relevant to autonomous driving, such as transitions into the night, rainy, or snowy domain. Overall, our approach shows great potential for application in deployment settings and enables operational design domain recognition via uncertainty, which allows for defensive perception, safe state triggers, warning notifications, and feedback for testing or development and adaptation of the perception stack. ",
    "url": "https://arxiv.org/abs/2308.06299",
    "authors": [
      "Hendrik Vogt",
      "Stefan Buehler",
      "Mark Schutera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.06306",
    "title": "Towards Packaging Unit Detection for Automated Palletizing Tasks",
    "abstract": "For various automated palletizing tasks, the detection of packaging units is a crucial step preceding the actual handling of the packaging units by an industrial robot. We propose an approach to this challenging problem that is fully trained on synthetically generated data and can be robustly applied to arbitrary real world packaging units without further training or setup effort. The proposed approach is able to handle sparse and low quality sensor data, can exploit prior knowledge if available and generalizes well to a wide range of products and application scenarios. To demonstrate the practical use of our approach, we conduct an extensive evaluation on real-world data with a wide range of different retail products. Further, we integrated our approach in a lab demonstrator and a commercial solution will be marketed through an industrial partner. ",
    "url": "https://arxiv.org/abs/2308.06306",
    "authors": [
      "Markus V\u00f6lk",
      "Kilian Kleeberger",
      "Werner Kraus",
      "Richard Bormann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.06309",
    "title": "Predicting Resilience with Neural Networks",
    "abstract": "Resilience engineering studies the ability of a system to survive and recover from disruptive events, which finds applications in several domains. Most studies emphasize resilience metrics to quantify system performance, whereas recent studies propose statistical modeling approaches to project system recovery time after degradation. Moreover, past studies are either performed on data after recovering or limited to idealized trends. Therefore, this paper proposes three alternative neural network (NN) approaches including (i) Artificial Neural Networks, (ii) Recurrent Neural Networks, and (iii) Long-Short Term Memory (LSTM) to model and predict system performance, including negative and positive factors driving resilience to quantify the impact of disruptive events and restorative activities. Goodness-of-fit measures are computed to evaluate the models and compared with a classical statistical model, including mean squared error and adjusted R squared. Our results indicate that NN models outperformed the traditional model on all goodness-of-fit measures. More specifically, LSTMs achieved an over 60\\% higher adjusted R squared, and decreased predictive error by 34-fold compared to the traditional method. These results suggest that NN models to predict resilience are both feasible and accurate and may find practical use in many important domains. ",
    "url": "https://arxiv.org/abs/2308.06309",
    "authors": [
      "Karen da Mata",
      "Priscila Silva",
      "Lance Fiondella"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2308.06338",
    "title": "Size Lowerbounds for Deep Operator Networks",
    "abstract": "Deep Operator Networks are an increasingly popular paradigm for solving regression in infinite dimensions and hence solve families of PDEs in one shot. In this work, we aim to establish a first-of-its-kind data-dependent lowerbound on the size of DeepONets required for them to be able to reduce empirical error on noisy data. In particular, we show that for low training errors to be obtained on $n$ data points it is necessary that the common output dimension of the branch and the trunk net be scaling as $\\Omega \\left ( {\\sqrt{n}} \\right )$. This inspires our experiments with DeepONets solving the advection-diffusion-reaction PDE, where we demonstrate the possibility that at a fixed model size, to leverage increase in this common output dimension and get monotonic lowering of training error, the size of the training data might necessarily need to scale quadratically with it. ",
    "url": "https://arxiv.org/abs/2308.06338",
    "authors": [
      "Anirbit Mukherjee",
      "Amartya Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.06354",
    "title": "Large Language Models to Identify Social Determinants of Health in  Electronic Health Records",
    "abstract": "Social determinants of health (SDoH) have an important impact on patient outcomes but are incompletely collected from the electronic health records (EHR). This study researched the ability of large language models to extract SDoH from free text in EHRs, where they are most commonly documented, and explored the role of synthetic clinical text for improving the extraction of these scarcely documented, yet extremely valuable, clinical data. 800 patient notes were annotated for SDoH categories, and several transformer-based models were evaluated. The study also experimented with synthetic data generation and assessed for algorithmic bias. Our best-performing models were fine-tuned Flan-T5 XL (macro-F1 0.71) for any SDoH, and Flan-T5 XXL (macro-F1 0.70). The benefit of augmenting fine-tuning with synthetic data varied across model architecture and size, with smaller Flan-T5 models (base and large) showing the greatest improvements in performance (delta F1 +0.12 to +0.23). Model performance was similar on the in-hospital system dataset but worse on the MIMIC-III dataset. Our best-performing fine-tuned models outperformed zero- and few-shot performance of ChatGPT-family models for both tasks. These fine-tuned models were less likely than ChatGPT to change their prediction when race/ethnicity and gender descriptors were added to the text, suggesting less algorithmic bias (p<0.05). At the patient-level, our models identified 93.8% of patients with adverse SDoH, while ICD-10 codes captured 2.0%. Our method can effectively extracted SDoH information from clinic notes, performing better compare to GPT zero- and few-shot settings. These models could enhance real-world evidence on SDoH and aid in identifying patients needing social support. ",
    "url": "https://arxiv.org/abs/2308.06354",
    "authors": [
      "Marco Guevara",
      "Shan Chen",
      "Spencer Thomas",
      "Tafadzwa L. Chaunzwa",
      "Idalid Franco",
      "Benjamin Kann",
      "Shalini Moningi",
      "Jack Qian",
      "Madeleine Goldstein",
      "Susan Harper",
      "Hugo JWL Aerts",
      "Guergana K. Savova",
      "Raymond H. Mak",
      "Danielle S. Bitterman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06358",
    "title": "CA2: Cyber Attacks Analytics",
    "abstract": "The VAST Challenge 2020 Mini-Challenge 1 requires participants to identify the responsible white hat groups behind a fictional Internet outage. To address this task, we have created a visual analytics system named CA2: Cyber Attacks Analytics. This system is designed to efficiently compare and match subgraphs within an extensive graph containing anonymized profiles. Additionally, we showcase an iterative workflow that utilizes our system's capabilities to pinpoint the responsible group. ",
    "url": "https://arxiv.org/abs/2308.06358",
    "authors": [
      "Luyu Cheng",
      "Bairui Su",
      "Yumeng Xue",
      "Xiaoyu Liu",
      "Yunhai Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.06378",
    "title": "DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System",
    "abstract": "A key challenge in eXplainable Artificial Intelligence is the well-known tradeoff between the transparency of an algorithm (i.e., how easily a human can directly understand the algorithm, as opposed to receiving a post-hoc explanation), and its accuracy. We report on the design of a new deep network that achieves improved transparency without sacrificing accuracy. We design a deep convolutional neuro-fuzzy inference system (DCNFIS) by hybridizing fuzzy logic and deep learning models and show that DCNFIS performs as accurately as three existing convolutional neural networks on four well-known datasets. We furthermore that DCNFIS outperforms state-of-the-art deep fuzzy systems. We then exploit the transparency of fuzzy logic by deriving explanations, in the form of saliency maps, from the fuzzy rules encoded in DCNFIS. We investigate the properties of these explanations in greater depth using the Fashion-MNIST dataset. ",
    "url": "https://arxiv.org/abs/2308.06378",
    "authors": [
      "Mojtaba Yeganejou",
      "Kimia Honari",
      "Ryan Kluzinski",
      "Scott Dick",
      "Michael Lipsett",
      "James Miller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06405",
    "title": "White-box Membership Inference Attacks against Diffusion Models",
    "abstract": "Diffusion models have begun to overshadow GANs and other generative models in industrial applications due to their superior image generation performance. The complex architecture of these models furnishes an extensive array of attack features. In light of this, we aim to design membership inference attacks (MIAs) catered to diffusion models. We first conduct an exhaustive analysis of existing MIAs on diffusion models, taking into account factors such as black-box/white-box models and the selection of attack features. We found that white-box attacks are highly applicable in real-world scenarios, and the most effective attacks presently are white-box. Departing from earlier research, which employs model loss as the attack feature for white-box MIAs, we employ model gradients in our attack, leveraging the fact that these gradients provide a more profound understanding of model responses to various samples. We subject these models to rigorous testing across a range of parameters, including training steps, sampling frequency, diffusion steps, and data variance. Across all experimental settings, our method consistently demonstrated near-flawless attack performance, with attack success rate approaching $100\\%$ and attack AUCROC near $1.0$. We also evaluate our attack against common defense mechanisms, and observe our attacks continue to exhibit commendable performance. ",
    "url": "https://arxiv.org/abs/2308.06405",
    "authors": [
      "Yan Pang",
      "Tianhao Wang",
      "Xuhui Kang",
      "Mengdi Huai",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.06410",
    "title": "Code Transpilation for Hardware Accelerators",
    "abstract": "DSLs and hardware accelerators have proven to be very effective in optimizing computationally expensive workloads. In this paper, we propose a solution to the challenge of manually rewriting legacy or unoptimized code in domain-specific languages and hardware accelerators. We introduce an approach that integrates two open-source tools: Metalift, a code translation framework, and Gemmini, a DNN accelerator generator. The integration of these two tools offers significant benefits, including simplified workflows for developers to run legacy code on Gemmini generated accelerators and a streamlined programming stack for Gemmini that reduces the effort required to add new instructions. This paper provides details on this integration and its potential to simplify and optimize computationally expensive workloads. ",
    "url": "https://arxiv.org/abs/2308.06410",
    "authors": [
      "Yuto Nishida",
      "Sahil Bhatia",
      "Shadaj Laddad",
      "Hasan Genc",
      "Yakun Sophia Shao",
      "Alvin Cheung"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2308.06412",
    "title": "Improving Pseudo Labels for Open-Vocabulary Object Detection",
    "abstract": "Recent studies show promising performance in open-vocabulary object detection (OVD) using pseudo labels (PLs) from pretrained vision and language models (VLMs). However, PLs generated by VLMs are extremely noisy due to the gap between the pretraining objective of VLMs and OVD, which blocks further advances on PLs. In this paper, we aim to reduce the noise in PLs and propose a method called online Self-training And a Split-and-fusion head for OVD (SAS-Det). First, the self-training finetunes VLMs to generate high quality PLs while prevents forgetting the knowledge learned in the pretraining. Second, a split-and-fusion (SAF) head is designed to remove the noise in localization of PLs, which is usually ignored in existing methods. It also fuses complementary knowledge learned from both precise ground truth and noisy pseudo labels to boost the performance. Extensive experiments demonstrate SAS-Det is both efficient and effective. Our pseudo labeling is 3 times faster than prior methods. SAS-Det outperforms prior state-of-the-art models of the same scale by a clear margin and achieves 37.4 AP$_{50}$ and 27.3 AP$_r$ on novel categories of the COCO and LVIS benchmarks, respectively. ",
    "url": "https://arxiv.org/abs/2308.06412",
    "authors": [
      "Shiyu Zhao",
      "Samuel Schulter",
      "Long Zhao",
      "Zhixing Zhang",
      "Vijay Kumar B.G",
      "Yumin Suh",
      "Manmohan Chandraker",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06413",
    "title": "Sparsity and Privacy in Secret Sharing: A Fundamental Trade-Off",
    "abstract": "This work investigates the design of sparse secret sharing schemes that encode a sparse private matrix into sparse shares. This investigation is motivated by distributed computing, where the multiplication of sparse and private matrices is moved from a computationally weak main node to untrusted worker machines. Classical secret-sharing schemes produce dense shares. However, sparsity can help speed up the computation. We show that, for matrices with i.i.d. entries, sparsity in the shares comes at a fundamental cost of weaker privacy. We derive a fundamental tradeoff between sparsity and privacy and construct optimal sparse secret sharing schemes that produce shares that leak the minimum amount of information for a desired sparsity of the shares. We apply our schemes to distributed sparse and private matrix multiplication schemes with no colluding workers while tolerating stragglers. For the setting of two non-communicating clusters of workers, we design a sparse one-time pad so that no private information is leaked to a cluster of untrusted and colluding workers, and the shares with bounded but non-zero leakage are assigned to a cluster of partially trusted workers. We conclude by discussing the necessity of using permutations for matrices with correlated entries. ",
    "url": "https://arxiv.org/abs/2308.06413",
    "authors": [
      "Rawad Bitar",
      "Maximilian Egger",
      "Antonia Wachter-Zeh",
      "Marvin Xhemrishi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.06419",
    "title": "Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed  Environments: A Systematic Review",
    "abstract": "Planning an autonomous vehicle's (AV) path in a space shared with pedestrians requires reasoning about pedestrians' future trajectories. A practical pedestrian trajectory prediction algorithm for the use of AVs needs to consider the effect of the vehicle's interactions with the pedestrians on pedestrians' future motion behaviours. In this regard, this paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in presence of vehicles that can be applied for unstructured environments. This paper also investigates specific considerations for pedestrian-vehicle interaction (compared with pedestrian-pedestrian interaction) and reviews how different variables such as prediction uncertainties and behavioural differences are accounted for in the previously proposed prediction models. PRISMA guidelines were followed. Articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. A total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. An overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. Research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments are discussed. ",
    "url": "https://arxiv.org/abs/2308.06419",
    "authors": [
      "Mahsa Golchoubian",
      "Moojan Ghafurian",
      "Kerstin Dautenhahn",
      "Nasser Lashgarian Azad"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.06421",
    "title": "Characterising Robust Instances of Ultimate Positivity for Linear  Dynamical Systems",
    "abstract": "Linear Dynamical Systems, both discrete and continuous, are invaluable mathematical models in a plethora of applications such the verification of probabilistic systems, model checking, computational biology, cyber-physical systems, and economics. We consider discrete Linear Recurrence Sequences and continuous C-finite functions, i.e. solutions to homogeneous Linear Differential Equations. The Ultimate Positivity Problem gives the recurrence relation and the initialisation as input and asks whether there is a step $n_0$ (resp. a time $t_0$) such that the Linear Recurrence Sequence $u[n] \\ge 0$ for $n > n_0$ (resp. solution to homogeneous linear differential equation $u(t) \\ge 0$ for $t > t_0$). There are intrinsic number-theoretic challenges to surmount in order to decide these problems, which crucially arise in engineering and the practical sciences. In these settings, the difficult corner cases are seldom relevant: tolerance to the inherent imprecision is especially critical. We thus characterise \\textit{robust} instances of the Ultimate Positivity Problem, i.e.\\ inputs for which the decision is locally constant. We describe the sets of Robust YES and Robust NO instances using the First Order Theory of the Reals. We show, via the admission of quantifier elimination by the First Order Theory of the Reals, that these sets are semialgebraic. ",
    "url": "https://arxiv.org/abs/2308.06421",
    "authors": [
      "Mihir Vahanwala"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2308.06422",
    "title": "Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of  Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation",
    "abstract": "As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 20% decrease in model size without compromising accuracy. Additionally, our method boasts a 12x reduction in search time relative to the best search-focused strategies currently available. As a result, our proposed method represents a leap forward in neural network design optimization, paving the way for quick model design and implementation in settings with limited resources, thereby propelling the potential of scalable deep learning solutions. ",
    "url": "https://arxiv.org/abs/2308.06422",
    "authors": [
      "Seyedarmin Azizi",
      "Mahdi Nazemi",
      "Arash Fayyazi",
      "Massoud Pedram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.06429",
    "title": "Genetic heterogeneity analysis using genetic algorithm and network  science",
    "abstract": "Through genome-wide association studies (GWAS), disease susceptible genetic variables can be identified by comparing the genetic data of individuals with and without a specific disease. However, the discovery of these associations poses a significant challenge due to genetic heterogeneity and feature interactions. Genetic variables intertwined with these effects often exhibit lower effect-size, and thus can be difficult to be detected using machine learning feature selection methods. To address these challenges, this paper introduces a novel feature selection mechanism for GWAS, named Feature Co-selection Network (FCSNet). FCS-Net is designed to extract heterogeneous subsets of genetic variables from a network constructed from multiple independent feature selection runs based on a genetic algorithm (GA), an evolutionary learning algorithm. We employ a non-linear machine learning algorithm to detect feature interaction. We introduce the Community Risk Score (CRS), a synthetic feature designed to quantify the collective disease association of each variable subset. Our experiment showcases the effectiveness of the utilized GA-based feature selection method in identifying feature interactions through synthetic data analysis. Furthermore, we apply our novel approach to a case-control colorectal cancer GWAS dataset. The resulting synthetic features are then used to explain the genetic heterogeneity in an additional case-only GWAS dataset. ",
    "url": "https://arxiv.org/abs/2308.06429",
    "authors": [
      "Zhendong Sha",
      "Yuanzhu Chen",
      "Ting Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2308.06430",
    "title": "How complex is the microarray dataset? A novel data complexity metric  for biological high-dimensional microarray data",
    "abstract": "Data complexity analysis quantifies the hardness of constructing a predictive model on a given dataset. However, the effectiveness of existing data complexity measures can be challenged by the existence of irrelevant features and feature interactions in biological micro-array data. We propose a novel data complexity measure, depth, that leverages an evolutionary inspired feature selection algorithm to quantify the complexity of micro-array data. By examining feature subsets of varying sizes, the approach offers a novel perspective on data complexity analysis. Unlike traditional metrics, depth is robust to irrelevant features and effectively captures complexity stemming from feature interactions. On synthetic micro-array data, depth outperforms existing methods in robustness to irrelevant features and identifying complexity from feature interactions. Applied to case-control genotype and gene-expression micro-array datasets, the results reveal that a single feature of gene-expression data can account for over 90% of the performance of multi-feature model, confirming the adequacy of the commonly used differentially expressed gene (DEG) feature selection method for the gene expression data. Our study also demonstrates that constructing predictive models for genotype data is harder than gene expression data. The results in this paper provide evidence for the use of interpretable machine learning algorithms on microarray data. ",
    "url": "https://arxiv.org/abs/2308.06430",
    "authors": [
      "Zhendong Sha",
      "Li Zhu",
      "Zijun Jiang",
      "Yuanzhu Chen",
      "Ting Hu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2308.06431",
    "title": "Performance Prediction for Multi-hop Questions",
    "abstract": "We study the problem of Query Performance Prediction (QPP) for open-domain multi-hop Question Answering (QA), where the task is to estimate the difficulty of evaluating a multi-hop question over a corpus. Despite the extensive research on predicting the performance of ad-hoc and QA retrieval models, there has been a lack of study on the estimation of the difficulty of multi-hop questions. The problem is challenging due to the multi-step nature of the retrieval process, potential dependency of the steps and the reasoning involved. To tackle this challenge, we propose multHP, a novel pre-retrieval method for predicting the performance of open-domain multi-hop questions. Our extensive evaluation on the largest multi-hop QA dataset using several modern QA systems shows that the proposed model is a strong predictor of the performance, outperforming traditional single-hop QPP models. Additionally, we demonstrate that our approach can be effectively used to optimize the parameters of QA systems, such as the number of documents to be retrieved, resulting in improved overall retrieval performance. ",
    "url": "https://arxiv.org/abs/2308.06431",
    "authors": [
      "Mohammadreza Samadi",
      "Davood Rafiei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.06434",
    "title": "Distributionally Robust Optimization and Invariant Representation  Learning for Addressing Subgroup Underrepresentation: Mechanisms and  Limitations",
    "abstract": "Spurious correlation caused by subgroup underrepresentation has received increasing attention as a source of bias that can be perpetuated by deep neural networks (DNNs). Distributionally robust optimization has shown success in addressing this bias, although the underlying working mechanism mostly relies on upweighting under-performing samples as surrogates for those underrepresented in data. At the same time, while invariant representation learning has been a powerful choice for removing nuisance-sensitive features, it has been little considered in settings where spurious correlations are caused by significant underrepresentation of subgroups. In this paper, we take the first step to better understand and improve the mechanisms for debiasing spurious correlation due to subgroup underrepresentation in medical image classification. Through a comprehensive evaluation study, we first show that 1) generalized reweighting of under-performing samples can be problematic when bias is not the only cause for poor performance, while 2) naive invariant representation learning suffers from spurious correlations itself. We then present a novel approach that leverages robust optimization to facilitate the learning of invariant representations at the presence of spurious correlations. Finetuned classifiers utilizing such representation demonstrated improved abilities to reduce subgroup performance disparity, while maintaining high average and worst-group performance. ",
    "url": "https://arxiv.org/abs/2308.06434",
    "authors": [
      "Nilesh Kumar",
      "Ruby Shrestha",
      "Zhiyuan Li",
      "Linwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06435",
    "title": "A Brief Wellbeing Training Session Delivered by a Humanoid Social Robot:  A Pilot Randomized Controlled Trial",
    "abstract": "Mental health and psychological distress are rising in adults, showing the importance of wellbeing promotion, support, and technique practice that is effective and accessible. Interactive social robots have been tested to deliver health programs but have not been explored to deliver wellbeing technique training in detail. A pilot randomised controlled trial was conducted to explore the feasibility of an autonomous humanoid social robot to deliver a brief mindful breathing technique to promote information around wellbeing. It contained two conditions: brief technique training (Technique) and control designed to represent a simple wait-list activity to represent a relationship-building discussion (Simple Rapport). This trial also explored willingness to discuss health-related topics with a robot. Recruitment uptake rate through convenience sampling was high (53%). A total of 230 participants took part (mean age = 29 years) with 71% being higher education students. There were moderate ratings of technique enjoyment, perceived usefulness, and likelihood to repeat the technique again. Interaction effects were found across measures with scores varying across gender and distress levels. Males with high distress and females with low distress who received the simple rapport activity reported greater comfort to discuss non-health topics than males with low distress and females with high distress. This trial marks a notable step towards the design and deployment of an autonomous wellbeing intervention to investigate the impact of a brief robot-delivered mindfulness training program for a sub-clinical population. ",
    "url": "https://arxiv.org/abs/2308.06435",
    "authors": [
      "Nicole Robinson",
      "Jennifer Connolly",
      "Gavin Suddrey",
      "David J. Kavanagh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.06436",
    "title": "A Domain-adaptive Physics-informed Neural Network for Inverse Problems  of Maxwell's Equations in Heterogeneous Media",
    "abstract": "Maxwell's equations are a collection of coupled partial differential equations (PDEs) that, together with the Lorentz force law, constitute the basis of classical electromagnetism and electric circuits. Effectively solving Maxwell's equations is crucial in various fields, like electromagnetic scattering and antenna design optimization. Physics-informed neural networks (PINNs) have shown powerful ability in solving PDEs. However, PINNs still struggle to solve Maxwell's equations in heterogeneous media. To this end, we propose a domain-adaptive PINN (da-PINN) to solve inverse problems of Maxwell's equations in heterogeneous media. First, we propose a location parameter of media interface to decompose the whole domain into several sub-domains. Furthermore, the electromagnetic interface conditions are incorporated into a loss function to improve the prediction performance near the interface. Then, we propose a domain-adaptive training strategy for da-PINN. Finally, the effectiveness of da-PINN is verified with two case studies. ",
    "url": "https://arxiv.org/abs/2308.06436",
    "authors": [
      "Shiyuan Piao",
      "Hong Gu",
      "Aina Wang",
      "Pan Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.06441",
    "title": "Calliope-Net: Automatic Generation of Graph Data Facts via Annotated  Node-link Diagrams",
    "abstract": "Graph or network data are widely studied in both data mining and visualization communities to review the relationship among different entities and groups. The data facts derived from graph visual analysis are important to help understand the social structures of complex data, especially for data journalism. However, it is challenging for data journalists to discover graph data facts and manually organize correlated facts around a meaningful topic due to the complexity of graph data and the difficulty to interpret graph narratives. Therefore, we present an automatic graph facts generation system, Calliope-Net, which consists of a fact discovery module, a fact organization module, and a visualization module. It creates annotated node-link diagrams with facts automatically discovered and organized from network data. A novel layout algorithm is designed to present meaningful and visually appealing annotated graphs. We evaluate the proposed system with two case studies and an in-lab user study. The results show that Calliope-Net can benefit users in discovering and understanding graph data facts with visually pleasing annotated visualizations. ",
    "url": "https://arxiv.org/abs/2308.06441",
    "authors": [
      "Qing Chen",
      "Nan Chen",
      "Wei Shuai",
      "Guande Wu",
      "Zhe Xu",
      "Hanghang Tong",
      "Nan Cao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.06443",
    "title": "Neural Latent Aligner: Cross-trial Alignment for Learning  Representations of Complex, Naturalistic Neural Data",
    "abstract": "Understanding the neural implementation of complex human behaviors is one of the major goals in neuroscience. To this end, it is crucial to find a true representation of the neural data, which is challenging due to the high complexity of behaviors and the low signal-to-ratio (SNR) of the signals. Here, we propose a novel unsupervised learning framework, Neural Latent Aligner (NLA), to find well-constrained, behaviorally relevant neural representations of complex behaviors. The key idea is to align representations across repeated trials to learn cross-trial consistent information. Furthermore, we propose a novel, fully differentiable time warping model (TWM) to resolve the temporal misalignment of trials. When applied to intracranial electrocorticography (ECoG) of natural speaking, our model learns better representations for decoding behaviors than the baseline models, especially in lower dimensional space. The TWM is empirically validated by measuring behavioral coherence between aligned trials. The proposed framework learns more cross-trial consistent representations than the baselines, and when visualized, the manifold reveals shared neural trajectories across trials. ",
    "url": "https://arxiv.org/abs/2308.06443",
    "authors": [
      "Cheol Jun Cho",
      "Edward F. Chang",
      "Gopala K. Anumanchipalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.06447",
    "title": "A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of  Physics-Informed Neural Networks: Application to Composites Autoclave  Processing",
    "abstract": "Physics-Informed Neural Networks (PINNs) have gained popularity in solving nonlinear partial differential equations (PDEs) via integrating physical laws into the training of neural networks, making them superior in many scientific and engineering applications. However, conventional PINNs still fall short in accurately approximating the solution of complex systems with strong nonlinearity, especially in long temporal domains. Besides, since PINNs are designed to approximate a specific realization of a given PDE system, they lack the necessary generalizability to efficiently adapt to new system configurations. This entails computationally expensive re-training from scratch for any new change in the system. To address these shortfalls, in this work a novel sequential meta-transfer (SMT) learning framework is proposed, offering a unified solution for both fast training and efficient adaptation of PINNs in highly nonlinear systems with long temporal domains. Specifically, the framework decomposes PDE's time domain into smaller time segments to create \"easier\" PDE problems for PINNs training. Then for each time interval, a meta-learner is assigned and trained to achieve an optimal initial state for rapid adaptation to a range of related tasks. Transfer learning principles are then leveraged across time intervals to further reduce the computational cost.Through a composites autoclave processing case study, it is shown that SMT is clearly able to enhance the adaptability of PINNs while significantly reducing computational cost, by a factor of 100. ",
    "url": "https://arxiv.org/abs/2308.06447",
    "authors": [
      "Milad Ramezankhani",
      "Abbas S. Milani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06450",
    "title": "Simple Model Also Works: A Novel Emotion Recognition Network in Textual  Conversation Based on Curriculum Learning Strategy",
    "abstract": "Emotion Recognition in Conversation (ERC) has emerged as a research hotspot in domains such as conversational robots and question-answer systems. How to efficiently and adequately retrieve contextual emotional cues has been one of the key challenges in the ERC task. Existing efforts do not fully model the context and employ complex network structures, resulting in excessive computational resource overhead without substantial performance improvement. In this paper, we propose a novel Emotion Recognition Network based on Curriculum Learning strategy (ERNetCL). The proposed ERNetCL primarily consists of Temporal Encoder (TE), Spatial Encoder (SE), and Curriculum Learning (CL) loss. We utilize TE and SE to combine the strengths of previous methods in a simplistic manner to efficiently capture temporal and spatial contextual information in the conversation. To simulate the way humans learn curriculum from easy to hard, we apply the idea of CL to the ERC task to progressively optimize the network parameters of ERNetCL. At the beginning of training, we assign lower learning weights to difficult samples. As the epoch increases, the learning weights for these samples are gradually raised. Extensive experiments on four datasets exhibit that our proposed method is effective and dramatically beats other baseline models. ",
    "url": "https://arxiv.org/abs/2308.06450",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Yingjian Liu",
      "Qing Zhou",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.06452",
    "title": "Improved YOLOv8 Detection Algorithm in Security Inspection Image",
    "abstract": "Security inspection is the first line of defense to ensure the safety of people's lives and property, and intelligent security inspection is an inevitable trend in the future development of the security inspection industry. Aiming at the problems of overlapping detection objects, false detection of contraband, and missed detection in the process of X-ray image detection, an improved X-ray contraband detection algorithm CSS-YOLO based on YOLOv8s is proposed. ",
    "url": "https://arxiv.org/abs/2308.06452",
    "authors": [
      "Liyao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06465",
    "title": "California Exodus? A Network Model of Population Redistribution in the  United States",
    "abstract": "Motivated by debates about California's net migration loss, we employ valued exponential-family random graph models to analyze the inter-county migration flow networks in the United States. We introduce a protocol that visualizes the complex effects of potential underlying mechanisms, and perform in silico knockout experiments to quantify their contribution to the California Exodus. We find that racial dynamics contribute to the California Exodus, urbanization ameliorates it, and political climate and housing costs have little impact. Moreover, the severity of the California Exodus depends on how one measures it, and California is not the state with the most substantial population loss. The paper demonstrates how generative statistical models can provide mechanistic insights beyond simple hypothesis-testing. ",
    "url": "https://arxiv.org/abs/2308.06465",
    "authors": [
      "Peng Huang",
      "Carter T. Butts"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2308.06467",
    "title": "Not So Robust After All: Evaluating the Robustness of Deep Neural  Networks to Unseen Adversarial Attacks",
    "abstract": "Deep neural networks (DNNs) have gained prominence in various applications, such as classification, recognition, and prediction, prompting increased scrutiny of their properties. A fundamental attribute of traditional DNNs is their vulnerability to modifications in input data, which has resulted in the investigation of adversarial attacks. These attacks manipulate the data in order to mislead a DNN. This study aims to challenge the efficacy and generalization of contemporary defense mechanisms against adversarial attacks. Specifically, we explore the hypothesis proposed by Ilyas et. al, which posits that DNN image features can be either robust or non-robust, with adversarial attacks targeting the latter. This hypothesis suggests that training a DNN on a dataset consisting solely of robust features should produce a model resistant to adversarial attacks. However, our experiments demonstrate that this is not universally true. To gain further insights into our findings, we analyze the impact of adversarial attack norms on DNN representations, focusing on samples subjected to $L_2$ and $L_{\\infty}$ norm attacks. Further, we employ canonical correlation analysis, visualize the representations, and calculate the mean distance between these representations and various DNN decision boundaries. Our results reveal a significant difference between $L_2$ and $L_{\\infty}$ norms, which could provide insights into the potential dangers posed by $L_{\\infty}$ norm attacks, previously underestimated by the research community. ",
    "url": "https://arxiv.org/abs/2308.06467",
    "authors": [
      "Roman Garaev",
      "Bader Rasheed",
      "Adil Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06468",
    "title": "Tiny and Efficient Model for the Edge Detection Generalization",
    "abstract": "Most high-level computer vision tasks rely on low-level image operations as their initial processes. Operations such as edge detection, image enhancement, and super-resolution, provide the foundations for higher level image analysis. In this work we address the edge detection considering three main objectives: simplicity, efficiency, and generalization since current state-of-the-art (SOTA) edge detection models are increased in complexity for better accuracy. To achieve this, we present Tiny and Efficient Edge Detector (TEED), a light convolutional neural network with only $58K$ parameters, less than $0.2$% of the state-of-the-art models. Training on the BIPED dataset takes $less than 30 minutes$, with each epoch requiring $less than 5 minutes$. Our proposed model is easy to train and it quickly converges within very first few epochs, while the predicted edge-maps are crisp and of high quality. Additionally, we propose a new dataset to test the generalization of edge detection, which comprises samples from popular images used in edge detection and image segmentation. The source code is available in https://github.com/xavysp/TEED. ",
    "url": "https://arxiv.org/abs/2308.06468",
    "authors": [
      "Xavier Soria",
      "Yachuan Li",
      "Mohammad Rouhani",
      "Angel D. Sappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06472",
    "title": "Flexible Keyword Spotting based on Homogeneous Audio-Text Embedding",
    "abstract": "Spotting user-defined/flexible keywords represented in text frequently uses an expensive text encoder for joint analysis with an audio encoder in an embedding space, which can suffer from heterogeneous modality representation (i.e., large mismatch) and increased complexity. In this work, we propose a novel architecture to efficiently detect arbitrary keywords based on an audio-compliant text encoder which inherently has homogeneous representation with audio embedding, and it is also much smaller than a compatible text encoder. Our text encoder converts the text to phonemes using a grapheme-to-phoneme (G2P) model, and then to an embedding using representative phoneme vectors, extracted from the paired audio encoder on rich speech datasets. We further augment our method with confusable keyword generation to develop an audio-text embedding verifier with strong discriminative power. Experimental results show that our scheme outperforms the state-of-the-art results on Libriphrase hard dataset, increasing Area Under the ROC Curve (AUC) metric from 84.21% to 92.7% and reducing Equal-Error-Rate (EER) metric from 23.36% to 14.4%. ",
    "url": "https://arxiv.org/abs/2308.06472",
    "authors": [
      "Kumari Nishu",
      "Minsik Cho",
      "Paul Dixon",
      "Devang Naik"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.06479",
    "title": "mmHawkeye: Passive UAV Detection with a COTS mmWave Radar",
    "abstract": "Small Unmanned Aerial Vehicles (UAVs) are becoming potential threats to security-sensitive areas and personal privacy. A UAV can shoot photos at height, but how to detect such an uninvited intruder is an open problem. This paper presents mmHawkeye, a passive approach for UAV detection with a COTS millimeter wave (mmWave) radar. mmHawkeye doesn't require prior knowledge of the type, motions, and flight trajectory of the UAV, while exploiting the signal feature induced by the UAV's periodic micro-motion (PMM) for long-range accurate detection. The design is therefore effective in dealing with low-SNR and uncertain reflected signals from the UAV. mmHawkeye can further track the UAV's position with dynamic programming and particle filtering, and identify it with a Long Short-Term Memory (LSTM) based detector. We implement mmHawkeye on a commercial mmWave radar and evaluate its performance under varied settings. The experimental results show that mmHawkeye has a detection accuracy of 95.8% and can realize detection at a range up to 80m. ",
    "url": "https://arxiv.org/abs/2308.06479",
    "authors": [
      "Jia Zhang",
      "Xin Na",
      "Rui Xi",
      "Yimiao Sun",
      "Yuan He"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.06480",
    "title": "Context-aware Event Forecasting via Graph Disentanglement",
    "abstract": "Event forecasting has been a demanding and challenging task throughout the entire human history. It plays a pivotal role in crisis alarming and disaster prevention in various aspects of the whole society. The task of event forecasting aims to model the relational and temporal patterns based on historical events and makes forecasting to what will happen in the future. Most existing studies on event forecasting formulate it as a problem of link prediction on temporal event graphs. However, such pure structured formulation suffers from two main limitations: 1) most events fall into general and high-level types in the event ontology, and therefore they tend to be coarse-grained and offers little utility which inevitably harms the forecasting accuracy; and 2) the events defined by a fixed ontology are unable to retain the out-of-ontology contextual information. To address these limitations, we propose a novel task of context-aware event forecasting which incorporates auxiliary contextual information. First, the categorical context provides supplementary fine-grained information to the coarse-grained events. Second and more importantly, the context provides additional information towards specific situation and condition, which is crucial or even determinant to what will happen next. However, it is challenging to properly integrate context into the event forecasting framework, considering the complex patterns in the multi-context scenario. Towards this end, we design a novel framework named Separation and Collaboration Graph Disentanglement (short as SeCoGD) for context-aware event forecasting. Since there is no available dataset for this novel task, we construct three large-scale datasets based on GDELT. Experimental results demonstrate that our model outperforms a list of SOTA methods. ",
    "url": "https://arxiv.org/abs/2308.06480",
    "authors": [
      "Yunshan Ma",
      "Chenchen Ye",
      "Zijian Wu",
      "Xiang Wang",
      "Yixin Cao",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.06483",
    "title": "BigWavGAN: A Wave-To-Wave Generative Adversarial Network for Music  Super-Resolution",
    "abstract": "Generally, Deep Neural Networks (DNNs) are expected to have high performance when their model size is large. However, large models failed to produce high-quality results commensurate with their scale in music Super-Resolution (SR). We attribute this to that DNNs cannot learn information commensurate with their size from standard mean square error losses. To unleash the potential of large DNN models in music SR, we propose BigWavGAN, which incorporates Demucs, a large-scale wave-to-wave model, with State-Of-The-Art (SOTA) discriminators and adversarial training strategies. Our discriminator consists of Multi-Scale Discriminator (MSD) and Multi-Resolution Discriminator (MRD). During inference, since only the generator is utilized, there are no additional parameters or computational resources required compared to the baseline model Demucs. Objective evaluation affirms the effectiveness of BigWavGAN in music SR. Subjective evaluations indicate that BigWavGAN can generate music with significantly high perceptual quality over the baseline model. Notably, BigWavGAN surpasses the SOTA music SR model in both simulated and real-world scenarios. Moreover, BigWavGAN represents its superior generalization ability to address out-of-distribution data. The conducted ablation study reveals the importance of our discriminators and training strategies. Samples are available on the demo page. ",
    "url": "https://arxiv.org/abs/2308.06483",
    "authors": [
      "Yenan Zhang",
      "Hiroshi Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.06488",
    "title": "Generating Faithful Text From a Knowledge Graph with Noisy Reference  Text",
    "abstract": "Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level of hallucination in the generated text by employing a controllable text generation technique. We evaluate our model's performance through the standard quantitative metrics as well as a ChatGPT-based quantitative and qualitative analysis. Our evaluation demonstrates the superior performance of our model over state-of-the-art KG-to-text models on faithfulness. ",
    "url": "https://arxiv.org/abs/2308.06488",
    "authors": [
      "Tahsina Hashem",
      "Weiqing Wang",
      "Derry Tanti Wijaya",
      "Mohammed Eunus Ali",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06493",
    "title": "EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes",
    "abstract": "Full-body ego-pose estimation from head and hand poses alone has become an active area of research to power articulate avatar representation on headset-based platforms. However, existing methods over-rely on the confines of the motion-capture spaces in which datasets were recorded, while simultaneously assuming continuous capture of joint motions and uniform body dimensions. In this paper, we propose EgoPoser, which overcomes these limitations by 1) rethinking the input representation for headset-based ego-pose estimation and introducing a novel motion decomposition method that predicts full-body pose independent of global positions, 2) robustly modeling body pose from intermittent hand position and orientation tracking only when inside a headset's field of view, and 3) generalizing across various body sizes for different users. Our experiments show that EgoPoser outperforms state-of-the-art methods both qualitatively and quantitatively, while maintaining a high inference speed of over 600 fps. EgoPoser establishes a robust baseline for future work, where full-body pose estimation needs no longer rely on outside-in capture and can scale to large-scene environments. ",
    "url": "https://arxiv.org/abs/2308.06493",
    "authors": [
      "Jiaxi Jiang",
      "Paul Streli",
      "Manuel Meier",
      "Andreas Fender",
      "Christian Holz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.06496",
    "title": "Performance Analysis for Resource Constrained Decentralized Federated  Learning Over Wireless Networks",
    "abstract": "Federated learning (FL) can lead to significant communication overhead and reliance on a central server. To address these challenges, decentralized federated learning (DFL) has been proposed as a more resilient framework. DFL involves parameter exchange between devices through a wireless network. This study analyzes the performance of resource-constrained DFL using different communication schemes (digital and analog) over wireless networks to optimize communication efficiency. Specifically, we provide convergence bounds for both digital and analog transmission approaches, enabling analysis of the model performance trained on DFL. Furthermore, for digital transmission, we investigate and analyze resource allocation between computation and communication and convergence rates, obtaining its communication complexity and the minimum probability of correction communication required for convergence guarantee. For analog transmission, we discuss the impact of channel fading and noise on the model performance and the maximum errors accumulation with convergence guarantee over fading channels. Finally, we conduct numerical simulations to evaluate the performance and convergence rate of convolutional neural networks (CNNs) and Vision Transformer (ViT) trained in the DFL framework on fashion-MNIST and CIFAR-10 datasets. Our simulation results validate our analysis and discussion, revealing how to improve performance by optimizing system parameters under different communication conditions. ",
    "url": "https://arxiv.org/abs/2308.06496",
    "authors": [
      "Zhigang Yan",
      "Dong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.06512",
    "title": "HyperFormer: Enhancing Entity and Relation Interaction for  Hyper-Relational Knowledge Graph Completion",
    "abstract": "Hyper-relational knowledge graphs (HKGs) extend standard knowledge graphs by associating attribute-value qualifiers to triples, which effectively represent additional fine-grained information about its associated triple. Hyper-relational knowledge graph completion (HKGC) aims at inferring unknown triples while considering its qualifiers. Most existing approaches to HKGC exploit a global-level graph structure to encode hyper-relational knowledge into the graph convolution message passing process. However, the addition of multi-hop information might bring noise into the triple prediction process. To address this problem, we propose HyperFormer, a model that considers local-level sequential information, which encodes the content of the entities, relations and qualifiers of a triple. More precisely, HyperFormer is composed of three different modules: an entity neighbor aggregator module allowing to integrate the information of the neighbors of an entity to capture different perspectives of it; a relation qualifier aggregator module to integrate hyper-relational knowledge into the corresponding relation to refine the representation of relational content; a convolution-based bidirectional interaction module based on a convolutional operation, capturing pairwise bidirectional interactions of entity-relation, entity-qualifier, and relation-qualifier. realize the depth perception of the content related to the current statement. Furthermore, we introduce a Mixture-of-Experts strategy into the feed-forward layers of HyperFormer to strengthen its representation capabilities while reducing the amount of model parameters and computation. Extensive experiments on three well-known datasets with four different conditions demonstrate HyperFormer's effectiveness. Datasets and code are available at https://github.com/zhiweihu1103/HKGC-HyperFormer. ",
    "url": "https://arxiv.org/abs/2308.06512",
    "authors": [
      "Zhiwei Hu",
      "V\u00edctor Guti\u00e9rrez-Basulto",
      "Zhiliang Xiang",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.06534",
    "title": "Dealing with Small Annotated Datasets for Deep Learning in Medical  Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing  Contrastive and Masked Autoencoder Methods for Convolutional Models",
    "abstract": "Deep learning in medical imaging has the potential to minimize the risk of diagnostic errors, reduce radiologist workload, and accelerate diagnosis. Training such deep learning models requires large and accurate datasets, with annotations for all training samples. However, in the medical imaging domain, annotated datasets for specific tasks are often small due to the high complexity of annotations, limited access, or the rarity of diseases. To address this challenge, deep learning models can be pre-trained on large image datasets without annotations using methods from the field of self-supervised learning. After pre-training, small annotated datasets are sufficient to fine-tune the models for a specific task, the so-called ``downstream task\". The most popular self-supervised pre-training approaches in medical imaging are based on contrastive learning. However, recent studies in natural image processing indicate a strong potential for masked autoencoder approaches. Our work compares state-of-the-art contrastive learning methods with the recently introduced masked autoencoder approach \"SparK\" for convolutional neural networks (CNNs) on medical images. Therefore we pre-train on a large unannotated CT image dataset and fine-tune on several downstream CT classification tasks. Due to the challenge of obtaining sufficient annotated training data in the medical imaging domain, it is of particular interest to evaluate how the self-supervised pre-training methods perform on small downstream datasets. By experimenting with gradually reducing the training dataset size of our downstream tasks, we find that the reduction has different effects depending on the type of pre-training chosen. The SparK pre-training method is more robust to the training dataset size than the contrastive methods. Based on our results, we propose the SparK pre-training for medical downstream tasks with small datasets. ",
    "url": "https://arxiv.org/abs/2308.06534",
    "authors": [
      "Daniel Wolf",
      "Tristan Payer",
      "Catharina Silvia Lisson",
      "Christoph Gerhard Lisson",
      "Meinrad Beer",
      "Timo Ropinski",
      "Michael G\u00f6tz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06549",
    "title": "Human Behavior-based Personalized Meal Recommendation and Menu Planning  Social System",
    "abstract": "The traditional dietary recommendation systems are basically nutrition or health-aware where the human feelings on food are ignored. Human affects vary when it comes to food cravings, and not all foods are appealing in all moods. A questionnaire-based and preference-aware meal recommendation system can be a solution. However, automated recognition of social affects on different foods and planning the menu considering nutritional demand and social-affect has some significant benefits of the questionnaire-based and preference-aware meal recommendations. A patient with severe illness, a person in a coma, or patients with locked-in syndrome and amyotrophic lateral sclerosis (ALS) cannot express their meal preferences. Therefore, the proposed framework includes a social-affective computing module to recognize the affects of different meals where the person's affect is detected using electroencephalography signals. EEG allows to capture the brain signals and analyze them to anticipate affective toward a food. In this study, we have used a 14-channel wireless Emotive Epoc+ to measure affectivity for different food items. A hierarchical ensemble method is applied to predict affectivity upon multiple feature extraction methods and TOPSIS (Technique for Order of Preference by Similarity to Ideal Solution) is used to generate a food list based on the predicted affectivity. In addition to the meal recommendation, an automated menu planning approach is also proposed considering a person's energy intake requirement, affectivity, and nutritional values of the different menus. The bin-packing algorithm is used for the personalized menu planning of breakfast, lunch, dinner, and snacks. The experimental findings reveal that the suggested affective computing, meal recommendation, and menu planning algorithms perform well across a variety of assessment parameters. ",
    "url": "https://arxiv.org/abs/2308.06549",
    "authors": [
      "Tanvir Islam",
      "Anika Rahman Joyita",
      "Md. Golam Rabiul Alam",
      "Mohammad Mehedi Hassan",
      "Md. Rafiul Hassan",
      "Raffaele Gravina"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06561",
    "title": "An Approximation Algorithm for Ancestral Maximum-Likelihood and  Phylogeography Inference Problems under Time Reversible Markov Evolutionary  Models",
    "abstract": "The ancestral maximum-likelihood and phylogeography problems are two fundamental problems involving evolutionary studies. The ancestral maximum-likelihood problem involves identifying a rooted tree alongside internal node sequences that maximizes the probability of observing a given set of sequences as leaves. The phylogeography problem extends the ancestral maximum-likelihood problem to incorporate geolocation of leaf and internal nodes. While a constant factor approximation algorithm has been established for the ancestral maximum-likelihood problem concerning two-state sequences, no such algorithm has been devised for any generalized instances of the problem. In this paper, we focus on a generalization of the two-state model, the time reversible Markov evolutionary models for sequences and geolocations. Under this evolutionary model, we present a $2\\log_2 k $-approximation algorithm, where $k$ is the number of input samples, addressing both the ancestral maximum-likelihood and phylogeography problems. This is the first approximation algorithm for the phylogeography problem. Furthermore, we show how to apply the algorithm on popular evolutionary models like generalized time-reversible (GTR) model and its specialization Jukes and Cantor 69 (JC69). ",
    "url": "https://arxiv.org/abs/2308.06561",
    "authors": [
      "Mohammad-Hadi Foroughmand-Araabi",
      "Sama Goliaei",
      "Kasra Alishahi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2308.06564",
    "title": "EquiDiff: A Conditional Equivariant Diffusion Model For Trajectory  Prediction",
    "abstract": "Accurate trajectory prediction is crucial for the safe and efficient operation of autonomous vehicles. The growing popularity of deep learning has led to the development of numerous methods for trajectory prediction. While deterministic deep learning models have been widely used, deep generative models have gained popularity as they learn data distributions from training data and account for trajectory uncertainties. In this study, we propose EquiDiff, a deep generative model for predicting future vehicle trajectories. EquiDiff is based on the conditional diffusion model, which generates future trajectories by incorporating historical information and random Gaussian noise. The backbone model of EquiDiff is an SO(2)-equivariant transformer that fully utilizes the geometric properties of location coordinates. In addition, we employ Recurrent Neural Networks and Graph Attention Networks to extract social interactions from historical trajectories. To evaluate the performance of EquiDiff, we conduct extensive experiments on the NGSIM dataset. Our results demonstrate that EquiDiff outperforms other baseline models in short-term prediction, but has slightly higher errors for long-term prediction. Furthermore, we conduct an ablation study to investigate the contribution of each component of EquiDiff to the prediction accuracy. Additionally, we present a visualization of the generation process of our diffusion model, providing insights into the uncertainty of the prediction. ",
    "url": "https://arxiv.org/abs/2308.06564",
    "authors": [
      "Kehua Chen",
      "Xianda Chen",
      "Zihan Yu",
      "Meixin Zhu",
      "Hai Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.06568",
    "title": "\"Zero Cost'' Majority Attacks on Permissionless Blockchains",
    "abstract": "The core premise of permissionless blockchains is their reliable and secure operation without the need to trust any individual agent. At the heart of blockchain consensus mechanisms is an explicit cost (whether work or stake) for participation in the network and the opportunity to add blocks to the blockchain. A key rationale for that cost is to make attacks on the network, which could be theoretically carried out if a majority of nodes were controlled by a single entity, too expensive to be worthwhile. We demonstrate that a majority attacker can successfully attack with a {\\em negative cost}, which shows that the protocol mechanisms are insufficient to create a secure network, and emphasizes the importance of socially driven mechanisms external to the protocol. At the same time, negative cost enables a new type of majority attack that is more likely to elude external scrutiny. ",
    "url": "https://arxiv.org/abs/2308.06568",
    "authors": [
      "Joshua S. Gans",
      "Hanna Halaburda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2308.06582",
    "title": "Gated Attention Coding for Training High-performance and Efficient  Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are emerging as an energy-efficient alternative to traditional artificial neural networks (ANNs) due to their unique spike-based event-driven nature. Coding is crucial in SNNs as it converts external input stimuli into spatio-temporal feature sequences. However, most existing deep SNNs rely on direct coding that generates powerless spike representation and lacks the temporal dynamics inherent in human vision. Hence, we introduce Gated Attention Coding (GAC), a plug-and-play module that leverages the multi-dimensional gated attention unit to efficiently encode inputs into powerful representations before feeding them into the SNN architecture. GAC functions as a preprocessing layer that does not disrupt the spike-driven nature of the SNN, making it amenable to efficient neuromorphic hardware implementation with minimal modifications. Through an observer model theoretical analysis, we demonstrate GAC's attention mechanism improves temporal dynamics and coding efficiency. Experiments on CIFAR10/100 and ImageNet datasets demonstrate that GAC achieves state-of-the-art accuracy with remarkable efficiency. Notably, we improve top-1 accuracy by 3.10\\% on CIFAR100 with only 6-time steps and 1.07\\% on ImageNet while reducing energy usage to 66.9\\% of the previous works. To our best knowledge, it is the first time to explore the attention-based dynamic coding scheme in deep SNNs, with exceptional effectiveness and efficiency on large-scale datasets. ",
    "url": "https://arxiv.org/abs/2308.06582",
    "authors": [
      "Xuerui Qiu",
      "Rui-Jie Zhu",
      "Yuhong Chou",
      "Zhaorui Wang",
      "Liang-jian Deng",
      "Guoqi Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.06585",
    "title": "Approximate Answering of Graph Queries",
    "abstract": "Knowledge graphs (KGs) are inherently incomplete because of incomplete world knowledge and bias in what is the input to the KG. Additionally, world knowledge constantly expands and evolves, making existing facts deprecated or introducing new ones. However, we would still want to be able to answer queries as if the graph were complete. In this chapter, we will give an overview of several methods which have been proposed to answer queries in such a setting. We will first provide an overview of the different query types which can be supported by these methods and datasets typically used for evaluation, as well as an insight into their limitations. Then, we give an overview of the different approaches and describe them in terms of expressiveness, supported graph types, and inference capabilities. ",
    "url": "https://arxiv.org/abs/2308.06585",
    "authors": [
      "Michael Cochez",
      "Dimitrios Alivanistos",
      "Erik Arakelyan",
      "Max Berrendorf",
      "Daniel Daza",
      "Mikhail Galkin",
      "Pasquale Minervini",
      "Mathias Niepert",
      "Hongyu Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.06596",
    "title": "On the Performance Trade-off of Distributed Integrated Sensing and  Communication Networks",
    "abstract": "In this letter, we analyze the performance trade-off in distributed integrated sensing and communication (ISAC) networks. Specifically, with the aid of stochastic geometry theory, we derive the probability of detection of that of the coverage given user number. Based on the analytical derivations, we provide a quantitative description of the performance limits and the performance trade-off between sensing and communication in a distributed ISAC network under the given transmit power and bandwidth budget. Extensive simulations are conducted and the numerical results validate the accuracy of our derivations. ",
    "url": "https://arxiv.org/abs/2308.06596",
    "authors": [
      "Xuran Li",
      "Shuaishuai Guo",
      "Tuo Li",
      "Xiaofeng Zou",
      "Dengwang Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.06612",
    "title": "On the Interplay of Convolutional Padding and Adversarial Robustness",
    "abstract": "It is common practice to apply padding prior to convolution operations to preserve the resolution of feature-maps in Convolutional Neural Networks (CNN). While many alternatives exist, this is often achieved by adding a border of zeros around the inputs. In this work, we show that adversarial attacks often result in perturbation anomalies at the image boundaries, which are the areas where padding is used. Consequently, we aim to provide an analysis of the interplay between padding and adversarial attacks and seek an answer to the question of how different padding modes (or their absence) affect adversarial robustness in various scenarios. ",
    "url": "https://arxiv.org/abs/2308.06612",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06615",
    "title": "Software refactoring and rewriting: from the perspective of code  transformations",
    "abstract": "To refactor already working code while keeping reliability, compatibility and perhaps security, we can borrow ideas from micropass/nanopass compilers. By treating the procedure of software refactoring as composing code transformations, and compressing repetitive transformations with automation tools, we can often obtain representations of refactoring processes short enough that their correctness can be analysed manually. Unlike in compilers, in refactoring we usually only need to consider the codebase in question, so regular text processing can be extensively used, fully exploiting patterns only present in the codebase. Aside from the direct application of code transformations from compilers, many other kinds of equivalence properties may also be exploited. In this paper, two refactoring projects are given as the main examples, where 10-100 times simplification has been achieved with the application of a few kinds of useful transformations. ",
    "url": "https://arxiv.org/abs/2308.06615",
    "authors": [
      "Yu Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.06619",
    "title": "Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?",
    "abstract": "Pruning is a widely used technique for reducing the size of deep neural networks while maintaining their performance. However, such a technique, despite being able to massively compress deep models, is hardly able to remove entire layers from a model (even when structured): is this an addressable task? In this study, we introduce EGP, an innovative Entropy Guided Pruning algorithm aimed at reducing the size of deep neural networks while preserving their performance. The key focus of EGP is to prioritize pruning connections in layers with low entropy, ultimately leading to their complete removal. Through extensive experiments conducted on popular models like ResNet-18 and Swin-T, our findings demonstrate that EGP effectively compresses deep neural networks while maintaining competitive performance levels. Our results not only shed light on the underlying mechanism behind the advantages of unstructured pruning, but also pave the way for further investigations into the intricate relationship between entropy, pruning techniques, and deep learning performance. The EGP algorithm and its insights hold great promise for advancing the field of network compression and optimization. The source code for EGP is released open-source. ",
    "url": "https://arxiv.org/abs/2308.06619",
    "authors": [
      "Liao Zhu",
      "Victor Qu\u00e9tu",
      "Van-Tam Nguyen",
      "Enzo Tartaglione"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06622",
    "title": "DFM-X: Augmentation by Leveraging Prior Knowledge of Shortcut Learning",
    "abstract": "Neural networks are prone to learn easy solutions from superficial statistics in the data, namely shortcut learning, which impairs generalization and robustness of models. We propose a data augmentation strategy, named DFM-X, that leverages knowledge about frequency shortcuts, encoded in Dominant Frequencies Maps computed for image classification models. We randomly select X% training images of certain classes for augmentation, and process them by retaining the frequencies included in the DFMs of other classes. This strategy compels the models to leverage a broader range of frequencies for classification, rather than relying on specific frequency sets. Thus, the models learn more deep and task-related semantics compared to their counterpart trained with standard setups. Unlike other commonly used augmentation techniques which focus on increasing the visual variations of training data, our method targets exploiting the original data efficiently, by distilling prior knowledge about destructive learning behavior of models from data. Our experimental results demonstrate that DFM-X improves robustness against common corruptions and adversarial attacks. It can be seamlessly integrated with other augmentation techniques to further enhance the robustness of models. ",
    "url": "https://arxiv.org/abs/2308.06622",
    "authors": [
      "Shunxin Wang",
      "Christoph Brune",
      "Raymond Veldhuis",
      "Nicola Strisciuglio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06628",
    "title": "Fusion-GRU: A Deep Learning Model for Future Bounding Box Prediction of  Traffic Agents in Risky Driving Videos",
    "abstract": "To ensure the safe and efficient navigation of autonomous vehicles and advanced driving assistance systems in complex traffic scenarios, predicting the future bounding boxes of surrounding traffic agents is crucial. However, simultaneously predicting the future location and scale of target traffic agents from the egocentric view poses challenges due to the vehicle's egomotion causing considerable field-of-view changes. Moreover, in anomalous or risky situations, tracking loss or abrupt motion changes limit the available observation time, requiring learning of cues within a short time window. Existing methods typically use a simple concatenation operation to combine different cues, overlooking their dynamics over time. To address this, this paper introduces the Fusion-Gated Recurrent Unit (Fusion-GRU) network, a novel encoder-decoder architecture for future bounding box localization. Unlike traditional GRUs, Fusion-GRU accounts for mutual and complex interactions among input features. Moreover, an intermediary estimator coupled with a self-attention aggregation layer is also introduced to learn sequential dependencies for long range prediction. Finally, a GRU decoder is employed to predict the future bounding boxes. The proposed method is evaluated on two publicly available datasets, ROL and HEV-I. The experimental results showcase the promising performance of the Fusion-GRU, demonstrating its effectiveness in predicting future bounding boxes of traffic agents. ",
    "url": "https://arxiv.org/abs/2308.06628",
    "authors": [
      "Muhammad Monjurul Karim",
      "Ruwen Qin",
      "Yinhai Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06629",
    "title": "Optimal FIFO grouping in public transit networks",
    "abstract": "This technical report is about grouping vehicles (so-called trips) in public transport into routes (or, as they are more commonly known: lines) so that two vehicles of a route do not overtake each other. We say that such a set of routes satisfies the FIFO property. An interesting question is: Given a set of trips, find a minimal FIFO grouping into routes. This question is especially interesting for route planning algorithms since a better route grouping leads to a better runtime. This contribution is structured as follows: First, all necessary details are formalised and defined, and then the algorithmic complexity of this problem is explained and proven. ",
    "url": "https://arxiv.org/abs/2308.06629",
    "authors": [
      "Patrick Steil"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.06635",
    "title": "3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking",
    "abstract": "Tracking 3D objects accurately and consistently is crucial for autonomous vehicles, enabling more reliable downstream tasks such as trajectory prediction and motion planning. Based on the substantial progress in object detection in recent years, the tracking-by-detection paradigm has become a popular choice due to its simplicity and efficiency. State-of-the-art 3D multi-object tracking (MOT) approaches typically rely on non-learned model-based algorithms such as Kalman Filter but require many manually tuned parameters. On the other hand, learning-based approaches face the problem of adapting the training to the online setting, leading to inevitable distribution mismatch between training and inference as well as suboptimal performance. In this work, we propose 3DMOTFormer, a learned geometry-based 3D MOT framework building upon the transformer architecture. We use an Edge-Augmented Graph Transformer to reason on the track-detection bipartite graph frame-by-frame and conduct data association via edge classification. To reduce the distribution mismatch between training and inference, we propose a novel online training strategy with an autoregressive and recurrent forward pass as well as sequential batch optimization. Using CenterPoint detections, our approach achieves 71.2% and 68.2% AMOTA on the nuScenes validation and test split, respectively. In addition, a trained 3DMOTFormer model generalizes well across different object detectors. Code is available at: https://github.com/dsx0511/3DMOTFormer. ",
    "url": "https://arxiv.org/abs/2308.06635",
    "authors": [
      "Shuxiao Ding",
      "Eike Rehder",
      "Lukas Schneider",
      "Marius Cordts",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06654",
    "title": "Polar Collision Grids: Effective Interaction Modelling for Pedestrian  Trajectory Prediction in Shared Space Using Collision Checks",
    "abstract": "Predicting pedestrians' trajectories is a crucial capability for autonomous vehicles' safe navigation, especially in spaces shared with pedestrians. Pedestrian motion in shared spaces is influenced by both the presence of vehicles and other pedestrians. Therefore, effectively modelling both pedestrian-pedestrian and pedestrian-vehicle interactions can increase the accuracy of the pedestrian trajectory prediction models. Despite the huge literature on ways to encode the effect of interacting agents on a pedestrian's predicted trajectory using deep-learning models, limited effort has been put into the effective selection of interacting agents. In the majority of cases, the interaction features used are mainly based on relative distances while paying less attention to the effect of the velocity and approaching direction in the interaction formulation. In this paper, we propose a heuristic-based process of selecting the interacting agents based on collision risk calculation. Focusing on interactions of potentially colliding agents with a target pedestrian, we propose the use of time-to-collision and the approach direction angle of two agents for encoding the interaction effect. This is done by introducing a novel polar collision grid map. Our results have shown predicted trajectories closer to the ground truth compared to existing methods (used as a baseline) on the HBS dataset. ",
    "url": "https://arxiv.org/abs/2308.06654",
    "authors": [
      "Mahsa Golchoubian",
      "Moojan Ghafurian",
      "Kerstin Dautenhahn",
      "Nasser Lashgarian Azad"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06658",
    "title": "Robust Localization of Aerial Vehicles via Active Control of Identical  Ground Vehicles",
    "abstract": "This paper addresses the problem of active collaborative localization in heterogeneous robot teams with unknown data association. It involves positioning a small number of identical unmanned ground vehicles (UGVs) at desired positions so that an unmanned aerial vehicle (UAV) can, through unlabelled measurements of UGVs, uniquely determine its global pose. We model the problem as a sequential two player game, in which the first player positions the UGVs and the second identifies the two distinct hypothetical poses of the UAV at which the sets of measurements to the UGVs differ by as little as possible. We solve the underlying problem from the vantage point of the first player for a subclass of measurement models using a mixture of local optimization and exhaustive search procedures. Real-world experiments with a team of UAV and UGVs show that our method can achieve centimeter-level global localization accuracy. We also show that our method consistently outperforms random positioning of UGVs by a large margin, with as much as a 90% reduction in position and angular estimation error. Our method can tolerate a significant amount of random as well as non-stochastic measurement noise. This indicates its potential for reliable state estimation on board size, weight, and power (SWaP) constrained UAVs. This work enables robust localization in perceptually-challenged GPS-denied environments, thus paving the road for large-scale multi-robot navigation and mapping. ",
    "url": "https://arxiv.org/abs/2308.06658",
    "authors": [
      "Igor Spasojevic",
      "Xu Liu",
      "Ankit Prabhu",
      "Alejandro Ribeiro",
      "George J. Pappas",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.06663",
    "title": "ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN",
    "abstract": "Anomaly detection in time series data, to identify points that deviate from normal behaviour, is a common problem in various domains such as manufacturing, medical imaging, and cybersecurity. Recently, Generative Adversarial Networks (GANs) are shown to be effective in detecting anomalies in time series data. The neural network architecture of GANs (i.e. Generator and Discriminator) can significantly improve anomaly detection accuracy. In this paper, we propose a new GAN model, named Adjusted-LSTM GAN (ALGAN), which adjusts the output of an LSTM network for improved anomaly detection in both univariate and multivariate time series data in an unsupervised setting. We evaluate the performance of ALGAN on 46 real-world univariate time series datasets and a large multivariate dataset that spans multiple domains. Our experiments demonstrate that ALGAN outperforms traditional, neural network-based, and other GAN-based methods for anomaly detection in time series data. ",
    "url": "https://arxiv.org/abs/2308.06663",
    "authors": [
      "Md Abul Bashar",
      "Richi Nayak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06672",
    "title": "A deep learning framework for multi-scale models based on  physics-informed neural networks",
    "abstract": "Physics-informed neural networks (PINN) combine deep neural networks with the solution of partial differential equations (PDEs), creating a new and promising research area for numerically solving PDEs. Faced with a class of multi-scale problems that include loss terms of different orders of magnitude in the loss function, it is challenging for standard PINN methods to obtain an available prediction. In this paper, we propose a new framework for solving multi-scale problems by reconstructing the loss function. The framework is based on the standard PINN method, and it modifies the loss function of the standard PINN method by applying different numbers of power operations to the loss terms of different magnitudes, so that the individual loss terms composing the loss function have approximately the same order of magnitude among themselves. In addition, we give a grouping regularization strategy, and this strategy can deal well with the problem which varies significantly in different subdomains. The proposed method enables loss terms with different magnitudes to be optimized simultaneously, and it advances the application of PINN for multi-scale problems. ",
    "url": "https://arxiv.org/abs/2308.06672",
    "authors": [
      "Yong Wang",
      "Yanzhong Yao",
      "Jiawei Guo",
      "Zhiming Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06679",
    "title": "Separable Gaussian Neural Networks: Structure, Analysis, and Function  Approximations",
    "abstract": "The Gaussian-radial-basis function neural network (GRBFNN) has been a popular choice for interpolation and classification. However, it is computationally intensive when the dimension of the input vector is high. To address this issue, we propose a new feedforward network - Separable Gaussian Neural Network (SGNN) by taking advantage of the separable property of Gaussian functions, which splits input data into multiple columns and sequentially feeds them into parallel layers formed by uni-variate Gaussian functions. This structure reduces the number of neurons from O(N^d) of GRBFNN to O(dN), which exponentially improves the computational speed of SGNN and makes it scale linearly as the input dimension increases. In addition, SGNN can preserve the dominant subspace of the Hessian matrix of GRBFNN in gradient descent training, leading to a similar level of accuracy to GRBFNN. It is experimentally demonstrated that SGNN can achieve 100 times speedup with a similar level of accuracy over GRBFNN on tri-variate function approximations. The SGNN also has better trainability and is more tuning-friendly than DNNs with RuLU and Sigmoid functions. For approximating functions with complex geometry, SGNN can lead to three orders of magnitude more accurate results than a RuLU-DNN with twice the number of layers and the number of neurons per layer. ",
    "url": "https://arxiv.org/abs/2308.06679",
    "authors": [
      "Siyuan Xing",
      "Jianqiao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06685",
    "title": "Video Captioning with Aggregated Features Based on Dual Graphs and Gated  Fusion",
    "abstract": "The application of video captioning models aims at translating the content of videos by using accurate natural language. Due to the complex nature inbetween object interaction in the video, the comprehensive understanding of spatio-temporal relations of objects remains a challenging task. Existing methods often fail in generating sufficient feature representations of video content. In this paper, we propose a video captioning model based on dual graphs and gated fusion: we adapt two types of graphs to generate feature representations of video content and utilize gated fusion to further understand these different levels of information. Using a dual-graphs model to generate appearance features and motion features respectively can utilize the content correlation in frames to generate various features from multiple perspectives. Among them, dual-graphs reasoning can enhance the content correlation in frame sequences to generate advanced semantic features; The gated fusion, on the other hand, aggregates the information in multiple feature representations for comprehensive video content understanding. The experiments conducted on worldly used datasets MSVD and MSR-VTT demonstrate state-of-the-art performance of our proposed approach. ",
    "url": "https://arxiv.org/abs/2308.06685",
    "authors": [
      "Yutao Jin",
      "Bin Liu",
      "Jing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06689",
    "title": "Estimator Meets Equilibrium Perspective: A Rectified Straight Through  Estimator for Binary Neural Networks Training",
    "abstract": "Binarization of neural networks is a dominant paradigm in neural networks compression. The pioneering work BinaryConnect uses Straight Through Estimator (STE) to mimic the gradients of the sign function, but it also causes the crucial inconsistency problem. Most of the previous methods design different estimators instead of STE to mitigate it. However, they ignore the fact that when reducing the estimating error, the gradient stability will decrease concomitantly. These highly divergent gradients will harm the model training and increase the risk of gradient vanishing and gradient exploding. To fully take the gradient stability into consideration, we present a new perspective to the BNNs training, regarding it as the equilibrium between the estimating error and the gradient stability. In this view, we firstly design two indicators to quantitatively demonstrate the equilibrium phenomenon. In addition, in order to balance the estimating error and the gradient stability well, we revise the original straight through estimator and propose a power function based estimator, Rectified Straight Through Estimator (ReSTE for short). Comparing to other estimators, ReSTE is rational and capable of flexibly balancing the estimating error with the gradient stability. Extensive experiments on CIFAR-10 and ImageNet datasets show that ReSTE has excellent performance and surpasses the state-of-the-art methods without any auxiliary modules or losses. ",
    "url": "https://arxiv.org/abs/2308.06689",
    "authors": [
      "Xiao-Ming Wu",
      "Dian Zheng",
      "Zuhao Liu",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06692",
    "title": "SimMatchV2: Semi-Supervised Learning with Graph Consistency",
    "abstract": "Semi-Supervised image classification is one of the most fundamental problem in computer vision, which significantly reduces the need for human labor. In this paper, we introduce a new semi-supervised learning algorithm - SimMatchV2, which formulates various consistency regularizations between labeled and unlabeled data from the graph perspective. In SimMatchV2, we regard the augmented view of a sample as a node, which consists of a label and its corresponding representation. Different nodes are connected with the edges, which are measured by the similarity of the node representations. Inspired by the message passing and node classification in graph theory, we propose four types of consistencies, namely 1) node-node consistency, 2) node-edge consistency, 3) edge-edge consistency, and 4) edge-node consistency. We also uncover that a simple feature normalization can reduce the gaps of the feature norm between different augmented views, significantly improving the performance of SimMatchV2. Our SimMatchV2 has been validated on multiple semi-supervised learning benchmarks. Notably, with ResNet-50 as our backbone and 300 epochs of training, SimMatchV2 achieves 71.9\\% and 76.2\\% Top-1 Accuracy with 1\\% and 10\\% labeled examples on ImageNet, which significantly outperforms the previous methods and achieves state-of-the-art performance. Code and pre-trained models are available at \\href{https://github.com/mingkai-zheng/SimMatchV2}{https://github.com/mingkai-zheng/SimMatchV2}. ",
    "url": "https://arxiv.org/abs/2308.06692",
    "authors": [
      "Mingkai Zheng",
      "Shan You",
      "Lang Huang",
      "Chen Luo",
      "Fei Wang",
      "Chen Qian",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06696",
    "title": "MACO: A Modality Adversarial and Contrastive Framework for  Modality-missing Multi-modal Knowledge Graph Completion",
    "abstract": "Recent years have seen significant advancements in multi-modal knowledge graph completion (MMKGC). MMKGC enhances knowledge graph completion (KGC) by integrating multi-modal entity information, thereby facilitating the discovery of unobserved triples in the large-scale knowledge graphs (KGs). Nevertheless, existing methods emphasize the design of elegant KGC models to facilitate modality interaction, neglecting the real-life problem of missing modalities in KGs. The missing modality information impedes modal interaction, consequently undermining the model's performance. In this paper, we propose a modality adversarial and contrastive framework (MACO) to solve the modality-missing problem in MMKGC. MACO trains a generator and discriminator adversarially to generate missing modality features that can be incorporated into the MMKGC model. Meanwhile, we design a cross-modal contrastive loss to improve the performance of the generator. Experiments on public benchmarks with further explorations demonstrate that MACO could achieve state-of-the-art results and serve as a versatile framework to bolster various MMKGC models. Our code and benchmark data are available at https://github.com/zjukg/MACO. ",
    "url": "https://arxiv.org/abs/2308.06696",
    "authors": [
      "Yichi Zhang",
      "Zhuo Chen",
      "Wen Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2308.06699",
    "title": "Neural Super-Resolution for Real-time Rendering with Radiance  Demodulation",
    "abstract": "Rendering high-resolution images in real-time applications (e.g., video games, virtual reality) is time-consuming, thus super-resolution technology becomes more and more crucial in real-time rendering. However, it is still challenging to preserve sharp texture details, keep the temporal stability and avoid the ghosting artifacts in the real-time rendering super-resolution. To this end, we introduce radiance demodulation into real-time rendering super-resolution, separating the rendered image or radiance into a lighting component and a material component, due to the fact that the light component tends to be smoother than the rendered image and the high-resolution material component with detailed textures can be easily obtained. Therefore, we perform the super-resolution only on the lighting component and re-modulate with the high-resolution material component to obtain the final super-resolution image. In this way, the texture details can be preserved much better. Then, we propose a reliable warping module by explicitly pointing out the unreliable occluded regions with a motion mask to remove the ghosting artifacts. We further enhance the temporal stability by designing a frame-recurrent neural network to aggregate the previous and current frames, which better captures the spatial-temporal correlation between reconstructed frames. As a result, our method is able to produce temporally stable results in real-time rendering with high-quality details, even in the highly challenging 4 $\\times$ 4 super-resolution scenarios. ",
    "url": "https://arxiv.org/abs/2308.06699",
    "authors": [
      "Jia Li",
      "Ziling Chen",
      "Xiaolong Wu",
      "Lu Wang",
      "Beibei Wang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.06701",
    "title": "Camouflaged Image Synthesis Is All You Need to Boost Camouflaged  Detection",
    "abstract": "Camouflaged objects that blend into natural scenes pose significant challenges for deep-learning models to detect and synthesize. While camouflaged object detection is a crucial task in computer vision with diverse real-world applications, this research topic has been constrained by limited data availability. We propose a framework for synthesizing camouflage data to enhance the detection of camouflaged objects in natural scenes. Our approach employs a generative model to produce realistic camouflage images, which can be used to train existing object detection models. Specifically, we use a camouflage environment generator supervised by a camouflage distribution classifier to synthesize the camouflage images, which are then fed into our generator to expand the dataset. Our framework outperforms the current state-of-the-art method on three datasets (COD10k, CAMO, and CHAMELEON), demonstrating its effectiveness in improving camouflaged object detection. This approach can serve as a plug-and-play data generation and augmentation module for existing camouflaged object detection tasks and provides a novel way to introduce more diversity and distributions into current camouflage datasets. ",
    "url": "https://arxiv.org/abs/2308.06701",
    "authors": [
      "Haichao Zhang",
      "Can Qin",
      "Yu Yin",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06703",
    "title": "Understanding the robustness difference between stochastic gradient  descent and adaptive gradient methods",
    "abstract": "Stochastic gradient descent (SGD) and adaptive gradient methods, such as Adam and RMSProp, have been widely used in training deep neural networks. We empirically show that while the difference between the standard generalization performance of models trained using these methods is small, those trained using SGD exhibit far greater robustness under input perturbations. Notably, our investigation demonstrates the presence of irrelevant frequencies in natural datasets, where alterations do not affect models' generalization performance. However, models trained with adaptive methods show sensitivity to these changes, suggesting that their use of irrelevant frequencies can lead to solutions sensitive to perturbations. To better understand this difference, we study the learning dynamics of gradient descent (GD) and sign gradient descent (signGD) on a synthetic dataset that mirrors natural signals. With a three-dimensional input space, the models optimized with GD and signGD have standard risks close to zero but vary in their adversarial risks. Our result shows that linear models' robustness to $\\ell_2$-norm bounded changes is inversely proportional to the model parameters' weight norm: a smaller weight norm implies better robustness. In the context of deep learning, our experiments show that SGD-trained neural networks show smaller Lipschitz constants, explaining the better robustness to input perturbations than those trained with adaptive gradient methods. ",
    "url": "https://arxiv.org/abs/2308.06703",
    "authors": [
      "Avery Ma",
      "Yangchen Pan",
      "Amir-massoud Farahmand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06707",
    "title": "Condition-Adaptive Graph Convolution Learning for Skeleton-Based Gait  Recognition",
    "abstract": "Graph convolutional networks have been widely applied in skeleton-based gait recognition. A key challenge in this task is to distinguish the individual walking styles of different subjects across various views. Existing state-of-the-art methods employ uniform convolutions to extract features from diverse sequences and ignore the effects of viewpoint changes. To overcome these limitations, we propose a condition-adaptive graph (CAG) convolution network that can dynamically adapt to the specific attributes of each skeleton sequence and the corresponding view angle. In contrast to using fixed weights for all joints and sequences, we introduce a joint-specific filter learning (JSFL) module in the CAG method, which produces sequence-adaptive filters at the joint level. The adaptive filters capture fine-grained patterns that are unique to each joint, enabling the extraction of diverse spatial-temporal information about body parts. Additionally, we design a view-adaptive topology learning (VATL) module that generates adaptive graph topologies. These graph topologies are used to correlate the joints adaptively according to the specific view conditions. Thus, CAG can simultaneously adjust to various walking styles and viewpoints. Experiments on the two most widely used datasets (i.e., CASIA-B and OU-MVLP) show that CAG surpasses all previous skeleton-based methods. Moreover, the recognition performance can be enhanced by simply combining CAG with appearance-based methods, demonstrating the ability of CAG to provide useful complementary information.The source code will be available at https://github.com/OliverHxh/CAG. ",
    "url": "https://arxiv.org/abs/2308.06707",
    "authors": [
      "Xiaohu Huang",
      "Xinggang Wang",
      "Zhidianqiu Jin",
      "Bo Yang",
      "Botao He",
      "Bin Feng",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06712",
    "title": "Compositional Feature Augmentation for Unbiased Scene Graph Generation",
    "abstract": "Scene Graph Generation (SGG) aims to detect all the visual relation triplets <sub, pred, obj> in a given image. With the emergence of various advanced techniques for better utilizing both the intrinsic and extrinsic information in each relation triplet, SGG has achieved great progress over the recent years. However, due to the ubiquitous long-tailed predicate distributions, today's SGG models are still easily biased to the head predicates. Currently, the most prevalent debiasing solutions for SGG are re-balancing methods, e.g., changing the distributions of original training samples. In this paper, we argue that all existing re-balancing strategies fail to increase the diversity of the relation triplet features of each predicate, which is critical for robust SGG. To this end, we propose a novel Compositional Feature Augmentation (CFA) strategy, which is the first unbiased SGG work to mitigate the bias issue from the perspective of increasing the diversity of triplet features. Specifically, we first decompose each relation triplet feature into two components: intrinsic feature and extrinsic feature, which correspond to the intrinsic characteristics and extrinsic contexts of a relation triplet, respectively. Then, we design two different feature augmentation modules to enrich the feature diversity of original relation triplets by replacing or mixing up either their intrinsic or extrinsic features from other samples. Due to its model-agnostic nature, CFA can be seamlessly incorporated into various SGG frameworks. Extensive ablations have shown that CFA achieves a new state-of-the-art performance on the trade-off between different metrics. ",
    "url": "https://arxiv.org/abs/2308.06712",
    "authors": [
      "Lin Li",
      "Guikun Chen",
      "Jun Xiao",
      "Yi Yang",
      "Chunping Wang",
      "Long Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06713",
    "title": "LAW-Diffusion: Complex Scene Generation by Diffusion with Layouts",
    "abstract": "Thanks to the rapid development of diffusion models, unprecedented progress has been witnessed in image synthesis. Prior works mostly rely on pre-trained linguistic models, but a text is often too abstract to properly specify all the spatial properties of an image, e.g., the layout configuration of a scene, leading to the sub-optimal results of complex scene generation. In this paper, we achieve accurate complex scene generation by proposing a semantically controllable Layout-AWare diffusion model, termed LAW-Diffusion. Distinct from the previous Layout-to-Image generation (L2I) methods that only explore category-aware relationships, LAW-Diffusion introduces a spatial dependency parser to encode the location-aware semantic coherence across objects as a layout embedding and produces a scene with perceptually harmonious object styles and contextual relations. To be specific, we delicately instantiate each object's regional semantics as an object region map and leverage a location-aware cross-object attention module to capture the spatial dependencies among those disentangled representations. We further propose an adaptive guidance schedule for our layout guidance to mitigate the trade-off between the regional semantic alignment and the texture fidelity of generated objects. Moreover, LAW-Diffusion allows for instance reconfiguration while maintaining the other regions in a synthesized image by introducing a layout-aware latent grafting mechanism to recompose its local regional semantics. To better verify the plausibility of generated scenes, we propose a new evaluation metric for the L2I task, dubbed Scene Relation Score (SRS) to measure how the images preserve the rational and harmonious relations among contextual objects. Comprehensive experiments demonstrate that our LAW-Diffusion yields the state-of-the-art generative performance, especially with coherent object relations. ",
    "url": "https://arxiv.org/abs/2308.06713",
    "authors": [
      "Binbin Yang",
      "Yi Luo",
      "Ziliang Chen",
      "Guangrun Wang",
      "Xiaodan Liang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06714",
    "title": "Learning on Graphs with Out-of-Distribution Nodes",
    "abstract": "Graph Neural Networks (GNNs) are state-of-the-art models for performing prediction tasks on graphs. While existing GNNs have shown great performance on various tasks related to graphs, little attention has been paid to the scenario where out-of-distribution (OOD) nodes exist in the graph during training and inference. Borrowing the concept from CV and NLP, we define OOD nodes as nodes with labels unseen from the training set. Since a lot of networks are automatically constructed by programs, real-world graphs are often noisy and may contain nodes from unknown distributions. In this work, we define the problem of graph learning with out-of-distribution nodes. Specifically, we aim to accomplish two tasks: 1) detect nodes which do not belong to the known distribution and 2) classify the remaining nodes to be one of the known classes. We demonstrate that the connection patterns in graphs are informative for outlier detection, and propose Out-of-Distribution Graph Attention Network (OODGAT), a novel GNN model which explicitly models the interaction between different kinds of nodes and separate inliers from outliers during feature propagation. Extensive experiments show that OODGAT outperforms existing outlier detection methods by a large margin, while being better or comparable in terms of in-distribution classification. ",
    "url": "https://arxiv.org/abs/2308.06714",
    "authors": [
      "Yu Song",
      "Donglin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06718",
    "title": "Generalized Independent Noise Condition for Estimating Causal Structure  with Latent Variables",
    "abstract": "We investigate the challenging task of learning causal structure in the presence of latent variables, including locating latent variables and determining their quantity, and identifying causal relationships among both latent and observed variables. To address this, we propose a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. Specifically, for two observed random vectors $\\bf{Y}$ and $\\bf{Z}$, GIN holds if and only if $\\omega^{\\intercal}\\mathbf{Y}$ and $\\mathbf{Z}$ are independent, where $\\omega$ is a non-zero parameter vector determined by the cross-covariance between $\\mathbf{Y}$ and $\\mathbf{Z}$. We then give necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous set $\\mathcal{S}$ relative to the parent set of $\\mathbf{Y}$ (w.r.t. the causal ordering), such that $\\mathcal{S}$ d-separates $\\mathbf{Y}$ from $\\mathbf{Z}$. Interestingly, we find that the independent noise condition (i.e., if there is no confounder, causes are independent of the residual derived from regressing the effect on the causes) can be seen as a special case of GIN. With such a connection between GIN and latent causal structures, we further leverage the proposed GIN condition, together with a well-designed search procedure, to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. We show that the underlying causal structure of a LiNGLaH is identifiable in light of GIN conditions under mild assumptions. Experimental results show the effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2308.06718",
    "authors": [
      "Feng Xie",
      "Biwei Huang",
      "Zhengming Chen",
      "Ruichu Cai",
      "Clark Glymour",
      "Zhi Geng",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2308.06719",
    "title": "3D Scene Graph Prediction on Point Clouds Using Knowledge Graphs",
    "abstract": "3D scene graph prediction is a task that aims to concurrently predict object classes and their relationships within a 3D environment. As these environments are primarily designed by and for humans, incorporating commonsense knowledge regarding objects and their relationships can significantly constrain and enhance the prediction of the scene graph. In this paper, we investigate the application of commonsense knowledge graphs for 3D scene graph prediction on point clouds of indoor scenes. Through experiments conducted on a real-world indoor dataset, we demonstrate that integrating external commonsense knowledge via the message-passing method leads to a 15.0 % improvement in scene graph prediction accuracy with external knowledge and $7.96\\%$ with internal knowledge when compared to state-of-the-art algorithms. We also tested in the real world with 10 frames per second for scene graph generation to show the usage of the model in a more realistic robotics setting. ",
    "url": "https://arxiv.org/abs/2308.06719",
    "authors": [
      "Yiding Qiu",
      "Henrik I. Christensen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06732",
    "title": "UD-MAC: Delay Tolerant Multiple Access Control Protocol for Unmanned  Aerial Vehicle Networks",
    "abstract": "In unmanned aerial vehicle (UAV) networks, high-capacity data transmission is of utmost importance for applications such as intelligent transportation, smart cities, and forest monitoring, which rely on the mobility of UAVs to collect and transmit large amount of data, including video and image data. Due to the short flight time of UAVs, the network capacity will be reduced when they return to the ground unit for charging. Hence, we suggest that UAVs can apply a store-carry-and-forward (SCF) transmission mode to carry packets on their way back to the ground unit for improving network throughput. In this paper, we propose a novel protocol, named UAV delay-tolerant multiple access control (UD-MAC), which can support different transmission modes in UAV networks. We set a higher priority for SCF transmission and analyze the probability of being in SCF mode to derive network throughput. The simulation results show that the network throughput of UD-MAC is improved by 57% to 83% compared to VeMAC. ",
    "url": "https://arxiv.org/abs/2308.06732",
    "authors": [
      "Yingying Zou",
      "Zhiqing Wei",
      "Yanpeng Cui",
      "Xinyi Liu",
      "Zhiyong Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.06741",
    "title": "Heterogeneous Multi-Agent Reinforcement Learning via Mirror Descent  Policy Optimization",
    "abstract": "This paper presents an extension of the Mirror Descent method to overcome challenges in cooperative Multi-Agent Reinforcement Learning (MARL) settings, where agents have varying abilities and individual policies. The proposed Heterogeneous-Agent Mirror Descent Policy Optimization (HAMDPO) algorithm utilizes the multi-agent advantage decomposition lemma to enable efficient policy updates for each agent while ensuring overall performance improvements. By iteratively updating agent policies through an approximate solution of the trust-region problem, HAMDPO guarantees stability and improves performance. Moreover, the HAMDPO algorithm is capable of handling both continuous and discrete action spaces for heterogeneous agents in various MARL problems. We evaluate HAMDPO on Multi-Agent MuJoCo and StarCraftII tasks, demonstrating its superiority over state-of-the-art algorithms such as HATRPO and HAPPO. These results suggest that HAMDPO is a promising approach for solving cooperative MARL problems and could potentially be extended to address other challenging problems in the field of MARL. ",
    "url": "https://arxiv.org/abs/2308.06741",
    "authors": [
      "Mohammad Mehdi Nasiri",
      "Mansoor Rezghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2308.06748",
    "title": "Target before Shooting: Accurate Anomaly Detection and Localization  under One Millisecond via Cascade Patch Retrieval",
    "abstract": "In this work, by re-examining the \"matching\" nature of Anomaly Detection (AD), we propose a new AD framework that simultaneously enjoys new records of AD accuracy and dramatically high running speed. In this framework, the anomaly detection problem is solved via a cascade patch retrieval procedure that retrieves the nearest neighbors for each test image patch in a coarse-to-fine fashion. Given a test sample, the top-K most similar training images are first selected based on a robust histogram matching process. Secondly, the nearest neighbor of each test patch is retrieved over the similar geometrical locations on those \"global nearest neighbors\", by using a carefully trained local metric. Finally, the anomaly score of each test image patch is calculated based on the distance to its \"local nearest neighbor\" and the \"non-background\" probability. The proposed method is termed \"Cascade Patch Retrieval\" (CPR) in this work. Different from the conventional patch-matching-based AD algorithms, CPR selects proper \"targets\" (reference images and locations) before \"shooting\" (patch-matching). On the well-acknowledged MVTec AD, BTAD and MVTec-3D AD datasets, the proposed algorithm consistently outperforms all the comparing SOTA methods by remarkable margins, measured by various AD metrics. Furthermore, CPR is extremely efficient. It runs at the speed of 113 FPS with the standard setting while its simplified version only requires less than 1 ms to process an image at the cost of a trivial accuracy drop. The code of CPR is available at https://github.com/flyinghu123/CPR. ",
    "url": "https://arxiv.org/abs/2308.06748",
    "authors": [
      "Hanxi Li",
      "Jianfei Hu",
      "Bo Li",
      "Hao Chen",
      "Yongbin Zheng",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06763",
    "title": "Discovering the Symptom Patterns of COVID-19 from Recovered and Deceased  Patients Using Apriori Association Rule Mining",
    "abstract": "The COVID-19 pandemic has a devastating impact globally, claiming millions of lives and causing significant social and economic disruptions. In order to optimize decision-making and allocate limited resources, it is essential to identify COVID-19 symptoms and determine the severity of each case. Machine learning algorithms offer a potent tool in the medical field, particularly in mining clinical datasets for useful information and guiding scientific decisions. Association rule mining is a machine learning technique for extracting hidden patterns from data. This paper presents an application of association rule mining based Apriori algorithm to discover symptom patterns from COVID-19 patients. The study, using 2875 records of patient, identified the most common symptoms as apnea (72%), cough (64%), fever (59%), weakness (18%), myalgia (14.5%), and sore throat (12%). The proposed method provides clinicians with valuable insight into disease that can assist them in managing and treating it effectively. ",
    "url": "https://arxiv.org/abs/2308.06763",
    "authors": [
      "Mohammad Dehghani",
      "Zahra Yazdanparast",
      "Mobin Mohammadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2308.06767",
    "title": "A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis,  and Recommendations",
    "abstract": "Modern deep neural networks, particularly recent large language models, come with massive model sizes that require significant computational and storage resources. To enable the deployment of modern models on resource-constrained environments and accelerate inference time, researchers have increasingly explored pruning techniques as a popular research direction in neural network compression. However, there is a dearth of up-to-date comprehensive review papers on pruning. To address this issue, in this survey, we provide a comprehensive review of existing research works on deep neural network pruning in a taxonomy of 1) universal/specific speedup, 2) when to prune, 3) how to prune, and 4) fusion of pruning and other compression techniques. We then provide a thorough comparative analysis of seven pairs of contrast settings for pruning (e.g., unstructured/structured) and explore emerging topics, including post-training pruning, different levels of supervision for pruning, and broader applications (e.g., adversarial robustness) to shed light on the commonalities and differences of existing methods and lay the foundation for further method development. To facilitate future research, we build a curated collection of datasets, networks, and evaluations on different applications. Finally, we provide some valuable recommendations on selecting pruning methods and prospect promising research directions. We build a repository at https://github.com/hrcheng1066/awesome-pruning. ",
    "url": "https://arxiv.org/abs/2308.06767",
    "authors": [
      "Hongrong Cheng",
      "Miao Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06780",
    "title": "Neural Networks at a Fraction with Pruned Quaternions",
    "abstract": "Contemporary state-of-the-art neural networks have increasingly large numbers of parameters, which prevents their deployment on devices with limited computational power. Pruning is one technique to remove unnecessary weights and reduce resource requirements for training and inference. In addition, for ML tasks where the input data is multi-dimensional, using higher-dimensional data embeddings such as complex numbers or quaternions has been shown to reduce the parameter count while maintaining accuracy. In this work, we conduct pruning on real and quaternion-valued implementations of different architectures on classification tasks. We find that for some architectures, at very high sparsity levels, quaternion models provide higher accuracies than their real counterparts. For example, at the task of image classification on CIFAR-10 using Conv-4, at $3\\%$ of the number of parameters as the original model, the pruned quaternion version outperforms the pruned real by more than $10\\%$. Experiments on various network architectures and datasets show that for deployment in extremely resource-constrained environments, a sparse quaternion network might be a better candidate than a real sparse model of similar architecture. ",
    "url": "https://arxiv.org/abs/2308.06780",
    "authors": [
      "Sahel Mohammad Iqbal",
      "Subhankar Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06787",
    "title": "RMP-Loss: Regularizing Membrane Potential Distribution for Spiking  Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) as one of the biology-inspired models have received much attention recently. It can significantly reduce energy consumption since they quantize the real-valued membrane potentials to 0/1 spikes to transmit information thus the multiplications of activations and weights can be replaced by additions when implemented on hardware. However, this quantization mechanism will inevitably introduce quantization error, thus causing catastrophic information loss. To address the quantization error problem, we propose a regularizing membrane potential loss (RMP-Loss) to adjust the distribution which is directly related to quantization error to a range close to the spikes. Our method is extremely simple to implement and straightforward to train an SNN. Furthermore, it is shown to consistently outperform previous state-of-the-art methods over different network architectures and datasets. ",
    "url": "https://arxiv.org/abs/2308.06787",
    "authors": [
      "Yufei Guo",
      "Xiaode Liu",
      "Yuanpei Chen",
      "Liwen Zhang",
      "Weihang Peng",
      "Yuhan Zhang",
      "Xuhui Huang",
      "Zhe Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06801",
    "title": "SAILOR: Structural Augmentation Based Tail Node Representation Learning",
    "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in representation learning for graphs recently. However, the effectiveness of GNNs, which capitalize on the key operation of message propagation, highly depends on the quality of the topology structure. Most of the graphs in real-world scenarios follow a long-tailed distribution on their node degrees, that is, a vast majority of the nodes in the graph are tail nodes with only a few connected edges. GNNs produce inferior node representations for tail nodes since they lack structural information. In the pursuit of promoting the expressiveness of GNNs for tail nodes, we explore how the deficiency of structural information deteriorates the performance of tail nodes and propose a general Structural Augmentation based taIL nOde Representation learning framework, dubbed as SAILOR, which can jointly learn to augment the graph structure and extract more informative representations for tail nodes. Extensive experiments on public benchmark datasets demonstrate that SAILOR can significantly improve the tail node representations and outperform the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2308.06801",
    "authors": [
      "Jie Liao",
      "Jintang Li",
      "Liang Chen",
      "Bingzhe Wu",
      "Yatao Bian",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06817",
    "title": "The Asymptotic Capacity of $X$-Secure $T$-Private Linear Computation  with Graph Based Replicated Storage",
    "abstract": "The problem of $X$-secure $T$-private linear computation with graph based replicated storage (GXSTPLC) is to enable the user to retrieve a linear combination of messages privately from a set of $N$ distributed servers where every message is only allowed to store among a subset of servers subject to an $X$-security constraint, i.e., any groups of up to $X$ colluding servers must reveal nothing about the messages. Besides, any groups of up to $T$ servers cannot learn anything about the coefficients of the linear combination retrieved by the user. In this work, we completely characterize the asymptotic capacity of GXSTPLC, i.e., the supremum of average number of desired symbols retrieved per downloaded symbol, in the limit as the number of messages $K$ approaches infinity. Specifically, it is shown that a prior linear programming based upper bound on the asymptotic capacity of GXSTPLC due to Jia and Jafar is tight by constructing achievability schemes. Notably, our achievability scheme also settles the exact capacity (i.e., for finite $K$) of $X$-secure linear combination with graph based replicated storage (GXSLC). Our achievability proof builds upon an achievability scheme for a closely related problem named asymmetric $\\mathbf{X}$-secure $\\mathbf{T}$-private linear computation with graph based replicated storage (Asymm-GXSTPLC) that guarantees non-uniform security and privacy levels across messages and coefficients. In particular, by carefully designing Asymm-GXSTPLC settings for GXSTPLC problems, the corresponding Asymm-GXSTPLC schemes can be reduced to asymptotic capacity achieving schemes for GXSTPLC. In regard to the achievability scheme for Asymm-GXSTPLC, interesting aspects of our construction include a novel query and answer design which makes use of a Vandermonde decomposition of Cauchy matrices, and a trade-off among message replication, security and privacy thresholds. ",
    "url": "https://arxiv.org/abs/2308.06817",
    "authors": [
      "Haobo Jia",
      "Zhuqing Jia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.06819",
    "title": "SoK: Realistic Adversarial Attacks and Defenses for Intelligent Network  Intrusion Detection",
    "abstract": "Machine Learning (ML) can be incredibly valuable to automate anomaly detection and cyber-attack classification, improving the way that Network Intrusion Detection (NID) is performed. However, despite the benefits of ML models, they are highly susceptible to adversarial cyber-attack examples specifically crafted to exploit them. A wide range of adversarial attacks have been created and researchers have worked on various defense strategies to safeguard ML models, but most were not intended for the specific constraints of a communication network and its communication protocols, so they may lead to unrealistic examples in the NID domain. This Systematization of Knowledge (SoK) consolidates and summarizes the state-of-the-art adversarial learning approaches that can generate realistic examples and could be used in real ML development and deployment scenarios with real network traffic flows. This SoK also describes the open challenges regarding the use of adversarial ML in the NID domain, defines the fundamental properties that are required for an adversarial example to be realistic, and provides guidelines for researchers to ensure that their future experiments are adequate for a real communication network. ",
    "url": "https://arxiv.org/abs/2308.06819",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Isabel Pra\u00e7a",
      "Eva Maia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.06822",
    "title": "Approximate and Weighted Data Reconstruction Attack in Federated  Learning",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that enables multiple clients to collaborate on building a machine learning model without sharing their private data. Although FL is considered privacy-preserved by design, recent data reconstruction attacks demonstrate that an attacker can recover clients' training data based on the parameters shared in FL. However, most existing methods fail to attack the most widely used horizontal Federated Averaging (FedAvg) scenario, where clients share model parameters after multiple local training steps. To tackle this issue, we propose an interpolation-based approximation method, which makes attacking FedAvg scenarios feasible by generating the intermediate model updates of the clients' local training processes. Then, we design a layer-wise weighted loss function to improve the data quality of reconstruction. We assign different weights to model updates in different layers concerning the neural network structure, with the weights tuned by Bayesian optimization. Finally, experimental results validate the superiority of our proposed approximate and weighted attack (AWA) method over the other state-of-the-art methods, as demonstrated by the substantial improvement in different evaluation metrics for image data reconstructions. ",
    "url": "https://arxiv.org/abs/2308.06822",
    "authors": [
      "Ziqi Wang",
      "Yongcun Song",
      "Enrique Zuazua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.06823",
    "title": "Exploration of graphs with excluded minors",
    "abstract": "We study the online graph exploration problem proposed by Kalyanasundaram and Pruhs (1994) and prove a constant competitive ratio on minor-free graphs. This result encompasses and significantly extends the graph classes that were previously known to admit a constant competitive ratio. The main ingredient of our proof is that we find a connection between the performance of the particular exploration algorithm Blocking and the existence of light spanners. Conversely, we exploit this connection to construct light spanners of bounded genus graphs. In particular, we achieve a lightness that improves on the best known upper bound for genus g>0 and recovers the known tight bound for the planar case (g=0). ",
    "url": "https://arxiv.org/abs/2308.06823",
    "authors": [
      "Julia Baligacs",
      "Yann Disser",
      "Irene Heinrich",
      "Pascal Schweitzer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2308.06827",
    "title": "Reinforcement Graph Clustering with Unknown Cluster Number",
    "abstract": "Deep graph clustering, which aims to group nodes into disjoint clusters by neural networks in an unsupervised manner, has attracted great attention in recent years. Although the performance has been largely improved, the excellent performance of the existing methods heavily relies on an accurately predefined cluster number, which is not always available in the real-world scenario. To enable the deep graph clustering algorithms to work without the guidance of the predefined cluster number, we propose a new deep graph clustering method termed Reinforcement Graph Clustering (RGC). In our proposed method, cluster number determination and unsupervised representation learning are unified into a uniform framework by the reinforcement learning mechanism. Concretely, the discriminative node representations are first learned with the contrastive pretext task. Then, to capture the clustering state accurately with both local and global information in the graph, both node and cluster states are considered. Subsequently, at each state, the qualities of different cluster numbers are evaluated by the quality network, and the greedy action is executed to determine the cluster number. In order to conduct feedback actions, the clustering-oriented reward function is proposed to enhance the cohesion of the same clusters and separate the different clusters. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method. The source code of RGC is shared at https://github.com/yueliu1999/RGC and a collection (papers, codes and, datasets) of deep graph clustering is shared at https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering on Github. ",
    "url": "https://arxiv.org/abs/2308.06827",
    "authors": [
      "Yue Liu",
      "Ke Liang",
      "Jun Xia",
      "Xihong Yang",
      "Sihang Zhou",
      "Meng Liu",
      "Xinwang Liu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06838",
    "title": "Generalizing Topological Graph Neural Networks with Paths",
    "abstract": "While Graph Neural Networks (GNNs) have made significant strides in diverse areas, they are hindered by a theoretical constraint known as the 1-Weisfeiler-Lehmann test. Even though latest advancements in higher-order GNNs can overcome this boundary, they typically center around certain graph components like cliques or cycles. However, our investigation goes a different route. We put emphasis on paths, which are inherent in every graph. We are able to construct a more general topological perspective and form a bridge to certain established theories about other topological domains. Interestingly, without any assumptions on graph sub-structures, our approach surpasses earlier techniques in this field, achieving state-of-the-art performance on several benchmarks. ",
    "url": "https://arxiv.org/abs/2308.06838",
    "authors": [
      "Quang Truong",
      "Peter Chin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06849",
    "title": "When Monte-Carlo Dropout Meets Multi-Exit: Optimizing Bayesian Neural  Networks on FPGA",
    "abstract": "Bayesian Neural Networks (BayesNNs) have demonstrated their capability of providing calibrated prediction for safety-critical applications such as medical imaging and autonomous driving. However, the high algorithmic complexity and the poor hardware performance of BayesNNs hinder their deployment in real-life applications. To bridge this gap, this paper proposes a novel multi-exit Monte-Carlo Dropout (MCD)-based BayesNN that achieves well-calibrated predictions with low algorithmic complexity. To further reduce the barrier to adopting BayesNNs, we propose a transformation framework that can generate FPGA-based accelerators for multi-exit MCD-based BayesNNs. Several novel optimization techniques are introduced to improve hardware performance. Our experiments demonstrate that our auto-generated accelerator achieves higher energy efficiency than CPU, GPU, and other state-of-the-art hardware implementations. ",
    "url": "https://arxiv.org/abs/2308.06849",
    "authors": [
      "Hongxiang Fan",
      "Hao Chen",
      "Liam Castelli",
      "Zhiqiang Que",
      "He Li",
      "Kenneth Long",
      "Wayne Luk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2308.06862",
    "title": "Effect of Choosing Loss Function when Using T-batching for  Representation Learning on Dynamic Networks",
    "abstract": "Representation learning methods have revolutionized machine learning on networks by converting discrete network structures into continuous domains. However, dynamic networks that evolve over time pose new challenges. To address this, dynamic representation learning methods have gained attention, offering benefits like reduced learning time and improved accuracy by utilizing temporal information. T-batching is a valuable technique for training dynamic network models that reduces training time while preserving vital conditions for accurate modeling. However, we have identified a limitation in the training loss function used with t-batching. Through mathematical analysis, we propose two alternative loss functions that overcome these issues, resulting in enhanced training performance. We extensively evaluate the proposed loss functions on synthetic and real-world dynamic networks. The results consistently demonstrate superior performance compared to the original loss function. Notably, in a real-world network characterized by diverse user interaction histories, the proposed loss functions achieved more than 26.9% enhancement in Mean Reciprocal Rank (MRR) and more than 11.8% improvement in Recall@10. These findings underscore the efficacy of the proposed loss functions in dynamic network modeling. ",
    "url": "https://arxiv.org/abs/2308.06862",
    "authors": [
      "Erfan Loghmani",
      "MohammadAmin Fazli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.06869",
    "title": "Shape-Graph Matching Network (SGM-net): Registration for Statistical  Shape Analysis",
    "abstract": "This paper focuses on the statistical analysis of shapes of data objects called shape graphs, a set of nodes connected by articulated curves with arbitrary shapes. A critical need here is a constrained registration of points (nodes to nodes, edges to edges) across objects. This, in turn, requires optimization over the permutation group, made challenging by differences in nodes (in terms of numbers, locations) and edges (in terms of shapes, placements, and sizes) across objects. This paper tackles this registration problem using a novel neural-network architecture and involves an unsupervised loss function developed using the elastic shape metric for curves. This architecture results in (1) state-of-the-art matching performance and (2) an order of magnitude reduction in the computational cost relative to baseline approaches. We demonstrate the effectiveness of the proposed approach using both simulated data and real-world 2D and 3D shape graphs. Code and data will be made publicly available after review to foster research. ",
    "url": "https://arxiv.org/abs/2308.06869",
    "authors": [
      "Shenyuan Liang",
      "Mauricio Pamplona Segundo",
      "Sathyanarayanan N. Aakur",
      "Sudeep Sarkar",
      "Anuj Srivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.06874",
    "title": "Joint Data Collection and Sensor Positioning in Multi-UAV-Assisted  Wireless Sensor Network",
    "abstract": "Due to the high mobility and easy deployment, unmanned aerial vehicles (UAVs) have attracted much attention in the field of wireless communication and positioning. To meet the challenges of lack of infrastructure coverage, uncertain sensor position and large amount of sensing data collection in wireless sensor network (WSN), this paper presents an efficient joint data collection and sensor positioning scheme for WSN supported by multiple UAVs. Specifically, a UAV is set as the main UAV to collect data, and other UAVs are used as auxiliary UAVs for sensor positioning using time difference of arrival (TDoA). A mixed-integer non-convex optimization problem with uncertain sensor position is established. The goal is to minimize the average positioning error of all sensors by jointly optimizing the UAV trajectories, sensor transmission schedule and positioning observation points (POPs). To solve this optimization model, the original problem is decomposed into two sub-problems based on the path discrete method. Firstly, the block coordinate descent (BCD) and successive convex approximation (SCA) techniques are applied to iteratively optimize the trajectory of the main UAV and the sensor transmission schedule, so as to maximize the minimum amount of data uploaded by the sensor. Then, based on the trajectory of the main UAV, a particle swarm optimization (PSO)-based algorithm is designed to optimize the POPs of UAVs. Finally, the spline curve is applied to generate the trajectories of auxiliary UAVs. The simulation results show that the proposed scheme can meet the requirements of data collection and has a good positioning performance. ",
    "url": "https://arxiv.org/abs/2308.06874",
    "authors": [
      "Mingyue Zhu",
      "Zhiqing Wei",
      "Chen Qiu",
      "Wangjun Jiang",
      "Huici Wu",
      "Zhiying Feng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.06917",
    "title": "Calling The Dead: Resilience In The WTC Communication Networks",
    "abstract": "Organizations in emergency settings must cope with various sources of disruption, most notably personnel loss. Death, incapacitation, or isolation of individuals within an organizational communication network can impair information passing, coordination, and connectivity, and may drive maladaptive responses such as repeated attempts to contact lost personnel (``calling the dead'') that themselves consume scarce resources. At the same time, organizations may respond to such disruption by reorganizing to restore function, a behavior that is fundamental to organizational resilience. Here, we use empirically calibrated models of communication for 17 groups of responders to the World Trade Center Disaster to examine the impact of exogenous removal of personnel on communication activity and network resilience. We find that removal of high-degree personnel and those in institutionally coordinative roles is particularly damaging to these organizations, with specialist responders being slower to adapt to losses. However, all organizations show adaptations to disruption, in some cases becoming better connected and making more complete use of personnel relative to control after experiencing losses. ",
    "url": "https://arxiv.org/abs/2308.06917",
    "authors": [
      "Selena M. Livas",
      "Scott Leo Renshaw",
      "Carter T. Butts"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2308.06931",
    "title": "FusionPlanner: A Multi-task Motion Planner for Mining Trucks using  Multi-sensor Fusion Method",
    "abstract": "In recent years, significant achievements have been made in motion planning for intelligent vehicles. However, as a typical unstructured environment, open-pit mining attracts limited attention due to its complex operational conditions and adverse environmental factors. A comprehensive paradigm for unmanned transportation in open-pit mines is proposed in this research, including a simulation platform, a testing benchmark, and a trustworthy and robust motion planner. \\textcolor{red}{Firstly, we propose a multi-task motion planning algorithm, called FusionPlanner, for autonomous mining trucks by the Multi-sensor fusion method to adapt both lateral and longitudinal control tasks for unmanned transportation. Then, we develop a novel benchmark called MiningNav, which offers three validation approaches to evaluate the trustworthiness and robustness of well-trained algorithms in transportation roads of open-pit mines. Finally, we introduce the Parallel Mining Simulator (PMS), a new high-fidelity simulator specifically designed for open-pit mining scenarios. PMS enables the users to manage and control open-pit mine transportation from both the single-truck control and multi-truck scheduling perspectives.} \\textcolor{red}{The performance of FusionPlanner is tested by MiningNav in PMS, and the empirical results demonstrate a significant reduction in the number of collisions and takeovers of our planner. We anticipate our unmanned transportation paradigm will bring mining trucks one step closer to trustworthiness and robustness in continuous round-the-clock unmanned transportation. ",
    "url": "https://arxiv.org/abs/2308.06931",
    "authors": [
      "Siyu Teng",
      "Luxi Li",
      "Yuchen Li",
      "Xuemin Hu",
      "Lingxi Li",
      "Yunfeng Ai",
      "Long Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06940",
    "title": "Moment Methods for Advection on Networks and an Application to Forest  Pest Life Cycle Models",
    "abstract": "This paper develops low-dimensional moment methods for advective problems on networks of domains. The evolution of a density function is described by a linear advection-diffusion-reaction equation on each domain, combined via advective flux coupling across domains in the network graph. The PDEs' coefficients vary in time and across domains but they are fixed along each domain. As a result, the solution on each domain is frequently close to a Gaussian that moves, decays, and widens. For that reason, this work studies moment methods that track only three degrees of freedom per domain -- in contrast to traditional PDE discretization methods that tend to require many more variables per domain. A simple ODE-based moment method is developed, as well as an asymptotic-preserving scheme. We apply the methodology to an application that models the life cycle of forest pests that undergo different life stages and developmental pathways. The model is calibrated for the spotted lanternfly, an invasive species present in the Eastern USA. We showcase that the moment method, despite its significant low-dimensionality, can successfully reproduce the prediction of the pest's establishment potential, compared to much higher-dimensional computational approaches. ",
    "url": "https://arxiv.org/abs/2308.06940",
    "authors": [
      "Rujeko Chinomona",
      "Kiera Kean",
      "Benjamin Seibold",
      "Jacob Woods"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.06945",
    "title": "Semantic-aware Network for Aerial-to-Ground Image Synthesis",
    "abstract": "Aerial-to-ground image synthesis is an emerging and challenging problem that aims to synthesize a ground image from an aerial image. Due to the highly different layout and object representation between the aerial and ground images, existing approaches usually fail to transfer the components of the aerial scene into the ground scene. In this paper, we propose a novel framework to explore the challenges by imposing enhanced structural alignment and semantic awareness. We introduce a novel semantic-attentive feature transformation module that allows to reconstruct the complex geographic structures by aligning the aerial feature to the ground layout. Furthermore, we propose semantic-aware loss functions by leveraging a pre-trained segmentation network. The network is enforced to synthesize realistic objects across various classes by separately calculating losses for different classes and balancing them. Extensive experiments including comparisons with previous methods and ablation studies show the effectiveness of the proposed framework both qualitatively and quantitatively. ",
    "url": "https://arxiv.org/abs/2308.06945",
    "authors": [
      "Jinhyun Jang",
      "Taeyong Song",
      "Kwanghoon Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06958",
    "title": "Hydrogen Supply Infrastructure Network Planning Approach towards  Chicken-egg Conundrum",
    "abstract": "In the early commercialization stage of hydrogen fuel cell vehicles (HFCVs), reasonable hydrogen supply infrastructure (HSI) planning decisions is a premise for promoting the popularization of HFCVs. However, there is a strong causality between HFCVs and hydrogen refueling stations (HRSs): the planning decisions of HRSs could affect the hydrogen refueling demand of HFCVs, and the growth of demand would in turn stimulate the further investment in HRSs, which is also known as the ``chicken and egg'' conundrum. Meanwhile, the hydrogen demand is uncertain with insufficient prior knowledge, and thus there is a decision-dependent uncertainty (DDU) in the planning issue. This poses great challenges to solving the optimization problem. To this end, this work establishes a multi-network HSI planning model coordinating hydrogen, power, and transportation networks. Then, to reflect the causal relationship between HFCVs and HRSs effectively without sufficient historical data, a distributionally robust optimization framework with decision-dependent uncertainty is developed. The uncertainty of hydrogen demand is modeled as a Wasserstein ambiguity set with a decision-dependent empirical probability distribution. Subsequently, to reduce the computational complexity caused by the introduction of a large number of scenarios and high-dimensional nonlinear constraints, we developed an improved distribution shaping method and techniques of scenario and variable reduction to derive the solvable form with less computing burden. Finally, the simulation results demonstrate that this method can reduce costs by at least 10.4% compared with traditional methods and will be more effective in large-scale HSI planning issues. Further, we put forward effective suggestions for the policymakers and investors to formulate relevant policies and decisions. ",
    "url": "https://arxiv.org/abs/2308.06958",
    "authors": [
      "Haoran Deng",
      "Bo Yang",
      "Mo-Yuen Chow",
      "Gang Yao",
      "Cailian Chen",
      "Xinping Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.06960",
    "title": "Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level  Tasks",
    "abstract": "Recently, graph neural networks (GNNs) have shown its unprecedented success in many graph-related tasks. However, GNNs face the label scarcity issue as other neural networks do. Thus, recent efforts try to pre-train GNNs on a large-scale unlabeled graph and adapt the knowledge from the unlabeled graph to the target downstream task. The adaptation is generally achieved by fine-tuning the pre-trained GNNs with a limited number of labeled data. Despite the importance of fine-tuning, current GNNs pre-training works often ignore designing a good fine-tuning strategy to better leverage transferred knowledge and improve the performance on downstream tasks. Only few works start to investigate a better fine-tuning strategy for pre-trained GNNs. But their designs either have strong assumptions or overlook the data-aware issue for various downstream datasets. Therefore, we aim to design a better fine-tuning strategy for pre-trained GNNs to improve the model performance in this paper. Given a pre-trained GNN, we propose to search to fine-tune pre-trained graph neural networks for graph-level tasks (S2PGNN), which adaptively design a suitable fine-tuning framework for the given labeled data on the downstream task. To ensure the improvement brought by searching fine-tuning strategy, we carefully summarize a proper search space of fine-tuning framework that is suitable for GNNs. The empirical studies show that S2PGNN can be implemented on the top of 10 famous pre-trained GNNs and consistently improve their performance. Besides, S2PGNN achieves better performance than existing fine-tuning strategies within and outside the GNN area. Our code is publicly available at \\url{https://anonymous.4open.science/r/code_icde2024-A9CB/}. ",
    "url": "https://arxiv.org/abs/2308.06960",
    "authors": [
      "Zhili Wang",
      "Shimin Di",
      "Lei Chen",
      "Xiaofang Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06961",
    "title": "Graph Structural Residuals: A Learning Approach to Diagnosis",
    "abstract": "Traditional model-based diagnosis relies on constructing explicit system models, a process that can be laborious and expertise-demanding. In this paper, we propose a novel framework that combines concepts of model-based diagnosis with deep graph structure learning. This data-driven approach leverages data to learn the system's underlying structure and provide dynamic observations, represented by two distinct graph adjacency matrices. Our work facilitates a seamless integration of graph structure learning with model-based diagnosis by making three main contributions: (i) redefining the constructs of system representation, observations, and faults (ii) introducing two distinct versions of a self-supervised graph structure learning model architecture and (iii) demonstrating the potential of our data-driven diagnostic method through experiments on a system of coupled oscillators. ",
    "url": "https://arxiv.org/abs/2308.06961",
    "authors": [
      "Jan Lukas Augustin",
      "Oliver Niggemann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06962",
    "title": "Color-NeuS: Reconstructing Neural Implicit Surfaces with Color",
    "abstract": "The reconstruction of object surfaces from multi-view images or monocular video is a fundamental issue in computer vision. However, much of the recent research concentrates on reconstructing geometry through implicit or explicit methods. In this paper, we shift our focus towards reconstructing mesh in conjunction with color. We remove the view-dependent color from neural volume rendering while retaining volume rendering performance through a relighting network. Mesh is extracted from the signed distance function (SDF) network for the surface, and color for each surface vertex is drawn from the global color network. To evaluate our approach, we conceived a in hand object scanning task featuring numerous occlusions and dramatic shifts in lighting conditions. We've gathered several videos for this task, and the results surpass those of any existing methods capable of reconstructing mesh alongside color. Additionally, our method's performance was assessed using public datasets, including DTU, BlendedMVS, and OmniObject3D. The results indicated that our method performs well across all these datasets. Project page: https://colmar-zlicheng.github.io/color_neus. ",
    "url": "https://arxiv.org/abs/2308.06962",
    "authors": [
      "Licheng Zhong",
      "Lixin Yang",
      "Kailin Li",
      "Haoyu Zhen",
      "Mei Han",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06965",
    "title": "AutoAssign+: Automatic Shared Embedding Assignment in Streaming  Recommendation",
    "abstract": "In the domain of streaming recommender systems, conventional methods for addressing new user IDs or item IDs typically involve assigning initial ID embeddings randomly. However, this practice results in two practical challenges: (i) Items or users with limited interactive data may yield suboptimal prediction performance. (ii) Embedding new IDs or low-frequency IDs necessitates consistently expanding the embedding table, leading to unnecessary memory consumption. In light of these concerns, we introduce a reinforcement learning-driven framework, namely AutoAssign+, that facilitates Automatic Shared Embedding Assignment Plus. To be specific, AutoAssign+ utilizes an Identity Agent as an actor network, which plays a dual role: (i) Representing low-frequency IDs field-wise with a small set of shared embeddings to enhance the embedding initialization, and (ii) Dynamically determining which ID features should be retained or eliminated in the embedding table. The policy of the agent is optimized with the guidance of a critic network. To evaluate the effectiveness of our approach, we perform extensive experiments on three commonly used benchmark datasets. Our experiment results demonstrate that AutoAssign+ is capable of significantly enhancing recommendation performance by mitigating the cold-start problem. Furthermore, our framework yields a reduction in memory usage of approximately 20-30%, verifying its practical effectiveness and efficiency for streaming recommender systems. ",
    "url": "https://arxiv.org/abs/2308.06965",
    "authors": [
      "Ziru Liu",
      "Kecheng Chen",
      "Fengyi Song",
      "Bo Chen",
      "Xiangyu Zhao",
      "Huifeng Guo",
      "Ruiming Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06973",
    "title": "Routing Recovery for UAV Networks with Deliberate Attacks: A  Reinforcement Learning based Approach",
    "abstract": "The unmanned aerial vehicle (UAV) network is popular these years due to its various applications. In the UAV network, routing is significantly affected by the distributed network topology, leading to the issue that UAVs are vulnerable to deliberate damage. Hence, this paper focuses on the routing plan and recovery for UAV networks with attacks. In detail, a deliberate attack model based on the importance of nodes is designed to represent enemy attacks. Then, a node importance ranking mechanism is presented, considering the degree of nodes and link importance. However, it is intractable to handle the routing problem by traditional methods for UAV networks, since link connections change with the UAV availability. Hence, an intelligent algorithm based on reinforcement learning is proposed to recover the routing path when UAVs are attacked. Simulations are conducted and numerical results verify the proposed mechanism performs better than other referred methods. ",
    "url": "https://arxiv.org/abs/2308.06973",
    "authors": [
      "Sijie He",
      "Ziye Jia",
      "Chao Dong",
      "Wei Wang",
      "Yilu Cao",
      "Yang Yang",
      "Qihui Wu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06975",
    "title": "Can Knowledge Graphs Simplify Text?",
    "abstract": "Knowledge Graph (KG)-to-Text Generation has seen recent improvements in generating fluent and informative sentences which describe a given KG. As KGs are widespread across multiple domains and contain important entity-relation information, and as text simplification aims to reduce the complexity of a text while preserving the meaning of the original text, we propose KGSimple, a novel approach to unsupervised text simplification which infuses KG-established techniques in order to construct a simplified KG path and generate a concise text which preserves the original input's meaning. Through an iterative and sampling KG-first approach, our model is capable of simplifying text when starting from a KG by learning to keep important information while harnessing KG-to-text generation to output fluent and descriptive sentences. We evaluate various settings of the KGSimple model on currently-available KG-to-text datasets, demonstrating its effectiveness compared to unsupervised text simplification models which start with a given complex text. Our code is available on GitHub. ",
    "url": "https://arxiv.org/abs/2308.06975",
    "authors": [
      "Anthony Colas",
      "Haodi Ma",
      "Xuanli He",
      "Yang Bai",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.06983",
    "title": "pNNCLR: Stochastic Pseudo Neighborhoods for Contrastive Learning based  Unsupervised Representation Learning Problems",
    "abstract": "Nearest neighbor (NN) sampling provides more semantic variations than pre-defined transformations for self-supervised learning (SSL) based image recognition problems. However, its performance is restricted by the quality of the support set, which holds positive samples for the contrastive loss. In this work, we show that the quality of the support set plays a crucial role in any nearest neighbor based method for SSL. We then provide a refined baseline (pNNCLR) to the nearest neighbor based SSL approach (NNCLR). To this end, we introduce pseudo nearest neighbors (pNN) to control the quality of the support set, wherein, rather than sampling the nearest neighbors, we sample in the vicinity of hard nearest neighbors by varying the magnitude of the resultant vector and employing a stochastic sampling strategy to improve the performance. Additionally, to stabilize the effects of uncertainty in NN-based learning, we employ a smooth-weight-update approach for training the proposed network. Evaluation of the proposed method on multiple public image recognition and medical image recognition datasets shows that it performs up to 8 percent better than the baseline nearest neighbor method, and is comparable to other previously proposed SSL methods. ",
    "url": "https://arxiv.org/abs/2308.06983",
    "authors": [
      "Momojit Biswas",
      "Himanshu Buckchash",
      "Dilip K. Prasad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06985",
    "title": "PatchContrast: Self-Supervised Pre-training for 3D Object Detection",
    "abstract": "Accurately detecting objects in the environment is a key challenge for autonomous vehicles. However, obtaining annotated data for detection is expensive and time-consuming. We introduce PatchContrast, a novel self-supervised point cloud pre-training framework for 3D object detection. We propose to utilize two levels of abstraction to learn discriminative representation from unlabeled data: proposal-level and patch-level. The proposal-level aims at localizing objects in relation to their surroundings, whereas the patch-level adds information about the internal connections between the object's components, hence distinguishing between different objects based on their individual components. We demonstrate how these levels can be integrated into self-supervised pre-training for various backbones to enhance the downstream 3D detection task. We show that our method outperforms existing state-of-the-art models on three commonly-used 3D detection datasets. ",
    "url": "https://arxiv.org/abs/2308.06985",
    "authors": [
      "Oren Shrout",
      "Ori Nitzan",
      "Yizhak Ben-Shabat",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06998",
    "title": "Mutual Information-driven Triple Interaction Network for Efficient Image  Dehazing",
    "abstract": "Multi-stage architectures have exhibited efficacy in image dehazing, which usually decomposes a challenging task into multiple more tractable sub-tasks and progressively estimates latent hazy-free images. Despite the remarkable progress, existing methods still suffer from the following shortcomings: (1) limited exploration of frequency domain information; (2) insufficient information interaction; (3) severe feature redundancy. To remedy these issues, we propose a novel Mutual Information-driven Triple interaction Network (MITNet) based on spatial-frequency dual domain information and two-stage architecture. To be specific, the first stage, named amplitude-guided haze removal, aims to recover the amplitude spectrum of the hazy images for haze removal. And the second stage, named phase-guided structure refined, devotes to learning the transformation and refinement of the phase spectrum. To facilitate the information exchange between two stages, an Adaptive Triple Interaction Module (ATIM) is developed to simultaneously aggregate cross-domain, cross-scale, and cross-stage features, where the fused features are further used to generate content-adaptive dynamic filters so that applying them to enhance global context representation. In addition, we impose the mutual information minimization constraint on paired scale encoder and decoder features from both stages. Such an operation can effectively reduce information redundancy and enhance cross-stage feature complementarity. Extensive experiments on multiple public datasets exhibit that our MITNet performs superior performance with lower model complexity.The code and models are available at https://github.com/it-hao/MITNet. ",
    "url": "https://arxiv.org/abs/2308.06998",
    "authors": [
      "Hao Shen",
      "Zhong-Qiu Zhao",
      "Yulun Zhang",
      "Zhao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07009",
    "title": "ACTIVE: Towards Highly Transferable 3D Physical Camouflage for Universal  and Robust Vehicle Evasion",
    "abstract": "Adversarial camouflage has garnered attention for its ability to attack object detectors from any viewpoint by covering the entire object's surface. However, universality and robustness in existing methods often fall short as the transferability aspect is often overlooked, thus restricting their application only to a specific target with limited performance. To address these challenges, we present Adversarial Camouflage for Transferable and Intensive Vehicle Evasion (ACTIVE), a state-of-the-art physical camouflage attack framework designed to generate universal and robust adversarial camouflage capable of concealing any 3D vehicle from detectors. Our framework incorporates innovative techniques to enhance universality and robustness: a refined texture rendering that enables common texture application to different vehicles without being constrained to a specific texture map, a novel stealth loss that renders the vehicle undetectable, and a smooth and camouflage loss to enhance the naturalness of the adversarial camouflage. Our extensive experiments on 15 different models show that ACTIVE consistently outperforms existing works on various public detectors, including the latest YOLOv7. Notably, our universality evaluations reveal promising transferability to other vehicle classes, tasks (segmentation models), and the real world, not just other vehicles. ",
    "url": "https://arxiv.org/abs/2308.07009",
    "authors": [
      "Naufal Suryanto",
      "Yongsu Kim",
      "Harashta Tatimma Larasati",
      "Hyoeun Kang",
      "Thi-Thu-Huong Le",
      "Yoonyoung Hong",
      "Hunmin Yang",
      "Se-Yoon Oh",
      "Howon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07024",
    "title": "PGT-Net: Progressive Guided Multi-task Neural Network for Small-area Wet  Fingerprint Denoising and Recognition",
    "abstract": "Fingerprint recognition on mobile devices is an important method for identity verification. However, real fingerprints usually contain sweat and moisture which leads to poor recognition performance. In addition, for rolling out slimmer and thinner phones, technology companies reduce the size of recognition sensors by embedding them with the power button. Therefore, the limited size of fingerprint data also increases the difficulty of recognition. Denoising the small-area wet fingerprint images to clean ones becomes crucial to improve recognition performance. In this paper, we propose an end-to-end trainable progressive guided multi-task neural network (PGT-Net). The PGT-Net includes a shared stage and specific multi-task stages, enabling the network to train binary and non-binary fingerprints sequentially. The binary information is regarded as guidance for output enhancement which is enriched with the ridge and valley details. Moreover, a novel residual scaling mechanism is introduced to stabilize the training process. Experiment results on the FW9395 and FT-lightnoised dataset provided by FocalTech shows that PGT-Net has promising performance on the wet-fingerprint denoising and significantly improves the fingerprint recognition rate (FRR). On the FT-lightnoised dataset, the FRR of fingerprint recognition can be declined from 17.75% to 4.47%. On the FW9395 dataset, the FRR of fingerprint recognition can be declined from 9.45% to 1.09%. ",
    "url": "https://arxiv.org/abs/2308.07024",
    "authors": [
      "Yu-Ting Li",
      "Ching-Te Chiu",
      "An-Ting Hsieh",
      "Mao-Hsiu Hsu",
      "Long Wenyong",
      "Jui-Min Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07026",
    "title": "AdvCLIP: Downstream-agnostic Adversarial Examples in Multimodal  Contrastive Learning",
    "abstract": "Multimodal contrastive learning aims to train a general-purpose feature extractor, such as CLIP, on vast amounts of raw, unlabeled paired image-text data. This can greatly benefit various complex downstream tasks, including cross-modal image-text retrieval and image classification. Despite its promising prospect, the security issue of cross-modal pre-trained encoder has not been fully explored yet, especially when the pre-trained encoder is publicly available for commercial use. In this work, we propose AdvCLIP, the first attack framework for generating downstream-agnostic adversarial examples based on cross-modal pre-trained encoders. AdvCLIP aims to construct a universal adversarial patch for a set of natural images that can fool all the downstream tasks inheriting the victim cross-modal pre-trained encoder. To address the challenges of heterogeneity between different modalities and unknown downstream tasks, we first build a topological graph structure to capture the relevant positions between target samples and their neighbors. Then, we design a topology-deviation based generative adversarial network to generate a universal adversarial patch. By adding the patch to images, we minimize their embeddings similarity to different modality and perturb the sample distribution in the feature space, achieving unviersal non-targeted attacks. Our results demonstrate the excellent attack performance of AdvCLIP on two types of downstream tasks across eight datasets. We also tailor three popular defenses to mitigate AdvCLIP, highlighting the need for new defense mechanisms to defend cross-modal pre-trained encoders. ",
    "url": "https://arxiv.org/abs/2308.07026",
    "authors": [
      "Ziqi Zhou",
      "Shengshan Hu",
      "Minghui Li",
      "Hangtao Zhang",
      "Yechao Zhang",
      "Hai Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07032",
    "title": "S3IM: Stochastic Structural SIMilarity and Its Unreasonable  Effectiveness for Neural Fields",
    "abstract": "Recently, Neural Radiance Field (NeRF) has shown great success in rendering novel-view images of a given scene by learning an implicit representation with only posed RGB images. NeRF and relevant neural field methods (e.g., neural surface representation) typically optimize a point-wise loss and make point-wise predictions, where one data point corresponds to one pixel. Unfortunately, this line of research failed to use the collective supervision of distant pixels, although it is known that pixels in an image or scene can provide rich structural information. To the best of our knowledge, we are the first to design a nonlocal multiplex training paradigm for NeRF and relevant neural field methods via a novel Stochastic Structural SIMilarity (S3IM) loss that processes multiple data points as a whole set instead of process multiple inputs independently. Our extensive experiments demonstrate the unreasonable effectiveness of S3IM in improving NeRF and neural surface representation for nearly free. The improvements of quality metrics can be particularly significant for those relatively difficult tasks: e.g., the test MSE loss unexpectedly drops by more than 90% for TensoRF and DVGO over eight novel view synthesis tasks; a 198% F-score gain and a 64% Chamfer $L_{1}$ distance reduction for NeuS over eight surface reconstruction tasks. Moreover, S3IM is consistently robust even with sparse inputs, corrupted images, and dynamic scenes. ",
    "url": "https://arxiv.org/abs/2308.07032",
    "authors": [
      "Zeke Xie",
      "Xindi Yang",
      "Yujie Yang",
      "Qi Sun",
      "Yixiang Jiang",
      "Haoran Wang",
      "Yunfeng Cai",
      "Mingming Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07034",
    "title": "An Inherent Trade-Off in Noisy Neural Communication with Rank-Order  Coding",
    "abstract": "Rank-order coding, a form of temporal coding, has emerged as a promising scheme to explain the rapid ability of the mammalian brain. Owing to its speed as well as efficiency, rank-order coding is increasingly gaining interest in diverse research areas beyond neuroscience. However, much uncertainty still exists about the performance of rank-order coding under noise. Herein we show what information rates are fundamentally possible and what trade-offs are at stake. An unexpected finding in this paper is the emergence of a special class of errors that, in a regime, increase with less noise. ",
    "url": "https://arxiv.org/abs/2308.07034",
    "authors": [
      "Ibrahim Alsolami",
      "Tomoki Fukai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07037",
    "title": "Bayesian Flow Networks",
    "abstract": "This paper introduces Bayesian Flow Networks (BFNs), a new class of generative model in which the parameters of a set of independent distributions are modified with Bayesian inference in the light of noisy data samples, then passed as input to a neural network that outputs a second, interdependent distribution. Starting from a simple prior and iteratively updating the two distributions yields a generative procedure similar to the reverse process of diffusion models; however it is conceptually simpler in that no forward process is required. Discrete and continuous-time loss functions are derived for continuous, discretised and discrete data, along with sample generation procedures. Notably, the network inputs for discrete data lie on the probability simplex, and are therefore natively differentiable, paving the way for gradient-based sample guidance and few-step generation in discrete domains such as language modelling. The loss function directly optimises data compression and places no restrictions on the network architecture. In our experiments BFNs achieve competitive log-likelihoods for image modelling on dynamically binarized MNIST and CIFAR-10, and outperform all known discrete diffusion models on the text8 character-level language modelling task. ",
    "url": "https://arxiv.org/abs/2308.07037",
    "authors": [
      "Alex Graves",
      "Rupesh Kumar Srivastava",
      "Timothy Atkinson",
      "Faustino Gomez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07050",
    "title": "Survey on video anomaly detection in dynamic scenes with moving cameras",
    "abstract": "The increasing popularity of compact and inexpensive cameras, e.g.~dash cameras, body cameras, and cameras equipped on robots, has sparked a growing interest in detecting anomalies within dynamic scenes recorded by moving cameras. However, existing reviews primarily concentrate on Video Anomaly Detection (VAD) methods assuming static cameras. The VAD literature with moving cameras remains fragmented, lacking comprehensive reviews to date. To address this gap, we endeavor to present the first comprehensive survey on Moving Camera Video Anomaly Detection (MC-VAD). We delve into the research papers related to MC-VAD, critically assessing their limitations and highlighting associated challenges. Our exploration encompasses three application domains: security, urban transportation, and marine environments, which in turn cover six specific tasks. We compile an extensive list of 25 publicly-available datasets spanning four distinct environments: underwater, water surface, ground, and aerial. We summarize the types of anomalies these datasets correspond to or contain, and present five main categories of approaches for detecting such anomalies. Lastly, we identify future research directions and discuss novel contributions that could advance the field of MC-VAD. With this survey, we aim to offer a valuable reference for researchers and practitioners striving to develop and advance state-of-the-art MC-VAD methods. ",
    "url": "https://arxiv.org/abs/2308.07050",
    "authors": [
      "Runyu Jiao",
      "Yi Wan",
      "Fabio Poiesi",
      "Yiming Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07051",
    "title": "Fourier neural operator for learning solutions to macroscopic traffic  flow models: Application to the forward and inverse problems",
    "abstract": "Deep learning methods are emerging as popular computational tools for solving forward and inverse problems in traffic flow. In this paper, we study a neural operator framework for learning solutions to nonlinear hyperbolic partial differential equations with applications in macroscopic traffic flow models. In this framework, an operator is trained to map heterogeneous and sparse traffic input data to the complete macroscopic traffic state in a supervised learning setting. We chose a physics-informed Fourier neural operator ($\\pi$-FNO) as the operator, where an additional physics loss based on a discrete conservation law regularizes the problem during training to improve the shock predictions. We also propose to use training data generated from random piecewise constant input data to systematically capture the shock and rarefied solutions. From experiments using the LWR traffic flow model, we found superior accuracy in predicting the density dynamics of a ring-road network and urban signalized road. We also found that the operator can be trained using simple traffic density dynamics, e.g., consisting of $2-3$ vehicle queues and $1-2$ traffic signal cycles, and it can predict density dynamics for heterogeneous vehicle queue distributions and multiple traffic signal cycles $(\\geq 2)$ with an acceptable error. The extrapolation error grew sub-linearly with input complexity for a proper choice of the model architecture and training data. Adding a physics regularizer aided in learning long-term traffic density dynamics, especially for problems with periodic boundary data. ",
    "url": "https://arxiv.org/abs/2308.07051",
    "authors": [
      "Bilal Thonnam Thodi",
      "Sai Venkata Ramana Ambadipudi",
      "Saif Eddin Jabari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.07092",
    "title": "Masked Motion Predictors are Strong 3D Action Representation Learners",
    "abstract": "In 3D human action recognition, limited supervised data makes it challenging to fully tap into the modeling potential of powerful networks such as transformers. As a result, researchers have been actively investigating effective self-supervised pre-training strategies. In this work, we show that instead of following the prevalent pretext task to perform masked self-component reconstruction in human joints, explicit contextual motion modeling is key to the success of learning effective feature representation for 3D action recognition. Formally, we propose the Masked Motion Prediction (MAMP) framework. To be specific, the proposed MAMP takes as input the masked spatio-temporal skeleton sequence and predicts the corresponding temporal motion of the masked human joints. Considering the high temporal redundancy of the skeleton sequence, in our MAMP, the motion information also acts as an empirical semantic richness prior that guide the masking process, promoting better attention to semantically rich temporal regions. Extensive experiments on NTU-60, NTU-120, and PKU-MMD datasets show that the proposed MAMP pre-training substantially improves the performance of the adopted vanilla transformer, achieving state-of-the-art results without bells and whistles. The source code of our MAMP is available at https://github.com/maoyunyao/MAMP. ",
    "url": "https://arxiv.org/abs/2308.07092",
    "authors": [
      "Yunyao Mao",
      "Jiajun Deng",
      "Wengang Zhou",
      "Yao Fang",
      "Wanli Ouyang",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07117",
    "title": "iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using  1D-2D CNN",
    "abstract": "The inverse short-time Fourier transform network (iSTFTNet) has garnered attention owing to its fast, lightweight, and high-fidelity speech synthesis. It obtains these characteristics using a fast and lightweight 1D CNN as the backbone and replacing some neural processes with iSTFT. Owing to the difficulty of a 1D CNN to model high-dimensional spectrograms, the frequency dimension is reduced via temporal upsampling. However, this strategy compromises the potential to enhance the speed. Therefore, we propose iSTFTNet2, an improved variant of iSTFTNet with a 1D-2D CNN that employs 1D and 2D CNNs to model temporal and spectrogram structures, respectively. We designed a 2D CNN that performs frequency upsampling after conversion in a few-frequency space. This design facilitates the modeling of high-dimensional spectrograms without compromising the speed. The results demonstrated that iSTFTNet2 made iSTFTNet faster and more lightweight with comparable speech quality. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/. ",
    "url": "https://arxiv.org/abs/2308.07117",
    "authors": [
      "Takuhiro Kaneko",
      "Hirokazu Kameoka",
      "Kou Tanaka",
      "Shogo Seki"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.07118",
    "title": "Neural radiance fields in the industrial and robotics domain:  applications, research opportunities and use cases",
    "abstract": "The proliferation of technologies, such as extended reality (XR), has increased the demand for high-quality three-dimensional (3D) graphical representations. Industrial 3D applications encompass computer-aided design (CAD), finite element analysis (FEA), scanning, and robotics. However, current methods employed for industrial 3D representations suffer from high implementation costs and reliance on manual human input for accurate 3D modeling. To address these challenges, neural radiance fields (NeRFs) have emerged as a promising approach for learning 3D scene representations based on provided training 2D images. Despite a growing interest in NeRFs, their potential applications in various industrial subdomains are still unexplored. In this paper, we deliver a comprehensive examination of NeRF industrial applications while also providing direction for future research endeavors. We also present a series of proof-of-concept experiments that demonstrate the potential of NeRFs in the industrial domain. These experiments include NeRF-based video compression techniques and using NeRFs for 3D motion estimation in the context of collision avoidance. In the video compression experiment, our results show compression savings up to 48\\% and 74\\% for resolutions of 1920x1080 and 300x168, respectively. The motion estimation experiment used a 3D animation of a robotic arm to train Dynamic-NeRF (D-NeRF) and achieved an average disparity map PSNR of 23 dB and an SSIM of 0.97. The code for our experiments is publicly available at https://github.com/Maftej/iisnerf . ",
    "url": "https://arxiv.org/abs/2308.07118",
    "authors": [
      "Eugen \u0160lapak",
      "Enric Pardo",
      "Mat\u00fa\u0161 Dopiriak",
      "Taras Maksymyuk",
      "Juraj Gazda"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07124",
    "title": "OctoPack: Instruction Tuning Code Large Language Models",
    "abstract": "Finetuning large language models (LLMs) on instructions leads to vast performance improvements on natural language tasks. We apply instruction tuning using code, leveraging the natural structure of Git commits, which pair code changes with human instructions. We compile CommitPack: 4 terabytes of Git commits across 350 programming languages. We benchmark CommitPack against other natural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B parameter StarCoder model, and achieve state-of-the-art performance among models not trained on OpenAI outputs, on the HumanEval Python benchmark (46.2% pass@1). We further introduce HumanEvalPack, expanding the HumanEval benchmark to a total of 3 coding tasks (Code Repair, Code Explanation, Code Synthesis) across 6 languages (Python, JavaScript, Java, Go, C++, Rust). Our models, OctoCoder and OctoGeeX, achieve the best performance across HumanEvalPack among all permissive models, demonstrating CommitPack's benefits in generalizing to a wider set of languages and natural coding tasks. Code, models and data are freely available at https://github.com/bigcode-project/octopack. ",
    "url": "https://arxiv.org/abs/2308.07124",
    "authors": [
      "Niklas Muennighoff",
      "Qian Liu",
      "Armel Zebaze",
      "Qinkai Zheng",
      "Binyuan Hui",
      "Terry Yue Zhuo",
      "Swayam Singh",
      "Xiangru Tang",
      "Leandro von Werra",
      "Shayne Longpre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07132",
    "title": "Data-Driven Robust Beamforming for Initial Access",
    "abstract": "We consider a robust beamforming problem where large amount of downlink (DL) channel state information (CSI) data available at a multiple antenna access point (AP) is used to improve the link quality to a user equipment (UE) for beyond-5G and 6G applications such as environment-specific initial access (IA) or wireless power transfer (WPT). As the DL CSI available at the current instant may be imperfect or outdated, we propose a novel scheme which utilizes the (unknown) correlation between the antenna domain and physical domain to localize the possible future UE positions from the historical CSI database. Then, we develop a codebook design procedure to maximize the minimum sum beamforming gain to that localized CSI neighborhood. We also incorporate a UE specific parameter to enlarge the neighborhood to robustify the link further. We adopt an indoor channel model to demonstrate the performance of our solution, and benchmark against a usually optimal (but now sub-optimal due to outdated CSI) maximum ratio transmission (MRT) and a subspace based method.We numerically show that our algorithm outperforms the other methods by a large margin. This shows that customized environment-specific solutions are important to solve many future wireless applications, and we have paved the way to develop further data-driven approaches. ",
    "url": "https://arxiv.org/abs/2308.07132",
    "authors": [
      "Sai Subramanyam Thoota",
      "Joao Vieira",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.07134",
    "title": "Natural Language is All a Graph Needs",
    "abstract": "The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundational model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scalable prompts based on natural language instructions, and use natural language to describe the geometric structure and node features of the graph for instruction tuning an LLMs to perform learning and inference on graphs in a generative manner. Our method exceeds all competitive GNN baselines on ogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of our method and sheds light on generative language models replacing GNNs as the foundation model for graph machine learning. ",
    "url": "https://arxiv.org/abs/2308.07134",
    "authors": [
      "Ruosong Ye",
      "Caiqi Zhang",
      "Runhui Wang",
      "Shuyuan Xu",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07148",
    "title": "Sustainable Cooperation in Peer-To-Peer Networks",
    "abstract": "Traditionally, peer-to-peer systems have relied on altruism and reciprocity. Although incentive-based models have gained prominence in new-generation peer-to-peer systems, it is essential to recognize the continued importance of cooperative principles in achieving performance, fairness, and correctness. The lack of this acknowledgment has paved the way for selfish peers to gain unfair advantages in these systems. As such, we address the challenge of selfish peers by devising a mechanism to reward sustained cooperation. Instead of relying on global accountability mechanisms, we propose a protocol that naturally aggregates local evaluations of cooperation. Traditional mechanisms are often vulnerable to Sybil and misreporting attacks. However, our approach overcomes these issues by limiting the benefits selfish peers can gain without incurring any cost. The viability of our algorithm is proven with a deployment to 27,259 Internet users and a realistic simulation of a blockchain gossip protocol. We show that our protocol sustains cooperation even in the presence of a majority of selfish peers while incurring only negligible overhead. ",
    "url": "https://arxiv.org/abs/2308.07148",
    "authors": [
      "Bulat Nasrulin",
      "Rowdy Chotkan",
      "Johan Pouwelse"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.07151",
    "title": "Diffusion Based Augmentation for Captioning and Retrieval in Cultural  Heritage",
    "abstract": "Cultural heritage applications and advanced machine learning models are creating a fruitful synergy to provide effective and accessible ways of interacting with artworks. Smart audio-guides, personalized art-related content and gamification approaches are just a few examples of how technology can be exploited to provide additional value to artists or exhibitions. Nonetheless, from a machine learning point of view, the amount of available artistic data is often not enough to train effective models. Off-the-shelf computer vision modules can still be exploited to some extent, yet a severe domain shift is present between art images and standard natural image datasets used to train such models. As a result, this can lead to degraded performance. This paper introduces a novel approach to address the challenges of limited annotated data and domain shifts in the cultural heritage domain. By leveraging generative vision-language models, we augment art datasets by generating diverse variations of artworks conditioned on their captions. This augmentation strategy enhances dataset diversity, bridging the gap between natural images and artworks, and improving the alignment of visual cues with knowledge from general-purpose datasets. The generated variations assist in training vision and language models with a deeper understanding of artistic characteristics and that are able to generate better captions with appropriate jargon. ",
    "url": "https://arxiv.org/abs/2308.07151",
    "authors": [
      "Dario Cioni",
      "Lorenzo Berlincioni",
      "Federico Becattini",
      "Alberto del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07163",
    "title": "HyperSparse Neural Networks: Shifting Exploration to Exploitation  through Adaptive Regularization",
    "abstract": "Sparse neural networks are a key factor in developing resource-efficient machine learning applications. We propose the novel and powerful sparse learning method Adaptive Regularized Training (ART) to compress dense into sparse networks. Instead of the commonly used binary mask during training to reduce the number of model weights, we inherently shrink weights close to zero in an iterative manner with increasing weight regularization. Our method compresses the pre-trained model knowledge into the weights of highest magnitude. Therefore, we introduce a novel regularization loss named HyperSparse that exploits the highest weights while conserving the ability of weight exploration. Extensive experiments on CIFAR and TinyImageNet show that our method leads to notable performance gains compared to other sparsification methods, especially in extremely high sparsity regimes up to 99.8 percent model sparsity. Additional investigations provide new insights into the patterns that are encoded in weights with high magnitudes. ",
    "url": "https://arxiv.org/abs/2308.07163",
    "authors": [
      "Patrick Glandorf",
      "Timo Kaiser",
      "Bodo Rosenhahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07170",
    "title": "PitchNet: A Fully Convolutional Neural Network for Pitch Estimation",
    "abstract": "In the domain of music and sound processing, pitch extraction plays a pivotal role. This research introduces \"PitchNet\", a convolutional neural network tailored for pitch extraction from the human singing voice, including acapella performances. Integrating autocorrelation with deep learning techniques, PitchNet aims to optimize the accuracy of pitch detection. Evaluation across datasets comprising synthetic sounds, opera recordings, and time-stretched vowels demonstrates its efficacy. This work paves the way for enhanced pitch extraction in both music and voice settings. ",
    "url": "https://arxiv.org/abs/2308.07170",
    "authors": [
      "Jeremy Cochoy"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.07193",
    "title": "Task Offloading for Smart Glasses in Healthcare: Enhancing Detection of  Elevated Body Temperature",
    "abstract": "Wearable devices like smart glasses have gained popularity across various applications. However, their limited computational capabilities pose challenges for tasks that require extensive processing, such as image and video processing, leading to drained device batteries. To address this, offloading such tasks to nearby powerful remote devices, such as mobile devices or remote servers, has emerged as a promising solution. This paper focuses on analyzing task-offloading scenarios for a healthcare monitoring application performed on smart wearable glasses, aiming to identify the optimal conditions for offloading. The study evaluates performance metrics including task completion time, computing capabilities, and energy consumption under realistic conditions. A specific use case is explored within an indoor area like an airport, where security agents wearing smart glasses to detect elevated body temperature in individuals, potentially indicating COVID-19. The findings highlight the potential benefits of task offloading for wearable devices in healthcare settings, demonstrating its practicality and relevance. ",
    "url": "https://arxiv.org/abs/2308.07193",
    "authors": [
      "Abdenacer Naouri",
      "Nabil Abdelkader Nouri",
      "Attia Qammar",
      "Feifei Shi",
      "Huansheng Ning",
      "Sahraoui Dhelim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2308.07200",
    "title": "Neural Categorical Priors for Physics-Based Character Control",
    "abstract": "Recent advances in learning reusable motion priors have demonstrated their effectiveness in generating naturalistic behaviors. In this paper, we propose a new learning framework in this paradigm for controlling physics-based characters with significantly improved motion quality and diversity over existing state-of-the-art methods. The proposed method uses reinforcement learning (RL) to initially track and imitate life-like movements from unstructured motion clips using the discrete information bottleneck, as adopted in the Vector Quantized Variational AutoEncoder (VQ-VAE). This structure compresses the most relevant information from the motion clips into a compact yet informative latent space, i.e., a discrete space over vector quantized codes. By sampling codes in the space from a trained categorical prior distribution, high-quality life-like behaviors can be generated, similar to the usage of VQ-VAE in computer vision. Although this prior distribution can be trained with the supervision of the encoder's output, it follows the original motion clip distribution in the dataset and could lead to imbalanced behaviors in our setting. To address the issue, we further propose a technique named prior shifting to adjust the prior distribution using curiosity-driven RL. The outcome distribution is demonstrated to offer sufficient behavioral diversity and significantly facilitates upper-level policy learning for downstream tasks. We conduct comprehensive experiments using humanoid characters on two challenging downstream tasks, sword-shield striking and two-player boxing game. Our results demonstrate that the proposed framework is capable of controlling the character to perform considerably high-quality movements in terms of behavioral strategies, diversity, and realism. Videos, codes, and data are available at https://tencent-roboticsx.github.io/NCP/. ",
    "url": "https://arxiv.org/abs/2308.07200",
    "authors": [
      "Qingxu Zhu",
      "He Zhang",
      "Mengting Lan",
      "Lei Han"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07202",
    "title": "Towards Robust Real-Time Scene Text Detection: From Semantic to Instance  Representation Learning",
    "abstract": "Due to the flexible representation of arbitrary-shaped scene text and simple pipeline, bottom-up segmentation-based methods begin to be mainstream in real-time scene text detection. Despite great progress, these methods show deficiencies in robustness and still suffer from false positives and instance adhesion. Different from existing methods which integrate multiple-granularity features or multiple outputs, we resort to the perspective of representation learning in which auxiliary tasks are utilized to enable the encoder to jointly learn robust features with the main task of per-pixel classification during optimization. For semantic representation learning, we propose global-dense semantic contrast (GDSC), in which a vector is extracted for global semantic representation, then used to perform element-wise contrast with the dense grid features. To learn instance-aware representation, we propose to combine top-down modeling (TDM) with the bottom-up framework to provide implicit instance-level clues for the encoder. With the proposed GDSC and TDM, the encoder network learns stronger representation without introducing any parameters and computations during inference. Equipped with a very light decoder, the detector can achieve more robust real-time scene text detection. Experimental results on four public datasets show that the proposed method can outperform or be comparable to the state-of-the-art on both accuracy and speed. Specifically, the proposed method achieves 87.2% F-measure with 48.2 FPS on Total-Text and 89.6% F-measure with 36.9 FPS on MSRA-TD500 on a single GeForce RTX 2080 Ti GPU. ",
    "url": "https://arxiv.org/abs/2308.07202",
    "authors": [
      "Xugong Qin",
      "Pengyuan Lyu",
      "Chengquan Zhang",
      "Yu Zhou",
      "Kun Yao",
      "Peng Zhang",
      "Hailun Lin",
      "Weiping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07204",
    "title": "Algorithms for the Training of Neural Support Vector Machines",
    "abstract": "Neural support vector machines (NSVMs) allow for the incorporation of domain knowledge in the design of the model architecture. In this article we introduce a set of training algorithms for NSVMs that leverage the Pegasos algorithm and provide a proof of concept by solving a set of standard machine learning tasks. ",
    "url": "https://arxiv.org/abs/2308.07204",
    "authors": [
      "Lars Simon",
      "Manuel Radons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07222",
    "title": "MM-GEF: Multi-modal representation meet collaborative filtering",
    "abstract": "In modern e-commerce, item content features in various modalities offer accurate yet comprehensive information to recommender systems. The majority of previous work either focuses on learning effective item representation during modelling user-item interactions, or exploring item-item relationships by analysing multi-modal features. Those methods, however, fail to incorporate the collaborative item-user-item relationships into the multi-modal feature-based item structure. In this work, we propose a graph-based item structure enhancement method MM-GEF: Multi-Modal recommendation with Graph Early-Fusion, which effectively combines the latent item structure underlying multi-modal contents with the collaborative signals. Instead of processing the content feature in different modalities separately, we show that the early-fusion of multi-modal features provides significant improvement. MM-GEF learns refined item representations by injecting structural information obtained from both multi-modal and collaborative signals. Through extensive experiments on four publicly available datasets, we demonstrate systematical improvements of our method over state-of-the-art multi-modal recommendation methods. ",
    "url": "https://arxiv.org/abs/2308.07222",
    "authors": [
      "Hao Wu",
      "Alejandro Ariza-Casabona",
      "Bart\u0142omiej Twardowski",
      "Tri Kurniawan Wijaya"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.07233",
    "title": "A Unifying Generator Loss Function for Generative Adversarial Networks",
    "abstract": "A unifying $\\alpha$-parametrized generator loss function is introduced for a dual-objective generative adversarial network (GAN), which uses a canonical (or classical) discriminator loss function such as the one in the original GAN (VanillaGAN) system. The generator loss function is based on a symmetric class probability estimation type function, $\\mathcal{L}_\\alpha$, and the resulting GAN system is termed $\\mathcal{L}_\\alpha$-GAN. Under an optimal discriminator, it is shown that the generator's optimization problem consists of minimizing a Jensen-$f_\\alpha$-divergence, a natural generalization of the Jensen-Shannon divergence, where $f_\\alpha$ is a convex function expressed in terms of the loss function $\\mathcal{L}_\\alpha$. It is also demonstrated that this $\\mathcal{L}_\\alpha$-GAN problem recovers as special cases a number of GAN problems in the literature, including VanillaGAN, Least Squares GAN (LSGAN), Least $k$th order GAN (L$k$GAN) and the recently introduced $(\\alpha_D,\\alpha_G)$-GAN with $\\alpha_D=1$. Finally, experimental results are conducted on three datasets, MNIST, CIFAR-10, and Stacked MNIST to illustrate the performance of various examples of the $\\mathcal{L}_\\alpha$-GAN system. ",
    "url": "https://arxiv.org/abs/2308.07233",
    "authors": [
      "Justin Veiner",
      "Fady Alajaji",
      "Bahman Gharesifard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07243",
    "title": "AAFACE: Attribute-aware Attentional Network for Face Recognition",
    "abstract": "In this paper, we present a new multi-branch neural network that simultaneously performs soft biometric (SB) prediction as an auxiliary modality and face recognition (FR) as the main task. Our proposed network named AAFace utilizes SB attributes to enhance the discriminative ability of FR representation. To achieve this goal, we propose an attribute-aware attentional integration (AAI) module to perform weighted integration of FR with SB feature maps. Our proposed AAI module is not only fully context-aware but also capable of learning complex relationships between input features by means of the sequential multi-scale channel and spatial sub-modules. Experimental results verify the superiority of our proposed network compared with the state-of-the-art (SoTA) SB prediction and FR methods. ",
    "url": "https://arxiv.org/abs/2308.07243",
    "authors": [
      "Niloufar Alipour Talemi",
      "Hossein Kashiani",
      "Sahar Rahimi Malakshan",
      "Mohammad Saeed Ebrahimi Saadabadi",
      "Nima Najafzadeh",
      "Mohammad Akyash",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07264",
    "title": "Efficient Real-time Smoke Filtration with 3D LiDAR for Search and Rescue  with Autonomous Heterogeneous Robotic Systems",
    "abstract": "Search and Rescue (SAR) missions in harsh and unstructured Sub-Terranean (Sub-T) environments in the presence of aerosol particles have recently become the main focus in the field of robotics. Aerosol particles such as smoke and dust directly affect the performance of any mobile robotic platform due to their reliance on their onboard perception systems for autonomous navigation and localization in Global Navigation Satellite System (GNSS)-denied environments. Although obstacle avoidance and object detection algorithms are robust to the presence of noise to some degree, their performance directly relies on the quality of captured data by onboard sensors such as Light Detection And Ranging (LiDAR) and camera. Thus, this paper proposes a novel modular agnostic filtration pipeline based on intensity and spatial information such as local point density for removal of detected smoke particles from Point Cloud (PCL) prior to its utilization for collision detection. Furthermore, the efficacy of the proposed framework in the presence of smoke during multiple frontier exploration missions is investigated while the experimental results are presented to facilitate comparison with other methodologies and their computational impact. This provides valuable insight to the research community for better utilization of filtration schemes based on available computation resources while considering the safe autonomous navigation of mobile robots. ",
    "url": "https://arxiv.org/abs/2308.07264",
    "authors": [
      "Alexander Kyuroson",
      "Anton Koval",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07279",
    "title": "A Robust Approach Towards Distinguishing Natural and Computer Generated  Images using Multi-Colorspace fused and Enriched Vision Transformer",
    "abstract": "The works in literature classifying natural and computer generated images are mostly designed as binary tasks either considering natural images versus computer graphics images only or natural images versus GAN generated images only, but not natural images versus both classes of the generated images. Also, even though this forensic classification task of distinguishing natural and computer generated images gets the support of the new convolutional neural networks and transformer based architectures that can give remarkable classification accuracies, they are seen to fail over the images that have undergone some post-processing operations usually performed to deceive the forensic algorithms, such as JPEG compression, gaussian noise, etc. This work proposes a robust approach towards distinguishing natural and computer generated images including both, computer graphics and GAN generated images using a fusion of two vision transformers where each of the transformer networks operates in different color spaces, one in RGB and the other in YCbCr color space. The proposed approach achieves high performance gain when compared to a set of baselines, and also achieves higher robustness and generalizability than the baselines. The features of the proposed model when visualized are seen to obtain higher separability for the classes than the input image features and the baseline features. This work also studies the attention map visualizations of the networks of the fused model and observes that the proposed methodology can capture more image information relevant to the forensic task of classifying natural and generated images. ",
    "url": "https://arxiv.org/abs/2308.07279",
    "authors": [
      "Manjary P Gangan",
      "Anoop Kadan",
      "Lajish V L"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07284",
    "title": "Cross-Attribute Matrix Factorization Model with Shared User Embedding",
    "abstract": "Over the past few years, deep learning has firmly established its prowess across various domains, including computer vision, speech recognition, and natural language processing. Motivated by its outstanding success, researchers have been directing their efforts towards applying deep learning techniques to recommender systems. Neural collaborative filtering (NCF) and Neural Matrix Factorization (NeuMF) refreshes the traditional inner product in matrix factorization with a neural architecture capable of learning complex and data-driven functions. While these models effectively capture user-item interactions, they overlook the specific attributes of both users and items. This can lead to robustness issues, especially for items and users that belong to the \"long tail\". Such challenges are commonly recognized in recommender systems as a part of the cold-start problem. A direct and intuitive approach to address this issue is by leveraging the features and attributes of the items and users themselves. In this paper, we introduce a refined NeuMF model that considers not only the interaction between users and items, but also acrossing associated attributes. Moreover, our proposed architecture features a shared user embedding, seamlessly integrating with user embeddings to imporve the robustness and effectively address the cold-start problem. Rigorous experiments on both the Movielens and Pinterest datasets demonstrate the superiority of our Cross-Attribute Matrix Factorization model, particularly in scenarios characterized by higher dataset sparsity. ",
    "url": "https://arxiv.org/abs/2308.07284",
    "authors": [
      "Wen Liang",
      "Zeng Fan",
      "Youzhi Liang",
      "Jianguo Jia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07293",
    "title": "DiffSED: Sound Event Detection with Denoising Diffusion",
    "abstract": "Sound Event Detection (SED) aims to predict the temporal boundaries of all the events of interest and their class labels, given an unconstrained audio sample. Taking either the splitand-classify (i.e., frame-level) strategy or the more principled event-level modeling approach, all existing methods consider the SED problem from the discriminative learning perspective. In this work, we reformulate the SED problem by taking a generative learning perspective. Specifically, we aim to generate sound temporal boundaries from noisy proposals in a denoising diffusion process, conditioned on a target audio sample. During training, our model learns to reverse the noising process by converting noisy latent queries to the groundtruth versions in the elegant Transformer decoder framework. Doing so enables the model generate accurate event boundaries from even noisy queries during inference. Extensive experiments on the Urban-SED and EPIC-Sounds datasets demonstrate that our model significantly outperforms existing alternatives, with 40+% faster convergence in training. ",
    "url": "https://arxiv.org/abs/2308.07293",
    "authors": [
      "Swapnil Bhosale",
      "Sauradip Nag",
      "Diptesh Kanojia",
      "Jiankang Deng",
      "Xiatian Zhu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.07305",
    "title": "Neural Authorship Attribution: Stylometric Analysis on Large Language  Models",
    "abstract": "Large language models (LLMs) such as GPT-4, PaLM, and Llama have significantly propelled the generation of AI-crafted text. With rising concerns about their potential misuse, there is a pressing need for AI-generated-text forensics. Neural authorship attribution is a forensic effort, seeking to trace AI-generated text back to its originating LLM. The LLM landscape can be divided into two primary categories: proprietary and open-source. In this work, we delve into these emerging categories of LLMs, focusing on the nuances of neural authorship attribution. To enrich our understanding, we carry out an empirical analysis of LLM writing signatures, highlighting the contrasts between proprietary and open-source models, and scrutinizing variations within each group. By integrating stylometric features across lexical, syntactic, and structural aspects of language, we explore their potential to yield interpretable results and augment pre-trained language model-based classifiers utilized in neural authorship attribution. Our findings, based on a range of state-of-the-art LLMs, provide empirical insights into neural authorship attribution, paving the way for future investigations aimed at mitigating the threats posed by AI-generated misinformation. ",
    "url": "https://arxiv.org/abs/2308.07305",
    "authors": [
      "Tharindu Kumarage",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06293",
    "title": "Target Detection on Hyperspectral Images Using MCMC and VI Trained  Bayesian Neural Networks",
    "abstract": "Neural networks (NN) have become almost ubiquitous with image classification, but in their standard form produce point estimates, with no measure of confidence. Bayesian neural networks (BNN) provide uncertainty quantification (UQ) for NN predictions and estimates through the posterior distribution. As NN are applied in more high-consequence applications, UQ is becoming a requirement. BNN provide a solution to this problem by not only giving accurate predictions and estimates, but also an interval that includes reasonable values within a desired probability. Despite their positive attributes, BNN are notoriously difficult and time consuming to train. Traditional Bayesian methods use Markov Chain Monte Carlo (MCMC), but this is often brushed aside as being too slow. The most common method is variational inference (VI) due to its fast computation, but there are multiple concerns with its efficacy. We apply and compare MCMC- and VI-trained BNN in the context of target detection in hyperspectral imagery (HSI), where materials of interest can be identified by their unique spectral signature. This is a challenging field, due to the numerous permuting effects practical collection of HSI has on measured spectra. Both models are trained using out-of-the-box tools on a high fidelity HSI target detection scene. Both MCMC- and VI-trained BNN perform well overall at target detection on a simulated HSI scene. This paper provides an example of how to utilize the benefits of UQ, but also to increase awareness that different training methods can give different results for the same model. If sufficient computational resources are available, the best approach rather than the fastest or most efficient should be used, especially for high consequence problems. ",
    "url": "https://arxiv.org/abs/2308.06293",
    "authors": [
      "Daniel Ries",
      "Jason Adams",
      "Joshua Zollweg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06301",
    "title": "Generalized Gr\u00f6tzsch Graphs",
    "abstract": "The aim of this paper is to present a generalization of Gr\\\"otzsch graph. Inspired by structure of the Gr\\\"otzsch's graph, we present constructions of two families of graphs, $G_m$ and $H_m$ for odd and even values of $m$ respectively and on $n = 2m +1$ vertices. We show that each member of this family is non-planar, triangle-free, and Hamiltonian. Further, when $m$ is odd the graph $G_m$ is maximal triangle-free, and when $m$ is even, the addition of exactly $\\frac{m}{2}$ edges makes the graph $H_m$ maximal triangle-free. We show that $G_m$ is 4-chromatic and $H_m$ is 3-chromatic for all $m$. Further, we note some other properties of these graphs and compare with Mycielski's construction. ",
    "url": "https://arxiv.org/abs/2308.06301",
    "authors": [
      "Ashish Upadhyay"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2308.06333",
    "title": "Deep Learning-Based Open Source Toolkit for Eosinophil Detection in  Pediatric Eosinophilic Esophagitis",
    "abstract": "Eosinophilic Esophagitis (EoE) is a chronic, immune/antigen-mediated esophageal disease, characterized by symptoms related to esophageal dysfunction and histological evidence of eosinophil-dominant inflammation. Owing to the intricate microscopic representation of EoE in imaging, current methodologies which depend on manual identification are not only labor-intensive but also prone to inaccuracies. In this study, we develop an open-source toolkit, named Open-EoE, to perform end-to-end whole slide image (WSI) level eosinophil (Eos) detection using one line of command via Docker. Specifically, the toolkit supports three state-of-the-art deep learning-based object detection models. Furthermore, Open-EoE further optimizes the performance by implementing an ensemble learning strategy, and enhancing the precision and reliability of our results. The experimental results demonstrated that the Open-EoE toolkit can efficiently detect Eos on a testing set with 289 WSIs. At the widely accepted threshold of >= 15 Eos per high power field (HPF) for diagnosing EoE, the Open-EoE achieved an accuracy of 91%, showing decent consistency with pathologist evaluations. This suggests a promising avenue for integrating machine learning methodologies into the diagnostic process for EoE. The docker and source code has been made publicly available at https://github.com/hrlblab/Open-EoE. ",
    "url": "https://arxiv.org/abs/2308.06333",
    "authors": [
      "Juming Xiong",
      "Yilin Liu",
      "Ruining Deng",
      "Regina N Tyree",
      "Hernan Correa",
      "Girish Hiremath",
      "Yaohong Wang",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06377",
    "title": "CATS v2: Hybrid encoders for robust medical segmentation",
    "abstract": "Convolutional Neural Networks (CNNs) have exhibited strong performance in medical image segmentation tasks by capturing high-level (local) information, such as edges and textures. However, due to the limited field of view of convolution kernel, it is hard for CNNs to fully represent global information. Recently, transformers have shown good performance for medical image segmentation due to their ability to better model long-range dependencies. Nevertheless, transformers struggle to capture high-level spatial features as effectively as CNNs. A good segmentation model should learn a better representation from local and global features to be both precise and semantically accurate. In our previous work, we proposed CATS, which is a U-shaped segmentation network augmented with transformer encoder. In this work, we further extend this model and propose CATS v2 with hybrid encoders. Specifically, hybrid encoders consist of a CNN-based encoder path paralleled to a transformer path with a shifted window, which better leverage both local and global information to produce robust 3D medical image segmentation. We fuse the information from the convolutional encoder and the transformer at the skip connections of different resolutions to form the final segmentation. The proposed method is evaluated on two public challenge datasets: Cross-Modality Domain Adaptation (CrossMoDA) and task 5 of Medical Segmentation Decathlon (MSD-5), to segment vestibular schwannoma (VS) and prostate, respectively. Compared with the state-of-the-art methods, our approach demonstrates superior performance in terms of higher Dice scores. ",
    "url": "https://arxiv.org/abs/2308.06377",
    "authors": [
      "Hao Li",
      "Han Liu",
      "Dewei Hu",
      "Xing Yao",
      "Jiacheng Wang",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06399",
    "title": "Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via  Mixed-Effect Models and Hierarchical Clustering",
    "abstract": "Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships. Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery of new connections and the improvement of improved model specification. Furthermore, we observe a reduction in prediction errors from 28\\% to 17\\%. By extending the applicability of BNs to complex data set structures, this approach contributes to the effective utilisation of BNs for hierarchical agronomic data. This, in turn, enhances their value as decision-support tools in the field. ",
    "url": "https://arxiv.org/abs/2308.06399",
    "authors": [
      "Lorenzo Vallegi",
      "Marco Scutari",
      "Federico Mattia Stefanini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2308.06481",
    "title": "Out-of-distribution multi-view auto-encoders for prostate cancer lesion  detection",
    "abstract": "Traditional deep learning (DL) approaches based on supervised learning paradigms require large amounts of annotated data that are rarely available in the medical domain. Unsupervised Out-of-distribution (OOD) detection is an alternative that requires less annotated data. Further, OOD applications exploit the class skewness commonly present in medical data. Magnetic resonance imaging (MRI) has proven to be useful for prostate cancer (PCa) diagnosis and management, but current DL approaches rely on T2w axial MRI, which suffers from low out-of-plane resolution. We propose a multi-stream approach to accommodate different T2w directions to improve the performance of PCa lesion detection in an OOD approach. We evaluate our approach on a publicly available data-set, obtaining better detection results in terms of AUC when compared to a single direction approach (73.1 vs 82.3). Our results show the potential of OOD approaches for PCa lesion detection based on MRI. ",
    "url": "https://arxiv.org/abs/2308.06481",
    "authors": [
      "Alvaro Fernandez-Quilez",
      "Linas Vidziunas",
      "\u00d8rjan Kl\u00f8vfjell Thoresen",
      "Ketil Oppedal",
      "Svein Reidar Kjosavik",
      "Trygve Eftest\u00f8l"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06562",
    "title": "Gradient-Based Markov Chain Monte Carlo for MIMO Detection",
    "abstract": "Accurately detecting symbols transmitted over multiple-input multiple-output (MIMO) wireless channels is crucial in realizing the benefits of MIMO techniques. However, optimal MIMO detection is associated with a complexity that grows exponentially with the MIMO dimensions and quickly becomes impractical. Recently, stochastic sampling-based Bayesian inference techniques, such as Markov chain Monte Carlo (MCMC), have been combined with the gradient descent (GD) method to provide a promising framework for MIMO detection. In this work, we propose to efficiently approach optimal detection by exploring the discrete search space via MCMC random walk accelerated by Nesterov's gradient method. Nesterov's GD guides MCMC to make efficient searches without the computationally expensive matrix inversion and line search. Our proposed method operates using multiple GDs per random walk, achieving sufficient descent towards important regions of the search space before adding random perturbations, guaranteeing high sampling efficiency. To provide augmented exploration, extra samples are derived through the trajectory of Nesterov's GD by simple operations, effectively supplementing the sample list for statistical inference and boosting the overall MIMO detection performance. Furthermore, we design an early stopping tactic to terminate unnecessary further searches, remarkably reducing the complexity. Simulation results and complexity analysis reveal that the proposed method achieves near-optimal performance in both uncoded and coded MIMO systems, adapts to realistic channel models, and scales well to large MIMO dimensions. ",
    "url": "https://arxiv.org/abs/2308.06562",
    "authors": [
      "Xingyu Zhou",
      "Le Liang",
      "Jing Zhang",
      "Chao-Kai Wen",
      "Shi Jin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2308.06746",
    "title": "Self-supervised Noise2noise Method Utilizing Corrupted Images with a  Modular Network for LDCT Denoising",
    "abstract": "Deep learning is a very promising technique for low-dose computed tomography (LDCT) image denoising. However, traditional deep learning methods require paired noisy and clean datasets, which are often difficult to obtain. This paper proposes a new method for performing LDCT image denoising with only LDCT data, which means that normal-dose CT (NDCT) is not needed. We adopt a combination including the self-supervised noise2noise model and the noisy-as-clean strategy. First, we add a second yet similar type of noise to LDCT images multiple times. Note that we use LDCT images based on the noisy-as-clean strategy for corruption instead of NDCT images. Then, the noise2noise model is executed with only the secondary corrupted images for training. We select a modular U-Net structure from several candidates with shared parameters to perform the task, which increases the receptive field without increasing the parameter size. The experimental results obtained on the Mayo LDCT dataset show the effectiveness of the proposed method compared with that of state-of-the-art deep learning methods. The developed code is available at https://github.com/XYuan01/Self-supervised-Noise2Noise-for-LDCT. ",
    "url": "https://arxiv.org/abs/2308.06746",
    "authors": [
      "Yuting Zhu",
      "Qiang He",
      "Yudong Yao",
      "Yueyang Teng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06769",
    "title": "Fr\u00e9chet Statistics Based Change Point Detection in Multivariate Hawkes  Process",
    "abstract": "This paper proposes a new approach for change point detection in causal networks of multivariate Hawkes processes using Frechet statistics. Our method splits the point process into overlapping windows, estimates kernel matrices in each window, and reconstructs the signed Laplacians by treating the kernel matrices as the adjacency matrices of the causal network. We demonstrate the effectiveness of our method through experiments on both simulated and real-world cryptocurrency datasets. Our results show that our method is capable of accurately detecting and characterizing changes in the causal structure of multivariate Hawkes processes, and may have potential applications in fields such as finance and neuroscience. The proposed method is an extension of previous work on Frechet statistics in point process settings and represents an important contribution to the field of change point detection in multivariate point processes. ",
    "url": "https://arxiv.org/abs/2308.06769",
    "authors": [
      "Rui Luo",
      "Vikram Krishnamurthy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.06776",
    "title": "Unsupervised Image Denoising in Real-World Scenarios via  Self-Collaboration Parallel Generative Adversarial Branches",
    "abstract": "Deep learning methods have shown remarkable performance in image denoising, particularly when trained on large-scale paired datasets. However, acquiring such paired datasets for real-world scenarios poses a significant challenge. Although unsupervised approaches based on generative adversarial networks offer a promising solution for denoising without paired datasets, they are difficult in surpassing the performance limitations of conventional GAN-based unsupervised frameworks without significantly modifying existing structures or increasing the computational complexity of denoisers. To address this problem, we propose a SC strategy for multiple denoisers. This strategy can achieve significant performance improvement without increasing the inference complexity of the GAN-based denoising framework. Its basic idea is to iteratively replace the previous less powerful denoiser in the filter-guided noise extraction module with the current powerful denoiser. This process generates better synthetic clean-noisy image pairs, leading to a more powerful denoiser for the next iteration. This baseline ensures the stability and effectiveness of the training network. The experimental results demonstrate the superiority of our method over state-of-the-art unsupervised methods. ",
    "url": "https://arxiv.org/abs/2308.06776",
    "authors": [
      "Xin Lin",
      "Chao Ren",
      "Xiao Liu",
      "Jie Huang",
      "Yinjie Lei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06807",
    "title": "Neural Networks for Programming Quantum Annealers",
    "abstract": "Quantum machine learning has the potential to enable advances in artificial intelligence, such as solving problems intractable on classical computers. Some fundamental ideas behind quantum machine learning are similar to kernel methods in classical machine learning. Both process information by mapping it into high-dimensional vector spaces without explicitly calculating their numerical values. We explore a setup for performing classification on labeled classical datasets, consisting of a classical neural network connected to a quantum annealer. The neural network programs the quantum annealer's controls and thereby maps the annealer's initial states into new states in the Hilbert space. The neural network's parameters are optimized to maximize the distance of states corresponding to inputs from different classes and minimize the distance between quantum states corresponding to the same class. Recent literature showed that at least some of the \"learning\" is due to the quantum annealer, connecting a small linear network to a quantum annealer and using it to learn small and linearly inseparable datasets. In this study, we consider a similar but not quite the same case, where a classical fully-fledged neural network is connected with a small quantum annealer. In such a setting, the fully-fledged classical neural-network already has built-in nonlinearity and learning power, and can already handle the classification problem alone, we want to see whether an additional quantum layer could boost its performance. We simulate this system to learn several common datasets, including those for image and sound recognition. We conclude that adding a small quantum annealer does not provide a significant benefit over just using a regular (nonlinear) classical neural network. ",
    "url": "https://arxiv.org/abs/2308.06807",
    "authors": [
      "Samuel Bosch",
      "Bobak Kiani",
      "Rui Yang",
      "Adrian Lupascu",
      "Seth Lloyd"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06855",
    "title": "Distance preservation in state-space methods for detecting causal  interactions in dynamical systems",
    "abstract": "We analyze the popular ``state-space'' class of algorithms for detecting casual interaction in coupled dynamical systems. These algorithms are often justified by Takens' embedding theorem, which provides conditions under which relationships involving attractors and their delay embeddings are continuous. In practice, however, state-space methods often do not directly test continuity, but rather the stronger property of how these relationships preserve inter-point distances. This paper theoretically and empirically explores state-space algorithms explicitly from the perspective of distance preservation. We first derive basic theoretical guarantees applicable to simple coupled systems, providing conditions under which the distance preservation of a certain map reveals underlying causal structure. Second, we demonstrate empirically that typical coupled systems do not satisfy distance preservation assumptions. Taken together, our results underline the dependence of state-space algorithms on intrinsic system properties and the relationship between the system and the function used to measure it -- properties that are not directly associated with causal interaction. ",
    "url": "https://arxiv.org/abs/2308.06855",
    "authors": [
      "Matthew O'Shaughnessy",
      "Mark Davenport",
      "Christopher Rozell"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.06873",
    "title": "SpeechX: Neural Codec Language Model as a Versatile Speech Transformer",
    "abstract": "Recent advancements in generative speech models based on audio-text prompts have enabled remarkable innovations like high-quality zero-shot text-to-speech. However, existing models still face limitations in handling diverse audio-text speech generation tasks involving transforming input speech and processing audio captured in adverse acoustic conditions. This paper introduces SpeechX, a versatile speech generation model capable of zero-shot TTS and various speech transformation tasks, dealing with both clean and noisy signals. SpeechX combines neural codec language modeling with multi-task learning using task-dependent prompting, enabling unified and extensible modeling and providing a consistent way for leveraging textual input in speech enhancement and transformation tasks. Experimental results show SpeechX's efficacy in various tasks, including zero-shot TTS, noise suppression, target speaker extraction, speech removal, and speech editing with or without background noise, achieving comparable or superior performance to specialized models across tasks. See https://aka.ms/speechx for demo samples. ",
    "url": "https://arxiv.org/abs/2308.06873",
    "authors": [
      "Xiaofei Wang",
      "Manthan Thakker",
      "Zhuo Chen",
      "Naoyuki Kanda",
      "Sefik Emre Eskimez",
      "Sanyuan Chen",
      "Min Tang",
      "Shujie Liu",
      "Jinyu Li",
      "Takuya Yoshioka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2308.06889",
    "title": "Robustness Stress Testing in Medical Image Classification",
    "abstract": "Deep neural networks have shown impressive performance for image-based disease detection. Performance is commonly evaluated through clinical validation on independent test sets to demonstrate clinically acceptable accuracy. Reporting good performance metrics on test sets, however, is not always a sufficient indication of the generalizability and robustness of an algorithm. In particular, when the test data is drawn from the same distribution as the training data, the iid test set performance can be an unreliable estimate of the accuracy on new data. In this paper, we employ stress testing to assess model robustness and subgroup performance disparities in disease detection models. We design progressive stress testing using five different bidirectional and unidirectional image perturbations with six different severity levels. As a use case, we apply stress tests to measure the robustness of disease detection models for chest X-ray and skin lesion images, and demonstrate the importance of studying class and domain-specific model behaviour. Our experiments indicate that some models may yield more robust and equitable performance than others. We also find that pretraining characteristics play an important role in downstream robustness. We conclude that progressive stress testing is a viable and important tool and should become standard practice in the clinical validation of image-based disease detection models. ",
    "url": "https://arxiv.org/abs/2308.06889",
    "authors": [
      "Mobarakol Islam",
      "Zeju Li",
      "Ben Glocker"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06957",
    "title": "CEmb-SAM: Segment Anything Model with Condition Embedding for Joint  Learning from Heterogeneous Datasets",
    "abstract": "Automated segmentation of ultrasound images can assist medical experts with diagnostic and therapeutic procedures. Although using the common modality of ultrasound, one typically needs separate datasets in order to segment, for example, different anatomical structures or lesions with different levels of malignancy. In this paper, we consider the problem of jointly learning from heterogeneous datasets so that the model can improve generalization abilities by leveraging the inherent variability among datasets. We merge the heterogeneous datasets into one dataset and refer to each component dataset as a subgroup. We propose to train a single segmentation model so that the model can adapt to each sub-group. For robust segmentation, we leverage recently proposed Segment Anything model (SAM) in order to incorporate sub-group information into the model. We propose SAM with Condition Embedding block (CEmb-SAM) which encodes sub-group conditions and combines them with image embeddings from SAM. The conditional embedding block effectively adapts SAM to each image sub-group by incorporating dataset properties through learnable parameters for normalization. Experiments show that CEmb-SAM outperforms the baseline methods on ultrasound image segmentation for peripheral nerves and breast cancer. The experiments highlight the effectiveness of Cemb-SAM in learning from heterogeneous datasets in medical image segmentation tasks. ",
    "url": "https://arxiv.org/abs/2308.06957",
    "authors": [
      "Dongik Shin",
      "Beomsuk Kim",
      "Seungjun Baek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06987",
    "title": "Deep convolutional neural networks for cyclic sensor data",
    "abstract": "Predictive maintenance plays a critical role in ensuring the uninterrupted operation of industrial systems and mitigating the potential risks associated with system failures. This study focuses on sensor-based condition monitoring and explores the application of deep learning techniques using a hydraulic system testbed dataset. Our investigation involves comparing the performance of three models: a baseline model employing conventional methods, a single CNN model with early sensor fusion, and a two-lane CNN model (2L-CNN) with late sensor fusion. The baseline model achieves an impressive test error rate of 1% by employing late sensor fusion, where feature extraction is performed individually for each sensor. However, the CNN model encounters challenges due to the diverse sensor characteristics, resulting in an error rate of 20.5%. To further investigate this issue, we conduct separate training for each sensor and observe variations in accuracy. Additionally, we evaluate the performance of the 2L-CNN model, which demonstrates significant improvement by reducing the error rate by 33% when considering the combination of the least and most optimal sensors. This study underscores the importance of effectively addressing the complexities posed by multi-sensor systems in sensor-based condition monitoring. ",
    "url": "https://arxiv.org/abs/2308.06987",
    "authors": [
      "Payman Goodarzi",
      "Yannick Robin",
      "Andreas Sch\u00fctze",
      "Tizian Schneider"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07003",
    "title": "Deepbet: Fast brain extraction of T1-weighted MRI using Convolutional  Neural Networks",
    "abstract": "Brain extraction in magnetic resonance imaging (MRI) data is an important segmentation step in many neuroimaging preprocessing pipelines. Image segmentation is one of the research fields in which deep learning had the biggest impact in recent years enabling high precision segmentation with minimal compute. Consequently, traditional brain extraction methods are now being replaced by deep learning-based methods. Here, we used a unique dataset comprising 568 T1-weighted (T1w) MR images from 191 different studies in combination with cutting edge deep learning methods to build a fast, high-precision brain extraction tool called deepbet. deepbet uses LinkNet, a modern UNet architecture, in a two stage prediction process. This increases its segmentation performance, setting a novel state-of-the-art performance during cross-validation with a median Dice score (DSC) of 99.0% on unseen datasets, outperforming current state of the art models (DSC = 97.8% and DSC = 97.9%). While current methods are more sensitive to outliers, resulting in Dice scores as low as 76.5%, deepbet manages to achieve a Dice score of > 96.9% for all samples. Finally, our model accelerates brain extraction by a factor of ~10 compared to current methods, enabling the processing of one image in ~2 seconds on low level hardware. ",
    "url": "https://arxiv.org/abs/2308.07003",
    "authors": [
      "Lukas Fisch",
      "Stefan Zumdick",
      "Carlotta Barkhau",
      "Daniel Emden",
      "Jan Ernsting",
      "Ramona Leenings",
      "Kelvin Sarink",
      "Nils R. Winter",
      "Benjamin Risse",
      "Udo Dannlowski",
      "Tim Hahn"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07012",
    "title": "Greedy online change point detection",
    "abstract": "Standard online change point detection (CPD) methods tend to have large false discovery rates as their detections are sensitive to outliers. To overcome this drawback, we propose Greedy Online Change Point Detection (GOCPD), a computationally appealing method which finds change points by maximizing the probability of the data coming from the (temporal) concatenation of two independent models. We show that, for time series with a single change point, this objective is unimodal and thus CPD can be accelerated via ternary search with logarithmic complexity. We demonstrate the effectiveness of GOCPD on synthetic data and validate our findings on real-world univariate and multivariate settings. ",
    "url": "https://arxiv.org/abs/2308.07012",
    "authors": [
      "Jou-Hui Ho",
      "Felipe Tobar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.07156",
    "title": "SAM Meets Robotic Surgery: An Empirical Study on Generalization,  Robustness and Adaptation",
    "abstract": "The Segment Anything Model (SAM) serves as a fundamental model for semantic segmentation and demonstrates remarkable generalization capabilities across a wide range of downstream scenarios. In this empirical study, we examine SAM's robustness and zero-shot generalizability in the field of robotic surgery. We comprehensively explore different scenarios, including prompted and unprompted situations, bounding box and points-based prompt approaches, as well as the ability to generalize under corruptions and perturbations at five severity levels. Additionally, we compare the performance of SAM with state-of-the-art supervised models. We conduct all the experiments with two well-known robotic instrument segmentation datasets from MICCAI EndoVis 2017 and 2018 challenges. Our extensive evaluation results reveal that although SAM shows remarkable zero-shot generalization ability with bounding box prompts, it struggles to segment the whole instrument with point-based prompts and unprompted settings. Furthermore, our qualitative figures demonstrate that the model either failed to predict certain parts of the instrument mask (e.g., jaws, wrist) or predicted parts of the instrument as wrong classes in the scenario of overlapping instruments within the same bounding box or with the point-based prompt. In fact, SAM struggles to identify instruments in complex surgical scenarios characterized by the presence of blood, reflection, blur, and shade. Additionally, SAM is insufficiently robust to maintain high performance when subjected to various forms of data corruption. We also attempt to fine-tune SAM using Low-rank Adaptation (LoRA) and propose SurgicalSAM, which shows the capability in class-wise mask prediction without prompt. Therefore, we can argue that, without further domain-specific fine-tuning, SAM is not ready for downstream surgical tasks. ",
    "url": "https://arxiv.org/abs/2308.07156",
    "authors": [
      "An Wang",
      "Mobarakol Islam",
      "Mengya Xu",
      "Yang Zhang",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07251",
    "title": "Large-kernel Attention for Efficient and Robust Brain Lesion  Segmentation",
    "abstract": "Vision transformers are effective deep learning models for vision tasks, including medical image segmentation. However, they lack efficiency and translational invariance, unlike convolutional neural networks (CNNs). To model long-range interactions in 3D brain lesion segmentation, we propose an all-convolutional transformer block variant of the U-Net architecture. We demonstrate that our model provides the greatest compromise in three factors: performance competitive with the state-of-the-art; parameter efficiency of a CNN; and the favourable inductive biases of a transformer. Our public implementation is available at https://github.com/liamchalcroft/MDUNet . ",
    "url": "https://arxiv.org/abs/2308.07251",
    "authors": [
      "Liam Chalcroft",
      "Ruben Louren\u00e7o Pereira",
      "Mikael Brudfors",
      "Andrew S. Kayser",
      "Mark D'Esposito",
      "Cathy J. Price",
      "Ioannis Pappas",
      "John Ashburner"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07302",
    "title": "Vibrational Stabilization of Cluster Synchronization in Oscillator  Networks",
    "abstract": "Cluster synchronization is of paramount importance for the normal functioning of numerous technological and natural systems. Deviations from normal cluster synchronization patterns are closely associated with various malfunctions, such as neurological disorders in the brain. Therefore, it is crucial to restore normal system functions by stabilizing the appropriate cluster synchronization patterns. Most existing studies focus on designing controllers based on state measurements to achieve system stabilization. However, in many real-world scenarios, measuring system states, such as neuronal activity in the brain, poses significant challenges, rendering the stabilization of such systems difficult. To overcome this challenge, in this paper, we employ an open-loop control strategy, vibrational control, which does not requires any state measurements. We establish some sufficient conditions under which vibrational inputs stabilize cluster synchronization. Further, we provide a tractable approach to design vibrational control. Finally, numerical experiments are conducted to demonstrate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2308.07302",
    "authors": [
      "Yuzhen Qin",
      "Alberto Maria Nobili",
      "Danielle S. Bassett",
      "Fabio Pasqualetti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:1903.10047",
    "title": "Approximation and Non-parametric Estimation of ResNet-type Convolutional  Neural Networks",
    "abstract": " Comments: Version 4: Fixed the constant B^{(fc)} in Theorems 1, 5 and the norm upper bound of w^{(l)}_m in Lemma 1. 8 pages + References 2 pages + Supplemental material 18 pages ",
    "url": "https://arxiv.org/abs/1903.10047",
    "authors": [
      "Kenta Oono",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:1905.12204",
    "title": "Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on  a Random Graph and Provable Auction-Fitted Q-learning",
    "abstract": " Title: Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on  a Random Graph and Provable Auction-Fitted Q-learning ",
    "url": "https://arxiv.org/abs/1905.12204",
    "authors": [
      "Hyunwook Kang",
      "Taehwan Kwon",
      "Jinkyoo Park",
      "James R. Morrison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.01868",
    "title": "Causal Collaborative Filtering",
    "abstract": " Comments: Accepted by the 2023 ACM SIGIR International Conference on Theory of Information Retrieval ",
    "url": "https://arxiv.org/abs/2102.01868",
    "authors": [
      "Shuyuan Xu",
      "Yingqiang Ge",
      "Yunqi Li",
      "Zuohui Fu",
      "Xu Chen",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.14032",
    "title": "Randomized Histogram Matching: A Simple Augmentation for Unsupervised  Domain Adaptation in Overhead Imagery",
    "abstract": " Comments: Includes a main paper (10 pages). This paper is currently undergoing peer review ",
    "url": "https://arxiv.org/abs/2104.14032",
    "authors": [
      "Can Yaras",
      "Kaleb Kassaw",
      "Bohao Huang",
      "Kyle Bradbury",
      "Jordan M. Malof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.03746",
    "title": "Contrastive Attraction and Contrastive Repulsion for Representation  Learning",
    "abstract": " Title: Contrastive Attraction and Contrastive Repulsion for Representation  Learning ",
    "url": "https://arxiv.org/abs/2105.03746",
    "authors": [
      "Huangjie Zheng",
      "Xu Chen",
      "Jiangchao Yao",
      "Hongxia Yang",
      "Chunyuan Li",
      "Ya Zhang",
      "Hao Zhang",
      "Ivor Tsang",
      "Jingren Zhou",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2105.10377",
    "title": "Adaptive Filters in Graph Convolutional Neural Networks",
    "abstract": " Comments: This paper has been published in its final version on \\textit{Pattern Recognition} journal with DOI this https URL in Open Access mode. Please consider it as final and peer-reviewed version ",
    "url": "https://arxiv.org/abs/2105.10377",
    "authors": [
      "Andrea Apicella",
      "Francesco Isgr\u00f2",
      "Andrea Pollastro",
      "Roberto Prevete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.03083",
    "title": "Wireless Network Scheduling with Discrete Propagation Delays: Theorems  and Algorithms",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2107.03083",
    "authors": [
      "Shenghao Yang",
      "Jun Ma",
      "Yanxiao Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2110.07122",
    "title": "Deconfounded Causal Collaborative Filtering",
    "abstract": " Comments: Accepted by the ACM Transactions on Recommender Systems (TORS) ",
    "url": "https://arxiv.org/abs/2110.07122",
    "authors": [
      "Shuyuan Xu",
      "Juntao Tan",
      "Shelby Heinecke",
      "Jia Li",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.06300",
    "title": "Time of Impact Dataset for Continuous Collision Detection and a Scalable  Conservative Algorithm",
    "abstract": " Title: Time of Impact Dataset for Continuous Collision Detection and a Scalable  Conservative Algorithm ",
    "url": "https://arxiv.org/abs/2112.06300",
    "authors": [
      "David Belgrod",
      "Bolun Wang",
      "Zachary Ferguson",
      "Xin Zhao",
      "Marco Attene",
      "Daniele Panozzo",
      "Teseo Schneider"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2201.04604",
    "title": "Fine-grained Graph Learning for Multi-view Subspace Clustering",
    "abstract": " Title: Fine-grained Graph Learning for Multi-view Subspace Clustering ",
    "url": "https://arxiv.org/abs/2201.04604",
    "authors": [
      "Yidi Wang",
      "Xiaobing Pei",
      "Haoxi Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10945",
    "title": "On the Power of Gradual Network Alignment Using Dual-Perception  Similarities",
    "abstract": " Comments: 16 pages, 11 figures, 4 tables; 13 pages, to appear in the IEEE Transactions on Pattern Analysis and Machine Intelligence (Please cite our journal version that will appear in an upcoming issue.) ",
    "url": "https://arxiv.org/abs/2201.10945",
    "authors": [
      "Jin-Duk Park",
      "Cong Tran",
      "Won-Yong Shin",
      "Xin Cao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.11885",
    "title": "A Partition-and-Merge Algorithm for Solving the Steiner Tree Problem in  Large Graphs",
    "abstract": " Comments: The problems and techniques of our paper have been studied long ago, so it is currently meaningless. Therefore, we are preparing to withdraw the manuscript ",
    "url": "https://arxiv.org/abs/2202.11885",
    "authors": [
      "Xinyu Wu",
      "Yi Zhou",
      "Jin-Kao Hao",
      "Zhang-Hua Fu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.06810",
    "title": "Automated Learning for Deformable Medical Image Registration by Jointly  Optimizing Network Architectures and Objective Functions",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2203.06810",
    "authors": [
      "Xin Fan",
      "Zi Li",
      "Ziyang Li",
      "Xiaolin Wang",
      "Risheng Liu",
      "Zhongxuan Luo",
      "Hao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10496",
    "title": "NeuralReshaper: Single-image Human-body Retouching with Deep Neural  Networks",
    "abstract": " Title: NeuralReshaper: Single-image Human-body Retouching with Deep Neural  Networks ",
    "url": "https://arxiv.org/abs/2203.10496",
    "authors": [
      "Beijia Chen",
      "Yuefan Shen",
      "Hongbo Fu",
      "Xiang Chen",
      "Kun Zhou",
      "Youyi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.12330",
    "title": "Predicting the generalization gap in neural networks using topological  data analysis",
    "abstract": " Comments: 24 pages, 7 figures. The Related Work section has been updated and the experiments have been executed anew including a 5x2-fold cross-validation scheme. Figure 4.3 has been crucially improved thanks to the discovery that the clusters of neural networks that appear in that figure correspond to different depths of the corresponding architectures ",
    "url": "https://arxiv.org/abs/2203.12330",
    "authors": [
      "Rub\u00e9n Ballester",
      "Xavier Arnal Clemente",
      "Carles Casacuberta",
      "Meysam Madadi",
      "Ciprian A. Corneanu",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2204.04083",
    "title": "POSTER: A Pyramid Cross-Fusion Transformer Network for Facial Expression  Recognition",
    "abstract": " Comments: ICCV Workshop (AMFG) 2023 ",
    "url": "https://arxiv.org/abs/2204.04083",
    "authors": [
      "Ce Zheng",
      "Matias Mendieta",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.09803",
    "title": "GUARD: Graph Universal Adversarial Defense",
    "abstract": " Comments: Accepted by CIKM 2023. Code is publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2204.09803",
    "authors": [
      "Jintang Li",
      "Jie Liao",
      "Ruofan Wu",
      "Liang Chen",
      "Zibin Zheng",
      "Jiawang Dan",
      "Changhua Meng",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.10952",
    "title": "Analysis of functional neural codes of deep learning models",
    "abstract": " Comments: 13 pages, 8 main figures, 3 supplemental figures, 3 supplemental tables ",
    "url": "https://arxiv.org/abs/2205.10952",
    "authors": [
      "Jung Hoon Lee",
      "Sujith Vijayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11338",
    "title": "Temporal Network Analysis Using Zigzag Persistence",
    "abstract": " Comments: Updated to include missing references ",
    "url": "https://arxiv.org/abs/2205.11338",
    "authors": [
      "Audun Myers",
      "David Mu\u00f1oz",
      "Firas Khasawneh",
      "Elizabeth Munch"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2206.06434",
    "title": "SmartGD: A GAN-Based Graph Drawing Framework for Diverse Aesthetic Goals",
    "abstract": " Title: SmartGD: A GAN-Based Graph Drawing Framework for Diverse Aesthetic Goals ",
    "url": "https://arxiv.org/abs/2206.06434",
    "authors": [
      "Xiaoqi Wang",
      "Kevin Yen",
      "Yifan Hu",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11662",
    "title": "Closeness Centrality Algorithms For Multilayer Networks",
    "abstract": " Title: Closeness Centrality Algorithms For Multilayer Networks ",
    "url": "https://arxiv.org/abs/2207.11662",
    "authors": [
      "Hamza Reza Pavel",
      "Abhishek Santra",
      "Sharma Chakravarthy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.11271",
    "title": "Split, Encode and Aggregate for Long Code Search",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2208.11271",
    "authors": [
      "Fan Hu",
      "Yanlin Wang",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Xirong Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2208.12697",
    "title": "Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction",
    "abstract": " Comments: ICLR 2023 Spotlight. Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2208.12697",
    "authors": [
      "Tong Wu",
      "Jiaqi Wang",
      "Xingang Pan",
      "Xudong Xu",
      "Christian Theobalt",
      "Ziwei Liu",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05674",
    "title": "Semi-supervised detection of structural damage using Variational  Autoencoder and a One-Class Support Vector Machine",
    "abstract": " Title: Semi-supervised detection of structural damage using Variational  Autoencoder and a One-Class Support Vector Machine ",
    "url": "https://arxiv.org/abs/2210.05674",
    "authors": [
      "Andrea Pollastro",
      "Giusiana Testa",
      "Antonio Bilotta",
      "Roberto Prevete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07346",
    "title": "An Embarrassingly Simple Backdoor Attack on Self-supervised Learning",
    "abstract": " Comments: The 2023 International Conference on Computer Vision (ICCV '23) ",
    "url": "https://arxiv.org/abs/2210.07346",
    "authors": [
      "Changjiang Li",
      "Ren Pang",
      "Zhaohan Xi",
      "Tianyu Du",
      "Shouling Ji",
      "Yuan Yao",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13869",
    "title": "A jet tagging algorithm of graph network with HaarPooling message  passing",
    "abstract": " Title: A jet tagging algorithm of graph network with HaarPooling message  passing ",
    "url": "https://arxiv.org/abs/2210.13869",
    "authors": [
      "Fei Ma",
      "Feiyi Liu",
      "Wei Li"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14312",
    "title": "JAX-DIPS: Neural bootstrapping of finite discretization methods and  application to elliptic problems with discontinuities",
    "abstract": " Title: JAX-DIPS: Neural bootstrapping of finite discretization methods and  application to elliptic problems with discontinuities ",
    "url": "https://arxiv.org/abs/2210.14312",
    "authors": [
      "Pouria Mistani",
      "Samira Pakravan",
      "Rajesh Ilango",
      "Frederic Gibou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2211.03226",
    "title": "Rotation-equivariant Graph Neural Networks for Learning Glassy Liquids  Representations",
    "abstract": " Comments: 15 pages, 9 figures plus references and appendix ",
    "url": "https://arxiv.org/abs/2211.03226",
    "authors": [
      "Francesco Saverio Pezzicoli",
      "Guillaume Charpiat",
      "Fran\u00e7ois P. Landes"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11475",
    "title": "Sensing-Assisted Communication in Vehicular Networks with Intelligent  Surface",
    "abstract": " Comments: IEEE Transactions on Vehicular Technology, 2023. arXiv admin note: text overlap with arXiv:2211.04200 ",
    "url": "https://arxiv.org/abs/2211.11475",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Wen Chen",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.14860",
    "title": "Foiling Explanations in Deep Neural Networks",
    "abstract": " Comments: Snir Vitrack Tamam and Raz Lapid contributed equally ",
    "url": "https://arxiv.org/abs/2211.14860",
    "authors": [
      "Snir Vitrack Tamam",
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.02234",
    "title": "Review of medical data analysis based on spiking neural networks",
    "abstract": " Title: Review of medical data analysis based on spiking neural networks ",
    "url": "https://arxiv.org/abs/2212.02234",
    "authors": [
      "X. Li",
      "X. Zhang",
      "X. Yi",
      "D. Liu",
      "H. Wang",
      "B. Zhang",
      "B. Zhang",
      "D. Zhao",
      "L. Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05124",
    "title": "Multi-view Graph Convolutional Networks with Differentiable Node  Selection",
    "abstract": " Title: Multi-view Graph Convolutional Networks with Differentiable Node  Selection ",
    "url": "https://arxiv.org/abs/2212.05124",
    "authors": [
      "Zhaoliang Chen",
      "Lele Fu",
      "Shunxin Xiao",
      "Shiping Wang",
      "Claudia Plant",
      "Wenzhong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.07462",
    "title": "Harmonic (Quantum) Neural Networks",
    "abstract": " Comments: 12 pages (main), 7 pages (supplementary), 7 figures ",
    "url": "https://arxiv.org/abs/2212.07462",
    "authors": [
      "Atiyo Ghosh",
      "Antonio A. Gentile",
      "Mario Dagrada",
      "Chul Lee",
      "Seong-Hyok Kim",
      "Hyukgeun Cha",
      "Yunjun Choi",
      "Brad Kim",
      "Jeong-Il Kye",
      "Vincent E. Elfving"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2301.06719",
    "title": "FemtoDet: An Object Detection Baseline for Energy Versus Performance  Tradeoffs",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2301.06719",
    "authors": [
      "Peng Tu",
      "Xu Xie",
      "Guo AI",
      "Yuexiang Li",
      "Yawen Huang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.08957",
    "title": "Slice Transformer and Self-supervised Learning for 6DoF Localization in  3D Point Cloud Maps",
    "abstract": " Comments: Accepted in IEEE International Conference on Robotics and Automation (ICRA), 2023 ",
    "url": "https://arxiv.org/abs/2301.08957",
    "authors": [
      "Muhammad Ibrahim",
      "Naveed Akhtar",
      "Saeed Anwar",
      "Michael Wise",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.12036",
    "title": "Analyzing Robustness of the Deep Reinforcement Learning Algorithm in  Ramp Metering Applications Considering False Data Injection Attack and  Defense",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2301.12036",
    "authors": [
      "Diyi Liu",
      "Lanmin Liu",
      "Lee D Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12292",
    "title": "Zero-shot causal learning",
    "abstract": " Title: Zero-shot causal learning ",
    "url": "https://arxiv.org/abs/2301.12292",
    "authors": [
      "Hamed Nilforoshan",
      "Michael Moor",
      "Yusuf Roohani",
      "Yining Chen",
      "Anja \u0160urina",
      "Michihiro Yasunaga",
      "Sara Oblak",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.03665",
    "title": "HumanMAC: Masked Motion Completion for Human Motion Prediction",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2302.03665",
    "authors": [
      "Ling-Hao Chen",
      "Jiawei Zhang",
      "Yewen Li",
      "Yiren Pang",
      "Xiaobo Xia",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.07753",
    "title": "From Prediction to Planning With Goal Conditioned Lane Graph Traversals",
    "abstract": " Title: From Prediction to Planning With Goal Conditioned Lane Graph Traversals ",
    "url": "https://arxiv.org/abs/2302.07753",
    "authors": [
      "Marcel Hallgarten",
      "Martin Stoll",
      "Andreas Zell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.09971",
    "title": "Social4Rec: Distilling User Preference from Social Graph for Video  Recommendation in Tencent",
    "abstract": " Title: Social4Rec: Distilling User Preference from Social Graph for Video  Recommendation in Tencent ",
    "url": "https://arxiv.org/abs/2302.09971",
    "authors": [
      "Xuanji Xiao",
      "Huaqiang Dai",
      "Qian Dong",
      "Shuzi Niu",
      "Yuzhen Liu",
      "Pei Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.11313",
    "title": "Time-varying Signals Recovery via Graph Neural Networks",
    "abstract": " Comments: Published in IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2023, Greece ",
    "url": "https://arxiv.org/abs/2302.11313",
    "authors": [
      "Jhon A. Castro-Correa",
      "Jhony H. Giraldo",
      "Anindya Mondal",
      "Mohsen Badiey",
      "Thierry Bouwmans",
      "Fragkiskos D. Malliaros"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.12537",
    "title": "Why Target Networks Stabilise Temporal Difference Methods",
    "abstract": " Comments: Found a small error in Appendix (Proposition 1, Appendix B3, penultimate line) that affects results presented in the original submission. These have been fixed and this version is the one accepted at ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.12537",
    "authors": [
      "Mattie Fellows",
      "Matthew J. A. Smith",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.13084",
    "title": "RemoteNet: Remote Sensing Image Segmentation Network based on  Global-Local Information",
    "abstract": " Title: RemoteNet: Remote Sensing Image Segmentation Network based on  Global-Local Information ",
    "url": "https://arxiv.org/abs/2302.13084",
    "authors": [
      "Satyawant Kumar",
      "Abhishek Kumar",
      "Dong-Gyu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.01464",
    "title": "Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using  Online Function Approximation",
    "abstract": " Title: Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using  Online Function Approximation ",
    "url": "https://arxiv.org/abs/2303.01464",
    "authors": [
      "Orin Levy",
      "Alon Cohen",
      "Asaf Cassel",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.01664",
    "title": "Miipher: A Robust Speech Restoration Model Integrating Self-Supervised  Speech and Text Representations",
    "abstract": " Comments: Accepted to WASPAA 2023 ",
    "url": "https://arxiv.org/abs/2303.01664",
    "authors": [
      "Yuma Koizumi",
      "Heiga Zen",
      "Shigeki Karita",
      "Yifan Ding",
      "Kohei Yatabe",
      "Nobuyuki Morioka",
      "Yu Zhang",
      "Wei Han",
      "Ankur Bapna",
      "Michiel Bacchiani"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.02813",
    "title": "Well-Connected Communities in Real-World and Synthetic Networks",
    "abstract": " Title: Well-Connected Communities in Real-World and Synthetic Networks ",
    "url": "https://arxiv.org/abs/2303.02813",
    "authors": [
      "Minhyuk Park",
      "Yasamin Tabatabaee",
      "Vikram Ramavarapu",
      "Baqiao Liu",
      "Vidya Kamath Pailodi",
      "Rajiv Ramachandran",
      "Dmitriy Korobskiy",
      "Fabio Ayres",
      "George Chacko",
      "Tandy Warnow"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2303.04980",
    "title": "Decision-BADGE: Decision-based Adversarial Batch Attack with Directional  Gradient Estimation",
    "abstract": " Comments: 9 pages (7 pages except for references), 4 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2303.04980",
    "authors": [
      "Geunhyeok Yu",
      "Minwoo Jeon",
      "Hyoseok Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05760",
    "title": "GameFormer: Game-theoretic Modeling and Learning of Transformer-based  Interactive Prediction and Planning for Autonomous Driving",
    "abstract": " Comments: 2023 IEEE/CVF International Conference on Computer Vision (ICCV) ",
    "url": "https://arxiv.org/abs/2303.05760",
    "authors": [
      "Zhiyu Huang",
      "Haochen Liu",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.12398",
    "title": "Multiscale Attention via Wavelet Neural Operators for Vision  Transformers",
    "abstract": " Title: Multiscale Attention via Wavelet Neural Operators for Vision  Transformers ",
    "url": "https://arxiv.org/abs/2303.12398",
    "authors": [
      "Anahita Nekoozadeh",
      "Mohammad Reza Ahmadzadeh",
      "Zahra Mardani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15421",
    "title": "ACAT: Adversarial Counterfactual Attention for Classification and  Detection in Medical Imaging",
    "abstract": " Comments: International Conference on Machine Learning 2023. 17 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2303.15421",
    "authors": [
      "Alessandro Fontanella",
      "Antreas Antoniou",
      "Wenwen Li",
      "Joanna Wardlaw",
      "Grant Mair",
      "Emanuele Trucco",
      "Amos Storkey"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16874",
    "title": "CheckerPose: Progressive Dense Keypoint Localization for Object Pose  Estimation with Graph Neural Network",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2303.16874",
    "authors": [
      "Ruyi Lian",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17900",
    "title": "Procedural Generation of Complex Roundabouts for Autonomous Vehicle  Testing",
    "abstract": " Comments: (6 Pages) Accepted at IEEE Intelligent Vehicles Symposium 2023 ",
    "url": "https://arxiv.org/abs/2303.17900",
    "authors": [
      "Zarif Ikram",
      "Golam Md Muktadir",
      "Jim Whitehead"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.18066",
    "title": "Finite Elements with Switch Detection for Direct Optimal Control of  Nonsmooth Systems with Set-Valued Step Functions",
    "abstract": " Comments: accepted for publication at the 62nd IEEE Conference on Decision and Control ",
    "url": "https://arxiv.org/abs/2303.18066",
    "authors": [
      "Armin Nurkanovi\u0107",
      "Jonathan Frey",
      "Anton Pozharskiy",
      "Moritz Diehl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.04512",
    "title": "Defense-Prefix for Preventing Typographic Attacks on CLIP",
    "abstract": " Comments: ICCV2023 Workshop ",
    "url": "https://arxiv.org/abs/2304.04512",
    "authors": [
      "Hiroki Azuma",
      "Yusuke Matsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12687",
    "title": "State-Dependent DMC with a Causal Helper",
    "abstract": " Comments: To appear in the IEEE Transactions on Information Theory ",
    "url": "https://arxiv.org/abs/2304.12687",
    "authors": [
      "Amos Lapidoth",
      "Ligong Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.01643",
    "title": "Neural LiDAR Fields for Novel View Synthesis",
    "abstract": " Comments: ICCV 2023 - camera ready. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2305.01643",
    "authors": [
      "Shengyu Huang",
      "Zan Gojcic",
      "Zian Wang",
      "Francis Williams",
      "Yoni Kasten",
      "Sanja Fidler",
      "Konrad Schindler",
      "Or Litany"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.03153",
    "title": "G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar  Tree Transformer",
    "abstract": " Title: G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar  Tree Transformer ",
    "url": "https://arxiv.org/abs/2305.03153",
    "authors": [
      "Kevin Zhang",
      "Vipul Mann",
      "Venkat Venkatasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Symbolic Computation (cs.SC)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.03308",
    "title": "Tiny-PPG: A Lightweight Deep Neural Network for Real-Time Detection of  Motion Artifacts in Photoplethysmogram Signals on Edge Devices",
    "abstract": " Title: Tiny-PPG: A Lightweight Deep Neural Network for Real-Time Detection of  Motion Artifacts in Photoplethysmogram Signals on Edge Devices ",
    "url": "https://arxiv.org/abs/2305.03308",
    "authors": [
      "Yali Zheng",
      "Chen Wu",
      "Peizheng Cai",
      "Zhiqiang Zhong",
      "Hongda Huang",
      "Yuqi Jiang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06599",
    "title": "Structured Chain-of-Thought Prompting for Code Generation",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2303.17780 ",
    "url": "https://arxiv.org/abs/2305.06599",
    "authors": [
      "Jia Allen Li",
      "Ge Li",
      "Yongmin Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.06715",
    "title": "Backpropagation-Free 4D Continuous Ant-Based Neural Topology Search",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2011.10831 ",
    "url": "https://arxiv.org/abs/2305.06715",
    "authors": [
      "AbdElRahman ElSaid",
      "Karl Ricanek",
      "Zeming Lyu",
      "Alexander Ororbia",
      "Travis Desell"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.10771",
    "title": "Seq-HGNN: Learning Sequential Node Representation on Heterogeneous Graph",
    "abstract": " Comments: SIGIR 2023 ",
    "url": "https://arxiv.org/abs/2305.10771",
    "authors": [
      "Chenguang Du",
      "Kaichun Yao",
      "Hengshu Zhu",
      "Deqing Wang",
      "Fuzhen Zhuang",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12622",
    "title": "Evaluating the Impact of Social Determinants on Health Prediction in the  Intensive Care Unit",
    "abstract": " Title: Evaluating the Impact of Social Determinants on Health Prediction in the  Intensive Care Unit ",
    "url": "https://arxiv.org/abs/2305.12622",
    "authors": [
      "Ming Ying Yang",
      "Gloria Hyunjung Kwak",
      "Tom Pollard",
      "Leo Anthony Celi",
      "Marzyeh Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.13924",
    "title": "Integrated Sensing and Communication based Outdoor Multi-Target  Detection, Tracking and Localization in Practical 5G Networks",
    "abstract": " Comments: Accepted by an open access journal (appearing on IEEEXplore soon) ",
    "url": "https://arxiv.org/abs/2305.13924",
    "authors": [
      "Ruiqi Liu",
      "Mengnan Jian",
      "Dawei Chen",
      "Xu Lin",
      "Yichao Cheng",
      "Wei Cheng",
      "Shijun Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2306.00709",
    "title": "Understanding the Social Context of Eating with Multimodal Smartphone  Sensing: The Role of Country Diversity",
    "abstract": " Comments: 25th ACM International Conference on Multimodal Interaction (ICMI) ",
    "url": "https://arxiv.org/abs/2306.00709",
    "authors": [
      "Nathan Kammoun",
      "Lakmal Meegahapola",
      "Daniel Gatica-Perez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2306.07946",
    "title": "STUDY: Socially Aware Temporally Causal Decoder Recommender Systems",
    "abstract": " Comments: 15 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2306.07946",
    "authors": [
      "Eltayeb Ahmed",
      "Diana Mincu",
      "Lauren Harrell",
      "Katherine Heller",
      "Subhrajit Roy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.10003",
    "title": "C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and  Generalizable Neural Surface Reconstruction",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2306.10003",
    "authors": [
      "Luoyuan Xu",
      "Tao Guan",
      "Yuesong Wang",
      "Wenkai Liu",
      "Zhaojie Zeng",
      "Junle Wang",
      "Wei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.11307",
    "title": "Transforming Graphs for Enhanced Attribute Clustering: An Innovative  Graph Transformer-Based Method",
    "abstract": " Title: Transforming Graphs for Enhanced Attribute Clustering: An Innovative  Graph Transformer-Based Method ",
    "url": "https://arxiv.org/abs/2306.11307",
    "authors": [
      "Shuo Han",
      "Jiacheng Liu",
      "Jiayun Wu",
      "Yinan Chen",
      "Li Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.13926",
    "title": "Graph Neural Networks Provably Benefit from Structural Information: A  Feature Learning Perspective",
    "abstract": " Comments: 33 pages, 7 figures. We have provided a clearer roadmap ",
    "url": "https://arxiv.org/abs/2306.13926",
    "authors": [
      "Wei Huang",
      "Yuan Cao",
      "Haonan Wang",
      "Xin Cao",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16741",
    "title": "Foundation Model for Endoscopy Video Analysis via Large-scale  Self-supervised Pre-train",
    "abstract": " Comments: MICCAI 2023 camera-ready version ",
    "url": "https://arxiv.org/abs/2306.16741",
    "authors": [
      "Zhao Wang",
      "Chang Liu",
      "Shaoting Zhang",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.00240",
    "title": "VesselMorph: Domain-Generalized Retinal Vessel Segmentation via  Shape-Aware Representation",
    "abstract": " Title: VesselMorph: Domain-Generalized Retinal Vessel Segmentation via  Shape-Aware Representation ",
    "url": "https://arxiv.org/abs/2307.00240",
    "authors": [
      "Dewei Hu",
      "Hao Li",
      "Han Liu",
      "Xing Yao",
      "Jiacheng Wang",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.01482",
    "title": "Nexus sine qua non: Essentially Connected Networks for Traffic  Forecasting",
    "abstract": " Title: Nexus sine qua non: Essentially Connected Networks for Traffic  Forecasting ",
    "url": "https://arxiv.org/abs/2307.01482",
    "authors": [
      "Tong Nie",
      "Guoyang Qin",
      "Lijun Sun",
      "Yunpeng Wang",
      "Jian Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07693",
    "title": "Neural Deformable Models for 3D Bi-Ventricular Heart Shape  Reconstruction and Modeling from 2D Sparse Cardiac Magnetic Resonance Imaging",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2307.07693",
    "authors": [
      "Meng Ye",
      "Dong Yang",
      "Mikael Kanski",
      "Leon Axel",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08492",
    "title": "SVDFormer: Complementing Point Cloud via Self-view Augmentation and  Self-structure Dual-generator",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2307.08492",
    "authors": [
      "Zhe Zhu",
      "Honghua Chen",
      "Xing He",
      "Weiming Wang",
      "Jing Qin",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08602",
    "title": "CaRT: Certified Safety and Robust Tracking in Learning-based Motion  Planning for Multi-Agent Systems",
    "abstract": " Comments: IEEE Conference on Decision and Control (CDC), Preprint Version, Accepted July, 2023 ",
    "url": "https://arxiv.org/abs/2307.08602",
    "authors": [
      "Hiroyasu Tsukamoto",
      "Benjamin Rivi\u00e8re",
      "Changrak Choi",
      "Amir Rahmani",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.11077",
    "title": "AlignDet: Aligning Pre-training and Fine-tuning in Object Detection",
    "abstract": " Comments: Camera Ready Version on ICCV 2023. Code and Models are publicly available. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2307.11077",
    "authors": [
      "Ming Li",
      "Jie Wu",
      "Xionghui Wang",
      "Chen Chen",
      "Jie Qin",
      "Xuefeng Xiao",
      "Rui Wang",
      "Min Zheng",
      "Xin Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12280",
    "title": "Downstream-agnostic Adversarial Examples",
    "abstract": " Comments: This paper has been accepted by the International Conference on Computer Vision (ICCV '23, October 2--6, 2023, Paris, France) ",
    "url": "https://arxiv.org/abs/2307.12280",
    "authors": [
      "Ziqi Zhou",
      "Shengshan Hu",
      "Ruizhi Zhao",
      "Qian Wang",
      "Leo Yu Zhang",
      "Junhui Hou",
      "Hai Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.16387",
    "title": "Relation-Oriented: Toward Knowledge-Aligned Causal AI",
    "abstract": " Title: Relation-Oriented: Toward Knowledge-Aligned Causal AI ",
    "url": "https://arxiv.org/abs/2307.16387",
    "authors": [
      "Jia Li",
      "Xiang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.16807",
    "title": "On the use of associative memory in Hopfield networks designed to solve  propositional satisfiability problems",
    "abstract": " Comments: 7 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2307.16807",
    "authors": [
      "Natalya Weber",
      "Werner Koch",
      "Ozan Erdem",
      "Tom Froese"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2308.01006",
    "title": "FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of  Autonomous Driving",
    "abstract": " Title: FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of  Autonomous Driving ",
    "url": "https://arxiv.org/abs/2308.01006",
    "authors": [
      "Tengju Ye",
      "Wei Jing",
      "Chunyong Hu",
      "Shikun Huang",
      "Lingping Gao",
      "Fangzhen Li",
      "Jingke Wang",
      "Ke Guo",
      "Wencong Xiao",
      "Weibo Mao",
      "Hang Zheng",
      "Kun Li",
      "Junbo Chen",
      "Kaicheng Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.01768",
    "title": "Multidimensional Data Analysis Based on Block Convolutional Tensor  Decomposition",
    "abstract": " Title: Multidimensional Data Analysis Based on Block Convolutional Tensor  Decomposition ",
    "url": "https://arxiv.org/abs/2308.01768",
    "authors": [
      "Mahdi Molavi",
      "Mansoor Rezghi",
      "Tayyebeh Saeedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01861",
    "title": "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on  Class-level Code Generation",
    "abstract": " Title: ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on  Class-level Code Generation ",
    "url": "https://arxiv.org/abs/2308.01861",
    "authors": [
      "Xueying Du",
      "Mingwei Liu",
      "Kaixin Wang",
      "Hanlin Wang",
      "Junwei Liu",
      "Yixuan Chen",
      "Jiayi Feng",
      "Chaofeng Sha",
      "Xin Peng",
      "Yiling Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.02293",
    "title": "A stochastic optimization approach to train non-linear neural networks  with a higher-order variation regularization",
    "abstract": " Comments: 13 pages, 24 figures ",
    "url": "https://arxiv.org/abs/2308.02293",
    "authors": [
      "Akifumi Okuno"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.02968",
    "title": "Robust estimation of exposure ratios in multi-exposure image stacks",
    "abstract": " Comments: 11 pages, 11 figures, journal ",
    "url": "https://arxiv.org/abs/2308.02968",
    "authors": [
      "Param Hanji",
      "Rafa\u0142 K. Mantiuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.03330",
    "title": "Expediting Neural Network Verification via Network Reduction",
    "abstract": " Title: Expediting Neural Network Verification via Network Reduction ",
    "url": "https://arxiv.org/abs/2308.03330",
    "authors": [
      "Yuyi Zhong",
      "Ruiwei Wang",
      "Siau-Cheng Khoo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.03669",
    "title": "Diffusion Model in Causal Inference with Unmeasured Confounders",
    "abstract": " Comments: 6 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2308.03669",
    "authors": [
      "Tatsuhiro Shimizu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.03900",
    "title": "Developability Approximation for Neural Implicits through Rank  Minimization",
    "abstract": " Title: Developability Approximation for Neural Implicits through Rank  Minimization ",
    "url": "https://arxiv.org/abs/2308.03900",
    "authors": [
      "Pratheba Selvaraju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.04714",
    "title": "A Computational Design Pipeline to Fabricate Sensing Network  Physicalizations",
    "abstract": " Comments: 11 pages, 8 figures; to be published in Proceedings of IEEE VIS 2023 ",
    "url": "https://arxiv.org/abs/2308.04714",
    "authors": [
      "S. Sandra Bae",
      "Takanori Fujiwara",
      "Anders Ynnerman",
      "Ellen Yi-Luen Do",
      "Michael L. Rivera",
      "Danielle Albers Szafir"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.04758",
    "title": "Bird's-Eye-View Scene Graph for Vision-Language Navigation",
    "abstract": " Comments: Accepted at ICCV 2023; Project page: this https URL ",
    "url": "https://arxiv.org/abs/2308.04758",
    "authors": [
      "Rui Liu",
      "Xiaohan Wang",
      "Wenguan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.04909",
    "title": "Adversarial Deep Reinforcement Learning for Cyber Security in Software  Defined Networks",
    "abstract": " Title: Adversarial Deep Reinforcement Learning for Cyber Security in Software  Defined Networks ",
    "url": "https://arxiv.org/abs/2308.04909",
    "authors": [
      "Luke Borchjes",
      "Clement Nyirenda",
      "Louise Leenen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05022",
    "title": "Feature Modulation Transformer: Cross-Refinement of Global  Representation via High-Frequency Prior for Image Super-Resolution",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2308.05022",
    "authors": [
      "Ao Li",
      "Le Zhang",
      "Yun Liu",
      "Ce Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.05034",
    "title": "Kairos: Practical Intrusion Detection and Investigation using  Whole-system Provenance",
    "abstract": " Comments: 23 pages, 16 figures, to appear in the 45th IEEE Symposium on Security and Privacy (S&P'24) ",
    "url": "https://arxiv.org/abs/2308.05034",
    "authors": [
      "Zijun Cheng",
      "Qiujian Lv",
      "Jinyuan Liang",
      "Yan Wang",
      "Degang Sun",
      "Thomas Pasquier",
      "Xueyuan Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05081",
    "title": "Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic  Role Labeling",
    "abstract": " Comments: Accepted by ACM MM 2023 ",
    "url": "https://arxiv.org/abs/2308.05081",
    "authors": [
      "Yu Zhao",
      "Hao Fei",
      "Yixin Cao",
      "Bobo Li",
      "Meishan Zhang",
      "Jianguo Wei",
      "Min Zhang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.05379",
    "title": "Beyond Semantics: Learning a Behavior Augmented Relevance Model with  Self-supervised Learning",
    "abstract": " Comments: Accepted by CIKM2023 ",
    "url": "https://arxiv.org/abs/2308.05379",
    "authors": [
      "Zeyuan Chen",
      "Wei Chen",
      "Jia Xu",
      "Zhongyi Liu",
      "Wei Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05508",
    "title": "Multi-domain Recommendation with Embedding Disentangling and Domain  Alignment",
    "abstract": " Comments: Accepted by CIKM'23 as a Long paper ",
    "url": "https://arxiv.org/abs/2308.05508",
    "authors": [
      "Wentao Ning",
      "Xiao Yan",
      "Weiwen Liu",
      "Reynold Cheng",
      "Rui Zhang",
      "Bo Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05707",
    "title": "Shadow Datasets, New challenging datasets for Causal Representation  Learning",
    "abstract": " Title: Shadow Datasets, New challenging datasets for Causal Representation  Learning ",
    "url": "https://arxiv.org/abs/2308.05707",
    "authors": [
      "Jiageng Zhu",
      "Hanchen Xie",
      "Jianhua Wu",
      "Jiazhi Li",
      "Mahyar Khayatkhoei",
      "Mohamed E. Hussein",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]