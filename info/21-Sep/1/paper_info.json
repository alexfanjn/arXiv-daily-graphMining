[
  {
    "id": "arXiv:2108.13621",
    "title": "Spike time displacement based error backpropagation in convolutional  spiking neural networks",
    "abstract": "We recently proposed the STiDi-BP algorithm, which avoids backward recursive gradient computation, for training multi-layer spiking neural networks (SNNs) with single-spike-based temporal coding. The algorithm employs a linear approximation to compute the derivative of the spike latency with respect to the membrane potential and it uses spiking neurons with piecewise linear postsynaptic potential to reduce the computational cost and the complexity of neural processing. In this paper, we extend the STiDi-BP algorithm to employ it in deeper and convolutional architectures. The evaluation results on the image classification task based on two popular benchmarks, MNIST and Fashion-MNIST datasets with the accuracies of respectively 99.2% and 92.8%, confirm that this algorithm has been applicable in deep SNNs. Another issue we consider is the reduction of memory storage and computational cost. To do so, we consider a convolutional SNN (CSNN) with two sets of weights: real-valued weights that are updated in the backward pass and their signs, binary weights, that are employed in the feedforward process. We evaluate the binary CSNN on two datasets of MNIST and Fashion-MNIST and obtain acceptable performance with a negligible accuracy drop with respect to real-valued weights (about $0.6%$ and $0.8%$ drops, respectively). ",
    "url": "https://arxiv.org/abs/2108.13621",
    "authors": [
      "Maryam Mirsadeghi",
      "Majid Shalchian",
      "Saeed Reza Kheradpisheh",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.13672",
    "title": "Medical SANSformers: Training self-supervised transformers without  attention for Electronic Medical Records",
    "abstract": "We leverage deep sequential models to tackle the problem of predicting healthcare utilization for patients, which could help governments to better allocate resources for future healthcare use. Specifically, we study the problem of \\textit{divergent subgroups}, wherein the outcome distribution in a smaller subset of the population considerably deviates from that of the general population. The traditional approach for building specialized models for divergent subgroups could be problematic if the size of the subgroup is very small (for example, rare diseases). To address this challenge, we first develop a novel attention-free sequential model, SANSformers, instilled with inductive biases suited for modeling clinical codes in electronic medical records. We then design a task-specific self-supervision objective and demonstrate its effectiveness, particularly in scarce data settings, by pre-training each model on the entire health registry (with close to one million patients) before fine-tuning for downstream tasks on the divergent subgroups. We compare the novel SANSformer architecture with the LSTM and Transformer models using two data sources and a multi-task learning objective that aids healthcare utilization prediction. Empirically, the attention-free SANSformer models perform consistently well across experiments, outperforming the baselines in most cases by at least $\\sim 10$\\%. Furthermore, the self-supervised pre-training boosts performance significantly throughout, for example by over $\\sim 50$\\% (and as high as $800$\\%) on $R^2$ score when predicting the number of hospital visits. ",
    "url": "https://arxiv.org/abs/2108.13672",
    "authors": [
      "Yogesh Kumar",
      "Alexander Ilin",
      "Henri Salo",
      "Sangita Kulathinal",
      "Maarit K. Leinonen",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.13689",
    "title": "An asymptotic-preserving discretization scheme for gas transport in pipe  networks",
    "abstract": "We consider the simulation of barotropic flow of gas in long pipes and pipe networks. Based on a Hamiltonian reformulation of the governing system, a fully discrete approximation scheme is proposed using mixed finite elements in space and an implicit Euler method in time. Assuming the existence of a smooth subsonic solution bounded away from vacuum, a full convergence analysis is presented based on relative energy estimates. Particular attention is paid to establishing error bounds that are uniform in the friction parameter. As a consequence, the method and results also cover the parabolic problem arising in the asymptotic large friction limit. The error estimates are derived in detail for a single pipe, but using appropriate coupling conditions and the particular structure of the problem and its discretization, the main results directly generalize to pipe networks. Numerical tests are presented for illustration. ",
    "url": "https://arxiv.org/abs/2108.13689",
    "authors": [
      "H. Egger",
      "J. Giesselmann",
      "T. Kunkel",
      "N. Philippi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2108.13800",
    "title": "Network psychometrics and cognitive network science open new ways for  detecting, understanding and tackling the complexity of math anxiety: A  review",
    "abstract": "Math anxiety is a clinical pathology impairing cognitive processing in math-related contexts. Originally thought to affect only inexperienced, low-achieving students, recent investigations show how math anxiety is vastly diffused even among high-performing learners. This review of data-informed studies outlines math anxiety as a complex system that: (i) cripples well-being, self-confidence and information processing on both conscious and subconscious levels, (ii) can be transmitted by social interactions, like a pathogen, and worsened by distorted perceptions, (iii) affects roughly 20% of students in 63 out of 64 worldwide educational systems but correlates weakly with academic performance, and (iv) poses a concrete threat to students' well-being, computational literacy and career prospects in science. These patterns underline the crucial need to go beyond performance for estimating math anxiety. Recent advances with network psychometrics and cognitive network science provide ideal frameworks for detecting, interpreting and intervening upon such clinical condition. Merging education research, psychology and data science, the approaches reviewed here reconstruct psychological constructs as complex systems, represented either as multivariate correlation models (e.g. graph exploratory analysis) or as cognitive networks of semantic/emotional associations (e.g. free association networks or forma mentis networks). Not only can these interconnected networks detect otherwise hidden levels of math anxiety but - more crucially - they can unveil the specific layout of interacting factors, e.g. key sources and targets, behind math anxiety in a given cohort. As discussed here, these network approaches open concrete ways for unveiling students' perceptions, emotions and mental well-being, and can enable future powerful data-informed interventions untangling math anxiety. ",
    "url": "https://arxiv.org/abs/2108.13800",
    "authors": [
      "Massimo Stella"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "History and Overview (math.HO)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2108.13898",
    "title": "The emojification of sentiment on social media: Collection and analysis  of a longitudinal Twitter sentiment dataset",
    "abstract": "Social media, as a means for computer-mediated communication, has been extensively used to study the sentiment expressed by users around events or topics. There is however a gap in the longitudinal study of how sentiment evolved in social media over the years. To fill this gap, we develop TM-Senti, a new large-scale, distantly supervised Twitter sentiment dataset with over 184 million tweets and covering a time period of over seven years. We describe and assess our methodology to put together a large-scale, emoticon- and emoji-based labelled sentiment analysis dataset, along with an analysis of the resulting dataset. Our analysis highlights interesting temporal changes, among others in the increasing use of emojis over emoticons. We publicly release the dataset for further research in tasks including sentiment analysis and text classification of tweets. The dataset can be fully rehydrated including tweet metadata and without missing tweets thanks to the archive of tweets publicly available on the Internet Archive, which the dataset is based on. ",
    "url": "https://arxiv.org/abs/2108.13898",
    "authors": [
      "Wenjie Yin",
      "Rabab Alkhalifa",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2108.13910",
    "title": "A manifold learning perspective on representation learning: Learning  decoder and representations without an encoder",
    "abstract": "Autoencoders are commonly used in representation learning. They consist of an encoder and a decoder, which provide a straightforward way to map $n$-dimensional data in input space to a lower $m$-dimensional representation space and back. The decoder itself defines an $m$-dimensional manifold in input space. Inspired by manifold learning, we show that the decoder can be trained on its own by learning the representations of the training samples along with the decoder weights using gradient descent. A sum-of-squares loss then corresponds to optimizing the manifold to have the smallest Euclidean distance to the training samples, and similarly for other loss functions. We derive expressions for the number of samples needed to specify the encoder and decoder and show that the decoder generally requires much less training samples to be well-specified compared to the encoder. We discuss training of autoencoders in this perspective and relate to previous work in the field that use noisy training examples and other types of regularization. On the natural image data sets MNIST and CIFAR10, we demonstrate that the decoder is much better suited to learn a low-dimensional representation, especially when trained on small data sets. Using simulated gene regulatory data, we further show that the decoder alone leads to better generalization and meaningful representations. Our approach of training the decoder alone facilitates representation learning even on small data sets and can lead to improved training of autoencoders. We hope that the simple analyses presented will also contribute to an improved conceptual understanding of representation learning. ",
    "url": "https://arxiv.org/abs/2108.13910",
    "authors": [
      "Viktoria Schuster",
      "Anders Krogh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.13939",
    "title": "ScatSimCLR: self-supervised contrastive learning with pretext task  regularization for small-scale datasets",
    "abstract": "In this paper, we consider a problem of self-supervised learning for small-scale datasets based on contrastive loss between multiple views of the data, which demonstrates the state-of-the-art performance in classification task. Despite the reported results, such factors as the complexity of training requiring complex architectures, the needed number of views produced by data augmentation, and their impact on the classification accuracy are understudied problems. To establish the role of these factors, we consider an architecture of contrastive loss system such as SimCLR, where baseline model is replaced by geometrically invariant \"hand-crafted\" network ScatNet with small trainable adapter network and argue that the number of parameters of the whole system and the number of views can be considerably reduced while practically preserving the same classification accuracy. In addition, we investigate the impact of regularization strategies using pretext task learning based on an estimation of parameters of augmentation transform such as rotation and jigsaw permutation for both traditional baseline models and ScatNet based models. Finally, we demonstrate that the proposed architecture with pretext task learning regularization achieves the state-of-the-art classification performance with a smaller number of trainable parameters and with reduced number of views. ",
    "url": "https://arxiv.org/abs/2108.13939",
    "authors": [
      "Vitaliy Kinakh",
      "Olga Taran",
      "Svyatoslav Voloshynovskiy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.13941",
    "title": "Bubblewrap: Online tiling and real-time flow prediction on neural  manifolds",
    "abstract": "While most classic studies of function in experimental neuroscience have focused on the coding properties of individual neurons, recent developments in recording technologies have resulted in an increasing emphasis on the dynamics of neural populations. This has given rise to a wide variety of models for analyzing population activity in relation to experimental variables, but direct testing of many neural population hypotheses requires intervening in the system based on current neural state, necessitating models capable of inferring neural state online. Existing approaches, primarily based on dynamical systems, require strong parametric assumptions that are easily violated in the noise-dominated regime and do not scale well to the thousands of data channels in modern experiments. To address this problem, we propose a method that combines fast, stable dimensionality reduction with a soft tiling of the resulting neural manifold, allowing dynamics to be approximated as a probability flow between tiles. This method can be fit efficiently using online expectation maximization, scales to tens of thousands of tiles, and outperforms existing methods when dynamics are noise-dominated or feature multi-modal transition probabilities. The resulting model can be trained at kiloHertz data rates, produces accurate approximations of neural dynamics within minutes, and generates predictions on submillisecond time scales. It retains predictive performance throughout many time steps into the future and is fast enough to serve as a component of closed-loop causal experiments. ",
    "url": "https://arxiv.org/abs/2108.13941",
    "authors": [
      "Anne Draelos",
      "Pranjal Gupta",
      "Na Young Jun",
      "Chaichontat Sriworarat",
      "John Pearson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.13975",
    "title": "Extrapolated DIscontinuity Tracking for complex 2D shock interactions",
    "abstract": "A new shock-tracking technique that avoids re-meshing the computational grid around the moving shock-front was recently proposed by the authors [1]. This paper describes further algorithmic improvements which make the extrapolated Discontinuity Tracking Technique (eDIT) capable of dealing with complex shock-topologies featuring shock-shock and shock-wall interactions. Various test-cases are included to describe the key features of the methodology and prove its order-of-convergence properties. ",
    "url": "https://arxiv.org/abs/2108.13975",
    "authors": [
      "Mirco Ciallella",
      "Mario Ricchiuto",
      "Renato Paciorri",
      "Aldo Bonfiglioli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2108.13989",
    "title": "DeepTaskAPT: Insider APT detection using Task-tree based Deep Learning",
    "abstract": "APT, known as Advanced Persistent Threat, is a difficult challenge for cyber defence. These threats make many traditional defences ineffective as the vulnerabilities exploited by these threats are insiders who have access to and are within the network. This paper proposes DeepTaskAPT, a heterogeneous task-tree based deep learning method to construct a baseline model based on sequences of tasks using a Long Short-Term Memory (LSTM) neural network that can be applied across different users to identify anomalous behaviour. Rather than applying the model to sequential log entries directly, as most current approaches do, DeepTaskAPT applies a process tree based task generation method to generate sequential log entries for the deep learning model. To assess the performance of DeepTaskAPT, we use a recently released synthetic dataset, DARPA Operationally Transparent Computing (OpTC) dataset and a real-world dataset, Los Alamos National Laboratory (LANL) dataset. Both of them are composed of host-based data collected from sensors. Our results show that DeepTaskAPT outperforms similar approaches e.g. DeepLog and the DeepTaskAPT baseline model demonstrate its capability to detect malicious traces in various attack scenarios while having high accuracy and low false-positive rates. To the best of knowledge this is the very first attempt of using recently introduced OpTC dataset for cyber threat detection. ",
    "url": "https://arxiv.org/abs/2108.13989",
    "authors": [
      "Mohammad Mamun",
      "Kevin Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.13414",
    "title": "Astrocytes mediate analogous memory in a multi-layer neuron-astrocytic  network",
    "abstract": "Modeling the neuronal processes underlying short-term working memory remains the focus of many theoretical studies in neuroscience. Here we propose a mathematical model of spiking neuron network (SNN) demonstrating how a piece of information can be maintained as a robust activity pattern for several seconds then completely disappear if no other stimuli come. Such short-term memory traces are preserved due to the activation of astrocytes accompanying the SNN. The astrocytes exhibit calcium transients at a time scale of seconds. These transients further modulate the efficiency of synaptic transmission and, hence, the firing rate of neighboring neurons at diverse timescales through gliotransmitter release. We show how such transients continuously encode frequencies of neuronal discharges and provide robust short-term storage of analogous information. This kind of short-term memory can keep operative information for seconds, then completely forget it to avoid overlapping with forthcoming patterns. The SNN is inter-connected with the astrocytic layer by local inter-cellular diffusive connections. The astrocytes are activated only when the neighboring neurons fire quite synchronously, e.g. when an information pattern is loaded. For illustration, we took greyscale photos of people's faces where the grey level encoded the level of applied current stimulating the neurons. The astrocyte feedback modulates (facilitates) synaptic transmission by varying the frequency of neuronal firing. We show how arbitrary patterns can be loaded, then stored for a certain interval of time, and retrieved if the appropriate clue pattern is applied to the input. ",
    "url": "https://arxiv.org/abs/2108.13414",
    "authors": [
      "Yuliya Tsybina",
      "Innokentiy Kastalskiy",
      "Mikhail Krivonosov",
      "Alexey Zaikin",
      "Victor Kazantsev",
      "Alexander Gorban",
      "Susanna Gordleeva"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.13844",
    "title": "Fiducial marker recovery and detection from severely truncated data in  navigation assisted spine surgery",
    "abstract": "Fiducial markers are commonly used in navigation assisted minimally invasive spine surgery (MISS) and they help transfer image coordinates into real world coordinates. In practice, these markers might be located outside the field-of-view (FOV), due to the limited detector sizes of C-arm cone-beam computed tomography (CBCT) systems used in intraoperative surgeries. As a consequence, reconstructed markers in CBCT volumes suffer from artifacts and have distorted shapes, which sets an obstacle for navigation. In this work, we propose two fiducial marker detection methods: direct detection from distorted markers (direct method) and detection after marker recovery (recovery method). For direct detection from distorted markers in reconstructed volumes, an efficient automatic marker detection method using two neural networks and a conventional circle detection algorithm is proposed. For marker recovery, a task-specific learning strategy is proposed to recover markers from severely truncated data. Afterwards, a conventional marker detection algorithm is applied for position detection. The two methods are evaluated on simulated data and real data, both achieving a marker registration error smaller than 0.2 mm. Our experiments demonstrate that the direct method is capable of detecting distorted markers accurately and the recovery method with task-specific learning has high robustness and generalizability on various data sets. In addition, the task-specific learning is able to reconstruct other structures of interest accurately, e.g. ribs for image-guided needle biopsy, from severely truncated data, which empowers CBCT systems with new potential applications. ",
    "url": "https://arxiv.org/abs/2108.13844",
    "authors": [
      "Fuxin Fan",
      "Bj\u00f6rn Kreher",
      "Holger Keil",
      "Maier Andreas",
      "Yixing Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.13914",
    "title": "On the interpretation of black-box default prediction models: an Italian  Small and Medium Enterprises case",
    "abstract": "Academic research and the financial industry have recently paid great attention to Machine Learning algorithms due to their power to solve complex learning tasks. In the field of firms' default prediction, however, the lack of interpretability has prevented the extensive adoption of the black-box type of models. To overcome this drawback and maintain the high performances of black-boxes, this paper relies on a model-agnostic approach. Accumulated Local Effects and Shapley values are used to shape the predictors' impact on the likelihood of default and rank them according to their contribution to the model outcome. Prediction is achieved by two Machine Learning algorithms (eXtreme Gradient Boosting and FeedForward Neural Network) compared with three standard discriminant models. Results show that our analysis of the Italian Small and Medium Enterprises manufacturing industry benefits from the overall highest classification power by the eXtreme Gradient Boosting algorithm without giving up a rich interpretation framework. ",
    "url": "https://arxiv.org/abs/2108.13914",
    "authors": [
      "Lisa Crosato",
      "Caterina Liberati",
      "Marco Repetto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2102.06408",
    "title": "Supervised training of spiking neural networks for robust deployment on  mixed-signal neuromorphic processors",
    "abstract": " Title: Supervised training of spiking neural networks for robust deployment on  mixed-signal neuromorphic processors ",
    "url": "https://arxiv.org/abs/2102.06408",
    "authors": [
      "Julian B\u00fcchel",
      "Dmitrii Zendrikov",
      "Sergio Solinas",
      "Giacomo Indiveri",
      "Dylan R. Muir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.06810",
    "title": "Understanding self-supervised Learning Dynamics without Contrastive  Pairs",
    "abstract": " Comments: ICML 2021 camera ready + Fix minor typo in Fig. 4 ",
    "url": "https://arxiv.org/abs/2102.06810",
    "authors": [
      "Yuandong Tian",
      "Xinlei Chen",
      "Surya Ganguli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.07402",
    "title": "Is cell ratio important in deep learning? A robust comparison of deep  learning methods for multi-scale cytopathology cell image classification:  from convolutional neural networks to visual transformers",
    "abstract": " Title: Is cell ratio important in deep learning? A robust comparison of deep  learning methods for multi-scale cytopathology cell image classification:  from convolutional neural networks to visual transformers ",
    "url": "https://arxiv.org/abs/2105.07402",
    "authors": [
      "Wanli Liu",
      "Chen Li",
      "Md Mamunur Rahamana",
      "Hongzan Sun",
      "Weiming Hu",
      "Haoyuan Chen",
      "Changhao Sun",
      "Yudong Yao",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.09040",
    "title": "Advances in integration of end-to-end neural and clustering-based  diarization for real conversational speech",
    "abstract": " Comments: 5 pages, 1 figure, Interspeech2021. (Update to include a reference to the code) ",
    "url": "https://arxiv.org/abs/2105.09040",
    "authors": [
      "Keisuke Kinoshita",
      "Marc Delcroix",
      "Naohiro Tawara"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2106.10912",
    "title": "Certifying a probabilistic parallel modular algorithm for rational  univariate representation",
    "abstract": " Title: Certifying a probabilistic parallel modular algorithm for rational  univariate representation ",
    "url": "https://arxiv.org/abs/2106.10912",
    "authors": [
      "Bernard Parisse"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2107.06941",
    "title": "Mutually improved endoscopic image synthesis and landmark detection in  unpaired image-to-image translation",
    "abstract": " Comments: Accepted for IEEE JBHI 2021, 13 pages, 8 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2107.06941",
    "authors": [
      "Lalith Sharan",
      "Gabriele Romano",
      "Sven Koehler",
      "Halvar Kelm",
      "Matthias Karck",
      "Raffaele De Simone",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]