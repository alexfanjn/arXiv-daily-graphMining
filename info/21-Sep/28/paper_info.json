[
  {
    "id": "arXiv:2109.12249",
    "title": "A general alternating-direction implicit framework with Gaussian process  regression parameter prediction for large sparse linear systems",
    "abstract": "This paper proposes an efficient general alternating-direction implicit (GADI) framework for solving large sparse linear systems. The convergence property of the GADI framework is discussed. Most of the existing ADI methods can be viewed as particular schemes of the developed framework. Meanwhile the GADI framework can derive new ADI methods. Moreover, as the algorithm efficiency is sensitive to the splitting parameters, we offer a data-driven approach, the Gaussian process regression (GPR) method based on the Bayesian inference, to predict the GADI framework's relatively optimal parameters. The GPR method requires a small training data set to learn the regression prediction mapping, which has sufficient accuracy and high generalization capability. It allows us to efficiently solve linear systems with a one-shot computation, and does not require any repeated computations to obtain relatively optimal splitting parameters. Finally, we use the three-dimensional convection-diffusion equation and continuous Sylvester matrix equation to examine the performance of our proposed methods. Numerical results demonstrate that the proposed framework is faster tens to thousands of times than the existing ADI methods, such as (inexact) Hermitian and skew-Hermitian splitting type methods in which the consumption of obtaining relatively optimal splitting parameters is ignored. Due to the efficiency of the developed methods, we can solve much larger linear systems which these existing ADI methods have been not reached. ",
    "url": "https://arxiv.org/abs/2109.12249",
    "authors": [
      "Kai Jiang",
      "Xuehong Su",
      "Juan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.12308",
    "title": "Brian2Loihi: An emulator for the neuromorphic chip Loihi using the  spiking neural network simulator Brian",
    "abstract": "Developing intelligent neuromorphic solutions remains a challenging endeavour. It requires a solid conceptual understanding of the hardware's fundamental building blocks. Beyond this, accessible and user-friendly prototyping is crucial to speed up the design pipeline. We developed an open source Loihi emulator based on the neural network simulator Brian that can easily be incorporated into existing simulation workflows. We demonstrate errorless Loihi emulation in software for a single neuron and for a recurrently connected spiking neural network. On-chip learning is also reviewed and implemented, with reasonable discrepancy due to stochastic rounding. This work provides a coherent presentation of Loihi's computational unit and introduces a new, easy-to-use Loihi prototyping package with the aim to help streamline conceptualisation and deployment of new algorithms. ",
    "url": "https://arxiv.org/abs/2109.12308",
    "authors": [
      "Carlo Michaelis",
      "Andrew B. Lehr",
      "Winfried Oed",
      "Christian Tetzlaff"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2109.12393",
    "title": "Sorting through the noise: Testing robustness of information processing  in pre-trained language models",
    "abstract": "Pre-trained LMs have shown impressive performance on downstream NLP tasks, but we have yet to establish a clear understanding of their sophistication when it comes to processing, retaining, and applying information presented in their input. In this paper we tackle a component of this question by examining robustness of models' ability to deploy relevant context information in the face of distracting content. We present models with cloze tasks requiring use of critical context information, and introduce distracting content to test how robustly the models retain and use that critical information for prediction. We also systematically manipulate the nature of these distractors, to shed light on dynamics of models' use of contextual cues. We find that although models appear in simple contexts to make predictions based on understanding and applying relevant facts from prior context, the presence of distracting but irrelevant content has clear impact in confusing model predictions. In particular, models appear particularly susceptible to factors of semantic similarity and word position. The findings are consistent with the conclusion that LM predictions are driven in large part by superficial contextual cues, rather than by robust representations of context meaning. ",
    "url": "https://arxiv.org/abs/2109.12393",
    "authors": [
      "Lalchand Pandia",
      "Allyson Ettinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.12418",
    "title": "Comb-based photonic neural population for parallel and nonlinear  processing",
    "abstract": "It is believed that neural information representation and processing relies on the neural population instead of a single neuron. In neuromorphic photonics, photonic neurons in the form of nonlinear responses have been extensively studied in single devices and temporal nodes. However, to construct a photonic neural population (PNP), the process of scaling up and massive interconnections remain challenging considering the physical complexity and response latency. Here, we propose a comb-based PNP interconnected by carrier coupling with superior scalability. Two unique properties of neural population are theoretically and experimentally demonstrated in the comb-based PNP, including nonlinear response curves and population activities coding. A classification task of three input patterns with dual radio-frequency (RF) tones is successfully implemented in a real-time manner, which manifests the comb-based PNP can make effective use of the ultra-broad bandwidth of photonics for parallel and nonlinear processing. ",
    "url": "https://arxiv.org/abs/2109.12418",
    "authors": [
      "Bowen Ma",
      "Junfeng Zhang",
      "Weiwen Zou"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2109.12441",
    "title": "Accelerated consensus in multi-agent networks via memory of local  averages",
    "abstract": "Classical mathematical models of information sharing and updating in multi-agent networks use linear operators. In the paradigmatic DeGroot model, agents update their states with linear combinations of their neighbors' current states. In prior work, an accelerated averaging model employing the use of memory has been suggested to accelerate convergence to a consensus state for undirected networks. There, the DeGroot update on the current states is followed by a linear combination with the previous states. We propose a modification where the DeGroot update is applied to the current and previous states and is then followed by a linear combination step. We show that this simple modification applied to undirected networks permits convergence even for periodic networks. Further, it allows for faster convergence than the DeGroot and accelerated averaging models for suitable networks and model parameters. ",
    "url": "https://arxiv.org/abs/2109.12441",
    "authors": [
      "Aditya Bhaskar",
      "Shriya Rangarajan",
      "Vikram Shree",
      "Mark Campbell",
      "Francesca Parise"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.12513",
    "title": "Generalized multiscale feature extraction for remaining useful life  prediction of bearings with generative adversarial networks",
    "abstract": "Bearing is a key component in industrial machinery and its failure may lead to unwanted downtime and economic loss. Hence, it is necessary to predict the remaining useful life (RUL) of bearings. Conventional data-driven approaches of RUL prediction require expert domain knowledge for manual feature extraction and may suffer from data distribution discrepancy between training and test data. In this study, we propose a novel generalized multiscale feature extraction method with generative adversarial networks. The adversarial training learns the distribution of training data from different bearings and is introduced for health stage division and RUL prediction. To capture the sequence feature from a one-dimensional vibration signal, we adapt a U-Net architecture that reconstructs features to process them with multiscale layers in the generator of the adversarial network. To validate the proposed method, comprehensive experiments on two rotating machinery datasets have been conducted to predict the RUL. The experimental results show that the proposed feature extraction method can effectively predict the RUL and outperforms the conventional RUL prediction approaches based on deep neural networks. The implementation code is available at https://github.com/opensuh/GMFE. ",
    "url": "https://arxiv.org/abs/2109.12513",
    "authors": [
      "Sungho Suh",
      "Paul Lukowicz",
      "Yong Oh Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12692",
    "title": "Equilibria and learning dynamics in mixed network  coordination/anti-coordination games",
    "abstract": "Whilst network coordination games and network anti-coordination games have received a considerable amount of attention in the literature, network games with coexisting coordinating and anti-coordinating players are known to exhibit more complex behaviors. In fact, depending on the network structure, such games may even fail to have pure-strategy Nash equilibria. An example is represented by the well-known matching pennies (discoordination) game. In this work, we first provide graph-theoretic conditions for the existence of pure-strategy Nash equilibria in mixed network coordination/anti-coordination games of arbitrary size. For the case where such conditions are met, we then study the asymptotic behavior of best-response dynamics and provide sufficient conditions for finite-time convergence to the set of Nash equilibria. Our results build on an extension and refinement of the notion of network cohesiveness and on the formulation of the new concept of network indecomposibility. ",
    "url": "https://arxiv.org/abs/2109.12692",
    "authors": [
      "Laura Arditti",
      "Giacomo Como",
      "Fabio Fagnani",
      "Martina Vanelli"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2109.12694",
    "title": "VP-GO: a \"light\" action-conditioned visual prediction model",
    "abstract": "Visual prediction models are a promising solution for visual-based robotic grasping of cluttered, unknown soft objects. Previous models from the literature are computationally greedy, which limits reproducibility; although some consider stochasticity in the prediction model, it is often too weak to catch the reality of robotics experiments involving grasping such objects. Furthermore, previous work focused on elementary movements that are not efficient to reason in terms of more complex semantic actions. To address these limitations, we propose VP-GO, a ``light'' stochastic action-conditioned visual prediction model. We propose a hierarchical decomposition of semantic grasping and manipulation actions into elementary end-effector movements, to ensure compatibility with existing models and datasets for visual prediction of robotic actions such as RoboNet. We also record and release a new open dataset for visual prediction of object grasping, called PandaGrasp. Our model can be pre-trained on RoboNet and fine-tuned on PandaGrasp, and performs similarly to more complex models in terms of signal prediction metrics. Qualitatively, it outperforms when predicting the outcome of complex grasps performed by our robot. ",
    "url": "https://arxiv.org/abs/2109.12694",
    "authors": [
      "Anji Ma",
      "Yoann Fleytoux",
      "Jean-Bapstiste Mouret",
      "Serena Ivaldi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.12724",
    "title": "Research on facial expression recognition based on Multimodal data  fusion and neural network",
    "abstract": "Facial expression recognition is a challenging task when neural network is applied to pattern recognition. Most of the current recognition research is based on single source facial data, which generally has the disadvantages of low accuracy and low robustness. In this paper, a neural network algorithm of facial expression recognition based on multimodal data fusion is proposed. The algorithm is based on the multimodal data, and it takes the facial image, the histogram of oriented gradient of the image and the facial landmarks as the input, and establishes CNN, LNN and HNN three sub neural networks to extract data features, using multimodal data feature fusion mechanism to improve the accuracy of facial expression recognition. Experimental results show that, benefiting by the complementarity of multimodal data, the algorithm has a great improvement in accuracy, robustness and detection speed compared with the traditional facial expression recognition algorithm. Especially in the case of partial occlusion, illumination and head posture transformation, the algorithm also shows a high confidence. ",
    "url": "https://arxiv.org/abs/2109.12724",
    "authors": [
      "Yi Han",
      "Xubin Wang",
      "Zhengyu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.12756",
    "title": "A novel network training approach for open set image recognition",
    "abstract": "Convolutional Neural Networks (CNNs) are commonly designed for closed set arrangements, where test instances only belong to some \"Known Known\" (KK) classes used in training. As such, they predict a class label for a test sample based on the distribution of the KK classes. However, when used under the Open Set Recognition (OSR) setup (where an input may belong to an \"Unknown Unknown\" or UU class), such a network will always classify a test instance as one of the KK classes even if it is from a UU class. As a solution, recently, data augmentation based on Generative Adversarial Networks(GAN) has been used. In this work, we propose a novel approach for mining a \"Known UnknownTrainer\" or KUT set and design a deep OSR Network (OSRNet) to harness this dataset. The goal isto teach OSRNet the essence of the UUs through KUT set, which is effectively a collection of mined \"hard Known Unknown negatives\". Once trained, OSRNet can detect the UUs while maintaining high classification accuracy on KKs. We evaluate OSRNet on six benchmark datasets and demonstrate it outperforms contemporary OSR methods. ",
    "url": "https://arxiv.org/abs/2109.12756",
    "authors": [
      "Md Tahmid Hossaina",
      "Shyh Wei Teng",
      "Guojun Lu",
      "Ferdous Sohel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12813",
    "title": "An optimised deep spiking neural network architecture without gradients",
    "abstract": "We present an end-to-end trainable modular event-driven neural architecture that uses local synaptic and threshold adaptation rules to perform transformations between arbitrary spatio-temporal spike patterns. The architecture represents a highly abstracted model of existing Spiking Neural Network (SNN) architectures. The proposed Optimized Deep Event-driven Spiking neural network Architecture (ODESA) can simultaneously learn hierarchical spatio-temporal features at multiple arbitrary time scales. ODESA performs online learning without the use of error back-propagation or the calculation of gradients. Through the use of simple local adaptive selection thresholds at each node, the network rapidly learns to appropriately allocate its neuronal resources at each layer for any given problem without using a real-valued error measure. These adaptive selection thresholds are the central feature of ODESA, ensuring network stability and remarkable robustness to noise as well as to the selection of initial system parameters. Network activations are inherently sparse due to a hard Winner-Take-All (WTA) constraint at each layer. We evaluate the architecture on existing spatio-temporal datasets, including the spike-encoded IRIS and TIDIGITS datasets, as well as a novel set of tasks based on International Morse Code that we created. These tests demonstrate the hierarchical spatio-temporal learning capabilities of ODESA. Through these tests, we demonstrate ODESA can optimally solve practical and highly challenging hierarchical spatio-temporal learning tasks with the minimum possible number of computing nodes. ",
    "url": "https://arxiv.org/abs/2109.12813",
    "authors": [
      "Yeshwanth Bethi",
      "Ying Xu",
      "Gregory Cohen",
      "Andre van Schaik",
      "Saeed Afshar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12855",
    "title": "Routing brain traffic through the von Neumann bottleneck: Efficient  cache usage in spiking neural network simulation code on general purpose  computers",
    "abstract": "Simulation is a third pillar next to experiment and theory in the study of complex dynamic systems such as biological neural networks. Contemporary brain-scale networks correspond to directed graphs of a few million nodes, each with an in-degree and out-degree of several thousands of edges, where nodes and edges correspond to the fundamental biological units, neurons and synapses, respectively. When considering a random graph, each node's edges are distributed across thousands of parallel processes. The activity in neuronal networks is also sparse. Each neuron occasionally transmits a brief signal, called spike, via its outgoing synapses to the corresponding target neurons. This spatial and temporal sparsity represents an inherent bottleneck for simulations on conventional computers: Fundamentally irregular memory-access patterns cause poor cache utilization. Using an established neuronal network simulation code as a reference implementation, we investigate how common techniques to recover cache performance such as software-induced prefetching and software pipelining can benefit a real-world application. The algorithmic changes reduce simulation time by up to 50%. The study exemplifies that many-core systems assigned with an intrinsically parallel computational problem can overcome the von Neumann bottleneck of conventional computer architectures. ",
    "url": "https://arxiv.org/abs/2109.12855",
    "authors": [
      "Jari Pronold",
      "Jakob Jordan",
      "Brian J. N. Wylie",
      "Itaru Kitayama",
      "Markus Diesmann",
      "Susanne Kunkel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2109.12985",
    "title": "Synerise at RecSys 2021: Twitter user engagement prediction with a fast  neural model",
    "abstract": "In this paper we present our 2nd place solution to ACM RecSys 2021 Challenge organized by Twitter. The challenge aims to predict user engagement for a set of tweets, offering an exceptionally large data set of 1 billion data points sampled from over four weeks of real Twitter interactions. Each data point contains multiple sources of information, such as tweet text along with engagement features, user features, and tweet features. The challenge brings the problem close to a real production environment by introducing strict latency constraints in the model evaluation phase: the average inference time for single tweet engagement prediction is limited to 6ms on a single CPU core with 64GB memory. Our proposed model relies on extensive feature engineering performed with methods such as the Efficient Manifold Density Estimator (EMDE) - our previously introduced algorithm based on Locality Sensitive Hashing method, and novel Fourier Feature Encoding, among others. In total, we create numerous features describing a user's Twitter account status and the content of a tweet. In order to adhere to the strict latency constraints, the underlying model is a simple residual feed-forward neural network. The system is a variation of our previous methods which proved successful in KDD Cup 2021, WSDM Challenge 2021, and SIGIR eCom Challenge 2020. We release the source code at: https://github.com/Synerise/recsys-challenge-2021 ",
    "url": "https://arxiv.org/abs/2109.12985",
    "authors": [
      "Micha\u0142 Daniluk",
      "Jacek D\u0105browski",
      "Barbara Rychalska",
      "Konrad Go\u0142uchowski"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.13076",
    "title": "Using neural networks to solve the 2D Poisson equation for electric  field computation in plasma fluid simulations",
    "abstract": "The Poisson equation is critical to get a self-consistent solution in plasma fluid simulations used for Hall effect thrusters and streamers discharges. Solving the 2D Poisson equation with zero Dirichlet boundary conditions using a deep neural network is investigated using multiple-scale architectures, defined in terms of number of branches, depth and receptive field. The latter is found critical to correctly capture large topological structures of the field. The investigation of multiple architectures, losses, and hyperparameters provides an optimum network to solve accurately the steady Poisson problem. Generalization to new resolutions and domain sizes is then proposed using a proper scaling of the network. Finally, found neural network solver, called PlasmaNet, is coupled with an unsteady Euler plasma fluid equations solver. The test case corresponds to electron plasma oscillations which is used to assess the accuracy of the neural network solution in a time-dependent simulation. In this time-evolving problem, a physical loss is necessary to produce a stable simulation. PlasmaNet is then benchmarked on meshes with increasing number of nodes, and compared with an existing solver based on a standard linear system algorithm for the Poisson equation. It outperforms the classical plasma solver, up to speedups 700 times faster on large meshes. PlasmaNet is finally tested on a more complex case of discharge propagation involving chemistry and advection. The guidelines established in previous sections are applied to build the CNN to solve the same Poisson equation but in cylindrical coordinates. Results reveal good CNN predictions with significant speedup. These results pave the way to new computational strategies to predict unsteady problems involving a Poisson equation, including configurations with coupled multiphysics interactions such as in plasma flows. ",
    "url": "https://arxiv.org/abs/2109.13076",
    "authors": [
      "Lionel Cheng",
      "Ekhi Ajuria Illarramendi",
      "Guillaume Bogopolsky",
      "Michael Bauerheim",
      "Benedicte Cuenot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2109.13208",
    "title": "Spiking neural networks trained via proxy",
    "abstract": "We propose a new learning algorithm to train spiking neural networks (SNN) using conventional artificial neural networks (ANN) as proxy. We couple two SNN and ANN networks, respectively, made of integrate-and-fire (IF) and ReLU neurons with the same network architectures and shared synaptic weights. The forward passes of the two networks are totally independent. By assuming IF neuron with rate-coding as an approximation of ReLU, we backpropagate the error of the SNN in the proxy ANN to update the shared weights, simply by replacing the ANN final output with that of the SNN. We applied the proposed proxy learning to deep convolutional SNNs and evaluated it on two benchmarked datasets of Fahion-MNIST and Cifar10 with 94.56% and 93.11% classification accuracy, respectively. The proposed networks could outperform other deep SNNs trained with tandem learning, surrogate gradient learning, or converted from deep ANNs. Converted SNNs require long simulation times to reach reasonable accuracies while our proxy learning leads to efficient SNNs with much shorter simulation times. ",
    "url": "https://arxiv.org/abs/2109.13208",
    "authors": [
      "Saeed Reza Kheradpisheh",
      "Maryam Mirsadeghi",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.13228",
    "title": "PASS: An ImageNet replacement for self-supervised pretraining without  humans",
    "abstract": "Computer vision has long relied on ImageNet and other large datasets of images sampled from the Internet for pretraining models. However, these datasets have ethical and technical shortcomings, such as containing personal information taken without consent, unclear license usage, biases, and, in some cases, even problematic image content. On the other hand, state-of-the-art pretraining is nowadays obtained with unsupervised methods, meaning that labelled datasets such as ImageNet may not be necessary, or perhaps not even optimal, for model pretraining. We thus propose an unlabelled dataset PASS: Pictures without humAns for Self-Supervision. PASS only contains images with CC-BY license and complete attribution metadata, addressing the copyright issue. Most importantly, it contains no images of people at all, and also avoids other types of images that are problematic for data protection or ethics. We show that PASS can be used for pretraining with methods such as MoCo-v2, SwAV and DINO. In the transfer learning setting, it yields similar downstream performances to ImageNet pretraining even on tasks that involve humans, such as human pose estimation. PASS does not make existing datasets obsolete, as for instance it is insufficient for benchmarking. However, it shows that model pretraining is often possible while using safer data, and it also provides the basis for a more robust evaluation of pretraining methods. ",
    "url": "https://arxiv.org/abs/2109.13228",
    "authors": [
      "Yuki M. Asano",
      "Christian Rupprecht",
      "Andrew Zisserman",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2109.12140",
    "title": "Vertebrate interval graphs",
    "abstract": "A vertebrate interval graph is an interval graph in which the maximum size of a set of independent vertices equals the number of maximal cliques. For any fixed $v \\ge 1$, there is a polynomial-time algorithm for deciding whether a vertebrate interval graph admits a vertex partition into two induced subgraphs with claw number at most $v$. In particular, when $v = 2$, whether a vertebrate interval graph can be partitioned into two proper interval graphs can be decided in polynomial time. ",
    "url": "https://arxiv.org/abs/2109.12140",
    "authors": [
      "Rain Jiang",
      "Kai Jiang",
      "Minghui Jiang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2109.12283",
    "title": "Scalable deeper graph neural networks for high-performance materials  property prediction",
    "abstract": "Machine learning (ML) based materials discovery has emerged as one of the most promising approaches for breakthroughs in materials science. While heuristic knowledge based descriptors have been combined with ML algorithms to achieve good performance, the complexity of the physicochemical mechanisms makes it urgently needed to exploit representation learning from either compositions or structures for building highly effective materials machine learning models. Among these methods, the graph neural networks have shown the best performance by its capability to learn high-level features from crystal structures. However, all these models suffer from their inability to scale up the models due to the over-smoothing issue of their message-passing GNN architecture. Here we propose a novel graph attention neural network model DeeperGATGNN with differentiable group normalization and skip-connections, which allows to train very deep graph neural network models (e.g. 30 layers compared to 3-9 layers in previous works). Through systematic benchmark studies over six benchmark datasets for energy and band gap predictions, we show that our scalable DeeperGATGNN model needs little costly hyper-parameter tuning for different datasets and achieves the state-of-the-art prediction performances over five properties out of six with up to 10\\% improvement. Our work shows that to deal with the high complexity of mapping the crystal materials structures to their properties, large-scale very deep graph neural networks are needed to achieve robust performances. ",
    "url": "https://arxiv.org/abs/2109.12283",
    "authors": [
      "Sadman Sadeed Omee",
      "Steph-Yves Louis",
      "Nihang Fu",
      "Lai Wei",
      "Sourin Dey",
      "Rongzhi Dong",
      "Qinyang Li",
      "Jianjun Hu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.12422",
    "title": "Equality of opportunity in travel behavior prediction with deep neural  networks and discrete choice models",
    "abstract": "Although researchers increasingly adopt machine learning to model travel behavior, they predominantly focus on prediction accuracy, ignoring the ethical challenges embedded in machine learning algorithms. This study introduces an important missing dimension - computational fairness - to travel behavior analysis. We first operationalize computational fairness by equality of opportunity, then differentiate between the bias inherent in data and the bias introduced by modeling. We then demonstrate the prediction disparities in travel behavior modeling using the 2017 National Household Travel Survey (NHTS) and the 2018-2019 My Daily Travel Survey in Chicago. Empirically, deep neural network (DNN) and discrete choice models (DCM) reveal consistent prediction disparities across multiple social groups: both over-predict the false negative rate of frequent driving for the ethnic minorities, the low-income and the disabled populations, and falsely predict a higher travel burden of the socially disadvantaged groups and the rural populations than reality. Comparing DNN with DCM, we find that DNN can outperform DCM in prediction disparities because of DNN's smaller misspecification error. To mitigate prediction disparities, this study introduces an absolute correlation regularization method, which is evaluated with synthetic and real-world data. The results demonstrate the prevalence of prediction disparities in travel behavior modeling, and the disparities still persist regarding a variety of model specifics such as the number of DNN layers, batch size and weight initialization. Since these prediction disparities can exacerbate social inequity if prediction results without fairness adjustment are used for transportation policy making, we advocate for careful consideration of the fairness problem in travel behavior modeling, and the use of bias mitigation algorithms for fair transport decisions. ",
    "url": "https://arxiv.org/abs/2109.12422",
    "authors": [
      "Yunhan Zheng",
      "Shenhao Wang",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2109.12434",
    "title": "Emergent behavior and neural dynamics in artificial agents tracking  turbulent plumes",
    "abstract": "Tracking a turbulent plume to locate its source is a complex control problem because it requires multi-sensory integration and must be robust to intermittent odors, changing wind direction, and variable plume statistics. This task is routinely performed by flying insects, often over long distances, in pursuit of food or mates. Several aspects of this remarkable behavior have been studied in detail in many experimental studies. Here, we take a complementary in silico approach, using artificial agents trained with reinforcement learning to develop an integrated understanding of the behaviors and neural computations that support plume tracking. Specifically, we use deep reinforcement learning (DRL) to train recurrent neural network (RNN) agents to locate the source of simulated turbulent plumes. Interestingly, the agents' emergent behaviors resemble those of flying insects, and the RNNs learn to represent task-relevant variables, such as head direction and time since last odor encounter. Our analyses suggest an intriguing experimentally testable hypothesis for tracking plumes in changing wind direction -- that agents follow local plume shape rather than the current wind direction. While reflexive short-memory behaviors are sufficient for tracking plumes in constant wind, longer timescales of memory are essential for tracking plumes that switch direction. At the level of neural dynamics, the RNNs' population activity is low-dimensional and organized into distinct dynamical structures, with some correspondence to behavioral modules. Our in silico approach provides key intuitions for turbulent plume tracking strategies and motivates future targeted experimental and theoretical developments. ",
    "url": "https://arxiv.org/abs/2109.12434",
    "authors": [
      "Satpreet Harcharan Singh",
      "Floris van Breugel",
      "Rajesh P. N. Rao",
      "Bingni Wen Brunton"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.12617",
    "title": "Structure-aware scale-adaptive networks for cancer segmentation in  whole-slide images",
    "abstract": "Cancer segmentation in whole-slide images is a fundamental step for viable tumour burden estimation, which is of great value for cancer assessment. However, factors like vague boundaries or small regions dissociated from viable tumour areas make it a challenging task. Considering the usefulness of multi-scale features in various vision-related tasks, we present a structure-aware scale-adaptive feature selection method for efficient and accurate cancer segmentation. Based on a segmentation network with a popular encoder-decoder architecture, a scale-adaptive module is proposed for selecting more robust features to represent the vague, non-rigid boundaries. Furthermore, a structural similarity metric is proposed for better tissue structure awareness to deal with small region segmentation. In addition, advanced designs including several attention mechanisms and the selective-kernel convolutions are applied to the baseline network for comparative study purposes. Extensive experimental results show that the proposed structure-aware scale-adaptive networks achieve outstanding performance on liver cancer segmentation when compared to top ten submitted results in the challenge of PAIP 2019. Further evaluation on colorectal cancer segmentation shows that the scale-adaptive module improves the baseline network or outperforms the other excellent designs of attention mechanisms when considering the tradeoff between efficiency and accuracy. ",
    "url": "https://arxiv.org/abs/2109.12617",
    "authors": [
      "Yibao Sun",
      "Giussepi Lopez",
      "Yaqi Wang",
      "Xingru Huang",
      "Huiyu Zhou",
      "Qianni Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.12827",
    "title": "Experimental symmetric private information retrieval with  measurement-device-independent quantum network",
    "abstract": "Retrieving information from a database, or information retrieval (IR), is a simple task with an expansive range of applications. However, oftentimes, the user and data centres involved in IR tasks would have privacy concerns. To this end, we require symmetric private information retrieval (SPIR), which possesses stringent system requirements that are challenging to meet in practice. This is especially so for SPIR with databases needing long-term security, for which the use of multiple data centres and a secure method of key distribution are necessary. In this paper, we report an experimental implementation of SPIR with information-theoretic secure keys generated by measurement-device-independent (MDI) QKD. In particular, we demonstrate the SPIR scheme on a simple fingerprint database, successfully retrieving a 582-byte fingerprint file from a database with 800 entries. Our simulation and experimental results show the feasibility of the proposed SPIR scheme, presenting a promising way for practical IR applications with privacy requirements. ",
    "url": "https://arxiv.org/abs/2109.12827",
    "authors": [
      "Chao Wang",
      "Wen Yu Kon",
      "Hong Jie Ng",
      "Charles C.-W. Lim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.12871",
    "title": "Strong entanglement distribution of quantum networks",
    "abstract": "Large-scale quantum networks have been employed to overcome practical constraints of transmissions and storage for single entangled systems. Our goal in this article is to explore the strong entanglement distribution of quantum networks. We firstly show any connected network consisting of generalized EPR states and GHZ states satisfies strong CKW monogamy inequality in terms of bipartite entanglement measure. This reveals interesting feature of high-dimensional entanglement with local tensor decomposition going beyond qubit entanglement. We then apply the new entanglement distribution relation in entangled networks for getting quantum max-flow min-cut theorem in terms of von Neumann entropy and R\\'{e}nyi-$\\alpha$ entropy. We finally classify entangled quantum networks by distinguishing network configurations under local unitary operations. These results provide new insights into characterizing quantum networks in quantum information processing. ",
    "url": "https://arxiv.org/abs/2109.12871",
    "authors": [
      "Xue Yang",
      "Yan-Han Yang",
      "Ming-Xing Luo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2109.12978",
    "title": "Application of graph theory in quantum computer science",
    "abstract": "In this dissertation we demonstrate that the continuous-time quantum walk models remain powerful for nontrivial graph structures. We consider two aspects of this problem. First, it is known that the standard Continuous-Time Quantum Walk (CTQW), proposed by Childs and Goldstone, can propagate quickly on the infinite path graph. However, the Schr\\\"odinger equation requires the Hamiltonian to be symmetric, and thus only undirected graphs can be implemented. In this thesis, we address the question, whether it is possible to construct a continuous-time quantum walk on general directed graphs, preserving its propagation properties. Secondly, the quantum spatial search defined through CTQW has been proven to work well on various undirected graphs. However, most of these graphs have very simple structures. The most advanced results concerned the Erd\\H{o}s-R\\'enyi model of random graphs, which is the most popular but not realistic random graph model, and Barab\\'asi-Albert random graphs, for which full quadratic speed-up was not confirmed. In the scope of this aspect we analyze, whether quantum speed-up is observed for complicated graph structures as well. ",
    "url": "https://arxiv.org/abs/2109.12978",
    "authors": [
      "Adam Glos"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2109.12993",
    "title": "Constructing bounded degree graphs with prescribed degree and neighbor  degree sequences",
    "abstract": "Let $D = d_1, d_2, \\ldots, d_n$ and $F = f_1, f_2,\\ldots, f_n$ be two sequences of positive integers. We consider the following decision problems: is there a $i)$ multigraph, $ii)$ loopless multigraph, $iii)$ simple graph, $iv)$ connected simple graph, $v)$ tree, $vi)$ caterpillar $G = (V,E)$ such that for all $k$, $d(v_k) = d_k$ and $\\sum_{w\\in \\mathcal{N}(v_k)} d(w) = f_k$ ($d(v)$ is the degree of $v$ and $\\mathcal{N}(v)$ is the set of neighbors of $v$). Here we show that all these decision problems can be solved in polynomial time if $\\max_{k} d_k$ is bounded. The problem is motivated by NMR spectroscopy of hydrocarbons. ",
    "url": "https://arxiv.org/abs/2109.12993",
    "authors": [
      "Uro\u0161 \u010cibej",
      "Aaron Li",
      "Istv\u00e1n Mikl\u00f3s",
      "Sohaib Nasir",
      "Varun Srikanth"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1911.00620",
    "title": "Improved bounds on the size of the smallest representation of relation  algebra $32_{65}$",
    "abstract": " Comments: 18 pages ",
    "url": "https://arxiv.org/abs/1911.00620",
    "authors": [
      "Jeremy F. Alm",
      "Michael Levet",
      "Saeed Moazami",
      "Jorge Montero-Vallejo",
      "Linda Pham",
      "Dave Sexton",
      "Xiaonan Xu"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2010.06415",
    "title": "Exact $p$-values for global network alignments via combinatorial  analysis of shared GO terms (Subtitle: REFANGO: Rigorous Evaluation of  Functional Alignments of Networks using Gene Ontology)",
    "abstract": " Comments: 22 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2010.06415",
    "authors": [
      "Wayne B. Hayes"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2012.09037",
    "title": "Copula-based synthetic data augmentation for machine-learning emulators",
    "abstract": " Comments: Published version ",
    "url": "https://arxiv.org/abs/2012.09037",
    "authors": [
      "David Meyer",
      "Thomas Nagler",
      "Robin J. Hogan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2108.07610",
    "title": "DRAEM -- A discriminatively trained reconstruction embedding for surface  anomaly detection",
    "abstract": " Comments: Accepted to ICCV2021 ",
    "url": "https://arxiv.org/abs/2108.07610",
    "authors": [
      "Vitjan Zavrtanik",
      "Matej Kristan",
      "Danijel Sko\u010daj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.00869",
    "title": "Assessing domain adaptation techniques for mitosis detection in  multi-scanner breast cancer histopathology images",
    "abstract": " Title: Assessing domain adaptation techniques for mitosis detection in  multi-scanner breast cancer histopathology images ",
    "url": "https://arxiv.org/abs/2109.00869",
    "authors": [
      "Jack Breen",
      "Kieran Zucker",
      "Nicolas Orsi",
      "Geoff Hall",
      "Nishant Ravikumar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.01451",
    "title": "Impact of GPU uncertainty on the training of predictive deep neural  networks",
    "abstract": " Title: Impact of GPU uncertainty on the training of predictive deep neural  networks ",
    "url": "https://arxiv.org/abs/2109.01451",
    "authors": [
      "Maciej Pietrowski",
      "Andrzej Gajda",
      "Takuto Yamamoto",
      "Taisuke Kobayashi",
      "Lana Sinapayen",
      "Eiji Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2109.06152",
    "title": "Enumerating independent sets in Abelian Cayley graphs",
    "abstract": " Comments: 21 pages, fixed minor typos and citations ",
    "url": "https://arxiv.org/abs/2109.06152",
    "authors": [
      "Aditya Potukuchi",
      "Liana Yepremyan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2109.10021",
    "title": "Stabilizing Elastic Weight Consolidation method in practical ML tasks  and using weight importances for neural network pruning",
    "abstract": " Comments: 16 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2109.10021",
    "authors": [
      "Alexey Kutalev",
      "Alisa Lapina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.11523",
    "title": "How much \"human-like\" visual experience do current self-supervised  learning algorithms need to achieve human-level object recognition?",
    "abstract": " Comments: v2 adds more details on image preprocessing, adds more discussion, fixes a few typos ",
    "url": "https://arxiv.org/abs/2109.11523",
    "authors": [
      "A. Emin Orhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  }
]