[
  {
    "id": "arXiv:2109.08796",
    "title": "Solar cell patent classification method based on keyword extraction and  deep neural network",
    "abstract": "With the growing impact of ESG on businesses, research related to renewable energy is receiving great attention. Solar cells are one of them, and accordingly, it can be said that the research value of solar cell patent analysis is very high. Patent documents have high research value. Being able to accurately analyze and classify patent documents can reveal several important technical relationships. It can also describe the business trends in that technology. And when it comes to investment, new industrial solutions will also be inspired and proposed to make important decisions. Therefore, we must carefully analyze patent documents and utilize the value of patents. To solve the solar cell patent classification problem, we propose a keyword extraction method and a deep neural network-based solar cell patent classification method. First, solar cell patents are analyzed for pretreatment. It then uses the KeyBERT algorithm to extract keywords and key phrases from the patent abstract to construct a lexical dictionary. We then build a solar cell patent classification model according to the deep neural network. Finally, we use a deep neural network-based solar cell patent classification model to classify power patents, and the training accuracy is greater than 95%. Also, the validation accuracy is about 87.5%. It can be seen that the deep neural network method can not only realize the classification of complex and difficult solar cell patents, but also have a good classification effect. ",
    "url": "https://arxiv.org/abs/2109.08796",
    "authors": [
      "Yongmin Yoo",
      "Dongjin Lim",
      "Tak-Sung Heo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.08830",
    "title": "MM-Deacon: Multimodal molecular domain embedding analysis via  contrastive learning",
    "abstract": "Molecular representation learning plays an essential role in cheminformatics. Recently, language model-based approaches have been popular as an alternative to traditional expert-designed features to encode molecules. However, these approaches only utilize a single modality for representing molecules. Driven by the fact that a given molecule can be described through different modalities such as Simplified Molecular Line Entry System (SMILES), The International Union of Pure and Applied Chemistry (IUPAC), and The IUPAC International Chemical Identifier (InChI), we propose a multimodal molecular embedding generation approach called MM-Deacon (multimodal molecular domain embedding analysis via contrastive learning). MM-Deacon is trained using SMILES and IUPAC molecule representations as two different modalities. First, SMILES and IUPAC strings are encoded by using two different transformer-based language models independently, then the contrastive loss is utilized to bring these encoded representations from different modalities closer to each other if they belong to the same molecule, and to push embeddings farther from each other if they belong to different molecules. We evaluate the robustness of our molecule embeddings on molecule clustering, cross-modal molecule search, drug similarity assessment and drug-drug interaction tasks. ",
    "url": "https://arxiv.org/abs/2109.08830",
    "authors": [
      "Zhihui Guo",
      "Pramod Kumar Sharma",
      "Liang Du",
      "Robin Abraham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2109.09083",
    "title": "Towards robustness under occlusion for face recognition",
    "abstract": "In this paper, we evaluate the effects of occlusions in the performance of a face recognition pipeline that uses a ResNet backbone. The classifier was trained on a subset of the CelebA-HQ dataset containing 5,478 images from 307 classes, to achieve top-1 error rate of 17.91%. We designed 8 different occlusion masks which were applied to the input images. This caused a significant drop in the classifier performance: its error rate for each mask became at least two times worse than before. In order to increase robustness under occlusions, we followed two approaches. The first is image inpainting using the pre-trained pluralistic image completion network. The second is Cutmix, a regularization strategy consisting of mixing training images and their labels using rectangular patches, making the classifier more robust against input corruptions. Both strategies revealed effective and interesting results were observed. In particular, the Cutmix approach makes the network more robust without requiring additional steps at the application time, though its training time is considerably longer. Our datasets containing the different occlusion masks as well as their inpainted counterparts are made publicly available to promote research on the field. ",
    "url": "https://arxiv.org/abs/2109.09083",
    "authors": [
      "Tomas M. Borges",
      "Teofilo E. de Campos",
      "Ricardo de Queiroz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.09108",
    "title": "A link between the steepest descent method and fixed-point iterations",
    "abstract": "We will make a link between the steepest descent method for an unconstrained minimisation problem and fixed-point iterations for its Euler-Lagrange equation. In this context, we shall rediscover the preconditioned nonlinear conjugate gradient method for the discretised problem. The benefit of the link between the two methods will be illustrated by a numerical experiment. ",
    "url": "https://arxiv.org/abs/2109.09108",
    "authors": [
      "Pascal Heid"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.09213",
    "title": "Capsule networks with non-iterative cluster routing",
    "abstract": "Capsule networks use routing algorithms to flow information between consecutive layers. In the existing routing procedures, capsules produce predictions (termed votes) for capsules of the next layer. In a nutshell, the next-layer capsule's input is a weighted sum over all the votes it receives. In this paper, we propose non-iterative cluster routing for capsule networks. In the proposed cluster routing, capsules produce vote clusters instead of individual votes for next-layer capsules, and each vote cluster sends its centroid to a next-layer capsule. Generally speaking, the next-layer capsule's input is a weighted sum over the centroid of each vote cluster it receives. The centroid that comes from a cluster with a smaller variance is assigned a larger weight in the weighted sum process. Compared with the state-of-the-art capsule networks, the proposed capsule networks achieve the best accuracy on the Fashion-MNIST and SVHN datasets with fewer parameters, and achieve the best accuracy on the smallNORB and CIFAR-10 datasets with a moderate number of parameters. The proposed capsule networks also produce capsules with disentangled representation and generalize well to images captured at novel viewpoints. The proposed capsule networks also preserve 2D spatial information of an input image in the capsule channels: if the capsule channels are rotated, the object reconstructed from these channels will be rotated by the same transformation. Codes are available at https://github.com/ZHAOZHIHAO/ClusterRouting. ",
    "url": "https://arxiv.org/abs/2109.09213",
    "authors": [
      "Zhihao Zhao",
      "Samuel Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.09244",
    "title": "A domain specific modeling and analysis environment for complex IoT  applications",
    "abstract": "To cope with the complexities found in the Internet of Things domain, designers and developers of IoT applications demand practical tools. Several model-driven engineering methodologies and tools have been developed to address such difficulties, but few of them address the analysis aspects. In this extended abstract, we introduce CHESSIoT, a domain-specific modeling environment for complex IoT applications. In addition, the existing supported real-time analysis mechanism, as well as a proposed code generation approach, are presented ",
    "url": "https://arxiv.org/abs/2109.09244",
    "authors": [
      "Felicien Ihirwe",
      "Davide Di Ruscio",
      "Silvia Mazzini",
      "Alfonso Pierantonio"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2109.09246",
    "title": "Splitfed learning without client-side synchronization: Analyzing  client-side split network portion size to overall performance",
    "abstract": "Federated Learning (FL), Split Learning (SL), and SplitFed Learning (SFL) are three recent developments in distributed machine learning that are gaining attention due to their ability to preserve the privacy of raw data. Thus, they are widely applicable in various domains where data is sensitive, such as large-scale medical image classification, internet-of-medical-things, and cross-organization phishing email detection. SFL is developed on the confluence point of FL and SL. It brings the best of FL and SL by providing parallel client-side machine learning model updates from the FL paradigm and a higher level of model privacy (while training) by splitting the model between the clients and server coming from SL. However, SFL has communication and computation overhead at the client-side due to the requirement of client-side model synchronization. For the resource-constrained client-side, removal of such requirements is required to gain efficiency in the learning. In this regard, this paper studies SFL without client-side model synchronization. The resulting architecture is known as Multi-head Split Learning. Our empirical studies considering the ResNet18 model on MNIST data under IID data distribution among distributed clients find that Multi-head Split Learning is feasible. Its performance is comparable to the SFL. Moreover, SFL provides only 1%-2% better accuracy than Multi-head Split Learning on the MNIST test set. To further strengthen our results, we study the Multi-head Split Learning with various client-side model portions and its impact on the overall performance. To this end, our results find a minimal impact on the overall performance of the model. ",
    "url": "https://arxiv.org/abs/2109.09246",
    "authors": [
      "Praveen Joshi",
      "Chandra Thapa",
      "Seyit Camtepe",
      "Mohammed Hasanuzzamana",
      "Ted Scully",
      "Haithem Afli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.09574",
    "title": "On the representation of non-holonomic power series",
    "abstract": "Holonomic functions play an essential role in Computer Algebra since they allow the application of many symbolic algorithms. Among all algorithmic attempts to find formulas for power series, the holonomic property remains the most important requirement to be satisfied by the function under consideration. The targeted functions mainly summarize that of meromorphic functions. However, expressions like $\\tan(z)$, $z/(\\exp(z)-1)$, $\\sec(z)$, etc. are not holonomic, therefore their power series are inaccessible by non-pattern matching implementations like the current Maple \\texttt{convert/FormalPowerSeries}. From the mathematical dictionaries, one can observe that most of the known closed-form formulas of non-holonomic power series involve another sequence whose evaluation linearly depends on some finite summations. In the case of $\\tan(z)$ and $\\sec(z)$ the corresponding sequences are the Bernoulli and Euler numbers, respectively. Thus providing a symbolic approach that yields explicit representations when linear summations for power series coefficients of non-holonomic functions appear, might be seen as a step forward towards the representation of non-holonomic power series. By adapting the method of ansatz with undetermined coefficients, we build an algorithm that computes least-order quadratic differential equations with polynomial coefficients for a large class of non-holonomic functions. A differential equation resulting from this procedure is converted into a recurrence equation by applying the Cauchy product formula and rewriting powers into polynomials and derivatives into shifts. Finally, using enough initial values we are able to give normal form representations to characterize several non-holonomic power series and prove non-trivial identities. We discuss this algorithm and its implementation for Maple 2022. ",
    "url": "https://arxiv.org/abs/2109.09574",
    "authors": [
      "Bertrand Teguia Tabuguia",
      "Wolfram Koepf"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2109.09587",
    "title": "Recommender systems based on graph embedding techniques: A comprehensive  review",
    "abstract": "Recommender systems, a pivotal tool to alleviate the information overload problem, aim to predict user's preferred items from millions of candidates by analyzing observed user-item relations. As for tackling the sparsity and cold start problems encountered by recommender systems, uncovering hidden (indirect) user-item relations by employing side information and knowledge to enrich observed information for the recommendation has been proven promising recently; and its performance is largely determined by the scalability of recommendation models in the face of the high complexity and large scale of side information and knowledge. Making great strides towards efficiently utilizing complex and large-scale data, research into graph embedding techniques is a major topic. Equipping recommender systems with graph embedding techniques contributes to outperforming the conventional recommendation implementing directly based on graph topology analysis and has been widely studied these years. This article systematically retrospects graph embedding-based recommendation from embedding techniques for bipartite graphs, general graphs, and knowledge graphs, and proposes a general design pipeline of that. In addition, comparing several representative graph embedding-based recommendation models with the most common-used conventional recommendation models, on simulations, manifests that the conventional models overall outperform the graph embedding-based ones in predicting implicit user-item interactions, revealing the relative weakness of graph embedding-based recommendation in these tasks. To foster future research, this article proposes constructive suggestions on making a trade-off between graph embedding-based recommendation and the conventional recommendation in different tasks as well as some open questions. ",
    "url": "https://arxiv.org/abs/2109.09587",
    "authors": [
      "Yue Deng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.08710",
    "title": "On-device neural speech synthesis",
    "abstract": "Recent advances in text-to-speech (TTS) synthesis, such as Tacotron and WaveRNN, have made it possible to construct a fully neural network based TTS system, by coupling the two components together. Such a system is conceptually simple as it only takes grapheme or phoneme input, uses Mel-spectrogram as an intermediate feature, and directly generates speech samples. The system achieves quality equal or close to natural speech. However, the high computational cost of the system and issues with robustness have limited their usage in real-world speech synthesis applications and products. In this paper, we present key modeling improvements and optimization strategies that enable deploying these models, not only on GPU servers, but also on mobile devices. The proposed system can generate high-quality 24 kHz speech at 5x faster than real time on server and 3x faster than real time on mobile devices. ",
    "url": "https://arxiv.org/abs/2109.08710",
    "authors": [
      "Sivanand Achanta",
      "Albert Antony",
      "Ladan Golipour",
      "Jiangchuan Li",
      "Tuomo Raitio",
      "Ramya Rasipuram",
      "Francesco Rossi",
      "Jennifer Shi",
      "Jaimin Upadhyay",
      "David Winarsky",
      "Hepeng Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Performance (cs.PF)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2109.08746",
    "title": "Persistent homology of convection cycles in network flows",
    "abstract": "Convection is a well-studied topic in fluid dynamics, yet it is less understood in the context of networks flows. Here, we incorporate techniques from topological data analysis (namely, persistent homology) to automate the detection and characterization of convective/cyclic/chiral flows over networks, particularly those that arise for irreversible Markov chains (MCs). As two applications, we study convection cycles arising under the PageRank algorithm, and we investigate chiral edges flows for a stochastic model of a bi-monomer's configuration dynamics. Our experiments highlight how system parameters -- e.g., the teleportation rate for PageRank and the transition rates of external and internal state changes for a monomer -- can act as homology regularizers of convection, which we summarize with persistence barcodes and homological bifurcation diagrams. Our approach establishes a new connection between the study of convection cycles and homology, the branch of mathematics that formally studies cycles, which has diverse potential applications throughout the sciences and engineering. ",
    "url": "https://arxiv.org/abs/2109.08746",
    "authors": [
      "Minh Quang Le",
      "Dane Taylor"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Social and Information Networks (cs.SI)",
      "Pattern Formation and Solitons (nlin.PS)"
    ]
  },
  {
    "id": "arXiv:2109.08813",
    "title": "Data-driven rational function neural networks: a new method for  generating analytical models of rock physics",
    "abstract": "Seismic wave velocity of underground rock plays important role in detecting internal structure of the Earth. Rock physics models have long been the focus of predicting wave velocity. However, construction of a theoretical model requires careful physical considerations and mathematical derivations, which means a long research process. In addition, various complicated situations often occur in practice, which brings great difficulties to the application of theoretical models. On the other hand, there are many empirical formulas based on real data. These empirical models are often simple and easy to use, but may be not based on physical principles and lack a proper formulation of physics. This work proposed a rational function neural networks (RafNN) for data-driven rock physics modeling. Based on the observation data set, this method can deduce a velocity model which not only satisfies the actual data distribution, but also has a proper mathematical form reflecting the inherent rock physics. The Gassmann's equation, which is the most commonly used theoretical model relating bulk modulus of porous rock to mineral composition, porosity and fluid, is perfectly reconstructed by using data-driven RafNN. The advantage of this method is that only observational data sets are required to extract model equations, and no complex mathematical and physical processes are involved. This work opens up for the first time a new avenue on constructing analytical expression of velocity models using neural networks and field data, which is of great interest for exploring the heterogeneous structure of the Earth. ",
    "url": "https://arxiv.org/abs/2109.08813",
    "authors": [
      "Weitao Sun"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2109.08956",
    "title": "Scenario adaptive disruption prediction study for next generation  burning-plasma tokamaks",
    "abstract": "Next generation high performance (HP) tokamaks risk damage from unmitigated disruptions at high current and power. Achieving reliable disruption prediction for a device's HP operation based on its low performance (LP) data is key to success. In this letter, through explorative data analysis and dedicated numerical experiments on multiple existing tokamaks, we demonstrate how the operational regimes of tokamaks can affect the power of a trained disruption predictor. First, our results suggest data-driven disruption predictors trained on abundant LP discharges work poorly on the HP regime of the same tokamak, which is a consequence of the distinct distributions of the tightly correlated signals related to disruptions in these two regimes. Second, we find that matching operational parameters among tokamaks strongly improves cross-machine accuracy which implies our model learns from the underlying scalings of dimensionless physics parameters like q_{95}, \\beta_{p} and confirms the importance of these parameters in disruption physics and cross machine domain matching from the data-driven perspective. Finally, our results show how in the absence of HP data from the target devices, the best predictivity of the HP regime for the target machine can be achieved by combining LP data from the target with HP data from other machines. These results provide a possible disruption predictor development strategy for next generation tokamaks, such as ITER and SPARC, and highlight the importance of developing on existing machines baseline scenario discharges of future tokamaks to collect more relevant disruptive data. ",
    "url": "https://arxiv.org/abs/2109.08956",
    "authors": [
      "J. Zhu",
      "C. Rea",
      "R.S. Granetz",
      "E. S. Marmar",
      "K. J. Montes",
      "R. Sweeney",
      "R.A. Tinguely",
      "D. L. Chen",
      "B. Shen",
      "B. J. Xiao",
      "D. Humphreys",
      "J. Barr",
      "O. Meneghini"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.08965",
    "title": "PCNN: A physics-constrained neural network for multiphase flows",
    "abstract": "The present study develops a physics-constrained neural network (PCNN) to predict sequential patterns and motions of multiphase flows (MPFs), which includes strong interactions among various fluid phases. To predict the order parameters, which locate individual phases, in the future time, the conditional neural processes and long short-term memory (CNP-LSTM) are applied to quickly infer the dynamics of the phases after encoding only a few observations. After that, the multiphase consistent and conservative boundedness mapping algorithm (MCBOM) is implemented to correct the order parameters predicted from CNP-LSTM in order to strictly satisfy the mass conservation, the summation of the volume fractions of the phases to be unity, the consistency of reduction, and the boundedness of the order parameters. Then, the density of the fluid mixture is updated from the corrected order parameters. Finally, the velocity in the future time is predicted by a physics-informed CNP-LSTM (PICNP-LSTM) where conservation of momentum is included in the loss function with the observed density and velocity as the inputs. The proposed PCNN for MPFs sequentially performs (CNP-LSTM)-(MCBOM)-(PICNP-LSTM), which avoids unphysical behaviors of the order parameters, accelerates the convergence, and requires fewer data to make predictions. Numerical experiments demonstrate that the proposed PCNN is capable of predicting MPFs effectively. ",
    "url": "https://arxiv.org/abs/2109.08965",
    "authors": [
      "Haoyang Zheng",
      "Ziyang Huang",
      "Guang Lin"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.09077",
    "title": "DECORAS: detection and characterization of radio-astronomical sources  using deep learning",
    "abstract": "We present DECORAS, a deep learning based approach to detect both point and extended sources from Very Long Baseline Interferometry (VLBI) observations. Our approach is based on an encoder-decoder neural network architecture that uses a low number of convolutional layers to provide a scalable solution for source detection. In addition, DECORAS performs source characterization in terms of the position, effective radius and peak brightness of the detected sources. We have trained and tested the network with images that are based on realistic Very Long Baseline Array (VLBA) observations at 20 cm. Also, these images have not gone through any prior de-convolution step and are directly related to the visibility data via a Fourier transform. We find that the source catalog generated by DECORAS has a better overall completeness and purity, when compared to a traditional source detection algorithm. DECORAS is complete at the 7.5$\\sigma$ level, and has an almost factor of two improvement in reliability at 5.5$\\sigma$. We find that DECORAS can recover the position of the detected sources to within 0.61 $\\pm$ 0.69 mas, and the effective radius and peak surface brightness are recovered to within 20 per cent for 98 and 94 per cent of the sources, respectively. Overall, we find that DECORAS provides a reliable source detection and characterization solution for future wide-field VLBI surveys. ",
    "url": "https://arxiv.org/abs/2109.09077",
    "authors": [
      "S.Rezaei",
      "J.P.McKean",
      "M.Biehl",
      "A.Javadpour"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.09119",
    "title": "Network Refinement: A unified framework for enhancing signal or removing  noise of networks",
    "abstract": "Networks are widely used in many fields for their powerful ability to provide vivid representations of relationships between variables. However, many of them may be corrupted by experimental noise or inappropriate network inference methods that inherently hamper the efficacy of network-based downstream analysis. Consequently, it's necessary to develop systematic methods for denoising networks, namely, improve the Signal-to-Noise Ratio (SNR) of noisy networks. In this paper, we have explored the properties of network signal and noise and proposed a novel network denoising framework called Network Refinement (NR) that adjusts the edge weights by applying a nonlinear graph operator based on a diffusion process defined by random walk on the graph. Specifically, this unified framework consists of two closely linked approaches named NR-F and NR-B, which improve the SNR of noisy input networks from two different perspectives: NR-F aims at enhancing signal strength, while NR-B aims at weakening noise strength. Users can choose from which angle to improve the SNR of the network according to the characteristics of the network itself. We show that NR can significantly refine the quality of many networks by several applications on simulated networks and typical real-world biological and social networks. ",
    "url": "https://arxiv.org/abs/2109.09119",
    "authors": [
      "Jiating Yu",
      "Jiacheng Leng",
      "Ling-Yun Wu"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Social and Information Networks (cs.SI)",
      "Biological Physics (physics.bio-ph)",
      "Physics and Society (physics.soc-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2109.09151",
    "title": "Locally-symplectic neural networks for learning volume-preserving  dynamics",
    "abstract": "We propose locally-symplectic neural networks LocSympNets for learning volume-preserving dynamics. The construction of LocSympNets stems from the theorem of local Hamiltonian description of the vector field of a volume-preserving dynamical system and the splitting methods based on symplectic integrators. Modified gradient modules of recently proposed symplecticity-preserving neural networks SympNets are used to construct locally-symplectic modules, which composition results in volume-preserving neural networks. LocSympNets are studied numerically considering linear and nonlinear dynamics, i.e., semi-discretized advection equation and Euler equations of the motion of a free rigid body, respectively. LocSympNets are able to learn linear and nonlinear dynamics to high degree of accuracy. When learning a single trajectory of the rigid body dynamics LocSympNets are able to learn both invariants of the system with absolute relative errors below 1% in long-time predictions and produce qualitatively good short-time predictions, when the learning of the whole system from randomly sampled data is considered. ",
    "url": "https://arxiv.org/abs/2109.09151",
    "authors": [
      "J\u0101nis Baj\u0101rs"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.09304",
    "title": "Deformed semicircle law and concentration of nonlinear random matrices  for ultra-wide neural networks",
    "abstract": "In this paper, we study the two-layer fully connected neural network given by $f(X)=\\frac{1}{\\sqrt{d_1}}\\boldsymbol{a}^\\top\\sigma\\left(WX\\right)$, where $X\\in\\mathbb{R}^{d_0\\times n}$ is a deterministic data matrix, $W\\in\\mathbb{R}^{d_1\\times d_0}$ and $\\boldsymbol{a}\\in\\mathbb{R}^{d_1}$ are random Gaussian weights, and $\\sigma$ is a nonlinear activation function. We obtain the limiting spectral distributions of two kernel matrices related to $f(X)$: the empirical conjugate kernel (CK) and neural tangent kernel (NTK), beyond the linear-width regime ($d_1\\asymp n$). Under the ultra-width regime $d_1/n\\to\\infty$, with proper assumptions on $X$ and $\\sigma$, a deformed semicircle law appears. Such limiting law is first proved for general centered sample covariance matrices with correlation and then specified for our neural network model. We also prove non-asymptotic concentrations of empirical CK and NTK around their limiting kernel in the spectral norm, and lower bounds on their smallest eigenvalues. As an application, we verify the random feature regression achieves the same asymptotic performance as its limiting kernel regression in ultra-width limit. The limiting training and test errors for random feature regression are calculated by corresponding kernel regression. We also provide a nonlinear Hanson-Wright inequality suitable for neural networks with random weights and Lipschitz activation functions. ",
    "url": "https://arxiv.org/abs/2109.09304",
    "authors": [
      "Zhichao Wang",
      "Yizhe Zhu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.09553",
    "title": "Betweenness centrality in dense spatial networks",
    "abstract": "The betweenness centrality (BC) is an important quantity for understanding the structure of complex large networks. However, its calculation is in general difficult and known in simple cases only. In particular, the BC has been exactly computed for graphs constructed over a set of $N$ points in the infinite density limit, displaying a universal behavior. We reconsider this calculation and propose an expansion for large and finite densities. We compute the lowest non-trivial order and show that it encodes how straight are shortest paths and is therefore non-universal and depends on the graph considered. We compare our analytical result to numerical simulations obtained for various graphs such as the minimum spanning tree, the nearest neighbor graph, the relative neighborhood graph, the random geometric graph, the Gabriel graph, or the Delaunay triangulation. We show that in most cases the agreement with our analytical result is excellent even for densities of points that are relatively low. This method and our results provide a framework for understanding and computing this important quantity in large spatial networks. ",
    "url": "https://arxiv.org/abs/2109.09553",
    "authors": [
      "Vincent Verbavatz",
      "Marc Barthelemy"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computational Geometry (cs.CG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2109.09710",
    "title": "Understanding neural networks with reproducing kernel Banach spaces",
    "abstract": "Characterizing the function spaces corresponding to neural networks can provide a way to understand their properties. In this paper we discuss how the theory of reproducing kernel Banach spaces can be used to tackle this challenge. In particular, we prove a representer theorem for a wide class of reproducing kernel Banach spaces that admit a suitable integral representation and include one hidden layer neural networks of possibly infinite width. Further, we show that, for a suitable class of ReLU activation functions, the norm in the corresponding reproducing kernel Banach space can be characterized in terms of the inverse Radon transform of a bounded real measure, with norm given by the total variation norm of the measure. Our analysis simplifies and extends recent results in [34,29,30]. ",
    "url": "https://arxiv.org/abs/2109.09710",
    "authors": [
      "Francesca Bartolucci",
      "Ernesto De Vito",
      "Lorenzo Rosasco",
      "Stefano Vigogna"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:1912.06087",
    "title": "Attention network forecasts time-to-failure in laboratory shear  experiments",
    "abstract": " Title: Attention network forecasts time-to-failure in laboratory shear  experiments ",
    "url": "https://arxiv.org/abs/1912.06087",
    "authors": [
      "Hope Jasperson",
      "David C. Bolton",
      "Paul Johnson",
      "Robert Guyer",
      "Chris Marone",
      "Maarten V. de Hoop"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.09245",
    "title": "An empirical study on using CNNs for fast radio signal prediction",
    "abstract": " Title: An empirical study on using CNNs for fast radio signal prediction ",
    "url": "https://arxiv.org/abs/2006.09245",
    "authors": [
      "Ozan Ozyegen",
      "Sanaz Mohammadjafari",
      "Karim El mokhtari",
      "Mucahit Cevik",
      "Jonathan Ethier",
      "Ayse Basar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.09373",
    "title": "The shape and simplicity biases of adversarially robust ImageNet-trained  CNNs",
    "abstract": " Title: The shape and simplicity biases of adversarially robust ImageNet-trained  CNNs ",
    "url": "https://arxiv.org/abs/2006.09373",
    "authors": [
      "Peijie Chen",
      "Chirag Agarwal",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2007.03253",
    "title": "Doubly infinite residual neural networks: a diffusion process approach",
    "abstract": " Title: Doubly infinite residual neural networks: a diffusion process approach ",
    "url": "https://arxiv.org/abs/2007.03253",
    "authors": [
      "Stefano Peluchetti",
      "Stefano Favaro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2010.00585",
    "title": "Wavenumber-explicit convergence of the $hp$-FEM for the full-space  heterogeneous Helmholtz equation with smooth coefficients",
    "abstract": " Title: Wavenumber-explicit convergence of the $hp$-FEM for the full-space  heterogeneous Helmholtz equation with smooth coefficients ",
    "url": "https://arxiv.org/abs/2010.00585",
    "authors": [
      "David Lafontaine",
      "Euan A. Spence",
      "Jared Wunsch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2101.00161",
    "title": "Design of heterogeneous multi-agent system for distributed computation",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1804.00638 ",
    "url": "https://arxiv.org/abs/2101.00161",
    "authors": [
      "Jin Gyu Lee",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2103.16351",
    "title": "Multi-planner intervention in network games with community structures",
    "abstract": " Comments: Accepted in 60th IEEE Conference of Decision and Control 2021 ",
    "url": "https://arxiv.org/abs/2103.16351",
    "authors": [
      "Kun Jin",
      "Mingyan Liu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2104.05608",
    "title": "Equivariant geometric learning for digital rock physics: estimating  formation factor and effective permeability tensors from Morse graph",
    "abstract": " Title: Equivariant geometric learning for digital rock physics: estimating  formation factor and effective permeability tensors from Morse graph ",
    "url": "https://arxiv.org/abs/2104.05608",
    "authors": [
      "Chen Cai",
      "Nikolaos Vlassis",
      "Lucas Magee",
      "Ran Ma",
      "Zeyu Xiong",
      "Bahador Bahmani",
      "Teng-Fong Wong",
      "Yusu Wang",
      "WaiChing Sun"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.05029",
    "title": "Adversarial examples attack based on random warm restart mechanism and  improved Nesterov momentum",
    "abstract": " Comments: 9 pages, 7 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2105.05029",
    "authors": [
      "Tiangang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2105.06844",
    "title": "Predicting speech intelligibility from EEG using a dilated convolutional  network",
    "abstract": " Comments: 12 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2105.06844",
    "authors": [
      "Bernd Accou",
      "Mohammad Jalilpour Monesi",
      "Hugo Van hamme",
      "Tom Francart"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2105.12441",
    "title": "DeepGaze IIE: Calibrated prediction in and out-of-domain for  state-of-the-art saliency modeling",
    "abstract": " Comments: Joint first authors, published in ICCV ",
    "url": "https://arxiv.org/abs/2105.12441",
    "authors": [
      "Akis Linardos",
      "Matthias K\u00fcmmerer",
      "Ori Press",
      "Matthias Bethge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.00647",
    "title": "Mapping the NFT revolution: market trends, trade networks and visual  features",
    "abstract": " Comments: Working paper, comments welcome ",
    "url": "https://arxiv.org/abs/2106.00647",
    "authors": [
      "Matthieu Nadini",
      "Laura Alessandretti",
      "Flavio Di Giacinto",
      "Mauro Martino",
      "Luca Maria Aiello",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2109.01451",
    "title": "Impact of GPU uncertainty on the training of predictive deep neural  networks",
    "abstract": " Title: Impact of GPU uncertainty on the training of predictive deep neural  networks ",
    "url": "https://arxiv.org/abs/2109.01451",
    "authors": [
      "Maciej Pietrowski",
      "Andrzej Gajda",
      "Takuto Yamamoto",
      "Taisuke Kobayashi",
      "Lana Sinapayen",
      "Eiji Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2109.01761",
    "title": "An empirical evaluation of attention-based multi-head models for  improved turbofan engine remaining useful life prediction",
    "abstract": " Comments: 32 pages, 13 figures, 8 tables, typos fixed ",
    "url": "https://arxiv.org/abs/2109.01761",
    "authors": [
      "Abiodun Ayodeji",
      "Wenhai Wang",
      "Jianzhong Su",
      "Jianquan Yuan",
      "Xinggao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.03697",
    "title": "U-FNO -- an enhanced Fourier neural operator based-deep learning model  for multiphase flow",
    "abstract": " Title: U-FNO -- an enhanced Fourier neural operator based-deep learning model  for multiphase flow ",
    "url": "https://arxiv.org/abs/2109.03697",
    "authors": [
      "Gege Wen",
      "Zongyi Li",
      "Kamyar Azizzadenesheli",
      "Anima Anandkumar",
      "Sally M. Benson"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.05664",
    "title": "Unsupervised domain adaptation for cross-modality liver segmentation via  joint adversarial learning and self-learning",
    "abstract": " Title: Unsupervised domain adaptation for cross-modality liver segmentation via  joint adversarial learning and self-learning ",
    "url": "https://arxiv.org/abs/2109.05664",
    "authors": [
      "Jin Hong",
      "Simon Chun-Ho Yu",
      "Weitian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  }
]