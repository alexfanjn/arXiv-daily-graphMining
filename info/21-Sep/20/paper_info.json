[
  {
    "id": "arXiv:2109.08215",
    "title": "Automatic prior selection for meta Bayesian optimization with a case  study on tuning deep neural network optimizers",
    "abstract": "The performance of deep neural networks can be highly sensitive to the choice of a variety of meta-parameters, such as optimizer parameters and model hyperparameters. Tuning these well, however, often requires extensive and costly experimentation. Bayesian optimization (BO) is a principled approach to solve such expensive hyperparameter tuning problems efficiently. Key to the performance of BO is specifying and refining a distribution over functions, which is used to reason about the optima of the underlying function being optimized. In this work, we consider the scenario where we have data from similar functions that allows us to specify a tighter distribution a priori. Specifically, we focus on the common but potentially costly task of tuning optimizer parameters for training neural networks. Building on the meta BO method from Wang et al. (2018), we develop practical improvements that (a) boost its performance by leveraging tuning results on multiple tasks without requiring observations for the same meta-parameter points across all tasks, and (b) retain its regret bound for a special case of our method. As a result, we provide a coherent BO solution for iterative optimization of continuous optimizer parameters. To verify our approach in realistic model training setups, we collected a large multi-task hyperparameter tuning dataset by training tens of thousands of configurations of near-state-of-the-art models on popular image and text datasets, as well as a protein sequence dataset. Our results show that on average, our method is able to locate good hyperparameters at least 3 times more efficiently than the best competing methods. ",
    "url": "https://arxiv.org/abs/2109.08215",
    "authors": [
      "Zi Wang",
      "George E. Dahl",
      "Kevin Swersky",
      "Chansoo Lee",
      "Zelda Mariet",
      "Zack Nado",
      "Justin Gilmer",
      "Jasper Snoek",
      "Zoubin Ghahramani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.08239",
    "title": "A computationally efficient framework for vector representation of  persistence diagrams",
    "abstract": "In Topological Data Analysis, a common way of quantifying the shape of data is to use a persistence diagram (PD). PDs are multisets of points in $\\mathbb{R}^2$ computed using tools of algebraic topology. However, this multi-set structure limits the utility of PDs in applications. Therefore, in recent years efforts have been directed towards extracting informative and efficient summaries from PDs to broaden the scope of their use for machine learning tasks. We propose a computationally efficient framework to convert a PD into a vector in $\\mathbb{R}^n$, called a vectorized persistence block (VPB). We show that our representation possesses many of the desired properties of vector-based summaries such as stability with respect to input noise, low computational cost and flexibility. Through simulation studies, we demonstrate the effectiveness of VPBs in terms of performance and computational cost within various learning tasks, namely clustering, classification and change point detection. ",
    "url": "https://arxiv.org/abs/2109.08239",
    "authors": [
      "Kit C. Chan",
      "Umar Islambekov",
      "Alexey Luchinsky",
      "Rebecca Sanders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2109.08247",
    "title": "Towards agricultural autonomy: crop row detection under varying field  conditions using deep learning",
    "abstract": "This paper presents a novel metric to evaluate the robustness of deep learning based semantic segmentation approaches for crop row detection under different field conditions encountered by a field robot. A dataset with ten main categories encountered under various field conditions was used for testing. The effect on these conditions on the angular accuracy of crop row detection was compared. A deep convolutional encoder decoder network is implemented to predict crop row masks using RGB input images. The predicted mask is then sent to a post processing algorithm to extract the crop rows. The deep learning model was found to be robust against shadows and growth stages of the crop while the performance was reduced under direct sunlight, increasing weed density, tramlines and discontinuities in crop rows when evaluated with the novel metric. ",
    "url": "https://arxiv.org/abs/2109.08247",
    "authors": [
      "Rajitha de Silva",
      "Grzegorz Cielniak",
      "Junfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.08527",
    "title": "An open GPS trajectory dataset and benchmark for travel mode detection",
    "abstract": "Travel mode detection has been a hot topic in the field of GPS trajectory-related processing. Former scholars have developed many mathematical methods to improve the accuracy of detection. Among these studies, almost all of the methods require ground truth dataset for training. A large amount of the studies choose to collect the GPS trajectory dataset for training by their customized ways. Currently, there is no open GPS dataset marked with travel mode. If there exists one, it will not only save a lot of efforts in model developing, but also help compare the performance of models. In this study, we propose and open GPS trajectory dataset marked with travel mode and benchmark for the travel mode detection. The dataset is collected by 7 independent volunteers in Japan and covers the time period of a complete month. The travel mode ranges from walking to railway. A part of routines are traveled repeatedly in different time slots to experience different road and travel conditions. We also provide a case study to distinguish the walking and bike trips in a massive GPS trajectory dataset. ",
    "url": "https://arxiv.org/abs/2109.08527",
    "authors": [
      "Jinyu Chen",
      "Haoran Zhang",
      "Xuan Song",
      "Ryosuke Shibasaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2109.08479",
    "title": "CardiSort: a convolutional neural network for cross vendor automated  sorting of cardiac MR images",
    "abstract": "Objectives: To develop an image-based automatic deep learning method to classify cardiac MR images by sequence type and imaging plane for improved clinical post-processing efficiency. Methods: Multi-vendor cardiac MRI studies were retrospectively collected from 4 centres and 3 vendors. A two-head convolutional neural network ('CardiSort') was trained to classify 35 sequences by imaging sequence (n=17) and plane (n=10). Single vendor training (SVT) on single centre images (n=234 patients) and multi-vendor training (MVT) with multicentre images (n = 479 patients, 3 centres) was performed. Model accuracy was compared to manual ground truth labels by an expert radiologist on a hold-out test set for both SVT and MVT. External validation of MVT (MVTexternal) was performed on data from 3 previously unseen magnet systems from 2 vendors (n=80 patients). Results: High sequence and plane accuracies were observed for SVT (85.2% and 93.2% respectively), and MVT (96.5% and 98.1% respectively) on the hold-out test set. MVTexternal yielded sequence accuracy of 92.7% and plane accuracy of 93.0%. There was high accuracy for common sequences and conventional cardiac planes. Poor accuracy was observed for underrepresented classes and sequences where there was greater variability in acquisition parameters across centres, such as perfusion imaging. Conclusions: A deep learning network was developed on multivendor data to classify MRI studies into component sequences and planes, with external validation. With refinement, it has potential to improve workflow by enabling automated sequence selection, an important first step in completely automated post-processing pipelines. ",
    "url": "https://arxiv.org/abs/2109.08479",
    "authors": [
      "Ruth P Lim",
      "Stefan Kachel",
      "Adriana DM Villa",
      "Leighton Kearney",
      "Nuno Bettencourt",
      "Alistair A Young",
      "Amedeo Chiribiri",
      "Cian M Scannell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2006.05470",
    "title": "Standardised convolutional filtering for radiomics",
    "abstract": " Comments: 61 pages. For additional information see this https URL Changes in v4: * See document. Changes in v3: * Clarified how to scale Laplacian-of-Gaussian filter kernels. * Added 2D filter tests. Changes in v2: * Clarified how to reach rotational invariance for convolutional filtering. * Reworked description of Simoncelli filter. * Added intended filter dimensionality as a test parameter ",
    "url": "https://arxiv.org/abs/2006.05470",
    "authors": [
      "Adrien Depeursinge",
      "Vincent Andrearczyk",
      "Philip Whybra",
      "Joost van Griethuysen",
      "Henning M\u00fcller",
      "Roger Schaer",
      "Martin Valli\u00e8res",
      "Alex Zwanenburg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2011.06923",
    "title": "LEAN: graph-based pruning for convolutional neural networks by  extracting longest chains",
    "abstract": " Comments: 10 pages + 2 pages references. Code is publicly available at: this https URL ",
    "url": "https://arxiv.org/abs/2011.06923",
    "authors": [
      "Richard Schoonhoven",
      "Allard A. Hendriksen",
      "Dani\u00ebl M. Pelt",
      "K. Joost Batenburg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2101.03170",
    "title": "BDNNSurv: Bayesian deep neural networks for survival analysis using  pseudo values",
    "abstract": " Title: BDNNSurv: Bayesian deep neural networks for survival analysis using  pseudo values ",
    "url": "https://arxiv.org/abs/2101.03170",
    "authors": [
      "Dai Feng",
      "Lili Zhao"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.08497",
    "title": "GKNet: grasp keypoint network for grasp candidates detection",
    "abstract": " Comments: 25 pages, 12 figures, 13 tables ",
    "url": "https://arxiv.org/abs/2106.08497",
    "authors": [
      "Ruinian Xu",
      "Fu-Jen Chu",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.07623",
    "title": "Correlation detection in trees for partial graph alignment",
    "abstract": " Comments: 32 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2107.07623",
    "authors": [
      "Luca Ganassali",
      "Laurent Massouli\u00e9",
      "Marc Lelarge"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.07277",
    "title": "Photon detection probability prediction using one-dimensional generative  neural network",
    "abstract": " Title: Photon detection probability prediction using one-dimensional generative  neural network ",
    "url": "https://arxiv.org/abs/2109.07277",
    "authors": [
      "Wei Mu",
      "Alexander I. Himmel",
      "Bryan Ramson"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  }
]