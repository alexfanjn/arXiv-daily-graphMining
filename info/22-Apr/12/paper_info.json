[
  {
    "id": "arXiv:2204.04213",
    "title": "Structure-aware Protein Self-supervised Learning",
    "abstract": "Protein representation learning methods have shown great potential to yield useful representation for many downstream tasks, especially on protein classification. Moreover, a few recent studies have shown great promise in addressing insufficient labels of proteins with self-supervised learning methods. However, existing protein language models are usually pretrained on protein sequences without considering the important protein structural information. To this end, we propose a novel structure-aware protein self-supervised learning method to effectively capture structural information of proteins. In particular, a well-designed graph neural network (GNN) model is pretrained to preserve the protein structural information with self-supervised tasks from a pairwise residue distance perspective and a dihedral angle perspective, respectively. Furthermore, we propose to leverage the available protein language model pretrained on protein sequences to enhance the self-supervised learning. Specifically, we identify the relation between the sequential information in the protein language model and the structural information in the specially designed GNN model via a novel pseudo bi-level optimization scheme. Experiments on several supervised downstream tasks verify the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2204.04213",
    "authors": [
      "Can Chen",
      "Jingbo Zhou",
      "Fan Wang",
      "Xue Liu",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2204.04236",
    "title": "ChildCI Framework: Analysis of Motor and Cognitive Development in  Children-Computer Interaction for Age Detection",
    "abstract": "This article presents a comprehensive analysis of the different tests proposed in the recent ChildCI framework, proving its potential for generating a better understanding of children's neuromotor and cognitive development along time, as well as their possible application in other research areas such as e-Health and e-Learning. In particular, we propose a set of over 100 global features related to motor and cognitive aspects of the children interaction with mobile devices, some of them collected and adapted from the literature. Furthermore, we analyse the robustness and discriminative power of the proposed feature set including experimental results for the task of children age group detection based on their motor and cognitive behaviors. Two different scenarios are considered in this study: i) single-test scenario, and ii) multiple-test scenario. Results over 93% accuracy are achieved using the publicly available ChildCIdb_v1 database (over 400 children from 18 months to 8 years old), proving the high correlation of children's age with the way they interact with mobile devices. ",
    "url": "https://arxiv.org/abs/2204.04236",
    "authors": [
      "Juan Carlos Ruiz-Garcia",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Jaime Herreros-Rodriguez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04240",
    "title": "Controlling Traffic with Humanoid Social Robot",
    "abstract": "The advancement of technology such as artificial intelligence, machine learning and internet of things it became easy to develop more humanoid robots and automate different processes. An interactive robot must have high social behavior so that it can be easily accepted by the people using it. In this study we designed a traffic police robot (TRAPROB) to automate the traffic control at intersection. The human police officer experiences high stress because of long duty hours as well as pose the risk of accidents. The digital electronic signals are automatic but we want to create a system which is more human like and looks like an officer controlling the traffic at intersection. We used Thiago++ robot in this study and modified its look to like a police officer, and then programmed it to imitate and make gestures just like traffic police officer makes gestures for controlling traffic. We evaluated the looks, gestures, functionality, and social behavior of the robot. We asked a limited sample of two participants to identify the TRAPBOT, rate its look, the social behaviors and gestures in comparison to a real life police officer. we found that people can identify the robot as traffic police robot. Our analysis also shows that TRAPBOT has appearance like a traffic robot and can make similar signal gestures as a traffic police officer. ",
    "url": "https://arxiv.org/abs/2204.04240",
    "authors": [
      "Faisal Ghaffar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2204.04242",
    "title": "Exploiting complex pattern features for interactive pattern mining",
    "abstract": "Recent years have seen a shift from a pattern mining process that has users define constraints before-hand, and sift through the results afterwards, to an interactive one. This new framework depends on exploiting user feedback to learn a quality function for patterns. Existing approaches have a weakness in that they use static pre-defined low-level features, and attempt to learn independent weights representing their importance to the user. As an alternative, we propose to work with more complex features that are derived directly from the pattern ranking imposed by the user. Learned weights are then aggregated onto lower-level features and help to drive the quality function in the right direction. We explore the effect of different parameter choices experimentally and find that using higher-complexity features leads to the selection of patterns that are better aligned with a hidden quality function while not adding significantly to the run times of the method. Getting good user feedback requires to quickly present diverse patterns, something that we achieve but pushing an existing diversity constraint into the sampling component of the interactive mining system LetSip. Resulting patterns allow in most cases to converge to a good solution more quickly. Combining the two improvements, finally, leads to an algorithm showing clear advantages over the existing state-of-the-art. ",
    "url": "https://arxiv.org/abs/2204.04242",
    "authors": [
      "Arnold Hien",
      "Samir Loudni",
      "Noureddine Aribi",
      "Abdelkader Ouali",
      "Albrecht Zimmermann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04245",
    "title": "Online Emotions During the Storming of the U.S. Capitol: Evidence from  the Social Media Network Parler",
    "abstract": "The storming of the U.S. Capitol on January 6, 2021 has led to the killing of 5 people and is widely regarded as an attack on democracy. The storming was largely coordinated through social media networks such as Twitter and \"Parler\". Yet little is known regarding how users interacted on Parler during the storming of the Capitol. In this work, we examine the emotion dynamics on Parler during the storming with regard to heterogeneity across time and users. For this, we segment the user base into different groups (e.g., Trump supporters and QAnon supporters). We use affective computing to infer the emotions in content, thereby allowing us to provide a comprehensive assessment of online emotions. Our evaluation is based on a large-scale dataset from Parler, comprising of 717,300 posts from 144,003 users. We find that the user base responded to the storming of the Capitol with an overall negative sentiment. Akin to this, Trump supporters also expressed a negative sentiment and high levels of unbelief. In contrast to that, QAnon supporters did not express a more negative sentiment during the storming. We further provide a cross-platform analysis and compare the emotion dynamics on Parler and Twitter. Our findings point at a comparatively less negative response to the incidents on Parler compared to Twitter accompanied by higher levels of disapproval and outrage. Our contribution to research is three-fold: (1) We identify online emotions that were characteristic of the storming; (2) we assess emotion dynamics across different user groups on Parler; (3) we compare the emotion dynamics on Parler and Twitter. Thereby, our work offers important implications for actively managing online emotions to prevent similar incidents in the future. ",
    "url": "https://arxiv.org/abs/2204.04245",
    "authors": [
      "Johannes Jakubik",
      "Michael V\u00f6ssing",
      "Dominik B\u00e4r",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.04247",
    "title": "Clone Detection on Large Scala Codebases",
    "abstract": "Code clones are identical or similar code segments. The wide existence of code clones can increase the cost of maintenance and jeopardise the quality of software. The research community has developed many techniques to detect code clones, however, there is little evidence of how these techniques may perform in industrial use cases. In this paper, we aim to uncover the differences when such techniques are applied in industrial use cases. We conducted large scale experimental research on the performance of two state-of-the-art code clone detection techniques, SourcererCC and AutoenCODE, on both open source projects and an industrial project written in the Scala language. Our results reveal that both algorithms perform differently on the industrial project, with the largest drop in precision being 30.7\\%, and the largest increase in recall being 32.4\\%. By manually labelling samples of the industrial project by its developers, we discovered that there are substantially less Type-3 clones in the aforementioned project than that in the open source projects. ",
    "url": "https://arxiv.org/abs/2204.04247",
    "authors": [
      "Wahidur Rahman",
      "Yisen Xu",
      "Fan Pu",
      "Jifeng Xuan",
      "Xiangyang Jia",
      "Michail Basios",
      "Leslie Kanthan",
      "Lingbo Li",
      "Fan Wu",
      "Baowen Xu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.04254",
    "title": "HBFL: A Hierarchical Blockchain-based Federated Learning Framework for a  Collaborative IoT Intrusion Detection",
    "abstract": "The continuous strengthening of the security posture of IoT ecosystems is vital due to the increasing number of interconnected devices and the volume of sensitive data shared. The utilisation of Machine Learning (ML) capabilities in the defence against IoT cyber attacks has many potential benefits. However, the currently proposed frameworks do not consider data privacy, secure architectures, and/or scalable deployments of IoT ecosystems. In this paper, we propose a hierarchical blockchain-based federated learning framework to enable secure and privacy-preserved collaborative IoT intrusion detection. We highlight and demonstrate the importance of sharing cyber threat intelligence among inter-organisational IoT networks to improve the model's detection capabilities. The proposed ML-based intrusion detection framework follows a hierarchical federated learning architecture to ensure the privacy of the learning process and organisational data. The transactions (model updates) and processes will run on a secure immutable ledger, and the conformance of executed tasks will be verified by the smart contract. We have tested our solution and demonstrated its feasibility by implementing it and evaluating the intrusion detection performance using a key IoT data set. The outcome is a securely designed ML-based intrusion detection system capable of detecting a wide range of malicious activities while preserving data privacy. ",
    "url": "https://arxiv.org/abs/2204.04254",
    "authors": [
      "Mohanad Sarhan",
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.04259",
    "title": "Evaluating the Adversarial Robustness for Fourier Neural Operators",
    "abstract": "In recent years, Machine-Learning (ML)-driven approaches have been widely used in scientific discovery domains. Among them, the Fourier Neural Operator (FNO) was the first to simulate turbulent flow with zero-shot super-resolution and superior accuracy, which significantly improves the speed when compared to traditional partial differential equation (PDE) solvers. To inspect the trustworthiness, we provide the first study on the adversarial robustness of scientific discovery models by generating adversarial examples for FNO, based on norm-bounded data input perturbations. Evaluated on the mean squared error between the FNO model's output and the PDE solver's output, our results show that the model's robustness degrades rapidly with increasing perturbation levels, particularly in non-simplistic cases like the 2D Darcy and the Navier cases. Our research provides a sensitivity analysis tool and evaluation principles for assessing the adversarial robustness of ML-based scientific discovery models. ",
    "url": "https://arxiv.org/abs/2204.04259",
    "authors": [
      "Abolaji D. Adesoji",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04301",
    "title": "Preliminary Results on Using Abstract AND-OR Graphs for Generalized  Solving of Stochastic Shortest Path Problems",
    "abstract": "Several goal-oriented problems in the real-world can be naturally expressed as Stochastic Shortest Path Problems (SSPs). However, a key difficulty for computing solutions for problems in the SSP framework is that the computational requirements often make finding solutions to even moderately sized problems intractable. Solutions to many of such problems can often be expressed as generalized policies that are quite easy to compute from small examples and are readily applicable to problems with a larger number of objects and/or different object names. In this paper, we provide a preliminary study on using canonical abstractions to compute such generalized policies and represent them as AND-OR graphs that translate to simple non-deterministic, memoryless controllers. Such policy structures naturally lend themselves to a hierarchical approach for solving problems and we show that our approach can be embedded in any SSP solver to compute hierarchically optimal policies. We conducted an empirical evaluation on some well-known planning benchmarks and difficult robotics domains and show that our approach is promising, often computing optimal policies significantly faster than state-of-art SSP solvers. ",
    "url": "https://arxiv.org/abs/2204.04301",
    "authors": [
      "Rushang Karia",
      "Rashmeet Kaur Nayyar",
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04329",
    "title": "An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks",
    "abstract": "With the surge of Machine Learning (ML), An emerging amount of intelligent applications have been developed. Deep Neural Networks (DNNs) have demonstrated unprecedented performance across various fields such as medical diagnosis and autonomous driving. While DNNs are widely employed in security-sensitive fields, they are identified to be vulnerable to Neural Trojan (NT) attacks that are controlled and activated by stealthy triggers. In this paper, we target to design a robust and adaptive Trojan detection scheme that inspects whether a pre-trained model has been Trojaned before its deployment. Prior works are oblivious of the intrinsic property of trigger distribution and try to reconstruct the trigger pattern using simple heuristics, i.e., stimulating the given model to incorrect outputs. As a result, their detection time and effectiveness are limited. We leverage the observation that the pixel trigger typically features spatial dependency and propose the first trigger approximation based black-box Trojan detection framework that enables a fast and scalable search of the trigger in the input space. Furthermore, our approach can also detect Trojans embedded in the feature space where certain filter transformations are used to activate the Trojan. We perform extensive experiments to investigate the performance of our approach across various datasets and ML models. Empirical results show that our approach achieves a ROC-AUC score of 0.93 on the public TrojAI dataset. Our code can be found at https://github.com/xinqiaozhang/adatrojan ",
    "url": "https://arxiv.org/abs/2204.04329",
    "authors": [
      "Xinqiao Zhang",
      "Huili Chen",
      "Ke Huang",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04332",
    "title": "Fundamental Limits on Detection With a Dual-function Radar Communication  System",
    "abstract": "This paper investigates the fundamental limits on the target detection performance with a dual-function multiple-input-multiple-output (MIMO) radar communication (RadCom) systems. By assuming the presence of a point-like target and a communication receiver, closed-form expressions for the maximum detection probability and the transmit waveforms achieving the optimal performance are derived. Results show that for the considered case, the dual-function system should transmit coherent waveforms to achieve the optimal detection performance. Moreover, the angle separation between the target and communication receiver has a great impact on the achievable detection performance. ",
    "url": "https://arxiv.org/abs/2204.04332",
    "authors": [
      "Bo Tang",
      "Zhongrui Huang",
      "Lilong Qin",
      "Hai Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.04338",
    "title": "Fuzzy temporal convolutional neural networks in P300-based  Brain-computer interface for smart home interaction",
    "abstract": "The processing and classification of electroencephalographic signals (EEG) are increasingly performed using deep learning frameworks, such as convolutional neural networks (CNNs), to generate abstract features from brain data, automatically paving the way for remarkable classification prowess. However, EEG patterns exhibit high variability across time and uncertainty due to noise. It is a significant problem to be addressed in P300-based Brain Computer Interface (BCI) for smart home interaction. It operates in a non-optimal natural environment where added noise is often present. In this work, we propose a sequential unification of temporal convolutional networks (TCNs) modified to EEG signals, LSTM cells, with a fuzzy neural block (FNB), which we called EEG-TCFNet. Fuzzy components may enable a higher tolerance to noisy conditions. We applied three different architectures comparing the effect of using block FNB to classify a P300 wave to build a BCI for smart home interaction with healthy and post-stroke individuals. Our results reported a maximum classification accuracy of 98.6% and 74.3% using the proposed method of EEG-TCFNet in subject-dependent strategy and subject-independent strategy, respectively. Overall, FNB usage in all three CNN topologies outperformed those without FNB. In addition, we compared the addition of FNB to other state-of-the-art methods and obtained higher classification accuracies on account of the integration with FNB. The remarkable performance of the proposed model, EEG-TCFNet, and the general integration of fuzzy units to other classifiers would pave the way for enhanced P300-based BCIs for smart home interaction within natural settings. ",
    "url": "https://arxiv.org/abs/2204.04338",
    "authors": [
      "Christian Flores Vega",
      "Jonathan Quevedo",
      "Elmer Escand\u00f3n",
      "Mehrin Kiani",
      "Weiping Ding",
      "Javier Andreu-Perez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2204.04344",
    "title": "Towards Better Chinese-centric Neural Machine Translation for  Low-resource Languages",
    "abstract": "The last decade has witnessed enormous improvements in science and technology, stimulating the growing demand for economic and cultural exchanges in various countries. Building a neural machine translation (NMT) system has become an urgent trend, especially in the low-resource setting. However, recent work tends to study NMT systems for low-resource languages centered on English, while few works focus on low-resource NMT systems centered on other languages such as Chinese. To achieve this, the low-resource multilingual translation challenge of the 2021 iFLYTEK AI Developer Competition provides the Chinese-centric multilingual low-resource NMT tasks, where participants are required to build NMT systems based on the provided low-resource samples. In this paper, we present the winner competition system that leverages monolingual word embeddings data enhancement, bilingual curriculum learning, and contrastive re-ranking. In addition, a new Incomplete-Trust (In-trust) loss function is proposed to replace the traditional cross-entropy loss when training. The experimental results demonstrate that the implementation of these ideas leads better performance than other state-of-the-art methods. All the experimental codes are released at: https://github.com/WENGSYX/Low-resource-text-translation. ",
    "url": "https://arxiv.org/abs/2204.04344",
    "authors": [
      "Bin Li",
      "Yixuan Weng",
      "Fei Xia",
      "Hanjun Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04360",
    "title": "Data Augmentation for Electrocardiograms",
    "abstract": "Neural network models have demonstrated impressive performance in predicting pathologies and outcomes from the 12-lead electrocardiogram (ECG). However, these models often need to be trained with large, labelled datasets, which are not available for many predictive tasks of interest. In this work, we perform an empirical study examining whether training time data augmentation methods can be used to improve performance on such data-scarce ECG prediction problems. We investigate how data augmentation strategies impact model performance when detecting cardiac abnormalities from the ECG. Motivated by our finding that the effectiveness of existing augmentation strategies is highly task-dependent, we introduce a new method, TaskAug, which defines a flexible augmentation policy that is optimized on a per-task basis. We outline an efficient learning algorithm to do so that leverages recent work in nested optimization and implicit differentiation. In experiments, considering three datasets and eight predictive tasks, we find that TaskAug is competitive with or improves on prior work, and the learned policies shed light on what transformations are most effective for different tasks. We distill key insights from our experimental evaluation, generating a set of best practices for applying data augmentation to ECG prediction problems. ",
    "url": "https://arxiv.org/abs/2204.04360",
    "authors": [
      "Aniruddh Raghu",
      "Divya Shanmugam",
      "Eugene Pomerantsev",
      "John Guttag",
      "Collin M. Stultz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04363",
    "title": "Attention guided global enhancement and local refinement network for  semantic segmentation",
    "abstract": "The encoder-decoder architecture is widely used as a lightweight semantic segmentation network. However, it struggles with a limited performance compared to a well-designed Dilated-FCN model for two major problems. First, commonly used upsampling methods in the decoder such as interpolation and deconvolution suffer from a local receptive field, unable to encode global contexts. Second, low-level features may bring noises to the network decoder through skip connections for the inadequacy of semantic concepts in early encoder layers. To tackle these challenges, a Global Enhancement Method is proposed to aggregate global information from high-level feature maps and adaptively distribute them to different decoder layers, alleviating the shortage of global contexts in the upsampling process. Besides, a Local Refinement Module is developed by utilizing the decoder features as the semantic guidance to refine the noisy encoder features before the fusion of these two (the decoder features and the encoder features). Then, the two methods are integrated into a Context Fusion Block, and based on that, a novel Attention guided Global enhancement and Local refinement Network (AGLN) is elaborately designed. Extensive experiments on PASCAL Context, ADE20K, and PASCAL VOC 2012 datasets have demonstrated the effectiveness of the proposed approach. In particular, with a vanilla ResNet-101 backbone, AGLN achieves the state-of-the-art result (56.23% mean IoU) on the PASCAL Context dataset. The code is available at https://github.com/zhasen1996/AGLN. ",
    "url": "https://arxiv.org/abs/2204.04363",
    "authors": [
      "Jiangyun Li",
      "Sen Zha",
      "Chen Chen",
      "Meng Ding",
      "Tianxiang Zhang",
      "Hong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04371",
    "title": "Learning to Dispatch Multi-Server Jobs in Bipartite Graphs with Unknown  Service Rates",
    "abstract": "Multi-server jobs are imperative in modern cloud computing systems. A multi-server job has multiple components and requests multiple servers for being served. How to allocate restricted computing devices to jobs is a topic of great concern, which leads to the job scheduling and load balancing algorithms thriving. However, current job dispatching algorithms require the service rates to be changeless and knowable, which is difficult to realize in production systems. Besides, for multi-server jobs, the dispatching decision for each job component follows the All-or-Nothing property under service locality constraints and resource capacity limits, which is not well supported by mainstream algorithms. In this paper, we propose a dispatching algorithm for multi-server jobs that learns the unknown service rates and simultaneously maximizes the expected Accumulative Social Welfare (Asw). We formulate the Asw as the sum of utilities of jobs and servers achieved over each time slot. The utility of a job is proportional to the valuation for being served, which is mainly impacted by the fluctuating but unknown service rates. We maximize the Asw without knowing the exact valuations, but approximate them with exploration-exploitation. From this, we bring in several evolving statistics and maximize the statistical Asw with dynamic programming. The proposed algorithm is proved to have a polynomial complexity and a State-of-the-Art regret. We validate it with extensive simulations and the results show that the proposed algorithm outperforms several benchmark policies with improvements by up to 73%, 36%, and 28%, respectively. ",
    "url": "https://arxiv.org/abs/2204.04371",
    "authors": [
      "Hailiang Zhao",
      "Shuiguang Deng",
      "Feiyi Chen",
      "Jianwei Yin",
      "Schahram Dustdar",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.04380",
    "title": "A dataset of ant colonies motion trajectories in indoor and outdoor  scenes for social cluster behavior study",
    "abstract": "Motion and interaction of social insects (such as ants) have been studied by many researchers to understand the clustering mechanism. Most studies in the field of ant behavior have only focused on indoor environments, while outdoor environments are still underexplored. In this paper, we collect 10 videos of ant colonies from different indoor and outdoor scenes. And we develop an image sequence marking software named VisualMarkData, which enables us to provide annotations of ants in the video. In all 5354 frames, the location information and the identification number of each ant are recorded for a total of 712 ants and 114112 annotations. Moreover, we provide visual analysis tools to assess and validate the technical quality and reproducibility of our data. It is hoped that this dataset will contribute to a deeper exploration on the behavior of the ant colony. ",
    "url": "https://arxiv.org/abs/2204.04380",
    "authors": [
      "Meihong Wu",
      "Xiaoyan Cao",
      "Xiaoyu Cao",
      "Shihui Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04381",
    "title": "Harmonic Centralization of Some Graph Families",
    "abstract": "Centrality describes the importance of nodes in a graph and is modeled by various measures. Freeman's centralization, on the other hand, is a general method for calculating a graph-level centrality score based on a node-level centrality measure. The latter enables us to compare graphs based on the extent to which the connections of a given network are concentrated on a single vertex or group of vertices. One of the measures of centrality in social network analysis is harmonic centrality. It sums the inverse of the geodesic distances of each node to other nodes where it is 0 if there is no path from one node to another, with the sum normalized by dividing it by $m-1$, where $m$ is the number of nodes of the graph. In this paper, we present some results regarding the harmonic centralization of some important families of graphs with the hope that formulas generated herein will be of use when one determines the harmonic centralization of more complex graphs. ",
    "url": "https://arxiv.org/abs/2204.04381",
    "authors": [
      "Jose Mari E. Ortega",
      "Rolito G. Eballe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.04385",
    "title": "Divergence-aware Federated Self-Supervised Learning",
    "abstract": "Self-supervised learning (SSL) is capable of learning remarkable representations from centrally available data. Recent works further implement federated learning with SSL to learn from rapidly growing decentralized unlabeled images (e.g., from cameras and phones), often resulted from privacy constraints. Extensive attention has been paid to SSL approaches based on Siamese networks. However, such an effort has not yet revealed deep insights into various fundamental building blocks for the federated self-supervised learning (FedSSL) architecture. We aim to fill in this gap via in-depth empirical study and propose a new method to tackle the non-independently and identically distributed (non-IID) data problem of decentralized data. Firstly, we introduce a generalized FedSSL framework that embraces existing SSL methods based on Siamese networks and presents flexibility catering to future methods. In this framework, a server coordinates multiple clients to conduct SSL training and periodically updates local models of clients with the aggregated global model. Using the framework, our study uncovers unique insights of FedSSL: 1) stop-gradient operation, previously reported to be essential, is not always necessary in FedSSL; 2) retaining local knowledge of clients in FedSSL is particularly beneficial for non-IID data. Inspired by the insights, we then propose a new approach for model update, Federated Divergence-aware Exponential Moving Average update (FedEMA). FedEMA updates local models of clients adaptively using EMA of the global model, where the decay rate is dynamically measured by model divergence. Extensive experiments demonstrate that FedEMA outperforms existing methods by 3-4% on linear evaluation. We hope that this work will provide useful insights for future research. ",
    "url": "https://arxiv.org/abs/2204.04385",
    "authors": [
      "Weiming Zhuang",
      "Yonggang Wen",
      "Shuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.04390",
    "title": "Deep neural network goes lighter: A case study of deep compression  techniques on automatic RF modulation recognition for Beyond 5G networks",
    "abstract": "Automatic RF modulation recognition is a primary signal intelligence (SIGINT) technique that serves as a physical layer authentication enabler and automated signal processing scheme for the beyond 5G and military networks. Most existing works rely on adopting deep neural network architectures to enable RF modulation recognition. The application of deep compression for the wireless domain, especially automatic RF modulation classification, is still in its infancy. Lightweight neural networks are key to sustain edge computation capability on resource-constrained platforms. In this letter, we provide an in-depth view of the state-of-the-art deep compression and acceleration techniques with an emphasis on edge deployment for beyond 5G networks. Finally, we present an extensive analysis of the representative acceleration approaches as a case study on automatic radar modulation classification and evaluate them in terms of the computational metrics. ",
    "url": "https://arxiv.org/abs/2204.04390",
    "authors": [
      "Anu Jagannath",
      "Jithin Jagannath",
      "Yanzhi Wang",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04397",
    "title": "Denoising Neural Network for News Recommendation with Positive and  Negative Implicit Feedback",
    "abstract": "News recommendation is different from movie or e-commercial recommendation as people usually do not grade the news. Therefore, user feedback for news is always implicit (click behavior, reading time, etc). Inevitably, there are noises in implicit feedback. On one hand, the user may exit immediately after clicking the news as he dislikes the news content, leaving the noise in his positive implicit feedback; on the other hand, the user may be recommended multiple interesting news at the same time and only click one of them, producing the noise in his negative implicit feedback. Opposite implicit feedback could construct more integrated user preferences and help each other to minimize the noise influence. Previous works on news recommendation only used positive implicit feedback and suffered from the noise impact. In this paper, we propose a denoising neural network for news recommendation with positive and negative implicit feedback, named DRPN. DRPN utilizes both feedback for recommendation with a module to denoise both positive and negative implicit feedback to further enhance the performance. Experiments on the real-world large-scale dataset demonstrate the state-of-the-art performance of DRPN. ",
    "url": "https://arxiv.org/abs/2204.04397",
    "authors": [
      "Yunfan Hu",
      "Zhaopeng Qiu",
      "Xian Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04403",
    "title": "Improve Generalization of Driving Policy at Signalized Intersections  with Adversarial Learning",
    "abstract": "Intersections are quite challenging among various driving scenes wherein the interaction of signal lights and distinct traffic actors poses great difficulty to learn a wise and robust driving policy. Current research rarely considers the diversity of intersections and stochastic behaviors of traffic participants. For practical applications, the randomness usually leads to some devastating events, which should be the focus of autonomous driving. This paper introduces an adversarial learning paradigm to boost the intelligence and robustness of driving policy for signalized intersections with dense traffic flow. Firstly, we design a static path planner which is capable of generating trackable candidate paths for multiple intersections with diversified topology. Next, a constrained optimal control problem (COCP) is built based on these candidate paths wherein the bounded uncertainty of dynamic models is considered to capture the randomness of driving environment. We propose adversarial policy gradient (APG) to solve the COCP wherein the adversarial policy is introduced to provide disturbances by seeking the most severe uncertainty while the driving policy learns to handle this situation by competition. Finally, a comprehensive system is established to conduct training and testing wherein the perception module is introduced and the human experience is incorporated to solve the yellow light dilemma. Experiments indicate that the trained policy can handle the signal lights flexibly meanwhile realizing the smooth and efficient passing with a humanoid paradigm. Besides, APG enables a large-margin improvement of the resistance to the abnormal behaviors and thus ensures a high safety level for the autonomous vehicle. ",
    "url": "https://arxiv.org/abs/2204.04403",
    "authors": [
      "Yangang Ren",
      "Guojian Zhan",
      "Liye Tang",
      "Shengbo Eben Li",
      "Jianhua Jiang",
      "Jingliang Duan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.04415",
    "title": "Robust Dynamic Average Consensus for a Network of Agents with  Time-varying Reference Signals",
    "abstract": "This paper presents continuous dynamic average consensus (DAC) algorithms for a group of agents to estimate the average of their time-varying reference signals cooperatively. We propose consensus algorithms that are robust to agents joining and leaving the network, at the same time, avoid the chattering phenomena and guarantee zero steady-state consensus error. Our algorithms are edge-based protocols with smooth functions in their internal structure to avoid the chattering effect. Furthermore, each agent is only capable of performing local computations and can only communicate with its local neighbors. For a balanced and strongly connected underlying communication graph, we provide the convergence analysis to determine the consensus design parameters that guarantee the agents' estimate of their average to asymptotically converge to the average of the time-varying reference signals of the agents. We provide simulation results to validate the proposed consensus algorithms and to perform a performance comparison of the proposed algorithms to existing algorithms in the literature. ",
    "url": "https://arxiv.org/abs/2204.04415",
    "authors": [
      "Solomon Gudeta",
      "Ali Karimoddini",
      "Mohammadreza Davoodi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.04421",
    "title": "Unbiased Directed Object Attention Graph for Object Navigation",
    "abstract": "Object navigation tasks require agents to locate specific objects in unknown environments based on visual information. Previously, graph convolutions were used to implicitly explore the relationships between objects. However, due to differences in visibility among objects, it is easy to generate biases in object attention. Thus, in this paper, we propose a directed object attention (DOA) graph to guide the agent in explicitly learning the attention relationships between objects, thereby reducing the object attention bias. In particular, we use the DOA graph to perform unbiased adaptive object attention (UAOA) on the object features and unbiased adaptive image attention (UAIA) on the raw images, respectively. To distinguish features in different branches, a concise adaptive branch energy distribution (ABED) method is proposed. We assess our methods on the AI2-Thor dataset. Compared with the state-of-the-art (SOTA) method, our method reports 7.4%, 8.1% and 17.6% increase in success rate (SR), success weighted by path length (SPL) and success weighted by action efficiency (SAE), respectively. ",
    "url": "https://arxiv.org/abs/2204.04421",
    "authors": [
      "Ronghao Dang",
      "Zhuofan Shi",
      "Liuyi Wang",
      "Zongtao He",
      "Chengju Liu",
      "Qijun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04431",
    "title": "A Spiking Neural Network Structure Implementing Reinforcement Learning",
    "abstract": "At present, implementation of learning mechanisms in spiking neural networks (SNN) cannot be considered as a solved scientific problem despite plenty of SNN learning algorithms proposed. It is also true for SNN implementation of reinforcement learning (RL), while RL is especially important for SNNs because of its close relationship to the domains most promising from the viewpoint of SNN application such as robotics. In the present paper, I describe an SNN structure which, seemingly, can be used in wide range of RL tasks. The distinctive feature of my approach is usage of only the spike forms of all signals involved - sensory input streams, output signals sent to actuators and reward/punishment signals. Besides that, selecting the neuron/plasticity models, I was guided by the requirement that they should be easily implemented on modern neurochips. The SNN structure considered in the paper includes spiking neurons described by a generalization of the LIFAT (leaky integrate-and-fire neuron with adaptive threshold) model and a simple spike timing dependent synaptic plasticity model (a generalization of dopamine-modulated plasticity). My concept is based on very general assumptions about RL task characteristics and has no visible limitations on its applicability. To test it, I selected a simple but non-trivial task of training the network to keep a chaotically moving light spot in the view field of an emulated DVS camera. Successful solution of this RL problem by the SNN described can be considered as evidence in favor of efficiency of my approach. ",
    "url": "https://arxiv.org/abs/2204.04431",
    "authors": [
      "Mikhail Kiselev"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.04440",
    "title": "Are Two Heads the Same as One? Identifying Disparate Treatment in Fair  Neural Networks",
    "abstract": "We show that deep neural networks that satisfy demographic parity do so through a form of race or gender awareness, and that the more we force a network to be fair, the more accurately we can recover race or gender from the internal state of the network. Based on this observation, we propose a simple two-stage solution for enforcing fairness. First, we train a two-headed network to predict the protected attribute (such as race or gender) alongside the original task, and second, we enforce demographic parity by taking a weighted sum of the heads. In the end, this approach creates a single-headed network with the same backbone architecture as the original network. Our approach has near identical performance compared to existing regularization-based or preprocessing methods, but has greater stability and higher accuracy where near exact demographic parity is required. To cement the relationship between these two approaches, we show that an unfair and optimally accurate classifier can be recovered by taking a weighted sum of a fair classifier and a classifier predicting the protected attribute. We use this to argue that both the fairness approaches and our explicit formulation demonstrate disparate treatment and that, consequentially, they are likely to be unlawful in a wide range of scenarios under the US law. ",
    "url": "https://arxiv.org/abs/2204.04440",
    "authors": [
      "Michael Lohaus",
      "Matth\u00e4us Kleindessner",
      "Krishnaram Kenthapadi",
      "Francesco Locatello",
      "Chris Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04444",
    "title": "Path-Tree Optimization in Partially Observable Environments using  Rapidly-Exploring Belief-Space Graphs",
    "abstract": "Robots often need to solve path planning problems where essential and discrete aspects of the environment are partially observable. This introduces a multi-modality, where the robot must be able to observe and infer the state of its environment. To tackle this problem, we introduce the Path-Tree Optimization (PTO) algorithm which plans a path-tree in belief-space. A path-tree is a tree-like motion with branching points where the robot receives an observation leading to a belief-state update. The robot takes different branches depending on the observation received. The algorithm has three main steps. First, a rapidly-exploring random graph (RRG) on the state space is grown. Second, the RRG is expanded to a belief-space graph by querying the observation model. In a third step, dynamic programming is performed on the belief-space graph to extract a path-tree. The resulting path-tree combines exploration with exploitation i.e. it balances the need for gaining knowledge about the environment with the need for reaching the goal. We demonstrate the algorithm capabilities on navigation and mobile manipulation tasks, and show its advantage over a baseline using a task and motion planning approach (TAMP) both in terms of optimality and runtime. ",
    "url": "https://arxiv.org/abs/2204.04444",
    "authors": [
      "Camille Phiquepal",
      "Andreas Orthey",
      "Nicolas Viennot",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.04452",
    "title": "Yes, Topology Matters in Decentralized Optimization: Refined Convergence  and Topology Learning under Heterogeneous Data",
    "abstract": "One of the key challenges in federated and decentralized learning is to design algorithms that efficiently deal with highly heterogeneous data distributions across agents. In this paper, we revisit the analysis of Decentralized Stochastic Gradient Descent algorithm (D-SGD), a popular decentralized learning algorithm, under data heterogeneity. We exhibit the key role played by a new quantity, that we call neighborhood heterogeneity, on the convergence rate of D-SGD. Unlike prior work, neighborhood heterogeneity is measured at the level of the neighborhood of an agent in the graph topology. By coupling the topology and the heterogeneity of the agents' distributions, our analysis sheds light on the poorly understood interplay between these two concepts in decentralized learning. We then argue that neighborhood heterogeneity provides a natural criterion to learn sparse data-dependent topologies that reduce (and can even eliminate) the otherwise detrimental effect of data heterogeneity on the convergence time of D-SGD. For the important case of classification with label skew, we formulate the problem of learning such a good topology as a tractable optimization problem that we solve with a Frank-Wolfe algorithm. Our approach provides a principled way to design a sparse topology that balances the number of iterations and the per-iteration communication costs of D-SGD under data heterogeneity. ",
    "url": "https://arxiv.org/abs/2204.04452",
    "authors": [
      "B. Le Bars",
      "A. Bellet",
      "M. Tommasi",
      "AM. Kermarrec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.04458",
    "title": "Understanding, Detecting, and Separating Out-of-Distribution Samples and  Adversarial Samples in Text Classification",
    "abstract": "In this paper, we study the differences and commonalities between statistically out-of-distribution (OOD) samples and adversarial (Adv) samples, both of which hurting a text classification model's performance. We conduct analyses to compare the two types of anomalies (OOD and Adv samples) with the in-distribution (ID) ones from three aspects: the input features, the hidden representations in each layer of the model, and the output probability distributions of the classifier. We find that OOD samples expose their aberration starting from the first layer, while the abnormalities of Adv samples do not emerge until the deeper layers of the model. We also illustrate that the models' output probabilities for Adv samples tend to be more unconfident. Based on our observations, we propose a simple method to separate ID, OOD, and Adv samples using the hidden representations and output probabilities of the model. On multiple combinations of ID, OOD datasets, and Adv attacks, our proposed method shows exceptional results on distinguishing ID, OOD, and Adv samples. ",
    "url": "https://arxiv.org/abs/2204.04458",
    "authors": [
      "Cheng-Han Chiang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04462",
    "title": "A3CLNN: Spatial, Spectral and Multiscale Attention ConvLSTM Neural  Network for Multisource Remote Sensing Data Classification",
    "abstract": "The problem of effectively exploiting the information multiple data sources has become a relevant but challenging research topic in remote sensing. In this paper, we propose a new approach to exploit the complementarity of two data sources: hyperspectral images (HSIs) and light detection and ranging (LiDAR) data. Specifically, we develop a new dual-channel spatial, spectral and multiscale attention convolutional long short-term memory neural network (called dual-channel A3CLNN) for feature extraction and classification of multisource remote sensing data. Spatial, spectral and multiscale attention mechanisms are first designed for HSI and LiDAR data in order to learn spectral- and spatial-enhanced feature representations, and to represent multiscale information for different classes. In the designed fusion network, a novel composite attention learning mechanism (combined with a three-level fusion strategy) is used to fully integrate the features in these two data sources. Finally, inspired by the idea of transfer learning, a novel stepwise training strategy is designed to yield a final classification result. Our experimental results, conducted on several multisource remote sensing data sets, demonstrate that the newly proposed dual-channel A3CLNN exhibits better feature representation ability (leading to more competitive classification performance) than other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.04462",
    "authors": [
      "Heng-Chao Li",
      "Wen-Shuai Hu",
      "Wei Li",
      "Jun Li",
      "Qian Du",
      "Antonio Plaza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.04481",
    "title": "KUCST@LT-EDI-ACL2022: Detecting Signs of Depression from Social Media  Text",
    "abstract": "In this paper we present our approach for detecting signs of depression from social media text. Our model relies on word unigrams, part-of-speech tags, readabilitiy measures and the use of first, second or third person and the number of words. Our best model obtained a macro F1-score of 0.439 and ranked 25th, out of 31 teams. We further take advantage of the interpretability of the Logistic Regression model and we make an attempt to interpret the model coefficients with the hope that these will be useful for further research on the topic. ",
    "url": "https://arxiv.org/abs/2204.04481",
    "authors": [
      "Manex Agirrezabal",
      "Janek Amann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04489",
    "title": "ShorTor: Improving Tor Network Latency via Multi-hop Overlay Routing",
    "abstract": "We present ShorTor, a protocol for reducing latency on the Tor network. ShorTor uses multi-hop overlay routing, a technique typically employed by content delivery networks, to influence the route Tor traffic takes across the internet. ShorTor functions as an overlay on top of onion routing-Tor's existing routing protocol and is run by Tor relays, making it independent of the path selection performed by Tor clients. As such, ShorTor reduces latency while preserving Tor's existing security properties. Specifically, the routes taken in ShorTor are in no way correlated to either the Tor user or their destination, including the geographic location of either party. We analyze the security of ShorTor using the AnoA framework, showing that ShorTor maintains all of Tor's anonymity guarantees. We augment our theoretical claims with an empirical analysis. To evaluate ShorTor's performance, we collect a real-world dataset of over 400,000 latency measurements between the 1,000 most popular Tor relays, which collectively see the vast majority of Tor traffic. With this data, we identify pairs of relays that could benefit from ShorTor: that is, two relays where introducing an additional intermediate network hop results in lower latency than the direct route between them. We use our measurement dataset to simulate the impact on end users by applying ShorTor to two million Tor circuits chosen according to Tor's specification. ShorTor reduces the latency for the 99th percentile of relay pairs in Tor by 148 ms. Similarly, ShorTor reduces the latency of Tor circuits by 122 ms at the 99th percentile. In practice, this translates to ShorTor truncating tail latencies for Tor which has a direct impact on page load times and, consequently, user experience on the Tor browser. ",
    "url": "https://arxiv.org/abs/2204.04489",
    "authors": [
      "Kyle Hogan",
      "Sacha Servan-Schreiber",
      "Zachary Newman",
      "Ben Weintraub",
      "Cristina Nita-Rotaru",
      "Srinivas Devadas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.04492",
    "title": "S4OD: Semi-Supervised learning for Single-Stage Object Detection",
    "abstract": "Single-stage detectors suffer from extreme foreground-background class imbalance, while two-stage detectors do not. Therefore, in semi-supervised object detection, two-stage detectors can deliver remarkable performance by only selecting high-quality pseudo labels based on classification scores. However, directly applying this strategy to single-stage detectors would aggravate the class imbalance with fewer positive samples. Thus, single-stage detectors have to consider both quality and quantity of pseudo labels simultaneously. In this paper, we design a dynamic self-adaptive threshold (DSAT) strategy in classification branch, which can automatically select pseudo labels to achieve an optimal trade-off between quality and quantity. Besides, to assess the regression quality of pseudo labels in single-stage detectors, we propose a module to compute the regression uncertainty of boxes based on Non-Maximum Suppression. By leveraging only 10% labeled data from COCO, our method achieves 35.0% AP on anchor-free detector (FCOS) and 32.9% on anchor-based detector (RetinaNet). ",
    "url": "https://arxiv.org/abs/2204.04492",
    "authors": [
      "Yueming Zhang",
      "Xingxu Yao",
      "Chao Liu",
      "Feng Chen",
      "Xiaolin Song",
      "Tengfei Xing",
      "Runbo Hu",
      "Hua Chai",
      "Pengfei Xu",
      "Guoshan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04510",
    "title": "Efficient Representation Learning of Subgraphs by Subgraph-To-Node  Translation",
    "abstract": "A subgraph is a data structure that can represent various real-world problems. We propose Subgraph-To-Node (S2N) translation, which is a novel formulation to efficiently learn representations of subgraphs. Specifically, given a set of subgraphs in the global graph, we construct a new graph by coarsely transforming subgraphs into nodes. We perform subgraph-level tasks as node-level tasks through this translation. By doing so, we can significantly reduce the memory and computational costs in both training and inference. We conduct experiments on four real-world datasets to evaluate performance and efficiency. Our experiments demonstrate that models with S2N translation are more efficient than state-of-the-art models without substantial performance decrease. ",
    "url": "https://arxiv.org/abs/2204.04510",
    "authors": [
      "Dongkwan Kim",
      "Alice Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.04511",
    "title": "FuNNscope: Visual microscope for interactively exploring the loss  landscape of fully connected neural networks",
    "abstract": "Despite their effective use in various fields, many aspects of neural networks are poorly understood. One important way to investigate the characteristics of neural networks is to explore the loss landscape. However, most models produce a high-dimensional non-convex landscape which is difficult to visualize. We discuss and extend existing visualization methods based on 1D- and 2D slicing with a novel method that approximates the actual loss landscape geometry by using charts with interpretable axes. Based on the assumption that observations on small neural networks can generalize to more complex systems and provide us with helpful insights, we focus on small models in the range of a few dozen weights, which enables computationally cheap experiments and the use of an interactive dashboard. We observe symmetries around the zero vector, the influence of different layers on the global landscape, the different weight sensitivities around a minimizer, and how gradient descent navigates high-loss obstacles. The user study resulted in an average SUS (System Usability Scale) score with suggestions for improvement and opened up a number of possible application scenarios, such as autoencoders and ensemble networks. ",
    "url": "https://arxiv.org/abs/2204.04511",
    "authors": [
      "Aleksandar Doknic",
      "Torsten M\u00f6ller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04518",
    "title": "Attention U-Net as a surrogate model for groundwater prediction",
    "abstract": "Numerical simulations of groundwater flow are used to analyze and predict the response of an aquifer system to its change in state by approximating the solution of the fundamental groundwater physical equations. The most used and classical methodologies, such as Finite Difference (FD) and Finite Element (FE) Methods, use iterative solvers which are associated with high computational cost. This study proposes a physics-based convolutional encoder-decoder neural network as a surrogate model to quickly calculate the response of the groundwater system. Holding strong promise in cross-domain mappings, encoder-decoder networks are applicable for learning complex input-output mappings of physical systems. This manuscript presents an Attention U-Net model that attempts to capture the fundamental input-output relations of the groundwater system and generates solutions of hydraulic head in the whole domain given a set of physical parameters and boundary conditions. The model accurately predicts the steady state response of a highly heterogeneous groundwater system given the locations and piezometric head of up to 3 wells as input. The network learns to pay attention only in the relevant parts of the domain and the generated hydraulic head field corresponds to the target samples in great detail. Even relative to coarse finite difference approximations the proposed model is shown to be significantly faster than a comparative state-of-the-art numerical solver, thus providing a base for further development of the presented networks as surrogate models for groundwater prediction. ",
    "url": "https://arxiv.org/abs/2204.04518",
    "authors": [
      "Maria Luisa Taccari",
      "Jonathan Nuttall",
      "Xiaohui Chen",
      "He Wang",
      "Bennie Minnema",
      "Peter K.Jimack"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04521",
    "title": "Benchmarking for Public Health Surveillance tasks on Social Media with a  Domain-Specific Pretrained Language Model",
    "abstract": "A user-generated text on social media enables health workers to keep track of information, identify possible outbreaks, forecast disease trends, monitor emergency cases, and ascertain disease awareness and response to official health correspondence. This exchange of health information on social media has been regarded as an attempt to enhance public health surveillance (PHS). Despite its potential, the technology is still in its early stages and is not ready for widespread application. Advancements in pretrained language models (PLMs) have facilitated the development of several domain-specific PLMs and a variety of downstream applications. However, there are no PLMs for social media tasks involving PHS. We present and release PHS-BERT, a transformer-based PLM, to identify tasks related to public health surveillance on social media. We compared and benchmarked the performance of PHS-BERT on 25 datasets from different social medial platforms related to 7 different PHS tasks. Compared with existing PLMs that are mainly evaluated on limited tasks, PHS-BERT achieved state-of-the-art performance on all 25 tested datasets, showing that our PLM is robust and generalizable in the common PHS tasks. By making PHS-BERT available, we aim to facilitate the community to reduce the computational cost and introduce new baselines for future works across various PHS-related tasks. ",
    "url": "https://arxiv.org/abs/2204.04521",
    "authors": [
      "Usman Naseem",
      "Byoung Chan Lee",
      "Matloob Khushi",
      "Jinman Kim",
      "Adam G. Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04522",
    "title": "Knowledge-Free Black-Box Watermark and Ownership Proof for Image  Classification Neural Networks",
    "abstract": "Watermarking has become a plausible candidate for ownership verification and intellectual property protection of deep neural networks. Regarding image classification neural networks, current watermarking schemes uniformly resort to backdoor triggers. However, injecting a backdoor into a neural network requires knowledge of the training dataset, which is usually unavailable in the real-world commercialization. Meanwhile, established watermarking schemes oversight the potential damage of exposed evidence during ownership verification and the watermarking algorithms themselves. Those concerns decline current watermarking schemes from industrial applications. To confront these challenges, we propose a knowledge-free black-box watermarking scheme for image classification neural networks. The image generator obtained from a data-free distillation process is leveraged to stabilize the network's performance during the backdoor injection. A delicate encoding and verification protocol is designed to ensure the scheme's security against knowledgable adversaries. We also give a pioneering analysis of the capacity of the watermarking scheme. Experiment results proved the functionality-preserving capability and security of the proposed watermarking scheme. ",
    "url": "https://arxiv.org/abs/2204.04522",
    "authors": [
      "Fangqi Li",
      "Shilin Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2204.04545",
    "title": "Self-Labeling Refinement for Robust Representation Learning with  Bootstrap Your Own Latent",
    "abstract": "In this work, we have worked towards two major goals. Firstly, we have investigated the importance of Batch Normalisation (BN) layers in a non-contrastive representation learning framework called Bootstrap Your Own Latent (BYOL). We conducted several experiments to conclude that BN layers are not necessary for representation learning in BYOL. Moreover, BYOL only learns from the positive pairs of images but ignores other semantically similar images in the same input batch. For the second goal, we have introduced two new loss functions to determine the semantically similar pairs in the same input batch of images and reduce the distance between their representations. These loss functions are Cross-Cosine Similarity Loss (CCSL) and Cross-Sigmoid Similarity Loss (CSSL). Using the proposed loss functions, we are able to surpass the performance of Vanilla BYOL (71.04%) by training the BYOL framework using CCSL loss (76.87%) on the STL10 dataset. BYOL trained using CSSL loss performs comparably with Vanilla BYOL. ",
    "url": "https://arxiv.org/abs/2204.04545",
    "authors": [
      "Siddhant Garg",
      "Dhruval Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04558",
    "title": "Trajectory Optimization Using Neural Network Gradients of Learned  Dynamics",
    "abstract": "Trajectory optimization methods have achieved an exceptional level of performance on real-world robots in recent years. These methods heavily rely on accurate physics simulators, yet some aspects of the physical world, such as friction, can only be captured to a limited extent by most simulators. The goal of this paper is to leverage trajectory optimization for performing highly dynamic and complex tasks with robotic systems in absence of an accurate physics simulator. This is achieved by applying machine learning techniques to learn a differentiable dynamics model of the system from data. On the example of a RC car, we show that from data collected in only 15 minutes of human-operated interactions with the car, a neural network is able to model highly nonlinear behaviors such as loss of traction and drifting. Furthermore, we use the analytical gradients of the neural network to perform gradient-based trajectory optimization, both in an offline and online setting. We find that our learned model is able to represent complex physical behavior, like drifting and gives unprecedented performance in combination with trajectory optimization methods. ",
    "url": "https://arxiv.org/abs/2204.04558",
    "authors": [
      "Nathanael K\u00f6hler",
      "Bhavya Sukhija",
      "Miguel Zamora",
      "Simon Zimmermann",
      "Stelian Coros"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04576",
    "title": "Adaptable Plug and Play Security Operations Center Leveraging a Novel  Programmable Plugin-based Intrusion Detection and Prevention System",
    "abstract": "The number of cyber-attacks have substantially increased over the past decade resulting in huge organizational financial losses. Indeed, it is no longer a matter of \"if\" but \"when\" a security incident will take place. A Security Operations Center(SOC) adoption will help in the detection, identification, prevention, and resolution of issues before they end up causing extensive cyber-related damage. In this paper, our proposed framework is brought about to address the problem that current open-source SOC implementations are plagued with. These include lack of ability to be strengthened on the fly, slow development processes, and their ineptness for continuous timely updates. We, herein, propose a framework that would offer a fully automated open-source SOC deployment; otherwise dubbed, a \"plug-and-play framework\"; full horizontal scalability incorporating a modular architecture. These underpinning features are meant to mitigate underlying SOC challenges, which often emerge as a result of many pre-determined and repeated processes, bolstering their ability for expansion with new tools. This is on top of enhancing their ability to handle more servers in the clusters as a single logical unit. We also introduce a new system of its kind called a Programmable Plugin-based Intrusion Detection and Prevention System (PPIDPS). This system will extend a SOC's ability to add any tool to the monitored devices while collecting logs that can trigger alerts whenever a suspicious behavior is detected. ",
    "url": "https://arxiv.org/abs/2204.04576",
    "authors": [
      "Ahmed S. Shatnawi",
      "Basheer Al-Duwairi",
      "Mahmoud M. Almazari",
      "Mohammad S. Alshakhatreh",
      "Ahmad N. Khader",
      "Abdullah A. Abdullah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.04588",
    "title": "Robust Cross-Modal Representation Learning with Progressive  Self-Distillation",
    "abstract": "The learning objective of vision-language approach of CLIP does not effectively account for the noisy many-to-many correspondences found in web-harvested image captioning datasets, which contributes to its compute and data inefficiency. To address this challenge, we introduce a novel training framework based on cross-modal contrastive learning that uses progressive self-distillation and soft image-text alignments to more efficiently learn robust representations from noisy data. Our model distills its own knowledge to dynamically generate soft-alignment targets for a subset of images and captions in every minibatch, which are then used to update its parameters. Extensive evaluation across 14 benchmark datasets shows that our method consistently outperforms its CLIP counterpart in multiple settings, including: (a) zero-shot classification, (b) linear probe transfer, and (c) image-text retrieval, without incurring added computational cost. Analysis using an ImageNet-based robustness test-bed reveals that our method offers better effective robustness to natural distribution shifts compared to both ImageNet-trained models and CLIP itself. Lastly, pretraining with datasets spanning two orders of magnitude in size shows that our improvements over CLIP tend to scale with number of training examples. ",
    "url": "https://arxiv.org/abs/2204.04588",
    "authors": [
      "Alex Andonian",
      "Shixing Chen",
      "Raffay Hamid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04601",
    "title": "Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic  Filter Attention",
    "abstract": "Interpretability is an important property for visual models as it helps researchers and users understand the internal mechanism of a complex model. However, generating semantic explanations about the learned representation is challenging without direct supervision to produce such explanations. We propose a general framework, Latent Visual Semantic Explainer (LaViSE), to teach any existing convolutional neural network to generate text descriptions about its own latent representations at the filter level. Our method constructs a mapping between the visual and semantic spaces using generic image datasets, using images and category names. It then transfers the mapping to the target domain which does not have semantic labels. The proposed framework employs a modular structure and enables to analyze any trained network whether or not its original training data is available. We show that our method can generate novel descriptions for learned filters beyond the set of categories defined in the training dataset and perform an extensive evaluation on multiple datasets. We also demonstrate a novel application of our method for unsupervised dataset bias analysis which allows us to automatically discover hidden biases in datasets or compare different subsets without using additional labels. The dataset and code are made public to facilitate further research. ",
    "url": "https://arxiv.org/abs/2204.04601",
    "authors": [
      "Yu Yang",
      "Seungbae Kim",
      "Jungseock Joo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04606",
    "title": "Towards efficient representation identification in supervised learning",
    "abstract": "Humans have a remarkable ability to disentangle complex sensory inputs (e.g., image, text) into simple factors of variation (e.g., shape, color) without much supervision. This ability has inspired many works that attempt to solve the following question: how do we invert the data generation process to extract those factors with minimal or no supervision? Several works in the literature on non-linear independent component analysis have established this negative result; without some knowledge of the data generation process or appropriate inductive biases, it is impossible to perform this inversion. In recent years, a lot of progress has been made on disentanglement under structural assumptions, e.g., when we have access to auxiliary information that makes the factors of variation conditionally independent. However, existing work requires a lot of auxiliary information, e.g., in supervised classification, it prescribes that the number of label classes should be at least equal to the total dimension of all factors of variation. In this work, we depart from these assumptions and ask: a) How can we get disentanglement when the auxiliary information does not provide conditional independence over the factors of variation? b) Can we reduce the amount of auxiliary information required for disentanglement? For a class of models where auxiliary information does not ensure conditional independence, we show theoretically and experimentally that disentanglement (to a large extent) is possible even when the auxiliary information dimension is much less than the dimension of the true latent representation. ",
    "url": "https://arxiv.org/abs/2204.04606",
    "authors": [
      "Kartik Ahuja",
      "Divyat Mahajan",
      "Vasilis Syrgkanis",
      "Ioannis Mitliagkas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.04607",
    "title": "Self-Supervised Video Representation Learning with Motion-Contrastive  Perception",
    "abstract": "Visual-only self-supervised learning has achieved significant improvement in video representation learning. Existing related methods encourage models to learn video representations by utilizing contrastive learning or designing specific pretext tasks. However, some models are likely to focus on the background, which is unimportant for learning video representations. To alleviate this problem, we propose a new view called long-range residual frame to obtain more motion-specific information. Based on this, we propose the Motion-Contrastive Perception Network (MCPNet), which consists of two branches, namely, Motion Information Perception (MIP) and Contrastive Instance Perception (CIP), to learn generic video representations by focusing on the changing areas in videos. Specifically, the MIP branch aims to learn fine-grained motion features, and the CIP branch performs contrastive learning to learn overall semantics information for each instance. Experiments on two benchmark datasets UCF-101 and HMDB-51 show that our method outperforms current state-of-the-art visual-only self-supervised approaches. ",
    "url": "https://arxiv.org/abs/2204.04607",
    "authors": [
      "Jinyu Liu",
      "Ying Cheng",
      "Yuejie Zhang",
      "Rui-Wei Zhao",
      "Rui Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04611",
    "title": "Decay No More: A Persistent Twitter Dataset for Learning Social Meaning",
    "abstract": "With the proliferation of social media, many studies resort to social media to construct datasets for developing social meaning understanding systems. For the popular case of Twitter, most researchers distribute tweet IDs without the actual text contents due to the data distribution policy of the platform. One issue is that the posts become increasingly inaccessible over time, which leads to unfair comparisons and a temporal bias in social media research. To alleviate this challenge of data decay, we leverage a paraphrase model to propose a new persistent English Twitter dataset for social meaning (PTSM). PTSM consists of $17$ social meaning datasets in $10$ categories of tasks. We experiment with two SOTA pre-trained language models and show that our PTSM can substitute the actual tweets with paraphrases with marginal performance loss. ",
    "url": "https://arxiv.org/abs/2204.04611",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed",
      "El Moatez Billah Nagoudi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04615",
    "title": "Learning Pixel-Level Distinctions for Video Highlight Detection",
    "abstract": "The goal of video highlight detection is to select the most attractive segments from a long video to depict the most interesting parts of the video. Existing methods typically focus on modeling relationship between different video segments in order to learning a model that can assign highlight scores to these segments; however, these approaches do not explicitly consider the contextual dependency within individual segments. To this end, we propose to learn pixel-level distinctions to improve the video highlight detection. This pixel-level distinction indicates whether or not each pixel in one video belongs to an interesting section. The advantages of modeling such fine-level distinctions are two-fold. First, it allows us to exploit the temporal and spatial relations of the content in one video, since the distinction of a pixel in one frame is highly dependent on both the content before this frame and the content around this pixel in this frame. Second, learning the pixel-level distinction also gives a good explanation to the video highlight task regarding what contents in a highlight segment will be attractive to people. We design an encoder-decoder network to estimate the pixel-level distinction, in which we leverage the 3D convolutional neural networks to exploit the temporal context information, and further take advantage of the visual saliency to model the spatial distinction. State-of-the-art performance on three public benchmarks clearly validates the effectiveness of our framework for video highlight detection. ",
    "url": "https://arxiv.org/abs/2204.04615",
    "authors": [
      "Fanyue Wei",
      "Biao Wang",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Wen Li",
      "Lixin Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04618",
    "title": "ME-GCN: Multi-dimensional Edge-Embedded Graph Convolutional Networks for  Semi-supervised Text Classification",
    "abstract": "Compared to sequential learning models, graph-based neural networks exhibit excellent ability in capturing global information and have been used for semi-supervised learning tasks. Most Graph Convolutional Networks are designed with the single-dimensional edge feature and failed to utilise the rich edge information about graphs. This paper introduces the ME-GCN (Multi-dimensional Edge-enhanced Graph Convolutional Networks) for semi-supervised text classification. A text graph for an entire corpus is firstly constructed to describe the undirected and multi-dimensional relationship of word-to-word, document-document, and word-to-document. The graph is initialised with corpus-trained multi-dimensional word and document node representation, and the relations are represented according to the distance of those words/documents nodes. Then, the generated graph is trained with ME-GCN, which considers the edge features as multi-stream signals, and each stream performs a separate graph convolutional operation. Our ME-GCN can integrate a rich source of graph edge information of the entire text corpus. The results have demonstrated that our proposed model has significantly outperformed the state-of-the-art methods across eight benchmark datasets. ",
    "url": "https://arxiv.org/abs/2204.04618",
    "authors": [
      "Kunze Wang",
      "Soyeon Caren Han",
      "Siqu Long",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04629",
    "title": "Pushing on Personality Detection from Verbal Behavior: A Transformer  Meets Text Contours of Psycholinguistic Features",
    "abstract": "Research at the intersection of personality psychology, computer science, and linguistics has recently focused increasingly on modeling and predicting personality from language use. We report two major improvements in predicting personality traits from text data: (1) to our knowledge, the most comprehensive set of theory-based psycholinguistic features and (2) hybrid models that integrate a pre-trained Transformer Language Model BERT and Bidirectional Long Short-Term Memory (BLSTM) networks trained on within-text distributions ('text contours') of psycholinguistic features. We experiment with BLSTM models (with and without Attention) and with two techniques for applying pre-trained language representations from the transformer model - 'feature-based' and 'fine-tuning'. We evaluate the performance of the models we built on two benchmark datasets that target the two dominant theoretical models of personality: the Big Five Essay dataset and the MBTI Kaggle dataset. Our results are encouraging as our models outperform existing work on the same datasets. More specifically, our models achieve improvement in classification accuracy by 2.9% on the Essay dataset and 8.28% on the Kaggle MBTI dataset. In addition, we perform ablation experiments to quantify the impact of different categories of psycholinguistic features in the respective personality prediction models. ",
    "url": "https://arxiv.org/abs/2204.04629",
    "authors": [
      "Elma Kerz",
      "Yu Qiao",
      "Sourabh Zanwar",
      "Daniel Wiechmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04634",
    "title": "Intersection Prediction from Single 360\u00b0 Image via Deep Detection  of Possible Direction of Travel",
    "abstract": "Movie-Map, an interactive first-person-view map that engages the user in a simulated walking experience, comprises short 360{\\deg} video segments separated by traffic intersections that are seamlessly connected according to the viewer's direction of travel. However, in wide urban-scale areas with numerous intersecting roads, manual intersection segmentation requires significant human effort. Therefore, automatic identification of intersections from 360{\\deg} videos is an important problem for scaling up Movie-Map. In this paper, we propose a novel method that identifies an intersection from individual frames in 360{\\deg} videos. Instead of formulating the intersection identification as a standard binary classification task with a 360{\\deg} image as input, we identify an intersection based on the number of the possible directions of travel (PDoT) in perspective images projected in eight directions from a single 360{\\deg} image detected by the neural network for handling various types of intersections. We constructed a large-scale 360{\\deg} Image Intersection Identification (iii360) dataset for training and evaluation where 360{\\deg} videos were collected from various areas such as school campus, downtown, suburb, and china town and demonstrate that our PDoT-based method achieves 88\\% accuracy, which is significantly better than that achieved by the direct naive binary classification based method. The source codes and a partial dataset will be shared in the community after the paper is published. ",
    "url": "https://arxiv.org/abs/2204.04634",
    "authors": [
      "Naoki Sugimoto",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2204.04636",
    "title": "\"That Is a Suspicious Reaction!\": Interpreting Logits Variation to  Detect NLP Adversarial Attacks",
    "abstract": "Adversarial attacks are a major challenge faced by current machine learning research. These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications. Extensive research in computer vision has been carried to develop reliable defense strategies. However, the same issue remains less explored in natural language processing. Our work presents a model-agnostic detector of adversarial text examples. The approach identifies patterns in the logits of the target classifier when perturbing the input text. The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks. ",
    "url": "https://arxiv.org/abs/2204.04636",
    "authors": [
      "Edoardo Mosca",
      "Shreyash Agarwal",
      "Javier Rando-Ramirez",
      "Georg Groh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04644",
    "title": "From graphs to DAGs: a low-complexity model and a scalable algorithm",
    "abstract": "Learning directed acyclic graphs (DAGs) is long known a critical challenge at the core of probabilistic and causal modeling. The NoTears approach of (Zheng et al., 2018), through a differentiable function involving the matrix exponential trace $\\mathrm{tr}(\\exp(\\cdot))$, opens up a way to learning DAGs via continuous optimization, though with a $O(d^3)$ complexity in the number $d$ of nodes. This paper presents a low-complexity model, called LoRAM for Low-Rank Additive Model, which combines low-rank matrix factorization with a sparsification mechanism for the continuous optimization of DAGs. The main contribution of the approach lies in an efficient gradient approximation method leveraging the low-rank property of the model, and its straightforward application to the computation of projections from graph matrices onto the DAG matrix space. The proposed method achieves a reduction from a cubic complexity to quadratic complexity while handling the same DAG characteristic function as NoTears, and scales easily up to thousands of nodes for the projection problem. The experiments show that the LoRAM achieves efficiency gains of orders of magnitude compared to the state-of-the-art at the expense of a very moderate accuracy loss in the considered range of sparse matrices, and with a low sensitivity to the rank choice of the model's low-rank component. ",
    "url": "https://arxiv.org/abs/2204.04644",
    "authors": [
      "Shuyu Dong",
      "Mich\u00e8le Sebag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.04645",
    "title": "Self-Supervised Audio-and-Text Pre-training with Extremely Low-Resource  Parallel Data",
    "abstract": "Multimodal pre-training for audio-and-text has recently been proved to be effective and has significantly improved the performance of many downstream speech understanding tasks. However, these state-of-the-art pre-training audio-text models work well only when provided with large amount of parallel audio-and-text data, which brings challenges on many languages that are rich in unimodal corpora but scarce of parallel cross-modal corpus. In this paper, we investigate whether it is possible to pre-train an audio-text multimodal model with extremely low-resource parallel data and extra non-parallel unimodal data. Our pre-training framework consists of the following components: (1) Intra-modal Denoising Auto-Encoding (IDAE), which is able to reconstruct input text (audio) representations from a noisy version of itself. (2) Cross-modal Denoising Auto-Encoding (CDAE), which is pre-trained to reconstruct the input text (audio), given both a noisy version of the input text (audio) and the corresponding translated noisy audio features (text embeddings). (3) Iterative Denoising Process (IDP), which iteratively translates raw audio (text) and the corresponding text embeddings (audio features) translated from previous iteration into the new less-noisy text embeddings (audio features). We adapt a dual cross-modal Transformer as our backbone model which consists of two unimodal encoders for IDAE and two cross-modal encoders for CDAE and IDP. Our method achieves comparable performance on multiple downstream speech understanding tasks compared with the model pre-trained on fully parallel data, demonstrating the great potential of the proposed method. Our code is available at: \\url{https://github.com/KarlYuKang/Low-Resource-Multimodal-Pre-training}. ",
    "url": "https://arxiv.org/abs/2204.04645",
    "authors": [
      "Yu Kang",
      "Tianqiao Liu",
      "Hang Li",
      "Yang Hao",
      "Wenbiao Ding"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.04646",
    "title": "Deep Embeddings for Robust User-Based Amateur Vocal Percussion  Classification",
    "abstract": "Vocal Percussion Transcription (VPT) is concerned with the automatic detection and classification of vocal percussion sound events, allowing music creators and producers to sketch drum lines on the fly. Classifier algorithms in VPT systems learn best from small user-specific datasets, which usually restrict modelling to small input feature sets to avoid data overfitting. This study explores several deep supervised learning strategies to obtain informative feature sets for amateur vocal percussion classification. We evaluated the performance of these sets on regular vocal percussion classification tasks and compared them with several baseline approaches including feature selection methods and a speech recognition engine. These proposed learning models were supervised with several label sets containing information from four different levels of abstraction: instrument-level, syllable-level, phoneme-level, and boxeme-level. Results suggest that convolutional neural networks supervised with syllable-level annotations produced the most informative embeddings for classification, which can be used as input representations to fit classifiers with. Finally, we used back-propagation-based saliency maps to investigate the importance of different spectrogram regions for feature learning. ",
    "url": "https://arxiv.org/abs/2204.04646",
    "authors": [
      "Alejandro Delgado",
      "Emir Demirel",
      "Vinod Subramanian",
      "Charalampos Saitis",
      "Mark Sandler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.04651",
    "title": "Deep Conditional Representation Learning for Drum Sample Retrieval by  Vocalisation",
    "abstract": "Imitating musical instruments with the human voice is an efficient way of communicating ideas between music producers, from sketching melody lines to clarifying desired sonorities. For this reason, there is an increasing interest in building applications that allow artists to efficiently pick target samples from big sound libraries just by imitating them vocally. In this study, we investigated the potential of conditional autoencoder models to learn informative features for Drum Sample Retrieval by Vocalisation (DSRV). We assessed the usefulness of their embeddings using four evaluation metrics, two of them relative to their acoustic properties and two of them relative to their perceptual properties via human listeners' similarity ratings. Results suggest that models conditioned on both sound-type labels (drum vs imitation) and drum-type labels (kick vs snare vs closed hi-hat vs opened hi-hat) learn the most informative embeddings for DSRV. We finally looked into individual differences in vocal imitation style via the Mantel test and found salient differences among participants, highlighting the importance of user information when designing DSRV systems. ",
    "url": "https://arxiv.org/abs/2204.04651",
    "authors": [
      "Alejandro Delgado",
      "Charalampos Saitis",
      "Emmanouil Benetos",
      "Mark Sandler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.04661",
    "title": "Expressiveness and Approximation Properties of Graph Neural Networks",
    "abstract": "Characterizing the separation power of graph neural networks (GNNs) provides an understanding of their limitations for graph learning tasks. Results regarding separation power are, however, usually geared at specific GNN architectures, and tools for understanding arbitrary GNN architectures are generally lacking. We provide an elegant way to easily obtain bounds on the separation power of GNNs in terms of the Weisfeiler-Leman (WL) tests, which have become the yardstick to measure the separation power of GNNs. The crux is to view GNNs as expressions in a procedural tensor language describing the computations in the layers of the GNNs. Then, by a simple analysis of the obtained expressions, in terms of the number of indexes and the nesting depth of summations, bounds on the separation power in terms of the WL-tests readily follow. We use tensor language to define Higher-Order Message-Passing Neural Networks (or k-MPNNs), a natural extension of MPNNs. Furthermore, the tensor language point of view allows for the derivation of universality results for classes of GNNs in a natural way. Our approach provides a toolbox with which GNN architecture designers can analyze the separation power of their GNNs, without needing to know the intricacies of the WL-tests. We also provide insights in what is needed to boost the separation power of GNNs. ",
    "url": "https://arxiv.org/abs/2204.04661",
    "authors": [
      "Floris Geerts",
      "Juan L. Reutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04665",
    "title": "Effective Out-of-Distribution Detection in Classifier Based on  PEDCC-Loss",
    "abstract": "Deep neural networks suffer from the overconfidence issue in the open world, meaning that classifiers could yield confident, incorrect predictions for out-of-distribution (OOD) samples. Thus, it is an urgent and challenging task to detect these samples drawn far away from training distribution based on the security considerations of artificial intelligence. Many current methods based on neural networks mainly rely on complex processing strategies, such as temperature scaling and input preprocessing, to obtain satisfactory results. In this paper, we propose an effective algorithm for detecting out-of-distribution examples utilizing PEDCC-Loss. We mathematically analyze the nature of the confidence score output by the PEDCC (Predefined Evenly-Distribution Class Centroids) classifier, and then construct a more effective scoring function to distinguish in-distribution (ID) and out-of-distribution. In this method, there is no need to preprocess the input samples and the computational burden of the algorithm is reduced. Experiments demonstrate that our method can achieve better OOD detection performance. ",
    "url": "https://arxiv.org/abs/2204.04665",
    "authors": [
      "Qiuyu Zhu",
      "Guohui Zheng",
      "Yingying Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04673",
    "title": "Optimal long-time decay rate of solutions of complete  monotonicity-preserving schemes for nonlinear time-fractional evolutionary  equations",
    "abstract": "The solution of the nonlinear initial-value problem $\\mathcal{D}_{t}^{\\alpha}y(t)=-\\lambda y(t)^{\\gamma}$ for $t>0$ with $y(0)>0$, where $\\mathcal{D}_{t}^{\\alpha}$ is a Caputo derivative of order $\\alpha\\in (0,1)$ and $\\lambda, \\gamma$ are positive parameters, is known to exhibit $O(t^{\\alpha/\\gamma})$ decay as $t\\to\\infty$. No corresponding result for any discretisation of this problem has previously been proved. In the present paper it is shown that for the class of complete monotonicity-preserving ($\\mathcal{CM}$-preserving) schemes (which includes the L1 and Gr\\\"unwald-Letnikov schemes) on uniform meshes $\\{t_n:=nh\\}_{n=0}^\\infty$, the discrete solution also has $O(t_{n}^{-\\alpha/\\gamma})$ decay as $t_{n}\\to\\infty$. This result is then extended to $\\mathcal{CM}$-preserving discretisations of certain time-fractional nonlinear subdiffusion problems such as the time-fractional porous media and $p$-Laplace equations. For the L1 scheme, the $O(t_{n}^{-\\alpha/\\gamma})$ decay result is shown to remain valid on a very general class of nonuniform meshes. Our analysis uses a discrete comparison principle with discrete subsolutions and supersolutions that are carefully constructed to give tight bounds on the discrete solution. Numerical experiments are provided to confirm our theoretical analysis. ",
    "url": "https://arxiv.org/abs/2204.04673",
    "authors": [
      "Dongling Wang",
      "Martin Stynes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.04674",
    "title": "Is my Driver Observation Model Overconfident? Input-guided Calibration  Networks for Reliable and Interpretable Confidence Estimates",
    "abstract": "Driver observation models are rarely deployed under perfect conditions. In practice, illumination, camera placement and type differ from the ones present during training and unforeseen behaviours may occur at any time. While observing the human behind the steering wheel leads to more intuitive human-vehicle-interaction and safer driving, it requires recognition algorithms which do not only predict the correct driver state, but also determine their prediction quality through realistic and interpretable confidence measures. Reliable uncertainty estimates are crucial for building trust and are a serious obstacle for deploying activity recognition networks in real driving systems. In this work, we for the first time examine how well the confidence values of modern driver observation models indeed match the probability of the correct outcome and show that raw neural network-based approaches tend to significantly overestimate their prediction quality. To correct this misalignment between the confidence values and the actual uncertainty, we consider two strategies. First, we enhance two activity recognition models often used for driver observation with temperature scaling-an off-the-shelf method for confidence calibration in image classification. Then, we introduce Calibrated Action Recognition with Input Guidance (CARING)-a novel approach leveraging an additional neural network to learn scaling the confidences depending on the video representation. Extensive experiments on the Drive&Act dataset demonstrate that both strategies drastically improve the quality of model confidences, while our CARING model out-performs both, the original architectures and their temperature scaling enhancement, leading to best uncertainty estimates. ",
    "url": "https://arxiv.org/abs/2204.04674",
    "authors": [
      "Alina Roitberg",
      "Kunyu Peng",
      "David Schneider",
      "Kailun Yang",
      "Marios Koulakis",
      "Manuel Martinez",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04704",
    "title": "An Efficient Pattern Mining Convolution Neural Network (CNN) algorithm  with Grey Wolf Optimization (GWO)",
    "abstract": "Automation of feature analysis in the dynamic image frame dataset deals with complexity of intensity mapping with normal and abnormal class. The threshold-based data clustering and feature analysis requires iterative model to learn the component of image frame in multi-pattern for different image frame data type. This paper proposed a novel model of feature analysis method with the CNN based on Convoluted Pattern of Wavelet Transform (CPWT) feature vectors that are optimized by Grey Wolf Optimization (GWO) algorithm. Initially, the image frame gets normalized by applying median filter to the image frame that reduce the noise and apply smoothening on it. From that, the edge information represents the boundary region of bright spot in the image frame. Neural network-based image frame classification performs repeated learning of the feature with minimum training of dataset to cluster the image frame pixels. Features of the filtered image frame was analyzed in different pattern of feature extraction model based on the convoluted model of wavelet transformation method. These features represent the different class of image frame in spatial and textural pattern of it. Convolutional Neural Network (CNN) classifier supports to analyze the features and classify the action label for the image frame dataset. This process enhances the classification with minimum number of training dataset. The performance of this proposed method can be validated by comparing with traditional state-of-art methods. ",
    "url": "https://arxiv.org/abs/2204.04704",
    "authors": [
      "Aatif Jamshed",
      "Bhawna Mallick",
      "Rajendra Kumar Bharti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04705",
    "title": "SplitNets: Designing Neural Architectures for Efficient Distributed  Computing on Head-Mounted Systems",
    "abstract": "We design deep neural networks (DNNs) and corresponding networks' splittings to distribute DNNs' workload to camera sensors and a centralized aggregator on head mounted devices to meet system performance targets in inference accuracy and latency under the given hardware resource constraints. To achieve an optimal balance among computation, communication, and performance, a split-aware neural architecture search framework, SplitNets, is introduced to conduct model designing, splitting, and communication reduction simultaneously. We further extend the framework to multi-view systems for learning to fuse inputs from multiple camera sensors with optimal performance and systemic efficiency. We validate SplitNets for single-view system on ImageNet as well as multi-view system on 3D classification, and show that the SplitNets framework achieves state-of-the-art (SOTA) performance and system latency compared with existing approaches. ",
    "url": "https://arxiv.org/abs/2204.04705",
    "authors": [
      "Xin Dong",
      "Barbara De Salvo",
      "Meng Li",
      "Chiao Liu",
      "Zhongnan Qu",
      "H.T. Kung",
      "Ziyun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.04707",
    "title": "Generative Adversarial Networks for Image Augmentation in Agriculture: A  Systematic Review",
    "abstract": "In agricultural image analysis, optimal model performance is keenly pursued for better fulfilling visual recognition tasks (e.g., image classification, segmentation, object detection and localization), in the presence of challenges with biological variability and unstructured environments. Large-scale, balanced and ground-truthed image datasets, however, are often difficult to obtain to fuel the development of advanced, high-performance models. As artificial intelligence through deep learning is impacting analysis and modeling of agricultural images, data augmentation plays a crucial role in boosting model performance while reducing manual efforts for data preparation, by algorithmically expanding training datasets. Beyond traditional data augmentation techniques, generative adversarial network (GAN) invented in 2014 in the computer vision community, provides a suite of novel approaches that can learn good data representations and generate highly realistic samples. Since 2017, there has been a growth of research into GANs for image augmentation or synthesis in agriculture for improved model performance. This paper presents an overview of the evolution of GAN architectures followed by a systematic review of their application to agriculture (https://github.com/Derekabc/GANs-Agriculture), involving various vision tasks for plant health, weeds, fruits, aquaculture, animal farming, plant phenotyping as well as postharvest detection of fruit defects. Challenges and opportunities of GANs are discussed for future research. ",
    "url": "https://arxiv.org/abs/2204.04707",
    "authors": [
      "Ebenezer Olaniyi",
      "Dong Chen",
      "Yuzhen Lu",
      "Yanbo Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.04711",
    "title": "Data Augmentation for Biomedical Factoid Question Answering",
    "abstract": "We study the effect of seven data augmentation (da) methods in factoid question answering, focusing on the biomedical domain, where obtaining training instances is particularly difficult. We experiment with data from the BioASQ challenge, which we augment with training instances obtained from an artificial biomedical machine reading comprehension dataset, or via back-translation, information retrieval, word substitution based on word2vec embeddings, or masked language modeling, question generation, or extending the given passage with additional context. We show that da can lead to very significant performance gains, even when using large pre-trained Transformers, contributing to a broader discussion of if/when da benefits large pre-trained models. One of the simplest da methods, word2vec-based word substitution, performed best and is recommended. We release our artificial training instances and code. ",
    "url": "https://arxiv.org/abs/2204.04711",
    "authors": [
      "Dimitris Pappas",
      "Prodromos Malakasiotis",
      "Ion Androutsopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04716",
    "title": "TOV: The Original Vision Model for Optical Remote Sensing Image  Understanding via Self-supervised Learning",
    "abstract": "Do we on the right way for remote sensing image understanding (RSIU) by training models via supervised data-dependent and task-dependent way, instead of human vision in a label-free and task-independent way? We argue that a more desirable RSIU model should be trained with intrinsic structure from data rather that extrinsic human labels to realize generalizability across a wide range of RSIU tasks. According to this hypothesis, we proposed \\textbf{T}he \\textbf{O}riginal \\textbf{V}ision model (TOV) in remote sensing filed. Trained by massive unlabeled optical data along a human-like self-supervised learning (SSL) path that is from general knowledge to specialized knowledge, TOV model can be easily adapted to various RSIU tasks, including scene classification, object detection, and semantic segmentation, and outperforms dominant ImageNet supervised pretrained method as well as two recently proposed SSL pretrained methods on majority of 12 publicly available benchmarks. Moreover, we analyze the influences of two key factors on the performance of building TOV model for RSIU, including the influence of using different data sampling methods and the selection of learning paths during self-supervised optimization. We believe that a general model which is trained by a label-free and task-independent way may be the next paradigm for RSIU and hope the insights distilled from this study can help to foster the development of an original vision model for RSIU. ",
    "url": "https://arxiv.org/abs/2204.04716",
    "authors": [
      "Chao Tao",
      "Ji Qia",
      "Guo Zhang",
      "Qing Zhu",
      "Weipeng Lu",
      "Haifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2204.04768",
    "title": "Analysis of Power-Oriented Fault Injection Attacks on Spiking Neural  Networks",
    "abstract": "Spiking Neural Networks (SNN) are quickly gaining traction as a viable alternative to Deep Neural Networks (DNN). In comparison to DNNs, SNNs are more computationally powerful and provide superior energy efficiency. SNNs, while exciting at first appearance, contain security-sensitive assets (e.g., neuron threshold voltage) and vulnerabilities (e.g., sensitivity of classification accuracy to neuron threshold voltage change) that adversaries can exploit. We investigate global fault injection attacks by employing external power supplies and laser-induced local power glitches to corrupt crucial training parameters such as spike amplitude and neuron's membrane threshold potential on SNNs developed using common analog neurons. We also evaluate the impact of power-based attacks on individual SNN layers for 0% (i.e., no attack) to 100% (i.e., whole layer under attack). We investigate the impact of the attacks on digit classification tasks and find that in the worst-case scenario, classification accuracy is reduced by 85.65%. We also propose defenses e.g., a robust current driver design that is immune to power-oriented attacks, improved circuit sizing of neuron components to reduce/recover the adversarial accuracy degradation at the cost of negligible area and 25% power overhead. We also present a dummy neuron-based voltage fault injection detection system with 1% power and area overhead. ",
    "url": "https://arxiv.org/abs/2204.04768",
    "authors": [
      "Karthikeyan Nagarajan",
      "Junde Li",
      "Sina Sayyah Ensan",
      "Mohammad Nasim Imtiaz Khan",
      "Sachhidh Kannan",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.04769",
    "title": "A review of knowledge graph application scenarios in cyber security",
    "abstract": "Facing the dynamic complex cyber environments, internal and external cyber threat intelligence, and the increasing risk of cyber-attack, knowledge graphs show great application potential in the cyber security area because of their capabilities in knowledge aggregation, representation, management, and reasoning. However, while most research has focused on how to develop a complete knowledge graph, it remains unclear how to apply the knowledge graph to solve industrial real challenges in cyber-attack and defense scenarios. In this review, we provide a brief overview of the basic concepts, schema, and construction approaches for the cyber security knowledge graph. To facilitate future research on cyber security knowledge graphs, we also present a curated collection of datasets and open-source libraries on the knowledge construction and information extraction task. In the major part of this article, we conduct a comparative review of the different works that elaborate on the recent progress in the application scenarios of the cyber security knowledge graph. Furthermore, a novel comprehensive classification framework is created to describe the connected works from nine primary categories and eighteen subcategories. Finally, we have a thorough outlook on several promising research directions based on the discussion of existing research flaws. ",
    "url": "https://arxiv.org/abs/2204.04769",
    "authors": [
      "Kai Liu",
      "Fei Wang",
      "Zhaoyun Ding",
      "Sheng Liang",
      "Zhengfei Yu",
      "Yun Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.04783",
    "title": "Temporal Knowledge Graph Reasoning with Low-rank and Model-agnostic  Representations",
    "abstract": "Temporal knowledge graph completion (TKGC) has become a popular approach for reasoning over the event and temporal knowledge graphs, targeting the completion of knowledge with accurate but missing information. In this context, tensor decomposition has successfully modeled interactions between entities and relations. Their effectiveness in static knowledge graph completion motivates us to introduce Time-LowFER, a family of parameter-efficient and time-aware extensions of the low-rank tensor factorization model LowFER. Noting several limitations in current approaches to represent time, we propose a cycle-aware time-encoding scheme for time features, which is model-agnostic and offers a more generalized representation of time. We implement our methods in a unified temporal knowledge graph embedding framework, focusing on time-sensitive data processing. The experiments show that our proposed methods perform on par or better than the state-of-the-art semantic matching models on two benchmarks. ",
    "url": "https://arxiv.org/abs/2204.04783",
    "authors": [
      "Ioannis Dikeoulias",
      "Saadullah Amin",
      "G\u00fcnter Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04788",
    "title": "DILEMMA: Self-Supervised Shape and Texture Learning with Transformers",
    "abstract": "There is a growing belief that deep neural networks with a shape bias may exhibit better generalization capabilities than models with a texture bias, because shape is a more reliable indicator of the object category. However, we show experimentally that existing measures of shape bias are not stable predictors of generalization and argue that shape discrimination should not come at the expense of texture discrimination. Thus, we propose a pseudo-task to explicitly boost both shape and texture discriminability in models trained via self-supervised learning. For this purpose, we train a ViT to detect which input token has been combined with an incorrect positional embedding. To retain texture discrimination, the ViT is also trained as in MoCo with a student-teacher architecture and a contrastive loss over an extra learnable class token. We call our method DILEMMA, which stands for Detection of Incorrect Location EMbeddings with MAsked inputs. We evaluate our method through fine-tuning on several datasets and show that it outperforms MoCoV3 and DINO. Moreover, we show that when downstream tasks are strongly reliant on shape (such as in the YOGA-82 pose dataset), our pre-trained features yield a significant gain over prior work. Code will be released upon publication. ",
    "url": "https://arxiv.org/abs/2204.04788",
    "authors": [
      "Sepehr Sameni",
      "Simon Jenni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04793",
    "title": "Fake news detection using parallel BERT deep neural networks",
    "abstract": "Fake news is a growing challenge for social networks and media. Detection of fake news always has been a problem for many years, but after the evolution of social networks and increasing speed of news dissemination in recent years has been considered again. There are several approaches to solving this problem, one of which is to detect fake news based on its text style using deep neural networks. In recent years, one of the most used forms of deep neural networks for natural language processing is transfer learning with transformers. BERT is one of the most promising transformers who outperforms other models in many NLP benchmarks. This article, we introduce MWPBert, which uses two parallel BERT networks to perform veracity detection on full-text news articles. One of the BERT networks encodes news headline, and another encodes news body. Since the input length of the BERT network is limited and constant and the news body is usually a long text, we cannot fed the whole news text into the BERT. Therefore, using the MaxWorth algorithm, we selected the part of the news text that is more valuable for fact-checking, and fed it into the BERT network. Finally, we encode the output of the two BERT networks to an output network to classify the news. The experiment results showed that the proposed model outperformed previous models in terms of accuracy and other performance measures. ",
    "url": "https://arxiv.org/abs/2204.04793",
    "authors": [
      "Mahmood Farokhian",
      "Vahid Rafe",
      "Hadi Veisi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04795",
    "title": "Edge Continual Learning for Dynamic Digital Twins over Wireless Networks",
    "abstract": "Digital twins (DTs) constitute a critical link between the real-world and the metaverse. To guarantee a robust connection between these two worlds, DTs should maintain accurate representations of the physical applications, while preserving synchronization between real and digital entities. In this paper, a novel edge continual learning framework is proposed to accurately model the evolving affinity between a physical twin (PT) and its corresponding cyber twin (CT) while maintaining their utmost synchronization. In particular, a CT is simulated as a deep neural network (DNN) at the wireless network edge to model an autonomous vehicle traversing an episodically dynamic environment. As the vehicular PT updates its driving policy in each episode, the CT is required to concurrently adapt its DNN model to the PT, which gives rise to a de-synchronization gap. Considering the history-aware nature of DTs, the model update process is posed a dual objective optimization problem whose goal is to jointly minimize the loss function over all encountered episodes and the corresponding de-synchronization time. As the de-synchronization time continues to increase over sequential episodes, an elastic weight consolidation (EWC) technique that regularizes the DT history is proposed to limit de-synchronization time. Furthermore, to address the plasticity-stability tradeoff accompanying the progressive growth of the EWC regularization terms, a modified EWC method that considers fair execution between the historical episodes of the DTs is adopted. Ultimately, the proposed framework achieves a simultaneously accurate and synchronous CT model that is robust to catastrophic forgetting. Simulation results show that the proposed solution can achieve an accuracy of 90 % while guaranteeing a minimal desynchronization time. ",
    "url": "https://arxiv.org/abs/2204.04795",
    "authors": [
      "Omar Hashash",
      "Christina Chaccour",
      "Walid Saad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.04796",
    "title": "SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric  Action Recognition",
    "abstract": "Learning an egocentric action recognition model from video data is challenging due to distractors (e.g., irrelevant objects) in the background. Further integrating object information into an action model is hence beneficial. Existing methods often leverage a generic object detector to identify and represent the objects in the scene. However, several important issues remain. Object class annotations of good quality for the target domain (dataset) are still required for learning good object representation. Besides, previous methods deeply couple the existing action models and need to retrain them jointly with object representation, leading to costly and inflexible integration. To overcome both limitations, we introduce Self-Supervised Learning Over Sets (SOS), an approach to pre-train a generic Objects In Contact (OIC) representation model from video object regions detected by an off-the-shelf hand-object contact detector. Instead of augmenting object regions individually as in conventional self-supervised learning, we view the action process as a means of natural data transformations with unique spatio-temporal continuity and exploit the inherent relationships among per-video object sets. Extensive experiments on two datasets, EPIC-KITCHENS-100 and EGTEA, show that our OIC significantly boosts the performance of multiple state-of-the-art video classification models. ",
    "url": "https://arxiv.org/abs/2204.04796",
    "authors": [
      "Victor Escorcia",
      "Ricardo Guerrero",
      "Xiatian Zhu",
      "Brais Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04802",
    "title": "On the pragmatism of using binary classifiers over data intensive neural  network classifiers for detection of COVID-19 from voice",
    "abstract": "Lately, there has been a global effort by multiple research groups to detect COVID-19 from voice. Different researchers use different kinds of information from the voice signal to achieve this. Various types of phonated sounds and the sound of cough and breath have all been used with varying degrees of success in automated voice-based COVID-19 detection apps. In this paper, we show that detecting COVID-19 from voice does not require custom-made non-standard features or complicated neural network classifiers rather it can be successfully done with just standard features and simple binary classifiers. In fact, we show that the latter is not only more accurate and interpretable and also more computationally efficient in that they can be run locally on small devices. We demonstrate this from a human-curated dataset collected and calibrated in clinical settings. On this dataset which comprises over 1000 speakers, a simple binary classifier is able to achieve 94% detection accuracy. ",
    "url": "https://arxiv.org/abs/2204.04802",
    "authors": [
      "Ankit Shah",
      "Hira Dhamyal",
      "Yang Gao",
      "Rita Singh",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.04813",
    "title": "Explanation Graph Generation via Pre-trained Language Models: An  Empirical Study with Contrastive Learning",
    "abstract": "Pre-trained sequence-to-sequence language models have led to widespread success in many natural language generation tasks. However, there has been relatively less work on analyzing their ability to generate structured outputs such as graphs. Unlike natural language, graphs have distinct structural and semantic properties in the context of a downstream NLP task, e.g., generating a graph that is connected and acyclic can be attributed to its structural constraints, while the semantics of a graph can refer to how meaningfully an edge represents the relation between two node concepts. In this work, we study pre-trained language models that generate explanation graphs in an end-to-end manner and analyze their ability to learn the structural constraints and semantics of such graphs. We first show that with limited supervision, pre-trained language models often generate graphs that either violate these constraints or are semantically incoherent. Since curating large amount of human-annotated graphs is expensive and tedious, we propose simple yet effective ways of graph perturbations via node and edge edit operations that lead to structurally and semantically positive and negative graphs. Next, we leverage these graphs in different contrastive learning models with Max-Margin and InfoNCE losses. Our methods lead to significant improvements in both structural and semantic accuracy of explanation graphs and also generalize to other similar graph generation tasks. Lastly, we show that human errors are the best negatives for contrastive learning and also that automatically generating more such human-like negative graphs can lead to further improvements. Our code and models are publicly available at https://github.com/swarnaHub/ExplagraphGen ",
    "url": "https://arxiv.org/abs/2204.04813",
    "authors": [
      "Swarnadeep Saha",
      "Prateek Yadav",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04821",
    "title": "Markov categories, causal theories, and the do-calculus",
    "abstract": "We give a category-theoretic treatment of causal models that formalizes the syntax for causal reasoning over a directed acyclic graph (DAG) by associating a free Markov category with the DAG in a canonical way. This framework enables us to define and study important concepts in causal reasoning from an abstract and \"purely causal\" point of view, such as causal independence/separation, causal conditionals, and decomposition of intervention effects. Our results regarding these concepts abstract away from the details of the commonly adopted causal models such as (recursive) structural equation models or causal Bayesian networks. They are therefore more widely applicable and in a way conceptually clearer. Our results are also intimately related to Judea Pearl's celebrated do-calculus, and yield a syntactic version of a core part of the calculus that is inherited in all causal models. In particular, it induces a simpler and specialized version of Pearl's do-calculus in the context of causal Bayesian networks, which we show is as strong as the full version. ",
    "url": "https://arxiv.org/abs/2204.04821",
    "authors": [
      "Yimu Yin",
      "Jiji Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2204.04823",
    "title": "ACuTE: Automatic Curriculum Transfer from Simple to Complex Environments",
    "abstract": "Despite recent advances in Reinforcement Learning (RL), many problems, especially real-world tasks, remain prohibitively expensive to learn. To address this issue, several lines of research have explored how tasks, or data samples themselves, can be sequenced into a curriculum to learn a problem that may otherwise be too difficult to learn from scratch. However, generating and optimizing a curriculum in a realistic scenario still requires extensive interactions with the environment. To address this challenge, we formulate the curriculum transfer problem, in which the schema of a curriculum optimized in a simpler, easy-to-solve environment (e.g., a grid world) is transferred to a complex, realistic scenario (e.g., a physics-based robotics simulation or the real world). We present \"ACuTE\", Automatic Curriculum Transfer from Simple to Complex Environments, a novel framework to solve this problem, and evaluate our proposed method by comparing it to other baseline approaches (e.g., domain adaptation) designed to speed up learning. We observe that our approach produces improved jumpstart and time-to-threshold performance even when adding task elements that further increase the difficulty of the realistic scenario. Finally, we demonstrate that our approach is independent of the learning algorithm used for curriculum generation, and is Sim2Real transferable to a real world scenario using a physical robot. ",
    "url": "https://arxiv.org/abs/2204.04823",
    "authors": [
      "Yash Shukla",
      "Christopher Thierauf",
      "Ramtin Hosseini",
      "Gyan Tatiya",
      "Jivko Sinapov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.04832",
    "title": "The Complexity of Temporal Vertex Cover in Small-Degree Graphs",
    "abstract": "Temporal graphs naturally model graphs whose underlying topology changes over time. Recently, the problems TEMPORAL VERTEX COVER (or TVC) and SLIDING-WINDOW TEMPORAL VERTEX COVER(or $\\Delta$-TVC for time-windows of a fixed-length $\\Delta$) have been established as natural extensions of the classic problem VERTEX COVER on static graphs with connections to areas such as surveillance in sensor networks. In this paper we initiate a systematic study of the complexity of TVC and $\\Delta$-TVC on sparse graphs. Our main result shows that for every $\\Delta\\geq 2$, $\\Delta$-TVC is NP-hard even when the underlying topology is described by a path or a cycle. This resolves an open problem from literature and shows a surprising contrast between $\\Delta$-TVC and TVC for which we provide a polynomial-time algorithm in the same setting. To circumvent this hardness, we present a number of exact and approximation algorithms for temporal graphs whose underlying topologies are given by a path, that have bounded vertex degree in every time step, or that admit a small-sized temporal vertex cover. ",
    "url": "https://arxiv.org/abs/2204.04832",
    "authors": [
      "Thekla Hamm",
      "Nina Klobas",
      "George B. Mertzios",
      "Paul G. Spirakis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.04836",
    "title": "Consistency Learning via Decoding Path Augmentation for Transformers in  Human Object Interaction Detection",
    "abstract": "Human-Object Interaction detection is a holistic visual recognition task that entails object detection as well as interaction classification. Previous works of HOI detection has been addressed by the various compositions of subset predictions, e.g., Image -> HO -> I, Image -> HI -> O. Recently, transformer based architecture for HOI has emerged, which directly predicts the HOI triplets in an end-to-end fashion (Image -> HOI). Motivated by various inference paths for HOI detection, we propose cross-path consistency learning (CPC), which is a novel end-to-end learning strategy to improve HOI detection for transformers by leveraging augmented decoding paths. CPC learning enforces all the possible predictions from permuted inference sequences to be consistent. This simple scheme makes the model learn consistent representations, thereby improving generalization without increasing model capacity. Our experiments demonstrate the effectiveness of our method, and we achieved significant improvement on V-COCO and HICO-DET compared to the baseline models. Our code is available at https://github.com/mlvlab/CPChoi. ",
    "url": "https://arxiv.org/abs/2204.04836",
    "authors": [
      "Jihwan Park",
      "SeungJun Lee",
      "Hwan Heo",
      "Hyeong Kyu Choi",
      "Hyunwoo J.Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04837",
    "title": "Dependable Intrusion Detection System for IoT: A Deep Transfer  Learning-based Approach",
    "abstract": "Security concerns for IoT applications have been alarming because of their widespread use in different enterprise systems. The potential threats to these applications are constantly emerging and changing, and therefore, sophisticated and dependable defense solutions are necessary against such threats. With the rapid development of IoT networks and evolving threat types, the traditional machine learning-based IDS must update to cope with the security requirements of the current sustainable IoT environment. In recent years, deep learning, and deep transfer learning have progressed and experienced great success in different fields and have emerged as a potential solution for dependable network intrusion detection. However, new and emerging challenges have arisen related to the accuracy, efficiency, scalability, and dependability of the traditional IDS in a heterogeneous IoT setup. This manuscript proposes a deep transfer learning-based dependable IDS model that outperforms several existing approaches. The unique contributions include effective attribute selection, which is best suited to identify normal and attack scenarios for a small amount of labeled data, designing a dependable deep transfer learning-based ResNet model, and evaluating considering real-world data. To this end, a comprehensive experimental performance evaluation has been conducted. Extensive analysis and performance evaluation show that the proposed model is robust, more efficient, and has demonstrated better performance, ensuring dependability. ",
    "url": "https://arxiv.org/abs/2204.04837",
    "authors": [
      "Sk. Tanzir Mehedi",
      "Adnan Anwar",
      "Ziaur Rahman",
      "Kawsar Ahmed",
      "Rafiqul Islam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04844",
    "title": "HFL at SemEval-2022 Task 8: A Linguistics-inspired Regression Model with  Data Augmentation for Multilingual News Similarity",
    "abstract": "This paper describes our system designed for SemEval-2022 Task 8: Multilingual News Article Similarity. We proposed a linguistics-inspired model trained with a few task-specific strategies. The main techniques of our system are: 1) data augmentation, 2) multi-label loss, 3) adapted R-Drop, 4) samples reconstruction with the head-tail combination. We also present a brief analysis of some negative methods like two-tower architecture. Our system ranked 1st on the leaderboard while achieving a Pearson's Correlation Coefficient of 0.818 on the official evaluation set. ",
    "url": "https://arxiv.org/abs/2204.04844",
    "authors": [
      "Zihang Xu",
      "Ziqing Yang",
      "Yiming Cui",
      "Zhigang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04853",
    "title": "Neural Lagrangian Schr\u00f6dinger bridge",
    "abstract": "Population dynamics is the study of temporal and spatial variation in the size of populations of organisms and is a major part of population ecology. One of the main difficulties in analyzing population dynamics is that we can only obtain observation data with coarse time intervals from fixed-point observations due to experimental costs or other constraints. Recently, modeling population dynamics by using continuous normalizing flows (CNFs) and dynamic optimal transport has been proposed to infer the expected trajectory of samples from a fixed-point observed population. While the sample behavior in CNF is deterministic, the actual sample in biological systems moves in an essentially random yet directional manner. Moreover, when a sample moves from point A to point B in dynamical systems, its trajectory is such that the corresponding action has the smallest possible value, known as the principle of least action. To satisfy these requirements of the sample trajectories, we formulate the Lagrangian Schr\\\"odinger bridge (LSB) problem and propose to solve it approximately using neural SDE with regularization. We also develop a model architecture that enables faster computation. Our experiments show that our solution to the LSB problem can approximate the dynamics at the population level and that using the prior knowledge introduced by the Lagrangian enables us to estimate the trajectories of individual samples with stochastic behavior. ",
    "url": "https://arxiv.org/abs/2204.04853",
    "authors": [
      "Takeshi Koshizuka",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2204.04855",
    "title": "Fusion of Self-supervised Learned Models for MOS Prediction",
    "abstract": "We participated in the mean opinion score (MOS) prediction challenge, 2022. This challenge aims to predict MOS scores of synthetic speech on two tracks, the main track and a more challenging sub-track: out-of-domain (OOD). To improve the accuracy of the predicted scores, we have explored several model fusion-related strategies and proposed a fused framework in which seven pretrained self-supervised learned (SSL) models have been engaged. These pretrained SSL models are derived from three ASR frameworks, including Wav2Vec, Hubert, and WavLM. For the OOD track, we followed the 7 SSL models selected on the main track and adopted a semi-supervised learning method to exploit the unlabeled data. According to the official analysis results, our system has achieved 1st rank in 6 out of 16 metrics and is one of the top 3 systems for 13 out of 16 metrics. Specifically, we have achieved the highest LCC, SRCC, and KTAU scores at the system level on main track, as well as the best performance on the LCC, SRCC, and KTAU evaluation metrics at the utterance level on OOD track. Compared with the basic SSL models, the prediction accuracy of the fused system has been largely improved, especially on OOD sub-track. ",
    "url": "https://arxiv.org/abs/2204.04855",
    "authors": [
      "Zhengdong Yang",
      "Wangjin Zhou",
      "Chenhui Chu",
      "Sheng Li",
      "Raj Dabre",
      "Raphael Rubino",
      "Yi Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.04861",
    "title": "SUMD: Super U-shaped Matrix Decomposition Convolutional neural network  for Image denoising",
    "abstract": "In this paper, we propose a novel and efficient CNN-based framework that leverages local and global context information for image denoising. Due to the limitations of convolution itself, the CNN-based method is generally unable to construct an effective and structured global feature representation, usually called the long-distance dependencies in the Transformer-based method. To tackle this problem, we introduce the matrix decomposition module(MD) in the network to establish the global context feature, comparable to the Transformer based method performance. Inspired by the design of multi-stage progressive restoration of U-shaped architecture, we further integrate the MD module into the multi-branches to acquire the relative global feature representation of the patch range at the current stage. Then, the stage input gradually rises to the overall scope and continuously improves the final feature. Experimental results on various image denoising datasets: SIDD, DND, and synthetic Gaussian noise datasets show that our model(SUMD) can produce comparable visual quality and accuracy results with Transformer-based methods. ",
    "url": "https://arxiv.org/abs/2204.04861",
    "authors": [
      "QiFan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04865",
    "title": "A novel stereo matching pipeline with robustness and unfixed disparity  search range",
    "abstract": "Stereo matching is an essential basis for various applications, but most stereo matching methods have poor generalization performance and require a fixed disparity search range. Moreover, current stereo matching methods focus on the scenes that only have positive disparities, but ignore the scenes that contain both positive and negative disparities, such as 3D movies. In this paper, we present a new stereo matching pipeline that first computes semi-dense disparity maps based on binocular disparity, and then completes the rest depending on monocular cues. The new stereo matching pipeline have the following advantages: It 1) has better generalization performance than most of the current stereo matching methods; 2) relaxes the limitation of a fixed disparity search range; 3) can handle the scenes that involve both positive and negative disparities, which has more potential applications, such as view synthesis in 3D multimedia and VR/AR. Experimental results demonstrate the effectiveness of our new stereo matching pipeline. ",
    "url": "https://arxiv.org/abs/2204.04865",
    "authors": [
      "Jiazhi Liu",
      "Feng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04867",
    "title": "Structured Graph Variational Autoencoders for Indoor Furniture layout  Generation",
    "abstract": "We present a structured graph variational autoencoder for generating the layout of indoor 3D scenes. Given the room type (e.g., living room or library) and the room layout (e.g., room elements such as floor and walls), our architecture generates a collection of objects (e.g., furniture items such as sofa, table and chairs) that is consistent with the room type and layout. This is a challenging problem because the generated scene should satisfy multiple constrains, e.g., each object must lie inside the room and two objects cannot occupy the same volume. To address these challenges, we propose a deep generative model that encodes these relationships as soft constraints on an attributed graph (e.g., the nodes capture attributes of room and furniture elements, such as class, pose and size, and the edges capture geometric relationships such as relative orientation). The architecture consists of a graph encoder that maps the input graph to a structured latent space, and a graph decoder that generates a furniture graph, given a latent code and the room graph. The latent space is modeled with auto-regressive priors, which facilitates the generation of highly structured scenes. We also propose an efficient training procedure that combines matching and constrained learning. Experiments on the 3D-FRONT dataset show that our method produces scenes that are diverse and are adapted to the room layout. ",
    "url": "https://arxiv.org/abs/2204.04867",
    "authors": [
      "Aditya Chattopadhyay",
      "Xi Zhang",
      "David Paul Wipf",
      "Rene Vidal",
      "Himanshu Arora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04868",
    "title": "On complex roots of the independence polynomial",
    "abstract": "It is known from the work of Shearer (1985) (and also Scott and Sokal (2005)) that the independence polynomial $Z_G(\\lambda)$ of a graph $G$ of maximum degree at most $d+1$ does not vanish provided that $\\vert{\\lambda}\\vert \\leq \\frac{d^d}{(d+1)^{d+1}}$. Significant extensions of this result have recently been given in the case $\\Re \\lambda \\geq 0$ by Peters and Regts (2019) and Bencs and Csikv\\'ari (arxiv:1807.08963). In this paper, our motivation is to further extend these results and find zero free regions when $\\Re \\lambda \\leq 0$. We begin by giving new geometric criteria for establishing zero-free regions as well as for carrying out semi-rigorous numerical explorations. We then provide two examples of the (rigorous) use of these criteria, by establishing two new zero-free regions in the left-half plane. We also improve upon the results of Bencs and P\\'eter Csikv\\'ari (arxiv:1807.08963) for the right half-plane using our framework. By a direct application of the interpolation method of Barvinok, combined with extensions due to Patel and Regts, these results also imply deterministic polynomial time approximation algorithms for the independence polynomial of bounded degree graphs in the new zero-free regions. ",
    "url": "https://arxiv.org/abs/2204.04868",
    "authors": [
      "Ferenc Bencs",
      "P\u00e9ter Csikv\u00e1ri",
      "Piyush Srivastava",
      "Jan Vondr\u00e1k"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2204.04874",
    "title": "Augmentation-Free Graph Contrastive Learning",
    "abstract": "Graph contrastive learning (GCL) is the most representative and prevalent self-supervised learning approach for graph-structured data. Despite its remarkable success, existing GCL methods highly rely on an augmentation scheme to learn the representations invariant across different augmentation views. In this work, we revisit such a convention in GCL through examining the effect of augmentation techniques on graph data via the lens of spectral theory. We found that graph augmentations preserve the low-frequency components and perturb the middle- and high-frequency components of the graph, which contributes to the success of GCL algorithms on homophilic graphs but hinders its application on heterophilic graphs, due to the high-frequency preference of heterophilic data. Motivated by this, we propose a novel, theoretically-principled, and augmentation-free GCL method, named AF-GCL, that (1) leverages the features aggregated by Graph Neural Network to construct the self-supervision signal instead of augmentations and therefore (2) is less sensitive to the graph homophily degree. Theoretically, We present the performance guarantee for AF-GCL as well as an analysis for understanding the efficacy of AF-GCL. Extensive experiments on 14 benchmark datasets with varying degrees of heterophily show that AF-GCL presents competitive or better performance on homophilic graphs and outperforms all existing state-of-the-art GCL methods on heterophilic graphs with significantly less computational overhead. ",
    "url": "https://arxiv.org/abs/2204.04874",
    "authors": [
      "Haonan Wang",
      "Jieyu Zhang",
      "Qi Zhu",
      "Wei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.04876",
    "title": "Lyapunov-Guided Embedding for Hyperparameter Selection in Recurrent  Neural Networks",
    "abstract": "Recurrent Neural Networks (RNN) are ubiquitous computing systems for sequences and multivariate time series data. While several robust architectures of RNN are known, it is unclear how to relate RNN initialization, architecture, and other hyperparameters with accuracy for a given task. In this work, we propose to treat RNN as dynamical systems and to correlate hyperparameters with accuracy through Lyapunov spectral analysis, a methodology specifically designed for nonlinear dynamical systems. To address the fact that RNN features go beyond the existing Lyapunov spectral analysis, we propose to infer relevant features from the Lyapunov spectrum with an Autoencoder and an embedding of its latent representation (AeLLE). Our studies of various RNN architectures show that AeLLE successfully correlates RNN Lyapunov spectrum with accuracy. Furthermore, the latent representation learned by AeLLE is generalizable to novel inputs from the same task and is formed early in the process of RNN training. The latter property allows for the prediction of the accuracy to which RNN would converge when training is complete. We conclude that representation of RNN through Lyapunov spectrum along with AeLLE, and assists with hyperparameter selection of RNN, provides a novel method for organization and interpretation of variants of RNN architectures. ",
    "url": "https://arxiv.org/abs/2204.04876",
    "authors": [
      "Ryan Vogt",
      "Yang Zheng",
      "Eli Shlizerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.04879",
    "title": "How to Find Your Friendly Neighborhood: Graph Attention Design with  Self-Supervision",
    "abstract": "Attention mechanism in graph neural networks is designed to assign larger weights to important neighbor nodes for better representation. However, what graph attention learns is not understood well, particularly when graphs are noisy. In this paper, we propose a self-supervised graph attention network (SuperGAT), an improved graph attention model for noisy graphs. Specifically, we exploit two attention forms compatible with a self-supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. By encoding edges, SuperGAT learns more expressive attention in distinguishing mislinked neighbors. We find two graph characteristics influence the effectiveness of attention forms and self-supervision: homophily and average degree. Thus, our recipe provides guidance on which attention design to use when those two graph characteristics are known. Our experiment on 17 real-world datasets demonstrates that our recipe generalizes across 15 datasets of them, and our models designed by recipe show improved performance over baselines. ",
    "url": "https://arxiv.org/abs/2204.04879",
    "authors": [
      "Dongkwan Kim",
      "Alice Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.04888",
    "title": "Knowledge Graph and Accurate Portrait Construction of Scientific and  Technological Academic Conferences",
    "abstract": "In recent years, with the continuous progress of science and technology, the number of scientific research achievements is increasing day by day, as the exchange platform and medium of scientific research achievements, the scientific and technological academic conferences have become more and more abundant. The convening of scientific and technological academic conferences will bring large number of academic papers, researchers, research institutions and other data, and the massive data brings difficulties for researchers to obtain valuable information. Therefore, it is of great significance to use deep learning technology to mine the core information in the data of scientific and technological academic conferences, and to realize a knowledge graph and accurate portrait system of scientific and technological academic conferences, so that researchers can obtain scientific research information faster. ",
    "url": "https://arxiv.org/abs/2204.04888",
    "authors": [
      "Runyu Yu",
      "Zhe Xue",
      "Ang Li"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04891",
    "title": "Methods of Informational Trends Analytics and Fake News Detection on  Twitter",
    "abstract": "In the paper, different approaches for the analysis of news trends on Twitter has been considered. For the analysis and case study, informational trends on Twitter caused by Russian invasion of Ukraine in 2022 year have been studied. A deep learning approach for fake news detection has been analyzed. The use of the theory of frequent itemsets and association rules, graph theory for news trends analytics have been considered. ",
    "url": "https://arxiv.org/abs/2204.04891",
    "authors": [
      "Bohdan M. Pavlyshenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.04898",
    "title": "PM4Py-GPU: a High-Performance General-Purpose Library for Process Mining",
    "abstract": "Open-source process mining provides many algorithms for the analysis of event data which could be used to analyze mainstream processes (e.g., O2C, P2P, CRM). However, compared to commercial tools, they lack the performance and struggle to analyze large amounts of data. This paper presents PM4Py-GPU, a Python process mining library based on the NVIDIA RAPIDS framework. Thanks to the dataframe columnar storage and the high level of parallelism, a significant speed-up is achieved on classic process mining computations and processing activities. ",
    "url": "https://arxiv.org/abs/2204.04898",
    "authors": [
      "Alessandro Berti",
      "Minh Phan Nghia",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2204.04910",
    "title": "A-DRIVE: Autonomous Deadlock Detection and Recovery at Road  Intersections for Connected and Automated Vehicles",
    "abstract": "Connected and Automated Vehicles (CAVs) are highly expected to improve traffic throughput and safety at road intersections, single-track lanes, and construction zones. However, multiple CAVs can block each other and create a mutual deadlock around these road segments (i) when vehicle systems have a failure, such as a communication failure, control failure, or localization failure and/or (ii) when vehicles use a long shared road segment. In this paper, we present an Autonomous Deadlock Detection and Recovery Protocol at Intersections for Automated Vehicles named A-DRIVE that is a decentralized and time-sensitive technique to improve traffic throughput and shorten worst-case recovery time. To enable the deadlock recovery with automated vehicles and with human-driven vehicles, A-DRIVE includes two components: V2V communication-based A-DRIVE and Local perception-based A-DRIVE. V2V communication-based A-DRIVE is designed for homogeneous traffic environments in which all the vehicles are connected and automated. Local perception-based A-DRIVE is for mixed traffic, where CAVs, non-connected automated vehicles, and human-driven vehicles co-exist and cooperate with one another. Since these two components are not exclusive, CAVs inclusively and seamlessly use them in practice. Finally, our simulation results show that A-DRIVE improves traffic throughput compared to a baseline protocol. ",
    "url": "https://arxiv.org/abs/2204.04910",
    "authors": [
      "Shunsuke Aoki",
      "Ragunathan",
      "Rajkumar"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2204.04911",
    "title": "Category-Aware Transformer Network for Better Human-Object Interaction  Detection",
    "abstract": "Human-Object Interactions (HOI) detection, which aims to localize a human and a relevant object while recognizing their interaction, is crucial for understanding a still image. Recently, transformer-based models have significantly advanced the progress of HOI detection. However, the capability of these models has not been fully explored since the Object Query of the model is always simply initialized as just zeros, which would affect the performance. In this paper, we try to study the issue of promoting transformer-based HOI detectors by initializing the Object Query with category-aware semantic information. To this end, we innovatively propose the Category-Aware Transformer Network (CATN). Specifically, the Object Query would be initialized via category priors represented by an external object detection model to yield better performance. Moreover, such category priors can be further used for enhancing the representation ability of features via the attention mechanism. We have firstly verified our idea via the Oracle experiment by initializing the Object Query with the groundtruth category information. And then extensive experiments have been conducted to show that a HOI detection model equipped with our idea outperforms the baseline by a large margin to achieve a new state-of-the-art result. ",
    "url": "https://arxiv.org/abs/2204.04911",
    "authors": [
      "Leizhen Dong",
      "Zhimin Li",
      "Kunlun Xu",
      "Zhijun Zhang",
      "Luxin Yan",
      "Sheng Zhong",
      "Xu Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04913",
    "title": "Permutation-Invariant Relational Network for Multi-person 3D Pose  Estimation",
    "abstract": "Recovering multi-person 3D poses from a single RGB image is a severely ill-conditioned problem due not only to the inherent 2D-3D depth ambiguity but also because of inter-person occlusions and body truncations. Recent works have shown promising results by simultaneously reasoning for different people but in all cases within a local neighborhood. An interesting exception is PI-Net, which introduces a self-attention block to reason for all people in the image at the same time and refine potentially noisy initial 3D poses. However, the proposed methodology requires defining one of the individuals as a reference, and the outcome of the algorithm is sensitive to this choice. In this paper, we model people interactions at a whole, independently of their number, and in a permutation-invariant manner building upon the Set Transformer. We leverage on this representation to refine the initial 3D poses estimated by off-the-shelf detectors. A thorough evaluation demonstrates that our approach is able to boost the performance of the initially estimated 3D poses by large margins, achieving state-of-the-art results on MuPoTS-3D, CMU Panoptic and NBA2K datasets. Additionally, the proposed module is computationally efficient and can be used as a drop-in complement for any 3D pose detector in multi-people scenes. ",
    "url": "https://arxiv.org/abs/2204.04913",
    "authors": [
      "Nicolas Ugrinovic",
      "Adria Ruiz",
      "Antonio Agudo",
      "Alberto Sanfeliu",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04918",
    "title": "When NAS Meets Trees: An Efficient Algorithm for Neural Architecture  Search",
    "abstract": "The key challenge in neural architecture search (NAS) is designing how to explore wisely in the huge search space. We propose a new NAS method called TNAS (NAS with trees), which improves search efficiency by exploring only a small number of architectures while also achieving a higher search accuracy. TNAS introduces an architecture tree and a binary operation tree, to factorize the search space and substantially reduce the exploration size. TNAS performs a modified bi-level Breadth-First Search in the proposed trees to discover a high-performance architecture. Impressively, TNAS finds the global optimal architecture on CIFAR-10 with test accuracy of 94.37\\% in four GPU hours in NAS-Bench-201. The average test accuracy is 94.35\\%, which outperforms the state-of-the-art. Code is available at: \\url{https://github.com/guochengqian/TNAS}. ",
    "url": "https://arxiv.org/abs/2204.04918",
    "authors": [
      "Guocheng Qian",
      "Xuanyang Zhang",
      "Guohao Li",
      "Chen Zhao",
      "Yukang Chen",
      "Xiangyu Zhang",
      "Bernard Ghanem",
      "Jian Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04944",
    "title": "Semantic Segmentation for Point Cloud Scenes via Dilated Graph Feature  Aggregation and Pyramid Decoders",
    "abstract": "Semantic segmentation of point clouds generates comprehensive understanding of scenes through densely predicting the category for each point. Due to the unicity of receptive field, semantic segmentation of point clouds remains challenging for the expression of multi-receptive field features, which brings about the misclassification of instances with similar spatial structures. In this paper, we propose a graph convolutional network DGFA-Net rooted in dilated graph feature aggregation (DGFA), guided by multi-basis aggregation loss (MALoss) calculated through Pyramid Decoders. To configure multi-receptive field features, DGFA which takes the proposed dilated graph convolution (DGConv) as its basic building block, is designed to aggregate multi-scale feature representation by capturing dilated graphs with various receptive regions. By simultaneously considering penalizing the receptive field information with point sets of different resolutions as calculation bases, we introduce Pyramid Decoders driven by MALoss for the diversity of receptive field bases. Combining these two aspects, DGFA-Net significantly improves the segmentation performance of instances with similar spatial structures. Experiments on S3DIS, ShapeNetPart and Toronto-3D show that DGFA-Net outperforms the baseline approach, achieving a new state-of-the-art segmentation performance. ",
    "url": "https://arxiv.org/abs/2204.04944",
    "authors": [
      "Yongqiang Mao",
      "Xian Sun",
      "Wenhui Diao",
      "Kaiqiang Chen",
      "Zonghao Guo",
      "Xiaonan Lu",
      "Kun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04952",
    "title": "MGIMN: Multi-Grained Interactive Matching Network for Few-shot Text  Classification",
    "abstract": "Text classification struggles to generalize to unseen classes with very few labeled text instances per class. In such a few-shot learning (FSL) setting, metric-based meta-learning approaches have shown promising results. Previous studies mainly aim to derive a prototype representation for each class. However, they neglect that it is challenging-yet-unnecessary to construct a compact representation which expresses the entire meaning for each class. They also ignore the importance to capture the inter-dependency between query and the support set for few-shot text classification. To deal with these issues, we propose a meta-learning based method MGIMN which performs instance-wise comparison followed by aggregation to generate class-wise matching vectors instead of prototype learning. The key of instance-wise comparison is the interactive matching within the class-specific context and episode-specific context. Extensive experiments demonstrate that the proposed method significantly outperforms the existing state-of-the-art approaches, under both the standard FSL and generalized FSL settings. ",
    "url": "https://arxiv.org/abs/2204.04952",
    "authors": [
      "Jianhai Zhang",
      "Mieradilijiang Maimaiti",
      "Xing Gao",
      "Yuanhang Zheng",
      "Ji Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.04959",
    "title": "HAKG: Hierarchy-Aware Knowledge Gated Network for Recommendation",
    "abstract": "Knowledge graph (KG) plays an increasingly important role to improve the recommendation performance and interpretability. A recent technical trend is to design end-to-end models based on information propagation schemes. However, existing propagation-based methods fail to (1) model the underlying hierarchical structures and relations, and (2) capture the high-order collaborative signals of items for learning high-quality user and item representations. In this paper, we propose a new model, called Hierarchy-Aware Knowledge Gated Network (HAKG), to tackle the aforementioned problems. Technically, we model users and items (that are captured by a user-item graph), as well as entities and relations (that are captured in a KG) in hyperbolic space, and design a hyperbolic aggregation scheme to gather relational contexts over KG. Meanwhile, we introduce a novel angle constraint to preserve characteristics of items in the embedding space. Furthermore, we propose a dual item embeddings design to represent and propagate collaborative signals and knowledge associations separately, and leverage the gated aggregation to distill discriminative information for better capturing user behavior patterns. Experimental results on three benchmark datasets show that, HAKG achieves significant improvement over the state-of-the-art methods like CKAN, Hyper-Know, and KGIN. Further analyses on the learned hyperbolic embeddings confirm that HAKG offers meaningful insights into the hierarchies of data. ",
    "url": "https://arxiv.org/abs/2204.04959",
    "authors": [
      "Yuntao Du",
      "Xinjun Zhu",
      "Lu Chen",
      "Baihua Zheng",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.04965",
    "title": "Multistream neural architectures for cued-speech recognition using a  pre-trained visual feature extractor and constrained CTC decoding",
    "abstract": "This paper proposes a simple and effective approach for automatic recognition of Cued Speech (CS), a visual communication tool that helps people with hearing impairment to understand spoken language with the help of hand gestures that can uniquely identify the uttered phonemes in complement to lipreading. The proposed approach is based on a pre-trained hand and lips tracker used for visual feature extraction and a phonetic decoder based on a multistream recurrent neural network trained with connectionist temporal classification loss and combined with a pronunciation lexicon. The proposed system is evaluated on an updated version of the French CS dataset CSF18 for which the phonetic transcription has been manually checked and corrected. With a decoding accuracy at the phonetic level of 70.88%, the proposed system outperforms our previous CNN-HMM decoder and competes with more complex baselines. ",
    "url": "https://arxiv.org/abs/2204.04965",
    "authors": [
      "Sanjana Sankar",
      "Denis Beautemps",
      "Thomas Hueber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.04968",
    "title": "Bimodal Camera Pose Prediction for Endoscopy",
    "abstract": "Deducing the 3D structure of endoscopic scenes from images remains extremely challenging. In addition to deformation and view-dependent lighting, tubular structures like the colon present problems stemming from the self-occluding, repetitive anatomical structures. In this paper, we propose SimCol, a synthetic dataset for camera pose estimation in colonoscopy and a novel method that explicitly learns a bimodal distribution to predict the endoscope pose. Our dataset replicates real colonoscope motion and highlights drawbacks of existing methods. We publish 18k RGB images from simulated colonoscopy with corresponding depth and camera poses and make our data generation environment in Unity publicly available. We evaluate different camera pose prediction methods and demonstrate that, when trained on our data, they generalize to real colonoscopy sequences and our bimodal approach outperforms prior unimodal work. ",
    "url": "https://arxiv.org/abs/2204.04968",
    "authors": [
      "Anita Rau",
      "Binod Bhattarai",
      "Lourdes Agapito",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04977",
    "title": "Regularization-based Pruning of Irrelevant Weights in Deep Neural  Architectures",
    "abstract": "Deep neural networks exploiting millions of parameters are nowadays the norm in deep learning applications. This is a potential issue because of the great amount of computational resources needed for training, and of the possible loss of generalization performance of overparametrized networks. We propose in this paper a method for learning sparse neural topologies via a regularization technique which identifies non relevant weights and selectively shrinks their norm, while performing a classic update for relevant ones. This technique, which is an improvement of classical weight decay, is based on the definition of a regularization term which can be added to any loss functional regardless of its form, resulting in a unified general framework exploitable in many different contexts. The actual elimination of parameters identified as irrelevant is handled by an iterative pruning algorithm. We tested the proposed technique on different image classification and Natural language generation tasks, obtaining results on par or better then competitors in terms of sparsity and metrics, while achieving strong models compression. ",
    "url": "https://arxiv.org/abs/2204.04977",
    "authors": [
      "Giovanni Bonetta",
      "Matteo Ribero",
      "Rossella Cancelliere"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04983",
    "title": "T- Hop: Tensor representation of paths in graph convolutional networks",
    "abstract": "We describe a method for encoding path information in graphs into a 3-d tensor. We show a connection between the introduced path representation scheme and powered adjacency matrices. To alleviate the heavy computational demands of working with the 3-d tensor, we propose to apply dimensionality reduction on the depth axis of the tensor. We then describe our the reduced 3-d matrix can be parlayed into a plausible graph convolutional layer, by infusing it into an established graph convolutional network framework such as MixHop. ",
    "url": "https://arxiv.org/abs/2204.04983",
    "authors": [
      "Abdulrahman Ibraheem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05010",
    "title": "Certified Reduced Basis Method for the Damped Wave Equations on Networks",
    "abstract": "In this paper we present a reduced basis method which yields structure-preservation and a tight a posteriori error bound for the simulation of the damped wave equations on networks. The error bound is based on the exponential decay of the energy inside the system and therefore allows for sharp bounds without the need of regularization parameters. The fast convergence of the reduced solution to the truth solution as well as the tightness of the error bound are verified numerically using an academic network as example. ",
    "url": "https://arxiv.org/abs/2204.05010",
    "authors": [
      "Nadine Stahl",
      "Bj\u00f6rn Liljegren-Sailer",
      "Nicole Marheineke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.05021",
    "title": "Landmarks and Regions: A Robust Approach to Data Extraction",
    "abstract": "We propose a new approach to extracting data items or field values from semi-structured documents. Examples of such problems include extracting passenger name, departure time and departure airport from a travel itinerary, or extracting price of an item from a purchase receipt. Traditional approaches to data extraction use machine learning or program synthesis to process the whole document to extract the desired fields. Such approaches are not robust to format changes in the document, and the extraction process typically fails even if changes are made to parts of the document that are unrelated to the desired fields of interest. We propose a new approach to data extraction based on the concepts of landmarks and regions. Humans routinely use landmarks in manual processing of documents to zoom in and focus their attention on small regions of interest in the document. Inspired by this human intuition, we use the notion of landmarks in program synthesis to automatically synthesize extraction programs that first extract a small region of interest, and then automatically extract the desired value from the region in a subsequent step. We have implemented our landmark-based extraction approach in a tool LRSyn, and show extensive evaluation on documents in HTML as well as scanned images of invoices and receipts. Our results show that our approach is robust to various types of format changes that routinely happen in real-world settings. ",
    "url": "https://arxiv.org/abs/2204.05021",
    "authors": [
      "Suresh Parthasarathy",
      "Lincy Pattanaik",
      "Anirudh Khatry",
      "Arun Iyer",
      "Arjun Radhakrishna",
      "Sriram Rajamani",
      "Mohammad Raza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2204.05036",
    "title": "Pareto Conditioned Networks",
    "abstract": "In multi-objective optimization, learning all the policies that reach Pareto-efficient solutions is an expensive process. The set of optimal policies can grow exponentially with the number of objectives, and recovering all solutions requires an exhaustive exploration of the entire state space. We propose Pareto Conditioned Networks (PCN), a method that uses a single neural network to encompass all non-dominated policies. PCN associates every past transition with its episode's return. It trains the network such that, when conditioned on this same return, it should reenact said transition. In doing so we transform the optimization problem into a classification problem. We recover a concrete policy by conditioning the network on the desired Pareto-efficient solution. Our method is stable as it learns in a supervised fashion, thus avoiding moving target issues. Moreover, by using a single network, PCN scales efficiently with the number of objectives. Finally, it makes minimal assumptions on the shape of the Pareto front, which makes it suitable to a wider range of problems than previous state-of-the-art multi-objective reinforcement learning algorithms. ",
    "url": "https://arxiv.org/abs/2204.05036",
    "authors": [
      "Mathieu Reymond",
      "Eugenio Bargiacchi",
      "Ann Now\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05041",
    "title": "Pyramid Grafting Network for One-Stage High Resolution Saliency  Detection",
    "abstract": "Recent salient object detection (SOD) methods based on deep neural network have achieved remarkable performance. However, most of existing SOD models designed for low-resolution input perform poorly on high-resolution images due to the contradiction between the sampling depth and the receptive field size. Aiming at resolving this contradiction, we propose a novel one-stage framework called Pyramid Grafting Network (PGNet), using transformer and CNN backbone to extract features from different resolution images independently and then graft the features from transformer branch to CNN branch. An attention-based Cross-Model Grafting Module (CMGM) is proposed to enable CNN branch to combine broken detailed information more holistically, guided by different source feature during decoding process. Moreover, we design an Attention Guided Loss (AGL) to explicitly supervise the attention matrix generated by CMGM to help the network better interact with the attention from different models. We contribute a new Ultra-High-Resolution Saliency Detection dataset UHRSD, containing 5,920 images at 4K-8K resolutions. To our knowledge, it is the largest dataset in both quantity and resolution for high-resolution SOD task, which can be used for training and testing in future research. Sufficient experiments on UHRSD and widely-used SOD datasets demonstrate that our method achieves superior performance compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.05041",
    "authors": [
      "Chenxi Xie",
      "Changqun Xia",
      "Mingcan Ma",
      "Zhirui Zhao",
      "Xiaowu Chen",
      "Jia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05072",
    "title": "Few-Shot Object Detection in Unseen Domains",
    "abstract": "Few-shot object detection (FSOD) has thrived in recent years to learn novel object classes with limited data by transfering knowledge gained on abundant base classes. FSOD approaches commonly assume that both the scarcely provided examples of novel classes and test-time data belong to the same domain. However, this assumption does not hold in various industrial and robotics applications (e.g., object grasping and manipulation), where a model can learn novel classes from a source domain while inferring on classes from a different target domain. In this work, we address the task of zero-shot domain adaptation, also known as domain generalization, for FSOD. Specifically, we assume that neither images nor labels of the novel classes in the target domain are available during training. Our approach for solving the domain gap is two-fold. First, we leverage a meta-training paradigm, where we learn domain-invariant features on the base classes. Second, we propose various data augmentations techniques on the few shots of novel classes to account for all possible domain-specific information. To further constraint the network into encoding domain-agnostic class-specific representations only, a contrastive loss is proposed to maximize the mutual information between foreground proposals and class prototypes, and to reduce the network's bias to the background information. Our experiments on the T-LESS dataset show that the proposed approach succeeds in alleviating the domain gap considerably without utilizing labels or images of novel categories from the target domain. ",
    "url": "https://arxiv.org/abs/2204.05072",
    "authors": [
      "Karim Guirguis",
      "George Eskandar",
      "Matthias Kayser",
      "Bin Yang",
      "Juergen Beyerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05076",
    "title": "End-to-End Speech Translation for Code Switched Speech",
    "abstract": "Code switching (CS) refers to the phenomenon of interchangeably using words and phrases from different languages. CS can pose significant accuracy challenges to NLP, due to the often monolingual nature of the underlying systems. In this work, we focus on CS in the context of English/Spanish conversations for the task of speech translation (ST), generating and evaluating both transcript and translation. To evaluate model performance on this task, we create a novel ST corpus derived from existing public data sets. We explore various ST architectures across two dimensions: cascaded (transcribe then translate) vs end-to-end (jointly transcribe and translate) and unidirectional (source -> target) vs bidirectional (source <-> target). We show that our ST architectures, and especially our bidirectional end-to-end architecture, perform well on CS speech, even when no CS training data is used. ",
    "url": "https://arxiv.org/abs/2204.05076",
    "authors": [
      "Orion Weller",
      "Matthias Sperber",
      "Telmo Pires",
      "Hendra Setiawan",
      "Christian Gollan",
      "Dominic Telaar",
      "Matthias Paulik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.05077",
    "title": "Learning Trajectories of Hamiltonian Systems with Neural Networks",
    "abstract": "Modeling of conservative systems with neural networks is an area of active research. A popular approach is to use Hamiltonian neural networks (HNNs) which rely on the assumptions that a conservative system is described with Hamilton's equations of motion. Many recent works focus on improving the integration schemes used when training HNNs. In this work, we propose to enhance HNNs with an estimation of a continuous-time trajectory of the modeled system using an additional neural network, called a deep hidden physics model in the literature. We demonstrate that the proposed integration scheme works well for HNNs, especially with low sampling rates, noisy and irregular observations. ",
    "url": "https://arxiv.org/abs/2204.05077",
    "authors": [
      "Katsiaryna Haitsiukevich",
      "Alexander Ilin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.05084",
    "title": "XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font  Generation",
    "abstract": "Generating a new font library is a very labor-intensive and time-consuming job for glyph-rich scripts. Few-shot font generation is thus required, as it requires only a few glyph references without fine-tuning during test. Existing methods follow the style-content disentanglement paradigm and expect novel fonts to be produced by combining the style codes of the reference glyphs and the content representations of the source. However, these few-shot font generation methods either fail to capture content-independent style representations, or employ localized component-wise style representations, which is insufficient to model many Chinese font styles that involve hyper-component features such as inter-component spacing and \"connected-stroke\". To resolve these drawbacks and make the style representations more reliable, we propose a self-supervised cross-modality pre-training strategy and a cross-modality transformer-based encoder that is conditioned jointly on the glyph image and the corresponding stroke labels. The cross-modality encoder is pre-trained in a self-supervised manner to allow effective capture of cross- and intra-modality correlations, which facilitates the content-style disentanglement and modeling style representations of all scales (stroke-level, component-level and character-level). The pre-trained encoder is then applied to the downstream font generation task without fine-tuning. Experimental comparisons of our method with state-of-the-art methods demonstrate our method successfully transfers styles of all scales. In addition, it only requires one reference glyph and achieves the lowest rate of bad cases in the few-shot font generation task 28% lower than the second best ",
    "url": "https://arxiv.org/abs/2204.05084",
    "authors": [
      "Wei Liu",
      "Fangyue Liu",
      "Fei Din",
      "Qian He",
      "Zili Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05088",
    "title": "M^2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified  Birds-Eye View Representation",
    "abstract": "In this paper, we propose M$^2$BEV, a unified framework that jointly performs 3D object detection and map segmentation in the Birds Eye View~(BEV) space with multi-camera image inputs. Unlike the majority of previous works which separately process detection and segmentation, M$^2$BEV infers both tasks with a unified model and improves efficiency. M$^2$BEV efficiently transforms multi-view 2D image features into the 3D BEV feature in ego-car coordinates. Such BEV representation is important as it enables different tasks to share a single encoder. Our framework further contains four important designs that benefit both accuracy and efficiency: (1) An efficient BEV encoder design that reduces the spatial dimension of a voxel feature map. (2) A dynamic box assignment strategy that uses learning-to-match to assign ground-truth 3D boxes with anchors. (3) A BEV centerness re-weighting that reinforces with larger weights for more distant predictions, and (4) Large-scale 2D detection pre-training and auxiliary supervision. We show that these designs significantly benefit the ill-posed camera-based 3D perception tasks where depth information is missing. M$^2$BEV is memory efficient, allowing significantly higher resolution images as input, with faster inference speed. Experiments on nuScenes show that M$^2$BEV achieves state-of-the-art results in both 3D object detection and BEV segmentation, with the best single model achieving 42.5 mAP and 57.0 mIoU in these two tasks, respectively. ",
    "url": "https://arxiv.org/abs/2204.05088",
    "authors": [
      "Enze Xie",
      "Zhiding Yu",
      "Daquan Zhou",
      "Jonah Philion",
      "Anima Anandkumar",
      "Sanja Fidler",
      "Ping Luo",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05096",
    "title": "Block-Segmentation Vectors for Arousal Prediction using Semi-supervised  Learning",
    "abstract": "To handle emotional expressions in computer applications, Russell's circum- plex model has been useful for representing emotions according to valence and arousal. In SentiWordNet, the level of valence is automatically assigned to a large number of synsets (groups of synonyms in WordNet) using semi-supervised learning. However, when assigning the level of arousal, the existing method proposed for SentiWordNet reduces the accuracy of sentiment prediction. In this paper, we propose a block-segmentation vector for predicting the arousal levels of many synsets from a small number of labeled words using semi-supervised learning. We analyze the distribution of arousal and non-arousal words in a corpus of sentences by comparing it with the distribution of valence words. We address the problem that arousal level prediction fails when arousal and non-arousal words are mixed together in some sentences. To capture the features of such arousal and non-arousal words, we generate word vectors based on inverted indexes by block IDs, where the corpus is divided into blocks in the flow of sentences. In the evaluation experiment, we show that the results of arousal prediction with the block-segmentation vectors outperform the results of the previous method in SentiWordNet. ",
    "url": "https://arxiv.org/abs/2204.05096",
    "authors": [
      "Yuki Odaka",
      "Ken Kaneiwa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05101",
    "title": "Concept Drift Adaptation for CTR Prediction in Online Advertising  Systems",
    "abstract": "Click-through rate (CTR) prediction is a crucial task in web search, recommender systems, and online advertisement displaying. In practical application, CTR models often serve with high-speed user-generated data streams, whose underlying distribution rapidly changing over time. The concept drift problem inevitably exists in those streaming data, which can lead to performance degradation due to the timeliness issue. To ensure model freshness, incremental learning has been widely adopted in real-world production systems. However, it is hard for the incremental update to achieve the balance of the CTR models between the adaptability to capture the fast-changing trends and generalization ability to retain common knowledge. In this paper, we propose adaptive mixture of experts (AdaMoE), a new framework to alleviate the concept drift problem by adaptive filtering in the data stream of CTR prediction. The extensive experiments on the offline industrial dataset and online A/B tests show that our AdaMoE significantly outperforms all incremental learning frameworks considered. ",
    "url": "https://arxiv.org/abs/2204.05101",
    "authors": [
      "Congcong Liu",
      "Yuejiang Li",
      "Xiwei Zhao",
      "Changping Peng",
      "Zhangang Lin",
      "Jingping Shao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05102",
    "title": "Convolutional autoencoders for spatially-informed ensemble  post-processing",
    "abstract": "Ensemble weather predictions typically show systematic errors that have to be corrected via post-processing. Even state-of-the-art post-processing methods based on neural networks often solely rely on location-specific predictors that require an interpolation of the physical weather model's spatial forecast fields to the target locations. However, potentially useful predictability information contained in large-scale spatial structures within the input fields is potentially lost in this interpolation step. Therefore, we propose the use of convolutional autoencoders to learn compact representations of spatial input fields which can then be used to augment location-specific information as additional inputs to post-processing models. The benefits of including this spatial information is demonstrated in a case study of 2-m temperature forecasts at surface stations in Germany. ",
    "url": "https://arxiv.org/abs/2204.05102",
    "authors": [
      "Sebastian Lerch",
      "Kai L. Polsterer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2204.05104",
    "title": "Self-Supervised Graph Neural Network for Multi-Source Domain Adaptation",
    "abstract": "Domain adaptation (DA) tries to tackle the scenarios when the test data does not fully follow the same distribution of the training data, and multi-source domain adaptation (MSDA) is very attractive for real world applications. By learning from large-scale unlabeled samples, self-supervised learning has now become a new trend in deep learning. It is worth noting that both self-supervised learning and multi-source domain adaptation share a similar goal: they both aim to leverage unlabeled data to learn more expressive representations. Unfortunately, traditional multi-task self-supervised learning faces two challenges: (1) the pretext task may not strongly relate to the downstream task, thus it could be difficult to learn useful knowledge being shared from the pretext task to the target task; (2) when the same feature extractor is shared between the pretext task and the downstream one and only different prediction heads are used, it is ineffective to enable inter-task information exchange and knowledge sharing. To address these issues, we propose a novel \\textbf{S}elf-\\textbf{S}upervised \\textbf{G}raph Neural Network (SSG), where a graph neural network is used as the bridge to enable more effective inter-task information exchange and knowledge sharing. More expressive representation is learned by adopting a mask token strategy to mask some domain information. Our extensive experiments have demonstrated that our proposed SSG method has achieved state-of-the-art results over four multi-source domain adaptation datasets, which have shown the effectiveness of our proposed SSG method from different aspects. ",
    "url": "https://arxiv.org/abs/2204.05104",
    "authors": [
      "Jin Yuan",
      "Feng Hou",
      "Yangzhou Du",
      "Zhongchao Shi",
      "Xin Geng",
      "Jianping Fan",
      "Yong Rui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05108",
    "title": "Improved Training of Physics-Informed Neural Networks with Model  Ensembles",
    "abstract": "Learning the solution of partial differential equations (PDEs) with a neural network (known in the literature as a physics-informed neural network, PINN) is an attractive alternative to traditional solvers due to its elegancy, greater flexibility and the ease of incorporating observed data. However, training PINNs is notoriously difficult in practice. One problem is the existence of multiple simple (but wrong) solutions which are attractive for PINNs when the solution interval is too large. In this paper, we propose to expand the solution interval gradually to make the PINN converge to the correct solution. To find a good schedule for the solution interval expansion, we train an ensemble of PINNs. The idea is that all ensemble members converge to the same solution in the vicinity of observed data (e.g., initial conditions) while they may be pulled towards different wrong solutions farther away from the observations. Therefore, we use the ensemble agreement as the criterion for including new points for computing the loss derived from PDEs. We show experimentally that the proposed method can improve the accuracy of the found solution. ",
    "url": "https://arxiv.org/abs/2204.05108",
    "authors": [
      "Katsiaryna Haitsiukevich",
      "Alexander Ilin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.05112",
    "title": "FastMapSVM: Classifying Complex Objects Using the FastMap Algorithm and  Support-Vector Machines",
    "abstract": "Neural Networks and related Deep Learning methods are currently at the leading edge of technologies used for classifying objects. However, they generally demand large amounts of time and data for model training; and their learned models can sometimes be difficult to interpret. In this paper, we present FastMapSVM, a novel interpretable Machine Learning framework for classifying complex objects. FastMapSVM combines the strengths of FastMap and Support-Vector Machines. FastMap is an efficient linear-time algorithm that maps complex objects to points in a Euclidean space, while preserving pairwise non-Euclidean distances between them. We demonstrate the efficiency and effectiveness of FastMapSVM in the context of classifying seismograms. We show that its performance, in terms of precision, recall, and accuracy, is comparable to that of other state-of-the-art methods. However, compared to other methods, FastMapSVM uses significantly smaller amounts of time and data for model training. It also provides a perspicuous visualization of the objects and the classification boundaries between them. We expect FastMapSVM to be viable for classification tasks in many other real-world domains. ",
    "url": "https://arxiv.org/abs/2204.05112",
    "authors": [
      "Malcolm C. A. White",
      "Kushal Sharma",
      "Ang Li",
      "T. K. Satish Kumar",
      "Nori Nakata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2204.05113",
    "title": "ShiftNAS: Towards Automatic Generation of Advanced Mulitplication-Less  Neural Networks",
    "abstract": "Multiplication-less neural networks significantly reduce the time and energy cost on the hardware platform, as the compute-intensive multiplications are replaced with lightweight bit-shift operations. However, existing bit-shift networks are all directly transferred from state-of-the-art convolutional neural networks (CNNs), which lead to non-negligible accuracy drop or even failure of model convergence. To combat this, we propose ShiftNAS, the first framework tailoring Neural Architecture Search (NAS) to substantially reduce the accuracy gap between bit-shift neural networks and their real-valued counterparts. Specifically, we pioneer dragging NAS into a shift-oriented search space and endow it with the robust topology-related search strategy and custom regularization and stabilization. As a result, our ShiftNAS breaks through the incompatibility of traditional NAS methods for bit-shift neural networks and achieves more desirable performance in terms of accuracy and convergence. Extensive experiments demonstrate that ShiftNAS sets a new state-of-the-art for bit-shift neural networks, where the accuracy increases (1.69-8.07)% on CIFAR10, (5.71-18.09)% on CIFAR100 and (4.36-67.07)% on ImageNet, especially when many conventional CNNs fail to converge on ImageNet with bit-shift weights. ",
    "url": "https://arxiv.org/abs/2204.05113",
    "authors": [
      "Xiaoxuan Lou",
      "Guowen Xu",
      "Kangjie Chen",
      "Guanlin Li",
      "Jiwei Li",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05126",
    "title": "General Hamiltonian Representation of ML Detection Relying on the  Quantum Approximate Optimization Algorithm",
    "abstract": "The quantum approximate optimization algorithm (QAOA) conceived for solving combinatorial optimization problems has attracted significant interest since it can be run on the existing noisy intermediate-scale quantum (NISQ) devices. A primary step of using the QAOA is the efficient Hamiltonian construction based on different problem instances. Hence, we solve the maximum likelihood (ML) detection problem for general constellations by appropriately adapting the QAOA, which gives rise to a new paradigm in communication systems. We first transform the ML detection problem into a weighted minimum $N$-satisfiability (WMIN-$N$-SAT) problem, where we formulate the objective function of the WMIN-$N$-SAT as a pseudo Boolean function. Furthermore, we formalize the connection between the degree of the objective function and the Gray-labelled modulation constellations. Explicitly, we show a series of results exploring the connection between the coefficients of the monomials and the patterns of the associated constellation points, which substantially simplifies the objective function with respect to the problem Hamiltonian of the QAOA. In particular, for an M-ary Gray-mapped quadrature amplitude modulation (MQAM) constellation, we show that the specific qubits encoding the in-phase components and those encoding the quadrature components are independent in the quantum system of interest, which allows the in-phase and quadrature components to be detected separately using the QAOA. Furthermore, we characterize the degree of the objective function in the WMIN-$N$-SAT problem corresponding to the ML detection of multiple-input and multiple-output (MIMO) channels. Finally, we evaluate the approximation ratio of the QAOA for the ML detection problem of quadrature phase shift keying (QPSK) relying on QAOA circuits of different depths. ",
    "url": "https://arxiv.org/abs/2204.05126",
    "authors": [
      "Jingjing Cui",
      "Gui Lu Long",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2204.05133",
    "title": "On the link between conscious function and general intelligence in  humans and machines",
    "abstract": "In popular media, there is often a connection drawn between the advent of awareness in artificial agents and those same agents simultaneously achieving human or superhuman level intelligence. In this work, we explore the validity and potential application of this seemingly intuitive link between consciousness and intelligence. We do so by examining the cognitive abilities associated with three contemporary theories of conscious function: Global Workspace Theory (GWT), Information Generation Theory (IGT), and Attention Schema Theory (AST). We find that all three theories specifically relate conscious function to some aspect of domain-general intelligence in humans. With this insight, we turn to the field of Artificial Intelligence (AI) and find that, while still far from demonstrating general intelligence, many state-of-the-art deep learning methods have begun to incorporate key aspects of each of the three functional theories. Given this apparent trend, we use the motivating example of mental time travel in humans to propose ways in which insights from each of the three theories may be combined into a unified model. We believe that doing so can enable the development of artificial agents which are not only more generally intelligent but are also consistent with multiple current theories of conscious function. ",
    "url": "https://arxiv.org/abs/2204.05133",
    "authors": [
      "Arthur Juliani",
      "Kai Arulkumaran",
      "Shuntaro Sasai",
      "Ryota Kanai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.05136",
    "title": "SoK: Privacy Preserving Machine Learning using Functional Encryption:  Opportunities and Challenges",
    "abstract": "With the advent of functional encryption, new possibilities for computation on encrypted data have arisen. Functional Encryption enables data owners to grant third-party access to perform specified computations without disclosing their inputs. It also provides computation results in plain, unlike Fully Homomorphic Encryption. The ubiquitousness of machine learning has led to the collection of massive private data in the cloud computing environment. This raises potential privacy issues and the need for more private and secure computing solutions. Numerous efforts have been made in privacy-preserving machine learning (PPML) to address security and privacy concerns. There are approaches based on fully homomorphic encryption (FHE), secure multiparty computation (SMC), and, more recently, functional encryption (FE). However, FE-based PPML is still in its infancy and has not yet gotten much attention compared to FHE-based PPML approaches. In this paper, we provide a systematization of PPML works based on FE summarizing state-of-the-art in the literature. We focus on Inner-product-FE and Quadratic-FE-based machine learning models for the PPML applications. We analyze the performance and usability of the available FE libraries and their applications to PPML. We also discuss potential directions for FE-based PPML approaches. To the best of our knowledge, this is the first work to systematize FE-based PPML approaches. ",
    "url": "https://arxiv.org/abs/2204.05136",
    "authors": [
      "Prajwal Panzade",
      "Daniel Takabi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05141",
    "title": "Learning Object-Centered Autotelic Behaviors with Graph Neural Networks",
    "abstract": "Although humans live in an open-ended world and endlessly face new challenges, they do not have to learn from scratch each time they face the next one. Rather, they have access to a handful of previously learned skills, which they rapidly adapt to new situations. In artificial intelligence, autotelic agents, which are intrinsically motivated to represent and set their own goals, exhibit promising skill adaptation capabilities. However, these capabilities are highly constrained by their policy and goal space representations. In this paper, we propose to investigate the impact of these representations on the learning capabilities of autotelic agents. We study different implementations of autotelic agents using four types of Graph Neural Networks policy representations and two types of goal spaces, either geometric or predicate-based. We show that combining object-centered architectures that are expressive enough with semantic relational goals enables an efficient transfer between skills and promotes behavioral diversity. We also release our graph-based implementations to encourage further research in this direction. ",
    "url": "https://arxiv.org/abs/2204.05141",
    "authors": [
      "Ahmed Akakzia",
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.05183",
    "title": "Building an ASR Error Robust Spoken Virtual Patient System in a Highly  Class-Imbalanced Scenario Without Speech Data",
    "abstract": "A Virtual Patient (VP) is a powerful tool for training medical students to take patient histories, where responding to a diverse set of spoken questions is essential to simulate natural conversations with a student. The performance of such a Spoken Language Understanding system (SLU) can be adversely affected by both the presence of Automatic Speech Recognition (ASR) errors in the test data and a high degree of class imbalance in the SLU training data. While these two issues have been addressed separately in prior work, we develop a novel two-step training methodology that tackles both these issues effectively in a single dialog agent. As it is difficult to collect spoken data from users without a functioning SLU system, our method does not rely on spoken data for training, rather we use an ASR error predictor to \"speechify\" the text data. Our method shows significant improvements over strong baselines on the VP intent classification task at various word error rate settings. ",
    "url": "https://arxiv.org/abs/2204.05183",
    "authors": [
      "Vishal Sunder",
      "Prashant Serai",
      "Eric Fosler-Lussier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.05184",
    "title": "Domain Adversarial Graph Convolutional Network Based on RSSI and  Crowdsensing for Indoor Localization",
    "abstract": "In recent years, due to the wider WiFi coverage and the popularization of mobile communication devices, the technology of indoor positioning using WiFi fingerprints has been rapidly developed. Currently, most supervised methods need to collect a large amount of data to construct fingerprint datasets, which is labor-intensive and time-consuming. To solve the problem, we proposed a novel WiDAGCN model that can be trained with a few labeled site survey data and unlabeled crowdsensing WiFi fingerprints. To comprehensively represent the topology structure of the data, we constructed heterogeneous graphs according to the received signal strength indicators (RSSIs) between the waypoints and WiFi access points (APs). We focus on the graph convolutional network (GCN) method and the representation of graph-level features, which were rarely involved in previous WiFi indoor localization studies. Then, we try to minimize the difference between the source and target domains and make full use of the unlabeled data in the target domain using the domain adversarial training scheme. A public indoor localization dataset containing different buildings was used to evaluate the performance of the model. The experimental results show that our system can achieve a competitive localization accuracy in large buildings such as shopping malls. ",
    "url": "https://arxiv.org/abs/2204.05184",
    "authors": [
      "Mingxin Zhang",
      "Zipei Fan",
      "Ryosuke Shibasaki",
      "Xuan Song"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.05192",
    "title": "Time-Adaptive Recurrent Neural Networks",
    "abstract": "Data are often sampled irregularly in time. Dealing with this using Recurrent Neural Networks (RNNs) traditionally involved ignoring the fact, feeding the time differences as additional inputs, or resampling the data. All these methods have their shortcomings. We propose an elegant alternative approach where instead the RNN is in effect resampled in time to match the time of the data. We use Echo State Network (ESN) and Gated Recurrent Unit (GRU) as the basis for our solution. Such RNNs can be seen as discretizations of continuous-time dynamical systems, which gives a solid theoretical ground for our approach. Similar recent observations have been made in feed-forward neural networks as neural ordinary differential equations. Our Time-Adaptive ESN (TAESN) and GRU (TAGRU) models allow for a direct model time setting and require no additional training, parameter tuning, or computation compared to the regular counterparts, thus retaining their original efficiency. We confirm empirically that our models can effectively compensate for the time-non-uniformity of the data and demonstrate that they compare favorably to data resampling, classical RNN methods, and alternative RNN models proposed to deal with time irregularities on several real-world nonuniform-time datasets. ",
    "url": "https://arxiv.org/abs/2204.05192",
    "authors": [
      "Mantas Luko\u0161evi\u010dius",
      "Arnas Uselis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.05193",
    "title": "Worldwide city transport typology prediction with sentence-BERT based  supervised learning via Wikipedia",
    "abstract": "An overwhelming majority of the world's human population lives in urban areas and cities. Understanding a city's transportation typology is immensely valuable for planners and policy makers whose decisions can potentially impact millions of city residents. Despite the value of understanding a city's typology, labeled data (city and it's typology) is scarce, and spans at most a few hundred cities in the current transportation literature. To break this barrier, we propose a supervised machine learning approach to predict a city's typology given the information in its Wikipedia page. Our method leverages recent breakthroughs in natural language processing, namely sentence-BERT, and shows how the text-based information from Wikipedia can be effectively used as a data source for city typology prediction tasks that can be applied to over 2000 cities worldwide. We propose a novel method for low-dimensional city representation using a city's Wikipedia page, which makes supervised learning of city typology labels tractable even with a few hundred labeled samples. These features are used with labeled city samples to train binary classifiers (logistic regression) for four different city typologies: (i) congestion, (ii) auto-heavy, (iii) transit-heavy, and (iv) bike-friendly cities resulting in reasonably high AUC scores of 0.87, 0.86, 0.61 and 0.94 respectively. Our approach provides sufficient flexibility for incorporating additional variables in the city typology models and can be applied to study other city typologies as well. Our findings can assist a diverse group of stakeholders in transportation and urban planning fields, and opens up new opportunities for using text-based information from Wikipedia (or similar platforms) as data sources in such fields. ",
    "url": "https://arxiv.org/abs/2204.05193",
    "authors": [
      "Srushti Rath",
      "Joseph Y.J. Chow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05208",
    "title": "\"FIJO\": a French Insurance Soft Skill Detection Dataset",
    "abstract": "Understanding the evolution of job requirements is becoming more important for workers, companies and public organizations to follow the fast transformation of the employment market. Fortunately, recent natural language processing (NLP) approaches allow for the development of methods to automatically extract information from job ads and recognize skills more precisely. However, these efficient approaches need a large amount of annotated data from the studied domain which is difficult to access, mainly due to intellectual property. This article proposes a new public dataset, FIJO, containing insurance job offers, including many soft skill annotations. To understand the potential of this dataset, we detail some characteristics and some limitations. Then, we present the results of skill detection algorithms using a named entity recognition approach and show that transformers-based models have good token-wise performances on this dataset. Lastly, we analyze some errors made by our best model to emphasize the difficulties that may arise when applying NLP approaches. ",
    "url": "https://arxiv.org/abs/2204.05208",
    "authors": [
      "David Beauchemin",
      "Julien Laumonier",
      "Yvan Le Ster",
      "Marouane Yassine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05220",
    "title": "CFA: Constraint-based Finetuning Approach for Generalized Few-Shot  Object Detection",
    "abstract": "Few-shot object detection (FSOD) seeks to detect novel categories with limited data by leveraging prior knowledge from abundant base data. Generalized few-shot object detection (G-FSOD) aims to tackle FSOD without forgetting previously seen base classes and, thus, accounts for a more realistic scenario, where both classes are encountered during test time. While current FSOD methods suffer from catastrophic forgetting, G-FSOD addresses this limitation yet exhibits a performance drop on novel tasks compared to the state-of-the-art FSOD. In this work, we propose a constraint-based finetuning approach (CFA) to alleviate catastrophic forgetting, while achieving competitive results on the novel task without increasing the model capacity. CFA adapts a continual learning method, namely Average Gradient Episodic Memory (A-GEM) to G-FSOD. Specifically, more constraints on the gradient search strategy are imposed from which a new gradient update rule is derived, allowing for better knowledge exchange between base and novel classes. To evaluate our method, we conduct extensive experiments on MS-COCO and PASCAL-VOC datasets. Our method outperforms current FSOD and G-FSOD approaches on the novel task with minor degeneration on the base task. Moreover, CFA is orthogonal to FSOD approaches and operates as a plug-and-play module without increasing the model capacity or inference time. ",
    "url": "https://arxiv.org/abs/2204.05220",
    "authors": [
      "Karim Guirguis",
      "Ahmed Hendawy",
      "George Eskandar",
      "Mohamed Abdelsamad",
      "Matthias Kayser",
      "Juergen Beyerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05239",
    "title": "Exploring the Universal Vulnerability of Prompt-based Learning Paradigm",
    "abstract": "Prompt-based learning paradigm bridges the gap between pre-training and fine-tuning, and works effectively under the few-shot setting. However, we find that this learning paradigm inherits the vulnerability from the pre-training stage, where model predictions can be misled by inserting certain triggers into the text. In this paper, we explore this universal vulnerability by either injecting backdoor triggers or searching for adversarial triggers on pre-trained language models using only plain text. In both scenarios, we demonstrate that our triggers can totally control or severely decrease the performance of prompt-based models fine-tuned on arbitrary downstream tasks, reflecting the universal vulnerability of the prompt-based learning paradigm. Further experiments show that adversarial triggers have good transferability among language models. We also find conventional fine-tuning models are not vulnerable to adversarial triggers constructed from pre-trained language models. We conclude by proposing a potential solution to mitigate our attack methods. Code and data are publicly available at https://github.com/leix28/prompt-universal-vulnerability ",
    "url": "https://arxiv.org/abs/2204.05239",
    "authors": [
      "Lei Xu",
      "Yangyi Chen",
      "Ganqu Cui",
      "Hongcheng Gao",
      "Zhiyuan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05245",
    "title": "Approximate Top-$m$ Arm Identification with Heterogeneous Reward  Variances",
    "abstract": "We study the effect of reward variance heterogeneity in the approximate top-$m$ arm identification setting. In this setting, the reward for the $i$-th arm follows a $\\sigma^2_i$-sub-Gaussian distribution, and the agent needs to incorporate this knowledge to minimize the expected number of arm pulls to identify $m$ arms with the largest means within error $\\epsilon$ out of the $n$ arms, with probability at least $1-\\delta$. We show that the worst-case sample complexity of this problem is $$\\Theta\\left( \\sum_{i =1}^n \\frac{\\sigma_i^2}{\\epsilon^2} \\ln\\frac{1}{\\delta} + \\sum_{i \\in G^{m}} \\frac{\\sigma_i^2}{\\epsilon^2} \\ln(m) + \\sum_{j \\in G^{l}} \\frac{\\sigma_j^2}{\\epsilon^2} \\text{Ent}(\\sigma^2_{G^{r}}) \\right),$$ where $G^{m}, G^{l}, G^{r}$ are certain specific subsets of the overall arm set $\\{1, 2, \\ldots, n\\}$, and $\\text{Ent}(\\cdot)$ is an entropy-like function which measures the heterogeneity of the variance proxies. The upper bound of the complexity is obtained using a divide-and-conquer style algorithm, while the matching lower bound relies on the study of a dual formulation. ",
    "url": "https://arxiv.org/abs/2204.05245",
    "authors": [
      "Ruida Zhou",
      "Chao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2204.05255",
    "title": "Narcissus: A Practical Clean-Label Backdoor Attack with Limited  Information",
    "abstract": "Backdoor attacks insert malicious data into a training set so that, during inference time, it misclassifies inputs that have been patched with a backdoor trigger as the malware specified label. For backdoor attacks to bypass human inspection, it is essential that the injected data appear to be correctly labeled. The attacks with such property are often referred to as \"clean-label attacks.\" Existing clean-label backdoor attacks require knowledge of the entire training set to be effective. Obtaining such knowledge is difficult or impossible because training data are often gathered from multiple sources (e.g., face images from different users). It remains a question whether backdoor attacks still present a real threat. This paper provides an affirmative answer to this question by designing an algorithm to mount clean-label backdoor attacks based only on the knowledge of representative examples from the target class. With poisoning equal to or less than 0.5% of the target-class data and 0.05% of the training set, we can train a model to classify test examples from arbitrary classes into the target class when the examples are patched with a backdoor trigger. Our attack works well across datasets and models, even when the trigger presents in the physical world. We explore the space of defenses and find that, surprisingly, our attack can evade the latest state-of-the-art defenses in their vanilla form, or after a simple twist, we can adapt to the downstream defenses. We study the cause of the intriguing effectiveness and find that because the trigger synthesized by our attack contains features as persistent as the original semantic features of the target class, any attempt to remove such triggers would inevitably hurt the model accuracy first. ",
    "url": "https://arxiv.org/abs/2204.05255",
    "authors": [
      "Yi Zeng",
      "Minzhou Pan",
      "Hoang Anh Just",
      "Lingjuan Lyu",
      "Meikang Qiu",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05258",
    "title": "Multi-view graph structure learning using subspace merging on Grassmann  manifold",
    "abstract": "Many successful learning algorithms have been recently developed to represent graph-structured data. For example, Graph Neural Networks (GNNs) have achieved considerable successes in various tasks such as node classification, graph classification, and link prediction. However, these methods are highly dependent on the quality of the input graph structure. One used approach to alleviate this problem is to learn the graph structure instead of relying on a manually designed graph. In this paper, we introduce a new graph structure learning approach using multi-view learning, named MV-GSL (Multi-View Graph Structure Learning), in which we aggregate different graph structure learning methods using subspace merging on Grassmann manifold to improve the quality of the learned graph structures. Extensive experiments are performed to evaluate the effectiveness of the proposed method on two benchmark datasets, Cora and Citeseer. Our experiments show that the proposed method has promising performance compared to single and other combined graph structure learning methods. ",
    "url": "https://arxiv.org/abs/2204.05258",
    "authors": [
      "Razieh Ghiasi",
      "Hossein Amirkhani",
      "Alireza Bosaghzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05265",
    "title": "The Importance of Future Information in Credit Card Fraud Detection",
    "abstract": "Fraud detection systems (FDS) mainly perform two tasks: (i) real-time detection while the payment is being processed and (ii) posterior detection to block the card retrospectively and avoid further frauds. Since human verification is often necessary and the payment processing time is limited, the second task manages the largest volume of transactions. In the literature, fraud detection challenges and algorithms performance are widely studied but the very formulation of the problem is never disrupted: it aims at predicting if a transaction is fraudulent based on its characteristics and the past transactions of the cardholder. Yet, in posterior detection, verification often takes days, so new payments on the card become available before a decision is taken. This is our motivation to propose a new paradigm: posterior fraud detection with \"future\" information. We start by providing evidence of the on-time availability of subsequent transactions, usable as extra context to improve detection. We then design a Bidirectional LSTM to make use of these transactions. On a real-world dataset with over 30 million transactions, it achieves higher performance than a regular LSTM, which is the state-of-the-art classifier for fraud detection that only uses the past context. We also introduce new metrics to show that the proposal catches more frauds, more compromised cards, and based on their earliest frauds. We believe that future works on this new paradigm will have a significant impact on the detection of compromised cards. ",
    "url": "https://arxiv.org/abs/2204.05265",
    "authors": [
      "Van Bach Nguyen",
      "Kanishka Ghosh Dastidar",
      "Michael Granitzer",
      "Wissam Siblini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05274",
    "title": "MIME: Adapting a Single Neural Network for Multi-task Inference with  Memory-efficient Dynamic Pruning",
    "abstract": "Recent years have seen a paradigm shift towards multi-task learning. This calls for memory and energy-efficient solutions for inference in a multi-task scenario. We propose an algorithm-hardware co-design approach called MIME. MIME reuses the weight parameters of a trained parent task and learns task-specific threshold parameters for inference on multiple child tasks. We find that MIME results in highly memory-efficient DRAM storage of neural-network parameters for multiple tasks compared to conventional multi-task inference. In addition, MIME results in input-dependent dynamic neuronal pruning, thereby enabling energy-efficient inference with higher throughput on a systolic-array hardware. Our experiments with benchmark datasets (child tasks)- CIFAR10, CIFAR100, and Fashion-MNIST, show that MIME achieves ~3.48x memory-efficiency and ~2.4-3.1x energy-savings compared to conventional multi-task inference in Pipelined task mode. ",
    "url": "https://arxiv.org/abs/2204.05274",
    "authors": [
      "Abhiroop Bhattacharjee",
      "Yeshwanth Venkatesha",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05289",
    "title": "Towards Online Domain Adaptive Object Detection",
    "abstract": "Existing object detection models assume both the training and test data are sampled from the same source domain. This assumption does not hold true when these detectors are deployed in real-world applications, where they encounter new visual domain. Unsupervised Domain Adaptation (UDA) methods are generally employed to mitigate the adverse effects caused by domain shift. Existing UDA methods operate in an offline manner where the model is first adapted towards the target domain and then deployed in real-world applications. However, this offline adaptation strategy is not suitable for real-world applications as the model frequently encounters new domain shifts. Hence, it becomes critical to develop a feasible UDA method that generalizes to these domain shifts encountered during deployment time in a continuous online manner. To this end, we propose a novel unified adaptation framework that adapts and improves generalization on the target domain in online settings. In particular, we introduce MemXformer - a cross-attention transformer-based memory module where items in the memory take advantage of domain shifts and record prototypical patterns of the target distribution. Further, MemXformer produces strong positive and negative pairs to guide a novel contrastive loss, which enhances target specific representation learning. Experiments on diverse detection benchmarks show that the proposed strategy can produce state-of-the-art performance in both online and offline settings. To the best of our knowledge, this is the first work to address online and offline adaptation settings for object detection. Code at https://github.com/Vibashan/online-od ",
    "url": "https://arxiv.org/abs/2204.05289",
    "authors": [
      "Vibashan VS",
      "Poojan Oza",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05306",
    "title": "Full-Spectrum Out-of-Distribution Detection",
    "abstract": "Existing out-of-distribution (OOD) detection literature clearly defines semantic shift as a sign of OOD but does not have a consensus over covariate shift. Samples experiencing covariate shift but not semantic shift are either excluded from the test set or treated as OOD, which contradicts the primary goal in machine learning -- being able to generalize beyond the training distribution. In this paper, we take into account both shift types and introduce full-spectrum OOD (FS-OOD) detection, a more realistic problem setting that considers both detecting semantic shift and being tolerant to covariate shift; and designs three benchmarks. These new benchmarks have a more fine-grained categorization of distributions (i.e., training ID, covariate-shifted ID, near-OOD, and far-OOD) for the purpose of more comprehensively evaluating the pros and cons of algorithms. To address the FS-OOD detection problem, we propose SEM, a simple feature-based semantics score function. SEM is mainly composed of two probability measures: one is based on high-level features containing both semantic and non-semantic information, while the other is based on low-level feature statistics only capturing non-semantic image styles. With a simple combination, the non-semantic part is cancelled out, which leaves only semantic information in SEM that can better handle FS-OOD detection. Extensive experiments on the three new benchmarks show that SEM significantly outperforms current state-of-the-art methods. Our code and benchmarks are released in https://github.com/Jingkang50/OpenOOD. ",
    "url": "https://arxiv.org/abs/2204.05306",
    "authors": [
      "Jingkang Yang",
      "Kaiyang Zhou",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04217",
    "title": "Feature-enhanced Adversarial Semi-supervised Semantic Segmentation  Network for Pulmonary Embolism Annotation",
    "abstract": "This study established a feature-enhanced adversarial semi-supervised semantic segmentation model to automatically annotate pulmonary embolism lesion areas in computed tomography pulmonary angiogram (CTPA) images. In current studies, all of the PE CTPA image segmentation methods are trained by supervised learning. However, the supervised learning models need to be retrained and the images need to be relabeled when the CTPA images come from different hospitals. This study proposed a semi-supervised learning method to make the model applicable to different datasets by adding a small amount of unlabeled images. By training the model with both labeled and unlabeled images, the accuracy of unlabeled images can be improved and the labeling cost can be reduced. Our semi-supervised segmentation model includes a segmentation network and a discriminator network. We added feature information generated from the encoder of segmentation network to the discriminator so that it can learn the similarity between predicted mask and ground truth mask. This HRNet-based architecture can maintain a higher resolution for convolutional operations so the prediction of small PE lesion areas can be improved. We used the labeled open-source dataset and the unlabeled National Cheng Kung University Hospital (NCKUH) (IRB number: B-ER-108-380) dataset to train the semi-supervised learning model, and the resulting mean intersection over union (mIOU), dice score, and sensitivity achieved 0.3510, 0.4854, and 0.4253, respectively on the NCKUH dataset. Then, we fine-tuned and tested the model with a small amount of unlabeled PE CTPA images from China Medical University Hospital (CMUH) (IRB number: CMUH110-REC3-173) dataset. Comparing the results of our semi-supervised model with the supervised model, the mIOU, dice score, and sensitivity improved from 0.2344, 0.3325, and 0.3151 to 0.3721, 0.5113, and 0.4967, respectively. ",
    "url": "https://arxiv.org/abs/2204.04217",
    "authors": [
      "Ting-Wei Cheng",
      "Jerry Chang",
      "Ching-Chun Huang",
      "Chin Kuo",
      "Yun-Chien Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04218",
    "title": "Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes  for Medical Image Super-Resolution",
    "abstract": "Super-resolving medical images can help physicians in providing more accurate diagnostics. In many situations, computed tomography (CT) or magnetic resonance imaging (MRI) techniques output several scans (modes) during a single investigation, which can jointly be used (in a multimodal fashion) to further boost the quality of super-resolution results. To this end, we propose a novel multimodal multi-head convolutional attention module to super-resolve CT and MRI scans. Our attention module uses the convolution operation to perform joint spatial-channel attention on multiple concatenated input tensors, where the kernel (receptive field) size controls the reduction rate of the spatial attention and the number of convolutional filters controls the reduction rate of the channel attention, respectively. We introduce multiple attention heads, each head having a distinct receptive field size corresponding to a particular reduction rate for the spatial attention. We integrate our multimodal multi-head convolutional attention (MMHCA) into two deep neural architectures for super-resolution and conduct experiments on three data sets. Our empirical results show the superiority of our attention module over the state-of-the-art attention mechanisms used in super-resolution. Moreover, we conduct an ablation study to assess the impact of the components involved in our attention module, e.g. the number of inputs or the number of heads. ",
    "url": "https://arxiv.org/abs/2204.04218",
    "authors": [
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu",
      "Andreea-Iuliana Miron",
      "Olivian Savencu",
      "Nicolae-Catalin Ristea",
      "Nicolae Verga",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04250",
    "title": "Understanding the Influence of Receptive Field and Network Complexity in  Neural-Network-Guided TEM Image Analysis",
    "abstract": "Trained neural networks are promising tools to analyze the ever-increasing amount of scientific image data, but it is unclear how to best customize these networks for the unique features in transmission electron micrographs. Here, we systematically examine how neural network architecture choices affect how neural networks segment, or pixel-wise separate, crystalline nanoparticles from amorphous background in transmission electron microscopy (TEM) images. We focus on decoupling the influence of receptive field, or the area of the input image that contributes to the output decision, from network complexity, which dictates the number of trainable parameters. We find that for low-resolution TEM images which rely on amplitude contrast to distinguish nanoparticles from background, the receptive field does not significantly influence segmentation performance. On the other hand, for high-resolution TEM images which rely on a combination of amplitude and phase contrast changes to identify nanoparticles, receptive field is a key parameter for increased performance, especially in images with minimal amplitude contrast. Our results provide insight and guidance as to how to adapt neural networks for applications with TEM datasets. ",
    "url": "https://arxiv.org/abs/2204.04250",
    "authors": [
      "Katherine Sytwu",
      "Catherine Groschner",
      "Mary C. Scott"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.04284",
    "title": "Auditory-Based Data Augmentation for End-to-End Automatic Speech  Recognition",
    "abstract": "End-to-end models have achieved significant improvement on automatic speech recognition. One common method to improve performance of these models is expanding the data-space through data augmentation. Meanwhile, human auditory inspired front-ends have also demonstrated improvement for automatic speech recognisers. In this work, a well-verified auditory-based model, which can simulate various hearing abilities, is investigated for the purpose of data augmentation for end-to-end speech recognition. By introducing the auditory model into the data augmentation process, end-to-end systems are encouraged to ignore variation from the signal that cannot be heard and thereby focus on robust features for speech recognition. Two mechanisms in the auditory model, spectral smearing and loudness recruitment, are studied on the LibriSpeech dataset with a transformer-based end-to-end model. The results show that the proposed augmentation methods can bring statistically significant improvement on the performance of the state-of-the-art SpecAugment. ",
    "url": "https://arxiv.org/abs/2204.04284",
    "authors": [
      "Zehai Tu",
      "Jack Deadman",
      "Ning Ma",
      "Jon Barker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.04287",
    "title": "Exploiting Hidden Representations from a DNN-based Speech Recogniser for  Speech Intelligibility Prediction in Hearing-impaired Listeners",
    "abstract": "An accurate objective speech intelligibility prediction algorithms is of great interest for many applications such as speech enhancement for hearing aids. Most algorithms measures the signal-to-noise ratios or correlations between the acoustic features of clean reference signals and degraded signals. However, these hand-picked acoustic features are usually not explicitly correlated with recognition. Meanwhile, deep neural network (DNN) based automatic speech recogniser (ASR) is approaching human performance in some speech recognition tasks. This work leverages the hidden representations from DNN-based ASR as features for speech intelligibility prediction in hearing-impaired listeners. The experiments based on a hearing aid intelligibility database show that the proposed method could make better prediction than a widely used short-time objective intelligibility (STOI) based binaural measure. ",
    "url": "https://arxiv.org/abs/2204.04287",
    "authors": [
      "Zehai Tu",
      "Ning Ma",
      "Jon Barker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2204.04288",
    "title": "Unsupervised Uncertainty Measures of Automatic Speech Recognition for  Non-intrusive Speech Intelligibility Prediction",
    "abstract": "Non-intrusive intelligibility prediction is important for its application in realistic scenarios, where a clean reference signal is difficult to access. The construction of many non-intrusive predictors require either ground truth intelligibility labels or clean reference signals for supervised learning. In this work, we leverage an unsupervised uncertainty estimation method for predicting speech intelligibility, which does not require intelligibility labels or reference signals to train the predictor. Our experiments demonstrate that the uncertainty from state-of-the-art end-to-end automatic speech recognition (ASR) models is highly correlated with speech intelligibility. The proposed method is evaluated on two databases and the results show that the unsupervised uncertainty measures of ASR models are more correlated with speech intelligibility from listening results than the predictions made by widely used intrusive methods. ",
    "url": "https://arxiv.org/abs/2204.04288",
    "authors": [
      "Zehai Tu",
      "Ning Ma",
      "Jon Barker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.04333",
    "title": "A Study of Using Cepstrogram for Countermeasure Against Replay Attacks",
    "abstract": "In this paper, we investigate the properties of the cepstrogram and demonstrate its effectiveness as a powerful feature for countermeasure against replay attacks. Cepstrum analysis of replay attacks suggests that crucial information for anti-spoofing against replay attacks may retain in the cepstrogram. Experimental results on the ASVspoof 2019 physical access (PA) database demonstrate that, compared with other features, the cepstrogram dominates in both single and fusion systems when building countermeasures against replay attacks. Our LCNN-based single and fusion systems with the cepstrogram feature outperform the corresponding LCNN-based systems without using the cepstrogram feature and several state-of-the-art (SOTA) single and fusion systems in the literature. ",
    "url": "https://arxiv.org/abs/2204.04333",
    "authors": [
      "Shih-Kuang Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.04348",
    "title": "Neural networks embrace learned diversity",
    "abstract": "Diversity conveys advantages in nature, yet homogeneous neurons typically comprise the layers of artificial neural networks. Here we construct neural networks from neurons that learn their own activation functions, quickly diversify, and subsequently outperform their homogeneous counterparts. Sub-networks instantiate the neurons, which meta-learn especially efficient sets of nonlinear responses. Such learned diversity provides examples of dynamical systems selecting diversity over uniformity and elucidates the role of diversity in natural and artificial systems. ",
    "url": "https://arxiv.org/abs/2204.04348",
    "authors": [
      "Anshul Choudhary",
      "Anil Radhakrishnan",
      "John F. Lindner",
      "Sudeshna Sinha",
      "William L. Ditto"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04430",
    "title": "CMOS Circuit Implementation of Spiking Neural Network for Pattern  Recognition Using On-chip Unsupervised STDP Learning",
    "abstract": "Computation on a large volume of data at high speed and low power requires energy-efficient computing architectures. Spiking neural network (SNN) with bio-inspired spike-timing-dependent plasticity learning (STDP) is a promising solution for energy-efficient neuromorphic systems than conventional artificial neural network (ANN). Previous works on SNN with STDP learning primarily uses memristive devices which are difficult to fabricate. Some reported works on SNN makes use of memristor macro models, which are software-based and cannot give complete insight into circuit implementation challenges. This article presents for the first time, a full circuit-level implementation of the SNN system featuring on-chip unsupervised STDP learning in standard CMOS technology. It does not involve the use of FPGAs, CPUs or GPUs for training the neural network. We demonstrated the complete circuit-level design, implementation and simulation of SNN with on-chip training and inference for pattern classification using 180 nm CMOS technology. A comprehensive comparison of the proposed SNN circuit with the previous related work is also presented. To demonstrate the versatility of the CMOS synapse circuit for application scenarios requiring rate-based learning, we have tuned the pair-based STDP circuit to obtain Bienenstock-Cooper-Munro (BCM) characteristics and applied it to heart rate classification. ",
    "url": "https://arxiv.org/abs/2204.04430",
    "authors": [
      "Sahibia Kaur Vohra",
      "Sherin A Thomas",
      "Mahendra Sakare",
      "Devarshi Mrinal Das"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.04875",
    "title": "Learning to Induce Causal Structure",
    "abstract": "The fundamental challenge in causal induction is to infer the underlying graph structure given observational and/or interventional data. Most existing causal induction algorithms operate by generating candidate graphs and then evaluating them using either score-based methods (including continuous optimization) or independence tests. In this work, instead of proposing scoring function or independence tests, we treat the inference process as a black box and design a neural network architecture that learns the mapping from both observational and interventional data to graph structures via supervised training on synthetic graphs. We show that the proposed model generalizes not only to new synthetic graphs but also to naturalistic graphs. ",
    "url": "https://arxiv.org/abs/2204.04875",
    "authors": [
      "Nan Rosemary Ke",
      "Silvia Chiappa",
      "Jane Wang",
      "Jorg Bornschein",
      "Theophane Weber",
      "Anirudh Goyal",
      "Matthew Botvinic",
      "Michael Mozer",
      "Danilo Jimenez Rezende"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04949",
    "title": "A Semantic Segmentation Network Based Real-Time Computer-Aided Diagnosis  System for Hydatidiform Mole Hydrops Lesion Recognition in Microscopic View",
    "abstract": "As a disease with malignant potential, hydatidiform mole (HM) is one of the most common gestational trophoblastic diseases. For pathologists, the HM section of hydrops lesions is an important basis for diagnosis. In pathology departments, the diverse microscopic manifestations of HM lesions and the limited view under the microscope mean that physicians with extensive diagnostic experience are required to prevent missed diagnosis and misdiagnosis. Feature extraction can significantly improve the accuracy and speed of the diagnostic process. As a remarkable diagnosis assisting technology, computer-aided diagnosis (CAD) has been widely used in clinical practice. We constructed a deep-learning-based CAD system to identify HM hydrops lesions in the microscopic view in real-time. The system consists of three modules; the image mosaic module and edge extension module process the image to improve the outcome of the hydrops lesion recognition module, which adopts a semantic segmentation network, our novel compound loss function, and a stepwise training function in order to achieve the best performance in identifying hydrops lesions. We evaluated our system using an HM hydrops dataset. Experiments show that our system is able to respond in real-time and correctly display the entire microscopic view with accurately labeled HM hydrops lesions. ",
    "url": "https://arxiv.org/abs/2204.04949",
    "authors": [
      "Chengze Zhu",
      "Pingge Hu",
      "Xianxu Zeng",
      "Xingtong Wang",
      "Zehua Ji",
      "Li Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04956",
    "title": "Segmentation Network with Compound Loss Function for Hydatidiform Mole  Hydrops Lesion Recognition",
    "abstract": "Pathological morphology diagnosis is the standard diagnosis method of hydatidiform mole. As a disease with malignant potential, the hydatidiform mole section of hydrops lesions is an important basis for diagnosis. Due to incomplete lesion development, early hydatidiform mole is difficult to distinguish, resulting in a low accuracy of clinical diagnosis. As a remarkable machine learning technology, image semantic segmentation networks have been used in many medical image recognition tasks. We developed a hydatidiform mole hydrops lesion segmentation model based on a novel loss function and training method. The model consists of different networks that segment the section image at the pixel and lesion levels. Our compound loss function assign weights to the segmentation results of the two levels to calculate the loss. We then propose a stagewise training method to combine the advantages of various loss functions at different levels. We evaluate our method on a hydatidiform mole hydrops dataset. Experiments show that the proposed model with our loss function and training method has good recognition performance under different segmentation metrics. ",
    "url": "https://arxiv.org/abs/2204.04956",
    "authors": [
      "Chengze Zhu",
      "Pingge Hu",
      "Xianxu Zeng",
      "Xingtong Wang",
      "Zehua Ji",
      "Li Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04993",
    "title": "Ischemic Stroke Lesion Segmentation Using Adversarial Learning",
    "abstract": "Ischemic stroke occurs through a blockage of clogged blood vessels supplying blood to the brain. Segmentation of the stroke lesion is vital to improve diagnosis, outcome assessment and treatment planning. In this work, we propose a segmentation model with adversarial learning for ischemic lesion segmentation. We adopt U-Net with skip connection and dropout as segmentation baseline network and a fully connected network (FCN) as discriminator network. Discriminator network consists of 5 convolution layers followed by leaky-ReLU and an upsampling layer to rescale the output to the size of the input map. Training a segmentation network along with an adversarial network can detect and correct higher order inconsistencies between the segmentation maps produced by ground-truth and the Segmentor. We exploit three modalities (CT, DPWI, CBF) of acute computed tomography (CT) perfusion data provided in ISLES 2018 (Ischemic Stroke Lesion Segmentation) for ischemic lesion segmentation. Our model has achieved dice accuracy of 42.10% with the cross-validation of training and 39% with the testing data. ",
    "url": "https://arxiv.org/abs/2204.04993",
    "authors": [
      "Mobarakol Islam",
      "N Rajiv Vaidyanathan",
      "V Jeya Maria Jose",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05103",
    "title": "Transformer-Based Self-Supervised Learning for Emotion Recognition",
    "abstract": "In order to exploit representations of time-series signals, such as physiological signals, it is essential that these representations capture relevant information from the whole signal. In this work, we propose to use a Transformer-based model to process electrocardiograms (ECG) for emotion recognition. Attention mechanisms of the Transformer can be used to build contextualized representations for a signal, giving more importance to relevant parts. These representations may then be processed with a fully-connected network to predict emotions. To overcome the relatively small size of datasets with emotional labels, we employ self-supervised learning. We gathered several ECG datasets with no labels of emotion to pre-train our model, which we then fine-tuned for emotion recognition on the AMIGOS dataset. We show that our approach reaches state-of-the-art performances for emotion recognition using ECG signals on AMIGOS. More generally, our experiments show that transformers and pre-training are promising strategies for emotion recognition with physiological signals. ",
    "url": "https://arxiv.org/abs/2204.05103",
    "authors": [
      "Juan Vazquez-Rodriguez",
      "Gr\u00e9goire Lefebvre",
      "Julien Cumin",
      "James L. Crowley"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.05132",
    "title": "A Spiking Neural Network based on Neural Manifold for Augmenting  Intracortical Brain-Computer Interface Data",
    "abstract": "Brain-computer interfaces (BCIs), transform neural signals in the brain into in-structions to control external devices. However, obtaining sufficient training data is difficult as well as limited. With the advent of advanced machine learning methods, the capability of brain-computer interfaces has been enhanced like never before, however, these methods require a large amount of data for training and thus require data augmentation of the limited data available. Here, we use spiking neural networks (SNN) as data generators. It is touted as the next-generation neu-ral network and is considered as one of the algorithms oriented to general artifi-cial intelligence because it borrows the neural information processing from bio-logical neurons. We use the SNN to generate neural spike information that is bio-interpretable and conforms to the intrinsic patterns in the original neural data. Ex-periments show that the model can directly synthesize new spike trains, which in turn improves the generalization ability of the BCI decoder. Both the input and output of the spiking neural model are spike information, which is a brain-inspired intelligence approach that can be better integrated with BCI in the future. ",
    "url": "https://arxiv.org/abs/2204.05132",
    "authors": [
      "Shengjie Zheng",
      "Wenyi Li",
      "Lang Qian",
      "Chenggang He",
      "Xiaojian Li"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05177",
    "title": "The PartialSpoof Database and Countermeasures for the Detection of Short  Generated Audio Segments Embedded in a Speech Utterance",
    "abstract": "Automatic speaker verification is susceptible to various manipulations and spoofing, such as text-to-speech (TTS) synthesis, voice conversion (VC), replay, tampering, and so on. In this paper, we consider a new spoofing scenario called \"Partial Spoof\" (PS) in which synthesized or transformed audio segments are embedded into a bona fide speech utterance. While existing countermeasures (CMs) can detect fully spoofed utterances, there is a need for their adaptation or extension to the PS scenario to detect utterances in which only a part of the audio signal is generated and hence only a fraction of an utterance is spoofed. For improved explainability, such new CMs should ideally also be able to detect such short spoofed segments. Our previous study introduced the first version of a speech database suitable for training CMs for the PS scenario and showed that, although it is possible to train CMs to execute the two types of detection described above, there is much room for improvement. In this paper we propose various improvements to construct a significantly more accurate CM that can detect short generated spoofed audio segments at finer temporal resolutions. First, we introduce newly proposed self-supervised pre-trained models as enhanced feature extractors. Second, we extend the PartialSpoof database by adding segment labels for various temporal resolutions, ranging from 20 ms to 640 ms. Third, we propose a new CM and training strategies that enable the simultaneous use of the utterance-level and segment-level labels at different temporal resolutions. We also show that the proposed CM is capable of detecting spoofing at the utterance level with low error rates, not only in the PS scenario but also in a related logical access (LA) scenario. The equal error rates of utterance-level detection on the PartialSpoof and the ASVspoof 2019 LA database were 0.47% and 0.59%, respectively. ",
    "url": "https://arxiv.org/abs/2204.05177",
    "authors": [
      "Lin Zhang",
      "Xin Wang",
      "Erica Cooper",
      "Nicholas Evans",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:1904.10631",
    "title": "Low-Memory Neural Network Training: A Technical Report",
    "abstract": " Comments: Version notes: Copyedits and citation fixes ",
    "url": "https://arxiv.org/abs/1904.10631",
    "authors": [
      "Nimit S. Sohoni",
      "Christopher R. Aberger",
      "Megan Leszczynski",
      "Jian Zhang",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1905.03577",
    "title": "Spatial-Spectral Feature Extraction via Deep ConvLSTM Neural Networks  for Hyperspectral Image Classification",
    "abstract": " Comments: 14 pages, 8 figures ",
    "url": "https://arxiv.org/abs/1905.03577",
    "authors": [
      "Wen-Shuai Hu",
      "Heng-Chao Li",
      "Lei Pan",
      "Wei Li",
      "Ran Tao",
      "Qian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1907.05168",
    "title": "Graph product structure for non-minor-closed classes",
    "abstract": " Comments: v2 Cosmetic improvements and a corrected bound for (layered-)(tree)width in Theorems 2, 9, 11, and Corollaries 1, 3, 4, 6, 12. v3 Complete restructure. v4 Major revision, improved constants for 1-planar and d-map graphs ",
    "url": "https://arxiv.org/abs/1907.05168",
    "authors": [
      "Vida Dujmovi\u0107",
      "Pat Morin",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1909.09927",
    "title": "Accelerating convolutional neural network by exploiting sparsity on GPUs",
    "abstract": " Title: Accelerating convolutional neural network by exploiting sparsity on GPUs ",
    "url": "https://arxiv.org/abs/1909.09927",
    "authors": [
      "Weizhi Xu",
      "Shengyu Fan",
      "Hui Yu",
      "Xin Fu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:1910.02684",
    "title": "Dynamic Self-training Framework for Graph Convolutional Networks",
    "abstract": " Comments: 11pages ",
    "url": "https://arxiv.org/abs/1910.02684",
    "authors": [
      "Ziang Zhou",
      "Shengzhong Zhang",
      "Zengfeng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2001.06570",
    "title": "Harmonic Convolutional Networks based on Discrete Cosine Transform",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:1812.03205 ",
    "url": "https://arxiv.org/abs/2001.06570",
    "authors": [
      "Matej Ulicny",
      "Vladimir A. Krylov",
      "Rozenn Dahyot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2002.05242",
    "title": "Leveraging Affect Transfer Learning for Behavior Prediction in an  Intelligent Tutoring System",
    "abstract": " Comments: Published at IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2021 - Best Poster Award (4% award rate) ",
    "url": "https://arxiv.org/abs/2002.05242",
    "authors": [
      "Nataniel Ruiz",
      "Hao Yu",
      "Danielle A. Allessio",
      "Mona Jalal",
      "Ajjen Joshi",
      "Thomas Murray",
      "John J. Magee",
      "Jacob R. Whitehill",
      "Vitaly Ablavsky",
      "Ivon Arroyo",
      "Beverly P. Woolf",
      "Stan Sclaroff",
      "Margrit Betke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2004.12164",
    "title": "Randomized spectral co-clustering for large-scale directed networks",
    "abstract": " Title: Randomized spectral co-clustering for large-scale directed networks ",
    "url": "https://arxiv.org/abs/2004.12164",
    "authors": [
      "Xiao Guo",
      "Yixuan Qiu",
      "Hai Zhang",
      "Xiangyu Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2005.09046",
    "title": "Improving the Effectiveness of Traceability Link Recovery using  Hierarchical Bayesian Networks",
    "abstract": " Comments: Accepted in the Proceedings of the 42nd International Conference on Software Engineering (ICSE'20), 13 pages ",
    "url": "https://arxiv.org/abs/2005.09046",
    "authors": [
      "Kevin Moran",
      "David N. Palacio",
      "Carlos Bernal-C\u00e1rdenas",
      "Daniel McCrystal",
      "Denys Poshyvanyk",
      "Chris Shenefiel",
      "Jeff Johnson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2006.08421",
    "title": "An approximation algorithm for joint caching and recommendations in  cache networks",
    "abstract": " Title: An approximation algorithm for joint caching and recommendations in  cache networks ",
    "url": "https://arxiv.org/abs/2006.08421",
    "authors": [
      "Dimitra Tsigkari",
      "Thrasyvoulos Spyropoulos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2006.13192",
    "title": "Adversarial Robustness of Deep Sensor Fusion Models",
    "abstract": " Title: Adversarial Robustness of Deep Sensor Fusion Models ",
    "url": "https://arxiv.org/abs/2006.13192",
    "authors": [
      "Shaojie Wang",
      "Tong Wu",
      "Ayan Chakrabarti",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2006.16140",
    "title": "Limits of Individual Consent and Models of Distributed Consent in Online  Social Networks",
    "abstract": " Title: Limits of Individual Consent and Models of Distributed Consent in Online  Social Networks ",
    "url": "https://arxiv.org/abs/2006.16140",
    "authors": [
      "Juniper Lovato",
      "Antoine Allard",
      "Randall Harp",
      "Jeremiah Onaolapo",
      "Laurent H\u00e9bert-Dufresne"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2007.12927",
    "title": "Neural networks with late-phase weights",
    "abstract": " Comments: 25 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2007.12927",
    "authors": [
      "Johannes von Oswald",
      "Seijin Kobayashi",
      "Alexander Meulemans",
      "Christian Henning",
      "Benjamin F. Grewe",
      "Jo\u00e3o Sacramento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.01341",
    "title": "Secure Encoded Instruction Graphs for End-to-End Data Validation in  Autonomous Robots",
    "abstract": " Comments: To be published in the IEEE Internet of Things Journal ",
    "url": "https://arxiv.org/abs/2009.01341",
    "authors": [
      "Jorge Pe\u00f1a Queralta",
      "Li Qingqing",
      "Eduardo Castell\u00f3 Ferrer",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2009.10054",
    "title": "Regularizing Attention Networks for Anomaly Detection in Visual Question  Answering",
    "abstract": " Comments: 16 pages, 7 figures, Accepted by AAAI-21 ",
    "url": "https://arxiv.org/abs/2009.10054",
    "authors": [
      "Doyup Lee",
      "Yeongjae Cheon",
      "Wook-Shin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.00830",
    "title": "VIO-UWB-Based Collaborative Localization and Dense Scene Reconstruction  within Heterogeneous Multi-Robot Systems",
    "abstract": " Title: VIO-UWB-Based Collaborative Localization and Dense Scene Reconstruction  within Heterogeneous Multi-Robot Systems ",
    "url": "https://arxiv.org/abs/2011.00830",
    "authors": [
      "Jorge Pe\u00f1a Queralta",
      "Li Qingqing",
      "Fabrizio Schiano",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2011.03526",
    "title": "Identifying Stress Responsive Genes using Overlapping Communities in  Co-expression Networks",
    "abstract": " Title: Identifying Stress Responsive Genes using Overlapping Communities in  Co-expression Networks ",
    "url": "https://arxiv.org/abs/2011.03526",
    "authors": [
      "Camila Riccio",
      "Jorge Finke",
      "Camilo Rocha"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2011.12945",
    "title": "No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained  Classification Problems",
    "abstract": " Comments: 40 pages. Published as a conference paper at NeurIPS 2020 ",
    "url": "https://arxiv.org/abs/2011.12945",
    "authors": [
      "Nimit S. Sohoni",
      "Jared A. Dunnmon",
      "Geoffrey Angus",
      "Albert Gu",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.04188",
    "title": "Learning to Represent Programs with Heterogeneous Graphs",
    "abstract": " Comments: Accepted by ICPC 2022 ",
    "url": "https://arxiv.org/abs/2012.04188",
    "authors": [
      "Wenhan Wang",
      "Kechi Zhang",
      "Ge Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2103.05893",
    "title": "A Jointly Optimal Design of Control and Scheduling in Networked Systems  under Denial-of-Service Attacks",
    "abstract": " Comments: 12 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2103.05893",
    "authors": [
      "Jingyi Lu",
      "Daniel E. Quevedo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2103.09504",
    "title": "PredRNN: A Recurrent Neural Network for Spatiotemporal Predictive  Learning",
    "abstract": " Comments: 17 pages, accepted by TPAMI ",
    "url": "https://arxiv.org/abs/2103.09504",
    "authors": [
      "Yunbo Wang",
      "Haixu Wu",
      "Jianjin Zhang",
      "Zhifeng Gao",
      "Jianmin Wang",
      "Philip S. Yu",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.10374",
    "title": "Consistency-based Active Learning for Object Detection",
    "abstract": " Comments: CVPR-2022 Workshop ",
    "url": "https://arxiv.org/abs/2103.10374",
    "authors": [
      "Weiping Yu",
      "Sijie Zhu",
      "Taojiannan Yang",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.14229",
    "title": "Assessing patient similarity through representation learning on medical  records",
    "abstract": " Title: Assessing patient similarity through representation learning on medical  records ",
    "url": "https://arxiv.org/abs/2104.14229",
    "authors": [
      "Hoda Memarzadeh",
      "Nasser Ghadiri",
      "Matthias Samwald",
      "Maryam Lotfi Shahreza"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.03148",
    "title": "A State-of-the-art Survey of Object Detection Techniques in  Microorganism Image Analysis: From Classical Methods to Deep Learning  Approaches",
    "abstract": " Title: A State-of-the-art Survey of Object Detection Techniques in  Microorganism Image Analysis: From Classical Methods to Deep Learning  Approaches ",
    "url": "https://arxiv.org/abs/2105.03148",
    "authors": [
      "Pingli Ma",
      "Chen Li",
      "Md Mamunur Rahaman",
      "Yudong Yao",
      "Jiawei Zhang",
      "Shuojia Zou",
      "Xin Zhao",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.04123",
    "title": "Neural Program Repair with Execution-based Backpropagation",
    "abstract": " Title: Neural Program Repair with Execution-based Backpropagation ",
    "url": "https://arxiv.org/abs/2105.04123",
    "authors": [
      "He Ye",
      "Matias Martinez",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2106.04569",
    "title": "Simulated Adversarial Testing of Face Recognition Models",
    "abstract": " Comments: Published at IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022 ",
    "url": "https://arxiv.org/abs/2106.04569",
    "authors": [
      "Nataniel Ruiz",
      "Adam Kortylewski",
      "Weichao Qiu",
      "Cihang Xie",
      "Sarah Adel Bargal",
      "Alan Yuille",
      "Stan Sclaroff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.07476",
    "title": "Training Graph Neural Networks with 1000 Layers",
    "abstract": " Comments: Accepted at ICML'2021. Code available at this https URL Work done during Guohao Li's internship at Intel Intelligent Systems Lab. Revised reference in v3 ",
    "url": "https://arxiv.org/abs/2106.07476",
    "authors": [
      "Guohao Li",
      "Matthias M\u00fcller",
      "Bernard Ghanem",
      "Vladlen Koltun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2106.14193",
    "title": "SAR-Net: Shape Alignment and Recovery Network for Category-level 6D  Object Pose and Size Estimation",
    "abstract": " Comments: accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2106.14193",
    "authors": [
      "Haitao Lin",
      "Zichang Liu",
      "Chilam Cheang",
      "Yanwei Fu",
      "Guodong Guo",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2106.14836",
    "title": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "abstract": " Title: Understanding Dynamics of Nonlinear Representation Learning and Its  Application ",
    "url": "https://arxiv.org/abs/2106.14836",
    "authors": [
      "Kenji Kawaguchi",
      "Linjun Zhang",
      "Zhun Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.15002",
    "title": "Characterization of the Variation Spaces Corresponding to Shallow Neural  Networks",
    "abstract": " Title: Characterization of the Variation Spaces Corresponding to Shallow Neural  Networks ",
    "url": "https://arxiv.org/abs/2106.15002",
    "authors": [
      "Jonathan W. Siegel",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.00083",
    "title": "Majorization Minimization Methods for Distributed Pose Graph  Optimization",
    "abstract": " Comments: 33 pages ",
    "url": "https://arxiv.org/abs/2108.00083",
    "authors": [
      "Taosha Fan",
      "Todd Murphey"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2108.00356",
    "title": "Improving Social Meaning Detection with Pragmatic Masking and Surrogate  Fine-Tuning",
    "abstract": " Comments: WASSA at ACL 2022 camera-ready ",
    "url": "https://arxiv.org/abs/2108.00356",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.02274",
    "title": "LEO: Learning Energy-based Models in Factor Graph Optimization",
    "abstract": " Comments: Accepted to Conference on Robot Learning (CoRL) 2021. 19 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2108.02274",
    "authors": [
      "Paloma Sodhi",
      "Eric Dexheimer",
      "Mustafa Mukadam",
      "Stuart Anderson",
      "Michael Kaess"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2108.03443",
    "title": "NODEO: A Neural Ordinary Differential Equation Based Optimization  Framework for Deformable Image Registration",
    "abstract": " Title: NODEO: A Neural Ordinary Differential Equation Based Optimization  Framework for Deformable Image Registration ",
    "url": "https://arxiv.org/abs/2108.03443",
    "authors": [
      "Yifan Wu",
      "Tom Z. Jiahao",
      "Jiancong Wang",
      "Paul A. Yushkevich",
      "M. Ani Hsieh",
      "James C. Gee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.07154",
    "title": "MMChat: Multi-Modal Chat Dataset on Social Media",
    "abstract": " Comments: Accepted by LREC2022. Dataset available in this https URL ",
    "url": "https://arxiv.org/abs/2108.07154",
    "authors": [
      "Yinhe Zheng",
      "Guanyi Chen",
      "Xin Liu",
      "Jian Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.08018",
    "title": "Timed Automata Robustness Analysis via Model Checking",
    "abstract": " Title: Timed Automata Robustness Analysis via Model Checking ",
    "url": "https://arxiv.org/abs/2108.08018",
    "authors": [
      "Jaroslav Bend\u00edk",
      "Ahmet Sencan",
      "Ebru Aydin Gol",
      "Ivana \u010cern\u00e1"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2108.09135",
    "title": "PatchCleanser: Certifiably Robust Defense against Adversarial Patches  for Any Image Classifier",
    "abstract": " Comments: USENIX Security Symposium 2022; extended technical report ",
    "url": "https://arxiv.org/abs/2108.09135",
    "authors": [
      "Chong Xiang",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2108.12176",
    "title": "Rethinking the Misalignment Problem in Dense Object Detection",
    "abstract": " Title: Rethinking the Misalignment Problem in Dense Object Detection ",
    "url": "https://arxiv.org/abs/2108.12176",
    "authors": [
      "Yang Yang",
      "Min Li",
      "Bo Meng",
      "Junxing Ren",
      "Degang Sun",
      "Zihao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12340",
    "title": "Distributed Online Optimization with Byzantine Adversarial Agents",
    "abstract": " Comments: 9 pages, 1 figure. To appear at ACC 2022 ",
    "url": "https://arxiv.org/abs/2109.12340",
    "authors": [
      "Sourav Sahoo",
      "Anand Gokhale",
      "Rachel Kalpana Kalaimani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.01861",
    "title": "Social Co-OS: Cyber-Human Social Co-Operating System",
    "abstract": " Comments: 19 pages, 12 figures. Revised version based on the proceeding of the Forum on Information Technology 2021, Aug. 25-27, Japan ",
    "url": "https://arxiv.org/abs/2110.01861",
    "authors": [
      "Takeshi Kato",
      "Yasuyuki Kudo",
      "Junichi Miyakoshi",
      "Misa Owa",
      "Yasuhiro Asa",
      "Takashi Numata",
      "Ryuji Mine",
      "Hiroyuki Mizuno"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2111.02331",
    "title": "LTD: Low Temperature Distillation for Robust Adversarial Training",
    "abstract": " Title: LTD: Low Temperature Distillation for Robust Adversarial Training ",
    "url": "https://arxiv.org/abs/2111.02331",
    "authors": [
      "Erh-Chung Chen",
      "Che-Rung Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.03126",
    "title": "Generative Adversarial Network for Probabilistic Forecast of Random  Dynamical System",
    "abstract": " Title: Generative Adversarial Network for Probabilistic Forecast of Random  Dynamical System ",
    "url": "https://arxiv.org/abs/2111.03126",
    "authors": [
      "Kyongmin Yeo",
      "Zan Li",
      "Wesley M. Gifford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.04682",
    "title": "SMU: smooth activation function for deep networks using smoothing  maximum technique",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2111.04682",
    "authors": [
      "Koushik Biswas",
      "Sandeep Kumar",
      "Shilpak Banerjee",
      "Ashish Kumar Pandey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2111.05063",
    "title": "Tightening the Approximation Error of Adversarial Risk with Auto Loss  Function Search",
    "abstract": " Title: Tightening the Approximation Error of Adversarial Risk with Auto Loss  Function Search ",
    "url": "https://arxiv.org/abs/2111.05063",
    "authors": [
      "Pengfei Xia",
      "Ziqiang Li",
      "Bin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.08440",
    "title": "On the Importance of Difficulty Calibration in Membership Inference  Attacks",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2111.08440",
    "authors": [
      "Lauren Watson",
      "Chuan Guo",
      "Graham Cormode",
      "Alex Sablayrolles"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.13656",
    "title": "Towards Low-Cost and Efficient Malaria Detection",
    "abstract": " Title: Towards Low-Cost and Efficient Malaria Detection ",
    "url": "https://arxiv.org/abs/2111.13656",
    "authors": [
      "Waqas Sultani",
      "Wajahat Nawaz",
      "Syed Javed",
      "Muhammad Sohail Danish",
      "Asma Saadia",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.00668",
    "title": "A Few-Shot Meta-Learning based Siamese Neural Network using Entropy  Features for Ransomware Classification",
    "abstract": " Title: A Few-Shot Meta-Learning based Siamese Neural Network using Entropy  Features for Ransomware Classification ",
    "url": "https://arxiv.org/abs/2112.00668",
    "authors": [
      "Jinting Zhu",
      "Julian Jang-Jaccard",
      "Amardeep Singh",
      "Ian Welch",
      "Harith AI-Sahaf",
      "Seyit Camtepe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.07528",
    "title": "n-CPS: Generalising Cross Pseudo Supervision to n Networks for  Semi-Supervised Semantic Segmentation",
    "abstract": " Title: n-CPS: Generalising Cross Pseudo Supervision to n Networks for  Semi-Supervised Semantic Segmentation ",
    "url": "https://arxiv.org/abs/2112.07528",
    "authors": [
      "Dominik Filipiak",
      "Piotr Tempczyk",
      "Marek Cygan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.09065",
    "title": "Macroscopic properties of buyer-seller networks in online marketplaces",
    "abstract": " Title: Macroscopic properties of buyer-seller networks in online marketplaces ",
    "url": "https://arxiv.org/abs/2112.09065",
    "authors": [
      "Alberto Bracci",
      "J\u00f6rn Boehnke",
      "Abeer ElBahrawy",
      "Nicola Perra",
      "Alexander Teytelboym",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2112.13388",
    "title": "The brain as a probabilistic transducer: an evolutionarily plausible  network architecture for knowledge representation, computation, and behavior",
    "abstract": " Title: The brain as a probabilistic transducer: an evolutionarily plausible  network architecture for knowledge representation, computation, and behavior ",
    "url": "https://arxiv.org/abs/2112.13388",
    "authors": [
      "Joseph Y. Halpern",
      "Arnon Lotem"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2112.13753",
    "title": "MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale  Recommendation Scenarios",
    "abstract": " Title: MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale  Recommendation Scenarios ",
    "url": "https://arxiv.org/abs/2112.13753",
    "authors": [
      "Xiaofeng Pan",
      "Ming Li",
      "Jing Zhang",
      "Keren Yu",
      "Luping Wang",
      "Hong Wen",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.15352",
    "title": "Intention Adaptive Graph Neural Network for Category-aware Session-based  Recommendation",
    "abstract": " Title: Intention Adaptive Graph Neural Network for Category-aware Session-based  Recommendation ",
    "url": "https://arxiv.org/abs/2112.15352",
    "authors": [
      "Chuan Cui",
      "Qi Shen",
      "Shixuan Zhu",
      "Yitong Pang",
      "Yiming Zhang",
      "Hanning Gao",
      "Zhihua Wei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.15399",
    "title": "InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering",
    "abstract": " Comments: CVPR 2022, Website: this http URL ",
    "url": "https://arxiv.org/abs/2112.15399",
    "authors": [
      "Mijeong Kim",
      "Seonguk Seo",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.15459",
    "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
    "abstract": " Comments: 14 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2112.15459",
    "authors": [
      "Samuele Bolotta",
      "Guillaume Dumas"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.00072",
    "title": "BARACK: Partially Supervised Group Robustness With Guarantees",
    "abstract": " Comments: 26 pages ",
    "url": "https://arxiv.org/abs/2201.00072",
    "authors": [
      "Nimit S. Sohoni",
      "Maziar Sanjabi",
      "Nicolas Ballas",
      "Aditya Grover",
      "Shaoliang Nie",
      "Hamed Firooz",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.06819",
    "title": "Sensor Scheduling Design for Complex Networks under a Distributed State  Estimation Framework",
    "abstract": " Title: Sensor Scheduling Design for Complex Networks under a Distributed State  Estimation Framework ",
    "url": "https://arxiv.org/abs/2201.06819",
    "authors": [
      "Peihu Duan",
      "Lidong He",
      "Lingying Huang",
      "Guanrong Chen",
      "Ling Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.07131",
    "title": "Leveraging Real Talking Faces via Self-Supervision for Robust Forgery  Detection",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2201.07131",
    "authors": [
      "Alexandros Haliassos",
      "Rodrigo Mira",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08281",
    "title": "Symplectic Momentum Neural Networks -- Using Discrete Variational  Mechanics as a prior in Deep Learning",
    "abstract": " Comments: 12 pages, 4 figures. Accepted at 4th Annual Learning for Dynamics & Control Conference ",
    "url": "https://arxiv.org/abs/2201.08281",
    "authors": [
      "Saul Santos",
      "Monica Ekal",
      "Rodrigo Ventura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.09360",
    "title": "POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for  COVID-19 Detection",
    "abstract": " Comments: Accepted at International Conference on Computational Science (ICCS) 2022, London ",
    "url": "https://arxiv.org/abs/2201.09360",
    "authors": [
      "Tomasz Szczepa\u0144ski",
      "Arkadiusz Sitek",
      "Tomasz Trzci\u0144ski",
      "Szymon P\u0142otka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11650",
    "title": "Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrences",
    "abstract": " Title: Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrences ",
    "url": "https://arxiv.org/abs/2201.11650",
    "authors": [
      "Thomas Guyet",
      "Wenbin Zhang",
      "Albert Bifet"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02015",
    "title": "Energy-Efficient High-Accuracy Spiking Neural Network Inference Using  Time-Domain Neurons",
    "abstract": " Comments: Accepted in AICAS 2022 ",
    "url": "https://arxiv.org/abs/2202.02015",
    "authors": [
      "Joonghyun Song",
      "Jiwon Shin",
      "Hanseok Kim",
      "Woo-Seok Choi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.02436",
    "title": "Neural Logic Analogy Learning",
    "abstract": " Comments: In Proceedings of the ICLR 2022 PAIR2Struct Workshop ",
    "url": "https://arxiv.org/abs/2202.02436",
    "authors": [
      "Yujia Fan",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2202.03834",
    "title": "FSM: FBS Set Management, An energy efficient multi-drone 3D trajectory  approach in cellular networks",
    "abstract": " Title: FSM: FBS Set Management, An energy efficient multi-drone 3D trajectory  approach in cellular networks ",
    "url": "https://arxiv.org/abs/2202.03834",
    "authors": [
      "Mehdi Sookhak",
      "Amir Hossein Mohajerzadeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.13013",
    "title": "Sign and Basis Invariant Networks for Spectral Graph Representation  Learning",
    "abstract": " Comments: 35 pages ",
    "url": "https://arxiv.org/abs/2202.13013",
    "authors": [
      "Derek Lim",
      "Joshua Robinson",
      "Lingxiao Zhao",
      "Tess Smidt",
      "Suvrit Sra",
      "Haggai Maron",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.13340",
    "title": "Enumeration of chordal planar graphs and maps",
    "abstract": " Comments: 12 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2202.13340",
    "authors": [
      "Jordi Castellv\u00ed",
      "Marc Noy",
      "Cl\u00e9ment Requil\u00e9"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.03107",
    "title": "Privacy Leakage in Proactive VR Streaming: Modeling and Tradeoff",
    "abstract": " Comments: 30 pages, 9 figures, submit to IEEE for possible publication, the proofs in this version of the manuscript is omitted and can be found in version 1 ",
    "url": "https://arxiv.org/abs/2203.03107",
    "authors": [
      "Xing Wei",
      "Chenyang Yang",
      "Chengjian Sun"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.05241",
    "title": "Theory of Network Wave (On a Primary Path)",
    "abstract": " Title: Theory of Network Wave (On a Primary Path) ",
    "url": "https://arxiv.org/abs/2203.05241",
    "authors": [
      "Bo Li",
      "Mao Yang",
      "Zhongjiang Yan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.06429",
    "title": "DFTR: Depth-supervised Fusion Transformer for Salient Object Detection",
    "abstract": " Comments: 15 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2203.06429",
    "authors": [
      "Heqin Zhu",
      "Xu Sun",
      "Yuexiang Li",
      "Kai Ma",
      "S. Kevin Zhou",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07229",
    "title": "Physico-chemical properties extraction from the fluorescence spectrum  with 1D-convolutional neural networks: application to olive oil",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2203.07229",
    "authors": [
      "Francesca Venturini",
      "Michela Sperti",
      "Umberto Michelucci",
      "Arnaud Gucciardi",
      "Vanessa M. Martose",
      "Marco A. Deriu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.08147",
    "title": "Energy-Latency Attacks via Sponge Poisoning",
    "abstract": " Comments: Preprint;15 pages ",
    "url": "https://arxiv.org/abs/2203.08147",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Ambra Demontis",
      "Battista Biggio",
      "Fabio Roli",
      "Marcello Pelillo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09096",
    "title": "DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications",
    "abstract": " Title: DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications ",
    "url": "https://arxiv.org/abs/2203.09096",
    "authors": [
      "Somaye Hashemifar",
      "Claudia Iriondo",
      "Evan Casey",
      "Mohsen Hejrati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.09553",
    "title": "Efficient Federated Learning on Knowledge Graphs via Privacy-preserving  Relation Embedding Aggregation",
    "abstract": " Comments: Accepted to ACL 2022 Workshop on Federated Learning for Natural Language Processing ",
    "url": "https://arxiv.org/abs/2203.09553",
    "authors": [
      "Kai Zhang",
      "Yu Wang",
      "Hongyi Wang",
      "Lifu Huang",
      "Carl Yang",
      "Lichao Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11200",
    "title": "Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with  Heterophily",
    "abstract": " Title: Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with  Heterophily ",
    "url": "https://arxiv.org/abs/2203.11200",
    "authors": [
      "Jie Chen",
      "Shouzhen Chen",
      "Junbin Gao",
      "Zengfeng Huang",
      "Junping Zhang",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11899",
    "title": "Transformer based ensemble for emotion detection",
    "abstract": " Comments: Accepted at WASSA, ACL 2022 ",
    "url": "https://arxiv.org/abs/2203.11899",
    "authors": [
      "Aditya Kane",
      "Shantanu Patankar",
      "Sahil Khose",
      "Neeraja Kirtane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.12062",
    "title": "Distributionally Robust Model Predictive Control with Total Variation  Distance",
    "abstract": " Title: Distributionally Robust Model Predictive Control with Total Variation  Distance ",
    "url": "https://arxiv.org/abs/2203.12062",
    "authors": [
      "Anushri Dixit",
      "Mohamadreza Ahmadi",
      "Joel W. Burdick"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.12870",
    "title": "RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust  Correspondence Field Estimation and Pose Optimization",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.12870",
    "authors": [
      "Yan Xu",
      "Kwan-Yee Lin",
      "Guofeng Zhang",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.12997",
    "title": "Hierarchical Nearest Neighbor Graph Embedding for Efficient  Dimensionality Reduction",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.12997",
    "authors": [
      "M. Saquib Sarfraz",
      "Marios Koulakis",
      "Constantin Seibold",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.13147",
    "title": "Self-Triggered Coordination Control of Connected Automated Vehicles in  Traffic Networks",
    "abstract": " Title: Self-Triggered Coordination Control of Connected Automated Vehicles in  Traffic Networks ",
    "url": "https://arxiv.org/abs/2203.13147",
    "authors": [
      "Nader Meskin",
      "Ehsan Sabouni",
      "Wei Xiao",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.14267",
    "title": "bitsa_nlp@LT-EDI-ACL2022: Leveraging Pretrained Language Models for  Detecting Homophobia and Transphobia in Social Media Comments",
    "abstract": " Comments: 6 pages, Accepted at LT-EDI workshop ACL 2022. Camera ready version. Addressed all reviewer comments. Added Baseline methods and Ablation study ",
    "url": "https://arxiv.org/abs/2203.14267",
    "authors": [
      "Vitthal Bhandari",
      "Poonam Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.14763",
    "title": "Analysis and Performance Evaluation of Mobility for Multi-Panel User  Equipment in 5G Networks",
    "abstract": " Comments: 7 pages, 7 figures. Accepted for presentation at the 2022 IEEE 95th Vehicular Technology Conference (VTC2022)-Spring, Helsinki, Finland ",
    "url": "https://arxiv.org/abs/2203.14763",
    "authors": [
      "Subhyal Bin Iqbal",
      "Ahmad Awada",
      "Umur Karabulut",
      "Ingo Viering",
      "Philipp Schulz",
      "Gerhard P. Fettweis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.15331",
    "title": "CNN Filter DB: An Empirical Investigation of Trained Convolutional  Filters",
    "abstract": " Comments: significantly reduced PDF size in v2; Accepted as ORAL at IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (CVPR) ",
    "url": "https://arxiv.org/abs/2203.15331",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16135",
    "title": "Kron-based Model-order Reduction of Open Mass-action Kinetics Chemical  Reaction Networks",
    "abstract": " Comments: Submitted to IEEE Transactions on Automatic Control ",
    "url": "https://arxiv.org/abs/2203.16135",
    "authors": [
      "Mohamad Agung Prawira Negara",
      "Azka Muji Burohman",
      "Bayu Jayawardhana"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.16328",
    "title": "Smooth Robust Tensor Completion for Background/Foreground Separation  with Missing Pixels: Novel Algorithm with Convergence Guarantee",
    "abstract": " Comments: 40 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2203.16328",
    "authors": [
      "Bo Shen",
      "Weijun Xie",
      "Zhenyu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.00697",
    "title": "Assisted Shortest Path Planning for a Convoy through a Repairable  Network",
    "abstract": " Title: Assisted Shortest Path Planning for a Convoy through a Repairable  Network ",
    "url": "https://arxiv.org/abs/2204.00697",
    "authors": [
      "Abhay Singh Bhadoriya",
      "Christopher Montez",
      "Sivakumar Rathinam",
      "Swaroop Darbha",
      "David W. Casbeer",
      "Satyanarayana G. Manyam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2204.03216",
    "title": "Neural Implicit Flow: a mesh-agnostic dimensionality reduction paradigm  of spatio-temporal data",
    "abstract": " Comments: 56 pages ",
    "url": "https://arxiv.org/abs/2204.03216",
    "authors": [
      "Shaowu Pan",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2204.03410",
    "title": "Incremental Prototype Prompt-tuning with Pre-trained Representation for  Class Incremental Learning",
    "abstract": " Title: Incremental Prototype Prompt-tuning with Pre-trained Representation for  Class Incremental Learning ",
    "url": "https://arxiv.org/abs/2204.03410",
    "authors": [
      "Jieren Deng",
      "Jianhua Hu",
      "Haojian Zhang",
      "Yunkuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03632",
    "title": "The Effects of Regularization and Data Augmentation are Class Dependent",
    "abstract": " Title: The Effects of Regularization and Data Augmentation are Class Dependent ",
    "url": "https://arxiv.org/abs/2204.03632",
    "authors": [
      "Randall Balestriero",
      "Leon Bottou",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.04090",
    "title": "Generative Adversarial Method Based on Neural Tangent Kernels",
    "abstract": " Title: Generative Adversarial Method Based on Neural Tangent Kernels ",
    "url": "https://arxiv.org/abs/2204.04090",
    "authors": [
      "Yu-Rong Zhang",
      "Sheng Yen Chou",
      "Shan-Hung Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04149",
    "title": "A Credible and Robust approach to Ego-Motion Estimation using an  Automotive Radar",
    "abstract": " Comments: In IEEE Robotics and Automation Letters ",
    "url": "https://arxiv.org/abs/2204.04149",
    "authors": [
      "Karim Haggag",
      "Sven Lange",
      "Tim Pfeifer",
      "Peter Protzel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  }
]