[
  {
    "id": "arXiv:2204.07176",
    "title": "A collaborative decomposition-based evolutionary algorithm integrating  normal and penalty-based boundary intersection for many-objective  optimization",
    "abstract": "Decomposition-based evolutionary algorithms have become fairly popular for many-objective optimization in recent years. However, the existing decomposition methods still are quite sensitive to the various shapes of frontiers of many-objective optimization problems (MaOPs). On the one hand, the cone decomposition methods such as the penalty-based boundary intersection (PBI) are incapable of acquiring uniform frontiers for MaOPs with very convex frontiers. On the other hand, the parallel reference lines of the parallel decomposition methods including the normal boundary intersection (NBI) might result in poor diversity because of under-sampling near the boundaries for MaOPs with concave frontiers. In this paper, a collaborative decomposition method is first proposed to integrate the advantages of parallel decomposition and cone decomposition to overcome their respective disadvantages. This method inherits the NBI-style Tchebycheff function as a convergence measure to heighten the convergence and uniformity of distribution of the PBI method. Moreover, this method also adaptively tunes the extent of rotating an NBI reference line towards a PBI reference line for every subproblem to enhance the diversity of distribution of the NBI method. Furthermore, a collaborative decomposition-based evolutionary algorithm (CoDEA) is presented for many-objective optimization. A collaborative decomposition-based environmental selection mechanism is primarily designed in CoDEA to rank all the individuals associated with the same PBI reference line in the boundary layer and pick out the best ranks. CoDEA is compared with several popular algorithms on 85 benchmark test instances. The experimental results show that CoDEA achieves high competitiveness benefiting from the collaborative decomposition maintaining a good balance among the convergence, uniformity, and diversity of distribution. ",
    "url": "https://arxiv.org/abs/2204.07176",
    "authors": [
      "Yu Wu",
      "Jianle Wei",
      "Weiqin Ying",
      "Yanqi Lan",
      "Zhen Cui",
      "Zhenyu Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07197",
    "title": "RobustScaler: QoS-Aware Autoscaling for Complex Workloads",
    "abstract": "Autoscaling is a critical component for efficient resource utilization with satisfactory quality of service (QoS) in cloud computing. This paper investigates proactive autoscaling for widely-used scaling-per-query applications where scaling is required for each query, such as container registry and function-as-a-service (FaaS). In these scenarios, the workload often exhibits high uncertainty with complex temporal patterns like periodicity, noises and outliers. Conservative strategies that scale out unnecessarily many instances lead to high resource costs whereas aggressive strategies may result in poor QoS. We present RobustScaler to achieve superior trade-off between cost and QoS. Specifically, we design a novel autoscaling framework based on non-homogeneous Poisson processes (NHPP) modeling and stochastically constrained optimization. Furthermore, we develop a specialized alternating direction method of multipliers (ADMM) to efficiently train the NHPP model, and rigorously prove the QoS guarantees delivered by our optimization-based proactive strategies. Extensive experiments show that RobustScaler outperforms common baseline autoscaling strategies in various real-world traces, with large margins for complex workload patterns. ",
    "url": "https://arxiv.org/abs/2204.07197",
    "authors": [
      "Huajie Qian",
      "Qingsong Wen",
      "Liang Sun",
      "Jing Gu",
      "Qiulin Niu",
      "Zhimin Tang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.07203",
    "title": "EXPERT: Public Benchmarks for Dynamic Heterogeneous Academic Graphs",
    "abstract": "Machine learning models that learn from dynamic graphs face nontrivial challenges in learning and inference as both nodes and edges change over time. The existing large-scale graph benchmark datasets that are widely used by the community primarily focus on homogeneous node and edge attributes and are static. In this work, we present a variety of large scale, dynamic heterogeneous academic graphs to test the effectiveness of models developed for multi-step graph forecasting tasks. Our novel datasets cover both context and content information extracted from scientific publications across two communities: Artificial Intelligence (AI) and Nuclear Nonproliferation (NN). In addition, we propose a systematic approach to improve the existing evaluation procedures used in the graph forecasting models. ",
    "url": "https://arxiv.org/abs/2204.07203",
    "authors": [
      "Sameera Horawalavithana",
      "Ellyn Ayton",
      "Anastasiya Usenko",
      "Shivam Sharma",
      "Jasmine Eshun",
      "Robin Cosbey",
      "Maria Glenski",
      "Svitlana Volkova"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07212",
    "title": "Reputation and Audit Bit Based Distributed Detection in the Presence of  Byzantine",
    "abstract": "In this paper, two reputation based algorithms called Reputation and audit based clustering (RAC) algorithm and Reputation and audit based clustering with auxiliary anchor node (RACA) algorithm are proposed to defend against Byzantine attacks in distributed detection networks when the fusion center (FC) has no prior knowledge of the attacking strategy of Byzantine nodes. By updating the reputation index of the sensors in cluster-based networks, the system can accurately identify Byzantine nodes. The simulation results show that both proposed algorithms have superior detection performance compared with other algorithms. The proposed RACA algorithm works well even when the number of Byzantine nodes exceeds half of the total number of sensors in the network. Furthermore, the robustness of our proposed algorithms is evaluated in a dynamically changing scenario, where the attacking parameters change over time. We show that our algorithms can still achieve superior detection performance. ",
    "url": "https://arxiv.org/abs/2204.07212",
    "authors": [
      "Chen Quan",
      "Yunghsiang S. Han",
      "Baocheng Geng",
      "Pramod K. Varshney"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.07221",
    "title": "Causal Disentanglement with Network Information for Debiased  Recommendations",
    "abstract": "Recommender systems aim to recommend new items to users by learning user and item representations. In practice, these representations are highly entangled as they consist of information about multiple factors, including user's interests, item attributes along with confounding factors such as user conformity, and item popularity. Considering these entangled representations for inferring user preference may lead to biased recommendations (e.g., when the recommender model recommends popular items even if they do not align with the user's interests). Recent research proposes to debias by modeling a recommender system from a causal perspective. The exposure and the ratings are analogous to the treatment and the outcome in the causal inference framework, respectively. The critical challenge in this setting is accounting for the hidden confounders. These confounders are unobserved, making it hard to measure them. On the other hand, since these confounders affect both the exposure and the ratings, it is essential to account for them in generating debiased recommendations. To better approximate hidden confounders, we propose to leverage network information (i.e., user-social and user-item networks), which are shown to influence how users discover and interact with an item. Aside from the user conformity, aspects of confounding such as item popularity present in the network information is also captured in our method with the aid of \\textit{causal disentanglement} which unravels the learned representations into independent factors that are responsible for (a) modeling the exposure of an item to the user, (b) predicting the ratings, and (c) controlling the hidden confounders. Experiments on real-world datasets validate the effectiveness of the proposed model for debiasing recommender systems. ",
    "url": "https://arxiv.org/abs/2204.07221",
    "authors": [
      "Paras Sheth",
      "Ruocheng Guo",
      "Lu Cheng",
      "Huan Liu",
      "K. Sel\u00e7uk Candan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.07225",
    "title": "MP-CodeCheck: Evolving Logical Expression Code Anomaly Learning with  Iterative Self-Supervision",
    "abstract": "Machine programming (MP) is concerned with automating software development. According to studies, software engineers spend upwards of 50% of their development time debugging software. To help accelerate debugging, we present MP-CodeCheck (MPCC). MPCC is an MP system that attempts to identify anomalous code patterns within logical program expressions. In designing MPCC, we developed two novel programming language representations, the formations of which are critical in its ability to exhaustively and efficiently process the billions of lines of code that are used in its self-supervised training. To quantify MPCC's performance, we compare it against ControlFlag, a state-of-the-art self-supervised code anomaly detection system; we find that MPCC is more spatially and temporally efficient. We demonstrate MPCC's anomalous code detection capabilities by exercising it on a variety of open-source GitHub repositories and one proprietary code base. We also provide a brief qualitative study on some of the different classes of code anomalies that MPCC can detect to provide an abbreviated insight into its capabilities. ",
    "url": "https://arxiv.org/abs/2204.07225",
    "authors": [
      "Urs C. Muff",
      "Celine Lee",
      "Paul Gottschlich",
      "Justin Gottschlich"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.07241",
    "title": "The Art of Prompting: Event Detection based on Type Specific Prompts",
    "abstract": "We compare various forms of prompts to represent event types and develop a unified framework to incorporate the event type specific prompts for supervised, few-shot, and zero-shot event detection. The experimental results demonstrate that a well-defined and comprehensive event type prompt can significantly improve the performance of event detection, especially when the annotated data is scarce (few-shot event detection) or not available (zero-shot event detection). By leveraging the semantics of event types, our unified framework shows up to 24.3\\% F-score gain over the previous state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2204.07241",
    "authors": [
      "Sijia Wang",
      "Mo Yu",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07243",
    "title": "PLGAN: Generative Adversarial Networks for Power-Line Segmentation in  Aerial Images",
    "abstract": "Accurate segmentation of power lines in various aerial images is very important for UAV flight safety. The complex background and very thin structures of power lines, however, make it an inherently difficult task in computer vision. This paper presents PLGAN, a simple yet effective method based on generative adversarial networks, to segment power lines from aerial images with different backgrounds. Instead of directly using the adversarial networks to generate the segmentation, we take their certain decoding features and embed them into another semantic segmentation network by considering more context, geometry, and appearance information of power lines. We further exploit the appropriate form of the generated images for high-quality feature embedding and define a new loss function in the Hough-transform parameter space to enhance the segmentation of very thin power lines. Extensive experiments and comprehensive analysis demonstrate that our proposed PLGAN outperforms the prior state-of-the-art methods for semantic segmentation and line detection. ",
    "url": "https://arxiv.org/abs/2204.07243",
    "authors": [
      "Rabab Abdelfattah",
      "Xiaofeng Wang",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07246",
    "title": "Robotic and Generative Adversarial Attacks in Offline Writer-independent  Signature Verification",
    "abstract": "This study explores how robots and generative approaches can be used to mount successful false-acceptance adversarial attacks on signature verification systems. Initially, a convolutional neural network topology and data augmentation strategy are explored and tuned, producing an 87.12% accurate model for the verification of 2,640 human signatures. Two robots are then tasked with forging 50 signatures, where 25 are used for the verification attack, and the remaining 25 are used for tuning of the model to defend against them. Adversarial attacks on the system show that there exists an information security risk; the Line-us robotic arm can fool the system 24% of the time and the iDraw 2.0 robot 32% of the time. A conditional GAN finds similar success, with around 30% forged signatures misclassified as genuine. Following fine-tune transfer learning of robotic and generative data, adversarial attacks are reduced below the model threshold by both robots and the GAN. It is observed that tuning the model reduces the risk of attack by robots to 8% and 12%, and that conditional generative adversarial attacks can be reduced to 4% when 25 images are presented and 5% when 1000 images are presented. ",
    "url": "https://arxiv.org/abs/2204.07246",
    "authors": [
      "Jordan J. Bird"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07258",
    "title": "Causal Transformer for Estimating Counterfactual Outcomes",
    "abstract": "Estimating counterfactual outcomes over time from observational data is relevant for many applications (e.g., personalized medicine). Yet, state-of-the-art methods build upon simple long short-term memory (LSTM) networks, thus rendering inferences for complex, long-range dependencies challenging. In this paper, we develop a novel Causal Transformer for estimating counterfactual outcomes over time. Our model is specifically designed to capture complex, long-range dependencies among time-varying confounders. For this, we combine three transformer subnetworks with separate inputs for time-varying covariates, previous treatments, and previous outcomes into a joint network with in-between cross-attentions. We further develop a custom, end-to-end training procedure for our Causal Transformer. Specifically, we propose a novel counterfactual domain confusion loss to address confounding bias: it aims to learn adversarial balanced representations, so that they are predictive of the next outcome but non-predictive of the current treatment assignment. We evaluate our Causal Transformer based on synthetic and real-world datasets, where it achieves superior performance over current baselines. To the best of our knowledge, this is the first work proposing transformer-based architecture for estimating counterfactual outcomes from longitudinal data. ",
    "url": "https://arxiv.org/abs/2204.07258",
    "authors": [
      "Valentyn Melnychuk",
      "Dennis Frauen",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.07261",
    "title": "Convergence and Implicit Regularization Properties of Gradient Descent  for Deep Residual Networks",
    "abstract": "We prove linear convergence of gradient descent to a global minimum for the training of deep residual networks with constant layer width and smooth activation function. We further show that the trained weights, as a function of the layer index, admits a scaling limit which is H\\\"older continuous as the depth of the network tends to infinity. The proofs are based on non-asymptotic estimates of the loss function and of norms of the network weights along the gradient descent path. We illustrate the relevance of our theoretical results to practical settings using detailed numerical experiments on supervised learning problems. ",
    "url": "https://arxiv.org/abs/2204.07261",
    "authors": [
      "Rama Cont",
      "Alain Rossier",
      "RenYuan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.07275",
    "title": "Incremental Prompting: Episodic Memory Prompt for Lifelong Event  Detection",
    "abstract": "Lifelong event detection aims to incrementally update a model with new event types and data while retaining the capability on previously learned old types. One critical challenge is that the model would catastrophically forget old types when continually trained on new data. In this paper, we introduce Episodic Memory Prompts (EMP) to explicitly preserve the learned task-specific knowledge. Our method adopts continuous prompt for each task and they are optimized to instruct the model prediction and learn event-specific representation. The EMPs learned in previous tasks are carried along with the model in subsequent tasks, and can serve as a memory module that keeps the old knowledge and transferring to new tasks. Experiment results demonstrate the effectiveness of our method. Furthermore, we also conduct a comprehensive analysis of the new and old event types in lifelong learning. ",
    "url": "https://arxiv.org/abs/2204.07275",
    "authors": [
      "Minqian Liu",
      "Shiyu Chang",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07300",
    "title": "Dense Learning based Semi-Supervised Object Detection",
    "abstract": "Semi-supervised object detection (SSOD) aims to facilitate the training and deployment of object detectors with the help of a large amount of unlabeled data. Though various self-training based and consistency-regularization based SSOD methods have been proposed, most of them are anchor-based detectors, ignoring the fact that in many real-world applications anchor-free detectors are more demanded. In this paper, we intend to bridge this gap and propose a DenSe Learning (DSL) based anchor-free SSOD algorithm. Specifically, we achieve this goal by introducing several novel techniques, including an Adaptive Filtering strategy for assigning multi-level and accurate dense pixel-wise pseudo-labels, an Aggregated Teacher for producing stable and precise pseudo-labels, and an uncertainty-consistency-regularization term among scales and shuffled patches for improving the generalization capability of the detector. Extensive experiments are conducted on MS-COCO and PASCAL-VOC, and the results show that our proposed DSL method records new state-of-the-art SSOD performance, surpassing existing methods by a large margin. Codes can be found at \\textcolor{blue}{https://github.com/chenbinghui1/DSL}. ",
    "url": "https://arxiv.org/abs/2204.07300",
    "authors": [
      "Binghui Chen",
      "Pengyu Li",
      "Xiang Chen",
      "Biao Wang",
      "Lei Zhang",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07321",
    "title": "Graph Pooling for Graph Neural Networks: Progress, Challenges, and  Opportunities",
    "abstract": "Graph neural networks have emerged as a leading architecture for many graph-level tasks such as graph classification and graph generation with a notable improvement. Among these tasks, graph pooling is an essential component of graph neural network architectures for obtaining a holistic graph-level representation of the entire graph. Although a great variety of methods have been proposed in this promising and fast-developing research field, to the best of our knowledge, little effort has been made to systematically summarize these methods. To set the stage for the development of future works, in this paper, we attempt to fill this gap by providing a broad review of recent methods on graph pooling. Specifically, 1) we first propose a taxonomy of existing graph pooling methods and provide a mathematical summary for each category; 2) next, we provide an overview of the libraries related to graph pooling, including the commonly used datasets, model architectures for downstream tasks, and open-source implementations; 3) then, we further outline in brief the applications that incorporate the idea of graph pooling in a number of domains; 4) and finally, we discuss some critical challenges faced by the current studies and share our insights on potential directions for improving graph pooling in the future. ",
    "url": "https://arxiv.org/abs/2204.07321",
    "authors": [
      "Chuang Liu",
      "Yibing Zhan",
      "Chang Li",
      "Bo Du",
      "Jia Wu",
      "Wenbin Hu",
      "Tongliang Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07328",
    "title": "Knowledgebra: An Algebraic Learning Framework for Knowledge Graph",
    "abstract": "Knowledge graph (KG) representation learning aims to encode entities and relations into dense continuous vector spaces such that knowledge contained in a dataset could be consistently represented. Dense embeddings trained from KG datasets benefit a variety of downstream tasks such as KG completion and link prediction. However, existing KG embedding methods fell short to provide a systematic solution for the global consistency of knowledge representation. We developed a mathematical language for KG based on an observation of their inherent algebraic structure, which we termed as Knowledgebra. By analyzing five distinct algebraic properties, we proved that the semigroup is the most reasonable algebraic structure for the relation embedding of a general knowledge graph. We implemented an instantiation model, SemE, using simple matrix semigroups, which exhibits state-of-the-art performance on standard datasets. Moreover, we proposed a regularization-based method to integrate chain-like logic rules derived from human knowledge into embedding training, which further demonstrates the power of the developed language. As far as we know, by applying abstract algebra in statistical learning, this work develops the first formal language for general knowledge graphs, and also sheds light on the problem of neural-symbolic integration from an algebraic perspective. ",
    "url": "https://arxiv.org/abs/2204.07328",
    "authors": [
      "Tong Yang",
      "Yifei Wang",
      "Long Sha",
      "Jan Engelbrecht",
      "Pengyu Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07335",
    "title": "A Keypoint-based Global Association Network for Lane Detection",
    "abstract": "Lane detection is a challenging task that requires predicting complex topology shapes of lane lines and distinguishing different types of lanes simultaneously. Earlier works follow a top-down roadmap to regress predefined anchors into various shapes of lane lines, which lacks enough flexibility to fit complex shapes of lanes due to the fixed anchor shapes. Lately, some works propose to formulate lane detection as a keypoint estimation problem to describe the shapes of lane lines more flexibly and gradually group adjacent keypoints belonging to the same lane line in a point-by-point manner, which is inefficient and time-consuming during postprocessing. In this paper, we propose a Global Association Network (GANet) to formulate the lane detection problem from a new perspective, where each keypoint is directly regressed to the starting point of the lane line instead of point-by-point extension. Concretely, the association of keypoints to their belonged lane line is conducted by predicting their offsets to the corresponding starting points of lanes globally without dependence on each other, which could be done in parallel to greatly improve efficiency. In addition, we further propose a Lane-aware Feature Aggregator (LFA), which adaptively captures the local correlations between adjacent keypoints to supplement local information to the global association. Extensive experiments on two popular lane detection benchmarks show that our method outperforms previous methods with F1 score of 79.63% on CULane and 97.71% on Tusimple dataset with high FPS. The code will be released at https://github.com/Wolfwjs/GANet. ",
    "url": "https://arxiv.org/abs/2204.07335",
    "authors": [
      "Jinsheng Wang",
      "Yinchao Ma",
      "Shaofei Huang",
      "Tianrui Hui",
      "Fei Wang",
      "Chen Qian",
      "Tianzhu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07347",
    "title": "Crowd counting with crowd attention convolutional neural network",
    "abstract": "Crowd counting is a challenging problem due to the scene complexity and scale variation. Although deep learning has achieved great improvement in crowd counting, scene complexity affects the judgement of these methods and they usually regard some objects as people mistakenly; causing potentially enormous errors in the crowd counting result. To address the problem, we propose a novel end-to-end model called Crowd Attention Convolutional Neural Network (CAT-CNN). Our CAT-CNN can adaptively assess the importance of a human head at each pixel location by automatically encoding a confidence map. With the guidance of the confidence map, the position of human head in estimated density map gets more attention to encode the final density map, which can avoid enormous misjudgements effectively. The crowd count can be obtained by integrating the final density map. To encode a highly refined density map, the total crowd count of each image is classified in a designed classification task and we first explicitly map the prior of the population-level category to feature maps. To verify the efficiency of our proposed method, extensive experiments are conducted on three highly challenging datasets. Results establish the superiority of our method over many state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.07347",
    "authors": [
      "Jiwei Chen",
      "Wen Su",
      "Zengfu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07350",
    "title": "Condition-Invariant and Compact Visual Place Description by  Convolutional Autoencoder",
    "abstract": "Visual place recognition (VPR) in condition-varying environments is still an open problem. Popular solutions are CNN-based image descriptors, which have been shown to outperform traditional image descriptors based on hand-crafted visual features. However, there are two drawbacks of current CNN-based descriptors: a) their high dimension and b) lack of generalization, leading to low efficiency and poor performance in applications. In this paper, we propose to use a convolutional autoencoder (CAE) to tackle this problem. We employ a high-level layer of a pre-trained CNN to generate features, and train a CAE to map the features to a low-dimensional space to improve the condition invariance property of the descriptor and reduce its dimension at the same time. We verify our method in three challenging datasets involving significant illumination changes, and our method is shown to be superior to the state-of-the-art. For the benefit of the community, we make public the source code. ",
    "url": "https://arxiv.org/abs/2204.07350",
    "authors": [
      "Hanjing Ye",
      "Weinan Chen",
      "Jingwen Yu",
      "Li He",
      "Yisheng Guan",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.07352",
    "title": "A Differentially Private Probabilistic Framework for Modeling the  Variability Across Federated Datasets of Heterogeneous Multi-View  Observations",
    "abstract": "We propose a novel federated learning paradigm to model data variability among heterogeneous clients in multi-centric studies. Our method is expressed through a hierarchical Bayesian latent variable model, where client-specific parameters are assumed to be realization from a global distribution at the master level, which is in turn estimated to account for data bias and variability across clients. We show that our framework can be effectively optimized through expectation maximization (EM) over latent master's distribution and clients' parameters. We also introduce formal differential privacy (DP) guarantees compatibly with our EM optimization scheme. We tested our method on the analysis of multi-modal medical imaging data and clinical scores from distributed clinical datasets of patients affected by Alzheimer's disease. We demonstrate that our method is robust when data is distributed either in iid and non-iid manners, even when local parameters perturbation is included to provide DP guarantees. Moreover, the variability of data, views and centers can be quantified in an interpretable manner, while guaranteeing high-quality data reconstruction as compared to state-of-the-art autoencoding models and federated learning schemes. The code is available at https://gitlab.inria.fr/epione/federated-multi-views-ppca. ",
    "url": "https://arxiv.org/abs/2204.07352",
    "authors": [
      "Irene Balelli",
      "Santiago Silva",
      "Marco Lorenzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2204.07359",
    "title": "Text Revision by On-the-Fly Representation Optimization",
    "abstract": "Text revision refers to a family of natural language generation tasks, where the source and target sequences share moderate resemblance in surface form but differentiate in attributes, such as text formality and simplicity. Current state-of-the-art methods formulate these tasks as sequence-to-sequence learning problems, which rely on large-scale parallel training corpus. In this paper, we present an iterative in-place editing approach for text revision, which requires no parallel data. In this approach, we simply fine-tune a pre-trained Transformer with masked language modeling and attribute classification. During inference, the editing at each iteration is realized by two-step span replacement. At the first step, the distributed representation of the text optimizes on the fly towards an attribute function. At the second step, a text span is masked and another new one is proposed conditioned on the optimized representation. The empirical experiments on two typical and important text revision tasks, text formalization and text simplification, show the effectiveness of our approach. It achieves competitive and even better performance than state-of-the-art supervised methods on text simplification, and gains better performance than strong unsupervised methods on text formalization \\footnote{Code and model are available at \\url{https://github.com/jingjingli01/OREO}}. ",
    "url": "https://arxiv.org/abs/2204.07359",
    "authors": [
      "Jingjing Li",
      "Zichao Li",
      "Tao Ge",
      "Irwin King",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.07372",
    "title": "Towards Building a Personalized Dialogue Generator via Implicit User  Persona Detection",
    "abstract": "Current works in the generation of personalized dialogue primarily contribute to the agent avoiding contradictory persona and driving the response more informative. However, we found that the generated responses from these models are mostly self-centered with little care for the other party since they ignore the user's persona. Moreover, we consider high-quality transmission is essentially built based on apprehending the persona of the other party. Motivated by this, we propose a novel personalized dialogue generator by detecting implicit user persona. Because it's difficult to collect a large number of personas for each user, we attempt to model the user's potential persona and its representation from the dialogue absence of any external information. Perception variable and fader variable are conceived utilizing Conditional Variational Inference. The two latent variables simulate the process of people being aware of the other party's persona and producing the corresponding expression in conversation. Finally, Posterior-discriminated Regularization is presented to enhance the training procedure. Empirical studies demonstrate that compared with the state-of-the-art methods, ours is more concerned with the user's persona and outperforms in evaluations. ",
    "url": "https://arxiv.org/abs/2204.07372",
    "authors": [
      "Itsugun Cho",
      "Dongyang Wang",
      "Ryota Takahashi",
      "Hiroaki Saito"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07373",
    "title": "Revisiting the Adversarial Robustness-Accuracy Tradeoff in Robot  Learning",
    "abstract": "Adversarial training (i.e., training on adversarially perturbed input data) is a well-studied method for making neural networks robust to potential adversarial attacks during inference. However, the improved robustness does not come for free but rather is accompanied by a decrease in overall model accuracy and performance. Recent work has shown that, in practical robot learning applications, the effects of adversarial training do not pose a fair trade-off but inflict a net loss when measured in holistic robot performance. This work revisits the robustness-accuracy trade-off in robot learning by systematically analyzing if recent advances in robust training methods and theory in conjunction with adversarial robot learning can make adversarial training suitable for real-world robot applications. We evaluate a wide variety of robot learning tasks ranging from autonomous driving in a high-fidelity environment amenable to sim-to-real deployment, to mobile robot gesture recognition. Our results demonstrate that, while these techniques make incremental improvements on the trade-off on a relative scale, the negative side-effects caused by adversarial training still outweigh the improvements by an order of magnitude. We conclude that more substantial advances in robust learning methods are necessary before they can benefit robot learning tasks in practice. ",
    "url": "https://arxiv.org/abs/2204.07373",
    "authors": [
      "Mathias Lechner",
      "Alexander Amini",
      "Daniela Rus",
      "Thomas A. Henzinger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07380",
    "title": "Crowd counting with segmentation attention convolutional neural network",
    "abstract": "Deep learning occupies an undisputed dominance in crowd counting. In this paper, we propose a novel convolutional neural network (CNN) architecture called SegCrowdNet. Despite the complex background in crowd scenes, the proposeSegCrowdNet still adaptively highlights the human head region and suppresses the non-head region by segmentation. With the guidance of an attention mechanism, the proposed SegCrowdNet pays more attention to the human head region and automatically encodes the highly refined density map. The crowd count can be obtained by integrating the density map. To adapt the variation of crowd counts, SegCrowdNet intelligently classifies the crowd count of each image into several groups. In addition, the multi-scale features are learned and extracted in the proposed SegCrowdNet to overcome the scale variations of the crowd. To verify the effectiveness of our proposed method, extensive experiments are conducted on four challenging datasets. The results demonstrate that our proposed SegCrowdNet achieves excellent performance compared with the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.07380",
    "authors": [
      "Jiwei Chen",
      "Zengfu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07390",
    "title": "Email Spam Detection Using Hierarchical Attention Hybrid Deep Learning  Method",
    "abstract": "Email is one of the most widely used ways to communicate, with millions of people and businesses relying on it to communicate and share knowledge and information on a daily basis. Nevertheless, the rise in email users has occurred a dramatic increase in spam emails in recent years. Processing and managing emails properly for individuals and companies are getting increasingly difficult. This article proposes a novel technique for email spam detection that is based on a combination of convolutional neural networks, gated recurrent units, and attention mechanisms. During system training, the network is selectively focused on necessary parts of the email text. The usage of convolution layers to extract more meaningful, abstract, and generalizable features by hierarchical representation is the major contribution of this study. Additionally, this contribution incorporates cross-dataset evaluation, which enables the generation of more independent performance results from the model's training dataset. According to cross-dataset evaluation results, the proposed technique advances the results of the present attention-based techniques by utilizing temporal convolutions, which give us more flexible receptive field sizes are utilized. The suggested technique's findings are compared to those of state-of-the-art models and show that our approach outperforms them. ",
    "url": "https://arxiv.org/abs/2204.07390",
    "authors": [
      "Sultan Zavrak",
      "Seyhmus Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.07394",
    "title": "FasterVideo: Efficient Online Joint Object Detection And Tracking",
    "abstract": "Object detection and tracking in videos represent essential and computationally demanding building blocks for current and future visual perception systems. In order to reduce the efficiency gap between available methods and computational requirements of real-world applications, we propose to re-think one of the most successful methods for image object detection, Faster R-CNN, and extend it to the video domain. Specifically, we extend the detection framework to learn instance-level embeddings which prove beneficial for data association and re-identification purposes. Focusing on the computational aspects of detection and tracking, our proposed method reaches a very high computational efficiency necessary for relevant applications, while still managing to compete with recent and state-of-the-art methods as shown in the experiments we conduct on standard object tracking benchmarks ",
    "url": "https://arxiv.org/abs/2204.07394",
    "authors": [
      "Issa Mouawad",
      "Francesca Odone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07403",
    "title": "Deep learning model solves change point detection for multiple change  types",
    "abstract": "A change points detection aims to catch an abrupt disorder in data distribution. Common approaches assume that there are only two fixed distributions for data: one before and another after a change point. Real-world data are richer than this assumption. There can be multiple different distributions before and after a change. We propose an approach that works in the multiple-distributions scenario. Our approach learn representations for semi-structured data suitable for change point detection, while a common classifiers-based approach fails. Moreover, our model is more robust, when predicting change points. The datasets used for benchmarking are sequences of images with and without change points in them. ",
    "url": "https://arxiv.org/abs/2204.07403",
    "authors": [
      "Alexander Stepikin",
      "Evgenia Romanenkova",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07408",
    "title": "Towards Fine-grained Causal Reasoning and QA",
    "abstract": "Understanding causality is key to the success of NLP applications, especially in high-stakes domains. Causality comes in various perspectives such as enable and prevent that, despite their importance, have been largely ignored in the literature. This paper introduces a novel fine-grained causal reasoning dataset and presents a series of novel predictive tasks in NLP, such as causality detection, event causality extraction, and Causal QA. Our dataset contains human annotations of 25K cause-effect event pairs and 24K question-answering pairs within multi-sentence samples, where each can have multiple causal relationships. Through extensive experiments and analysis, we show that the complex relations in our dataset bring unique challenges to state-of-the-art methods across all three tasks and highlight potential research opportunities, especially in developing \"causal-thinking\" methods. ",
    "url": "https://arxiv.org/abs/2204.07408",
    "authors": [
      "Linyi Yang",
      "Zhen Wang",
      "Yuxiang Wu",
      "Jie Yang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2204.07410",
    "title": "Initialisation and Grammar Design in Grammar-Guided Evolutionary  Computation",
    "abstract": "Grammars provide a convenient and powerful mechanism to define the space of possible solutions for a range of problems. However, when used in grammatical evolution (GE), great care must be taken in the design of a grammar to ensure that the polymorphic nature of the genotype-to-phenotype mapping does not impede search. Additionally, recent work has highlighted the importance of the initialisation method on GE's performance. While recent work has shed light on the matters of initialisation and grammar design with respect to GE, their impact on other methods, such as random search and context-free grammar genetic programming (CFG-GP), is largely unknown. This paper examines GE, random search and CFG-GP under a range of benchmark problems using several different initialisation routines and grammar designs. The results suggest that CFG-GP is less sensitive to initialisation and grammar design than both GE and random search: we also demonstrate that observed cases of poor performance by CFG-GP are managed through simple adjustment of tuning parameters. We conclude that CFG-GP is a strong base from which to conduct grammar-guided evolutionary search, and that future work should focus on understanding the parameter space of CFG-GP for better application. ",
    "url": "https://arxiv.org/abs/2204.07410",
    "authors": [
      "Grant Dick",
      "Peter A. Whigham"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.07413",
    "title": "Super Resolution for Turbulent Flows in 2D: Stabilized Physics Informed  Neural Networks",
    "abstract": "We propose a new design of a neural network for solving a zero shot super resolution problem for turbulent flows. We embed Luenberger-type observer into the network's architecture to inform the network of the physics of the process, and to provide error correction and stabilization mechanisms. In addition, to compensate for decrease of observer's performance due to the presence of unknown destabilizing forcing, the network is designed to estimate the contribution of the unknown forcing implicitly from the data over the course of training. By running a set of numerical experiments, we demonstrate that the proposed network does recover unknown forcing from data and is capable of predicting turbulent flows in high resolution from low resolution noisy observations. ",
    "url": "https://arxiv.org/abs/2204.07413",
    "authors": [
      "Mykhaylo Zayats",
      "Ma\u0142gorzata J. Zimo\u0144",
      "Kyongmin Yeo",
      "Sergiy Zhuk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2204.07415",
    "title": "Universal approximation property of invertible neural networks",
    "abstract": "Invertible neural networks (INNs) are neural network architectures with invertibility by design. Thanks to their invertibility and the tractability of Jacobian, INNs have various machine learning applications such as probabilistic modeling, generative modeling, and representation learning. However, their attractive properties often come at the cost of restricting the layer designs, which poses a question on their representation power: can we use these models to approximate sufficiently diverse functions? To answer this question, we have developed a general theoretical framework to investigate the representation power of INNs, building on a structure theorem of differential geometry. The framework simplifies the approximation problem of diffeomorphisms, which enables us to show the universal approximation properties of INNs. We apply the framework to two representative classes of INNs, namely Coupling-Flow-based INNs (CF-INNs) and Neural Ordinary Differential Equations (NODEs), and elucidate their high representation power despite the restrictions on their architectures. ",
    "url": "https://arxiv.org/abs/2204.07415",
    "authors": [
      "Isao Ishikawa",
      "Takeshi Teshima",
      "Koichi Tojo",
      "Kenta Oono",
      "Masahiro Ikeda",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.07429",
    "title": "Experimentally realized memristive memory augmented neural network",
    "abstract": "Lifelong on-device learning is a key challenge for machine intelligence, and this requires learning from few, often single, samples. Memory augmented neural network has been proposed to achieve the goal, but the memory module has to be stored in an off-chip memory due to its size. Therefore the practical use has been heavily limited. Previous works on emerging memory-based implementation have difficulties in scaling up because different modules with various structures are difficult to integrate on the same chip and the small sense margin of the content addressable memory for the memory module heavily limited the degree of mismatch calculation. In this work, we implement the entire memory augmented neural network architecture in a fully integrated memristive crossbar platform and achieve an accuracy that closely matches standard software on digital hardware for the Omniglot dataset. The successful demonstration is supported by implementing new functions in crossbars in addition to widely reported matrix multiplications. For example, the locality-sensitive hashing operation is implemented in crossbar arrays by exploiting the intrinsic stochasticity of memristor devices. Besides, the content-addressable memory module is realized in crossbars, which also supports the degree of mismatches. Simulations based on experimentally validated models show such an implementation can be efficiently scaled up for one-shot learning on the Mini-ImageNet dataset. The successful demonstration paves the way for practical on-device lifelong learning and opens possibilities for novel attention-based algorithms not possible in conventional hardware. ",
    "url": "https://arxiv.org/abs/2204.07429",
    "authors": [
      "Ruibin Mao",
      "Bo Wen",
      "Yahui Zhao",
      "Arman Kazemi",
      "Ann Franchesca Laguna",
      "Michael Neimier",
      "X. Sharon Hu",
      "Xia Sheng",
      "Catherine E. Graves",
      "John Paul Strachan",
      "Can Li"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.07431",
    "title": "The Importance of Landscape Features for Performance Prediction of  Modular CMA-ES Variants",
    "abstract": "Selecting the most suitable algorithm and determining its hyperparameters for a given optimization problem is a challenging task. Accurately predicting how well a certain algorithm could solve the problem is hence desirable. Recent studies in single-objective numerical optimization show that supervised machine learning methods can predict algorithm performance using landscape features extracted from the problem instances. Existing approaches typically treat the algorithms as black-boxes, without consideration of their characteristics. To investigate in this work if a selection of landscape features that depends on algorithms properties could further improve regression accuracy, we regard the modular CMA-ES framework and estimate how much each landscape feature contributes to the best algorithm performance regression models. Exploratory data analysis performed on this data indicate that the set of most relevant features does not depend on the configuration of individual modules, but the influence that these features have on regression accuracy does. In addition, we have shown that by using classifiers that take the features relevance on the model accuracy, we are able to predict the status of individual modules in the CMA-ES configurations. ",
    "url": "https://arxiv.org/abs/2204.07431",
    "authors": [
      "Ana Kostovska",
      "Diederick Vermetten",
      "Sa\u0161o D\u017eeroski",
      "Carola Doerr",
      "Peter Koro\u0161ec",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07434",
    "title": "ERGO: Event Relational Graph Transformer for Document-level Event  Causality Identification",
    "abstract": "Document-level Event Causality Identification (DECI) aims to identify causal relations between event pairs in a document. It poses a great challenge of across-sentence reasoning without clear causal indicators. In this paper, we propose a novel Event Relational Graph TransfOrmer (ERGO) framework for DECI, which improves existing state-of-the-art (SOTA) methods upon two aspects. First, we formulate DECI as a node classification problem by constructing an event relational graph, without the needs of prior knowledge or tools. Second, ERGO seamlessly integrates event-pair relation classification and global inference, which leverages a Relational Graph Transformer (RGT) to capture the potential causal chain. Besides, we introduce edge-building strategies and adaptive focal loss to deal with the massive false positives caused by common spurious correlation. Extensive experiments on two benchmark datasets show that ERGO significantly outperforms previous SOTA methods (13.1% F1 gains on average). We have conducted extensive quantitative analysis and case studies to provide insights for future research directions (Section 4.8). ",
    "url": "https://arxiv.org/abs/2204.07434",
    "authors": [
      "Meiqi Chen",
      "Yixin Cao",
      "Kunquan Deng",
      "Mukai Li",
      "Kun Wang",
      "Jing Shao",
      "Yan Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07439",
    "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold",
    "abstract": "Binary Neural Networks (BNNs) have emerged as a promising solution for reducing the memory footprint and compute costs of deep neural networks. BNNs, on the other hand, suffer from information loss because binary activations are limited to only two values, resulting in reduced accuracy. To improve the accuracy, previous studies have attempted to control the distribution of binary activation by manually shifting the threshold of the activation function or making the shift amount trainable. During the process, they usually depended on statistical information computed from a batch. We argue that using statistical data from a batch fails to capture the crucial information for each input instance in BNN computations, and the differences between statistical information computed from each instance need to be considered when determining the binary activation threshold of each instance. Based on the concept, we propose the Binary Neural Network with INSTAnce-aware threshold (INSTA-BNN), which decides the activation threshold value considering the difference between statistical data computed from a batch and each instance. The proposed INSTA-BNN outperforms the baseline by 2.5% and 2.3% on the ImageNet classification task with comparable computing cost, achieving 68.0% and 71.7% top-1 accuracy on ResNet-18 and MobileNetV1 based models, respectively. ",
    "url": "https://arxiv.org/abs/2204.07439",
    "authors": [
      "Changhun Lee",
      "Hyungjun Kim",
      "Eunhyeok Park",
      "Jae-Joon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07456",
    "title": "ORCNet: A context-based network to simultaneously segment the ocular  region components",
    "abstract": "Accurate extraction of the Region of Interest is critical for successful ocular region-based biometrics. In this direction, we propose a new context-based segmentation approach, entitled Ocular Region Context Network (ORCNet), introducing a specific loss function, i.e., he Punish Context Loss (PC-Loss). The PC-Loss punishes the segmentation losses of a network by using a percentage difference value between the ground truth and the segmented masks. We obtain the percentage difference by taking into account Biederman's semantic relationship concepts, in which we use three contexts (semantic, spatial, and scale) to evaluate the relationships of the objects in an image. Our proposal achieved promising results in the evaluated scenarios: iris, sclera, and ALL (iris + sclera) segmentations, utperforming the literature baseline techniques. The ORCNet with ResNet-152 outperforms the best baseline (EncNet with ResNet-152) on average by 2.27%, 28.26% and 6.43% in terms of F-Score, Error Rate and Intersection Over Union, respectively. We also provide (for research purposes) 3,191 manually labeled masks for the MICHE-I database, as another contribution of our work. ",
    "url": "https://arxiv.org/abs/2204.07456",
    "authors": [
      "Diego Rafael Lucio",
      "Luiz A. Zanlorensi",
      "Yandre Maldonado e Gomes da Costa",
      "David Menotti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07464",
    "title": "Improving Pre-trained Language Models with Syntactic Dependency  Prediction Task for Chinese Semantic Error Recognition",
    "abstract": "Existing Chinese text error detection mainly focuses on spelling and simple grammatical errors. These errors have been studied extensively and are relatively simple for humans. On the contrary, Chinese semantic errors are understudied and more complex that humans cannot easily recognize. The task of this paper is Chinese Semantic Error Recognition (CSER), a binary classification task to determine whether a sentence contains semantic errors. The current research has no effective method to solve this task. In this paper, we inherit the model structure of BERT and design several syntax-related pre-training tasks so that the model can learn syntactic knowledge. Our pre-training tasks consider both the directionality of the dependency structure and the diversity of the dependency relationship. Due to the lack of a published dataset for CSER, we build a high-quality dataset for CSER for the first time named Corpus of Chinese Linguistic Semantic Acceptability (CoCLSA). The experimental results on the CoCLSA show that our methods outperform universal pre-trained models and syntax-infused models. ",
    "url": "https://arxiv.org/abs/2204.07464",
    "authors": [
      "Bo Sun",
      "Baoxin Wang",
      "Wanxiang Che",
      "Dayong Wu",
      "Zhigang Chen",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07475",
    "title": "Kernel similarity matching with Hebbian neural networks",
    "abstract": "Recent works have derived neural networks with online correlation-based learning rules to perform \\textit{kernel similarity matching}. These works applied existing linear similarity matching algorithms to nonlinear features generated with random Fourier methods. In this paper attempt to perform kernel similarity matching by directly learning the nonlinear features. Our algorithm proceeds by deriving and then minimizing an upper bound for the sum of squared errors between output and input kernel similarities. The construction of our upper bound leads to online correlation-based learning rules which can be implemented with a 1 layer recurrent neural network. In addition to generating high-dimensional linearly separable representations, we show that our upper bound naturally yields representations which are sparse and selective for specific input patterns. We compare the approximation quality of our method to neural random Fourier method and variants of the popular but non-biological \"Nystr{\\\"o}m\" method for approximating the kernel matrix. Our method appears to be comparable or better than randomly sampled Nystr{\\\"o}m methods when the outputs are relatively low dimensional (although still potentially higher dimensional than the inputs) but less faithful when the outputs are very high dimensional. ",
    "url": "https://arxiv.org/abs/2204.07475",
    "authors": [
      "Kyle Luther",
      "H. Sebastian Seung"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07482",
    "title": "Towards PAC Multi-Object Detection and Tracking",
    "abstract": "Accurately detecting and tracking multi-objects is important for safety-critical applications such as autonomous navigation. However, it remains challenging to provide guarantees on the performance of state-of-the-art techniques based on deep learning. We consider a strategy known as conformal prediction, which predicts sets of labels instead of a single label; in the classification and regression settings, these algorithms can guarantee that the true label lies within the prediction set with high probability. Building on these ideas, we propose multi-object detection and tracking algorithms that come with probably approximately correct (PAC) guarantees. They do so by constructing both a prediction set around each object detection as well as around the set of edge transitions; given an object, the detection prediction set contains its true bounding box with high probability, and the edge prediction set contains its true transition across frames with high probability. We empirically demonstrate that our method can detect and track objects with PAC guarantees on the COCO and MOT-17 datasets. ",
    "url": "https://arxiv.org/abs/2204.07482",
    "authors": [
      "Shuo Li",
      "Sangdon Park",
      "Xiayan Ji",
      "Insup Lee",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07501",
    "title": "Evaluating few shot and Contrastive learning Methods for Code Clone  Detection",
    "abstract": "Context: Code Clone Detection (CCD) is a software engineering task that is used for plagiarism detection, code search, and code comprehension. Recently, deep learning-based models have achieved an F1 score (a metric used to assess classifiers) of $\\sim$95\\% on the CodeXGLUE benchmark. These models require many training data, mainly fine-tuned on Java or C++ datasets. However, no previous study evaluates the generalizability of these models where a limited amount of annotated data is available. Objective: The main objective of this research is to assess the ability of the CCD models as well as few shot learning algorithms for unseen programming problems and new languages (i.e., the model is not trained on these problems/languages). Method: We assess the generalizability of the state of the art models for CCD in few shot settings (i.e., only a few samples are available for fine-tuning) by setting three scenarios: i) unseen problems, ii) unseen languages, iii) combination of new languages and new problems. We choose three datasets of BigCloneBench, POJ-104, and CodeNet and Java, C++, and Ruby languages. Then, we employ Model Agnostic Meta-learning (MAML), where the model learns a meta-learner capable of extracting transferable knowledge from the train set; so that the model can be fine-tuned using a few samples. Finally, we combine contrastive learning with MAML to further study whether it can improve the results of MAML. ",
    "url": "https://arxiv.org/abs/2204.07501",
    "authors": [
      "Mohamad Khajezade",
      "Fatemeh Hendijani Fard",
      "Mohamed S. Shehata"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.07519",
    "title": "An Introductory Review of Spiking Neural Network and Artificial Neural  Network: From Biological Intelligence to Artificial Intelligence",
    "abstract": "Recently, stemming from the rapid development of artificial intelligence, which has gained expansive success in pattern recognition, robotics, and bioinformatics, neuroscience is also gaining tremendous progress. A kind of spiking neural network with biological interpretability is gradually receiving wide attention, and this kind of neural network is also regarded as one of the directions toward general artificial intelligence. This review introduces the following sections, the biological background of spiking neurons and the theoretical basis, different neuronal models, the connectivity of neural circuits, the mainstream neural network learning mechanisms and network architectures, etc. This review hopes to attract different researchers and advance the development of brain-inspired intelligence and artificial intelligence. ",
    "url": "https://arxiv.org/abs/2204.07519",
    "authors": [
      "Shengjie Zheng",
      "Lang Qian",
      "Pingsheng Li",
      "Chenggang He",
      "Xiaoqin Qin",
      "Xiaojian Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07524",
    "title": "Neural Structured Prediction for Inductive Node Classification",
    "abstract": "This paper studies node classification in the inductive setting, i.e., aiming to learn a model on labeled training graphs and generalize it to infer node labels on unlabeled test graphs. This problem has been extensively studied with graph neural networks (GNNs) by learning effective node representations, as well as traditional structured prediction methods for modeling the structured output of node labels, e.g., conditional random fields (CRFs). In this paper, we present a new approach called the Structured Proxy Network (SPN), which combines the advantages of both worlds. SPN defines flexible potential functions of CRFs with GNNs. However, learning such a model is nontrivial as it involves optimizing a maximin game with high-cost inference. Inspired by the underlying connection between joint and marginal distributions defined by Markov networks, we propose to solve an approximate version of the optimization problem as a proxy, which yields a near-optimal solution, making learning more efficient. Extensive experiments on two settings show that our approach outperforms many competitive baselines. ",
    "url": "https://arxiv.org/abs/2204.07524",
    "authors": [
      "Meng Qu",
      "Huiyu Cai",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07539",
    "title": "Stability and Robustness of a Hybrid Control Law for the Half-bridge  Inverter",
    "abstract": "Hybrid systems combine both discrete and continuous state dynamics. Power electronic inverters are inherently hybrid systems: they are controlled via discrete-valued switching inputs which determine the evolution of the continuous-valued current and voltage state dynamics. Hybrid systems analysis could prove increasingly useful as large numbers of renewable energy sources are incorporated to the grid with inverters as their interface. In this work, we explore a hybrid systems approach for the stability analysis of power and power electronic systems. We provide an analytical proof showing that the use of a hybrid model for the half-bridge inverter allows the derivation of a control law that drives the system states to desired sinusoidal voltage and current references. We derive an analytical expression for a global Lyapunov function for the dynamical system in terms of the system parameters, which proves uniform, global, and asymptotic stability of the origin in error coordinates. Moreover, we demonstrate robustness to parameter changes through this Lyapunov function. We validate these results via simulation. Finally, we show empirically the incorporation of droop control with this hybrid systems approach. In the low-inertia grid community, the juxtaposition of droop control with the hybrid switching control can be considered a grid-forming control strategy using a switched inverter model. ",
    "url": "https://arxiv.org/abs/2204.07539",
    "authors": [
      "Gabriel E. Col\u00f3n-Reyes",
      "Kaylene C. Stocking",
      "Duncan S. Callaway",
      "Claire J. Tomlin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.07566",
    "title": "Improving Frame-Online Neural Speech Enhancement with Overlapped-Frame  Prediction",
    "abstract": "Frame-online speech enhancement systems in the short-time Fourier transform (STFT) domain usually have an algorithmic latency equal to the window size due to the use of the overlap-add algorithm in the inverse STFT (iSTFT). This algorithmic latency allows the enhancement models to leverage future contextual information up to a length equal to the window size. However, current frame-online systems only partially leverage this future information. To fully exploit this information, this study proposes an overlapped-frame prediction technique for deep learning based frame-online speech enhancement, where at each frame our deep neural network (DNN) predicts the current and several past frames that are necessary for overlap-add, instead of only predicting the current frame. In addition, we propose a novel loss function to account for the scale difference between predicted and oracle target signals. Evaluations results on a noisy-reverberant speech enhancement task show the effectiveness of the proposed algorithms. ",
    "url": "https://arxiv.org/abs/2204.07566",
    "authors": [
      "Zhong-Qiu Wang",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.07569",
    "title": "Deep Learning-based List Sphere Decoding for Faster-than-Nyquist (FTN)  Signaling Detection",
    "abstract": "Faster-than-Nyquist (FTN) signaling is a candidate non-orthonormal transmission technique to improve the spectral efficiency (SE) of future communication systems. However, such improvements of the SE are at the cost of additional computational complexity to remove the intentionally introduced intersymbol interference. In this paper, we investigate the use of deep learning (DL) to reduce the detection complexity of FTN signaling. To eliminate the need of having a noise whitening filter at the receiver, we first present an equivalent FTN signaling model based on using a set of orthonormal basis functions and identify its operation region. Second, we propose a DL-based list sphere decoding (DL-LSD) algorithm that selects and updates the initial radius of the original LSD to guarantee a pre-defined number $N_{\\text{L}}$ of lattice points inside the hypersphere. This is achieved by training a neural network to output an approximate initial radius that includes $N_{\\text{L}}$ lattice points. At the testing phase, if the hypersphere has more than $N_{\\text{L}}$ lattice points, we keep the $N_{\\text{L}}$ closest points to the point corresponding to the received FTN signal; however, if the hypersphere has less than $N_{\\text{L}}$ points, we increase the approximate initial radius by a value that depends on the standard deviation of the distribution of the output radii from the training phase. Then, the approximate value of the log-likelihood ratio (LLR) is calculated based on the obtained $N_{\\text{L}}$ points. Simulation results show that the computational complexity of the proposed DL-LSD is lower than its counterpart of the original LSD by orders of magnitude. ",
    "url": "https://arxiv.org/abs/2204.07569",
    "authors": [
      "Sina Abbasi",
      "Ebrahim Bedeer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.07576",
    "title": "The Distributed Information Bottleneck reveals the explanatory structure  of complex systems",
    "abstract": "The fruits of science are relationships made comprehensible, often by way of approximation. While deep learning is an extremely powerful way to find relationships in data, its use in science has been hindered by the difficulty of understanding the learned relationships. The Information Bottleneck (IB) is an information theoretic framework for understanding a relationship between an input and an output in terms of a trade-off between the fidelity and complexity of approximations to the relationship. Here we show that a crucial modification -- distributing bottlenecks across multiple components of the input -- opens fundamentally new avenues for interpretable deep learning in science. The Distributed Information Bottleneck throttles the downstream complexity of interactions between the components of the input, deconstructing a relationship into meaningful approximations found through deep learning without requiring custom-made datasets or neural network architectures. Applied to a complex system, the approximations illuminate aspects of the system's nature by restricting -- and monitoring -- the information about different components incorporated into the approximation. We demonstrate the Distributed IB's explanatory utility in systems drawn from applied mathematics and condensed matter physics. In the former, we deconstruct a Boolean circuit into approximations that isolate the most informative subsets of input components without requiring exhaustive search. In the latter, we localize information about future plastic rearrangement in the static structure of a sheared glass, and find the information to be more or less diffuse depending on the system's preparation. By way of a principled scheme of approximations, the Distributed IB brings much-needed interpretability to deep learning and enables unprecedented analysis of information flow through a system. ",
    "url": "https://arxiv.org/abs/2204.07576",
    "authors": [
      "Kieran A. Murphy",
      "Dani S. Bassett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2204.07163",
    "title": "Cross-Frequency Coupling Increases Memory Capacity in Oscillatory Neural  Networks",
    "abstract": "An open problem in neuroscience is to explain the functional role of oscillations in neural networks, contributing, for example, to perception, attention, and memory. Cross-frequency coupling (CFC) is associated with information integration across populations of neurons. Impaired CFC is linked to neurological disease. It is unclear what role CFC has in information processing and brain functional connectivity. We construct a model of CFC which predicts a computational role for observed $\\theta - \\gamma$ oscillatory circuits in the hippocampus and cortex. Our model predicts that the complex dynamics in recurrent and feedforward networks of coupled oscillators performs robust information storage and pattern retrieval. Based on phasor associative memories (PAM), we present a novel oscillator neural network (ONN) model that includes subharmonic injection locking (SHIL) and which reproduces experimental observations of CFC. We show that the presence of CFC increases the memory capacity of a population of neurons connected by plastic synapses. CFC enables error-free pattern retrieval whereas pattern retrieval fails without CFC. In addition, the trade-offs between sparse connectivity, capacity, and information per connection are identified. The associative memory is based on a complex-valued neural network, or phasor neural network (PNN). We show that for values of $Q$ which are the same as the ratio of $\\gamma$ to $\\theta$ oscillations observed in the hippocampus and the cortex, the associative memory achieves greater capacity and information storage than previous models. The novel contributions of this work are providing a computational framework based on oscillator dynamics which predicts the functional role of neural oscillations and connecting concepts in neural network theory and dynamical system theory. ",
    "url": "https://arxiv.org/abs/2204.07163",
    "authors": [
      "Connor Bybee",
      "Alexander Belsten",
      "Friedrich T. Sommer"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.07186",
    "title": "Optimal quadratic binding for relational reasoning in vector symbolic  neural architectures",
    "abstract": "Binding operation is fundamental to many cognitive processes, such as cognitive map formation, relational reasoning, and language comprehension. In these processes, two different modalities, such as location and objects, events and their contextual cues, and words and their roles, need to be bound together, but little is known about the underlying neural mechanisms. Previous works introduced a binding model based on quadratic functions of bound pairs, followed by vector summation of multiple pairs. Based on this framework, we address following questions: Which classes of quadratic matrices are optimal for decoding relational structures? And what is the resultant accuracy? We introduce a new class of binding matrices based on a matrix representation of octonion algebra, an eight-dimensional extension of complex numbers. We show that these matrices enable a more accurate unbinding than previously known methods when a small number of pairs are present. Moreover, numerical optimization of a binding operator converges to this octonion binding. We also show that when there are a large number of bound pairs, however, a random quadratic binding performs as well as the octonion and previously-proposed binding methods. This study thus provides new insight into potential neural mechanisms of binding operations in the brain. ",
    "url": "https://arxiv.org/abs/2204.07186",
    "authors": [
      "Naoki Hiratani",
      "Haim Sompolinsky"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.07230",
    "title": "Learning two-phase microstructure evolution using neural operators and  autoencoder architectures",
    "abstract": "Phase-field modeling is an effective mesoscale method for capturing the evolution dynamics of materials, e.g., in spinodal decomposition of a two-phase mixture. However, the accuracy of high-fidelity phase field models comes at a substantial computational cost. Hence, fast and generalizable surrogate models are needed to alleviate the cost in computationally taxing processes such as in optimization and design of materials. The intrinsic discontinuous nature of the physical phenomena incurred by the presence of sharp phase boundaries makes the training of the surrogate model cumbersome. We develop a new framework that integrates a convolutional autoencoder architecture with a deep neural operator (DeepONet) to learn the dynamic evolution of a two-phase mixture. We utilize the convolutional autoencoder to provide a compact representation of the microstructure data in a low-dimensional latent space. DeepONet, which consists of two sub-networks, one for encoding the input function at a fixed number of sensors locations (branch net) and another for encoding the locations for the output functions (trunk net), learns the mesoscale dynamics of the microstructure evolution in the latent space. The decoder part of the convolutional autoencoder can then reconstruct the time-evolved microstructure from the DeepONet predictions. The result is an efficient and accurate accelerated phase-field framework that outperforms other neural-network-based approaches while at the same time being robust to noisy inputs. ",
    "url": "https://arxiv.org/abs/2204.07230",
    "authors": [
      "Vivek Oommen",
      "Khemraj Shukla",
      "Somdatta Goswami",
      "Remi Dingreville",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2204.07234",
    "title": "Physics-Aware Recurrent Convolutional (PARC) Neural Networks to  Assimilate Meso-scale Reactive Mechanics of Energetic Materials",
    "abstract": "The thermomechanical properties of energetic materials (EM) are known to be a function of their microscopic structures, i.e., morphological configurations of crystals and pores. This microstructural dependency has motivated vigorous research in the EM community, seeking to engineer material microstructures with targeted properties and performance under the materials-by-design paradigm. However, establishing the complex structure-property-performance (SPP) relationships of EMs demands extensive experimental and simulation efforts, and assimilating and encapsulating these relationships in usable models is a challenge. Here, we present a novel deep learning method, Physics-Aware Recurrent Convolutional (PARC) Neural Network, that can \"learn\" the mesoscale thermo-mechanics of EM microstructures during the shock-to-detonation transition (SDT). We show that this new approach can produce accurate high-fidelity predictions of time-evolving temperature and pressure fields of the same quality as the state-of-the-art direct numerical simulations (DNS), despite the dramatic reduction of computing time, from hours and days on a high-performance computing cluster (HPC) to a little more than a second on a commodity laptop. We also demonstrate that PARC can provide physical insights, i.e., the artificial neurons can illuminate the underlying physics by identifying which microstructural features led to critical hotspots and what are the characteristics of \"critical\" versus \"non-critical\" microstructures. This new knowledge generated alongside the capacity to conduct high-throughput experiments will broaden our theoretical understanding of the initiation mechanisms of EM detonation, as a step towards engineering EMs with specific properties. ",
    "url": "https://arxiv.org/abs/2204.07234",
    "authors": [
      "Phong C.H. Nguyen",
      "Joseph B. Choi",
      "Yen-Thi Nguyen",
      "Pradeep K. Seshadri",
      "H.S. Udaykumar",
      "Stephen Baek"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07253",
    "title": "Early Myocardial Infarction Detection with One-Class Classification over  Multi-view Echocardiography",
    "abstract": "Myocardial infarction (MI) is the leading cause of mortality and morbidity in the world. Early therapeutics of MI can ensure the prevention of further myocardial necrosis. Echocardiography is the fundamental imaging technique that can reveal the earliest sign of MI. However, the scarcity of echocardiographic datasets for the MI detection is the major issue for training data-driven classification algorithms. In this study, we propose a framework for early detection of MI over multi-view echocardiography that leverages one-class classification (OCC) techniques. The OCC techniques are used to train a model for detecting a specific target class using instances from that particular category only. We investigated the usage of uni-modal and multi-modal one-class classification techniques in the proposed framework using the HMC-QU dataset that includes apical 4-chamber (A4C) and apical 2-chamber (A2C) views in a total of 260 echocardiography recordings. Experimental results show that the multi-modal approach achieves a sensitivity level of 85.23% and F1-Score of 80.21%. ",
    "url": "https://arxiv.org/abs/2204.07253",
    "authors": [
      "Aysen Degerli",
      "Fahad Sohrab",
      "Serkan Kiranyaz",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07291",
    "title": "The training response law explains how deep neural networks learn",
    "abstract": "Deep neural network is the widely applied technology in this decade. In spite of the fruitful applications, the mechanism behind that is still to be elucidated. We study the learning process with a very simple supervised learning encoding problem. As a result, we found a simple law, in the training response, which describes neural tangent kernel. The response consists of a power law like decay multiplied by a simple response kernel. We can construct a simple mean-field dynamical model with the law, which explains how the network learns. In the learning, the input space is split into sub-spaces along competition between the kernels. With the iterated splits and the aging, the network gets more complexity, but finally loses its plasticity. ",
    "url": "https://arxiv.org/abs/2204.07291",
    "authors": [
      "Kenichi Nakazato"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07314",
    "title": "Feature Compression for Rate Constrained Object Detection on the Edge",
    "abstract": "Recent advances in computer vision has led to a growth of interest in deploying visual analytics model on mobile devices. However, most mobile devices have limited computing power, which prohibits them from running large scale visual analytics neural networks. An emerging approach to solve this problem is to offload the computation of these neural networks to computing resources at an edge server. Efficient computation offloading requires optimizing the trade-off between multiple objectives including compressed data rate, analytics performance, and computation speed. In this work, we consider a \"split computation\" system to offload a part of the computation of the YOLO object detection model. We propose a learnable feature compression approach to compress the intermediate YOLO features with light-weight computation. We train the feature compression and decompression module together with the YOLO model to optimize the object detection accuracy under a rate constraint. Compared to baseline methods that apply either standard image compression or learned image compression at the mobile and perform image decompression and YOLO at the edge, the proposed system achieves higher detection accuracy at the low to medium rate range. Furthermore, the proposed system requires substantially lower computation time on the mobile device with CPU only. ",
    "url": "https://arxiv.org/abs/2204.07314",
    "authors": [
      "Zhongzheng Yuan",
      "Samyak Rawlekar",
      "Siddharth Garg",
      "Elza Erkip",
      "Yao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.07344",
    "title": "CAiD: Context-Aware Instance Discrimination for Self-supervised Learning  in Medical Imaging",
    "abstract": "Recently, self-supervised instance discrimination methods have achieved significant success in learning visual representations from unlabeled photographic images. However, given the marked differences between photographic and medical images, the efficacy of instance-based objectives, focusing on learning the most discriminative global features in the image (i.e., wheels in bicycle), remains unknown in medical imaging. Our preliminary analysis showed that high global similarity of medical images in terms of anatomy hampers instance discrimination methods for capturing a set of distinct features, negatively impacting their performance on medical downstream tasks. To alleviate this limitation, we have developed a simple yet effective self-supervised framework, called Context-Aware instance Discrimination (CAiD). CAiD aims to improve instance discrimination learning by providing finer and more discriminative information encoded from a diverse local context of unlabeled medical images. We conduct a systematic analysis to investigate the utility of the learned features from a three-pronged perspective: (i) generalizability and transferability, (ii) separability in the embedding space, and (iii) reusability. Our extensive experiments demonstrate that CAiD (1) enriches representations learned from existing instance discrimination methods; (2) delivers more discriminative features by adequately capturing finer contextual information from individual medial images; and (3) improves reusability of low/mid-level features compared to standard instance discriminative methods. As open science, all codes and pre-trained models are available on our GitHub page: https://github.com/JLiangLab/CAiD. ",
    "url": "https://arxiv.org/abs/2204.07344",
    "authors": [
      "Mohammad Reza Hosseinzadeh Taher",
      "Fatemeh Haghighi",
      "Michael B. Gotway",
      "Jianming Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07353",
    "title": "Anomalous Sound Detection Based on Machine Activity Detection",
    "abstract": "We have developed an unsupervised anomalous sound detection method for machine condition monitoring that utilizes an auxiliary task -- detecting when the target machine is active. First, we train a model that detects machine activity by using normal data with machine activity labels and then use the activity-detection error as the anomaly score for a given sound clip if we have access to the ground-truth activity labels in the inference phase. If these labels are not available, the anomaly score is calculated through outlier detection on the embedding vectors obtained by the activity-detection model. Solving this auxiliary task enables the model to learn the difference between the target machine sounds and similar background noise, which makes it possible to identify small deviations in the target sounds. Experimental results showed that the proposed method improves the anomaly-detection performance of the conventional method complementarily by means of an ensemble. ",
    "url": "https://arxiv.org/abs/2204.07353",
    "authors": [
      "Tomoya Nishida",
      "Kota Dohi",
      "Takashi Endo",
      "Masaaki Yamamoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.07360",
    "title": "Spatio-Temporal-Frequency Graph Attention Convolutional Network for  Aircraft Recognition Based on Heterogeneous Radar Network",
    "abstract": "This paper proposes a knowledge-and-data-driven graph neural network-based collaboration learning model for reliable aircraft recognition in a heterogeneous radar network. The aircraft recognizability analysis shows that: (1) the semantic feature of an aircraft is motion patterns driven by the kinetic characteristics, and (2) the grammatical features contained in the radar cross-section (RCS) signals present spatial-temporal-frequency (STF) diversity decided by both the electromagnetic radiation shape and motion pattern of the aircraft. Then a STF graph attention convolutional network (STFGACN) is developed to distill semantic features from the RCS signals received by the heterogeneous radar network. Extensive experiment results verify that the STFGACN outperforms the baseline methods in terms of detection accuracy, and ablation experiments are carried out to further show that the expansion of the information dimension can gain considerable benefits to perform robustly in the low signal-to-noise ratio region. ",
    "url": "https://arxiv.org/abs/2204.07360",
    "authors": [
      "Han Meng",
      "Yuexing Peng",
      "Wenbo Wang",
      "Peng Cheng",
      "Yonghui Li",
      "Wei Xiang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07362",
    "title": "Decoding Neural Correlation of Language-Specific Imagined Speech using  EEG Signals",
    "abstract": "Speech impairments due to cerebral lesions and degenerative disorders can be devastating. For humans with severe speech deficits, imagined speech in the brain-computer interface has been a promising hope for reconstructing the neural signals of speech production. However, studies in the EEG-based imagined speech domain still have some limitations due to high variability in spatial and temporal information and low signal-to-noise ratio. In this paper, we investigated the neural signals for two groups of native speakers with two tasks with different languages, English and Chinese. Our assumption was that English, a non-tonal and phonogram-based language, would have spectral differences in neural computation compared to Chinese, a tonal and ideogram-based language. The results showed the significant difference in the relative power spectral density between English and Chinese in specific frequency band groups. Also, the spatial evaluation of Chinese native speakers in the theta band was distinctive during the imagination task. Hence, this paper would suggest the key spectral and spatial information of word imagination with specialized language while decoding the neural signals of speech. ",
    "url": "https://arxiv.org/abs/2204.07362",
    "authors": [
      "Keon-Woo Lee",
      "Dae-Hyeok Lee",
      "Sung-Jin Kim",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.07497",
    "title": "Helicity-conservative Physics-informed Neural Network Model for  Navier-Stokes Equations",
    "abstract": "We design the helicity-conservative physics-informed neural network model for the Navier-Stokes equation in the ideal case. The key is to provide an appropriate PDE model as loss function so that its neural network solutions produce helicity conservation. Physics-informed neural network model is based on the strong form of PDE. We show that the relevant helicity-conservative finite element method based on the weak formulation of PDE can be somewhat different. More precisely, we compares the PINN formulation and the finite element method based on the weak formulation for conserving helicity and argues that for the conservation, strong PDE is more natural. Our result is justified by theory as well. Furthermore, a couple of numerical calculations are demonstrated to confirm our theoretical finding. ",
    "url": "https://arxiv.org/abs/2204.07497",
    "authors": [
      "Ziqian Li",
      "Jiwei Jia",
      "Young Ju Lee",
      "Zheng Lu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.07532",
    "title": "Accurate ADMET Prediction with XGBoost",
    "abstract": "The absorption, distribution, metabolism, excretion, and toxicity (ADMET) properties are important in drug discovery as they define efficacy and safety. Here, we apply an ensemble of features, including fingerprints and descriptors, and a tree-based machine learning model, extreme gradient boosting, for accurate ADMET prediction. Our model performs well in the Therapeutics Data Commons ADMET benchmark group. For 22 tasks, our model is ranked first in 10 tasks and top 3 in 18 tasks. ",
    "url": "https://arxiv.org/abs/2204.07532",
    "authors": [
      "Hao Tian",
      "Rajas Ketkar",
      "Peng Tao"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:1909.04746",
    "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data",
    "abstract": " Comments: AISTATS 2020. 31 pages, 1 algorithm, 5 theorems, 6 figures ",
    "url": "https://arxiv.org/abs/1909.04746",
    "authors": [
      "Ahmed Khaled",
      "Konstantin Mishchenko",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.05624",
    "title": "Adjoined Networks: A Training Paradigm with Applications to Network  Compression",
    "abstract": " Comments: Published at AAAI 2022 Spring Symposium on Machine Learning and Knowledge Engineering for Hybrid Intelligence Code available at: this https URL ",
    "url": "https://arxiv.org/abs/2006.05624",
    "authors": [
      "Utkarsh Nath",
      "Shrinu Kushagra",
      "Yingzhen Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.09258",
    "title": "Can You Spot the Chameleon? Adversarially Camouflaging Images from  Co-Salient Object Detection",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2009.09258",
    "authors": [
      "Ruijun Gao",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Hongkai Yu",
      "Huazhu Fu",
      "Wei Feng",
      "Yang Liu",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.06200",
    "title": "Efficient neural networks for real-time modeling of analog dynamic range  compression",
    "abstract": " Comments: Updated and will appear at 152nd AES Convention (note title change) ",
    "url": "https://arxiv.org/abs/2102.06200",
    "authors": [
      "Christian J. Steinmetz",
      "Joshua D. Reiss"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2102.10892",
    "title": "Non-Crossing Shortest Paths in Undirected Unweighted Planar Graphs in  Linear Time",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2102.10892",
    "authors": [
      "Lorenzo Balzotti",
      "Paolo G. Franciosa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2104.00969",
    "title": "TubeR: Tubelet Transformer for Video Action Detection",
    "abstract": " Comments: Accepted at CVPR 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2104.00969",
    "authors": [
      "Jiaojiao Zhao",
      "Yanyi Zhang",
      "Xinyu Li",
      "Hao Chen",
      "Shuai Bing",
      "Mingze Xu",
      "Chunhui Liu",
      "Kaustav Kundu",
      "Yuanjun Xiong",
      "Davide Modolo",
      "Ivan Marsic",
      "Cees G.M. Snoek",
      "Joseph Tighe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.00329",
    "title": "Dispatchable Region for Active Distribution Networks Using Approximate  Second-Order Cone Relaxation",
    "abstract": " Title: Dispatchable Region for Active Distribution Networks Using Approximate  Second-Order Cone Relaxation ",
    "url": "https://arxiv.org/abs/2107.00329",
    "authors": [
      "Zhigang Li",
      "Wenjing Huang",
      "J. H. Zheng",
      "Q. H. Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2107.08939",
    "title": "DHNet: Double MPEG-4 Compression Detection via Multiple DCT Histograms",
    "abstract": " Comments: Accepted to IEEE MultiMedia ",
    "url": "https://arxiv.org/abs/2107.08939",
    "authors": [
      "Seung-Hun Nam",
      "Wonhyuk Ahn",
      "Myung-Joon Kwon",
      "Jihyeon Kang",
      "In-Jae Yu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.00909",
    "title": "Sparsifying the Update Step in Graph Neural Networks",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2109.00909",
    "authors": [
      "Johannes F. Lutzeyer",
      "Changmin Wu",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2109.09574",
    "title": "On the representation of non-holonomic univariate power series",
    "abstract": " Comments: 20 pages; 26 references. Update: revised version ",
    "url": "https://arxiv.org/abs/2109.09574",
    "authors": [
      "Bertrand Teguia Tabuguia",
      "Wolfram Koepf"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2109.12171",
    "title": "NICE: Robust Scheduling through Reinforcement Learning-Guided Integer  Programming",
    "abstract": " Comments: Accepted in 36th AAAI Conference. 7 pages + 2 pages appendix, 1 figure. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2109.12171",
    "authors": [
      "Luke Kenworthy",
      "Siddharth Nayak",
      "Christopher Chin",
      "Hamsa Balakrishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.01775",
    "title": "Deep Instance Segmentation with Automotive Radar Detection Points",
    "abstract": " Comments: 11 pages, 9 figures, 3 tables, accepted by IEEE Transactions on Intelligent Vehicles ",
    "url": "https://arxiv.org/abs/2110.01775",
    "authors": [
      "Jianan Liu",
      "Weiyi Xiong",
      "Liping Bai",
      "Yuxuan Xia",
      "Tao Huang",
      "Wanli Ouyang",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.03310",
    "title": "Solving the Dirichlet problem for the Monge-Amp\u00e8re equation using  neural networks",
    "abstract": " Comments: 22 pages, 7 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2110.03310",
    "authors": [
      "Kaj Nystr\u00f6m",
      "Matias Vestberg"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.04331",
    "title": "MusicNet: Compact Convolutional Neural Network for Real-time Background  Music Detection",
    "abstract": " Title: MusicNet: Compact Convolutional Neural Network for Real-time Background  Music Detection ",
    "url": "https://arxiv.org/abs/2110.04331",
    "authors": [
      "Chandan K.A. Reddy",
      "Vishak Gopa",
      "Harishchandra Dubey",
      "Sergiy Matusevych",
      "Ross Cutler",
      "Robert Aichner"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2110.04391",
    "title": "Aura: Privacy-preserving augmentation to improve test set diversity in  noise suppression applications",
    "abstract": " Title: Aura: Privacy-preserving augmentation to improve test set diversity in  noise suppression applications ",
    "url": "https://arxiv.org/abs/2110.04391",
    "authors": [
      "Xavier Gitiaux",
      "Aditya Khant",
      "Ebrahim Beyrami",
      "Chandan Reddy",
      "Jayant Gupchup",
      "Ross Cutler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2111.06483",
    "title": "Sequential Aggregation and Rematerialization: Distributed Full-batch  Training of Graph Neural Networks on Large Graphs",
    "abstract": " Title: Sequential Aggregation and Rematerialization: Distributed Full-batch  Training of Graph Neural Networks on Large Graphs ",
    "url": "https://arxiv.org/abs/2111.06483",
    "authors": [
      "Hesham Mostafa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.10541",
    "title": "Retrieve-then-extract Based Knowledge Graph Querying Using Graph Neural  Networks",
    "abstract": " Title: Retrieve-then-extract Based Knowledge Graph Querying Using Graph Neural  Networks ",
    "url": "https://arxiv.org/abs/2111.10541",
    "authors": [
      "Hanning Gao",
      "Lingfei Wu",
      "Po Hu",
      "Zhihua Wei",
      "Fangli Xu",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.04629",
    "title": "Transferability Properties of Graph Neural Networks",
    "abstract": " Comments: Submitted to IEEE TSP ",
    "url": "https://arxiv.org/abs/2112.04629",
    "authors": [
      "Luana Ruiz",
      "Luiz F. O. Chamon",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2112.06197",
    "title": "Video as Conditional Graph Hierarchy for Multi-Granular Question  Answering",
    "abstract": " Comments: AAAI'22 (Oral) ",
    "url": "https://arxiv.org/abs/2112.06197",
    "authors": [
      "Junbin Xiao",
      "Angela Yao",
      "Zhiyuan Liu",
      "Yicong Li",
      "Wei Ji",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2203.07029",
    "title": "SuperCone: Unified User Segmentation over Heterogeneous Experts via  Concept Meta-learning",
    "abstract": " Title: SuperCone: Unified User Segmentation over Heterogeneous Experts via  Concept Meta-learning ",
    "url": "https://arxiv.org/abs/2203.07029",
    "authors": [
      "Keqian Li",
      "Yifan Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.16110",
    "title": "Weakly-supervised Temporal Path Representation Learning with Contrastive  Curriculum Learning -- Extended Version",
    "abstract": " Comments: This paper has been accepted by IEEE ICDE-22 ",
    "url": "https://arxiv.org/abs/2203.16110",
    "authors": [
      "Sean Bin Yang",
      "Chenjuan Guo",
      "Jilin Hu",
      "Bin Yang",
      "Jian Tang",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.00804",
    "title": "Diffusion dynamics of competing information on networks",
    "abstract": " Comments: 5 pages + supplemental material ",
    "url": "https://arxiv.org/abs/2204.00804",
    "authors": [
      "Teruyoshi Kobayashi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.01671",
    "title": "Exemplar-based Pattern Synthesis with Implicit Periodic Field Network",
    "abstract": " Comments: 8 pages, CVPR 2022 ",
    "url": "https://arxiv.org/abs/2204.01671",
    "authors": [
      "Haiwei Chen",
      "Jiayi Liu",
      "Weikai Chen",
      "Shichen Liu",
      "Yajie Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03281",
    "title": "Single-shot Embedding Dimension Search in Recommender System",
    "abstract": " Title: Single-shot Embedding Dimension Search in Recommender System ",
    "url": "https://arxiv.org/abs/2204.03281",
    "authors": [
      "Liang Qu",
      "Yonghong Ye",
      "Ningzhi Tang",
      "Lixin Zhang",
      "Yuhui Shi",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.03316",
    "title": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "abstract": " Title: Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion ",
    "url": "https://arxiv.org/abs/2204.03316",
    "authors": [
      "HanQin Cai",
      "Jian-Feng Cai",
      "Juntao You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.05255",
    "title": "Narcissus: A Practical Clean-Label Backdoor Attack with Limited  Information",
    "abstract": " Comments: 13 pages of the main text ",
    "url": "https://arxiv.org/abs/2204.05255",
    "authors": [
      "Yi Zeng",
      "Minzhou Pan",
      "Hoang Anh Just",
      "Lingjuan Lyu",
      "Meikang Qiu",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05423",
    "title": "Automated Task Updates of Temporal Logic Specifications for  Heterogeneous Robots",
    "abstract": " Comments: Accepted by IEEE International Conference on Robotics and Automation (ICRA) 2022 ",
    "url": "https://arxiv.org/abs/2204.05423",
    "authors": [
      "Amy Fang",
      "Hadas Kress-Gazit"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.06677",
    "title": "Dynamic Schema Graph Fusion Network for Multi-Domain Dialogue State  Tracking",
    "abstract": " Comments: Accepted by ACL 2022 ",
    "url": "https://arxiv.org/abs/2204.06677",
    "authors": [
      "Yue Feng",
      "Aldo Lipani",
      "Fanghua Ye",
      "Qiang Zhang",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.06718",
    "title": "Learning Convolutional Neural Networks in the Frequency Domain",
    "abstract": " Title: Learning Convolutional Neural Networks in the Frequency Domain ",
    "url": "https://arxiv.org/abs/2204.06718",
    "authors": [
      "Hengyue Pan",
      "Yixin Chen",
      "Xin Niu",
      "Wenbo Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]