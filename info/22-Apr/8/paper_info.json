[
  {
    "id": "arXiv:2204.02970",
    "title": "Evolutionary Programmer: Autonomously Creating Path Planning Programs  based on Evolutionary Algorithms",
    "abstract": "Evolutionary algorithms are wildly used in unmanned aerial vehicle path planning for their flexibility and effectiveness. Nevertheless, they are so sensitive to the change of environment that can't adapt to all scenarios. Due to this drawback, the previously successful planner frequently fail in a new scene. In this paper, a first-of-its-kind machine learning method named Evolutionary Programmer is proposed to solve this problem. Concretely, the most commonly used Evolutionary Algorithms are decomposed into a series of operators, which constitute the operator library of the system. The new method recompose the operators to a integrated planner, thus, the most suitable operators can be selected for adapting to the changing circumstances. Different from normal machine programmers, this method focuses on a specific task with high-level integrated instructions and thus alleviate the problem of huge search space caused by the briefness of instructions. On this basis, a 64-bit sequence is presented to represent path planner and then evolved with the modified Genetic Algorithm. Finally, the most suitable planner is created by utilizing the information of the previous planner and various randomly generated ones. ",
    "url": "https://arxiv.org/abs/2204.02970",
    "authors": [
      "Jiabin Lou",
      "Rong Ding",
      "Wenjun Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03017",
    "title": "Learning from Untrimmed Videos: Self-Supervised Video Representation  Learning with Hierarchical Consistency",
    "abstract": "Natural videos provide rich visual contents for self-supervised learning. Yet most existing approaches for learning spatio-temporal representations rely on manually trimmed videos, leading to limited diversity in visual patterns and limited performance gain. In this work, we aim to learn representations by leveraging more abundant information in untrimmed videos. To this end, we propose to learn a hierarchy of consistencies in videos, i.e., visual consistency and topical consistency, corresponding respectively to clip pairs that tend to be visually similar when separated by a short time span and share similar topics when separated by a long time span. Specifically, a hierarchical consistency learning framework HiCo is presented, where the visually consistent pairs are encouraged to have the same representation through contrastive learning, while the topically consistent pairs are coupled through a topical classifier that distinguishes whether they are topic related. Further, we impose a gradual sampling algorithm for proposed hierarchical consistency learning, and demonstrate its theoretical superiority. Empirically, we show that not only HiCo can generate stronger representations on untrimmed videos, it also improves the representation quality when applied to trimmed videos. This is in contrast to standard contrastive learning that fails to learn appropriate representations from untrimmed videos. ",
    "url": "https://arxiv.org/abs/2204.03017",
    "authors": [
      "Zhiwu Qing",
      "Shiwei Zhang",
      "Ziyuan Huang",
      "Yi Xu",
      "Xiang Wang",
      "Mingqian Tang",
      "Changxin Gao",
      "Rong Jin",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03027",
    "title": "Federated Learning for Distributed Spectrum Sensing in NextG  Communication Networks",
    "abstract": "NextG networks are intended to provide the flexibility of sharing the spectrum with incumbent users and support various spectrum monitoring tasks such as anomaly detection, fault diagnostics, user equipment identification, and authentication. A network of wireless sensors is needed to monitor the spectrum for signal transmissions of interest over a large deployment area. Each sensor receives signals under a specific channel condition depending on its location and trains an individual model of a deep neural network (DNN) accordingly to classify signals. To improve the accuracy, individual sensors may exchange sensing data or sensor results with each other or with a fusion center (such as in cooperative spectrum sensing). In this paper, distributed federated learning over a multi-hop wireless network is considered to collectively train a DNN for signal identification. In distributed federated learning, each sensor broadcasts its trained model to its neighbors, collects the DNN models from its neighbors, and aggregates them to initialize its own model for the next round of training. Without exchanging any spectrum data, this process is repeated over time such that a common DNN is built across the network while preserving the privacy associated with signals collected at different locations. Signal classification accuracy and convergence time are evaluated for different network topologies (including line, star, ring, grid, and random networks) and packet loss events. Then, the reduction of communication overhead and energy consumption is considered with random participation of sensors in model updates. The results show the feasibility of extending cooperative spectrum sensing over a general multi-hop wireless network through federated learning and indicate its robustness to wireless network effects, thereby sustaining high accuracy with low communication overhead and energy consumption. ",
    "url": "https://arxiv.org/abs/2204.03027",
    "authors": [
      "Yi Shi",
      "Yalin E. Sagduyu",
      "Tugba Erpek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03040",
    "title": "SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural  Text-to-Speech Synthesis",
    "abstract": "In this work, we present the SOMOS dataset, the first large-scale mean opinion scores (MOS) dataset consisting of solely neural text-to-speech (TTS) samples. It can be employed to train automatic MOS prediction systems focused on the assessment of modern synthesizers, and can stimulate advancements in acoustic model evaluation. It consists of 20K synthetic utterances of the LJ Speech voice, a public domain speech dataset which is a common benchmark for building neural acoustic models and vocoders. Utterances are generated from 200 TTS systems including vanilla neural acoustic models as well as models which allow prosodic variations. An LPCNet vocoder is used for all systems, so that the samples' variation depends only on the acoustic models. The synthesized utterances provide balanced and adequate domain and length coverage. We collect MOS naturalness evaluations on 3 English Amazon Mechanical Turk locales and share practices leading to reliable crowdsourced annotations for this task. Baseline results of state-of-the-art MOS prediction models on the SOMOS dataset are presented, while we show the challenges that such models face when assigned to evaluate synthetic utterances. ",
    "url": "https://arxiv.org/abs/2204.03040",
    "authors": [
      "Georgia Maniati",
      "Alexandra Vioni",
      "Nikolaos Ellinas",
      "Karolos Nikitaras",
      "Konstantinos Klapsas",
      "June Sig Sung",
      "Gunu Jho",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.03059",
    "title": "Semantic Sensor Network Ontology based Decision Support System for  Forest Fire Management",
    "abstract": "The forests are significant assets for every country. When it gets destroyed, it may negatively impact the environment, and forest fire is one of the primary causes. Fire weather indices are widely used to measure fire danger and are used to issue bushfire warnings. It can also be used to predict the demand for emergency management resources. Sensor networks have grown in popularity in data collection and processing capabilities for a variety of applications in industries such as medical, environmental monitoring, home automation etc. Semantic sensor networks can collect various climatic circumstances like wind speed, temperature, and relative humidity. However, estimating fire weather indices is challenging due to the various issues involved in processing the data streams generated by the sensors. Hence, the importance of forest fire detection has increased day by day. The underlying Semantic Sensor Network (SSN) ontologies are built to allow developers to create rules for calculating fire weather indices and also the convert dataset into Resource Description Framework (RDF). This research describes the various steps involved in developing rules for calculating fire weather indices. Besides, this work presents a Web-based mapping interface to help users visualize the changes in fire weather indices over time. With the help of the inference rule, it designed a decision support system using the SSN ontology and query on it through SPARQL. The proposed fire management system acts according to the situation, supports reasoning and the general semantics of the open-world followed by all the ontologies ",
    "url": "https://arxiv.org/abs/2204.03059",
    "authors": [
      "Ritesh Chandra",
      "Sonali Agarwal",
      "Navjot Singh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2204.03062",
    "title": "Abusive and Threatening Language Detection in Urdu using Supervised  Machine Learning and Feature Combinations",
    "abstract": "This paper presents the system descriptions submitted at the FIRE Shared Task 2021 on Urdu's Abusive and Threatening Language Detection Task. This challenge aims at automatically identifying abusive and threatening tweets written in Urdu. Our submitted results were selected for the third recognition at the competition. This paper reports a non-exhaustive list of experiments that allowed us to reach the submitted results. Moreover, after the result declaration of the competition, we managed to attain even better results than the submitted results. Our models achieved 0.8318 F1 score on Task A (Abusive Language Detection for Urdu Tweets) and 0.4931 F1 score on Task B (Threatening Language Detection for Urdu Tweets). Results show that Support Vector Machines with stopwords removed, lemmatization applied, and features vector created by the combinations of word n-grams for n=1,2,3 produced the best results for Task A. For Task B, Support Vector Machines with stopwords removed, lemmatization not applied, feature vector created from a pre-trained Urdu Word2Vec (on word unigrams and bigrams), and making the dataset balanced using oversampling technique produced the best results. The code is made available for reproducibility. ",
    "url": "https://arxiv.org/abs/2204.03062",
    "authors": [
      "Muhammad Humayoun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.03064",
    "title": "The 2021 Urdu Fake News Detection Task using Supervised Machine Learning  and Feature Combinations",
    "abstract": "This paper presents the system description submitted at the FIRE Shared Task: \"The 2021 Fake News Detection in the Urdu Language\". This challenge aims at automatically identifying Fake news written in Urdu. Our submitted results ranked fifth in the competition. However, after the result declaration of the competition, we managed to attain even better results than the submitted results. The best F1 Macro score achieved by one of our models is 0.6674, higher than the second-best score in the competition. The result is achieved on Support Vector Machines (polynomial kernel degree 1) with stopwords removed, lemmatization applied, and selecting the 20K best features out of 1.557 million features in total (which were produced by Word n-grams n=1,2,3,4 and Char n-grams n=2,3,4,5,6). The code is made available for reproducibility. ",
    "url": "https://arxiv.org/abs/2204.03064",
    "authors": [
      "Muhammad Humayoun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.03080",
    "title": "Graph Neural Networks Designed for Different Graph Types: A Survey",
    "abstract": "Graphs are ubiquitous in nature and can therefore serve as models for many practical but also theoretical problems. Based on this, the young research field of Graph Neural Networks (GNNs) has emerged. Despite the youth of the field and the speed in which new models are developed, many good surveys have been published in the last years. Nevertheless, an overview on which graph types can be modeled by GNNs is missing. In this survey, we give a detailed overview of already existing GNNs and, unlike previous surveys, categorize them according to their ability to handle different graph types. We consider GNNs operating on static as well as on dynamic graphs of different structural constitutions, with or without node or edge attributes. Moreover in the dynamic case, we separate the models in discrete-time and continuous-time dynamic graphs based on their architecture. According to our findings, there are still graph types, that are not covered by existing GNN models. Specifically, models concerning heterogeneity in attributes are missing and the deletion of nodes and edges is only covered rarely. ",
    "url": "https://arxiv.org/abs/2204.03080",
    "authors": [
      "Josephine M. Thomas",
      "Alice Moallemy-Oureh",
      "Silvia Beddar-Wiesing",
      "Clara Holzh\u00fcter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03083",
    "title": "Audio-Visual Person-of-Interest DeepFake Detection",
    "abstract": "Face manipulation technology is advancing very rapidly, and new methods are being proposed day by day. The aim of this work is to propose a deepfake detector that can cope with the wide variety of manipulation methods and scenarios encountered in the real world. Our key insight is that each person has specific biometric characteristics that a synthetic generator cannot likely reproduce. Accordingly, we extract high-level audio-visual biometric features which characterize the identity of a person, and use them to create a person-of-interest (POI) deepfake detector. We leverage a contrastive learning paradigm to learn the moving-face and audio segments embeddings that are most discriminative for each identity. As a result, when the video and/or audio of a person is manipulated, its representation in the embedding space becomes inconsistent with the real identity, allowing reliable detection. Training is carried out exclusively on real talking-face videos, thus the detector does not depend on any specific manipulation method and yields the highest generalization ability. In addition, our method can detect both single-modality (audio-only, video-only) and multi-modality (audio-video) attacks, and is robust to low-quality or corrupted videos by building only on high-level semantic features. Experiments on a wide variety of datasets confirm that our method ensures a SOTA performance, with an average improvement in terms of AUC of around 3%, 10%, and 7% for high-quality, low quality and attacked videos, respectively. ",
    "url": "https://arxiv.org/abs/2204.03083",
    "authors": [
      "Davide Cozzolino",
      "Matthias Nie\u00dfner",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.03098",
    "title": "Closed Ranks: The Discursive Value of Military Support for Indian  Politicians on Social Media",
    "abstract": "Influencers play a crucial role in shaping public narratives through information creation and diffusion in the Global South. While public figures from various walks of life and their impact on public discourse have been studied, defence veterans as influencers of the political discourse have been largely overlooked. Veterans matter in the public spehere as a normatively important political lobby. They are also interesting because, unlike active-duty military officers, they are not restricted from taking public sides on politics, so their posts may provide a window into the views of those still in the service. In this work, we systematically analyze the engagement on Twitter of self-described defence-related accounts and politician accounts that post on defence-related issues. We find that self-described defence-related accounts disproportionately engage with the current ruling party in India. We find that politicians promote their closeness to the defence services and nationalist credentials through engagements with defence-related influencers. We briefly consider the institutional implications of these patterns and connections ",
    "url": "https://arxiv.org/abs/2204.03098",
    "authors": [
      "Soham De",
      "Agrima Seth",
      "Arshia Arya",
      "Steven Wilkinson",
      "Sushant Singh",
      "Joyojeet Singh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.03101",
    "title": "Hierarchical Self-supervised Representation Learning for Movie  Understanding",
    "abstract": "Most self-supervised video representation learning approaches focus on action recognition. In contrast, in this paper we focus on self-supervised video learning for movie understanding and propose a novel hierarchical self-supervised pretraining strategy that separately pretrains each level of our hierarchical movie understanding model (based on [37]). Specifically, we propose to pretrain the low-level video backbone using a contrastive learning objective, while pretrain the higher-level video contextualizer using an event mask prediction task, which enables the usage of different data sources for pretraining different levels of the hierarchy. We first show that our self-supervised pretraining strategies are effective and lead to improved performance on all tasks and metrics on VidSitu benchmark [37] (e.g., improving on semantic role prediction from 47% to 61% CIDEr scores). We further demonstrate the effectiveness of our contextualized event features on LVU tasks [54], both when used alone and when combined with instance features, showing their complementarity. ",
    "url": "https://arxiv.org/abs/2204.03101",
    "authors": [
      "Fanyi Xiao",
      "Kaustav Kundu",
      "Joseph Tighe",
      "Davide Modolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03117",
    "title": "BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based  Sentiment Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that aims to align aspects and corresponding sentiments for aspect-specific sentiment polarity inference. It is challenging because a sentence may contain multiple aspects or complicated (e.g., conditional, coordinating, or adversative) relations. Recently, exploiting dependency syntax information with graph neural networks has been the most popular trend. Despite its success, methods that heavily rely on the dependency tree pose challenges in accurately modeling the alignment of the aspects and their words indicative of sentiment, since the dependency tree may provide noisy signals of unrelated associations (e.g., the \"conj\" relation between \"great\" and \"dreadful\" in Figure 2). In this paper, to alleviate this problem, we propose a Bi-Syntax aware Graph Attention Network (BiSyn-GAT+). Specifically, BiSyn-GAT+ fully exploits the syntax information (e.g., phrase segmentation and hierarchical structure) of the constituent tree of a sentence to model the sentiment-aware context of every single aspect (called intra-context) and the sentiment relations across aspects (called inter-context) for learning. Experiments on four benchmark datasets demonstrate that BiSyn-GAT+ outperforms the state-of-the-art methods consistently. ",
    "url": "https://arxiv.org/abs/2204.03117",
    "authors": [
      "Shuo Liang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Fei Wang",
      "Zhiyong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03125",
    "title": "Deep transfer learning for system identification using long short-term  memory neural networks",
    "abstract": "Recurrent neural networks (RNNs) have many advantages over more traditional system identification techniques. They may be applied to linear and nonlinear systems, and they require fewer modeling assumptions. However, these neural network models may also need larger amounts of data to learn and generalize. Furthermore, neural networks training is a time-consuming process. Hence, building upon long-short term memory neural networks (LSTM), this paper proposes using two types of deep transfer learning, namely parameter fine-tuning and freezing, to reduce the data and computation requirements for system identification. We apply these techniques to identify two dynamical systems, namely a second-order linear system and a Wiener-Hammerstein nonlinear system. Results show that compared with direct learning, our method accelerates learning by 10% to 50%, which also saves data and computing resources. ",
    "url": "https://arxiv.org/abs/2204.03125",
    "authors": [
      "Kaicheng Niu",
      "Mi Zhou",
      "Chaouki T. Abdallah",
      "Mohammad Hayajneh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03141",
    "title": "Adversarial Machine Learning Attacks Against Video Anomaly Detection  Systems",
    "abstract": "Anomaly detection in videos is an important computer vision problem with various applications including automated video surveillance. Although adversarial attacks on image understanding models have been heavily investigated, there is not much work on adversarial machine learning targeting video understanding models and no previous work which focuses on video anomaly detection. To this end, we investigate an adversarial machine learning attack against video anomaly detection systems, that can be implemented via an easy-to-perform cyber-attack. Since surveillance cameras are usually connected to the server running the anomaly detection model through a wireless network, they are prone to cyber-attacks targeting the wireless connection. We demonstrate how Wi-Fi deauthentication attack, a notoriously easy-to-perform and effective denial-of-service (DoS) attack, can be utilized to generate adversarial data for video anomaly detection systems. Specifically, we apply several effects caused by the Wi-Fi deauthentication attack on video quality (e.g., slow down, freeze, fast forward, low resolution) to the popular benchmark datasets for video anomaly detection. Our experiments with several state-of-the-art anomaly detection models show that the attackers can significantly undermine the reliability of video anomaly detection systems by causing frequent false alarms and hiding physical anomalies from the surveillance system. ",
    "url": "https://arxiv.org/abs/2204.03141",
    "authors": [
      "Furkan Mumcu",
      "Keval Doshi",
      "Yasin Yilmaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03154",
    "title": "Optimization Models and Interpretations for Three Types of Adversarial  Perturbations against Support Vector Machines",
    "abstract": "Adversarial perturbations have drawn great attentions in various deep neural networks. Most of them are computed by iterations and cannot be interpreted very well. In contrast, little attentions are paid to basic machine learning models such as support vector machines. In this paper, we investigate the optimization models and the interpretations for three types of adversarial perturbations against support vector machines, including sample-adversarial perturbations (sAP), class-universal adversarial perturbations (cuAP) as well as universal adversarial perturbations (uAP). For linear binary/multi classification support vector machines (SVMs), we derive the explicit solutions for sAP, cuAP and uAP (binary case), and approximate solution for uAP of multi-classification. We also obtain the upper bound of fooling rate for uAP. Such results not only increase the interpretability of the three adversarial perturbations, but also provide great convenience in computation since iterative process can be avoided. Numerical results show that our method is fast and effective in calculating three types of adversarial perturbations. ",
    "url": "https://arxiv.org/abs/2204.03154",
    "authors": [
      "Wen Su",
      "Qingna Li",
      "Chunfeng Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.03173",
    "title": "Enhancement on Model Interpretability and Sleep Stage Scoring  Performance with A Novel Pipeline Based on Deep Neural Network",
    "abstract": "Considering the natural frequency characteristics in sleep medicine, this paper first proposes a time-frequency framework for the representation learning of the electroencephalogram (EEG) following the definition of the American Academy of Sleep Medicine. To meet the temporal-random and transient nature of the defining characteristics of sleep stages, we further design a context-sensitive flexible pipeline that automatically adapts to the attributes of data itself. That is, the input EEG spectrogram is partitioned into a sequence of patches in the time and frequency axes, and then input to a delicate deep learning network for further representation learning to extract the stage-dependent features, which are used in the classification step finally. The proposed pipeline is validated against a large database, i.e., the Sleep Heart Health Study (SHHS), and the results demonstrate that the competitive performance for the wake, N2, and N3 stages outperforms the state-of-art works, with the F1 scores being 0.93, 0.88, and 0.87, respectively, and the proposed method has a high inter-rater reliability of 0.80 kappa. Importantly, we visualize the stage scoring process of the model decision with the Layer-wise Relevance Propagation (LRP) method, which shows that the proposed pipeline is more sensitive and perceivable in the decision-making process than the baseline pipelines. Therefore, the pipeline together with the LRP method can provide better model interpretability, which is important for clinical support. ",
    "url": "https://arxiv.org/abs/2204.03173",
    "authors": [
      "Zheng Chen",
      "Ziwei Yang",
      "Ming Huang",
      "Toshiyo Tamura",
      "Naoaki Ono",
      "MD Altaf-Ul-Amin",
      "Shigehiko Kanaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.03178",
    "title": "3M: Multi-loss, Multi-path and Multi-level Neural Networks for speech  recognition",
    "abstract": "Recently, Conformer based CTC/AED model has become a mainstream architecture for ASR. In this paper, based on our prior work, we identify and integrate several approaches to achieve further improvements for ASR tasks, which we denote as multi-loss, multi-path and multi-level, summarized as \"3M\" model. Specifically, multi-loss refers to the joint CTC/AED loss and multi-path denotes the Mixture-of-Experts(MoE) architecture which can effectively increase the model capacity without remarkably increasing computation cost. Multi-level means that we introduce auxiliary loss at multiple level of a deep model to help training. We evaluate our proposed method on the public WenetSpeech dataset and experimental results show that the proposed method provides 12.2%-17.6% relative CER improvement over the baseline model trained by Wenet toolkit. On our large scale dataset of 150k hours corpus, the 3M model has also shown obvious superiority over the baseline Conformer model. ",
    "url": "https://arxiv.org/abs/2204.03178",
    "authors": [
      "Zhao You",
      "Shulin Feng",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.03191",
    "title": "Efficient Community Detection in Large-Scale Dynamic Networks Using  Topological Data Analysis",
    "abstract": "In this paper, we propose a method that extends the persistence-based topological data analysis (TDA) that is typically used for characterizing shapes to general networks. We introduce the concept of the community tree, a tree structure established based on clique communities from the clique percolation method, to summarize the topological structures in a network from a persistence perspective. Furthermore, we develop efficient algorithms to construct and update community trees by maintaining a series of clique graphs in the form of spanning forests, in which each spanning tree is built on an underlying Euler Tour tree. With the information revealed by community trees and the corresponding persistence diagrams, our proposed approach is able to detect clique communities and keep track of the major structural changes during their evolution given a stability threshold. The results demonstrate its effectiveness in extracting useful structural insights for time-varying social networks. ",
    "url": "https://arxiv.org/abs/2204.03191",
    "authors": [
      "Wei Guo",
      "Ruqian Chen",
      "Yen-Chi Chen",
      "Ashis G. Banerjee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.03196",
    "title": "A Framework for Following Temporal Logic Instructions with Unknown  Causal Dependencies",
    "abstract": "Teaching a deep reinforcement learning (RL) agent to follow instructions in multi-task environments is a challenging problem. We consider that user defines every task by a linear temporal logic (LTL) formula. However, some causal dependencies in complex environments may be unknown to the user in advance. Hence, when human user is specifying instructions, the robot cannot solve the tasks by simply following the given instructions. In this work, we propose a hierarchical reinforcement learning (HRL) framework in which a symbolic transition model is learned to efficiently produce high-level plans that can guide the agent efficiently solve different tasks. Specifically, the symbolic transition model is learned by inductive logic programming (ILP) to capture logic rules of state transitions. By planning over the product of the symbolic transition model and the automaton derived from the LTL formula, the agent can resolve causal dependencies and break a causally complex problem down into a sequence of simpler low-level sub-tasks. We evaluate the proposed framework on three environments in both discrete and continuous domains, showing advantages over previous representative methods. ",
    "url": "https://arxiv.org/abs/2204.03196",
    "authors": [
      "Duo Xu",
      "Faramarz Fekri"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.03208",
    "title": "A Joint Learning Approach for Semi-supervised Neural Topic Modeling",
    "abstract": "Topic models are some of the most popular ways to represent textual data in an interpret-able manner. Recently, advances in deep generative models, specifically auto-encoding variational Bayes (AEVB), have led to the introduction of unsupervised neural topic models, which leverage deep generative models as opposed to traditional statistics-based topic models. We extend upon these neural topic models by introducing the Label-Indexed Neural Topic Model (LI-NTM), which is, to the extent of our knowledge, the first effective upstream semi-supervised neural topic model. We find that LI-NTM outperforms existing neural topic models in document reconstruction benchmarks, with the most notable results in low labeled data regimes and for data-sets with informative labels; furthermore, our jointly learned classifier outperforms baseline classifiers in ablation studies. ",
    "url": "https://arxiv.org/abs/2204.03208",
    "authors": [
      "Jeffrey Chiu",
      "Rajat Mittal",
      "Neehal Tumma",
      "Abhishek Sharma",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.03214",
    "title": "Transformer-Based Language Models for Software Vulnerability Detection:  Performance, Model's Security and Platforms",
    "abstract": "The large transformer-based language models demonstrate excellent performance in natural language processing. By considering the closeness of natural languages to the high-level programming language such as C/C++, this work studies how good are the large transformer-based language models detecting software vulnerabilities. Our results demonstrate the well performance of these models on software vulnerability detection. The answer enables extending transformer-based language models to vulnerability detection and leveraging superior performance beyond the natural language processing domain. Besides, we perform the model's security check using Microsoft's Counterfit, a command-line tool to assess the model's security. Our results find that these models are vulnerable to adversarial examples. In this regard, we present a simple countermeasure and its result. Experimenting with large models is always a challenge due to the requirement of computing resources and platforms/libraries & dependencies. Based on the experiences and difficulties we faced during this work, we present our recommendation while choosing the platforms to run these large models. Moreover, the popular platforms are surveyed thoroughly in this paper. ",
    "url": "https://arxiv.org/abs/2204.03214",
    "authors": [
      "Chandra Thapa",
      "Seung Ick Jang",
      "Muhammad Ejaz Ahmed",
      "Seyit Camtepe",
      "Josef Pieprzyk",
      "Surya Nepal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03216",
    "title": "Neural Implicit Flow: a mesh-agnostic dimensionality reduction paradigm  of spatio-temporal data",
    "abstract": "High-dimensional spatio-temporal dynamics can often be encoded in a low-dimensional subspace. Engineering applications for modeling, characterization, design, and control of such large-scale systems often rely on dimensionality reduction to make solutions computationally tractable in real-time. Common existing paradigms for dimensionality reduction include linear methods, such as the singular value decomposition (SVD), and nonlinear methods, such as variants of convolutional autoencoders (CAE). However, these encoding techniques lack the ability to efficiently represent the complexity associated with spatio-temporal data, which often requires variable geometry, non-uniform grid resolution, adaptive meshing, and/or parametric dependencies.To resolve these practical engineering challenges, we propose a general framework called Neural Implicit Flow (NIF) that enables a mesh-agnostic, low-rank representation of large-scale, parametric, spatial-temporal data. NIF consists of two modified multilayer perceptrons (MLPs): (i) ShapeNet, which isolates and represents the spatial complexity, and (ii) ParameterNet, which accounts for any other input complexity, including parametric dependencies, time, and sensor measurements. We demonstrate the utility of NIF for parametric surrogate modeling, enabling the interpretable representation and compression of complex spatio-temporal dynamics, efficient many-spatial-query tasks, and improved generalization performance for sparse reconstruction. ",
    "url": "https://arxiv.org/abs/2204.03216",
    "authors": [
      "Shaowu Pan",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2204.03217",
    "title": "Resiliency of Nonlinear Control Systems to Stealthy Sensor Attacks",
    "abstract": "In this work, we focus on analyzing vulnerability of nonlinear dynamical control systems to stealthy sensor attacks. We start by defining the notion of stealthy attacks in the most general form by leveraging Neyman-Pearson lemma; specifically, an attack is considered to be stealthy if it is stealthy from (i.e., undetected by) any intrusion detector -- i.e., the probability of the detection is not better than a random guess. We then provide a sufficient condition under which a nonlinear control system is vulnerable to stealthy attacks, in terms of moving the system to an unsafe region due to the attacks. In particular, we show that if the closed-loop system is incrementally exponentially stable while the open-loop plant is incrementally unstable, then the system is vulnerable to stealthy yet impactful attacks on sensors. Finally, we illustrate our results on a case study. ",
    "url": "https://arxiv.org/abs/2204.03217",
    "authors": [
      "Amir Khazraei",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.03225",
    "title": "Explicit Feature Interaction-aware Graph Neural Networks",
    "abstract": "Graph neural networks are powerful methods to handle graph-structured data. However, existing graph neural networks only learn higher-order feature interactions implicitly. Thus, they cannot capture information that occurred in low-order feature interactions. To overcome this problem, we propose Explicit Feature Interaction-aware Graph Neural Network (EFI-GNN), which explicitly learns arbitrary-order feature interactions. EFI-GNN can jointly learn with any other graph neural network. We demonstrate that the joint learning method always enhances performance on the various node classification tasks. Furthermore, since EFI-GNN is inherently a linear model, we can interpret the prediction result of EFI-GNN. With the computation rule, we can obtain an any-order feature's effect on the decision. By that, we visualize the effects of the first-order and second-order features as a form of a heatmap. ",
    "url": "https://arxiv.org/abs/2204.03225",
    "authors": [
      "Minkyu Kim",
      "Hyun-Soo Choi",
      "Jinho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03243",
    "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal  Generators",
    "abstract": "We present a new framework AMOS that pretrains text encoders with an Adversarial learning curriculum via a Mixture Of Signals from multiple auxiliary generators. Following ELECTRA-style pretraining, the main encoder is trained as a discriminator to detect replaced tokens generated by auxiliary masked language models (MLMs). Different from ELECTRA which trains one MLM as the generator, we jointly train multiple MLMs of different sizes to provide training signals at various levels of difficulty. To push the discriminator to learn better with challenging replaced tokens, we learn mixture weights over the auxiliary MLMs' outputs to maximize the discriminator loss by backpropagating the gradient from the discriminator via Gumbel-Softmax. For better pretraining efficiency, we propose a way to assemble multiple MLMs into one unified auxiliary model. AMOS outperforms ELECTRA and recent state-of-the-art pretrained models by about 1 point on the GLUE benchmark for BERT base-sized models. ",
    "url": "https://arxiv.org/abs/2204.03243",
    "authors": [
      "Yu Meng",
      "Chenyan Xiong",
      "Payal Bajaj",
      "Saurabh Tiwary",
      "Paul Bennett",
      "Jiawei Han",
      "Xia Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03262",
    "title": "Korean Online Hate Speech Dataset for Multilabel Classification: How Can  Social Science Aid Developing Better Hate Speech Dataset?",
    "abstract": "We suggest a multilabel Korean online hate speech dataset that covers seven categories of hate speech: (1) Race and Nationality, (2) Religion, (3) Regionalism, (4) Ageism, (5) Misogyny, (6) Sexual Minorities, and (7) Male. Our 35K dataset consists of 24K online comments with Krippendorff's Alpha label accordance of .713, 2.2K neutral sentences from Wikipedia, 1.7K additionally labeled sentences generated by the Human-in-the-Loop procedure and rule-generated 7.1K neutral sentences. The base model with 24K initial dataset achieved the accuracy of LRAP .892, but improved to .919 after being combined with 11K additional data. Unlike the conventional binary hate and non-hate dichotomy approach, we designed a dataset considering both the cultural and linguistic context to overcome the limitations of western culture-based English texts. Thus, this paper is not only limited to presenting a local hate speech dataset but extends as a manual for building a more generalized hate speech dataset with diverse cultural backgrounds based on social science perspectives. ",
    "url": "https://arxiv.org/abs/2204.03262",
    "authors": [
      "TaeYoung Kang",
      "Eunrang Kwon",
      "Junbum Lee",
      "Youngeun Nam",
      "Junmo Song",
      "JeongKyu Suh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2204.03272",
    "title": "mulEEG: A Multi-View Representation Learning on EEG Signals",
    "abstract": "Modeling effective representations using multiple views that positively influence each other is challenging, and the existing methods perform poorly on Electroencephalogram (EEG) signals for sleep-staging tasks. In this paper, we propose a novel multi-view self-supervised method (mulEEG) for unsupervised EEG representation learning. Our method attempts to effectively utilize the complementary information available in multiple views to learn better representations. We introduce diverse loss that further encourages complementary information across multiple views. Our method with no access to labels beats the supervised training while outperforming multi-view baseline methods on transfer learning experiments carried out on sleep-staging tasks. We posit that our method was able to learn better representations by using complementary multi-views. ",
    "url": "https://arxiv.org/abs/2204.03272",
    "authors": [
      "Vamsi Kumar",
      "Likith Reddy",
      "Shivam Kumar Sharma",
      "Kamalakar Dadi",
      "Chiranjeevi Yarra",
      "Bapi S. Raju",
      "Srijithesh Rajendran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.03281",
    "title": "Single-shot Embedding Dimension Search in Recommender System",
    "abstract": "As a crucial component of most modern deep recommender systems, feature embedding maps high-dimensional sparse user/item features into low-dimensional dense embeddings. However, these embeddings are usually assigned a unified dimension, which suffers from the following issues: (1) high memory usage and computation cost. (2) sub-optimal performance due to inferior dimension assignments. In order to alleviate the above issues, some works focus on automated embedding dimension search by formulating it as hyper-parameter optimization or embedding pruning problems. However, they either require well-designed search space for hyperparameters or need time-consuming optimization procedures. In this paper, we propose a Single-Shot Embedding Dimension Search method, called SSEDS, which can efficiently assign dimensions for each feature field via a single-shot embedding pruning operation while maintaining the recommendation accuracy of the model. Specifically, it introduces a criterion for identifying the importance of each embedding dimension for each feature field. As a result, SSEDS could automatically obtain mixed-dimensional embeddings by explicitly reducing redundant embedding dimensions based on the corresponding dimension importance ranking and the predefined parameter budget. Furthermore, the proposed SSEDS is model-agnostic, meaning that it could be integrated into different base recommendation models. The extensive offline experiments are conducted on two widely used public datasets for CTR prediction tasks, and the results demonstrate that SSEDS can still achieve strong recommendation performance even if it has reduced 90\\% parameters. Moreover, SSEDS has also been deployed on the WeChat Subscription platform for practical recommendation services. The 7-day online A/B test results show that SSEDS can significantly improve the performance of the online recommendation model. ",
    "url": "https://arxiv.org/abs/2204.03281",
    "authors": [
      "Liang Qu",
      "Yonghong Ye",
      "Ningzhi Tang",
      "Lixin Zhang",
      "Yuhui Shi",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.03286",
    "title": "Entailment Graph Learning with Textual Entailment and Soft Transitivity",
    "abstract": "Typed entailment graphs try to learn the entailment relations between predicates from text and model them as edges between predicate nodes. The construction of entailment graphs usually suffers from severe sparsity and unreliability of distributional similarity. We propose a two-stage method, Entailment Graph with Textual Entailment and Transitivity (EGT2). EGT2 learns local entailment relations by recognizing possible textual entailment between template sentences formed by typed CCG-parsed predicates. Based on the generated local graph, EGT2 then uses three novel soft transitivity constraints to consider the logical transitivity in entailment structures. Experiments on benchmark datasets show that EGT2 can well model the transitivity in entailment graph to alleviate the sparsity issue, and lead to significant improvement over current state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.03286",
    "authors": [
      "Zhibin Chen",
      "Yansong Feng",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.03293",
    "title": "Enhancing Semantic Code Search with Multimodal Contrastive Learning and  Soft Data Augmentation",
    "abstract": "Code search aims to retrieve the most semantically relevant code snippet for a given natural language query. Recently, large-scale code pre-trained models such as CodeBERT and GraphCodeBERT learn generic representations of source code and have achieved substantial improvement on code search task. However, the high-quality sequence-level representations of code snippets have not been sufficiently explored. In this paper, we propose a new approach with multimodal contrastive learning and soft data augmentation for code search. Multimodal contrastive learning is used to pull together the representations of code-query pairs and push apart the unpaired code snippets and queries. Moreover, data augmentation is critical in contrastive learning for learning high-quality representations. However, only semantic-preserving augmentations for source code are considered in existing work. In this work, we propose to do soft data augmentation by dynamically masking and replacing some tokens in code sequences to generate code snippets that are similar but not necessarily semantic-preserving as positive samples for paired queries. We conduct extensive experiments to evaluate the effectiveness of our approach on a large-scale dataset with six programming languages. The experimental results show that our approach significantly outperforms the state-of-the-art methods. We also adapt our techniques to several pre-trained models such as RoBERTa and CodeBERT, and significantly boost their performance on the code search task. ",
    "url": "https://arxiv.org/abs/2204.03293",
    "authors": [
      "Ensheng Shi",
      "Wenchao Gub",
      "Yanlin Wang",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03297",
    "title": "A Multi-Transformation Evolutionary Framework for Influence Maximization  in Social Networks",
    "abstract": "Influence maximization is a key issue for mining the deep information of social networks, which aims to select a seed set from the network to maximize the number of influenced nodes. To evaluate the influence spread of a seed set efficiently, existing works have proposed some proxy models (transformations) with lower computational costs to replace the expensive Monte Carlo simulation process. These alternate transformations based on network prior knowledge induce different search behaviors with similar characteristics from various perspectives. For a specific case, it is difficult for users to determine a suitable transformation a priori. Keeping those in mind, we propose a multi-transformation evolutionary framework for influence maximization (MTEFIM) to exploit the potential similarities and unique advantages of alternate transformations and avoid users to determine the most suitable one manually. In MTEFIM, multiple transformations are optimized simultaneously as multiple tasks. Each transformation is assigned an evolutionary solver. Three major components of MTEFIM are conducted: 1) estimating the potential relationship across transformations based on the degree of overlap across individuals (seed sets) of different populations, 2) transferring individuals across populations adaptively according to the inter-transformation relationship, 3) selecting the final output seed set containing all the proxy model knowledge. The effectiveness of MTEFIM is validated on four real-world social networks. Experimental results show that MTEFIM can efficiently utilize the potentially transferable knowledge across multiple transformations to achieve highly competitive performance compared to several popular IM-specific methods. The implementation of MTEFIM can be accessed at https://github.com/xiaofangxd/MTEFIM. ",
    "url": "https://arxiv.org/abs/2204.03297",
    "authors": [
      "Chao Wang",
      "Jiaxuan Zhao",
      "Lingling Li",
      "Licheng Jiao",
      "Jing Liu",
      "Kai Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.03299",
    "title": "On the Impact of Social Media Recommendations on Opinion Consensus",
    "abstract": "We consider a discrete opinion formation problem in a setting where agents are influenced by both information diffused by their social relations and from recommendations received directly from the social media manager. We study how the \"strength\" of the influence of the social media and the homophily ratio affect the probability of the agents of reaching a consensus and how these factors can determine the type of consensus reached. In a simple 2-symmetric block model we prove that agents converge either to a consensus or to a persistent disagreement. In particular, we show that when the homophily ratio is large, the social media has a very low capacity of determining the outcome of the opinion dynamics. On the other hand, when the homophily ratio is low, the social media influence can have an important role on the dynamics, either by making harder to reach a consensus or inducing it on extreme opinions. Finally, in order to extend our analysis to more general and realistic settings we give some experimental evidences that our results still hold on general networks. ",
    "url": "https://arxiv.org/abs/2204.03299",
    "authors": [
      "Vincenzo Auletta",
      "Antonio Coppola",
      "Diodato Ferraioli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2204.03311",
    "title": "How to design a network architecture using availability",
    "abstract": "The best way to design a network is to take into account Availability values and Capacity Planning. You already saw Availability expressed with numbers such as 99.99%. The purpose of this document is to introduce the way to compute Availability values using Reliability Block Diagrams. ",
    "url": "https://arxiv.org/abs/2204.03311",
    "authors": [
      "Gilbert Moisio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.03316",
    "title": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "abstract": "We study the robust matrix completion problem for the low-rank Hankel matrix, which detects the sparse corruptions caused by extreme outliers while we try to recover the original Hankel matrix from the partial observation. In this paper, we explore the convenient Hankel structure and propose a novel non-convex algorithm, coined Hankel Structured Gradient Descent (HSGD), for large-scale robust Hankel matrix completion problems. HSGD is highly computing- and sample-efficient compared to the state-of-the-arts. The recovery guarantee with a linear convergence rate has been established for HSGD under some mild assumptions. The empirical advantages of HSGD are verified on both synthetic datasets and real-world nuclear magnetic resonance signals. ",
    "url": "https://arxiv.org/abs/2204.03316",
    "authors": [
      "HanQin Cai",
      "Jian-Feng Cai",
      "Juntao You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.03330",
    "title": "Coarse-to-Fine Feature Mining for Video Semantic Segmentation",
    "abstract": "The contextual information plays a core role in semantic segmentation. As for video semantic segmentation, the contexts include static contexts and motional contexts, corresponding to static content and moving content in a video clip, respectively. The static contexts are well exploited in image semantic segmentation by learning multi-scale and global/long-range features. The motional contexts are studied in previous video semantic segmentation. However, there is no research about how to simultaneously learn static and motional contexts which are highly correlated and complementary to each other. To address this problem, we propose a Coarse-to-Fine Feature Mining (CFFM) technique to learn a unified presentation of static contexts and motional contexts. This technique consists of two parts: coarse-to-fine feature assembling and cross-frame feature mining. The former operation prepares data for further processing, enabling the subsequent joint learning of static and motional contexts. The latter operation mines useful information/contexts from the sequential frames to enhance the video contexts of the features of the target frame. The enhanced features can be directly applied for the final prediction. Experimental results on popular benchmarks demonstrate that the proposed CFFM performs favorably against state-of-the-art methods for video semantic segmentation. Our implementation is available at https://github.com/GuoleiSun/VSS-CFFM ",
    "url": "https://arxiv.org/abs/2204.03330",
    "authors": [
      "Guolei Sun",
      "Yun Liu",
      "Henghui Ding",
      "Thomas Probst",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03332",
    "title": "Predicting Performance of Heterogeneous AI Systems with Discrete-Event  Simulations",
    "abstract": "In recent years, artificial intelligence (AI) technologies have found industrial applications in various fields. AI systems typically possess complex software and heterogeneous CPU/GPU hardware architecture, making it difficult to answer basic questions considering performance evaluation and software optimization. Where is the bottleneck impeding the system? How does the performance scale with the workload? How the speed-up of a specific module would contribute to the whole system? Finding the answers to these questions through experiments on the real system could require a lot of computational, human, financial, and time resources. A solution to cut these costs is to use a fast and accurate simulation model preparatory to implementing anything in the real system. In this paper, we propose a discrete-event simulation model of a high-load heterogeneous AI system in the context of video analytics. Using the proposed model, we estimate: 1) the performance scalability with the increasing number of cameras; 2) the performance impact of integrating a new module; 3) the performance gain from optimizing a single module. We show that the performance estimation accuracy of the proposed model is higher than 90%. We also demonstrate, that the considered system possesses a counter-intuitive relationship between workload and performance, which nevertheless is correctly inferred by the proposed simulation model. ",
    "url": "https://arxiv.org/abs/2204.03332",
    "authors": [
      "Vyacheslav Zhdanovskiy",
      "Lev Teplyakov",
      "Anton Grigoryev"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2204.03333",
    "title": "Learning to Sieve: Prediction of Grading Curves from Images of Concrete  Aggregate",
    "abstract": "A large component of the building material concrete consists of aggregate with varying particle sizes between 0.125 and 32 mm. Its actual size distribution significantly affects the quality characteristics of the final concrete in both, the fresh and hardened states. The usually unknown variations in the size distribution of the aggregate particles, which can be large especially when using recycled aggregate materials, are typically compensated by an increased usage of cement which, however, has severe negative impacts on economical and ecological aspects of the concrete production. In order to allow a precise control of the target properties of the concrete, unknown variations in the size distribution have to be quantified to enable a proper adaptation of the concrete's mixture design in real time. To this end, this paper proposes a deep learning based method for the determination of concrete aggregate grading curves. In this context, we propose a network architecture applying multi-scale feature extraction modules in order to handle the strongly diverse object sizes of the particles. Furthermore, we propose and publish a novel dataset of concrete aggregate used for the quantitative evaluation of our method. ",
    "url": "https://arxiv.org/abs/2204.03333",
    "authors": [
      "Max Coenen",
      "Dries Beyer",
      "Christian Heipke",
      "Michael Haist"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03341",
    "title": "Robust and Explainable Autoencoders for Unsupervised Time Series Outlier  Detection---Extended Version",
    "abstract": "Time series data occurs widely, and outlier detection is a fundamental problem in data mining, which has numerous applications. Existing autoencoder-based approaches deliver state-of-the-art performance on challenging real-world data but are vulnerable to outliers and exhibit low explainability. To address these two limitations, we propose robust and explainable unsupervised autoencoder frameworks that decompose an input time series into a clean time series and an outlier time series using autoencoders. Improved explainability is achieved because clean time series are better explained with easy-to-understand patterns such as trends and periodicities. We provide insight into this by means of a post-hoc explainability analysis and empirical studies. In addition, since outliers are separated from clean time series iteratively, our approach offers improved robustness to outliers, which in turn improves accuracy. We evaluate our approach on five real-world datasets and report improvements over the state-of-the-art approaches in terms of robustness and explainability. This is an extended version of \"Robust and Explainable Autoencoders for Unsupervised Time Series Outlier Detection\", to appear in IEEE ICDE 2022. ",
    "url": "https://arxiv.org/abs/2204.03341",
    "authors": [
      "Tung Kieu",
      "Bin Yang",
      "Chenjuan Guo",
      "Christian S. Jensen",
      "Yan Zhao",
      "Feiteng Huang",
      "Kai Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2204.03350",
    "title": "Implementing a Real-Time, YOLOv5 based Social Distancing Measuring  System for Covid-19",
    "abstract": "The purpose of this work is, to provide a YOLOv5 deep learning-based social distance monitoring framework using an overhead view perspective. In addition, we have developed a custom defined model YOLOv5 modified CSP (Cross Stage Partial Network) and assessed the performance on COCO and Visdrone dataset with and without transfer learning. Our findings show that the developed model successfully identifies the individual who violates the social distances. The accuracy of 81.7% for the modified bottleneck CSP without transfer learning is observed on COCO dataset after training the model for 300 epochs whereas for the same epochs, the default YOLOv5 model is attaining 80.1% accuracy with transfer learning. This shows an improvement in accuracy by our modified bottleneck CSP model. For the Visdrone dataset, we are able to achieve an accuracy of upto 56.5% for certain classes and especially an accuracy of 40% for people and pedestrians with transfer learning using the default YOLOv5s model for 30 epochs. While the modified bottleneck CSP is able to perform slightly better than the default model with an accuracy score of upto 58.1% for certain classes and an accuracy of ~40.4% for people and pedestrians. ",
    "url": "https://arxiv.org/abs/2204.03350",
    "authors": [
      "Narayana Darapaneni",
      "Shrawan Kumar",
      "Selvarangan Krishnan",
      "Hemalatha K",
      "Arunkumar Rajagopal",
      "Nagendra",
      "Anwesh Reddy Paduri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03361",
    "title": "Robust Event-Driven Interactions in Cooperative Multi-Agent Learning",
    "abstract": "We present an approach to reduce the communication required between agents in a Multi-Agent learning system by exploiting the inherent robustness of the underlying Markov Decision Process. We compute so-called robustness surrogate functions (off-line), that give agents a conservative indication of how far their state measurements can deviate before they need to update other agents in the system. This results in fully distributed decision functions, enabling agents to decide when it is necessary to update others. We derive bounds on the optimality of the resulting systems in terms of the discounted sum of rewards obtained, and show these bounds are a function of the design parameters. Additionally, we extend the results for the case where the robustness surrogate functions are learned from data, and present experimental results demonstrating a significant reduction in communication events between agents. ",
    "url": "https://arxiv.org/abs/2204.03361",
    "authors": [
      "Daniel Jarne Ornia",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.03371",
    "title": "Detection of Distracted Driver using Convolution Neural Network",
    "abstract": "With over 50 million car sales annually and over 1.3 million deaths every year due to motor accidents we have chosen this space. India accounts for 11 per cent of global death in road accidents. Drivers are held responsible for 78% of accidents. Road safety problems in developing countries is a major concern and human behavior is ascribed as one of the main causes and accelerators of road safety problems. Driver distraction has been identified as the main reason for accidents. Distractions can be caused due to reasons such as mobile usage, drinking, operating instruments, facial makeup, social interaction. For the scope of this project, we will focus on building a highly efficient ML model to classify different driver distractions at runtime using computer vision. We would also analyze the overall speed and scalability of the model in order to be able to set it up on an edge device. We use CNN, VGG-16, RestNet50 and ensemble of CNN to predict the classes. ",
    "url": "https://arxiv.org/abs/2204.03371",
    "authors": [
      "Narayana Darapaneni",
      "Jai Arora",
      "MoniShankar Hazra",
      "Naman Vig",
      "Simrandeep Singh Gandhi",
      "Saurabh Gupta",
      "Anwesh Reddy Paduri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03397",
    "title": "Defending Active Directory by Combining Neural Network based Dynamic  Program and Evolutionary Diversity Optimisation",
    "abstract": "Active Directory (AD) is the default security management system for Windows domain networks. We study a Stackelberg game model between one attacker and one defender on an AD attack graph. The attacker initially has access to a set of entry nodes. The attacker can expand this set by strategically exploring edges. Every edge has a detection rate and a failure rate. The attacker aims to maximize their chance of successfully reaching the destination before getting detected. The defender's task is to block a constant number of edges to decrease the attacker's chance of success. We show that the problem is #P-hard and, therefore, intractable to solve exactly. We convert the attacker's problem to an exponential sized Dynamic Program that is approximated by a Neural Network (NN). Once trained, the NN provides an efficient fitness function for the defender's Evolutionary Diversity Optimisation (EDO). The diversity emphasis on the defender's solution provides a diverse set of training samples, which improves the training accuracy of our NN for modelling the attacker. We go back and forth between NN training and EDO. Experimental results show that for R500 graph, our proposed EDO based defense is less than 1% away from the optimal defense. ",
    "url": "https://arxiv.org/abs/2204.03397",
    "authors": [
      "Diksha Goel",
      "Max Hector Ward-Graham",
      "Aneta Neumann",
      "Frank Neumann",
      "Hung Nguyen",
      "Mingyu Guo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.03400",
    "title": "Surrogate-Assisted Evolutionary Generative Design Of Breakwaters Using  Deep Convolutional Networks",
    "abstract": "In the paper, a multi-objective evolutionary surrogate-assisted approach for the fast and effective generative design of coastal breakwaters is proposed. To approximate the computationally expensive objective functions, the deep convolutional neural network is used as a surrogate model. This model allows optimizing a configuration of breakwaters with a different number of structures and segments. In addition to the surrogate, an assistant model was developed to estimate the confidence of predictions. The proposed approach was tested on the synthetic water area, the SWAN model was used to calculate the wave heights. The experimental results confirm that the proposed approach allows obtaining more effective (less expensive with better protective properties) solutions than non-surrogate approaches for the same time. ",
    "url": "https://arxiv.org/abs/2204.03400",
    "authors": [
      "Nikita O. Starodubcev",
      "Nikolay O. Nikitin",
      "Anna V. Kalyuzhnaya"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.03410",
    "title": "Incremental Prototype Prompt-tuning with Pre-trained Representation for  Class Incremental Learning",
    "abstract": "Class incremental learning has attracted much attention, but most existing works still continually fine-tune the representation model, resulting in much catastrophic forgetting. Instead of struggling to fight against such forgetting by replaying or distillation like most of the existing methods, we take the pre-train-and-prompt-tuning paradigm to sequentially learn new visual concepts based on a fixed semantic rich pre-trained representation model by incremental prototype prompt-tuning (IPP), which substantially reduces the catastrophic forgetting. In addition, an example prototype classification is proposed to compensate for semantic drift, the problem caused by learning bias at different phases. Extensive experiments conducted on the three incremental learning benchmarks demonstrate that our method consistently outperforms other state-of-the-art methods with a large margin. ",
    "url": "https://arxiv.org/abs/2204.03410",
    "authors": [
      "Jieren Deng",
      "Jianhua Hu",
      "Haojian Zhang",
      "Yunkuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03418",
    "title": "Continual Inference: A Library for Efficient Online Inference with Deep  Neural Networks in PyTorch",
    "abstract": "We present Continual Inference, a Python library for implementing Continual Inference Networks (CINs) in PyTorch, a class of Neural Networks designed specifically for efficient inference in both online and batch processing scenarios. We offer a comprehensive introduction and guide to CINs and their implementation in practice, and provide best-practices and code examples for composing complex modules for modern Deep Learning. Continual Inference is readily downloadable via the Python Package Index and at \\url{www.github.com/lukashedegaard/continual-inference}. ",
    "url": "https://arxiv.org/abs/2204.03418",
    "authors": [
      "Lukas Hedegaard",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03421",
    "title": "Self supervised learning for robust voice cloning",
    "abstract": "Voice cloning is a difficult task which requires robust and informative features incorporated in a high quality TTS system in order to effectively copy an unseen speaker's voice. In our work, we utilize features learned in a self-supervised framework via the Bootstrap Your Own Latent (BYOL) method, which is shown to produce high quality speech representations when specific audio augmentations are applied to the vanilla algorithm. We further extend the augmentations in the training procedure to aid the resulting features to capture the speaker identity and to make them robust to noise and acoustic conditions. The learned features are used as pre-trained utterance-level embeddings and as inputs to a Non-Attentive Tacotron based architecture, aiming to achieve multispeaker speech synthesis without utilizing additional speaker features. This method enables us to train our model in an unlabeled multispeaker dataset as well as use unseen speaker embeddings to copy a speaker's voice. Subjective and objective evaluations are used to validate the proposed model, as well as the robustness to the acoustic conditions of the target utterance. ",
    "url": "https://arxiv.org/abs/2204.03421",
    "authors": [
      "Konstantinos Klapsas",
      "Nikolaos Ellinas",
      "Karolos Nikitaras",
      "Georgios Vamvoukakis",
      "Panos Kakoulidis",
      "Konstantinos Markopoulos",
      "Spyros Raptis",
      "June Sig Sung",
      "Gunu Jho",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.03456",
    "title": "Few-Shot Forecasting of Time-Series with Heterogeneous Channels",
    "abstract": "Learning complex time series forecasting models usually requires a large amount of data, as each model is trained from scratch for each task/data set. Leveraging learning experience with similar datasets is a well-established technique for classification problems called few-shot classification. However, existing approaches cannot be applied to time-series forecasting because i) multivariate time-series datasets have different channels and ii) forecasting is principally different from classification. In this paper we formalize the problem of few-shot forecasting of time-series with heterogeneous channels for the first time. Extending recent work on heterogeneous attributes in vector data, we develop a model composed of permutation-invariant deep set-blocks which incorporate a temporal embedding. We assemble the first meta-dataset of 40 multivariate time-series datasets and show through experiments that our model provides a good generalization, outperforming baselines carried over from simpler scenarios that either fail to learn across tasks or miss temporal information. ",
    "url": "https://arxiv.org/abs/2204.03456",
    "authors": [
      "Lukas Brinkmeyer",
      "Rafael Rego Drumond",
      "Johannes Burchert",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03497",
    "title": "Generalised Latent Assimilation in Heterogeneous Reduced Spaces with  Machine Learning Surrogate Models",
    "abstract": "Reduced-order modelling and low-dimensional surrogate models generated using machine learning algorithms have been widely applied in high-dimensional dynamical systems to improve the algorithmic efficiency. In this paper, we develop a system which combines reduced-order surrogate models with a novel data assimilation (DA) technique used to incorporate real-time observations from different physical spaces. We make use of local smooth surrogate functions which link the space of encoded system variables and the one of current observations to perform variational DA with a low computational cost. The new system, named Generalised Latent Assimilation can benefit both the efficiency provided by the reduced-order modelling and the accuracy of data assimilation. A theoretical analysis of the difference between surrogate and original assimilation cost function is also provided in this paper where an upper bound, depending on the size of the local training set, is given. The new approach is tested on a high-dimensional CFD application of a two-phase liquid flow with non-linear observation operators that current Latent Assimilation methods can not handle. Numerical results demonstrate that the proposed assimilation approach can significantly improve the reconstruction and prediction accuracy of the deep learning surrogate model which is nearly 1000 times faster than the CFD simulation. ",
    "url": "https://arxiv.org/abs/2204.03497",
    "authors": [
      "Sibo Cheng",
      "Jianhua Chen",
      "Charitos Anastasiou",
      "Panagiota Angeli",
      "Omar K. Matar",
      "Yi-Ke Guo",
      "Christopher C. Pain",
      "Rossella Arcucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2204.03506",
    "title": "QCRI's COVID-19 Disinformation Detector: A System to Fight the COVID-19  Infodemic in Social Media",
    "abstract": "Fighting the ongoing COVID-19 infodemic has been declared as one of the most important focus areas by the World Health Organization since the onset of the COVID-19 pandemic. While the information that is consumed and disseminated consists of promoting fake cures, rumors, and conspiracy theories to spreading xenophobia and panic, at the same time there is information (e.g., containing advice, promoting cure) that can help different stakeholders such as policy-makers. Social media platforms enable the infodemic and there has been an effort to curate the content on such platforms, analyze and debunk them. While a majority of the research efforts consider one or two aspects (e.g., detecting factuality) of such information, in this study we focus on a multifaceted approach, including an API,\\url{https://app.swaggerhub.com/apis/yifan2019/Tanbih/0.8.0/} and a demo system,\\url{https://covid19.tanbih.org}, which we made freely and publicly available. We believe that this will facilitate researchers and different stakeholders. A screencast of the API services and demo is available.\\url{https://youtu.be/zhbcSvxEKMk} ",
    "url": "https://arxiv.org/abs/2204.03506",
    "authors": [
      "Preslav Nakov",
      "Firoj Alam",
      "Yifan Zhang",
      "Animesh Prakash",
      "Fahim Dalvi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.03525",
    "title": "Temporal Alignment for History Representation in Reinforcement Learning",
    "abstract": "Environments in Reinforcement Learning are usually only partially observable. To address this problem, a possible solution is to provide the agent with information about the past. However, providing complete observations of numerous steps can be excessive. Inspired by human memory, we propose to represent history with only important changes in the environment and, in our approach, to obtain automatically this representation using self-supervision. Our method (TempAl) aligns temporally-close frames, revealing a general, slowly varying state of the environment. This procedure is based on contrastive loss, which pulls embeddings of nearby observations to each other while pushing away other samples from the batch. It can be interpreted as a metric that captures the temporal relations of observations. We propose to combine both common instantaneous and our history representation and we evaluate TempAl on all available Atari games from the Arcade Learning Environment. TempAl surpasses the instantaneous-only baseline in 35 environments out of 49. The source code of the method and of all the experiments is available at https://github.com/htdt/tempal. ",
    "url": "https://arxiv.org/abs/2204.03525",
    "authors": [
      "Aleksandr Ermolov",
      "Enver Sangineto",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03526",
    "title": "Reconstructing Bayesian Networks on a Quantum Annealer",
    "abstract": "Bayesian networks are widely used probabilistic graphical models, whose structure is hard to learn starting from the generated data. O'Gorman et al. have proposed an algorithm to encode this task, i.e., the Bayesian network structure learning (BSNL), into a form that can be solved through quantum annealing, but they have not provided an experimental evaluation of it. In this paper, we present (i) an implementation in Python of O'Gorman's algorithm, (ii) a divide et impera approach that allows addressing BNSL problems of larger sizes in order to overcome the limitations imposed by the current architectures, and (iii) their empirical evaluation. Specifically, several problems with an increasing number of variables have been used in the experiments. The results have shown the effectiveness of O'Gorman's formulation for BNSL instances of small sizes, and the superiority of the divide et impera approach on the direct execution of O'Gorman's algorithm. ",
    "url": "https://arxiv.org/abs/2204.03526",
    "authors": [
      "Enrico Zardini",
      "Massimo Rizzoli",
      "Sebastiano Dissegna",
      "Enrico Blanzieri",
      "Davide Pastorello"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2204.03528",
    "title": "Visualizing Deep Neural Networks with Topographic Activation Maps",
    "abstract": "Machine Learning with Deep Neural Networks (DNNs) has become a successful tool in solving tasks across various fields of application. The success of DNNs is strongly connected to their high complexity in terms of the number of network layers or of neurons in each layer, which severely complicates to understand how DNNs solve their learned task. To improve the explainability of DNNs, we adapt methods from neuroscience because this field has a rich experience in analyzing complex and opaque systems. In this work, we draw inspiration from how neuroscience uses topographic maps to visualize the activity of the brain when it performs certain tasks. Transferring this approach to DNNs can help to visualize and understand their internal processes more intuitively, too. However, the inner structures of brains and DNNs differ substantially. Therefore, to be able to visualize activations of neurons in DNNs as topographic maps, we research techniques to layout the neurons in a two-dimensional space in which neurons of similar activity are in the vicinity of each other. In this work, we introduce and compare different methods to obtain a topographic layout of the neurons in a network layer. Moreover, we demonstrate how to use the resulting topographic activation maps to identify errors or encoded biases in DNNs or data sets. Our novel visualization technique improves the transparency of DNN-based algorithmic decision-making systems and is accessible to a broad audience because topographic maps are intuitive to interpret without expert-knowledge in Machine Learning. ",
    "url": "https://arxiv.org/abs/2204.03528",
    "authors": [
      "Andreas Krug",
      "Raihan Kabir Ratul",
      "Sebastian Stober"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.03529",
    "title": "FedADMM: A Robust Federated Deep Learning Framework with Adaptivity to  System Heterogeneity",
    "abstract": "Federated Learning (FL) is an emerging framework for distributed processing of large data volumes by edge devices subject to limited communication bandwidths, heterogeneity in data distributions and computational resources, as well as privacy considerations. In this paper, we introduce a new FL protocol termed FedADMM based on primal-dual optimization. The proposed method leverages dual variables to tackle statistical heterogeneity, and accommodates system heterogeneity by tolerating variable amount of work performed by clients. FedADMM maintains identical communication costs per round as FedAvg/Prox, and generalizes them via the augmented Lagrangian. A convergence proof is established for nonconvex objectives, under no restrictions in terms of data dissimilarity or number of participants per round of the algorithm. We demonstrate the merits through extensive experiments on real datasets, under both IID and non-IID data distributions across clients. FedADMM consistently outperforms all baseline methods in terms of communication efficiency, with the number of rounds needed to reach a prescribed accuracy reduced by up to 87%. The algorithm effectively adapts to heterogeneous data distributions through the use of dual variables, without the need for hyperparameter tuning, and its advantages are more pronounced in large-scale systems. ",
    "url": "https://arxiv.org/abs/2204.03529",
    "authors": [
      "Yonghai Gong",
      "Yichuan Li",
      "Nikolaos M. Freris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03541",
    "title": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge  Distillation",
    "abstract": "Most existing Human-Object Interaction~(HOI) Detection methods rely heavily on full annotations with predefined HOI categories, which is limited in diversity and costly to scale further. We aim at advancing zero-shot HOI detection to detect both seen and unseen HOIs simultaneously. The fundamental challenges are to discover potential human-object pairs and identify novel HOI categories. To overcome the above challenges, we propose a novel end-to-end zero-shot HOI Detection (EoID) framework via vision-language knowledge distillation. We first design an Interactive Score module combined with a Two-stage Bipartite Matching algorithm to achieve interaction distinguishment for human-object pairs in an action-agnostic manner. Then we transfer the distribution of action probability from the pretrained vision-language teacher as well as the seen ground truth to the HOI model to attain zero-shot HOI classification. Extensive experiments on HICO-Det dataset demonstrate that our model discovers potential interactive pairs and enables the recognition of unseen HOIs. Finally, our method outperforms the previous SOTA by 8.92% on unseen mAP and 10.18% on overall mAP under UA setting, by 6.02% on unseen mAP and 9.1% on overall mAP under UC setting. Moreover, our method is generalizable to large-scale object detection data to further scale up the action sets. The source code will be available at: https://github.com/mrwu-mac/EoID. ",
    "url": "https://arxiv.org/abs/2204.03541",
    "authors": [
      "Mingrui Wu",
      "Jiaxin Gu",
      "Yunhang Shen",
      "Mingbao Lin",
      "Chao Chen",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03556",
    "title": "Goodbye Tracking? Impact of iOS App Tracking Transparency and Privacy  Labels",
    "abstract": "Tracking is a highly privacy-invasive data collection practice that has been ubiquitous in mobile apps for many years due to its role in supporting advertising-based revenue models. In defence of user privacy, Apple introduced two significant changes with iOS 14: App Tracking Transparency (ATT), a mandatory opt-in system for enabling tracking on iOS, and Privacy Nutrition Labels, which disclose what kinds of data each app processes. This paper studies two versions of 1,759 iOS apps from the UK App Store: one version from before iOS 14 and one that has been updated to comply with the new rules. We find that Apple's new policies, as promised, prevent the collection of the Identifier for Advertisers (IDFA), an identifier used to facilitate cross-app user tracking. However, many apps still collect device information that can be used to track users at a group level (cohort tracking) or identify individuals probabilistically (fingerprinting). We find real-world evidence of apps computing and agreeing on a fingerprinting-derived identifier through the use of server-side code, thereby violating Apple's policies and exposing the limits of what ATT can do against tracking on iOS. This is especially concerning because we explicitly refused opt-in to tracking in our study, and consent is a legal requirement for tracking under EU and UK data protection law. We find that Apple itself engages in some forms of tracking and exempts invasive data practices like first-party tracking and credit scoring from its new rules, and that the new Privacy Nutrition Labels were often inaccurate. Overall, our findings suggest that, while tracking individual users is more difficult now, the changes reinforce existing market power of gatekeeper companies with access to large troves of first-party data. ",
    "url": "https://arxiv.org/abs/2204.03556",
    "authors": [
      "Konrad Kollnig",
      "Anastasia Shuba",
      "Max Van Kleek",
      "Reuben Binns",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2204.03559",
    "title": "Practical Digital Disguises: Leveraging Face Swaps to Protect Patient  Privacy",
    "abstract": "With rapid advancements in image generation technology, face swapping for privacy protection has emerged as an active area of research. The ultimate benefit is improved access to video datasets, e.g. in healthcare settings. Recent literature has proposed deep network-based architectures to perform facial swaps and reported the associated reduction in facial recognition accuracy. However, there is not much reporting on how well these methods preserve the types of semantic information needed for the privatized videos to remain useful for their intended application. Our main contribution is a novel end-to-end face swapping pipeline for recorded videos of standardized assessments of autism symptoms in children. Through this design, we are the first to provide a methodology for assessing the privacy-utility trade-offs for the face swapping approach to patient privacy protection. Our methodology can show, for example, that current deep network based face swapping is bottle-necked by face detection in real world videos, and the extent to which gaze and expression information is preserved by face swaps relative to baseline privatization methods such as blurring. ",
    "url": "https://arxiv.org/abs/2204.03559",
    "authors": [
      "Ethan Wilson",
      "Frederick Shic",
      "Jenny Skytta",
      "Eakta Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03594",
    "title": "Heterogeneous Target Speech Separation",
    "abstract": "We introduce a new paradigm for single-channel target source separation where the sources of interest can be distinguished using non-mutually exclusive concepts (e.g., loudness, gender, language, spatial location, etc). Our proposed heterogeneous separation framework can seamlessly leverage datasets with large distribution shifts and learn cross-domain representations under a variety of concepts used as conditioning. Our experiments show that training separation models with heterogeneous conditions facilitates the generalization to new concepts with unseen out-of-domain data while also performing substantially higher than single-domain specialist models. Notably, such training leads to more robust learning of new harder source separation discriminative concepts and can yield improvements over permutation invariant training with oracle source selection. We analyze the intrinsic behavior of source separation training with heterogeneous metadata and propose ways to alleviate emerging problems with challenging separation conditions. We release the collection of preparation recipes for all datasets used to further promote research towards this challenging task. ",
    "url": "https://arxiv.org/abs/2204.03594",
    "authors": [
      "Efthymios Tzinis",
      "Gordon Wichern",
      "Aswin Subramanian",
      "Paris Smaragdis",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.03597",
    "title": "Imitating, Fast and Slow: Robust learning from demonstrations via  decision-time planning",
    "abstract": "The goal of imitation learning is to mimic expert behavior from demonstrations, without access to an explicit reward signal. A popular class of approach infers the (unknown) reward function via inverse reinforcement learning (IRL) followed by maximizing this reward function via reinforcement learning (RL). The policies learned via these approaches are however very brittle in practice and deteriorate quickly even with small test-time perturbations due to compounding errors. We propose Imitation with Planning at Test-time (IMPLANT), a new meta-algorithm for imitation learning that utilizes decision-time planning to correct for compounding errors of any base imitation policy. In contrast to existing approaches, we retain both the imitation policy and the rewards model at decision-time, thereby benefiting from the learning signal of the two components. Empirically, we demonstrate that IMPLANT significantly outperforms benchmark imitation learning approaches on standard control environments and excels at zero-shot generalization when subject to challenging perturbations in test-time dynamics. ",
    "url": "https://arxiv.org/abs/2204.03597",
    "authors": [
      "Carl Qi",
      "Pieter Abbeel",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03620",
    "title": "An Online Learning Approach to Shortest Path and Backpressure Routing in  Wireless Networks",
    "abstract": "We consider the adaptive routing problem in multihop wireless networks. The link states are assumed to be random variables drawn from unknown distributions, independent and identically distributed across links and time. This model has attracted a growing interest recently in cognitive radio networks and adaptive communication systems. In such networks, devices are cognitive in the sense of learning the link states and updating the transmission parameters to allow efficient resource utilization. This model contrasts sharply with the vast literature on routing algorithms that assumed complete knowledge about the link state means. The goal is to design an algorithm that learns online optimal paths for data transmissions to maximize the network throughput while attaining low path cost over flows in the network. We develop a novel Online Learning for Shortest path and Backpressure (OLSB) algorithm to achieve this goal. We analyze the performance of OLSB rigorously and show that it achieves a logarithmic regret with time, defined as the loss of an algorithm as compared to a genie that has complete knowledge about the link state means. We further evaluate the performance of OLSB numerically via extensive simulations, which support the theoretical findings and demonstrate its high efficiency. ",
    "url": "https://arxiv.org/abs/2204.03620",
    "authors": [
      "Omer Amar",
      "Kobi Cohen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.03632",
    "title": "The Effects of Regularization and Data Augmentation are Class Dependent",
    "abstract": "Regularization is a fundamental technique to prevent over-fitting and to improve generalization performances by constraining a model's complexity. Current Deep Networks heavily rely on regularizers such as Data-Augmentation (DA) or weight-decay, and employ structural risk minimization, i.e. cross-validation, to select the optimal regularization hyper-parameters. In this study, we demonstrate that techniques such as DA or weight decay produce a model with a reduced complexity that is unfair across classes. The optimal amount of DA or weight decay found from cross-validation leads to disastrous model performances on some classes e.g. on Imagenet with a resnet50, the \"barn spider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by introducing random crop DA during training. Even more surprising, such performance drop also appears when introducing uninformative regularization techniques such as weight decay. Those results demonstrate that our search for ever increasing generalization performance -- averaged over all classes and samples -- has left us with models and regularizers that silently sacrifice performances on some classes. This scenario can become dangerous when deploying a model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on INaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889 when introducing random crop DA during the Imagenet pre-training phase. Those results demonstrate that designing novel regularizers without class-dependent bias remains an open research question. ",
    "url": "https://arxiv.org/abs/2204.03632",
    "authors": [
      "Randall Balestriero",
      "Leon Bottou",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.03636",
    "title": "SurroundDepth: Entangling Surrounding Views for Self-Supervised  Multi-Camera Depth Estimation",
    "abstract": "Depth estimation from images serves as the fundamental step of 3D perception for autonomous driving and is an economical alternative to expensive depth sensors like LiDAR. The temporal photometric consistency enables self-supervised depth estimation without labels, further facilitating its application. However, most existing methods predict the depth solely based on each monocular image and ignore the correlations among multiple surrounding cameras, which are typically available for modern self-driving vehicles. In this paper, we propose a SurroundDepth method to incorporate the information from multiple surrounding views to predict depth maps across cameras. Specifically, we employ a joint network to process all the surrounding views and propose a cross-view transformer to effectively fuse the information from multiple views. We apply cross-view self-attention to efficiently enable the global interactions between multi-camera feature maps. Different from self-supervised monocular depth estimation, we are able to predict real-world scales given multi-camera extrinsic matrices. To achieve this goal, we adopt structure-from-motion to extract scale-aware pseudo depths to pretrain the models. Further, instead of predicting the ego-motion of each individual camera, we estimate a universal ego-motion of the vehicle and transfer it to each view to achieve multi-view consistency. In experiments, our method achieves the state-of-the-art performance on the challenging multi-camera depth estimation datasets DDAD and nuScenes. ",
    "url": "https://arxiv.org/abs/2204.03636",
    "authors": [
      "Yi Wei",
      "Linqing Zhao",
      "Wenzhao Zheng",
      "Zheng Zhu",
      "Yongming Rao",
      "Guan Huang",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02969",
    "title": "Holistic Fault Detection and Diagnosis System in Imbalanced, Scarce,  Multi-Domain (ISMD) Data Setting for Component-Level Prognostics and Health  Management (PHM)",
    "abstract": "In the current Industrial 4.0 revolution, Prognostics and Health Management (PHM) is an emerging field of research. The difficulty of obtaining data from electromechanical systems in an industrial setting increases proportionally with the scale and accessibility of the automated industry, resulting in a less interpolated PHM system. To put it another way, the development of an accurate PHM system for each industrial system necessitates a unique dataset acquired under specified conditions. In most circumstances, obtaining this one-of-a-kind dataset is difficult, and the resulting dataset has a significant imbalance, a lack of certain useful information, and multi-domain knowledge. To address this, this paper provides a fault detection and diagnosis system that evaluates and pre-processes Imbalanced, Scarce, Multi-Domain (ISMD) data acquired from an industrial robot utilizing Signal Processing (SP) techniques and Deep Learning-based (DL) domain knowledge transfer. The domain knowledge transfer is used to produce a synthetic dataset with a high interpolation rate that contains all the useful information about each domain. For domain knowledge transfer and data generation, Continuous Wavelet Transform (CWT) with Generative Adversarial Network (GAN) was used, as well as Convolutional Neural Network (CNN) to test the suggested methodology using transfer learning and categorize several faults. The proposed methodology was tested on a real experimental bench that included an industrial robot created by Hyundai Robotics Co. This development resulted in a satisfactory resolution with 99.7% (highest) classification accuracy achieved by transfer learning on several CNN benchmark models. ",
    "url": "https://arxiv.org/abs/2204.02969",
    "authors": [
      "Ali Rohan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.02978",
    "title": "End-To-End Optimization of Online Neural Network-supported Two-Stage  Dereverberation for Hearing Devices",
    "abstract": "A two-stage online dereverberation algorithm for hearing devices is presented in this paper. The approach combines a multi-channel multi-frame linear filtering approach with a single-channel single-frame post-filter. Both components rely on power spectral density (PSD) estimates provided by deep neural networks (DNNs). This contribution extends our prior work, which shows that directly optimizing for a criterion at the output of the multi-channel linear filtering stage results in a more efficient dereverberation, as compared to placing the criterion at the output of the DNN to optimize the PSD estimation. In the present work, we show that the dereverberation performance of the proposed first stage particularly improves the early-to-mid reverberation ratio if trained end-to-end. We thus argue that it can be combined with a post-filtering stage which benefits from the early-to-mid ratio improvement and is consequently able to efficiently suppress the residual late reverberation. This proposed two stage procedure is shown to be both very effective in terms of dereverberation performance and computational demands. Furthermore, the proposed system can be adapted to the needs of different types of hearing-device users by controlling the amount of reduction of early reflections. The proposed system outperforms the previously proposed end-to-end DNN-supported linear filtering algorithm, as well as other traditional approaches, based on an evaluation using the noise-free version of the WHAMR! dataset. ",
    "url": "https://arxiv.org/abs/2204.02978",
    "authors": [
      "Jean-Marie Lemercier",
      "Joachim Thiemann",
      "Raphael Koning",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.03145",
    "title": "DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors",
    "abstract": "DeepTensor is a computationally efficient framework for low-rank decomposition of matrices and tensors using deep generative networks. We decompose a tensor as the product of low-rank tensor factors (e.g., a matrix as the outer product of two vectors), where each low-rank tensor is generated by a deep network (DN) that is trained in a self-supervised manner to minimize the mean-squared approximation error. Our key observation is that the implicit regularization inherent in DNs enables them to capture nonlinear signal structures (e.g., manifolds) that are out of the reach of classical linear methods like the singular value decomposition (SVD) and principal component analysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance deteriorates when the tensor's entries deviate from additive white Gaussian noise, we demonstrate that the performance of DeepTensor is robust to a wide range of distributions. We validate that DeepTensor is a robust and computationally efficient drop-in replacement for the SVD, PCA, nonnegative matrix factorization (NMF), and similar decompositions by exploring a range of real-world applications, including hyperspectral image denoising, 3D MRI tomography, and image classification. In particular, DeepTensor offers a 6dB signal-to-noise ratio improvement over standard denoising methods for signals corrupted by Poisson noise and learns to decompose 3D tensors 60 times faster than a single DN equipped with 3D convolutions. ",
    "url": "https://arxiv.org/abs/2204.03145",
    "authors": [
      "Vishwanath Saragadam",
      "Randall Balestriero",
      "Ashok Veeraraghavan",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.03197",
    "title": "MDA GAN: Adversarial-Learning-based 3-D Seismic Data Interpolation and  Reconstruction for Complex Missing",
    "abstract": "The interpolation and reconstruction of missing traces is a crucial step in seismic data processing, moreover it is also a highly ill-posed problem, especially for complex cases such as high-ratio random discrete missing, continuous missing and missing in rich fault or salt body surveys. These complex cases are rarely mentioned in current sparse or low-rank priorbased and deep learning-based approaches. To cope with complex missing cases, we propose Multi-Dimensional Adversarial GAN (MDA GAN), a novel 3-D GAN framework. It employs three discriminators to ensure the consistency of the reconstructed data with the original data distribution in each dimension. The feature splicing module (FSM) is designed and embedded into the generator of this framework, which automatically splices the features of the unmissing part with those of the reconstructed part (missing part), thus fully preserving the information of the unmissing part. To prevent pixel distortion in the seismic data caused by the adversarial learning process, we propose a new reconstruction loss Tanh Cross Entropy (TCE) loss to provide smoother gradients. We experimentally verified the effectiveness of the individual components of the study and then tested the method on multiple publicly available data. The method achieves reasonable reconstructions for up to 95% of random discrete missing, 100 traces of continuous missing and more complex hybrid missing. In surveys of fault-rich and salt bodies, the method can achieve promising reconstructions with up to 75% missing in each of the three directions (98.2% in total). ",
    "url": "https://arxiv.org/abs/2204.03197",
    "authors": [
      "Yimin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Timing Li",
      "Shaoquan Tan",
      "Zongchao Huang"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03204",
    "title": "Convolutional Neural Network for Early Pulmonary Embolism Detection via  Computed Tomography Pulmonary Angiography",
    "abstract": "This study was conducted to develop a computer-aided detection (CAD) system for triaging patients with pulmonary embolism (PE). The purpose of the system was to reduce the death rate during the waiting period. Computed tomography pulmonary angiography (CTPA) is used for PE diagnosis. Because CTPA reports require a radiologist to review the case and suggest further management, this creates a waiting period during which patients may die. Our proposed CAD method was thus designed to triage patients with PE from those without PE. In contrast to related studies involving CAD systems that identify key PE lesion images to expedite PE diagnosis, our system comprises a novel classification-model ensemble for PE detection and a segmentation model for PE lesion labeling. The models were trained using data from National Cheng Kung University Hospital and open resources. The classification model yielded 0.73 for receiver operating characteristic curve (accuracy = 0.85), while the mean intersection over union was 0.689 for the segmentation model. The proposed CAD system can distinguish between patients with and without PE and automatically label PE lesions to expedite PE diagnosis ",
    "url": "https://arxiv.org/abs/2204.03204",
    "authors": [
      "Ching-Yuan Yu",
      "Ming-Che Chang",
      "Yun-Chien Cheng",
      "Chin Kuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03213",
    "title": "MC-UNet Multi-module Concatenation based on U-shape Network for Retinal  Blood Vessels Segmentation",
    "abstract": "Accurate segmentation of the blood vessels of the retina is an important step in clinical diagnosis of ophthalmic diseases. Many deep learning frameworks have come up for retinal blood vessels segmentation tasks. However, the complex vascular structure and uncertain pathological features make the blood vessel segmentation still very challenging. A novel U-shaped network named Multi-module Concatenation which is based on Atrous convolution and multi-kernel pooling is put forward to retinal vessels segmentation in this paper. The proposed network structure retains three layers the essential structure of U-Net, in which the atrous convolution combining the multi-kernel pooling blocks are designed to obtain more contextual information. The spatial attention module is concatenated with dense atrous convolution module and multi-kernel pooling module to form a multi-module concatenation. And different dilation rates are selected by cascading to acquire a larger receptive field in atrous convolution. Adequate comparative experiments are conducted on these public retinal datasets: DRIVE, STARE and CHASE_DB1. The results show that the proposed method is effective, especially for microvessels. The code will be put out at https://github.com/Rebeccala/MC-UNet ",
    "url": "https://arxiv.org/abs/2204.03213",
    "authors": [
      "Ting Zhang",
      "Jun Li",
      "Yi Zhao",
      "Nan Chen",
      "Han Zhou",
      "Hongtao Xu",
      "Zihao Guan",
      "Changcai Yang",
      "Lanyan Xue",
      "Riqing Chen",
      "Lifang Wei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03219",
    "title": "DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training  and Distribution of Opinion Scores",
    "abstract": "Mean opinion score (MOS) is a typical subjective evaluation metric for speech synthesis systems. Since collecting MOS is time-consuming, it would be desirable if there are accurate MOS prediction models for automatic evaluation. In this work, we propose DDOS, a novel MOS prediction model. DDOS utilizes domain adaptive pre-training to further pre-train self-supervised learning models on synthetic speech. And a proposed module is added to model the opinion score distribution of each utterance. With the proposed components, DDOS outperforms previous works on BVCC dataset. And the zero shot transfer result on BC2019 dataset is significantly improved. DDOS also wins second place in Interspeech 2022 VoiceMOS challenge in terms of system-level score. ",
    "url": "https://arxiv.org/abs/2204.03219",
    "authors": [
      "Wei-Cheng Tseng",
      "Wei-Tsung Kao",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.03238",
    "title": "Unsupervised Quantized Prosody Representation for Controllable Speech  Synthesis",
    "abstract": "In this paper, we propose a novel prosody disentangle method for prosodic Text-to-Speech (TTS) model, which introduces the vector quantization (VQ) method to the auxiliary prosody encoder to obtain the decomposed prosody representations in an unsupervised manner. Rely on its advantages, the speaking styles, such as pitch, speaking velocity, local pitch variance, etc., are decomposed automatically into the latent quantize vectors. We also investigate the internal mechanism of VQ disentangle process by means of a latent variables counter and find that higher value dimensions usually represent prosody information. Experiments show that our model can control the speaking styles of synthesis results by directly manipulating the latent variables. The objective and subjective evaluations illustrated that our model outperforms the popular models. ",
    "url": "https://arxiv.org/abs/2204.03238",
    "authors": [
      "Yutian Wang",
      "Yuankun Xie",
      "Kun Zhao",
      "Hui Wang",
      "Qin Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2204.03294",
    "title": "Heterogeneous Ultra-Dense Networks with Traffic Hotspots: A Unified  Handover Analysis",
    "abstract": "With the ever-growing communication demands and the unceasing miniaturization of mobile devices, the Internet of Things is expanding the amount of mobile terminals to an enormous level. To deal with such numbers of communication data, plenty of base stations (BSs) need to be deployed. However, denser deployments of heterogeneous networks (HetNets) lead to more frequent handovers, which could increase network burden and degrade the users experience, especially in traffic hotspot areas. In this paper, we develop a unified framework to investigate the handover performance of wireless networks with traffic hotspots. Using the stochastic geometry, we derive the theoretical expressions of average distances and handover metrics in HetNets, where the correlations between users and BSs in hotspots are captured. Specifically, the distributions of macro cells are modeled as independent Poisson point processes (PPPs), and the two tiers of small cells outside and inside the hotspots are modeled as PPP and Poisson cluster process (PCP) separately. A modified random waypoint (MRWP) model is also proposed to eliminate the density wave phenomenon in traditional models and to increase the accuracy of handover decision. By combining the PCP and MRWP model, the distributions of distances from a typical terminal to the BSs in different tiers are derived. Afterwards, we derive the expressions of average distances from a typical terminal to different BSs, and reveal that the handover rate, handover failure rate, and ping-pong rate are deduced as the functions of BS density, scattering variance of clustered small cell, user velocity, and threshold of triggered time. Simulation results verify the accuracy of the proposed analytical model and closed-form theoretical expressions. ",
    "url": "https://arxiv.org/abs/2204.03294",
    "authors": [
      "He Zhou",
      "Haibo Zhou",
      "Jianguo Li",
      "Kai Yang",
      "Jianping An",
      "Xuemin",
      "Shen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.03305",
    "title": "MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility  Prediction Model for Hearing Aids",
    "abstract": "Improving the user's hearing ability to understand speech in noisy environments is critical to the development of hearing aid (HA) devices. For this, it is important to derive a metric that can fairly predict speech intelligibility for HA users. A straightforward approach is to conduct a subjective listening test and use the test results as an evaluation metric. However, conducting large-scale listening tests is time-consuming and expensive. Therefore, several evaluation metrics were derived as surrogates for subjective listening test results. In this study, we propose a multi-branched speech intelligibility prediction model (MBI-Net), for predicting the subjective intelligibility scores of HA users. MBI-Net consists of two branches of models, with each branch consisting of a hearing loss model, a cross-domain feature extraction module, and a speech intelligibility prediction model, to process speech signals from one channel. The outputs of the two branches are fused through a linear layer to obtain predicted speech intelligibility scores. Experimental results confirm the effectiveness of MBI-Net, which produces higher prediction scores than the baseline system in Track 1 and Track 2 on the Clarity Prediction Challenge 2022 dataset. ",
    "url": "https://arxiv.org/abs/2204.03305",
    "authors": [
      "Ryandhimas E. Zezario",
      "Fei Chen",
      "Chiou-Shann Fuh",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.03310",
    "title": "MTI-Net: A Multi-Target Speech Intelligibility Prediction Model",
    "abstract": "Recently, deep learning (DL)-based non-intrusive speech assessment models have attracted great attention. Many studies report that these DL-based models yield satisfactory assessment performance and good flexibility, but their performance in unseen environments remains a challenge. Furthermore, compared to quality scores, fewer studies elaborate deep learning models to estimate intelligibility scores. This study proposes a multi-task speech intelligibility prediction model, called MTI-Net, for simultaneously predicting human and machine intelligibility measures. Specifically, given a speech utterance, MTI-Net is designed to predict subjective listening test results and word error rate (WER) scores. We also investigate several methods that can improve the prediction performance of MTI-Net. First, we compare different features (including low-level features and embeddings from self-supervised learning (SSL) models) and prediction targets of MTI-Net. Second, we explore the effect of transfer learning and multi-tasking learning on training MTI-Net. Finally, we examine the potential advantages of fine-tuning SSL embeddings. Experimental results demonstrate the effectiveness of using cross-domain features, multi-task learning, and fine-tuning SSL embeddings. Furthermore, it is confirmed that the intelligibility and WER scores predicted by MTI-Net are highly correlated with the ground-truth scores. ",
    "url": "https://arxiv.org/abs/2204.03310",
    "authors": [
      "Ryandhimas E. Zezario",
      "Szu-wei Fu",
      "Fei Chen",
      "Chiou-Shann Fuh",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.03428",
    "title": "Detecting Vocal Fatigue with Neural Embeddings",
    "abstract": "Vocal fatigue refers to the feeling of tiredness and weakness of voice due to extended utilization. This paper investigates the effectiveness of neural embeddings for the detection of vocal fatigue. We compare x-vectors, ECAPA-TDNN, and wav2vec 2.0 embeddings on a corpus of academic spoken English. Low-dimensional mappings of the data reveal that neural embeddings capture information about the change in vocal characteristics of a speaker during prolonged voice usage. We show that vocal fatigue can be reliably predicted using all three kinds of neural embeddings after only 50 minutes of continuous speaking when temporal smoothing and normalization are applied to the extracted embeddings. We employ support vector machines for classification and achieve accuracy scores of 81% using x-vectors, 85% using ECAPA-TDNN embeddings, and 82% using wav2vec 2.0 embeddings as input features. We obtain an accuracy score of 76%, when the trained system is applied to a different speaker and recording environment without any adaptation. ",
    "url": "https://arxiv.org/abs/2204.03428",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Ilja Baumann",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.03439",
    "title": "Half-sibling regression meets exoplanet imaging: PSF modeling and  subtraction using a flexible, domain knowledge-driven, causal framework",
    "abstract": "High-contrast imaging of exoplanets hinges on powerful post-processing methods to denoise the data and separate the signal of a companion from its host star, which is typically orders of magnitude brighter. Existing post-processing algorithms do not use all prior domain knowledge that is available about the problem. We propose a new method that builds on our understanding of the systematic noise and the causal structure of the data-generating process. Our algorithm is based on a modified version of half-sibling regression (HSR), a flexible denoising framework that combines ideas from the fields of machine learning and causality. We adapt the method to address the specific requirements of high-contrast exoplanet imaging data obtained in pupil tracking mode. The key idea is to estimate the systematic noise in a pixel by regressing the time series of this pixel onto a set of causally independent, signal-free predictor pixels. We use regularized linear models in this work; however, other (non-linear) models are also possible. In a second step, we demonstrate how the HSR framework allows us to incorporate observing conditions such as wind speed or air temperature as additional predictors. When we apply our method to four data sets from the VLT/NACO instrument, our algorithm provides a better false-positive fraction than PCA-based PSF subtraction, a popular baseline method in the field. Additionally, we find that the HSR-based method provides direct and accurate estimates for the contrast of the exoplanets without the need to insert artificial companions for calibration in the data sets. Finally, we present first evidence that using the observing conditions as additional predictors can improve the results. Our HSR-based method provides an alternative, flexible and promising approach to the challenge of modeling and subtracting the stellar PSF and systematic noise in exoplanet imaging data. ",
    "url": "https://arxiv.org/abs/2204.03439",
    "authors": [
      "Timothy D. Gebhard",
      "Markus J. Bonse",
      "Sascha P. Quanz",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03547",
    "title": "Evaluating Procedures for Establishing Generative Adversarial  Network-based Stochastic Image Models in Medical Imaging",
    "abstract": "Modern generative models, such as generative adversarial networks (GANs), hold tremendous promise for several areas of medical imaging, such as unconditional medical image synthesis, image restoration, reconstruction and translation, and optimization of imaging systems. However, procedures for establishing stochastic image models (SIMs) using GANs remain generic and do not address specific issues relevant to medical imaging. In this work, canonical SIMs that simulate realistic vessels in angiography images are employed to evaluate procedures for establishing SIMs using GANs. The GAN-based SIM is compared to the canonical SIM based on its ability to reproduce those statistics that are meaningful to the particular medically realistic SIM considered. It is shown that evaluating GANs using classical metrics and medically relevant metrics may lead to different conclusions about the fidelity of the trained GANs. This work highlights the need for the development of objective metrics for evaluating GANs. ",
    "url": "https://arxiv.org/abs/2204.03547",
    "authors": [
      "Varun A. Kelkar",
      "Dimitrios S. Gotsis",
      "Frank J. Brooks",
      "Kyle J. Myers",
      "Prabhat KC",
      "Rongping Zeng",
      "Mark A. Anastasio"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2204.03564",
    "title": "RF Signal Transformation and Classification using Deep Neural Networks",
    "abstract": "Deep neural networks (DNNs) designed for computer vision and natural language processing tasks cannot be directly applied to the radio frequency (RF) datasets. To address this challenge, we propose to convert the raw RF data to data types that are suitable for off-the-shelf DNNs by introducing a convolutional transform technique. In addition, we propose a simple 5-layer convolutional neural network architecture (CONV-5) that can operate with raw RF I/Q data without any transformation. Further, we put forward an RF dataset, referred to as RF1024, to facilitate future RF research. RF1024 consists of 8 different RF modulation classes with each class having 1000/200 training/test samples. Each sample of the RF1024 dataset contains 1024 complex I/Q values. Lastly, the experiments are performed on the RadioML2016 and RF1024 datasets to demonstrate the improved classification performance. ",
    "url": "https://arxiv.org/abs/2204.03564",
    "authors": [
      "Umar Khalid",
      "Nazmul Karim",
      "Nazanin Rahnavard"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03565",
    "title": "Adaptive Spike-Like Representation of EEG Signals for Sleep Stages  Scoring",
    "abstract": "Recently there has seen promising results on automatic stage scoring by extracting spatio-temporal features from electroencephalogram (EEG). Such methods entail laborious manual feature engineering and domain knowledge. In this study, we propose an adaptive scheme to probabilistically encode, filter and accumulate the input signals and weight the resultant features by the half-Gaussian probabilities of signal intensities. The adaptive representations are subsequently fed into a transformer model to automatically mine the relevance between features and corresponding stages. Extensive experiments on the largest public dataset against state-of-the-art methods validate the effectiveness of our proposed method and reveal promising future directions. ",
    "url": "https://arxiv.org/abs/2204.03565",
    "authors": [
      "Lingwei Zhu",
      "Koki Odani",
      "Ziwei Yang",
      "Guang Shi",
      "Yirong Kan",
      "Zheng Chen",
      "Renyuan Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.03618",
    "title": "Pneumonia Detection in Chest X-Rays using Neural Networks",
    "abstract": "With the advancement in AI, deep learning techniques are widely used to design robust classification models in several areas such as medical diagnosis tasks in which it achieves good performance. In this paper, we have proposed the CNN model (Convolutional Neural Network) for the classification of Chest X-ray images for Radiological Society of North America Pneumonia (RSNA) datasets. The study also tries to achieve the same RSNA benchmark results using the limited computational resources by trying out various approaches to the methodologies that have been implemented in recent years. The proposed method is based on a non-complex CNN and the use of transfer learning algorithms like Xception, InceptionV3/V4, EfficientNetB7. Along with this, the study also tries to achieve the same RSNA benchmark results using the limited computational resources by trying out various approaches to the methodologies that have been implemented in recent years. The RSNA benchmark MAP score is 0.25, but using the Mask RCNN model on a stratified sample of 3017 along with image augmentation gave a MAP score of 0.15. Meanwhile, the YoloV3 without any hyperparameter tuning gave the MAP score of 0.32 but still, the loss keeps decreasing. Running the model for a greater number of iterations can give better results. ",
    "url": "https://arxiv.org/abs/2204.03618",
    "authors": [
      "Narayana Darapaneni",
      "Ashish Ranjan",
      "Dany Bright",
      "Devendra Trivedi",
      "Ketul Kumar",
      "Vivek Kumar",
      "Anwesh Reddy Paduri"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1709.06172",
    "title": "On the Complexity of Robust Stable Marriage",
    "abstract": " Comments: Accepted for publication in COCOA'17 ",
    "url": "https://arxiv.org/abs/1709.06172",
    "authors": [
      "Begum Genc",
      "Mohamed Siala",
      "Gilles Simonin",
      "Barry O'Sullivan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:1812.10779",
    "title": "Semantic Driven Multi-Camera Pedestrian Detection",
    "abstract": " Comments: Preprint accepted in Springer Knowledge and Information Systems (KAIS) ",
    "url": "https://arxiv.org/abs/1812.10779",
    "authors": [
      "Alejandro L\u00f3pez-Cifuentes",
      "Marcos Escudero-Vi\u00f1olo",
      "Jes\u00fas Besc\u00f3s",
      "Pablo Carballeira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2006.00575",
    "title": "Neural Entity Linking: A Survey of Models Based on Deep Learning",
    "abstract": " Comments: Published in Semantic Web journal ",
    "url": "https://arxiv.org/abs/2006.00575",
    "authors": [
      "Ozge Sevgili",
      "Artem Shelmanov",
      "Mikhail Arkhipov",
      "Alexander Panchenko",
      "Chris Biemann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2008.09371",
    "title": "Towards Improving Selective Prediction Ability of NLP Systems",
    "abstract": " Comments: ACL 2022 RepL4NLP Workshop ",
    "url": "https://arxiv.org/abs/2008.09371",
    "authors": [
      "Neeraj Varshney",
      "Swaroop Mishra",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.05454",
    "title": "Joint Adaptive Graph and Structured Sparsity Regularization for  Unsupervised Feature Selection",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2010.03728 ",
    "url": "https://arxiv.org/abs/2010.05454",
    "authors": [
      "Zhenzhen Sun",
      "Yuanlong Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.12844",
    "title": "Physics-informed neural networks for myocardial perfusion MRI  quantification",
    "abstract": " Comments: Published in Medical Image Analysis ",
    "url": "https://arxiv.org/abs/2011.12844",
    "authors": [
      "Rudolf L.M. van Herten",
      "Amedeo Chiribiri",
      "Marcel Breeuwer",
      "Mitko Veta",
      "Cian M. Scannell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2104.11123",
    "title": "Universal Horn Sentences and the Joint Embedding Property",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2104.11123",
    "authors": [
      "Manuel Bodirsky",
      "Jakub Rydval",
      "Andr\u00e9 Schrottenloher"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2106.02190",
    "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug  Discovery",
    "abstract": " Title: Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug  Discovery ",
    "url": "https://arxiv.org/abs/2106.02190",
    "authors": [
      "Yulun Wu",
      "Mikaela Cashman",
      "Nicholas Choma",
      "\u00c9rica T. Prates",
      "Ver\u00f3nica G. Melesse Vergara",
      "Andrew Chen",
      "Manesh Shah",
      "Austin Clyde",
      "Thomas S. Brettin",
      "Wibe A. de Jong",
      "Neeraj Kumar",
      "Martha S. Head",
      "Rick L. Stevens",
      "Peter Nugent",
      "Daniel A. Jacobson",
      "James B. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2106.04564",
    "title": "Are Pretrained Transformers Robust in Intent Classification? A Missing  Ingredient in Evaluation of Out-of-Scope Intent Detection",
    "abstract": " Comments: ACL 2022 Workshop on NLP for Conversational AI ",
    "url": "https://arxiv.org/abs/2106.04564",
    "authors": [
      "Jianguo Zhang",
      "Kazuma Hashimoto",
      "Yao Wan",
      "Zhiwei Liu",
      "Ye Liu",
      "Caiming Xiong",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.14836",
    "title": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "abstract": " Title: Understanding Dynamics of Nonlinear Representation Learning and Its  Application ",
    "url": "https://arxiv.org/abs/2106.14836",
    "authors": [
      "Kenji Kawaguchi",
      "Linjun Zhang",
      "Zhun Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.04276",
    "title": "Secure Consensus via Objective Coding: Robustness Analysis to Channel  Tampering",
    "abstract": " Comments: 12 pages, 5 figures, submitted to IEEE Transactions on Systems, Man and Cybernetics: Systems ",
    "url": "https://arxiv.org/abs/2107.04276",
    "authors": [
      "Marco Fabris",
      "Daniel Zelazo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.09395",
    "title": "Unsupervised Cycle-consistent Generative Adversarial Networks for  Pan-sharpening",
    "abstract": " Comments: 14 pages, 8 figures, and 7 tables. Accepted by TGRS ",
    "url": "https://arxiv.org/abs/2109.09395",
    "authors": [
      "Huanyu Zhou",
      "Qingjie Liu",
      "Dawei Weng",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2109.10476",
    "title": "Self-Supervised Learning to Prove Equivalence Between Programs via  Semantics-Preserving Rewrite Rules",
    "abstract": " Comments: 18 pages ",
    "url": "https://arxiv.org/abs/2109.10476",
    "authors": [
      "Steve Kommrusch",
      "Martin Monperrus",
      "Louis-No\u00ebl Pouchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2110.05319",
    "title": "Efficient Training of 3D Seismic Image Fault Segmentation Network under  Sparse Labels by Weakening Anomaly Annotation",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2110.05319",
    "authors": [
      "Yimin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Timing Li",
      "Shaoquan Tan",
      "Zongchao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2110.06864",
    "title": "ByteTrack: Multi-Object Tracking by Associating Every Detection Box",
    "abstract": " Title: ByteTrack: Multi-Object Tracking by Associating Every Detection Box ",
    "url": "https://arxiv.org/abs/2110.06864",
    "authors": [
      "Yifu Zhang",
      "Peize Sun",
      "Yi Jiang",
      "Dongdong Yu",
      "Fucheng Weng",
      "Zehuan Yuan",
      "Ping Luo",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.05113",
    "title": "Membership Inference Attacks Against Self-supervised Speech Models",
    "abstract": " Comments: Submitted to Interspeech 2022. Code will be available in the future ",
    "url": "https://arxiv.org/abs/2111.05113",
    "authors": [
      "Wei-Cheng Tseng",
      "Wei-Tsung Kao",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.08853",
    "title": "NNSynth: Neural Network Guided Abstraction-Based Controller Synthesis  for Stochastic Systems",
    "abstract": " Title: NNSynth: Neural Network Guided Abstraction-Based Controller Synthesis  for Stochastic Systems ",
    "url": "https://arxiv.org/abs/2111.08853",
    "authors": [
      "Xiaowu Sun",
      "Yasser Shoukry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2111.14507",
    "title": "SPIN: Simplifying Polar Invariance for Neural networks Application to  vision-based irradiance forecasting",
    "abstract": " Comments: CVPR 2022 - OmniCV workshop (oral) ",
    "url": "https://arxiv.org/abs/2111.14507",
    "authors": [
      "Quentin Paletta",
      "Anthony Hu",
      "Guillaume Arbod",
      "Philippe Blanc",
      "Joan Lasenby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01967",
    "title": "IRShield: A Countermeasure Against Adversarial Physical-Layer Wireless  Sensing",
    "abstract": " Title: IRShield: A Countermeasure Against Adversarial Physical-Layer Wireless  Sensing ",
    "url": "https://arxiv.org/abs/2112.01967",
    "authors": [
      "Paul Staat",
      "Simon Mulzer",
      "Stefan Roth",
      "Veelasha Moonsamy",
      "Markus Heinrichs",
      "Rainer Kronberger",
      "Aydin Sezgin",
      "Christof Paar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.03288",
    "title": "Dense Depth Priors for Neural Radiance Fields from Sparse Input Views",
    "abstract": " Comments: CVPR 2022, project page: this https URL , video: this https URL ",
    "url": "https://arxiv.org/abs/2112.03288",
    "authors": [
      "Barbara Roessle",
      "Jonathan T. Barron",
      "Ben Mildenhall",
      "Pratul P. Srinivasan",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.07116",
    "title": "Robust Computation Tree Logic",
    "abstract": " Comments: 23 pages, 1 figure, to be published in the proceedings of NASA Formal Methods (NFM), 2022 ",
    "url": "https://arxiv.org/abs/2201.07116",
    "authors": [
      "Satya Prakash Nayak",
      "Daniel Neider",
      "Rajarshi Roy",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2201.07537",
    "title": "Graph Neural Network-based Android Malware Classification with Jumping  Knowledge",
    "abstract": " Comments: will appear in IEEE Conference on Dependable and Secure Computing 2022 ",
    "url": "https://arxiv.org/abs/2201.07537",
    "authors": [
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Mohanad Sarhan",
      "Marcus Gallagher",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06934",
    "title": "Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection",
    "abstract": " Comments: Submitted to ICIP 2022, 5 pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2202.06934",
    "authors": [
      "Fatih Cagatay Akyon",
      "Sinan Onur Altinuc",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07073",
    "title": "Discriminability-enforcing loss to improve representation learning",
    "abstract": " Comments: Accepted in CVPR Workshops ",
    "url": "https://arxiv.org/abs/2202.07073",
    "authors": [
      "Florinel-Alin Croitoru",
      "Diana-Nicoleta Grigore",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08712",
    "title": "Mining On Alzheimer's Diseases Related Knowledge Graph to Identity  Potential AD-related Semantic Triples for Drug Repurposing",
    "abstract": " Comments: Submitted to the BMC Bioinformatics ",
    "url": "https://arxiv.org/abs/2202.08712",
    "authors": [
      "Yi Nian",
      "Xinyue Hu",
      "Rui Zhang",
      "Jingna Feng",
      "Jingcheng Du",
      "Fang Li",
      "Yong Chen",
      "Cui Tao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.03605",
    "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "abstract": " Title: DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection ",
    "url": "https://arxiv.org/abs/2203.03605",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Shilong Liu",
      "Lei Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06416",
    "title": "Concentration Network for Reinforcement Learning of Large-Scale  Multi-Agent Systems",
    "abstract": " Comments: AAAI-2022 ",
    "url": "https://arxiv.org/abs/2203.06416",
    "authors": [
      "Qingxu Fu",
      "Tenghai Qiu",
      "Jianqiang Yi",
      "Zhiqiang Pu",
      "Shiguang Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2203.12273",
    "title": "DAN: a Segmentation-free Document Attention Network for Handwritten  Document Recognition",
    "abstract": " Title: DAN: a Segmentation-free Document Attention Network for Handwritten  Document Recognition ",
    "url": "https://arxiv.org/abs/2203.12273",
    "authors": [
      "Denis Coquenet",
      "Cl\u00e9ment Chatelain",
      "Thierry Paquet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15937",
    "title": "Improving Mispronunciation Detection with Wav2vec2-based Momentum  Pseudo-Labeling for Accentedness and Intelligibility Assessment",
    "abstract": " Comments: Submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.15937",
    "authors": [
      "Mu Yang",
      "Kevin Hirschi",
      "Stephen D. Looney",
      "Okim Kang",
      "John H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16063",
    "title": "Pay Attention to Hidden States for Video Deblurring: Ping-Pong Recurrent  Neural Networks and Selective Non-Local Attention",
    "abstract": " Comments: also attached the supplementary material ",
    "url": "https://arxiv.org/abs/2203.16063",
    "authors": [
      "JoonKyu Park",
      "Seungjun Nah",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16995",
    "title": "Message Passing Neural Networks for Hypergraphs",
    "abstract": " Title: Message Passing Neural Networks for Hypergraphs ",
    "url": "https://arxiv.org/abs/2203.16995",
    "authors": [
      "Sajjad Heydari",
      "Lorenzo Livi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.00762",
    "title": "Do learned representations respect causal relationships?",
    "abstract": " Title: Do learned representations respect causal relationships? ",
    "url": "https://arxiv.org/abs/2204.00762",
    "authors": [
      "Lan Wang",
      "Vishnu Naresh Boddeti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.00790",
    "title": "SAD: A Large-scale Dataset towards Airport Detection in Synthetic  Aperture Radar Images",
    "abstract": " Title: SAD: A Large-scale Dataset towards Airport Detection in Synthetic  Aperture Radar Images ",
    "url": "https://arxiv.org/abs/2204.00790",
    "authors": [
      "Daochang Wang",
      "Fan Zhang",
      "Fei Ma",
      "Wei Hu",
      "Yu Tang",
      "Yongsheng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.00840",
    "title": "Rotated Object Detection via Scale-invariant Mahalanobis Distance in  Aerial Images",
    "abstract": " Comments: 5 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2204.00840",
    "authors": [
      "Siyang Wen",
      "Wei Guo",
      "Yi Liu",
      "Ruijie Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.01303",
    "title": "GraFN: Semi-Supervised Node Classification on Graph with Few Labels via  Non-Parametric Distribution Assignment",
    "abstract": " Comments: SIGIR 2022(Short Paper) ",
    "url": "https://arxiv.org/abs/2204.01303",
    "authors": [
      "Junseok Lee",
      "Yunhak Oh",
      "Yeonjun In",
      "Namkyeong Lee",
      "Dongmin Hyun",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.01543",
    "title": "Causality, Causal Discovery, and Causal Inference in Structural  Engineering",
    "abstract": " Title: Causality, Causal Discovery, and Causal Inference in Structural  Engineering ",
    "url": "https://arxiv.org/abs/2204.01543",
    "authors": [
      "M.Z. Naser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2204.02128",
    "title": "Computing in Anonymous Dynamic Networks Is Linear",
    "abstract": " Comments: 31 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2204.02128",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  }
]