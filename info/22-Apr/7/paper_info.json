[
  {
    "id": "arXiv:2204.02399",
    "title": "Multi-Modal Hypergraph Diffusion Network with Dual Prior for Alzheimer  Classification",
    "abstract": "The automatic early diagnosis of prodromal stages of Alzheimer's disease is of great relevance for patient treatment to improve quality of life. We address this problem as a multi-modal classification task. Multi-modal data provides richer and complementary information. However, existing techniques only consider either lower order relations between the data and single/multi-modal imaging data. In this work, we introduce a novel semi-supervised hypergraph learning framework for Alzheimer's disease diagnosis. Our framework allows for higher-order relations among multi-modal imaging and non-imaging data whilst requiring a tiny labelled set. Firstly, we introduce a dual embedding strategy for constructing a robust hypergraph that preserves the data semantics. We achieve this by enforcing perturbation invariance at the image and graph levels using a contrastive based mechanism. Secondly, we present a dynamically adjusted hypergraph diffusion model, via a semi-explicit flow, to improve the predictive uncertainty. We demonstrate, through our experiments, that our framework is able to outperform current techniques for Alzheimer's disease diagnosis. ",
    "url": "https://arxiv.org/abs/2204.02399",
    "authors": [
      "Angelica I. Aviles-Rivero",
      "Christina Runkel",
      "Nicolas Papadakis",
      "Zoe Kourtzi",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.02402",
    "title": "Comment on \"Black Box Prediction Methods in Sports Medicine Deserve a  Red Card for Reckless Practice: A Change of Tactics is Needed to Advance  Athlete Care\"",
    "abstract": "In this paper we examine the claims made by Bullock et. al. on the applicability of black-box injury risk approaches in the sports injury domain. Overall, we agree that transparency is necessary for Machine Learning models to be useful in this field. However, there are areas of research that address precisely the concerns of the authors and strongly temper their conclusions. In the following we look at how these issues are being tackled by the Machine Learning community. ",
    "url": "https://arxiv.org/abs/2204.02402",
    "authors": [
      "Jakim Berndsen",
      "Derek McHugh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02441",
    "title": "Imaging Conductivity from Current Density Magnitude using Neural  Networks",
    "abstract": "Conductivity imaging represents one of the most important tasks in medical imaging. In this work we develop a neural network based reconstruction technique for imaging the conductivity from the magnitude of the internal current density. It is achieved by formulating the problem as a relaxed weighted least-gradient problem, and then approximating its minimizer by standard fully connected feedforward neural networks. We derive bounds on two components of the generalization error, i.e., approximation error and statistical error, explicitly in terms of properties of the neural networks (e.g., depth, total number of parameters, and the bound of the network parameters). We illustrate the performance and distinct features of the approach on several numerical experiments. Numerically, it is observed that the approach enjoys remarkable robustness with respect to the presence of data noise. ",
    "url": "https://arxiv.org/abs/2204.02441",
    "authors": [
      "Bangti Jin",
      "Xiyao Li",
      "Xiliang Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.02446",
    "title": "Detecting Cloud-Based Phishing Attacks by Combining Deep Learning Models",
    "abstract": "Web-based phishing attacks nowadays exploit popular cloud web hosting services and apps such as Google Sites and Typeform for hosting their attacks. Since these attacks originate from reputable domains and IP addresses of the cloud services, traditional phishing detection methods such as IP reputation monitoring and blacklisting are not very effective. Here we investigate the effectiveness of deep learning models in detecting this class of cloud-based phishing attacks. Specifically, we evaluate deep learning models for three phishing detection methods--LSTM model for URL analysis, YOLOv2 model for logo analysis, and triplet network model for visual similarity analysis. We train the models using well-known datasets and test their performance on phishing attacks in the wild. Our results qualitatively explain why the models succeed or fail. Furthermore, our results highlight how combining results from the individual models can improve the effectiveness of detecting cloud-based phishing attacks. ",
    "url": "https://arxiv.org/abs/2204.02446",
    "authors": [
      "Medha Atre",
      "Birendra Jha",
      "Ashwini Rao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02455",
    "title": "Improving Voice Trigger Detection with Metric Learning",
    "abstract": "Voice trigger detection is an important task, which enables activating a voice assistant when a target user speaks a keyword phrase. A detector is typically trained on speech data independent of speaker information and used for the voice trigger detection task. However, such a speaker independent voice trigger detector typically suffers from performance degradation on speech from underrepresented groups, such as accented speakers. In this work, we propose a novel voice trigger detector that can use a small number of utterances from a target speaker to improve detection accuracy. Our proposed model employs an encoder-decoder architecture. While the encoder performs speaker independent voice trigger detection, similar to the conventional detector, the decoder predicts a personalized embedding for each utterance. A personalized voice trigger score is then obtained as a similarity score between the embeddings of enrollment utterances and a test utterance. The personalized embedding allows adapting to target speaker's speech when computing the voice trigger score, hence improving voice trigger detection accuracy. Experimental results show that the proposed approach achieves a 38% relative reduction in a false rejection rate (FRR) compared to a baseline speaker independent voice trigger model. ",
    "url": "https://arxiv.org/abs/2204.02455",
    "authors": [
      "Prateeth Nayak",
      "Takuya Higuchi",
      "Anmol Gupta",
      "Shivesh Ranjan",
      "Stephen Shum",
      "Siddharth Sigtia",
      "Erik Marchi",
      "Varun Lakshminarasimhan",
      "Minsik Cho",
      "Saurabh Adya",
      "Chandra Dhir",
      "Ahmed Tewfik"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02458",
    "title": "Robust Active Visual Perching with Quadrotors on Inclined Surfaces",
    "abstract": "Autonomous Micro Aerial Vehicles are deployed for a variety tasks including surveillance and monitoring. Perching and staring allow the vehicle to monitor targets without flying, saving battery power and increasing the overall mission time without the need to frequently replace batteries. This paper addresses the Active Visual Perching (AVP) control problem to autonomously perch on inclined surfaces up to $90^\\circ$. Our approach generates dynamically feasible trajectories to navigate and perch on a desired target location, while taking into account actuator and Field of View (FoV) constraints. By replanning in mid-flight, we take advantage of more accurate target localization increasing the perching maneuver's robustness to target localization or control errors. We leverage the Karush-Kuhn-Tucker (KKT) conditions to identify the compatibility between planning objectives and the visual sensing constraint during the planned maneuver. Furthermore, we experimentally identify the corresponding boundary conditions that maximizes the spatio-temporal target visibility during the perching maneuver. The proposed approach works on-board in real-time with significant computational constraints relying exclusively on cameras and an Inertial Measurement Unit (IMU). Experimental results validate the proposed approach and shows the higher success rate as well as increased target interception precision and accuracy with respect to a one-shot planning approach, while still retaining aggressive capabilities with flight envelopes that include large excursions from the hover position on inclined surfaces up to 90$^\\circ$, angular speeds up to 750~deg/s, and accelerations up to 10~m/s$^2$. ",
    "url": "https://arxiv.org/abs/2204.02458",
    "authors": [
      "Jeffrey Mao",
      "Stephen Nogar",
      "Christopher Kroninger",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.02461",
    "title": "Less is More: Fairness in Wide-Area Proof-of-Work Blockchain Networks",
    "abstract": "Blockchain is rapidly emerging as an important class of network application, with a unique set of trust, security and transparency properties. In a blockchain system, participants record and update the `server-side' state of an application as blocks of a replicated, immutable ledger using a consensus protocol over the Internet. Mining blocks has become lucrative in recent years; e.g., a miner receives over USD 200,000 per mined block in Bitcoin today. A key factor affecting mining rewards, is the latency of broadcasting blocks over the network. In this paper, we consider the problem of topology design for optimizing mining rewards in a wide-area blockchain network that uses a Proof-of-Work protocol for consensus. Contrary to general wisdom that a faster network is always better for miners, we show a counter intuitive result where a slower network is actually beneficial to some miners. This is because competing miners must choose neighbors that not only decrease their own latency to others, but also ensure that the latency between other miners do not decrease because of itself. We formalize this problem, and provide both theoretical analysis and experimental results to support our claim. ",
    "url": "https://arxiv.org/abs/2204.02461",
    "authors": [
      "Yifan Mao",
      "Shaileshh Bojja Venkatakrishnan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.02470",
    "title": "Combining Spectral and Self-Supervised Features for Low Resource Speech  Recognition and Translation",
    "abstract": "Self-Supervised Learning (SSL) models have been successfully applied in various deep learning-based speech tasks, particularly those with a limited amount of data. However, the quality of SSL representations depends highly on the relatedness between the SSL training domain(s) and the target data domain. On the contrary, spectral feature (SF) extractors such as log Mel-filterbanks are hand-crafted non-learnable components, and could be more robust to domain shifts. The present work examines the assumption that combining non-learnable SF extractors to SSL models is an effective approach to low resource speech tasks. We propose a learnable and interpretable framework to combine SF and SSL representations. The proposed framework outperforms significantly both baseline and SSL models on Automatic Speech Recognition (ASR) and Speech Translation (ST) tasks on three low resource datasets. We additionally design a mixture of experts based combination model. This last model reveals that the relative contribution of SSL models over conventional SF extractors is very small in case of domain mismatch between SSL training set and the target language data. ",
    "url": "https://arxiv.org/abs/2204.02470",
    "authors": [
      "Dan Berrebbi",
      "Jiatong Shi",
      "Brian Yan",
      "Osbel Lopez-Francisco",
      "Jonathan D. Amith",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02481",
    "title": "Adversarial Robustness through the Lens of Convolutional Filters",
    "abstract": "Deep learning models are intrinsically sensitive to distribution shifts in the input data. In particular, small, barely perceivable perturbations to the input data can force models to make wrong predictions with high confidence. An common defense mechanism is regularization through adversarial training which injects worst-case perturbations back into training to strengthen the decision boundaries, and to reduce overfitting. In this context, we perform an investigation of 3x3 convolution filters that form in adversarially-trained models. Filters are extracted from 71 public models of the linf-RobustBench CIFAR-10/100 and ImageNet1k leaderboard and compared to filters extracted from models built on the same architectures but trained without robust regularization. We observe that adversarially-robust models appear to form more diverse, less sparse, and more orthogonal convolution filters than their normal counterparts. The largest differences between robust and normal models are found in the deepest layers, and the very first convolution layer, which consistently and predominantly forms filters that can partially eliminate perturbations, irrespective of the architecture. Data & Project website: https://github.com/paulgavrikov/cvpr22w_RobustnessThroughTheLens ",
    "url": "https://arxiv.org/abs/2204.02481",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02482",
    "title": "PDNPulse: Sensing PCB Anomaly with the Intrinsic Power Delivery Network",
    "abstract": "The ubiquitous presence of printed circuit boards (PCBs) in modern electronic systems and embedded devices makes their integrity a top security concern. To take advantage of the economies of scale, today's PCB design and manufacturing are often performed by suppliers around the globe, exposing them to many security vulnerabilities along the segmented PCB supply chain. Moreover, the increasing complexity of the PCB designs also leaves ample room for numerous sneaky board-level attacks to be implemented throughout each stage of a PCB's lifetime, threatening many electronic devices. In this paper, we propose PDNPulse, a power delivery network (PDN) based PCB anomaly detection framework that can identify a wide spectrum of board-level malicious modifications. PDNPulse leverages the fact that the PDN's characteristics are inevitably affected by modifications to the PCB, no matter how minuscule. By detecting changes to the PDN impedance profile and using the Frechet distance-based anomaly detection algorithms, PDNPulse can robustly and successfully discern malicious modifications across the system. Using PDNPulse, we conduct extensive experiments on seven commercial-off-the-shelf PCBs, covering different design scales, different threat models, and seven different anomaly types. The results confirm that PDNPulse creates an effective security asymmetry between attack and defense. ",
    "url": "https://arxiv.org/abs/2204.02482",
    "authors": [
      "Huifeng Zhu",
      "Haoqi Shan",
      "Dean Sullivan",
      "Xiaolong Guo",
      "Yier Jin",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2204.02485",
    "title": "Training-Free Robust Multimodal Learning via Sample-Wise Jacobian  Regularization",
    "abstract": "Multimodal fusion emerges as an appealing technique to improve model performances on many tasks. Nevertheless, the robustness of such fusion methods is rarely involved in the present literature. In this paper, we propose a training-free robust late-fusion method by exploiting conditional independence assumption and Jacobian regularization. Our key is to minimize the Frobenius norm of a Jacobian matrix, where the resulting optimization problem is relaxed to a tractable Sylvester equation. Furthermore, we provide a theoretical error bound of our method and some insights about the function of the extra modality. Several numerical experiments on AV-MNIST, RAVDESS, and VGGsound demonstrate the efficacy of our method under both adversarial attacks and random corruptions. ",
    "url": "https://arxiv.org/abs/2204.02485",
    "authors": [
      "Zhengqi Gao",
      "Sucheng Ren",
      "Zihui Xue",
      "Siting Li",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02488",
    "title": "Discovering and forecasting extreme events via active learning in neural  operators",
    "abstract": "Extreme events in society and nature, such as pandemic spikes or rogue waves, can have catastrophic consequences. Characterizing extremes is difficult as they occur rarely, arise from seemingly benign conditions, and belong to complex and often unknown infinite-dimensional systems. Such challenges render attempts at characterizing them as moot. We address each of these difficulties by combining novel training schemes in Bayesian experimental design (BED) with an ensemble of deep neural operators (DNOs). This model-agnostic framework pairs a BED scheme that actively selects data for quantifying extreme events with an ensemble of DNOs that approximate infinite-dimensional nonlinear operators. We find that not only does this framework clearly beat Gaussian processes (GPs) but that 1) shallow ensembles of just two members perform best; 2) extremes are uncovered regardless of the state of initial data (i.e. with or without extremes); 3) our method eliminates \"double-descent\" phenomena; 4) the use of batches of suboptimal acquisition points compared to step-by-step global optima does not hinder BED performance; and 5) Monte Carlo acquisition outperforms standard minimizers in high-dimensions. Together these conclusions form the foundation of an AI-assisted experimental infrastructure that can efficiently infer and pinpoint critical situations across many domains, from physical to societal systems. ",
    "url": "https://arxiv.org/abs/2204.02488",
    "authors": [
      "Ethan Pickering",
      "George Em Karniadakis",
      "Themistoklis P. Sapsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.02494",
    "title": "Leveraging Disentangled Representations to Improve Vision-Based  Keystroke Inference Attacks Under Low Data",
    "abstract": "Keystroke inference attacks are a form of side-channel attacks in which an attacker leverages various techniques to recover a user's keystrokes as she inputs information into some display (e.g., while sending a text message or entering her pin). Typically, these attacks leverage machine learning approaches, but assessing the realism of the threat space has lagged behind the pace of machine learning advancements, due in-part, to the challenges in curating large real-life datasets. We aim to overcome the challenge of having limited number of real data by introducing a video domain adaptation technique that is able to leverage synthetic data through supervised disentangled learning. Specifically, for a given domain, we decompose the observed data into two factors of variation: Style and Content. Doing so provides four learned representations: real-life style, synthetic style, real-life content and synthetic content. Then, we combine them into feature representations from all combinations of style-content pairings across domains, and train a model on these combined representations to classify the content (i.e., labels) of a given datapoint in the style of another domain. We evaluate our method on real-life data using a variety of metrics to quantify the amount of information an attacker is able to recover. We show that our method prevents our model from overfitting to a small real-life training set, indicating that our method is an effective form of data augmentation, thereby making keystroke inference attacks more practical. ",
    "url": "https://arxiv.org/abs/2204.02494",
    "authors": [
      "John Lim",
      "Jan-Michael Frahm",
      "Fabian Monrose"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.02500",
    "title": "User-Level Differential Privacy against Attribute Inference Attack of  Speech Emotion Recognition in Federated Learning",
    "abstract": "Many existing privacy-enhanced speech emotion recognition (SER) frameworks focus on perturbing the original speech data through adversarial training within a centralized machine learning setup. However, this privacy protection scheme can fail since the adversary can still access the perturbed data. In recent years, distributed learning algorithms, especially federated learning (FL), have gained popularity to protect privacy in machine learning applications. While FL provides good intuition to safeguard privacy by keeping the data on local devices, prior work has shown that privacy attacks, such as attribute inference attacks, are achievable for SER systems trained using FL. In this work, we propose to evaluate the user-level differential privacy (UDP) in mitigating the privacy leaks of the SER system in FL. UDP provides theoretical privacy guarantees with privacy parameters $\\epsilon$ and $\\delta$. Our results show that the UDP can effectively decrease attribute information leakage while keeping the utility of the SER system with the adversary accessing one model update. However, the efficacy of the UDP suffers when the FL system leaks more model updates to the adversary. We make the code publicly available to reproduce the results in https://github.com/usc-sail/fed-ser-leakage. ",
    "url": "https://arxiv.org/abs/2204.02500",
    "authors": [
      "Tiantian Feng",
      "Raghuveer Peri",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02525",
    "title": "Mars: Near-Optimal Throughput with Shallow Buffers in Reconfigurable  Datacenter Networks",
    "abstract": "The performance of large-scale computing systems often critically depends on high-performance communication networks. Dynamically reconfigurable topologies, e.g., based on optical circuit switches, are emerging as an innovative new technology to deal with the explosive growth of datacenter traffic. Specifically, periodic reconfigurable datacenter networks (RDCNs) such as RotorNet (SIGCOMM 2017), Opera (NSDI 2020) and Sirius (SIGCOMM 2020) have been shown to provide high throughput, by emulating a complete graph through fast periodic circuit switch scheduling. However, to achieve such a high throughput, existing reconfigurable network designs pay a high price: in terms of potentially high delays, but also, as we show as a first contribution in this paper, in terms of the high buffer requirements. In particular, we show that under buffer constraints, emulating the high-throughput complete-graph is infeasible at scale, and we uncover a spectrum of unvisited and attractive alternative RDCNs, which emulate regular graphs of lower node degree. We present Mars, a periodic reconfigurable topology which emulates a $d$-regular graph with near-optimal throughput. In particular, we systematically analyze how the degree $d$ can be optimized for throughput given the available buffer and delay tolerance of the datacenter. ",
    "url": "https://arxiv.org/abs/2204.02525",
    "authors": [
      "Vamsi Addanki",
      "Chen Avin",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.02538",
    "title": "IoT-Scan: Network Reconnaissance for the Internet of Things",
    "abstract": "Network reconnaissance is a core networking and security procedure aimed at discovering devices and their properties. For IP-based networks, several network reconnaissance tools are available, such as Nmap. For the Internet of Things (IoT), there is currently no similar tool capable of discovering devices across multiple protocols. In this paper, we present IoT-Scan, a universal IoT network reconnaissance tool. IoT-Scan is based on software defined radio (SDR) technology, which allows for a flexible software-based implementation of radio protocols. We present a series of passive, active, multi-channel, and multi-protocol scanning algorithms to speed up the discovery of devices with IoT-Scan. We benchmark the passive scanning algorithms against a theoretical traffic model based on the non-uniform coupon collector problem. We implement the scanning algorithms and compare their performance for four popular IoT protocols: Zigbee, Bluetooth LE, Z-Wave, and LoRa. Through extensive experiments with dozens of IoT devices, we demonstrate that our implementation experiences minimal packet losses and achieves performance near the theoretical benchmark. Using multi-protocol scanning, we further demonstrate a reduction of 70\\% in the discovery times of Bluetooth and Zigbee devices in the 2.4\\,GHz band and of LoRa and Z-Wave devices in the 900\\,MHz band, compared to sequential passive scanning. We make our implementation and data available to the research community to allow independent replication of our results and facilitate further development of the tool. ",
    "url": "https://arxiv.org/abs/2204.02538",
    "authors": [
      "Stefan Gvozdenovic",
      "Johannes K Becker",
      "John Mikulskis",
      "David Starobinski"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.02549",
    "title": "C3KG: A Chinese Commonsense Conversation Knowledge Graph",
    "abstract": "Existing commonsense knowledge bases often organize tuples in an isolated manner, which is deficient for commonsense conversational models to plan the next steps. To fill the gap, we curate a large-scale multi-turn human-written conversation corpus, and create the first Chinese commonsense conversation knowledge graph which incorporates both social commonsense knowledge and dialog flow information. To show the potential of our graph, we develop a graph-conversation matching approach, and benchmark two graph-grounded conversational tasks. ",
    "url": "https://arxiv.org/abs/2204.02549",
    "authors": [
      "Dawei Li",
      "Yanran Li",
      "Jiayi Zhang",
      "Ke Li",
      "Chen Wei",
      "Jianwei Cui",
      "Bin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.02553",
    "title": "RODD: A Self-Supervised Approach for Robust Out-of-Distribution  Detection",
    "abstract": "Recent studies have addressed the concern of detecting and rejecting the out-of-distribution (OOD) samples as a major challenge in the safe deployment of deep learning (DL) models. It is desired that the DL model should only be confident about the in-distribution (ID) data which reinforces the driving principle of the OOD detection. In this paper, we propose a simple yet effective generalized OOD detection method independent of out-of-distribution datasets. Our approach relies on self-supervised feature learning of the training samples, where the embeddings lie on a compact low-dimensional space. Motivated by the recent studies that show self-supervised adversarial contrastive learning helps robustify the model, we empirically show that a pre-trained model with self-supervised contrastive learning yields a better model for uni-dimensional feature learning in the latent space. The method proposed in this work referred to as \\texttt{RODD}, outperforms SOTA detection performance on an extensive suite of benchmark datasets on OOD detection tasks. On the CIFAR-100 benchmarks, \\texttt{RODD} achieves a 26.97 $\\%$ lower false-positive rate (FPR@95) compared to SOTA methods. ",
    "url": "https://arxiv.org/abs/2204.02553",
    "authors": [
      "Umar Khalid",
      "Ashkan Esmaeili",
      "Nazmul Karim",
      "Nazanin Rahnavard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02566",
    "title": "Modeling Temporal-Modal Entity Graph for Procedural Multimodal Machine  Comprehension",
    "abstract": "Procedural Multimodal Documents (PMDs) organize textual instructions and corresponding images step by step. Comprehending PMDs and inducing their representations for the downstream reasoning tasks is designated as Procedural MultiModal Machine Comprehension (M3C). In this study, we approach Procedural M3C at a fine-grained level (compared with existing explorations at a document or sentence level), that is, entity. With delicate consideration, we model entity both in its temporal and cross-modal relation and propose a novel Temporal-Modal Entity Graph (TMEG). Specifically, graph structure is formulated to capture textual and visual entities and trace their temporal-modal evolution. In addition, a graph aggregation module is introduced to conduct graph encoding and reasoning. Comprehensive experiments across three Procedural M3C tasks are conducted on a traditional dataset RecipeQA and our new dataset CraftQA, which can better evaluate the generalization of TMEG. ",
    "url": "https://arxiv.org/abs/2204.02566",
    "authors": [
      "Huibin Zhang",
      "Zhengkun Zhang",
      "Yao Zhang",
      "Jun Wang",
      "Yufan Li",
      "Ning jiang",
      "Xin wei",
      "Zhenglu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2204.02567",
    "title": "FairNeuron: Improving Deep Neural Network Fairness with Adversary Games  on Selective Neurons",
    "abstract": "With Deep Neural Network (DNN) being integrated into a growing number of critical systems with far-reaching impacts on society, there are increasing concerns on their ethical performance, such as fairness. Unfortunately, model fairness and accuracy in many cases are contradictory goals to optimize. To solve this issue, there has been a number of work trying to improve model fairness by using an adversarial game in model level. This approach introduces an adversary that evaluates the fairness of a model besides its prediction accuracy on the main task, and performs joint-optimization to achieve a balanced result. In this paper, we noticed that when performing backward propagation based training, such contradictory phenomenon has shown on individual neuron level. Based on this observation, we propose FairNeuron, a DNN model automatic repairing tool, to mitigate fairness concerns and balance the accuracy-fairness trade-off without introducing another model. It works on detecting neurons with contradictory optimization directions from accuracy and fairness training goals, and achieving a trade-off by selective dropout. Comparing with state-of-the-art methods, our approach is lightweight, making it scalable and more efficient. Our evaluation on 3 datasets shows that FairNeuron can effectively improve all models' fairness while maintaining a stable utility. ",
    "url": "https://arxiv.org/abs/2204.02567",
    "authors": [
      "Xuanqi Gao",
      "Juan Zhai",
      "Shiqing Ma",
      "Chao Shen",
      "Yufei Chen",
      "Qian Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.02581",
    "title": "Banana Sub-Family Classification and Quality Prediction using Computer  Vision",
    "abstract": "India is the second largest producer of fruits and vegetables in the world, and one of the largest consumers of fruits like Banana, Papaya and Mangoes through retail and ecommerce giants like BigBasket, Grofers and Amazon Fresh. However, adoption of technology in supply chain and retail stores is still low and there is a great potential to adopt computer-vision based technology for identification and classification of fruits. We have chosen banana fruit to build a computer vision based model to carry out the following three use-cases (a) Identify Banana from a given image (b) Determine sub-family or variety of Banana (c) Determine the quality of Banana. Successful execution of these use-cases using computer-vision model would greatly help with overall inventory management automation, quality control, quick and efficient weighing and billing which all are manual labor intensive currently. In this work, we suggest a machine learning pipeline that combines the ideas of CNNs, transfer learning, and data augmentation towards improving Banana fruit sub family and quality image classification. We have built a basic CNN and then went on to tune a MobileNet Banana classification model using a combination of self-curated and publicly-available dataset of 3064 images. The results show an overall 93.4% and 100% accuracy for sub-family/variety and for quality test classifications respectively. ",
    "url": "https://arxiv.org/abs/2204.02581",
    "authors": [
      "Narayana Darapaneni",
      "Arjun Tanndalam",
      "Mohit Gupta",
      "Neeta Taneja",
      "Prabu Purushothaman",
      "Swati Eswar",
      "Anwesh Reddy Paduri",
      "Thangaselvi Arichandrapandian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.02597",
    "title": "Fine-Grained Predicates Learning for Scene Graph Generation",
    "abstract": "The performance of current Scene Graph Generation models is severely hampered by some hard-to-distinguish predicates, e.g., \"woman-on/standing on/walking on-beach\" or \"woman-near/looking at/in front of-child\". While general SGG models are prone to predict head predicates and existing re-balancing strategies prefer tail categories, none of them can appropriately handle these hard-to-distinguish predicates. To tackle this issue, inspired by fine-grained image classification, which focuses on differentiating among hard-to-distinguish object classes, we propose a method named Fine-Grained Predicates Learning (FGPL) which aims at differentiating among hard-to-distinguish predicates for Scene Graph Generation task. Specifically, we first introduce a Predicate Lattice that helps SGG models to figure out fine-grained predicate pairs. Then, utilizing the Predicate Lattice, we propose a Category Discriminating Loss and an Entity Discriminating Loss, which both contribute to distinguishing fine-grained predicates while maintaining learned discriminatory power over recognizable ones. The proposed model-agnostic strategy significantly boosts the performances of three benchmark models (Transformer, VCTree, and Motif) by 22.8\\%, 24.1\\% and 21.7\\% of Mean Recall (mR@100) on the Predicate Classification sub-task, respectively. Our model also outperforms state-of-the-art methods by a large margin (i.e., 6.1\\%, 4.6\\%, and 3.2\\% of Mean Recall (mR@100)) on the Visual Genome dataset. ",
    "url": "https://arxiv.org/abs/2204.02597",
    "authors": [
      "Xinyu Lyu",
      "Lianli Gao",
      "Yuyu Guo",
      "Zhou Zhao",
      "Hao Huang",
      "Heng Tao Shen",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02602",
    "title": "Distributed Transition Systems with Tags for Privacy Analysis",
    "abstract": "We present a logical framework that formally models how a given private information P stored on a given database D, can get captured progressively, by an agent/adversary querying the database repeatedly.Named DLTTS (Distributed Labeled Tagged Transition System), the frame-work borrows ideas from several domains: Probabilistic Automata of Segala, Probabilistic Concurrent Systems, and Probabilistic labelled transition systems. To every node on a DLTTS is attached a tag that represents the 'current' knowledge of the adversary, acquired from the responses of the answering mechanism of the DBMS to his/her queries, at the nodes traversed earlier, along any given run; this knowledge is completed at the same node, with further relational deductions, possibly in combination with 'public' information from other databases given in advance. A 'blackbox' mechanism is also part of a DLTTS, and it is meant as an oracle; its role is to tell if the private information has been deduced by the adversary at the current node, and if so terminate the run. An additional special feature is that the blackbox also gives information on how 'close',or how 'far', the knowledge of the adversary is, from the private information P , at the current node. A metric is defined for that purpose, on the set of all 'type compatible' tuples from the given database, the data themselves being typed with the headers of the base. Despite the transition systems flavor of our framework, this metric is not 'behavioral' in the sense presented in some other works. It is exclusively database oriented,and allows to define new notions of adjacency and of -indistinguishabilty between databases, more generally than those usually based on the Hamming metric (and a restricted notion of adjacency). Examples are given all along to illustrate how our framework works. Keywords:Database, Privacy, Transition System, Probability, Distribution. ",
    "url": "https://arxiv.org/abs/2204.02602",
    "authors": [
      "Siva Anantharaman",
      "Sabine Frittella",
      "Benjamin Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.02604",
    "title": "Interactive Evolutionary Multi-Objective Optimization via  Learning-to-Rank",
    "abstract": "In practical multi-criterion decision-making, it is cumbersome if a decision maker (DM) is asked to choose among a set of trade-off alternatives covering the whole Pareto-optimal front. This is a paradox in conventional evolutionary multi-objective optimization (EMO) that always aim to achieve a well balance between convergence and diversity. In essence, the ultimate goal of multi-objective optimization is to help a decision maker (DM) identify solution(s) of interest (SOI) achieving satisfactory trade-offs among multiple conflicting criteria. Bearing this in mind, this paper develops a framework for designing preference-based EMO algorithms to find SOI in an interactive manner. Its core idea is to involve human in the loop of EMO. After every several iterations, the DM is invited to elicit her feedback with regard to a couple of incumbent candidates. By collecting such information, her preference is progressively learned by a learning-to-rank neural network and then applied to guide the baseline EMO algorithm. Note that this framework is so general that any existing EMO algorithm can be applied in a plug-in manner. Experiments on $48$ benchmark test problems with up to 10 objectives fully demonstrate the effectiveness of our proposed algorithms for finding SOI. ",
    "url": "https://arxiv.org/abs/2204.02604",
    "authors": [
      "Ke Li",
      "Guiyu Lai",
      "Xin Yao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.02620",
    "title": "Towards Robust Adaptive Object Detection under Noisy Annotations",
    "abstract": "Domain Adaptive Object Detection (DAOD) models a joint distribution of images and labels from an annotated source domain and learns a domain-invariant transformation to estimate the target labels with the given target domain images. Existing methods assume that the source domain labels are completely clean, yet large-scale datasets often contain error-prone annotations due to instance ambiguity, which may lead to a biased source distribution and severely degrade the performance of the domain adaptive detector de facto. In this paper, we represent the first effort to formulate noisy DAOD and propose a Noise Latent Transferability Exploration (NLTE) framework to address this issue. It is featured with 1) Potential Instance Mining (PIM), which leverages eligible proposals to recapture the miss-annotated instances from the background; 2) Morphable Graph Relation Module (MGRM), which models the adaptation feasibility and transition probability of noisy samples with relation matrices; 3) Entropy-Aware Gradient Reconcilement (EAGR), which incorporates the semantic information into the discrimination process and enforces the gradients provided by noisy and clean samples to be consistent towards learning domain-invariant representations. A thorough evaluation on benchmark DAOD datasets with noisy source annotations validates the effectiveness of NLTE. In particular, NLTE improves the mAP by 8.4\\% under 60\\% corrupted annotations and even approaches the ideal upper bound of training on a clean source dataset. ",
    "url": "https://arxiv.org/abs/2204.02620",
    "authors": [
      "Xinyu Liu",
      "Wuyang Li",
      "Qiushi Yang",
      "Baopu Li",
      "Yixuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02626",
    "title": "A Weakly Supervised Propagation Model for Rumor Verification and Stance  Detection with Multiple Instance Learning",
    "abstract": "The diffusion of rumors on microblogs generally follows a propagation tree structure, that provides valuable clues on how an original message is transmitted and responded by users over time. Recent studies reveal that rumor detection and stance detection are two different but relevant tasks which can jointly enhance each other, e.g., rumors can be debunked by cross-checking the stances conveyed by their relevant microblog posts, and stances are also conditioned on the nature of the rumor. However, most stance detection methods require enormous post-level stance labels for training, which are labor-intensive given a large number of posts. Enlightened by Multiple Instance Learning (MIL) scheme, we first represent the diffusion of claims with bottom-up and top-down trees, then propose two tree-structured weakly supervised frameworks to jointly classify rumors and stances, where only the bag-level labels concerning claim's veracity are needed. Specifically, we convert the multi-class problem into a multiple MIL-based binary classification problem where each binary model focuses on differentiating a target stance or rumor type and other types. Finally, we propose a hierarchical attention mechanism to aggregate the binary predictions, including (1) a bottom-up or top-down tree attention layer to aggregate binary stances into binary veracity; and (2) a discriminative attention layer to aggregate the binary class into finer-grained classes. Extensive experiments conducted on three Twitter-based datasets demonstrate promising performance of our model on both claim-level rumor detection and post-level stance classification compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.02626",
    "authors": [
      "Ruichao Yang",
      "Jing Ma",
      "Hongzhan Lin",
      "Wei Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.02633",
    "title": "DAGAM: Data Augmentation with Generation And Modification",
    "abstract": "Text classification is a representative downstream task of natural language processing, and has exhibited excellent performance since the advent of pre-trained language models based on Transformer architecture. However, in pre-trained language models, under-fitting often occurs due to the size of the model being very large compared to the amount of available training data. Along with significant importance of data collection in modern machine learning paradigm, studies have been actively conducted for natural language data augmentation. In light of this, we introduce three data augmentation schemes that help reduce underfitting problems of large-scale language models. Primarily we use a generation model for data augmentation, which is defined as Data Augmentation with Generation (DAG). Next, we augment data using text modification techniques such as corruption and word order change (Data Augmentation with Modification, DAM). Finally, we propose Data Augmentation with Generation And Modification (DAGAM), which combines DAG and DAM techniques for a boosted performance. We conduct data augmentation for six benchmark datasets of text classification task, and verify the usefulness of DAG, DAM, and DAGAM through BERT-based fine-tuning and evaluation, deriving better results compared to the performance with original datasets. ",
    "url": "https://arxiv.org/abs/2204.02633",
    "authors": [
      "Byeong-Cheol Jo",
      "Tak-Sung Heo",
      "Yeongjoon Park",
      "Yongmin Yoo",
      "Won Ik Cho",
      "Kyungsun Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.02650",
    "title": "Spatio-Temporal Dynamic Graph Relation Learning for Urban Metro Flow  Prediction",
    "abstract": "Urban metro flow prediction is of great value for metro operation scheduling, passenger flow management and personal travel planning. However, it faces two main challenges. First, different metro stations, e.g. transfer stations and non-transfer stations, have unique traffic patterns. Second, it is challenging to model complex spatio-temporal dynamic relation of metro stations. To address these challenges, we develop a spatio-temporal dynamic graph relational learning model (STDGRL) to predict urban metro station flow. First, we propose a spatio-temporal node embedding representation module to capture the traffic patterns of different stations. Second, we employ a dynamic graph relationship learning module to learn dynamic spatial relationships between metro stations without a predefined graph adjacency matrix. Finally, we provide a transformer-based long-term relationship prediction module for long-term metro flow prediction. Extensive experiments are conducted based on metro data in Beijing, Shanghai, Chongqing and Hangzhou. Experimental results show the advantages of our method beyond 11 baselines for urban metro flow prediction. ",
    "url": "https://arxiv.org/abs/2204.02650",
    "authors": [
      "Peng Xie",
      "Minbo Ma",
      "Tianrui Li",
      "Shenggong Ji",
      "Shengdong Du",
      "Zeng Yu",
      "Junbo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.02651",
    "title": "Scheduling Coflows for Minimizing the Total Weighted Completion Time in  Identical Parallel Networks",
    "abstract": "Coflow is a recently proposed network abstraction to capture communication patterns in data centers. The coflow scheduling problem in large data centers is one of the most important $NP$-hard problems. Previous research on coflow scheduling focused mainly on the single-switch model. However, with recent technological developments, this single-core model is no longer sufficient. This paper considers the coflow scheduling problem in identical parallel networks. The identical parallel network is an architecture based on multiple network cores running in parallel. Coflow can be considered as divisible or indivisible. Different flows in a divisible coflow can be transmitted through different network cores. Considering the divisible coflow scheduling problem, we propose a $(6-\\frac{2}{m})$-approximation algorithm with arbitrary release times, and a $(5-\\frac{2}{m})$-approximation without release time, where $m$ is the number of network cores. On the other hand, when coflow is indivisible, we propose a $(7-\\frac{2}{m})$-approximation algorithm with arbitrary release times, and a $(6-\\frac{2}{m})$-approximation without release time. ",
    "url": "https://arxiv.org/abs/2204.02651",
    "authors": [
      "Chi-Yeh Chen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.02654",
    "title": "Adversarial Analysis of the Differentially-Private Federated Learning in  Cyber-Physical Critical Infrastructures",
    "abstract": "Differential privacy (DP) is considered to be an effective privacy-preservation method to secure the promising distributed machine learning (ML) paradigm-federated learning (FL) from privacy attacks (e.g., membership inference attack). Nevertheless, while the DP mechanism greatly alleviates privacy concerns, recent studies have shown that it can be exploited to conduct security attacks (e.g., false data injection attacks). To address such attacks on FL-based applications in critical infrastructures, in this paper, we perform the first systematic study on the DP-exploited poisoning attacks from an adversarial point of view. We demonstrate that the DP method, despite providing a level of privacy guarantee, can effectively open a new poisoning attack vector for the adversary. Our theoretical analysis and empirical evaluation of a smart grid dataset show the FL performance degradation (sub-optimal model generation) scenario due to the differential noise-exploited selective model poisoning attacks. As a countermeasure, we propose a reinforcement learning-based differential privacy level selection (rDP) process. The rDP process utilizes the differential privacy parameters (privacy loss, information leakage probability, etc.) and the losses to intelligently generate an optimal privacy level for the nodes. The evaluation shows the accumulated reward and errors of the proposed technique converge to an optimal privacy policy. ",
    "url": "https://arxiv.org/abs/2204.02654",
    "authors": [
      "Md Tamjid Hossain",
      "Shahriar Badsha",
      "Hung",
      "Haoting Shen",
      "Shafkat Islam",
      "Ibrahim Khalil",
      "Xun Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.02656",
    "title": "CHIEF: Clustering with Higher-order Motifs in Big Networks",
    "abstract": "Clustering a group of vertices in networks facilitates applications across different domains, such as social computing and Internet of Things. However, challenges arises for clustering networks with increased scale. This paper proposes a solution which consists of two motif clustering techniques: standard acceleration CHIEF-ST and approximate acceleration CHIEF-AP. Both algorithms first find the maximal k-edge-connected subgraphs within the target networks to lower the network scale, then employ higher-order motifs in clustering. In the first procedure, we propose to lower the network scale by optimizing the network structure with maximal k-edge-connected subgraphs. For CHIEF-ST, we illustrate that all target motifs will be kept after this procedure when the minimum node degree of the target motif is equal or greater than k. For CHIEF-AP, we prove that the eigenvalues of the adjacency matrix and the Laplacian matrix are relatively stable after this step. That is, CHIEF-ST has no influence on motif clustering, whereas CHIEF-AP introduces limited yet acceptable impact. In the second procedure, we employ higher-order motifs, i.e., heterogeneous four-node motifs clustering in higher-order dense networks. The contributions of CHIEF are two-fold: (1) improved efficiency of motif clustering for big networks; (2) verification of higher-order motif significance. The proposed solutions are found to outperform baseline approaches according to experiments on real and synthetic networks, which demonstrates CHIEF's strength in large network analysis. Meanwhile, higher-order motifs are proved to perform better than traditional triangle motifs in clustering. ",
    "url": "https://arxiv.org/abs/2204.02656",
    "authors": [
      "Feng Xia",
      "Shuo Yu",
      "Chengfei Liu",
      "Ivan Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02667",
    "title": "Familiarity-based Collaborative Team Recognition in Academic Social  Networks",
    "abstract": "Collaborative teamwork is key to major scientific discoveries. However, the prevalence of collaboration among researchers makes team recognition increasingly challenging. Previous studies have demonstrated that people are more likely to collaborate with individuals they are familiar with. In this work, we employ the definition of familiarity and then propose MOTO (faMiliarity-based cOllaborative Team recOgnition algorithm) to recognize collaborative teams. MOTO calculates the shortest distance matrix within the global collaboration network and the local density of each node. Central team members are initially recognized based on local density. Then MOTO recognizes the remaining team members by using the familiarity metric and shortest distance matrix. Extensive experiments have been conducted upon a large-scale data set. The experimental results show that compared with baseline methods, MOTO can recognize the largest number of teams. The teams recognized by MOTO possess more cohesive team structures and lower team communication costs compared with other methods. MOTO utilizes familiarity in team recognition to identify cohesive academic teams. The recognized teams are in line with real-world collaborative teamwork patterns. Based on team recognition using MOTO, the research team structure and performance are further analyzed for given time periods. The number of teams that consist of members from different institutions increases gradually. Such teams are found to perform better in comparison with those whose members are from the same institution. ",
    "url": "https://arxiv.org/abs/2204.02667",
    "authors": [
      "Shuo Yu",
      "Feng Xia",
      "Chen Zhang",
      "Kathleen Keogh",
      "Honglong Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.02668",
    "title": "Disentangling the Computational Complexity of Network Untangling",
    "abstract": "We study the network untangling problem introduced by Rozenshtein, Tatti, and Gionis [DMKD 2021], which is a variant of Vertex Cover on temporal graphs -- graphs whose edge set changes over discrete time steps. They introduce two problem variants. The goal is to select at most $k$ time intervals for each vertex such that all time-edges are covered and (depending on the problem variant) either the maximum interval length or the total sum of interval lengths is minimized. This problem has data mining applications in finding activity timelines that explain the interactions of entities in complex networks. Both variants of the problem are NP-hard. In this paper, we initiate a multivariate complexity analysis involving the following parameters: number of vertices, lifetime of the temporal graph, number of intervals per vertex, and the interval length bound. For both problem versions, we (almost) completely settle the parameterized complexity for all combinations of those four parameters, thereby delineating the border of fixed-parameter tractability. ",
    "url": "https://arxiv.org/abs/2204.02668",
    "authors": [
      "Vincent Froese",
      "Pascal Kunz",
      "Philipp Zschoche"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.02674",
    "title": "Faster-TAD: Towards Temporal Action Detection with Proposal Generation  and Classification in a Unified Network",
    "abstract": "Temporal action detection (TAD) aims to detect the semantic labels and boundaries of action instances in untrimmed videos. Current mainstream approaches are multi-step solutions, which fall short in efficiency and flexibility. In this paper, we propose a unified network for TAD, termed Faster-TAD, by re-purposing a Faster-RCNN like architecture. To tackle the unique difficulty in TAD, we make important improvements over the original framework. We propose a new Context-Adaptive Proposal Module and an innovative Fake-Proposal Generation Block. What's more, we use atomic action features to improve the performance. Faster-TAD simplifies the pipeline of TAD and gets remarkable performance on lots of benchmarks, i.e., ActivityNet-1.3 (40.01% mAP), HACS Segments (38.39% mAP), SoccerNet-Action Spotting (54.09% mAP). It outperforms existing single-network detector by a large margin. ",
    "url": "https://arxiv.org/abs/2204.02674",
    "authors": [
      "Shimin Chen",
      "Chen Chen",
      "Wei Li",
      "Xunqiang Tao",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02675",
    "title": "Rolling Colors: Adversarial Laser Exploits against Traffic Light  Recognition",
    "abstract": "Traffic light recognition is essential for fully autonomous driving in urban areas. In this paper, we investigate the feasibility of fooling traffic light recognition mechanisms by shedding laser interference on the camera. By exploiting the rolling shutter of CMOS sensors, we manage to inject a color stripe overlapped on the traffic light in the image, which can cause a red light to be recognized as a green light or vice versa. To increase the success rate, we design an optimization method to search for effective laser parameters based on empirical models of laser interference. Our evaluation in emulated and real-world setups on 2 state-of-the-art recognition systems and 5 cameras reports a maximum success rate of 30% and 86.25% for Red-to-Green and Green-to-Red attacks. We observe that the attack is effective in continuous frames from more than 40 meters away against a moving vehicle, which may cause end-to-end impacts on self-driving such as running a red light or emergency stop. To mitigate the threat, we propose redesigning the rolling shutter mechanism. ",
    "url": "https://arxiv.org/abs/2204.02675",
    "authors": [
      "Chen Yan",
      "Zhijian Xu",
      "Zhanyuan Yin",
      "Xiaoyu Ji",
      "Wenyuan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.02709",
    "title": "Evolutionary Diversity Optimisation for The Traveling Thief Problem",
    "abstract": "There has been a growing interest in the evolutionary computation community to compute a diverse set of high-quality solutions for a given optimisation problem. This can provide the practitioners with invaluable information about the solution space and robustness against imperfect modelling and minor problems' changes. It also enables the decision-makers to involve their interests and choose between various solutions. In this study, we investigate for the first time a prominent multi-component optimisation problem, namely the Traveling Thief Problem (TTP), in the context of evolutionary diversity optimisation. We introduce a bi-level evolutionary algorithm to maximise the structural diversity of the set of solutions. Moreover, we examine the inter-dependency among the components of the problem in terms of structural diversity and empirically determine the best method to obtain diversity. We also conduct a comprehensive experimental investigation to examine the introduced algorithm and compare the results to another recently introduced framework based on the use of Quality Diversity (QD). Our experimental results show a significant improvement of the QD approach in terms of structural diversity for most TTP benchmark instances. ",
    "url": "https://arxiv.org/abs/2204.02709",
    "authors": [
      "Adel Nikfarjam",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.02720",
    "title": "Efficient attack sequences in m-eternal domination",
    "abstract": "We study the m-eternal domination problem from the perspective of the attacker. For many graph classes, the minimum required number of guards to defend eternally is known. By definition, if the defender has less than the required number of guards, then there exists a sequence of attacks that ensures the attacker's victory. Little is known about such sequences of attacks, in particular, no bound on its length is known. We show that if the game is played on a tree $T$ on $n$ vertices and the defender has less than the necessary number of guards, then the attacker can win in at most $n$ turns. Furthermore, we present an efficient procedure that produces such an attacking strategy. ",
    "url": "https://arxiv.org/abs/2204.02720",
    "authors": [
      "V\u00e1clav Bla\u017eej",
      "Jan Maty\u00e1\u0161 K\u0159i\u0161\u0165an",
      "Tom\u00e1\u0161 Valla"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2204.02725",
    "title": "Improving Multi-task Generalization Ability for Neural Text Matching via  Prompt Learning",
    "abstract": "Text matching is a fundamental technique in both information retrieval and natural language processing. Text matching tasks share the same paradigm that determines the relationship between two given texts. Evidently, the relationships vary from task to task, e.g. relevance in document retrieval, semantic alignment in paraphrase identification and answerable judgment in question answering. However, the essential signals for text matching remain in a finite scope, i.e. exact matching, semantic matching, and inference matching. Recent state-of-the-art neural text matching models, e.g. pre-trained language models (PLMs), are hard to generalize to different tasks. It is because the end-to-end supervised learning on task-specific dataset makes model overemphasize the data sample bias and task-specific signals instead of the essential matching signals, which ruins the generalization of model to different tasks. To overcome this problem, we adopt a specialization-generalization training strategy and refer to it as Match-Prompt. In specialization stage, descriptions of different matching tasks are mapped to only a few prompt tokens. In generalization stage, text matching model explores the essential matching signals by being trained on diverse multiple matching tasks. High diverse matching tasks avoid model fitting the data sample bias on a specific task, so that model can focus on learning the essential matching signals. Meanwhile, the prompt tokens obtained in the first step are added to the corresponding tasks to help the model distinguish different task-specific matching signals. Experimental results on eighteen public datasets show that Match-Prompt can significantly improve multi-task generalization capability of PLMs in text matching, and yield better in-domain multi-task, out-of-domain multi-task and new task adaptation performance than task-specific model. ",
    "url": "https://arxiv.org/abs/2204.02725",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.02735",
    "title": "Distilling Robust and Non-Robust Features in Adversarial Examples by  Information Bottleneck",
    "abstract": "Adversarial examples, generated by carefully crafted perturbation, have attracted considerable attention in research fields. Recent works have argued that the existence of the robust and non-robust features is a primary cause of the adversarial examples, and investigated their internal interactions in the feature space. In this paper, we propose a way of explicitly distilling feature representation into the robust and non-robust features, using Information Bottleneck. Specifically, we inject noise variation to each feature unit and evaluate the information flow in the feature representation to dichotomize feature units either robust or non-robust, based on the noise variation magnitude. Through comprehensive experiments, we demonstrate that the distilled features are highly correlated with adversarial prediction, and they have human-perceptible semantic information by themselves. Furthermore, we present an attack mechanism intensifying the gradient of non-robust features that is directly related to the model prediction, and validate its effectiveness of breaking model robustness. ",
    "url": "https://arxiv.org/abs/2204.02735",
    "authors": [
      "Junho Kim",
      "Byung-Kwan Lee",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02737",
    "title": "Adversarial Learning to Reason in an Arbitrary Logic",
    "abstract": "Existing approaches to learning to prove theorems focus on particular logics and datasets. In this work, we propose Monte-Carlo simulations guided by reinforcement learning that can work in an arbitrarily specified logic, without any human knowledge or set of problems. Since the algorithm does not need any training dataset, it is able to learn to work with any logical foundation, even when there is no body of proofs or even conjectures available. We practically demonstrate the feasibility of the approach in multiple logical systems. The approach is stronger than training on randomly generated data but weaker than the approaches trained on tailored axiom and conjecture sets. It however allows us to apply machine learning to automated theorem proving for many logics, where no such attempts have been tried to date, such as intuitionistic logic or linear logic. ",
    "url": "https://arxiv.org/abs/2204.02737",
    "authors": [
      "Stanis\u0142aw J. Purga\u0142",
      "Cezary Kaliszyk"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.02738",
    "title": "Masking Adversarial Damage: Finding Adversarial Saliency for Robust and  Sparse Network",
    "abstract": "Adversarial examples provoke weak reliability and potential security issues in deep neural networks. Although adversarial training has been widely studied to improve adversarial robustness, it works in an over-parameterized regime and requires high computations and large memory budgets. To bridge adversarial robustness and model compression, we propose a novel adversarial pruning method, Masking Adversarial Damage (MAD) that employs second-order information of adversarial loss. By using it, we can accurately estimate adversarial saliency for model parameters and determine which parameters can be pruned without weakening adversarial robustness. Furthermore, we reveal that model parameters of initial layer are highly sensitive to the adversarial examples and show that compressed feature representation retains semantic information for the target objects. Through extensive experiments on three public datasets, we demonstrate that MAD effectively prunes adversarially trained networks without loosing adversarial robustness and shows better performance than previous adversarial pruning methods. ",
    "url": "https://arxiv.org/abs/2204.02738",
    "authors": [
      "Byung-Kwan Lee",
      "Junho Kim",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02739",
    "title": "P4RROT: Generating P4 Code for the Application Layer",
    "abstract": "Throughput and latency critical applications could often benefit of performing computations close to the client. To enable this, distributed computing paradigms such as edge computing have recently emerged. However, with the advent of programmable data planes, computations cannot only be performed by servers but they can be offloaded to network switches. Languages like P4 enable to flexibly reprogram the entire packet processing pipeline. Though these devices promise high throughput and ultra-low response times, implementing application-layer tasks in the data plane programming language P4 is still challenging for an application developer who is not familiar with networking domain. In this paper, we first identify and examine obstacles and pain points one can experience when offloading server-based computations to the network. Then we present P4RROT, a code generator (in form of a library) which allows to overcome these limitations by providing a user-friendly API to describe computations to be offloaded. After discussing the design choices behind P4RROT, we introduce our proof-of-concept implementation for two P4 targets: Netronome SmartNIC and BMv2. ",
    "url": "https://arxiv.org/abs/2204.02739",
    "authors": [
      "Csaba Gy\u00f6rgyi",
      "S\u00e1ndor Laki",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.02752",
    "title": "Multi-Objective Evolutionary Beer Optimisation",
    "abstract": "Food production is a complex process which can benefit from many optimisation approaches. However, there is growing interest in methods that support customisation of food properties to satisfy individual consumer preferences. This paper addresses the personalisation of beer properties. Having identified components of the production process for craft beers whose production tends to be less standardised, we introduce a system which enables brewers to map the desired beer properties into ingredients dosage and combination. Previously explored approaches include direct use of structural equations as well as global machine learning methods. We introduce a framework which uses an evolutionary method supporting multi-objective optimisation. This work identifies problem-dependent objectives, their associations, and proposes a workflow to automate the discovery of multiple novel recipes based on user-defined criteria. The quality of the solutions generated by the multi-objective optimiser is compared against solutions from multiple runs of the method, and those of a single objective evolutionary technique. This comparison provides a road-map allowing the users to choose among more varied options or to fine-tune one of the favourite identified solution. The experiments presented here demonstrate the usability of the framework as well as the transparency of its criteria. ",
    "url": "https://arxiv.org/abs/2204.02752",
    "authors": [
      "Mohammad Majid al-Rifaie",
      "Marc Cavazza"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.02765",
    "title": "Code Search: A Survey of Techniques for Finding Code",
    "abstract": "The immense amounts of source code provide ample challenges and opportunities during software development. To handle the size of code bases, developers commonly search for code, e.g., when trying to find where a particular feature is implemented or when looking for code examples to reuse. To support developers in finding relevant code, various code search engines have been proposed. This article surveys 30 years of research on code search, giving a comprehensive overview of challenges and techniques that address them. We discuss the kinds of queries that code search engines support, how to preprocess and expand queries, different techniques for indexing and retrieving code, and ways to rank and prune search results. Moreover, we describe empirical studies of code search in practice. Based on the discussion of prior work, we conclude the article with an outline of challenges and opportunities to be addressed in the future. ",
    "url": "https://arxiv.org/abs/2204.02765",
    "authors": [
      "Luca Di Grazia",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.02772",
    "title": "Semi-DRDNet Semi-supervised Detail-recovery Image Deraining Network via  Unpaired Contrastive Learning",
    "abstract": "The intricacy of rainy image contents often leads cutting-edge deraining models to image degradation including remnant rain, wrongly-removed details, and distorted appearance. Such degradation is further exacerbated when applying the models trained on synthetic data to real-world rainy images. We raise an intriguing question -- if leveraging both accessible unpaired clean/rainy yet real-world images and additional detail repair guidance, can improve the generalization ability of a deraining model? To answer it, we propose a semi-supervised detail-recovery image deraining network (termed as Semi-DRDNet). Semi-DRDNet consists of three branches: 1) for removing rain streaks without remnants, we present a \\textit{squeeze-and-excitation} (SE)-based rain residual network; 2) for encouraging the lost details to return, we construct a \\textit{structure detail context aggregation} (SDCAB)-based detail repair network; to our knowledge, this is the first time; and 3) for bridging the domain gap, we develop a novel contrastive regularization network to learn from unpaired positive (clean) and negative (rainy) yet real-world images. As a semi-supervised learning paradigm, Semi-DRDNet operates smoothly on both synthetic and real-world rainy data in terms of deraining robustness and detail accuracy. Comparisons on four datasets show clear visual and numerical improvements of our Semi-DRDNet over thirteen state-of-the-arts. ",
    "url": "https://arxiv.org/abs/2204.02772",
    "authors": [
      "Yiyang Shen",
      "Sen Deng",
      "Wenhan Yang",
      "Mingqiang Wei",
      "Haoran Xie",
      "XiaoPing Zhang",
      "Jing Qin",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02782",
    "title": "How Do Graph Networks Generalize to Large and Diverse Molecular Systems?",
    "abstract": "The predominant method of demonstrating progress of atomic graph neural networks are benchmarks on small and limited datasets. The implicit hypothesis behind this approach is that progress on these narrow datasets generalize to the large diversity of chemistry. This generalizability would be very helpful for research, but currently remains untested. In this work we test this assumption by identifying four aspects of complexity in which many datasets are lacking: 1. Chemical diversity (number of different elements), 2. system size (number of atoms per sample), 3. dataset size (number of data samples), and 4. domain shift (similarity of the training and test set). We introduce multiple subsets of the large Open Catalyst 2020 (OC20) dataset to independently investigate each of these aspects. We then perform 21 ablation studies and sensitivity analyses on 9 datasets testing both previously proposed and new model enhancements. We find that some improvements are consistent between datasets, but many are not and some even have opposite effects. Based on this analysis, we identify a smaller dataset that correlates well with the full OC20 dataset, and propose the GemNet-OC model, which outperforms the previous state-of-the-art on OC20 by 16%, while reducing training time by a factor of 10. Overall, our findings challenge the common belief that graph neural networks work equally well independent of dataset size and diversity, and suggest that caution must be exercised when making generalizations based on narrow datasets. ",
    "url": "https://arxiv.org/abs/2204.02782",
    "authors": [
      "Johannes Gasteiger",
      "Muhammed Shuaibi",
      "Anuroop Sriram",
      "Stephan G\u00fcnnemann",
      "Zachary Ulissi",
      "C. Lawrence Zitnick",
      "Abhishek Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2204.02787",
    "title": "DiffSearch: A Scalable and Precise Search Engine for Code Changes",
    "abstract": "The source code of successful projects is evolving all the time, resulting in hundreds of thousands of code changes stored in source code repositories. This wealth of data can be useful, e.g., to find changes similar to a planned code change or examples of recurring code improvements. This paper presents DiffSearch, a search engine that, given a query that describes a code change, returns a set of changes that match the query. The approach is enabled by three key contributions. First, we present a query language that extends the underlying programming language with wildcards and placeholders, providing an intuitive way of formulating queries that is easy to adapt to different programming languages. Second, to ensure scalability, the approach indexes code changes in a one-time preprocessing step, mapping them into a feature space, and then performs an efficient search in the feature space for each query. Third, to guarantee precision, i.e., that any returned code change indeed matches the given query, we present a tree-based matching algorithm that checks whether a query can be expanded to a concrete code change. We present implementations for Java, JavaScript, and Python, and show that the approach responds within seconds to queries across one million code changes, has a recall of 80.7% for Java, 89.6% for Python, and 90.4% for JavaScript, enables users to find relevant code changes more effectively than a regular expression-based search, and is helpful for gathering a large-scale dataset of real-world bug fixes. ",
    "url": "https://arxiv.org/abs/2204.02787",
    "authors": [
      "Luca Di Grazia",
      "Paul Bredl",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.02791",
    "title": "Implicit Motion-Compensated Network for Unsupervised Video Object  Segmentation",
    "abstract": "Unsupervised video object segmentation (UVOS) aims at automatically separating the primary foreground object(s) from the background in a video sequence. Existing UVOS methods either lack robustness when there are visually similar surroundings (appearance-based) or suffer from deterioration in the quality of their predictions because of dynamic background and inaccurate flow (flow-based). To overcome the limitations, we propose an implicit motion-compensated network (IMCNet) combining complementary cues ($\\textit{i.e.}$, appearance and motion) with aligned motion information from the adjacent frames to the current frame at the feature level without estimating optical flows. The proposed IMCNet consists of an affinity computing module (ACM), an attention propagation module (APM), and a motion compensation module (MCM). The light-weight ACM extracts commonality between neighboring input frames based on appearance features. The APM then transmits global correlation in a top-down manner. Through coarse-to-fine iterative inspiring, the APM will refine object regions from multiple resolutions so as to efficiently avoid losing details. Finally, the MCM aligns motion information from temporally adjacent frames to the current frame which achieves implicit motion compensation at the feature level. We perform extensive experiments on $\\textit{DAVIS}_{\\textit{16}}$ and $\\textit{YouTube-Objects}$. Our network achieves favorable performance while running at a faster speed compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.02791",
    "authors": [
      "Lin Xi",
      "Weihai Chen",
      "Xingming Wu",
      "Zhong Liu",
      "Zhengguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02804",
    "title": "Federated Self-supervised Speech Representations: Are We There Yet?",
    "abstract": "The ubiquity of microphone-enabled devices has lead to large amounts of unlabelled audio data being produced at the edge. The integration of self-supervised learning (SSL) and federated learning (FL) into one coherent system can potentially offer data privacy guarantees while also advancing the quality and robustness of speech representations. In this paper, we provide a first-of-its-kind systematic study of the feasibility and complexities for training speech SSL models under FL scenarios from the perspective of algorithms, hardware, and systems limits. Despite the high potential of their combination, we find existing system constraints and algorithmic behaviour make SSL and FL systems nearly impossible to build today. Yet critically, our results indicate specific performance bottlenecks and research opportunities that would allow this situation to be reversed. While our analysis suggests that, given existing trends in hardware, hybrid SSL and FL speech systems will not be viable until 2027. We believe this study can act as a roadmap to accelerate work towards reaching this milestone much earlier. ",
    "url": "https://arxiv.org/abs/2204.02804",
    "authors": [
      "Yan Gao",
      "Javier Fernandez-Marques",
      "Titouan Parcollet",
      "Abhinav Mehrotra",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02824",
    "title": "ShowFace: Coordinated Face Inpainting with Memory-Disentangled  Refinement Networks",
    "abstract": "Face inpainting aims to complete the corrupted regions of the face images, which requires coordination between the completed areas and the non-corrupted areas. Recently, memory-oriented methods illustrate great prospects in the generation related tasks by introducing an external memory module to improve image coordination. However, such methods still have limitations in restoring the consistency and continuity for specificfacial semantic parts. In this paper, we propose the coarse-to-fine Memory-Disentangled Refinement Networks (MDRNets) for coordinated face inpainting, in which two collaborative modules are integrated, Disentangled Memory Module (DMM) and Mask-Region Enhanced Module (MREM). Specifically, the DMM establishes a group of disentangled memory blocks to store the semantic-decoupled face representations, which could provide the most relevant information to refine the semantic-level coordination. The MREM involves a masked correlation mining mechanism to enhance the feature relationships into the corrupted regions, which could also make up for the correlation loss caused by memory disentanglement. Furthermore, to better improve the inter-coordination between the corrupted and non-corrupted regions and enhance the intra-coordination in corrupted regions, we design InCo2 Loss, a pair of similarity based losses to constrain the feature consistency. Eventually, extensive experiments conducted on CelebA-HQ and FFHQ datasets demonstrate the superiority of our MDRNets compared with previous State-Of-The-Art methods. ",
    "url": "https://arxiv.org/abs/2204.02824",
    "authors": [
      "Zhuojie Wu",
      "Xingqun Qi",
      "Zijian Wang",
      "Wanting Zhou",
      "Kun Yuan",
      "Muyi Sun",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02844",
    "title": "Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware  Adversarial Training",
    "abstract": "Existing deep learning real denoising methods require a large amount of noisy-clean image pairs for supervision. Nonetheless, capturing a real noisy-clean dataset is an unacceptable expensive and cumbersome procedure. To alleviate this problem, this work investigates how to generate realistic noisy images. Firstly, we formulate a simple yet reasonable noise model that treats each real noisy pixel as a random variable. This model splits the noisy image generation problem into two sub-problems: image domain alignment and noise domain alignment. Subsequently, we propose a novel framework, namely Pixel-level Noise-aware Generative Adversarial Network (PNGAN). PNGAN employs a pre-trained real denoiser to map the fake and real noisy images into a nearly noise-free solution space to perform image domain alignment. Simultaneously, PNGAN establishes a pixel-level adversarial training to conduct noise domain alignment. Additionally, for better noise fitting, we present an efficient architecture Simple Multi-scale Network (SMNet) as the generator. Qualitative validation shows that noise generated by PNGAN is highly similar to real noise in terms of intensity and distribution. Quantitative experiments demonstrate that a series of denoisers trained with the generated noisy images achieve state-of-the-art (SOTA) results on four real denoising benchmarks. ",
    "url": "https://arxiv.org/abs/2204.02844",
    "authors": [
      "Yuanhao Cai",
      "Xiaowan Hu",
      "Haoqian Wang",
      "Yulun Zhang",
      "Hanspeter Pfister",
      "Donglai Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.02883",
    "title": "Data-driven Robust LQR with Multiplicative Noise via System Level  Synthesis",
    "abstract": "This paper aims to develop a data-driven method for solving the closed-loop state-feedback control of a discrete-time LQR problem for systems affected by multiplicative norm bounded model uncertainty. To synthesize a tractable robust state feedback policy, first, we adopt the recently developed system-level synthesis (SLS) framework to reformulate the LQR control design closed-loop system responses rather than the control gain. In many situations, however, the solution to this worst-case optimization problem may be too conservative since it sets out to enforce the design constraints for every possible value of the uncertainty. To deal with this issue, we reformulate this optimization problem as a chance-constrained program (CCP), where the guarantees are not expressed as deterministic satisfaction against all possible uncertainty outcomes but rather expressed as guarantees against uncertainty outcomes. To approximately solve the CCP without requiring prior knowledge of how the uncertainties in the system matrices are described, we employ the so-called scenario approach, which provides probabilistic guarantees based on a finite number of samples and results in a convex optimization program with moderate computational complexity. Finally, numerical simulations are presented to illustrate the theoretical findings. ",
    "url": "https://arxiv.org/abs/2204.02883",
    "authors": [
      "Majid Mazouchi",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.02887",
    "title": "Sampling-based Fast Gradient Rescaling Method for Highly Transferable  Adversarial Attacks",
    "abstract": "Deep neural networks have shown to be very vulnerable to adversarial examples crafted by adding human-imperceptible perturbations to benign inputs. After achieving impressive attack success rates in the white-box setting, more focus is shifted to black-box attacks. In either case, the common gradient-based approaches generally use the $sign$ function to generate perturbations at the end of the process. However, only a few works pay attention to the limitation of the $sign$ function. Deviation between the original gradient and the generated noises may lead to inaccurate gradient update estimation and suboptimal solutions for adversarial transferability, which is crucial for black-box attacks. To address this issue, we propose a Sampling-based Fast Gradient Rescaling Method (S-FGRM) to improve the transferability of the crafted adversarial examples. Specifically, we use data rescaling to substitute the inefficient $sign$ function in gradient-based attacks without extra computational cost. We also propose a Depth First Sampling method to eliminate the fluctuation of rescaling and stabilize the gradient update. Our method can be used in any gradient-based optimizations and is extensible to be integrated with various input transformation or ensemble methods for further improving the adversarial transferability. Extensive experiments on the standard ImageNet dataset show that our S-FGRM could significantly boost the transferability of gradient-based attacks and outperform the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2204.02887",
    "authors": [
      "Xu Han",
      "Anmin Liu",
      "Yifeng Xiong",
      "Yanbo Fan",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02898",
    "title": "End-to-End Instance Edge Detection",
    "abstract": "Edge detection has long been an important problem in the field of computer vision. Previous works have explored category-agnostic or category-aware edge detection. In this paper, we explore edge detection in the context of object instances. Although object boundaries could be easily derived from segmentation masks, in practice, instance segmentation models are trained to maximize IoU to the ground-truth mask, which means that segmentation boundaries are not enforced to precisely align with ground-truth edge boundaries. Thus, the task of instance edge detection itself is different and critical. Since precise edge detection requires high resolution feature maps, we design a novel transformer architecture that efficiently combines a FPN and a transformer decoder to enable cross attention on multi-scale high resolution feature maps within a reasonable computation budget. Further, we propose a light weight dense prediction head that is applicable to both instance edge and mask detection. Finally, we use a penalty reduced focal loss to effectively train the model with point supervision on instance edges, which can reduce annotation costs. We demonstrate highly competitive instance edge detection performance compared to state-of-the-art baselines, and also show that the proposed task and loss are complementary to instance segmentation and object detection. ",
    "url": "https://arxiv.org/abs/2204.02898",
    "authors": [
      "Xueyan Zou",
      "Haotian Liu",
      "Yong Jae Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02902",
    "title": "Efficient Bayesian Network Structure Learning via Parameterized Local  Search on Topological Orderings",
    "abstract": "In Bayesian Network Structure Learning (BNSL), one is given a variable set and parent scores for each variable and aims to compute a DAG, called Bayesian network, that maximizes the sum of parent scores, possibly under some structural constraints. Even very restricted special cases of BNSL are computationally hard, and, thus, in practice heuristics such as local search are used. A natural approach for a local search algorithm is a hill climbing strategy, where one replaces a given BNSL solution by a better solution within some pre-defined neighborhood as long as this is possible. We study ordering-based local search, where a solution is described via a topological ordering of the variables. We show that given such a topological ordering, one can compute an optimal DAG whose ordering is within inversion distance $r$ in subexponential FPT time; the parameter $r$ allows to balance between solution quality and running time of the local search algorithm. This running time bound can be achieved for BNSL without structural constraints and for all structural constraints that can be expressed via a sum of weights that are associated with each parent set. We also introduce a related distance called `window inversions distance' and show that the corresponding local search problem can also be solved in subexponential FPT time for the parameter $r$. For two further natural modification operations on the variable orderings, we show that algorithms with an FPT time for $r$ are unlikely. We also outline the limits of ordering-based local search by showing that it cannot be used for common structural constraints on the moralized graph of the network. ",
    "url": "https://arxiv.org/abs/2204.02902",
    "authors": [
      "Niels Gr\u00fcttemeier",
      "Christian Komusiewicz",
      "Nils Morawietz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02932",
    "title": "An Empirical Study of End-to-End Temporal Action Detection",
    "abstract": "Temporal action detection (TAD) is an important yet challenging task in video understanding. It aims to simultaneously predict the semantic label and the temporal interval of every action instance in an untrimmed video. Rather than end-to-end learning, most existing methods adopt a head-only learning paradigm, where the video encoder is pre-trained for action classification, and only the detection head upon the encoder is optimized for TAD. The effect of end-to-end learning is not systematically evaluated. Besides, there lacks an in-depth study on the efficiency-accuracy trade-off in end-to-end TAD. In this paper, we present an empirical study of end-to-end temporal action detection. We validate the advantage of end-to-end learning over head-only learning and observe up to 11\\% performance improvement. Besides, we study the effects of multiple design choices that affect the TAD performance and speed, including detection head, video encoder, and resolution of input videos. Based on the findings, we build a mid-resolution baseline detector, which achieves the state-of-the-art performance of end-to-end methods while running more than 4$\\times$ faster. We hope that this paper can serve as a guide for end-to-end learning and inspire future research in this field. Code and models are available at \\url{https://github.com/xlliu7/E2E-TAD}. ",
    "url": "https://arxiv.org/abs/2204.02932",
    "authors": [
      "Xiaolong Liu",
      "Song Bai",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02934",
    "title": "Parallel, Portable Algorithms for Distance-2 Maximal Independent Set and  Graph Coarsening",
    "abstract": "Given a graph, finding the distance-2 maximal independent set (MIS-2) of the vertices is a problem that is useful in several contexts such as algebraic multigrid coarsening or multilevel graph partitioning. Such multilevel methods rely on finding the independent vertices so they can be used as seeds for aggregation in a multilevel scheme. We present a parallel MIS-2 algorithm to improve performance on modern accelerator hardware. This algorithm is implemented using the Kokkos programming model to enable performance portability. We demonstrate the portability of the algorithm and the performance on a variety of architectures (x86/ARM CPUs and NVIDIA/AMD GPUs). The resulting algorithm is also deterministic, producing an identical result for a given input across all of these platforms. The new MIS-2 implementation outperforms implementations in state of the art libraries like CUSP and ViennaCL by 3-8x while producing similar quality results. We further demonstrate the benefits of this approach by developing parallel graph coarsening scheme for two different use cases. First, we develop an algebraic multigrid (AMG) aggregation scheme using parallel MIS-2 and demonstrate the benefits as opposed to previous approaches used in the MueLu multigrid package in Trilinos. We also describe an approach for implementing a parallel multicolor \"cluster\" Gauss-Seidel preconditioner using this MIS-2 coarsening, and demonstrate better performance with an efficient, parallel, multicolor Gauss-Seidel algorithm. ",
    "url": "https://arxiv.org/abs/2204.02934",
    "authors": [
      "Brian Kelley",
      "Sivasankaran Rajamanickam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.02937",
    "title": "Last Layer Re-Training is Sufficient for Robustness to Spurious  Correlations",
    "abstract": "Neural network classifiers can largely rely on simple spurious features, such as backgrounds, to make predictions. However, even in these cases, we show that they still often learn core features associated with the desired attributes of the data, contrary to recent findings. Inspired by this insight, we demonstrate that simple last layer retraining can match or outperform state-of-the-art approaches on spurious correlation benchmarks, but with profoundly lower complexity and computational expenses. Moreover, we show that last layer retraining on large ImageNet-trained models can also significantly reduce reliance on background and texture information, improving robustness to covariate shift, after only minutes of training on a single GPU. ",
    "url": "https://arxiv.org/abs/2204.02937",
    "authors": [
      "Polina Kirichenko",
      "Pavel Izmailov",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.02942",
    "title": "A Design Methodology for Fault-Tolerant Computing using Astrocyte Neural  Networks",
    "abstract": "We propose a design methodology to facilitate fault tolerance of deep learning models. First, we implement a many-core fault-tolerant neuromorphic hardware design, where neuron and synapse circuitries in each neuromorphic core are enclosed with astrocyte circuitries, the star-shaped glial cells of the brain that facilitate self-repair by restoring the spike firing frequency of a failed neuron using a closed-loop retrograde feedback signal. Next, we introduce astrocytes in a deep learning model to achieve the required degree of tolerance to hardware faults. Finally, we use a system software to partition the astrocyte-enabled model into clusters and implement them on the proposed fault-tolerant neuromorphic design. We evaluate this design methodology using seven deep learning inference models and show that it is both area and power efficient. ",
    "url": "https://arxiv.org/abs/2204.02942",
    "authors": [
      "Murat I\u015f\u0131k",
      "Ankita Paul",
      "M. Lakshmi Varshika",
      "Anup Das"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.02944",
    "title": "\"The Pedestrian next to the Lamppost\" Adaptive Object Graphs for Better  Instantaneous Mapping",
    "abstract": "Estimating a semantically segmented bird's-eye-view (BEV) map from a single image has become a popular technique for autonomous control and navigation. However, they show an increase in localization error with distance from the camera. While such an increase in error is entirely expected - localization is harder at distance - much of the drop in performance can be attributed to the cues used by current texture-based models, in particular, they make heavy use of object-ground intersections (such as shadows), which become increasingly sparse and uncertain for distant objects. In this work, we address these shortcomings in BEV-mapping by learning the spatial relationship between objects in a scene. We propose a graph neural network which predicts BEV objects from a monocular image by spatially reasoning about an object within the context of other objects. Our approach sets a new state-of-the-art in BEV estimation from monocular images across three large-scale datasets, including a 50% relative improvement for objects on nuScenes. ",
    "url": "https://arxiv.org/abs/2204.02944",
    "authors": [
      "Avishkar Saha",
      "Oscar Mendez",
      "Chris Russell",
      "Richard Bowden"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02958",
    "title": "LEAD: Self-Supervised Landmark Estimation by Aligning Distributions of  Feature Similarity",
    "abstract": "In this work, we introduce LEAD, an approach to discover landmarks from an unannotated collection of category-specific images. Existing works in self-supervised landmark detection are based on learning dense (pixel-level) feature representations from an image, which are further used to learn landmarks in a semi-supervised manner. While there have been advances in self-supervised learning of image features for instance-level tasks like classification, these methods do not ensure dense equivariant representations. The property of equivariance is of interest for dense prediction tasks like landmark estimation. In this work, we introduce an approach to enhance the learning of dense equivariant representations in a self-supervised fashion. We follow a two-stage training approach: first, we train a network using the BYOL objective which operates at an instance level. The correspondences obtained through this network are further used to train a dense and compact representation of the image using a lightweight network. We show that having such a prior in the feature extractor helps in landmark detection, even under drastically limited number of annotations while also improving generalization across scale variations. ",
    "url": "https://arxiv.org/abs/2204.02958",
    "authors": [
      "Tejan Karmali",
      "Abhinav Atrishi",
      "Sai Sree Harsha",
      "Susmit Agrawal",
      "Varun Jampani",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02964",
    "title": "Unleashing Vanilla Vision Transformer with Masked Image Modeling for  Object Detection",
    "abstract": "We present an approach to efficiently and effectively adapt a masked image modeling (MIM) pre-trained vanilla Vision Transformer (ViT) for object detection, which is based on our two novel observations: (i) A MIM pre-trained vanilla ViT can work surprisingly well in the challenging object-level recognition scenario even with random sampled partial observations, e.g., only 25% ~ 50% of the input sequence. (ii) In order to construct multi-scale representations for object detection, a random initialized compact convolutional stem supplants the pre-trained large kernel patchify stem, and its intermediate features can naturally serve as the higher resolution inputs of a feature pyramid without upsampling. While the pre-trained ViT is only regarded as the third-stage of our detector's backbone instead of the whole feature extractor, resulting in a ConvNet-ViT hybrid architecture. The proposed detector, named MIMDet, enables a MIM pre-trained vanilla ViT to outperform hierarchical Swin Transformer by 2.3 box AP and 2.5 mask AP on COCO, and achieve even better results compared with other adapted vanilla ViT using a more modest fine-tuning recipe while converging 2.8x faster. Code and pre-trained models are available at \\url{https://github.com/hustvl/MIMDet}. ",
    "url": "https://arxiv.org/abs/2204.02964",
    "authors": [
      "Yuxin Fang",
      "Shusheng Yang",
      "Shijie Wang",
      "Yixiao Ge",
      "Ying Shan",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02965",
    "title": "LilNetX: Lightweight Networks with EXtreme Model Compression and  Structured Sparsification",
    "abstract": "We introduce LilNetX, an end-to-end trainable technique for neural networks that enables learning models with specified accuracy-rate-computation trade-off. Prior works approach these problems one at a time and often require post-processing or multistage training which become less practical and do not scale very well for large datasets or architectures. Our method constructs a joint training objective that penalizes the self-information of network parameters in a reparameterized latent space to encourage small model size while also introducing priors to increase structured sparsity in the parameter space to reduce computation. We achieve up to 50% smaller model size and 98% model sparsity on ResNet-20 while retaining the same accuracy on the CIFAR-10 dataset as well as 35% smaller model size and 42% structured sparsity on ResNet-50 trained on ImageNet, when compared to existing state-of-the-art model compression methods. Code is available at https://github.com/Sharath-girish/LilNetX. ",
    "url": "https://arxiv.org/abs/2204.02965",
    "authors": [
      "Sharath Girish",
      "Kamal Gupta",
      "Saurabh Singh",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02967",
    "title": "Enhanced Direct Speech-to-Speech Translation Using Self-supervised  Pre-training and Data Augmentation",
    "abstract": "Direct speech-to-speech translation (S2ST) models suffer from data scarcity issues as there exists little parallel S2ST data, compared to the amount of data available for conventional cascaded systems that consist of automatic speech recognition (ASR), machine translation (MT), and text-to-speech (TTS) synthesis. In this work, we explore self-supervised pre-training with unlabeled speech data and data augmentation to tackle this issue. We take advantage of a recently proposed speech-to-unit translation (S2UT) framework that encodes target speech into discrete representations, and transfer pre-training and efficient partial finetuning techniques that work well for speech-to-text translation (S2T) to the S2UT domain by studying both speech encoder and discrete unit decoder pre-training. Our experiments show that self-supervised pre-training consistently improves model performance compared with multitask learning with a BLEU gain of 4.3-12.0 under various data setups, and it can be further combined with data augmentation techniques that apply MT to create weakly supervised training data. Audio samples are available at: https://facebookresearch.github.io/speech_translation/enhanced_direct_s2st_units/index.html . ",
    "url": "https://arxiv.org/abs/2204.02967",
    "authors": [
      "Sravya Popuri",
      "Peng-Jen Chen",
      "Changhan Wang",
      "Juan Pino",
      "Yossi Adi",
      "Jiatao Gu",
      "Wei-Ning Hsu",
      "Ann Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02968",
    "title": "Temporal Alignment Networks for Long-term Video",
    "abstract": "The objective of this paper is a temporal alignment network that ingests long term video sequences, and associated text sentences, in order to: (1) determine if a sentence is alignable with the video; and (2) if it is alignable, then determine its alignment. The challenge is to train such networks from large-scale datasets, such as HowTo100M, where the associated text sentences have significant noise, and are only weakly aligned when relevant. Apart from proposing the alignment network, we also make four contributions: (i) we describe a novel co-training method that enables to denoise and train on raw instructional videos without using manual annotation, despite the considerable noise; (ii) to benchmark the alignment performance, we manually curate a 10-hour subset of HowTo100M, totalling 80 videos, with sparse temporal descriptions. Our proposed model, trained on HowTo100M, outperforms strong baselines (CLIP, MIL-NCE) on this alignment dataset by a significant margin; (iii) we apply the trained model in the zero-shot settings to multiple downstream video understanding tasks and achieve state-of-the-art results, including text-video retrieval on YouCook2, and weakly supervised video action segmentation on Breakfast-Action; (iv) we use the automatically aligned HowTo100M annotations for end-to-end finetuning of the backbone model, and obtain improved performance on downstream action recognition tasks. ",
    "url": "https://arxiv.org/abs/2204.02968",
    "authors": [
      "Tengda Han",
      "Weidi Xie",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02404",
    "title": "Hospital-Agnostic Image Representation Learning in Digital Pathology",
    "abstract": "Whole Slide Images (WSIs) in digital pathology are used to diagnose cancer subtypes. The difference in procedures to acquire WSIs at various trial sites gives rise to variability in the histopathology images, thus making consistent diagnosis challenging. These differences may stem from variability in image acquisition through multi-vendor scanners, variable acquisition parameters, and differences in staining procedure; as well, patient demographics may bias the glass slide batches before image acquisition. These variabilities are assumed to cause a domain shift in the images of different hospitals. It is crucial to overcome this domain shift because an ideal machine-learning model must be able to work on the diverse sources of images, independent of the acquisition center. A domain generalization technique is leveraged in this study to improve the generalization capability of a Deep Neural Network (DNN), to an unseen histopathology image set (i.e., from an unseen hospital/trial site) in the presence of domain shift. According to experimental results, the conventional supervised-learning regime generalizes poorly to data collected from different hospitals. However, the proposed hospital-agnostic learning can improve the generalization considering the low-dimensional latent space representation visualization, and classification accuracy results. ",
    "url": "https://arxiv.org/abs/2204.02404",
    "authors": [
      "Milad Sikaroudi",
      "Shahryar Rahnamayan",
      "H.R. Tizhoosh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02405",
    "title": "Zero-shot Blind Image Denoising via Implicit Neural Representations",
    "abstract": "Recent denoising algorithms based on the \"blind-spot\" strategy show impressive blind image denoising performances, without utilizing any external dataset. While the methods excel in recovering highly contaminated images, we observe that such algorithms are often less effective under a low-noise or real noise regime. To address this gap, we propose an alternative denoising strategy that leverages the architectural inductive bias of implicit neural representations (INRs), based on our two findings: (1) INR tends to fit the low-frequency clean image signal faster than the high-frequency noise, and (2) INR layers that are closer to the output play more critical roles in fitting higher-frequency parts. Building on these observations, we propose a denoising algorithm that maximizes the innate denoising capability of INRs by penalizing the growth of deeper layer weights. We show that our method outperforms existing zero-shot denoising methods under an extensive set of low-noise or real-noise scenarios. ",
    "url": "https://arxiv.org/abs/2204.02405",
    "authors": [
      "Chaewon Kim",
      "Jaeho Lee",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02406",
    "title": "A deep learning framework for the detection and quantification of drusen  and reticular pseudodrusen on optical coherence tomography",
    "abstract": "Purpose - To develop and validate a deep learning (DL) framework for the detection and quantification of drusen and reticular pseudodrusen (RPD) on optical coherence tomography scans. Design - Development and validation of deep learning models for classification and feature segmentation. Methods - A DL framework was developed consisting of a classification model and an out-of-distribution (OOD) detection model for the identification of ungradable scans; a classification model to identify scans with drusen or RPD; and an image segmentation model to independently segment lesions as RPD or drusen. Data were obtained from 1284 participants in the UK Biobank (UKBB) with a self-reported diagnosis of age-related macular degeneration (AMD) and 250 UKBB controls. Drusen and RPD were manually delineated by five retina specialists. The main outcome measures were sensitivity, specificity, area under the ROC curve (AUC), kappa, accuracy and intraclass correlation coefficient (ICC). Results - The classification models performed strongly at their respective tasks (0.95, 0.93, and 0.99 AUC, respectively, for the ungradable scans classifier, the OOD model, and the drusen and RPD classification model). The mean ICC for drusen and RPD area vs. graders was 0.74 and 0.61, respectively, compared with 0.69 and 0.68 for intergrader agreement. FROC curves showed that the model's sensitivity was close to human performance. Conclusions - The models achieved high classification and segmentation performance, similar to human performance. Application of this robust framework will further our understanding of RPD as a separate entity from drusen in both research and clinical settings. ",
    "url": "https://arxiv.org/abs/2204.02406",
    "authors": [
      "Roy Schwartz",
      "Hagar Khalid",
      "Sandra Liakopoulos",
      "Yanling Ouyang",
      "Coen de Vente",
      "Cristina Gonz\u00e1lez-Gonzalo",
      "Aaron Y. Lee",
      "Robyn Guymer",
      "Emily Y. Chew",
      "Catherine Egan",
      "Zhichao Wu",
      "Himeesh Kumar",
      "Joseph Farrington",
      "Clara I. S\u00e1nchez",
      "Adnan Tufail"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02480",
    "title": "Learning Optimal K-space Acquisition and Reconstruction using  Physics-Informed Neural Networks",
    "abstract": "The inherent slow imaging speed of Magnetic Resonance Image (MRI) has spurred the development of various acceleration methods, typically through heuristically undersampling the MRI measurement domain known as k-space. Recently, deep neural networks have been applied to reconstruct undersampled k-space data and have shown improved reconstruction performance. While most of these methods focus on designing novel reconstruction networks or new training strategies for a given undersampling pattern, \\textit{e.g.}, Cartesian undersampling or Non-Cartesian sampling, to date, there is limited research aiming to learn and optimize k-space sampling strategies using deep neural networks. This work proposes a novel optimization framework to learn k-space sampling trajectories by considering it as an Ordinary Differential Equation (ODE) problem that can be solved using neural ODE. In particular, the sampling of k-space data is framed as a dynamic system, in which neural ODE is formulated to approximate the system with additional constraints on MRI physics. In addition, we have also demonstrated that trajectory optimization and image reconstruction can be learned collaboratively for improved imaging efficiency and reconstruction performance. Experiments were conducted on different in-vivo datasets (\\textit{e.g.}, brain and knee images) acquired with different sequences. Initial results have shown that our proposed method can generate better image quality in accelerated MRI than conventional undersampling schemes in Cartesian and Non-Cartesian acquisitions. ",
    "url": "https://arxiv.org/abs/2204.02480",
    "authors": [
      "Wei Peng",
      "Li Feng",
      "Guoying Zhao",
      "Fang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02493",
    "title": "Distributed Robust Control for Systems with Structured Uncertainties",
    "abstract": "We present D-Phi iteration: an algorithm for distributed, localized, and scalable robust control of systems with structured uncertainties. This algorithm combines the System Level Synthesis (SLS) parametrization for distributed control with stability criteria from L1, L-infinity, and nu robust control. We show in simulation that this algorithm achieves near-optimal nominal performance (within 12% of the LQR controller) while doubling or tripling the stability margin (depending on the stability criterion) compared to the LQR controller. To the best of our knowledge, this is the first distributed and localized algorithm for structured robust control; furthermore, algorithm complexity depends only on the size of local neighborhoods and is independent of global system size. We additionally characterize the suitability of different robustness criteria for distributed and localized computation, and discuss open questions on the topic of distributed robust control. ",
    "url": "https://arxiv.org/abs/2204.02493",
    "authors": [
      "Jing Shuang Li",
      "John C. Doyle"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.02513",
    "title": "In-Pocket 3D Graphs Enhance Ligand-Target Compatibility in Generative  Small-Molecule Creation",
    "abstract": "Proteins in complex with small molecule ligands represent the core of structure-based drug discovery. However, three-dimensional representations are absent from most deep-learning-based generative models. We here present a graph-based generative modeling technology that encodes explicit 3D protein-ligand contacts within a relational graph architecture. The models combine a conditional variational autoencoder that allows for activity-specific molecule generation with putative contact generation that provides predictions of molecular interactions within the target binding pocket. We show that molecules generated with our 3D procedure are more compatible with the binding pocket of the dopamine D2 receptor than those produced by a comparable ligand-based 2D generative method, as measured by docking scores, expected stereochemistry, and recoverability in commercial chemical databases. Predicted protein-ligand contacts were found among highest-ranked docking poses with a high recovery rate. This work shows how the structural context of a protein target can be used to enhance molecule generation. ",
    "url": "https://arxiv.org/abs/2204.02513",
    "authors": [
      "Seung-gu Kang",
      "Jeffrey K. Weber",
      "Joseph A. Morrone",
      "Leili Zhang",
      "Tien Huynh",
      "Wendy D. Cornell"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2204.02623",
    "title": "Attention-based CNN-LSTM and XGBoost hybrid model for stock prediction",
    "abstract": "Stock market plays an important role in the economic development. Due to the complex volatility of the stock market, the research and prediction on the change of the stock price, can avoid the risk for the investors. The traditional time series model ARIMA can not describe the nonlinearity, and can not achieve satisfactory results in the stock prediction. As neural networks are with strong nonlinear generalization ability, this paper proposes an attention-based CNN-LSTM and XGBoost hybrid model to predict the stock price. The model constructed in this paper integrates the time series model, the Convolutional Neural Networks with Attention mechanism, the Long Short-Term Memory network, and XGBoost regressor in a non-linear relationship, and improves the prediction accuracy. The model can fully mine the historical information of the stock market in multiple periods. The stock data is first preprocessed through ARIMA. Then, the deep learning architecture formed in pretraining-finetuning framework is adopted. The pre-training model is the Attention-based CNN-LSTM model based on sequence-to-sequence framework. The model first uses convolution to extract the deep features of the original stock data, and then uses the Long Short-Term Memory networks to mine the long-term time series features. Finally, the XGBoost model is adopted for fine-tuning. The results show that the hybrid model is more effective and the prediction accuracy is relatively high, which can help investors or institutions to make decisions and achieve the purpose of expanding return and avoiding risk. Source code is available at https://github.com/zshicode/Attention-CLX-stock-prediction. ",
    "url": "https://arxiv.org/abs/2204.02623",
    "authors": [
      "Zhuangwei Shi",
      "Yang Hu",
      "Guangliang Mo",
      "Jian Wu"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02631",
    "title": "Super-resolved multi-temporal segmentation with deep  permutation-invariant networks",
    "abstract": "Multi-image super-resolution from multi-temporal satellite acquisitions of a scene has recently enjoyed great success thanks to new deep learning models. In this paper, we go beyond classic image reconstruction at a higher resolution by studying a super-resolved inference problem, namely semantic segmentation at a spatial resolution higher than the one of sensing platform. We expand upon recently proposed models exploiting temporal permutation invariance with a multi-resolution fusion module able to infer the rich semantic information needed by the segmentation task. The model presented in this paper has recently won the AI4EO challenge on Enhanced Sentinel 2 Agriculture. ",
    "url": "https://arxiv.org/abs/2204.02631",
    "authors": [
      "Diego Valsesia",
      "Enrico Magli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02694",
    "title": "Customizable End-to-end Optimization of Online Neural Network-supported  Dereverberation for Hearing Devices",
    "abstract": "This work focuses on online dereverberation for hearing devices using the weighted prediction error (WPE) algorithm. WPE filtering requires an estimate of the target speech power spectral density (PSD). Recently deep neural networks (DNNs) have been used for this task. However, these approaches optimize the PSD estimate which only indirectly affects the WPE output, thus potentially resulting in limited dereverberation. In this paper, we propose an end-to-end approach specialized for online processing, that directly optimizes the dereverberated output signal. In addition, we propose to adapt it to the needs of different types of hearing-device users by modifying the optimization target as well as the WPE algorithm characteristics used in training. We show that the proposed end-to-end approach outperforms the traditional and conventional DNN-supported WPEs on a noise-free version of the WHAMR! dataset. ",
    "url": "https://arxiv.org/abs/2204.02694",
    "authors": [
      "Jean-Marie Lemercier",
      "Joachim Thiemann",
      "Raphael Koning",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.02741",
    "title": "Neural Network-augmented Kalman Filtering for Robust Online Speech  Dereverberation in Noisy Reverberant Environments",
    "abstract": "In this paper, a neural network-augmented algorithm for noise-robust online dereverberation with a Kalman filtering variant of the weighted prediction error (WPE) method is proposed. The filter stochastic variations are predicted by a deep neural network (DNN) trained end-to-end using the filter residual error and signal characteristics. The presented framework allows for robust dereverberation on a single-channel noisy reverberant dataset similar to WHAMR!. The Kalman filtering WPE introduces distortions in the enhanced signal when predicting the filter variations from the residual error only, if the target speech power spectral density is not perfectly known and the observation is noisy. The proposed approach avoids these distortions by correcting the filter variations estimation in a data-driven way, increasing the robustness of the method to noisy scenarios. Furthermore, it yields a strong dereverberation and denoising performance compared to a DNN-supported recursive least squares variant of WPE, especially for highly noisy inputs. ",
    "url": "https://arxiv.org/abs/2204.02741",
    "authors": [
      "Jean-Marie Lemercier",
      "Joachim Thiemann",
      "Raphael Koning",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.02797",
    "title": "Classification of NEQR Processed Classical Images using Quantum Neural  Networks (QNN)",
    "abstract": "A quantum neural network (QNN) is interpreted today as any quantum circuit with trainable continuous parameters. This work builds on previous works by the authors and addresses QNN for image classification with Novel Enhanced Quantum Representation of (NEQR) processed classical data where Principal component analysis (PCA) and Projected Quantum Kernel features (PQK) were investigated previously by the authors as a path to quantum advantage for the same classical dataset. For each of these cases the Fashion-MNIST dataset was downscaled using PCA to convert into quantum data where the classical NN easily outperformed the QNN. However, we demonstrated quantum advantage by using PQK where quantum models achieved more than ~90% accuracy surpassing their classical counterpart on the same training dataset as in the first case. In this current work, we use the same dataset fed into a QNN and compare that with performance of a classical NN model. We built an NEQR model circuit to pre-process the same data and feed the images into the QNN. Our results showed marginal improvements (only about ~5.0%) where the QNN performance with NEQR exceeded the performance of QNN without NEQR. We conclude that given the computational cost and the massive circuit depth associated with running NEQR, the advantage offered by this specific Quantum Image Processing (QIMP) algorithm is questionable at least for classical image dataset. No actual quantum computing hardware platform exists today that can support the circuit depth needed to run NEQR even for the reduced image sizes of our toy classical dataset. ",
    "url": "https://arxiv.org/abs/2204.02797",
    "authors": [
      "Santanu Ganguly"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1701.07447",
    "title": "An Explicit, Coupled-Layer Construction of a High-Rate Regenerating Code  with Low Sub-Packetization Level, Small Field Size and $d< (n-1)$",
    "abstract": " Comments: In the revised version, a correction is made in the rate calculation. The rate reduces and the code fails to be an MSR code. arXiv admin note: text overlap with arXiv:1607.07335 ",
    "url": "https://arxiv.org/abs/1701.07447",
    "authors": [
      "Birenjith Sasidharan",
      "Myna Vajha",
      "P. Vijay Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:1704.01069",
    "title": "ME R-CNN: Multi-Expert R-CNN for Object Detection",
    "abstract": " Comments: IEEE Transactions on Image Processing ",
    "url": "https://arxiv.org/abs/1704.01069",
    "authors": [
      "Hyungtae Lee",
      "Sungmin Eum",
      "Heesung Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1902.03871",
    "title": "Learning V1 Simple Cells with Vector Representation of Local Content and  Matrix Representation of Local Motion",
    "abstract": " Title: Learning V1 Simple Cells with Vector Representation of Local Content and  Matrix Representation of Local Motion ",
    "url": "https://arxiv.org/abs/1902.03871",
    "authors": [
      "Ruiqi Gao",
      "Jianwen Xie",
      "Siyuan Huang",
      "Yufan Ren",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1911.09419",
    "title": "Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction",
    "abstract": " Comments: Accepted to AAAI 2020 ",
    "url": "https://arxiv.org/abs/1911.09419",
    "authors": [
      "Zhanqiu Zhang",
      "Jianyu Cai",
      "Yongdong Zhang",
      "Jie Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.09365",
    "title": "Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing",
    "abstract": " Comments: v5 is the camera-ready version of this paper on ICLR 2022 ",
    "url": "https://arxiv.org/abs/2006.09365",
    "authors": [
      "Sai Praneeth Karimireddy",
      "Lie He",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.06069",
    "title": "Semantically Adversarial Learnable Filters",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2008.06069",
    "authors": [
      "Ali Shahin Shamsabadi",
      "Changjae Oh",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2009.04544",
    "title": "Self-Adaptive Physics-Informed Neural Networks using a Soft Attention  Mechanism",
    "abstract": " Comments: Submitted to Journal of Computational Physics ",
    "url": "https://arxiv.org/abs/2009.04544",
    "authors": [
      "Levi McClenny",
      "Ulisses Braga-Neto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2101.05043",
    "title": "Video action recognition for lane-change classification and prediction  of surrounding vehicles",
    "abstract": " Comments: Accepted Manuscript IEEE Transactions on Intelligent Vehicles. arXiv admin note: substantial text overlap with arXiv:2008.10869 ",
    "url": "https://arxiv.org/abs/2101.05043",
    "authors": [
      "Mahdi Biparva",
      "David Fern\u00e1ndez-Llorca",
      "Rub\u00e9n Izquierdo-Gonzalo",
      "John K. Tsotsos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2102.07064",
    "title": "NeRF--: Neural Radiance Fields Without Known Camera Parameters",
    "abstract": " Comments: Project page see this https URL Add a break point analysis experiment and release a BLEFF dataset ",
    "url": "https://arxiv.org/abs/2102.07064",
    "authors": [
      "Zirui Wang",
      "Shangzhe Wu",
      "Weidi Xie",
      "Min Chen",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.11399",
    "title": "Learning Calibrated-Guidance for Object Detection in Aerial Images",
    "abstract": " Title: Learning Calibrated-Guidance for Object Detection in Aerial Images ",
    "url": "https://arxiv.org/abs/2103.11399",
    "authors": [
      "Zongqi Wei",
      "Dong Liang",
      "Dong Zhang",
      "Liyan Zhang",
      "Qixiang Geng",
      "Mingqiang Wei",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.01546",
    "title": "Graph Sampling Based Deep Metric Learning for Generalizable Person  Re-Identification",
    "abstract": " Comments: This paper has been accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2104.01546",
    "authors": [
      "Shengcai Liao",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.05087",
    "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion  Attacks in Deep RL",
    "abstract": " Comments: In the 10th International Conference on Learning Representations (ICLR 2022) ",
    "url": "https://arxiv.org/abs/2106.05087",
    "authors": [
      "Yanchao Sun",
      "Ruijie Zheng",
      "Yongyuan Liang",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.14836",
    "title": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "abstract": " Title: Understanding Dynamics of Nonlinear Representation Learning and Its  Application ",
    "url": "https://arxiv.org/abs/2106.14836",
    "authors": [
      "Kenji Kawaguchi",
      "Linjun Zhang",
      "Zhun Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.15850",
    "title": "Exploring Robust Architectures for Deep Artificial Neural Networks",
    "abstract": " Comments: 27 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2106.15850",
    "authors": [
      "Asim Waqas",
      "Ghulam Rasool",
      "Hamza Farooq",
      "Nidhal C. Bouaynaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.00710",
    "title": "Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition  Based on Wrist-worn Sensors",
    "abstract": " Comments: Published in IEEE Pervasive Computing in 2022. 12 pages + 2. 2 Figures and 3 tables ",
    "url": "https://arxiv.org/abs/2107.00710",
    "authors": [
      "Ulysse C\u00f4t\u00e9-Allard",
      "Petter Jakobsen",
      "Andrea Stautland",
      "Tine Nordgreen",
      "Ole Bernt Fasmer",
      "Ketil Joachim Oedegaard",
      "Jim Torresen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.06773",
    "title": "Relational graph convolutional networks for predicting blood-brain  barrier penetration of drug molecules",
    "abstract": " Title: Relational graph convolutional networks for predicting blood-brain  barrier penetration of drug molecules ",
    "url": "https://arxiv.org/abs/2107.06773",
    "authors": [
      "Yan Ding",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.03775",
    "title": "FedZKT: Zero-Shot Knowledge Transfer towards Resource-Constrained  Federated Learning with Heterogeneous On-Device Models",
    "abstract": " Comments: This paper has been accepted to ICDCS 2022 ",
    "url": "https://arxiv.org/abs/2109.03775",
    "authors": [
      "Lan Zhang",
      "Dapeng Wu",
      "Xiaoyong Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.06096",
    "title": "The Grammar-Learning Trajectories of Neural Language Models",
    "abstract": " Comments: ACL camera-ready ",
    "url": "https://arxiv.org/abs/2109.06096",
    "authors": [
      "Leshem Choshen",
      "Guy Hacohen",
      "Daphna Weinshall",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.15285",
    "title": "Improving Neural Ranking via Lossless Knowledge Distillation",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2109.15285",
    "authors": [
      "Zhen Qin",
      "Le Yan",
      "Yi Tay",
      "Honglei Zhuang",
      "Xuanhui Wang",
      "Michael Bendersky",
      "Marc Najork"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2110.05116",
    "title": "Towards Explainable Real Estate Valuation via Evolutionary Algorithms",
    "abstract": " Title: Towards Explainable Real Estate Valuation via Evolutionary Algorithms ",
    "url": "https://arxiv.org/abs/2110.05116",
    "authors": [
      "Sebastian Angrick",
      "Ben Bals",
      "Niko Hastrich",
      "Maximilian Kleissl",
      "Jonas Schmidt",
      "Vanja Dosko\u010d",
      "Maximilian Katzmann",
      "Louise Molitor",
      "Tobias Friedrich"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2110.10757",
    "title": "TPARN: Triple-path Attentive Recurrent Network for Time-domain  Multichannel Speech Enhancement",
    "abstract": " Comments: Accepted for publication in ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2110.10757",
    "authors": [
      "Ashutosh Pandey",
      "Buye Xu",
      "Anurag Kumar",
      "Jacob Donley",
      "Paul Calamia",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.13146",
    "title": "Reduce the rank calculation of a high-dimensional sparse matrix based on  network controllability theory",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2110.13146",
    "authors": [
      "Chen Zhao",
      "Yuqing Liu",
      "Li Hu",
      "Zhengzhong Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.14170",
    "title": "Meta-Knowledge Transfer for Inductive Knowledge Graph Embedding",
    "abstract": " Comments: SIGIR 2022 ",
    "url": "https://arxiv.org/abs/2110.14170",
    "authors": [
      "Mingyang Chen",
      "Wen Zhang",
      "Yushan Zhu",
      "Hongting Zhou",
      "Zonggang Yuan",
      "Changliang Xu",
      "Huajun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2111.09771",
    "title": "Transformer-S2A: Robust and Efficient Speech-to-Animation",
    "abstract": " Comments: Accepted by ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2111.09771",
    "authors": [
      "Liyang Chen",
      "Zhiyong Wu",
      "Jun Ling",
      "Runnan Li",
      "Xu Tan",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.11426",
    "title": "Neural Fields in Visual Computing and Beyond",
    "abstract": " Comments: Equal advising: Vincent Sitzmann and Srinath Sridhar ",
    "url": "https://arxiv.org/abs/2111.11426",
    "authors": [
      "Yiheng Xie",
      "Towaki Takikawa",
      "Shunsuke Saito",
      "Or Litany",
      "Shiqin Yan",
      "Numair Khan",
      "Federico Tombari",
      "James Tompkin",
      "Vincent Sitzmann",
      "Srinath Sridhar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.15222",
    "title": "SP-SEDT: Self-supervised Pre-training for Sound Event Detection  Transformer",
    "abstract": " Comments: Submitted to interspeech 2022; added experiments for section 4 ",
    "url": "https://arxiv.org/abs/2111.15222",
    "authors": [
      "Zhirong Ye",
      "Xiangdong Wang",
      "Hong Liu",
      "Yueliang Qian",
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.15234",
    "title": "NeRFReN: Neural Radiance Fields with Reflections",
    "abstract": " Comments: Accepted to CVPR 2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2111.15234",
    "authors": [
      "Yuan-Chen Guo",
      "Di Kang",
      "Linchao Bao",
      "Yu He",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2111.15491",
    "title": "PolyWorld: Polygonal Building Extraction with Graph Neural Networks in  Satellite Images",
    "abstract": " Title: PolyWorld: Polygonal Building Extraction with Graph Neural Networks in  Satellite Images ",
    "url": "https://arxiv.org/abs/2111.15491",
    "authors": [
      "Stefano Zorzi",
      "Shabab Bazrafkan",
      "Stefan Habenschuss",
      "Friedrich Fraundorfer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15594",
    "title": "A Neural Network Solves, Explains, and Generates University Math  Problems by Program Synthesis and Few-Shot Learning at Human Level",
    "abstract": " Comments: 180 pages, 8 figures, 280 tables ",
    "url": "https://arxiv.org/abs/2112.15594",
    "authors": [
      "Iddo Drori",
      "Sarah Zhang",
      "Reece Shuttleworth",
      "Leonard Tang",
      "Albert Lu",
      "Elizabeth Ke",
      "Kevin Liu",
      "Linda Chen",
      "Sunny Tran",
      "Newman Cheng",
      "Roman Wang",
      "Nikhil Singh",
      "Taylor L. Patti",
      "Jayson Lynch",
      "Avi Shporer",
      "Nakul Verma",
      "Eugene Wu",
      "Gilbert Strang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.05545",
    "title": "Multimodal registration of FISH and nanoSIMS images using convolutional  neural network models",
    "abstract": " Title: Multimodal registration of FISH and nanoSIMS images using convolutional  neural network models ",
    "url": "https://arxiv.org/abs/2201.05545",
    "authors": [
      "Xiaojia He",
      "Christof Meile",
      "Suchendra M. Bhandarkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.09953",
    "title": "Challenges in Migrating Imperative Deep Learning Programs to Graph  Execution: An Empirical Study",
    "abstract": " Comments: International Conference on Mining Software Repositories, MSR 2022. ACM/IEEE, ACM, May 2022 ",
    "url": "https://arxiv.org/abs/2201.09953",
    "authors": [
      "Tatiana Castro V\u00e9lez",
      "Raffi Khatchadourian",
      "Mehdi Bagherzadeh",
      "Anita Raja"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2202.05452",
    "title": "Information Design for Differential Privacy",
    "abstract": " Title: Information Design for Differential Privacy ",
    "url": "https://arxiv.org/abs/2202.05452",
    "authors": [
      "Ian M. Schmutte",
      "Nathan Yoder"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.13457",
    "title": "Enhancing Legal Argument Mining with Domain Pre-training and Neural  Networks",
    "abstract": " Title: Enhancing Legal Argument Mining with Domain Pre-training and Neural  Networks ",
    "url": "https://arxiv.org/abs/2202.13457",
    "authors": [
      "Gechuan Zhang",
      "Paul Nulty",
      "David Lillis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.04746",
    "title": "SkinningNet: Two-Stream Graph Convolutional Neural Network for Skinning  Prediction of Synthetic Characters",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.04746",
    "authors": [
      "Albert Mosella-Montoro",
      "Javier Ruiz-Hidalgo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08392",
    "title": "Patch-Fool: Are Vision Transformers Always Robust Against Adversarial  Perturbations?",
    "abstract": " Comments: Accepted at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2203.08392",
    "authors": [
      "Yonggan Fu",
      "Shunyao Zhang",
      "Shang Wu",
      "Cheng Wan",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.12899",
    "title": "Expression Classification using Concatenation of Deep Neural Network for  the 3rd ABAW3 Competition",
    "abstract": " Title: Expression Classification using Concatenation of Deep Neural Network for  the 3rd ABAW3 Competition ",
    "url": "https://arxiv.org/abs/2203.12899",
    "authors": [
      "Kim Ngan Phan",
      "Hong-Hai Nguyen",
      "Van-Thong Huynh",
      "Soo-Hyung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.12949",
    "title": "Duality-Induced Regularizer for Semantic Matching Knowledge Graph  Embeddings",
    "abstract": " Comments: Accepted to TPAMI. This work is a journal extension of our NeurIPS'20 paper arXiv:2011.05816 ",
    "url": "https://arxiv.org/abs/2203.12949",
    "authors": [
      "Jie Wang",
      "Zhanqiu Zhang",
      "Zhihao Shi",
      "Jianyu Cai",
      "Shuiwang Ji",
      "Feng Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.13273",
    "title": "On Exploiting Layerwise Gradient Statistics for Effective Training of  Deep Neural Networks",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2203.13273",
    "authors": [
      "Guoqiang Zhang",
      "Kenta Niwa",
      "W. Bastiaan Kleijn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.14328",
    "title": "On the Neural Tangent Kernel Analysis of Randomly Pruned Wide Neural  Networks",
    "abstract": " Title: On the Neural Tangent Kernel Analysis of Randomly Pruned Wide Neural  Networks ",
    "url": "https://arxiv.org/abs/2203.14328",
    "authors": [
      "Hongru Yang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.14550",
    "title": "CenterLoc3D: Monocular 3D Vehicle Localization Network for Roadside  Surveillance Cameras",
    "abstract": " Comments: 15 pages, 15 figures. v2. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2203.14550",
    "authors": [
      "Tang Xinyao",
      "Song Huansheng",
      "Wang Wei",
      "Zhao Chunhui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15112",
    "title": "Domain Knowledge Driven Pseudo Labels for Interpretable Goal-Conditioned  Interactive Trajectory Prediction",
    "abstract": " Title: Domain Knowledge Driven Pseudo Labels for Interpretable Goal-Conditioned  Interactive Trajectory Prediction ",
    "url": "https://arxiv.org/abs/2203.15112",
    "authors": [
      "Lingfeng Sun",
      "Chen Tang",
      "Yaru Niu",
      "Enna Sachdeva",
      "Chiho Choi",
      "Teruhisa Misu",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.16939",
    "title": "Hypergraph Convolutional Networks via Equivalency between Hypergraphs  and Undirected Graphs",
    "abstract": " Title: Hypergraph Convolutional Networks via Equivalency between Hypergraphs  and Undirected Graphs ",
    "url": "https://arxiv.org/abs/2203.16939",
    "authors": [
      "Jiying Zhang",
      "Fuyang Li",
      "Xi Xiao",
      "Tingyang Xu",
      "Yu Rong",
      "Junzhou Huang",
      "Yatao Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.17089",
    "title": "Quantum-Aided Meta-Learning for Bayesian Binary Neural Networks via Born  Machines",
    "abstract": " Comments: submitted for publication ",
    "url": "https://arxiv.org/abs/2203.17089",
    "authors": [
      "Ivana Nikoloska",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.01028",
    "title": "MSCCD: Grammar Pluggable Clone Detection Based on ANTLR Parser  Generation",
    "abstract": " Comments: ICPC2022 ",
    "url": "https://arxiv.org/abs/2204.01028",
    "authors": [
      "Wenqing Zhu",
      "Norihiro Yoshida",
      "Toshihiro Kamiya",
      "Eunjong Choi",
      "Hiroaki Takada"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.01618",
    "title": "Deep-Ensemble-Based Uncertainty Quantification in Spatiotemporal Graph  Neural Networks for Traffic Forecasting",
    "abstract": " Title: Deep-Ensemble-Based Uncertainty Quantification in Spatiotemporal Graph  Neural Networks for Traffic Forecasting ",
    "url": "https://arxiv.org/abs/2204.01618",
    "authors": [
      "Tanwi Mallick",
      "Prasanna Balaprakash",
      "Jane Macfarlane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.01708",
    "title": "MRI-based Multi-task Decoupling Learning for Alzheimer's Disease  Detection and MMSE Score Prediction: A Multi-site Validation",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2204.01708",
    "authors": [
      "Xu Tian",
      "Jin Liu",
      "Hulin Kuang",
      "Yu Sheng",
      "Jianxin Wang",
      "Alzheimer's Disease Neuroimaging Initiative"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.01732",
    "title": "A high-order tensor completion algorithm based on Fully-Connected Tensor  Network weighted optimization",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2204.01732",
    "authors": [
      "Peilin Yang",
      "Yonghui Huang",
      "Yuning Qiu",
      "Weijun Sun",
      "Guoxu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.01734",
    "title": "On Explaining Multimodal Hateful Meme Detection Models",
    "abstract": " Title: On Explaining Multimodal Hateful Meme Detection Models ",
    "url": "https://arxiv.org/abs/2204.01734",
    "authors": [
      "Ming Shan Hee",
      "Roy Ka-Wei Lee",
      "Wen-Haw Chong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.01943",
    "title": "Unified Implicit Neural Stylization",
    "abstract": " Title: Unified Implicit Neural Stylization ",
    "url": "https://arxiv.org/abs/2204.01943",
    "authors": [
      "Zhiwen Fan",
      "Yifan Jiang",
      "Peihao Wang",
      "Xinyu Gong",
      "Dejia Xu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.02128",
    "title": "Computing in Anonymous Dynamic Networks Is Linear",
    "abstract": " Comments: 31 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2204.02128",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.02130",
    "title": "SemanticCAP: Chromatin Accessibility Prediction Enhanced by Features  Learning from a Language Model",
    "abstract": " Title: SemanticCAP: Chromatin Accessibility Prediction Enhanced by Features  Learning from a Language Model ",
    "url": "https://arxiv.org/abs/2204.02130",
    "authors": [
      "Yikang Zhang",
      "Xiaomin Chu",
      "Yelu Jiang",
      "Hongjie Wu",
      "Lijun Quan"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  }
]