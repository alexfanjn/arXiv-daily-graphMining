[
  {
    "id": "arXiv:2204.08458",
    "title": "SuperpixelGridCut, SuperpixelGridMean and SuperpixelGridMix Data  Augmentation",
    "abstract": "A novel approach of data augmentation based on irregular superpixel decomposition is proposed. This approach called SuperpixelGridMasks permits to extend original image datasets that are required by training stages of machine learning-related analysis architectures towards increasing their performances. Three variants named SuperpixelGridCut, SuperpixelGridMean and SuperpixelGridMix are presented. These grid-based methods produce a new style of image transformations using the dropping and fusing of information. Extensive experiments using various image classification models and datasets show that baseline performances can be significantly outperformed using our methods. The comparative study also shows that our methods can overpass the performances of other data augmentations. Experimental results obtained over image recognition datasets of varied natures show the efficiency of these new methods. SuperpixelGridCut, SuperpixelGridMean and SuperpixelGridMix codes are publicly available at https://github.com/hammoudiproject/SuperpixelGridMasks ",
    "url": "https://arxiv.org/abs/2204.08458",
    "authors": [
      "Karim Hammoudi",
      "Adnane Cabani",
      "Bouthaina Slika",
      "Halim Benhabiles",
      "Fadi Dornaika",
      "Mahmoud Melkemi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08460",
    "title": "3D Convolutional Networks for Action Recognition: Application to Sport  Gesture Recognition",
    "abstract": "3D convolutional networks is a good means to perform tasks such as video segmentation into coherent spatio-temporal chunks and classification of them with regard to a target taxonomy. In the chapter we are interested in the classification of continuous video takes with repeatable actions, such as strokes of table tennis. Filmed in a free marker less ecological environment, these videos represent a challenge from both segmentation and classification point of view. The 3D convnets are an efficient tool for solving these problems with window-based approaches. ",
    "url": "https://arxiv.org/abs/2204.08460",
    "authors": [
      "Pierre-Etienne Martin",
      "J Benois-Pineau",
      "R P\u00e9teri",
      "A Zemmari",
      "J Morlier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.08461",
    "title": "Investigating Temporal Convolutional Neural Networks for Satellite Image  Time Series Classification",
    "abstract": "Satellite Image Time Series (SITS) of the Earth's surface provide detailed land cover maps, with their quality in the spatial and temporal dimensions consistently improving. These image time series are integral for developing systems that aim to produce accurate, up-to-date land cover maps of the Earth's surface. Applications are wide-ranging, with notable examples including ecosystem mapping, vegetation process monitoring and anthropogenic land-use change tracking. Recently proposed methods for SITS classification have demonstrated respectable merit, but these methods tend to lack native mechanisms that exploit the temporal dimension of the data; commonly resulting in extensive data pre-processing prohibitively long training times. To overcome these shortcomings, this paper seeks to study and enhance the newly proposed method for SITS classification from literature; namely Temporal CNNs. Comprehensive experiments are carried out on two benchmark SITS datasets with the results demonstrating that Temporal CNNs display a superior or competitive performance to the benchmark algorithms for both datasets. Investigations into the Temporal CNNs architecture also highlighted the non-trivial task of optimising the model for a new dataset. ",
    "url": "https://arxiv.org/abs/2204.08461",
    "authors": [
      "James Brock",
      "Zahraa S. Abdallah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08465",
    "title": "Intelligent Spatial Interpolation-based Frost Prediction Methodology  using Artificial Neural Networks with Limited Local Data",
    "abstract": "The weather phenomenon of frost poses great threats to agriculture. Since it damages the crops and plants from upstream of the supply chain, the potential impact of frosts is significant for agriculture-related industries. As recent frost prediction methods are based on on-site historical data and sensors, extra development and deployment time are required for data collection in any new site. The aim of this article is to eliminate the dependency on on-site historical data and sensors for frost prediction methods. In this article, a frost prediction method based on spatial interpolation is proposed. The models use climate data from existing weather stations, digital elevation models surveys, and normalized difference vegetation index data to estimate a target site's next hour minimum temperature. The proposed method utilizes ensemble learning to increase the model accuracy. Ensemble methods include averaging and weighted averaging. Climate datasets are obtained from 75 weather stations across New South Wales and Australian Capital Territory areas of Australia. The models are constructed with five-fold validation, splitting the weather stations into five testing dataset folds. For each fold, the other stations act as training datasets. After the models are constructed, three experiments are conducted. The first experiment compares the results generated by models between different folds. Then, the second experiment compares the accuracy of different methods. The final experiment reveals the effect of available stations on the proposed models. The results show that the proposed method reached a detection rate up to 92.55%. This method could be implemented as an alternative solution when on-site historical datasets are scarce. ",
    "url": "https://arxiv.org/abs/2204.08465",
    "authors": [
      "Ian Zhou",
      "Justin Lipman",
      "Mehran Abolhasan",
      "Negin Shariati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08474",
    "title": "AB/BA analysis: A framework for estimating keyword spotting recall  improvement while maintaining audio privacy",
    "abstract": "Evaluation of keyword spotting (KWS) systems that detect keywords in speech is a challenging task under realistic privacy constraints. The KWS is designed to only collect data when the keyword is present, limiting the availability of hard samples that may contain false negatives, and preventing direct estimation of model recall from production data. Alternatively, complementary data collected from other sources may not be fully representative of the real application. In this work, we propose an evaluation technique which we call AB/BA analysis. Our framework evaluates a candidate KWS model B against a baseline model A, using cross-dataset offline decoding for relative recall estimation, without requiring negative examples. Moreover, we propose a formulation with assumptions that allow estimation of relative false positive rate between models with low variance even when the number of false positives is small. Finally, we propose to leverage machine-generated soft labels, in a technique we call Semi-Supervised AB/BA analysis, that improves the analysis time, privacy, and cost. Experiments with both simulation and real data show that AB/BA analysis is successful at measuring recall improvement in conjunction with the trade-off in relative false positive rate. ",
    "url": "https://arxiv.org/abs/2204.08474",
    "authors": [
      "Raphael Petegrosso",
      "Vasistakrishna Baderdinni",
      "Thibaud Senechal",
      "Benjamin L. Bullough"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.08476",
    "title": "Research on Domain Information Mining and Theme Evolution of Scientific  Papers",
    "abstract": "In recent years, with the increase of social investment in scientific research, the number of research results in various fields has increased significantly. Cross-disciplinary research results have gradually become an emerging frontier research direction. There is a certain dependence between a large number of research results. It is difficult to effectively analyze today's scientific research results when looking at a single research field in isolation. How to effectively use the huge number of scientific papers to help researchers becomes a challenge. This paper introduces the research status at home and abroad in terms of domain information mining and topic evolution law of scientific and technological papers from three aspects: the semantic feature representation learning of scientific and technological papers, the field information mining of scientific and technological papers, and the mining and prediction of research topic evolution rules of scientific and technological papers. ",
    "url": "https://arxiv.org/abs/2204.08476",
    "authors": [
      "Changwei Zheng",
      "Zhe Xue",
      "Meiyu Liang",
      "Feifei Kou",
      "Zeli Guan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08479",
    "title": "Inductive Biases for Object-Centric Representations of Complex Textures",
    "abstract": "Understanding which inductive biases could be useful for the unsupervised learning of object-centric representations of natural scenes is challenging. Here, we use neural style transfer to generate datasets where objects have complex textures while still retaining ground-truth annotations. We find that, when a model effectively balances the importance of shape and appearance in the training objective, it can achieve better separation of the objects and learn more useful object representations. ",
    "url": "https://arxiv.org/abs/2204.08479",
    "authors": [
      "Samuele Papa",
      "Ole Winther",
      "Andrea Dittadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08504",
    "title": "CGC: Contrastive Graph Clustering for Community Detection and Tracking",
    "abstract": "Given entities and their interactions in the web data, which may have occurred at different time, how can we find communities of entities and track their evolution? In this paper, we approach this important task from graph clustering perspective. Recently, state-of-the-art clustering performance in various domains has been achieved by deep clustering methods. Especially, deep graph clustering (DGC) methods have successfully extended deep clustering to graph-structured data by learning node representations and cluster assignments in a joint optimization framework. Despite some differences in modeling choices (e.g., encoder architectures), existing DGC methods are mainly based on autoencoders and use the same clustering objective with relatively minor adaptations. Also, while many real-world graphs are dynamic, previous DGC methods considered only static graphs. In this work, we develop CGC, a novel end-to-end framework for graph clustering, which fundamentally differs from existing methods. CGC learns node embeddings and cluster assignments in a contrastive graph learning framework, where positive and negative samples are carefully selected in a multi-level scheme such that they reflect hierarchical community structures and network homophily. Also, we extend CGC for time-evolving data, where temporal graph clustering is performed in an incremental learning fashion, with the ability to detect change points. Extensive evaluation on real-world graphs demonstrates that the proposed CGC consistently outperforms existing methods. ",
    "url": "https://arxiv.org/abs/2204.08504",
    "authors": [
      "Namyong Park",
      "Ryan Rossi",
      "Eunyee Koh",
      "Iftikhar Ahamath Burhanuddin",
      "Sungchul Kim",
      "Fan Du",
      "Nesreen Ahmed",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08529",
    "title": "Improving Information Cascade Modeling by Social Topology and Dual Role  User Dependency",
    "abstract": "In the last decade, information diffusion (also known as information cascade) on social networks has been massively investigated due to its application values in many fields. In recent years, many sequential models including those models based on recurrent neural networks have been broadly employed to predict information cascade. However, the user dependencies in a cascade sequence captured by sequential models are generally unidirectional and inconsistent with diffusion trees. For example, the true trigger of a successor may be a non-immediate predecessor rather than the immediate predecessor in the sequence. To capture user dependencies more sufficiently which are crucial to precise cascade modeling, we propose a non-sequential information cascade model named as TAN-DRUD (Topology-aware Attention Networks with Dual Role User Dependency). TAN-DRUD obtains satisfactory performance on information cascade modeling through capturing the dual role user dependencies of information sender and receiver, which is inspired by the classic communication theory. Furthermore, TANDRUD incorporates social topology into two-level attention networks for enhanced information diffusion prediction. Our extensive experiments on three cascade datasets demonstrate that our model is not only superior to the state-of-the-art cascade models, but also capable of exploiting topology information and inferring diffusion trees. ",
    "url": "https://arxiv.org/abs/2204.08529",
    "authors": [
      "Baichuan Liu",
      "Deqing Yang",
      "Yueyi Wang",
      "Yuchen Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08545",
    "title": "A Novel Region Duplication Detection Algorithm Based on Hybrid Approach",
    "abstract": "The digital images from various sources are ubiquitous due to easy availability of high bandwidth Internet. Digital images are easy to tamper with good or bad intentions. Non-availability of pre-embedded information in digital images makes the tampering detection process more difficult in case of digital forensics. Thus, passive image tampering is difficult to detect. There are various algorithms available for detecting image tampering. However, these algorithms have some drawbacks, due to which all types of tampering cannot be detected. In this paper researchers intend to present the types of image tampering and its detection techniques with example based approach. This paper also illustrates insights into the various existing algorithms and tries to find out efficient algorithm out of them. ",
    "url": "https://arxiv.org/abs/2204.08545",
    "authors": [
      "Kshipra Tatkare",
      "Manoj Devare"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08557",
    "title": "PIDGeuN: Graph Neural Network-Enabled Transient Dynamics Prediction of  Networked Microgrids Through Full-Field Measurement",
    "abstract": "A Physics-Informed Dynamic Graph Neural Network (PIDGeuN) is presented to accurately, efficiently and robustly predict the nonlinear transient dynamics of microgrids in the presence of disturbances. The graph-based architecture of PIDGeuN provides a natural representation of the microgrid topology. Using only the state information that is practically measurable, PIDGeuN employs a time delay embedding formulation to fully reproduce the system dynamics, avoiding the dependency of conventional methods on internal dynamic states such as controllers. Based on a judiciously designed message passing mechanism, the PIDGeuN incorporates two physics-informed techniques to improve its prediction performance, including a physics-data-infusion approach to determining the inter-dependencies between buses, and a loss term to respect the known physical law of the power system, i.e., the Kirchhoff's law, to ensure the feasibility of the model prediction. Extensive tests show that PIDGeuN can provide accurate and robust prediction of transient dynamics for nonlinear microgrids over a long-term time period. Therefore, the PIDGeuN offers a potent tool for the modeling of large scale networked microgrids (NMs), with potential applications to predictive or preventive control in real time applications for the stable and resilient operations of NMs. ",
    "url": "https://arxiv.org/abs/2204.08557",
    "authors": [
      "Yin Yu",
      "Xinyuan Jiang",
      "Daning Huang",
      "Yan Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.08570",
    "title": "A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy,  Robustness, Fairness, and Explainability",
    "abstract": "Graph Neural Networks (GNNs) have made rapid developments in the recent years. Due to their great ability in modeling graph-structured data, GNNs are vastly used in various applications, including high-stakes scenarios such as financial analysis, traffic predictions, and drug discovery. Despite their great potential in benefiting humans in the real world, recent study shows that GNNs can leak private information, are vulnerable to adversarial attacks, can inherit and magnify societal bias from training data and lack interpretability, which have risk of causing unintentional harm to the users and society. For example, existing works demonstrate that attackers can fool the GNNs to give the outcome they desire with unnoticeable perturbation on training graph. GNNs trained on social networks may embed the discrimination in their decision process, strengthening the undesirable societal bias. Consequently, trustworthy GNNs in various aspects are emerging to prevent the harm from GNN models and increase the users' trust in GNNs. In this paper, we give a comprehensive survey of GNNs in the computational aspects of privacy, robustness, fairness, and explainability. For each aspect, we give the taxonomy of the related methods and formulate the general frameworks for the multiple categories of trustworthy GNNs. We also discuss the future research directions of each aspect and connections between these aspects to help achieve trustworthiness. ",
    "url": "https://arxiv.org/abs/2204.08570",
    "authors": [
      "Enyan Dai",
      "Tianxiang Zhao",
      "Huaisheng Zhu",
      "Junjie Xu",
      "Zhimeng Guo",
      "Hui Liu",
      "Jiliang Tang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.08587",
    "title": "Spatial-Temporal Hypergraph Self-Supervised Learning for Crime  Prediction",
    "abstract": "Crime has become a major concern in many cities, which calls for the rising demand for timely predicting citywide crime occurrence. Accurate crime prediction results are vital for the beforehand decision-making of government to alleviate the increasing concern about the public safety. While many efforts have been devoted to proposing various spatial-temporal forecasting techniques to explore dependence across locations and time periods, most of them follow a supervised learning manner, which limits their spatial-temporal representation ability on sparse crime data. Inspired by the recent success in self-supervised learning, this work proposes a Spatial-Temporal Hypergraph Self-Supervised Learning framework (ST-HSL) to tackle the label scarcity issue in crime prediction. Specifically, we propose the cross-region hypergraph structure learning to encode region-wise crime dependency under the entire urban space. Furthermore, we design the dual-stage self-supervised learning paradigm, to not only jointly capture local- and global-level spatial-temporal crime patterns, but also supplement the sparse crime representation by augmenting region self-discrimination. We perform extensive experiments on two real-life crime datasets. Evaluation results show that our ST-HSL significantly outperforms state-of-the-art baselines. Further analysis provides insights into the superiority of our ST-HSL method in the representation of spatial-temporal crime patterns. The implementation code is available at https://github.com/LZH-YS1998/STHSL. ",
    "url": "https://arxiv.org/abs/2204.08587",
    "authors": [
      "Zhonghang Li",
      "Chao Huang",
      "Lianghao Xia",
      "Yong Xu",
      "Jian Pei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2204.08609",
    "title": "\"Flux+Mutability\": A Conditional Generative Approach to One-Class  Classification and Anomaly Detection",
    "abstract": "Anomaly Detection is becoming increasingly popular within the experimental physics community. At experiments such as the Large Hadron Collider, anomaly detection is at the forefront of finding new physics beyond the Standard Model. This paper details the implementation of a novel Machine Learning architecture, called Flux+Mutability, which combines cutting-edge conditional generative models with clustering algorithms. In the `flux' stage we learn the distribution of a reference class. The `mutability' stage at inference addresses if data significantly deviates from the reference class. We demonstrate the validity of our approach and its connection to multiple problems spanning from one-class classification to anomaly detection. In particular, we apply our method to the isolation of neutral showers in an electromagnetic calorimeter and show its performance in detecting anomalous dijets events from standard QCD background. This approach limits assumptions on the reference sample and remains agnostic to the complementary class of objects of a given problem. We describe the possibility of dynamically generating a reference population and defining selection criteria via quantile cuts. Remarkably this flexible architecture can be deployed for a wide range of problems, and applications like multi-class classification or data quality control are left for further exploration. ",
    "url": "https://arxiv.org/abs/2204.08609",
    "authors": [
      "C. Fanelli",
      "J. Giroux",
      "Z. Papandreou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Nuclear Experiment (nucl-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2204.08610",
    "title": "Image Data Augmentation for Deep Learning: A Survey",
    "abstract": "Deep learning has achieved remarkable results in many computer vision tasks. Deep neural networks typically rely on large amounts of training data to avoid overfitting. However, labeled data for real-world applications may be limited. By improving the quantity and diversity of training data, data augmentation has become an inevitable part of deep learning model training with image data. As an effective way to improve the sufficiency and diversity of training data, data augmentation has become a necessary part of successful application of deep learning models on image data. In this paper, we systematically review different image data augmentation methods. We propose a taxonomy of reviewed methods and present the strengths and limitations of these methods. We also conduct extensive experiments with various data augmentation methods on three typical computer vision tasks, including semantic segmentation, image classification and object detection. Finally, we discuss current challenges faced by data augmentation and future research directions to put forward some useful research guidance. ",
    "url": "https://arxiv.org/abs/2204.08610",
    "authors": [
      "Suorong Yang",
      "Weikang Xiao",
      "Mengcheng Zhang",
      "Suhan Guo",
      "Jian Zhao",
      "Furao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08612",
    "title": "Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors",
    "abstract": "Deepfakes utilise Artificial Intelligence (AI) techniques to create synthetic media where the likeness of one person is replaced with another. There are growing concerns that deepfakes can be maliciously used to create misleading and harmful digital contents. As deepfakes become more common, there is a dire need for deepfake detection technology to help spot deepfake media. Present deepfake detection models are able to achieve outstanding accuracy (>90%). However, most of them are limited to within-dataset scenario, where the same dataset is used for training and testing. Most models do not generalise well enough in cross-dataset scenario, where models are tested on unseen datasets from another source. Furthermore, state-of-the-art deepfake detection models rely on neural network-based classification models that are known to be vulnerable to adversarial attacks. Motivated by the need for a robust deepfake detection model, this study adapts metamorphic testing (MT) principles to help identify potential factors that could influence the robustness of the examined model, while overcoming the test oracle problem in this domain. Metamorphic testing is specifically chosen as the testing technique as it fits our demand to address learning-based system testing with probabilistic outcomes from largely black-box components, based on potentially large input domains. We performed our evaluations on MesoInception-4 and TwoStreamNet models, which are the state-of-the-art deepfake detection models. This study identified makeup application as an adversarial attack that could fool deepfake detectors. Our experimental results demonstrate that both the MesoInception-4 and TwoStreamNet models degrade in their performance by up to 30\\% when the input data is perturbed with makeup. ",
    "url": "https://arxiv.org/abs/2204.08612",
    "authors": [
      "Nyee Thoang Lim",
      "Meng Yi Kuan",
      "Muxin Pu",
      "Mei Kuan Lim",
      "Chun Yong Chong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08613",
    "title": "Self-Supervised Equivariant Learning for Oriented Keypoint Detection",
    "abstract": "Detecting robust keypoints from an image is an integral part of many computer vision problems, and the characteristic orientation and scale of keypoints play an important role for keypoint description and matching. Existing learning-based methods for keypoint detection rely on standard translation-equivariant CNNs but often fail to detect reliable keypoints against geometric variations. To learn to detect robust oriented keypoints, we introduce a self-supervised learning framework using rotation-equivariant CNNs. We propose a dense orientation alignment loss by an image pair generated by synthetic transformations for training a histogram-based orientation map. Our method outperforms the previous methods on an image matching benchmark and a camera pose estimation benchmark. ",
    "url": "https://arxiv.org/abs/2204.08613",
    "authors": [
      "Jongmin Lee",
      "Byungjin Kim",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08621",
    "title": "Proximal Implicit ODE Solvers for Accelerating Learning Neural ODEs",
    "abstract": "Learning neural ODEs often requires solving very stiff ODE systems, primarily using explicit adaptive step size ODE solvers. These solvers are computationally expensive, requiring the use of tiny step sizes for numerical stability and accuracy guarantees. This paper considers learning neural ODEs using implicit ODE solvers of different orders leveraging proximal operators. The proximal implicit solver consists of inner-outer iterations: the inner iterations approximate each implicit update step using a fast optimization algorithm, and the outer iterations solve the ODE system over time. The proximal implicit ODE solver guarantees superiority over explicit solvers in numerical stability and computational efficiency. We validate the advantages of proximal implicit solvers over existing popular neural ODE solvers on various challenging benchmark tasks, including learning continuous-depth graph neural networks and continuous normalizing flows. ",
    "url": "https://arxiv.org/abs/2204.08621",
    "authors": [
      "Justin Baker",
      "Hedi Xia",
      "Yiwei Wang",
      "Elena Cherkaev",
      "Akil Narayan",
      "Long Chen",
      "Jack Xin",
      "Andrea L. Bertozzi",
      "Stanley J. Osher",
      "Bao Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08625",
    "title": "Self Supervised Adversarial Domain Adaptation for Cross-Corpus and  Cross-Language Speech Emotion Recognition",
    "abstract": "Despite the recent advancement in speech emotion recognition (SER) within a single corpus setting, the performance of these SER systems degrades significantly for cross-corpus and cross-language scenarios. The key reason is the lack of generalisation in SER systems towards unseen conditions, which causes them to perform poorly in cross-corpus and cross-language settings. Recent studies focus on utilising adversarial methods to learn domain generalised representation for improving cross-corpus and cross-language SER to address this issue. However, many of these methods only focus on cross-corpus SER without addressing the cross-language SER performance degradation due to a larger domain gap between source and target language data. This contribution proposes an adversarial dual discriminator (ADDi) network that uses the three-players adversarial game to learn generalised representations without requiring any target data labels. We also introduce a self-supervised ADDi (sADDi) network that utilises self-supervised pre-training with unlabelled data. We propose synthetic data generation as a pretext task in sADDi, enabling the network to produce emotionally discriminative and domain invariant representations and providing complementary synthetic data to augment the system. The proposed model is rigorously evaluated using five publicly available datasets in three languages and compared with multiple studies on cross-corpus and cross-language SER. Experimental results demonstrate that the proposed model achieves improved performance compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.08625",
    "authors": [
      "Siddique Latif",
      "Rajib Rana",
      "Sara Khalifa",
      "Raja Jurdak",
      "Bj\u00f6rn Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.08636",
    "title": "Detection Interval for Diffusion Molecular Communication: How Long is  Enough?",
    "abstract": "Molecular communication has a key role to play in future medical applications, including detecting, analyzing, and addressing infectious disease outbreaks. Overcoming inter-symbol interference (ISI) is one of the key challenges in the design of molecular communication systems. In this paper, we propose to optimize the detection interval to minimize the impact of ISI while ensuring the accurate detection of the transmitted information symbol, which is suitable for the absorbing and passive receivers. For tractability, based on the signal-to-interference difference (SID) and signal-to-interference-and-noise amplitude ratio (SINAR), we propose a modified-SINAR (mSINAR) to measure the bit error rate (BER) performance for the molecular communication system with a variable detection interval. Besides, we derive the optimal detection interval in closed form. Using simulation results, we show that the BER performance of our proposed mSINAR scheme is superior to the competing schemes, and achieves similar performance to optimal intervals found by the exhaustive search. ",
    "url": "https://arxiv.org/abs/2204.08636",
    "authors": [
      "Xuan Chen",
      "Miaowen Wen",
      "Fei Ji",
      "Yu Huang",
      "Yuankun Tang",
      "Andrew W. Eckford"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.08653",
    "title": "On The Cross-Modal Transfer from Natural Language to Code through  Adapter Modules",
    "abstract": "Pre-trained neural Language Models (PTLM), such as CodeBERT, are recently used in software engineering as models pre-trained on large source code corpora. Their knowledge is transferred to downstream tasks (e.g. code clone detection) via fine-tuning. In natural language processing (NLP), other alternatives for transferring the knowledge of PTLMs are explored through using adapters, compact, parameter efficient modules inserted in the layers of the PTLM. Although adapters are known to facilitate adapting to many downstream tasks compared to fine-tuning the model that require retraining all of the models' parameters -- which owes to the adapters' plug and play nature and being parameter efficient -- their usage in software engineering is not explored. Here, we explore the knowledge transfer using adapters and based on the Naturalness Hypothesis proposed by Hindle et. al \\cite{hindle2016naturalness}. Thus, studying the bimodality of adapters for two tasks of cloze test and code clone detection, compared to their benchmarks from the CodeXGLUE platform. These adapters are trained using programming languages and are inserted in a PTLM that is pre-trained on English corpora (N-PTLM). Three programming languages, C/C++, Python, and Java, are studied along with extensive experiments on the best setup used for adapters. Improving the results of the N-PTLM confirms the success of the adapters in knowledge transfer to software engineering, which sometimes are in par with or exceed the results of a PTLM trained on source code; while being more efficient in terms of the number of parameters, memory usage, and inference time. Our results can open new directions to build smaller models for more software engineering tasks. We open source all the scripts and the trained adapters. ",
    "url": "https://arxiv.org/abs/2204.08653",
    "authors": [
      "Divyam Goel",
      "Ramansh Grover",
      "Fatemeh H. Fard"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08656",
    "title": "Network Bandwidth Variation-Adapted State Transfer for Geo-Replicated  State Machines and its Application to Dynamic Replica Replacement",
    "abstract": "This paper proposes a new state transfer method for geographic state machine replication (SMR) that dynamically allocates the state to be transferred among replicas according to changes in communication bandwidths. SMR improves fault tolerance by replicating a service to multiple replicas. When a replica is newly added or recovered from a failure, the other replicas transfer the current state of the service to it. However, in geographic SMR, the communication bandwidths of replicas are different and constantly changing. Therefore, existing state transfer methods cannot fully utilize the available bandwidth, and their state transfer time increases. To overcome this problem, our method divides the state into multiple chunks and assigns them to replicas based on each replica's bandwidth so that the broader a replica's bandwidth is, the more chunks it transfers. The proposed method also updates the chunk assignment of each replica dynamically based on the currently estimated bandwidth. The performance evaluation on Amazon EC2 shows that the proposed method reduces the state transfer time by up to 47% compared to the existing one. In addition, we apply the proposed method to dynamic replacement of replicas, which can mitigate latency degradation caused by network trouble, and evaluate how fast the method can relocate a replica. ",
    "url": "https://arxiv.org/abs/2204.08656",
    "authors": [
      "Tairi Chiba",
      "Ren Ohmura",
      "Junya Nakamura"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.08665",
    "title": "Interventional Behavior Prediction: Avoiding Overly Confident  Anticipation in Interactive Prediction",
    "abstract": "Conditional behavior prediction (CBP) builds up the foundation for a coherent interactive prediction and planning framework that can enable more efficient and less conservative maneuvers in interactive scenarios. In CBP task, we train a prediction model approximating the posterior distribution of target agents' future trajectories conditioned on the future trajectory of an assigned ego agent. However, we argue that CBP may provide overly confident anticipation on how the autonomous agent may influence the target agents' behavior. Consequently, it is risky for the planner to query a CBP model. Instead, we should treat the planned trajectory as an intervention and let the model learn the trajectory distribution under intervention. We refer to it as the interventional behavior prediction (IBP) task. Moreover, to properly evaluate an IBP model with offline datasets, we propose a Shapley-value-based metric to testify if the prediction model satisfies the inherent temporal independence of an interventional distribution. We show that the proposed metric can effectively identify a CBP model violating the temporal independence, which plays an important role when establishing IBP benchmarks. ",
    "url": "https://arxiv.org/abs/2204.08665",
    "authors": [
      "Chen Tang",
      "Wei Zhan",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.08669",
    "title": "Mono vs Multilingual BERT for Hate Speech Detection and Text  Classification: A Case Study in Marathi",
    "abstract": "Transformers are the most eminent architectures used for a vast range of Natural Language Processing tasks. These models are pre-trained over a large text corpus and are meant to serve state-of-the-art results over tasks like text classification. In this work, we conduct a comparative study between monolingual and multilingual BERT models. We focus on the Marathi language and evaluate the models on the datasets for hate speech detection, sentiment analysis and simple text classification in Marathi. We use standard multilingual models such as mBERT, indicBERT and xlm-RoBERTa and compare with MahaBERT, MahaALBERT and MahaRoBERTa, the monolingual models for Marathi. We further show that Marathi monolingual models outperform the multilingual BERT variants on five different downstream fine-tuning experiments. We also evaluate sentence embeddings from these models by freezing the BERT encoder layers. We show that monolingual MahaBERT based models provide rich representations as compared to sentence embeddings from multi-lingual counterparts. However, we observe that these embeddings are not generic enough and do not work well on out of domain social media datasets. We consider two Marathi hate speech datasets L3Cube-MahaHate, HASOC-2021, a Marathi sentiment classification dataset L3Cube-MahaSent, and Marathi Headline, Articles classification datasets. ",
    "url": "https://arxiv.org/abs/2204.08669",
    "authors": [
      "Abhishek Velankar",
      "Hrushikesh Patil",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08676",
    "title": "Auto-Icon+: An Automated End-to-End Code Generation Tool for Icon  Designs in UI Development",
    "abstract": "Approximately 50% of development resources are devoted to UI development tasks [9]. Occupying a large proportion of development resources, developing icons can be a time-consuming task, because developers need to consider not only effective implementation methods but also easy-to-understand descriptions. In this paper, we present Auto-Icon+, an approach for automatically generating readable and efficient code for icons from design artifacts. According to our interviews to understand the gap between designers (icons are assembled from multiple components) and developers (icons as single images), we apply a heuristic clustering algorithm to compose the components into an icon image. We then propose an approach based on a deep learning model and computer vision methods to convert the composed icon image to fonts with descriptive labels, thereby reducing the laborious manual effort for developers and facilitating UI development. We quantitatively evaluate the quality of our method in the real world UI development environment and demonstrate that our method offers developers accurate, efficient, readable, and usable code for icon designs, in terms of saving 65.2% implementing time. ",
    "url": "https://arxiv.org/abs/2204.08676",
    "authors": [
      "Sidong Feng",
      "Minmin Jiang",
      "Tingting Zhou",
      "Yankun Zhen",
      "Chunyang Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.08682",
    "title": "Investigation of a Data Split Strategy Involving the Time Axis in  Adverse Event Prediction Using Machine Learning",
    "abstract": "Adverse events are a serious issue in drug development and many prediction methods using machine learning have been developed. The random split cross-validation is the de facto standard for model building and evaluation in machine learning, but care should be taken in adverse event prediction because this approach tends to be overoptimistic compared with the real-world situation. The time split, which uses the time axis, is considered suitable for real-world prediction. However, the differences in model performance obtained using the time and random splits are not fully understood. To understand the differences, we compared the model performance between the time and random splits using eight types of compound information as input, eight adverse events as targets, and six machine learning algorithms. The random split showed higher area under the curve values than did the time split for six of eight targets. The chemical spaces of the training and test datasets of the time split were similar, suggesting that the concept of applicability domain is insufficient to explain the differences derived from the splitting. The area under the curve differences were smaller for the protein interaction than for the other datasets. Subsequent detailed analyses suggested the danger of confounding in the use of knowledge-based information in the time split. These findings indicate the importance of understanding the differences between the time and random splits in adverse event prediction and suggest that appropriate use of the splitting strategies and interpretation of results are necessary for the real-world prediction of adverse events. ",
    "url": "https://arxiv.org/abs/2204.08682",
    "authors": [
      "Katsuhisa Morita",
      "Tadahaya Mizuno",
      "Hiroyuki Kusuhara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2204.08688",
    "title": "DecBERT: Enhancing the Language Understanding of BERT with Causal  Attention Masks",
    "abstract": "Since 2017, the Transformer-based models play critical roles in various downstream Natural Language Processing tasks. However, a common limitation of the attention mechanism utilized in Transformer Encoder is that it cannot automatically capture the information of word order, so explicit position embeddings are generally required to be fed into the target model. In contrast, Transformer Decoder with the causal attention masks is naturally sensitive to the word order. In this work, we focus on improving the position encoding ability of BERT with the causal attention masks. Furthermore, we propose a new pre-trained language model DecBERT and evaluate it on the GLUE benchmark. Experimental results show that (1) the causal attention mask is effective for BERT on the language understanding tasks; (2) our DecBERT model without position embeddings achieve comparable performance on the GLUE benchmark; and (3) our modification accelerates the pre-training process and DecBERT w/ PE achieves better overall performance than the baseline systems when pre-training with the same amount of computational resources. ",
    "url": "https://arxiv.org/abs/2204.08688",
    "authors": [
      "Ziyang Luo",
      "Yadong Xi",
      "Jing Ma",
      "Zhiwei Yang",
      "Xiaoxi Mao",
      "Changjie Fan",
      "Rongsheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.08689",
    "title": "Generating Authentic Adversarial Examples beyond Meaning-preserving with  Doubly Round-trip Translation",
    "abstract": "Generating adversarial examples for Neural Machine Translation (NMT) with single Round-Trip Translation (RTT) has achieved promising results by releasing the meaning-preserving restriction. However, a potential pitfall for this approach is that we cannot decide whether the generated examples are adversarial to the target NMT model or the auxiliary backward one, as the reconstruction error through the RTT can be related to either. To remedy this problem, we propose a new criterion for NMT adversarial examples based on the Doubly Round-Trip Translation (DRTT). Specifically, apart from the source-target-source RTT, we also consider the target-source-target one, which is utilized to pick out the authentic adversarial examples for the target NMT model. Additionally, to enhance the robustness of the NMT model, we introduce the masked language models to construct bilingual adversarial pairs based on DRTT, which are used to train the NMT model directly. Extensive experiments on both the clean and noisy test sets (including the artificial and natural noise) show that our approach substantially improves the robustness of NMT models. ",
    "url": "https://arxiv.org/abs/2204.08689",
    "authors": [
      "Siyu Lai",
      "Zhen Yang",
      "Fandong Meng",
      "Xue Zhang",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.08690",
    "title": "Independence Testing for Bounded Degree Bayesian Network",
    "abstract": "We study the following independence testing problem: given access to samples from a distribution $P$ over $\\{0,1\\}^n$, decide whether $P$ is a product distribution or whether it is $\\varepsilon$-far in total variation distance from any product distribution. For arbitrary distributions, this problem requires $\\exp(n)$ samples. We show in this work that if $P$ has a sparse structure, then in fact only linearly many samples are required. Specifically, if $P$ is Markov with respect to a Bayesian network whose underlying DAG has in-degree bounded by $d$, then $\\tilde{\\Theta}(2^{d/2}\\cdot n/\\varepsilon^2)$ samples are necessary and sufficient for independence testing. ",
    "url": "https://arxiv.org/abs/2204.08690",
    "authors": [
      "Arnab Bhattacharyya",
      "Cl\u00e9ment L. Canonne",
      "Joy Qiping Yang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2204.08696",
    "title": "CTCNet: A CNN-Transformer Cooperation Network for Face Image  Super-Resolution",
    "abstract": "Recently, deep convolution neural networks (CNNs) steered face super-resolution methods have achieved great progress in restoring degraded facial details by jointly training with facial priors. However, these methods have some obvious limitations. On the one hand, multi-task joint learning requires additional marking on the dataset, and the introduced prior network will significantly increase the computational cost of the model. On the other hand, the limited receptive field of CNN will reduce the fidelity and naturalness of the reconstructed facial images, resulting in suboptimal reconstructed images. In this work, we propose an efficient CNN-Transformer Cooperation Network (CTCNet) for face super-resolution tasks, which uses the multi-scale connected encoder-decoder architecture as the backbone. Specifically, we first devise a novel Local-Global Feature Cooperation Module (LGCM), which is composed of a Facial Structure Attention Unit (FSAU) and a Transformer block, to promote the consistency of local facial detail and global facial structure restoration simultaneously. Then, we design an efficient Local Feature Refinement Module (LFRM) to enhance the local facial structure information. Finally, to further improve the restoration of fine facial details, we present a Multi-scale Feature Fusion Unit (MFFU) to adaptively fuse the features from different stages in the encoder procedure. Comprehensive evaluations on various datasets have assessed that the proposed CTCNet can outperform other state-of-the-art methods significantly. ",
    "url": "https://arxiv.org/abs/2204.08696",
    "authors": [
      "Guangwei Gao",
      "Zixiang Xu",
      "Juncheng Li",
      "Jian Yang",
      "Tieyong Zeng",
      "Guo-Jun Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08697",
    "title": "A Multi-Opinion Based Metric for Quantifying Polarization on Social  Networks: A Case Study from India",
    "abstract": "Social media has been known to be a hotbed of political and social communications and analyzing the polarization of opinions has been gaining attention. In this study, we have proposed a measure for quantifying polarization on social networks. The proposed metric, unlike state-of-the-art methods, does not assume a two-opinion scenario and applies to multiple opinions. Our metric was tested on both binary opinion based benchmark networks as well as synthetically opinion-labeled social networks with a multi-opinion scenario and varying degrees of polarization. The metric showed promising results for social networks with different levels of polarization. The method was then employed to study polarization using data obtained from Twitter concerning the tri-opinion (\"pro\", \"anti\" and \"neutral\") based communications regarding the implementation of the Citizenship Amendment Act (CAA) in India. We have measured the polarization on a variety of social networks such as communication networks based on retweets or mentions, a social relationships network based on follower-followee connections and finally hybrid networks by combining the communication networks with the social relationships network. The proposed method suggested a high level of polarization among the users with respect to sharing posts on Twitter, thereby indicating the highly contentious nature of the issue. We also obtained a high polarization score for a social relationships network. Thus indicating the presence of homophily among users i.e. opinion on CAA is in-line with their social relationships on the platform. For a retweet based hybrid network, the scores returned by our polarization metric highlighted opinion to be the key driver in retweeting behaviour irrespective of the social relationships among users. On the contrary, the mention based communications among the users were not polarized in nature. ",
    "url": "https://arxiv.org/abs/2204.08697",
    "authors": [
      "Maneet Singh",
      "S.R.S. Iyengar",
      "Rishemjit Kaur"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.08717",
    "title": "Shape-Aware Monocular 3D Object Detection",
    "abstract": "The detection of 3D objects through a single perspective camera is a challenging issue. The anchor-free and keypoint-based models receive increasing attention recently due to their effectiveness and simplicity. However, most of these methods are vulnerable to occluded and truncated objects. In this paper, a single-stage monocular 3D object detection model is proposed. An instance-segmentation head is integrated into the model training, which allows the model to be aware of the visible shape of a target object. The detection largely avoids interference from irrelevant regions surrounding the target objects. In addition, we also reveal that the popular IoU-based evaluation metrics, which were originally designed for evaluating stereo or LiDAR-based detection methods, are insensitive to the improvement of monocular 3D object detection algorithms. A novel evaluation metric, namely average depth similarity (ADS) is proposed for the monocular 3D object detection models. Our method outperforms the baseline on both the popular and the proposed evaluation metrics while maintaining real-time efficiency. ",
    "url": "https://arxiv.org/abs/2204.08717",
    "authors": [
      "Wei Chen",
      "Jie Zhao",
      "Wan-Lei Zhao",
      "Song-Yuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08726",
    "title": "Jacobian Ensembles Improve Robustness Trade-offs to Adversarial Attacks",
    "abstract": "Deep neural networks have become an integral part of our software infrastructure and are being deployed in many widely-used and safety-critical applications. However, their integration into many systems also brings with it the vulnerability to test time attacks in the form of Universal Adversarial Perturbations (UAPs). UAPs are a class of perturbations that when applied to any input causes model misclassification. Although there is an ongoing effort to defend models against these adversarial attacks, it is often difficult to reconcile the trade-offs in model accuracy and robustness to adversarial attacks. Jacobian regularization has been shown to improve the robustness of models against UAPs, whilst model ensembles have been widely adopted to improve both predictive performance and model robustness. In this work, we propose a novel approach, Jacobian Ensembles-a combination of Jacobian regularization and model ensembles to significantly increase the robustness against UAPs whilst maintaining or improving model accuracy. Our results show that Jacobian Ensembles achieves previously unseen levels of accuracy and robustness, greatly improving over previous methods that tend to skew towards only either accuracy or robustness. ",
    "url": "https://arxiv.org/abs/2204.08726",
    "authors": [
      "Kenneth T. Co",
      "David Martinez-Rego",
      "Zhongyuan Hau",
      "Emil C. Lupu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08734",
    "title": "Muffin: Testing Deep Learning Libraries via Neural Architecture Fuzzing",
    "abstract": "Deep learning (DL) techniques are proven effective in many challenging tasks, and become widely-adopted in practice. However, previous work has shown that DL libraries, the basis of building and executing DL models, contain bugs and can cause severe consequences. Unfortunately, existing testing approaches still cannot comprehensively exercise DL libraries. They utilize existing trained models and only detect bugs in model inference phase. In this work we propose Muffin to address these issues. To this end, Muffin applies a specifically-designed model fuzzing approach, which allows it to generate diverse DL models to explore the target library, instead of relying only on existing trained models. Muffin makes differential testing feasible in the model training phase by tailoring a set of metrics to measure the inconsistencies between different DL libraries. In this way, Muffin can best exercise the library code to detect more bugs. To evaluate the effectiveness of Muffin, we conduct experiments on three widely-used DL libraries. The results demonstrate that Muffin can detect 39 new bugs in the latest release versions of popular DL libraries, including Tensorflow, CNTK, and Theano. ",
    "url": "https://arxiv.org/abs/2204.08734",
    "authors": [
      "Jiazhen Gu",
      "Xuchuan Luo",
      "Yangfan Zhou",
      "Xin Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.08735",
    "title": "Neural Collapse Inspired Attraction-Repulsion-Balanced Loss for  Imbalanced Learning",
    "abstract": "Class imbalance distribution widely exists in real-world engineering. However, the mainstream optimization algorithms that seek to minimize error will trap the deep learning model in sub-optimums when facing extreme class imbalance. It seriously harms the classification precision, especially on the minor classes. The essential reason is that the gradients of the classifier weights are imbalanced among the components from different classes. In this paper, we propose Attraction-Repulsion-Balanced Loss (ARB-Loss) to balance the different components of the gradients. We perform experiments on the large-scale classification and segmentation datasets and our ARB-Loss can achieve state-of-the-art performance via only one-stage training instead of 2-stage learning like nowadays SOTA works. ",
    "url": "https://arxiv.org/abs/2204.08735",
    "authors": [
      "Liang Xie",
      "Yibo Yang",
      "Deng Cai",
      "Dacheng Tao",
      "Xiaofei He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.08743",
    "title": "On the Use of Causal Graphical Models for Designing Experiments in the  Automotive Domain",
    "abstract": "Randomized field experiments are the gold standard for evaluating the impact of software changes on customers. In the online domain, randomization has been the main tool to ensure exchangeability. However, due to the different deployment conditions and the high dependence on the surrounding environment, designing experiments for automotive software needs to consider a higher number of restricted variables to ensure conditional exchangeability. In this paper, we show how at Volvo Cars we utilize causal graphical models to design experiments and explicitly communicate the assumptions of experiments. These graphical models are used to further assess the experiment validity, compute direct and indirect causal effects, and reason on the transportability of the causal conclusions. ",
    "url": "https://arxiv.org/abs/2204.08743",
    "authors": [
      "David Issa Mattos",
      "Yuchu Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.08745",
    "title": "Augmentation of Atmospheric Turbulence Effects on Thermal Adapted Object  Detection Models",
    "abstract": "Atmospheric turbulence has a degrading effect on the image quality of long-range observation systems. As a result of various elements such as temperature, wind velocity, humidity, etc., turbulence is characterized by random fluctuations in the refractive index of the atmosphere. It is a phenomenon that may occur in various imaging spectra such as the visible or the infrared bands. In this paper, we analyze the effects of atmospheric turbulence on object detection performance in thermal imagery. We use a geometric turbulence model to simulate turbulence effects on a medium-scale thermal image set, namely \"FLIR ADAS v2\". We apply thermal domain adaptation to state-of-the-art object detectors and propose a data augmentation strategy to increase the performance of object detectors which utilizes turbulent images in different severity levels as training data. Our results show that the proposed data augmentation strategy yields an increase in performance for both turbulent and non-turbulent thermal test images. ",
    "url": "https://arxiv.org/abs/2204.08745",
    "authors": [
      "Engin Uzun",
      "Ahmet Anil Dursun",
      "Erdem Akagunduz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08747",
    "title": "Multi-View Spatial-Temporal Network for Continuous Sign Language  Recognition",
    "abstract": "Sign language is a beautiful visual language and is also the primary language used by speaking and hearing-impaired people. However, sign language has many complex expressions, which are difficult for the public to understand and master. Sign language recognition algorithms will significantly facilitate communication between hearing-impaired people and normal people. Traditional continuous sign language recognition often uses a sequence learning method based on Convolutional Neural Network (CNN) and Long Short-Term Memory Network (LSTM). These methods can only learn spatial and temporal features separately, which cannot learn the complex spatial-temporal features of sign language. LSTM is also difficult to learn long-term dependencies. To alleviate these problems, this paper proposes a multi-view spatial-temporal continuous sign language recognition network. The network consists of three parts. The first part is a Multi-View Spatial-Temporal Feature Extractor Network (MSTN), which can directly extract the spatial-temporal features of RGB and skeleton data; the second is a sign language encoder network based on Transformer, which can learn long-term dependencies; the third is a Connectionist Temporal Classification (CTC) decoder network, which is used to predict the whole meaning of the continuous sign language. Our algorithm is tested on two public sign language datasets SLR-100 and PHOENIX-Weather 2014T (RWTH). As a result, our method achieves excellent performance on both datasets. The word error rate on the SLR-100 dataset is 1.9%, and the word error rate on the RWTHPHOENIX-Weather dataset is 22.8%. ",
    "url": "https://arxiv.org/abs/2204.08747",
    "authors": [
      "Ronghui Li",
      "Lu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08758",
    "title": "Enhancing CTR Prediction with Context-Aware Feature Representation  Learning",
    "abstract": "CTR prediction has been widely used in the real world. Many methods model feature interaction to improve their performance. However, most methods only learn a fixed representation for each feature without considering the varying importance of each feature under different contexts, resulting in inferior performance. Recently, several methods tried to learn vector-level weights for feature representations to address the fixed representation issue. However, they only produce linear transformations to refine the fixed feature representations, which are still not flexible enough to capture the varying importance of each feature under different contexts. In this paper, we propose a novel module named Feature Refinement Network (FRNet), which learns context-aware feature representations at bit-level for each feature in different contexts. FRNet consists of two key components: 1) Information Extraction Unit (IEU), which captures contextual information and cross-feature relationships to guide context-aware feature refinement; and 2) Complementary Selection Gate (CSGate), which adaptively integrates the original and complementary feature representations learned in IEU with bit-level weights. Notably, FRNet is orthogonal to existing CTR methods and thus can be applied in many existing methods to boost their performance. Comprehensive experiments are conducted to verify the effectiveness, efficiency, and compatibility of FRNet. ",
    "url": "https://arxiv.org/abs/2204.08758",
    "authors": [
      "Fangye Wang",
      "Yingxu Wang",
      "Dongsheng Li",
      "Hansu Gu",
      "Tun Lu",
      "Peng Zhang",
      "Ning Gu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.08759",
    "title": "Edge-enhanced Feature Distillation Network for Efficient  Super-Resolution",
    "abstract": "With the recently massive development in convolution neural networks, numerous lightweight CNN-based image super-resolution methods have been proposed for practical deployments on edge devices. However, most existing methods focus on one specific aspect: network or loss design, which leads to the difficulty of minimizing the model size. To address the issue, we conclude block devising, architecture searching, and loss design to obtain a more efficient SR structure. In this paper, we proposed an edge-enhanced feature distillation network, named EFDN, to preserve the high-frequency information under constrained resources. In detail, we build an edge-enhanced convolution block based on the existing reparameterization methods. Meanwhile, we propose edge-enhanced gradient loss to calibrate the reparameterized path training. Experimental results show that our edge-enhanced strategies preserve the edge and significantly improve the final restoration quality. Code is available at https://github.com/icandle/EFDN. ",
    "url": "https://arxiv.org/abs/2204.08759",
    "authors": [
      "Yan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.08766",
    "title": "Modeling Missing Annotations for Incremental Learning in Object  Detection",
    "abstract": "Despite the recent advances in the field of object detection, common architectures are still ill-suited to incrementally detect new categories over time. They are vulnerable to catastrophic forgetting: they forget what has been already learned while updating their parameters in absence of the original training data. Previous works extended standard classification methods in the object detection task, mainly adopting the knowledge distillation framework. However, we argue that object detection introduces an additional problem, which has been overlooked. While objects belonging to new classes are learned thanks to their annotations, if no supervision is provided for other objects that may still be present in the input, the model learns to associate them to background regions. We propose to handle these missing annotations by revisiting the standard knowledge distillation framework. Our approach outperforms current state-of-the-art methods in every setting of the Pascal-VOC dataset. We further propose an extension to instance segmentation, outperforming the other baselines. In this work, we propose to handle the missing annotations by revisiting the standard knowledge distillation framework. We show that our approach outperforms current state-of-the-art methods in every setting of the Pascal-VOC 2007 dataset. Moreover, we propose a simple extension to instance segmentation, showing that it outperforms the other baselines. ",
    "url": "https://arxiv.org/abs/2204.08766",
    "authors": [
      "Fabio Cermelli",
      "Antonino Geraci",
      "Dario Fontanel",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08768",
    "title": "Binary Multi Channel Morphological Neural Network",
    "abstract": "Neural networks and particularly Deep learning have been comparatively little studied from the theoretical point of view. Conversely, Mathematical Morphology is a discipline with solid theoretical foundations. We combine these domains to propose a new type of neural architecture that is theoretically more explainable. We introduce a Binary Morphological Neural Network (BiMoNN) built upon the convolutional neural network. We design it for learning morphological networks with binary inputs and outputs. We demonstrate an equivalence between BiMoNNs and morphological operators that we can use to binarize entire networks. These can learn classical morphological operators and show promising results on a medical imaging application. ",
    "url": "https://arxiv.org/abs/2204.08768",
    "authors": [
      "Theodore Aouad",
      "Hugues Talbot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08770",
    "title": "GroupNet: Multiscale Hypergraph Neural Networks for Trajectory  Prediction with Relational Reasoning",
    "abstract": "Demystifying the interactions among multiple agents from their past trajectories is fundamental to precise and interpretable trajectory prediction. However, previous works only consider pair-wise interactions with limited relational reasoning. To promote more comprehensive interaction modeling for relational reasoning, we propose GroupNet, a multiscale hypergraph neural network, which is novel in terms of both interaction capturing and representation learning. From the aspect of interaction capturing, we propose a trainable multiscale hypergraph to capture both pair-wise and group-wise interactions at multiple group sizes. From the aspect of interaction representation learning, we propose a three-element format that can be learnt end-to-end and explicitly reason some relational factors including the interaction strength and category. We apply GroupNet into both CVAE-based prediction system and previous state-of-the-art prediction systems for predicting socially plausible trajectories with relational reasoning. To validate the ability of relational reasoning, we experiment with synthetic physics simulations to reflect the ability to capture group behaviors, reason interaction strength and interaction category. To validate the effectiveness of prediction, we conduct extensive experiments on three real-world trajectory prediction datasets, including NBA, SDD and ETH-UCY; and we show that with GroupNet, the CVAE-based prediction system outperforms state-of-the-art methods. We also show that adding GroupNet will further improve the performance of previous state-of-the-art prediction systems. ",
    "url": "https://arxiv.org/abs/2204.08770",
    "authors": [
      "Chenxin Xu",
      "Maosen Li",
      "Zhenyang Ni",
      "Ya Zhang",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08771",
    "title": "EXIT: Extrapolation and Interpolation-based Neural Controlled  Differential Equations for Time-series Classification and Forecasting",
    "abstract": "Deep learning inspired by differential equations is a recent research trend and has marked the state of the art performance for many machine learning tasks. Among them, time-series modeling with neural controlled differential equations (NCDEs) is considered as a breakthrough. In many cases, NCDE-based models not only provide better accuracy than recurrent neural networks (RNNs) but also make it possible to process irregular time-series. In this work, we enhance NCDEs by redesigning their core part, i.e., generating a continuous path from a discrete time-series input. NCDEs typically use interpolation algorithms to convert discrete time-series samples to continuous paths. However, we propose to i) generate another latent continuous path using an encoder-decoder architecture, which corresponds to the interpolation process of NCDEs, i.e., our neural network-based interpolation vs. the existing explicit interpolation, and ii) exploit the generative characteristic of the decoder, i.e., extrapolation beyond the time domain of original data if needed. Therefore, our NCDE design can use both the interpolated and the extrapolated information for downstream machine learning tasks. In our experiments with 5 real-world datasets and 12 baselines, our extrapolation and interpolation-based NCDEs outperform existing baselines by non-trivial margins. ",
    "url": "https://arxiv.org/abs/2204.08771",
    "authors": [
      "Sheo Yon Jhin",
      "Jaehoon Lee",
      "Minju Jo",
      "Seungji Kook",
      "Jinsung Jeon",
      "Jihyeon Hyeong",
      "Jayoung Kim",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08781",
    "title": "LORD: Lower-Dimensional Embedding of Log-Signature in Neural Rough  Differential Equations",
    "abstract": "The problem of processing very long time-series data (e.g., a length of more than 10,000) is a long-standing research problem in machine learning. Recently, one breakthrough, called neural rough differential equations (NRDEs), has been proposed and has shown that it is able to process such data. Their main concept is to use the log-signature transform, which is known to be more efficient than the Fourier transform for irregular long time-series, to convert a very long time-series sample into a relatively shorter series of feature vectors. However, the log-signature transform causes non-trivial spatial overheads. To this end, we present the method of LOweR-Dimensional embedding of log-signature (LORD), where we define an NRDE-based autoencoder to implant the higher-depth log-signature knowledge into the lower-depth log-signature. We show that the encoder successfully combines the higher-depth and the lower-depth log-signature knowledge, which greatly stabilizes the training process and increases the model accuracy. In our experiments with benchmark datasets, the improvement ratio by our method is up to 75\\% in terms of various classification and forecasting evaluation metrics. ",
    "url": "https://arxiv.org/abs/2204.08781",
    "authors": [
      "Jaehoon Lee",
      "Jinsung Jeon",
      "Sheo yon Jhin",
      "Jihyeon Hyeong",
      "Jayoung Kim",
      "Minju Jo",
      "Kook Seungji",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08810",
    "title": "RNNCTPs: A Neural Symbolic Reasoning Method Using Dynamic Knowledge  Partitioning Technology",
    "abstract": "Although traditional symbolic reasoning methods are highly interpretable, their application in knowledge graph link prediction is limited due to their low computational efficiency. In this paper, we propose a new neural symbolic reasoning method: RNNCTPs, which improves computational efficiency by re-filtering the knowledge selection of Conditional Theorem Provers (CTPs), and is less sensitive to the embedding size parameter. RNNCTPs are divided into relation selectors and predictors. The relation selectors are trained efficiently and interpretably, so that the whole model can dynamically generate knowledge for the inference of the predictor. In all four datasets, the method shows competitive performance against traditional methods on the link prediction task, and can have higher applicability to the selection of datasets relative to CTPs. ",
    "url": "https://arxiv.org/abs/2204.08810",
    "authors": [
      "Yu-hao Wu",
      "Hou-biao Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic (math.LO)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.08822",
    "title": "A Convolutional-Attentional Neural Framework for Structure-Aware  Performance-Score Synchronization",
    "abstract": "Performance-score synchronization is an integral task in signal processing, which entails generating an accurate mapping between an audio recording of a performance and the corresponding musical score. Traditional synchronization methods compute alignment using knowledge-driven and stochastic approaches, and are typically unable to generalize well to different domains and modalities. We present a novel data-driven method for structure-aware performance-score synchronization. We propose a convolutional-attentional architecture trained with a custom loss based on time-series divergence. We conduct experiments for the audio-to-MIDI and audio-to-image alignment tasks pertained to different score modalities. We validate the effectiveness of our method via ablation studies and comparisons with state-of-the-art alignment approaches. We demonstrate that our approach outperforms previous synchronization methods for a variety of test settings across score modalities and acoustic conditions. Our method is also robust to structural differences between the performance and score sequences, which is a common limitation of standard alignment approaches. ",
    "url": "https://arxiv.org/abs/2204.08822",
    "authors": [
      "Ruchit Agrawal",
      "Daniel Wolff",
      "Simon Dixon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.08828",
    "title": "Detect-and-describe: Joint learning framework for detection and  description of objects",
    "abstract": "Traditional object detection answers two questions; \"what\" (what the object is?) and \"where\" (where the object is?). \"what\" part of the object detection can be fine-grained further i.e. \"what type\", \"what shape\" and \"what material\" etc. This results in the shifting of the object detection tasks to the object description paradigm. Describing an object provides additional detail that enables us to understand the characteristics and attributes of the object (\"plastic boat\" not just boat, \"glass bottle\" not just bottle). This additional information can implicitly be used to gain insight into unseen objects (e.g. unknown object is \"metallic\", \"has wheels\"), which is not possible in traditional object detection. In this paper, we present a new approach to simultaneously detect objects and infer their attributes, we call it Detect and Describe (DaD) framework. DaD is a deep learning-based approach that extends object detection to object attribute prediction as well. We train our model on aPascal train set and evaluate our approach on aPascal test set. We achieve 97.0% in Area Under the Receiver Operating Characteristic Curve (AUC) for object attributes prediction on aPascal test set. We also show qualitative results for object attribute prediction on unseen objects, which demonstrate the effectiveness of our approach for describing unknown objects. ",
    "url": "https://arxiv.org/abs/2204.08828",
    "authors": [
      "Addel Zafar",
      "Umar Khalid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08838",
    "title": "Rumor Detection with Self-supervised Learning on Texts and Social Graph",
    "abstract": "Rumor detection has become an emerging and active research field in recent years. At the core is to model the rumor characteristics inherent in rich information, such as propagation patterns in social network and semantic patterns in post content, and differentiate them from the truth. However, existing works on rumor detection fall short in modeling heterogeneous information, either using one single information source only (e.g. social network, or post content) or ignoring the relations among multiple sources (e.g. fusing social and content features via simple concatenation). Therefore, they possibly have drawbacks in comprehensively understanding the rumors, and detecting them accurately. In this work, we explore contrastive self-supervised learning on heterogeneous information sources, so as to reveal their relations and characterize rumors better. Technically, we supplement the main supervised task of detection with an auxiliary self-supervised task, which enriches post representations via post self-discrimination. Specifically, given two heterogeneous views of a post (i.e. representations encoding social patterns and semantic patterns), the discrimination is done by maximizing the mutual information between different views of the same post compared to that of other posts. We devise cluster-wise and instance-wise approaches to generate the views and conduct the discrimination, considering different relations of information sources. We term this framework as Self-supervised Rumor Detection (SRD). Extensive experiments on three real-world datasets validate the effectiveness of SRD for automatic rumor detection on social media. ",
    "url": "https://arxiv.org/abs/2204.08838",
    "authors": [
      "Yuan Gao",
      "Xiang Wang",
      "Xiangnan He",
      "Huamin Feng",
      "Yongdong Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08839",
    "title": "Unsupervised Learning of Efficient Geometry-Aware Neural Articulated  Representations",
    "abstract": "We propose an unsupervised method for 3D geometry-aware representation learning of articulated objects. Though photorealistic images of articulated objects can be rendered with explicit pose control through existing 3D neural representations, these methods require ground truth 3D pose and foreground masks for training, which are expensive to obtain. We obviate this need by learning the representations with GAN training. From random poses and latent vectors, the generator is trained to produce realistic images of articulated objects by adversarial training. To avoid a large computational cost for GAN training, we propose an efficient neural representation for articulated objects based on tri-planes and then present a GAN-based framework for its unsupervised training. Experiments demonstrate the efficiency of our method and show that GAN-based training enables learning of controllable 3D representations without supervision. ",
    "url": "https://arxiv.org/abs/2204.08839",
    "authors": [
      "Atsuhiro Noguchi",
      "Xiao Sun",
      "Stephen Lin",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08846",
    "title": "Differentiating Network Flows for Priority-Aware Scheduling of Incoming  Packets in Real-Time IoT Systems",
    "abstract": "When IP-packet processing is unconditionally carried out on behalf of an operating system kernel thread, processing systems can experience overload in high incoming traffic scenarios. This is especially worrying for embedded real-time devices controlling their physical environment in industrial IoT scenarios and automotive systems. We propose an embedded real-time aware IP stack adaption with an early demultiplexing scheme for incoming packets and subsequent per-flow aperiodic scheduling. By instrumenting existing embedded IP stacks, rigid prioritization with minimal latency is deployed without the need of further task resources. Simple mitigation techniques can be applied to individual flows, causing hardly measurable overhead while at the same time protecting the system from overload conditions. Our IP stack adaption is able to reduce the low-priority packet processing time by over 86% compared to an unmodified stack. The network subsystem can thereby remain active at a 7x higher general traffic load before disabling the receive IRQ as a last resort to assure deadlines. ",
    "url": "https://arxiv.org/abs/2204.08846",
    "authors": [
      "Christoph Blumschein",
      "Ilja Behnke",
      "Lauritz Thamsen",
      "Odej Kao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2204.08853",
    "title": "Core Box Image Recognition and its Improvement with a New Augmentation  Technique",
    "abstract": "Most methods for automated full-bore rock core image analysis (description, colour, properties distribution, etc.) are based on separate core column analyses. The core is usually imaged in a box because of the significant amount of time taken to get an image for each core column. The work presents an innovative method and algorithm for core columns extraction from core boxes. The conditions for core boxes imaging may differ tremendously. Such differences are disastrous for machine learning algorithms which need a large dataset describing all possible data variations. Still, such images have some standard features - a box and core. Thus, we can emulate different environments with a unique augmentation described in this work. It is called template-like augmentation (TLA). The method is described and tested on various environments, and results are compared on an algorithm trained on both 'traditional' data and a mix of traditional and TLA data. The algorithm trained with TLA data provides better metrics and can detect core on most new images, unlike the algorithm trained on data without TLA. The algorithm for core column extraction implemented in an automated core description system speeds up the core box processing by a factor of 20. ",
    "url": "https://arxiv.org/abs/2204.08853",
    "authors": [
      "E.E. Baraboshkin",
      "A.E. Demidov",
      "D.M. Orlov",
      "D.A. Koroteev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08870",
    "title": "OpenGlue: Open Source Graph Neural Net Based Pipeline for Image Matching",
    "abstract": "We present OpenGlue: a free open-source framework for image matching, that uses a Graph Neural Network-based matcher inspired by SuperGlue \\cite{sarlin20superglue}. We show that including additional geometrical information, such as local feature scale, orientation, and affine geometry, when available (e.g. for SIFT features), significantly improves the performance of the OpenGlue matcher. We study the influence of the various attention mechanisms on accuracy and speed. We also present a simple architectural improvement by combining local descriptors with context-aware descriptors. The code and pretrained OpenGlue models for the different local features are publicly available. ",
    "url": "https://arxiv.org/abs/2204.08870",
    "authors": [
      "Ostap Viniavskyi",
      "Mariia Dobko",
      "Dmytro Mishkin",
      "Oles Dobosevych"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08895",
    "title": "Invertible Mask Network for Face Privacy-Preserving",
    "abstract": "Face privacy-preserving is one of the hotspots that arises dramatic interests of research. However, the existing face privacy-preserving methods aim at causing the missing of semantic information of face and cannot preserve the reusability of original facial information. To achieve the naturalness of the processed face and the recoverability of the original protected face, this paper proposes face privacy-preserving method based on Invertible \"Mask\" Network (IMN). In IMN, we introduce a Mask-net to generate \"Mask\" face firstly. Then, put the \"Mask\" face onto the protected face and generate the masked face, in which the masked face is indistinguishable from \"Mask\" face. Finally, \"Mask\" face can be put off from the masked face and obtain the recovered face to the authorized users, in which the recovered face is visually indistinguishable from the protected face. The experimental results show that the proposed method can not only effectively protect the privacy of the protected face, but also almost perfectly recover the protected face from the masked face. ",
    "url": "https://arxiv.org/abs/2204.08895",
    "authors": [
      "Yang Yang",
      "Yiyang Huang",
      "Ming Shi",
      "Kejiang Chen",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.08916",
    "title": "Heterogeneous Feature Augmentation for Ponzi Detection in Ethereum",
    "abstract": "While blockchain technology triggers new industrial and technological revolutions, it also brings new challenges. Recently, a large number of new scams with a \"blockchain\" sock-puppet continue to emerge, such as Ponzi schemes, money laundering, etc., seriously threatening financial security. Existing fraud detection methods in blockchain mainly concentrate on manual feature and graph analytics, which first construct a homogeneous transaction graph using partial blockchain data and then use graph analytics to detect anomaly, resulting in a loss of pattern information. In this paper, we mainly focus on Ponzi scheme detection and propose HFAug, a generic Heterogeneous Feature Augmentation module that can capture the heterogeneous information associated with account behavior patterns and can be combined with existing Ponzi detection methods. HFAug learns the metapath-based behavior characteristics in an auxiliary heterogeneous interaction graph, and aggregates the heterogeneous features to corresponding account nodes in the homogeneous one where the Ponzi detection methods are performed. Comprehensive experimental results demonstrate that our HFAug can help existing Ponzi detection methods achieve significant performance improvement on Ethereum datasets, suggesting the effectiveness of heterogeneous information on detecting Ponzi schemes. ",
    "url": "https://arxiv.org/abs/2204.08916",
    "authors": [
      "Chengxiang Jin",
      "Jie Jin",
      "Jiajun Zhou",
      "Jiajing Wu",
      "Qi Xuan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.08917",
    "title": "Global-and-Local Collaborative Learning for Co-Salient Object Detection",
    "abstract": "The goal of co-salient object detection (CoSOD) is to discover salient objects that commonly appear in a query group containing two or more relevant images. Therefore, how to effectively extract inter-image correspondence is crucial for the CoSOD task. In this paper, we propose a global-and-local collaborative learning architecture, which includes a global correspondence modeling (GCM) and a local correspondence modeling (LCM) to capture comprehensive inter-image corresponding relationship among different images from the global and local perspectives. Firstly, we treat different images as different time slices and use 3D convolution to integrate all intra features intuitively, which can more fully extract the global group semantics. Secondly, we design a pairwise correlation transformation (PCT) to explore similarity correspondence between pairwise images and combine the multiple local pairwise correspondences to generate the local inter-image relationship. Thirdly, the inter-image relationships of the GCM and LCM are integrated through a global-and-local correspondence aggregation (GLA) module to explore more comprehensive inter-image collaboration cues. Finally, the intra- and inter-features are adaptively integrated by an intra-and-inter weighting fusion (AEWF) module to learn co-saliency features and predict the co-saliency map. The proposed GLNet is evaluated on three prevailing CoSOD benchmark datasets, demonstrating that our model trained on a small dataset (about 3k images) still outperforms eleven state-of-the-art competitors trained on some large datasets (about 8k-200k images). ",
    "url": "https://arxiv.org/abs/2204.08917",
    "authors": [
      "Runmin Cong",
      "Ning Yang",
      "Chongyi Li",
      "Huazhu Fu",
      "Yao Zhao",
      "Qingming Huang",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08941",
    "title": "CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex",
    "abstract": "CodexDB is an SQL processing engine whose internals can be customized via natural language instructions. CodexDB is based on OpenAI's GPT-3 Codex model which translates text into code. It is a framework on top of GPT-3 Codex that decomposes complex SQL queries into a series of simple processing steps, described in natural language. Processing steps are enriched with user-provided instructions and descriptions of database properties. Codex translates the resulting text into query processing code. An early prototype of CodexDB is able to generate correct code for a majority of queries of the WikiSQL benchmark and can be customized in various ways. ",
    "url": "https://arxiv.org/abs/2204.08941",
    "authors": [
      "Immanuel Trummer"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08951",
    "title": "Seculator: A Fast and Secure Neural Processing Unit",
    "abstract": "Securing deep neural networks (DNNs) is a problem of significant interest since an ML model incorporates high-quality intellectual property, features of data sets painstakingly collated by mechanical turks, and novel methods of training on large cluster computers. Sadly, attacks to extract model parameters are on the rise, and thus designers are being forced to create architectures for securing such models. State-of-the-art proposals in this field take the deterministic memory access patterns of such networks into cognizance (albeit partially), group a set of memory blocks into a tile, and maintain state at the level of tiles (to reduce storage space). For providing integrity guarantees (tamper avoidance), they don't propose any significant optimizations, and still maintain block-level state. We observe that it is possible to exploit the deterministic memory access patterns of DNNs even further, and maintain state information for only the current tile and current layer, which may comprise a large number of tiles. This reduces the storage space, reduces the number of memory accesses, increases performance, and simplifies the design without sacrificing any security guarantees. The key techniques in our proposed accelerator architecture, Seculator, are to encode memory access patterns to create a small HW-based tile version number generator for a given layer, and to store layer-level MACs. We completely eliminate the need for having a MAC cache and a tile version number store (as used in related work). We show that using intelligently-designed mathematical operations, these structures are not required. By reducing such overheads, we show a speedup of 16% over the closest competing work. ",
    "url": "https://arxiv.org/abs/2204.08951",
    "authors": [
      "Nivedita Shrivastava",
      "Smruti R. Sarangi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2204.08952",
    "title": "Retrieval Enhanced Data Augmentation for Question Answering on Privacy  Policies",
    "abstract": "Prior studies in privacy policies frame the question answering (QA) tasks as identifying the most relevant text segment or a list of sentences from the policy document for a user query. However, annotating such a dataset is challenging as it requires specific domain expertise (e.g., law academics). Even if we manage a small-scale one, a bottleneck that remains is that the labeled data are heavily imbalanced (only a few segments are relevant) --limiting the gain in this domain. Therefore, in this paper, we develop a novel data augmentation framework based on ensembling retriever models that captures the relevant text segments from unlabeled policy documents and expand the positive examples in the training set. In addition, to improve the diversity and quality of the augmented data, we leverage multiple pre-trained language models (LMs) and cascaded them with noise reduction oracles. Using our augmented data on the PrivacyQA benchmark, we elevate the existing baseline by a large margin (10\\% F1) and achieve a new state-of-the-art F1 score of 50\\%. Our ablation studies provide further insights into the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2204.08952",
    "authors": [
      "Md Rizwan Parvez",
      "Jianfeng Chi",
      "Wasi Uddin Ahmad",
      "Yuan Tian",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.08958",
    "title": "MANIQA: Multi-dimension Attention Network for No-Reference Image Quality  Assessment",
    "abstract": "No-Reference Image Quality Assessment (NR-IQA) aims to assess the perceptual quality of images in accordance with human subjective perception. Unfortunately, existing NR-IQA methods are far from meeting the needs of predicting accurate quality scores on GAN-based distortion images. To this end, we propose Multi-dimension Attention Network for no-reference Image Quality Assessment (MANIQA) to improve the performance on GAN-based distortion. We firstly extract features via ViT, then to strengthen global and local interactions, we propose the Transposed Attention Block (TAB) and the Scale Swin Transformer Block (SSTB). These two modules apply attention mechanisms across the channel and spatial dimension, respectively. In this multi-dimensional manner, the modules cooperatively increase the interaction among different regions of images globally and locally. Finally, a dual branch structure for patch-weighted quality prediction is applied to predict the final score depending on the weight of each patch's score. Experimental results demonstrate that MANIQA outperforms state-of-the-art methods on four standard datasets (LIVE, TID2013, CSIQ, and KADID-10K) by a large margin. Besides, our method ranked first place in the final testing phase of the NTIRE 2022 Perceptual Image Quality Assessment Challenge Track 2: No-Reference. Codes and models are available at https://github.com/IIGROUP/MANIQA. ",
    "url": "https://arxiv.org/abs/2204.08958",
    "authors": [
      "Sidi Yang",
      "Tianhe Wu",
      "Shuwei Shi",
      "Shanshan Lao Yuan Gong",
      "Mingdeng Cao",
      "Jiahao Wang",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2204.08961",
    "title": "Optimal Layered Defense For Site Protection",
    "abstract": "We present a model for layered security with applications to the protection of sites such as stadiums or large gathering places. We formulate the problem as one of maximizing the capture of illegal contraband. The objective function is indefinite and only limited information can be gained when the problem is solved by standard convex optimization methods. In order to solve the model, we develop a dynamic programming approach, and study its convergence properties. Additionally, we formulate a version of the problem aimed at addressing intelligent adversaries who can adjust their direction of attack as they observe changes in the site security. Furthermore, we also develop a method for the solution of the latter model. Finally, we perform computational experiments to demonstrate the use of our methods. ",
    "url": "https://arxiv.org/abs/2204.08961",
    "authors": [
      "Tsvetan Asamov",
      "Emre Yamangil",
      "Endre Boros",
      "Paul Kantor",
      "Fred Roberts"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.08977",
    "title": "Disappeared Command: Spoofing Attack On Automatic Speech Recognition  Systems with Sound Masking",
    "abstract": "The development of deep learning technology has greatly promoted the performance improvement of automatic speech recognition (ASR) technology, which has demonstrated an ability comparable to human hearing in many tasks. Voice interfaces are becoming more and more widely used as input for many applications and smart devices. However, existing research has shown that DNN is easily disturbed by slight disturbances and makes false recognition, which is extremely dangerous for intelligent voice applications controlled by voice. ",
    "url": "https://arxiv.org/abs/2204.08977",
    "authors": [
      "Jinghui Xu",
      "Jiangshan Zhang",
      "Jifeng Zhu",
      "Yong Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.08999",
    "title": "STPA-driven Multilevel Runtime Monitoring for In-time Hazard Detection",
    "abstract": "Runtime verification or runtime monitoring equips safety-critical cyber-physical systems to augment design assurance measures and ensure operational safety and security. Cyber-physical systems have interaction failures, attack surfaces, and attack vectors resulting in unanticipated hazards and loss scenarios. These interaction failures pose challenges to runtime verification regarding monitoring specifications and monitoring placements for in-time detection of hazards. We develop a well-formed workflow model that connects system theoretic process analysis, commonly referred to as STPA, hazard causation information to lower-level runtime monitoring to detect hazards at the operational phase. Specifically, our model follows the DepDevOps paradigm to provide evidence and insights to runtime monitoring on what to monitor, where to monitor, and the monitoring context. We demonstrate and evaluate the value of multilevel monitors by injecting hazards on an autonomous emergency braking system model. ",
    "url": "https://arxiv.org/abs/2204.08999",
    "authors": [
      "Smitha Gautham",
      "Georgios Bakirtzis",
      "Alexander Will",
      "Athira V. Jayakumar",
      "Carl R. Elks"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.09030",
    "title": "Decentralized Control of Distributed Cloud Networks with Generalized  Network Flows",
    "abstract": "Emerging distributed cloud architectures, e.g., fog and mobile edge computing, are playing an increasingly important role in the efficient delivery of real-time stream-processing applications such as augmented reality, multiplayer gaming, and industrial automation. While such applications require processed streams to be shared and simultaneously consumed by multiple users/devices, existing technologies lack efficient mechanisms to deal with their inherent multicast nature, leading to unnecessary traffic redundancy and network congestion. In this paper, we establish a unified framework for distributed cloud network control with generalized (mixed-cast) traffic flows that allows optimizing the distributed execution of the required packet processing, forwarding, and replication operations. We first characterize the enlarged multicast network stability region under the new control framework (with respect to its unicast counterpart). We then design a novel queuing system that allows scheduling data packets according to their current destination sets, and leverage Lyapunov drift-plus-penalty theory to develop the first fully decentralized, throughput- and cost-optimal algorithm for multicast cloud network flow control. Numerical experiments validate analytical results and demonstrate the performance gain of the proposed design over existing cloud network control techniques. ",
    "url": "https://arxiv.org/abs/2204.09030",
    "authors": [
      "Yang Cai",
      "Jaime Llorca",
      "Antonia M. Tulino",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.09035",
    "title": "Massively Parallel Computation and Sublinear-Time Algorithms for  Embedded Planar Graphs",
    "abstract": "While algorithms for planar graphs have received a lot of attention, few papers have focused on the additional power that one gets from assuming an embedding of the graph is available. While in the classic sequential setting, this assumption gives no additional power (as a planar graph can be embedded in linear time), we show that this is far from being the case in other settings. We assume that the embedding is straight-line, but our methods also generalize to non-straight-line embeddings. Specifically, we focus on sublinear-time computation and massively parallel computation (MPC). Our main technical contribution is a sublinear-time algorithm for computing a relaxed version of an $r$-division. We then show how this can be used to estimate Lipschitz additive graph parameters. This includes, for example, the maximum matching, maximum independent set, or the minimum dominating set. We also show how this can be used to solve some property testing problems with respect to the vertex edit distance. In the second part of our paper, we show an MPC algorithm that computes an $r$-division of the input graph. We show how this can be used to solve various classical graph problems with space per machine of $O(n^{2/3+\\epsilon})$ for some $\\epsilon>0$, and while performing $O(1)$ rounds. This includes for example approximate shortest paths or the minimum spanning tree. Our results also imply an improved MPC algorithm for Euclidean minimum spanning tree. ",
    "url": "https://arxiv.org/abs/2204.09035",
    "authors": [
      "Jacob Holm",
      "Jakub T\u011btek"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.09041",
    "title": "Unsupervised detection of ash dieback disease (Hymenoscyphus fraxineus)  using diffusion-based hyperspectral image clustering",
    "abstract": "Ash dieback (Hymenoscyphus fraxineus) is an introduced fungal disease that is causing the widespread death of ash trees across Europe. Remote sensing hyperspectral images encode rich structure that has been exploited for the detection of dieback disease in ash trees using supervised machine learning techniques. However, to understand the state of forest health at landscape-scale, accurate unsupervised approaches are needed. This article investigates the use of the unsupervised Diffusion and VCA-Assisted Image Segmentation (D-VIS) clustering algorithm for the detection of ash dieback disease in a forest site near Cambridge, United Kingdom. The unsupervised clustering presented in this work has high overlap with the supervised classification of previous work on this scene (overall accuracy = 71%). Thus, unsupervised learning may be used for the remote detection of ash dieback disease without the need for expert labeling. ",
    "url": "https://arxiv.org/abs/2204.09041",
    "authors": [
      "Sam L. Polk",
      "Aland H. Y. Chan",
      "Kangning Cui",
      "Robert J. Plemmons",
      "David A. Coomes",
      "James M. Murphy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2012.03675",
    "title": "Binary Segmentation of Seismic Facies Using Encoder-Decoder Neural  Networks",
    "abstract": "The interpretation of seismic data is vital for characterizing sediments' shape in areas of geological study. In seismic interpretation, deep learning becomes useful for reducing the dependence on handcrafted facies segmentation geometry and the time required to study geological areas. This work presents a Deep Neural Network for Facies Segmentation (DNFS) to obtain state-of-the-art results for seismic facies segmentation. DNFS is trained using a combination of cross-entropy and Jaccard loss functions. Our results show that DNFS obtains highly detailed predictions for seismic facies segmentation using fewer parameters than StNet and U-Net. ",
    "url": "https://arxiv.org/abs/2012.03675",
    "authors": [
      "Gefersom Lima",
      "Gabriel Ramos",
      "Sandro Rigo",
      "Felipe Zeiser",
      "Ariane da Silveira"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08466",
    "title": "Robust PCA Unrolling Network for Super-resolution Vessel Extraction in  X-ray Coronary Angiography",
    "abstract": "Although robust PCA has been increasingly adopted to extract vessels from X-ray coronary angiography (XCA) images, challenging problems such as inefficient vessel-sparsity modelling, noisy and dynamic background artefacts, and high computational cost still remain unsolved. Therefore, we propose a novel robust PCA unrolling network with sparse feature selection for super-resolution XCA vessel imaging. Being embedded within a patch-wise spatiotemporal super-resolution framework that is built upon a pooling layer and a convolutional long short-term memory network, the proposed network can not only gradually prune complex vessel-like artefacts and noisy backgrounds in XCA during network training but also iteratively learn and select the high-level spatiotemporal semantic information of moving contrast agents flowing in the XCA-imaged vessels. The experimental results show that the proposed method significantly outperforms state-of-the-art methods, especially in the imaging of the vessel network and its distal vessels, by restoring the intensity and geometry profiles of heterogeneous vessels against complex and dynamic backgrounds. ",
    "url": "https://arxiv.org/abs/2204.08466",
    "authors": [
      "Binjie Qin",
      "Haohao Mao",
      "Yiming Liu",
      "Jun Zhao",
      "Yisong Lv",
      "Yueqi Zhu",
      "Song Ding",
      "Xu Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2204.08508",
    "title": "Entropy of labeled versus unlabeled networks",
    "abstract": "The structure of a network is an unlabeled graph, yet graphs in most models of complex networks are labeled by meaningless random integers. Is the associated labeling noise always negligible, or can it overpower the network-structural signal? To address this question, we introduce and consider the sparse unlabeled versions of popular network models, and compare their entropy against the original labeled versions. We show that labeled and unlabeled Erdos-Renyi graphs are entropically equivalent, even though their degree distributions are very different. The labeled and unlabeled versions of the configuration model may have different prefactors in their leading entropy terms, although this remains conjectural. Our main results are upper and lower bounds for the entropy of labeled and unlabeled one-dimensional random geometric graphs. We show that their unlabeled entropy is negligible in comparison with the labeled entropy. These results imply that in sparse networks the entropy of meaningless labeling may dominate the entropy of the network structure, suggesting a need for a thorough reexamination of the statistical foundations of network modeling. ",
    "url": "https://arxiv.org/abs/2204.08508",
    "authors": [
      "Jeremy Paton",
      "Harrison Hartle",
      "Jakob Stepanyants",
      "Pim van der Hoorn",
      "Dmitri Krioukov"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2204.08528",
    "title": "An Optimal Time Variable Learning Framework for Deep Neural Networks",
    "abstract": "Feature propagation in Deep Neural Networks (DNNs) can be associated to nonlinear discrete dynamical systems. The novelty, in this paper, lies in letting the discretization parameter (time step-size) vary from layer to layer, which needs to be learned, in an optimization framework. The proposed framework can be applied to any of the existing networks such as ResNet, DenseNet or Fractional-DNN. This framework is shown to help overcome the vanishing and exploding gradient issues. Stability of some of the existing continuous DNNs such as Fractional-DNN is also studied. The proposed approach is applied to an ill-posed 3D-Maxwell's equation. ",
    "url": "https://arxiv.org/abs/2204.08528",
    "authors": [
      "Harbir Antil",
      "Hugo D\u00edaz",
      "Evelyn Herberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.08574",
    "title": "Adaptive Noisy Data Augmentation for Regularized Estimation and  Inference in Generalized Linear Models",
    "abstract": "We propose the AdaPtive Noise Augmentation (PANDA) procedure to regularize the estimation and inference of generalized linear models (GLMs). PANDA iteratively optimizes the objective function given noise augmented data until convergence to obtain the regularized model estimates. The augmented noises are designed to achieve various regularization effects, including $l_0$, bridge (lasso and ridge included), elastic net, adaptive lasso, and SCAD, as well as group lasso and fused ridge. We examine the tail bound of the noise-augmented loss function and establish the almost sure convergence of the noise-augmented loss function and its minimizer to the expected penalized loss function and its minimizer, respectively. We derive the asymptotic distributions for the regularized parameters, based on which, inferences can be obtained simultaneously with variable selection. PANDA exhibits ensemble learning behaviors that help further decrease the generalization error. Computationally, PANDA is easy to code, leveraging existing software for implementing GLMs, without resorting to complicated optimization techniques. We demonstrate the superior or similar performance of PANDA against the existing approaches of the same type of regularizers in simulated and real-life data. We show that the inferences through PANDA achieve nominal or near-nominal coverage and are far more efficient compared to a popular existing post-selection procedure. ",
    "url": "https://arxiv.org/abs/2204.08574",
    "authors": [
      "Yinan Li",
      "Fang Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2204.08608",
    "title": "G2GT: Retrosynthesis Prediction with Graph to Graph Attention Neural  Network and Self-Training",
    "abstract": "Retrosynthesis prediction is one of the fundamental challenges in organic chemistry and related fields. The goal is to find reactants molecules that can synthesize product molecules. To solve this task, we propose a new graph-to-graph transformation model, G2GT, in which the graph encoder and graph decoder are built upon the standard transformer structure. We also show that self-training, a powerful data augmentation method that utilizes unlabeled molecule data, can significantly improve the model's performance. Inspired by the reaction type label and ensemble learning, we proposed a novel weak ensemble method to enhance diversity. We combined beam search, nucleus, and top-k sampling methods to further improve inference diversity and proposed a simple ranking algorithm to retrieve the final top-10 results. We achieved new state-of-the-art results on both the USPTO-50K dataset, with top1 accuracy of 54%, and the larger data set USPTO-full, with top1 accuracy of 50%, and competitive top-10 results. ",
    "url": "https://arxiv.org/abs/2204.08608",
    "authors": [
      "Zaiyun Lin",
      "Shiqiu Yin",
      "Lei Shi",
      "Wenbiao Zhou",
      "YingSheng Zhang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08692",
    "title": "Time Domain Adversarial Voice Conversion for ADD 2022",
    "abstract": "In this paper, we describe our speech generation system for the first Audio Deep Synthesis Detection Challenge (ADD 2022). Firstly, we build an any-to-many voice conversion (VC) system to convert source speech with arbitrary language content into the target speaker%u2019s fake speech. Then the converted speech generated from VC is post-processed in the time domain to improve the deception ability. The experimental results show that our system has adversarial ability against anti-spoofing detectors with a little compromise in audio quality and speaker similarity. This system ranks top in Track 3.1 in the ADD 2022, showing that our method could also gain good generalization ability against different detectors. ",
    "url": "https://arxiv.org/abs/2204.08692",
    "authors": [
      "Cheng Wen",
      "Tingwei Guo",
      "Xingjun Tan",
      "Rui Yan",
      "Shuran Zhou",
      "Chuandong Xie",
      "Wei Zou",
      "Xiangang Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.08720",
    "title": "Audio Deep Fake Detection System with Neural Stitching for ADD 2022",
    "abstract": "This paper describes our best system and methodology for ADD 2022: The First Audio Deep Synthesis Detection Challenge\\cite{Yi2022ADD}. The very same system was used for both two rounds of evaluation in Track 3.2 with a similar training methodology. The first round of Track 3.2 data is generated from Text-to-Speech(TTS) or voice conversion (VC) algorithms, while the second round of data consists of generated fake audio from other participants in Track 3.1, aiming to spoof our systems. Our systems use a standard 34-layer ResNet, with multi-head attention pooling \\cite{india2019self} to learn the discriminative embedding for fake audio and spoof detection. We further utilize neural stitching to boost the model's generalization capability in order to perform equally well in different tasks, and more details will be explained in the following sessions. The experiments show that our proposed method outperforms all other systems with a 10.1% equal error rate(EER) in Track 3.2. ",
    "url": "https://arxiv.org/abs/2204.08720",
    "authors": [
      "Rui Yan",
      "Cheng Wen",
      "Shuran Zhou",
      "Tingwei Guo",
      "Wei Zou",
      "Xiangang Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.08765",
    "title": "Single-Channel Speech Dereverberation using Subband Network with A  Reverberation Time Shortening Target",
    "abstract": "This work proposes a subband network for single-channel speech dereverberation, and also a new learning target based on reverberation time shortening (RTS). In the time-frequency domain, we propose to use a subband network to perform dereverberation for different frequency bands independently. The time-domain convolution can be well decomposed to subband convolutions, thence it is reasonable to train the subband network to perform subband deconvolution. The learning target for dereverberation is usually set as the direct-path speech or optionally with some early reflections. This type of target suddenly truncates the reverberation, and thus it may not be suitable for network training, and leads to a large prediction error. In this work, we propose a RTS learning target to suppress reverberation and meanwhile maintain the exponential decaying property of reverberation, which will ease the network training, and thus reduce the prediction error and signal distortions. Experiments show that the subband network can achieve outstanding dereverberation performance, and the proposed target has a smaller prediction error than the target of direct-path speech and early reflections. ",
    "url": "https://arxiv.org/abs/2204.08765",
    "authors": [
      "Rui Zhou",
      "Wenye Zhu",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.08797",
    "title": "Two-Stream Graph Convolutional Network for Intra-oral Scanner Image  Segmentation",
    "abstract": "Precise segmentation of teeth from intra-oral scanner images is an essential task in computer-aided orthodontic surgical planning. The state-of-the-art deep learning-based methods often simply concatenate the raw geometric attributes (i.e., coordinates and normal vectors) of mesh cells to train a single-stream network for automatic intra-oral scanner image segmentation. However, since different raw attributes reveal completely different geometric information, the naive concatenation of different raw attributes at the (low-level) input stage may bring unnecessary confusion in describing and differentiating between mesh cells, thus hampering the learning of high-level geometric representations for the segmentation task. To address this issue, we design a two-stream graph convolutional network (i.e., TSGCN), which can effectively handle inter-view confusion between different raw attributes to more effectively fuse their complementary information and learn discriminative multi-view geometric representations. Specifically, our TSGCN adopts two input-specific graph-learning streams to extract complementary high-level geometric representations from coordinates and normal vectors, respectively. Then, these single-view representations are further fused by a self-attention module to adaptively balance the contributions of different views in learning more discriminative multi-view representations for accurate and fully automatic tooth segmentation. We have evaluated our TSGCN on a real-patient dataset of dental (mesh) models acquired by 3D intraoral scanners. Experimental results show that our TSGCN significantly outperforms state-of-the-art methods in 3D tooth (surface) segmentation. Github: https://github.com/ZhangLingMing1/TSGCNet. ",
    "url": "https://arxiv.org/abs/2204.08797",
    "authors": [
      "Yue Zhao",
      "Lingming Zhang",
      "Yang Liu",
      "Deyu Meng",
      "Zhiming Cui",
      "Chenqiang Gao",
      "Xinbo Gao",
      "Chunfeng Lian",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08990",
    "title": "Study of Robust Sparsity-Aware RLS algorithms with Jointly-Optimized  Parameters for Impulsive Noise Environments",
    "abstract": "This paper proposes a unified sparsity-aware robust recursive least-squares RLS (S-RRLS) algorithm for the identification of sparse systems under impulsive noise. The proposed algorithm generalizes multiple algorithms only by replacing the specified criterion of robustness and sparsity-aware penalty. Furthermore, by jointly optimizing the forgetting factor and the sparsity penalty parameter, we develop the jointly-optimized S-RRLS (JO-S-RRLS) algorithm, which not only exhibits low misadjustment but also can track well sudden changes of a sparse system. Simulations in impulsive noise scenarios demonstrate that the proposed S-RRLS and JO-S-RRLS algorithms outperform existing techniques. ",
    "url": "https://arxiv.org/abs/2204.08990",
    "authors": [
      "Y. Yu",
      "L. Lu",
      "Y. Zakharov",
      "R. C. de Lamare",
      "B. Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08994",
    "title": "Calculate the Optimum Threshold for Double Energy Detection Technique in  Cognitive Radio Networks (CRNs)",
    "abstract": "One of the most important technical challenges when designing a Cognitive Radio Networks (CRNs) is spectrum sensing, which has the responsibility of recognizing the presence or absence of the primary users in the frequency bands. A common technique used for spectrum sensing is double energy detection since it can operate without any prior information regarding the characteristics of the primary user signals. A double threshold energy detection algorithm is based on the use of two thresholds, to check the energy of the received signals and decided whether the spectrum is occupied or not. Furthermore, thresholds play a key role in the energy detection algorithm, by considering the stochastic features of noise in this model, as a result calculating the optimal threshold is a crucial task. In this paper, the Bi-Section algorithm was used to detect the optimum energy level in the fuzzy region which is an area between the low and high energy threshold. For this purpose, the decision threshold was determined by the use of the Bisection function for cognitive users. Numerical simulations show that the proposed method achieves better detection performance than the conventional double-threshold energy-sensing schemes. Moreover, the presented technique has advantages such as increasing the probability of detection of primary users and decreasing the probability of Collison between primary and secondary users. ",
    "url": "https://arxiv.org/abs/2204.08994",
    "authors": [
      "Morteza Alijani",
      "Anas Osman"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.09019",
    "title": "Hybrid Transformer Network for Different Horizons-based Enriched Wind  Speed Forecasting",
    "abstract": "Highly accurate different horizon-based wind speed forecasting facilitates a better modern power system. This paper proposed a novel astute hybrid wind speed forecasting model and applied it to different horizons. The proposed hybrid forecasting model decomposes the original wind speed data into IMFs (Intrinsic Mode Function) using Improved Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN). We fed the obtained subseries from ICEEMDAN to the transformer network. Each transformer network computes the forecast subseries and then passes to the fusion phase. Get the primary wind speed forecasting from the fusion of individual transformer network forecast subseries. Estimate the residual error values and predict errors using a multilayer perceptron neural network. The forecast error is added to the primary forecast wind speed to leverage the high accuracy of wind speed forecasting. Comparative analysis with real-time Kethanur, India wind farm dataset results reveals the proposed ICEEMDAN-TNF-MLPN-RECS hybrid model's superior performance with MAE=1.7096*10^-07, MAPE=2.8416*10^-06, MRE=2.8416*10^-08, MSE=5.0206*10^-14, and RMSE=2.2407*10^-07 for case study 1 and MAE=6.1565*10^-07, MAPE=9.5005*10^-06, MRE=9.5005*10^-08, MSE=8.9289*10^-13, and RMSE=9.4493*10^-07 for case study 2 enriched wind speed forecasting than state-of-the-art methods and reduces the burden on the power system engineer. ",
    "url": "https://arxiv.org/abs/2204.09019",
    "authors": [
      "Dr. M. Madhiarasan",
      "Prof. Partha Pratim Roy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:1911.03129",
    "title": "A Novel Sybil Attack Detection Scheme Based on Edge Computing for Mobile  IoT Environment",
    "abstract": " Comments: The RSSI-based detection scheme might have faults which need further resolving. I request for a withdraw for this article to improve the detection scheme ",
    "url": "https://arxiv.org/abs/1911.03129",
    "authors": [
      "Manli Yuan",
      "Liwei Lin",
      "Zhengyu Wu",
      "Xiucai Ye"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2001.00937",
    "title": "Resilient Multi-Dimensional Consensus in Adversarial Environment",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:1911.10836 ",
    "url": "https://arxiv.org/abs/2001.00937",
    "authors": [
      "Jiaqi Yan",
      "Xiuxian Li",
      "Yilin Mo",
      "Changyun Wen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2007.02686",
    "title": "Meta-Learning through Hebbian Plasticity in Random Networks",
    "abstract": " Comments: v5: Typo in initialization values corrected. v4: Typo in equation in 3.1 corrected. v3: Bug that made diagonal patterns appear has been fixed. Simulations have been re-run and plots updated. v2: Figures 1, 7 and Table 1 updated, new results on 4.1 added, typos corrected, references added ",
    "url": "https://arxiv.org/abs/2007.02686",
    "authors": [
      "Elias Najarro",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.11232",
    "title": "NeuralAnnot: Neural Annotator for 3D Human Mesh Training Sets",
    "abstract": " Comments: Published at CVPRW 2022 ",
    "url": "https://arxiv.org/abs/2011.11232",
    "authors": [
      "Gyeongsik Moon",
      "Hongsuk Choi",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.01870",
    "title": "Model-free Neural Counterfactual Regret Minimization with Bootstrap  Learning",
    "abstract": " Title: Model-free Neural Counterfactual Regret Minimization with Bootstrap  Learning ",
    "url": "https://arxiv.org/abs/2012.01870",
    "authors": [
      "Weiming Liu",
      "Bin Li",
      "Julian Togelius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2102.08501",
    "title": "DEUP: Direct Epistemic Uncertainty Prediction",
    "abstract": " Title: DEUP: Direct Epistemic Uncertainty Prediction ",
    "url": "https://arxiv.org/abs/2102.08501",
    "authors": [
      "Salem Lahlou",
      "Moksh Jain",
      "Hadi Nekoei",
      "Victor Butoi",
      "Paul Bertin",
      "Jarrid Rector-Brooks",
      "Maksym Korablyov",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.12634",
    "title": "Epidemic Spreading and Digital Contact Tracing: Effects of Heterogeneous  Mixing and Quarantine Failures",
    "abstract": " Title: Epidemic Spreading and Digital Contact Tracing: Effects of Heterogeneous  Mixing and Quarantine Failures ",
    "url": "https://arxiv.org/abs/2103.12634",
    "authors": [
      "Abbas K. Rizi",
      "Ali Faqeeh",
      "Arash Badie-Modiri",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2104.09770",
    "title": "M2TR: Multi-modal Multi-scale Transformers for Deepfake Detection",
    "abstract": " Comments: accepted by ICMR 2022 ",
    "url": "https://arxiv.org/abs/2104.09770",
    "authors": [
      "Junke Wang",
      "Zuxuan Wu",
      "Wenhao Ouyang",
      "Xintong Han",
      "Jingjing Chen",
      "Ser-Nam Lim",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.04400",
    "title": "CSRNet: Cascaded Selective Resolution Network for Real-time Semantic  Segmentation",
    "abstract": " Title: CSRNet: Cascaded Selective Resolution Network for Real-time Semantic  Segmentation ",
    "url": "https://arxiv.org/abs/2106.04400",
    "authors": [
      "Jingjing Xiong",
      "Lai-Man Po",
      "Wing-Yin Yu",
      "Chang Zhou",
      "Pengfei Xian",
      "Weifeng Ou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.09887",
    "title": "An overview of mixing augmentation methods and augmentation strategies",
    "abstract": " Title: An overview of mixing augmentation methods and augmentation strategies ",
    "url": "https://arxiv.org/abs/2107.09887",
    "authors": [
      "Dominik Lewy",
      "Jacek Ma\u0144dziuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.05021",
    "title": "A Deep Learning-Based Unified Framework for Red Lesions Detection on  Retinal Fundus Images",
    "abstract": " Title: A Deep Learning-Based Unified Framework for Red Lesions Detection on  Retinal Fundus Images ",
    "url": "https://arxiv.org/abs/2109.05021",
    "authors": [
      "Norah Asiri",
      "Muhammad Hussain",
      "Fadwa Al Adel",
      "Hatim Aboalsamh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12390",
    "title": "Model reduction for the material point method via an implicit neural  representation of the deformation map",
    "abstract": " Title: Model reduction for the material point method via an implicit neural  representation of the deformation map ",
    "url": "https://arxiv.org/abs/2109.12390",
    "authors": [
      "Peter Yichen Chen",
      "Maurizio Chiaramonte",
      "Eitan Grinspun",
      "Kevin Carlberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.03302",
    "title": "MPSN: Motion-aware Pseudo Siamese Network for Indoor Video Head  Detection in Buildings",
    "abstract": " Title: MPSN: Motion-aware Pseudo Siamese Network for Indoor Video Head  Detection in Buildings ",
    "url": "https://arxiv.org/abs/2110.03302",
    "authors": [
      "Kailai Sun",
      "Xiaoteng Ma",
      "Peng Liu",
      "Qianchuan Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.10249",
    "title": "Neural Stochastic Partial Differential Equations: Resolution-Invariant  Learning of Continuous Spatiotemporal Dynamics",
    "abstract": " Title: Neural Stochastic Partial Differential Equations: Resolution-Invariant  Learning of Continuous Spatiotemporal Dynamics ",
    "url": "https://arxiv.org/abs/2110.10249",
    "authors": [
      "Cristopher Salvi",
      "Maud Lemercier",
      "Andris Gerasimovics"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12698",
    "title": "Open-Vocabulary Instance Segmentation via Robust Cross-Modal  Pseudo-Labeling",
    "abstract": " Title: Open-Vocabulary Instance Segmentation via Robust Cross-Modal  Pseudo-Labeling ",
    "url": "https://arxiv.org/abs/2111.12698",
    "authors": [
      "Dat Huynh",
      "Jason Kuen",
      "Zhe Lin",
      "Jiuxiang Gu",
      "Ehsan Elhamifar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.13328",
    "title": "Advantage of the key relay protocol over secure network coding",
    "abstract": " Comments: 15 pages, 14 figures. v2: We improved Theorem 2 ",
    "url": "https://arxiv.org/abs/2111.13328",
    "authors": [
      "Go Kato",
      "Mikio Fujiwara",
      "Toyohiro Tsurumaru"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2111.14484",
    "title": "Energy-Efficient Implementation of Generative Adversarial Networks on  Passive RRAM Crossbar Arrays",
    "abstract": " Title: Energy-Efficient Implementation of Generative Adversarial Networks on  Passive RRAM Crossbar Arrays ",
    "url": "https://arxiv.org/abs/2111.14484",
    "authors": [
      "Siddharth Satyam",
      "Honey Nikam",
      "Shubham Sahay"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2112.02713",
    "title": "Joint Symmetry Detection and Shape Matching for Non-Rigid Point Cloud",
    "abstract": " Comments: Under Review. arXiv admin note: substantial text overlap with arXiv:2110.02994 ",
    "url": "https://arxiv.org/abs/2112.02713",
    "authors": [
      "Abhishek Sharma",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14391",
    "title": "Perceptive Mobile Network with Distributed Target Monitoring Terminals:  Leaking Communication Energy for Sensing",
    "abstract": " Comments: This paper has been submitted to the IEEE for possible publication ",
    "url": "https://arxiv.org/abs/2112.14391",
    "authors": [
      "Lei Xie",
      "Peilan Wang",
      "S.H. Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.04048",
    "title": "SnapFuzz: An Efficient Fuzzing Framework for Network Applications",
    "abstract": " Title: SnapFuzz: An Efficient Fuzzing Framework for Network Applications ",
    "url": "https://arxiv.org/abs/2201.04048",
    "authors": [
      "Anastasios Andronidis",
      "Cristian Cadar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.10316",
    "title": "Niching-based Evolutionary Diversity Optimization for the Traveling  Salesperson Problem",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2201.10316",
    "authors": [
      "Anh Viet Do",
      "Mingyu Guo",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.12811",
    "title": "A DFS Algorithm for Maximum Matchings in General Graphs",
    "abstract": " Comments: 17 pages, 9 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2201.12811",
    "authors": [
      "Tony T. Lee",
      "Bojun Lu",
      "Hanli Chu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2202.02232",
    "title": "Bootstrapped Representation Learning for Skeleton-Based Action  Recognition",
    "abstract": " Comments: Accepted: 2022 IEEE CVPR Workshop on Learning with Limited Labelled Data for Image and Video Understanding (L3D-IVU) ",
    "url": "https://arxiv.org/abs/2202.02232",
    "authors": [
      "Olivier Moliner",
      "Sangxia Huang",
      "Kalle \u00c5str\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04639",
    "title": "Point-Level Region Contrast for Object Detection Pre-Training",
    "abstract": " Comments: CVPR 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2202.04639",
    "authors": [
      "Yutong Bai",
      "Xinlei Chen",
      "Alexander Kirillov",
      "Alan Yuille",
      "Alexander C. Berg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.05337",
    "title": "Neural Network Training Using Closed-Loop Data: Hazards and an  Instrumental Variable (IVNN) Solution",
    "abstract": " Title: Neural Network Training Using Closed-Loop Data: Hazards and an  Instrumental Variable (IVNN) Solution ",
    "url": "https://arxiv.org/abs/2202.05337",
    "authors": [
      "Johan Kon",
      "Marcel Heertjes",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.08766",
    "title": "Can DtN and GenEO coarse spaces be sufficiently robust for heterogeneous  Helmholtz problems?",
    "abstract": " Title: Can DtN and GenEO coarse spaces be sufficiently robust for heterogeneous  Helmholtz problems? ",
    "url": "https://arxiv.org/abs/2202.08766",
    "authors": [
      "Niall Bootland",
      "Victorita Dolean"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.01247",
    "title": "H4D: Human 4D Modeling by Learning Neural Compositional Representation",
    "abstract": " Comments: Accepted by CVPR 2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2203.01247",
    "authors": [
      "Boyan Jiang",
      "Yinda Zhang",
      "Xingkui Wei",
      "Xiangyang Xue",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01520",
    "title": "An Open Challenge for Inductive Link Prediction on Knowledge Graphs",
    "abstract": " Comments: Accepted at the Workshop on Graph Learning Benchmarks @ The WebConf 2022 ",
    "url": "https://arxiv.org/abs/2203.01520",
    "authors": [
      "Mikhail Galkin",
      "Max Berrendorf",
      "Charles Tapley Hoyt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07544",
    "title": "A Unified Framework for Rank-based Evaluation Metrics for Link  Prediction in Knowledge Graphs",
    "abstract": " Comments: Accepted at the Workshop on Graph Learning Benchmarks @ The WebConf 2022 ",
    "url": "https://arxiv.org/abs/2203.07544",
    "authors": [
      "Charles Tapley Hoyt",
      "Max Berrendorf",
      "Mikhail Galkin",
      "Volker Tresp",
      "Benjamin M. Gyori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.12601",
    "title": "R3M: A Universal Visual Representation for Robot Manipulation",
    "abstract": " Title: R3M: A Universal Visual Representation for Robot Manipulation ",
    "url": "https://arxiv.org/abs/2203.12601",
    "authors": [
      "Suraj Nair",
      "Aravind Rajeswaran",
      "Vikash Kumar",
      "Chelsea Finn",
      "Abhinav Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.14260",
    "title": "Unsupervised Vision-Language Parsing: Seamlessly Bridging Visual Scene  Graphs with Language Structures via Dependency Relationships",
    "abstract": " Comments: We decide to refine this paper further ",
    "url": "https://arxiv.org/abs/2203.14260",
    "authors": [
      "Chao Lou",
      "Wenjuan Han",
      "Yuhuan Lin",
      "Zilong Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.00352",
    "title": "On the Efficiency of Integrating Self-supervised Learning and  Meta-learning for User-defined Few-shot Keyword Spotting",
    "abstract": " Comments: Submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2204.00352",
    "authors": [
      "Wei-Tsung Kao",
      "Yuen-Kwei Wu",
      "Chia-Ping Chen",
      "Zhi-Sheng Chen",
      "Yu-Pao Tsai",
      "Hung-Yi Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02470",
    "title": "Combining Spectral and Self-Supervised Features for Low Resource Speech  Recognition and Translation",
    "abstract": " Comments: 5 pages, 2 figures, submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2204.02470",
    "authors": [
      "Dan Berrebbi",
      "Jiatong Shi",
      "Brian Yan",
      "Osbel Lopez-Francisco",
      "Jonathan D. Amith",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.04149",
    "title": "A Credible and Robust approach to Ego-Motion Estimation using an  Automotive Radar",
    "abstract": " Comments: Withdraw V1, IEEE RAL header Copyrights should be in the first page and have been done on V2 ",
    "url": "https://arxiv.org/abs/2204.04149",
    "authors": [
      "Karim Haggag",
      "Sven Lange",
      "Tim Pfeifer",
      "Peter Protzel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.04853",
    "title": "Neural Lagrangian Schr\u00f6dinger Bridge",
    "abstract": " Title: Neural Lagrangian Schr\u00f6dinger Bridge ",
    "url": "https://arxiv.org/abs/2204.04853",
    "authors": [
      "Takeshi Koshizuka",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2204.05088",
    "title": "M$^2$BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified  Birds-Eye View Representation",
    "abstract": " Comments: Tech Report ",
    "url": "https://arxiv.org/abs/2204.05088",
    "authors": [
      "Enze Xie",
      "Zhiding Yu",
      "Daquan Zhou",
      "Jonah Philion",
      "Anima Anandkumar",
      "Sanja Fidler",
      "Ping Luo",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.06386",
    "title": "Efficient Deep Neural Network Accelerator Using Controlled Ferroelectric  Domain Dynamics",
    "abstract": " Title: Efficient Deep Neural Network Accelerator Using Controlled Ferroelectric  Domain Dynamics ",
    "url": "https://arxiv.org/abs/2204.06386",
    "authors": [
      "Sayani Majumdar"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2204.06718",
    "title": "Learning Convolutional Neural Networks in the Frequency Domain",
    "abstract": " Title: Learning Convolutional Neural Networks in the Frequency Domain ",
    "url": "https://arxiv.org/abs/2204.06718",
    "authors": [
      "Hengyue Pan",
      "Yixin Chen",
      "Xin Niu",
      "Wenbo Zhou",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07579",
    "title": "Interpretable Fault Diagnosis of Rolling Element Bearings with Temporal  Logic Neural Network",
    "abstract": " Title: Interpretable Fault Diagnosis of Rolling Element Bearings with Temporal  Logic Neural Network ",
    "url": "https://arxiv.org/abs/2204.07579",
    "authors": [
      "Gang Chen",
      "Yu Lu",
      "Rong Su",
      "Zhaodan Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.08143",
    "title": "Detect Rumors in Microblog Posts for Low-Resource Domains via  Adversarial Contrastive Learning",
    "abstract": " Comments: The first study for the low-resource rumor detection on social media in cross-domain and cross-lingual settings ",
    "url": "https://arxiv.org/abs/2204.08143",
    "authors": [
      "Hongzhan Lin",
      "Jing Ma",
      "Liangliang Chen",
      "Zhiwei Yang",
      "Mingfei Cheng",
      "Guang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.08352",
    "title": "MHSCNet: A Multimodal Hierarchical Shot-aware Convolutional Network for  Video Summarization",
    "abstract": " Title: MHSCNet: A Multimodal Hierarchical Shot-aware Convolutional Network for  Video Summarization ",
    "url": "https://arxiv.org/abs/2204.08352",
    "authors": [
      "Wujiang Xu",
      "Shaoshuai Li",
      "Qiongxu Ma",
      "Yunan Zhao",
      "Sheng Guo",
      "Xiaobo Guo",
      "Bing Han",
      "Junchi Yan",
      "Yifei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.08454",
    "title": "Revisiting Consistency Regularization for Semi-supervised Change  Detection in Remote Sensing Images",
    "abstract": " Comments: Code available at this https URL 36 pages ",
    "url": "https://arxiv.org/abs/2204.08454",
    "authors": [
      "Wele Gedara Chaminda Bandara",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  }
]