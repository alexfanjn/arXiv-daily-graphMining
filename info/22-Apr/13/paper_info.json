[
  {
    "id": "arXiv:2204.05311",
    "title": "Causal Discovery and Causal Learning for Fire Resistance Evaluation:  Incorporating Domain Knowledge",
    "abstract": "Experiments remain the gold standard to establish an understanding of fire-related phenomena. A primary goal in designing tests is to uncover the data generating process (i.e., the how and why the observations we see come to be); or simply what causes such observations. Uncovering such a process not only advances our knowledge but also provides us with the capability to be able to predict phenomena accurately. This paper presents an approach that leverages causal discovery and causal inference to evaluate the fire resistance of structural members. In this approach, causal discovery algorithms are adopted to uncover the causal structure between key variables pertaining to the fire resistance of reinforced concrete (RC) columns. Then, companion inference algorithms are applied to infer (estimate) the influence of each variable on the fire resistance given a specific intervention. Finally, this study ends by contrasting the algorithmic causal discovery with that obtained from domain knowledge and traditional machine learning. Our findings clearly show the potential and merit of adopting causality into our domain. ",
    "url": "https://arxiv.org/abs/2204.05311",
    "authors": [
      "M.Z. Naser",
      "Aybike Ozyuksel Ciftcioglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2204.05351",
    "title": "Graph Ordering Attention Networks",
    "abstract": "Graph Neural Networks (GNNs) have been successfully used in many problems involving graph-structured data, achieving state-of-the-art performance. GNNs typically employ a message-passing scheme, in which every node aggregates information from its neighbors using a permutation-invariant aggregation function. Standard well-examined choices such as the mean or sum aggregation functions have limited capabilities, as they are not able to capture interactions among neighbors. In this work, we formalize these interactions using an information-theoretic framework that notably includes synergistic information. Driven by this definition, we introduce the Graph Ordering Attention (GOAT) layer, a novel GNN component that captures interactions between nodes in a neighborhood. This is achieved by learning local node orderings via an attention mechanism and processing the ordered representations using a recurrent neural network aggregator. This design allows us to make use of a permutation-sensitive aggregator while maintaining the permutation-equivariance of the proposed GOAT layer. The GOAT model demonstrates its increased performance in modeling graph metrics that capture complex information, such as the betweenness centrality and the effective size of a node. In practical use-cases, its superior modeling capability is confirmed through its success in several real-world node classification benchmarks. ",
    "url": "https://arxiv.org/abs/2204.05351",
    "authors": [
      "Michail Chatzianastasis",
      "Johannes F. Lutzeyer",
      "George Dasoulas",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05352",
    "title": "Large-Scale Streaming End-to-End Speech Translation with Neural  Transducers",
    "abstract": "Neural transducers have been widely used in automatic speech recognition (ASR). In this paper, we introduce it to streaming end-to-end speech translation (ST), which aims to convert audio signals to texts in other languages directly. Compared with cascaded ST that performs ASR followed by text-based machine translation (MT), the proposed Transformer transducer (TT)-based ST model drastically reduces inference latency, exploits speech information, and avoids error propagation from ASR to MT. To improve the modeling capacity, we propose attention pooling for the joint network in TT. In addition, we extend TT-based ST to multilingual ST, which generates texts of multiple languages at the same time. Experimental results on a large-scale 50 thousand (K) hours pseudo-labeled training set show that TT-based ST not only significantly reduces inference time but also outperforms non-streaming cascaded ST for English-German translation. ",
    "url": "https://arxiv.org/abs/2204.05352",
    "authors": [
      "Jian Xue",
      "Peidong Wang",
      "Jinyu Li",
      "Matt Post",
      "Yashesh Gaur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05365",
    "title": "PolyARBerNN: A Neural Network Guided Solver and Optimizer for Bounded  Polynomial Inequalities",
    "abstract": "Constraints solvers play a significant role in the analysis, synthesis, and formal verification of complex embedded and cyber-physical systems. In this paper, we study the problem of designing a scalable constraints solver for an important class of constraints named polynomial constraint inequalities (also known as non-linear real arithmetic theory). In this paper, we introduce a solver named PolyARBerNN that uses convex polynomials as abstractions for highly nonlinear polynomials. Such abstractions were previously shown to be powerful to prune the search space and restrict the usage of sound and complete solvers to small search spaces. Compared with the previous efforts on using convex abstractions, PolyARBerNN provides three main contributions namely (i) a neural network guided abstraction refinement procedure that helps selecting the right abstraction out of a set of pre-defined abstractions, (ii) a Bernstein polynomial-based search space pruning mechanism that can be used to compute tight estimates of the polynomial maximum and minimum values which can be used as an additional abstraction of the polynomials, and (iii) an optimizer that transforms polynomial objective functions into polynomial constraints (on the gradient of the objective function) whose solutions are guaranteed to be close to the global optima. These enhancements together allowed the PolyARBerNN solver to solve complex instances and scales more favorably compared to the state-of-art non-linear real arithmetic solvers while maintaining the soundness and completeness of the resulting solver. In particular, our test benches show that PolyARBerNN achieved 100X speedup compared with Z3 8.9, Yices 2.6, and NASALib (a solver that uses Bernstein expansion to solve multivariate polynomial constraints) on a variety of standard test benches. ",
    "url": "https://arxiv.org/abs/2204.05365",
    "authors": [
      "Wael Fatnassi",
      "Yasser shoukry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.05381",
    "title": "Self-supervised Vision Transformers for Joint SAR-optical Representation  Learning",
    "abstract": "Self-supervised learning (SSL) has attracted much interest in remote sensing and earth observation due to its ability to learn task-agnostic representations without human annotation. While most of the existing SSL works in remote sensing utilize ConvNet backbones and focus on a single modality, we explore the potential of vision transformers (ViTs) for joint SAR-optical representation learning. Based on DINO, a state-of-the-art SSL algorithm that distills knowledge from two augmented views of an input image, we combine SAR and optical imagery by concatenating all channels to a unified input. Subsequently, we randomly mask out channels of one modality as a data augmentation strategy. While training, the model gets fed optical-only, SAR-only, and SAR-optical image pairs learning both inner- and intra-modality representations. Experimental results employing the BigEarthNet-MM dataset demonstrate the benefits of both, the ViT backbones and the proposed multimodal SSL algorithm DINO-MM. ",
    "url": "https://arxiv.org/abs/2204.05381",
    "authors": [
      "Yi Wang",
      "Conrad M Albrecht",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05422",
    "title": "SATA: Sparsity-Aware Training Accelerator for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) have gained huge attention as a potential energy-efficient alternative to conventional Artificial Neural Networks (ANNs) due to their inherent high-sparsity activation. Recently, SNNs with backpropagation through time (BPTT) have achieved a higher accuracy result on image recognition tasks compared to other SNN training algorithms. Despite the success on the algorithm perspective, prior works neglect the evaluation of the hardware energy overheads of BPTT, due to the lack of a hardware evaluation platform for SNN training algorithm design. Moreover, although SNNs have been long seen as an energy-efficient counterpart of ANNs, a quantitative comparison between the training cost of SNNs and ANNs is missing. To address the above-mentioned issues, in this work, we introduce SATA (Sparsity-Aware Training Accelerator), a BPTT-based training accelerator for SNNs. The proposed SATA provides a simple and re-configurable accelerator architecture for the general-purpose hardware evaluation platform, which makes it easier to analyze the training energy for SNN training algorithms. Based on SATA, we show quantitative analyses on the energy efficiency of SNN training and make a comparison between the training cost of SNNs and ANNs. The results show that SNNs consume $1.27\\times$ more total energy with considering sparsity (spikes, gradient of firing function, and gradient of membrane potential) when compared to ANNs. We find that such high training energy cost is from time-repetitive convolution operations and data movements during backpropagation. Moreover, to guide the future SNN training algorithm design, we provide several observations on energy efficiency with respect to different SNN-specific training parameters. ",
    "url": "https://arxiv.org/abs/2204.05422",
    "authors": [
      "Ruokai Yin",
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2204.05423",
    "title": "Automated Task Updates of Temporal Logic Specifications for  Heterogeneous Robots",
    "abstract": "Given a heterogeneous group of robots executing a complex task represented in Linear Temporal Logic, and a new set of tasks for the group, we define the task update problem and propose a framework for automatically updating individual robot tasks given their respective existing tasks and capabilities. Our heuristic, token-based, conflict resolution task allocation algorithm generates a near-optimal assignment for the new task. We demonstrate the scalability of our approach through simulations of multi-robot tasks. ",
    "url": "https://arxiv.org/abs/2204.05423",
    "authors": [
      "Amy Fang",
      "Hadas Kress-Gazit"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.05427",
    "title": "Generalizing Adversarial Explanations with Grad-CAM",
    "abstract": "Gradient-weighted Class Activation Mapping (Grad- CAM), is an example-based explanation method that provides a gradient activation heat map as an explanation for Convolution Neural Network (CNN) models. The drawback of this method is that it cannot be used to generalize CNN behaviour. In this paper, we present a novel method that extends Grad-CAM from example-based explanations to a method for explaining global model behaviour. This is achieved by introducing two new metrics, (i) Mean Observed Dissimilarity (MOD) and (ii) Variation in Dissimilarity (VID), for model generalization. These metrics are computed by comparing a Normalized Inverted Structural Similarity Index (NISSIM) metric of the Grad-CAM generated heatmap for samples from the original test set and samples from the adversarial test set. For our experiment, we study adversarial attacks on deep models such as VGG16, ResNet50, and ResNet101, and wide models such as InceptionNetv3 and XceptionNet using Fast Gradient Sign Method (FGSM). We then compute the metrics MOD and VID for the automatic face recognition (AFR) use case with the VGGFace2 dataset. We observe a consistent shift in the region highlighted in the Grad-CAM heatmap, reflecting its participation to the decision making, across all models under adversarial attacks. The proposed method can be used to understand adversarial attacks and explain the behaviour of black box CNN models for image analysis. ",
    "url": "https://arxiv.org/abs/2204.05427",
    "authors": [
      "Tanmay Chakraborty",
      "Utkarsh Trehan",
      "Khawla Mallat",
      "Jean-Luc Dugelay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.05432",
    "title": "A Simple Approach to Adversarial Robustness in Few-shot Image  Classification",
    "abstract": "Few-shot image classification, where the goal is to generalize to tasks with limited labeled data, has seen great progress over the years. However, the classifiers are vulnerable to adversarial examples, posing a question regarding their generalization capabilities. Recent works have tried to combine meta-learning approaches with adversarial training to improve the robustness of few-shot classifiers. We show that a simple transfer-learning based approach can be used to train adversarially robust few-shot classifiers. We also present a method for novel classification task based on calibrating the centroid of the few-shot category towards the base classes. We show that standard adversarial training on base categories along with calibrated centroid-based classifier in the novel categories, outperforms or is on-par with state-of-the-art advanced methods on standard benchmarks for few-shot learning. Our method is simple, easy to scale, and with little effort can lead to robust few-shot classifiers. Code is available here: \\url{https://github.com/UCDvision/Simple_few_shot.git} ",
    "url": "https://arxiv.org/abs/2204.05432",
    "authors": [
      "Akshayvarun Subramanya",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05436",
    "title": "Heterogeneous Acceleration Pipeline for Recommendation System Training",
    "abstract": "Recommendation systems are unique as they show a conflation of compute and memory intensity due to their deep learning and massive embedding tables. Training these models typically involve a hybrid CPU-GPU mode, where GPUs accelerate the deep learning portion and the CPUs store and process the memory-intensive embedding tables. The hybrid mode incurs a substantial CPU-to-GPU transfer time and relies on main memory bandwidth to feed embeddings to GPU for deep learning acceleration. Alternatively, we can store the entire embeddings across GPUs to avoid the transfer time and utilize the GPU's High Bandwidth Memory (HBM). This approach requires GPU-to-GPU backend communication and scales the number of GPUs with the size of the embedding tables. To overcome these concerns, this paper offers a heterogeneous acceleration pipeline, called Hotline. Hotline leverages the insight that only a small number of embedding entries are accessed frequently, and can easily fit in a single GPU's HBM. Hotline implements a data-aware and model-aware scheduling pipeline that utilizes the (1) CPU main memory for not-frequently-accessed embeddings and (2) GPUs' local memory for frequently-accessed embeddings. Hotline improves the training throughput by dynamically stitching the execution of popular and not-popular inputs through a novel hardware accelerator and feeding to the GPUs. Results on real-world datasets and recommender models show that Hotline reduces the average training time by 3x and 1.8x in comparison to Intel-optimized CPU-GPU DLRM and HugeCTR-optimized GPU-only baseline, respectively. Hotline increases the overall training throughput to 35.7 epochs/hour in comparison to 5.3 epochs/hour for the Intel-optimized DLRM baseline ",
    "url": "https://arxiv.org/abs/2204.05436",
    "authors": [
      "Muhammad Adnan",
      "Yassaman Ebrahimzadeh Maboud",
      "Divya Mahajan",
      "Prashant J. Nair"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05437",
    "title": "Implementing Online Reinforcement Learning with Temporal Neural Networks",
    "abstract": "A Temporal Neural Network (TNN) architecture for implementing efficient online reinforcement learning is proposed and studied via simulation. The proposed T-learning system is composed of a frontend TNN that implements online unsupervised clustering and a backend TNN that implements online reinforcement learning. The reinforcement learning paradigm employs biologically plausible neo-Hebbian three-factor learning rules. As a working example, a prototype implementation of the cart-pole problem (balancing an inverted pendulum) is studied via simulation. ",
    "url": "https://arxiv.org/abs/2204.05437",
    "authors": [
      "James E. Smith"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.05439",
    "title": "A Web-Scale Analysis of the Community Origins of Image Memes",
    "abstract": "Where do the most popular online cultural artifacts such as image memes originate? Media narratives suggest that cultural innovations often originate in peripheral communities and then diffuse to the mainstream core; behavioral science suggests that intermediate network positions that bridge between the periphery and the core are especially likely to originate many influential cultural innovations. Research has yet to fully adjudicate between these predictions because prior work focuses on individual platforms such as Twitter; however, any single platform is only a small, incomplete part of the larger online cultural ecosystem. In this paper, we perform the first analysis of the origins and diffusion of image memes at web scale, via a one-month crawl of all indexible online communities that principally share meme images with English text overlays. Our results suggest that communities at the core of the network originate the most highly diffused image memes: the top 10% of communities by network centrality originate the memes that generate 62% of the image meme diffusion events on the web. A zero-inflated negative binomial regression confirms that memes from core communities are more likely to diffuse than those from peripheral communities even when controlling for community size and activity level. However, a replication analysis that follows the traditional approach of testing the same question only within a single large community, Reddit, finds the regression coefficients reversed -- underscoring the importance of engaging in web-scale, cross-community analyses. The ecosystem-level viewpoint of this work positions the web as a highly centralized generator of cultural artifacts such as image memes. ",
    "url": "https://arxiv.org/abs/2204.05439",
    "authors": [
      "Durim Morina",
      "Michael S. Bernstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.05443",
    "title": "A Protocol for Validating Social Navigation Policies",
    "abstract": "Enabling socially acceptable behavior for situated agents is a major goal of recent robotics research. Robots should not only operate safely around humans, but also abide by complex social norms. A key challenge for developing socially-compliant policies is measuring the quality of their behavior. Social behavior is enormously complex, making it difficult to create reliable metrics to gauge the performance of algorithms. In this paper, we propose a protocol for social navigation benchmarking that defines a set of canonical social navigation scenarios and an in-situ metric for evaluating performance on these scenarios using questionnaires. Our experiments show this protocol is realistic, scalable, and repeatable across runs and physical spaces. Our protocol can be replicated verbatim or it can be used to define a social navigation benchmark for novel scenarios. Our goal is to introduce a protocol for benchmarking social scenarios that is homogeneous and comparable. ",
    "url": "https://arxiv.org/abs/2204.05443",
    "authors": [
      "S\u00f6ren Pirk",
      "Edward Lee",
      "Xuesu Xiao",
      "Leila Takayama",
      "Anthony Francis",
      "Alexander Toshev"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2204.05449",
    "title": "Neural Processes with Stochastic Attention: Paying more attention to the  context dataset",
    "abstract": "Neural processes (NPs) aim to stochastically complete unseen data points based on a given context dataset. NPs essentially leverage a given dataset as a context representation to derive a suitable identifier for a novel task. To improve the prediction accuracy, many variants of NPs have investigated context embedding approaches that generally design novel network architectures and aggregation functions satisfying permutation invariant. In this work, we propose a stochastic attention mechanism for NPs to capture appropriate context information. From the perspective of information theory, we demonstrate that the proposed method encourages context embedding to be differentiated from a target dataset, allowing NPs to consider features in a target dataset and context embedding independently. We observe that the proposed method can appropriately capture context embedding even under noisy data sets and restricted task distributions, where typical NPs suffer from a lack of context embeddings. We empirically show that our approach substantially outperforms conventional NPs in various domains through 1D regression, predator-prey model, and image completion. Moreover, the proposed method is also validated by MovieLens-10k dataset, a real-world problem. ",
    "url": "https://arxiv.org/abs/2204.05449",
    "authors": [
      "Mingyu Kim",
      "Kyeongryeol Go",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05454",
    "title": "Are Multimodal Transformers Robust to Missing Modality?",
    "abstract": "Multimodal data collected from the real world are often imperfect due to missing modalities. Therefore multimodal models that are robust against modal-incomplete data are highly preferred. Recently, Transformer models have shown great success in processing multimodal data. However, existing work has been limited to either architecture designs or pre-training strategies; whether Transformer models are naturally robust against missing-modal data has rarely been investigated. In this paper, we present the first-of-its-kind work to comprehensively investigate the behavior of Transformers in the presence of modal-incomplete data. Unsurprising, we find Transformer models are sensitive to missing modalities while different modal fusion strategies will significantly affect the robustness. What surprised us is that the optimal fusion strategy is dataset dependent even for the same Transformer model; there does not exist a universal strategy that works in general cases. Based on these findings, we propose a principle method to improve the robustness of Transformer models by automatically searching for an optimal fusion strategy regarding input data. Experimental validations on three benchmarks support the superior performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2204.05454",
    "authors": [
      "Mengmeng Ma",
      "Jian Ren",
      "Long Zhao",
      "Davide Testuggine",
      "Xi Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05462",
    "title": "Out-Of-Distribution Detection In Unsupervised Continual Learning",
    "abstract": "Unsupervised continual learning aims to learn new tasks incrementally without requiring human annotations. However, most existing methods, especially those targeted on image classification, only work in a simplified scenario by assuming all new data belong to new tasks, which is not realistic if the class labels are not provided. Therefore, to perform unsupervised continual learning in real life applications, an out-of-distribution detector is required at beginning to identify whether each new data corresponds to a new task or already learned tasks, which still remains under-explored yet. In this work, we formulate the problem for Out-of-distribution Detection in Unsupervised Continual Learning (OOD-UCL) with the corresponding evaluation protocol. In addition, we propose a novel OOD detection method by correcting the output bias at first and then enhancing the output confidence for in-distribution data based on task discriminativeness, which can be applied directly without modifying the learning procedures and objectives of continual learning. Our method is evaluated on CIFAR-100 dataset by following the proposed evaluation protocol and we show improved performance compared with existing OOD detection methods under the unsupervised continual learning scenario. ",
    "url": "https://arxiv.org/abs/2204.05462",
    "authors": [
      "Jiangpeng He",
      "Fengqing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05463",
    "title": "Construction of high-order robust theta-methods with applications in  anomalous models",
    "abstract": "A general conversion strategy by involving a shifted parameter $\\theta$ is proposed to construct high-order accuracy difference formulas for fractional calculus operators. By converting the second-order backward difference formula with such strategy, a novel $\\theta$-scheme with correction terms is developed for the subdiffusion problem with nonsmooth data, which is robust even for very small $\\alpha$ and can resolve the initial singularity.The optimal error estimates are carried out with essential arguments and are verified by numerical tests. ",
    "url": "https://arxiv.org/abs/2204.05463",
    "authors": [
      "Baoli Yin",
      "Guoyu Zhang",
      "Yang Liu",
      "Hong Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.05472",
    "title": "Breaking Fair Binary Classification with Optimal Flipping Attacks",
    "abstract": "Minimizing risk with fairness constraints is one of the popular approaches to learning a fair classifier. Recent works showed that this approach yields an unfair classifier if the training set is corrupted. In this work, we study the minimum amount of data corruption required for a successful flipping attack. First, we find lower/upper bounds on this quantity and show that these bounds are tight when the target model is the unique unconstrained risk minimizer. Second, we propose a computationally efficient data poisoning attack algorithm that can compromise the performance of fair learning algorithms. ",
    "url": "https://arxiv.org/abs/2204.05472",
    "authors": [
      "Changhun Jo",
      "Jy-yong Sohn",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2204.05476",
    "title": "Accurate Discharge Coefficient Prediction of Streamlined Weirs by  Coupling Linear Regression and Deep Convolutional Gated Recurrent Unit",
    "abstract": "Streamlined weirs which are a nature-inspired type of weir have gained tremendous attention among hydraulic engineers, mainly owing to their established performance with high discharge coefficients. Computational fluid dynamics (CFD) is considered as a robust tool to predict the discharge coefficient. To bypass the computational cost of CFD-based assessment, the present study proposes data-driven modeling techniques, as an alternative to CFD simulation, to predict the discharge coefficient based on an experimental dataset. To this end, after splitting the dataset using a k fold cross validation technique, the performance assessment of classical and hybrid machine learning deep learning (ML DL) algorithms is undertaken. Among ML techniques linear regression (LR) random forest (RF) support vector machine (SVM) k-nearest neighbor (KNN) and decision tree (DT) algorithms are studied. In the context of DL, long short-term memory (LSTM) convolutional neural network (CNN) and gated recurrent unit (GRU) and their hybrid forms such as LSTM GRU, CNN LSTM and CNN GRU techniques, are compared using different error metrics. It is found that the proposed three layer hierarchical DL algorithm consisting of a convolutional layer coupled with two subsequent GRU levels, which is also hybridized with the LR method, leads to lower error metrics. This paper paves the way for data-driven modeling of streamlined weirs. ",
    "url": "https://arxiv.org/abs/2204.05476",
    "authors": [
      "Weibin Chen",
      "Danial Sharifrazi",
      "Guoxi Liang",
      "Shahab S. Band",
      "Kwok Wing Chau",
      "Amir Mosavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05477",
    "title": "Deep Normed Embeddings for Patient Representation",
    "abstract": "We introduce a novel contrastive representation learning objective and a training scheme for clinical time series. Specifically, we project high dimensional E.H.R. data to a closed unit ball of low dimension, encoding geometric priors so that the origin represents an idealized perfect health state and the euclidean norm is associated with the patient's mortality risk. Moreover, using septic patients as an example, we show how we could learn to associate the angle between two vectors with the different organ system failures, thereby, learning a compact representation which is indicative of both mortality risk and specific organ failure. We show how the learned embedding can be used for online patient monitoring, supplement clinicians and improve performance of downstream machine learning tasks. This work was partially motivated from the desire and the need to introduce a systematic way of defining intermediate rewards for Reinforcement Learning in critical care medicine. Hence, we also show how such a design in terms of the learned embedding can result in qualitatively different policies and value distributions, as compared with using only terminal rewards. ",
    "url": "https://arxiv.org/abs/2204.05477",
    "authors": [
      "Thesath Nanayakkara",
      "Gilles Clermont",
      "Christopher James Langmead",
      "David Swigon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2204.05483",
    "title": "Redwood: Using Collision Detection to Grow a Large-Scale Intent  Classification Dataset",
    "abstract": "Dialog systems must be capable of incorporating new skills via updates over time in order to reflect new use cases or deployment scenarios. Similarly, developers of such ML-driven systems need to be able to add new training data to an already-existing dataset to support these new skills. In intent classification systems, problems can arise if training data for a new skill's intent overlaps semantically with an already-existing intent. We call such cases collisions. This paper introduces the task of intent collision detection between multiple datasets for the purposes of growing a system's skillset. We introduce several methods for detecting collisions, and evaluate our methods on real datasets that exhibit collisions. To highlight the need for intent collision detection, we show that model performance suffers if new data is added in such a way that does not arbitrate colliding intents. Finally, we use collision detection to construct and benchmark a new dataset, Redwood, which is composed of 451 ntent categories from 13 original intent classification datasets, making it the largest publicly available intent classification benchmark. ",
    "url": "https://arxiv.org/abs/2204.05483",
    "authors": [
      "Stefan Larson",
      "Kevin Leach"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05486",
    "title": "Neural Graph Matching for Modification Similarity Applied to Electronic  Document Comparison",
    "abstract": "In this paper, we present a novel neural graph matching approach applied to document comparison. Document comparison is a common task in the legal and financial industries. In some cases, the most important differences may be the addition or omission of words, sentences, clauses, or paragraphs. However, it is a challenging task without recording or tracing whole edited process. Under many temporal uncertainties, we explore the potentiality of our approach to proximate the accurate comparison to make sure which element blocks have a relation of edition with others. In beginning, we apply a document layout analysis that combining traditional and modern technics to segment layout in blocks of various types appropriately. Then we transform this issue to a problem of layout graph matching with textual awareness. About graph matching, it is a long-studied problem with a broad range of applications. However, different from previous works focusing on visual images or structural layout, we also bring textual features into our model for adapting this domain. Specifically, based on the electronic document, we introduce an encoder to deal with the visual presentation decoding from PDF. Additionally, because the modifications can cause the inconsistency of document layout analysis between modified documents and the blocks can be merged and split, Sinkhorn divergence is adopted in our graph neural approach, which tries to overcome both these issues with many-to-many block matching. We demonstrate this on two categories of layouts, as follows., legal agreement and scientific articles, collected from our real-case datasets. ",
    "url": "https://arxiv.org/abs/2204.05486",
    "authors": [
      "Po-Fang Hsu",
      "Chiching Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05488",
    "title": "Overlapping Word Removal is All You Need: Revisiting Data Imbalance in  Hope Speech Detection",
    "abstract": "Hope Speech Detection, a task of recognizing positive expressions, has made significant strides recently. However, much of the current works focus on model development without considering the issue of inherent imbalance in the data. Our work revisits this issue in hope-speech detection by introducing focal loss, data augmentation, and pre-processing strategies. Accordingly, we find that introducing focal loss as part of Multilingual-BERT's (M-BERT) training process mitigates the effect of class imbalance and improves overall F1-Macro by 0.11. At the same time, contextual and back-translation-based word augmentation with M-BERT improves results by 0.10 over baseline despite imbalance. Finally, we show that overlapping word removal based on pre-processing, though simple, improves F1-Macro by 0.28. In due process, we present detailed studies depicting various behaviors of each of these strategies and summarize key findings from our empirical results for those interested in getting the most out of M-BERT for hope speech detection under real-world conditions of data imbalance. ",
    "url": "https://arxiv.org/abs/2204.05488",
    "authors": [
      "Hariharan RamakrishnaIyer LekshmiAmmal",
      "Manikandan Ravikiran",
      "Gayathri Nisha",
      "Navyasree Balamuralidhar",
      "Adithya Madhusoodanan",
      "Anand Kumar Madasamy",
      "Bharathi Raja Chakravarthi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05490",
    "title": "Modelling Evolutionary and Stationary User Preferences for Temporal Sets  Prediction",
    "abstract": "Given a sequence of sets, where each set is associated with a timestamp and contains an arbitrary number of elements, the task of temporal sets prediction aims to predict the elements in the subsequent set. Previous studies for temporal sets prediction mainly capture each user's evolutionary preference by learning from his/her own sequence. Although insightful, we argue that: 1) the collaborative signals latent in different users' sequences are essential but have not been exploited; 2) users also tend to show stationary preferences while existing methods fail to consider. To this end, we propose an integrated learning framework to model both the evolutionary and the stationary preferences of users for temporal sets prediction, which first constructs a universal sequence by chronologically arranging all the user-set interactions, and then learns on each user-set interaction. In particular, for each user-set interaction, we first design an evolutionary user preference modelling component to track the user's time-evolving preference and exploit the latent collaborative signals among different users. This component maintains a memory bank to store memories of the related user and elements, and continuously updates their memories based on the currently encoded messages and the past memories. Then, we devise a stationary user preference modelling module to discover each user's personalized characteristics according to the historical sequence, which adaptively aggregates the previously interacted elements from dual perspectives with the guidance of the user's and elements' embeddings. Finally, we develop a set-batch algorithm to improve the model efficiency, which can create time-consistent batches in advance and achieve 3.5x training speedups on average. Experiments on real-world datasets demonstrate the effectiveness and good interpretability of our approach. ",
    "url": "https://arxiv.org/abs/2204.05490",
    "authors": [
      "Le Yu",
      "Zihang Liu",
      "Tongyu Zhu",
      "Leilei Sun",
      "Bowen Du",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05492",
    "title": "The performance of quadratic models for complex phase retrieval",
    "abstract": "The aim of this paper is to study the performance of the amplitude-based model $\\widehat{x} \\in {\\rm argmin}_{x\\in \\mathbb{C}^d}\\sum_{j=1}^m\\left(|\\langle a_j,x\\rangle |-b_j\\right)^2$, where $b_j=|\\langle a_j,x_0\\rangle|+\\eta_j$ and $x_0\\in {\\mathbb C}^d$ is a target signal. The model is raised in phase retrieval and one has developed many efficient algorithms to solve it. However, there are very few results about the estimation performance in complex case. We show that $\\min_{\\theta\\in[0,2\\pi)}\\|\\widehat{x}-\\exp(i\\theta)\\cdot x_0\\|_2 \\lesssim \\frac{\\|\\eta\\|_2}{\\sqrt{m}}$ holds with high probability provided the measurement vectors $a_j\\in {\\mathbb C}^d,$ $j=1,\\ldots,m,$ are complex Gaussian random vectors and $m\\gtrsim d$. Here $\\eta=(\\eta_1,\\ldots,\\eta_m)\\in \\mathbb{R}^m$ is the noise vector without any assumption on the distribution. Furthermore, we prove that the reconstruction error is sharp. For the case where the target signal $x_0\\in \\mathbb{C}^{d}$ is sparse, we establish a similar result for the nonlinear constrained LASSO. This paper presents the first theoretical guarantee on quadratic models for complex phase retrieval. To accomplish this, we leverage a strong version of restricted isometry property for low-rank matrices. ",
    "url": "https://arxiv.org/abs/2204.05492",
    "authors": [
      "Yu Xia",
      "Zhiqiang Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.05496",
    "title": "Scalable privacy-preserving cancer type prediction with homomorphic  encryption",
    "abstract": "Machine Learning (ML) alleviates the challenges of high-dimensional data analysis and improves decision making in critical applications like healthcare. Effective cancer type from high-dimensional genetic mutation data can be useful for cancer diagnosis and treatment, if the distinguishable patterns between cancer types are identified. At the same time, analysis of high-dimensional data is computationally expensive and is often outsourced to cloud services. Privacy concerns in outsourced ML, especially in the field of genetics, motivate the use of encrypted computation, like Homomorphic Encryption (HE). But restrictive overheads of encrypted computation deter its usage. In this work, we explore the challenges of privacy preserving cancer detection using a real-world dataset consisting of more than 2 million genetic information for several cancer types. Since the data is inherently high-dimensional, we explore smaller ML models for cancer prediction to enable fast inference in the privacy preserving domain. We develop a solution for privacy preserving cancer inference which first leverages the domain knowledge on somatic mutations to efficiently encode genetic mutations and then uses statistical tests for feature selection. Our logistic regression model, built using our novel encoding scheme, achieves 0.98 micro-average area under curve with 13% higher test accuracy than similar studies. We exhaustively test our model's predictive capabilities by analyzing the genes used by the model. Furthermore, we propose a fast matrix multiplication algorithm that can efficiently handle high-dimensional data. Experimental results show that, even with 40,000 features, our proposed matrix multiplication algorithm can speed up concurrent inference of multiple individuals by approximately 10x and inference of a single individual by approximately 550x, in comparison to standard matrix multiplication. ",
    "url": "https://arxiv.org/abs/2204.05496",
    "authors": [
      "Esha Sarkar",
      "Eduardo Chielle",
      "Gamze Gursoy",
      "Leo Chen",
      "Mark Gerstein",
      "Michail Maniatakos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05499",
    "title": "Position-aware Location Regression Network for Temporal Video Grounding",
    "abstract": "The key to successful grounding for video surveillance is to understand a semantic phrase corresponding to important actors and objects. Conventional methods ignore comprehensive contexts for the phrase or require heavy computation for multiple phrases. To understand comprehensive contexts with only one semantic phrase, we propose Position-aware Location Regression Network (PLRN) which exploits position-aware features of a query and a video. Specifically, PLRN first encodes both the video and query using positional information of words and video segments. Then, a semantic phrase feature is extracted from an encoded query with attention. The semantic phrase feature and encoded video are merged and made into a context-aware feature by reflecting local and global contexts. Finally, PLRN predicts start, end, center, and width values of a grounding boundary. Our experiments show that PLRN achieves competitive performance over existing methods with less computation time and memory. ",
    "url": "https://arxiv.org/abs/2204.05499",
    "authors": [
      "Sunoh Kim",
      "Kimin Yun",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05503",
    "title": "FSOINet: Feature-Space Optimization-Inspired Network for Image  Compressive Sensing",
    "abstract": "In recent years, deep learning-based image compressive sensing (ICS) methods have achieved brilliant success. Many optimization-inspired networks have been proposed to bring the insights of optimization algorithms into the network structure design and have achieved excellent reconstruction quality with low computational complexity. But they keep the information flow in pixel space as traditional algorithms by updating and transferring the image in pixel space, which does not fully use the information in the image features. In this paper, we propose the idea of achieving information flow phase by phase in feature space and design a Feature-Space Optimization-Inspired Network (dubbed FSOINet) to implement it by mapping both steps of proximal gradient descent algorithm from pixel space to feature space. Moreover, the sampling matrix is learned end-to-end with other network parameters. Experiments show that the proposed FSOINet outperforms the existing state-of-the-art methods by a large margin both quantitatively and qualitatively. The source code is available on https://github.com/cwjjun/FSOINet. ",
    "url": "https://arxiv.org/abs/2204.05503",
    "authors": [
      "Wenjun Chen",
      "Chunling Yang",
      "Xin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05507",
    "title": "Inducing Social Optimality in Games via Adaptive Incentive Design",
    "abstract": "How can a social planner adaptively incentivize selfish agents who are learning in a strategic environment to induce a socially optimal outcome in the long run? We propose a two-timescale learning dynamics to answer this question in both atomic and non-atomic games. In our learning dynamics, players adopt a class of learning rules to update their strategies at a faster timescale, while a social planner updates the incentive mechanism at a slower timescale. In particular, the update of the incentive mechanism is based on each player's externality, which is evaluated as the difference between the player's marginal cost and the society's marginal cost in each time step. We show that any fixed point of our learning dynamics corresponds to the optimal incentive mechanism such that the corresponding Nash equilibrium also achieves social optimality. We also provide sufficient conditions for the learning dynamics to converge to a fixed point so that the adaptive incentive mechanism eventually induces a socially optimal outcome. Finally, we demonstrate that the sufficient conditions for convergence are satisfied in a variety of games, including (i) atomic networked quadratic aggregative games, (ii) atomic Cournot competition, and (iii) non-atomic network routing games. ",
    "url": "https://arxiv.org/abs/2204.05507",
    "authors": [
      "Chinmay Maheshwari",
      "Kshitij Kulkarni",
      "Manxi Wu",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)",
      "Theoretical Economics (econ.TH)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.05508",
    "title": "Fast Selective Flushing to Mitigate Contention-based Cache Timing  Attacks",
    "abstract": "Caches are widely used to improve performance in modern processors. By carefully evicting cache lines and identifying cache hit/miss time, contention-based cache timing channel attacks can be orchestrated to leak information from the victim process. Existing hardware countermeasures explored cache partitioning and randomization, are either costly, not applicable for the L1 data cache, or are vulnerable to sophisticated attacks. Countermeasures using cache flush exist but are slow since all cache lines have to be evacuated during a cache flush. In this paper, we propose for the first time a hardware/software flush-based countermeasure, called fast selective flushing (FaSe). By utilizing an ISA extension (one flush instruction) and cache modification (additional state bits and control logic), FaSe selectively flushes cache lines and provides a mitigation method with a similar effect to existing methods using naive flushing methods. FaSe is implemented on RISC-V Rocket Core/Chip and evaluated on Xilinx FPGA running user programs and the Linux operating system. Our experimental results show that FaSe reduces time overhead significantly by 36% for user programs and 42% for the operating system compared to the methods with naive flushing, with less than 1% hardware overhead. Our security test shows FaSe is capable of mitigating target cache timing attacks. ",
    "url": "https://arxiv.org/abs/2204.05508",
    "authors": [
      "Tuo Li",
      "Sri Parameswaran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2204.05515",
    "title": "CLMLF:A Contrastive Learning and Multi-Layer Fusion Method for  Multimodal Sentiment Detection",
    "abstract": "Compared with unimodal data, multimodal data can provide more features to help the model analyze the sentiment of data. Previous research works rarely consider token-level feature fusion, and few works explore learning the common features related to sentiment in multimodal data to help the model fuse multimodal features. In this paper, we propose a Contrastive Learning and Multi-Layer Fusion (CLMLF) method for multimodal sentiment detection. Specifically, we first encode text and image to obtain hidden representations, and then use a multi-layer fusion module to align and fuse the token-level features of text and image. In addition to the sentiment analysis task, we also designed two contrastive learning tasks, label based contrastive learning and data based contrastive learning tasks, which will help the model learn common features related to sentiment in multimodal data. Extensive experiments conducted on three publicly available multimodal datasets demonstrate the effectiveness of our approach for multimodal sentiment detection compared with existing methods. The codes are available for use at https://github.com/Link-Li/CLMLF ",
    "url": "https://arxiv.org/abs/2204.05515",
    "authors": [
      "Zhen Li",
      "Bing Xu",
      "Conghui Zhu",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05518",
    "title": "Trigger-GNN: A Trigger-Based Graph Neural Network for Nested Named  Entity Recognition",
    "abstract": "Nested named entity recognition (NER) aims to identify the entity boundaries and recognize categories of the named entities in a complex hierarchical sentence. Some works have been done using character-level, word-level, or lexicon-level based models. However, such researches ignore the role of the complementary annotations. In this paper, we propose a trigger-based graph neural network (Trigger-GNN) to leverage the nested NER. It obtains the complementary annotation embeddings through entity trigger encoding and semantic matching, and tackle nested entity utilizing an efficient graph message passing architecture, aggregation-update mode. We posit that using entity triggers as external annotations can add in complementary supervision signals on the whole sentences. It helps the model to learn and generalize more efficiently and cost-effectively. Experiments show that the Trigger-GNN consistently outperforms the baselines on four public NER datasets, and it can effectively alleviate the nested NER. ",
    "url": "https://arxiv.org/abs/2204.05518",
    "authors": [
      "Yuan Sui",
      "Fanyang Bu",
      "Yingting Hu",
      "Wei Yan",
      "Liang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05533",
    "title": "How does fake news use a thumbnail? CLIP-based Multimodal Detection on  the Unrepresentative News Image",
    "abstract": "This study investigates how fake news uses a thumbnail for a news article with a focus on whether a news article's thumbnail represents the news content correctly. A news article shared with an irrelevant thumbnail can mislead readers into having a wrong impression of the issue, especially in social media environments where users are less likely to click the link and consume the entire content. We propose to capture the degree of semantic incongruity in the multimodal relation by using the pretrained CLIP representation. From a source-level analysis, we found that fake news employs a more incongruous image to the main content than general news. Going further, we attempted to detect news articles with image-text incongruity. Evaluation experiments suggest that CLIP-based methods can successfully detect news articles in which the thumbnail is semantically irrelevant to news text. This study contributes to the research by providing a novel view on tackling online fake news and misinformation. Code and datasets are available at https://github.com/ssu-humane/fake-news-thumbnail. ",
    "url": "https://arxiv.org/abs/2204.05533",
    "authors": [
      "Hyewon Choi",
      "Yejun Yoon",
      "Seunghyun Yoon",
      "Kunwoo Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.05538",
    "title": "NightLab: A Dual-level Architecture with Hardness Detection for  Segmentation at Night",
    "abstract": "The semantic segmentation of nighttime scenes is a challenging problem that is key to impactful applications like self-driving cars. Yet, it has received little attention compared to its daytime counterpart. In this paper, we propose NightLab, a novel nighttime segmentation framework that leverages multiple deep learning models imbued with night-aware features to yield State-of-The-Art (SoTA) performance on multiple night segmentation benchmarks. Notably, NightLab contains models at two levels of granularity, i.e. image and regional, and each level is composed of light adaptation and segmentation modules. Given a nighttime image, the image level model provides an initial segmentation estimate while, in parallel, a hardness detection module identifies regions and their surrounding context that need further analysis. A regional level model focuses on these difficult regions to provide a significantly improved segmentation. All the models in NightLab are trained end-to-end using a set of proposed night-aware losses without handcrafted heuristics. Extensive experiments on the NightCity and BDD100K datasets show NightLab achieves SoTA performance compared to concurrent methods. ",
    "url": "https://arxiv.org/abs/2204.05538",
    "authors": [
      "Xueqing Deng",
      "Peng Wang",
      "Xiaochen Lian",
      "Shawn Newsam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05541",
    "title": "Not always about you: Prioritizing community needs when developing  endangered language technology",
    "abstract": "Languages are classified as low-resource when they lack the quantity of data necessary for training statistical and machine learning tools and models. Causes of resource scarcity vary but can include poor access to technology for developing these resources, a relatively small population of speakers, or a lack of urgency for collecting such resources in bilingual populations where the second language is high-resource. As a result, the languages described as low-resource in the literature are as different as Finnish on the one hand, with millions of speakers using it in every imaginable domain, and Seneca, with only a small-handful of fluent speakers using the language primarily in a restricted domain. While issues stemming from the lack of resources necessary to train models unite this disparate group of languages, many other issues cut across the divide between widely-spoken low resource languages and endangered languages. In this position paper, we discuss the unique technological, cultural, practical, and ethical challenges that researchers and indigenous speech community members face when working together to develop language technology to support endangered language documentation and revitalization. We report the perspectives of language teachers, Master Speakers and elders from indigenous communities, as well as the point of view of academics. We describe an ongoing fruitful collaboration and make recommendations for future partnerships between academic researchers and language community stakeholders. ",
    "url": "https://arxiv.org/abs/2204.05541",
    "authors": [
      "Zoey Liu",
      "Crystal Richardson",
      "Richard Hatcher Jr",
      "Emily Prud'hommeaux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05554",
    "title": "Towards Optimal Kron-based Reduction Of Networks (Opti-KRON) for the  Electric Power Grid",
    "abstract": "For fast timescales or long prediction horizons, the AC optimal power flow (OPF) problem becomes a computational challenge for large-scale, realistic AC networks. To overcome this challenge, this paper presents a novel network reduction methodology that leverages an efficient mixed-integer linear programming (MILP) formulation of a Kron-based reduction that is optimal in the sense that it balances the degree of the reduction with resulting modeling errors in the reduced network. The method takes as inputs the full AC network and a pre-computed library of AC load flow data and uses the graph Laplacian to constraint nodal reductions to only be feasible for neighbors of non-reduced nodes. This results in a highly effective MILP formulation which is embedded within an iterative scheme to successively improve the Kron-based network reduction until convergence. The resulting optimal network reduction is, thus, grounded in the physics of the full network. The accuracy of the network reduction methodology is then explored for a 100+ node medium-voltage distribution feeder example across a wide range of operating conditions. It is finally shown that a network reduction of 25-85% can be achieved within seconds and with worst-case voltage magnitude deviation errors within any super node cluster of less than 0.01pu. These results illustrate that the proposed optimization-based approach to Kron reduction of networks is viable for larger networks and suitable for use within various power system applications. ",
    "url": "https://arxiv.org/abs/2204.05554",
    "authors": [
      "Samuel Chevalier",
      "Mads R. Almassalkhi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.05562",
    "title": "FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient  Package for Federated Graph Learning",
    "abstract": "The incredible development of federated learning (FL) has benefited various tasks in the domains of computer vision and natural language processing, and the existing frameworks such as TFF and FATE has made the deployment easy in real-world applications. However, federated graph learning (FGL), even though graph data are prevalent, has not been well supported due to its unique characteristics and requirements. The lack of FGL-related framework increases the efforts for accomplishing reproducible research and deploying in real-world applications. Motivated by such strong demand, in this paper, we first discuss the challenges in creating an easy-to-use FGL package and accordingly present our implemented package FederatedScope-GNN (FS-G), which provides (1) a unified view for modularizing and expressing FGL algorithms; (2) comprehensive DataZoo and ModelZoo for out-of-the-box FGL capability; (3) an efficient model auto-tuning component; and (4) off-the-shelf privacy attack and defense abilities. We validate the effectiveness of FS-G by conducting extensive experiments, which simultaneously gains many valuable insights about FGL for the community. Moreover, we employ FS-G to serve the FGL application in real-world E-commerce scenarios, where the attained improvements indicate great potential business benefits. We publicly release FS-G at https://github.com/alibaba/FederatedScope to promote FGL's research and enable broad applications that would otherwise be infeasible due to the lack of a dedicated package. ",
    "url": "https://arxiv.org/abs/2204.05562",
    "authors": [
      "Zhen Wang",
      "Weirui Kuang",
      "Yuexiang Xie",
      "Liuyi Yao",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05571",
    "title": "Speech Emotion Recognition with Global-Aware Fusion on Multi-scale  Feature Representation",
    "abstract": "Speech Emotion Recognition (SER) is a fundamental task to predict the emotion label from speech data. Recent works mostly focus on using convolutional neural networks~(CNNs) to learn local attention map on fixed-scale feature representation by viewing time-varied spectral features as images. However, rich emotional feature at different scales and important global information are not able to be well captured due to the limits of existing CNNs for SER. In this paper, we propose a novel GLobal-Aware Multi-scale (GLAM) neural network (The code is available at https://github.com/lixiangucas01/GLAM) to learn multi-scale feature representation with global-aware fusion module to attend emotional information. Specifically, GLAM iteratively utilizes multiple convolutional kernels with different scales to learn multiple feature representation. Then, instead of using attention-based methods, a simple but effective global-aware fusion module is applied to grab most important emotional information globally. Experiments on the benchmark corpus IEMOCAP over four emotions demonstrates the superiority of our proposed model with 2.5% to 4.5% improvements on four common metrics compared to previous state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2204.05571",
    "authors": [
      "Wenjing Zhu",
      "Xiang Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.05575",
    "title": "DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative  3D Object Detection",
    "abstract": "Autonomous driving faces great safety challenges for a lack of global perspective and the limitation of long-range perception capabilities. It has been widely agreed that vehicle-infrastructure cooperation is required to achieve Level 5 autonomy. However, there is still NO dataset from real scenarios available for computer vision researchers to work on vehicle-infrastructure cooperation-related problems. To accelerate computer vision research and innovation for Vehicle-Infrastructure Cooperative Autonomous Driving (VICAD), we release DAIR-V2X Dataset, which is the first large-scale, multi-modality, multi-view dataset from real scenarios for VICAD. DAIR-V2X comprises 71254 LiDAR frames and 71254 Camera frames, and all frames are captured from real scenes with 3D annotations. The Vehicle-Infrastructure Cooperative 3D Object Detection problem (VIC3D) is introduced, formulating the problem of collaboratively locating and identifying 3D objects using sensory inputs from both vehicle and infrastructure. In addition to solving traditional 3D object detection problems, the solution of VIC3D needs to consider the temporal asynchrony problem between vehicle and infrastructure sensors and the data transmission cost between them. Furthermore, we propose Time Compensation Late Fusion (TCLF), a late fusion framework for the VIC3D task as a benchmark based on DAIR-V2X. Find data, code, and more up-to-date information at https://thudair.baai.ac.cn/index and https://github.com/AIR-THU/DAIR-V2X. ",
    "url": "https://arxiv.org/abs/2204.05575",
    "authors": [
      "Haibao Yu",
      "Yizhen Luo",
      "Mao Shu",
      "Yiyi Huo",
      "Zebang Yang",
      "Yifeng Shi",
      "Zhenglong Guo",
      "Hanyu Li",
      "Xing Hu",
      "Jirui Yuan",
      "Zaiqing Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05585",
    "title": "SwinNet: Swin Transformer drives edge-aware RGB-D and RGB-T salient  object detection",
    "abstract": "Convolutional neural networks (CNNs) are good at extracting contexture features within certain receptive fields, while transformers can model the global long-range dependency features. By absorbing the advantage of transformer and the merit of CNN, Swin Transformer shows strong feature representation ability. Based on it, we propose a cross-modality fusion model SwinNet for RGB-D and RGB-T salient object detection. It is driven by Swin Transformer to extract the hierarchical features, boosted by attention mechanism to bridge the gap between two modalities, and guided by edge information to sharp the contour of salient object. To be specific, two-stream Swin Transformer encoder first extracts multi-modality features, and then spatial alignment and channel re-calibration module is presented to optimize intra-level cross-modality features. To clarify the fuzzy boundary, edge-guided decoder achieves inter-level cross-modality fusion under the guidance of edge features. The proposed model outperforms the state-of-the-art models on RGB-D and RGB-T datasets, showing that it provides more insight into the cross-modality complementarity task. ",
    "url": "https://arxiv.org/abs/2204.05585",
    "authors": [
      "Zhengyi Liu",
      "Yacheng Tan",
      "Qian He",
      "Yun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05591",
    "title": "Automatic detection of glaucoma via fundus imaging and artificial  intelligence: A review",
    "abstract": "Glaucoma is a leading cause of irreversible vision impairment globally and cases are continuously rising worldwide. Early detection is crucial, allowing timely intervention which can prevent further visual field loss. To detect glaucoma, examination of the optic nerve head via fundus imaging can be performed, at the centre of which is the assessment of the optic cup and disc boundaries. Fundus imaging is non-invasive and low-cost; however, the image examination relies on subjective, time-consuming, and costly expert assessments. A timely question to ask is can artificial intelligence mimic glaucoma assessments made by experts. Namely, can artificial intelligence automatically find the boundaries of the optic cup and disc (providing a so-called segmented fundus image) and then use the segmented image to identify glaucoma with high accuracy. We conducted a comprehensive review on artificial intelligence-enabled glaucoma detection frameworks that produce and use segmented fundus images. We found 28 papers and identified two main approaches: 1) logical rule-based frameworks, based on a set of simplistic decision rules; and 2) machine learning/statistical modelling based frameworks. We summarise the state-of-art of the two approaches and highlight the key hurdles to overcome for artificial intelligence-enabled glaucoma detection frameworks to be translated into clinical practice. ",
    "url": "https://arxiv.org/abs/2204.05591",
    "authors": [
      "Lauren Coan",
      "Bryan Williams",
      "Krishna Adithya Venkatesh",
      "Swati Upadhyaya",
      "Silvester Czanner",
      "Rengaraj Venkatesh",
      "Colin E. Willoughby",
      "Srinivasan Kavitha",
      "Gabriela Czanner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05597",
    "title": "Evolutionary Algorithms for Limiting the Effect of Uncertainty for the  Knapsack Problem with Stochastic Profits",
    "abstract": "Evolutionary algorithms have been widely used for a range of stochastic optimization problems in order to address complex real-world optimization problems. We consider the knapsack problem where the profits involve uncertainties. Such a stochastic setting reflects important real-world scenarios where the profit that can be realized is uncertain. We introduce different ways of dealing with stochastic profits based on tail inequalities such as Chebyshev's inequality and Hoeffding bounds that allow to limit the impact of uncertainties. We examine simple evolutionary algorithms and the use of heavy tail mutation and a problem-specific crossover operator for optimizing uncertain profits. Our experimental investigations on different benchmarks instances show the results of different approaches based on tail inequalities as well as improvements achievable through heavy tail mutation and the problem specific crossover operator. ",
    "url": "https://arxiv.org/abs/2204.05597",
    "authors": [
      "Aneta Neumann",
      "Yue Xie",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.05604",
    "title": "Towards Open-Set Object Detection and Discovery",
    "abstract": "With the human pursuit of knowledge, open-set object detection (OSOD) has been designed to identify unknown objects in a dynamic world. However, an issue with the current setting is that all the predicted unknown objects share the same category as \"unknown\", which require incremental learning via a human-in-the-loop approach to label novel classes. In order to address this problem, we present a new task, namely Open-Set Object Detection and Discovery (OSODD). This new task aims to extend the ability of open-set object detectors to further discover the categories of unknown objects based on their visual appearance without human effort. We propose a two-stage method that first uses an open-set object detector to predict both known and unknown objects. Then, we study the representation of predicted objects in an unsupervised manner and discover new categories from the set of unknown objects. With this method, a detector is able to detect objects belonging to known classes and define novel categories for objects of unknown classes with minimal supervision. We show the performance of our model on the MS-COCO dataset under a thorough evaluation protocol. We hope that our work will promote further research towards a more robust real-world detection system. ",
    "url": "https://arxiv.org/abs/2204.05604",
    "authors": [
      "Jiyang Zheng",
      "Weihao Li",
      "Jie Hong",
      "Lars Petersson",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05605",
    "title": "Regression or Classification? Reflection on BP prediction from PPG data  using Deep Neural Networks in the scope of practical applications",
    "abstract": "Photoplethysmographic (PPG) signals offer diagnostic potential beyond heart rate analysis or blood oxygen level monitoring. In the recent past, research focused extensively on non-invasive PPG-based approaches to blood pressure (BP) estimation. These approaches can be subdivided into regression and classification methods. The latter assign PPG signals to predefined BP intervals that represent clinically relevant ranges. The former predict systolic (SBP) and diastolic (DBP) BP as continuous variables and are of particular interest to the research community. However, the reported accuracies of BP regression methods vary widely among publications with some authors even questioning the feasibility of PPG-based BP regression altogether. In our work, we compare BP regression and classification approaches. We argue that BP classification might provide diagnostic value that is equivalent to regression in many clinically relevant scenarios while being similar or even superior in terms of performance. We compare several established neural architectures using publicly available PPG data for SBP regression and classification with and without personalization using subject-specific data. We found that classification and regression models perform similar before personalization. However, after personalization, the accuracy of classification based methods outperformed regression approaches. We conclude that BP classification might be preferable over BP regression in certain scenarios where a coarser segmentation of the BP range is sufficient. ",
    "url": "https://arxiv.org/abs/2204.05605",
    "authors": [
      "Fabian Schrumpf",
      "Paul Rudi Serdack",
      "Mirco Fuchs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05632",
    "title": "Malware Analysis with Symbolic Execution and Graph Kernel",
    "abstract": "Malware analysis techniques are divided into static and dynamic analysis. Both techniques can be bypassed by circumvention techniques such as obfuscation. In a series of works, the authors have promoted the use of symbolic executions combined with machine learning to avoid such traps. Most of those works rely on natural graph-based representations that can then be plugged into graph-based learning algorithms such as Gspan. There are two main problems with this approach. The first one is in the cost of computing the graph. Indeed, working with graphs requires one to compute and representing the entire state-space of the file under analysis. As such computation is too cumbersome, the techniques often rely on developing strategies to compute a representative subgraph of the behaviors. Unfortunately, efficient graph-building strategies remain weakly explored. The second problem is in the classification itself. Graph-based machine learning algorithms rely on comparing the biggest common structures. This sidelines small but specific parts of the malware signature. In addition, it does not allow us to work with efficient algorithms such as support vector machine. We propose a new efficient open source toolchain for machine learning-based classification. We also explore how graph-kernel techniques can be used in the process. We focus on the 1-dimensional Weisfeiler-Lehman kernel, which can capture local similarities between graphs. Our experimental results show that our approach outperforms existing ones by an impressive factor. ",
    "url": "https://arxiv.org/abs/2204.05632",
    "authors": [
      "Charles-Henry Bertrand Van Ouytsel",
      "Axel Legay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05639",
    "title": "Neural Network Pruning by Cooperative Coevolution",
    "abstract": "Neural network pruning is a popular model compression method which can significantly reduce the computing cost with negligible loss of accuracy. Recently, filters are often pruned directly by designing proper criteria or using auxiliary modules to measure their importance, which, however, requires expertise and trial-and-error. Due to the advantage of automation, pruning by evolutionary algorithms (EAs) has attracted much attention, but the performance is limited for deep neural networks as the search space can be quite large. In this paper, we propose a new filter pruning algorithm CCEP by cooperative coevolution, which prunes the filters in each layer by EAs separately. That is, CCEP reduces the pruning space by a divide-and-conquer strategy. The experiments show that CCEP can achieve a competitive performance with the state-of-the-art pruning methods, e.g., prune ResNet56 for $63.42\\%$ FLOPs on CIFAR10 with $-0.24\\%$ accuracy drop, and ResNet50 for $44.56\\%$ FLOPs on ImageNet with $0.07\\%$ accuracy drop. ",
    "url": "https://arxiv.org/abs/2204.05639",
    "authors": [
      "Haopu Shang",
      "Jia-Liang Wu",
      "Wenjing Hong",
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.05663",
    "title": "Robust online joint state/input/parameter estimation of linear systems",
    "abstract": "This paper presents a method for jointly estimating the state, input, and parameters of linear systems in an online fashion. The method is specially designed for measurements that are corrupted with non-Gaussian noise or outliers, which are commonly found in engineering applications. In particular, it combines recursive, alternating, and iteratively-reweighted least squares into a single, one-step algorithm, which solves the estimation problem online and benefits from the robustness of least-deviation regression methods. The convergence of the iterative method is formally guaranteed. Numerical experiments show the good performance of the estimation algorithm in presence of outliers and in comparison to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2204.05663",
    "authors": [
      "Jean-S\u00e9bastien Brouillon",
      "Keith Moffat",
      "Florian D\u00f6rfler",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.05666",
    "title": "Three-Stream Joint Network for Zero-Shot Sketch-Based Image Retrieval",
    "abstract": "The Zero-Shot Sketch-based Image Retrieval (ZS-SBIR) is a challenging task because of the large domain gap between sketches and natural images as well as the semantic inconsistency between seen and unseen categories. Previous literature bridges seen and unseen categories by semantic embedding, which requires prior knowledge of the exact class names and additional extraction efforts. And most works reduce domain gap by mapping sketches and natural images into a common high-level space using constructed sketch-image pairs, which ignore the unpaired information between images and sketches. To address these issues, in this paper, we propose a novel Three-Stream Joint Training Network (3JOIN) for the ZS-SBIR task. To narrow the domain differences between sketches and images, we extract edge maps for natural images and treat them as a bridge between images and sketches, which have similar content to images and similar style to sketches. For exploiting a sufficient combination of sketches, natural images, and edge maps, a novel three-stream joint training network is proposed. In addition, we use a teacher network to extract the implicit semantics of the samples without the aid of other semantics and transfer the learned knowledge to unseen classes. Extensive experiments conducted on two real-world datasets demonstrate the superiority of our proposed method. ",
    "url": "https://arxiv.org/abs/2204.05666",
    "authors": [
      "Yu-Wei Zhan",
      "Xin Luo",
      "Yongxin Wang",
      "Zhen-Duo Chen",
      "Xin-Shun Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05674",
    "title": "A Generative Approach for Financial Causality Extraction",
    "abstract": "Causality represents the foremost relation between events in financial documents such as financial news articles, financial reports. Each financial causality contains a cause span and an effect span. Previous works proposed sequence labeling approaches to solve this task. But sequence labeling models find it difficult to extract multiple causalities and overlapping causalities from the text segments. In this paper, we explore a generative approach for causality extraction using the encoder-decoder framework and pointer networks. We use a causality dataset from the financial domain, \\textit{FinCausal}, for our experiments and our proposed framework achieves very competitive performance on this dataset. ",
    "url": "https://arxiv.org/abs/2204.05674",
    "authors": [
      "Tapas Nayak",
      "Soumya Sharma",
      "Yash Butala",
      "Koustuv Dasgupta",
      "Pawan Goyal",
      "Niloy Ganguly"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05682",
    "title": "A Robust Learning Rule for Soft-Bounded Memristive Synapses Competitive  with Supervised Learning in Standard Spiking Neural Networks",
    "abstract": "Memristive devices are a class of circuit elements that shows great promise as future building block for brain-inspired computing. One influential view in theoretical neuroscience sees the brain as a function-computing device: given input signals, the brain applies a function in order to generate new internal states and motor outputs. Therefore, being able to approximate functions is a fundamental axiom to build upon for future brain research and to derive more efficient computational machines. In this work we apply a novel supervised learning algorithm - based on controlling niobium-doped strontium titanate memristive synapses - to learning non-trivial multidimensional functions. By implementing our method into the spiking neural network simulator Nengo, we show that we are able to at least match the performance obtained when using ideal, linear synapses and - in doing so - that this kind of memristive device can be harnessed as computational substrate to move towards more efficient, brain-inspired computing. ",
    "url": "https://arxiv.org/abs/2204.05682",
    "authors": [
      "Thomas F. Tiotto",
      "Jelmer P. Borst",
      "Niels A. Taatgen"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.05690",
    "title": "Fault Detection and Localization in Active Distribution Networks using  Optimally Placed Phasor Measurements Units",
    "abstract": "This paper introduces an algorithm able to detect and localize the occurrance of a fault in an Active Distribution Network, using the measurements collected by Phasor Measurement Units (PMUs). First, a basic algorithm that works under the assumption that all grid buses are equipped with a PMU is designed. Then, formal observability conditions that allow detection and localization with a reduced number of PMUs are provided. Based on these conditions, the algorithm is extended to perform correctly when not all network buses are monitored. Moreover, an Optimal Positioning Algorithm, always based on the observability conditions, is designed. This algorithm allows the user to customize the fault localization resolution. The approach is validated through simulations carried out on a benchmark active distribution network. ",
    "url": "https://arxiv.org/abs/2204.05690",
    "authors": [
      "Francesco Conte",
      "Fabio D'Agostino",
      "Bruno Gabriele",
      "Giacomo-Piero Schiapparelli",
      "Federico Silvestro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.05695",
    "title": "Self-Supervised Losses for One-Class Textual Anomaly Detection",
    "abstract": "Current deep learning methods for anomaly detection in text rely on supervisory signals in inliers that may be unobtainable or bespoke architectures that are difficult to tune. We study a simpler alternative: fine-tuning Transformers on the inlier data with self-supervised objectives and using the losses as an anomaly score. Overall, the self-supervision approach outperforms other methods under various anomaly detection scenarios, improving the AUROC score on semantic anomalies by 11.6% and on syntactic anomalies by 22.8% on average. Additionally, the optimal objective and resultant learnt representation depend on the type of downstream anomaly. The separability of anomalies and inliers signals that a representation is more effective for detecting semantic anomalies, whilst the presence of narrow feature directions signals a representation that is effective for detecting syntactic anomalies. ",
    "url": "https://arxiv.org/abs/2204.05695",
    "authors": [
      "Kimberly T. Mai",
      "Toby Davies",
      "Lewis D. Griffin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05699",
    "title": "Unsupervised Anomaly and Change Detection with Multivariate  Gaussianization",
    "abstract": "Anomaly detection is a field of intense research. Identifying low probability events in data/images is a challenging problem given the high-dimensionality of the data, especially when no (or little) information about the anomaly is available a priori. While plenty of methods are available, the vast majority of them do not scale well to large datasets and require the choice of some (very often critical) hyperparameters. Therefore, unsupervised and computationally efficient detection methods become strictly necessary. We propose an unsupervised method for detecting anomalies and changes in remote sensing images by means of a multivariate Gaussianization methodology that allows to estimate multivariate densities accurately, a long-standing problem in statistics and machine learning. The methodology transforms arbitrarily complex multivariate data into a multivariate Gaussian distribution. Since the transformation is differentiable, by applying the change of variables formula one can estimate the probability at any point of the original domain. The assumption is straightforward: pixels with low estimated probability are considered anomalies. Our method can describe any multivariate distribution, makes an efficient use of memory and computational resources, and is parameter-free. We show the efficiency of the method in experiments involving both anomaly detection and change detection in different remote sensing image sets. Results show that our approach outperforms other linear and nonlinear methods in terms of detection power in both anomaly and change detection scenarios, showing robustness and scalability to dimensionality and sample sizes. ",
    "url": "https://arxiv.org/abs/2204.05699",
    "authors": [
      "Jos\u00e9 A. Padr\u00f3n-Hidalgo",
      "Valero Laparra",
      "Gustau Camps-Valls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Physics (physics.comp-ph)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2204.05703",
    "title": "Back to the Roots: Reconstructing Large and Complex Cranial Defects  using an Image-based Statistical Shape Model",
    "abstract": "Designing implants for large and complex cranial defects is a challenging task, even for professional designers. Current efforts on automating the design process focused mainly on convolutional neural networks (CNN), which have produced state-of-the-art results on reconstructing synthetic defects. However, existing CNN-based methods have been difficult to translate to clinical practice in cranioplasty, as their performance on complex and irregular cranial defects remains unsatisfactory. In this paper, a statistical shape model (SSM) built directly on the segmentation masks of the skulls is presented. We evaluate the SSM on several cranial implant design tasks, and the results show that, while the SSM performs suboptimally on synthetic defects compared to CNN-based approaches, it is capable of reconstructing large and complex defects with only minor manual corrections. The quality of the resulting implants is examined and assured by experienced neurosurgeons. In contrast, CNN-based approaches, even with massive data augmentation, fail or produce less-than-satisfactory implants for these cases. Codes are publicly available at https://github.com/Jianningli/ssm ",
    "url": "https://arxiv.org/abs/2204.05703",
    "authors": [
      "Jianning Li",
      "David G. Ellis",
      "Antonio Pepe",
      "Christina Gsaxner",
      "Michele R. Aizenberg",
      "Jens Kleesiek",
      "Jan Egger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05723",
    "title": "Distributed Transmission and Spatially Coupled Forward Error Correction  in Regenerative Multipoint-to-Point Networks",
    "abstract": "We investigate the performance of coded modulation for multi-hop regenerative optical networks. We analyze options for computing decoder input LLRs, show reach increases by optimized regenerator placement and experimentally compare strategies and guidelines for distributed FEC. ",
    "url": "https://arxiv.org/abs/2204.05723",
    "authors": [
      "Laurent Schmalen",
      "Tobias A. Eriksson",
      "Fred Buchali",
      "Roman Dischler",
      "Ulrich Gebhard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2204.05727",
    "title": "LiDAR Road-Atlas: An Efficient Map Representation for General 3D Urban  Environment",
    "abstract": "In this work, we propose the LiDAR Road-Atlas, a compactable and efficient 3D map representation, for autonomous robot or vehicle navigation in general urban environment. The LiDAR Road-Atlas can be generated by an online mapping framework based on incrementally merging local 2D occupancy grid maps (2D-OGM). Specifically, the contributions of our LiDAR Road-Atlas representation are threefold. First, we solve the challenging problem of creating local 2D-OGM in non-structured urban scenes based on a real-time delimitation of traversable and curb regions in LiDAR point cloud. Second, we achieve accurate 3D mapping in multiple-layer urban road scenarios by a probabilistic fusion scheme. Third, we achieve very efficient 3D map representation of general environment thanks to the automatic local-OGM induced traversable-region labeling and a sparse probabilistic local point-cloud encoding. Given the LiDAR Road-Atlas, one can achieve accurate vehicle localization, path planning and some other tasks. Our map representation is insensitive to dynamic objects which can be filtered out in the resulting map based on a probabilistic fusion. Empirically, we compare our map representation with a couple of popular map representation methods in robotics and autonomous driving societies, and our map representation is more favorable in terms of efficiency, scalability and compactness. In addition, we also evaluate localization accuracy extensively given the created LiDAR Road-Atlas representations on several public benchmark datasets. With a 16-channel LiDAR sensor, our method achieves an average global localization errors of 0.26m (translation) and 1.07 degrees (rotation) on the Apollo dataset, and 0.89m (translation) and 1.29 degrees (rotation) on the MulRan dataset, respectively, at 10Hz, which validates the promising performance of our map representation for autonomous driving. ",
    "url": "https://arxiv.org/abs/2204.05727",
    "authors": [
      "Banghe Wu",
      "Chengzhong Xu",
      "Hui Kong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.05758",
    "title": "Backdoor Attack against NLP models with Robustness-Aware Perturbation  defense",
    "abstract": "Backdoor attack intends to embed hidden backdoor into deep neural networks (DNNs), such that the attacked model performs well on benign samples, whereas its prediction will be maliciously changed if the hidden backdoor is activated by the attacker defined trigger. This threat could happen when the training process is not fully controlled, such as training on third-party data-sets or adopting third-party models. There has been a lot of research and different methods to defend such type of backdoor attacks, one being robustness-aware perturbation-based defense method. This method mainly exploits big gap of robustness between poisoned and clean samples. In our work, we break this defense by controlling the robustness gap between poisoned and clean samples using adversarial training step. ",
    "url": "https://arxiv.org/abs/2204.05758",
    "authors": [
      "Shaik Mohammed Maqsood",
      "Viveros Manuela Ceron",
      "Addluri GowthamKrishna"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05764",
    "title": "Examining the Proximity of Adversarial Examples to Class Manifolds in  Deep Networks",
    "abstract": "Deep neural networks achieve remarkable performance in multiple fields. However, after proper training they suffer from an inherent vulnerability against adversarial examples (AEs). In this work we shed light on inner representations of the AEs by analysing their activations on the hidden layers. We test various types of AEs, each crafted using a specific norm constraint, which affects their visual appearance and eventually their behavior in the trained networks. Our results in image classification tasks (MNIST and CIFAR-10) reveal qualitative differences between the individual types of AEs, when comparing their proximity to the class-specific manifolds on the inner representations. We propose two methods that can be used to compare the distances to class-specific manifolds, regardless of the changing dimensions throughout the network. Using these methods, we consistently confirm that some of the adversarials do not necessarily leave the proximity of the manifold of the correct class, not even in the last hidden layer of the neural network. Next, using UMAP visualisation technique, we project the class activations to 2D space. The results indicate that the activations of the individual AEs are entangled with the activations of the test set. This, however, does not hold for a group of crafted inputs called the rubbish class. We also confirm the entanglement of adversarials with the test set numerically using the soft nearest neighbour loss. ",
    "url": "https://arxiv.org/abs/2204.05764",
    "authors": [
      "\u0160tefan P\u00f3co\u0161",
      "Iveta Be\u010dkov\u00e1",
      "Igor Farka\u0161"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05798",
    "title": "Multi-View Breast Cancer Classification via Hypercomplex Neural Networks",
    "abstract": "Traditionally, deep learning-based methods for breast cancer classification perform a single-view analysis. However, radiologists simultaneously analyze all four views that compose a mammography exam, owing to the correlations contained in mammography views, which present crucial information for identifying tumors. In light of this, some studies have started to propose multi-view methods. Nevertheless, in such existing architectures, mammogram views are processed as independent images by separate convolutional branches, thus losing correlations among them. To overcome such limitations, in this paper we propose a novel approach for multi-view breast cancer classification based on parameterized hypercomplex neural networks. Thanks to hypercomplex algebra properties, our networks are able to model, and thus leverage, existing correlations between the different views that comprise a mammogram exam, thus mimicking the reading process performed by clinicians. As a consequence, the proposed method is able to handle the information of a patient altogether without breaking the multi-view nature of the exam. Starting from the proposed hypercomplex approach, we define architectures designed to process two-view exams, namely PHResNets, and four-view exams, i.e., PHYSEnet and PHYSBOnet, with the ability to grasp inter-view correlations in a wide range of clinical use cases. Through an extensive experimental evaluation conducted with two publicly available datasets, CBIS-DDSM and INbreast, we demonstrate that our parameterized hypercomplex models clearly outperform real-valued counterparts and also state-of-the-art methods, proving that breast cancer classification benefits from the proposed multi-view architecture. Full code and pretrained models for complete reproducibility of our experiments are freely available at: https://github.com/ispamm/PHBreast. ",
    "url": "https://arxiv.org/abs/2204.05798",
    "authors": [
      "Eleonora Lopez",
      "Eleonora Grassucci",
      "Martina Valleriani",
      "Danilo Comminiello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05821",
    "title": "Single-Purpose Algorithms vs. a Generic Graph Summarizer for Computing  $k$-Bisimulations on Large Graphs",
    "abstract": "We investigate whether a generic graph summarization approach BRS can outperform an existing single-purpose parallel algorithm for bisimulation. Furthermore, we investigate whether an existing sequential bisimulation algorithm can effectively be computed by the parallel BRS algorithm and how such generic implementations compete against a parallel variant. To give a fair comparison, we have reimplemented the original algorithms in the same framework as was used for the generic BRS algorithm. We evaluate the performance of the two native implementations against the implementations in the BRS algorithm for $k$-bisimulation with $k=1, \\dots, 10$, using five real-world and synthetic graph datasets containing between $100$ million and two billion edges. Our results show that our generic BRS algorithm outperforms the respective native bisimulation algorithms for any value of~$k$. The generic algorithm has no disadvantage over the native parallel algorithm. Furthermore, the execution times of the generic BRS algorithm for the native parallel and native sequential bisimulation variants are very similar. This shows that the bisimulation variant computed by the native sequential algorithm can be effectively computed in parallel by our BRS algorithm. These insights open a new path for efficiently computing bisimulations on large graphs. ",
    "url": "https://arxiv.org/abs/2204.05821",
    "authors": [
      "Jannik Rau",
      "David Richerby",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2204.05823",
    "title": "Adaptive Cross-Attention-Driven Spatial-Spectral Graph Convolutional  Network for Hyperspectral Image Classification",
    "abstract": "Recently, graph convolutional networks (GCNs) have been developed to explore spatial relationship between pixels, achieving better classification performance of hyperspectral images (HSIs). However, these methods fail to sufficiently leverage the relationship between spectral bands in HSI data. As such, we propose an adaptive cross-attention-driven spatial-spectral graph convolutional network (ACSS-GCN), which is composed of a spatial GCN (Sa-GCN) subnetwork, a spectral GCN (Se-GCN) subnetwork, and a graph cross-attention fusion module (GCAFM). Specifically, Sa-GCN and Se-GCN are proposed to extract the spatial and spectral features by modeling correlations between spatial pixels and between spectral bands, respectively. Then, by integrating attention mechanism into information aggregation of graph, the GCAFM, including three parts, i.e., spatial graph attention block, spectral graph attention block, and fusion block, is designed to fuse the spatial and spectral features and suppress noise interference in Sa-GCN and Se-GCN. Moreover, the idea of the adaptive graph is introduced to explore an optimal graph through back propagation during the training process. Experiments on two HSI data sets show that the proposed method achieves better performance than other classification methods. ",
    "url": "https://arxiv.org/abs/2204.05823",
    "authors": [
      "Jin-Yu Yang",
      "Heng-Chao Li",
      "Wen-Shuai Hu",
      "Lei Pan",
      "Qian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05826",
    "title": "Delay Optimization of Conventional Non-Coherent Differential CPM  Detection",
    "abstract": "The conventional non-coherent differential detection of continuous phase modulation (CPM) is quite robust to channel impairments such as phase and Doppler shifts. Its implementation is on top of that simple. It consists in multiplying the received baseband signal by its conjugate and delayed version of one symbol period. However it suffers from a signal-to-noise ratio gap compared to the optimum coherent detection. In this paper, we improve the error rate performance of the conventional differential detection by using a delay higher than one symbol period. We derive the trellis description as well as the branch and cumulative metric that take into account a delay of $K$ symbol periods. We then derive an optimization criterion of $K$ based on the minimum Euclidean distance between two differential signals. We finally determine optimized delays for some popular CPM formats whose values are confirmed by error rate simulations. ",
    "url": "https://arxiv.org/abs/2204.05826",
    "authors": [
      "Anouar Jerbi",
      "Karine Amis",
      "Fr\u00e9d\u00e9ric Guilloud",
      "Tarik Benaddi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2204.05872",
    "title": "Robust Quantification of Gender Disparity in Pre-Modern English  Literature using Natural Language Processing",
    "abstract": "Research has continued to shed light on the extent and significance of gender disparity in social, cultural and economic spheres. More recently, computational tools from the Natural Language Processing (NLP) literature have been proposed for measuring such disparity using relatively extensive datasets and empirically rigorous methodologies. In this paper, we contribute to this line of research by studying gender disparity, at scale, in copyright-expired literary texts published in the pre-modern period (defined in this work as the period ranging from the mid-nineteenth through the mid-twentieth century). One of the challenges in using such tools is to ensure quality control, and by extension, trustworthy statistical analysis. Another challenge is in using materials and methods that are publicly available and have been established for some time, both to ensure that they can be used and vetted in the future, and also, to add confidence to the methodology itself. We present our solution to addressing these challenges, and using multiple measures, demonstrate the significant discrepancy between the prevalence of female characters and male characters in pre-modern literature. The evidence suggests that the discrepancy declines when the author is female. The discrepancy seems to be relatively stable as we plot data over the decades in this century-long period. Finally, we aim to carefully describe both the limitations and ethical caveats associated with this study, and others like it. ",
    "url": "https://arxiv.org/abs/2204.05872",
    "authors": [
      "Akarsh Nagaraj",
      "Mayank Kejriwal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2204.05885",
    "title": "A Hierarchical Block Distance Model for Ultra Low-Dimensional Graph  Representations",
    "abstract": "Graph Representation Learning (GRL) has become central for characterizing structures of complex networks and performing tasks such as link prediction, node classification, network reconstruction, and community detection. Whereas numerous generative GRL models have been proposed, many approaches have prohibitive computational requirements hampering large-scale network analysis, fewer are able to explicitly account for structure emerging at multiple scales, and only a few explicitly respect important network properties such as homophily and transitivity. This paper proposes a novel scalable graph representation learning method named the Hierarchical Block Distance Model (HBDM). The HBDM imposes a multiscale block structure akin to stochastic block modeling (SBM) and accounts for homophily and transitivity by accurately approximating the latent distance model (LDM) throughout the inferred hierarchy. The HBDM naturally accommodates unipartite, directed, and bipartite networks whereas the hierarchy is designed to ensure linearithmic time and space complexity enabling the analysis of very large-scale networks. We evaluate the performance of the HBDM on massive networks consisting of millions of nodes. Importantly, we find that the proposed HBDM framework significantly outperforms recent scalable approaches in all considered downstream tasks. Surprisingly, we observe superior performance even imposing ultra-low two-dimensional embeddings facilitating accurate direct and hierarchical-aware network visualization and interpretation. ",
    "url": "https://arxiv.org/abs/2204.05885",
    "authors": [
      "Nikolaos Nakis",
      "Abdulkadir \u00c7elikkanat",
      "Sune Lehmann J\u00f8rgensen",
      "Morten M\u00f8rup"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05892",
    "title": "NARX Identification using Derivative-Based Regularized Neural Networks",
    "abstract": "This work presents a novel regularization method for the identification of Nonlinear Autoregressive eXogenous (NARX) models. The regularization method promotes the exponential decay of the influence of past input samples on the current model output. This is done by penalizing the sensitivity (i.e. partial derivative) of the NARX model simulated output with respect to the past inputs. The effectiveness of the approach is demonstrated through a simulation example, where a neural network NARX model is identified with this novel method. Moreover, it is shown that the proposed regularization approach improves the model accuracy in terms of simulation error performance compared to that of other regularization methods and model classes. ",
    "url": "https://arxiv.org/abs/2204.05892",
    "authors": [
      "L.H. Peeters",
      "G.I. Beintema",
      "M. Forgione",
      "M. Schoukens"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05902",
    "title": "Scratch as Social Network: Topic Modeling and Sentiment Analysis in  Scratch Projects",
    "abstract": "Societal matters like the Black Lives Matter (BLM) movement influence software engineering, as the recent debate on replacing certain discriminatory terms such as whitelist/blacklist has shown. Identifying relevant and trending societal matters is important, and often done using social network analysis for traditional social media channels such as twitter. In this paper we explore whether this type of analysis can also be used for introspection of the software world, by looking at the thriving scene of young Scratch programmers. The educational programming language Scratch is not only used for teaching programming concepts, but offers a platform for young programmers to express and share their creativity on any topics of relevance. By analyzing titles and project comments in a dataset of 106.032 Scratch projects, we explore which topics are common in the Scratch community, whether socially relevant events are reflected and how how the sentiment in the comments is. It turns out that the diversity of topics within the Scratch projects make the analysis process challenging. Our results nevertheless show that topics from pop and net culture in particular are present, and even recent societal events such as the Covid-19 pandemic or BLM are to some extent reflected in Scratch. The tone in the comments is mostly positive with catchy youth language. Hence, despite the challenges, Scratch projects can be studied in the same way as social networks, which opens up new possibilities to improve our understanding of the behavior and motivation of novice programmers. ",
    "url": "https://arxiv.org/abs/2204.05902",
    "authors": [
      "Isabella Gra\u00dfl",
      "Gordon Fraser"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.05905",
    "title": "Few-shot Forgery Detection via Guided Adversarial Interpolation",
    "abstract": "Realistic visual media synthesis is becoming a critical societal issue with the surge of face manipulation models; new forgery approaches emerge at an unprecedented pace. Unfortunately, existing forgery detection methods suffer significant performance drops when applied to novel forgery approaches. In this work, we address the few-shot forgery detection problem by designing a comprehensive benchmark based on coverage analysis among various forgery approaches, and proposing Guided Adversarial Interpolation (GAI). Our key insight is that there exist transferable distribution characteristics among different forgery approaches with the majority and minority classes. Specifically, we enhance the discriminative ability against novel forgery approaches via adversarially interpolating the artifacts of the minority samples to the majority samples under the guidance of a teacher network. Unlike the standard re-balancing method which usually results in over-fitting to minority classes, our method simultaneously takes account of the diversity of majority information as well as the significance of minority information. Extensive experiments demonstrate that our GAI achieves state-of-the-art performances on the established few-shot forgery detection benchmark. Notably, our method is also validated to be robust to choices of majority and minority forgery approaches. ",
    "url": "https://arxiv.org/abs/2204.05905",
    "authors": [
      "Haonan Qiu",
      "Siyu Chen",
      "Bei Gan",
      "Kun Wang",
      "Huafeng Shi",
      "Jing Shao",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05909",
    "title": "Learning Performance Graphs from Demonstrations via Task-Based  Evaluations",
    "abstract": "In the learning from demonstration (LfD) paradigm, understanding and evaluating the demonstrated behaviors plays a critical role in extracting control policies for robots. Without this knowledge, a robot may infer incorrect reward functions that lead to undesirable or unsafe control policies. Recent work has proposed an LfD framework where a user provides a set of formal task specifications to guide LfD, to address the challenge of reward shaping. However, in this framework, specifications are manually ordered in a performance graph (a partial order that specifies relative importance between the specifications). The main contribution of this paper is an algorithm to learn the performance graph directly from the user-provided demonstrations, and show that the reward functions generated using the learned performance graph generate similar policies to those from manually specified performance graphs. We perform a user study that shows that priorities specified by users on behaviors in a simulated highway driving domain match the automatically inferred performance graph. This establishes that we can accurately evaluate user demonstrations with respect to task specifications without expert criteria. ",
    "url": "https://arxiv.org/abs/2204.05909",
    "authors": [
      "Aniruddh G. Puranic",
      "Jyotirmoy V. Deshmukh",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05916",
    "title": "How to design a network architecture using capacity planning",
    "abstract": "Building a network architecture must answer to organization needs, but also to two major elements which are the need for dependability and performance. By performance, we must understand the ability to meet an immediate need and the ability to scale without reducing the performance of the whole as new elements are added to the network infrastructure. This last point is covered by Capacity Planning domain. ",
    "url": "https://arxiv.org/abs/2204.05916",
    "authors": [
      "Gilbert Moisio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.05939",
    "title": "Mining Logical Event Schemas From Pre-Trained Language Models",
    "abstract": "We present NESL (the Neuro-Episodic Schema Learner), an event schema learning system that combines large language models, FrameNet parsing, a powerful logical representation of language, and a set of simple behavioral schemas meant to bootstrap the learning process. In lieu of a pre-made corpus of stories, our dataset is a continuous feed of \"situation samples\" from a pre-trained language model, which are then parsed into FrameNet frames, mapped into simple behavioral schemas, and combined and generalized into complex, hierarchical schemas for a variety of everyday scenarios. We show that careful sampling from the language model can help emphasize stereotypical properties of situations and de-emphasize irrelevant details, and that the resulting schemas specify situations more comprehensively than those learned by other systems. ",
    "url": "https://arxiv.org/abs/2204.05939",
    "authors": [
      "Lane Lawley",
      "Lenhart Schubert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05941",
    "title": "Arch-Graph: Acyclic Architecture Relation Predictor for  Task-Transferable Neural Architecture Search",
    "abstract": "Neural Architecture Search (NAS) aims to find efficient models for multiple tasks. Beyond seeking solutions for a single task, there are surging interests in transferring network design knowledge across multiple tasks. In this line of research, effectively modeling task correlations is vital yet highly neglected. Therefore, we propose \\textbf{Arch-Graph}, a transferable NAS method that predicts task-specific optimal architectures with respect to given task embeddings. It leverages correlations across multiple tasks by using their embeddings as a part of the predictor's input for fast adaptation. We also formulate NAS as an architecture relation graph prediction problem, with the relational graph constructed by treating candidate architectures as nodes and their pairwise relations as edges. To enforce some basic properties such as acyclicity in the relational graph, we add additional constraints to the optimization process, converting NAS into the problem of finding a Maximal Weighted Acyclic Subgraph (MWAS). Our algorithm then strives to eliminate cycles and only establish edges in the graph if the rank results can be trusted. Through MWAS, Arch-Graph can effectively rank candidate models for each task with only a small budget to finetune the predictor. With extensive experiments on TransNAS-Bench-101, we show Arch-Graph's transferability and high sample efficiency across numerous tasks, beating many NAS methods designed for both single-task and multi-task search. It is able to find top 0.16\\% and 0.29\\% architectures on average on two search spaces under the budget of only 50 models. ",
    "url": "https://arxiv.org/abs/2204.05941",
    "authors": [
      "Minbin Huang",
      "Zhijian Huang",
      "Changlin Li",
      "Xin Chen",
      "Hang Xu",
      "Zhenguo Li",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05953",
    "title": "Explore More Guidance: A Task-aware Instruction Network for Sign  Language Translation Enhanced with Data Augmentation",
    "abstract": "Sign language recognition and translation first uses a recognition module to generate glosses from sign language videos and then employs a translation module to translate glosses into spoken sentences. Most existing works focus on the recognition step, while paying less attention to sign language translation. In this work, we propose a task-aware instruction network, namely TIN-SLT, for sign language translation, by introducing the instruction module and the learning-based feature fuse strategy into a Transformer network. In this way, the pre-trained model's language ability can be well explored and utilized to further boost the translation performance. Moreover, by exploring the representation space of sign language glosses and target spoken language, we propose a multi-level data augmentation scheme to adjust the data distribution of the training set. We conduct extensive experiments on two challenging benchmark datasets, PHOENIX-2014-T and ASLG-PC12, on which our method outperforms former best solutions by 1.65 and 1.42 in terms of BLEU-4. Our code is published at https://github.com/yongcaoplus/TIN-SLT. ",
    "url": "https://arxiv.org/abs/2204.05953",
    "authors": [
      "Yong Cao",
      "Wei Li",
      "Xianzhi Li",
      "Min Chen",
      "Guangyong Chen",
      "Long Hu",
      "Zhengdao Li",
      "Hwang Kai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.05957",
    "title": "Localization Distillation for Object Detection",
    "abstract": "Previous knowledge distillation (KD) methods for object detection mostly focus on feature imitation instead of mimicking the classification logits due to its inefficiency in distilling the localization information. In this paper, we investigate whether logit mimicking always lags behind feature imitation. Towards this goal, we first present a novel localization distillation (LD) method which can efficiently transfer the localization knowledge from the teacher to the student. Second, we introduce the concept of valuable localization region that can aid to selectively distill the classification and localization knowledge for a certain region. Combining these two new components, for the first time, we show that logit mimicking can outperform feature imitation and the absence of localization distillation is a critical reason for why logit mimicking underperforms for years. The thorough studies exhibit the great potential of logit mimicking that can significantly alleviate the localization ambiguity, learn robust feature representation, and ease the training difficulty in the early stage. We also provide the theoretical connection between the proposed LD and the classification KD, that they share the equivalent optimization effect. Our distillation scheme is simple as well as effective and can be easily applied to both dense horizontal object detectors and rotated object detectors. Extensive experiments on the MS COCO, PASCAL VOC, and DOTA benchmarks demonstrate that our method can achieve considerable AP improvement without any sacrifice on the inference speed. Our source code and pretrained models are publicly available at https://github.com/HikariTJU/LD. ",
    "url": "https://arxiv.org/abs/2204.05957",
    "authors": [
      "Zhaohui Zheng",
      "Rongguang Ye",
      "Qibin Hou",
      "Dongwei Ren",
      "Ping Wang",
      "Wangmeng Zuo",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05963",
    "title": "Safety in Augmented Importance Sampling: Performance Bounds for Robust  MPPI",
    "abstract": "This work explores the nature of augmented importance sampling in safety-constrained model predictive control problems. When operating in a constrained environment, sampling based model predictive control and motion planning typically utilizes penalty functions or expensive optimization based control barrier algorithms to maintain feasibility of forward sampling. In contrast the presented algorithm utilizes discrete embedded barrier states in augmented importance sampling to apply feedback with respect to a nominal state when sampling. We will demonstrate that this approach of safety of discrete embedded barrier states in augmented importance sampling is more sample efficient by metric of collision free trajectories, is computationally feasible to perform per sample, and results in better safety performance on a cluttered navigation task with extreme un-modeled disturbances. In addition, we will utilize the theoretical properties of augmented importance sampling and safety control to derive a new bound on the free energy of the system. ",
    "url": "https://arxiv.org/abs/2204.05963",
    "authors": [
      "Manan Gandhi",
      "Hassan Almubarak",
      "Yuichiro Aoyama",
      "Evangelos Theodorou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.05994",
    "title": "Malceiver: Perceiver with Hierarchical and Multi-modal Features for  Android Malware Detection",
    "abstract": "We propose the Malceiver, a hierarchical Perceiver model for Android malware detection that makes use of multi-modal features. The primary inputs are the opcode sequence and the requested permissions of a given Android APK file. To reach a malware classification decision the model combines hierarchical features extracted from the opcode sequence together with the requested permissions. The model's architecture is based on the Perceiver/PerceiverIO which allows for very long opcode sequences to be processed efficiently. Our proposed model can be easily extended to use multi-modal features. We show experimentally that this model outperforms a conventional CNN architecture for opcode sequence based malware detection. We then show that using additional modalities improves performance. Our proposed architecture opens new avenues for the use of Transformer-style networks in malware research. ",
    "url": "https://arxiv.org/abs/2204.05994",
    "authors": [
      "Niall McLaughlin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05400",
    "title": "Transfer Learning for Autonomous Chatter Detection in Machining",
    "abstract": "Large-amplitude chatter vibrations are one of the most important phenomena in machining processes. It is often detrimental in cutting operations causing a poor surface finish and decreased tool life. Therefore, chatter detection using machine learning has been an active research area over the last decade. Three challenges can be identified in applying machine learning for chatter detection at large in industry: an insufficient understanding of the universality of chatter features across different processes, the need for automating feature extraction, and the existence of limited data for each specific workpiece-machine tool combination. These three challenges can be grouped under the umbrella of transfer learning. This paper studies automating chatter detection by evaluating transfer learning of prominent as well as novel chatter detection methods. We investigate chatter classification accuracy using a variety of features extracted from turning and milling experiments with different cutting configurations. The studied methods include Fast Fourier Transform (FFT), Power Spectral Density (PSD), the Auto-correlation Function (ACF), Wavelet Packet Transform (WPT), and Ensemble Empirical Mode Decomposition (EEMD). We also examine more recent approaches based on Topological Data Analysis (TDA) and similarity measures of time series based on Discrete Time Warping (DTW). We evaluate the transfer learning potential of each approach by training and testing both within and across the turning and milling data sets. Our results show that carefully chosen time-frequency features can lead to high classification accuracies albeit at the cost of requiring manual pre-processing and the tagging of an expert user. On the other hand, we found that the TDA and DTW approaches can provide accuracies and F1 scores on par with the time-frequency methods without the need for manual preprocessing. ",
    "url": "https://arxiv.org/abs/2204.05400",
    "authors": [
      "Melih C. Yesilli",
      "Firas A. Khasawneh",
      "Brian Mann"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05419",
    "title": "Can Self-Supervised Learning solve the problem of child speech  recognition?",
    "abstract": "Despite recent advancements in deep learning technologies, Child Speech Recognition remains a challenging task. Current Automatic Speech Recognition (ASR) models required substantial amounts of annotated data for training, which is scarce. In this work, we explore using the ASR model, wav2vec2, with different pretraining and finetuning configurations for self supervised learning (SSL) towards improving automatic child speech recognition. The pretrained wav2vec2 models were finetuned using different amounts of child speech training data to discover the optimum amount of data required to finetune the model for the task of child ASR. Our trained model receives the best word error rate (WER) of 8.37 on the in domain MyST dataset and WER of 10.38 on the out of domain PFSTAR dataset. We do not use any Language Models (LM) in our experiments. ",
    "url": "https://arxiv.org/abs/2204.05419",
    "authors": [
      "Rishabh Jain",
      "Mariam Yiwere",
      "Dan Bigioi",
      "Peter Corcoran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.05440",
    "title": "Lost Vibration Test Data Recovery Using Convolutional Neural Network: A  Case Study",
    "abstract": "Data loss in Structural Health Monitoring (SHM) networks has recently become one of the main challenges for engineers. Therefore, a data recovery method for SHM, generally an expensive procedure, is essential. Lately, some techniques offered to recover this valuable raw data using Neural Network (NN) algorithms. Among them, the convolutional neural network (CNN) based on convolution, a mathematical operation, can be applied to non-image datasets such as signals to extract important features without human supervision. However, the effect of different parameters has not been studied and optimized for SHM applications. Therefore, this paper aims to propose different architectures and investigate the effects of different hyperparameters for one of the newest proposed methods, which is based on a CNN algorithm for the Alamosa Canyon Bridge as a real structure. For this purpose, three different CNN models were considered to predict one and two malfunctioned sensors by finding the correlation between other sensors, respectively. Then the CNN algorithm was trained by experimental data, and the results showed that the method had a reliable performance in predicting Alamosa Canyon Bridge's missed data. The accuracy of the model was increased by adding a convolutional layer. Also, a standard neural network with two hidden layers was trained with the same inputs and outputs of the CNN models. Based on the results, the CNN model had higher accuracy, lower computational cost, and was faster than the standard neural network. ",
    "url": "https://arxiv.org/abs/2204.05440",
    "authors": [
      "Pouya Moeinifard",
      "Mohammad Sadra Rajabi",
      "Maryam Bitaraf"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.05573",
    "title": "Convolutional recurrent autoencoder network for learning underwater  ocean acoustics",
    "abstract": "Underwater ocean acoustics is a complex physical phenomenon involving not only widely varying physical parameters and dynamical scales but also uncertainties in the ocean parameters. Thus, it is difficult to construct generalized physical models which can work in a broad range of situations. In this regard, we propose a convolutional recurrent autoencoder network (CRAN) architecture, which is a data-driven deep learning model for acoustic propagation. Being data-driven it is independent of how the data is obtained and can be employed for learning various ocean acoustic phenomena. The CRAN model can learn a reduced-dimensional representation of physical data and can predict the system evolution efficiently. Two cases of increasing complexity are considered to demonstrate the generalization ability of the CRAN. The first case is a one-dimensional wave propagation with spatially-varying discontinuous initial conditions. The second case corresponds to a far-field transmission loss distribution in a two-dimensional ocean domain with depth-dependent sources. For both cases, the CRAN can learn the essential elements of wave propagation physics such as characteristic patterns while predicting long-time system evolution with satisfactory accuracy. Such ability of the CRAN to learn complex ocean acoustics phenomena has the potential of real-time prediction for marine vessel decision-making and online control. ",
    "url": "https://arxiv.org/abs/2204.05573",
    "authors": [
      "Wrik Mallik",
      "Rajeev K. Jaiman",
      "Jasmin Jelovica"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.05753",
    "title": "Enhancement of Pitch Controllability using Timbre-Preserving Pitch  Augmentation in FastPitch",
    "abstract": "The recently developed pitch-controllable text-to-speech (TTS) model, i.e. FastPitch, was conditioned for the pitch contours. However, the quality of the synthesized speech degraded considerably for pitch values that deviated significantly from the average pitch; i.e. the ability to control pitch was limited. To address this issue, we propose two algorithms to improve the robustness of FastPitch. First, we propose a novel timbre-preserving pitch-shifting algorithm for natural pitch augmentation. Pitch-shifted speech samples sound more natural when using the proposed algorithm because the speaker's vocal timbre is maintained. Moreover, we propose a training algorithm that defines FastPitch using pitch-augmented speech datasets with different pitch ranges for the same sentence. The experimental results demonstrate that the proposed algorithms improve the pitch controllability of FastPitch. ",
    "url": "https://arxiv.org/abs/2204.05753",
    "authors": [
      "Hanbin Bae",
      "Young-Sun Joo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.05778",
    "title": "Unsupervised Anomaly Detection in 3D Brain MRI using Deep Learning with  impured training data",
    "abstract": "The detection of lesions in magnetic resonance imaging (MRI)-scans of human brains remains challenging, time-consuming and error-prone. Recently, unsupervised anomaly detection (UAD) methods have shown promising results for this task. These methods rely on training data sets that solely contain healthy samples. Compared to supervised approaches, this significantly reduces the need for an extensive amount of labeled training data. However, data labelling remains error-prone. We study how unhealthy samples within the training data affect anomaly detection performance for brain MRI-scans. For our evaluations, we consider three publicly available data sets and use autoencoders (AE) as a well-established baseline method for UAD. We systematically evaluate the effect of impured training data by injecting different quantities of unhealthy samples to our training set of healthy samples from T1-weighted MRI-scans. We evaluate a method to identify falsely labeled samples directly during training based on the reconstruction error of the AE. Our results show that training with impured data decreases the UAD performance notably even with few falsely labeled samples. By performing outlier removal directly during training based on the reconstruction-loss, we demonstrate that falsely labeled data can be detected and removed to mitigate the effect of falsely labeled data. Overall, we highlight the importance of clean data sets for UAD in brain MRI and demonstrate an approach for detecting falsely labeled data directly during training. ",
    "url": "https://arxiv.org/abs/2204.05778",
    "authors": [
      "Finn Behrendt",
      "Marcel Bengs",
      "Frederik Rogge",
      "Julia Kr\u00fcger",
      "Roland Opfer",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05781",
    "title": "Cryptocurrency Return Prediction Using Investor Sentiment Extracted by  BERT-Based Classifiers from News Articles, Reddit Posts and Tweets",
    "abstract": "This paper studies the extent at which investor sentiment contributes to cryptocurrency return prediction. Investor sentiment is extracted from news articles, Reddit posts and Tweets using BERT-based classifiers fine-tuned on this specific text data. As this data is unlabeled, a weak supervision approach by pseudo-labeling using a zero-shot classifier is used. Contribution of sentiment is then examined using a variety of machine learning models. Each model is trained on data with and without sentiment separately. The conclusion is that sentiment leads to higher prediction accuracy and additional investment profit when the models are analyzed collectively, although this does not hold true for every single model. ",
    "url": "https://arxiv.org/abs/2204.05781",
    "authors": [
      "Duygu Ider"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05783",
    "title": "Stock Price Prediction using Sentiment Analysis and Deep Learning for  Indian Markets",
    "abstract": "Stock market prediction has been an active area of research for a considerable period. Arrival of computing, followed by Machine Learning has upgraded the speed of research as well as opened new avenues. As part of this research study, we aimed to predict the future stock movement of shares using the historical prices aided with availability of sentiment data. Two models were used as part of the exercise, LSTM was the first model with historical prices as the independent variable. Sentiment Analysis captured using Intensity Analyzer was used as the major parameter for Random Forest Model used for the second part, some macro parameters like Gold, Oil prices, USD exchange rate and Indian Govt. Securities yields were also added to the model for improved accuracy of the model. As the end product, prices of 4 stocks viz. Reliance, HDFC Bank, TCS and SBI were predicted using the aforementioned two models. The results were evaluated using RMSE metric. ",
    "url": "https://arxiv.org/abs/2204.05783",
    "authors": [
      "Narayana Darapaneni",
      "Anwesh Reddy Paduri",
      "Himank Sharma",
      "Milind Manjrekar",
      "Nutan Hindlekar",
      "Pranali Bhagat",
      "Usha Aiyer",
      "Yogesh Agarwal"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05791",
    "title": "Square coloring planar graphs with automatic discharging",
    "abstract": "The discharging method is a powerful proof technique, especially for graph coloring problems. Its major downside is that it often requires lengthy case analyses, which are sometimes given to a computer for verification. However, it is much less common to use a computer to actively look for a discharging proof. In this paper, we use a Linear Programming approach to automatically look for a discharging proof. While our system is not entirely autonomous, we manage to make some progress towards Wegner's conjecture for distance-$2$ coloring of planar graphs, by showing that $12$ colors are sufficient to color at distance $2$ every planar graph with maximum degree $4$. ",
    "url": "https://arxiv.org/abs/2204.05791",
    "authors": [
      "Nicolas Bousquet",
      "Lucas de Meyer",
      "Quentin Deschamps",
      "Th\u00e9o Pierron"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.05917",
    "title": "Spatiotemporal Estimation of TROPOMI NO2 Column with Depthwise Partial  Convolutional Neural Network",
    "abstract": "Satellite-derived measurements are negatively impacted by cloud cover and surface reflectivity. These biases must be discarded and significantly increase the amount of missing data within remote sensing images. This paper expands the application of a partial convolutional neural network (PCNN) to incorporate depthwise convolution layers, conferring temporal dimensionality to the imputation process. The addition of a temporal dimension to the imputation process adds a state of successive existence within the dataset which spatial imputation cannot capture. The depthwise convolution process enables the PCNN to independently convolve the data for each channel. The deep learning system is trained with the Community Multiscale Air Quality model-simulated tropospheric column density of Nitrogen Dioxide (TCDNO2) to impute TROPOspheric Monitoring Instrument TCDNO2. The depthwise PCNN model achieves an index of agreement of 0.82 and outperforms the default PCNN models, with and without temporal dimensionality of data, and conventional data imputation methods such as inverse distance weighting by 3-11% and 8-15% in the index of agreement and correlation, respectively. The model demonstrates more consistency in the reconstruction of TROPOspheric Monitoring Instrument tropospheric column density of NO2 images. The model has also demonstrated the accurate imputation of remote sensing images with over 95% of the data missing. PCNN enables the accurate imputation of remote sensing data with large regions of missing data and will benefit future researchers conducting data assimilation for numerical models, emission studies, and human health impact analyses from air pollution. ",
    "url": "https://arxiv.org/abs/2204.05917",
    "authors": [
      "Yannic Lops",
      "Masoud Ghahremanloo",
      "Arman Pouyaei",
      "Yunsoo Choi",
      "Jia Jung",
      "Seyedali Mousavinezhad",
      "Ahmed Khan Salman",
      "Davyda Hammond"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1907.04108",
    "title": "Scaling Limit of Neural Networks with the Xavier Initialization and  Convergence to a Global Minimum",
    "abstract": " Comments: The results of this technical note have been extended and generalized in arXiv:1911.07304. In the present note the full details for the proof of the special case studied here are presented ",
    "url": "https://arxiv.org/abs/1907.04108",
    "authors": [
      "Justin Sirignano",
      "Konstantinos Spiliopoulos"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.11713",
    "title": "Online Structural Change-point Detection of High-dimensional Streaming  Data via Dynamic Sparse Subspace Learning",
    "abstract": " Title: Online Structural Change-point Detection of High-dimensional Streaming  Data via Dynamic Sparse Subspace Learning ",
    "url": "https://arxiv.org/abs/2009.11713",
    "authors": [
      "Ruiyu Xu",
      "Jianguo Wu",
      "Xiaowei Yue",
      "Yongxiang Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.04188",
    "title": "Learning to Represent Programs with Heterogeneous Graphs",
    "abstract": " Comments: Accepted by ICPC 2022 ",
    "url": "https://arxiv.org/abs/2012.04188",
    "authors": [
      "Kechi Zhang",
      "Wenhan Wang",
      "Huangzhao Zhang",
      "Ge Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2012.10289",
    "title": "HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection",
    "abstract": " Comments: 12 pages, 7 figues, 8 tables. Accepted at AAAI 2021 ",
    "url": "https://arxiv.org/abs/2012.10289",
    "authors": [
      "Binny Mathew",
      "Punyajoy Saha",
      "Seid Muhie Yimam",
      "Chris Biemann",
      "Pawan Goyal",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2102.03586",
    "title": "CMS-LSTM: Context Embedding and Multi-Scale Spatiotemporal Expression  LSTM for Predictive Learning",
    "abstract": " Comments: Accept at ICME2022 ",
    "url": "https://arxiv.org/abs/2102.03586",
    "authors": [
      "Zenghao Chai",
      "Zhengzhuo Xu",
      "Yunpeng Bai",
      "Zhihui Lin",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.09722",
    "title": "Staircase Sign Method for Boosting Adversarial Attacks",
    "abstract": " Title: Staircase Sign Method for Boosting Adversarial Attacks ",
    "url": "https://arxiv.org/abs/2104.09722",
    "authors": [
      "Qilong Zhang",
      "Xiaosu Zhu",
      "Jingkuan Song",
      "Lianli Gao",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.04301",
    "title": "ADASYN-Random Forest Based Intrusion Detection Model",
    "abstract": " Comments: Accepted by SPML 2021 and hereby declared that the research of this paper has nothing to do with Linyue Zhou, so we deleted her name ",
    "url": "https://arxiv.org/abs/2105.04301",
    "authors": [
      "Zhewei Chen",
      "Wenwen Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.07224",
    "title": "Estimating Heterogeneous Causal Effect of Polysubstance Usage on Drug  Overdose from Large-Scale Electronic Health Record",
    "abstract": " Comments: Accepted in 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (IEEE EMBC). arXiv admin note: text overlap with arXiv:2010.14774, arXiv:1905.03297 by other authors ",
    "url": "https://arxiv.org/abs/2105.07224",
    "authors": [
      "Vaishali Mahipal",
      "Mohammad Arif Ul Alam"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.08543",
    "title": "Tackling the Challenges in Scene Graph Generation with Local-to-Global  Interactions",
    "abstract": " Comments: IEEE Transactions on Neural Networks and Learning Systems (TNNLS) ",
    "url": "https://arxiv.org/abs/2106.08543",
    "authors": [
      "Sangmin Woo",
      "Junhyug Noh",
      "Kangil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.03821",
    "title": "Edge Sampling and Graph Parameter Estimation via Vertex Neighborhood  Accesses",
    "abstract": " Comments: Extended abstract of this paper to appear at STOC 2022. This paper subsumes the arXiv report (arXiv:2009.11178) ",
    "url": "https://arxiv.org/abs/2107.03821",
    "authors": [
      "Jakub T\u011btek",
      "Mikkel Thorup"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2107.09539",
    "title": "Parametric Scattering Networks",
    "abstract": " Title: Parametric Scattering Networks ",
    "url": "https://arxiv.org/abs/2107.09539",
    "authors": [
      "Shanel Gauthier",
      "Benjamin Th\u00e9rien",
      "Laurent Als\u00e8ne-Racicot",
      "Muawiz Chaudhary",
      "Irina Rish",
      "Eugene Belilovsky",
      "Michael Eickenberg",
      "Guy Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2108.01941",
    "title": "Automatic cerebral hemisphere segmentation in rat MRI with lesions via  attention-based convolutional neural networks",
    "abstract": " Title: Automatic cerebral hemisphere segmentation in rat MRI with lesions via  attention-based convolutional neural networks ",
    "url": "https://arxiv.org/abs/2108.01941",
    "authors": [
      "Juan Miguel Valverde",
      "Artem Shatillo",
      "Riccardo de Feo",
      "Jussi Tohka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.09375",
    "title": "Cascade Watchdog: A Multi-tiered Adversarial Guard for Outlier Detection",
    "abstract": " Title: Cascade Watchdog: A Multi-tiered Adversarial Guard for Outlier Detection ",
    "url": "https://arxiv.org/abs/2108.09375",
    "authors": [
      "Glauco Amigo",
      "Justin M. Bui",
      "Robert J. Marks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.13584",
    "title": "From Less to More: Spectral Splitting and Aggregation Network for  Hyperspectral Face Super-Resolution",
    "abstract": " Comments: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) ",
    "url": "https://arxiv.org/abs/2108.13584",
    "authors": [
      "Junjun Jiang",
      "Chenyang Wang",
      "Xianming Liu",
      "Kui Jiang",
      "Jiayi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.03777",
    "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning  the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
    "abstract": " Comments: accepted to appear at the ACL 2022 Main conference, see also: arXiv:2204.03954 for an extension with multi-label classification ",
    "url": "https://arxiv.org/abs/2109.03777",
    "authors": [
      "Lukas Galke",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.06270",
    "title": "STraTA: Self-Training with Task Augmentation for Better Few-shot  Learning",
    "abstract": " Comments: Accepted as a main conference paper at EMNLP 2021, 17 pages, 3 figures, 11 tables ",
    "url": "https://arxiv.org/abs/2109.06270",
    "authors": [
      "Tu Vu",
      "Minh-Thang Luong",
      "Quoc V. Le",
      "Grady Simon",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.12061",
    "title": "Computing the Barnes $G$-function and the gamma function in the entire  complex plane",
    "abstract": " Title: Computing the Barnes $G$-function and the gamma function in the entire  complex plane ",
    "url": "https://arxiv.org/abs/2109.12061",
    "authors": [
      "Alexey Kuznetsov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.13748",
    "title": "Improving Autoencoder Training Performance for Hyperspectral Unmixing  with Network Reinitialisation",
    "abstract": " Title: Improving Autoencoder Training Performance for Hyperspectral Unmixing  with Network Reinitialisation ",
    "url": "https://arxiv.org/abs/2109.13748",
    "authors": [
      "Kamil Ksi\u0105\u017cek",
      "Przemys\u0142aw G\u0142omb",
      "Micha\u0142 Romaszewski",
      "Micha\u0142 Cholewa",
      "Bartosz Grabowski",
      "Kriszti\u00e1n B\u00faza"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.14768",
    "title": "Distributed Asynchronous Games With Causal Memory are Undecidable",
    "abstract": " Title: Distributed Asynchronous Games With Causal Memory are Undecidable ",
    "url": "https://arxiv.org/abs/2110.14768",
    "authors": [
      "Hugo Gimbert"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.01821",
    "title": "Catch Me If You Can: Blackbox Adversarial Attacks on Automatic Speech  Recognition using Frequency Masking",
    "abstract": " Comments: 11 pages, 7 figures and 3 tables ",
    "url": "https://arxiv.org/abs/2112.01821",
    "authors": [
      "Xiaoliang Wu",
      "Ajitha Rajan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2112.02500",
    "title": "Global-Local Context Network for Person Search",
    "abstract": " Title: Global-Local Context Network for Person Search ",
    "url": "https://arxiv.org/abs/2112.02500",
    "authors": [
      "Peng Zheng",
      "Jie Qin",
      "Yichao Yan",
      "Bingbing Ni",
      "Xiaogang Cheng",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03570",
    "title": "Membership Inference Attacks From First Principles",
    "abstract": " Title: Membership Inference Attacks From First Principles ",
    "url": "https://arxiv.org/abs/2112.03570",
    "authors": [
      "Nicholas Carlini",
      "Steve Chien",
      "Milad Nasr",
      "Shuang Song",
      "Andreas Terzis",
      "Florian Tramer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04632",
    "title": "Recurrent Glimpse-based Decoder for Detection with Transformer",
    "abstract": " Title: Recurrent Glimpse-based Decoder for Detection with Transformer ",
    "url": "https://arxiv.org/abs/2112.04632",
    "authors": [
      "Zhe Chen",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.06054",
    "title": "Deterministic and Discriminative Imitation (D2-Imitation): Revisiting  Adversarial Imitation for Sample Efficiency",
    "abstract": " Comments: AAAI 2022 ",
    "url": "https://arxiv.org/abs/2112.06054",
    "authors": [
      "Mingfei Sun",
      "Sam Devlin",
      "Katja Hofmann",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.08655",
    "title": "Feature Distillation Interaction Weighting Network for Lightweight Image  Super-Resolution",
    "abstract": " Comments: 9 pages, 9 figures, 4 tables, AAAI2022 ",
    "url": "https://arxiv.org/abs/2112.08655",
    "authors": [
      "Guangwei Gao",
      "Wenjie Li",
      "Juncheng Li",
      "Fei Wu",
      "Huimin Lu",
      "Yi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.13485",
    "title": "An efficient mining scheme for high utility itemsets",
    "abstract": " Comments: Code shall be improved for run-time and memory requirements ",
    "url": "https://arxiv.org/abs/2112.13485",
    "authors": [
      "Pushp",
      "Satish Chand"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2112.13753",
    "title": "MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale  Recommendation Scenarios",
    "abstract": " Title: MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale  Recommendation Scenarios ",
    "url": "https://arxiv.org/abs/2112.13753",
    "authors": [
      "Xiaofeng Pan",
      "Ming Li",
      "Jing Zhang",
      "Keren Yu",
      "Luping Wang",
      "Hong Wen",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.14238",
    "title": "AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video  Recognition",
    "abstract": " Comments: Accepted by CVPR-2022 ",
    "url": "https://arxiv.org/abs/2112.14238",
    "authors": [
      "Yulin Wang",
      "Yang Yue",
      "Yuanze Lin",
      "Haojun Jiang",
      "Zihang Lai",
      "Victor Kulikov",
      "Nikita Orlov",
      "Humphrey Shi",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04056",
    "title": "State Estimation in Electric Power Systems Leveraging Graph Neural  Networks",
    "abstract": " Comments: 6 pages, 6 figures, conference paper ",
    "url": "https://arxiv.org/abs/2201.04056",
    "authors": [
      "Ognjen Kundacina",
      "Mirsad Cosovic",
      "Dejan Vukobratovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.06993",
    "title": "Spiker: an FPGA-optimized Hardware acceleration for Spiking Neural  Networks",
    "abstract": " Comments: 6 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2201.06993",
    "authors": [
      "Alessio Carpegna",
      "Alessandro Savino",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.08281",
    "title": "Symplectic Momentum Neural Networks -- Using Discrete Variational  Mechanics as a prior in Deep Learning",
    "abstract": " Comments: 12 pages, 4 figures. Accepted at 4th Annual Learning for Dynamics & Control Conference ",
    "url": "https://arxiv.org/abs/2201.08281",
    "authors": [
      "Saul Santos",
      "Monica Ekal",
      "Rodrigo Ventura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08294",
    "title": "Statistical prediction of extreme events from small datasets",
    "abstract": " Title: Statistical prediction of extreme events from small datasets ",
    "url": "https://arxiv.org/abs/2201.08294",
    "authors": [
      "Alberto Racca",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2201.09151",
    "title": "An External Stability Audit Framework to Test the Validity of  Personality Prediction in AI Hiring",
    "abstract": " Title: An External Stability Audit Framework to Test the Validity of  Personality Prediction in AI Hiring ",
    "url": "https://arxiv.org/abs/2201.09151",
    "authors": [
      "Alene K. Rhea",
      "Kelsey Markey",
      "Lauren D'Arinzo",
      "Hilke Schellmann",
      "Mona Sloane",
      "Paul Squires",
      "Falaah Arif Kahn",
      "Julia Stoyanovich"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10285",
    "title": "Efficient Approximations of the Fisher Matrix in Neural Networks using  Kronecker Product Singular Value Decomposition",
    "abstract": " Title: Efficient Approximations of the Fisher Matrix in Neural Networks using  Kronecker Product Singular Value Decomposition ",
    "url": "https://arxiv.org/abs/2201.10285",
    "authors": [
      "Abdoulaye Koroko",
      "Ani Anciaux-Sedrakian",
      "Ibtihel Gharbia",
      "Val\u00e9rie Gar\u00e8s",
      "Mounir Haddou",
      "Quang Huy Tran"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03133",
    "title": "Rate Coding or Direct Coding: Which One is Better for Accurate, Robust,  and Energy-efficient Spiking Neural Networks?",
    "abstract": " Comments: Accepted to ICASSP2022 ",
    "url": "https://arxiv.org/abs/2202.03133",
    "authors": [
      "Youngeun Kim",
      "Hyoungseob Park",
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Yeshwanth Venkatesha",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.05447",
    "title": "PSACCF: Prioritized Online Slice Admission Control Considering Fairness  in 5G/B5G Networks",
    "abstract": " Title: PSACCF: Prioritized Online Slice Admission Control Considering Fairness  in 5G/B5G Networks ",
    "url": "https://arxiv.org/abs/2202.05447",
    "authors": [
      "Miao Dai",
      "Long Luo",
      "Jing Ren",
      "Hongfang Yu",
      "Gang Sun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2202.13074",
    "title": "Neuro-Inspired Deep Neural Networks with Sparse, Strong Activations",
    "abstract": " Comments: 5 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2202.13074",
    "authors": [
      "Metehan Cekic",
      "Can Bakiskan",
      "Upamanyu Madhow"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01052",
    "title": "Unsupervised Anomaly Detection from Time-of-Flight Depth Images",
    "abstract": " Title: Unsupervised Anomaly Detection from Time-of-Flight Depth Images ",
    "url": "https://arxiv.org/abs/2203.01052",
    "authors": [
      "Pascal Schneider",
      "Jason Rambach",
      "Bruno Mirbach",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.02378",
    "title": "DiT: Self-supervised Pre-training for Document Image Transformer",
    "abstract": " Comments: Work in Progress ",
    "url": "https://arxiv.org/abs/2203.02378",
    "authors": [
      "Junlong Li",
      "Yiheng Xu",
      "Tengchao Lv",
      "Lei Cui",
      "Cha Zhang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06414",
    "title": "A survey in Adversarial Defences and Robustness in NLP",
    "abstract": " Title: A survey in Adversarial Defences and Robustness in NLP ",
    "url": "https://arxiv.org/abs/2203.06414",
    "authors": [
      "Shreya Goyal",
      "Sumanth Doddapaneni",
      "Mitesh M.Khapra",
      "Balaraman Ravindran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.10496",
    "title": "NeuralReshaper: Single-image Human-body Retouching with Deep Neural  Networks",
    "abstract": " Title: NeuralReshaper: Single-image Human-body Retouching with Deep Neural  Networks ",
    "url": "https://arxiv.org/abs/2203.10496",
    "authors": [
      "Beijia Chen",
      "Hongbo Fu",
      "Xiang Chen",
      "Kun Zhou",
      "Youyi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.11089",
    "title": "PersFormer: 3D Lane Detection via Perspective Transformer and the  OpenLane Benchmark",
    "abstract": " Comments: Update project page: this https URL | OpenLane dataset: this https URL ",
    "url": "https://arxiv.org/abs/2203.11089",
    "authors": [
      "Li Chen",
      "Chonghao Sima",
      "Yang Li",
      "Zehan Zheng",
      "Jiajie Xu",
      "Xiangwei Geng",
      "Hongyang Li",
      "Conghui He",
      "Jianping Shi",
      "Yu Qiao",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11804",
    "title": "Information-Theoretic Approaches to Differential Privacy",
    "abstract": " Title: Information-Theoretic Approaches to Differential Privacy ",
    "url": "https://arxiv.org/abs/2203.11804",
    "authors": [
      "Ayse Unsal",
      "Melek Onen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.13369",
    "title": "Gender and Racial Stereotype Detection in Legal Opinion Word Embeddings",
    "abstract": " Comments: Accepted at AAAI-22, AI for Social Impact Track ",
    "url": "https://arxiv.org/abs/2203.13369",
    "authors": [
      "Sean Matthews",
      "John Hudzina",
      "Dawn Sepehr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.14769",
    "title": "A Long Short-term Memory Based Recurrent Neural Network for  Interventional MRI Reconstruction",
    "abstract": " Title: A Long Short-term Memory Based Recurrent Neural Network for  Interventional MRI Reconstruction ",
    "url": "https://arxiv.org/abs/2203.14769",
    "authors": [
      "Ruiyang Zhao",
      "Zhao He",
      "Tao Wang",
      "Suhao Qiu",
      "Pawel Herman",
      "Yanle Hu",
      "Chencheng Zhang",
      "Dinggang Shen",
      "Bomin Sun",
      "Guang-Zhong Yang",
      "Yuan Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2203.15522",
    "title": "Collision-Free Navigation using Evolutionary Symmetrical Neural Networks",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1609.08414 ",
    "url": "https://arxiv.org/abs/2203.15522",
    "authors": [
      "Hesham M. Eraqi",
      "Mena Nagiub",
      "Peter Sidra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15526",
    "title": "Interactive Audio-text Representation for Automated Audio Captioning  with Contrastive Learning",
    "abstract": " Comments: Submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.15526",
    "authors": [
      "Chen Chen",
      "Nana Hou",
      "Yuchen Hu",
      "Heqing Zou",
      "Xiaofeng Qi",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16027",
    "title": "Clozer: Adaptable Data Augmentation for Cloze-style Reading  Comprehension",
    "abstract": " Title: Clozer: Adaptable Data Augmentation for Cloze-style Reading  Comprehension ",
    "url": "https://arxiv.org/abs/2203.16027",
    "authors": [
      "Holy Lovenia",
      "Bryan Wilie",
      "Willy Chung",
      "Min Zeng",
      "Samuel Cahyawijaya",
      "Su Dan",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.01737",
    "title": "Feature robustness and sex differences in medical imaging: a case study  in MRI-based Alzheimer's disease detection",
    "abstract": " Comments: Submitted to MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2204.01737",
    "authors": [
      "Eike Petersen",
      "Aasa Feragen",
      "Maria Luise da Costa Zemsch",
      "Anders Henriksen",
      "Oskar Eiler Wiese Christensen",
      "Melanie Ganz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02480",
    "title": "Learning Optimal K-space Acquisition and Reconstruction using  Physics-Informed Neural Networks",
    "abstract": " Comments: Accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2204.02480",
    "authors": [
      "Wei Peng",
      "Li Feng",
      "Guoying Zhao",
      "Fang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04149",
    "title": "A Credible and Robust approach to Ego-Motion Estimation using an  Automotive Radar",
    "abstract": " Comments: Withdraw V1, IEEE RAL header Copyrights should be in the first page and have been done on V2 ",
    "url": "https://arxiv.org/abs/2204.04149",
    "authors": [
      "Karim Haggag",
      "Sven Lange",
      "Tim Pfeifer",
      "Peter Protzel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.04218",
    "title": "Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes  for Medical Image Super-Resolution",
    "abstract": " Title: Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes  for Medical Image Super-Resolution ",
    "url": "https://arxiv.org/abs/2204.04218",
    "authors": [
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu",
      "Andreea-Iuliana Miron",
      "Olivian Savencu",
      "Nicolae-Catalin Ristea",
      "Nicolae Verga",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05041",
    "title": "Pyramid Grafting Network for One-Stage High Resolution Saliency  Detection",
    "abstract": " Comments: Camera-Ready, CVPR 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2204.05041",
    "authors": [
      "Chenxi Xie",
      "Changqun Xia",
      "Mingcan Ma",
      "Zhirui Zhao",
      "Xiaowu Chen",
      "Jia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]