[
  {
    "id": "arXiv:2303.11337",
    "title": "Recursive Euclidean Distance Based Robust Aggregation Technique For  Federated Learning",
    "abstract": "Federated learning has gained popularity as a solution to data availability and privacy challenges in machine learning. However, the aggregation process of local model updates to obtain a global model in federated learning is susceptible to malicious attacks, such as backdoor poisoning, label-flipping, and membership inference. Malicious users aim to sabotage the collaborative learning process by training the local model with malicious data. In this paper, we propose a novel robust aggregation approach based on recursive Euclidean distance calculation. Our approach measures the distance of the local models from the previous global model and assigns weights accordingly. Local models far away from the global model are assigned smaller weights to minimize the data poisoning effect during aggregation. Our experiments demonstrate that the proposed algorithm outperforms state-of-the-art algorithms by at least $5\\%$ in accuracy while reducing time complexity by less than $55\\%$. Our contribution is significant as it addresses the critical issue of malicious attacks in federated learning while improving the accuracy of the global model. ",
    "url": "https://arxiv.org/abs/2303.11337",
    "authors": [
      "Charuka Herath",
      "Yogachandran Rahulamathavan",
      "Xiaolan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11339",
    "title": "FedMAE: Federated Self-Supervised Learning with One-Block Masked  Auto-Encoder",
    "abstract": "Latest federated learning (FL) methods started to focus on how to use unlabeled data in clients for training due to users' privacy concerns, high labeling costs, or lack of expertise. However, current Federated Semi-Supervised/Self-Supervised Learning (FSSL) approaches fail to learn large-scale images because of the limited computing resources of local clients. In this paper, we introduce a new framework FedMAE, which stands for Federated Masked AutoEncoder, to address the problem of how to utilize unlabeled large-scale images for FL. Specifically, FedMAE can pre-train one-block Masked AutoEncoder (MAE) using large images in lightweight client devices, and then cascades multiple pre-trained one-block MAEs in the server to build a multi-block ViT backbone for downstream tasks. Theoretical analysis and experimental results on image reconstruction and classification show that our FedMAE achieves superior performance compared to the state-of-the-art FSSL methods. ",
    "url": "https://arxiv.org/abs/2303.11339",
    "authors": [
      "Nan Yang",
      "Xuanyu Chen",
      "Charles Z. Liu",
      "Dong Yuan",
      "Wei Bao",
      "Lizhen Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11340",
    "title": "HDformer: A Higher Dimensional Transformer for Diabetes Detection  Utilizing Long Range Vascular Signals",
    "abstract": "Diabetes mellitus is a worldwide concern, and early detection can help to prevent serious complications. Low-cost, non-invasive detection methods, which take cardiovascular signals into deep learning models, have emerged. However, limited accuracy constrains their clinical usage. In this paper, we present a new Transformer-based architecture, Higher Dimensional Transformer (HDformer), which takes long-range photoplethysmography (PPG) signals to detect diabetes. The long-range PPG contains broader and deeper signal contextual information compared to the less-than-one-minute PPG signals commonly utilized in existing research. To increase the capability and efficiency of processing the long range data, we propose a new attention module Time Square Attention (TSA), reducing the volume of the tokens by more than 10x, while retaining the local/global dependencies. It converts the 1-dimensional inputs into 2-dimensional representations and groups adjacent points into a single 2D token, using the 2D Transformer models as the backbone of the encoder. It generates the dynamic patch sizes into a gated mixture-of-experts (MoE) network as decoder, which optimizes the learning on different attention areas. Extensive experimentations show that HDformer results in the state-of-the-art performance (sensitivity 98.4, accuracy 97.3, specificity 92.8, and AUC 0.929) on the standard MIMIC-III dataset, surpassing existing studies. This work is the first time to take long-range, non-invasive PPG signals via Transformer for diabetes detection, achieving a more scalable and convenient solution compared to traditional invasive approaches. The proposed HDformer can also be scaled to analyze general long-range biomedical waveforms. A wearable prototype finger-ring is designed as a proof of concept. ",
    "url": "https://arxiv.org/abs/2303.11340",
    "authors": [
      "Ella Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.11341",
    "title": "What does it take to catch a Chinchilla? Verifying Rules on Large-Scale  Neural Network Training via Compute Monitoring",
    "abstract": "As advanced machine learning systems' capabilities begin to play a significant role in geopolitics and societal order, it may become imperative that (1) governments be able to enforce rules on the development of advanced ML systems within their borders, and (2) countries be able to verify each other's compliance with potential future international agreements on advanced ML development. This work analyzes one mechanism to achieve this, by monitoring the computing hardware used for large-scale NN training. The framework's primary goal is to provide governments high confidence that no actor uses large quantities of specialized ML chips to execute a training run in violation of agreed rules. At the same time, the system does not curtail the use of consumer computing devices, and maintains the privacy and confidentiality of ML practitioners' models, data, and hyperparameters. The system consists of interventions at three stages: (1) using on-chip firmware to occasionally save snapshots of the the neural network weights stored in device memory, in a form that an inspector could later retrieve; (2) saving sufficient information about each training run to prove to inspectors the details of the training run that had resulted in the snapshotted weights; and (3) monitoring the chip supply chain to ensure that no actor can avoid discovery by amassing a large quantity of un-tracked chips. The proposed design decomposes the ML training rule verification problem into a series of narrow technical challenges, including a new variant of the Proof-of-Learning problem [Jia et al. '21]. ",
    "url": "https://arxiv.org/abs/2303.11341",
    "authors": [
      "Yonadav Shavit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11364",
    "title": "DehazeNeRF: Multiple Image Haze Removal and 3D Shape Reconstruction  using Neural Radiance Fields",
    "abstract": "Neural radiance fields (NeRFs) have demonstrated state-of-the-art performance for 3D computer vision tasks, including novel view synthesis and 3D shape reconstruction. However, these methods fail in adverse weather conditions. To address this challenge, we introduce DehazeNeRF as a framework that robustly operates in hazy conditions. DehazeNeRF extends the volume rendering equation by adding physically realistic terms that model atmospheric scattering. By parameterizing these terms using suitable networks that match the physical properties, we introduce effective inductive biases, which, together with the proposed regularizations, allow DehazeNeRF to demonstrate successful multi-view haze removal, novel view synthesis, and 3D shape reconstruction where existing approaches fail. ",
    "url": "https://arxiv.org/abs/2303.11364",
    "authors": [
      "Wei-Ting Chen",
      "Wang Yifan",
      "Sy-Yen Kuo",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11373",
    "title": "Neural Constraint Satisfaction: Hierarchical Abstraction for  Combinatorial Generalization in Object Rearrangement",
    "abstract": "Object rearrangement is a challenge for embodied agents because solving these tasks requires generalizing across a combinatorially large set of configurations of entities and their locations. Worse, the representations of these entities are unknown and must be inferred from sensory percepts. We present a hierarchical abstraction approach to uncover these underlying entities and achieve combinatorial generalization from unstructured visual inputs. By constructing a factorized transition graph over clusters of entity representations inferred from pixels, we show how to learn a correspondence between intervening on states of entities in the agent's model and acting on objects in the environment. We use this correspondence to develop a method for control that generalizes to different numbers and configurations of objects, which outperforms current offline deep RL methods when evaluated on simulated rearrangement tasks. ",
    "url": "https://arxiv.org/abs/2303.11373",
    "authors": [
      "Michael Chang",
      "Alyssa L. Dayan",
      "Franziska Meier",
      "Thomas L. Griffiths",
      "Sergey Levine",
      "Amy Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.11376",
    "title": "GNN-Ensemble: Towards Random Decision Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have enjoyed wide spread applications in graph-structured data. However, existing graph based applications commonly lack annotated data. GNNs are required to learn latent patterns from a limited amount of training data to perform inferences on a vast amount of test data. The increased complexity of GNNs, as well as a single point of model parameter initialization, usually lead to overfitting and sub-optimal performance. In addition, it is known that GNNs are vulnerable to adversarial attacks. In this paper, we push one step forward on the ensemble learning of GNNs with improved accuracy, generalization, and adversarial robustness. Following the principles of stochastic modeling, we propose a new method called GNN-Ensemble to construct an ensemble of random decision graph neural networks whose capacity can be arbitrarily expanded for improvement in performance. The essence of the method is to build multiple GNNs in randomly selected substructures in the topological space and subfeatures in the feature space, and then combine them for final decision making. These GNNs in different substructure and subfeature spaces generalize their classification in complementary ways. Consequently, their combined classification performance can be improved and overfitting on the training data can be effectively reduced. In the meantime, we show that GNN-Ensemble can significantly improve the adversarial robustness against attacks on GNNs. ",
    "url": "https://arxiv.org/abs/2303.11376",
    "authors": [
      "Wenqi Wei",
      "Mu Qiao",
      "Divyesh Jadav"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11403",
    "title": "eP-ALM: Efficient Perceptual Augmentation of Language Models",
    "abstract": "Large Language Models (LLMs) have so far impressed the world, with unprecedented capabilities that emerge in models at large scales. On the vision side, transformer models (i.e., ViT) are following the same trend, achieving the best performance on challenging benchmarks. With the abundance of such unimodal models, a natural question arises; do we need also to follow this trend to tackle multimodal tasks? In this work, we propose to rather direct effort to efficient adaptations of existing models, and propose to augment Language Models with perception. Existing approaches for adapting pretrained models for vision-language tasks still rely on several key components that hinder their efficiency. In particular, they still train a large number of parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP) trained on huge image-text datasets, and add significant inference overhead. In addition, most of these approaches have focused on Zero-Shot and In Context Learning, with little to no effort on direct finetuning. We investigate the minimal computational effort needed to adapt unimodal models for multimodal tasks and propose a new challenging setup, alongside different approaches, that efficiently adapts unimodal pretrained models. We show that by freezing more than 99\\% of total parameters, training only one linear projection layer, and prepending only one trainable token, our approach (dubbed eP-ALM) significantly outperforms other baselines on VQA and Captioning across Image, Video, and Audio modalities, following the proposed setup. The code will be available here: https://github.com/mshukor/eP-ALM. ",
    "url": "https://arxiv.org/abs/2303.11403",
    "authors": [
      "Mustafa Shukor",
      "Corentin Dancette",
      "Matthieu Cord"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11407",
    "title": "Distributed Resilient Interval Observers for Bounded-Error LTI Systems  Subject to False Data Injection Attacks",
    "abstract": "This paper proposes a novel distributed interval-valued simultaneous state and input observer for linear time-invariant (LTI) systems that are subject to attacks or unknown inputs injected both on their sensors and actuators. Each agent in the network leverages a singular value decomposition (SVD) based transformation to decompose its observations into two components, one of them unaffected by the attack signal, which helps to obtain local interval estimates of the state and unknown input and then uses intersection to compute the best interval estimate among neighboring nodes. We show that the computed intervals are guaranteed to contain the true state and input trajectories, and we provide conditions under which the observer is stable. Furthermore, we provide a method for designing stabilizing gains that minimize an upper bound on the worst-case steady-state observer error. We demonstrate our algorithm on an IEEE 14-bus power system. ",
    "url": "https://arxiv.org/abs/2303.11407",
    "authors": [
      "Mohammad Khajenejad",
      "Scott Brown",
      "Sonia Martinez"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.11419",
    "title": "EPiC: Ensemble of Partial Point Clouds for Robust Classification",
    "abstract": "Robust point cloud classification is crucial for real-world applications, as consumer-type 3D sensors often yield partial and noisy data, degraded by various artifacts. In this work we propose a general ensemble framework, based on partial point cloud sampling. Each ensemble member is exposed to only partial input data. Three sampling strategies are used jointly, two local ones, based on patches and curves, and a global one of random sampling. We demonstrate the robustness of our method to various local and global degradations. We show that our framework significantly improves the robustness of top classification netowrks by a large margin. Our experimental setting uses the recently introduced ModelNet-C database by Ren et al.[24], where we reach SOTA both on unaugmented and on augmented data. Our unaugmented mean Corruption Error (mCE) is 0.64 (current SOTA is 0.86) and 0.50 for augmented data (current SOTA is 0.57). We analyze and explain these remarkable results through diversity analysis. ",
    "url": "https://arxiv.org/abs/2303.11419",
    "authors": [
      "Meir Yossef Levi",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11424",
    "title": "Polynomial Implicit Neural Representations For Large Diverse Datasets",
    "abstract": "Implicit neural representations (INR) have gained significant popularity for signal and image representation for many end-tasks, such as superresolution, 3D modeling, and more. Most INR architectures rely on sinusoidal positional encoding, which accounts for high-frequency information in data. However, the finite encoding size restricts the model's representational power. Higher representational power is needed to go from representing a single given image to representing large and diverse datasets. Our approach addresses this gap by representing an image with a polynomial function and eliminates the need for positional encodings. Therefore, to achieve a progressively higher degree of polynomial representation, we use element-wise multiplications between features and affine-transformed coordinate locations after every ReLU layer. The proposed method is evaluated qualitatively and quantitatively on large datasets like ImageNet. The proposed Poly-INR model performs comparably to state-of-the-art generative models without any convolution, normalization, or self-attention layers, and with far fewer trainable parameters. With much fewer training parameters and higher representative power, our approach paves the way for broader adoption of INR models for generative modeling tasks in complex domains. The code is available at \\url{https://github.com/Rajhans0/Poly_INR} ",
    "url": "https://arxiv.org/abs/2303.11424",
    "authors": [
      "Rajhans Singh",
      "Ankita Shukla",
      "Pavan Turaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11453",
    "title": "Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing  and Neural Networks with Quadratic Activations",
    "abstract": "Pruning schemes have been widely used in practice to reduce the complexity of trained models with a massive number of parameters. Several practical studies have shown that pruning an overparameterized model and fine-tuning generalizes well to new samples. Although the above pipeline, which we refer to as pruning + fine-tuning, has been extremely successful in lowering the complexity of trained models, there is very little known about the theory behind this success. In this paper we address this issue by investigating the pruning + fine-tuning framework on the overparameterized matrix sensing problem, with the ground truth denoted $U_\\star \\in \\mathbb{R}^{d \\times r}$ and the overparameterized model $U \\in \\mathbb{R}^{d \\times k}$ with $k \\gg r$. We study the approximate local minima of the empirical mean square error, augmented with a smooth version of a group Lasso regularizer, $\\sum_{i=1}^k \\| U e_i \\|_2$ and show that pruning the low $\\ell_2$-norm columns results in a solution $U_{\\text{prune}}$ which has the minimum number of columns $r$, yet is close to the ground truth in training loss. Initializing the subsequent fine-tuning phase from $U_{\\text{prune}}$, the resulting solution converges linearly to a generalization error of $O(\\sqrt{rd/n})$ ignoring lower order terms, which is statistically optimal. While our analysis provides insights into the role of regularization in pruning, we also show that running gradient descent in the absence of regularization results in models which {are not suitable for greedy pruning}, i.e., many columns could have their $\\ell_2$ norm comparable to that of the maximum. Lastly, we extend our results for the training and pruning of two-layer neural networks with quadratic activation functions. Our results provide the first rigorous insights on why greedy pruning + fine-tuning leads to smaller models which also generalize well. ",
    "url": "https://arxiv.org/abs/2303.11453",
    "authors": [
      "Nived Rajaraman",
      "Devvrit",
      "Aryan Mokhtari",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.11454",
    "title": "How (Implicit) Regularization of ReLU Neural Networks Characterizes the  Learned Function -- Part II: the Multi-D Case of Two Layers with Random First  Layer",
    "abstract": "Randomized neural networks (randomized NNs), where only the terminal layer's weights are optimized constitute a powerful model class to reduce computational time in training the neural network model. At the same time, these models generalize surprisingly well in various regression and classification tasks. In this paper, we give an exact macroscopic characterization (i.e., a characterization in function space) of the generalization behavior of randomized, shallow NNs with ReLU activation (RSNs). We show that RSNs correspond to a generalized additive model (GAM)-typed regression in which infinitely many directions are considered: the infinite generalized additive model (IGAM). The IGAM is formalized as solution to an optimization problem in function space for a specific regularization functional and a fairly general loss. This work is an extension to multivariate NNs of prior work, where we showed how wide RSNs with ReLU activation behave like spline regression under certain conditions and if the input is one-dimensional. ",
    "url": "https://arxiv.org/abs/2303.11454",
    "authors": [
      "Jakob Heiss",
      "Josef Teichmann",
      "Hanna Wutte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.11457",
    "title": "Team Coordination on Graphs with State-Dependent Edge Cost",
    "abstract": "This paper studies a team coordination problem in a graph environment. Specifically, we incorporate \"support\" action which an agent can take to reduce the cost for its teammate to traverse some edges that have higher costs otherwise. Due to this added feature, the graph traversal is no longer a standard multi-agent path planning problem. To solve this new problem, we propose a novel formulation by posing it as a planning problem in the joint state space: the joint state graph (JSG). Since the edges of JSG implicitly incorporate the support actions taken by the agents, we are able to now optimize the joint actions by solving a standard single-agent path planning problem in JSG. One main drawback of this approach is the curse of dimensionality in both the number of agents and the size of the graph. To improve scalability in graph size, we further propose a hierarchical decomposition method to perform path planning in two levels. We provide complexity analysis as well as a statistical analysis to demonstrate the efficiency of our algorithm. ",
    "url": "https://arxiv.org/abs/2303.11457",
    "authors": [
      "Sara Oughourli",
      "Manshi Limbu",
      "Zechen Hu",
      "Xuan Wang",
      "Xuesu Xiao",
      "Daigo Shishika"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.11459",
    "title": "Fairness-Aware Graph Filter Design",
    "abstract": "Graphs are mathematical tools that can be used to represent complex real-world systems, such as financial markets and social networks. Hence, machine learning (ML) over graphs has attracted significant attention recently. However, it has been demonstrated that ML over graphs amplifies the already existing bias towards certain under-represented groups in various decision-making problems due to the information aggregation over biased graph structures. Faced with this challenge, in this paper, we design a fair graph filter that can be employed in a versatile manner for graph-based learning tasks. The design of the proposed filter is based on a bias analysis and its optimality in mitigating bias compared to its fairness-agnostic counterpart is established. Experiments on real-world networks for node classification demonstrate the efficacy of the proposed filter design in mitigating bias, while attaining similar utility and better stability compared to baseline algorithms. ",
    "url": "https://arxiv.org/abs/2303.11459",
    "authors": [
      "O.Deniz Kose",
      "Yanning Shen",
      "Gonzalo Mateos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.11466",
    "title": "On interval edge-colorings of planar graphs",
    "abstract": "An edge-coloring of a graph $G$ with colors $1,\\ldots,t$ is called an \\emph{interval $t$-coloring} if all colors are used and the colors of edges incident to each vertex of $G$ are distinct and form an interval of integers. In 1990, Kamalian proved that if a graph $G$ with at least one edge has an interval $t$-coloring, then $t\\leq 2|V(G)|-3$. In 2002, Axenovich improved this upper bound for planar graphs: if a planar graph $G$ admits an interval $t$-coloring, then $t\\leq \\frac{11}{6}|V(G)|$. In the same paper Axenovich suggested a conjecture that if a planar graph $G$ has an interval $t$-coloring, then $t\\leq \\frac{3}{2}|V(G)|$. In this paper we confirm the conjecture by showing that if a planar graph $G$ admits an interval $t$-coloring, then $t\\leq \\frac{3|V(G)|-4}{2}$. We also prove that if an outerplanar graph $G$ has an interval $t$-coloring, then $t\\leq |V(G)|-1$. Moreover, all these upper bounds are sharp. ",
    "url": "https://arxiv.org/abs/2303.11466",
    "authors": [
      "Arsen Hambardzumyan",
      "Levon Muradyan"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.11470",
    "title": "Did You Train on My Dataset? Towards Public Dataset Protection with  Clean-Label Backdoor Watermarking",
    "abstract": "The huge supporting training data on the Internet has been a key factor in the success of deep learning models. However, this abundance of public-available data also raises concerns about the unauthorized exploitation of datasets for commercial purposes, which is forbidden by dataset licenses. In this paper, we propose a backdoor-based watermarking approach that serves as a general framework for safeguarding public-available data. By inserting a small number of watermarking samples into the dataset, our approach enables the learning model to implicitly learn a secret function set by defenders. This hidden function can then be used as a watermark to track down third-party models that use the dataset illegally. Unfortunately, existing backdoor insertion methods often entail adding arbitrary and mislabeled data to the training set, leading to a significant drop in performance and easy detection by anomaly detection algorithms. To overcome this challenge, we introduce a clean-label backdoor watermarking framework that uses imperceptible perturbations to replace mislabeled samples. As a result, the watermarking samples remain consistent with the original labels, making them difficult to detect. Our experiments on text, image, and audio datasets demonstrate that the proposed framework effectively safeguards datasets with minimal impact on original task performance. We also show that adding just 1% of watermarking samples can inject a traceable watermarking function and that our watermarking samples are stealthy and look benign upon visual inspection. ",
    "url": "https://arxiv.org/abs/2303.11470",
    "authors": [
      "Ruixiang Tang",
      "Qizhang Feng",
      "Ninghao Liu",
      "Fan Yang",
      "Xia Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.11492",
    "title": "TSNZeek: An Open-source Intrusion Detection System for IEEE 802.1  Time-sensitive Networking",
    "abstract": "IEEE 802.1 Time-sensitive Networking~(TSN) standards are envisioned to replace legacy network protocols in critical domains to ensure reliable and deterministic communication over off-the-shelf Ethernet equipment. However, they lack security countermeasures and can even impose new attack vectors that may lead to hazardous consequences. This paper presents the first open-source security monitoring and intrusion detection mechanism, TSNZeek, for IEEE 802.1 TSN protocols. We extend an existing monitoring tool, Zeek, with a new packet parsing grammar to process TSN data traffic and a rule-based attack detection engine for TSN-specific threats. We also discuss various security-related configuration and design aspects for IEEE 802.1 TSN monitoring. Our experiments show that TSNZeek causes only ~5% CPU overhead on top of Zeek and successfully detects various threats in a real TSN testbed. ",
    "url": "https://arxiv.org/abs/2303.11492",
    "authors": [
      "Do\u011fanalp Ergen\u00e7",
      "Robin Schenderlein",
      "Mathias Fischer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.11511",
    "title": "STDLens: Model Hijacking-resilient Federated Learning for Object  Detection",
    "abstract": "Federated Learning (FL) has been gaining popularity as a collaborative learning framework to train deep learning-based object detection models over a distributed population of clients. Despite its advantages, FL is vulnerable to model hijacking. The attacker can control how the object detection system should misbehave by implanting Trojaned gradients using only a small number of compromised clients in the collaborative learning process. This paper introduces STDLens, a principled approach to safeguarding FL against such attacks. We first investigate existing mitigation mechanisms and analyze their failures caused by the inherent errors in spatial clustering analysis on gradients. Based on the insights, we introduce a three-tier forensic framework to identify and expel Trojaned gradients and reclaim the performance over the course of FL. We consider three types of adaptive attacks and demonstrate the robustness of STDLens against advanced adversaries. Extensive experiments show that STDLens can protect FL against different model hijacking attacks and outperform existing methods in identifying and removing Trojaned gradients with significantly higher precision and much lower false-positive rates. ",
    "url": "https://arxiv.org/abs/2303.11511",
    "authors": [
      "Ka-Ho Chow",
      "Ling Liu",
      "Wenqi Wei",
      "Fatih Ilhan",
      "Yanzhao Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11514",
    "title": "Service-based Trajectory Planning in Multi-Drone Skyway Networks",
    "abstract": "We present a demonstration of service-based trajectory planning for a drone delivery system in a multi-drone skyway network. We conduct several experiments using Crazyflie drones to collect the drone's position data, wind speed and direction, and wind effects on voltage consumption rates. The experiments are run for a varying number of recharging stations, wind speed, and wind direction in a multi-drone skyway network. Demo: https://youtu.be/zEwqdtEmmiw ",
    "url": "https://arxiv.org/abs/2303.11514",
    "authors": [
      "Sarah Bradley",
      "Albertus Alvin Janitra",
      "Babar Shahzaad",
      "Balsam Alkouz",
      "Athman Bouguettaya",
      "Abdallah Lakhdari"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.11536",
    "title": "Indeterminate Probability Neural Network",
    "abstract": "We propose a new general model called IPNN - Indeterminate Probability Neural Network, which combines neural network and probability theory together. In the classical probability theory, the calculation of probability is based on the occurrence of events, which is hardly used in current neural networks. In this paper, we propose a new general probability theory, which is an extension of classical probability theory, and makes classical probability theory a special case to our theory. Besides, for our proposed neural network framework, the output of neural network is defined as probability events, and based on the statistical analysis of these events, the inference model for classification task is deduced. IPNN shows new property: It can perform unsupervised clustering while doing classification. Besides, IPNN is capable of making very large classification with very small neural network, e.g. model with 100 output nodes can classify 10 billion categories. Theoretical advantages are reflected in experimental results. ",
    "url": "https://arxiv.org/abs/2303.11536",
    "authors": [
      "Tao Yang",
      "Chuang Liu",
      "Xiaofeng Ma",
      "Weijia Lu",
      "Ning Wu",
      "Bingyang Li",
      "Zhifei Yang",
      "Peng Liu",
      "Lin Sun",
      "Xiaodong Zhang",
      "Can Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11537",
    "title": "Interactive Geometry Editing of Neural Radiance Fields",
    "abstract": "In this paper, we propose a method that enables the interactive geometry editing for neural radiance fields manipulation. We use two cages(inner cage and outer cage) to enable editing of a scene. Various operations are applicable to the two cages. Operations on the inner cage lead to desired deformation of inner cage and adjustment of the outer cage. Operations on the outer cage lead to deformation without changing the rest space. Users can editing the scene with translation, rotation, scaling or any combination of these. And the operations on the corners and edges of the cage are also supported. Our method does not need any explicit 3D geometry representations. The interactive geometry editing applies directly to the implicit neural radiance fields. The deformation results demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2303.11537",
    "authors": [
      "Shaoxu Li",
      "Ye Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11540",
    "title": "MSTFormer: Motion Inspired Spatial-temporal Transformer with  Dynamic-aware Attention for long-term Vessel Trajectory Prediction",
    "abstract": "Incorporating the dynamics knowledge into the model is critical for achieving accurate trajectory prediction while considering the spatial and temporal characteristics of the vessel. However, existing methods rarely consider the underlying dynamics knowledge and directly use machine learning algorithms to predict the trajectories. Intuitively, the vessel's motions are following the laws of dynamics, e.g., the speed of a vessel decreases when turning a corner. Yet, it is challenging to combine dynamic knowledge and neural networks due to their inherent heterogeneity. Against this background, we propose MSTFormer, a motion inspired vessel trajectory prediction method based on Transformer. The contribution of this work is threefold. First, we design a data augmentation method to describe the spatial features and motion features of the trajectory. Second, we propose a Multi-headed Dynamic-aware Self-attention mechanism to focus on trajectory points with frequent motion transformations. Finally, we construct a knowledge-inspired loss function to further boost the performance of the model. Experimental results on real-world datasets show that our strategy not only effectively improves long-term predictive capability but also outperforms backbones on cornering data.The ablation analysis further confirms the efficacy of the proposed method. To the best of our knowledge, MSTFormer is the first neural network model for trajectory prediction fused with vessel motion dynamics, providing a worthwhile direction for future research.The source code is available at https://github.com/simple316/MSTFormer. ",
    "url": "https://arxiv.org/abs/2303.11540",
    "authors": [
      "Huimin Qiang",
      "Zhiyuan Guo",
      "Shiyuan Xie",
      "Xiaodong Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11551",
    "title": "ModEFormer: Modality-Preserving Embedding for Audio-Video  Synchronization using Transformers",
    "abstract": "Lack of audio-video synchronization is a common problem during television broadcasts and video conferencing, leading to an unsatisfactory viewing experience. A widely accepted paradigm is to create an error detection mechanism that identifies the cases when audio is leading or lagging. We propose ModEFormer, which independently extracts audio and video embeddings using modality-specific transformers. Different from the other transformer-based approaches, ModEFormer preserves the modality of the input streams which allows us to use a larger batch size with more negative audio samples for contrastive learning. Further, we propose a trade-off between the number of negative samples and number of unique samples in a batch to significantly exceed the performance of previous methods. Experimental results show that ModEFormer achieves state-of-the-art performance, 94.5% for LRS2 and 90.9% for LRS3. Finally, we demonstrate how ModEFormer can be used for offset detection for test clips. ",
    "url": "https://arxiv.org/abs/2303.11551",
    "authors": [
      "Akash Gupta",
      "Rohun Tripathi",
      "Wondong Jang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.11552",
    "title": "Boosting Verified Training for Robust Image Classifications via  Abstraction",
    "abstract": "This paper proposes a novel, abstraction-based, certified training method for robust image classifiers. Via abstraction, all perturbed images are mapped into intervals before feeding into neural networks for training. By training on intervals, all the perturbed images that are mapped to the same interval are classified as the same label, rendering the variance of training sets to be small and the loss landscape of the models to be smooth. Consequently, our approach significantly improves the robustness of trained models. For the abstraction, our training method also enables a sound and complete black-box verification approach, which is orthogonal and scalable to arbitrary types of neural networks regardless of their sizes and architectures. We evaluate our method on a wide range of benchmarks in different scales. The experimental results show that our method outperforms state of the art by (i) reducing the verified errors of trained models up to 95.64%; (ii) totally achieving up to 602.50x speedup; and (iii) scaling up to larger models with up to 138 million trainable parameters. The demo is available at https://github.com/zhangzhaodi233/ABSCERT.git. ",
    "url": "https://arxiv.org/abs/2303.11552",
    "authors": [
      "Zhaodi Zhang",
      "Zhiyi Xue",
      "Yang Chen",
      "Si Liu",
      "Yueling Zhang",
      "Jing Liu",
      "Min Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11560",
    "title": "Smart-Tree: Neural Medial Axis Approximation of Point Clouds for 3D Tree  Skeletonization",
    "abstract": "In this paper, we present Smart-Tree, a supervised method for approximating the medial axes of branch skeletons from a tree's point cloud. A sparse voxel convolutional neural network extracts each input point's radius and direction towards the medial axis. A greedy algorithm performs robust skeletonization using the estimated medial axis. The proposed method provides robustness to complex tree structures and improves fidelity when dealing with self-occlusions, complex geometry, touching branches, and varying point densities. We train and test the method using a multi-species synthetic tree data set and perform qualitative analysis on a real-life tree point cloud. Experimentation with synthetic and real-world datasets demonstrates the robustness of our approach over the current state-of-the-art method. Further research will focus on training the method on a broader range of tree species and improving robustness to point cloud gaps. The details to obtain the dataset are at https://github.com/uc-vision/synthetic-trees. ",
    "url": "https://arxiv.org/abs/2303.11560",
    "authors": [
      "Harry Dobbs",
      "Oliver Batchelor",
      "Richard Green",
      "James Atlas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11567",
    "title": "One-to-Few Label Assignment for End-to-End Dense Detection",
    "abstract": "One-to-one (o2o) label assignment plays a key role for transformer based end-to-end detection, and it has been recently introduced in fully convolutional detectors for end-to-end dense detection. However, o2o can degrade the feature learning efficiency due to the limited number of positive samples. Though extra positive samples are introduced to mitigate this issue in recent DETRs, the computation of self- and cross- attentions in the decoder limits its practical application to dense and fully convolutional detectors. In this work, we propose a simple yet effective one-to-few (o2f) label assignment strategy for end-to-end dense detection. Apart from defining one positive and many negative anchors for each object, we define several soft anchors, which serve as positive and negative samples simultaneously. The positive and negative weights of these soft anchors are dynamically adjusted during training so that they can contribute more to ``representation learning'' in the early training stage, and contribute more to ``duplicated prediction removal'' in the later stage. The detector trained in this way can not only learn a strong feature representation but also perform end-to-end dense detection. Experiments on COCO and CrowdHuman datasets demonstrate the effectiveness of the o2f scheme. Code is available at https://github.com/strongwolf/o2f. ",
    "url": "https://arxiv.org/abs/2303.11567",
    "authors": [
      "Shuai Li",
      "Minghan Li",
      "Ruihuang Li",
      "Chenhang He",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11575",
    "title": "\"I Want the Payment Process to be Cool'': Understanding How Interaction  Factors into Security and Privacy Perception of Authentication in Virtual  Reality",
    "abstract": "Users embrace the rapid development of virtual reality (VR) technology. We are witnessing a widespread adoption of VR technology in more routine settings, such as gaming, social interactions, shopping, and commerce. VR systems access sensitive user data and assets when handling these routine activities, including payment, which raises the need for user authentication in VR. However, there is a limited understanding of how users perceive user authentication in VR, in particular, how users' interaction experiences factor into their perception of security and privacy. Our work adopts a ``technology probe'' approach to understand this question. We design technology probes of authentication in VR based on existing authentication interactions in both VR and the physical world. Further, we embed these probes in the routine payment of a VR game. Our qualitative analysis reveals that users face unique usability challenges in VR authentication, e.g., in motion control. Such challenges also hinder users from accessing security and privacy accurately in VR authentication. Users' expectations for VR authentication mainly center on improvements in interaction. However, their expectations could appear nonspecific and conflicting. We provide recommendations to accommodate users' expectations and resolve conflicts between usability and security. ",
    "url": "https://arxiv.org/abs/2303.11575",
    "authors": [
      "Jingjie Li",
      "Sunpreet Singh Arora",
      "Kassem Fawaz",
      "Younghyun Kim",
      "Can Liu",
      "Sebastian Meiser",
      "Mohsen Minaei",
      "Maliheh Shirvanian",
      "Kim Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.11591",
    "title": "SVCNet: Scribble-based Video Colorization Network with Temporal  Aggregation",
    "abstract": "In this paper, we propose a scribble-based video colorization network with temporal aggregation called SVCNet. It can colorize monochrome videos based on different user-given color scribbles. It addresses three common issues in the scribble-based video colorization area: colorization vividness, temporal consistency, and color bleeding. To improve the colorization quality and strengthen the temporal consistency, we adopt two sequential sub-networks in SVCNet for precise colorization and temporal smoothing, respectively. The first stage includes a pyramid feature encoder to incorporate color scribbles with a grayscale frame, and a semantic feature encoder to extract semantics. The second stage finetunes the output from the first stage by aggregating the information of neighboring colorized frames (as short-range connections) and the first colorized frame (as a long-range connection). To alleviate the color bleeding artifacts, we learn video colorization and segmentation simultaneously. Furthermore, we set the majority of operations on a fixed small image resolution and use a Super-resolution Module at the tail of SVCNet to recover original sizes. It allows the SVCNet to fit different image resolutions at the inference. Finally, we evaluate the proposed SVCNet on DAVIS and Videvo benchmarks. The experimental results demonstrate that SVCNet produces both higher-quality and more temporally consistent videos than other well-known video colorization approaches. The codes and models can be found at https://github.com/zhaoyuzhi/SVCNet. ",
    "url": "https://arxiv.org/abs/2303.11591",
    "authors": [
      "Yuzhi Zhao",
      "Lai-Man Po",
      "Kangcheng Liu",
      "Xuehui Wang",
      "Wing-Yin Yu",
      "Pengfei Xian",
      "Yujia Zhang",
      "Mengyang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.11595",
    "title": "Effective Ambiguity Attack Against Passport-based DNN Intellectual  Property Protection Schemes through Fully Connected Layer Substitution",
    "abstract": "Since training a deep neural network (DNN) is costly, the well-trained deep models can be regarded as valuable intellectual property (IP) assets. The IP protection associated with deep models has been receiving increasing attentions in recent years. Passport-based method, which replaces normalization layers with passport layers, has been one of the few protection solutions that are claimed to be secure against advanced attacks. In this work, we tackle the issue of evaluating the security of passport-based IP protection methods. We propose a novel and effective ambiguity attack against passport-based method, capable of successfully forging multiple valid passports with a small training dataset. This is accomplished by inserting a specially designed accessory block ahead of the passport parameters. Using less than 10% of training data, with the forged passport, the model exhibits almost indistinguishable performance difference (less than 2%) compared with that of the authorized passport. In addition, it is shown that our attack strategy can be readily generalized to attack other IP protection methods based on watermark embedding. Directions for potential remedy solutions are also given. ",
    "url": "https://arxiv.org/abs/2303.11595",
    "authors": [
      "Yiming Chen",
      "Jinyu Tian",
      "Xiangyu Chen",
      "Jiantao Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.11597",
    "title": "Geodesic cycle length distributions in fictional character networks",
    "abstract": "A geodesic cycle in a graph is a cycle with no shortcuts, so that the shortest path between any two nodes in the cycle is the path along the cycle itself. A recently published paper used random graph models to investigate the geodesic cycle length distributions of a unique set of delusional social networks, first examined in an earlier work, as well as some other publicly available social networks. Here I test the hypothesis, suggested in the former work, that fictional character networks, and in particular those from works by a single author, might have geodesic cycle length distributions which are extremely unlikely under random graph models, as the delusional social networks do. The results do not show any support for this hypothesis. In addition, the recently published work is reproduced using a method for counting geodesic cycles exactly, rather than the approximate method used originally. The substantive conclusions of that work are unchanged, but some differences in the results for particular networks are described. ",
    "url": "https://arxiv.org/abs/2303.11597",
    "authors": [
      "Alex Stivala"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.11611",
    "title": "Model Robustness Meets Data Privacy: Adversarial Robustness Distillation  without Original Data",
    "abstract": "Large-scale deep learning models have achieved great performance based on large-scale datasets. Moreover, the existing Adversarial Training (AT) can further improve the robustness of these large models. However, these large models are difficult to deploy to mobile devices, and the effect of AT on small models is very limited. In addition, the data privacy issue (e.g., face data and diagnosis report) may lead to the original data being unavailable, which relies on data-free knowledge distillation technology for training. To tackle these issues, we propose a challenging novel task called Data-Free Adversarial Robustness Distillation (DFARD), which tries to train small, easily deployable, robust models without relying on the original data. We find the combination of existing techniques resulted in degraded model performance due to fixed training objectives and scarce information content. First, an interactive strategy is designed for more efficient knowledge transfer to find more suitable training objectives at each epoch. Then, we explore an adaptive balance method to suppress information loss and obtain more data information than previous methods. Experiments show that our method improves baseline performance on the novel task. ",
    "url": "https://arxiv.org/abs/2303.11611",
    "authors": [
      "Yuzheng Wang",
      "Zhaoyu Chen",
      "Dingkang Yang",
      "Pinxue Guo",
      "Kaixun Jiang",
      "Wenqiang Zhang",
      "Lizhe Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11615",
    "title": "Robust Table Structure Recognition with Dynamic Queries Enhanced  Detection Transformer",
    "abstract": "We present a new table structure recognition (TSR) approach, called TSRFormer, to robustly recognizing the structures of complex tables with geometrical distortions from various table images. Unlike previous methods, we formulate table separation line prediction as a line regression problem instead of an image segmentation problem and propose a new two-stage dynamic queries enhanced DETR based separation line regression approach, named DQ-DETR, to predict separation lines from table images directly. Compared to Vallina DETR, we propose three improvements in DQ-DETR to make the two-stage DETR framework work efficiently and effectively for the separation line prediction task: 1) A new query design, named Dynamic Query, to decouple single line query into separable point queries which could intuitively improve the localization accuracy for regression tasks; 2) A dynamic queries based progressive line regression approach to progressively regressing points on the line which further enhances localization accuracy for distorted tables; 3) A prior-enhanced matching strategy to solve the slow convergence issue of DETR. After separation line prediction, a simple relation network based cell merging module is used to recover spanning cells. With these new techniques, our TSRFormer achieves state-of-the-art performance on several benchmark datasets, including SciTSR, PubTabNet, WTW and FinTabNet. Furthermore, we have validated the robustness and high localization accuracy of our approach to tables with complex structures, borderless cells, large blank spaces, empty or spanning cells as well as distorted or even curved shapes on a more challenging real-world in-house dataset. ",
    "url": "https://arxiv.org/abs/2303.11615",
    "authors": [
      "Jiawei Wang",
      "Weihong Lin",
      "Chixiang Ma",
      "Mingze Li",
      "Zheng Sun",
      "Lei Sun",
      "Qiang Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11617",
    "title": "Adaptive quadratures for nonlinear approximation of low-dimensional PDEs  using smooth neural networks",
    "abstract": "Physics-informed neural networks (PINNs) and their variants have recently emerged as alternatives to traditional partial differential equation (PDE) solvers, but little literature has focused on devising accurate numerical integration methods for neural networks (NNs), which is essential for getting accurate solutions. In this work, we propose adaptive quadratures for the accurate integration of neural networks and apply them to loss functions appearing in low-dimensional PDE discretisations. We show that at opposite ends of the spectrum, continuous piecewise linear (CPWL) activation functions enable one to bound the integration error, while smooth activations ease the convergence of the optimisation problem. We strike a balance by considering a CPWL approximation of a smooth activation function. The CPWL activation is used to obtain an adaptive decomposition of the domain into regions where the network is almost linear, and we derive an adaptive global quadrature from this mesh. The loss function is then obtained by evaluating the smooth network (together with other quantities, e.g., the forcing term) at the quadrature points. We propose a method to approximate a class of smooth activations by CPWL functions and show that it has a quadratic convergence rate. We then derive an upper bound for the overall integration error of our proposed adaptive quadrature. The benefits of our quadrature are evaluated on a strong and weak formulation of the Poisson equation in dimensions one and two. Our numerical experiments suggest that compared to Monte-Carlo integration, our adaptive quadrature makes the convergence of NNs quicker and more robust to parameter initialisation while needing significantly fewer integration points and keeping similar training times. ",
    "url": "https://arxiv.org/abs/2303.11617",
    "authors": [
      "Alexandre Magueresse",
      "Santiago Badia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.11625",
    "title": "Information-containing Adversarial Perturbation for Combating Facial  Manipulation Systems",
    "abstract": "With the development of deep learning technology, the facial manipulation system has become powerful and easy to use. Such systems can modify the attributes of the given facial images, such as hair color, gender, and age. Malicious applications of such systems pose a serious threat to individuals' privacy and reputation. Existing studies have proposed various approaches to protect images against facial manipulations. Passive defense methods aim to detect whether the face is real or fake, which works for posterior forensics but can not prevent malicious manipulation. Initiative defense methods protect images upfront by injecting adversarial perturbations into images to disrupt facial manipulation systems but can not identify whether the image is fake. To address the limitation of existing methods, we propose a novel two-tier protection method named Information-containing Adversarial Perturbation (IAP), which provides more comprehensive protection for {facial images}. We use an encoder to map a facial image and its identity message to a cross-model adversarial example which can disrupt multiple facial manipulation systems to achieve initiative protection. Recovering the message in adversarial examples with a decoder serves passive protection, contributing to provenance tracking and fake image detection. We introduce a feature-level correlation measurement that is more suitable to measure the difference between the facial images than the commonly used mean squared error. Moreover, we propose a spectral diffusion method to spread messages to different frequency channels, thereby improving the robustness of the message against facial manipulation. Extensive experimental results demonstrate that our proposed IAP can recover the messages from the adversarial examples with high average accuracy and effectively disrupt the facial manipulation systems. ",
    "url": "https://arxiv.org/abs/2303.11625",
    "authors": [
      "Yao Zhu",
      "Yuefeng Chen",
      "Xiaodan Li",
      "Rong Zhang",
      "Xiang Tian",
      "Bolun Zheng",
      "Yaowu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11640",
    "title": "An Observer-based Switching Algorithm for Safety under Sensor  Denial-of-Service Attacks",
    "abstract": "The design of safe-critical control algorithms for systems under Denial-of-Service (DoS) attacks on the system output is studied in this work. We aim to address scenarios where attack-mitigation approaches are not feasible, and the system needs to maintain safety under adversarial attacks. We propose an attack-recovery strategy by designing a switching observer and characterizing bounds in the error of a state estimation scheme by specifying tolerable limits on the time length of attacks. Then, we propose a switching control algorithm that renders forward invariant a set for the observer. Thus, by satisfying the error bounds of the state estimation, we guarantee that the safe set is rendered conditionally invariant with respect to a set of initial conditions. A numerical example illustrates the efficacy of the approach. ",
    "url": "https://arxiv.org/abs/2303.11640",
    "authors": [
      "Santiago Jimenez Leudo",
      "Kunal Garg",
      "Ricardo G. Sanfelice",
      "Alvaro A. Cardenas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.11649",
    "title": "CoopInit: Initializing Generative Adversarial Networks via Cooperative  Learning",
    "abstract": "Numerous research efforts have been made to stabilize the training of the Generative Adversarial Networks (GANs), such as through regularization and architecture design. However, we identify the instability can also arise from the fragile balance at the early stage of adversarial learning. This paper proposes the CoopInit, a simple yet effective cooperative learning-based initialization strategy that can quickly learn a good starting point for GANs, with a very small computation overhead during training. The proposed algorithm consists of two learning stages: (i) Cooperative initialization stage: The discriminator of GAN is treated as an energy-based model (EBM) and is optimized via maximum likelihood estimation (MLE), with the help of the GAN's generator to provide synthetic data to approximate the learning gradients. The EBM also guides the MLE learning of the generator via MCMC teaching; (ii) Adversarial finalization stage: After a few iterations of initialization, the algorithm seamlessly transits to the regular mini-max adversarial training until convergence. The motivation is that the MLE-based initialization stage drives the model towards mode coverage, which is helpful in alleviating the issue of mode dropping during the adversarial learning stage. We demonstrate the effectiveness of the proposed approach on image generation and one-sided unpaired image-to-image translation tasks through extensive experiments. ",
    "url": "https://arxiv.org/abs/2303.11649",
    "authors": [
      "Yang Zhao",
      "Jianwen Xie",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.11666",
    "title": "A Survey on Causal Inference for Recommendation",
    "abstract": "Recently, causal inference has attracted increasing attention from researchers of recommender systems (RS), which analyzes the relationship between a cause and its effect and has a wide range of real-world applications in multiple fields. Causal inference can model the causality in recommender systems like confounding effects and deal with counterfactual problems such as offline policy evaluation and data augmentation. Although there are already some valuable surveys on causal recommendations, these surveys introduce approaches in a relatively isolated way and lack theoretical analysis of existing methods. Due to the unfamiliarity with causality to RS researchers, it is both necessary and challenging to comprehensively review the relevant studies from the perspective of causal theory, which might be instructive for the readers to propose new approaches in practice. This survey attempts to provide a systematic review of up-to-date papers in this area from a theoretical standpoint. Firstly, we introduce the fundamental concepts of causal inference as the basis of the following review. Then we propose a new taxonomy from the perspective of causal techniques and further discuss technical details about how existing methods apply causal inference to address specific recommender issues. Finally, we highlight some promising directions for future research in this field. ",
    "url": "https://arxiv.org/abs/2303.11666",
    "authors": [
      "Huishi Luo",
      "Fuzhen Zhuang",
      "Ruobing Xie",
      "Hengshu Zhu",
      "Deqing Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.11668",
    "title": "Focus or Not: A Baseline for Anomaly Event Detection On the Open Public  Places with Satellite Images",
    "abstract": "In recent years, monitoring the world wide area with satellite images has been emerged as an important issue. Site monitoring task can be divided into two independent tasks; 1) Change Detection and 2) Anomaly Event Detection. Unlike to change detection research is actively conducted based on the numerous datasets(\\eg LEVIR-CD, WHU-CD, S2Looking, xView2 and etc...) to meet up the expectations of industries or governments, research on AI models for detecting anomaly events is passively and rarely conducted. In this paper, we introduce a novel satellite imagery dataset(AED-RS) for detecting anomaly events on the open public places. AED-RS Dataset contains satellite images of normal and abnormal situations of 8 open public places from all over the world. Each places are labeled with different criteria based on the difference of characteristics of each places. With this dataset, we introduce a baseline model for our dataset TB-FLOW, which can be trained in weakly-supervised manner and shows reasonable performance on the AED-RS Dataset compared with the other NF(Normalizing-Flow) based anomaly detection models. Our dataset and code will be publicly open in \\url{https://github.com/SIAnalytics/RS_AnomalyDetection.git}. ",
    "url": "https://arxiv.org/abs/2303.11668",
    "authors": [
      "Yongjin Jeon",
      "Youngtack Oh",
      "Doyoung Jeong",
      "Hyunguk Choi",
      "Junsik Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11698",
    "title": "Data Augmentation For Label Enhancement",
    "abstract": "Label distribution (LD) uses the description degree to describe instances, which provides more fine-grained supervision information when learning with label ambiguity. Nevertheless, LD is unavailable in many real-world applications. To obtain LD, label enhancement (LE) has emerged to recover LD from logical label. Existing LE approach have the following problems: (\\textbf{i}) They use logical label to train mappings to LD, but the supervision information is too loose, which can lead to inaccurate model prediction; (\\textbf{ii}) They ignore feature redundancy and use the collected features directly. To solve (\\textbf{i}), we use the topology of the feature space to generate more accurate label-confidence. To solve (\\textbf{ii}), we proposed a novel supervised LE dimensionality reduction approach, which projects the original data into a lower dimensional feature space. Combining the above two, we obtain the augmented data for LE. Further, we proposed a novel nonlinear LE model based on the label-confidence and reduced features. Extensive experiments on 12 real-world datasets are conducted and the results show that our method consistently outperforms the other five comparing approaches. ",
    "url": "https://arxiv.org/abs/2303.11698",
    "authors": [
      "Zhiqiang Kou",
      "Yuheng Jia",
      "Jing Wang",
      "Boyu Shi",
      "Xin Geng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11700",
    "title": "Dynamically Expandable Graph Convolution for Streaming Recommendation",
    "abstract": "Personalized recommender systems have been widely studied and deployed to reduce information overload and satisfy users' diverse needs. However, conventional recommendation models solely conduct a one-time training-test fashion and can hardly adapt to evolving demands, considering user preference shifts and ever-increasing users and items in the real world. To tackle such challenges, the streaming recommendation is proposed and has attracted great attention recently. Among these, continual graph learning is widely regarded as a promising approach for the streaming recommendation by academia and industry. However, existing methods either rely on the historical data replay which is often not practical under increasingly strict data regulations, or can seldom solve the \\textit{over-stability} issue. To overcome these difficulties, we propose a novel \\textbf{D}ynamically \\textbf{E}xpandable \\textbf{G}raph \\textbf{C}onvolution (DEGC) algorithm from a \\textit{model isolation} perspective for the streaming recommendation which is orthogonal to previous methods. Based on the motivation of disentangling outdated short-term preferences from useful long-term preferences, we design a sequence of operations including graph convolution pruning, refining, and expanding to only preserve beneficial long-term preference-related parameters and extract fresh short-term preferences. Moreover, we model the temporal user preference, which is utilized as user embedding initialization, for better capturing the individual-level preference shifts. Extensive experiments on the three most representative GCN-based recommendation models and four industrial datasets demonstrate the effectiveness and robustness of our method. ",
    "url": "https://arxiv.org/abs/2303.11700",
    "authors": [
      "Bowei He",
      "Xu He",
      "Yingxue Zhang",
      "Ruiming Tang",
      "Chen Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.11703",
    "title": "Being an Influencer is Hard: The Complexity of Influence Maximization in  Temporal Graphs with a Fixed Source",
    "abstract": "We consider the influence maximization problem over a temporal graph, where there is a single fixed source. We deviate from the standard model of influence maximization, where the goal is to choose the set of most influential vertices. Instead, in our model we are given a fixed vertex, or source, and the goal is to find the best time steps to transmit so that the influence of this vertex is maximized. We frame this problem as a spreading process that follows a variant of the susceptible-infected-susceptible (SIS) model and we focus on four objective functions. In the MaxSpread objective, the goal is to maximize the total number of vertices that get infected at least once. In the MaxViral objective, the goal is to maximize the number of vertices that are infected at the same time step. In the MaxViralTstep objective, the goal is to maximize the number of vertices that are infected at a given time step. Finally, in MinNonViralTime, the goal is to maximize the total number of vertices that get infected every $d$ time steps. We perform a thorough complexity theoretic analysis for these four objectives over three different scenarios: (1) the unconstrained setting where the source can transmit whenever it wants; (2) the window-constrained setting where the source has to transmit at either a predetermined, or a shifting window; (3) the periodic setting where the temporal graph has a small period. We prove that all of these problems, with the exception of MaxSpread for periodic graphs, are intractable even for very simple underlying graphs. ",
    "url": "https://arxiv.org/abs/2303.11703",
    "authors": [
      "Argyrios Deligkas",
      "Michelle D\u00f6ring",
      "Eduard Eiben",
      "Tiger-Lily Goldsmith",
      "George Skretas"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.11722",
    "title": "Implicit Neural Representation for Cooperative Low-light Image  Enhancement",
    "abstract": "The following three factors restrict the application of existing low-light image enhancement methods: unpredictable brightness degradation and noise, inherent gap between metric-favorable and visual-friendly versions, and the limited paired training data. To address these limitations, we propose an implicit Neural Representation method for Cooperative low-light image enhancement, dubbed NeRCo. It robustly recovers perceptual-friendly results in an unsupervised manner. Concretely, NeRCo unifies the diverse degradation factors of real-world scenes with a controllable fitting function, leading to better robustness. In addition, for the output results, we introduce semantic-orientated supervision with priors from the pre-trained vision-language model. Instead of merely following reference images, it encourages results to meet subjective expectations, finding more visual-friendly solutions. Further, to ease the reliance on paired data and reduce solution space, we develop a dual-closed-loop constrained enhancement module. It is trained cooperatively with other affiliated modules in a self-supervised manner. Finally, extensive experiments demonstrate the robustness and superior effectiveness of our proposed NeRCo. Our code is available at https://github.com/Ysz2022/NeRCo. ",
    "url": "https://arxiv.org/abs/2303.11722",
    "authors": [
      "Shuzhou Yang",
      "Moxuan Ding",
      "Yanmin Wu",
      "Zihan Li",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11725",
    "title": "Online Learning of Wheel Odometry Correction for Mobile Robots with  Attention-based Neural Network",
    "abstract": "Modern robotic platforms need a reliable localization system to operate daily beside humans. Simple pose estimation algorithms based on filtered wheel and inertial odometry often fail in the presence of abrupt kinematic changes and wheel slips. Moreover, despite the recent success of visual odometry, service and assistive robotic tasks often present challenging environmental conditions where visual-based solutions fail due to poor lighting or repetitive feature patterns. In this work, we propose an innovative online learning approach for wheel odometry correction, paving the way for a robust multi-source localization system. An efficient attention-based neural network architecture has been studied to combine precise performances with real-time inference. The proposed solution shows remarkable results compared to a standard neural network and filter-based odometry correction algorithms. Nonetheless, the online learning paradigm avoids the time-consuming data collection procedure and can be adopted on a generic robotic platform on-the-fly. ",
    "url": "https://arxiv.org/abs/2303.11725",
    "authors": [
      "Alessandro Navone",
      "Mauro Martini",
      "Simone Angarano",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11728",
    "title": "ExtremeNeRF: Few-shot Neural Radiance Fields Under Unconstrained  Illumination",
    "abstract": "In this paper, we propose a new challenge that synthesizes a novel view in a more practical environment, where the number of input multi-view images is limited and illumination variations are significant. Despite recent success, neural radiance fields (NeRF) require a massive amount of input multi-view images taken under constrained illuminations. To address the problem, we suggest ExtremeNeRF, which utilizes occlusion-aware multiview albedo consistency, supported by geometric alignment and depth consistency. We extract intrinsic image components that should be illumination-invariant across different views, enabling direct appearance comparison between the input and novel view under unconstrained illumination. We provide extensive experimental results for an evaluation of the task, using the newly built NeRF Extreme benchmark, which is the first in-the-wild novel view synthesis benchmark taken under multiple viewing directions and varying illuminations. The project page is at https://seokyeong94.github.io/ExtremeNeRF/ ",
    "url": "https://arxiv.org/abs/2303.11728",
    "authors": [
      "SeokYeong Lee",
      "JunYong Choi",
      "Seungryong Kim",
      "Ig-Jae Kim",
      "Junghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11733",
    "title": "DIPPM: a Deep Learning Inference Performance Predictive Model using  Graph Neural Networks",
    "abstract": "Deep Learning (DL) has developed to become a corner-stone in many everyday applications that we are now relying on. However, making sure that the DL model uses the underlying hardware efficiently takes a lot of effort. Knowledge about inference characteristics can help to find the right match so that enough resources are given to the model, but not too much. We have developed a DL Inference Performance Predictive Model (DIPPM) that predicts the inference latency, energy, and memory usage of a given input DL model on the NVIDIA A100 GPU. We also devised an algorithm to suggest the appropriate A100 Multi-Instance GPU profile from the output of DIPPM. We developed a methodology to convert DL models expressed in multiple frameworks to a generalized graph structure that is used in DIPPM. It means DIPPM can parse input DL models from various frameworks. Our DIPPM can be used not only helps to find suitable hardware configurations but also helps to perform rapid design-space exploration for the inference performance of a model. We constructed a graph multi-regression dataset consisting of 10,508 different DL models to train and evaluate the performance of DIPPM, and reached a resulting Mean Absolute Percentage Error (MAPE) as low as 1.9%. ",
    "url": "https://arxiv.org/abs/2303.11733",
    "authors": [
      "Karthick Panner Selvam",
      "Mats Brorsson"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11745",
    "title": "Poisoning Attacks in Federated Edge Learning for Digital Twin 6G-enabled  IoTs: An Anticipatory Study",
    "abstract": "Federated edge learning can be essential in supporting privacy-preserving, artificial intelligence (AI)-enabled activities in digital twin 6G-enabled Internet of Things (IoT) environments. However, we need to also consider the potential of attacks targeting the underlying AI systems (e.g., adversaries seek to corrupt data on the IoT devices during local updates or corrupt the model updates); hence, in this article, we propose an anticipatory study for poisoning attacks in federated edge learning for digital twin 6G-enabled IoT environments. Specifically, we study the influence of adversaries on the training and development of federated learning models in digital twin 6G-enabled IoT environments. We demonstrate that attackers can carry out poisoning attacks in two different learning settings, namely: centralized learning and federated learning, and successful attacks can severely reduce the model's accuracy. We comprehensively evaluate the attacks on a new cyber security dataset designed for IoT applications with three deep neural networks under the non-independent and identically distributed (Non-IID) data and the independent and identically distributed (IID) data. The poisoning attacks, on an attack classification problem, can lead to a decrease in accuracy from 94.93% to 85.98% with IID data and from 94.18% to 30.04% with Non-IID. ",
    "url": "https://arxiv.org/abs/2303.11745",
    "authors": [
      "Mohamed Amine Ferrag",
      "Burak Kantarci",
      "Lucas C. Cordeiro",
      "Merouane Debbah",
      "Kim-Kwang Raymond Choo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11746",
    "title": "Recommendation Systems in Libraries: an Application with Heterogeneous  Data Sources",
    "abstract": "The Reading&Machine project exploits the support of digitalization to increase the attractiveness of libraries and improve the users' experience. The project implements an application that helps the users in their decision-making process, providing recommendation system (RecSys)-generated lists of books the users might be interested in, and showing them through an interactive Virtual Reality (VR)-based Graphical User Interface (GUI). In this paper, we focus on the design and testing of the recommendation system, employing data about all users' loans over the past 9 years from the network of libraries located in Turin, Italy. In addition, we use data collected by the Anobii online social community of readers, who share their feedback and additional information about books they read. Armed with this heterogeneous data, we build and evaluate Content Based (CB) and Collaborative Filtering (CF) approaches. Our results show that the CF outperforms the CB approach, improving by up to 47\\% the relevant recommendations provided to a reader. However, the performance of the CB approach is heavily dependent on the number of books the reader has already read, and it can work even better than CF for users with a large history. Finally, our evaluations highlight that the performances of both approaches are significantly improved if the system integrates and leverages the information from the Anobii dataset, which allows us to include more user readings (for CF) and richer book metadata (for CB). ",
    "url": "https://arxiv.org/abs/2303.11746",
    "authors": [
      "Alessandro Speciale",
      "Greta Vallero",
      "Luca Vassio",
      "Marco Mellia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11749",
    "title": "Detecting Everything in the Open World: Towards Universal Object  Detection",
    "abstract": "In this paper, we formally address universal object detection, which aims to detect every scene and predict every category. The dependence on human annotations, the limited visual information, and the novel categories in the open world severely restrict the universality of traditional detectors. We propose \\textbf{UniDetector}, a universal object detector that has the ability to recognize enormous categories in the open world. The critical points for the universality of UniDetector are: 1) it leverages images of multiple sources and heterogeneous label spaces for training through the alignment of image and text spaces, which guarantees sufficient information for universal representations. 2) it generalizes to the open world easily while keeping the balance between seen and unseen classes, thanks to abundant information from both vision and language modalities. 3) it further promotes the generalization ability to novel categories through our proposed decoupling training manner and probability calibration. These contributions allow UniDetector to detect over 7k categories, the largest measurable category size so far, with only about 500 classes participating in training. Our UniDetector behaves the strong zero-shot generalization ability on large-vocabulary datasets like LVIS, ImageNetBoxes, and VisualGenome - it surpasses the traditional supervised baselines by more than 4\\% on average without seeing any corresponding images. On 13 public detection datasets with various scenes, UniDetector also achieves state-of-the-art performance with only a 3\\% amount of training data. ",
    "url": "https://arxiv.org/abs/2303.11749",
    "authors": [
      "Zhenyu Wang",
      "Yali Li",
      "Xi Chen",
      "Ser-Nam Lim",
      "Antonio Torralba",
      "Hengshuang Zhao",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11751",
    "title": "Generative AI for Cyber Threat-Hunting in 6G-enabled IoT Networks",
    "abstract": "The next generation of cellular technology, 6G, is being developed to enable a wide range of new applications and services for the Internet of Things (IoT). One of 6G's main advantages for IoT applications is its ability to support much higher data rates and bandwidth as well as to support ultra-low latency. However, with this increased connectivity will come to an increased risk of cyber threats, as attackers will be able to exploit the large network of connected devices. Generative Artificial Intelligence (AI) can be used to detect and prevent cyber attacks by continuously learning and adapting to new threats and vulnerabilities. In this paper, we discuss the use of generative AI for cyber threat-hunting (CTH) in 6G-enabled IoT networks. Then, we propose a new generative adversarial network (GAN) and Transformer-based model for CTH in 6G-enabled IoT Networks. The experimental analysis results with a new cyber security dataset demonstrate that the Transformer-based security model for CTH can detect IoT attacks with a high overall accuracy of 95%. We examine the challenges and opportunities and conclude by highlighting the potential of generative AI in enhancing the security of 6G-enabled IoT networks and call for further research to be conducted in this area. ",
    "url": "https://arxiv.org/abs/2303.11751",
    "authors": [
      "Mohamed Amine Ferrag",
      "Merouane Debbah",
      "Muna Al-Hawawreh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.11754",
    "title": "Projections of Model Spaces for Latent Graph Inference",
    "abstract": "Graph Neural Networks leverage the connectivity structure of graphs as an inductive bias. Latent graph inference focuses on learning an adequate graph structure to diffuse information on and improve the downstream performance of the model. In this work we employ stereographic projections of the hyperbolic and spherical model spaces, as well as products of Riemannian manifolds, for the purpose of latent graph inference. Stereographically projected model spaces achieve comparable performance to their non-projected counterparts, while providing theoretical guarantees that avoid divergence of the spaces when the curvature tends to zero. We perform experiments on both homophilic and heterophilic graphs. ",
    "url": "https://arxiv.org/abs/2303.11754",
    "authors": [
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "\u00c1lvaro Arroyo",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11755",
    "title": "LIMITR: Leveraging Local Information for Medical Image-Text  Representation",
    "abstract": "Medical imaging analysis plays a critical role in the diagnosis and treatment of various medical conditions. This paper focuses on chest X-ray images and their corresponding radiological reports. It presents a new model that learns a joint X-ray image & report representation. The model is based on a novel alignment scheme between the visual data and the text, which takes into account both local and global information. Furthermore, the model integrates domain-specific information of two types -- lateral images and the consistent visual structure of chest images. Our representation is shown to benefit three types of retrieval tasks: text-image retrieval, class-based retrieval, and phrase-grounding. ",
    "url": "https://arxiv.org/abs/2303.11755",
    "authors": [
      "Gefen Dawidowicz",
      "Elad Hirsch",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11757",
    "title": "NSTO: Neural Synthesizing Topology Optimization for Modulated Structure  Generation",
    "abstract": "Nature evolves structures like honeycombs at optimized performance with limited material. These efficient structures can be artificially created with the collaboration of structural topology optimization and additive manufacturing. However, the extensive computation cost of topology optimization causes low mesh resolution, long solving time, and rough boundaries that fail to match the requirements for meeting the growing personal fabrication demands and printing capability. Therefore, we propose the neural synthesizing topology optimization that leverages a self-supervised coordinate-based network to optimize structures with significantly shorter computation time, where the network encodes the structural material layout as an implicit function of coordinates. Continuous solution space is further generated from optimization tasks under varying boundary conditions or constraints for users' instant inference of novel solutions. We demonstrate the system's efficacy for a broad usage scenario through numerical experiments and 3D printing. ",
    "url": "https://arxiv.org/abs/2303.11757",
    "authors": [
      "Shengze Zhong",
      "Parinya Punpongsanon",
      "Daisuke Iwai",
      "Kosuke Sato"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.11759",
    "title": "Simulating Malaria Detection in Laboratories using Deep Learning",
    "abstract": "Malaria is usually diagnosed by a microbiologist by examining a small sample of blood smear. Reducing mortality from malaria infection is possible if it is diagnosed early and followed with appropriate treatment. While the WHO has set audacious goals of reducing malaria incidence and mortality rates by 90% in 2030 and eliminating malaria in 35 countries by that time, it still remains a difficult challenge. Computer-assisted diagnostics are on the rise these days as they can be used effectively as a primary test in the absence of or providing assistance to a physician or pathologist. The purpose of this paper is to describe an approach to detecting, localizing and counting parasitic cells in blood sample images towards easing the burden on healthcare workers. ",
    "url": "https://arxiv.org/abs/2303.11759",
    "authors": [
      "Onyekachukwu R. Okonji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11760",
    "title": "Real-Time Cyberattack Detection with Offline and Online Learning",
    "abstract": "This paper presents several novel algorithms for real-time cyberattack detection using the Auto-Associative Deep Random Neural Network, which were developed in the HORIZON 2020 IoTAC Project. Some of these algorithms require offline learning, while others require the algorithm to learn during its normal operation while it is also testing the flow of incoming traffic to detect possible attacks. Most of the methods we present are designed to be used at a single node, while one specific method collects data from multiple network ports to detect and monitor the spread of a Botnet. The evaluation of the accuracy of all the methods is carried out with real attack traces. These novel methods are also compared with other state-of-the-art approaches, showing that they offer better or equal performance, at lower computational learning and shorter detection times as compared to the existing approaches. ",
    "url": "https://arxiv.org/abs/2303.11760",
    "authors": [
      "Erol Gelenbe",
      "Mert Nak\u0131p"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.11793",
    "title": "OTJR: Optimal Transport Meets Optimal Jacobian Regularization for  Adversarial Robustness",
    "abstract": "Deep neural networks are widely recognized as being vulnerable to adversarial perturbation. To overcome this challenge, developing a robust classifier is crucial. So far, two well-known defenses have been adopted to improve the learning of robust classifiers, namely adversarial training (AT) and Jacobian regularization. However, each approach behaves differently against adversarial perturbations. First, our work carefully analyzes and characterizes these two schools of approaches, both theoretically and empirically, to demonstrate how each approach impacts the robust learning of a classifier. Next, we propose our novel Optimal Transport with Jacobian regularization method, dubbed OTJR, jointly incorporating the input-output Jacobian regularization into the AT by leveraging the optimal transport theory. In particular, we employ the Sliced Wasserstein (SW) distance that can efficiently push the adversarial samples' representations closer to those of clean samples, regardless of the number of classes within the dataset. The SW distance provides the adversarial samples' movement directions, which are much more informative and powerful for the Jacobian regularization. Our extensive experiments demonstrate the effectiveness of our proposed method, which jointly incorporates Jacobian regularization into AT. Furthermore, we demonstrate that our proposed method consistently enhances the model's robustness with CIFAR-100 dataset under various adversarial attack settings, achieving up to 28.49% under AutoAttack. ",
    "url": "https://arxiv.org/abs/2303.11793",
    "authors": [
      "Binh M. Le",
      "Shahroz Tariq",
      "Simon S. Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11803",
    "title": "Fighting over-fitting with quantization for learning deep neural  networks on noisy labels",
    "abstract": "The rising performance of deep neural networks is often empirically attributed to an increase in the available computational power, which allows complex models to be trained upon large amounts of annotated data. However, increased model complexity leads to costly deployment of modern neural networks, while gathering such amounts of data requires huge costs to avoid label noise. In this work, we study the ability of compression methods to tackle both of these problems at once. We hypothesize that quantization-aware training, by restricting the expressivity of neural networks, behaves as a regularization. Thus, it may help fighting overfitting on noisy data while also allowing for the compression of the model at inference. We first validate this claim on a controlled test with manually introduced label noise. Furthermore, we also test the proposed method on Facial Action Unit detection, where labels are typically noisy due to the subtlety of the task. In all cases, our results suggests that quantization significantly improve the results compared with existing baselines, regularization as well as other compression methods. ",
    "url": "https://arxiv.org/abs/2303.11803",
    "authors": [
      "Gauthier Tallec",
      "Edouard Yvinec",
      "Arnaud Dapogny",
      "Kevin Bailly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11811",
    "title": "Efficient and scalable hybrid fluid-particle simulations with  geometrically resolved particles on heterogeneous CPU-GPU architectures",
    "abstract": "In recent years, it has become increasingly popular to accelerate numerical simulations using Graphics Processing Unit (GPU)s. In multiphysics simulations, the various combined methodologies may have distinctly different computational characteristics. Therefore, the best-suited hardware architecture can differ between the simulation components. Furthermore, not all coupled software frameworks may support all hardware. These issues predestinate or even force hybrid implementations, i.e., different simulation components running on different hardware. We introduce a hybrid coupled fluid-particle implementation with geometrically resolved particles. The simulation utilizes GPUs for the fluid dynamics, whereas the particle simulation runs on Central Processing Unit (CPU)s. We examine the performance of two contrasting cases of a fluidized bed simulation on a heterogeneous supercomputer. The hybrid overhead (i.e., the CPU-GPU communication) is negligible. The fluid simulation shows good performance utilizing nearly the entire memory bandwidth. Still, the GPU run time accounts for most of the total time. The parallel efficiency in a weak scaling benchmark for 1024 A100 GPUs is up to 71%. Frequent CPU-CPU communications occurring in the particle simulation are the leading cause of the decrease in parallel efficiency. The results show that hybrid implementations are promising for large-scale multiphysics simulations on heterogeneous supercomputers. ",
    "url": "https://arxiv.org/abs/2303.11811",
    "authors": [
      "Samuel Kemmler",
      "Christoph Rettinger",
      "Harald K\u00f6stler"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.11835",
    "title": "Lipschitz-bounded 1D convolutional neural networks using the Cayley  transform and the controllability Gramian",
    "abstract": "We establish a layer-wise parameterization for 1D convolutional neural networks (CNNs) with built-in end-to-end robustness guarantees. Herein, we use the Lipschitz constant of the input-output mapping characterized by a CNN as a robustness measure. We base our parameterization on the Cayley transform that parameterizes orthogonal matrices and the controllability Gramian for the state space representation of the convolutional layers. The proposed parameterization by design fulfills linear matrix inequalities that are sufficient for Lipschitz continuity of the CNN, which further enables unconstrained training of Lipschitz-bounded 1D CNNs. Finally, we train Lipschitz-bounded 1D CNNs for the classification of heart arrythmia data and show their improved robustness. ",
    "url": "https://arxiv.org/abs/2303.11835",
    "authors": [
      "Patricia Pauli",
      "Ruigang Wang",
      "Ian R. Manchester",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.11848",
    "title": "Dens-PU: PU Learning with Density-Based Positive Labeled Augmentation",
    "abstract": "This study proposes a novel approach for solving the PU learning problem based on an anomaly-detection strategy. Latent encodings extracted from positive-labeled data are linearly combined to acquire new samples. These new samples are used as embeddings to increase the density of positive-labeled data and, thus, define a boundary that approximates the positive class. The further a sample is from the boundary the more it is considered as a negative sample. Once a set of negative samples is obtained, the PU learning problem reduces to binary classification. The approach, named Dens-PU due to its reliance on the density of positive-labeled data, was evaluated using benchmark image datasets, and state-of-the-art results were attained. ",
    "url": "https://arxiv.org/abs/2303.11848",
    "authors": [
      "Vasileios Sevetlidis",
      "George Pavlidis",
      "Spyridon Mouroutsos",
      "Antonios Gasteratos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11853",
    "title": "LoRCoN-LO: Long-term Recurrent Convolutional Network-based LiDAR  Odometry",
    "abstract": "We propose a deep learning-based LiDAR odometry estimation method called LoRCoN-LO that utilizes the long-term recurrent convolutional network (LRCN) structure. The LRCN layer is a structure that can process spatial and temporal information at once by using both CNN and LSTM layers. This feature is suitable for predicting continuous robot movements as it uses point clouds that contain spatial information. Therefore, we built a LoRCoN-LO model using the LRCN layer, and predicted the pose of the robot through this model. For performance verification, we conducted experiments exploiting a public dataset (KITTI). The results of the experiment show that LoRCoN-LO displays accurate odometry prediction in the dataset. The code is available at https://github.com/donghwijung/LoRCoN-LO. ",
    "url": "https://arxiv.org/abs/2303.11853",
    "authors": [
      "Donghwi Jung",
      "Jae-Kyung Cho",
      "Younghwa Jung",
      "Soohyun Shin",
      "Seong-Woo Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11858",
    "title": "Modeling Relational Patterns for Logical Query Answering over Knowledge  Graphs",
    "abstract": "Answering first-order logical (FOL) queries over knowledge graphs (KG) remains a challenging task mainly due to KG incompleteness. Query embedding approaches this problem by computing the low-dimensional vector representations of entities, relations, and logical queries. KGs exhibit relational patterns such as symmetry and composition and modeling the patterns can further enhance the performance of query embedding models. However, the role of such patterns in answering FOL queries by query embedding models has not been yet studied in the literature. In this paper, we fill in this research gap and empower FOL queries reasoning with pattern inference by introducing an inductive bias that allows for learning relation patterns. To this end, we develop a novel query embedding method, RoConE, that defines query regions as geometric cones and algebraic query operators by rotations in complex space. RoConE combines the advantages of Cone as a well-specified geometric representation for query embedding, and also the rotation operator as a powerful algebraic operation for pattern inference. Our experimental results on several benchmark datasets confirm the advantage of relational patterns for enhancing logical query answering task. ",
    "url": "https://arxiv.org/abs/2303.11858",
    "authors": [
      "Yunjie He",
      "Mojtaba Nayyeri",
      "Bo Xiong",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11890",
    "title": "Combining Robust Control and Machine Learning for Uncertain Nonlinear  Systems Subject to Persistent Disturbances",
    "abstract": "This paper proposes a control strategy consisting of a robust controller and an Echo State Network (ESN) based control law for stabilizing a class of uncertain nonlinear discrete-time systems subject to persistent disturbances. Firstly, the robust controller is designed to ensure that the closed-loop system is Input-to-State Stable (ISS) with a guaranteed stability region regardless of the ESN control action and exogenous disturbances. Then, the ESN based controller is trained in order to mitigate the effects of disturbances on the system output. A numerical example demonstrates the potentials of the proposed control design method. ",
    "url": "https://arxiv.org/abs/2303.11890",
    "authors": [
      "A. Banderchuk",
      "D. Coutinho",
      "E. Camponogara"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.11899",
    "title": "Multi-agent Reinforcement Learning for Regional Signal control in  Large-scale Grid Traffic network",
    "abstract": "Adaptive traffic signal control with Multi-agent Reinforcement Learning(MARL) is a very popular topic nowadays. In most existing novel methods, one agent controls single intersections and these methods focus on the cooperation between intersections. However, the non-stationary property of MARL still limits the performance of the above methods as the size of traffic networks grows. One compromised strategy is to assign one agent with a region of intersections to reduce the number of agents. There are two challenges in this strategy, one is how to partition a traffic network into small regions and the other is how to search for the optimal joint actions for a region of intersections. In this paper, we propose a novel training framework RegionLight where our region partition rule is based on the adjacency between the intersection and extended Branching Dueling Q-Network(BDQ) to Dynamic Branching Dueling Q-Network(DBDQ) to bound the growth of the size of joint action space and alleviate the bias introduced by imaginary intersections outside of the boundary of the traffic network. Our experiments on both real datasets and synthetic datasets demonstrate that our framework performs best among other novel frameworks and that our region partition rule is robust. ",
    "url": "https://arxiv.org/abs/2303.11899",
    "authors": [
      "Hankang Gu",
      "Shangbo Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11912",
    "title": "Deephys: Deep Electrophysiology, Debugging Neural Networks under  Distribution Shifts",
    "abstract": "Deep Neural Networks (DNNs) often fail in out-of-distribution scenarios. In this paper, we introduce a tool to visualize and understand such failures. We draw inspiration from concepts from neural electrophysiology, which are based on inspecting the internal functioning of a neural networks by analyzing the feature tuning and invariances of individual units. Deep Electrophysiology, in short Deephys, provides insights of the DNN's failures in out-of-distribution scenarios by comparative visualization of the neural activity in in-distribution and out-of-distribution datasets. Deephys provides seamless analyses of individual neurons, individual images, and a set of set of images from a category, and it is capable of revealing failures due to the presence of spurious features and novel features. We substantiate the validity of the qualitative visualizations of Deephys thorough quantitative analyses using convolutional and transformers architectures, in several datasets and distribution shifts (namely, colored MNIST, CIFAR-10 and ImageNet). ",
    "url": "https://arxiv.org/abs/2303.11912",
    "authors": [
      "Anirban Sarkar",
      "Matthew Groth",
      "Ian Mason",
      "Tomotake Sasaki",
      "Xavier Boix"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11917",
    "title": "Efficient Decision-based Black-box Patch Attacks on Video Recognition",
    "abstract": "Although Deep Neural Networks (DNNs) have demonstrated excellent performance, they are vulnerable to adversarial patches that introduce perceptible and localized perturbations to the input. Generating adversarial patches on images has received much attention, while adversarial patches on videos have not been well investigated. Further, decision-based attacks, where attackers only access the predicted hard labels by querying threat models, have not been well explored on video models either, even if they are practical in real-world video recognition scenes. The absence of such studies leads to a huge gap in the robustness assessment for video models. To bridge this gap, this work first explores decision-based patch attacks on video models. We analyze that the huge parameter space brought by videos and the minimal information returned by decision-based models both greatly increase the attack difficulty and query burden. To achieve a query-efficient attack, we propose a spatial-temporal differential evolution (STDE) framework. First, STDE introduces target videos as patch textures and only adds patches on keyframes that are adaptively selected by temporal difference. Second, STDE takes minimizing the patch area as the optimization objective and adopts spatialtemporal mutation and crossover to search for the global optimum without falling into the local optimum. Experiments show STDE has demonstrated state-of-the-art performance in terms of threat, efficiency and imperceptibility. Hence, STDE has the potential to be a powerful tool for evaluating the robustness of video recognition models. ",
    "url": "https://arxiv.org/abs/2303.11917",
    "authors": [
      "Kaixun Jiang",
      "Zhaoyu Chen",
      "Tony Huang",
      "Jiafeng Wang",
      "Dingkang Yang",
      "Bo Li",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11926",
    "title": "Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D  Object Detection",
    "abstract": "In this paper, we propose a long-sequence modeling framework, named StreamPETR, for multi-view 3D object detection. Built upon the sparse query design in the PETR series, we systematically develop an object-centric temporal mechanism. The model is performed in an online manner and the long-term historical information is propagated through object queries frame by frame. Besides, we introduce a motion-aware layer normalization to model the movement of the objects. StreamPETR achieves significant performance improvements only with negligible computation cost, compared to the single-frame baseline. On the standard nuScenes benchmark, it reaches a new state-of-the-art performance (63.6% NDS). The lightweight version realizes 45.0% mAP and 31.7 FPS, outperforming the state-of-the-art method (SOLOFusion) by 2.3% mAP and 1.8x faster FPS. Code will be available at https://github.com/exiawsh/StreamPETR.git. ",
    "url": "https://arxiv.org/abs/2303.11926",
    "authors": [
      "Shihao Wang",
      "Yingfei Liu",
      "Tiancai Wang",
      "Ying Li",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11943",
    "title": "Data assimilation for sparsification of reaction diffusion systems in a  complex network",
    "abstract": "The study focuses on complex networks that are underlying graphs with an embedded dynamical system. We aim to reduce the number of edges in the network while minimizing its impact on network dynamics. We present an algorithmic framework that produces sparse graphs meaning graphs with fewer edges on reaction-diffusion complex systems on undirected graphs. We formulate the sparsification problem as a data assimilation problem on a Reduced order model space(ROM) space along with constraints targeted towards preserving the eigenmodes of the Laplacian matrix under perturbations(L = D - A, where D is the diagonal matrix of degrees and A is the adjacency matrix of the graph). We propose approximations for finding the eigenvalues and eigenvectors of the Laplacian matrix subject to perturbations. We demonstrate the effectiveness of our approach on several real-world graphs. ",
    "url": "https://arxiv.org/abs/2303.11943",
    "authors": [
      "Abhishek Ajayakumar",
      "Soumyendu Raha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.11945",
    "title": "Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and  Cross-Attention",
    "abstract": "Massive rumors usually appear along with breaking news or trending topics, seriously hindering the truth. Existing rumor detection methods are mostly focused on the same domain, and thus have poor performance in cross-domain scenarios due to domain shift. In this work, we propose an end-to-end instance-wise and prototype-wise contrastive learning model with a cross-attention mechanism for cross-domain rumor detection. The model not only performs cross-domain feature alignment but also enforces target samples to align with the corresponding prototypes of a given source domain. Since target labels in a target domain are unavailable, we use a clustering-based approach with carefully initialized centers by a batch of source domain samples to produce pseudo labels. Moreover, we use a cross-attention mechanism on a pair of source data and target data with the same labels to learn domain-invariant representations. Because the samples in a domain pair tend to express similar semantic patterns, especially on the people's attitudes (e.g., supporting or denying) towards the same category of rumors, the discrepancy between a pair of the source domain and target domain will be decreased. We conduct experiments on four groups of cross-domain datasets and show that our proposed model achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2303.11945",
    "authors": [
      "Hongyan Ran",
      "Caiyan Jia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11949",
    "title": "A fuzzy adaptive evolutionary-based feature selection and machine  learning framework for single and multi-objective body fat prediction",
    "abstract": "Predicting body fat can provide medical practitioners and users with essential information for preventing and diagnosing heart diseases. Hybrid machine learning models offer better performance than simple regression analysis methods by selecting relevant body measurements and capturing complex nonlinear relationships among selected features in modelling body fat prediction problems. There are, however, some disadvantages to them. Current machine learning. Modelling body fat prediction as a combinatorial single- and multi-objective optimisation problem often gets stuck in local optima. When multiple feature subsets produce similar or close predictions, avoiding local optima becomes more complex. Evolutionary feature selection has been used to solve several machine-learning-based optimisation problems. A fuzzy set theory determines appropriate levels of exploration and exploitation while managing parameterisation and computational costs. A weighted-sum body fat prediction approach was explored using evolutionary feature selection, fuzzy set theory, and machine learning algorithms, integrating contradictory metrics into a single composite goal optimised by fuzzy adaptive evolutionary feature selection. Hybrid fuzzy adaptive global learning local search universal diversity-based feature selection is applied to this single-objective feature selection-machine learning framework (FAGLSUD-based FS-ML). While using fewer features, this model achieved a more accurate and stable estimate of body fat percentage than other hybrid and state-of-the-art machine learning models. A multi-objective FAGLSUD-based FS-MLP is also proposed to analyse accuracy, stability, and dimensionality conflicts simultaneously. To make informed decisions about fat deposits in the most vital body parts and blood lipid levels, medical practitioners and users can use a well-distributed Pareto set of trade-off solutions. ",
    "url": "https://arxiv.org/abs/2303.11949",
    "authors": [
      "Farshid Keivanian",
      "Raymond Chiong",
      "Zongwen Fan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11950",
    "title": "Learning A Sparse Transformer Network for Effective Image Deraining",
    "abstract": "Transformers-based methods have achieved significant performance in image deraining as they can model the non-local information which is vital for high-quality image reconstruction. In this paper, we find that most existing Transformers usually use all similarities of the tokens from the query-key pairs for the feature aggregation. However, if the tokens from the query are different from those of the key, the self-attention values estimated from these tokens also involve in feature aggregation, which accordingly interferes with the clear image restoration. To overcome this problem, we propose an effective DeRaining network, Sparse Transformer (DRSformer) that can adaptively keep the most useful self-attention values for feature aggregation so that the aggregated features better facilitate high-quality image reconstruction. Specifically, we develop a learnable top-k selection operator to adaptively retain the most crucial attention scores from the keys for each query for better feature aggregation. Simultaneously, as the naive feed-forward network in Transformers does not model the multi-scale information that is important for latent clear image restoration, we develop an effective mixed-scale feed-forward network to generate better features for image deraining. To learn an enriched set of hybrid features, which combines local context from CNN operators, we equip our model with mixture of experts feature compensator to present a cooperation refinement deraining scheme. Extensive experimental results on the commonly used benchmarks demonstrate that the proposed method achieves favorable performance against state-of-the-art approaches. The source code and trained models are available at https://github.com/cschenxiang/DRSformer. ",
    "url": "https://arxiv.org/abs/2303.11950",
    "authors": [
      "Xiang Chen",
      "Hao Li",
      "Mingqiang Li",
      "Jinshan Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11963",
    "title": "NEMTO: Neural Environment Matting for Novel View and Relighting  Synthesis of Transparent Objects",
    "abstract": "We propose NEMTO, the first end-to-end neural rendering pipeline to model 3D transparent objects with complex geometry and unknown indices of refraction. Commonly used appearance modeling such as the Disney BSDF model cannot accurately address this challenging problem due to the complex light paths bending through refractions and the strong dependency of surface appearance on illumination. With 2D images of the transparent object as input, our method is capable of high-quality novel view and relighting synthesis. We leverage implicit Signed Distance Functions (SDF) to model the object geometry and propose a refraction-aware ray bending network to model the effects of light refraction within the object. Our ray bending network is more tolerant to geometric inaccuracies than traditional physically-based methods for rendering transparent objects. We provide extensive evaluations on both synthetic and real-world datasets to demonstrate our high-quality synthesis and the applicability of our method. ",
    "url": "https://arxiv.org/abs/2303.11963",
    "authors": [
      "Dongqing Wang",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.11966",
    "title": "Multi-Robot Planning on Dynamic Topological Graphs using Mixed-Integer  Programming",
    "abstract": "Planning for multi-robot teams in complex environments is a challenging problem, especially when these teams must coordinate to accomplish a common objective. In general, optimal solutions to these planning problems are computationally intractable, since the decision space grows exponentially with the number of robots. In this paper, we present a novel approach for multi-robot planning on topological graphs using mixed-integer programming. Central to our approach is the notion of a dynamic topological graph, where edge weights vary dynamically based on the locations of the robots in the graph. We construct this graph using the critical features of the planning problem and the relationships between robots; we then leverage mixed-integer programming to minimize a shared cost that depends on the paths of all robots through the graph. To improve computational tractability, we formulated an objective function with a fully convex relaxation and designed our decision space around eliminating the exponential dependence on the number of robots. We test our approach on a multi-robot reconnaissance scenario, where robots must coordinate to minimize detectability and maximize safety while gathering information. We demonstrate that our approach is able to scale to a series of representative scenarios and is capable of computing optimal coordinated strategic behaviors for autonomous multi-robot teams in seconds. ",
    "url": "https://arxiv.org/abs/2303.11966",
    "authors": [
      "Cora A. Dimmig",
      "Kevin C. Wolfe",
      "Joseph Moore"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.11969",
    "title": "Explain To Me: Salience-Based Explainability for Synthetic Face  Detection Models",
    "abstract": "The performance of convolutional neural networks has continued to improve over the last decade. At the same time, as model complexity grows, it becomes increasingly more difficult to explain model decisions. Such explanations may be of critical importance for reliable operation of human-machine pairing setups, or for model selection when the \"best\" model among many equally-accurate models must be established. Saliency maps represent one popular way of explaining model decisions by highlighting image regions models deem important when making a prediction. However, examining salience maps at scale is not practical. In this paper, we propose five novel methods of leveraging model salience to explain a model behavior at scale. These methods ask: (a) what is the average entropy for a model's salience maps, (b) how does model salience change when fed out-of-set samples, (c) how closely does model salience follow geometrical transformations, (d) what is the stability of model salience across independent training runs, and (e) how does model salience react to salience-guided image degradations. To assess the proposed measures on a concrete and topical problem, we conducted a series of experiments for the task of synthetic face detection with two types of models: those trained traditionally with cross-entropy loss, and those guided by human salience when training to increase model generalizability. These two types of models are characterized by different, interpretable properties of their salience maps, which allows for the evaluation of the correctness of the proposed measures. We offer source codes for each measure along with this paper. ",
    "url": "https://arxiv.org/abs/2303.11969",
    "authors": [
      "Colton Crum",
      "Patrick Tinsley",
      "Aidan Boyd",
      "Jacob Piland",
      "Christopher Sweet",
      "Timothy Kelley",
      "Kevin Bowyer",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11971",
    "title": "Defect Detection Approaches Based on Simulated Reference Image",
    "abstract": "This work is addressing the problem of defect anomaly detection based on a clean reference image. Specifically, we focus on SEM semiconductor defects in addition to several natural image anomalies. There are well-known methods to create a simulation of an artificial reference image by its defect specimen. In this work, we introduce several applications for this capability, that the simulated reference is beneficial for improving their results. Among these defect detection methods are classic computer vision applied on difference-image, supervised deep-learning (DL) based on human labels, and unsupervised DL which is trained on feature-level patterns of normal reference images. We show in this study how to incorporate correctly the simulated reference image for these defect and anomaly detection applications. As our experiment demonstrates, simulated reference achieves higher performance than the real reference of an image of a defect and anomaly. This advantage of simulated reference occurs mainly due to the less noise and geometric variations together with better alignment and registration to the original defect background. ",
    "url": "https://arxiv.org/abs/2303.11971",
    "authors": [
      "Nati Ofir",
      "Yotam Ben Shoshan",
      "Ran Badanes",
      "Boris Sherman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.11977",
    "title": "Deep trip generation with graph neural networks for bike sharing system  expansion",
    "abstract": "Bike sharing is emerging globally as an active, convenient, and sustainable mode of transportation. To plan successful bike-sharing systems (BSSs), many cities start from a small-scale pilot and gradually expand the system to cover more areas. For station-based BSSs, this means planning new stations based on existing ones over time, which requires prediction of the number of trips generated by these new stations across the whole system. Previous studies typically rely on relatively simple regression or machine learning models, which are limited in capturing complex spatial relationships. Despite the growing literature in deep learning methods for travel demand prediction, they are mostly developed for short-term prediction based on time series data, assuming no structural changes to the system. In this study, we focus on the trip generation problem for BSS expansion, and propose a graph neural network (GNN) approach to predicting the station-level demand based on multi-source urban built environment data. Specifically, it constructs multiple localized graphs centered on each target station and uses attention mechanisms to learn the correlation weights between stations. We further illustrate that the proposed approach can be regarded as a generalized spatial regression model, indicating the commonalities between spatial regression and GNNs. The model is evaluated based on realistic experiments using multi-year BSS data from New York City, and the results validate the superior performance of our approach compared to existing methods. We also demonstrate the interpretability of the model for uncovering the effects of built environment features and spatial interactions between stations, which can provide strategic guidance for BSS station location selection and capacity planning. ",
    "url": "https://arxiv.org/abs/2303.11977",
    "authors": [
      "Yuebing Liang",
      "Fangyi Ding",
      "Guan Huang",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11982",
    "title": "Quantized Zero Dynamics Attacks against Sampled-data Control Systems",
    "abstract": "For networked control systems, cyber-security issues have gained much attention in recent years. In this paper, we consider the so-called zero dynamics attacks, which form an important class of false data injection attacks, with a special focus on the effects of quantization in a sampled-data control setting. When the attack signals must be quantized, some error will be necessarily introduced, potentially increasing the chance of detection through the output of the system. In this paper, we show however that the attacker may reduce such errors by avoiding to directly quantize the attack signal. We look at two approaches for generating quantized attacks which can keep the error in the output smaller than a specified level by using the knowledge of the system dynamics. The methods are based on a dynamic quantization technique and a modified version of zero dynamics attacks. Numerical examples are provided to verify the effectiveness of the proposed methods. ",
    "url": "https://arxiv.org/abs/2303.11982",
    "authors": [
      "Kosuke Kimura",
      "Hideaki Ishii"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.12001",
    "title": "Visual Representation Learning from Unlabeled Video using Contrastive  Masked Autoencoders",
    "abstract": "Masked Autoencoders (MAEs) learn self-supervised representations by randomly masking input image patches and a reconstruction loss. Alternatively, contrastive learning self-supervised methods encourage two versions of the same input to have a similar representation, while pulling apart the representations for different inputs. We propose ViC-MAE, a general method that combines both MAE and contrastive learning by pooling the local feature representations learned under the MAE reconstruction objective and leveraging this global representation under a contrastive objective across video frames. We show that visual representations learned under ViC-MAE generalize well to both video classification and image classification tasks. Using a backbone ViT-B/16 network pre-trained on the Moments in Time (MiT) dataset, we obtain state-of-the-art transfer learning from video to images on Imagenet-1k by improving 1.58% in absolute top-1 accuracy from a recent previous work. Moreover, our method maintains a competitive transfer-learning performance of 81.50% top-1 accuracy on the Kinetics-400 video classification benchmark. In addition, we show that despite its simplicity, ViC-MAE yields improved results compared to combining MAE pre-training with previously proposed contrastive objectives such as VicReg and SiamSiam. ",
    "url": "https://arxiv.org/abs/2303.12001",
    "authors": [
      "Jefferson Hernandez",
      "Ruben Villegas",
      "Vicente Ordonez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12012",
    "title": "NeAT: Learning Neural Implicit Surfaces with Arbitrary Topologies from  Multi-view Images",
    "abstract": "Recent progress in neural implicit functions has set new state-of-the-art in reconstructing high-fidelity 3D shapes from a collection of images. However, these approaches are limited to closed surfaces as they require the surface to be represented by a signed distance field. In this paper, we propose NeAT, a new neural rendering framework that can learn implicit surfaces with arbitrary topologies from multi-view images. In particular, NeAT represents the 3D surface as a level set of a signed distance function (SDF) with a validity branch for estimating the surface existence probability at the query positions. We also develop a novel neural volume rendering method, which uses SDF and validity to calculate the volume opacity and avoids rendering points with low validity. NeAT supports easy field-to-mesh conversion using the classic Marching Cubes algorithm. Extensive experiments on DTU, MGN, and Deep Fashion 3D datasets indicate that our approach is able to faithfully reconstruct both watertight and non-watertight surfaces. In particular, NeAT significantly outperforms the state-of-the-art methods in the task of open surface reconstruction both quantitatively and qualitatively. ",
    "url": "https://arxiv.org/abs/2303.12012",
    "authors": [
      "Xiaoxu Meng",
      "Weikai Chen",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.12016",
    "title": "Automatic evaluation of herding behavior in towed fishing gear using  end-to-end training of CNN and attention-based networks",
    "abstract": "This paper considers the automatic classification of herding behavior in the cluttered low-visibility environment that typically surrounds towed fishing gear. The paper compares three convolutional and attention-based deep action recognition network architectures trained end-to-end on a small set of video sequences captured by a remotely controlled camera and classified by an expert in fishing technology. The sequences depict a scene in front of a fishing trawl where the conventional herding mechanism has been replaced by directed laser light. The goal is to detect the presence of a fish in the sequence and classify whether or not the fish reacts to the lasers. A two-stream CNN model, a CNN-transformer hybrid, and a pure transformer model were trained end-to-end to achieve 63%, 54%, and 60% 10-fold classification accuracy on the three-class task when compared to the human expert. Inspection of the activation maps learned by the three networks raises questions about the attributes of the sequences the models may be learning, specifically whether changes in viewpoint introduced by human camera operators that affect the position of laser lines in the video frames may interfere with the classification. This underlines the importance of careful experimental design when capturing scientific data for automatic end-to-end evaluation and the usefulness of inspecting the trained models. ",
    "url": "https://arxiv.org/abs/2303.12016",
    "authors": [
      "Orri Steinn Gu\u00f0finnsson",
      "T\u00fdr Vilhj\u00e1lmsson",
      "Martin Eineborg",
      "Torfi Thorhallsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12021",
    "title": "Graph Kalman Filters",
    "abstract": "The well-known Kalman filters model dynamical systems by relying on state-space representations with the next state updated, and its uncertainty controlled, by fresh information associated with newly observed system outputs. This paper generalizes, for the first time in the literature, Kalman and extended Kalman filters to discrete-time settings where inputs, states, and outputs are represented as attributed graphs whose topology and attributes can change with time. The setup allows us to adapt the framework to cases where the output is a vector or a scalar too (node/graph level tasks). Within the proposed theoretical framework, the unknown state-transition and the readout functions are learned end-to-end along with the downstream prediction task. ",
    "url": "https://arxiv.org/abs/2303.12021",
    "authors": [
      "Cesare Alippi",
      "Daniele Zambon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.12029",
    "title": "Wearing Masks Implies Refuting Trump?: Towards Target-specific User  Stance Prediction across Events in COVID-19 and US Election 2020",
    "abstract": "People who share similar opinions towards controversial topics could form an echo chamber and may share similar political views toward other topics as well. The existence of such connections, which we call connected behavior, gives researchers a unique opportunity to predict how one would behave for a future event given their past behaviors. In this work, we propose a framework to conduct connected behavior analysis. Neural stance detection models are trained on Twitter data collected on three seemingly independent topics, i.e., wearing a mask, racial equality, and Trump, to detect people's stance, which we consider as their online behavior in each topic-related event. Our results reveal a strong connection between the stances toward the three topical events and demonstrate the power of past behaviors in predicting one's future behavior. ",
    "url": "https://arxiv.org/abs/2303.12029",
    "authors": [
      "Hong Zhang",
      "Haewoon Kwak",
      "Wei Gao",
      "Jisun An"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.12054",
    "title": "Influencer Backdoor Attack on Semantic Segmentation",
    "abstract": "When a small number of poisoned samples are injected into the training dataset of a deep neural network, the network can be induced to exhibit malicious behavior during inferences, which poses potential threats to real-world applications. While they have been intensively studied in classification, backdoor attacks on semantic segmentation have been largely overlooked. Unlike classification, semantic segmentation aims to classify every pixel within a given image. In this work, we explore backdoor attacks on segmentation models to misclassify all pixels of a victim class by injecting a specific trigger on non-victim pixels during inferences, which is dubbed Influencer Backdoor Attack (IBA). IBA is expected to maintain the classification accuracy of non-victim pixels and misleads classifications of all victim pixels in every single inference. Specifically, we consider two types of IBA scenarios, i.e., 1) Free-position IBA: the trigger can be positioned freely except for pixels of the victim class, and 2) Long-distance IBA: the trigger can only be positioned somewhere far from victim pixels, given the possible practical constraint. Based on the context aggregation ability of segmentation models, we propose techniques to improve IBA for the scenarios. Concretely, for free-position IBA, we propose a simple, yet effective Nearest Neighbor trigger injection strategy for poisoned sample creation. For long-distance IBA, we propose a novel Pixel Random Labeling strategy. Our extensive experiments reveal that current segmentation models do suffer from backdoor attacks, and verify that our proposed techniques can further increase attack performance. ",
    "url": "https://arxiv.org/abs/2303.12054",
    "authors": [
      "Haoheng Lan",
      "Jindong Gu",
      "Philip Torr",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12059",
    "title": "Motion Matters: Neural Motion Transfer for Better Camera Physiological  Sensing",
    "abstract": "Machine learning models for camera-based physiological measurement can have weak generalization due to a lack of representative training data. Body motion is one of the most significant sources of noise when attempting to recover the subtle cardiac pulse from a video. We explore motion transfer as a form of data augmentation to introduce motion variation while preserving physiological changes. We adapt a neural video synthesis approach to augment videos for the task of remote photoplethysmography (PPG) and study the effects of motion augmentation with respect to 1) the magnitude and 2) the type of motion. After training on motion-augmented versions of publicly available datasets, the presented inter-dataset results on five benchmark datasets show improvements of up to 75% over existing state-of-the-art results. Our findings illustrate the utility of motion transfer as a data augmentation technique for improving the generalization of models for camera-based physiological sensing. We release our code and pre-trained models for using motion transfer as a data augmentation technique on our project page: https://motion-matters.github.io/ ",
    "url": "https://arxiv.org/abs/2303.12059",
    "authors": [
      "Akshay Paruchuri",
      "Xin Liu",
      "Yulu Pan",
      "Shwetak Patel",
      "Daniel McDuff",
      "Soumyadip Sengupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12076",
    "title": "Dexterity from Touch: Self-Supervised Pre-Training of Tactile  Representations with Robotic Play",
    "abstract": "Teaching dexterity to multi-fingered robots has been a longstanding challenge in robotics. Most prominent work in this area focuses on learning controllers or policies that either operate on visual observations or state estimates derived from vision. However, such methods perform poorly on fine-grained manipulation tasks that require reasoning about contact forces or about objects occluded by the hand itself. In this work, we present T-Dex, a new approach for tactile-based dexterity, that operates in two phases. In the first phase, we collect 2.5 hours of play data, which is used to train self-supervised tactile encoders. This is necessary to bring high-dimensional tactile readings to a lower-dimensional embedding. In the second phase, given a handful of demonstrations for a dexterous task, we learn non-parametric policies that combine the tactile observations with visual ones. Across five challenging dexterous tasks, we show that our tactile-based dexterity models outperform purely vision and torque-based models by an average of 1.7X. Finally, we provide a detailed analysis on factors critical to T-Dex including the importance of play data, architectures, and representation learning. ",
    "url": "https://arxiv.org/abs/2303.12076",
    "authors": [
      "Irmak Guzey",
      "Ben Evans",
      "Soumith Chintala",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12077",
    "title": "VAD: Vectorized Scene Representation for Efficient Autonomous Driving",
    "abstract": "Autonomous driving requires a comprehensive understanding of the surrounding environment for reliable trajectory planning. Previous works rely on dense rasterized scene representation (e.g., agent occupancy and semantic map) to perform planning, which is computationally intensive and misses the instance-level structure information. In this paper, we propose VAD, an end-to-end vectorized paradigm for autonomous driving, which models the driving scene as fully vectorized representation. The proposed vectorized paradigm has two significant advantages. On one hand, VAD exploits the vectorized agent motion and map elements as explicit instance-level planning constraints which effectively improves planning safety. On the other hand, VAD runs much faster than previous end-to-end planning methods by getting rid of computation-intensive rasterized representation and hand-designed post-processing steps. VAD achieves state-of-the-art end-to-end planning performance on the nuScenes dataset, outperforming the previous best method by a large margin (reducing the average collision rate by 48.4%). Besides, VAD greatly improves the inference speed (up to 9.3x), which is critical for the real-world deployment of an autonomous driving system. Code and models will be released for facilitating future research. ",
    "url": "https://arxiv.org/abs/2303.12077",
    "authors": [
      "Bo Jiang",
      "Shaoyu Chen",
      "Qing Xu",
      "Bencheng Liao",
      "Jiajie Chen",
      "Helong Zhou",
      "Qian Zhang",
      "Wenyu Liu",
      "Chang Huang",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11409",
    "title": "Supercomputing tensor networks for U(1) symmetric quantum many-body  systems",
    "abstract": "Simulation of many-body systems is extremely computationally intensive, and tensor network schemes have long been used to make these tasks more tractable via approximation. Recently, tensor network algorithms that can exploit the inherent symmetries of the underlying quantum systems have been proposed to further reduce computational complexity. One class of systems, namely those exhibiting a global U(1) symmetry, is especially interesting. We provide a state-of-the-art, graphical processing unit-accelerated, and highly parallel supercomputer implementation of the tensor network algorithm that takes advantage of U(1) symmetry, opening up the possibility of a wide range of quantum systems for future numerical investigations. ",
    "url": "https://arxiv.org/abs/2303.11409",
    "authors": [
      "Minzhao Liu",
      "Changhun Oh",
      "Junyu Liu",
      "Liang Jiang",
      "Yuri Alexeev"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2303.11423",
    "title": "Heart Murmur and Abnormal PCG Detection via Wavelet Scattering Transform  & a 1D-CNN",
    "abstract": "This work leverages deep learning (DL) techniques in order to do automatic and accurate heart murmur detection from phonocardiogram (PCG) recordings. Two public PCG datasets (CirCor Digiscope 2022 dataset and PCG 2016 dataset) from Physionet online database are utilized to train and test three custom neural networks (NN): a 1D convolutional neural network (CNN), a long short-term memory (LSTM) recurrent neural network (RNN), and a convolutional RNN (C-RNN). Under our proposed method, we first do pre-processing on both datasets in order to prepare the data for the NNs. Key pre-processing steps include the following: denoising, segmentation, re-labeling of noise-only segments, data normalization, and time-frequency analysis of the PCG segments using wavelet scattering transform. To evaluate the performance of the three NNs we have implemented, we conduct four experiments, first three using PCG 2022 dataset, and fourth using PCG 2016 dataset. It turns out that our custom 1D-CNN outperforms other two NNs (LSTM- RNN and C-RNN) as well as the state-of-the-art. Specifically, for experiment E1 (murmur detection using original PCG 2022 dataset), our 1D-CNN model achieves an accuracy of 82.28%, weighted accuracy of 83.81%, F1-score of 65.79%, and and area under receive operating charactertic (AUROC) curve of 90.79%. For experiment E2 (mumur detection using PCG 2022 dataset with unknown class removed), our 1D-CNN model achieves an accuracy of 87.05%, F1-score of 87.72%, and AUROC of 94.4%. For experiment E3 (murmur detection using PCG 2022 dataset with re-labeling of segments), our 1D-CNN model achieves an accuracy of 82.86%, weighted accuracy of 86.30%, F1-score of 81.87%, and AUROC of 93.45%. For experiment E4 (abnormal PCG detection using PCG 2016 dataset), our 1D-CNN model achieves an accuracy of 96.30%, F1-score of 96.29% and AUROC of 98.17%. ",
    "url": "https://arxiv.org/abs/2303.11423",
    "authors": [
      "Ahmed Patwa",
      "Muhammad Mahboob Ur Rahman",
      "Tareq Y. Al-Naffouri"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11427",
    "title": "Learning Model-Free Robust Precoding for Cooperative Multibeam Satellite  Communications",
    "abstract": "Direct Low Earth Orbit satellite-to-handheld links are expected to be part of a new era in satellite communications. Space-Division Multiple Access precoding is a technique that reduces interference among satellite beams, therefore increasing spectral efficiency by allowing cooperating satellites to reuse frequency. Over the past decades, optimal precoding solutions with perfect channel state information have been proposed for several scenarios, whereas robust precoding with only imperfect channel state information has been mostly studied for simplified models. In particular, for Low Earth Orbit satellite applications such simplified models might not be accurate. In this paper, we use the function approximation capabilities of the Soft Actor-Critic deep Reinforcement Learning algorithm to learn robust precoding with no knowledge of the system imperfections. ",
    "url": "https://arxiv.org/abs/2303.11427",
    "authors": [
      "Steffen Gracla",
      "Alea Schr\u00f6der",
      "Maik R\u00f6per",
      "Carsten Bockelmann",
      "Dirk W\u00fcbben",
      "Armin Dekorsy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11429",
    "title": "Machine learning-based detection of cardiovascular disease using ECG  signals: performance vs. complexity",
    "abstract": "Cardiovascular disease remains a significant problem in modern society. Among non-invasive techniques, the electrocardiogram (ECG) is one of the most reliable methods for detecting abnormalities in cardiac activities. However, ECG interpretation requires expert knowledge and it is time-consuming. Developing a novel method to detect the disease early could prevent death and complication. The paper presents novel various approaches for classifying cardiac diseases from ECG recordings. The first approach suggests the Poincare representation of ECG signal and deep-learning-based image classifiers (ResNet50 and DenseNet121 were learned over Poincare diagrams), which showed decent performance in predicting AF (atrial fibrillation) but not other types of arrhythmia. XGBoost, a gradient-boosting model, showed an acceptable performance in long-term data but had a long inference time due to highly-consuming calculation within the pre-processing phase. Finally, the 1D convolutional model, specifically the 1D ResNet, showed the best results in both studied CinC 2017 and CinC 2020 datasets, reaching the F1 score of 85% and 71%, respectively, and that was superior to the first-ranking solution of each challenge. The paper also investigated efficiency metrics such as power consumption and equivalent CO2 emissions, with one-dimensional models like 1D CNN and 1D ResNet being the most energy efficient. Model interpretation analysis showed that the DenseNet detected AF using heart rate variability while the 1DResNet assessed AF pattern in raw ECG signals. ",
    "url": "https://arxiv.org/abs/2303.11429",
    "authors": [
      "Huy Pham",
      "Konstantin Egorov",
      "Alexey Kazakov",
      "Semen Budennyy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11448",
    "title": "Geometrical aspects of lattice gauge equivariant convolutional neural  networks",
    "abstract": "Lattice gauge equivariant convolutional neural networks (L-CNNs) are a framework for convolutional neural networks that can be applied to non-Abelian lattice gauge theories without violating gauge symmetry. We demonstrate how L-CNNs can be equipped with global group equivariance. This allows us to extend the formulation to be equivariant not just under translations but under global lattice symmetries such as rotations and reflections. Additionally, we provide a geometric formulation of L-CNNs and show how convolutions in L-CNNs arise as a special case of gauge equivariant neural networks on SU($N$) principal bundles. ",
    "url": "https://arxiv.org/abs/2303.11448",
    "authors": [
      "Jimmy Aronsson",
      "David I. M\u00fcller",
      "Daniel Schuh"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.11473",
    "title": "Sandwiched Video Compression: Efficiently Extending the Reach of  Standard Codecs with Neural Wrappers",
    "abstract": "We propose sandwiched video compression -- a video compression system that wraps neural networks around a standard video codec. The sandwich framework consists of a neural pre- and post-processor with a standard video codec between them. The networks are trained jointly to optimize a rate-distortion loss function with the goal of significantly improving over the standard codec in various compression scenarios. End-to-end training in this setting requires a differentiable proxy for the standard video codec, which incorporates temporal processing with motion compensation, inter/intra mode decisions, and in-loop filtering. We propose differentiable approximations to key video codec components and demonstrate that the neural codes of the sandwich lead to significantly better rate-distortion performance compared to compressing the original frames of the input video in two important scenarios. When transporting high-resolution video via low-resolution HEVC, the sandwich system obtains 6.5 dB improvements over standard HEVC. More importantly, using the well-known perceptual similarity metric, LPIPS, we observe $~30 \\%$ improvements in rate at the same quality over HEVC. Last but not least we show that pre- and post-processors formed by very modestly-parameterized, light-weight networks can closely approximate these results. ",
    "url": "https://arxiv.org/abs/2303.11473",
    "authors": [
      "Berivan Isik",
      "Onur G. Guleryuz",
      "Danhang Tang",
      "Jonathan Taylor",
      "Philip A. Chou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.11475",
    "title": "Explosive cooperation in social dilemmas on higher-order networks",
    "abstract": "Understanding how cooperative behaviours can emerge from competitive interactions is an open problem in biology and social sciences. While interactions are usually modelled as pairwise networks, the units of many real-world systems can also interact in groups of three or more. Here, we introduce a general framework to extend pairwise games to higher-order networks. By studying social dilemmas on hypergraphs with a tunable structure, we find an explosive transition to cooperation triggered by a critical number of higher-order games. The associated bistable regime implies that an initial critical mass of cooperators is also required for the emergence of prosocial behavior. Our results show that higher-order interactions provide a novel explanation for the survival of cooperation. ",
    "url": "https://arxiv.org/abs/2303.11475",
    "authors": [
      "Andrea Civilini",
      "Onkar Sadekar",
      "Federico Battiston",
      "Jes\u00fas G\u00f3mez-Garde\u00f1es",
      "Vito Latora"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2303.11592",
    "title": "Lightweight Hybrid Video Compression Framework Using Reference-Guided  Restoration Network",
    "abstract": "Recent deep-learning-based video compression methods brought coding gains over conventional codecs such as AVC and HEVC. However, learning-based codecs generally require considerable computation time and model complexity. In this paper, we propose a new lightweight hybrid video codec consisting of a conventional video codec(HEVC / VVC), a lossless image codec, and our new restoration network. Precisely, our encoder consists of the conventional video encoder and a lossless image encoder, transmitting a lossy-compressed video bitstream along with a losslessly-compressed reference frame. The decoder is constructed with corresponding video/image decoders and a new restoration network, which enhances the compressed video in two-step processes. In the first step, a network trained with a large video dataset restores the details lost by the conventional encoder. Then, we further boost the video quality with the guidance of a reference image, which is a losslessly compressed video frame. The reference image provides video-specific information, which can be utilized to better restore the details of a compressed video. Experimental results show that the proposed method achieves comparable performance to top-tier methods, even when applied to HEVC. Nevertheless, our method has lower complexity, a faster run time, and can be easily integrated into existing conventional codecs. ",
    "url": "https://arxiv.org/abs/2303.11592",
    "authors": [
      "Hochang Rhee",
      "Seyun Kim",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11699",
    "title": "Neural networks trained on synthetically generated crystals can extract  structural information from ICSD powder X-ray diffractograms",
    "abstract": "Machine learning techniques have successfully been used to extract structural information such as the crystal space group from powder X-ray diffractograms. However, training directly on simulated diffractograms from databases such as the ICSD is challenging due to its limited size, class-inhomogeneity, and bias toward certain structure types. We propose an alternative approach of generating synthetic crystals with random coordinates by using the symmetry operations of each space group. Based on this approach, we demonstrate online training of deep ResNet-like models on up to a few million unique on-the-fly generated synthetic diffractograms per hour. For our chosen task of space group classification, we achieved a test accuracy of 79.9% on unseen ICSD structure types from most space groups. This surpasses the 56.1% accuracy of the current state-of-the-art approach of training on ICSD crystals directly. Our results demonstrate that synthetically generated crystals can be used to extract structural information from ICSD powder diffractograms, which makes it possible to apply very large state-of-the-art machine learning models in the area of powder X-ray diffraction. We further show first steps toward applying our methodology to experimental data, where automated XRD data analysis is crucial, especially in high-throughput settings. While we focused on the prediction of the space group, our approach has the potential to be extended to related tasks in the future. ",
    "url": "https://arxiv.org/abs/2303.11699",
    "authors": [
      "Henrik Schopmans",
      "Patrick Reiser",
      "Pascal Friederich"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11701",
    "title": "A High-Frequency Focused Network for Lightweight Single Image  Super-Resolution",
    "abstract": "Lightweight neural networks for single-image super-resolution (SISR) tasks have made substantial breakthroughs in recent years. Compared to low-frequency information, high-frequency detail is much more difficult to reconstruct. Most SISR models allocate equal computational resources for low-frequency and high-frequency information, which leads to redundant processing of simple low-frequency information and inadequate recovery of more challenging high-frequency information. We propose a novel High-Frequency Focused Network (HFFN) through High-Frequency Focused Blocks (HFFBs) that selectively enhance high-frequency information while minimizing redundant feature computation of low-frequency information. The HFFB effectively allocates more computational resources to the more challenging reconstruction of high-frequency information. Moreover, we propose a Local Feature Fusion Block (LFFB) effectively fuses features from multiple HFFBs in a local region, utilizing complementary information across layers to enhance feature representativeness and reduce artifacts in reconstructed images. We assess the efficacy of our proposed HFFN on five benchmark datasets and show that it significantly enhances the super-resolution performance of the network. Our experimental results demonstrate state-of-the-art performance in reconstructing high-frequency information while using a low number of parameters. ",
    "url": "https://arxiv.org/abs/2303.11701",
    "authors": [
      "Xiaotian Weng",
      "Yi Chen",
      "Zhichao Zheng",
      "Yanhui Gu",
      "Junsheng Zhou",
      "Yudong Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11735",
    "title": "Tensor networks for quantum machine learning",
    "abstract": "Once developed for quantum theory, tensor networks have been established as a successful machine learning paradigm. Now, they have been ported back to the quantum realm in the emerging field of quantum machine learning to assess problems that classical computers are unable to solve efficiently. Their nature at the interface between physics and machine learning makes tensor networks easily deployable on quantum computers. In this review article, we shed light on one of the major architectures considered to be predestined for variational quantum machine learning. In particular, we discuss how layouts like MPS, PEPS, TTNs and MERA can be mapped to a quantum computer, how they can be used for machine learning and data encoding and which implementation techniques improve their performance. ",
    "url": "https://arxiv.org/abs/2303.11735",
    "authors": [
      "Hans-Martin Rieser",
      "Frank K\u00f6ster",
      "Arne Peter Raulf"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11807",
    "title": "Capacity Maximization of the 6G Networks Deploying IRS",
    "abstract": "The objective of the work is to improve the capacity of the micro cell, i.e., enabling the micro cell base station of a two-tier network to serve an increased number of devices. Therefore, the work deployed an IRS in a micro cell and achieved significant improvements in the performance with a reduced transmit power of the micro base station. ",
    "url": "https://arxiv.org/abs/2303.11807",
    "authors": [
      "Mobasshir Mahbub",
      "Raed M. Shubair"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.11837",
    "title": "Self-supervised learning of a tailored Convolutional Auto Encoder for  histopathological prostate grading",
    "abstract": "According to GLOBOCAN 2020, prostate cancer is the second most common cancer in men worldwide and the fourth most prevalent cancer overall. For pathologists, grading prostate cancer is challenging, especially when discriminating between Grade 3 (G3) and Grade 4 (G4). This paper proposes a Self-Supervised Learning (SSL) framework to classify prostate histopathological images when labeled images are scarce. In particular, a tailored Convolutional Auto Encoder (CAE) is trained to reconstruct 128x128x3 patches of prostate cancer Whole Slide Images (WSIs) as a pretext task. The downstream task of the proposed SSL paradigm is the automatic grading of histopathological patches of prostate cancer. The presented framework reports promising results on the validation set, obtaining an overall accuracy of 83% and on the test set, achieving an overall accuracy value of 76% with F1-score of 77% in G4. ",
    "url": "https://arxiv.org/abs/2303.11837",
    "authors": [
      "Zahra Tabatabaei",
      "Adrian colomer",
      "Kjersti Engan",
      "Javier Oliver",
      "Valery Naranjo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12002",
    "title": "End-to-End Integration of Speech Separation and Voice Activity Detection  for Low-Latency Diarization of Telephone Conversations",
    "abstract": "Recent works show that speech separation guided diarization (SSGD) is an increasingly promising direction, mainly thanks to the recent progress in speech separation. It performs diarization by first separating the speakers and then applying voice activity detection (VAD) on each separated stream. In this work we conduct an in-depth study of SSGD in the conversational telephone speech (CTS) domain, focusing mainly on low-latency streaming diarization applications. We consider three state-of-the-art speech separation (SSep) algorithms and study their performance both in online and offline scenarios, considering non-causal and causal implementations as well as continuous SSep (CSS) windowed inference. We compare different SSGD algorithms on two widely used CTS datasets: CALLHOME and Fisher Corpus (Part 1 and 2) and evaluate both separation and diarization performance. To improve performance, a novel, causal and computationally efficient leakage removal algorithm is proposed, which significantly decreases false alarms. We also explore, for the first time, fully end-to-end SSGD integration between SSep and VAD modules. Crucially, this enables fine-tuning on real-world data for which oracle speakers sources are not available. In particular, our best model achieves 8.8% DER on CALLHOME, which outperforms the current state-of-the-art end-to-end neural diarization model, despite being trained on an order of magnitude less data and having significantly lower latency, i.e., 0.1 vs. 1 seconds. Finally, we also show that the separated signals can be readily used also for automatic speech recognition, reaching performance close to using oracle sources in some configurations. ",
    "url": "https://arxiv.org/abs/2303.12002",
    "authors": [
      "Giovanni Morrone",
      "Samuele Cornell",
      "Luca Serafini",
      "Enrico Zovato",
      "Alessio Brutti",
      "Stefano Squartini"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:1911.02621",
    "title": "The Threat of Adversarial Attacks on Machine Learning in Network  Security -- A Survey",
    "abstract": " Title: The Threat of Adversarial Attacks on Machine Learning in Network  Security -- A Survey ",
    "url": "https://arxiv.org/abs/1911.02621",
    "authors": [
      "Olakunle Ibitoye",
      "Rana Abou-Khamis",
      "Mohamed el Shehaby",
      "Ashraf Matrawy",
      "M. Omair Shafiq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2106.09614",
    "title": "Robust Model-based Face Reconstruction through Weakly-Supervised Outlier  Segmentation",
    "abstract": " Comments: 20 pages, CVPR2023 ",
    "url": "https://arxiv.org/abs/2106.09614",
    "authors": [
      "Chunlu Li",
      "Andreas Morel-Forster",
      "Thomas Vetter",
      "Bernhard Egger",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.09543",
    "title": "DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with  Gradient-Disentangled Embedding Sharing",
    "abstract": " Comments: 16 pages, 10 tables, 2 Figures. The DeBERTaV3 model significantly improves performance of the downstream NLU tasks over models with a similar structure, e.g. DeBERTaV3 large achieves 91.37% average GLUE score which is 1.37% over DeBERTa large. XSmall has only 22M backbone parameters, but significantly outperforms RoBERTa/XLNet-base. Paper is published as a conference paper at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2111.09543",
    "authors": [
      "Pengcheng He",
      "Jianfeng Gao",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12273",
    "title": "Sharpness-aware Quantization for Deep Neural Networks",
    "abstract": " Comments: Tech report ",
    "url": "https://arxiv.org/abs/2111.12273",
    "authors": [
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03186",
    "title": "Bandits Corrupted by Nature: Lower Bounds on Regret and Robust  Optimistic Algorithm",
    "abstract": " Title: Bandits Corrupted by Nature: Lower Bounds on Regret and Robust  Optimistic Algorithm ",
    "url": "https://arxiv.org/abs/2203.03186",
    "authors": [
      "Debabrota Basu",
      "Odalric-Ambrym Maillard",
      "Timoth\u00e9e Mathieu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2203.03235",
    "title": "Pre-trained Token-replaced Detection Model as Few-shot Learner",
    "abstract": " Comments: Accepted to COLING 2022. The code is publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2203.03235",
    "authors": [
      "Zicheng Li",
      "Shoushan Li",
      "Guodong Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07120",
    "title": "Neural Message Passing for Objective-Based Uncertainty Quantification  and Optimal Experimental Design",
    "abstract": " Comments: 14 pages, 5 figures, accepted by Engineering Applications of Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2203.07120",
    "authors": [
      "Qihua Chen",
      "Xuejin Chen",
      "Hyun-Myung Woo",
      "Byung-Jun Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.15793",
    "title": "Instance Relation Graph Guided Source-Free Domain Adaptive Object  Detection",
    "abstract": " Comments: Accepted to CVPR 2023. Project site: \\href{https://viudomain.github.io/irg-sfda-web/}{this https URL} ",
    "url": "https://arxiv.org/abs/2203.15793",
    "authors": [
      "Vibashan VS",
      "Poojan Oza",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07075",
    "title": "Learning and controlling the source-filter representation of speech with  a variational autoencoder",
    "abstract": " Comments: 23 pages, 7 figures, companion website: this https URL ",
    "url": "https://arxiv.org/abs/2204.07075",
    "authors": [
      "Samir Sadok",
      "Simon Leglaive",
      "Laurent Girin",
      "Xavier Alameda-Pineda",
      "Renaud S\u00e9guier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.14230",
    "title": "Semi-supervised Semantics-guided Adversarial Training for Trajectory  Prediction",
    "abstract": " Comments: 11 pages, adversarial training for trajectory prediction ",
    "url": "https://arxiv.org/abs/2205.14230",
    "authors": [
      "Ruochen Jiao",
      "Xiangguo Liu",
      "Takami Sato",
      "Qi Alfred Chen",
      "Qi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.14311",
    "title": "MolScribe: Robust Molecular Structure Recognition with Image-To-Graph  Generation",
    "abstract": " Comments: To be published in the Journal of Chemical Information and Modeling ",
    "url": "https://arxiv.org/abs/2205.14311",
    "authors": [
      "Yujie Qian",
      "Jiang Guo",
      "Zhengkai Tu",
      "Zhening Li",
      "Connor W. Coley",
      "Regina Barzilay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09490",
    "title": "A Bounded-Confidence Model of Opinion Dynamics with Heterogeneous  Node-Activity Levels",
    "abstract": " Comments: revised version, 11 figures ",
    "url": "https://arxiv.org/abs/2206.09490",
    "authors": [
      "Grace J. Li",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2207.03020",
    "title": "Mechanisms of True and False Rumor Sharing in Social Media: Collective  Intelligence or Herd Behavior?",
    "abstract": " Comments: Accepted at CSCW 23 ",
    "url": "https://arxiv.org/abs/2207.03020",
    "authors": [
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.05930",
    "title": "On the Complexity of Identifying Strongly Regular Graphs",
    "abstract": " Comments: New result- GI is not AC0-reducible to isomorphism testing of conference graphs; fixed minor bugs and typos from previous version ",
    "url": "https://arxiv.org/abs/2207.05930",
    "authors": [
      "Michael Levet"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2207.06726",
    "title": "Octuplet Loss: Make Face Recognition Robust to Image Resolution",
    "abstract": " Title: Octuplet Loss: Make Face Recognition Robust to Image Resolution ",
    "url": "https://arxiv.org/abs/2207.06726",
    "authors": [
      "Martin Knoche",
      "Mohamed Elkadeem",
      "Stefan H\u00f6rmann",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.04319",
    "title": "PhyGNNet: Solving spatiotemporal PDEs with Physics-informed Graph Neural  Network",
    "abstract": " Comments: there some errors in method describtion ",
    "url": "https://arxiv.org/abs/2208.04319",
    "authors": [
      "Longxiang Jiang",
      "Liyuan Wang",
      "Xinkun Chu",
      "Yonghao Xiao",
      "Hao Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.05949",
    "title": "Valid Inference after Causal Discovery",
    "abstract": " Title: Valid Inference after Causal Discovery ",
    "url": "https://arxiv.org/abs/2208.05949",
    "authors": [
      "Paula Gradu",
      "Tijana Zrnic",
      "Yixin Wang",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.10930",
    "title": "FS-BAN: Born-Again Networks for Domain Generalization Few-Shot  Classification",
    "abstract": " Comments: 15 pages, 9 figures, 15 tables. IEEE Transactions on Image Processing (TIP), 2023 ",
    "url": "https://arxiv.org/abs/2208.10930",
    "authors": [
      "Yunqing Zhao",
      "Ngai-Man Cheung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.12849",
    "title": "AirTrack: Onboard Deep Learning Framework for Long-Range Aircraft  Detection and Tracking",
    "abstract": " Comments: 7 pages, 5 figures, ICRA 2023 ",
    "url": "https://arxiv.org/abs/2209.12849",
    "authors": [
      "Sourish Ghosh",
      "Jay Patrikar",
      "Brady Moon",
      "Milad Moghassem Hamidi",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14699",
    "title": "ARQ-based Average Consensus over Unreliable Directed Network Topologies",
    "abstract": " Title: ARQ-based Average Consensus over Unreliable Directed Network Topologies ",
    "url": "https://arxiv.org/abs/2209.14699",
    "authors": [
      "Evagoras Makridis",
      "Themistoklis Charalambous",
      "Christoforos N. Hadjicostis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.01340",
    "title": "Safe Self-Supervised Learning in Real of Visuo-Tactile Feedback Policies  for Industrial Insertion",
    "abstract": " Title: Safe Self-Supervised Learning in Real of Visuo-Tactile Feedback Policies  for Industrial Insertion ",
    "url": "https://arxiv.org/abs/2210.01340",
    "authors": [
      "Letian Fu",
      "Huang Huang",
      "Lars Berscheid",
      "Hui Li",
      "Ken Goldberg",
      "Sachin Chitta"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.11035",
    "title": "PointTAD: Multi-Label Temporal Action Detection with Learnable Query  Points",
    "abstract": " Comments: NeurIPS 2022 camera ready version ",
    "url": "https://arxiv.org/abs/2210.11035",
    "authors": [
      "Jing Tan",
      "Xiaotong Zhao",
      "Xintian Shi",
      "Bin Kang",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11478",
    "title": "Neural Co-Processors for Restoring Brain Function: Results from a  Cortical Model of Grasping",
    "abstract": " Comments: 45 pages, 19 figures. Submitted the IOP Journal of Neural Engineering ",
    "url": "https://arxiv.org/abs/2210.11478",
    "authors": [
      "Matthew J. Bryan",
      "Linxing Preston Jiang",
      "Rajesh P N Rao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.06689",
    "title": "TINC: Tree-structured Implicit Neural Compression",
    "abstract": " Comments: Accepted to CVPR2023 ",
    "url": "https://arxiv.org/abs/2211.06689",
    "authors": [
      "Runzhao Yang",
      "Tingxiong Xiao",
      "Yuxiao Cheng",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08326",
    "title": "Contrastive learning for regression in multi-site brain age prediction",
    "abstract": " Comments: 5 pages ",
    "url": "https://arxiv.org/abs/2211.08326",
    "authors": [
      "Carlo Alberto Barbano",
      "Benoit Dufumier",
      "Edouard Duchesnay",
      "Marco Grangetto",
      "Pietro Gori"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10381",
    "title": "Environmental Sensor Placement with Convolutional Gaussian Neural  Processes",
    "abstract": " Comments: In review for the Climate Informatics 2023 special issue of Environmental Data Science ",
    "url": "https://arxiv.org/abs/2211.10381",
    "authors": [
      "Tom R. Andersson",
      "Wessel P. Bruinsma",
      "Stratis Markou",
      "James Requeima",
      "Alejandro Coca-Castro",
      "Anna Vaughan",
      "Anna-Louise Ellis",
      "Matthew Lazzara",
      "Daniel C. Jones",
      "J. Scott Hosking",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11039",
    "title": "Deep Composite Face Image Attacks: Generation, Vulnerability and  Detection",
    "abstract": " Comments: The submitted paper is accepted in IEEE Access 2023 ",
    "url": "https://arxiv.org/abs/2211.11039",
    "authors": [
      "Jag Mohan Singh",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11317",
    "title": "DeSTSeg: Segmentation Guided Denoising Student-Teacher for Anomaly  Detection",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2211.11317",
    "authors": [
      "Xuan Zhang",
      "Shiyu Li",
      "Xi Li",
      "Ping Huang",
      "Jiulong Shan",
      "Ting Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11561",
    "title": "SAMSON: Sharpness-Aware Minimization Scaled by Outlier Normalization for  Improving DNN Generalization and Robustness",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2211.11561",
    "authors": [
      "Gon\u00e7alo Mordido",
      "S\u00e9bastien Henwood",
      "Sarath Chandar",
      "Fran\u00e7ois Leduc-Primeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13868",
    "title": "Can Knowledge of End-to-End Text-to-Speech Models Improve Neural  MIDI-to-Audio Synthesis Systems?",
    "abstract": " Comments: Accepted by ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.13868",
    "authors": [
      "Xuan Shi",
      "Erica Cooper",
      "Xin Wang",
      "Junichi Yamagishi",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.14308",
    "title": "WALDO: Future Video Synthesis using Object Layer Decomposition and  Parametric Flow Prediction",
    "abstract": " Title: WALDO: Future Video Synthesis using Object Layer Decomposition and  Parametric Flow Prediction ",
    "url": "https://arxiv.org/abs/2211.14308",
    "authors": [
      "Guillaume Le Moing",
      "Jean Ponce",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16433",
    "title": "On Robust Observer Design for System Motion on SE(3) Using Onboard  Visual Sensors",
    "abstract": " Comments: Need Further Improvement ",
    "url": "https://arxiv.org/abs/2211.16433",
    "authors": [
      "Tong Zhang",
      "Ying Tan",
      "Xiang Chen",
      "Zike Lei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.00543",
    "title": "Fine-Grained Selective Similarity Integration for Drug-Target  Interaction Prediction",
    "abstract": " Title: Fine-Grained Selective Similarity Integration for Drug-Target  Interaction Prediction ",
    "url": "https://arxiv.org/abs/2212.00543",
    "authors": [
      "Bin Liu",
      "Jin Wang",
      "Kaiwei Sun",
      "Grigorios Tsoumakas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.07356",
    "title": "Scheduling and Aggregation Design for Asynchronous Federated Learning  over Wireless Networks",
    "abstract": " Title: Scheduling and Aggregation Design for Asynchronous Federated Learning  over Wireless Networks ",
    "url": "https://arxiv.org/abs/2212.07356",
    "authors": [
      "Chung-Hsuan Hu",
      "Zheng Chen",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.08877",
    "title": "Evolutionary games on multilayer networks: coordination and equilibrium  selection",
    "abstract": " Title: Evolutionary games on multilayer networks: coordination and equilibrium  selection ",
    "url": "https://arxiv.org/abs/2212.08877",
    "authors": [
      "Tomasz Raducha",
      "Maxi San Miguel"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2212.09069",
    "title": "Masked Wavelet Representation for Compact Neural Radiance Fields",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2212.09069",
    "authors": [
      "Daniel Rho",
      "Byeonghyeon Lee",
      "Seungtae Nam",
      "Joo Chan Lee",
      "Jong Hwan Ko",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.10245",
    "title": "Neural Belief Propagation Decoding of Quantum LDPC Codes Using  Overcomplete Check Matrices",
    "abstract": " Comments: accepted at 2023 IEEE Information Theory Workshop (ITW) ",
    "url": "https://arxiv.org/abs/2212.10245",
    "authors": [
      "Sisi Miao",
      "Alexander Schnerring",
      "Haizheng Li",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2301.02239",
    "title": "Robust Dynamic Radiance Fields",
    "abstract": " Comments: CVPR 2023. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2301.02239",
    "authors": [
      "Yu-Lun Liu",
      "Chen Gao",
      "Andreas Meuleman",
      "Hung-Yu Tseng",
      "Ayush Saraf",
      "Changil Kim",
      "Yung-Yu Chuang",
      "Johannes Kopf",
      "Jia-Bin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.04347",
    "title": "Counteracts: Testing Stereotypical Representation in Pre-trained  Language Models",
    "abstract": " Comments: FACCT; to be submitted to ",
    "url": "https://arxiv.org/abs/2301.04347",
    "authors": [
      "Damin Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.05599",
    "title": "Short-length SSVEP data extension by a novel generative adversarial  networks based framework",
    "abstract": " Comments: 16 pages, 10 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2301.05599",
    "authors": [
      "Yudong Pan",
      "Ning Li",
      "Yangsong Zhang",
      "Peng Xu",
      "Dezhong Yao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.12814",
    "title": "Complexity of Gaussian boson sampling with tensor networks",
    "abstract": " Comments: 14 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2301.12814",
    "authors": [
      "Minzhao Liu",
      "Changhun Oh",
      "Junyu Liu",
      "Liang Jiang",
      "Yuri Alexeev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2302.01826",
    "title": "Graph Embedding for Mapping Interdisciplinary Research Networks",
    "abstract": " Title: Graph Embedding for Mapping Interdisciplinary Research Networks ",
    "url": "https://arxiv.org/abs/2302.01826",
    "authors": [
      "Eoghan Cunningham",
      "Derek Greene"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2302.02601",
    "title": "Learning Representations of Bi-level Knowledge Graphs for Reasoning  beyond Link Prediction",
    "abstract": " Comments: 14 pages, 3 figures, 15 tables. 37th AAAI Conference on Artificial Intelligence (AAAI 2023) ",
    "url": "https://arxiv.org/abs/2302.02601",
    "authors": [
      "Chanyoung Chung",
      "Joyce Jiyoung Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04775",
    "title": "Adap-$\u03c4$: Adaptively Modulating Embedding Magnitude for  Recommendation",
    "abstract": " Title: Adap-$\u03c4$: Adaptively Modulating Embedding Magnitude for  Recommendation ",
    "url": "https://arxiv.org/abs/2302.04775",
    "authors": [
      "Jiawei Chen",
      "Junkang Wu",
      "Jiancan Wu",
      "Sheng Zhou",
      "Xuezhi Cao",
      "Xiangnan He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.09461",
    "title": "Liveness score-based regression neural networks for face anti-spoofing",
    "abstract": " Comments: Submission to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2302.09461",
    "authors": [
      "Youngjun Kwak",
      "Minyoung Jung",
      "Hunjae Yoo",
      "JinHo Shin",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10873",
    "title": "Context-Aware Timewise VAEs for Real-Time Vehicle Trajectory Prediction",
    "abstract": " Title: Context-Aware Timewise VAEs for Real-Time Vehicle Trajectory Prediction ",
    "url": "https://arxiv.org/abs/2302.10873",
    "authors": [
      "Pei Xu",
      "Jean-Bernard Hayet",
      "Ioannis Karamouzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12465",
    "title": "PaGE-Link: Path-based Graph Neural Network Explanation for Heterogeneous  Link Prediction",
    "abstract": " Title: PaGE-Link: Path-based Graph Neural Network Explanation for Heterogeneous  Link Prediction ",
    "url": "https://arxiv.org/abs/2302.12465",
    "authors": [
      "Shichang Zhang",
      "Jiani Zhang",
      "Xiang Song",
      "Soji Adeshina",
      "Da Zheng",
      "Christos Faloutsos",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.14332",
    "title": "Markerless Camera-to-Robot Pose Estimation via Self-supervised  Sim-to-Real Transfer",
    "abstract": " Comments: 14 pages, 9 figures. Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2302.14332",
    "authors": [
      "Jingpei Lu",
      "Florian Richter",
      "Michael C. Yip"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.01593",
    "title": "QAID: Question Answering Inspired Few-shot Intent Detection",
    "abstract": " Comments: ICLR paper ",
    "url": "https://arxiv.org/abs/2303.01593",
    "authors": [
      "Asaf Yehudai",
      "Matan Vetzler",
      "Yosi Mass",
      "Koren Lazar",
      "Doron Cohen",
      "Boaz Carmeli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.01765",
    "title": "Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand  Disentanglement",
    "abstract": " Comments: Accepted at CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.01765",
    "authors": [
      "Xingqun Qi",
      "Chen Liu",
      "Muyi Sun",
      "Lincheng Li",
      "Changjie Fan",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06152",
    "title": "Why is That a Good or Not a Good Frying Pan? -- Knowledge Representation  for Functions of Objects and Tools for Design Understanding, Improvement, and  Generation",
    "abstract": " Comments: 11 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2303.06152",
    "authors": [
      "Seng-Beng Ho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06500",
    "title": "Diffusion-Based Hierarchical Multi-Label Object Detection to Analyze  Panoramic Dental X-rays",
    "abstract": " Title: Diffusion-Based Hierarchical Multi-Label Object Detection to Analyze  Panoramic Dental X-rays ",
    "url": "https://arxiv.org/abs/2303.06500",
    "authors": [
      "Ibrahim Ethem Hamamci",
      "Sezgin Er",
      "Enis Simsar",
      "Anjany Sekuboyina",
      "Mustafa Gundogar",
      "Bernd Stadlinger",
      "Albert Mehl",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07397",
    "title": "Fast exploration and learning of latent graphs with aliased observations",
    "abstract": " Comments: v2: Added extra figure and fixed typos ",
    "url": "https://arxiv.org/abs/2303.07397",
    "authors": [
      "Miguel Lazaro-Gredilla",
      "Ishan Deshpande",
      "Sivaramakrishnan Swaminathan",
      "Meet Dave",
      "Dileep George"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07543",
    "title": "WDiscOOD: Out-of-Distribution Detection via Whitened Linear  Discriminative Analysis",
    "abstract": " Title: WDiscOOD: Out-of-Distribution Detection via Whitened Linear  Discriminative Analysis ",
    "url": "https://arxiv.org/abs/2303.07543",
    "authors": [
      "Yiye Chen",
      "Yunzhi Lin",
      "Ruinian Xu",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07797",
    "title": "Automated Self-Supervised Learning for Recommendation",
    "abstract": " Comments: Accepted by ACM The Web Conference, 2023 ",
    "url": "https://arxiv.org/abs/2303.07797",
    "authors": [
      "Lianghao Xia",
      "Chao Huang",
      "Chunzhen Huang",
      "Kangyi Lin",
      "Tao Yu",
      "Ben Kao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.08955",
    "title": "Large-scale End-of-Life Prediction of Hard Disks in Distributed  Datacenters",
    "abstract": " Comments: 8 pages, 9 figures and 6 tables ",
    "url": "https://arxiv.org/abs/2303.08955",
    "authors": [
      "Rohan Mohapatra",
      "Austin Coursey",
      "Saptarshi Sengupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.09026",
    "title": "Commonsense Knowledge Assisted Deep Learning for Resource-constrained  and Fine-grained Object Detection",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2303.09026",
    "authors": [
      "Pu Zhang",
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09093",
    "title": "GLEN: General-Purpose Event Detection for Thousands of Types",
    "abstract": " Comments: The first two authors contributed equally. (15 pages, 11 figures) ",
    "url": "https://arxiv.org/abs/2303.09093",
    "authors": [
      "Qiusi Zhan",
      "Sha Li",
      "Kathryn Conger",
      "Martha Palmer",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.09280",
    "title": "Topology optimization with physics-informed neural networks: application  to noninvasive detection of hidden geometries",
    "abstract": " Comments: 24 pages, 16 figures including supplementary information. Added supplementary movies ",
    "url": "https://arxiv.org/abs/2303.09280",
    "authors": [
      "Saviz Mowlavi",
      "Ken Kamrin"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10135",
    "title": "Efficient and Feasible Robotic Assembly Sequence Planning via Graph  Representation Learning",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2303.10135",
    "authors": [
      "Matan Atad",
      "Jianxiang Feng",
      "Ismael Rodr\u00edguez",
      "Maximilian Durner",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10444",
    "title": "Stall Number Detection of Cow Teats Key Frames",
    "abstract": " Title: Stall Number Detection of Cow Teats Key Frames ",
    "url": "https://arxiv.org/abs/2303.10444",
    "authors": [
      "Youshan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10449",
    "title": "Uncertainty-Aware Optimal Transport for Semantically Coherent  Out-of-Distribution Detection",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.10449",
    "authors": [
      "Fan Lu",
      "Kai Zhu",
      "Wei Zhai",
      "Kecheng Zheng",
      "Yang Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10770",
    "title": "RN-Net: Reservoir Nodes-Enabled Neuromorphic Vision Sensing Network",
    "abstract": " Comments: 11 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2303.10770",
    "authors": [
      "Sangmin Yoo",
      "Eric Yeu-Jer Lee",
      "Ziyu Wang",
      "Xinxin Wang",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.10780",
    "title": "A Comprehensive Review of Spiking Neural Networks: Interpretation,  Optimization, Efficiency, and Best Practices",
    "abstract": " Title: A Comprehensive Review of Spiking Neural Networks: Interpretation,  Optimization, Efficiency, and Best Practices ",
    "url": "https://arxiv.org/abs/2303.10780",
    "authors": [
      "Kai Malcolm",
      "Josue Casco-Rodriguez"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.11239",
    "title": "Training Invertible Neural Networks as Autoencoders",
    "abstract": " Comments: Conference Paper at GCPR2019 ",
    "url": "https://arxiv.org/abs/2303.11239",
    "authors": [
      "The-Gia Leo Nguyen",
      "Lynton Ardizzone",
      "Ullrich K\u00f6the"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11293",
    "title": "Advancing Network Securing Strategies with Network Algorithms for  Integrated Air Defense System (IADS) Missile Batteries",
    "abstract": " Title: Advancing Network Securing Strategies with Network Algorithms for  Integrated Air Defense System (IADS) Missile Batteries ",
    "url": "https://arxiv.org/abs/2303.11293",
    "authors": [
      "Rakib Hassan Pran"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  }
]