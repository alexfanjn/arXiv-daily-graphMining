[
  {
    "id": "arXiv:2303.08819",
    "title": "Ask and You Shall Receive (a Graph Drawing): Testing ChatGPT's Potential  to Apply Graph Layout Algorithms",
    "abstract": "Large language models (LLMs) have recently taken the world by storm. They can generate coherent text, hold meaningful conversations, and be taught concepts and basic sets of instructions - such as the steps of an algorithm. In this context, we are interested in exploring the application of LLMs to graph drawing algorithms by performing experiments on ChatGPT. These algorithms are used to improve the readability of graph visualizations. The probabilistic nature of LLMs presents challenges to implementing algorithms correctly, but we believe that LLMs' ability to learn from vast amounts of data and apply complex operations may lead to interesting graph drawing results. For example, we could enable users with limited coding backgrounds to use simple natural language to create effective graph visualizations. Natural language specification would make data visualization more accessible and user-friendly for a wider range of users. Exploring LLMs' capabilities for graph drawing can also help us better understand how to formulate complex algorithms for LLMs; a type of knowledge that could transfer to other areas of computer science. Overall, our goal is to shed light on the exciting possibilities of using LLMs for graph drawing while providing a balanced assessment of the challenges and opportunities they present. A free copy of this paper with all supplemental materials required to reproduce our results is available on https://osf.io/n5rxd/?view_only=f09cbc2621f44074810b7d843f1e12f9 ",
    "url": "https://arxiv.org/abs/2303.08819",
    "authors": [
      "Sara Di Bartolomeo",
      "Giorgio Severi",
      "Victor Schetinger",
      "Cody Dunne"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08823",
    "title": "Wireless Sensor Networks anomaly detection using Machine Learning: A  Survey",
    "abstract": "Wireless Sensor Networks (WSNs) have become increasingly valuable in various civil/military applications like industrial process control, civil engineering applications such as buildings structural strength monitoring, environmental monitoring, border intrusion, IoT (Internet of Things), and healthcare. However, the sensed data generated by WSNs is often noisy and unreliable, making it a challenge to detect and diagnose anomalies. Machine learning (ML) techniques have been widely used to address this problem by detecting and identifying unusual patterns in the sensed data. This survey paper provides an overview of the state of the art applications of ML techniques for data anomaly detection in WSN domains. We first introduce the characteristics of WSNs and the challenges of anomaly detection in WSNs. Then, we review various ML techniques such as supervised, unsupervised, and semi-supervised learning that have been applied to WSN data anomaly detection. We also compare different ML-based approaches and their performance evaluation metrics. Finally, we discuss open research challenges and future directions for applying ML techniques in WSNs sensed data anomaly detection. ",
    "url": "https://arxiv.org/abs/2303.08823",
    "authors": [
      "Ahsnaul Haque",
      "Md Naseef-Ur-Rahman Chowdhury",
      "Hamdy Soliman",
      "Mohammad Sahinur Hossen",
      "Tanjim Fatima",
      "Imtiaz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08824",
    "title": "Intelligent Reflecting Vehicle Surface: A Novel IRS Paradigm for Moving  Vehicular Networks",
    "abstract": "Intelligent reflecting surface (IRS) has recently received much attention from the research community due to its potential to achieve high spectral and power efficiency cost-effectively. In addition to traditional cellular networks, the use of IRS in vehicular networks is also considered. Prior works on IRS-aided vehicle-to-everything communications focus on deploying reflection surfaces on the facades of buildings along the road for sidelink performance enhancement. This paper goes beyond the state of the art by presenting a novel paradigm coined Intelligent Reflecting Vehicle Surface (IRVS). It embeds a massive number of reflection elements on vehicles' surfaces to aid moving vehicular networks in military and emergency communications. We propose an alternative optimization method to optimize jointly active beamforming at the base station and passive reflection across multiple randomly-distributed vehicle surfaces. Performance evaluation in terms of sum spectral efficiency under continuous, discrete, and random phase shifts is conducted. Numerical results reveal that IRVS can substantially improve the capacity of a moving vehicular network. ",
    "url": "https://arxiv.org/abs/2303.08824",
    "authors": [
      "Wei Jiang",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.08848",
    "title": "PENet: A Joint Panoptic Edge Detection Network",
    "abstract": "In recent years, compact and efficient scene understanding representations have gained popularity in increasing situational awareness and autonomy of robotic systems. In this work, we illustrate the concept of a panoptic edge segmentation and propose PENet, a novel detection network called that combines semantic edge detection and instance-level perception into a compact panoptic edge representation. This is obtained through a joint network by multi-task learning that concurrently predicts semantic edges, instance centers and offset flow map without bounding box predictions exploiting the cross-task correlations among the tasks. The proposed approach allows extending semantic edge detection to panoptic edge detection which encapsulates both category-aware and instance-aware segmentation. We validate the proposed panoptic edge segmentation method and demonstrate its effectiveness on the real-world Cityscapes dataset. ",
    "url": "https://arxiv.org/abs/2303.08848",
    "authors": [
      "Yang Zhou",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.08859",
    "title": "Multi-Competitive Virus Spread over a Time-Varying Networked SIS Model  with an Infrastructure Network",
    "abstract": "We study the spread of multi-competitive viruses over a (possibly) time-varying network of individuals accounting for the presence of shared infrastructure networks that further enables transmission of the virus. We establish a sufficient condition for exponentially fast eradication of a virus for: 1) time-invariant graphs, 2) time-varying graphs with symmetric interactions between individuals and homogeneous virus spread across the network (same healing and infection rate for all individuals), and 3) directed and slowly varying graphs with heterogeneous virus spread (not necessarily same healing and infection rates for all individuals) across the network. Numerical examples illustrate our theoretical results and indicate that, for the time-varying case, violation of the aforementioned sufficient conditions could lead to the persistence of a virus. ",
    "url": "https://arxiv.org/abs/2303.08859",
    "authors": [
      "Sebin Gracy",
      "Yuan Wang",
      "Philip E. Pare",
      "Cesar A Uribe"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2303.08864",
    "title": "GRNN-based Real-time Fault Chain Prediction",
    "abstract": "This paper proposes a data-driven graphical framework for the real-time search of risky cascading fault chains (FCs). While identifying risky FCs is pivotal to alleviating cascading failures, the complex spatio-temporal dependencies among the components of the power system render challenges to modeling and analyzing FCs. Furthermore, the real-time search of risky FCs faces an inherent combinatorial complexity that grows exponentially with the size of the system. The proposed framework leverages the recent advances in graph recurrent neural networks to circumvent the computational complexities of the real-time search of FCs. The search process is formalized as a partially observable Markov decision process (POMDP), which is subsequently solved via a time-varying graph recurrent neural network (GRNN) that judiciously accounts for the inherent temporal and spatial structures of the data generated by the system. The key features of this structure include (i) leveraging the spatial structure of the data induced by the system topology, (ii) leveraging the temporal structure of data induced by system dynamics, and (iii) efficiently summarizing the system's history in the latent space of the GRNN. The proposed framework's efficiency is compared to the relevant literature on the IEEE 39-bus New England system and the IEEE 118-bus system. ",
    "url": "https://arxiv.org/abs/2303.08864",
    "authors": [
      "Anmol Dwivedi",
      "Ali Tajer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.08866",
    "title": "EvalAttAI: A Holistic Approach to Evaluating Attribution Maps in Robust  and Non-Robust Models",
    "abstract": "The expansion of explainable artificial intelligence as a field of research has generated numerous methods of visualizing and understanding the black box of a machine learning model. Attribution maps are generally used to highlight the parts of the input image that influence the model to make a specific decision. On the other hand, the robustness of machine learning models to natural noise and adversarial attacks is also being actively explored. This paper focuses on evaluating methods of attribution mapping to find whether robust neural networks are more explainable. We explore this problem within the application of classification for medical imaging. Explainability research is at an impasse. There are many methods of attribution mapping, but no current consensus on how to evaluate them and determine the ones that are the best. Our experiments on multiple datasets (natural and medical imaging) and various attribution methods reveal that two popular evaluation metrics, Deletion and Insertion, have inherent limitations and yield contradictory results. We propose a new explainability faithfulness metric (called EvalAttAI) that addresses the limitations of prior metrics. Using our novel evaluation, we found that Bayesian deep neural networks using the Variational Density Propagation technique were consistently more explainable when used with the best performing attribution method, the Vanilla Gradient. However, in general, various types of robust neural networks may not be more explainable, despite these models producing more visually plausible attribution maps. ",
    "url": "https://arxiv.org/abs/2303.08866",
    "authors": [
      "Ian E. Nielsen",
      "Ravi P. Ramachandran",
      "Nidhal Bouaynaya",
      "Hassan M. Fathallah-Shaykh",
      "Ghulam Rasool"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08871",
    "title": "WIP: Federated Learning for Routing in Swarm Based Distributed Multi-Hop  Networks",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are a rapidly emerging technology offering fast and cost-effective solutions for many areas, including public safety, surveillance, and wireless networks. However, due to the highly dynamic network topology of UAVs, traditional mesh networking protocols, such as the Better Approach to Mobile Ad-hoc Networking (B.A.T.M.A.N.), are unsuitable. To this end, we investigate modifying the B.A.T.M.A.N. routing protocol with a machine learning (ML) model and propose implementing this solution using federated learning (FL). This work aims to aid the routing protocol to learn to predict future network topologies and preemptively make routing decisions to minimize network congestion. We also present an FL testbed built on a network emulator for future testing of the proposed ML aided B.A.T.M.A.N. routing protocol. ",
    "url": "https://arxiv.org/abs/2303.08871",
    "authors": [
      "Martha Cash",
      "Joseph Murphy",
      "Alexander Wyglinski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.08873",
    "title": "Machine Learning-Driven Adaptive OpenMP For Portable Performance on  Heterogeneous Systems",
    "abstract": "Heterogeneity has become a mainstream architecture design choice for building High Performance Computing systems. However, heterogeneity poses significant challenges for achieving performance portability of execution. Adapting a program to a new heterogeneous platform is laborious and requires developers to manually explore a vast space of execution parameters. To address those challenges, this paper proposes new extensions to OpenMP for autonomous, machine learning-driven adaptation. Our solution includes a set of novel language constructs, compiler transformations, and runtime support. We propose a producer-consumer pattern to flexibly define multiple, different variants of OpenMP code regions to enable adaptation. Those regions are transparently profiled at runtime to autonomously learn optimizing machine learning models that dynamically select the fastest variant. Our approach significantly reduces users' efforts of programming adaptive applications on heterogeneous architectures by leveraging machine learning techniques and code generation capabilities of OpenMP compilation. Using a complete reference implementation in Clang/LLVM we evaluate three use-cases of adaptive CPU-GPU execution. Experiments with HPC proxy applications and benchmarks demonstrate that the proposed adaptive OpenMP extensions automatically choose the best performing code variants for various adaptation possibilities, in several different heterogeneous platforms of CPUs and GPUs. ",
    "url": "https://arxiv.org/abs/2303.08873",
    "authors": [
      "Giorgis Georgakoudis",
      "Konstantinos Parasyris",
      "Chunhua Liao",
      "David Beckingsale",
      "Todd Gamblin",
      "Bronis de Supinski"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08889",
    "title": "Characterizing and Predicting Social Correction on Twitter",
    "abstract": "Online misinformation has been a serious threat to public health and society. Social media users are known to reply to misinformation posts with counter-misinformation messages, which have been shown to be effective in curbing the spread of misinformation. This is called social correction. However, the characteristics of tweets that attract social correction versus those that do not remain unknown. To close the gap, we focus on answering the following two research questions: (1) ``Given a tweet, will it be countered by other users?'', and (2) ``If yes, what will be the magnitude of countering it?''. This exploration will help develop mechanisms to guide users' misinformation correction efforts and to measure disparity across users who get corrected. In this work, we first create a novel dataset with 690,047 pairs of misinformation tweets and counter-misinformation replies. Then, stratified analysis of tweet linguistic and engagement features as well as tweet posters' user attributes are conducted to illustrate the factors that are significant in determining whether a tweet will get countered. Finally, predictive classifiers are created to predict the likelihood of a misinformation tweet to get countered and the degree to which that tweet will be countered. The code and data is accessible on https://github.com/claws-lab/social-correction-twitter. ",
    "url": "https://arxiv.org/abs/2303.08889",
    "authors": [
      "Yingchen Ma",
      "Bing He",
      "Nathan Subrahmanian",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.08896",
    "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for  Generative Large Language Models",
    "abstract": "Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts. However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output. Existing fact-checking approaches either require access to token-level output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate, often complex, modules. In this work, we propose \"SelfCheckGPT\", a simple sampling-based approach that can be used to fact-check black-box models in a zero-resource fashion, i.e. without an external database. SelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given concept, sampled responses are likely to be similar and contain consistent facts. However, for hallucinated facts, stochastically sampled responses are likely to diverge and contradict one another. We investigate this approach by using GPT-3 to generate passages about individuals from the WikiBio dataset, and manually annotate the factuality of the generated passages. We demonstrate that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii) rank passages in terms of factuality. We compare our approach to several existing baselines and show that in sentence hallucination detection, our approach has AUC-PR scores comparable to grey-box methods, while SelfCheckGPT is best at passage factuality assessment. ",
    "url": "https://arxiv.org/abs/2303.08896",
    "authors": [
      "Potsawee Manakul",
      "Adian Liusie",
      "Mark J. F. Gales"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.08933",
    "title": "Efficient Planning of Multi-Robot Collective Transport using Graph  Reinforcement Learning with Higher Order Topological Abstraction",
    "abstract": "Efficient multi-robot task allocation (MRTA) is fundamental to various time-sensitive applications such as disaster response, warehouse operations, and construction. This paper tackles a particular class of these problems that we call MRTA-collective transport or MRTA-CT -- here tasks present varying workloads and deadlines, and robots are subject to flight range, communication range, and payload constraints. For large instances of these problems involving 100s-1000's of tasks and 10s-100s of robots, traditional non-learning solvers are often time-inefficient, and emerging learning-based policies do not scale well to larger-sized problems without costly retraining. To address this gap, we use a recently proposed encoder-decoder graph neural network involving Capsule networks and multi-head attention mechanism, and innovatively add topological descriptors (TD) as new features to improve transferability to unseen problems of similar and larger size. Persistent homology is used to derive the TD, and proximal policy optimization is used to train our TD-augmented graph neural network. The resulting policy model compares favorably to state-of-the-art non-learning baselines while being much faster. The benefit of using TD is readily evident when scaling to test problems of size larger than those used in training. ",
    "url": "https://arxiv.org/abs/2303.08933",
    "authors": [
      "Steve Paul",
      "Wenyuan Li",
      "Brian Smyth",
      "Yuzhou Chen",
      "Yulia Gel",
      "Souma Chowdhury"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.08934",
    "title": "PTMTorrent: A Dataset for Mining Open-source Pre-trained Model Packages",
    "abstract": "Due to the cost of developing and training deep learning models from scratch, machine learning engineers have begun to reuse pre-trained models (PTMs) and fine-tune them for downstream tasks. PTM registries known as \"model hubs\" support engineers in distributing and reusing deep learning models. PTM packages include pre-trained weights, documentation, model architectures, datasets, and metadata. Mining the information in PTM packages will enable the discovery of engineering phenomena and tools to support software engineers. However, accessing this information is difficult - there are many PTM registries, and both the registries and the individual packages may have rate limiting for accessing the data. We present an open-source dataset, PTMTorrent, to facilitate the evaluation and understanding of PTM packages. This paper describes the creation, structure, usage, and limitations of the dataset. The dataset includes a snapshot of 5 model hubs and a total of 15,913 PTM packages. These packages are represented in a uniform data schema for cross-hub mining. We describe prior uses of this data and suggest research opportunities for mining using our dataset. The PTMTorrent dataset (v1) is available at: https://app.globus.org/file-manager?origin_id=55e17a6e-9d8f-11ed-a2a2-8383522b48d9&origin_path=%2F~%2F. Our dataset generation tools are available on GitHub: https://doi.org/10.5281/zenodo.7570357. ",
    "url": "https://arxiv.org/abs/2303.08934",
    "authors": [
      "Wenxin Jiang",
      "Nicholas Synovic",
      "Purvish Jajal",
      "Taylor R. Schorlemmer",
      "Arav Tewari",
      "Bhavesh Pareek",
      "George K. Thiruvathukal",
      "James C. Davis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.08944",
    "title": "Certifiable (Multi)Robustness Against Patch Attacks Using ERM",
    "abstract": "Consider patch attacks, where at test-time an adversary manipulates a test image with a patch in order to induce a targeted misclassification. We consider a recent defense to patch attacks, Patch-Cleanser (Xiang et al. [2022]). The Patch-Cleanser algorithm requires a prediction model to have a ``two-mask correctness'' property, meaning that the prediction model should correctly classify any image when any two blank masks replace portions of the image. Xiang et al. learn a prediction model to be robust to two-mask operations by augmenting the training set with pairs of masks at random locations of training images and performing empirical risk minimization (ERM) on the augmented dataset. However, in the non-realizable setting when no predictor is perfectly correct on all two-mask operations on all images, we exhibit an example where ERM fails. To overcome this challenge, we propose a different algorithm that provably learns a predictor robust to all two-mask operations using an ERM oracle, based on prior work by Feige et al. [2015]. We also extend this result to a multiple-group setting, where we can learn a predictor that achieves low robust loss on all groups simultaneously. ",
    "url": "https://arxiv.org/abs/2303.08944",
    "authors": [
      "Saba Ahmadi",
      "Avrim Blum",
      "Omar Montasser",
      "Kevin Stangl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08955",
    "title": "Large-scale End-of-Life Prediction of Hard Disks in Distributed  Datacenters",
    "abstract": "On a daily basis, data centers process huge volumes of data backed by the proliferation of inexpensive hard disks. Data stored in these disks serve a range of critical functional needs from financial, and healthcare to aerospace. As such, premature disk failure and consequent loss of data can be catastrophic. To mitigate the risk of failures, cloud storage providers perform condition-based monitoring and replace hard disks before they fail. By estimating the remaining useful life of hard disk drives, one can predict the time-to-failure of a particular device and replace it at the right time, ensuring maximum utilization whilst reducing operational costs. In this work, large-scale predictive analyses are performed using severely skewed health statistics data by incorporating customized feature engineering and a suite of sequence learners. Past work suggests using LSTMs as an excellent approach to predicting remaining useful life. To this end, we present an encoder-decoder LSTM model where the context gained from understanding health statistics sequences aid in predicting an output sequence of the number of days remaining before a disk potentially fails. The models developed in this work are trained and tested across an exhaustive set of all of the 10 years of S.M.A.R.T. health data in circulation from Backblaze and on a wide variety of disk instances. It closes the knowledge gap on what full-scale training achieves on thousands of devices and advances the state-of-the-art by providing tangible metrics for evaluation and generalization for practitioners looking to extend their workflow to all years of health data in circulation across disk manufacturers. The encoder-decoder LSTM posted an RMSE of 0.83 on an exhaustive set while being able to generalize competitively over the other Seagate family hard drives. ",
    "url": "https://arxiv.org/abs/2303.08955",
    "authors": [
      "Rohan Mohapatra",
      "Austin Coursey",
      "Saptarshi Sengupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.08964",
    "title": "CS-TGN: Community Search via Temporal Graph Neural Networks",
    "abstract": "Searching for local communities is an important research challenge that allows for personalized community discovery and supports advanced data analysis in various complex networks, such as the World Wide Web, social networks, and brain networks. The evolution of these networks over time has motivated several recent studies to identify local communities in temporal networks. Given any query nodes, Community Search aims to find a densely connected subgraph containing query nodes. However, existing community search approaches in temporal networks have two main limitations: (1) they adopt pre-defined subgraph patterns to model communities, which cannot find communities that do not conform to these patterns in real-world networks, and (2) they only use the aggregation of disjoint structural information to measure quality, missing the dynamic of connections and temporal properties. In this paper, we propose a query-driven Temporal Graph Convolutional Network (CS-TGN) that can capture flexible community structures by learning from the ground-truth communities in a data-driven manner. CS-TGN first combines the local query-dependent structure and the global graph embedding in each snapshot of the network and then uses a GRU cell with contextual attention to learn the dynamics of interactions and update node embeddings over time. We demonstrate how this model can be used for interactive community search in an online setting, allowing users to evaluate the found communities and provide feedback. Experiments on real-world temporal graphs with ground-truth communities validate the superior quality of the solutions obtained and the efficiency of our model in both temporal and interactive static settings. ",
    "url": "https://arxiv.org/abs/2303.08964",
    "authors": [
      "Farnoosh Hashemi",
      "Ali Behrouz",
      "Milad Rezaei Hajidehi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08965",
    "title": "Robust Pivoting Manipulation using Contact Implicit Bilevel Optimization",
    "abstract": "Generalizable manipulation requires that robots be able to interact with novel objects and environment. This requirement makes manipulation extremely challenging as a robot has to reason about complex frictional interactions with uncertainty in physical properties of the object and the environment. In this paper, we study robust optimization for planning of pivoting manipulation in the presence of uncertainties. We present insights about how friction can be exploited to compensate for inaccuracies in the estimates of the physical properties during manipulation. Under certain assumptions, we derive analytical expressions for stability margin provided by friction during pivoting manipulation. This margin is then used in a Contact Implicit Bilevel Optimization (CIBO) framework to optimize a trajectory that maximizes this stability margin to provide robustness against uncertainty in several physical parameters of the object. We present analysis of the stability margin with respect to several parameters involved in the underlying bilevel optimization problem. We demonstrate our proposed method using a 6 DoF manipulator for manipulating several different objects. ",
    "url": "https://arxiv.org/abs/2303.08965",
    "authors": [
      "Yuki Shirai",
      "Devesh K. Jha",
      "Arvind U. Raghunathan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.08977",
    "title": "DeblurSR: Event-Based Motion Deblurring Under the Spiking Representation",
    "abstract": "We present DeblurSR, a novel motion deblurring approach that converts a blurry image into a sharp video. DeblurSR utilizes event data to compensate for motion ambiguities and exploits the spiking representation to parameterize the sharp output video as a mapping from time to intensity. Our key contribution, the Spiking Representation (SR), is inspired by the neuromorphic principles determining how biological neurons communicate with each other in living organisms. We discuss why the spikes can represent sharp edges and how the spiking parameters are interpreted from the neuromorphic perspective. DeblurSR has higher output quality and requires fewer computing resources than state-of-the-art event-based motion deblurring methods. We additionally show that our approach easily extends to video super-resolution when combined with recent advances in implicit neural representation. The implementation and animated visualization of DeblurSR are available at https://github.com/chensong1995/DeblurSR. ",
    "url": "https://arxiv.org/abs/2303.08977",
    "authors": [
      "Chen Song",
      "Chandrajit Bajaj",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08983",
    "title": "Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness  with Dataset Reinforcement",
    "abstract": "We propose Dataset Reinforcement, a strategy to improve a dataset once such that the accuracy of any model architecture trained on the reinforced dataset is improved at no additional training cost for users. We propose a Dataset Reinforcement strategy based on data augmentation and knowledge distillation. Our generic strategy is designed based on extensive analysis across CNN- and transformer-based models and performing large-scale study of distillation with state-of-the-art models with various data augmentations. We create a reinforced version of the ImageNet training dataset, called ImageNet+, as well as reinforced datasets CIFAR-100+, Flowers-102+, and Food-101+. Models trained with ImageNet+ are more accurate, robust, and calibrated, and transfer well to downstream tasks (e.g., segmentation and detection). As an example, the accuracy of ResNet-50 improves by 1.7% on the ImageNet validation set, 3.5% on ImageNetV2, and 10.0% on ImageNet-R. Expected Calibration Error (ECE) on the ImageNet validation set is also reduced by 9.9%. Using this backbone with Mask-RCNN for object detection on MS-COCO, the mean average precision improves by 0.8%. We reach similar gains for MobileNets, ViTs, and Swin-Transformers. For MobileNetV3 and Swin-Tiny we observe significant improvements on ImageNet-R/A/C of up to 10% improved robustness. Models pretrained on ImageNet+ and fine-tuned on CIFAR-100+, Flowers-102+, and Food-101+, reach up to 3.4% improved accuracy. ",
    "url": "https://arxiv.org/abs/2303.08983",
    "authors": [
      "Fartash Faghri",
      "Hadi Pouransari",
      "Sachin Mehta",
      "Mehrdad Farajtabar",
      "Ali Farhadi",
      "Mohammad Rastegari",
      "Oncel Tuzel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08988",
    "title": "Connectivity-Aware Semi-Decentralized Federated Learning over  Time-Varying D2D Networks",
    "abstract": "Semi-decentralized federated learning blends the conventional device to-server (D2S) interaction structure of federated model training with localized device-to-device (D2D) communications. We study this architecture over practical edge networks with multiple D2D clusters modeled as time-varying and directed communication graphs. Our investigation results in an algorithm that controls the fundamental trade-off between (a) the rate of convergence of the model training process towards the global optimizer, and (b) the number of D2S transmissions required for global aggregation. Specifically, in our semi-decentralized methodology, D2D consensus updates are injected into the federated averaging framework based on column-stochastic weight matrices that encapsulate the connectivity within the clusters. To arrive at our algorithm, we show how the expected optimality gap in the current global model depends on the greatest two singular values of the weighted adjacency matrices (and hence on the densities) of the D2D clusters. We then derive tight bounds on these singular values in terms of the node degrees of the D2D clusters, and we use the resulting expressions to design a threshold on the number of clients required to participate in any given global aggregation round so as to ensure a desired convergence rate. Simulations performed on real-world datasets reveal that our connectivity-aware algorithm reduces the total communication cost required to reach a target accuracy significantly compared with baselines depending on the connectivity structure and the learning task. ",
    "url": "https://arxiv.org/abs/2303.08988",
    "authors": [
      "Rohit Parasnis",
      "Seyyedali Hosseinalipour",
      "Yun-Wei Chu",
      "Christopher G. Brinton",
      "Mung Chiang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.08994",
    "title": "Physics-Informed Neural Networks for Time-Domain Simulations: Accuracy,  Computational Cost, and Flexibility",
    "abstract": "The simulation of power system dynamics poses a computationally expensive task. Considering the growing uncertainty of generation and demand patterns, thousands of scenarios need to be continuously assessed to ensure the safety of power systems. Physics-Informed Neural Networks (PINNs) have recently emerged as a promising solution for drastically accelerating computations of non-linear dynamical systems. This work investigates the applicability of these methods for power system dynamics, focusing on the dynamic response to load disturbances. Comparing the prediction of PINNs to the solution of conventional solvers, we find that PINNs can be 10 to 1000 times faster than conventional solvers. At the same time, we find them to be sufficiently accurate and numerically stable even for large time steps. To facilitate a deeper understanding, this paper also presents a new regularisation of Neural Network (NN) training by introducing a gradient-based term in the loss function. The resulting NNs, which we call dtNNs, help us deliver a comprehensive analysis about the strengths and weaknesses of the NN based approaches, how incorporating knowledge of the underlying physics affects NN performance, and how this compares with conventional solvers for power system dynamics. ",
    "url": "https://arxiv.org/abs/2303.08994",
    "authors": [
      "Jochen Stiasny",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08995",
    "title": "Fast and Accurate Object Detection on Asymmetrical Receptive Field",
    "abstract": "Object detection has been used in a wide range of industries. For example, in autonomous driving, the task of object detection is to accurately and efficiently identify and locate a large number of predefined classes of object instances (vehicles, pedestrians, traffic signs, etc.) from videos of roads. In robotics, the industry robot needs to recognize specific machine elements. In the security field, the camera should accurately recognize each face of people. With the wide application of deep learning, the accuracy and efficiency of object detection have been greatly improved, but object detection based on deep learning still faces challenges. Different applications of object detection have different requirements, including highly accurate detection, multi-category object detection, real-time detection, robustness to occlusions, etc. To address the above challenges, based on extensive literature research, this paper analyzes methods for improving and optimizing mainstream object detection algorithms from the perspective of evolution of one-stage and two-stage object detection algorithms. Furthermore, this article proposes methods for improving object detection accuracy from the perspective of changing receptive fields. The new model is based on the original YOLOv5 (You Look Only Once) with some modifications. The structure of the head part of YOLOv5 is modified by adding asymmetrical pooling layers. As a result, the accuracy of the algorithm is improved while ensuring the speed. The performances of the new model in this article are compared with original YOLOv5 model and analyzed from several parameters. And the evaluation of the new model is presented in four situations. Moreover, the summary and outlooks are made on the problems to be solved and the research directions in the future. ",
    "url": "https://arxiv.org/abs/2303.08995",
    "authors": [
      "Liguo Zhou",
      "Tianhao Lin",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08998",
    "title": "Unified Visual Relationship Detection with Vision and Language Models",
    "abstract": "This work focuses on training a single visual relationship detector predicting over the union of label spaces from multiple datasets. Merging labels spanning different datasets could be challenging due to inconsistent taxonomies. The issue is exacerbated in visual relationship detection when second-order visual semantics are introduced between pairs of objects. To address this challenge, we propose UniVRD, a novel bottom-up method for Unified Visual Relationship Detection by leveraging vision and language models (VLMs). VLMs provide well-aligned image and text embeddings, where similar relationships are optimized to be close to each other for semantic unification. Our bottom-up design enables the model to enjoy the benefit of training with both object detection and visual relationship datasets. Empirical results on both human-object interaction detection and scene-graph generation demonstrate the competitive performance of our model. UniVRD achieves 38.07 mAP on HICO-DET, outperforming the current best bottom-up HOI detector by 60% relatively. More importantly, we show that our unified detector performs as well as dataset-specific models in mAP, and achieves further improvements when we scale up the model. ",
    "url": "https://arxiv.org/abs/2303.08998",
    "authors": [
      "Long Zhao",
      "Liangzhe Yuan",
      "Boqing Gong",
      "Yin Cui",
      "Florian Schroff",
      "Ming-Hsuan Yang",
      "Hartwig Adam",
      "Ting Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09008",
    "title": "Not Seen, Not Heard in the Digital World! Measuring Privacy Practices in  Children's Apps",
    "abstract": "The digital age has brought a world of opportunity to children. Connectivity can be a game-changer for some of the world's most marginalized children. However, while legislatures around the world have enacted regulations to protect children's online privacy, and app stores have instituted various protections, privacy in mobile apps remains a growing concern for parents and wider society. In this paper, we explore the potential privacy issues and threats that exist in these apps. We investigate 20,195 mobile apps from the Google Play store that are designed particularly for children (Family apps) or include children in their target user groups (Normal apps). Using both static and dynamic analysis, we find that 4.47% of Family apps request location permissions, even though collecting location information from children is forbidden by the Play store, and 81.25% of Family apps use trackers (which are not allowed in children's apps). Even major developers with 40+ kids apps on the Play store use ad trackers. Furthermore, we find that most permission request notifications are not well designed for children, and 19.25% apps have inconsistent content age ratings across the different protection authorities. Our findings suggest that, despite significant attention to children's privacy, a large gap between regulatory provisions, app store policies, and actual development practices exist. Our research sheds light for government policymakers, app stores, and developers. ",
    "url": "https://arxiv.org/abs/2303.09008",
    "authors": [
      "Ruoxi Sun",
      "Minhui Xue",
      "Gareth Tyson",
      "Shuo Wang",
      "Seyit Camtepe",
      "Surya Nepal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.09024",
    "title": "DeeBBAA: A benchmark Deep Black Box Adversarial Attack against  Cyber-Physical Power Systems",
    "abstract": "An increased energy demand, and environmental pressure to accommodate higher levels of renewable energy and flexible loads like electric vehicles have led to numerous smart transformations in the modern power systems. These transformations make the cyber-physical power system highly susceptible to cyber-adversaries targeting its numerous operations. In this work, a novel black box adversarial attack strategy is proposed targeting the AC state estimation operation of an unknown power system using historical data. Specifically, false data is injected into the measurements obtained from a small subset of the power system components which leads to significant deviations in the state estimates. Experiments carried out on the IEEE 39 bus and 118 bus test systems make it evident that the proposed strategy, called DeeBBAA, can evade numerous conventional and state-of-the-art attack detection mechanisms with very high probability. ",
    "url": "https://arxiv.org/abs/2303.09024",
    "authors": [
      "Arnab Bhattacharjee",
      "Tapan K. Saha",
      "Ashu Verma",
      "Sukumar Mishra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.09026",
    "title": "Commonsense Knowledge Assisted Deep Learning for Resource-constrained  and Fine-grained Object Detection",
    "abstract": "In this paper, we consider fine-grained image object detection in resource-constrained cases such as edge computing. Deep learning (DL), namely learning with deep neural networks (DNNs), has become the dominating approach to object detection. To achieve accurate fine-grained detection, one needs to employ a large enough DNN model and a vast amount of data annotations, which brings a challenge for using modern DL object detectors in resource-constrained cases. To this end, we propose an approach, which leverages commonsense knowledge to assist a coarse-grained object detector to get accurate fine-grained detection results. Specifically, we introduce a commonsense knowledge inference module (CKIM) to process coarse-grained lables given by a benchmark DL detector to produce fine-grained lables. We consider both crisp-rule and fuzzy-rule based inference in our CKIM; the latter is used to handle ambiguity in the target semantic labels. We implement our method based on several modern DL detectors, namely YOLOv4, Mobilenetv3-SSD and YOLOv7-tiny. Experiment results show that our approach outperforms benchmark detectors remarkably in terms of accuracy, model size and processing latency. ",
    "url": "https://arxiv.org/abs/2303.09026",
    "authors": [
      "Pu Zhang",
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09030",
    "title": "Large Selective Kernel Network for Remote Sensing Object Detection",
    "abstract": "Recent research on remote sensing object detection has largely focused on improving the representation of oriented bounding boxes but has overlooked the unique prior knowledge presented in remote sensing scenarios. Such prior knowledge can be useful because tiny remote sensing objects may be mistakenly detected without referencing a sufficiently long-range context, and the long-range context required by different types of objects can vary. In this paper, we take these priors into account and propose the Large Selective Kernel Network (LSKNet). LSKNet can dynamically adjust its large spatial receptive field to better model the ranging context of various objects in remote sensing scenarios. To the best of our knowledge, this is the first time that large and selective kernel mechanisms have been explored in the field of remote sensing object detection. Without bells and whistles, LSKNet sets new state-of-the-art scores on standard benchmarks, i.e., HRSC2016 (98.46\\% mAP), DOTA-v1.0 (81.64\\% mAP) and FAIR1M-v1.0 (47.87\\% mAP). Based on a similar technique, we rank 2nd place in 2022 the Greater Bay Area International Algorithm Competition. Code is available at https://github.com/zcablii/Large-Selective-Kernel-Network. ",
    "url": "https://arxiv.org/abs/2303.09030",
    "authors": [
      "Yuxuan Li",
      "Qibin Hou",
      "Zhaohui Zheng",
      "Ming-Ming Cheng",
      "Jian Yang",
      "Xiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09034",
    "title": "Unsupervised Facial Expression Representation Learning with Contrastive  Local Warping",
    "abstract": "This paper investigates unsupervised representation learning for facial expression analysis. We think Unsupervised Facial Expression Representation (UFER) deserves exploration and has the potential to address some key challenges in facial expression analysis, such as scaling, annotation bias, the discrepancy between discrete labels and continuous emotions, and model pre-training. Such motivated, we propose a UFER method with contrastive local warping (ContraWarping), which leverages the insight that the emotional expression is robust to current global transformation (affine transformation, color jitter, etc.) but can be easily changed by random local warping. Therefore, given a facial image, ContraWarping employs some global transformations and local warping to generate its positive and negative samples and sets up a novel contrastive learning framework. Our in-depth investigation shows that: 1) the positive pairs from global transformations may be exploited with general self-supervised learning (e.g., BYOL) and already bring some informative features, and 2) the negative pairs from local warping explicitly introduce expression-related variation and further bring substantial improvement. Based on ContraWarping, we demonstrate the benefit of UFER under two facial expression analysis scenarios: facial expression recognition and image retrieval. For example, directly using ContraWarping features for linear probing achieves 79.14% accuracy on RAF-DB, significantly reducing the gap towards the full-supervised counterpart (88.92% / 84.81% with/without pre-training). ",
    "url": "https://arxiv.org/abs/2303.09034",
    "authors": [
      "Fanglei Xue",
      "Yifan Sun",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09035",
    "title": "Extracting the Brain-like Representation by an Improved Self-Organizing  Map for Image Classification",
    "abstract": "Backpropagation-based supervised learning has achieved great success in computer vision tasks. However, its biological plausibility is always controversial. Recently, the bio-inspired Hebbian learning rule (HLR) has received extensive attention. Self-Organizing Map (SOM) uses the competitive HLR to establish connections between neurons, obtaining visual features in an unsupervised way. Although the representation of SOM neurons shows some brain-like characteristics, it is still quite different from the neuron representation in the human visual cortex. This paper proposes an improved SOM with multi-winner, multi-code, and local receptive field, named mlSOM. We observe that the neuron representation of mlSOM is similar to the human visual cortex. Furthermore, mlSOM shows a sparse distributed representation of objects, which has also been found in the human inferior temporal area. In addition, experiments show that mlSOM achieves better classification accuracy than the original SOM and other state-of-the-art HLR-based methods. The code is accessible at https://github.com/JiaHongZ/mlSOM. ",
    "url": "https://arxiv.org/abs/2303.09035",
    "authors": [
      "Jiahong Zhang",
      "Lihong Cao",
      "Moning Zhang",
      "Wenlong Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09042",
    "title": "Embedding Theory of Reservoir Computing and Reducing Reservoir Network  Using Time Delays",
    "abstract": "Reservoir computing (RC), a particular form of recurrent neural network, is under explosive development due to its exceptional efficacy and high performance in reconstruction or/and prediction of complex physical systems. However, the mechanism triggering such effective applications of RC is still unclear, awaiting deep and systematic exploration. Here, combining the delayed embedding theory with the generalized embedding theory, we rigorously prove that RC is essentially a high dimensional embedding of the original input nonlinear dynamical system. Thus, using this embedding property, we unify into a universal framework the standard RC and the time-delayed RC where we novelly introduce time delays only into the network's output layer, and we further find a trade-off relation between the time delays and the number of neurons in RC. Based on this finding, we significantly reduce the network size of RC for reconstructing and predicting some representative physical systems, and, more surprisingly, only using a single neuron reservoir with time delays is sometimes sufficient for achieving those tasks. ",
    "url": "https://arxiv.org/abs/2303.09042",
    "authors": [
      "Xing-Yue Duan",
      "Xiong Ying",
      "Si-Yang Leng",
      "J\u00fcrgen Kurths",
      "Wei Lin",
      "Huan-Fei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2303.09046",
    "title": "Self-Supervised Visual Representation Learning on Food Images",
    "abstract": "Food image analysis is the groundwork for image-based dietary assessment, which is the process of monitoring what kinds of food and how much energy is consumed using captured food or eating scene images. Existing deep learning-based methods learn the visual representation for downstream tasks based on human annotation of each food image. However, most food images in real life are obtained without labels, and data annotation requires plenty of time and human effort, which is not feasible for real-world applications. To make use of the vast amount of unlabeled images, many existing works focus on unsupervised or self-supervised learning of visual representations directly from unlabeled data. However, none of these existing works focus on food images, which is more challenging than general objects due to its high inter-class similarity and intra-class variance. In this paper, we focus on the implementation and analysis of existing representative self-supervised learning methods on food images. Specifically, we first compare the performance of six selected self-supervised learning models on the Food-101 dataset. Then we analyze the pros and cons of each selected model when training on food data to identify the key factors that can help improve the performance. Finally, we propose several ideas for future work on self-supervised visual representation learning for food images. ",
    "url": "https://arxiv.org/abs/2303.09046",
    "authors": [
      "Andrew Peng",
      "Jiangpeng He",
      "Fengqing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.09051",
    "title": "Robust Evaluation of Diffusion-Based Adversarial Purification",
    "abstract": "We question the current evaluation practice on diffusion-based purification methods. Diffusion-based purification methods aim to remove adversarial effects from an input data point at test time. The approach gains increasing attention as an alternative to adversarial training due to the disentangling between training and testing. Well-known white-box attacks are often employed to measure the robustness of the purification. However, it is unknown whether these attacks are the most effective for the diffusion-based purification since the attacks are often tailored for adversarial training. We analyze the current practices and provide a new guideline for measuring the robustness of purification methods against adversarial attacks. Based on our analysis, we further propose a new purification strategy showing competitive results against the state-of-the-art adversarial training approaches. ",
    "url": "https://arxiv.org/abs/2303.09051",
    "authors": [
      "Minjong Lee",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09061",
    "title": "MixTeacher: Mining Promising Labels with Mixed Scale Teacher for  Semi-Supervised Object Detection",
    "abstract": "Scale variation across object instances remains a key challenge in object detection task. Despite the remarkable progress made by modern detection models, this challenge is particularly evident in the semi-supervised case. While existing semi-supervised object detection methods rely on strict conditions to filter high-quality pseudo labels from network predictions, we observe that objects with extreme scale tend to have low confidence, resulting in a lack of positive supervision for these objects. In this paper, we propose a novel framework that addresses the scale variation problem by introducing a mixed scale teacher to improve pseudo label generation and scale-invariant learning. Additionally, we propose mining pseudo labels using score promotion of predictions across scales, which benefits from better predictions from mixed scale features. Our extensive experiments on MS COCO and PASCAL VOC benchmarks under various semi-supervised settings demonstrate that our method achieves new state-of-the-art performance. The code and models are available at \\url{https://github.com/lliuz/MixTeacher}. ",
    "url": "https://arxiv.org/abs/2303.09061",
    "authors": [
      "Liang Liu",
      "Boshen Zhang",
      "Jiangning Zhang",
      "Wuhao Zhang",
      "Zhenye Gan",
      "Guanzhong Tian",
      "Wenbing Zhu",
      "Yabiao Wang",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09063",
    "title": "Plant Disease Detection using Region-Based Convolutional Neural Network",
    "abstract": "Agriculture plays an important role in the food and economy of Bangladesh. The rapid growth of population over the years also has increased the demand for food production. One of the major reasons behind low crop production is numerous bacteria, virus and fungal plant diseases. Early detection of plant diseases and proper usage of pesticides and fertilizers are vital for preventing the diseases and boost the yield. Most of the farmers use generalized pesticides and fertilizers in the entire fields without specifically knowing the condition of the plants. Thus the production cost oftentimes increases, and, not only that, sometimes this becomes detrimental to the yield. Deep Learning models are found to be very effective to automatically detect plant diseases from images of plants, thereby reducing the need for human specialists. This paper aims at building a lightweight deep learning model for predicting leaf disease in tomato plants. By modifying the region-based convolutional neural network, we design an efficient and effective model that demonstrates satisfactory empirical performance on a benchmark dataset. Our proposed model can easily be deployed in a larger system where drones take images of leaves and these images will be fed into our model to know the health condition. ",
    "url": "https://arxiv.org/abs/2303.09063",
    "authors": [
      "Hasin Rehana",
      "Muhammad Ibrahim",
      "Md. Haider Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09068",
    "title": "VFP: Converting Tabular Data for IIoT into Images Considering  Correlations of Attributes for Convolutional Neural Networks",
    "abstract": "For tabular data generated from IIoT devices, traditional machine learning (ML) techniques based on the decision tree algorithm have been employed. However, these methods have limitations in processing tabular data where real number attributes dominate. To address this issue, DeepInsight, REFINED, and IGTD were proposed to convert tabular data into images for utilizing convolutional neural networks (CNNs). They gather similar features in some specific spots of an image to make the converted image look like an actual image. Gathering similar features contrasts with traditional ML techniques for tabular data, which drops some highly correlated attributes to avoid overfitting. Also, previous converting methods fixed the image size, and there are wasted or insufficient pixels according to the number of attributes of tabular data. Therefore, this paper proposes a new converting method, Vortex Feature Positioning (VFP). VFP considers the correlation of features and places similar features far away from each. Features are positioned in the vortex shape from the center of an image, and the number of attributes determines the image size. VFP shows better test performance than traditional ML techniques for tabular data and previous converting methods in five datasets: Iris, Wine, Dry Bean, Epileptic Seizure, and SECOM, which have differences in the number of attributes. ",
    "url": "https://arxiv.org/abs/2303.09068",
    "authors": [
      "Jong-Ik Park",
      "Cheol-Ho Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.09079",
    "title": "SSL-Cleanse: Trojan Detection and Mitigation in Self-Supervised Learning",
    "abstract": "Self-supervised learning (SSL) is a commonly used approach to learning and encoding data representations. By using a pre-trained SSL image encoder and training a downstream classifier on top of it, impressive performance can be achieved on various tasks with very little labeled data. The increasing usage of SSL has led to an uptick in security research related to SSL encoders and the development of various Trojan attacks. The danger posed by Trojan attacks inserted in SSL encoders lies in their ability to operate covertly and spread widely among various users and devices. The presence of backdoor behavior in Trojaned encoders can inadvertently be inherited by downstream classifiers, making it even more difficult to detect and mitigate the threat. Although current Trojan detection methods in supervised learning can potentially safeguard SSL downstream classifiers, identifying and addressing triggers in the SSL encoder before its widespread dissemination is a challenging task. This is because downstream tasks are not always known, dataset labels are not available, and even the original training dataset is not accessible during the SSL encoder Trojan detection. This paper presents an innovative technique called SSL-Cleanse that is designed to detect and mitigate backdoor attacks in SSL encoders. We evaluated SSL-Cleanse on various datasets using 300 models, achieving an average detection success rate of 83.7% on ImageNet-100. After mitigating backdoors, on average, backdoored encoders achieve 0.24% attack success rate without great accuracy loss, proving the effectiveness of SSL-Cleanse. ",
    "url": "https://arxiv.org/abs/2303.09079",
    "authors": [
      "Mengxin Zheng",
      "Jiaqi Xue",
      "Xun Chen",
      "Lei Jiang",
      "Qian Lou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09081",
    "title": "Physical and Economic Viability of Cryptocurrency Mining for Provision  of Frequency Regulation: A Real-World Texas Case Study",
    "abstract": "Demand flexibility plays a pivotal role in modern power systems with high penetration of variable energy resources. In recent years, one of the fastest-growing flexible energy demands has been proof-of-work-based cryptocurrency mining facilities. Due to their competitive ramping capabilities and demonstrated flexibility, such fast-responding loads are capable of participating in frequency regulation services for the grid while simultaneously increasing their own operational revenue. In this paper, we investigate the physical and economic viability of employing cryptocurrency mining facilities to provide frequency regulation in large power systems. We quantify mining facilities' operational profit, and propose a decision-making framework to explore their optimal participation strategy and account for the most influential factors. We employ real-world ERCOT ancillary services data in our case study to investigate the conditions under which provision of frequency regulation in the Texas grid is profitable. We also perform transient level simulations using a synthetic Texas grid to demonstrate the competitiveness of mining facilities at frequency regulation provision. ",
    "url": "https://arxiv.org/abs/2303.09081",
    "authors": [
      "Rayan El Helou",
      "Ali Menati",
      "Le Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.09086",
    "title": "Optimal Intervention on Weighted Networks via Edge Centrality",
    "abstract": "Suppose there is a spreading process such as an infectious disease propagating on a graph. How would we reduce the number of affected nodes in the spreading process? This question appears in recent studies about implementing mobility interventions on mobility networks (Chang et al. (2021)). A practical algorithm to reduce infections on unweighted graphs is to remove edges with the highest edge centrality score (Tong et al. (2012)), which is the product of two adjacent nodes' eigenscores. However, mobility networks have weighted edges; Thus, an intervention measure would involve edge-weight reduction besides edge removal. Motivated by this example, we revisit the problem of minimizing top eigenvalue(s) on weighted graphs by decreasing edge weights up to a fixed budget. We observe that the edge centrality score of Tong et al. (2012) is equal to the gradient of the largest eigenvalue of $WW^{\\top}$, where $W$ denotes the weight matrix of the graph. We then present generalized edge centrality scores as the gradient of the sum of the largest $r$ eigenvalues of $WW^{\\top}$. With this generalization, we design an iterative algorithm to find the optimal edge-weight reduction to shrink the largest $r$ eigenvalues of $WW^{\\top}$ under a given edge-weight reduction budget. We also extend our algorithm and its guarantee to time-varying graphs, whose weights evolve over time. We perform a detailed empirical study to validate our approach. Our algorithm significantly reduces the number of infections compared with existing methods on eleven weighted networks. Further, we illustrate several properties of our algorithm, including the benefit of choosing the rank $r$, fast convergence to global optimum, and an almost linear runtime per iteration. ",
    "url": "https://arxiv.org/abs/2303.09086",
    "authors": [
      "Dongyue Li",
      "Tina Eliassi-Rad",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.09093",
    "title": "GLEN: General-Purpose Event Detection for Thousands of Types",
    "abstract": "The development of event extraction systems has been hindered by the absence of wide-coverage, large-scale datasets. To make event extraction systems more accessible, we build a general-purpose event detection dataset GLEN, which covers 3,465 different event types, making it over 20x larger in ontology than any current dataset. GLEN is created by utilizing the DWD Overlay, which provides a mapping between Wikidata Qnodes and PropBank rolesets. This enables us to use the abundant existing annotation for PropBank as distant supervision. In addition, we also propose a new multi-stage event detection model specifically designed to handle the large ontology size and partial labels in GLEN. We show that our model exhibits superior performance (~10% F1 gain) compared to both conventional classification baselines and newer definition-based models. Finally, we perform error analysis and show that label noise is still the largest challenge for improving performance. ",
    "url": "https://arxiv.org/abs/2303.09093",
    "authors": [
      "Qiusi Zhan",
      "Sha Li",
      "Kathryn Conger",
      "Martha Palmer",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.09105",
    "title": "Rethinking Model Ensemble in Transfer-based Adversarial Attacks",
    "abstract": "Deep learning models are vulnerable to adversarial examples. Transfer-based adversarial attacks attract tremendous attention as they can identify the weaknesses of deep learning models in a black-box manner. An effective strategy to improve the transferability of adversarial examples is attacking an ensemble of models. However, previous works simply average the outputs of different models, lacking an in-depth analysis on how and why model ensemble can strongly improve the transferability. In this work, we rethink the ensemble in adversarial attacks and define the common weakness of model ensemble with the properties of the flatness of loss landscape and the closeness to the local optimum of each model. We empirically and theoretically show that these two properties are strongly correlated with the transferability and propose a Common Weakness Attack (CWA) to generate more transferable adversarial examples by promoting these two properties. Experimental results on both image classification and object detection tasks validate the effectiveness of our approach to improve the adversarial transferability, especially when attacking adversarially trained models. ",
    "url": "https://arxiv.org/abs/2303.09105",
    "authors": [
      "Huanran Chen",
      "Yichi Zhang",
      "Yinpeng Dong",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09114",
    "title": "AU-aware graph convolutional network for Macro- and Micro-expression  spotting",
    "abstract": "Automatic Micro-Expression (ME) spotting in long videos is a crucial step in ME analysis but also a challenging task due to the short duration and low intensity of MEs. When solving this problem, previous works generally lack in considering the structures of human faces and the correspondence between expressions and relevant facial muscles. To address this issue for better performance of ME spotting, this paper seeks to extract finer spatial features by modeling the relationships between facial Regions of Interest (ROIs). Specifically, we propose a graph convolutional-based network, called Action-Unit-aWare Graph Convolutional Network (AUW-GCN). Furthermore, to inject prior information and to cope with the problem of small datasets, AU-related statistics are encoded into the network. Comprehensive experiments show that our results outperform baseline methods consistently and achieve new SOTA performance in two benchmark datasets,CAS(ME)^2 and SAMM-LV. Our code is available at https://github.com/xjtupanda/AUW-GCN. ",
    "url": "https://arxiv.org/abs/2303.09114",
    "authors": [
      "Shukang Yin",
      "Shiwei Wu",
      "Tong Xu",
      "Shifeng Liu",
      "Sirui Zhao",
      "Enhong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09117",
    "title": "Visual-Linguistic Causal Intervention for Radiology Report Generation",
    "abstract": "Automatic radiology report generation is essential for computer-aided diagnosis and medication guidance. Importantly, automatic radiology report generation (RRG) can relieve the heavy burden of radiologists by generating medical reports automatically from visual-linguistic data relations. However, due to the spurious correlations within image-text data induced by visual and linguistic biases, it is challenging to generate accurate reports that reliably describe abnormalities. Besides, the cross-modal confounder is usually unobservable and difficult to be eliminated explicitly. In this paper, we mitigate the cross-modal data bias for RRG from a new perspective, i.e., visual-linguistic causal intervention, and propose a novel Visual-Linguistic Causal Intervention (VLCI) framework for RRG, which consists of a visual deconfounding module (VDM) and a linguistic deconfounding module (LDM), to implicitly deconfound the visual-linguistic confounder by causal front-door intervention. Specifically, the VDM explores and disentangles the visual confounder from the patch-based local and global features without object detection due to the absence of universal clinic semantic extraction. Simultaneously, the LDM eliminates the linguistic confounder caused by salient visual features and high-frequency context without constructing specific dictionaries. Extensive experiments on IU-Xray and MIMIC-CXR datasets show that our VLCI outperforms the state-of-the-art RRG methods significantly. Source code and models are available at https://github.com/WissingChen/VLCI. ",
    "url": "https://arxiv.org/abs/2303.09117",
    "authors": [
      "Weixing Chen",
      "Yang Liu",
      "Ce Wang",
      "Guanbin Li",
      "Jiarui Zhu",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09124",
    "title": "Fiber Tract Shape Measures Inform Prediction of Non-Imaging Phenotypes",
    "abstract": "Neuroimaging measures of the brain's white matter connections can enable the prediction of non-imaging phenotypes, such as demographic and cognitive measures. Existing works have investigated traditional microstructure and connectivity measures from diffusion MRI tractography, without considering the shape of the connections reconstructed by tractography. In this paper, we investigate the potential of fiber tract shape features for predicting non-imaging phenotypes, both individually and in combination with traditional features. We focus on three basic shape features: length, diameter, and elongation. Two different prediction methods are used, including a traditional regression method and a deep-learning-based prediction method. Experiments use an efficient two-stage fusion strategy for prediction using microstructure, connectivity, and shape measures. To reduce predictive bias due to brain size, normalized shape features are also investigated. Experimental results on the Human Connectome Project (HCP) young adult dataset (n=1065) demonstrate that individual shape features are predictive of non-imaging phenotypes. When combined with microstructure and connectivity features, shape features significantly improve performance for predicting the cognitive score TPVT (NIH Toolbox picture vocabulary test). Overall, this study demonstrates that the shape of fiber tracts contains useful information for the description and study of the living human brain using machine learning. ",
    "url": "https://arxiv.org/abs/2303.09124",
    "authors": [
      "Wan Liu",
      "Yuqian Chen",
      "Chuyang Ye",
      "Nikos Makris",
      "Yogesh Rathi",
      "Weidong Cai",
      "Fan Zhang",
      "Lauren J. O' Donnell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09128",
    "title": "Exploring Distributional Shifts in Large Language Models for Code  Analysis",
    "abstract": "We systematically study the capacity of two large language models for code - CodeT5 and Codex - to generalize to out-of-domain data. In this study, we consider two fundamental applications - code summarization, and code generation. We split data into domains following its natural boundaries - by an organization, by a project, and by a module within the software project. This makes recognition of in-domain vs out-of-domain data at the time of deployment trivial. We establish that samples from each new domain present both models with a significant challenge of distribution shift. We study how well different established methods can adapt models to better generalize to new domains. Our experiments show that while multitask learning alone is a reasonable baseline, combining it with few-shot finetuning on examples retrieved from training data can achieve very strong performance. In fact, according to our experiments, this solution can outperform direct finetuning for very low-data scenarios. Finally, we consider variations of this approach to create a more broadly applicable method to adapt to multiple domains at once. We find that in the case of code generation, a model adapted to multiple domains simultaneously performs on par with those adapted to each domain individually. ",
    "url": "https://arxiv.org/abs/2303.09128",
    "authors": [
      "Shushan Arakelyan",
      "Rocktim Jyoti Das",
      "Yi Mao",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.09152",
    "title": "Learning a Room with the Occ-SDF Hybrid: Signed Distance Function  Mingled with Occupancy Aids Scene Representation",
    "abstract": "Implicit neural rendering, which uses signed distance function (SDF) representation with geometric priors (such as depth or surface normal), has led to impressive progress in the surface reconstruction of large-scale scenes. However, applying this method to reconstruct a room-level scene from images may miss structures in low-intensity areas or small and thin objects. We conducted experiments on three datasets to identify limitations of the original color rendering loss and priors-embedded SDF scene representation. We found that the color rendering loss results in optimization bias against low-intensity areas, causing gradient vanishing and leaving these areas unoptimized. To address this issue, we propose a feature-based color rendering loss that utilizes non-zero feature values to bring back optimization signals. Additionally, the SDF representation can be influenced by objects along a ray path, disrupting the monotonic change of SDF values when a single object is present. To counteract this, we explore using the occupancy representation, which encodes each point separately and is unaffected by objects along a querying ray. Our experimental results demonstrate that the joint forces of the feature-based rendering loss and Occ-SDF hybrid representation scheme can provide high-quality reconstruction results, especially in challenging room-level scenarios. The code would be released. ",
    "url": "https://arxiv.org/abs/2303.09152",
    "authors": [
      "Xiaoyang Lyu",
      "Peng Dai",
      "Zizhang Li",
      "Dongyu Yan",
      "Yi Lin",
      "Yifan Peng",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09171",
    "title": "Fine-Grained and High-Faithfulness Explanations for Convolutional Neural  Networks",
    "abstract": "Recently, explaining CNNs has become a research hotspot. CAM (Class Activation Map)-based methods and LRP (Layer-wise Relevance Propagation) method are two common explanation methods. However, due to the small spatial resolution of the last convolutional layer, the CAM-based methods can often only generate coarse-grained visual explanations that provide a coarse location of the target object. LRP and its variants, on the other hand, can generate fine-grained explanations. But the faithfulness of the explanations is too low. In this paper, we propose FG-CAM (fine-grained CAM), which extends the CAM-based methods to generate fine-grained visual explanations with high faithfulness. FG-CAM uses the relationship between two adjacent layers of feature maps with resolution difference to gradually increase the explanation resolution, while finding the contributing pixels and filtering out the pixels that do not contribute at each step. Our method not only solves the shortcoming of CAM-based methods without changing their characteristics, but also generates fine-grained explanations that have higher faithfulness than LRP and its variants. We also present FG-CAM with denoising, which is a variant of FG-CAM and is able to generate less noisy explanations with almost no change in explanation faithfulness. Experimental results show that the performance of FG-CAM is almost unaffected by the explanation resolution. FG-CAM outperforms existing CAM-based methods significantly in the both shallow and intermediate convolutional layers, and outperforms LRP and its variations significantly in the input layer. ",
    "url": "https://arxiv.org/abs/2303.09171",
    "authors": [
      "Changqing Qiu",
      "Fusheng Jin",
      "Yining Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09173",
    "title": "Network-based Control of Epidemic via Flattening the Infection Curve:  High-Clustered vs. Low-Clustered Social Networks",
    "abstract": "Recent studies in network science and control have shown a meaningful relationship between the epidemic processes (e.g., COVID-19 spread) and some network properties. This paper studies how such network properties, namely clustering coefficient and centrality measures (or node influence metrics), affect the spread of viruses and the growth of epidemics over scale-free networks. The results can be used to target individuals (the nodes in the network) to \\textit{flatten the infection curve}. This so-called flattening of the infection curve is to reduce the health service costs and burden to the authorities/governments. Our Monte-Carlo simulation results show that clustered networks are, in general, easier to flatten the infection curve, i.e., with the same connectivity and the same number of isolated individuals they result in more flattened curves. Moreover, distance-based centrality measures, which target the nodes based on their average network distance to other nodes (and not the node degrees), are better choices for targeting individuals for isolation/vaccination. ",
    "url": "https://arxiv.org/abs/2303.09173",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.09174",
    "title": "Grab What You Need: Rethinking Complex Table Structure Recognition with  Flexible Components Deliberation",
    "abstract": "Recently, Table Structure Recognition (TSR) task, aiming at identifying table structure into machine readable formats, has received increasing interest in the community. While impressive success, most single table component-based methods can not perform well on unregularized table cases distracted by not only complicated inner structure but also exterior capture distortion. In this paper, we raise it as Complex TSR problem, where the performance degeneration of existing methods is attributable to their inefficient component usage and redundant post-processing. To mitigate it, we shift our perspective from table component extraction towards the efficient multiple components leverage, which awaits further exploration in the field. Specifically, we propose a seminal method, termed GrabTab, equipped with newly proposed Component Deliberator. Thanks to its progressive deliberation mechanism, our GrabTab can flexibly accommodate to most complex tables with reasonable components selected but without complicated post-processing involved. Quantitative experimental results on public benchmarks demonstrate that our method significantly outperforms the state-of-the-arts, especially under more challenging scenes. ",
    "url": "https://arxiv.org/abs/2303.09174",
    "authors": [
      "Hao Liu",
      "Xin Li",
      "Mingming Gong",
      "Bing Liu",
      "Yunfei Wu",
      "Deqiang Jiang",
      "Yinsong Liu",
      "Xing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09190",
    "title": "A Framework for Real-time Object Detection and Image Restoration",
    "abstract": "Object detection and single image super-resolution are classic problems in computer vision (CV). The object detection task aims to recognize the objects in input images, while the image restoration task aims to reconstruct high quality images from given low quality images. In this paper, a two-stage framework for object detection and image restoration is proposed. The first stage uses YOLO series algorithms to complete the object detection and then performs image cropping. In the second stage, this work improves Swin Transformer and uses the new proposed algorithm to connect the Swin Transformer layer to design a new neural network architecture. We name the newly proposed network for image restoration SwinOIR. This work compares the model performance of different versions of YOLO detection algorithms on MS COCO dataset and Pascal VOC dataset, demonstrating the suitability of different YOLO network models for the first stage of the framework in different scenarios. For image super-resolution task, it compares the model performance of using different methods of connecting Swin Transformer layers and design different sizes of SwinOIR for use in different life scenarios. Our implementation code is released at https://github.com/Rubbbbbbbbby/SwinOIR. ",
    "url": "https://arxiv.org/abs/2303.09190",
    "authors": [
      "Rui-Yang Ju",
      "Chih-Chia Chen",
      "Jen-Shiun Chiang",
      "Yu-Shian Lin",
      "Wei-Han Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09197",
    "title": "Temporality and Causality in Abstract Argumentation",
    "abstract": "In the context of abstract argumentation, we present the benefits of considering temporality, i.e. the order in which arguments are enunciated, as well as causality. We propose a formal method to rewrite the concepts of acyclic abstract argumentation frameworks into an action language, that allows us to model the evolution of the world, and to establish causal relationships between the enunciation of arguments and their consequences, whether direct or indirect. An Answer Set Programming implementation is also proposed, as well as perspectives towards explanations. ",
    "url": "https://arxiv.org/abs/2303.09197",
    "authors": [
      "Y. Munro",
      "C. Sarmiento",
      "I. Bloch",
      "G. Bourgne",
      "M.-J. Lesot"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09200",
    "title": "Reduction of rain-induced errors for wind speed estimation on SAR  observations using convolutional neural networks",
    "abstract": "Synthetic Aperture Radar is known to be able to provide high-resolution estimates of surface wind speed. These estimates usually rely on a Geophysical Model Function (GMF) that has difficulties accounting for non-wind processes such as rain events. Convolutional neural network, on the other hand, have the capacity to use contextual information and have demonstrated their ability to delimit rainfall areas. By carefully building a large dataset of SAR observations from the Copernicus Sentinel-1 mission, collocated with both GMF and atmospheric model wind speeds as well as rainfall estimates, we were able to train a wind speed estimator with reduced errors under rain. Collocations with in-situ wind speed measurements from buoys show a root mean square error that is reduced by 27% (resp. 45%) under rainfall estimated at more than 1 mm/h (resp. 3 mm/h). These results demonstrate the capacity of deep learning models to correct rain-related errors in SAR products. ",
    "url": "https://arxiv.org/abs/2303.09200",
    "authors": [
      "Aur\u00e9lien Colin",
      "Pierre Tandeo",
      "Charles Peureux",
      "Romain Husson",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2303.09210",
    "title": "A Dual Branch Network for Emotional Reaction Intensity Estimation",
    "abstract": "Emotional Reaction Intensity(ERI) estimation is an important task in multimodal scenarios, and has fundamental applications in medicine, safe driving and other fields. In this paper, we propose a solution to the ERI challenge of the fifth Affective Behavior Analysis in-the-wild(ABAW), a dual-branch based multi-output regression model. The spatial attention is used to better extract visual features, and the Mel-Frequency Cepstral Coefficients technology extracts acoustic features, and a method named modality dropout is added to fusion multimodal features. Our method achieves excellent results on the official validation set. ",
    "url": "https://arxiv.org/abs/2303.09210",
    "authors": [
      "Jun Yu",
      "Jichao Zhu",
      "Wangyuan Zhu",
      "Zhongpeng Cai",
      "Guochen Xie",
      "Renda Li",
      "Gongpeng Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.09234",
    "title": "NAISR: A 3D Neural Additive Model for Interpretable Shape Representation",
    "abstract": "Deep implicit functions (DIFs) have emerged as a powerful paradigm for many computer vision tasks such as 3D shape reconstruction, generation, registration, completion, editing, and understanding. However, given a set of 3D shapes with associated covariates there is at present no shape representation method which allows to precisely represent the shapes while capturing the individual dependencies on each covariate. Such a method would be of high utility to researchers to discover knowledge hidden in a population of shapes. We propose a 3D Neural Additive Model for Interpretable Shape Representation (NAISR) which describes individual shapes by deforming a shape atlas in accordance to the effect of disentangled covariates. Our approach captures shape population trends and allows for patient-specific predictions through shape transfer. NAISR is the first approach to combine the benefits of deep implicit shape representations with an atlas deforming according to specified covariates. Although our driving problem is the construction of an airway atlas, NAISR is a general approach for modeling, representing, and investigating shape populations. We evaluate NAISR with respect to shape reconstruction, shape disentanglement, shape evolution, and shape transfer for the pediatric upper airway. Our experiments demonstrate that NAISR achieves competitive shape reconstruction performance while retaining interpretability. ",
    "url": "https://arxiv.org/abs/2303.09234",
    "authors": [
      "Yining Jiao",
      "Carlton Zdanski",
      "Julia Kimbell",
      "Andrew Prince",
      "Cameron Worden",
      "Samuel Kirse",
      "Christopher Rutter",
      "Benjamin Shields",
      "William Dunn",
      "Jisan Mahmud",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09240",
    "title": "Human Reaction Intensity Estimation with Ensemble of Multi-task Networks",
    "abstract": "Facial expression in-the-wild is essential for various interactive computing domains. Especially, \"Emotional Reaction Intensity\" (ERI) is an important topic in the facial expression recognition task. In this paper, we propose a multi-emotional task learning-based approach and present preliminary results for the ERI challenge introduced in the 5th affective behavior analysis in-the-wild (ABAW) competition. Our method achieved the mean PCC score of 0.3254. ",
    "url": "https://arxiv.org/abs/2303.09240",
    "authors": [
      "JiYeon Oh",
      "Daun Kim",
      "Jae-Yeop Jeong",
      "Yeong-Gi Hong",
      "Jin-Woo Jeong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09252",
    "title": "GridCLIP: One-Stage Object Detection by Grid-Level CLIP Representation  Learning",
    "abstract": "A vision-language foundation model pretrained on very large-scale image-text paired data has the potential to provide generalizable knowledge representation for downstream visual recognition and detection tasks, especially on supplementing the undersampled categories in downstream model training. Recent studies utilizing CLIP for object detection have shown that a two-stage detector design typically outperforms a one-stage detector, while requiring more expensive training resources and longer inference time. In this work, we propose a one-stage detector GridCLIP that narrows its performance gap to those of two-stage detectors, with approximately 43 and 5 times faster than its two-stage counterpart (ViLD) in the training and test process respectively. GridCLIP learns grid-level representations to adapt to the intrinsic principle of one-stage detection learning by expanding the conventional CLIP image-text holistic mapping to a more fine-grained, grid-text alignment. This differs from the region-text mapping in two-stage detectors that apply CLIP directly by treating regions as images. Specifically, GridCLIP performs Grid-level Alignment to adapt the CLIP image-level representations to grid-level representations by aligning to CLIP category representations to learn the annotated (especially frequent) categories. To learn generalizable visual representations of broader categories, especially undersampled ones, we perform Image-level Alignment during training to propagate broad pre-learned categories in the CLIP image encoder from the image-level to the grid-level representations. Experiments show that the learned CLIP-based grid-level representations boost the performance of undersampled (infrequent and novel) categories, reaching comparable detection performance on the LVIS benchmark. ",
    "url": "https://arxiv.org/abs/2303.09252",
    "authors": [
      "Jiayi Lin",
      "Shaogang Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09280",
    "title": "Topology optimization with physics-informed neural networks: application  to noninvasive detection of hidden geometries",
    "abstract": "Detecting hidden geometrical structures from surface measurements under electromagnetic, acoustic, or mechanical loading is the goal of noninvasive imaging techniques in medical and industrial applications. Solving the inverse problem can be challenging due to the unknown topology and geometry, the sparsity of the data, and the complexity of the physical laws. Physics-informed neural networks (PINNs) have shown promise as a simple-yet-powerful tool for problem inversion, but they have yet to be applied to general problems with a priori unknown topology. Here, we introduce a topology optimization framework based on PINNs that solves geometry detection problems without prior knowledge of the number or types of shapes. We allow for arbitrary solution topology by representing the geometry using a material density field that approaches binary values thanks to a novel eikonal regularization. We validate our framework by detecting the number, locations, and shapes of hidden voids and inclusions in linear and nonlinear elastic bodies using measurements of outer surface displacement from a single mechanical loading experiment. Our methodology opens a pathway for PINNs to solve various engineering problems targeting geometry optimization. ",
    "url": "https://arxiv.org/abs/2303.09280",
    "authors": [
      "Saviz Mowlavi",
      "Ken Kamrin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.09287",
    "title": "Semitopology: a new topological model of heterogeneous consensus",
    "abstract": "A distributed system is permissionless when participants can join and leave the network without permission from a central authority. Many modern distributed systems are naturally permissionless, in the sense that a central permissioning authority would defeat their design purpose: this includes blockchains, filesharing protocols, some voting systems, and more. By their permissionless nature, such systems are heterogeneous: participants may only have a partial view of the system, and they may also have different goals and beliefs. Thus, the traditional notion of consensus -- i.e. system-wide agreement -- may not be adequate, and we may need to generalise it. This is a challenge: how should we understand what heterogeneous consensus is; what mathematical framework might this require; and how can we use this to build understanding and mathematical models of robust, effective, and secure permissionless systems in practice? We analyse heterogeneous consensus using semitopology as a framework. This is like topology, but without the restriction that intersections of opens be open. Semitopologies have a rich theory which is related to topology, but with its own distinct character and mathematics. We introduce novel well-behavedness conditions, including an anti-Hausdorff property and a new notion of `topen set', and we show how these structures relate to consensus. We give a restriction of semitopologies to witness semitopologies, which are an algorithmically tractable subclass corresponding to Horn clause theories, having particularly good mathematical properties. We introduce and study several other basic notions that are specific and novel to semitopologies, and study how known quantities in topology, such as dense subsets and closures, display interesting and useful new behaviour in this new semitopological context. ",
    "url": "https://arxiv.org/abs/2303.09287",
    "authors": [
      "Murdoch Gabbay",
      "Giuliano Losa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "General Topology (math.GN)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2303.09293",
    "title": "A transformer-based approach to video frame-level prediction in  Affective Behaviour Analysis In-the-wild",
    "abstract": "In recent years, transformer architecture has been a dominating paradigm in many applications, including affective computing. In this report, we propose our transformer-based model to handle Emotion Classification Task in the 5th Affective Behavior Analysis In-the-wild Competition. By leveraging the attentive model and the synthetic dataset, we attain a score of 0.4775 on the validation set of Aff-Wild2, the dataset provided by the organizer. ",
    "url": "https://arxiv.org/abs/2303.09293",
    "authors": [
      "Dang-Khanh Nguyen",
      "Ngoc-Huynh Ho",
      "Sudarshan Pant",
      "Hyung-Jeong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.09295",
    "title": "DIRE for Diffusion-Generated Image Detection",
    "abstract": "Diffusion models have shown remarkable success in visual synthesis, but have also raised concerns about potential abuse for malicious purposes. In this paper, we seek to build a detector for telling apart real images from diffusion-generated images. We find that existing detectors struggle to detect images generated by diffusion models, even if we include generated images from a specific diffusion model in their training data. To address this issue, we propose a novel image representation called DIffusion Reconstruction Error (DIRE), which measures the error between an input image and its reconstruction counterpart by a pre-trained diffusion model. We observe that diffusion-generated images can be approximately reconstructed by a diffusion model while real images cannot. It provides a hint that DIRE can serve as a bridge to distinguish generated and real images. DIRE provides an effective way to detect images generated by most diffusion models, and it is general for detecting generated images from unseen diffusion models and robust to various perturbations. Furthermore, we establish a comprehensive diffusion-generated benchmark including images generated by eight diffusion models to evaluate the performance of diffusion-generated image detectors. Extensive experiments on our collected benchmark demonstrate that DIRE exhibits superiority over previous generated-image detectors. The code and dataset are available at https://github.com/ZhendongWang6/DIRE. ",
    "url": "https://arxiv.org/abs/2303.09295",
    "authors": [
      "Zhendong Wang",
      "Jianmin Bao",
      "Wengang Zhou",
      "Weilun Wang",
      "Hezhen Hu",
      "Hong Chen",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09306",
    "title": "Towards Robust Bangla Complex Named Entity Recognition",
    "abstract": "Named Entity Recognition (NER) is a fundamental task in natural language processing that involves identifying and classifying named entities in text. But much work hasn't been done for complex named entity recognition in Bangla, despite being the seventh most spoken language globally. CNER is a more challenging task than traditional NER as it involves identifying and classifying complex and compound entities, which are not common in Bangla language. In this paper, we present the winning solution of Bangla Complex Named Entity Recognition Challenge - addressing the CNER task on BanglaCoNER dataset using two different approaches, namely Conditional Random Fields (CRF) and finetuning transformer based Deep Learning models such as BanglaBERT. The dataset consisted of 15300 sentences for training and 800 sentences for validation, in the .conll format. Exploratory Data Analysis (EDA) on the dataset revealed that the dataset had 7 different NER tags, with notable presence of English words, suggesting that the dataset is synthetic and likely a product of translation. We experimented with a variety of feature combinations including Part of Speech (POS) tags, word suffixes, Gazetteers, and cluster information from embeddings, while also finetuning the BanglaBERT (large) model for NER. We found that not all linguistic patterns are immediately apparent or even intuitive to humans, which is why Deep Learning based models has proved to be the more effective model in NLP, including CNER task. Our fine tuned BanglaBERT (large) model achieves an F1 Score of 0.79 on the validation set. Overall, our study highlights the importance of Bangla Complex Named Entity Recognition, particularly in the context of synthetic datasets. Our findings also demonstrate the efficacy of Deep Learning models such as BanglaBERT for NER in Bangla language. ",
    "url": "https://arxiv.org/abs/2303.09306",
    "authors": [
      "HAZ Sameen Shahgir",
      "Ramisa Alam",
      "Md. Zarif Ul Alam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09310",
    "title": "GLH-Water: A Large-Scale Dataset for Global Surface Water Detection in  Large-Size Very-High-Resolution Satellite Imagery",
    "abstract": "Global surface water detection in very-high-resolution (VHR) satellite imagery can directly serve major applications such as refined flood mapping and water resource assessment. Although achievements have been made in detecting surface water in small-size satellite images corresponding to local geographic scales, datasets and methods suitable for mapping and analyzing global surface water have yet to be explored. To encourage the development of this task and facilitate the implementation of relevant applications, we propose the GLH-water dataset that consists of 250 satellite images and manually labeled surface water annotations that are distributed globally and contain water bodies exhibiting a wide variety of types (e.g., rivers, lakes, and ponds in forests, irrigated fields, bare areas, and urban areas). Each image is of the size 12,800 $\\times$ 12,800 pixels at 0.3 meter spatial resolution. To build a benchmark for GLH-water, we perform extensive experiments employing representative surface water detection models, popular semantic segmentation models, and ultra-high resolution segmentation models. Furthermore, we also design a strong baseline with the novel pyramid consistency loss (PCL) to initially explore this challenge. Finally, we implement the cross-dataset and pilot area generalization experiments, and the superior performance illustrates the strong generalization and practical application of GLH-water. The dataset is available at https://jack-bo1220.github.io/project/GLH-water.html. ",
    "url": "https://arxiv.org/abs/2303.09310",
    "authors": [
      "Yansheng Li",
      "Bo Dang",
      "Wanchun Li",
      "Yongjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09314",
    "title": "TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection",
    "abstract": "Multimodal hate detection, which aims to identify harmful content online such as memes, is crucial for building a wholesome internet environment. Previous work has made enlightening exploration in detecting explicit hate remarks. However, most of their approaches neglect the analysis of implicit harm, which is particularly challenging as explicit text markers and demographic visual cues are often twisted or missing. The leveraged cross-modal attention mechanisms also suffer from the distributional modality gap and lack logical interpretability. To address these semantic gaps issues, we propose TOT: a topology-aware optimal transport framework to decipher the implicit harm in memes scenario, which formulates the cross-modal aligning problem as solutions for optimal transportation plans. Specifically, we leverage an optimal transport kernel method to capture complementary information from multiple modalities. The kernel embedding provides a non-linear transformation ability to reproduce a kernel Hilbert space (RKHS), which reflects significance for eliminating the distributional modality gap. Moreover, we perceive the topology information based on aligned representations to conduct bipartite graph path reasoning. The newly achieved state-of-the-art performance on two publicly available benchmark datasets, together with further visual analysis, demonstrate the superiority of TOT in capturing implicit cross-modal alignment. ",
    "url": "https://arxiv.org/abs/2303.09314",
    "authors": [
      "Linhao Zhang",
      "Li Jin",
      "Xian Sun",
      "Guangluan Xu",
      "Zequn Zhang",
      "Xiaoyu Li",
      "Nayu Liu",
      "Shiyao Yan",
      "Qing Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.09343",
    "title": "Real-time elastic partial shape matching using a neural network-based  adjoint method",
    "abstract": "Surface matching usually provides significant deformations that can lead to structural failure due to the lack of physical policy. In this context, partial surface matching of non-linear deformable bodies is crucial in engineering to govern structure deformations. In this article, we propose to formulate the registration problem as an optimal control problem using an artificial neural network where the unknown is the surface force distribution that applies to the object and the resulting deformation computed using a hyper-elastic model. The optimization problem is solved using an adjoint method where the hyper-elastic problem is solved using the feed-forward neural network and the adjoint problem is obtained through the backpropagation of the network. Our process improves the computation speed by multiple orders of magnitude while providing acceptable registration errors. ",
    "url": "https://arxiv.org/abs/2303.09343",
    "authors": [
      "Alban Odot",
      "Guillaume Mestdagh",
      "Yannick Privat",
      "St\u00e9phane Cotin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.09347",
    "title": "CSSL-MHTR: Continual Self-Supervised Learning for Scalable Multi-script  Handwritten Text Recognition",
    "abstract": "Self-supervised learning has recently emerged as a strong alternative in document analysis. These approaches are now capable of learning high-quality image representations and overcoming the limitations of supervised methods, which require a large amount of labeled data. However, these methods are unable to capture new knowledge in an incremental fashion, where data is presented to the model sequentially, which is closer to the realistic scenario. In this paper, we explore the potential of continual self-supervised learning to alleviate the catastrophic forgetting problem in handwritten text recognition, as an example of sequence recognition. Our method consists in adding intermediate layers called adapters for each task, and efficiently distilling knowledge from the previous model while learning the current task. Our proposed framework is efficient in both computation and memory complexity. To demonstrate its effectiveness, we evaluate our method by transferring the learned model to diverse text recognition downstream tasks, including Latin and non-Latin scripts. As far as we know, this is the first application of continual self-supervised learning for handwritten text recognition. We attain state-of-the-art performance on English, Italian and Russian scripts, whilst adding only a few parameters per task. The code and trained models will be publicly available. ",
    "url": "https://arxiv.org/abs/2303.09347",
    "authors": [
      "Marwa Dhiaf",
      "Mohamed Ali Souibgui",
      "Kai Wang",
      "Yuyang Liu",
      "Yousri Kessentini",
      "Alicia Forn\u00e9s",
      "Ahmed Cheikh Rouhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09373",
    "title": "3D Masked Autoencoding and Pseudo-labeling for Domain Adaptive  Segmentation of Heterogeneous Infant Brain MRI",
    "abstract": "Robust segmentation of infant brain MRI across multiple ages, modalities, and sites remains challenging due to the intrinsic heterogeneity caused by different MRI scanners, vendors, or acquisition sequences, as well as varying stages of neurodevelopment. To address this challenge, previous studies have explored domain adaptation (DA) algorithms from various perspectives, including feature alignment, entropy minimization, contrast synthesis (style transfer), and pseudo-labeling. This paper introduces a novel framework called MAPSeg (Masked Autoencoding and Pseudo-labelling Segmentation) to address the challenges of cross-age, cross-modality, and cross-site segmentation of subcortical regions in infant brain MRI. Utilizing 3D masked autoencoding as well as masked pseudo-labeling, the model is able to jointly learn from labeled source domain data and unlabeled target domain data. We evaluated our framework on expert-annotated datasets acquired from different ages and sites. MAPSeg consistently outperformed other methods, including previous state-of-the-art supervised baselines, domain generalization, and domain adaptation frameworks in segmenting subcortical regions regardless of age, modality, or acquisition site. The code and pretrained encoder will be publicly available at https://github.com/XuzheZ/MAPSeg ",
    "url": "https://arxiv.org/abs/2303.09373",
    "authors": [
      "Xuzhe Zhang",
      "Yuhao Wu",
      "Jia Guo",
      "Jerod M. Rasmussen",
      "Thomas G. O'Connor",
      "Hyagriv N. Simhan",
      "Sonja Entringer",
      "Pathik D. Wadhwa",
      "Claudia Buss",
      "Cristiane S. Duarte",
      "Andrea Jackowski",
      "Hai Li",
      "Jonathan Posner",
      "Andrew F. Laine",
      "Yun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09375",
    "title": "DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human  Avatars",
    "abstract": "We present DINAR, an approach for creating realistic rigged fullbody avatars from single RGB images. Similarly to previous works, our method uses neural textures combined with the SMPL-X body model to achieve photo-realistic quality of avatars while keeping them easy to animate and fast to infer. To restore the texture, we use a latent diffusion model and show how such model can be trained in the neural texture space. The use of the diffusion model allows us to realistically reconstruct large unseen regions such as the back of a person given the frontal view. The models in our pipeline are trained using 2D images and videos only. In the experiments, our approach achieves state-of-the-art rendering quality and good generalization to new poses and viewpoints. In particular, the approach improves state-of-the-art on the SnapshotPeople public benchmark. ",
    "url": "https://arxiv.org/abs/2303.09375",
    "authors": [
      "David Svitov",
      "Dmitrii Gudkov",
      "Renat Bashirov",
      "Victor Lemptisky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09401",
    "title": "Heterogeneous Unlabeled and Labeled RFS Filter Fusion for Scalable  Multisensor Multitarget Tracking",
    "abstract": "This paper proposes a heterogenous density fusion approach to scalable multisensor multitarget tracking where the local, inter-connected sensors run different types of random finite set (RFS) filters according to their respective capacity and need. They result in heterogenous multitarget densities that are to be fused with each other in a proper means for more robust and accurate detection and localization of the targets. Our recent work has exposed a key common property of effective arithmetic average (AA) fusion approaches to both unlabeled and labeled RFS filters which are all built on averaging their relevant un-labeled/labeled probability hypothesis densities (PHDs). Thanks to this, this paper proposes the first ever heterogenous unlabeled and labeled RFS filter cooperation approach based on Gaussian mixture implementations where the local Gaussian components (L-GCs) are so optimized that the resulting unlabeled PHDs best fit their AA, regardless of the specific type of the local densities. To this end, a computationally efficient, approximate approach is proposed which only revises the weights of the L-GCs, keeping the other parameters of L-GCs unchanged. In particular, the PHD filter, the unlabeled and labeled multi-Bernoulli (MB/LMB) filters are considered. Simulations have demonstrated the effectiveness of the proposed approach for both homogeneous and heterogenous fusion of the PHD-MB- LMB filters in different configurations. ",
    "url": "https://arxiv.org/abs/2303.09401",
    "authors": [
      "Tiancheng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.09402",
    "title": "ToxVis: Enabling Interpretability of Implicit vs. Explicit Toxicity  Detection Models with Interactive Visualization",
    "abstract": "The rise of hate speech on online platforms has led to an urgent need for effective content moderation. However, the subjective and multi-faceted nature of hateful online content, including implicit hate speech, poses significant challenges to human moderators and content moderation systems. To address this issue, we developed ToxVis, a visually interactive and explainable tool for classifying hate speech into three categories: implicit, explicit, and non-hateful. We fine-tuned two transformer-based models using RoBERTa, XLNET, and GPT-3 and used deep learning interpretation techniques to provide explanations for the classification results. ToxVis enables users to input potentially hateful text and receive a classification result along with a visual explanation of which words contributed most to the decision. By making the classification process explainable, ToxVis provides a valuable tool for understanding the nuances of hateful content and supporting more effective content moderation. Our research contributes to the growing body of work aimed at mitigating the harms caused by online hate speech and demonstrates the potential for combining state-of-the-art natural language processing models with interpretable deep learning techniques to address this critical issue. Finally, ToxVis can serve as a resource for content moderators, social media platforms, and researchers working to combat the spread of hate speech online. ",
    "url": "https://arxiv.org/abs/2303.09402",
    "authors": [
      "Uma Gunturi",
      "Xiaohan Ding",
      "Eugenia H. Rho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.09431",
    "title": "NeRFMeshing: Distilling Neural Radiance Fields into  Geometrically-Accurate 3D Meshes",
    "abstract": "With the introduction of Neural Radiance Fields (NeRFs), novel view synthesis has recently made a big leap forward. At the core, NeRF proposes that each 3D point can emit radiance, allowing to conduct view synthesis using differentiable volumetric rendering. While neural radiance fields can accurately represent 3D scenes for computing the image rendering, 3D meshes are still the main scene representation supported by most computer graphics and simulation pipelines, enabling tasks such as real time rendering and physics-based simulations. Obtaining 3D meshes from neural radiance fields still remains an open challenge since NeRFs are optimized for view synthesis, not enforcing an accurate underlying geometry on the radiance field. We thus propose a novel compact and flexible architecture that enables easy 3D surface reconstruction from any NeRF-driven approach. Upon having trained the radiance field, we distill the volumetric 3D representation into a Signed Surface Approximation Network, allowing easy extraction of the 3D mesh and appearance. Our final 3D mesh is physically accurate and can be rendered in real time on an array of devices. ",
    "url": "https://arxiv.org/abs/2303.09431",
    "authors": [
      "Marie-Julie Rakotosaona",
      "Fabian Manhardt",
      "Diego Martin Arroyo",
      "Michael Niemeyer",
      "Abhijit Kundu",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09483",
    "title": "Achieving a Better Stability-Plasticity Trade-off via Auxiliary Networks  in Continual Learning",
    "abstract": "In contrast to the natural capabilities of humans to learn new tasks in a sequential fashion, neural networks are known to suffer from catastrophic forgetting, where the model's performances on old tasks drop dramatically after being optimized for a new task. Since then, the continual learning (CL) community has proposed several solutions aiming to equip the neural network with the ability to learn the current task (plasticity) while still achieving high accuracy on the previous tasks (stability). Despite remarkable improvements, the plasticity-stability trade-off is still far from being solved and its underlying mechanism is poorly understood. In this work, we propose Auxiliary Network Continual Learning (ANCL), a novel method that applies an additional auxiliary network which promotes plasticity to the continually learned model which mainly focuses on stability. More concretely, the proposed framework materializes in a regularizer that naturally interpolates between plasticity and stability, surpassing strong baselines on task incremental and class incremental scenarios. Through extensive analyses on ANCL solutions, we identify some essential principles beneath the stability-plasticity trade-off. ",
    "url": "https://arxiv.org/abs/2303.09483",
    "authors": [
      "Sanghwan Kim",
      "Lorenzo Noci",
      "Antonio Orvieto",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09484",
    "title": "A Novel Autoencoders-LSTM Model for Stroke Outcome Prediction using  Multimodal MRI Data",
    "abstract": "Patient outcome prediction is critical in management of ischemic stroke. In this paper, a novel machine learning model is proposed for stroke outcome prediction using multimodal Magnetic Resonance Imaging (MRI). The proposed model consists of two serial levels of Autoencoders (AEs), where different AEs at level 1 are used for learning unimodal features from different MRI modalities and a AE at level 2 is used to combine the unimodal features into compressed multimodal features. The sequences of multimodal features of a given patient are then used by an LSTM network for predicting outcome score. The proposed AE2-LSTM model is proved to be an effective approach for better addressing the multimodality and volumetric nature of MRI data. Experimental results show that the proposed AE2-LSTM outperforms the existing state-of-the art models by achieving highest AUC=0.71 and lowest MAE=0.34. ",
    "url": "https://arxiv.org/abs/2303.09484",
    "authors": [
      "Nima Hatami",
      "Laura Mechtouff",
      "David Rousseau",
      "Tae-Hee Cho",
      "Omer Eker",
      "Yves Berthezene",
      "Carole Frindel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09495",
    "title": "Among Us: Adversarially Robust Collaborative Perception by Consensus",
    "abstract": "Multiple robots could perceive a scene (e.g., detect objects) collaboratively better than individuals, although easily suffer from adversarial attacks when using deep learning. This could be addressed by the adversarial defense, but its training requires the often-unknown attacking mechanism. Differently, we propose ROBOSAC, a novel sampling-based defense strategy generalizable to unseen attackers. Our key idea is that collaborative perception should lead to consensus rather than dissensus in results compared to individual perception. This leads to our hypothesize-and-verify framework: perception results with and without collaboration from a random subset of teammates are compared until reaching a consensus. In such a framework, more teammates in the sampled subset often entail better perception performance but require longer sampling time to reject potential attackers. Thus, we derive how many sampling trials are needed to ensure the desired size of an attacker-free subset, or equivalently, the maximum size of such a subset that we can successfully sample within a given number of trials. We validate our method on the task of collaborative 3D object detection in autonomous driving scenarios. ",
    "url": "https://arxiv.org/abs/2303.09495",
    "authors": [
      "Yiming Li",
      "Qi Fang",
      "Jiamu Bai",
      "Siheng Chen",
      "Felix Juefei-Xu",
      "Chen Feng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.09497",
    "title": "Gate Recurrent Unit Network based on Hilbert-Schmidt Independence  Criterion for State-of-Health Estimation",
    "abstract": "State-of-health (SOH) estimation is a key step in ensuring the safe and reliable operation of batteries. Due to issues such as varying data distribution and sequence length in different cycles, most existing methods require health feature extraction technique, which can be time-consuming and labor-intensive. GRU can well solve this problem due to the simple structure and superior performance, receiving widespread attentions. However, redundant information still exists within the network and impacts the accuracy of SOH estimation. To address this issue, a new GRU network based on Hilbert-Schmidt Independence Criterion (GRU-HSIC) is proposed. First, a zero masking network is used to transform all battery data measured with varying lengths every cycle into sequences of the same length, while still retaining information about the original data size in each cycle. Second, the Hilbert-Schmidt Independence Criterion (HSIC) bottleneck, which evolved from Information Bottleneck (IB) theory, is extended to GRU to compress the information from hidden layers. To evaluate the proposed method, we conducted experiments on datasets from the Center for Advanced Life Cycle Engineering (CALCE) of the University of Maryland and NASA Ames Prognostics Center of Excellence. Experimental results demonstrate that our model achieves higher accuracy than other recurrent models. ",
    "url": "https://arxiv.org/abs/2303.09497",
    "authors": [
      "Ziyue Huang",
      "Lujuan Dang",
      "Yuqing Xie",
      "Wentao Ma",
      "Badong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.09515",
    "title": "Large Population Games on Constrained Unreliable Networks",
    "abstract": "This paper studies an $N$--agent cost-coupled game where the agents are connected via an unreliable capacity constrained network. Each agent receives state information over that network which loses packets with probability $p$. A Base station (BS) actively schedules agent communications over the network by minimizing a weighted Age of Information (WAoI) based cost function under a capacity limit $\\mathcal{C} < N$ on the number of transmission attempts at each instant. Under a standard information structure, we show that the problem can be decoupled into a scheduling problem for the BS and a game problem for the $N$ agents. Since the scheduling problem is an NP hard combinatorics problem, we propose an approximately optimal solution which approaches the optimal solution as $N \\rightarrow \\infty$. In the process, we also provide some insights on the case without channel erasure. Next, to solve the large population game problem, we use the mean-field game framework to compute an approximate decentralized Nash equilibrium. Finally, we validate the theoretical results using a numerical example. ",
    "url": "https://arxiv.org/abs/2303.09515",
    "authors": [
      "Shubham Aggarwal",
      "Muhammad Aneeq uz Zaman",
      "Melih Bastopcu",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.09530",
    "title": "Tackling Clutter in Radar Data -- Label Generation and Detection Using  PointNet++",
    "abstract": "Radar sensors employed for environment perception, e.g. in autonomous vehicles, output a lot of unwanted clutter. These points, for which no corresponding real objects exist, are a major source of errors in following processing steps like object detection or tracking. We therefore present two novel neural network setups for identifying clutter. The input data, network architectures and training configuration are adjusted specifically for this task. Special attention is paid to the downsampling of point clouds composed of multiple sensor scans. In an extensive evaluation, the new setups display substantially better performance than existing approaches. Because there is no suitable public data set in which clutter is annotated, we design a method to automatically generate the respective labels. By applying it to existing data with object annotations and releasing its code, we effectively create the first freely available radar clutter data set representing real-world driving scenarios. Code and instructions are accessible at www.github.com/kopp-j/clutter-ds. ",
    "url": "https://arxiv.org/abs/2303.09530",
    "authors": [
      "Johannes Kopp",
      "Dominik Kellner",
      "Aldi Piroli",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.09531",
    "title": "GLASU: A Communication-Efficient Algorithm for Federated Learning with  Vertically Distributed Graph Data",
    "abstract": "Vertical federated learning (VFL) is a distributed learning paradigm, where computing clients collectively train a model based on the partial features of the same set of samples they possess. Current research on VFL focuses on the case when samples are independent, but it rarely addresses an emerging scenario when samples are interrelated through a graph. For graph-structured data, graph neural networks (GNNs) are competitive machine learning models, but a naive implementation in the VFL setting causes a significant communication overhead. Moreover, the analysis of the training is faced with a challenge caused by the biased stochastic gradients. In this paper, we propose a model splitting method that splits a backbone GNN across the clients and the server and a communication-efficient algorithm, GLASU, to train such a model. GLASU adopts lazy aggregation and stale updates to skip aggregation when evaluating the model and skip feature exchanges during training, greatly reducing communication. We offer a theoretical analysis and conduct extensive numerical experiments on real-world datasets, showing that the proposed algorithm effectively trains a GNN model, whose performance matches that of the backbone GNN when trained in a centralized manner. ",
    "url": "https://arxiv.org/abs/2303.09531",
    "authors": [
      "Xinwei Zhang",
      "Mingyi Hong",
      "Jie Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.09536",
    "title": "Deep Metric Learning for Unsupervised Remote Sensing Change Detection",
    "abstract": "Remote Sensing Change Detection (RS-CD) aims to detect relevant changes from Multi-Temporal Remote Sensing Images (MT-RSIs), which aids in various RS applications such as land cover, land use, human development analysis, and disaster response. The performance of existing RS-CD methods is attributed to training on large annotated datasets. Furthermore, most of these models are less transferable in the sense that the trained model often performs very poorly when there is a domain gap between training and test datasets. This paper proposes an unsupervised CD method based on deep metric learning that can deal with both of these issues. Given an MT-RSI, the proposed method generates corresponding change probability map by iteratively optimizing an unsupervised CD loss without training it on a large dataset. Our unsupervised CD method consists of two interconnected deep networks, namely Deep-Change Probability Generator (D-CPG) and Deep-Feature Extractor (D-FE). The D-CPG is designed to predict change and no change probability maps for a given MT-RSI, while D-FE is used to extract deep features of MT-RSI that will be further used in the proposed unsupervised CD loss. We use transfer learning capability to initialize the parameters of D-FE. We iteratively optimize the parameters of D-CPG and D-FE for a given MT-RSI by minimizing the proposed unsupervised ``similarity-dissimilarity loss''. This loss is motivated by the principle of metric learning where we simultaneously maximize the distance between change pair-wise pixels while minimizing the distance between no-change pair-wise pixels in bi-temporal image domain and their deep feature domain. The experiments conducted on three CD datasets show that our unsupervised CD method achieves significant improvements over the state-of-the-art supervised and unsupervised CD methods. Code available at https://github.com/wgcban/Metric-CD ",
    "url": "https://arxiv.org/abs/2303.09536",
    "authors": [
      "Wele Gedara Chaminda Bandara",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.09551",
    "title": "SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving",
    "abstract": "3D scene understanding plays a vital role in vision-based autonomous driving. While most existing methods focus on 3D object detection, they have difficulty describing real-world objects of arbitrary shapes and infinite classes. Towards a more comprehensive perception of a 3D scene, in this paper, we propose a SurroundOcc method to predict the 3D occupancy with multi-camera images. We first extract multi-scale features for each image and adopt spatial 2D-3D attention to lift them to the 3D volume space. Then we apply 3D convolutions to progressively upsample the volume features and impose supervision on multiple levels. To obtain dense occupancy prediction, we design a pipeline to generate dense occupancy ground truth without expansive occupancy annotations. Specifically, we fuse multi-frame LiDAR scans of dynamic objects and static scenes separately. Then we adopt Poisson Reconstruction to fill the holes and voxelize the mesh to get dense occupancy labels. Extensive experiments on nuScenes and SemanticKITTI datasets demonstrate the superiority of our method. Code and dataset are available at https://github.com/weiyithu/SurroundOcc ",
    "url": "https://arxiv.org/abs/2303.09551",
    "authors": [
      "Yi Wei",
      "Linqing Zhao",
      "Wenzhao Zheng",
      "Zheng Zhu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09552",
    "title": "Dataflow graphs as complete causal graphs",
    "abstract": "Component-based development is one of the core principles behind modern software engineering practices. Understanding of causal relationships between components of a software system can yield significant benefits to developers. Yet modern software design approaches make it difficult to track and discover such relationships at system scale, which leads to growing intellectual debt. In this paper we consider an alternative approach to software design, flow-based programming (FBP), and draw the attention of the community to the connection between dataflow graphs produced by FBP and structural causal models. With expository examples we show how this connection can be leveraged to improve day-to-day tasks in software projects, including fault localisation, business analysis and experimentation. ",
    "url": "https://arxiv.org/abs/2303.09552",
    "authors": [
      "Andrei Paleyes",
      "Siyuan Guo",
      "Bernhard Sch\u00f6lkopf",
      "Neil D. Lawrence"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08818",
    "title": "Boosting Convolutional Neural Networks' Protein Binding Site Prediction  Capacity Using SE(3)-invariant transformers, Transfer Learning and  Homology-based Augmentation",
    "abstract": "Figuring out small molecule binding sites in target proteins, in the resolution of either pocket or residue, is critical in many virtual and real drug-discovery scenarios. Since it is not always easy to find such binding sites based on domain knowledge or traditional methods, different deep learning methods that predict binding sites out of protein structures have been developed in recent years. Here we present a new such deep learning algorithm, that significantly outperformed all state-of-the-art baselines in terms of the both resolutions$\\unicode{x2013}$pocket and residue. This good performance was also demonstrated in a case study involving the protein human serum albumin and its binding sites. Our algorithm included new ideas both in the model architecture and in the training method. For the model architecture, it incorporated SE(3)-invariant geometric self-attention layers that operate on top of residue-level CNN outputs. This residue-level processing of the model allowed a transfer learning between the two resolutions, which turned out to significantly improve the binding pocket prediction. Moreover, we developed novel augmentation method based on protein homology, which prevented our model from over-fitting. Overall, we believe that our contribution to the literature is twofold. First, we provided a new computational method for binding site prediction that is relevant to real-world applications, as shown by the good performance on different benchmarks and case study. Second, the novel ideas in our method$\\unicode{x2013}$the model architecture, transfer learning and the homology augmentation$\\unicode{x2013}$would serve as useful components in future works. ",
    "url": "https://arxiv.org/abs/2303.08818",
    "authors": [
      "Daeseok Lee",
      "Bonggun Shin",
      "Jeunghyun Byun"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2303.08874",
    "title": "Bayesian Quadrature for Neural Ensemble Search",
    "abstract": "Ensembling can improve the performance of Neural Networks, but existing approaches struggle when the architecture likelihood surface has dispersed, narrow peaks. Furthermore, existing methods construct equally weighted ensembles, and this is likely to be vulnerable to the failure modes of the weaker architectures. By viewing ensembling as approximately marginalising over architectures we construct ensembles using the tools of Bayesian Quadrature -- tools which are well suited to the exploration of likelihood surfaces with dispersed, narrow peaks. Additionally, the resulting ensembles consist of architectures weighted commensurate with their performance. We show empirically -- in terms of test likelihood, accuracy, and expected calibration error -- that our method outperforms state-of-the-art baselines, and verify via ablation studies that its components do so independently. ",
    "url": "https://arxiv.org/abs/2303.08874",
    "authors": [
      "Saad Hamid",
      "Xingchen Wan",
      "Martin J\u00f8rgensen",
      "Binxin Ru",
      "Michael Osborne"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08893",
    "title": "A Multifidelity deep operator network approach to closure for multiscale  systems",
    "abstract": "Projection-based reduced order models (PROMs) have shown promise in representing the behavior of multiscale systems using a small set of generalized (or latent) variables. Despite their success, PROMs can be susceptible to inaccuracies, even instabilities, due to the improper accounting of the interaction between the resolved and unresolved scales of the multiscale system (known as the closure problem). In the current work, we interpret closure as a multifidelity problem and use a multifidelity deep operator network (DeepONet) framework to address it. In addition, to enhance the stability and/or accuracy of the multifidelity-based closure, we employ the recently developed \"in-the-loop\" training approach from the literature on coupling physics and machine learning models. The resulting approach is tested on shock advection for the one-dimensional viscous Burgers equation and vortex merging for the two-dimensional Navier-Stokes equations. The numerical experiments show significant improvement of the predictive ability of the closure-corrected PROM over the un-corrected one both in the interpolative and the extrapolative regimes. ",
    "url": "https://arxiv.org/abs/2303.08893",
    "authors": [
      "Shady E. Ahmed",
      "Panos Stinis"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2303.09004",
    "title": "Robust Data-Driven Safe Control using Density Functions",
    "abstract": "This paper presents a tractable framework for data-driven synthesis of robustly safe control laws. Given noisy experimental data and some priors about the structure of the system, the goal is to synthesize a state feedback law such that the trajectories of the closed loop system are guaranteed to avoid an unsafe set even in the presence of unknown but bounded disturbances (process noise). The main result of the paper shows that for polynomial dynamics, this problem can be reduced to a tractable convex optimization by combining elements from polynomial optimization and the theorem of alternatives. This optimization provides both a rational control law and a density function safety certificate. These results are illustrated with numerical examples. ",
    "url": "https://arxiv.org/abs/2303.09004",
    "authors": [
      "Jian Zheng",
      "Tianyu Dai",
      "Jared Miller",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.09017",
    "title": "The Geometry of Causality",
    "abstract": "We provide a unified operational framework for the study of causality, non-locality and contextuality, in a fully device-independent and theory-independent setting. We define causaltopes, our chosen portmanteau of \"causal polytopes\", for arbitrary spaces of input histories and arbitrary choices of input contexts. We show that causaltopes are obtained by slicing simpler polytopes of conditional probability distributions with a set of causality equations, which we fully characterise. We provide efficient linear programs to compute the maximal component of an empirical model supported by any given sub-causaltope, as well as the associated causal fraction. We introduce a notion of causal separability relative to arbitrary causal constraints. We provide efficient linear programs to compute the maximal causally separable component of an empirical model, and hence its causally separable fraction, as the component jointly supported by certain sub-causaltopes. We study causal fractions and causal separability for several novel examples, including a selection of quantum switches with entangled or contextual control. In the process, we demonstrate the existence of \"causal contextuality\", a phenomenon where causal inseparability is clearly correlated to, or even directly implied by, non-locality and contextuality. ",
    "url": "https://arxiv.org/abs/2303.09017",
    "authors": [
      "Stefano Gogioso",
      "Nicola Pinzani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2303.09088",
    "title": "MetaRegNet: Metamorphic Image Registration Using Flow-Driven Residual  Networks",
    "abstract": "Deep learning based methods provide efficient solutions to medical image registration, including the challenging problem of diffeomorphic image registration. However, most methods register normal image pairs, facing difficulty handling those with missing correspondences, e.g., in the presence of pathology like tumors. We desire an efficient solution to jointly account for spatial deformations and appearance changes in the pathological regions where the correspondences are missing, i.e., finding a solution to metamorphic image registration. Some approaches are proposed to tackle this problem, but they cannot properly handle large pathological regions and deformations around pathologies. In this paper, we propose a deep metamorphic image registration network (MetaRegNet), which adopts time-varying flows to drive spatial diffeomorphic deformations and generate intensity variations. We evaluate MetaRegNet on two datasets, i.e., BraTS 2021 with brain tumors and 3D-IRCADb-01 with liver tumors, showing promising results in registering a healthy and tumor image pair. The source code is available online. ",
    "url": "https://arxiv.org/abs/2303.09088",
    "authors": [
      "Ankita Joshi",
      "Yi Hong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09133",
    "title": "Predicting nonlinear reshaping of periodic signals in optical fibre with  a neural network",
    "abstract": "We deploy a supervised machine-learning model based on a neural network to predict the temporal and spectral reshaping of a simple sinusoidal modulation into a pulse train having a comb structure in the frequency domain, which occurs upon nonlinear propagation in an optical fibre. Both normal and anomalous second-order dispersion regimes of the fibre are studied, and the speed of the neural network is leveraged to probe the space of input parameters for the generation of custom combs or the occurrence of significant temporal or spectral focusing. ",
    "url": "https://arxiv.org/abs/2303.09133",
    "authors": [
      "Sonia Boscolo",
      "J.M. Dudley",
      "Christophe Finot"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09154",
    "title": "Bayesian Generalization Error in Linear Neural Networks with Concept  Bottleneck Structure and Multitask Formulation",
    "abstract": "Concept bottleneck model (CBM) is a ubiquitous method that can interpret neural networks using concepts. In CBM, concepts are inserted between the output layer and the last intermediate layer as observable values. This helps in understanding the reason behind the outputs generated by the neural networks: the weights corresponding to the concepts from the last hidden layer to the output layer. However, it has not yet been possible to understand the behavior of the generalization error in CBM since a neural network is a singular statistical model in general. When the model is singular, a one to one map from the parameters to probability distributions cannot be created. This non-identifiability makes it difficult to analyze the generalization performance. In this study, we mathematically clarify the Bayesian generalization error and free energy of CBM when its architecture is three-layered linear neural networks. We also consider a multitask problem where the neural network outputs not only the original output but also the concepts. The results show that CBM drastically changes the behavior of the parameter region and the Bayesian generalization error in three-layered linear neural networks as compared with the standard version, whereas the multitask formulation does not. ",
    "url": "https://arxiv.org/abs/2303.09154",
    "authors": [
      "Naoki Hayashi",
      "Yoshihide Sawada"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2303.09232",
    "title": "Generative Adversarial Network for Personalized Art Therapy in Melanoma  Disease Management",
    "abstract": "Melanoma is the most lethal type of skin cancer. Patients are vulnerable to mental health illnesses which can reduce the effectiveness of the cancer treatment and the patients adherence to drug plans. It is crucial to preserve the mental health of patients while they are receiving treatment. However, current art therapy approaches are not personal and unique to the patient. We aim to provide a well-trained image style transfer model that can quickly generate unique art from personal dermoscopic melanoma images as an additional tool for art therapy in disease management of melanoma. Visual art appreciation as a common form of art therapy in disease management that measurably reduces the degree of psychological distress. We developed a network based on the cycle-consistent generative adversarial network for style transfer that generates personalized and unique artworks from dermoscopic melanoma images. We developed a model that converts melanoma images into unique flower-themed artworks that relate to the shape of the lesion and are therefore personal to the patient. Further, we altered the initial framework and made comparisons and evaluations of the results. With this, we increased the options in the toolbox for art therapy in disease management of melanoma. The development of an easy-to-use user interface ensures the availability of the approach to stakeholders. The transformation of melanoma into flower-themed artworks is achieved by the proposed model and the graphical user interface. This contribution opens a new field of GANs in art therapy and could lead to more personalized disease management. ",
    "url": "https://arxiv.org/abs/2303.09232",
    "authors": [
      "Lennart J\u00fctte",
      "Ning Wand",
      "Bernhard Roth"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09316",
    "title": "Higher-order correlations reveal complex memory in temporal hypergraphs",
    "abstract": "Many real-world complex systems are characterized by interactions in groups that change in time. Current temporal network approaches, however, are unable to describe group dynamics, as they are based on pairwise interactions only. Here, we use time-varying hypergraphs to describe such systems, and we introduce a framework based on higher-order correlations to characterize their temporal organization. We analyze various social systems, finding that groups of different sizes have typical patterns of long-range temporal correlations. Moreover, our method reveals the presence of non-trivial temporal interdependencies between different group sizes. We introduce a model of temporal hypergraphs with non-Markovian group interactions, which reveals complex memory as a fundamental mechanism underlying the pattern in the data. ",
    "url": "https://arxiv.org/abs/2303.09316",
    "authors": [
      "Luca Gallo",
      "Lucas Lacasa",
      "Vito Latora",
      "Federico Battiston"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Applied Physics (physics.app-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2303.09340",
    "title": "Improving Automated Hemorrhage Detection in Sparse-view Computed  Tomography via Deep Convolutional Neural Network based Artifact Reduction",
    "abstract": "Intracranial hemorrhage poses a serious health problem requiring rapid and often intensive medical treatment. For diagnosis, a Cranial Computed Tomography (CCT) scan is usually performed. However, the increased health risk caused by radiation is a concern. The most important strategy to reduce this potential risk is to keep the radiation dose as low as possible and consistent with the diagnostic task. Sparse-view CT can be an effective strategy to reduce dose by reducing the total number of views acquired, albeit at the expense of image quality. In this work, we use a U-Net architecture to reduce artifacts from sparse-view CCTs, predicting fully sampled reconstructions from sparse-view ones. We evaluate the hemorrhage detectability in the predicted CCTs with a hemorrhage classification convolutional neural network, trained on fully sampled CCTs to detect and classify different sub-types of hemorrhages. Our results suggest that the automated classification and detection accuracy of hemorrhages in sparse-view CCTs can be improved substantially by the U-Net. This demonstrates the feasibility of rapid automated hemorrhage detection on low-dose CT data to assist radiologists in routine clinical practice. ",
    "url": "https://arxiv.org/abs/2303.09340",
    "authors": [
      "Johannes Thalhammer",
      "Manuel Schultheiss",
      "Tina Dorosti",
      "Tobias Lasser",
      "Franz Pfeiffer",
      "Daniela Pfeiffer",
      "Florian Schaff"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2303.09397",
    "title": "Cryptocurrency Price Prediction using Twitter Sentiment Analysis",
    "abstract": "The cryptocurrency ecosystem has been the centre of discussion on many social media platforms, following its noted volatility and varied opinions. Twitter is rapidly being utilised as a news source and a medium for bitcoin discussion. Our algorithm seeks to use historical prices and sentiment of tweets to forecast the price of Bitcoin. In this study, we develop an end-to-end model that can forecast the sentiment of a set of tweets (using a Bidirectional Encoder Representations from Transformers - based Neural Network Model) and forecast the price of Bitcoin (using Gated Recurrent Unit) using the predicted sentiment and other metrics like historical cryptocurrency price data, tweet volume, a user's following, and whether or not a user is verified. The sentiment prediction gave a Mean Absolute Percentage Error of 9.45%, an average of real-time data, and test data. The mean absolute percent error for the price prediction was 3.6%. ",
    "url": "https://arxiv.org/abs/2303.09397",
    "authors": [
      "Haritha GB",
      "Sahana N.B"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09406",
    "title": "Stock Price Prediction Using Temporal Graph Model with Value Chain Data",
    "abstract": "Stock price prediction is a crucial element in financial trading as it allows traders to make informed decisions about buying, selling, and holding stocks. Accurate predictions of future stock prices can help traders optimize their trading strategies and maximize their profits. In this paper, we introduce a neural network-based stock return prediction method, the Long Short-Term Memory Graph Convolutional Neural Network (LSTM-GCN) model, which combines the Graph Convolutional Network (GCN) and Long Short-Term Memory (LSTM) Cells. Specifically, the GCN is used to capture complex topological structures and spatial dependence from value chain data, while the LSTM captures temporal dependence and dynamic changes in stock returns data. We evaluated the LSTM-GCN model on two datasets consisting of constituents of Eurostoxx 600 and S&P 500. Our experiments demonstrate that the LSTM-GCN model can capture additional information from value chain data that are not fully reflected in price data, and the predictions outperform baseline models on both datasets. ",
    "url": "https://arxiv.org/abs/2303.09406",
    "authors": [
      "Chang Liu",
      "Sandra Paterlini"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2303.09440",
    "title": "Enhanced detection of the presence and severity of COVID-19 from CT  scans using lung segmentation",
    "abstract": "Improving automated analysis of medical imaging will provide clinicians more options in providing care for patients. The 2023 AI-enabled Medical Image Analysis Workshop and Covid-19 Diagnosis Competition (AI-MIA-COV19D) provides an opportunity to test and refine machine learning methods for detecting the presence and severity of COVID-19 in patients from CT scans. This paper presents version 2 of Cov3d, a deep learning model submitted in the 2022 competition. The model has been improved through a preprocessing step which segments the lungs in the CT scan and crops the input to this region. It results in a validation macro F1 score for predicting the presence of COVID-19 in the CT scans at 92.2% which is significantly above the baseline of 74%. It gives a macro F1 score for predicting the severity of COVID-19 on the validation set for task 2 as 67% which is above the baseline of 38%. ",
    "url": "https://arxiv.org/abs/2303.09440",
    "authors": [
      "Robert Turnbull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1803.09007",
    "title": "Detrimental Network Effects in Privacy: A Graph-theoretic Model for  Node-based Intrusions",
    "abstract": " Comments: Published in Cell Patterns 4.1 (2023): 100662 at this https URL ",
    "url": "https://arxiv.org/abs/1803.09007",
    "authors": [
      "Florimond Houssiau",
      "Piotr Sapiezynski",
      "Laura Radaelli",
      "Erez Shmueli",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2009.00150",
    "title": "Exactly Optimal Bayesian Quickest Change Detection for Hidden Markov  Models",
    "abstract": " Title: Exactly Optimal Bayesian Quickest Change Detection for Hidden Markov  Models ",
    "url": "https://arxiv.org/abs/2009.00150",
    "authors": [
      "Jason J. Ford",
      "Jasmin James",
      "Timothy L. Molloy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2101.02390",
    "title": "SDGNN: Learning Node Representation for Signed Directed Networks",
    "abstract": " Comments: Accepted and to appear at AAAI2021 ",
    "url": "https://arxiv.org/abs/2101.02390",
    "authors": [
      "Junjie Huang",
      "Huawei Shen",
      "Liang Hou",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2102.06867",
    "title": "CPP-Net: Context-aware Polygon Proposal Network for Nucleus Segmentation",
    "abstract": " Comments: Accepted Version to IEEE Transactions on Image Processing ",
    "url": "https://arxiv.org/abs/2102.06867",
    "authors": [
      "Shengcong Chen",
      "Changxing Ding",
      "Minfeng Liu",
      "Jun Cheng",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.00882",
    "title": "k-apices of minor-closed graph classes. I. Bounding the obstructions",
    "abstract": " Comments: 48 pages and 12 figures. arXiv admin note: text overlap with arXiv:2004.12692 ",
    "url": "https://arxiv.org/abs/2103.00882",
    "authors": [
      "Ignasi Sau",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2105.14835",
    "title": "Towards Lower Bounds on the Depth of ReLU Neural Networks",
    "abstract": " Comments: Authors' accepted manuscript for SIAM Journal on Discrete Mathematics. A preliminary conference version appeared at NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2105.14835",
    "authors": [
      "Christoph Hertrich",
      "Amitabh Basu",
      "Marco Di Summa",
      "Martin Skutella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.13638",
    "title": "Transient Stability Analysis with Physics-Informed Neural Networks",
    "abstract": " Comments: 9 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2106.13638",
    "authors": [
      "Jochen Stiasny",
      "Georgios S. Misyris",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.15278",
    "title": "Open-Set Representation Learning through Combinatorial Embedding",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2106.15278",
    "authors": [
      "Geeho Kim",
      "Junoh Kang",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.11990",
    "title": "Augmentation Pathways Network for Visual Recognition",
    "abstract": " Comments: accepted by TPAMI 2023 ",
    "url": "https://arxiv.org/abs/2107.11990",
    "authors": [
      "Yalong Bai",
      "Mohan Zhou",
      "Wei Zhang",
      "Bowen Zhou",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.08614",
    "title": "UNIQORN: Unified Question Answering over RDF Knowledge Graphs and  Natural Language Text",
    "abstract": " Comments: 34 pages ",
    "url": "https://arxiv.org/abs/2108.08614",
    "authors": [
      "Soumajit Pramanik",
      "Jesujoba Alabi",
      "Rishiraj Saha Roy",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.01636",
    "title": "Empirical Study of Named Entity Recognition Performance Using  Distribution-aware Word Embedding",
    "abstract": " Comments: Want to review again ",
    "url": "https://arxiv.org/abs/2109.01636",
    "authors": [
      "Xin Chen",
      "Qi Zhao",
      "Xinyang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01177",
    "title": "MutualFormer: Multi-Modality Representation Learning via Cross-Diffusion  Attention",
    "abstract": " Title: MutualFormer: Multi-Modality Representation Learning via Cross-Diffusion  Attention ",
    "url": "https://arxiv.org/abs/2112.01177",
    "authors": [
      "Xixi Wang",
      "Xiao Wang",
      "Bo Jiang",
      "Jin Tang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.07197",
    "title": "Novel Algorithms for Efficient Mining of Connected Induced Subgraphs of  a Given Cardinality",
    "abstract": " Title: Novel Algorithms for Efficient Mining of Connected Induced Subgraphs of  a Given Cardinality ",
    "url": "https://arxiv.org/abs/2112.07197",
    "authors": [
      "Shanshan Wang",
      "Chenglong Xiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2112.09181",
    "title": "Approximation of functions with one-bit neural networks",
    "abstract": " Comments: 45 pages, 7 figures, significant changes and additions ",
    "url": "https://arxiv.org/abs/2112.09181",
    "authors": [
      "C. Sinan G\u00fcnt\u00fcrk",
      "Weilin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.10953",
    "title": "An adaptation of InfoMap to absorbing random walks using  absorption-scaled graphs",
    "abstract": " Title: An adaptation of InfoMap to absorbing random walks using  absorption-scaled graphs ",
    "url": "https://arxiv.org/abs/2112.10953",
    "authors": [
      "Esteban Vargas Bernal",
      "Mason A. Porter",
      "Joseph H. Tien"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2202.03382",
    "title": "Corrupted Image Modeling for Self-Supervised Visual Pre-Training",
    "abstract": " Comments: ICLR 2023 ",
    "url": "https://arxiv.org/abs/2202.03382",
    "authors": [
      "Yuxin Fang",
      "Li Dong",
      "Hangbo Bao",
      "Xinggang Wang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.14360",
    "title": "Observation-Centric SORT: Rethinking SORT for Robust Multi-Object  Tracking",
    "abstract": " Comments: Accepted by CVPR 2023. 8 pages + 10 pages of appendix. Renamed OOS as Observation-centric Re-Update (ORU) ",
    "url": "https://arxiv.org/abs/2203.14360",
    "authors": [
      "Jinkun Cao",
      "Jiangmiao Pang",
      "Xinshuo Weng",
      "Rawal Khirodkar",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11775",
    "title": "Constrained Monotonic Neural Networks",
    "abstract": " Comments: too many typos and errors in statements ",
    "url": "https://arxiv.org/abs/2205.11775",
    "authors": [
      "Davor Runje",
      "Sharath M. Shankaranarayana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.14375",
    "title": "WaveMix: A Resource-efficient Neural Network for Image Analysis",
    "abstract": " Comments: 20 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2205.14375",
    "authors": [
      "Pranav Jeevan",
      "Kavitha Viswanathan",
      "Anandu A S",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15160",
    "title": "On algorithmic applications of sim-width and mim-width of $(H_1,  H_2)$-free graphs",
    "abstract": " Title: On algorithmic applications of sim-width and mim-width of $(H_1,  H_2)$-free graphs ",
    "url": "https://arxiv.org/abs/2205.15160",
    "authors": [
      "Andrea Munaro",
      "Shizhou Yang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.06513",
    "title": "FibeRed: Fiberwise Dimensionality Reduction of Topologically Complex  Data with Vector Bundles",
    "abstract": " Comments: 15 pages + 10 page appendix, 15 figures + 1 table. To appear in proceedings of 39th International Symposium on Computational Geometry ",
    "url": "https://arxiv.org/abs/2206.06513",
    "authors": [
      "Luis Scoccola",
      "Jose A. Perea"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.07441",
    "title": "WatchPed: Pedestrian Crossing Intention Prediction Using Embedded  Sensors of Smartwatch",
    "abstract": " Title: WatchPed: Pedestrian Crossing Intention Prediction Using Embedded  Sensors of Smartwatch ",
    "url": "https://arxiv.org/abs/2208.07441",
    "authors": [
      "Jibran Ali Abbasi",
      "Navid Mohammad Imran",
      "Lokesh Chandra Das",
      "Myounggyu Won"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.08664",
    "title": "Enhancing Diffusion-Based Image Synthesis with Robust Classifier  Guidance",
    "abstract": " Comments: Accepted to TMLR ",
    "url": "https://arxiv.org/abs/2208.08664",
    "authors": [
      "Bahjat Kawar",
      "Roy Ganz",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14863",
    "title": "Neural Networks Efficiently Learn Low-Dimensional Representations with  SGD",
    "abstract": " Comments: 39 pages, 2 figures. To appear in the International Conference on Learning Representations (ICLR), 2023 ",
    "url": "https://arxiv.org/abs/2209.14863",
    "authors": [
      "Alireza Mousavi-Hosseini",
      "Sejun Park",
      "Manuela Girotti",
      "Ioannis Mitliagkas",
      "Murat A. Erdogdu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00647",
    "title": "IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable  Novel View Synthesis",
    "abstract": " Comments: Project webpage: this https URL, code: this https URL ",
    "url": "https://arxiv.org/abs/2210.00647",
    "authors": [
      "Weicai Ye",
      "Shuo Chen",
      "Chong Bao",
      "Hujun Bao",
      "Marc Pollefeys",
      "Zhaopeng Cui",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.01341",
    "title": "Safe and Stable Control Synthesis for Uncertain System Models via  Distributionally Robust Optimization",
    "abstract": " Title: Safe and Stable Control Synthesis for Uncertain System Models via  Distributionally Robust Optimization ",
    "url": "https://arxiv.org/abs/2210.01341",
    "authors": [
      "Kehan Long",
      "Yinzhuang Yi",
      "Jorge Cortes",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.06284",
    "title": "Visual Prompting for Adversarial Robustness",
    "abstract": " Comments: ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.06284",
    "authors": [
      "Aochuan Chen",
      "Peter Lorenz",
      "Yuguang Yao",
      "Pin-Yu Chen",
      "Sijia Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15586",
    "title": "Joint Multi-Person Body Detection and Orientation Estimation via One  Unified Embedding",
    "abstract": " Title: Joint Multi-Person Body Detection and Orientation Estimation via One  Unified Embedding ",
    "url": "https://arxiv.org/abs/2210.15586",
    "authors": [
      "Huayi Zhou",
      "Fei Jiang",
      "Jiaxin Si",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.17457",
    "title": "Agglomeration of Polygonal Grids using Graph Neural Networks with  applications to Multigrid solvers",
    "abstract": " Title: Agglomeration of Polygonal Grids using Graph Neural Networks with  applications to Multigrid solvers ",
    "url": "https://arxiv.org/abs/2210.17457",
    "authors": [
      "P. F. Antonietti",
      "N. Farenga",
      "E. Manuzzi",
      "G. Martinelli",
      "L. Saverio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11761",
    "title": "From Node Interaction to Hop Interaction: New Effective and Scalable  Graph Learning Paradigm",
    "abstract": " Comments: accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2211.11761",
    "authors": [
      "Jie Chen",
      "Zilong Li",
      "Yin Zhu",
      "Junping Zhang",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11950",
    "title": "UpCycling: Semi-supervised 3D Object Detection without Sharing Raw-level  Unlabeled Scenes",
    "abstract": " Comments: We have updated the results to fix errors in the experimental process, which resulted in some logical changes. We also have added new experiments related to privacy protection. The previous version (v1) has been discarded ",
    "url": "https://arxiv.org/abs/2211.11950",
    "authors": [
      "Sunwook Hwang",
      "Youngseok Kim",
      "Seongwon Kim",
      "Saewoong Bahk",
      "Hyung-Sin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12254",
    "title": "SPIn-NeRF: Multiview Segmentation and Perceptual Inpainting with Neural  Radiance Fields",
    "abstract": " Comments: Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2211.12254",
    "authors": [
      "Ashkan Mirzaei",
      "Tristan Aumentado-Armstrong",
      "Konstantinos G. Derpanis",
      "Jonathan Kelly",
      "Marcus A. Brubaker",
      "Igor Gilitschenski",
      "Alex Levinshtein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.02201",
    "title": "Relative Timing Information and Orthology in Evolutionary Scenarios",
    "abstract": " Title: Relative Timing Information and Orthology in Evolutionary Scenarios ",
    "url": "https://arxiv.org/abs/2212.02201",
    "authors": [
      "David Schaller",
      "Tom Hartmann",
      "Manuel Lafond",
      "Nicolas Wieseke",
      "Peter F. Stadler",
      "Marc Hellmuth"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2212.02400",
    "title": "Location-Aware Self-Supervised Transformers for Semantic Segmentation",
    "abstract": " Title: Location-Aware Self-Supervised Transformers for Semantic Segmentation ",
    "url": "https://arxiv.org/abs/2212.02400",
    "authors": [
      "Mathilde Caron",
      "Neil Houlsby",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04319",
    "title": "On the Robustness of Normalizing Flows for Inverse Problems in Imaging",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2212.04319",
    "authors": [
      "Seongmin Hong",
      "Inbum Park",
      "Se Young Chun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.06331",
    "title": "DeepMapping2: Self-Supervised Large-Scale LiDAR Map Optimization",
    "abstract": " Comments: accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2212.06331",
    "authors": [
      "Chao Chen",
      "Xinhao Liu",
      "Yiming Li",
      "Li Ding",
      "Chen Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.13667",
    "title": "Learning When to Use Adaptive Adversarial Image Perturbations against  Autonomous Vehicles",
    "abstract": " Title: Learning When to Use Adaptive Adversarial Image Perturbations against  Autonomous Vehicles ",
    "url": "https://arxiv.org/abs/2212.13667",
    "authors": [
      "Hyung-Jin Yoon",
      "Hamidreza Jafarnejadsani",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.14197",
    "title": "Self-Supervised Pre-training for 3D Point Clouds via View-Specific  Point-to-Image Translation",
    "abstract": " Title: Self-Supervised Pre-training for 3D Point Clouds via View-Specific  Point-to-Image Translation ",
    "url": "https://arxiv.org/abs/2212.14197",
    "authors": [
      "Qijian Zhang",
      "Junhui Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.09498",
    "title": "Triplet Contrastive Representation Learning for Unsupervised Vehicle  Re-identification",
    "abstract": " Title: Triplet Contrastive Representation Learning for Unsupervised Vehicle  Re-identification ",
    "url": "https://arxiv.org/abs/2301.09498",
    "authors": [
      "Fei Shen",
      "Xiaoyu Du",
      "Liyan Zhang",
      "Xiangbo Shu",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11494",
    "title": "Learning Vortex Dynamics for Fluid Inference and Prediction",
    "abstract": " Comments: ICLR 2023, project webpage: this https URL ",
    "url": "https://arxiv.org/abs/2301.11494",
    "authors": [
      "Yitong Deng",
      "Hong-Xing Yu",
      "Jiajun Wu",
      "Bo Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2301.11559",
    "title": "Enabling Multi-threading in Heterogeneous Quantum-Classical Programming  Models",
    "abstract": " Title: Enabling Multi-threading in Heterogeneous Quantum-Classical Programming  Models ",
    "url": "https://arxiv.org/abs/2301.11559",
    "authors": [
      "Akihiro Hayashi",
      "Austin Adams",
      "Jeffrey Young",
      "Alexander McCaskey",
      "Eugene Dumitrescu",
      "Vivek Sarkar",
      "Thomas M. Conte"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.11705",
    "title": "FedPH: Privacy-enhanced Heterogeneous Federated Learning",
    "abstract": " Title: FedPH: Privacy-enhanced Heterogeneous Federated Learning ",
    "url": "https://arxiv.org/abs/2301.11705",
    "authors": [
      "Kuang Hangdong",
      "Mi Bo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.03507",
    "title": "Meta-Learning Siamese Network for Few-Shot Text Classification",
    "abstract": " Title: Meta-Learning Siamese Network for Few-Shot Text Classification ",
    "url": "https://arxiv.org/abs/2302.03507",
    "authors": [
      "Chengcheng Han",
      "Yuhe Wang",
      "Yingnan Fu",
      "Xiang Li",
      "Minghui Qiu",
      "Ming Gao",
      "Aoying Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.06751",
    "title": "OpenHLS: High-Level Synthesis for Low-Latency Deep Neural Networks for  Experimental Science",
    "abstract": " Title: OpenHLS: High-Level Synthesis for Low-Latency Deep Neural Networks for  Experimental Science ",
    "url": "https://arxiv.org/abs/2302.06751",
    "authors": [
      "Maksim Levental",
      "Arham Khan",
      "Ryan Chard",
      "Kazutomo Yoshii",
      "Kyle Chard",
      "Ian Foster"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.08135",
    "title": "A Truthful Referral Auction Over Networks",
    "abstract": " Title: A Truthful Referral Auction Over Networks ",
    "url": "https://arxiv.org/abs/2302.08135",
    "authors": [
      "Youjia Zhang",
      "Pingzhong Tang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.09335",
    "title": "Knowledge Graph Completion based on Tensor Decomposition for Disease  Gene Prediction",
    "abstract": " Title: Knowledge Graph Completion based on Tensor Decomposition for Disease  Gene Prediction ",
    "url": "https://arxiv.org/abs/2302.09335",
    "authors": [
      "Xinyan Wang",
      "Ting Jia",
      "Chongyu Wang",
      "Kuan Xu",
      "Zixin Shu",
      "Jian Yu",
      "Kuo Yang",
      "Xuezhong Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.11208",
    "title": "KS-DETR: Knowledge Sharing in Attention Learning for Detection  Transformer",
    "abstract": " Title: KS-DETR: Knowledge Sharing in Attention Learning for Detection  Transformer ",
    "url": "https://arxiv.org/abs/2302.11208",
    "authors": [
      "Kaikai Zhao",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.14146",
    "title": "Markov Conditions and Factorization in Logical Credal Networks",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2302.14146",
    "authors": [
      "Fabio Gagliardi Cozman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.01332",
    "title": "Self-Supervised Few-Shot Learning for Ischemic Stroke Lesion  Segmentation",
    "abstract": " Title: Self-Supervised Few-Shot Learning for Ischemic Stroke Lesion  Segmentation ",
    "url": "https://arxiv.org/abs/2303.01332",
    "authors": [
      "Luca Tomasetti",
      "Stine Hansen",
      "Mahdieh Khanmohammadi",
      "Kjersti Engan",
      "Liv Jorunn H\u00f8llesli",
      "Kathinka D\u00e6hli Kurz",
      "Michael Kampffmeyer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02542",
    "title": "Physics-informed neural network for friction-involved nonsmooth dynamics  problems",
    "abstract": " Comments: 37 Pages, 24 figures ",
    "url": "https://arxiv.org/abs/2303.02542",
    "authors": [
      "Zilin Li",
      "Jinshuai Bai",
      "Huajing Ouyang",
      "Saulo Martelli",
      "Ming Tang",
      "Hongtao Wei",
      "Pan Liu",
      "Wei-Ron Han",
      "Yuantong Gu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.03684",
    "title": "MOSO: Decomposing MOtion, Scene and Object for Video Prediction",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.03684",
    "authors": [
      "Mingzhen Sun",
      "Weining Wang",
      "Xinxin Zhu",
      "Jing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04738",
    "title": "Defectors: A Large, Diverse Python Dataset for Defect Prediction",
    "abstract": " Title: Defectors: A Large, Diverse Python Dataset for Defect Prediction ",
    "url": "https://arxiv.org/abs/2303.04738",
    "authors": [
      "Parvez Mahbub",
      "Ohiduzzaman Shuvo",
      "Mohammad Masudur Rahman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.05499",
    "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set  Object Detection",
    "abstract": " Comments: Code will be available at this https URL ",
    "url": "https://arxiv.org/abs/2303.05499",
    "authors": [
      "Shilong Liu",
      "Zhaoyang Zeng",
      "Tianhe Ren",
      "Feng Li",
      "Hao Zhang",
      "Jie Yang",
      "Chunyuan Li",
      "Jianwei Yang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05735",
    "title": "Hardware Acceleration of Neural Graphics",
    "abstract": " Title: Hardware Acceleration of Neural Graphics ",
    "url": "https://arxiv.org/abs/2303.05735",
    "authors": [
      "Muhammad Husnain Mubarik",
      "Ramakrishna Kanungo",
      "Tobias Zirr",
      "Rakesh Kumar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06438",
    "title": "On Neural Architectures for Deep Learning-based Source Separation of  Co-Channel OFDM Signals",
    "abstract": " Title: On Neural Architectures for Deep Learning-based Source Separation of  Co-Channel OFDM Signals ",
    "url": "https://arxiv.org/abs/2303.06438",
    "authors": [
      "Gary C.F. Lee",
      "Amir Weiss",
      "Alejandro Lancho",
      "Yury Polyanskiy",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07347",
    "title": "TriDet: Temporal Action Detection with Relative Boundary Modeling",
    "abstract": " Comments: CVPR2023; Temporal Action Detection; Temporal Action Localization ",
    "url": "https://arxiv.org/abs/2303.07347",
    "authors": [
      "Dingfeng Shi",
      "Yujie Zhong",
      "Qiong Cao",
      "Lin Ma",
      "Jia Li",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.07653",
    "title": "NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from  Multi-view Images",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.07653",
    "authors": [
      "Yunfan Ye",
      "Renjiao Yi",
      "Zhirui Gao",
      "Chenyang Zhu",
      "Zhiping Cai",
      "Kai Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07937",
    "title": "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D  Generation",
    "abstract": " Comments: Project page this https URL ",
    "url": "https://arxiv.org/abs/2303.07937",
    "authors": [
      "Junyoung Seo",
      "Wooseok Jang",
      "Min-Seop Kwak",
      "Jaehoon Ko",
      "Hyeonsu Kim",
      "Junho Kim",
      "Jin-Hwa Kim",
      "Jiyoung Lee",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08157",
    "title": "Graph Neural Network Surrogates of Fair Graph Filtering",
    "abstract": " Comments: 40 pages, 5 figures, 5 papers ",
    "url": "https://arxiv.org/abs/2303.08157",
    "authors": [
      "Emmanouil Krasanakis",
      "Symeon Papadopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.08455",
    "title": "On the uncertainty analysis of the data-enabled physics-informed neural  network for solving neutron diffusion eigenvalue problem",
    "abstract": " Comments: The experiments in Figures 6 and 10 of the article have errors and need to be rerun ",
    "url": "https://arxiv.org/abs/2303.08455",
    "authors": [
      "Yu Yang",
      "Helin Gong",
      "Qihong Yang",
      "Yangtao Deng",
      "Qiaolin He",
      "Shiquan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  }
]