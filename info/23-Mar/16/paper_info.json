[
  {
    "id": "arXiv:2303.08156",
    "title": "Nonlinear Hyperspectral Unmixing based on Multilinear Mixing Model using  Convolutional Autoencoders",
    "abstract": "Unsupervised spectral unmixing consists of representing each observed pixel as a combination of several pure materials called endmembers with their corresponding abundance fractions. Beyond the linear assumption, various nonlinear unmixing models have been proposed, with the associated optimization problems solved either by traditional optimization algorithms or deep learning techniques. Current deep learning-based nonlinear unmixing focuses on the models in additive, bilinear-based formulations. By interpreting the reflection process using the discrete Markov chain, the multilinear mixing model (MLM) successfully accounts for the up to infinite-order interactions between endmembers. However, to simulate the physics process of MLM by neural networks explicitly is a challenging problem that has not been approached by far. In this article, we propose a novel autoencoder-based network for unsupervised unmixing based on MLM. Benefitting from an elaborate network design, the relationships among all the model parameters {\\em i.e.}, endmembers, abundances, and transition probability parameters are explicitly modeled. There are two modes: MLM-1DAE considers only pixel-wise spectral information, and MLM-3DAE exploits the spectral-spatial correlations within input patches. Experiments on both the synthetic and real datasets demonstrate the effectiveness of the proposed method as it achieves competitive performance to the classic solutions of MLM. ",
    "url": "https://arxiv.org/abs/2303.08156",
    "authors": [
      "Tingting Fang",
      "Fei Zhu",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.08157",
    "title": "Graph Neural Network Surrogates of Fair Graph Filtering",
    "abstract": "Graph filters that transform prior node values to posterior scores via edge propagation often support graph mining tasks affecting humans, such as recommendation and ranking. Thus, it is important to make them fair in terms of satisfying statistical parity constraints between groups of nodes (e.g., distribute score mass between genders proportionally to their representation). To achieve this while minimally perturbing the original posteriors, we introduce a filter-aware universal approximation framework for posterior objectives. This defines appropriate graph neural networks trained at runtime to be similar to filters but also locally optimize a large class of objectives, including fairness-aware ones. Experiments on a collection of 8 filters and 5 graphs show that our approach performs equally well or better than alternatives in meeting parity constraints while preserving the AUC of score-based community member recommendation and creating minimal utility loss in prior diffusion. ",
    "url": "https://arxiv.org/abs/2303.08157",
    "authors": [
      "Emmanouil Krasanakis",
      "Symeon Papadopulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.08169",
    "title": "Allegro-Legato: Scalable, Fast, and Robust Neural-Network Quantum  Molecular Dynamics via Sharpness-Aware Minimization",
    "abstract": "Neural-network quantum molecular dynamics (NNQMD) simulations based on machine learning are revolutionizing atomistic simulations of materials by providing quantum-mechanical accuracy but orders-of-magnitude faster, illustrated by ACM Gordon Bell prize (2020) and finalist (2021). State-of-the-art (SOTA) NNQMD model founded on group theory featuring rotational equivariance and local descriptors has provided much higher accuracy and speed than those models, thus named Allegro (meaning fast). On massively parallel supercomputers, however, it suffers a fidelity-scaling problem, where growing number of unphysical predictions of interatomic forces prohibits simulations involving larger numbers of atoms for longer times. Here, we solve this problem by combining the Allegro model with sharpness aware minimization (SAM) for enhancing the robustness of model through improved smoothness of the loss landscape. The resulting Allegro-Legato (meaning fast and \"smooth\") model was shown to elongate the time-to-failure $t_\\textrm{failure}$, without sacrificing computational speed or accuracy. Specifically, Allegro-Legato exhibits much weaker dependence of timei-to-failure on the problem size, $t_{\\textrm{failure}} \\propto N^{-0.14}$ ($N$ is the number of atoms) compared to the SOTA Allegro model $\\left(t_{\\textrm{failure}} \\propto N^{-0.29}\\right)$, i.e., systematically delayed time-to-failure, thus allowing much larger and longer NNQMD simulations without failure. The model also exhibits excellent computational scalability and GPU acceleration on the Polaris supercomputer at Argonne Leadership Computing Facility. Such scalable, accurate, fast and robust NNQMD models will likely find broad applications in NNQMD simulations on emerging exaflop/s computers, with a specific example of accounting for nuclear quantum effects in the dynamics of ammonia. ",
    "url": "https://arxiv.org/abs/2303.08169",
    "authors": [
      "Hikaru Ibayashi",
      "Taufeq Mohammed Razakh",
      "Liqiu Yang",
      "Thomas Linker",
      "Marco Olguin",
      "Shinnosuke Hattori",
      "Ye Luo",
      "Rajiv K. Kalia",
      "Aiichiro Nakano",
      "Ken-ichi Nomura",
      "Priya Vashishta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2303.08193",
    "title": "RODD: Robust Outlier Detection in Data Cubes",
    "abstract": "Data cubes are multidimensional databases, often built from several separate databases, that serve as flexible basis for data analysis. Surprisingly, outlier detection on data cubes has not yet been treated extensively. In this work, we provide the first framework to evaluate robust outlier detection methods in data cubes (RODD). We introduce a novel random forest-based outlier detection approach (RODD-RF) and compare it with more traditional methods based on robust location estimators. We propose a general type of test data and examine all methods in a simulation study. Moreover, we apply ROOD-RF to real world data. The results show that RODD-RF can lead to improved outlier detection. ",
    "url": "https://arxiv.org/abs/2303.08193",
    "authors": [
      "Lara Kuhlmann",
      "Daniel Wilmes",
      "Emmanuel M\u00fcller",
      "Markus Pauly",
      "Daniel Horn"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08213",
    "title": "The Overview of Privacy Labels and their Compatibility with Privacy  Policies",
    "abstract": "Privacy nutrition labels provide a way to understand an app's key data practices without reading the long and hard-to-read privacy policies. Recently, the app distribution platforms for iOS(Apple) and Android(Google) have implemented mandates requiring app developers to fill privacy nutrition labels highlighting their privacy practices such as data collection, data sharing, and security practices. These privacy labels contain very fine-grained information about the apps' data practices such as the data types and purposes associated with each data type. This provides us with a unique vantage point from which we can understand apps' data practices at scale. ",
    "url": "https://arxiv.org/abs/2303.08213",
    "authors": [
      "Rishabh Khandelwal",
      "Asmit Nayak",
      "Paul Chung",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.08225",
    "title": "Graph Transformer GANs for Graph-Constrained House Generation",
    "abstract": "We present a novel graph Transformer generative adversarial network (GTGAN) to learn effective graph node relations in an end-to-end fashion for the challenging graph-constrained house generation task. The proposed graph-Transformer-based generator includes a novel graph Transformer encoder that combines graph convolutions and self-attentions in a Transformer to model both local and global interactions across connected and non-connected graph nodes. Specifically, the proposed connected node attention (CNA) and non-connected node attention (NNA) aim to capture the global relations across connected nodes and non-connected nodes in the input graph, respectively. The proposed graph modeling block (GMB) aims to exploit local vertex interactions based on a house layout topology. Moreover, we propose a new node classification-based discriminator to preserve the high-level semantic and discriminative node features for different house components. Finally, we propose a novel graph-based cycle-consistency loss that aims at maintaining the relative spatial relationships between ground truth and predicted graphs. Experiments on two challenging graph-constrained house generation tasks (i.e., house layout and roof generation) with two public datasets demonstrate the effectiveness of GTGAN in terms of objective quantitative scores and subjective visual realism. New state-of-the-art results are established by large margins on both tasks. ",
    "url": "https://arxiv.org/abs/2303.08225",
    "authors": [
      "Hao Tang",
      "Zhenyu Zhang",
      "Humphrey Shi",
      "Bo Li",
      "Ling Shao",
      "Nicu Sebe",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08227",
    "title": "Hall effect thruster design via deep neural network for additive  manufacturing",
    "abstract": "Hall effect thrusters are one of the most versatile and popular electric propulsion systems for space use. Industry trends towards interplanetary missions arise advances in design development of such propulsion systems. It is understood that correct sizing of discharge channel in Hall effect thruster impact performance greatly. Since the complete physics model of such propulsion system is not yet optimized for fast computations and design iterations, most thrusters are being designed using so-called scaling laws. But this work focuses on rather novel approach, which is outlined less frequently than ordinary scaling design approach in literature. Using deep machine learning it is possible to create predictive performance model, which can be used to effortlessly get design of required hall thruster with required characteristics using way less computational power than design from scratch and way more flexible than usual scaling approach. ",
    "url": "https://arxiv.org/abs/2303.08227",
    "authors": [
      "Konstantin Korolev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Space Physics (physics.space-ph)"
    ]
  },
  {
    "id": "arXiv:2303.08229",
    "title": "Sensor network design for post-combustion CO2 capture plants: economy,  complexity and robustness",
    "abstract": "State estimation is crucial for the monitoring and control of post-combustion CO2 capture plants (PCCPs). The performance of state estimation is highly reliant on the configuration of sensors. In this work, we consider the problem of sensor selection for PCCPs and propose a computationally efficient method to determine an appropriate number of sensors and the corresponding placement of the sensors. The objective is to find the (near-)optimal set of sensors that provides the maximum degree of observability for state estimation while satisfying the budget constraint. Specifically, we resort to the information contained in the sensitivity matrix calculated around the operating region of a PCCP to quantify the degree of observability of the entire system corresponding to the placed sensors. The sensor selection problem is converted to an optimization problem, and is efficiently solved by a one-by-one removal approach through sensitivity analysis. Next, we extend our approach to study fault tolerance (resilience) of the selected sensors to sensor malfunction. The resilient sensor selection problem is to find a sensor network that gives good estimation performance even when some of the sensors fail, thereby improving the overall system robustness. The resilient sensor selection problem is formulated as a max-min optimization problem. We show how the proposed approach can be adapted to solve the sensor selection max-min optimization problem. By implementing the proposed approaches, the sensor network is configured for the PCCP efficiently. ",
    "url": "https://arxiv.org/abs/2303.08229",
    "authors": [
      "Siyu Liu",
      "Xunyuan Yin",
      "Jinfeng Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2303.08230",
    "title": "Bayesian Beta-Bernoulli Process Sparse Coding with Deep Neural Networks",
    "abstract": "Several approximate inference methods have been proposed for deep discrete latent variable models. However, non-parametric methods which have previously been successfully employed for classical sparse coding models have largely been unexplored in the context of deep models. We propose a non-parametric iterative algorithm for learning discrete latent representations in such deep models. Additionally, to learn scale invariant discrete features, we propose local data scaling variables. Lastly, to encourage sparsity in our representations, we propose a Beta-Bernoulli process prior on the latent factors. We evaluate our spare coding model coupled with different likelihood models. We evaluate our method across datasets with varying characteristics and compare our results to current amortized approximate inference methods. ",
    "url": "https://arxiv.org/abs/2303.08230",
    "authors": [
      "Arunesh Mittal",
      "Kai Yang",
      "Paul Sajda",
      "John Paisley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.08240",
    "title": "Parametric Surface Constrained Upsampler Network for Point Cloud",
    "abstract": "Designing a point cloud upsampler, which aims to generate a clean and dense point cloud given a sparse point representation, is a fundamental and challenging problem in computer vision. A line of attempts achieves this goal by establishing a point-to-point mapping function via deep neural networks. However, these approaches are prone to produce outlier points due to the lack of explicit surface-level constraints. To solve this problem, we introduce a novel surface regularizer into the upsampler network by forcing the neural network to learn the underlying parametric surface represented by bicubic functions and rotation functions, where the new generated points are then constrained on the underlying surface. These designs are integrated into two different networks for two tasks that take advantages of upsampling layers - point cloud upsampling and point cloud completion for evaluation. The state-of-the-art experimental results on both tasks demonstrate the effectiveness of the proposed method. The implementation code will be available at https://github.com/corecai163/PSCU. ",
    "url": "https://arxiv.org/abs/2303.08240",
    "authors": [
      "Pingping Cai",
      "Zhenyao Wu",
      "Xinyi Wu",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08244",
    "title": "Casual Source Code Editing",
    "abstract": "There has been substantial research undertaken on the role of computational systems that encourage autotelic creativity. Previous studies on the role of software in autotelic creativity have not explored code editing tools in much detail. This study sets out to examine the role of code editing tools in autotelic creativity. The principal findings of this research are that existing code editors can be adapted to support casual creativity, and that casual creators exhibit standard interaction design patterns. ",
    "url": "https://arxiv.org/abs/2303.08244",
    "authors": [
      "Ender Minyard"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.08248",
    "title": "An Intrusion Detection Mechanism for MANETs Based on Deep Learning  Artificial Neural Networks (ANNs)",
    "abstract": "Mobile Ad-hoc Network (MANET) is a distributed, decentralized network of wireless portable nodes connecting directly without any fixed communication base station or centralized administration. Nodes in MANET move continuously in random directions and follow an arbitrary manner, which presents numerous challenges to these networks and make them more susceptible to different security threats. Due to this decentralized nature of their overall architecture, combined with the limitation of hardware resources, those infrastructure-less networks are more susceptible to different security attacks such as black hole attack, network partition, node selfishness, and Denial of Service (DoS) attacks. This work aims to present, investigate, and design an intrusion detection predictive technique for Mobile Ad hoc networks using deep learning artificial neural networks (ANNs). A simulation-based evaluation and a deep ANNs modelling for detecting and isolating a Denial of Service (DoS) attack are presented to improve the overall security level of Mobile ad hoc networks. ",
    "url": "https://arxiv.org/abs/2303.08248",
    "authors": [
      "Mohamad T Sultan",
      "Hesham El Sayed",
      "Manzoor Ahmed Khan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.08256",
    "title": "Gamora: Graph Learning based Symbolic Reasoning for Large-Scale Boolean  Networks",
    "abstract": "Reasoning high-level abstractions from bit-blasted Boolean networks (BNs) such as gate-level netlists can significantly benefit functional verification, logic minimization, datapath synthesis, malicious logic identification, etc. Mostly, conventional reasoning approaches leverage structural hashing and functional propagation, suffering from limited scalability and inefficient usage of modern computing power. In response, we propose a novel symbolic reasoning framework exploiting graph neural networks (GNNs) and GPU acceleration to reason high-level functional blocks from gate-level netlists, namely Gamora, which offers high reasoning performance w.r.t exact reasoning algorithms, strong scalability to BNs with over 33 million nodes, and generalization capability from simple to complex designs. To further demonstrate the capability of Gamora, we also evaluate its reasoning performance after various technology mapping options, since technology-dependent optimizations are known to make functional reasoning much more challenging. Experimental results show that (1) Gamora reaches almost 100% and over 97% reasoning accuracy for carry-save-array (CSA) and Booth-encoded multipliers, respectively, with up to six orders of magnitude speedups compared to the state-of-the-art implementation in the ABC framework; (2) Gamora maintains high reasoning accuracy (>92%) in finding functional modules after complex technology mapping, upon which we comprehensively analyze the impacts on Gamora reasoning from technology mapping. ",
    "url": "https://arxiv.org/abs/2303.08256",
    "authors": [
      "Nan Wu",
      "Yingjie Li",
      "Cong Hao",
      "Steve Dai",
      "Cunxi Yu",
      "Yuan Xie"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2303.08264",
    "title": "Neuro-symbolic Commonsense Social Reasoning",
    "abstract": "Social norms underlie all human social interactions, yet formalizing and reasoning with them remains a major challenge for AI systems. We present a novel system for taking social rules of thumb (ROTs) in natural language from the Social Chemistry 101 dataset and converting them to first-order logic where reasoning is performed using a neuro-symbolic theorem prover. We accomplish this in several steps. First, ROTs are converted into Abstract Meaning Representation (AMR), which is a graphical representation of the concepts in a sentence, and align the AMR with RoBERTa embeddings. We then generate alternate simplified versions of the AMR via a novel algorithm, recombining and merging embeddings for added robustness against different wordings of text, and incorrect AMR parses. The AMR is then converted into first-order logic, and is queried with a neuro-symbolic theorem prover. The goal of this paper is to develop and evaluate a neuro-symbolic method which performs explicit reasoning about social situations in a logical form. ",
    "url": "https://arxiv.org/abs/2303.08264",
    "authors": [
      "David Chanin",
      "Anthony Hunter"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08273",
    "title": "Towards a Deep Learning Pain-Level Detection Deployment at UAE for  Patient-Centric-Pain Management and Diagnosis Support: Framework and  Performance Evaluation",
    "abstract": "The outbreak of the COVID-19 pandemic revealed the criticality of timely intervention in a situation exacerbated by a shortage in medical staff and equipment. Pain-level screening is the initial step toward identifying the severity of patient conditions. Automatic recognition of state and feelings help in identifying patient symptoms to take immediate adequate action and providing a patient-centric medical plan tailored to a patient's state. In this paper, we propose a framework for pain-level detection for deployment in the United Arab Emirates and assess its performance using the most used approaches in the literature. Our results show that a deployment of a pain-level deep learning detection framework is promising in identifying the pain level accurately. ",
    "url": "https://arxiv.org/abs/2303.08273",
    "authors": [
      "Leila Ismail",
      "Muhammad Danish Waseem"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.08289",
    "title": "Improving Adversarial Robustness with Hypersphere Embedding and  Angular-based Regularizations",
    "abstract": "Adversarial training (AT) methods have been found to be effective against adversarial attacks on deep neural networks. Many variants of AT have been proposed to improve its performance. Pang et al. [1] have recently shown that incorporating hypersphere embedding (HE) into the existing AT procedures enhances robustness. We observe that the existing AT procedures are not designed for the HE framework, and thus fail to adequately learn the angular discriminative information available in the HE framework. In this paper, we propose integrating HE into AT with regularization terms that exploit the rich angular information available in the HE framework. Specifically, our method, termed angular-AT, adds regularization terms to AT that explicitly enforce weight-feature compactness and inter-class separation; all expressed in terms of angular features. Experimental results show that angular-AT further improves adversarial robustness. ",
    "url": "https://arxiv.org/abs/2303.08289",
    "authors": [
      "Olukorede Fakorede",
      "Ashutosh Nirala",
      "Modeste Atsague",
      "Jin Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08316",
    "title": "MSF: Motion-guided Sequential Fusion for Efficient 3D Object Detection  from Point Cloud Sequences",
    "abstract": "Point cloud sequences are commonly used to accurately detect 3D objects in applications such as autonomous driving. Current top-performing multi-frame detectors mostly follow a Detect-and-Fuse framework, which extracts features from each frame of the sequence and fuses them to detect the objects in the current frame. However, this inevitably leads to redundant computation since adjacent frames are highly correlated. In this paper, we propose an efficient Motion-guided Sequential Fusion (MSF) method, which exploits the continuity of object motion to mine useful sequential contexts for object detection in the current frame. We first generate 3D proposals on the current frame and propagate them to preceding frames based on the estimated velocities. The points-of-interest are then pooled from the sequence and encoded as proposal features. A novel Bidirectional Feature Aggregation (BiFA) module is further proposed to facilitate the interactions of proposal features across frames. Besides, we optimize the point cloud pooling by a voxel-based sampling technique so that millions of points can be processed in several milliseconds. The proposed MSF method achieves not only better efficiency than other multi-frame detectors but also leading accuracy, with 83.12% and 78.30% mAP on the LEVEL1 and LEVEL2 test sets of Waymo Open Dataset, respectively. Codes can be found at \\url{https://github.com/skyhehe123/MSF}. ",
    "url": "https://arxiv.org/abs/2303.08316",
    "authors": [
      "Chenhang He",
      "Ruihuang Li",
      "Yabin Zhang",
      "Shuai Li",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08318",
    "title": "Micro-video Tagging via Jointly Modeling Social Influence and Tag  Relation",
    "abstract": "The last decade has witnessed the proliferation of micro-videos on various user-generated content platforms. According to our statistics, around 85.7\\% of micro-videos lack annotation. In this paper, we focus on annotating micro-videos with tags. Existing methods mostly focus on analyzing video content, neglecting users' social influence and tag relation. Meanwhile, existing tag relation construction methods suffer from either deficient performance or low tag coverage. To jointly model social influence and tag relation, we formulate micro-video tagging as a link prediction problem in a constructed heterogeneous network. Specifically, the tag relation (represented by tag ontology) is constructed in a semi-supervised manner. Then, we combine tag relation, video-tag annotation, and user-follow relation to build the network. Afterward, a better video and tag representation are derived through Behavior Spread modeling and visual and linguistic knowledge aggregation. Finally, the semantic similarity between each micro-video and all candidate tags is calculated in this video-tag network. Extensive experiments on industrial datasets of three verticals verify the superiority of our model compared with several state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2303.08318",
    "authors": [
      "Xiao Wang",
      "Tian Gan",
      "Yinwei Wei",
      "Jianlong Wu",
      "Dai Meng",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08322",
    "title": "Optimization Design for Federated Learning in Heterogeneous 6G Networks",
    "abstract": "With the rapid advancement of 5G networks, billions of smart Internet of Things (IoT) devices along with an enormous amount of data are generated at the network edge. While still at an early age, it is expected that the evolving 6G network will adopt advanced artificial intelligence (AI) technologies to collect, transmit, and learn this valuable data for innovative applications and intelligent services. However, traditional machine learning (ML) approaches require centralizing the training data in the data center or cloud, raising serious user-privacy concerns. Federated learning, as an emerging distributed AI paradigm with privacy-preserving nature, is anticipated to be a key enabler for achieving ubiquitous AI in 6G networks. However, there are several system and statistical heterogeneity challenges for effective and efficient FL implementation in 6G networks. In this article, we investigate the optimization approaches that can effectively address the challenging heterogeneity issues from three aspects: incentive mechanism design, network resource management, and personalized model optimization. We also present some open problems and promising directions for future research. ",
    "url": "https://arxiv.org/abs/2303.08322",
    "authors": [
      "Bing Luo",
      "Xiaomin Ouyang",
      "Peng Sun",
      "Pengchao Han",
      "Ningning Ding",
      "Jianwei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.08338",
    "title": "Latent space approaches to aggregate network data",
    "abstract": "Large-scale network data can pose computational challenges, be expensive to acquire, and compromise the privacy of individuals in social networks. We show that the locations and scales of latent space cluster models can be inferred from the number of connections between groups alone. We demonstrate this modelling approach using synthetic data and apply it to friendships between students collected as part of the Add Health study, eliminating the need for node-level connection data. The method thus protects the privacy of individuals and simplifies data sharing. It also offers performance advantages over node-level latent space models because the computational cost scales with the number of clusters rather than the number of nodes. ",
    "url": "https://arxiv.org/abs/2303.08338",
    "authors": [
      "Till Hoffmann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.08342",
    "title": "Autonomous Soundscape Augmentation with Multimodal Fusion of Visual and  Participant-linked Inputs",
    "abstract": "Autonomous soundscape augmentation systems typically use trained models to pick optimal maskers to effect a desired perceptual change. While acoustic information is paramount to such systems, contextual information, including participant demographics and the visual environment, also influences acoustic perception. Hence, we propose modular modifications to an existing attention-based deep neural network, to allow early, mid-level, and late feature fusion of participant-linked, visual, and acoustic features. Ablation studies on module configurations and corresponding fusion methods using the ARAUS dataset show that contextual features improve the model performance in a statistically significant manner on the normalized ISO Pleasantness, to a mean squared error of $0.1194\\pm0.0012$ for the best-performing all-modality model, against $0.1217\\pm0.0009$ for the audio-only model. Soundscape augmentation systems can thereby leverage multimodal inputs for improved performance. We also investigate the impact of individual participant-linked factors using trained models to illustrate improvements in model explainability. ",
    "url": "https://arxiv.org/abs/2303.08342",
    "authors": [
      "Kenneth Ooi",
      "Karn N. Watcharasupat",
      "Bhan Lam",
      "Zhen-Ting Ong",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.08346",
    "title": "Robust Preference-Guided Denoising for Graph based Social Recommendation",
    "abstract": "Graph Neural Network(GNN) based social recommendation models improve the prediction accuracy of user preference by leveraging GNN in exploiting preference similarity contained in social relations. However, in terms of both effectiveness and efficiency of recommendation, a large portion of social relations can be redundant or even noisy, e.g., it is quite normal that friends share no preference in a certain domain. Existing models do not fully solve this problem of relation redundancy and noise, as they directly characterize social influence over the full social network. In this paper, we instead propose to improve graph based social recommendation by only retaining the informative social relations to ensure an efficient and effective influence diffusion, i.e., graph denoising. Our designed denoising method is preference-guided to model social relation confidence and benefits user preference learning in return by providing a denoised but more informative social graph for recommendation models. Moreover, to avoid interference of noisy social relations, it designs a self-correcting curriculum learning module and an adaptive denoising strategy, both favoring highly-confident samples. Experimental results on three public datasets demonstrate its consistent capability of improving two state-of-the-art social recommendation models by robustly removing 10-40% of original relations. We release the source code at https://github.com/tsinghua-fib-lab/Graph-Denoising-SocialRec. ",
    "url": "https://arxiv.org/abs/2303.08346",
    "authors": [
      "Yuhan Quan",
      "Jingtao Ding",
      "Chen Gao",
      "Lingling Yi",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.08348",
    "title": "Active Teacher for Semi-Supervised Object Detection",
    "abstract": "In this paper, we study teacher-student learning from the perspective of data initialization and propose a novel algorithm called Active Teacher(Source code are available at: \\url{https://github.com/HunterJ-Lin/ActiveTeacher}) for semi-supervised object detection (SSOD). Active Teacher extends the teacher-student framework to an iterative version, where the label set is partially initialized and gradually augmented by evaluating three key factors of unlabeled examples, including difficulty, information and diversity. With this design, Active Teacher can maximize the effect of limited label information while improving the quality of pseudo-labels. To validate our approach, we conduct extensive experiments on the MS-COCO benchmark and compare Active Teacher with a set of recently proposed SSOD methods. The experimental results not only validate the superior performance gain of Active Teacher over the compared methods, but also show that it enables the baseline network, ie, Faster-RCNN, to achieve 100% supervised performance with much less label expenditure, ie 40% labeled examples on MS-COCO. More importantly, we believe that the experimental analyses in this paper can provide useful empirical knowledge for data annotation in practical applications. ",
    "url": "https://arxiv.org/abs/2303.08348",
    "authors": [
      "Peng Mi",
      "Jianghang Lin",
      "Yiyi Zhou",
      "Yunhang Shen",
      "Gen Luo",
      "Xiaoshuai Sun",
      "Liujuan Cao",
      "Rongrong Fu",
      "Qiang Xu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08358",
    "title": "DICNet: Deep Instance-Level Contrastive Network for Double Incomplete  Multi-View Multi-Label Classification",
    "abstract": "In recent years, multi-view multi-label learning has aroused extensive research enthusiasm. However, multi-view multi-label data in the real world is commonly incomplete due to the uncertain factors of data collection and manual annotation, which means that not only multi-view features are often missing, and label completeness is also difficult to be satisfied. To deal with the double incomplete multi-view multi-label classification problem, we propose a deep instance-level contrastive network, namely DICNet. Different from conventional methods, our DICNet focuses on leveraging deep neural network to exploit the high-level semantic representations of samples rather than shallow-level features. First, we utilize the stacked autoencoders to build an end-to-end multi-view feature extraction framework to learn the view-specific representations of samples. Furthermore, in order to improve the consensus representation ability, we introduce an incomplete instance-level contrastive learning scheme to guide the encoders to better extract the consensus information of multiple views and use a multi-view weighted fusion module to enhance the discrimination of semantic features. Overall, our DICNet is adept in capturing consistent discriminative representations of multi-view multi-label data and avoiding the negative effects of missing views and missing labels. Extensive experiments performed on five datasets validate that our method outperforms other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2303.08358",
    "authors": [
      "Chengliang Liu",
      "Jie Wen",
      "Xiaoling Luo",
      "Chao Huang",
      "Zhihao Wu",
      "Yong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08361",
    "title": "Towards Cooperative Federated Learning over Heterogeneous Edge/Fog  Networks",
    "abstract": "Federated learning (FL) has been promoted as a popular technique for training machine learning (ML) models over edge/fog networks. Traditional implementations of FL have largely neglected the potential for inter-network cooperation, treating edge/fog devices and other infrastructure participating in ML as separate processing elements. Consequently, FL has been vulnerable to several dimensions of network heterogeneity, such as varying computation capabilities, communication resources, data qualities, and privacy demands. We advocate for cooperative federated learning (CFL), a cooperative edge/fog ML paradigm built on device-to-device (D2D) and device-to-server (D2S) interactions. Through D2D and D2S cooperation, CFL counteracts network heterogeneity in edge/fog networks through enabling a model/data/resource pooling mechanism, which will yield substantial improvements in ML model training quality and network resource consumption. We propose a set of core methodologies that form the foundation of D2D and D2S cooperation and present preliminary experiments that demonstrate their benefits. We also discuss new FL functionalities enabled by this cooperative framework such as the integration of unlabeled data and heterogeneous device privacy into ML model training. Finally, we describe some open research directions at the intersection of cooperative edge/fog and FL. ",
    "url": "https://arxiv.org/abs/2303.08361",
    "authors": [
      "Su Wang",
      "Seyyedali Hosseinalipour",
      "Vaneet Aggarwal",
      "Christopher G. Brinton",
      "David J. Love",
      "Weifeng Su",
      "Mung Chiang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.08367",
    "title": "Uncertainty-Aware Pedestrian Trajectory Prediction via Distributional  Diffusion",
    "abstract": "Tremendous efforts have been devoted to pedestrian trajectory prediction using generative modeling for accommodating uncertainty and multi-modality in human behaviors. An individual's inherent uncertainty, e.g., change of destination, can be masked by complex patterns resulting from the movements of interacting pedestrians. However, latent variable-based generative models often entangle such uncertainty with complexity, leading to either limited expressivity or overconfident predictions. In this work, we propose to separately model these two factors by implicitly deriving a flexible distribution that describes complex pedestrians' movements, whereas incorporating predictive uncertainty of individuals with explicit density functions over their future locations. More specifically, we present an uncertainty-aware pedestrian trajectory prediction framework, parameterizing sufficient statistics for the distributions of locations that jointly comprise the multi-modal trajectories. We further estimate these parameters of interest by approximating a denoising process that progressively recovers pedestrian movements from noise. Unlike prior studies, we translate the predictive stochasticity to the explicit distribution, making it readily used to generate plausible future trajectories indicating individuals' self-uncertainty. Moreover, our framework is model-agnostic for compatibility with different neural network architectures. We empirically show the performance advantages of our framework on widely-used benchmarks, outperforming state-of-the-art in most scenes even with lighter backbones. ",
    "url": "https://arxiv.org/abs/2303.08367",
    "authors": [
      "Yao Liu",
      "Zesheng Ye",
      "Binghao Li",
      "Lina Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08370",
    "title": "Harnessing Low-Frequency Neural Fields for Few-Shot View Synthesis",
    "abstract": "Neural Radiance Fields (NeRF) have led to breakthroughs in the novel view synthesis problem. Positional Encoding (P.E.) is a critical factor that brings the impressive performance of NeRF, where low-dimensional coordinates are mapped to high-dimensional space to better recover scene details. However, blindly increasing the frequency of P.E. leads to overfitting when the reconstruction problem is highly underconstrained, \\eg, few-shot images for training. We harness low-frequency neural fields to regularize high-frequency neural fields from overfitting to better address the problem of few-shot view synthesis. We propose reconstructing with a low-frequency only field and then finishing details with a high-frequency equipped field. Unlike most existing solutions that regularize the output space (\\ie, rendered images), our regularization is conducted in the input space (\\ie, signal frequency). We further propose a simple-yet-effective strategy for tuning the frequency to avoid overfitting few-shot inputs: enforcing consistency among the frequency domain of rendered 2D images. Thanks to the input space regularizing scheme, our method readily applies to inputs beyond spatial locations, such as the time dimension in dynamic scenes. Comparisons with state-of-the-art on both synthetic and natural datasets validate the effectiveness of our proposed solution for few-shot view synthesis. Code is available at \\href{https://github.com/lsongx/halo}{https://github.com/lsongx/halo}. ",
    "url": "https://arxiv.org/abs/2303.08370",
    "authors": [
      "Liangchen Song",
      "Zhong Li",
      "Xuan Gong",
      "Lele Chen",
      "Zhang Chen",
      "Yi Xu",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08389",
    "title": "PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning",
    "abstract": "Vulnerability to lexical perturbation is a critical weakness of automatic evaluation metrics for image captioning. This paper proposes Perturbation Robust Multi-Lingual CLIPScore(PR-MCS), which exhibits robustness to such perturbations, as a novel reference-free image captioning metric applicable to multiple languages. To achieve perturbation robustness, we fine-tune the text encoder of CLIP with our language-agnostic method to distinguish the perturbed text from the original text. To verify the robustness of PR-MCS, we introduce a new fine-grained evaluation dataset consisting of detailed captions, critical objects, and the relationships between the objects for 3, 000 images in five languages. In our experiments, PR-MCS significantly outperforms baseline metrics in capturing lexical noise of all various perturbation types in all five languages, proving that PR-MCS is highly robust to lexical perturbations. ",
    "url": "https://arxiv.org/abs/2303.08389",
    "authors": [
      "Yongil Kim",
      "Yerin Hwang",
      "Hyeongu Yun",
      "Seunghyun Yoon",
      "Trung Bui",
      "Kyomin Jung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.08398",
    "title": "A Triplet-loss Dilated Residual Network for High-Resolution  Representation Learning in Image Retrieval",
    "abstract": "Content-based image retrieval is the process of retrieving a subset of images from an extensive image gallery based on visual contents, such as color, shape or spatial relations, and texture. In some applications, such as localization, image retrieval is employed as the initial step. In such cases, the accuracy of the top-retrieved images significantly affects the overall system accuracy. The current paper introduces a simple yet efficient image retrieval system with a fewer trainable parameters, which offers acceptable accuracy in top-retrieved images. The proposed method benefits from a dilated residual convolutional neural network with triplet loss. Experimental evaluations show that this model can extract richer information (i.e., high-resolution representations) by enlarging the receptive field, thus improving image retrieval accuracy without increasing the depth or complexity of the model. To enhance the extracted representations' robustness, the current research obtains candidate regions of interest from each feature map and applies Generalized-Mean pooling to the regions. As the choice of triplets in a triplet-based network affects the model training, we employ a triplet online mining method. We test the performance of the proposed method under various configurations on two of the challenging image-retrieval datasets, namely Revisited Paris6k (RPar) and UKBench. The experimental results show an accuracy of 94.54 and 80.23 (mean precision at rank 10) in the RPar medium and hard modes and 3.86 (recall at rank 4) in the UKBench dataset, respectively. ",
    "url": "https://arxiv.org/abs/2303.08398",
    "authors": [
      "Saeideh Yousefzadeh",
      "Hamidreza Pourreza",
      "Hamidreza Mahyar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08403",
    "title": "DualFair: Fair Representation Learning at Both Group and Individual  Levels via Contrastive Self-supervision",
    "abstract": "Algorithmic fairness has become an important machine learning problem, especially for mission-critical Web applications. This work presents a self-supervised model, called DualFair, that can debias sensitive attributes like gender and race from learned representations. Unlike existing models that target a single type of fairness, our model jointly optimizes for two fairness criteria - group fairness and counterfactual fairness - and hence makes fairer predictions at both the group and individual levels. Our model uses contrastive loss to generate embeddings that are indistinguishable for each protected group, while forcing the embeddings of counterfactual pairs to be similar. It then uses a self-knowledge distillation method to maintain the quality of representation for the downstream tasks. Extensive analysis over multiple datasets confirms the model's validity and further shows the synergy of jointly addressing two fairness criteria, suggesting the model's potential value in fair intelligent Web applications. ",
    "url": "https://arxiv.org/abs/2303.08403",
    "authors": [
      "Sungwon Han",
      "Seungeon Lee",
      "Fangzhao Wu",
      "Sundong Kim",
      "Chuhan Wu",
      "Xiting Wang",
      "Xing Xie",
      "Meeyoung Cha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.08414",
    "title": "From Local Binary Patterns to Pixel Difference Networks for Efficient  Visual Representation Learning",
    "abstract": "LBP is a successful hand-crafted feature descriptor in computer vision. However, in the deep learning era, deep neural networks, especially convolutional neural networks (CNNs) can automatically learn powerful task-aware features that are more discriminative and of higher representational capacity. To some extent, such hand-crafted features can be safely ignored when designing deep computer vision models. Nevertheless, due to LBP's preferable properties in visual representation learning, an interesting topic has arisen to explore the value of LBP in enhancing modern deep models in terms of efficiency, memory consumption, and predictive performance. In this paper, we provide a comprehensive review on such efforts which aims to incorporate the LBP mechanism into the design of CNN modules to make deep models stronger. In retrospect of what has been achieved so far, the paper discusses open challenges and directions for future research. ",
    "url": "https://arxiv.org/abs/2303.08414",
    "authors": [
      "Zhuo Su",
      "Matti Pietik\u00e4inen",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08419",
    "title": "Multi-Modal Facial Expression Recognition with Transformer-Based Fusion  Networks and Dynamic Sampling",
    "abstract": "Facial expression recognition is important for various purpose such as emotion detection, mental health analysis, and human-machine interaction. In facial expression recognition, incorporating audio information along with still images can provide a more comprehensive understanding of an expression state. This paper presents the Multi-modal facial expression recognition methods for Affective Behavior in-the-wild (ABAW) challenge at CVPR 2023. We propose a Modal Fusion Module (MFM) to fuse audio-visual information. The modalities used are image and audio, and features are extracted based on Swin Transformer to forward the MFM. Our approach also addresses imbalances in the dataset through data resampling in training dataset and leverages the rich modal in a single frame using dynmaic data sampling, leading to improved performance. ",
    "url": "https://arxiv.org/abs/2303.08419",
    "authors": [
      "Jun-Hwa Kim",
      "Namho Kim",
      "Chee Sun Won"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08435",
    "title": "Physics-Informed Optical Kernel Regression Using Complex-valued Neural  Fields",
    "abstract": "Lithography is fundamental to integrated circuit fabrication, necessitating large computation overhead. The advancement of machine learning (ML)-based lithography models alleviates the trade-offs between manufacturing process expense and capability. However, all previous methods regard the lithography system as an image-to-image black box mapping, utilizing network parameters to learn by rote mappings from massive mask-to-aerial or mask-to-resist image pairs, resulting in poor generalization capability. In this paper, we propose a new ML-based paradigm disassembling the rigorous lithographic model into non-parametric mask operations and learned optical kernels containing determinant source, pupil, and lithography information. By optimizing complex-valued neural fields to perform optical kernel regression from coordinates, our method can accurately restore lithography system using a small-scale training dataset with fewer parameters, demonstrating superior generalization capability as well. Experiments show that our framework can use 31\\% of parameters while achieving 69$\\times$ smaller mean squared error with 1.3$\\times$ higher throughput than the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2303.08435",
    "authors": [
      "Guojin Chen",
      "Zehua Pei",
      "Haoyu Yang",
      "Yuzhe Ma",
      "Bei Yu",
      "Martin D. F. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.08439",
    "title": "Real Face Foundation Representation Learning for Generalized Deepfake  Detection",
    "abstract": "The emergence of deepfake technologies has become a matter of social concern as they pose threats to individual privacy and public security. It is now of great significance to develop reliable deepfake detectors. However, with numerous face manipulation algorithms present, it is almost impossible to collect sufficient representative fake faces, and it is hard for existing detectors to generalize to all types of manipulation. Therefore, we turn to learn the distribution of real faces, and indirectly identify fake images that deviate from the real face distribution. In this study, we propose Real Face Foundation Representation Learning (RFFR), which aims to learn a general representation from large-scale real face datasets and detect potential artifacts outside the distribution of RFFR. Specifically, we train a model on real face datasets by masked image modeling (MIM), which results in a discrepancy between input faces and the reconstructed ones when applying the model on fake samples. This discrepancy reveals the low-level artifacts not contained in RFFR, making it easier to build a deepfake detector sensitive to all kinds of potential artifacts outside the distribution of RFFR. Extensive experiments demonstrate that our method brings about better generalization performance, as it significantly outperforms the state-of-the-art methods in cross-manipulation evaluations, and has the potential to further improve by introducing extra real faces for training RFFR. ",
    "url": "https://arxiv.org/abs/2303.08439",
    "authors": [
      "Liang Shi",
      "Jie Zhang",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08455",
    "title": "On the uncertainty analysis of the data-enabled physics-informed neural  network for solving neutron diffusion eigenvalue problem",
    "abstract": "In practical engineering experiments, the data obtained through detectors are inevitably noisy. For the already proposed data-enabled physics-informed neural network (DEPINN) \\citep{DEPINN}, we investigate the performance of DEPINN in calculating the neutron diffusion eigenvalue problem from several perspectives when the prior data contain different scales of noise. Further, in order to reduce the effect of noise and improve the utilization of the noisy prior data, we propose innovative interval loss functions and give some rigorous mathematical proofs. The robustness of DEPINN is examined on two typical benchmark problems through a large number of numerical results, and the effectiveness of the proposed interval loss function is demonstrated by comparison. This paper confirms the feasibility of the improved DEPINN for practical engineering applications in nuclear reactor physics. ",
    "url": "https://arxiv.org/abs/2303.08455",
    "authors": [
      "Yu Yang",
      "Helin Gong",
      "Qihong Yang",
      "Yangtao Deng",
      "Qiaolin He",
      "Shiquan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2303.08457",
    "title": "Altruistic and Profit-oriented: Making Sense of Roles in Web3 Community  from Airdrop Perspective",
    "abstract": "Regardless of which community, incentivizing users is a necessity for well-sustainable operations. In the blockchain-backed Web3 communities, known for their transparency and security, airdrop serves as a widespread incentive mechanism for allocating capital and power. However, it remains a controversy on how to justify airdrop to incentive and empower the decentralized governance. In this paper, we use ParaSwap as an example to propose a role taxonomy methodology through a data-driven study to understand the characteristic of community members and the effectiveness of airdrop. We find that users receive more rewards tend to take positive actions towards the community. We summarize several arbitrage patterns and confirm the current detection is not sufficient in screening out airdrop hunters. In conjunction with the results, we discuss from the aspects of interaction, financialization, and system design to conclude the challenges and possible research directions for decentralized communities. ",
    "url": "https://arxiv.org/abs/2303.08457",
    "authors": [
      "Sizheng Fan",
      "Tian Min",
      "Xiao Wu",
      "Wei Cai"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.08459",
    "title": "Hybrid-Physical Probabilistic Forecasting for a Set of Photovoltaic  Systems using Recurrent Neural Networks",
    "abstract": "Accurate intra-day forecasts of the power output by PhotoVoltaic (PV) systems are critical to improve the operation of energy distribution grids. We describe a hybrid-physical model, which aims at improving deterministic intra-day forecasts, issued by a PV performance model fed by Numerical Weather Predictions (NWP), by using them as covariates in the context of an autoregressive recurrent neural model. Our proposal repurposes a neural model initially used in the retail sector, and discloses a novel truncated Gaussian output distribution. We experimentally compare many model variants to alternatives from the literature, and an ablation study shows that the components in the best performing variant work synergistically to reach a skill score of 7.54% with respect to the NWP-driven PV performance model baseline. ",
    "url": "https://arxiv.org/abs/2303.08459",
    "authors": [
      "Pierrick Bruneau",
      "David Fiorelli",
      "Christian Braun",
      "Daniel Koster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08466",
    "title": "Mining False Positive Examples for Text-Based Person Re-identification",
    "abstract": "Text-based person re-identification (ReID) aims to identify images of the targeted person from a large-scale person image database according to a given textual description. However, due to significant inter-modal gaps, text-based person ReID remains a challenging problem. Most existing methods generally rely heavily on the similarity contributed by matched word-region pairs, while neglecting mismatched word-region pairs which may play a decisive role. Accordingly, we propose to mine false positive examples (MFPE) via a jointly optimized multi-branch architecture to handle this problem. MFPE contains three branches including a false positive mining (FPM) branch to highlight the role of mismatched word-region pairs. Besides, MFPE delicately designs a cross-relu loss to increase the gap of similarity scores between matched and mismatched word-region pairs. Extensive experiments on CUHK-PEDES demonstrate the superior effectiveness of MFPE. Our code is released at https://github.com/xx-adeline/MFPE. ",
    "url": "https://arxiv.org/abs/2303.08466",
    "authors": [
      "Wenhao Xu",
      "Zhiyin Shao",
      "Changxing Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08473",
    "title": "Unsupervised Traffic Scene Generation with Synthetic 3D Scene Graphs",
    "abstract": "Image synthesis driven by computer graphics achieved recently a remarkable realism, yet synthetic image data generated this way reveals a significant domain gap with respect to real-world data. This is especially true in autonomous driving scenarios, which represent a critical aspect for overcoming utilizing synthetic data for training neural networks. We propose a method based on domain-invariant scene representation to directly synthesize traffic scene imagery without rendering. Specifically, we rely on synthetic scene graphs as our internal representation and introduce an unsupervised neural network architecture for realistic traffic scene synthesis. We enhance synthetic scene graphs with spatial information about the scene and demonstrate the effectiveness of our approach through scene manipulation. ",
    "url": "https://arxiv.org/abs/2303.08473",
    "authors": [
      "Artem Savkin",
      "Rachid Ellouze",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.08476",
    "title": "Bayesian Learning for the Robust Verification of Autonomous Robots",
    "abstract": "We develop a novel Bayesian learning framework that enables the runtime verification of autonomous robots performing critical missions in uncertain environments. Our framework exploits prior knowledge and observations of the verified robotic system to learn expected ranges of values for the occurrence rates of its events. We support both events observed regularly during system operation, and singular events such as catastrophic failures or the completion of difficult one-off tasks. Furthermore, we use the learnt event-rate ranges to assemble interval continuous-time Markov models, and we apply quantitative verification to these models to compute expected intervals of variation for key system properties. These intervals reflect the uncertainty intrinsic to many real-world systems, enabling the robust verification of their quantitative properties under parametric uncertainty. We apply the proposed framework to the case study of verification of an autonomous robotic mission for underwater infrastructure inspection and repair. ",
    "url": "https://arxiv.org/abs/2303.08476",
    "authors": [
      "Xingyu Zhao",
      "Simos Gerasimou",
      "Radu Calinescu",
      "Calum Imrie",
      "Valentin Robu",
      "David Flynn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08481",
    "title": "SeqCo-DETR: Sequence Consistency Training for Self-Supervised Object  Detection with Transformers",
    "abstract": "Self-supervised pre-training and transformer-based networks have significantly improved the performance of object detection. However, most of the current self-supervised object detection methods are built on convolutional-based architectures. We believe that the transformers' sequence characteristics should be considered when designing a transformer-based self-supervised method for the object detection task. To this end, we propose SeqCo-DETR, a novel Sequence Consistency-based self-supervised method for object DEtection with TRansformers. SeqCo-DETR defines a simple but effective pretext by minimizes the discrepancy of the output sequences of transformers with different image views as input and leverages bipartite matching to find the most relevant sequence pairs to improve the sequence-level self-supervised representation learning performance. Furthermore, we provide a mask-based augmentation strategy incorporated with the sequence consistency strategy to extract more representative contextual information about the object for the object detection task. Our method achieves state-of-the-art results on MS COCO (45.8 AP) and PASCAL VOC (64.1 AP), demonstrating the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2303.08481",
    "authors": [
      "Guoqiang Jin",
      "Fan Yang",
      "Mingshan Sun",
      "Ruyi Zhao",
      "Yakun Liu",
      "Wei Li",
      "Tianpeng Bao",
      "Liwei Wu",
      "Xingyu Zeng",
      "Rui Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08498",
    "title": "BEVHeight: A Robust Framework for Vision-based Roadside 3D Object  Detection",
    "abstract": "While most recent autonomous driving system focuses on developing perception methods on ego-vehicle sensors, people tend to overlook an alternative approach to leverage intelligent roadside cameras to extend the perception ability beyond the visual range. We discover that the state-of-the-art vision-centric bird's eye view detection methods have inferior performances on roadside cameras. This is because these methods mainly focus on recovering the depth regarding the camera center, where the depth difference between the car and the ground quickly shrinks while the distance increases. In this paper, we propose a simple yet effective approach, dubbed BEVHeight, to address this issue. In essence, instead of predicting the pixel-wise depth, we regress the height to the ground to achieve a distance-agnostic formulation to ease the optimization process of camera-only perception methods. On popular 3D detection benchmarks of roadside cameras, our method surpasses all previous vision-centric methods by a significant margin. The code is available at {\\url{https://github.com/ADLab-AutoDrive/BEVHeight}}. ",
    "url": "https://arxiv.org/abs/2303.08498",
    "authors": [
      "Lei Yang",
      "Kaicheng Yu",
      "Tao Tang",
      "Jun Li",
      "Kun Yuan",
      "Li Wang",
      "Xinyu Zhang",
      "Peng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08505",
    "title": "RIS-Enabled Smart Wireless Environments: Deployment Scenarios, Network  Architecture, Bandwidth and Area of Influence",
    "abstract": "Reconfigurable Intelligent Surfaces (RISs) constitute the key enabler for programmable electromagnetic propagation environments, and are lately being considered as a candidate physical-layer technology for the demanding connectivity, reliability, localization, and sustainability requirements of next generation wireless networks. In this paper, we first present the deployment scenarios for RIS-enabled smart wireless environments that have been recently designed within the ongoing European Union Horizon 2020 RISE-6G project, as well as a network architecture integrating RISs with existing standardized interfaces. We identify various RIS deployment strategies and sketch the core architectural requirements in terms of RIS control and signaling, depending on the RIS hardware architectures and respective capabilities. Furthermore, we introduce and discuss, with the aid of simulations and reflectarray measurements, two novel metrics that emerge in the context of RIS-empowered wireless systems: the RIS bandwidth and area of influence. Their extensive investigation corroborates the need for careful deployment and planning of the RIS technology in future networks. ",
    "url": "https://arxiv.org/abs/2303.08505",
    "authors": [
      "George C. Alexandropoulos",
      "Dinh-Thuy Phan-Huy",
      "Kostantinos D. Katsanos",
      "Maurizio Crozzoli",
      "Henk Wymeersch",
      "Petar Popovski",
      "Philippe Ratajczak",
      "Yohann B\u00e9n\u00e9dic",
      "Marie-Helene Hamon",
      "Sebastien Herraiz Gonzalez",
      "Placido Mursia",
      "Marco Rossanese",
      "Vincenzo Sciancalepore",
      "Jean-Baptiste Gros",
      "Sergio Terranova",
      "Gabriele Gradoni",
      "Paolo Di Lorenzo",
      "Moustafa Rahal",
      "Benoit Denis",
      "Raffaele D'Errico",
      "Antonio Clemente",
      "Emilio Calvanese Strinati"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2303.08509",
    "title": "Black-box Adversarial Example Attack towards FCG Based Android Malware  Detection under Incomplete Feature Information",
    "abstract": "The function call graph (FCG) based Android malware detection methods have recently attracted increasing attention due to their promising performance. However, these methods are susceptible to adversarial examples (AEs). In this paper, we design a novel black-box AE attack towards the FCG based malware detection system, called BagAmmo. To mislead its target system, BagAmmo purposefully perturbs the FCG feature of malware through inserting \"never-executed\" function calls into malware code. The main challenges are two-fold. First, the malware functionality should not be changed by adversarial perturbation. Second, the information of the target system (e.g., the graph feature granularity and the output probabilities) is absent. To preserve malware functionality, BagAmmo employs the try-catch trap to insert function calls to perturb the FCG of malware. Without the knowledge about feature granularity and output probabilities, BagAmmo adopts the architecture of generative adversarial network (GAN), and leverages a multi-population co-evolution algorithm (i.e., Apoem) to generate the desired perturbation. Every population in Apoem represents a possible feature granularity, and the real feature granularity can be achieved when Apoem converges. Through extensive experiments on over 44k Android apps and 32 target models, we evaluate the effectiveness, efficiency and resilience of BagAmmo. BagAmmo achieves an average attack success rate of over 99.9% on MaMaDroid, APIGraph and GCN, and still performs well in the scenario of concept drift and data imbalance. Moreover, BagAmmo outperforms the state-of-the-art attack SRL in attack success rate. ",
    "url": "https://arxiv.org/abs/2303.08509",
    "authors": [
      "Heng Li",
      "Zhang Cheng",
      "Bang Wu",
      "Liheng Yuan",
      "Cuiying Gao",
      "Wei Yuan",
      "Xiapu Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.08525",
    "title": "MRGAN360: Multi-stage Recurrent Generative Adversarial Network for 360  Degree Image Saliency Prediction",
    "abstract": "Thanks to the ability of providing an immersive and interactive experience, the uptake of 360 degree image content has been rapidly growing in consumer and industrial applications. Compared to planar 2D images, saliency prediction for 360 degree images is more challenging due to their high resolutions and spherical viewing ranges. Currently, most high-performance saliency prediction models for omnidirectional images (ODIs) rely on deeper or broader convolutional neural networks (CNNs), which benefit from CNNs' superior feature representation capabilities while suffering from their high computational costs. In this paper, inspired by the human visual cognitive process, i.e., human being's perception of a visual scene is always accomplished by multiple stages of analysis, we propose a novel multi-stage recurrent generative adversarial networks for ODIs dubbed MRGAN360, to predict the saliency maps stage by stage. At each stage, the prediction model takes as input the original image and the output of the previous stage and outputs a more accurate saliency map. We employ a recurrent neural network among adjacent prediction stages to model their correlations, and exploit a discriminator at the end of each stage to supervise the output saliency map. In addition, we share the weights among all the stages to obtain a lightweight architecture that is computationally cheap. Extensive experiments are conducted to demonstrate that our proposed model outperforms the state-of-the-art model in terms of both prediction accuracy and model size. ",
    "url": "https://arxiv.org/abs/2303.08525",
    "authors": [
      "Pan Gao",
      "Xinlang Chen",
      "Rong Quan",
      "Wei Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.08536",
    "title": "Watch or Listen: Robust Audio-Visual Speech Recognition with Visual  Corruption Modeling and Reliability Scoring",
    "abstract": "This paper deals with Audio-Visual Speech Recognition (AVSR) under multimodal input corruption situations where audio inputs and visual inputs are both corrupted, which is not well addressed in previous research directions. Previous studies have focused on how to complement the corrupted audio inputs with the clean visual inputs with the assumption of the availability of clean visual inputs. However, in real life, clean visual inputs are not always accessible and can even be corrupted by occluded lip regions or noises. Thus, we firstly analyze that the previous AVSR models are not indeed robust to the corruption of multimodal input streams, the audio and the visual inputs, compared to uni-modal models. Then, we design multimodal input corruption modeling to develop robust AVSR models. Lastly, we propose a novel AVSR framework, namely Audio-Visual Reliability Scoring module (AV-RelScore), that is robust to the corrupted multimodal inputs. The AV-RelScore can determine which input modal stream is reliable or not for the prediction and also can exploit the more reliable streams in prediction. The effectiveness of the proposed method is evaluated with comprehensive experiments on popular benchmark databases, LRS2 and LRS3. We also show that the reliability scores obtained by AV-RelScore well reflect the degree of corruption and make the proposed model focus on the reliable multimodal representations. ",
    "url": "https://arxiv.org/abs/2303.08536",
    "authors": [
      "Joanna Hong",
      "Minsu Kim",
      "Jeongsoo Choi",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.08544",
    "title": "Joint Security-vs-QoS Game Theoretical Optimization for Intrusion  Response Mechanisms for Future Network Systems",
    "abstract": "Network connectivity exposes the network infrastructure and assets to vulnerabilities that attackers can exploit. Protecting network assets against attacks requires the application of security countermeasures. Nevertheless, employing countermeasures incurs costs, such as monetary costs, along with time and energy to prepare and deploy the countermeasures. Thus, an Intrusion Response System (IRS) shall consider security and QoS costs when dynamically selecting the countermeasures to address the detected attacks. This has motivated us to formulate a joint Security-vs-QoS optimization problem to select the best countermeasures in an IRS. The problem is then transformed into a matching game-theoretical model. Considering the monetary costs and attack coverage constraints, we first derive the theoretical upper bound for the problem and later propose stable matching-based solutions to address the trade-off. The performance of the proposed solution, considering different settings, is validated over a series of simulations. ",
    "url": "https://arxiv.org/abs/2303.08544",
    "authors": [
      "Arash Bozorgchenani",
      "Charilaos C. Zarakovitis",
      "Su Fong Chien",
      "Qiang Ni",
      "Antonios Gouglidis",
      "Wissam Mallouli",
      "Heng Siong Lim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.08545",
    "title": "Local Region Perception and Relationship Learning Combined with Feature  Fusion for Facial Action Unit Detection",
    "abstract": "Human affective behavior analysis plays a vital role in human-computer interaction (HCI) systems. In this paper, we introduce our submission to the CVPR 2023 Competition on Affective Behavior Analysis in-the-wild (ABAW). We propose a single-stage trained AU detection framework. Specifically, in order to effectively extract facial local region features related to AU detection, we use a local region perception module to effectively extract features of different AUs. Meanwhile, we use a graph neural network-based relational learning module to capture the relationship between AUs. In addition, considering the role of the overall feature of the target face on AU detection, we also use the feature fusion module to fuse the feature information extracted by the backbone network and the AU feature information extracted by the relationship learning module. We also adopted some sampling methods, data augmentation techniques and post-processing strategies to further improve the performance of the model. ",
    "url": "https://arxiv.org/abs/2303.08545",
    "authors": [
      "Jun Yu",
      "Renda Li",
      "Zhongpeng Cai",
      "Gongpeng Zhao",
      "Guochen Xie",
      "Jichao Zhu",
      "Wangyuan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08561",
    "title": "Enhancing Unsupervised Audio Representation Learning via Adversarial  Sample Generation",
    "abstract": "Existing audio analysis methods generally first transform the audio stream to spectrogram, and then feed it into CNN for further analysis. A standard CNN recognizes specific visual patterns over feature map, then pools for high-level representation, which overlooks the positional information of recognized patterns. However, unlike natural image, the semantic of an audio spectrogram is sensitive to positional change, as its vertical and horizontal axes indicate the frequency and temporal information of the audio, instead of naive rectangular coordinates. Thus, the insensitivity of CNN to positional change plays a negative role on audio spectrogram encoding. To address this issue, this paper proposes a new self-supervised learning mechanism, which enhances the audio representation by first generating adversarial samples (\\textit{i.e.}, negative samples), then driving CNN to distinguish the embeddings of negative pairs in the latent space. Extensive experiments show that the proposed approach achieves best or competitive results on 9 downstream datasets compared with previous methods, which verifies its effectiveness on audio representation learning. ",
    "url": "https://arxiv.org/abs/2303.08561",
    "authors": [
      "Yulin Pan",
      "Xiangteng He",
      "Biao Gong",
      "Yuxin Peng",
      "Yiliang Lv"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.08574",
    "title": "WikiCoder: Learning to Write Knowledge-Powered Code",
    "abstract": "We tackle the problem of automatic generation of computer programs from a few pairs of input-output examples. The starting point of this work is the observation that in many applications a solution program must use external knowledge not present in the examples: we call such programs knowledge-powered since they can refer to information collected from a knowledge graph such as Wikipedia. This paper makes a first step towards knowledge-powered program synthesis. We present WikiCoder, a system building upon state of the art machine-learned program synthesizers and integrating knowledge graphs. We evaluate it to show its wide applicability over different domains and discuss its limitations. WikiCoder solves tasks that no program synthesizers were able to solve before thanks to the use of knowledge graphs, while integrating with recent developments in the field to operate at scale. ",
    "url": "https://arxiv.org/abs/2303.08574",
    "authors": [
      "Th\u00e9o Matricon",
      "Nathana\u00ebl Fijalkow",
      "Ga\u00ebtan Margueritte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.08581",
    "title": "Model Extraction Attacks on Split Federated Learning",
    "abstract": "Federated Learning (FL) is a popular collaborative learning scheme involving multiple clients and a server. FL focuses on protecting clients' data but turns out to be highly vulnerable to Intellectual Property (IP) threats. Since FL periodically collects and distributes the model parameters, a free-rider can download the latest model and thus steal model IP. Split Federated Learning (SFL), a recent variant of FL that supports training with resource-constrained clients, splits the model into two, giving one part of the model to clients (client-side model), and the remaining part to the server (server-side model). Thus SFL prevents model leakage by design. Moreover, by blocking prediction queries, it can be made resistant to advanced IP threats such as traditional Model Extraction (ME) attacks. While SFL is better than FL in terms of providing IP protection, it is still vulnerable. In this paper, we expose the vulnerability of SFL and show how malicious clients can launch ME attacks by querying the gradient information from the server side. We propose five variants of ME attack which differs in the gradient usage as well as in the data assumptions. We show that under practical cases, the proposed ME attacks work exceptionally well for SFL. For instance, when the server-side model has five layers, our proposed ME attack can achieve over 90% accuracy with less than 2% accuracy degradation with VGG-11 on CIFAR-10. ",
    "url": "https://arxiv.org/abs/2303.08581",
    "authors": [
      "Jingtao Li",
      "Adnan Siraj Rakin",
      "Xing Chen",
      "Li Yang",
      "Zhezhi He",
      "Deliang Fan",
      "Chaitali Chakrabarti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08606",
    "title": "On the Calibration and Uncertainty with P\u00f3lya-Gamma Augmentation for  Dialog Retrieval Models",
    "abstract": "Deep neural retrieval models have amply demonstrated their power but estimating the reliability of their predictions remains challenging. Most dialog response retrieval models output a single score for a response on how relevant it is to a given question. However, the bad calibration of deep neural network results in various uncertainty for the single score such that the unreliable predictions always misinform user decisions. To investigate these issues, we present an efficient calibration and uncertainty estimation framework PG-DRR for dialog response retrieval models which adds a Gaussian Process layer to a deterministic deep neural network and recovers conjugacy for tractable posterior inference by P\\'{o}lya-Gamma augmentation. Finally, PG-DRR achieves the lowest empirical calibration error (ECE) in the in-domain datasets and the distributional shift task while keeping $R_{10}@1$ and MAP performance. ",
    "url": "https://arxiv.org/abs/2303.08606",
    "authors": [
      "Tong Ye",
      "Shijing Si",
      "Jianzong Wang",
      "Ning Cheng",
      "Zhitao Li",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08610",
    "title": "Blind Estimation of Audio Processing Graph",
    "abstract": "Musicians and audio engineers sculpt and transform their sounds by connecting multiple processors, forming an audio processing graph. However, most deep-learning methods overlook this real-world practice and assume fixed graph settings. To bridge this gap, we develop a system that reconstructs the entire graph from a given reference audio. We first generate a realistic graph-reference pair dataset and train a simple blind estimation system composed of a convolutional reference encoder and a transformer-based graph decoder. We apply our model to singing voice effects and drum mixing estimation tasks. Evaluation results show that our method can reconstruct complex signal routings, including multi-band processing and sidechaining. ",
    "url": "https://arxiv.org/abs/2303.08610",
    "authors": [
      "Sungho Lee",
      "Jaehyun Park",
      "Seungryeol Paik",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.08644",
    "title": "RGI : Regularized Graph Infomax for self-supervised learning on graphs",
    "abstract": "Self-supervised learning is gaining considerable attention as a solution to avoid the requirement of extensive annotations in representation learning on graphs. We introduce \\textit{Regularized Graph Infomax (RGI)}, a simple yet effective framework for node level self-supervised learning on graphs that trains a graph neural network encoder by maximizing the mutual information between node level local and global views, in contrast to previous works that employ graph level global views. The method promotes the predictability between views while regularizing the covariance matrices of the representations. Therefore, RGI is non-contrastive, does not depend on complex asymmetric architectures nor training tricks, is augmentation-free and does not rely on a two branch architecture. We run RGI on both transductive and inductive settings with popular graph benchmarks and show that it can achieve state-of-the-art performance regardless of its simplicity. ",
    "url": "https://arxiv.org/abs/2303.08644",
    "authors": [
      "Oscar Pina",
      "Ver\u00f3nica Vilaplana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08671",
    "title": "A Dual-Cluster-Head Based Medium Access Control for Large-Scale UAV  Ad-Hoc Networks",
    "abstract": "Unmanned Aerial Vehicle (UAV) ad hoc network has achieved significant growth for its flexibility, extensibility, and high deployability in recent years. The application of clustering scheme for UAV ad hoc network is imperative to enhance the performance of throughput and energy efficiency. In conventional clustering scheme, a single cluster head (CH) is always assigned in each cluster. However, this method has some weaknesses such as overload and premature death of CH when the number of UAVs increased. In order to solve this problem, we propose a dual-cluster-head based medium access control (DCHMAC) scheme for large-scale UAV networks. In DCHMAC, two CHs are elected to manage resource allocation and data forwarding cooperatively. Specifically, two CHs work on different channels. One of CH is used for intra-cluster communication and the other one is for inter-cluster communication. A Markov chain model is developed to analyse the throughput of the network. Simulation result shows that compared with FM-MAC (flying ad hoc networks multi-channel MAC,FM-MAC), DCHMAC improves the throughput by approximately 20%-50% and prolongs the network lifetime by approximately 40%. ",
    "url": "https://arxiv.org/abs/2303.08671",
    "authors": [
      "Xinru Zhao",
      "Zhiqing Wei",
      "Yingying Zou",
      "Hao Ma",
      "Yanpeng Cui",
      "Zhiyong Feng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.08686",
    "title": "Weakly Supervised Monocular 3D Object Detection using Multi-View  Projection and Direction Consistency",
    "abstract": "Monocular 3D object detection has become a mainstream approach in automatic driving for its easy application. A prominent advantage is that it does not need LiDAR point clouds during the inference. However, most current methods still rely on 3D point cloud data for labeling the ground truths used in the training phase. This inconsistency between the training and inference makes it hard to utilize the large-scale feedback data and increases the data collection expenses. To bridge this gap, we propose a new weakly supervised monocular 3D objection detection method, which can train the model with only 2D labels marked on images. To be specific, we explore three types of consistency in this task, i.e. the projection, multi-view and direction consistency, and design a weakly-supervised architecture based on these consistencies. Moreover, we propose a new 2D direction labeling method in this task to guide the model for accurate rotation direction prediction. Experiments show that our weakly-supervised method achieves comparable performance with some fully supervised methods. When used as a pre-training method, our model can significantly outperform the corresponding fully-supervised baseline with only 1/3 3D labels. https://github.com/weakmono3d/weakmono3d ",
    "url": "https://arxiv.org/abs/2303.08686",
    "authors": [
      "Runzhou Tao",
      "Wencheng Han",
      "Zhongying Qiu",
      "Cheng-zhong Xu",
      "Jianbing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08695",
    "title": "RefiNeRF: Modelling dynamic neural radiance fields with inconsistent or  missing camera parameters",
    "abstract": "Novel view synthesis (NVS) is a challenging task in computer vision that involves synthesizing new views of a scene from a limited set of input images. Neural Radiance Fields (NeRF) have emerged as a powerful approach to address this problem, but they require accurate knowledge of camera \\textit{intrinsic} and \\textit{extrinsic} parameters. Traditionally, structure-from-motion (SfM) and multi-view stereo (MVS) approaches have been used to extract camera parameters, but these methods can be unreliable and may fail in certain cases. In this paper, we propose a novel technique that leverages unposed images from dynamic datasets, such as the NVIDIA dynamic scenes dataset, to learn camera parameters directly from data. Our approach is highly extensible and can be integrated into existing NeRF architectures with minimal modifications. We demonstrate the effectiveness of our method on a variety of static and dynamic scenes and show that it outperforms traditional SfM and MVS approaches. The code for our method is publicly available at \\href{https://github.com/redacted/refinerf}{https://github.com/redacted/refinerf}. Our approach offers a promising new direction for improving the accuracy and robustness of NVS using NeRF, and we anticipate that it will be a valuable tool for a wide range of applications in computer vision and graphics. ",
    "url": "https://arxiv.org/abs/2303.08695",
    "authors": [
      "Shuja Khalid",
      "Frank Rudzicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08720",
    "title": "Practicality of generalization guarantees for unsupervised domain  adaptation with neural networks",
    "abstract": "Understanding generalization is crucial to confidently engineer and deploy machine learning models, especially when deployment implies a shift in the data domain. For such domain adaptation problems, we seek generalization bounds which are tractably computable and tight. If these desiderata can be reached, the bounds can serve as guarantees for adequate performance in deployment. However, in applications where deep neural networks are the models of choice, deriving results which fulfill these remains an unresolved challenge; most existing bounds are either vacuous or has non-estimable terms, even in favorable conditions. In this work, we evaluate existing bounds from the literature with potential to satisfy our desiderata on domain adaptation image classification tasks, where deep neural networks are preferred. We find that all bounds are vacuous and that sample generalization terms account for much of the observed looseness, especially when these terms interact with measures of domain shift. To overcome this and arrive at the tightest possible results, we combine each bound with recent data-dependent PAC-Bayes analysis, greatly improving the guarantees. We find that, when domain overlap can be assumed, a simple importance weighting extension of previous work provides the tightest estimable bound. Finally, we study which terms dominate the bounds and identify possible directions for further improvement. ",
    "url": "https://arxiv.org/abs/2303.08720",
    "authors": [
      "Adam Breitholtz",
      "Fredrik D. Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.08727",
    "title": "Background Matters: Enhancing Out-of-distribution Detection with Domain  Features",
    "abstract": "Detecting out-of-distribution (OOD) inputs is a principal task for ensuring the safety of deploying deep-neural-network classifiers in open-world scenarios. OOD samples can be drawn from arbitrary distributions and exhibit deviations from in-distribution (ID) data in various dimensions, such as foreground semantic features (e.g., vehicle images vs. ID samples in fruit classification) and background domain features (e.g., textural images vs. ID samples in object recognition). Existing methods focus on detecting OOD samples based on the semantic features, while neglecting the other dimensions such as the domain features. This paper considers the importance of the domain features in OOD detection and proposes to leverage them to enhance the semantic-feature-based OOD detection methods. To this end, we propose a novel generic framework that can learn the domain features from the ID training samples by a dense prediction approach, with which different existing semantic-feature-based OOD detection methods can be seamlessly combined to jointly learn the in-distribution features from both the semantic and domain dimensions. Extensive experiments show that our approach 1) can substantially enhance the performance of four different state-of-the-art (SotA) OOD detection methods on multiple widely-used OOD datasets with diverse domain features, and 2) achieves new SotA performance on these benchmarks. ",
    "url": "https://arxiv.org/abs/2303.08727",
    "authors": [
      "Choubo Ding",
      "Guansong Pang",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08729",
    "title": "DACOS-A Manually Annotated Dataset of Code Smells",
    "abstract": "Researchers apply machine-learning techniques for code smell detection to counter the subjectivity of many code smells. Such approaches need a large, manually annotated dataset for training and benchmarking. Existing literature offers a few datasets; however, they are small in size and, more importantly, do not focus on the subjective code snippets. In this paper, we present DACOS, a manually annotated dataset containing 10,267 annotations for 5,192 code snippets. The dataset targets three kinds of code smells at different granularity: multifaceted abstraction, complex method, and long parameter list. The dataset is created in two phases. The first phase helps us identify the code snippets that are potentially subjective by determining the thresholds of metrics used to detect a smell. The second phase collects annotations for potentially subjective snippets. We also offer an extended dataset DACOSX that includes definitely benign and definitely smelly snippets by using the thresholds identified in the first phase. We have developed TagMan, a web application to help annotators view and mark the snippets one-by-one and record the provided annotations. We make the datasets and the web application accessible publicly. This dataset will help researchers working on smell detection techniques to build relevant and context-aware machine-learning models. ",
    "url": "https://arxiv.org/abs/2303.08729",
    "authors": [
      "Himesh Nandani",
      "Mootez Saad",
      "Tushar Sharma"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2303.08730",
    "title": "DiffusionAD: Denoising Diffusion for Anomaly Detection",
    "abstract": "Anomaly detection is widely applied due to its remarkable effectiveness and efficiency in meeting the needs of real-world industrial manufacturing. We introduce a new pipeline, DiffusionAD, to anomaly detection. We frame anomaly detection as a ``noise-to-norm'' paradigm, in which anomalies are identified as inconsistencies between a query image and its flawless approximation. Our pipeline achieves this by restoring the anomalous regions from the noisy corrupted query image while keeping the normal regions unchanged. DiffusionAD includes a denoising sub-network and a segmentation sub-network, which work together to provide intuitive anomaly detection and localization in an end-to-end manner, without the need for complicated post-processing steps. Remarkably, during inference, this framework delivers satisfactory performance with just one diffusion reverse process step, which is tens to hundreds of times faster than general diffusion methods. Extensive evaluations on standard and challenging benchmarks including VisA and DAGM show that DiffusionAD outperforms current state-of-the-art paradigms, demonstrating the effectiveness and generalizability of the proposed pipeline. ",
    "url": "https://arxiv.org/abs/2303.08730",
    "authors": [
      "Hui Zhang",
      "Zheng Wang",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08731",
    "title": "Bridging adaptive management and reinforcement learning for more robust  decisions",
    "abstract": "From out-competing grandmasters in chess to informing high-stakes healthcare decisions, emerging methods from artificial intelligence are increasingly capable of making complex and strategic decisions in diverse, high-dimensional, and uncertain situations. But can these methods help us devise robust strategies for managing environmental systems under great uncertainty? Here we explore how reinforcement learning, a subfield of artificial intelligence, approaches decision problems through a lens similar to adaptive environmental management: learning through experience to gradually improve decisions with updated knowledge. We review where reinforcement learning (RL) holds promise for improving evidence-informed adaptive management decisions even when classical optimization methods are intractable. For example, model-free deep RL might help identify quantitative decision strategies even when models are nonidentifiable. Finally, we discuss technical and social issues that arise when applying reinforcement learning to adaptive management problems in the environmental domain. Our synthesis suggests that environmental management and computer science can learn from one another about the practices, promises, and perils of experience-based decision-making. ",
    "url": "https://arxiv.org/abs/2303.08731",
    "authors": [
      "Melissa Chapman",
      "Lily Xu",
      "Marcus Lapeyrolerie",
      "Carl Boettiger"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.08744",
    "title": "Towards Phytoplankton Parasite Detection Using Autoencoders",
    "abstract": "Phytoplankton parasites are largely understudied microbial components with a potentially significant ecological impact on phytoplankton bloom dynamics. To better understand their impact, we need improved detection methods to integrate phytoplankton parasite interactions in monitoring aquatic ecosystems. Automated imaging devices usually produce high amount of phytoplankton image data, while the occurrence of anomalous phytoplankton data is rare. Thus, we propose an unsupervised anomaly detection system based on the similarity of the original and autoencoder-reconstructed samples. With this approach, we were able to reach an overall F1 score of 0.75 in nine phytoplankton species, which could be further improved by species-specific fine-tuning. The proposed unsupervised approach was further compared with the supervised Faster R-CNN based object detector. With this supervised approach and the model trained on plankton species and anomalies, we were able to reach the highest F1 score of 0.86. However, the unsupervised approach is expected to be more universal as it can detect also unknown anomalies and it does not require any annotated anomalous data that may not be always available in sufficient quantities. Although other studies have dealt with plankton anomaly detection in terms of non-plankton particles, or air bubble detection, our paper is according to our best knowledge the first one which focuses on automated anomaly detection considering putative phytoplankton parasites or infections. ",
    "url": "https://arxiv.org/abs/2303.08744",
    "authors": [
      "Simon Bilik",
      "Daniel Baktrakhanov",
      "Tuomas Eerola",
      "Lumi Haraguchi",
      "Kaisa Kraft",
      "Silke Van den Wyngaert",
      "Jonna Kangas",
      "Conny Sj\u00f6qvist",
      "Karin Madsen",
      "Lasse Lensu",
      "Heikki K\u00e4lvi\u00e4inen",
      "Karel Horak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08746",
    "title": "J-Parallelio -- automatic parallelization framework for Java virtual  machine code",
    "abstract": "Manual translation of the algorithms from sequential version to its parallel counterpart is time consuming and can be done only with the specific knowledge of hardware accelerator architecture, parallel programming or programming environment. The automation of this process makes porting the code much easier and faster. The key aspect in this case is how efficient the generated parallel code will be. The paper describes J-Parallelio, the framework for automatic analysis of the bytecode source codes and its parallelisation on multicore processors. The process consists of a few steps. First step is a process of decompilation of JVM and its translation to internal abstract syntax tree, the dependency extraction and memory analysis is performed. Finally, the mapping process is performed which consists of a set of rules responsible for translating the input virtual machine source code to its parallel version. The main novelty is that it can deal with pure Java virtual machine and can generate parallel code for multicore processors. This makes the system portable and it can work with different languages based on JVM after some small modifications. The efficiency of automatically translated source codes were compared with their manually written counterparts on chosen benchmarks. ",
    "url": "https://arxiv.org/abs/2303.08746",
    "authors": [
      "Krzysztof Stuglik",
      "Piotr Listkiewicz",
      "Mateusz Kulczyk",
      "Marcin Pietron"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.08767",
    "title": "Highly Personalized Text Embedding for Image Manipulation by Stable  Diffusion",
    "abstract": "Diffusion models have shown superior performance in image generation and manipulation, but the inherent stochasticity presents challenges in preserving and manipulating image content and identity. While previous approaches like DreamBooth and Textual Inversion have proposed model or latent representation personalization to maintain the content, their reliance on multiple reference images and complex training limits their practicality. In this paper, we present a simple yet highly effective approach to personalization using highly personalized (HiPer) text embedding by decomposing the CLIP embedding space for personalization and content manipulation. Our method does not require model fine-tuning or identifiers, yet still enables manipulation of background, texture, and motion with just a single image and target text. Through experiments on diverse target texts, we demonstrate that our approach produces highly personalized and complex semantic image edits across a wide range of tasks. We believe that the novel understanding of the text embedding space presented in this work has the potential to inspire further research across various tasks. ",
    "url": "https://arxiv.org/abs/2303.08767",
    "authors": [
      "Inhwa Han",
      "Serin Yang",
      "Taesung Kwon",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08803",
    "title": "Cloud Services Enable Efficient AI-Guided Simulation Workflows across  Heterogeneous Resources",
    "abstract": "Applications that fuse machine learning and simulation can benefit from the use of multiple computing resources, with, for example, simulation codes running on highly parallel supercomputers and AI training and inference tasks on specialized accelerators. Here, we present our experiences deploying two AI-guided simulation workflows across such heterogeneous systems. A unique aspect of our approach is our use of cloud-hosted management services to manage challenging aspects of cross-resource authentication and authorization, function-as-a-service (FaaS) function invocation, and data transfer. We show that these methods can achieve performance parity with systems that rely on direct connection between resources. We achieve parity by integrating the FaaS system and data transfer capabilities with a system that passes data by reference among managers and workers, and a user-configurable steering algorithm to hide data transfer latencies. We anticipate that this ease of use can enable routine use of heterogeneous resources in computational science. ",
    "url": "https://arxiv.org/abs/2303.08803",
    "authors": [
      "Logan Ward",
      "J. Gregory Pauloski",
      "Valerie Hayot-Sasson",
      "Ryan Chard",
      "Yadu Babuji",
      "Ganesh Sivaraman",
      "Sutanay Choudhury",
      "Kyle Chard",
      "Rajeev Thakur",
      "Ian Foster"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08811",
    "title": "Relax, it doesn't matter how you get there: A new self-supervised  approach for multi-timescale behavior analysis",
    "abstract": "Natural behavior consists of dynamics that are complex and unpredictable, especially when trying to predict many steps into the future. While some success has been found in building representations of behavior under constrained or simplified task-based conditions, many of these models cannot be applied to free and naturalistic settings where behavior becomes increasingly hard to model. In this work, we develop a multi-task representation learning model for behavior that combines two novel components: (i) An action prediction objective that aims to predict the distribution of actions over future timesteps, and (ii) A multi-scale architecture that builds separate latent spaces to accommodate short- and long-term dynamics. After demonstrating the ability of the method to build representations of both local and global dynamics in realistic robots in varying environments and terrains, we apply our method to the MABe 2022 Multi-agent behavior challenge, where our model ranks 1st overall and on all global tasks, and 1st or 2nd on 7 out of 9 frame-level tasks. In all of these cases, we show that our model can build representations that capture the many different factors that drive behavior and solve a wide range of downstream tasks. ",
    "url": "https://arxiv.org/abs/2303.08811",
    "authors": [
      "Mehdi Azabou",
      "Michael Mendelson",
      "Nauman Ahad",
      "Maks Sorokin",
      "Shantanu Thakoor",
      "Carolina Urzay",
      "Eva L. Dyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.08815",
    "title": "Lane Graph as Path: Continuity-preserving Path-wise Modeling for Online  Lane Graph Construction",
    "abstract": "Online lane graph construction is a promising but challenging task in autonomous driving. Previous methods usually model the lane graph at the pixel or piece level, and recover the lane graph by pixel-wise or piece-wise connection, which breaks down the continuity of the lane. Human drivers focus on and drive along the continuous and complete paths instead of considering lane pieces. Autonomous vehicles also require path-specific guidance from lane graph for trajectory planning. We argue that the path, which indicates the traffic flow, is the primitive of the lane graph. Motivated by this, we propose to model the lane graph in a novel path-wise manner, which well preserves the continuity of the lane and encodes traffic information for planning. We present a path-based online lane graph construction method, termed LaneGAP, which end-to-end learns the path and recovers the lane graph via a Path2Graph algorithm. We qualitatively and quantitatively demonstrate the superiority of LaneGAP over conventional pixel-based and piece-based methods. Abundant visualizations show LaneGAP can cope with diverse traffic conditions. Code and models will be released at \\url{https://github.com/hustvl/LaneGAP} for facilitating future research. ",
    "url": "https://arxiv.org/abs/2303.08815",
    "authors": [
      "Bencheng Liao",
      "Shaoyu Chen",
      "Bo Jiang",
      "Tianheng Cheng",
      "Qian Zhang",
      "Wenyu Liu",
      "Chang Huang",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.08216",
    "title": "Efficiently Training Vision Transformers on Structural MRI Scans for  Alzheimer's Disease Detection",
    "abstract": "Neuroimaging of large populations is valuable to identify factors that promote or resist brain disease, and to assist diagnosis, subtyping, and prognosis. Data-driven models such as convolutional neural networks (CNNs) have increasingly been applied to brain images to perform diagnostic and prognostic tasks by learning robust features. Vision transformers (ViT) - a new class of deep learning architectures - have emerged in recent years as an alternative to CNNs for several computer vision applications. Here we tested variants of the ViT architecture for a range of desired neuroimaging downstream tasks based on difficulty, in this case for sex and Alzheimer's disease (AD) classification based on 3D brain MRI. In our experiments, two vision transformer architecture variants achieved an AUC of 0.987 for sex and 0.892 for AD classification, respectively. We independently evaluated our models on data from two benchmark AD datasets. We achieved a performance boost of 5% and 9-10% upon fine-tuning vision transformer models pre-trained on synthetic (generated by a latent diffusion model) and real MRI scans, respectively. Our main contributions include testing the effects of different ViT training strategies including pre-training, data augmentation and learning rate warm-ups followed by annealing, as pertaining to the neuroimaging domain. These techniques are essential for training ViT-like models for neuroimaging applications where training data is usually limited. We also analyzed the effect of the amount of training data utilized on the test-time performance of the ViT via data-model scaling curves. ",
    "url": "https://arxiv.org/abs/2303.08216",
    "authors": [
      "Nikhil J. Dhinagar",
      "Sophia I. Thomopoulos",
      "Emily Laltoo",
      "Paul M. Thompson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.08366",
    "title": "VENUS: A Geometrical Representation for Quantum State Visualization",
    "abstract": "Visualizations have played a crucial role in helping quantum computing users explore quantum states in various quantum computing applications. Among them, Bloch Sphere is the widely-used visualization for showing quantum states, which leverages angles to represent quantum amplitudes. However, it cannot support the visualization of quantum entanglement and superposition, the two essential properties of quantum computing. To address this issue, we propose VENUS, a novel visualization for quantum state representation. By explicitly correlating 2D geometric shapes based on the math foundation of quantum computing characteristics, VENUS effectively represents quantum amplitudes of both the single qubit and two qubits for quantum entanglement. Also, we use multiple coordinated semicircles to naturally encode probability distribution, making the quantum superposition intuitive to analyze. We conducted two well-designed case studies and an in-depth expert interview to evaluate the usefulness and effectiveness of VENUS. The result shows that VENUS can effectively facilitate the exploration of quantum states for the single qubit and two qubits. ",
    "url": "https://arxiv.org/abs/2303.08366",
    "authors": [
      "Shaolun Ruan",
      "Ribo Yuan",
      "Yong Wang",
      "Yanna Lin",
      "Ying Mao",
      "Weiwen Jiang",
      "Zhepeng Wang",
      "Wei Xu",
      "Qiang Guan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.08416",
    "title": "Lung Nodule Segmentation and Low-Confidence Region Prediction with  Uncertainty-Aware Attention Mechanism",
    "abstract": "Radiologists have different training and clinical experiences, so they may provide various segmentation annotations for a lung nodule, which causes segmentation uncertainty among multiple annotations. Conventional methods usually chose a single annotation as the learning target or tried to learn a latent space of various annotations. Still, they wasted the valuable information of consensus or disagreements ingrained in the multiple annotations. This paper proposes an Uncertainty-Aware Attention Mechanism (UAAM), which utilizes consensus or disagreements among annotations to produce a better segmentation. In UAAM, we propose a Multi-Confidence Mask (MCM), which is a combination of a Low-Confidence (LC) Mask and a High-Confidence (HC) Mask. LC mask indicates regions with low segmentation confidence, which may cause different segmentation options among radiologists. Following UAAM, we further design an Uncertainty-Guide Segmentation Network (UGS-Net), which contains three modules:Feature Extracting Module captures a general feature of a lung nodule. Uncertainty-Aware Module produce three features for the annotations' union, intersection, and annotation set. Finally, Intersection-Union Constraining Module use distances between three features to balance the predictions of final segmentation, LC mask, and HC mask. To fully demonstrate the performance of our method, we propose a Complex Nodule Challenge on LIDC-IDRI, which tests UGS-Net's segmentation performance on the lung nodules that are difficult to segment by U-Net. Experimental results demonstrate that our method can significantly improve the segmentation performance on nodules with poor segmentation by U-Net. ",
    "url": "https://arxiv.org/abs/2303.08416",
    "authors": [
      "Han Yang",
      "Qiuli Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08441",
    "title": "Mumford representation and Riemann Roch space of a divisor on a  hyperelliptic curve",
    "abstract": "For an (imaginary) hyperelliptic curve $ \\mathcal{H} $ of genus $g$, with a Weierstrass point $\\Omega$, taken as the point at infinity, we determine a basis of the Riemann-Roch space $\\mathcal{L}(\\Delta + m \\Omega)$, where $\\Delta$ is of degree zero, directly from the Mumford representation of $\\Delta$. This provides in turn a generating matrix of a Goppa code. ",
    "url": "https://arxiv.org/abs/2303.08441",
    "authors": [
      "Giovanni Falcone",
      "Giuseppe Filippone"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.08452",
    "title": "Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly  Detection",
    "abstract": "Early and accurate disease detection is crucial for patient management and successful treatment outcomes. However, the automatic identification of anomalies in medical images can be challenging. Conventional methods rely on large labeled datasets which are difficult to obtain. To overcome these limitations, we introduce a novel unsupervised approach, called PHANES (Pseudo Healthy generative networks for ANomaly Segmentation). Our method has the capability of reversing anomalies, i.e., preserving healthy tissue and replacing anomalous regions with pseudo-healthy (PH) reconstructions. Unlike recent diffusion models, our method does not rely on a learned noise distribution nor does it introduce random alterations to the entire image. Instead, we use latent generative networks to create masks around possible anomalies, which are refined using inpainting generative networks. We demonstrate the effectiveness of PHANES in detecting stroke lesions in T1w brain MRI datasets and show significant improvements over state-of-the-art (SOTA) methods. We believe that our proposed framework will open new avenues for interpretable, fast, and accurate anomaly segmentation with the potential to support various clinical-oriented downstream tasks. ",
    "url": "https://arxiv.org/abs/2303.08452",
    "authors": [
      "Cosmin I Bercea",
      "Benedikt Wiestler",
      "Daniel Rueckert",
      "Julia A Schnabel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08490",
    "title": "Strong Baseline and Bag of Tricks for COVID-19 Detection of CT Scans",
    "abstract": "This paper investigates the application of deep learning models for lung Computed Tomography (CT) image analysis. Traditional deep learning frameworks encounter compatibility issues due to variations in slice numbers and resolutions in CT images, which stem from the use of different machines. Commonly, individual slices are predicted and subsequently merged to obtain the final result; however, this approach lacks slice-wise feature learning and consequently results in decreased performance. We propose a novel slice selection method for each CT dataset to address this limitation, effectively filtering out uncertain slices and enhancing the model's performance. Furthermore, we introduce a spatial-slice feature learning (SSFL) technique\\cite{hsu2022} that employs a conventional and efficient backbone model for slice feature training, followed by extracting one-dimensional data from the trained model for COVID and non-COVID classification using a dedicated classification model. Leveraging these experimental steps, we integrate one-dimensional features with multiple slices for channel merging and employ a 2D convolutional neural network (CNN) model for classification. In addition to the aforementioned methods, we explore various high-performance classification models, ultimately achieving promising results. ",
    "url": "https://arxiv.org/abs/2303.08490",
    "authors": [
      "Chih-Chung Hsu",
      "Chih-Yu Jian",
      "Chia-Ming Lee",
      "Chi-Han Tsai",
      "Sheng-Chieh Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08540",
    "title": "Automatic scenario generation for efficient solution of robust optimal  control problems",
    "abstract": "Existing methods for nonlinear robust control often use scenario-based approaches to formulate the control problem as large nonlinear optimization problems. The optimization problems are challenging to solve due to their size, especially if the control problems include time-varying uncertainty. This paper draws from local reduction methods used in semi-infinite optimization to solve robust optimal control problems with parametric and time-varying uncertainty. By iteratively adding interim worst-case scenarios to the problem, methods based on local reduction provide a way to manage the total number of scenarios. We show that the local reduction method for optimal control problems consists of solving a series of simplified optimal control problems to find worst-case constraint violations. In particular, we present examples where local reduction methods find worst-case scenarios that are not on the boundary of the uncertainty set. We also provide bounds on the error if local solvers are used. The proposed approach is illustrated with two case studies with parametric and additive time-varying uncertainty. In the first case study, the number of scenarios obtained from local reduction is 101, smaller than in the case when all $2^{14+3\\times192}$ extreme scenarios are considered. In the second case study, the number of scenarios obtained from the local reduction is two compared to 512 extreme scenarios. Our approach was able to satisfy the constraints both for parametric uncertainty and time-varying disturbances, whereas approaches from literature either violated the constraints or became computationally expensive. ",
    "url": "https://arxiv.org/abs/2303.08540",
    "authors": [
      "Marta Zagorowska",
      "Paola Falugi",
      "Edward O'Dwyer",
      "Eric C. Kerrigan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.08552",
    "title": "Joint Graph and Vertex Importance Learning",
    "abstract": "In this paper, we explore the topic of graph learning from the perspective of the Irregularity-Aware Graph Fourier Transform, with the goal of learning the graph signal space inner product to better model data. We propose a novel method to learn a graph with smaller edge weight upper bounds compared to combinatorial Laplacian approaches. Experimentally, our approach yields much sparser graphs compared to a combinatorial Laplacian approach, with a more interpretable model. ",
    "url": "https://arxiv.org/abs/2303.08552",
    "authors": [
      "Benjamin Girault",
      "Eduardo Pavez",
      "Antonio Ortega"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08569",
    "title": "EGFR mutation prediction using F18-FDG PET-CT based radiomics features  in non-small cell lung cancer",
    "abstract": "Lung cancer is the leading cause of cancer death in the world. Accurate determination of the EGFR (epidermal growth factor receptor) mutation status is highly relevant for the proper treatment of this patients. Purpose: The aim of this study was to predict the mutational status of the EGFR in non-small cell lung cancer patients using radiomics features extracted from PET-CT images. Methods: Retrospective study that involve 34 patients with lung cancer confirmed by histology and EGFR status mutation assessment. A total of 2.205 radiomics features were extracted from manual segmentation of the PET-CT images using pyradiomics library. Both computed tomography and positron emission tomography images were used. All images were acquired with intravenous iodinated contrast and F18-FDG. Preprocessing includes resampling, normalization, and discretization of the pixel intensity. Three methods were used for the feature selection process: backward selection (set 1), forward selection (set 2), and feature importance analysis of random forest model (set 3). Nine machine learning methods were used for radiomics model building. Results: 35.2% of patients had EGFR mutation, without significant differences in age, gender, tumor size and SUVmax. After the feature selection process 6, 7 and 17 radiomics features were selected, respectively in each group. The best performances were obtained by Ridge Regression in set 1: AUC of 0.826 (95% CI, 0.811 - 0.839), Random Forest in set 2: AUC of 0.823 (95% CI, 0.808 - 0.838) and Neural Network in set 3: AUC of 0.821 (95% CI, 0.808 - 0.835). Conclusion: The radiomics features analysis has the potential of predicting clinically relevant mutations in lung cancer patients through a non-invasive methodology. ",
    "url": "https://arxiv.org/abs/2303.08569",
    "authors": [
      "Hector Henriquez",
      "Diana Fuentes",
      "Francisco Suarez",
      "Patricio Gonzalez"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08674",
    "title": "Speech Signal Improvement Using Causal Generative Diffusion Models",
    "abstract": "In this paper, we present a causal speech signal improvement system that is designed to handle different types of distortions. The method is based on a generative diffusion model which has been shown to work well in scenarios with missing data and non-linear corruptions. To guarantee causal processing, we modify the network architecture of our previous work and replace global normalization with causal adaptive gain control. We generate diverse training data containing a broad range of distortions. This work was performed in the context of an \"ICASSP Signal Processing Grand Challenge\" and submitted to the non-real-time track of the \"Speech Signal Improvement Challenge 2023\", where it was ranked fifth. ",
    "url": "https://arxiv.org/abs/2303.08674",
    "authors": [
      "Julius Richter",
      "Simon Welker",
      "Jean-Marie Lemercier",
      "Bunlong Lay",
      "Tal Peer",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.08680",
    "title": "Muti-Agent Proximal Policy Optimization For Data Freshness in  UAV-assisted Networks",
    "abstract": "Unmanned aerial vehicles (UAVs) are seen as a promising technology to perform a wide range of tasks in wireless communication networks. In this work, we consider the deployment of a group of UAVs to collect the data generated by IoT devices. Specifically, we focus on the case where the collected data is time-sensitive, and it is critical to maintain its timeliness. Our objective is to optimally design the UAVs' trajectories and the subsets of visited IoT devices such as the global Age-of-Updates (AoU) is minimized. To this end, we formulate the studied problem as a mixed-integer nonlinear programming (MINLP) under time and quality of service constraints. To efficiently solve the resulting optimization problem, we investigate the cooperative Multi-Agent Reinforcement Learning (MARL) framework and propose an RL approach based on the popular on-policy Reinforcement Learning (RL) algorithm: Policy Proximal Optimization (PPO). Our approach leverages the centralized training decentralized execution (CTDE) framework where the UAVs learn their optimal policies while training a centralized value function. Our simulation results show that the proposed MAPPO approach reduces the global AoU by at least a factor of 1/2 compared to conventional off-policy reinforcement learning approaches. ",
    "url": "https://arxiv.org/abs/2303.08680",
    "authors": [
      "Mouhamed Naby Ndiaye",
      "El Houcine Bergou",
      "Hajar El Hammouti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08726",
    "title": "The Number of Edges in Maximal 2-planar Graphs",
    "abstract": "A graph is $2$-planar if it has local crossing number two, that is, it can be drawn in the plane such that every edge has at most two crossings. A graph is maximal $2$-planar if no edge can be added such that the resulting graph remains $2$-planar. A $2$-planar graph on $n$ vertices has at most $5n-10$ edges, and some (maximal) $2$-planar graphs -- referred to as optimal $2$-planar -- achieve this bound. However, in strong contrast to maximal planar graphs, a maximal $2$-planar graph may have fewer than the maximum possible number of edges. In this paper, we determine the minimum edge density of maximal $2$-planar graphs by proving that every maximal $2$-planar graph on $n\\ge 5$ vertices has at least $2n$ edges. We also show that this bound is tight, up to an additive constant. The lower bound is based on an analysis of the degree distribution in specific classes of drawings of the graph. The upper bound construction is verified by carefully exploring the space of admissible drawings using computer support. ",
    "url": "https://arxiv.org/abs/2303.08726",
    "authors": [
      "Michael Hoffmann",
      "Meghana M. Reddy"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.08740",
    "title": "2D and 3D CNN-Based Fusion Approach for COVID-19 Severity Prediction  from 3D CT-Scans",
    "abstract": "Since the appearance of Covid-19 in late 2019, Covid-19 has become an active research topic for the artificial intelligence (AI) community. One of the most interesting AI topics is Covid-19 analysis of medical imaging. CT-scan imaging is the most informative tool about this disease. This work is part of the 3nd COV19D competition for Covid-19 Severity Prediction. In order to deal with the big gap between the validation and test results that were shown in the previous version of this competition, we proposed to combine the prediction of 2D and 3D CNN predictions. For the 2D CNN approach, we propose 2B-InceptResnet architecture which consists of two paths for segmented lungs and infection of all slices of the input CT-scan, respectively. Each path consists of ConvLayer and Inception-ResNet pretrained model on ImageNet. For the 3D CNN approach, we propose hybrid-DeCoVNet architecture which consists of four blocks: Stem, four 3D-ResNet layers, Classification Head and Decision layer. Our proposed approaches outperformed the baseline approach in the validation data of the 3nd COV19D competition for Covid-19 Severity Prediction by 36%. ",
    "url": "https://arxiv.org/abs/2303.08740",
    "authors": [
      "Fares Bougourzi",
      "Fadi Dornaika",
      "Amir Nakib",
      "Cosimo Distante",
      "Abdelmalik Taleb-Ahmed"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08760",
    "title": "Deep Calibration With Artificial Neural Network: A Performance  Comparison on Option Pricing Models",
    "abstract": "This paper explores Artificial Neural Network (ANN) as a model-free solution for a calibration algorithm of option pricing models. We construct ANNs to calibrate parameters for two well-known GARCH-type option pricing models: Duan's GARCH and the classical tempered stable GARCH that significantly improve upon the limitation of the Black-Scholes model but have suffered from computation complexity. To mitigate this technical difficulty, we train ANNs with a dataset generated by Monte Carlo Simulation (MCS) method and apply them to calibrate optimal parameters. The performance results indicate that the ANN approach consistently outperforms MCS and takes advantage of faster computation times once trained. The Greeks of options are also discussed. ",
    "url": "https://arxiv.org/abs/2303.08760",
    "authors": [
      "Young Shin Kim",
      "Hyangju Kim",
      "Jaehyung Choi"
    ],
    "subjectives": [
      "Mathematical Finance (q-fin.MF)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08812",
    "title": "Trigger-Level Event Reconstruction for Neutrino Telescopes Using Sparse  Submanifold Convolutional Neural Networks",
    "abstract": "Convolutional neural networks (CNNs) have seen extensive applications in scientific data analysis, including in neutrino telescopes. However, the data from these experiments present numerous challenges to CNNs, such as non-regular geometry, sparsity, and high dimensionality. Consequently, CNNs are highly inefficient on neutrino telescope data, and require significant pre-processing that results in information loss. We propose sparse submanifold convolutions (SSCNNs) as a solution to these issues and show that the SSCNN event reconstruction performance is comparable to or better than traditional and machine learning algorithms. Additionally, our SSCNN runs approximately 16 times faster than a traditional CNN on a GPU. As a result of this speedup, it is expected to be capable of handling the trigger-level event rate of IceCube-scale neutrino telescopes. These networks could be used to improve the first estimation of the neutrino energy and direction to seed more advanced reconstructions, or to provide this information to an alert-sending system to quickly follow-up interesting events. ",
    "url": "https://arxiv.org/abs/2303.08812",
    "authors": [
      "Felix J. Yu",
      "Jeffrey Lazar",
      "Carlos A. Arg\u00fcelles"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2008.06302",
    "title": "Computation Offloading in Heterogeneous Vehicular Edge Networks: On-line  and Off-policy Bandit Solutions",
    "abstract": " Comments: Published in IEEE Transactions on Mobile Computing, Vol 21, Issue 12, Dec 2022 ",
    "url": "https://arxiv.org/abs/2008.06302",
    "authors": [
      "Arash Bozorgchenani",
      "Setareh Maghsudi",
      "Daniele Tarchi",
      "Ekram Hossain"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2009.09213",
    "title": "Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2009.09213",
    "authors": [
      "Yihao Huang",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Yang Liu",
      "Geguang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.06484",
    "title": "Robust High-speed Running for Quadruped Robots via Deep Reinforcement  Learning",
    "abstract": " Title: Robust High-speed Running for Quadruped Robots via Deep Reinforcement  Learning ",
    "url": "https://arxiv.org/abs/2103.06484",
    "authors": [
      "Guillaume Bellegarda",
      "Yiyu Chen",
      "Zhuochen Liu",
      "Quan Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.03135",
    "title": "Label Noise in Adversarial Training: A Novel Perspective to Study Robust  Overfitting",
    "abstract": " Comments: Neurips 2022 (Oral presentation) ",
    "url": "https://arxiv.org/abs/2110.03135",
    "authors": [
      "Chengyu Dong",
      "Liyuan Liu",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.00038",
    "title": "Robust and Provably Monotonic Networks",
    "abstract": " Comments: 15 pages, 7 figures, v2 extended journal version, v1 presented at the Machine Learning and the Physical Sciences Workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS) December 13, 2021 ",
    "url": "https://arxiv.org/abs/2112.00038",
    "authors": [
      "Ouail Kitouni",
      "Niklas Nolte",
      "Mike Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2112.13309",
    "title": "Learning Cross-Scale Weighted Prediction for Efficient Neural Video  Compression",
    "abstract": " Comments: Preprint. Revised after peer-reviewimg ",
    "url": "https://arxiv.org/abs/2112.13309",
    "authors": [
      "Zongyu Guo",
      "Runsen Feng",
      "Zhizheng Zhang",
      "Xin Jin",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11012",
    "title": "Learning Resilient Radio Resource Management Policies with Graph Neural  Networks",
    "abstract": " Comments: Accepted by IEEE Transactions on Signal Processing. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2203.11012",
    "authors": [
      "Navid NaderiAlizadeh",
      "Mark Eisen",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.15901",
    "title": "Connections between Deep Equilibrium and Sparse Representation Models  with Application to Hyperspectral Image Denoising",
    "abstract": " Title: Connections between Deep Equilibrium and Sparse Representation Models  with Application to Hyperspectral Image Denoising ",
    "url": "https://arxiv.org/abs/2203.15901",
    "authors": [
      "Alexandros Gkillas",
      "Dimitris Ampeliotis",
      "Kostas Berberidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.02405",
    "title": "Image Protection for Robust Cropping Localization and Recovery",
    "abstract": " Comments: Accepted by IEEE ICME 2023 ",
    "url": "https://arxiv.org/abs/2206.02405",
    "authors": [
      "Qichao Ying",
      "Hang Zhou",
      "Xiaoxiao Hu",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.11736",
    "title": "NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds",
    "abstract": " Title: NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds ",
    "url": "https://arxiv.org/abs/2206.11736",
    "authors": [
      "Patrick Feeney",
      "Sarah Schneider",
      "Panagiotis Lymperopoulos",
      "Liping Liu",
      "Matthias Scheutz",
      "Michael C. Hughes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14767",
    "title": "Verified Causal Broadcast with Liquid Haskell",
    "abstract": " Comments: Appeared at IFL 2022 ",
    "url": "https://arxiv.org/abs/2206.14767",
    "authors": [
      "Patrick Redmond",
      "Gan Shen",
      "Niki Vazou",
      "Lindsey Kuper"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2207.07333",
    "title": "Rainfall Estimation with SAR using NEXRAD collocations with  Convolutional Neural Networks",
    "abstract": " Comments: 9 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2207.07333",
    "authors": [
      "Aur\u00e9lien Colin",
      "Pierre Tandeo",
      "Charles Peureux",
      "Romain Husson",
      "Nicolas Long\u00e9p\u00e9",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.02131",
    "title": "Masked Vision and Language Modeling for Multi-modal Representation  Learning",
    "abstract": " Comments: International Conference on Learning Representations (ICLR) 2023 ",
    "url": "https://arxiv.org/abs/2208.02131",
    "authors": [
      "Gukyeong Kwon",
      "Zhaowei Cai",
      "Avinash Ravichandran",
      "Erhan Bas",
      "Rahul Bhotika",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06081",
    "title": "Slicing4Meta: An Intelligent Integration Framework with  Multi-dimensional Network Resources for Metaverse-as-a-Service in Web 3.0",
    "abstract": " Title: Slicing4Meta: An Intelligent Integration Framework with  Multi-dimensional Network Resources for Metaverse-as-a-Service in Web 3.0 ",
    "url": "https://arxiv.org/abs/2208.06081",
    "authors": [
      "Yi-Jing Liu",
      "Hongyang Du",
      "Dusit Niyato",
      "Gang Feng",
      "Jiawen Kang",
      "Zehui Xiong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.01610",
    "title": "Generalization in Neural Networks: A Broad Survey",
    "abstract": " Title: Generalization in Neural Networks: A Broad Survey ",
    "url": "https://arxiv.org/abs/2209.01610",
    "authors": [
      "Chris Rohlfs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.10150",
    "title": "RNGDet++: Road Network Graph Detection by Transformer with Instance  Segmentation and Multi-scale Features Enhancement",
    "abstract": " Comments: Accepted by IEEE Robotics and Automation Letters (RA-L) ",
    "url": "https://arxiv.org/abs/2209.10150",
    "authors": [
      "Zhenhua Xu",
      "Yuxuan Liu",
      "Yuxiang Sun",
      "Ming Liu",
      "Lujia Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.00513",
    "title": "Gradient Gating for Deep Multi-Rate Learning on Graphs",
    "abstract": " Title: Gradient Gating for Deep Multi-Rate Learning on Graphs ",
    "url": "https://arxiv.org/abs/2210.00513",
    "authors": [
      "T. Konstantin Rusch",
      "Benjamin P. Chamberlain",
      "Michael W. Mahoney",
      "Michael M. Bronstein",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.02226",
    "title": "Null Hypothesis Test for Anomaly Detection",
    "abstract": " Comments: 10 pages, 3 figures, 1 Table. Matches published version at Physics Letters B. All code is available at this https URL Comments welcome! ",
    "url": "https://arxiv.org/abs/2210.02226",
    "authors": [
      "Jernej F. Kamenik",
      "Manuel Szewc"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2210.05669",
    "title": "A generic diffusion-based approach for 3D human pose prediction in the  wild",
    "abstract": " Comments: Accepted to ICRA 2023 ",
    "url": "https://arxiv.org/abs/2210.05669",
    "authors": [
      "Saeed Saadatnejad",
      "Ali Rasekh",
      "Mohammadreza Mofayezi",
      "Yasamin Medghalchi",
      "Sara Rajabzadeh",
      "Taylor Mordan",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.06575",
    "title": "GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and  Specular Objects Using Generalizable NeRF",
    "abstract": " Comments: IEEE International Conference on Robotics and Automation (ICRA), 2023 ",
    "url": "https://arxiv.org/abs/2210.06575",
    "authors": [
      "Qiyu Dai",
      "Yan Zhu",
      "Yiran Geng",
      "Ciyu Ruan",
      "Jiazhao Zhang",
      "He Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07241",
    "title": "Visual Reinforcement Learning with Self-Supervised 3D Representations",
    "abstract": " Comments: Accepted in RA-L 2023 and IROS 2023. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2210.07241",
    "authors": [
      "Yanjie Ze",
      "Nicklas Hansen",
      "Yinbo Chen",
      "Mohit Jain",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.11407",
    "title": "Similarity of Neural Architectures Based on Input Gradient  Transferability",
    "abstract": " Comments: 21pages, 10 figures, 1.5MB ",
    "url": "https://arxiv.org/abs/2210.11407",
    "authors": [
      "Jaehui Hwang",
      "Dongyoon Han",
      "Byeongho Heo",
      "Song Park",
      "Sanghyuk Chun",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14688",
    "title": "Scaling Law Analysis for Covariance Based Activity Detection in  Cooperative Multi-Cell Massive MIMO",
    "abstract": " Comments: 5 pages, 2 figures, accepted for publication in IEEE ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.14688",
    "authors": [
      "Ziyue Wang",
      "Ya-Feng Liu",
      "Zhaorui Wang",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.16043",
    "title": "Analyzing Acoustic Word Embeddings from Pre-trained Self-supervised  Speech Models",
    "abstract": " Comments: Accepted to IEEE ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.16043",
    "authors": [
      "Ramon Sanabria",
      "Hao Tang",
      "Sharon Goldwater"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.16751",
    "title": "Formalizing Statistical Causality via Modal Logic",
    "abstract": " Title: Formalizing Statistical Causality via Modal Logic ",
    "url": "https://arxiv.org/abs/2210.16751",
    "authors": [
      "Yusuke Kawamoto",
      "Tetsuya Sato",
      "Kohei Suenaga"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.17312",
    "title": "Training Neural Networks for Sequential Change-point Detection",
    "abstract": " Title: Training Neural Networks for Sequential Change-point Detection ",
    "url": "https://arxiv.org/abs/2210.17312",
    "authors": [
      "Junghwan Lee",
      "Yao Xie",
      "Xiuyuan Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.00335",
    "title": "Recurrent Neural Networks and Universal Approximation of Bayesian  Filters",
    "abstract": " Title: Recurrent Neural Networks and Universal Approximation of Bayesian  Filters ",
    "url": "https://arxiv.org/abs/2211.00335",
    "authors": [
      "Adrian N. Bishop",
      "Edwin V. Bonilla"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.02332",
    "title": "Once-for-All Sequence Compression for Self-Supervised Speech Models",
    "abstract": " Comments: Accepted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.02332",
    "authors": [
      "Hsuan-Jui Chen",
      "Yen Meng",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.06444",
    "title": "Probabilistic Debiasing of Scene Graphs",
    "abstract": " Comments: Accepted at CVPR 2023. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2211.06444",
    "authors": [
      "Bashirul Azam Biswas",
      "Qiang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08540",
    "title": "VGFlow: Visibility guided Flow Network for Human Reposing",
    "abstract": " Comments: Selected for publication in CVPR2023 ",
    "url": "https://arxiv.org/abs/2211.08540",
    "authors": [
      "Rishabh Jain",
      "Krishna Kumar Singh",
      "Mayur Hemani",
      "Jingwan Lu",
      "Mausooom Sarkar",
      "Duygu Ceylan",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.13202",
    "title": "Lite-Mono: A Lightweight CNN and Transformer Architecture for  Self-Supervised Monocular Depth Estimation",
    "abstract": " Comments: Accepted to CVPR2023 ",
    "url": "https://arxiv.org/abs/2211.13202",
    "authors": [
      "Ning Zhang",
      "Francesco Nex",
      "George Vosselman",
      "Norman Kerle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14265",
    "title": "Multiscale methods for solving wave equations on spatial networks",
    "abstract": " Title: Multiscale methods for solving wave equations on spatial networks ",
    "url": "https://arxiv.org/abs/2211.14265",
    "authors": [
      "Morgan G\u00f6rtz",
      "Per Ljung",
      "Axel M\u00e5lqvist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.15115",
    "title": "Generalized Category Discovery with Decoupled Prototypical Network",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.15115",
    "authors": [
      "Wenbin An",
      "Feng Tian",
      "Qinghua Zheng",
      "Wei Ding",
      "QianYing Wang",
      "Ping Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15158",
    "title": "Heterogeneous Graph Learning for Multi-modal Medical Data Analysis",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.15158",
    "authors": [
      "Sein Kim",
      "Namkyeong Lee",
      "Junseok Lee",
      "Dongmin Hyun",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04681",
    "title": "Dynamic Test-Time Augmentation via Differentiable Functions",
    "abstract": " Title: Dynamic Test-Time Augmentation via Differentiable Functions ",
    "url": "https://arxiv.org/abs/2212.04681",
    "authors": [
      "Shohei Enomoto",
      "Monikka Roslianna Busto",
      "Takeharu Eda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01006",
    "title": "Policy Pre-training for Autonomous Driving via Self-supervised Geometric  Modeling",
    "abstract": " Comments: ICLR2023 ",
    "url": "https://arxiv.org/abs/2301.01006",
    "authors": [
      "Penghao Wu",
      "Li Chen",
      "Hongyang Li",
      "Xiaosong Jia",
      "Junchi Yan",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01970",
    "title": "CAT: LoCalization and IdentificAtion Cascade Detection Transformer for  Open-World Object Detection",
    "abstract": " Title: CAT: LoCalization and IdentificAtion Cascade Detection Transformer for  Open-World Object Detection ",
    "url": "https://arxiv.org/abs/2301.01970",
    "authors": [
      "Shuailei Ma",
      "Yuefeng Wang",
      "Jiaqi Fan",
      "Ying Wei",
      "Thomas H. Li",
      "Hongli Liu",
      "Fanbing Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.03194",
    "title": "Few-shot Semantic Segmentation with Support-induced Graph Convolutional  Network",
    "abstract": " Comments: Accepted in BMVC2022 as oral presentation ",
    "url": "https://arxiv.org/abs/2301.03194",
    "authors": [
      "Jie Liu",
      "Yanqi Bao",
      "Wenzhe Yin",
      "Haochen Wang",
      "Yang Gao",
      "Jan-Jakob Sonke",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.08077",
    "title": "A Distributed Machine Learning-Based Approach for IRS-Enhanced Cell-Free  MIMO Networks",
    "abstract": " Comments: This paper has been submitted to IEEE Transactions for possible publications ",
    "url": "https://arxiv.org/abs/2301.08077",
    "authors": [
      "Chen Chen",
      "Sai Xu",
      "Jiliang Zhang",
      "Jie Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.08104",
    "title": "Author as Character and Narrator: Deconstructing Personal Narratives  from the r/AmITheAsshole Reddit Community",
    "abstract": " Comments: Accepted to the 17th International AAAI Conference on Web and Social Media (ICWSM), 2023 ",
    "url": "https://arxiv.org/abs/2301.08104",
    "authors": [
      "Salvatore Giorgi",
      "Ke Zhao",
      "Alexander H. Feng",
      "Lara J. Martin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11166",
    "title": "Flex-Net: A Graph Neural Network Approach to Resource Management in  Flexible Duplex Networks",
    "abstract": " Title: Flex-Net: A Graph Neural Network Approach to Resource Management in  Flexible Duplex Networks ",
    "url": "https://arxiv.org/abs/2301.11166",
    "authors": [
      "Tharaka Perera",
      "Saman Atapattu",
      "Yuting Fang",
      "Prathapasinghe Dharmawansa",
      "Jamie Evans"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.13428",
    "title": "Contrast and Clustering: Learning Neighborhood Pair Representation for  Source-free Domain Adaptation",
    "abstract": " Comments: Journal articles ",
    "url": "https://arxiv.org/abs/2301.13428",
    "authors": [
      "Yuqi Chen",
      "Xiangbin Zhu",
      "Yonggang Li",
      "Yingjian Li",
      "Yuanwang Wei",
      "Haojie Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00422",
    "title": "Robust online active learning",
    "abstract": " Title: Robust online active learning ",
    "url": "https://arxiv.org/abs/2302.00422",
    "authors": [
      "Davide Cacciarelli",
      "Murat Kulahci",
      "John S\u00f8lve Tyssedal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.08664",
    "title": "Socialz: Multi-Feature Social Fuzz Testing",
    "abstract": " Title: Socialz: Multi-Feature Social Fuzz Testing ",
    "url": "https://arxiv.org/abs/2302.08664",
    "authors": [
      "Francisco Zanartu",
      "Christoph Treude",
      "Markus Wagner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.10390",
    "title": "DrasCLR: A Self-supervised Framework of Learning Disease-related and  Anatomy-specific Representation for 3D Medical Images",
    "abstract": " Comments: Added some recent references ",
    "url": "https://arxiv.org/abs/2302.10390",
    "authors": [
      "Ke Yu",
      "Li Sun",
      "Junxiang Chen",
      "Max Reynolds",
      "Tigmanshu Chaudhary",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11814",
    "title": "FTM: A Frame-level Timeline Modeling Method for Temporal Graph  Representation Learning",
    "abstract": " Comments: Accepted in AAAI 2023, oral ",
    "url": "https://arxiv.org/abs/2302.11814",
    "authors": [
      "Bowen Cao",
      "Qichen Ye",
      "Weiyuan Xu",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.13629",
    "title": "Estimation of continuous environments by robot swarms: Correlated  networks and decision-making",
    "abstract": " Comments: \\c{opyright} Accepted at IEEE/International Conference on Robotics and Automation (ICRA) 2023, 7 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2302.13629",
    "authors": [
      "Mohsen Raoufi",
      "Pawel Romanczuk",
      "Heiko Hamann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.00575",
    "title": "IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint  Multi-Agent Trajectory Prediction",
    "abstract": " Comments: CVPR 2023 accepted ",
    "url": "https://arxiv.org/abs/2303.00575",
    "authors": [
      "Dekai Zhu",
      "Guangyao Zhai",
      "Yan Di",
      "Fabian Manhardt",
      "Hendrik Berkemeyer",
      "Tuan Tran",
      "Nassir Navab",
      "Federico Tombari",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.01046",
    "title": "Jointly Visual- and Semantic-Aware Graph Memory Networks for Temporal  Sentence Localization in Videos",
    "abstract": " Comments: Accepted by ICASSP2023 ",
    "url": "https://arxiv.org/abs/2303.01046",
    "authors": [
      "Daizong Liu",
      "Pan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.02462",
    "title": "Towards Improved Illicit Node Detection with Positive-Unlabelled  Learning",
    "abstract": " Comments: accepted at the 5th edition of the IEEE International Conference on Blockchain and Cryptocurrency (ICBC 2023) ",
    "url": "https://arxiv.org/abs/2303.02462",
    "authors": [
      "Junliang Luo",
      "Farimah Poursafaei",
      "Xue Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02489",
    "title": "CapDet: Unifying Dense Captioning and Open-World Detection Pretraining",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.02489",
    "authors": [
      "Yanxin Long",
      "Youpeng Wen",
      "Jianhua Han",
      "Hang Xu",
      "Pengzhen Ren",
      "Wei Zhang",
      "Shen Zhao",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04253",
    "title": "SKGHOI: Spatial-Semantic Knowledge Graph for Human-Object Interaction  Detection",
    "abstract": " Comments: 10 pages, 3 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2303.04253",
    "authors": [
      "Lijing Zhu",
      "Qizhen Lan",
      "Alvaro Velasquez",
      "Houbing Song",
      "Acharya Kamal",
      "Qing Tian",
      "Shuteng Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05007",
    "title": "Towards Robust Image-in-Audio Deep Steganography",
    "abstract": " Comments: 8 pages, 5 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2303.05007",
    "authors": [
      "Jaume Ros",
      "Margarita Geleta",
      "Jordi Pons",
      "Xavier Giro-i-Nieto"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.06885",
    "title": "DR2: Diffusion-based Robust Degradation Remover for Blind Face  Restoration",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.06885",
    "authors": [
      "Zhixin Wang",
      "Xiaoyun Zhang",
      "Ziying Zhang",
      "Huangjie Zheng",
      "Mingyuan Zhou",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06980",
    "title": "Self-supervised based general laboratory progress pretrained model for  cardiovascular event detection",
    "abstract": " Title: Self-supervised based general laboratory progress pretrained model for  cardiovascular event detection ",
    "url": "https://arxiv.org/abs/2303.06980",
    "authors": [
      "Li-Chin Chen",
      "Kuo-Hsuan Hung",
      "Yi-Ju Tseng",
      "Hsin-Yao Wang",
      "Tse-Min Lu",
      "Wei-Chieh Huang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07474",
    "title": "Can Adversarial Examples Be Parsed to Reveal Victim Model Information?",
    "abstract": " Title: Can Adversarial Examples Be Parsed to Reveal Victim Model Information? ",
    "url": "https://arxiv.org/abs/2303.07474",
    "authors": [
      "Yuguang Yao",
      "Jiancheng Liu",
      "Yifan Gong",
      "Xiaoming Liu",
      "Yanzhi Wang",
      "Xue Lin",
      "Sijia Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07812",
    "title": "Termination of Graph Transformation Systems using Weighted Subgraph  Counting",
    "abstract": " Comments: 24 pages. v2 fixes a formatting issue in the appendix ",
    "url": "https://arxiv.org/abs/2303.07812",
    "authors": [
      "Roy Overbeek",
      "J\u00f6rg Endrullis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2303.07884",
    "title": "Distributed least square solution method to linear algebraic equations  over multiagent networks",
    "abstract": " Comments: I need to correct some unclear points in the paper ",
    "url": "https://arxiv.org/abs/2303.07884",
    "authors": [
      "Viet Hoang Pham",
      "Hyo-Sung Ahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.07937",
    "title": "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D  Generation",
    "abstract": " Comments: Project page this https URL ",
    "url": "https://arxiv.org/abs/2303.07937",
    "authors": [
      "Junyoung Seo",
      "Wooseok Jang",
      "Min-Seop Kwak",
      "Jaehoon Ko",
      "Hyeonsu Kim",
      "Junho Kim",
      "Jin-Hwa Kim",
      "Jiyoung Lee",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07982",
    "title": "A Structural Approach to Tree Decompositions of Knots and Spatial Graphs",
    "abstract": " Title: A Structural Approach to Tree Decompositions of Knots and Spatial Graphs ",
    "url": "https://arxiv.org/abs/2303.07982",
    "authors": [
      "Corentin Lunel",
      "Arnaud de Mesmay"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2303.08131",
    "title": "A Simple Framework for Open-Vocabulary Segmentation and Detection",
    "abstract": " Comments: A Simple Framework for Open-Vocabulary Segmentation and Detection ",
    "url": "https://arxiv.org/abs/2303.08131",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Xueyan Zou",
      "Shilong Liu",
      "Chunyuan Li",
      "Jianfeng Gao",
      "Jianwei Yang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]