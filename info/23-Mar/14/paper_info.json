[
  {
    "id": "arXiv:2303.06151",
    "title": "NoiseCAM: Explainable AI for the Boundary Between Noise and Adversarial  Attacks",
    "abstract": "Deep Learning (DL) and Deep Neural Networks (DNNs) are widely used in various domains. However, adversarial attacks can easily mislead a neural network and lead to wrong decisions. Defense mechanisms are highly preferred in safety-critical applications. In this paper, firstly, we use the gradient class activation map (GradCAM) to analyze the behavior deviation of the VGG-16 network when its inputs are mixed with adversarial perturbation or Gaussian noise. In particular, our method can locate vulnerable layers that are sensitive to adversarial perturbation and Gaussian noise. We also show that the behavior deviation of vulnerable layers can be used to detect adversarial examples. Secondly, we propose a novel NoiseCAM algorithm that integrates information from globally and pixel-level weighted class activation maps. Our algorithm is susceptible to adversarial perturbations and will not respond to Gaussian random noise mixed in the inputs. Third, we compare detecting adversarial examples using both behavior deviation and NoiseCAM, and we show that NoiseCAM outperforms behavior deviation modeling in its overall performance. Our work could provide a useful tool to defend against certain adversarial attacks on deep neural networks. ",
    "url": "https://arxiv.org/abs/2303.06151",
    "authors": [
      "Wenkai Tan",
      "Justus Renkhoff",
      "Alvaro Velasquez",
      "Ziyu Wang",
      "Lusi Li",
      "Jian Wang",
      "Shuteng Niu",
      "Fan Yang",
      "Yongxin Liu",
      "Houbing Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06152",
    "title": "Why is That a Good or Not a Good Frying Pan? -- Knowledge Representation  for Functions of Objects and Tools for Design Understanding, Improvement, and  Generation for Design Understanding, Improvement, and Generation",
    "abstract": "The understanding of the functional aspects of objects and tools is of paramount importance in supporting an intelligent system in navigating around in the environment and interacting with various objects, structures, and systems, to help fulfil its goals. A detailed understanding of functionalities can also lead to design improvements and novel designs that would enhance the operations of AI and robotic systems on the one hand, and human lives on the other. This paper demonstrates how a particular object - in this case, a frying pan - and its participation in the processes it is designed to support - in this case, the frying process - can be represented in a general function representational language and framework, that can be used to flesh out the processes and functionalities involved, leading to a deep conceptual understanding with explainability of functionalities that allows the system to answer \"why\" questions - why is something a good frying pan, say, or why a certain part on the frying pan is designed in a certain way? Or, why is something not a good frying pan? This supports the re-design and improvement on design of objects, artifacts, and tools, as well as the potential for generating novel designs that are functionally accurate, usable, and satisfactory. ",
    "url": "https://arxiv.org/abs/2303.06152",
    "authors": [
      "Seng-Beng Ho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06155",
    "title": "Digital Twin-Assisted Knowledge Distillation Framework for Heterogeneous  Federated Learning",
    "abstract": "In this paper, to deal with the heterogeneity in federated learning (FL) systems, a knowledge distillation (KD) driven training framework for FL is proposed, where each user can select its neural network model on demand and distill knowledge from a big teacher model using its own private dataset. To overcome the challenge of train the big teacher model in resource limited user devices, the digital twin (DT) is exploit in the way that the teacher model can be trained at DT located in the server with enough computing resources. Then, during model distillation, each user can update the parameters of its model at either the physical entity or the digital agent. The joint problem of model selection and training offloading and resource allocation for users is formulated as a mixed integer programming (MIP) problem. To solve the problem, Q-learning and optimization are jointly used, where Q-learning selects models for users and determines whether to train locally or on the server, and optimization is used to allocate resources for users based on the output of Q-learning. Simulation results show the proposed DT-assisted KD framework and joint optimization method can significantly improve the average accuracy of users while reducing the total delay. ",
    "url": "https://arxiv.org/abs/2303.06155",
    "authors": [
      "Xiucheng Wang",
      "Nan Cheng",
      "Longfei Ma",
      "Ruijin Sun",
      "Rong Chai",
      "Ning Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.06169",
    "title": "MOELA: A Multi-Objective Evolutionary/Learning Design Space Exploration  Framework for 3D Heterogeneous Manycore Platforms",
    "abstract": "To enable emerging applications such as deep machine learning and graph processing, 3D network-on-chip (NoC) enabled heterogeneous manycore platforms that can integrate many processing elements (PEs) are needed. However, designing such complex systems with multiple objectives can be challenging due to the huge associated design space and long evaluation times. To optimize such systems, we propose a new multi-objective design space exploration framework called MOELA that combines the benefits of evolutionary-based search with a learning-based local search to quickly determine PE and communication link placement to optimize multiple objectives (e.g., latency, throughput, and energy) in 3D NoC enabled heterogeneous manycore systems. Compared to state-of-the-art approaches, MOELA increases the speed of finding solutions by up to 128x, leads to a better Pareto Hypervolume (PHV) by up to 12.14x and improves energy-delay-product (EDP) by up to 7.7% in a 5-objective scenario. ",
    "url": "https://arxiv.org/abs/2303.06169",
    "authors": [
      "Sirui Qi",
      "Yingheng Li",
      "Sudeep Pasricha",
      "Ryan Gary Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2303.06177",
    "title": "Software Vulnerability Prediction Knowledge Transferring Between  Programming Languages",
    "abstract": "Developing automated and smart software vulnerability detection models has been receiving great attention from both research and development communities. One of the biggest challenges in this area is the lack of code samples for all different programming languages. In this study, we address this issue by proposing a transfer learning technique to leverage available datasets and generate a model to detect common vulnerabilities in different programming languages. We use C source code samples to train a Convolutional Neural Network (CNN) model, then, we use Java source code samples to adopt and evaluate the learned model. We use code samples from two benchmark datasets: NIST Software Assurance Reference Dataset (SARD) and Draper VDISC dataset. The results show that proposed model detects vulnerabilities in both C and Java codes with average recall of 72\\%. Additionally, we employ explainable AI to investigate how much each feature contributes to the knowledge transfer mechanisms between C and Java in the proposed model. ",
    "url": "https://arxiv.org/abs/2303.06177",
    "authors": [
      "Khadija Hanifi",
      "Ramin F Fouladi",
      "Basak Gencer Unsalver",
      "Goksu Karadag"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06199",
    "title": "Turning Strengths into Weaknesses: A Certified Robustness Inspired  Attack Framework against Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have achieved state-of-the-art performance in many graph learning tasks. However, recent studies show that GNNs are vulnerable to both test-time evasion and training-time poisoning attacks that perturb the graph structure. While existing attack methods have shown promising attack performance, we would like to design an attack framework to further enhance the performance. In particular, our attack framework is inspired by certified robustness, which was originally used by defenders to defend against adversarial attacks. We are the first, from the attacker perspective, to leverage its properties to better attack GNNs. Specifically, we first derive nodes' certified perturbation sizes against graph evasion and poisoning attacks based on randomized smoothing, respectively. A larger certified perturbation size of a node indicates this node is theoretically more robust to graph perturbations. Such a property motivates us to focus more on nodes with smaller certified perturbation sizes, as they are easier to be attacked after graph perturbations. Accordingly, we design a certified robustness inspired attack loss, when incorporated into (any) existing attacks, produces our certified robustness inspired attack counterpart. We apply our framework to the existing attacks and results show it can significantly enhance the existing base attacks' performance. ",
    "url": "https://arxiv.org/abs/2303.06199",
    "authors": [
      "Binghui Wang",
      "Meng Pang",
      "Yun Dong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.06202",
    "title": "A POV-based Highway Vehicle Trajectory Dataset and Prediction  Architecture",
    "abstract": "Vehicle Trajectory datasets that provide multiple point-of-views (POVs) can be valuable for various traffic safety and management applications. Despite the abundance of trajectory datasets, few offer a comprehensive and diverse range of driving scenes, capturing multiple viewpoints of various highway layouts, merging lanes, and configurations. This limits their ability to capture the nuanced interactions between drivers, vehicles, and the roadway infrastructure. We introduce the \\emph{Carolinas Highway Dataset (CHD\\footnote{\\emph{CHD} available at: \\url{https://github.com/TeCSAR-UNCC/Carolinas\\_Dataset}})}, a vehicle trajectory, detection, and tracking dataset. \\emph{CHD} is a collection of 1.6 million frames captured in highway-based videos from eye-level and high-angle POVs at eight locations across Carolinas with 338,000 vehicle trajectories. The locations, timing of recordings, and camera angles were carefully selected to capture various road geometries, traffic patterns, lighting conditions, and driving behaviors. We also present \\emph{PishguVe}\\footnote{\\emph{PishguVe} code available at: \\url{https://github.com/TeCSAR-UNCC/PishguVe}}, a novel vehicle trajectory prediction architecture that uses attention-based graph isomorphism and convolutional neural networks. The results demonstrate that \\emph{PishguVe} outperforms existing algorithms to become the new state-of-the-art (SotA) in bird's-eye, eye-level, and high-angle POV trajectory datasets. Specifically, it achieves a 12.50\\% and 10.20\\% improvement in ADE and FDE, respectively, over the current SotA on NGSIM dataset. Compared to best-performing models on CHD, \\emph{PishguVe} achieves lower ADE and FDE on eye-level data by 14.58\\% and 27.38\\%, respectively, and improves ADE and FDE on high-angle data by 8.3\\% and 6.9\\%, respectively. ",
    "url": "https://arxiv.org/abs/2303.06202",
    "authors": [
      "Vinit Katariya",
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06210",
    "title": "A Theoretical Analysis Of Nearest Neighbor Search On Approximate Near  Neighbor Graph",
    "abstract": "Graph-based algorithms have demonstrated state-of-the-art performance in the nearest neighbor search (NN-Search) problem. These empirical successes urge the need for theoretical results that guarantee the search quality and efficiency of these algorithms. However, there exists a practice-to-theory gap in the graph-based NN-Search algorithms. Current theoretical literature focuses on greedy search on exact near neighbor graph while practitioners use approximate near neighbor graph (ANN-Graph) to reduce the preprocessing time. This work bridges this gap by presenting the theoretical guarantees of solving NN-Search via greedy search on ANN-Graph for low dimensional and dense vectors. To build this bridge, we leverage several novel tools from computational geometry. Our results provide quantification of the trade-offs associated with the approximation while building a near neighbor graph. We hope our results will open the door for more provable efficient graph-based NN-Search algorithms. ",
    "url": "https://arxiv.org/abs/2303.06210",
    "authors": [
      "Anshumali Shrivastava",
      "Zhao Song",
      "Zhaozhuo Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06213",
    "title": "CHGNN: A Semi-Supervised Contrastive Hypergraph Learning Network",
    "abstract": "Hypergraphs can model higher-order relationships among data objects that are found in applications such as social networks and bioinformatics. However, recent studies on hypergraph learning that extend graph convolutional networks to hypergraphs cannot learn effectively from features of unlabeled data. To such learning, we propose a contrastive hypergraph neural network, CHGNN, that exploits self-supervised contrastive learning techniques to learn from labeled and unlabeled data. First, CHGNN includes an adaptive hypergraph view generator that adopts an auto-augmentation strategy and learns a perturbed probability distribution of minimal sufficient views. Second, CHGNN encompasses an improved hypergraph encoder that considers hyperedge homogeneity to fuse information effectively. Third, CHGNN is equipped with a joint loss function that combines a similarity loss for the view generator, a node classification loss, and a hyperedge homogeneity loss to inject supervision signals. It also includes basic and cross-validation contrastive losses, associated with an enhanced contrastive loss training process. Experimental results on nine real datasets offer insight into the effectiveness of CHGNN, showing that it outperforms 13 competitors in terms of classification accuracy consistently. ",
    "url": "https://arxiv.org/abs/2303.06213",
    "authors": [
      "Yumeng Song",
      "Yu Gu",
      "Tianyi Li",
      "Jianzhong Qi",
      "Zhenghao Liu",
      "Christian S. Jensen",
      "Ge Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06222",
    "title": "Robust MADER: Decentralized Multiagent Trajectory Planner Robust to  Communication Delay in Dynamic Environments",
    "abstract": "Communication delays can be catastrophic for multiagent systems. However, most existing state-of-the-art multiagent trajectory planners assume perfect communication and therefore lack a strategy to rectify this issue in real-world environments. To address this challenge, we propose Robust MADER (RMADER), a decentralized, asynchronous multiagent trajectory planner robust to communication delay. By always keeping a guaranteed collision-free trajectory and performing a delay check step, RMADER is able to guarantee safety even under communication delay. We perform an in-depth analysis of trajectory deconfliction among agents, extensive benchmark studies, and hardware flight experiments with multiple dynamic obstacles. We show that RMADER outperforms existing approaches by achieving a 100% success rate of collision-free trajectory generation, whereas the next best asynchronous decentralized method only achieves 83% success. ",
    "url": "https://arxiv.org/abs/2303.06222",
    "authors": [
      "Kota Kondo",
      "Reinaldo Figueroa",
      "Juan Rached",
      "Jesus Tordesillas",
      "Parker C. Lusk",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.06232",
    "title": "MCROOD: Multi-Class Radar Out-Of-Distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection has recently received special attention due to its critical role in safely deploying modern deep learning (DL) architectures. This work proposes a reconstruction-based multi-class OOD detector that operates on radar range doppler images (RDIs). The detector aims to classify any moving object other than a person sitting, standing, or walking as OOD. We also provide a simple yet effective pre-processing technique to detect minor human body movements like breathing. The simple idea is called respiration detector (RESPD) and eases the OOD detection, especially for human sitting and standing classes. On our dataset collected by 60GHz short-range FMCW Radar, we achieve AUROCs of 97.45%, 92.13%, and 96.58% for sitting, standing, and walking classes, respectively. We perform extensive experiments and show that our method outperforms state-of-the-art (SOTA) OOD detection methods. Also, our pipeline performs 24 times faster than the second-best method and is very suitable for real-time processing. ",
    "url": "https://arxiv.org/abs/2303.06232",
    "authors": [
      "Sabri Mustafa Kahya",
      "Muhammet Sami Yavuz",
      "Eckehard Steinbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.06241",
    "title": "Do we need entire training data for adversarial training?",
    "abstract": "Deep Neural Networks (DNNs) are being used to solve a wide range of problems in many domains including safety-critical domains like self-driving cars and medical imagery. DNNs suffer from vulnerability against adversarial attacks. In the past few years, numerous approaches have been proposed to tackle this problem by training networks using adversarial training. Almost all the approaches generate adversarial examples for the entire training dataset, thus increasing the training time drastically. We show that we can decrease the training time for any adversarial training algorithm by using only a subset of training data for adversarial training. To select the subset, we filter the adversarially-prone samples from the training data. We perform a simple adversarial attack on all training examples to filter this subset. In this attack, we add a small perturbation to each pixel and a few grid lines to the input image. We perform adversarial training on the adversarially-prone subset and mix it with vanilla training performed on the entire dataset. Our results show that when our method-agnostic approach is plugged into FGSM, we achieve a speedup of 3.52x on MNIST and 1.98x on the CIFAR-10 dataset with comparable robust accuracy. We also test our approach on state-of-the-art Free adversarial training and achieve a speedup of 1.2x in training time with a marginal drop in robust accuracy on the ImageNet dataset. ",
    "url": "https://arxiv.org/abs/2303.06241",
    "authors": [
      "Vipul Gupta",
      "Apurva Narayan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06242",
    "title": "HYperbolic Self-Paced Learning for Self-Supervised Skeleton-based Action  Representations",
    "abstract": "Self-paced learning has been beneficial for tasks where some initial knowledge is available, such as weakly supervised learning and domain adaptation, to select and order the training sample sequence, from easy to complex. However its applicability remains unexplored in unsupervised learning, whereby the knowledge of the task matures during training. We propose a novel HYperbolic Self-Paced model (HYSP) for learning skeleton-based action representations. HYSP adopts self-supervision: it uses data augmentations to generate two views of the same sample, and it learns by matching one (named online) to the other (the target). We propose to use hyperbolic uncertainty to determine the algorithmic learning pace, under the assumption that less uncertain samples should be more strongly driving the training, with a larger weight and pace. Hyperbolic uncertainty is a by-product of the adopted hyperbolic neural networks, it matures during training and it comes with no extra cost, compared to the established Euclidean SSL framework counterparts. When tested on three established skeleton-based action recognition datasets, HYSP outperforms the state-of-the-art on PKU-MMD I, as well as on 2 out of 3 downstream tasks on NTU-60 and NTU-120. Additionally, HYSP only uses positive pairs and bypasses therefore the complex and computationally-demanding mining procedures required for the negatives in contrastive techniques. Code is available at https://github.com/paolomandica/HYSP. ",
    "url": "https://arxiv.org/abs/2303.06242",
    "authors": [
      "Luca Franco",
      "Paolo Mandica",
      "Bharti Munjal",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06277",
    "title": "SPOTR: Spatio-temporal Pose Transformers for Human Motion Prediction",
    "abstract": "3D human motion prediction is a research area of high significance and a challenge in computer vision. It is useful for the design of many applications including robotics and autonomous driving. Traditionally, autogregressive models have been used to predict human motion. However, these models have high computation needs and error accumulation that make it difficult to use them for realtime applications. In this paper, we present a non-autogressive model for human motion prediction. We focus on learning spatio-temporal representations non-autoregressively for generation of plausible future motions. We propose a novel architecture that leverages the recently proposed Transformers. Human motion involves complex spatio-temporal dynamics with joints affecting the position and rotation of each other even though they are not connected directly. The proposed model extracts these dynamics using both convolutions and the self-attention mechanism. Using specialized spatial and temporal self-attention to augment the features extracted through convolution allows our model to generate spatio-temporally coherent predictions in parallel independent of the activity. Our contributions are threefold: (i) we frame human motion prediction as a sequence-to-sequence problem and propose a non-autoregressive Transformer to forecast a sequence of poses in parallel; (ii) our method is activity agnostic; (iii) we show that despite its simplicity, our approach is able to make accurate predictions, achieving better or comparable results compared to the state-of-the-art on two public datasets, with far fewer parameters and much faster inference. ",
    "url": "https://arxiv.org/abs/2303.06277",
    "authors": [
      "Avinash Ajit Nargund",
      "Misha Sra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06280",
    "title": "Investigating Stateful Defenses Against Black-Box Adversarial Examples",
    "abstract": "Defending machine-learning (ML) models against white-box adversarial attacks has proven to be extremely difficult. Instead, recent work has proposed stateful defenses in an attempt to defend against a more restricted black-box attacker. These defenses operate by tracking a history of incoming model queries, and rejecting those that are suspiciously similar. The current state-of-the-art stateful defense Blacklight was proposed at USENIX Security '22 and claims to prevent nearly 100% of attacks on both the CIFAR10 and ImageNet datasets. In this paper, we observe that an attacker can significantly reduce the accuracy of a Blacklight-protected classifier (e.g., from 82.2% to 6.4% on CIFAR10) by simply adjusting the parameters of an existing black-box attack. Motivated by this surprising observation, since existing attacks were evaluated by the Blacklight authors, we provide a systematization of stateful defenses to understand why existing stateful defense models fail. Finally, we propose a stronger evaluation strategy for stateful defenses comprised of adaptive score and hard-label based black-box attacks. We use these attacks to successfully reduce even reconfigured versions of Blacklight to as low as 0% robust accuracy. ",
    "url": "https://arxiv.org/abs/2303.06280",
    "authors": [
      "Ryan Feng",
      "Ashish Hooda",
      "Neal Mangaokar",
      "Kassem Fawaz",
      "Somesh Jha",
      "Atul Prakash"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06284",
    "title": "Prospecting Community Development Strength based on Economic Graph: From  Categorization to Scoring",
    "abstract": "Recent years have witnessed a growing number of researches on community characterization. In contrast to the large body of researches on the categorical measures (rise or decline) for evaluating the community development, we propose to estimate the community development strength (to which degree the rise or decline is). More specifically, given already known categorical information of community development, we are attempting to quantify the community development strength, which is of great interest. Motivated by the increasing availability of large-scale data on the network between entities among communities, we investigate how to score the the community's development strength. We formally define our task as prospecting community development strength from categorization based on multi-relational network information and identify two challenges as follows: (1) limited guidance for integrating entity multi-relational network in quantifying the community development strength; (2) the existence of selection effect that the community development strength has on network formation. Aiming at these challenges, we start by a hybrid of discriminative and generative approaches on multi-relational network-based community development strength quantification. Then a network generation process is exploited to debias the selection process. In the end, we empirically evaluate the proposed model by applying it to quantify enterprise business development strength. Experimental results demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2303.06284",
    "authors": [
      "Chang Liao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.06293",
    "title": "Space-Invariant Projection in Streaming Network Embedding",
    "abstract": "Newly arriving nodes in dynamics networks would gradually make the node embedding space drifted and the retraining of node embedding and downstream models indispensable. An exact threshold size of these new nodes, below which the node embedding space will be predicatively maintained, however, is rarely considered in either theory or experiment. From the view of matrix perturbation theory, a threshold of the maximum number of new nodes that keep the node embedding space approximately equivalent is analytically provided and empirically validated. It is therefore theoretically guaranteed that as the size of newly arriving nodes is below this threshold, embeddings of these new nodes can be quickly derived from embeddings of original nodes. A generation framework, Space-Invariant Projection (SIP), is accordingly proposed to enables arbitrary static MF-based embedding schemes to embed new nodes in dynamics networks fast. The time complexity of SIP is linear with the network size. By combining SIP with four state-of-the-art MF-based schemes, we show that SIP exhibits not only wide adaptability but also strong empirical performance in terms of efficiency and efficacy on the node classification task in three real datasets. ",
    "url": "https://arxiv.org/abs/2303.06293",
    "authors": [
      "Yanwen Zhang",
      "Huiwen Wang",
      "Jichang Zhao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06302",
    "title": "Adversarial Attacks and Defenses in Machine Learning-Powered Networks: A  Contemporary Survey",
    "abstract": "Adversarial attacks and defenses in machine learning and deep neural network have been gaining significant attention due to the rapidly growing applications of deep learning in the Internet and relevant scenarios. This survey provides a comprehensive overview of the recent advancements in the field of adversarial attack and defense techniques, with a focus on deep neural network-based classification models. Specifically, we conduct a comprehensive classification of recent adversarial attack methods and state-of-the-art adversarial defense techniques based on attack principles, and present them in visually appealing tables and tree diagrams. This is based on a rigorous evaluation of the existing works, including an analysis of their strengths and limitations. We also categorize the methods into counter-attack detection and robustness enhancement, with a specific focus on regularization-based methods for enhancing robustness. New avenues of attack are also explored, including search-based, decision-based, drop-based, and physical-world attacks, and a hierarchical classification of the latest defense methods is provided, highlighting the challenges of balancing training costs with performance, maintaining clean accuracy, overcoming the effect of gradient masking, and ensuring method transferability. At last, the lessons learned and open challenges are summarized with future research opportunities recommended. ",
    "url": "https://arxiv.org/abs/2303.06302",
    "authors": [
      "Yulong Wang",
      "Tong Sun",
      "Shenghong Li",
      "Xin Yuan",
      "Wei Ni",
      "Ekram Hossain",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06304",
    "title": "Multi-Context Interaction Network for Few-Shot Segmentation",
    "abstract": "Few-Shot Segmentation (FSS) is challenging for limited support images and large intra-class appearance discrepancies. Due to the huge difference between support and query samples, most existing approaches focus on extracting high-level representations of the same layers for support-query correlations but neglect the shift issue between different layers and scales. In this paper, we propose a Multi-Context Interaction Network (MCINet) to remedy this issue by fully exploiting and interacting with the multi-scale contextual information contained in the support-query pairs. Specifically, MCINet improves FSS from the perspectives of boosting the query representations by incorporating the low-level structural information from another query branch into the high-level semantic features, enhancing the support-query correlations by exploiting both the same-layer and adjacent-layer features, and refining the predicted results by a multi-scale mask prediction strategy, with which the different scale contents have bidirectionally interacted. Experiments on two benchmarks demonstrate that our approach reaches SOTA performances and outperforms the best competitors with many desirable advantages, especially on the challenging COCO dataset. ",
    "url": "https://arxiv.org/abs/2303.06304",
    "authors": [
      "Hao Chen",
      "Yunlong Yu",
      "Yonghan Dong",
      "Zheming Lu",
      "Yingming Li",
      "Zhongfei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06307",
    "title": "Fisher Markets with Social Influence",
    "abstract": "A Fisher market is an economic model of buyer and seller interactions in which each buyer's utility depends only on the bundle of goods she obtains. Many people's interests, however, are affected by their social interactions with others. In this paper, we introduce a generalization of Fisher markets, namely influence Fisher markets, which captures the impact of social influence on buyers' utilities. We show that competitive equilibria in influence Fisher markets correspond to generalized Nash equilibria in an associated pseudo-game, which implies the existence of competitive equilibria in all influence Fisher markets with continuous and concave utility functions. We then construct a monotone pseudo-game, whose variational equilibria and their duals together characterize competitive equilibria in influence Fisher markets with continuous, jointly concave, and homogeneous utility functions. This observation implies that competitive equilibria in these markets can be computed in polynomial time under standard smoothness assumptions on the utility functions. The dual of this second pseudo-game enables us to interpret the competitive equilibria of influence CCH Fisher markets as the solutions to a system of simultaneous Stackelberg games. Finally, we derive a novel first-order method that solves this Stackelberg system in polynomial time, prove that it is equivalent to computing competitive equilibrium prices via t\\^{a}tonnement, and run experiments that confirm our theoretical results. ",
    "url": "https://arxiv.org/abs/2303.06307",
    "authors": [
      "Jiayi Zhao",
      "Denizalp Goktas",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2303.06310",
    "title": "Driver Drowsiness Detection System: An Approach By Machine Learning  Application",
    "abstract": "The majority of human deaths and injuries are caused by traffic accidents. A million people worldwide die each year due to traffic accident injuries, consistent with the World Health Organization. Drivers who do not receive enough sleep, rest, or who feel weary may fall asleep behind the wheel, endangering both themselves and other road users. The research on road accidents specified that major road accidents occur due to drowsiness while driving. These days, it is observed that tired driving is the main reason to occur drowsiness. Now, drowsiness becomes the main principle for to increase in the number of road accidents. This becomes a major issue in a world which is very important to resolve as soon as possible. The predominant goal of all devices is to improve the performance to detect drowsiness in real time. Many devices were developed to detect drowsiness, which depend on different artificial intelligence algorithms. So, our research is also related to driver drowsiness detection which can identify the drowsiness of a driver by identifying the face and then followed by eye tracking. The extracted eye image is matched with the dataset by the system. With the help of the dataset, the system detected that if eyes were close for a certain range, it could ring an alarm to alert the driver and if the eyes were open after the alert, then it could continue tracking. If the eyes were open then the score that we set decreased and if the eyes were closed then the score increased. This paper focus to resolve the problem of drowsiness detection with an accuracy of 80% and helps to reduce road accidents. ",
    "url": "https://arxiv.org/abs/2303.06310",
    "authors": [
      "Jagbeer Singh",
      "Ritika Kanojia",
      "Rishika Singh",
      "Rishita Bansal",
      "Sakshi Bansal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06316",
    "title": "One Neuron Saved Is One Neuron Earned: On Parametric Efficiency of  Quadratic Networks",
    "abstract": "Inspired by neuronal diversity in the biological neural system, a plethora of studies proposed to design novel types of artificial neurons and introduce neuronal diversity into artificial neural networks. Recently proposed quadratic neuron, which replaces the inner-product operation in conventional neurons with a quadratic one, have achieved great success in many essential tasks. Despite the promising results of quadratic neurons, there is still an unresolved issue: \\textit{Is the superior performance of quadratic networks simply due to the increased parameters or due to the intrinsic expressive capability?} Without clarifying this issue, the performance of quadratic networks is always suspicious. Additionally, resolving this issue is reduced to finding killer applications of quadratic networks. In this paper, with theoretical and empirical studies, we show that quadratic networks enjoy parametric efficiency, thereby confirming that the superior performance of quadratic networks is due to the intrinsic expressive capability. This intrinsic expressive ability comes from that quadratic neurons can easily represent nonlinear interaction, while it is hard for conventional neurons. Theoretically, we derive the approximation efficiency of the quadratic network over conventional ones in terms of real space and manifolds. Moreover, from the perspective of the Barron space, we demonstrate that there exists a functional space whose functions can be approximated by quadratic networks in a dimension-free error, but the approximation error of conventional networks is dependent on dimensions. Empirically, experimental results on synthetic data, classic benchmarks, and real-world applications show that quadratic models broadly enjoy parametric efficiency, and the gain of efficiency depends on the task. ",
    "url": "https://arxiv.org/abs/2303.06316",
    "authors": [
      "Feng-Lei Fan",
      "Hang-Cheng Dong",
      "Zhongming Wu",
      "Lecheng Ruan",
      "Tieyong Zeng",
      "Yiming Cui",
      "Jing-Xiao Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.06329",
    "title": "MetaViewer: Towards A Unified Multi-View Representation",
    "abstract": "Existing multi-view representation learning methods typically follow a specific-to-uniform pipeline, extracting latent features from each view and then fusing or aligning them to obtain the unified object representation. However, the manually pre-specify fusion functions and view-private redundant information mixed in features potentially degrade the quality of the derived representation. To overcome them, we propose a novel bi-level-optimization-based multi-view learning framework, where the representation is learned in a uniform-to-specific manner. Specifically, we train a meta-learner, namely MetaViewer, to learn fusion and model the view-shared meta representation in outer-level optimization. Start with this meta representation, view-specific base-learners are then required to rapidly reconstruct the corresponding view in inner-level. MetaViewer eventually updates by observing reconstruction processes from uniform to specific over all views, and learns an optimal fusion scheme that separates and filters out view-private information. Extensive experimental results in downstream tasks such as classification and clustering demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2303.06329",
    "authors": [
      "Ren Wang",
      "Haoliang Sun",
      "Yuling Ma",
      "Xiaoming Xi",
      "Yilong Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06330",
    "title": "PRSNet: A Masked Self-Supervised Learning Pedestrian Re-Identification  Method",
    "abstract": "In recent years, self-supervised learning has attracted widespread academic debate and addressed many of the key issues of computer vision. The present research focus is on how to construct a good agent task that allows for improved network learning of advanced semantic information on images so that model reasoning is accelerated during pre-training of the current task. In order to solve the problem that existing feature extraction networks are pre-trained on the ImageNet dataset and cannot extract the fine-grained information in pedestrian images well, and the existing pre-task of contrast self-supervised learning may destroy the original properties of pedestrian images, this paper designs a pre-task of mask reconstruction to obtain a pre-training model with strong robustness and uses it for the pedestrian re-identification task. The training optimization of the network is performed by improving the triplet loss based on the centroid, and the mask image is added as an additional sample to the loss calculation, so that the network can better cope with the pedestrian matching in practical applications after the training is completed. This method achieves about 5% higher mAP on Marker1501 and CUHK03 data than existing self-supervised learning pedestrian re-identification methods, and about 1% higher for Rank1, and ablation experiments are conducted to demonstrate the feasibility of this method. Our model code is located at https://github.com/ZJieX/prsnet. ",
    "url": "https://arxiv.org/abs/2303.06330",
    "authors": [
      "Zhijie Xiao",
      "Zhicheng Dong",
      "Hao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06335",
    "title": "Just Flip: Flipped Observation Generation and Optimization for Neural  Radiance Fields to Cover Unobserved View",
    "abstract": "With the advent of Neural Radiance Field (NeRF), representing 3D scenes through multiple observations has shown remarkable improvements in performance. Since this cutting-edge technique is able to obtain high-resolution renderings by interpolating dense 3D environments, various approaches have been proposed to apply NeRF for the spatial understanding of robot perception. However, previous works are challenging to represent unobserved scenes or views on the unexplored robot trajectory, as these works do not take into account 3D reconstruction without observation information. To overcome this problem, we propose a method to generate flipped observation in order to cover unexisting observation for unexplored robot trajectory. To achieve this, we propose a data augmentation method for 3D reconstruction using NeRF by flipping observed images, and estimating flipped camera 6DOF poses. Our technique exploits the property of objects being geometrically symmetric, making it simple but fast and powerful, thereby making it suitable for robotic applications where real-time performance is important. We demonstrate that our method significantly improves three representative perceptual quality measures on the NeRF synthetic dataset. ",
    "url": "https://arxiv.org/abs/2303.06335",
    "authors": [
      "Minjae Lee",
      "Kyeongsu Kang",
      "Hyeonwoo Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.06342",
    "title": "Enhanced K-Radar: Optimal Density Reduction to Improve Detection  Performance and Accessibility of 4D Radar Tensor-based Object Detection",
    "abstract": "Recent works have shown the superior robustness of four-dimensional (4D) Radar-based three-dimensional (3D) object detection in adverse weather conditions. However, processing 4D Radar data remains a challenge due to the large data size, which require substantial amount of memory for computing and storage. In previous work, an online density reduction is performed on the 4D Radar Tensor (4DRT) to reduce the data size, in which the density reduction level is chosen arbitrarily. However, the impact of density reduction on the detection performance and memory consumption remains largely unknown. In this paper, we aim to address this issue by conducting extensive hyperparamter tuning on the density reduction level. Experimental results show that increasing the density level from 0.01% to 50% of the original 4DRT density level proportionally improves the detection performance, at a cost of memory consumption. However, when the density level is increased beyond 5%, only the memory consumption increases, while the detection performance oscillates below the peak point. In addition to the optimized density hyperparameter, we also introduce 4D Sparse Radar Tensor (4DSRT), a new representation for 4D Radar data with offline density reduction, leading to a significantly reduced raw data size. An optimized development kit for training the neural networks is also provided, which along with the utilization of 4DSRT, improves training speed by a factor of 17.1 compared to the state-of-the-art 4DRT-based neural networks. All codes are available at: https://github.com/kaist-avelab/K-Radar. ",
    "url": "https://arxiv.org/abs/2303.06342",
    "authors": [
      "Dong-Hee Paek",
      "Seung-Hyun Kong",
      "Kevin Tirta Wijaya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06344",
    "title": "Contrastive Learning under Heterophily",
    "abstract": "Graph Neural Networks are powerful tools for learning node representations when task-specific node labels are available. However, obtaining labels for graphs is expensive in many applications. This is particularly the case for large graphs. To address this, there has been a body of work to learn node representations in a self-supervised manner without labels. Contrastive learning (CL), has been particularly popular to learn representations in a self-supervised manner. In general, CL methods work by maximizing the similarity between representations of augmented views of the same example, and minimizing the similarity between augmented views of different examples. However, existing graph CL methods cannot learn high-quality representations under heterophily, where connected nodes tend to belong to different classes. This is because under heterophily, augmentations of the same example may not be similar to each other. In this work, we address the above problem by proposing the first graph CL method, HLCL, for learning node representations, under heterophily. HLCL uses a high-pass and a low-pass graph filter to generate different views of the same node. Then, it contrasts the two filtered views to learn the final node representations. Effectively, the high-pass filter captures the dissimilarity between nodes in a neighborhood and the low-pass filter captures the similarity between neighboring nodes.Contrasting the two filtered views allows HLCL to learn rich node representations for graphs, under heterophily and homophily.Empirically, HLCL outperforms state-of-the-art graph CL methods on benchmark heterophily datasets and large-scale real-world datasets by up to 10%. ",
    "url": "https://arxiv.org/abs/2303.06344",
    "authors": [
      "Wenhan Yang",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06349",
    "title": "Resurrecting Recurrent Neural Networks for Long Sequences",
    "abstract": "Recurrent Neural Networks (RNNs) offer fast inference on long sequences but are hard to optimize and slow to train. Deep state-space models (SSMs) have recently been shown to perform remarkably well on long sequence modeling tasks, and have the added benefits of fast parallelizable training and RNN-like fast inference. However, while SSMs are superficially similar to RNNs, there are important differences that make it unclear where their performance boost over RNNs comes from. In this paper, we show that careful design of deep RNNs using standard signal propagation arguments can recover the impressive performance of deep SSMs on long-range reasoning tasks, while also matching their training speed. To achieve this, we analyze and ablate a series of changes to standard RNNs including linearizing and diagonalizing the recurrence, using better parameterizations and initializations, and ensuring proper normalization of the forward pass. Our results provide new insights on the origins of the impressive performance of deep SSMs, while also introducing an RNN block called the Linear Recurrent Unit that matches both their performance on the Long Range Arena benchmark and their computational efficiency. ",
    "url": "https://arxiv.org/abs/2303.06349",
    "authors": [
      "Antonio Orvieto",
      "Samuel L Smith",
      "Albert Gu",
      "Anushan Fernando",
      "Caglar Gulcehre",
      "Razvan Pascanu",
      "Soham De"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06350",
    "title": "Spatio-Temporal Attention Network for Persistent Monitoring of Multiple  Mobile Targets",
    "abstract": "This work focuses on the persistent monitoring problem, where a set of targets moving based on an unknown model must be monitored by an autonomous mobile robot with a limited sensing range. To keep each target's position estimate as accurate as possible, the robot needs to adaptively plan its path to (re-)visit all the targets and update its belief from measurements collected along the way. In doing so, the main challenge is to strike a balance between exploitation, i.e., re-visiting previously-located targets, and exploration, i.e., finding new targets or re-acquiring lost ones. Encouraged by recent advances in deep reinforcement learning, we introduce an attention-based neural solution to the persistent monitoring problem, where the agent can learn the inter-dependencies between targets, i.e., their spatial and temporal correlations, conditioned on past measurements. This endows the agent with the ability to determine which target, time, and location to attend to across multiple scales, which we show also helps relax the usual limitations of a finite target set. We experimentally demonstrate that our method outperforms other baselines in terms of number of targets visits and average estimation error in complex environments. Finally, we implement and validate our model in a drone-based simulation experiment to monitor mobile ground targets in a high-fidelity simulator. ",
    "url": "https://arxiv.org/abs/2303.06350",
    "authors": [
      "Yizhuo Wang",
      "Yutong Wang",
      "Yuhong Cao",
      "Guillaume Sartoretti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.06353",
    "title": "Secure and Multi-Step Computation Offloading and Resource Allocation in  Ultra-Dense Multi-Task NOMA-Enabled IoT Networks",
    "abstract": "Ultra-dense networks are widely regarded as a promising solution to explosively growing applications of Internet-of-Things (IoT) mobile devices (IMDs). However, complicated and severe interferences need to be tackled properly in such networks. To this end, both orthogonal multiple access (OMA) and non-orthogonal multiple access (NOMA) are utilized at first. Then, in order to attain a goal of green and secure computation offloading, under the proportional allocation of computational resources and the constraints of latency and security cost, joint device association, channel selection, security service assignment, power control and computation offloading are done for minimizing the overall energy consumed by all IMDs. It is noteworthy that multi-step computation offloading is concentrated to balance the network loads and utilize computing resources fully. Since the finally formulated problem is in a nonlinear mixed-integer form, it may be very difficult to find its closed-form solution. To solve it, an improved whale optimization algorithm (IWOA) is designed. As for this algorithm, the convergence, computational complexity and parallel implementation are analyzed in detail. Simulation results show that the designed algorithm may achieve lower energy consumption than other existing algorithms under the constraints of latency and security cost. ",
    "url": "https://arxiv.org/abs/2303.06353",
    "authors": [
      "Tianqing Zhou",
      "Yanyan Fu",
      "Dong Qin",
      "Xuefang Nie",
      "Nan Jiang",
      "Chunguo Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.06357",
    "title": "CASP-Net: Rethinking Video Saliency Prediction from an  Audio-VisualConsistency Perceptual Perspective",
    "abstract": "Incorporating the audio stream enables Video Saliency Prediction (VSP) to imitate the selective attention mechanism of human brain. By focusing on the benefits of joint auditory and visual information, most VSP methods are capable of exploiting semantic correlation between vision and audio modalities but ignoring the negative effects due to the temporal inconsistency of audio-visual intrinsics. Inspired by the biological inconsistency-correction within multi-sensory information, in this study, a consistency-aware audio-visual saliency prediction network (CASP-Net) is proposed, which takes a comprehensive consideration of the audio-visual semantic interaction and consistent perception. In addition a two-stream encoder for elegant association between video frames and corresponding sound source, a novel consistency-aware predictive coding is also designed to improve the consistency within audio and visual representations iteratively. To further aggregate the multi-scale audio-visual information, a saliency decoder is introduced for the final saliency map generation. Substantial experiments demonstrate that the proposed CASP-Net outperforms the other state-of-the-art methods on six challenging audio-visual eye-tracking datasets. For a demo of our system please see our project webpage. ",
    "url": "https://arxiv.org/abs/2303.06357",
    "authors": [
      "Junwen Xiong",
      "Ganglai Wang",
      "Peng Zhang",
      "Wei Huang",
      "Yufei Zha",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06367",
    "title": "Probing neural representations of scene perception in a hippocampally  dependent task using artificial neural networks",
    "abstract": "Deep artificial neural networks (DNNs) trained through backpropagation provide effective models of the mammalian visual system, accurately capturing the hierarchy of neural responses through primary visual cortex to inferior temporal cortex (IT). However, the ability of these networks to explain representations in higher cortical areas is relatively lacking and considerably less well researched. For example, DNNs have been less successful as a model of the egocentric to allocentric transformation embodied by circuits in retrosplenial and posterior parietal cortex. We describe a novel scene perception benchmark inspired by a hippocampal dependent task, designed to probe the ability of DNNs to transform scenes viewed from different egocentric perspectives. Using a network architecture inspired by the connectivity between temporal lobe structures and the hippocampus, we demonstrate that DNNs trained using a triplet loss can learn this task. Moreover, by enforcing a factorized latent space, we can split information propagation into \"what\" and \"where\" pathways, which we use to reconstruct the input. This allows us to beat the state-of-the-art for unsupervised object segmentation on the CATER and MOVi-A,B,C benchmarks. ",
    "url": "https://arxiv.org/abs/2303.06367",
    "authors": [
      "Markus Frey",
      "Christian F. Doeller",
      "Caswell Barry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06371",
    "title": "AugDiff: Diffusion based Feature Augmentation for Multiple Instance  Learning in Whole Slide Image",
    "abstract": "Multiple Instance Learning (MIL), a powerful strategy for weakly supervised learning, is able to perform various prediction tasks on gigapixel Whole Slide Images (WSIs). However, the tens of thousands of patches in WSIs usually incur a vast computational burden for image augmentation, limiting the MIL model's improvement in performance. Currently, the feature augmentation-based MIL framework is a promising solution, while existing methods such as Mixup often produce unrealistic features. To explore a more efficient and practical augmentation method, we introduce the Diffusion Model (DM) into MIL for the first time and propose a feature augmentation framework called AugDiff. Specifically, we employ the generation diversity of DM to improve the quality of feature augmentation and the step-by-step generation property to control the retention of semantic information. We conduct extensive experiments over three distinct cancer datasets, two different feature extractors, and three prevalent MIL algorithms to evaluate the performance of AugDiff. Ablation study and visualization further verify the effectiveness. Moreover, we highlight AugDiff's higher-quality augmented feature over image augmentation and its superiority over self-supervised learning. The generalization over external datasets indicates its broader applications. ",
    "url": "https://arxiv.org/abs/2303.06371",
    "authors": [
      "Zhuchen Shao",
      "Liuxi Dai",
      "Yifeng Wang",
      "Haoqian Wang",
      "Yongbing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06378",
    "title": "Learning Grounded Vision-Language Representation for Versatile  Understanding in Untrimmed Videos",
    "abstract": "Joint video-language learning has received increasing attention in recent years. However, existing works mainly focus on single or multiple trimmed video clips (events), which makes human-annotated event boundaries necessary during inference. To break away from the ties, we propose a grounded vision-language learning framework for untrimmed videos, which automatically detects informative events and effectively excavates the alignments between multi-sentence descriptions and corresponding event segments. Instead of coarse-level video-language alignments, we present two dual pretext tasks to encourage fine-grained segment-level alignments, i.e., text-to-event grounding (TEG) and event-to-text generation (ETG). TEG learns to adaptively ground the possible event proposals given a set of sentences by estimating the cross-modal distance in a joint semantic space. Meanwhile, ETG aims to reconstruct (generate) the matched texts given event proposals, encouraging the event representation to retain meaningful semantic information. To encourage accurate label assignment between the event set and the text set, we propose a novel semantic-aware cost to mitigate the sub-optimal matching results caused by ambiguous boundary annotations. Our framework is easily extensible to tasks covering visually-grounded language understanding and generation. We achieve state-of-the-art dense video captioning performance on ActivityNet Captions, YouCook2 and YouMakeup, and competitive performance on several other language generation and understanding tasks. Our method also achieved 1st place in both the MTVG and MDVC tasks of the PIC 4th Challenge. ",
    "url": "https://arxiv.org/abs/2303.06378",
    "authors": [
      "Teng Wang",
      "Jinrui Zhang",
      "Feng Zheng",
      "Wenhao Jiang",
      "Ran Cheng",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06379",
    "title": "TaylorAECNet: A Taylor Style Neural Network for Full-Band Echo  Cancellation",
    "abstract": "This paper describes aecX team's entry to the ICASSP 2023 acoustic echo cancellation (AEC) challenge. Our system consists of an adaptive filter and a proposed full-band Taylor-style acoustic echo cancellation neural network (TaylorAECNet) as a post-filter. Specifically, we leverage the recent advances in Taylor expansion based decoupling-style interpretable speech enhancement and explore its feasibility in the AEC task. Our TaylorAECNet based approach achieves an overall mean opinion score (MOS) of 4.241, a word accuracy (WAcc) ratio of 0.767, and ranks 5th in the non-personalized track (track 1). ",
    "url": "https://arxiv.org/abs/2303.06379",
    "authors": [
      "Weiming Xu",
      "Zhihao Guo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.06380",
    "title": "Semi-supervised Hand Appearance Recovery via Structure Disentanglement  and Dual Adversarial Discrimination",
    "abstract": "Enormous hand images with reliable annotations are collected through marker-based MoCap. Unfortunately, degradations caused by markers limit their application in hand appearance reconstruction. A clear appearance recovery insight is an image-to-image translation trained with unpaired data. However, most frameworks fail because there exists structure inconsistency from a degraded hand to a bare one. The core of our approach is to first disentangle the bare hand structure from those degraded images and then wrap the appearance to this structure with a dual adversarial discrimination (DAD) scheme. Both modules take full advantage of the semi-supervised learning paradigm: The structure disentanglement benefits from the modeling ability of ViT, and the translator is enhanced by the dual discrimination on both translation processes and translation results. Comprehensive evaluations have been conducted to prove that our framework can robustly recover photo-realistic hand appearance from diverse marker-contained and even object-occluded datasets. It provides a novel avenue to acquire bare hand appearance data for other downstream learning problems.The codes will be publicly available at https://www.yangangwang.com ",
    "url": "https://arxiv.org/abs/2303.06380",
    "authors": [
      "Zimeng Zhao",
      "Binghui Zuo",
      "Zhiyu Long",
      "Yangang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06388",
    "title": "FAC: 3D Representation Learning via Foreground Aware Feature Contrast",
    "abstract": "Contrastive learning has recently demonstrated great potential for unsupervised pre-training in 3D scene understanding tasks. However, most existing work randomly selects point features as anchors while building contrast, leading to a clear bias toward background points that often dominate in 3D scenes. Also, object awareness and foreground-to-background discrimination are neglected, making contrastive learning less effective. To tackle these issues, we propose a general foreground-aware feature contrast (FAC) framework to learn more effective point cloud representations in pre-training. FAC consists of two novel contrast designs to construct more effective and informative contrast pairs. The first is building positive pairs within the same foreground segment where points tend to have the same semantics. The second is that we prevent over-discrimination between 3D segments/objects and encourage foreground-to-background distinctions at the segment level with adaptive feature learning in a Siamese correspondence network, which adaptively learns feature correlations within and across point cloud views effectively. Visualization with point activation maps shows that our contrast pairs capture clear correspondences among foreground regions during pre-training. Quantitative experiments also show that FAC achieves superior knowledge transfer and data efficiency in various downstream 3D semantic segmentation and object detection tasks. ",
    "url": "https://arxiv.org/abs/2303.06388",
    "authors": [
      "Kangcheng Liu",
      "Aoran Xiao",
      "Xiaoqin Zhang",
      "Shijian Lu",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06407",
    "title": "Automatic Detection of Signalling Behaviour from Assistance Dogs as they  Forecast the Onset of Epileptic Seizures in Humans",
    "abstract": "Epilepsy or the occurrence of epileptic seizures, is one of the world's most well-known neurological disorders affecting millions of people. Seizures mostly occur due to non-coordinated electrical discharges in the human brain and may cause damage, including collapse and loss of consciousness. If the onset of a seizure can be forecast then the subject can be placed into a safe environment or position so that self-injury as a result of a collapse can be minimised. However there are no definitive methods to predict seizures in an everyday, uncontrolled environment. Previous studies have shown that pet dogs have the ability to detect the onset of an epileptic seizure by scenting the characteristic volatile organic compounds exuded through the skin by a subject prior a seizure occurring and there are cases where assistance dogs, trained to scent the onset of a seizure, can signal this to their owner/trainer. In this work we identify how we can automatically detect the signalling behaviours of trained assistance dogs and use this to alert their owner. Using data from an accelerometer worn on the collar of a dog we describe how we gathered movement data from 11 trained dogs for a total of 107 days as they exhibited signalling behaviour on command. We present the machine learning techniques used to accurately detect signalling from routine dog behaviour. This work is a step towards automatic alerting of the likely onset of an epileptic seizure from the signalling behaviour of a trained assistance dog. ",
    "url": "https://arxiv.org/abs/2303.06407",
    "authors": [
      "Hitesh Raju",
      "Ankit Sharma",
      "Aoife Smeaton",
      "Alan F. Smeaton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06410",
    "title": "Brain Diffuser: An End-to-End Brain Image to Brain Network Pipeline",
    "abstract": "Brain network analysis is essential for diagnosing and intervention for Alzheimer's disease (AD). However, previous research relied primarily on specific time-consuming and subjective toolkits. Only few tools can obtain the structural brain networks from brain diffusion tensor images (DTI). In this paper, we propose a diffusion based end-to-end brain network generative model Brain Diffuser that directly shapes the structural brain networks from DTI. Compared to existing toolkits, Brain Diffuser exploits more structural connectivity features and disease-related information by analyzing disparities in structural brain networks across subjects. For the case of Alzheimer's disease, the proposed model performs better than the results from existing toolkits on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. ",
    "url": "https://arxiv.org/abs/2303.06410",
    "authors": [
      "Xuhang Chen",
      "Baiying Lei",
      "Chi-Man Pun",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06418",
    "title": "Rethinking the Multi-view Stereo from the Perspective of Rendering-based  Augmentation",
    "abstract": "GigaMVS presents several challenges to existing Multi-View Stereo (MVS) algorithms for its large scale, complex occlusions, and gigapixel images. To address these problems, we first apply one of the state-of-the-art learning-based MVS methods, --MVSFormer, to overcome intractable scenarios such as textureless and reflections regions suffered by traditional PatchMatch methods, but it fails in a few large scenes' reconstructions. Moreover, traditional PatchMatch algorithms such as ACMMP, OpenMVS, and RealityCapture are leveraged to further improve the completeness in large scenes. Furthermore, to unify both advantages of deep learning methods and the traditional PatchMatch, we propose to render depth and color images to further fine-tune the MVSFormer model. Notably, we find that the MVS method could produce much better predictions through rendered images due to the coincident illumination, which we believe is significant for the MVS community. Thus, MVSFormer is capable of generalizing to large-scale scenes and complementarily solves the textureless reconstruction problem. Finally, we have assembled all point clouds mentioned above \\textit{except ones from RealityCapture} and ranked Top-1 on the competitive GigaReconstruction. ",
    "url": "https://arxiv.org/abs/2303.06418",
    "authors": [
      "Chenjie Cao",
      "Xinlin Ren",
      "Xiangyang Xue",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06419",
    "title": "Robust Learning from Explanations",
    "abstract": "Machine learning from explanations (MLX) is an approach to learning that uses human-provided annotations of relevant features for each input to ensure that model predictions are right for the right reasons. Existing MLX approaches rely heavily on a specific model interpretation approach and require strong parameter regularization to align model and human explanations, leading to sub-optimal performance. We recast MLX as an adversarial robustness problem, where human explanations specify a lower dimensional manifold from which perturbations can be drawn, and show both theoretically and empirically how this approach alleviates the need for strong parameter regularization. We consider various approaches to achieving robustness, leading to improved performance over prior MLX methods. Finally, we combine robustness with an earlier MLX method, yielding state-of-the-art results on both synthetic and real-world benchmarks. ",
    "url": "https://arxiv.org/abs/2303.06419",
    "authors": [
      "Juyeon Heo",
      "Vihari Piratla",
      "Matthew Wicker",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06425",
    "title": "Improving the Robustness of Deep Convolutional Neural Networks Through  Feature Learning",
    "abstract": "Deep convolutional neural network (DCNN for short) models are vulnerable to examples with small perturbations. Adversarial training (AT for short) is a widely used approach to enhance the robustness of DCNN models by data augmentation. In AT, the DCNN models are trained with clean examples and adversarial examples (AE for short) which are generated using a specific attack method, aiming to gain ability to defend themselves when facing the unseen AEs. However, in practice, the trained DCNN models are often fooled by the AEs generated by the novel attack methods. This naturally raises a question: can a DCNN model learn certain features which are insensitive to small perturbations, and further defend itself no matter what attack methods are presented. To answer this question, this paper makes a beginning effort by proposing a shallow binary feature module (SBFM for short), which can be integrated into any popular backbone. The SBFM includes two types of layers, i.e., Sobel layer and threshold layer. In Sobel layer, there are four parallel feature maps which represent horizontal, vertical, and diagonal edge features, respectively. And in threshold layer, it turns the edge features learnt by Sobel layer to the binary features, which then are feeded into the fully connected layers for classification with the features learnt by the backbone. We integrate SBFM into VGG16 and ResNet34, respectively, and conduct experiments on multiple datasets. Experimental results demonstrate, under FGSM attack with $\\epsilon=8/255$, the SBFM integrated models can achieve averagely 35\\% higher accuracy than the original ones, and in CIFAR-10 and TinyImageNet datasets, the SBFM integrated models can achieve averagely 75\\% classification accuracy. The work in this paper shows it is promising to enhance the robustness of DCNN models through feature learning. ",
    "url": "https://arxiv.org/abs/2303.06425",
    "authors": [
      "Jin Ding",
      "Jie-Chao Zhao",
      "Yong-Zhi Sun",
      "Ping Tan",
      "Ji-En Ma",
      "You-Tong Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06431",
    "title": "Anomaly Detection with Ensemble of Encoder and Decoder",
    "abstract": "Hacking and false data injection from adversaries can threaten power grids' everyday operations and cause significant economic loss. Anomaly detection in power grids aims to detect and discriminate anomalies caused by cyber attacks against the power system, which is essential for keeping power grids working correctly and efficiently. Different methods have been applied for anomaly detection, such as statistical methods and machine learning-based methods. Usually, machine learning-based methods need to model the normal data distribution. In this work, we propose a novel anomaly detection method by modeling the data distribution of normal samples via multiple encoders and decoders. Specifically, the proposed method maps input samples into a latent space and then reconstructs output samples from latent vectors. The extra encoder finally maps reconstructed samples to latent representations. During the training phase, we optimize parameters by minimizing the reconstruction loss and encoding loss. Training samples are re-weighted to focus more on missed correlations between features of normal data. Furthermore, we employ the long short-term memory model as encoders and decoders to test its effectiveness. We also investigate a meta-learning-based framework for hyper-parameter tuning of our approach. Experiment results on network intrusion and power system datasets demonstrate the effectiveness of our proposed method, where our models consistently outperform all baselines. ",
    "url": "https://arxiv.org/abs/2303.06431",
    "authors": [
      "Xijuan Sun",
      "Di Wu",
      "Arnaud Zinflou",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06455",
    "title": "Graph Neural Network contextual embedding for Deep Learning on Tabular  Data",
    "abstract": "All industries are trying to leverage Artificial Intelligence (AI) based on their existing big data which is available in so called tabular form, where each record is composed of a number of heterogeneous continuous and categorical columns also known as features. Deep Learning (DL) has consituted a major breathrough for AI in fields related to human skills like natural language processing, but its applicability to tabular data has been more challenging. More classical Machine Learning (ML) models like tree-based ensemble ones usually perform better. In this manuscript a novel DL model that uses Graph Neural Network (GNN), more specifically Interaction Network (IN), for contextual embedding is introduced. Its results outperform those of the recently published survey with DL benchmark based on five public datasets, achieving also competitive results when compared to boosted-tree solutions. ",
    "url": "https://arxiv.org/abs/2303.06455",
    "authors": [
      "Mario Villaiz\u00e1n-Vallelado",
      "Matteo Salvatori",
      "Bel\u00e9n Carro Martinez",
      "Antonio Javier Sanchez Esguevillas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06456",
    "title": "NetworkNarratives: Data Tours for Visual Network Exploration and  Analysis",
    "abstract": "This paper introduces semi-automatic data tours to aid the exploration of complex networks. Exploring networks requires significant effort and expertise and can be time-consuming and challenging. Distinct from guidance and recommender systems for visual analytics, we provide a set of goal-oriented tours for network overview, ego-network analysis, community exploration, and other tasks. Based on interviews with five network analysts, we developed a user interface (NetworkNarratives) and 10 example tours. The interface allows analysts to navigate an interactive slideshow featuring facts about the network using visualizations and textual annotations. On each slide, an analyst can freely explore the network and specify nodes, links, or subgraphs as seed elements for follow-up tours. Two studies, comprising eight expert and 14 novice analysts, show that data tours reduce exploration effort, support learning about network exploration, and can aid the dissemination of analysis results. NetworkNarratives is available online, together with detailed illustrations for each tour. ",
    "url": "https://arxiv.org/abs/2303.06456",
    "authors": [
      "Wenchao Li",
      "Sarah Sch\u00f6ttler",
      "James Scott-Brown",
      "Yun Wang",
      "Siming Chen",
      "Huamin Qu",
      "Benjamin Bach"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.06468",
    "title": "Accurate Prediction of Global Mean Temperature through Data  Transformation Techniques",
    "abstract": "It is important to predict how the Global Mean Temperature (GMT) will evolve in the next few decades. The ability to predict historical data is a necessary first step toward the actual goal of making long-range forecasts. This paper examines the advantage of statistical and simpler Machine Learning (ML) methods instead of directly using complex ML algorithms and Deep Learning Neural Networks (DNN). Often neglected data transformation methods prior to applying different algorithms have been used as a means of improving predictive accuracy. The GMT time series is treated both as a univariate time series and also cast as a regression problem. Some steps of data transformations were found to be effective. Various simple ML methods did as well or better than the more well-known ones showing merit in trying a large bouquet of algorithms as a first step. Fifty-six algorithms were subject to Box-Cox, Yeo-Johnson, and first-order differencing and compared with the absence of them. Predictions for the annual GMT testing data were better than that published so far, with the lowest RMSE value of 0.02 $^\\circ$C. RMSE for five-year mean GMT values for the test data ranged from 0.00002 to 0.00036 $^\\circ$C. ",
    "url": "https://arxiv.org/abs/2303.06468",
    "authors": [
      "Debdarsan Niyogi",
      "J. Srinivasan"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06471",
    "title": "Multimodal Data Integration for Oncology in the Era of Deep Neural  Networks: A Review",
    "abstract": "Cancer has relational information residing at varying scales, modalities, and resolutions of the acquired data, such as radiology, pathology, genomics, proteomics, and clinical records. Integrating diverse data types can improve the accuracy and reliability of cancer diagnosis and treatment. There can be disease-related information that is too subtle for humans or existing technological tools to discern visually. Traditional methods typically focus on partial or unimodal information about biological systems at individual scales and fail to encapsulate the complete spectrum of the heterogeneous nature of data. Deep neural networks have facilitated the development of sophisticated multimodal data fusion approaches that can extract and integrate relevant information from multiple sources. Recent deep learning frameworks such as Graph Neural Networks (GNNs) and Transformers have shown remarkable success in multimodal learning. This review article provides an in-depth analysis of the state-of-the-art in GNNs and Transformers for multimodal data fusion in oncology settings, highlighting notable research studies and their findings. We also discuss the foundations of multimodal learning, inherent challenges, and opportunities for integrative learning in oncology. By examining the current state and potential future developments of multimodal data integration in oncology, we aim to demonstrate the promising role that multimodal neural networks can play in cancer prevention, early detection, and treatment through informed oncology practices in personalized settings. ",
    "url": "https://arxiv.org/abs/2303.06471",
    "authors": [
      "Asim Waqas",
      "Aakash Tripathi",
      "Ravi P. Ramachandran",
      "Paul Stewart",
      "Ghulam Rasool"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06478",
    "title": "PyPoll: A python library automating mining of networks, discussions and  polarization on Twitter",
    "abstract": "Today online social networks have a high impact in our society as more and more people use them for communicating with each other, express their opinions, participating in public discussions, etc. In particular, Twitter is one of the most popular social network platforms people mainly use for political discussions. This attracted the interest of many research studies that analyzed social phenomena on Twitter, by collecting data, analysing communication patterns, and exploring the structure of user networks. While previous works share many common methodologies for data collection and analysis, these are mainly re-implemented every time by researchers in a custom way. In this paper, we introduce PyPoll an open-source Python library that operationalizes common analysis tasks for Twitter discussions. With PyPoll users can perform Twitter graph mining, calculate the polarization index and generate interactive visualizations without needing third-party tools. We believe that PyPoll can help researchers automate their tasks by giving them methods that are easy to use. Also, we demonstrate the use of the library by presenting two use cases; the PyPoll visualization app, an online application for graph visualizing and sharing, and the Political Lighthouse, a Web portal for displaying the polarization in various political topics on Twitter. ",
    "url": "https://arxiv.org/abs/2303.06478",
    "authors": [
      "Dimitrios Panteleimon Giakatos",
      "Pavlos Sermpezis",
      "Athena Vakali"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.06484",
    "title": "Generalizing and Decoupling Neural Collapse via Hyperspherical  Uniformity Gap",
    "abstract": "The neural collapse (NC) phenomenon describes an underlying geometric symmetry for deep neural networks, where both deeply learned features and classifiers converge to a simplex equiangular tight frame. It has been shown that both cross-entropy loss and mean square error can provably lead to NC. We remove NC's key assumption on the feature dimension and the number of classes, and then present a generalized neural collapse (GNC) hypothesis that effectively subsumes the original NC. Inspired by how NC characterizes the training target of neural networks, we decouple GNC into two objectives: minimal intra-class variability and maximal inter-class separability. We then use hyperspherical uniformity (which characterizes the degree of uniformity on the unit hypersphere) as a unified framework to quantify these two objectives. Finally, we propose a general objective -- hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical uniformity. HUG not only provably converges to GNC, but also decouples GNC into two separate objectives. Unlike cross-entropy loss that couples intra-class compactness and inter-class separability, HUG enjoys more flexibility and serves as a good alternative loss function. Empirical results show that HUG works well in terms of generalization and robustness. ",
    "url": "https://arxiv.org/abs/2303.06484",
    "authors": [
      "Weiyang Liu",
      "Longhui Yu",
      "Adrian Weller",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.06486",
    "title": "SHIELD: An Adaptive and Lightweight Defense against the Remote Power  Side-Channel Attacks on Multi-tenant FPGAs",
    "abstract": "Dynamic partial reconfiguration enables multi-tenancy in cloud-based FPGAs, which presents security challenges for tenants, IPs, and data. Malicious users can exploit FPGAs for remote side-channel attacks (SCAs), and shared on-chip resources can be used for attacks. Logical separation can ensure design integrity, but on-chip resources can still be exploited. Conventional SCA mitigation can help, but it requires significant effort, and bitstream checking techniques are not highly accurate. An active on-chip defense mechanism is needed for tenant confidentiality. Toward this, we propose a lightweight shielding technique utilizing ring oscillators (ROs) to protect applications against remote power SCA. Unlike existing RO-based approaches, in our methodology, an offline pre-processing stage is proposed to carefully configure power monitors and an obfuscating circuit concerning the resource constraints of the board. Detection of power fluctuations due to application execution enables the obfuscating circuit to flatten the power consumption trace. To evaluate the effectiveness of the proposed SHIELD, we implemented it on a Xilinx Zynq-7000 FPGA board executing an RSA encryption algorithm. Due to the SHIELD, the number of traces required to extract the encryption key is increased by 166x, making an attack extremely hard at run-time. Note that the proposed SHIELD does not require any modification in the target application. Our methodology also shows up to 54% less power consumption and up to 26% less area overhead than the state-of-the-art random noise-addition-based defense. ",
    "url": "https://arxiv.org/abs/2303.06486",
    "authors": [
      "Mahya Morid Ahmadi",
      "Faiq Khalid",
      "Radha Vaidya",
      "Florian Kriebel",
      "Andreas Steininger",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.06500",
    "title": "Diffusion-Based Hierarchical Multi-Label Object Detection to Analyze  Panoramic Dental X-rays",
    "abstract": "Due to the necessity for precise treatment planning, the use of panoramic X-rays to identify different dental diseases has tremendously increased. Although numerous ML models have been developed for the interpretation of panoramic X-rays, there has not been an end-to-end model developed that can identify problematic teeth with dental enumeration and associated diagnoses at the same time. To develop such a model, we structure the three distinct types of annotated data hierarchically following the FDI system, the first labeled with only quadrant, the second labeled with quadrant-enumeration, and the third fully labeled with quadrant-enumeration-diagnosis. To learn from all three hierarchies jointly, we introduce a novel diffusion-based hierarchical multi-label object detection framework by adapting a diffusion-based method that formulates object detection as a denoising diffusion process from noisy boxes to object boxes. Specifically, to take advantage of the hierarchically annotated data, our method utilizes a novel noisy box manipulation technique by adapting the denoising process in the diffusion network with the inference from the previously trained model in hierarchical order. We also utilize a multi-label object detection method to learn efficiently from partial annotations and to give all the needed information about each abnormal tooth for treatment planning. Experimental results show that our method significantly outperforms state-of-the-art object detection methods, including RetinaNet, Faster R-CNN, DETR, and DiffusionDet for the analysis of panoramic X-rays, demonstrating the great potential of our method for hierarchically and partially annotated datasets. The code and the data are available at: https://github.com/ibrahimethemhamamci/HierarchicalDet. ",
    "url": "https://arxiv.org/abs/2303.06500",
    "authors": [
      "Ibrahim Ethem Hamamci",
      "Sezgin Er",
      "Enis Simsar",
      "Anjany Sekuboyina",
      "Mustafa Gundogar",
      "Bernd Stadlinger",
      "Albert Mehl",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06504",
    "title": "Normal-guided Garment UV Prediction for Human Re-texturing",
    "abstract": "Clothes undergo complex geometric deformations, which lead to appearance changes. To edit human videos in a physically plausible way, a texture map must take into account not only the garment transformation induced by the body movements and clothes fitting, but also its 3D fine-grained surface geometry. This poses, however, a new challenge of 3D reconstruction of dynamic clothes from an image or a video. In this paper, we show that it is possible to edit dressed human images and videos without 3D reconstruction. We estimate a geometry aware texture map between the garment region in an image and the texture space, a.k.a, UV map. Our UV map is designed to preserve isometry with respect to the underlying 3D surface by making use of the 3D surface normals predicted from the image. Our approach captures the underlying geometry of the garment in a self-supervised way, requiring no ground truth annotation of UV maps and can be readily extended to predict temporally coherent UV maps. We demonstrate that our method outperforms the state-of-the-art human UV map estimation approaches on both real and synthetic data. ",
    "url": "https://arxiv.org/abs/2303.06504",
    "authors": [
      "Yasamin Jafarian",
      "Tuanfeng Y. Wang",
      "Duygu Ceylan",
      "Jimei Yang",
      "Nathan Carr",
      "Yi Zhou",
      "Hyun Soo Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06510",
    "title": "E2CoPre: Energy Efficient and Cooperative Collision Avoidance for UAV  Swarms with Trajectory Prediction",
    "abstract": "This paper addresses the collision avoidance problem of UAV swarms in three-dimensional (3D) space. The key challenges are energy efficiency and cooperation of swarm members. We propose to combine Artificial Potential Field (APF) with Particle Swarm Planning (PSO). APF provides environmental awareness and implicit coordination to UAVs. PSO searches for the optimal trajectories for each UAV in terms of safety and energy efficiency by minimizing a fitness function. The fitness function exploits the advantages of the Active Contour Model in image processing for trajectory planning. Lastly, vehicle-to-vehicle collisions are detected in advance based on trajectory prediction and are resolved by cooperatively adjusting the altitude of UAVs. Simulation results demonstrate that our method can save up to 80\\% of energy compared to state-of-the-art schemes. ",
    "url": "https://arxiv.org/abs/2303.06510",
    "authors": [
      "Shuangyao Huang",
      "Haibo Zhang",
      "Zhiyi Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.06513",
    "title": "Detection of DDoS Attacks in Software Defined Networking Using Machine  Learning Models",
    "abstract": "The concept of Software Defined Networking (SDN) represents a modern approach to networking that separates the control plane from the data plane through network abstraction, resulting in a flexible, programmable and dynamic architecture compared to traditional networks. The separation of control and data planes has led to a high degree of network resilience, but has also given rise to new security risks, including the threat of distributed denial-of-service (DDoS) attacks, which pose a new challenge in the SDN environment. In this paper, the effectiveness of using machine learning algorithms to detect distributed denial-of-service (DDoS) attacks in software-defined networking (SDN) environments is investigated. Four algorithms, including Random Forest, Decision Tree, Support Vector Machine, and XGBoost, were tested on the CICDDoS2019 dataset, with the timestamp feature dropped among others. Performance was assessed by measures of accuracy, recall, accuracy, and F1 score, with the Random Forest algorithm having the highest accuracy, at 68.9%. The results indicate that ML-based detection is a more accurate and effective method for identifying DDoS attacks in SDN, despite the computational requirements of non-parametric algorithms. ",
    "url": "https://arxiv.org/abs/2303.06513",
    "authors": [
      "Ahmad Hamarshe",
      "Huthaifa I. Ashqar",
      "Mohammad Hamarsheh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.06514",
    "title": "Credit Card Fraud Detection Using Enhanced Random Forest Classifier for  Imbalanced Data",
    "abstract": "The credit card has become the most popular payment method for both online and offline transactions. The necessity to create a fraud detection algorithm to precisely identify and stop fraudulent activity arises as a result of both the development of technology and the rise in fraud cases. This paper implements the random forest (RF) algorithm to solve the issue in the hand. A dataset of credit card transactions was used in this study. The main problem when dealing with credit card fraud detection is the imbalanced dataset in which most of the transaction are non-fraud ones. To overcome the problem of the imbalanced dataset, the synthetic minority over-sampling technique (SMOTE) was used. Implementing the hyperparameters technique to enhance the performance of the random forest classifier. The results showed that the RF classifier gained an accuracy of 98% and about 98% of F1-score value, which is promising. We also believe that our model is relatively easy to apply and can overcome the issue of imbalanced data for fraud detection applications. ",
    "url": "https://arxiv.org/abs/2303.06514",
    "authors": [
      "AlsharifHasan Mohamad Aburbeian",
      "Huthaifa I. Ashqar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.06516",
    "title": "Opening Up the Neural Network Classifier for Shap Score Computation",
    "abstract": "We address the problem of efficiently computing Shap explanation scores for classifications with machine learning models. With this goal, we show the transformation of binary neural networks (BNNs) for classification into deterministic and decomposable Boolean circuits, for which knowledge compilation techniques are used. The resulting circuit is treated as an open-box model, to compute Shap scores by means of a recent efficient algorithm for this class of circuits. Detailed experiments show a considerable gain in performance in comparison with computing Shap directly on the BNN treated as a black-box model. ",
    "url": "https://arxiv.org/abs/2303.06516",
    "authors": [
      "Leopoldo Bertossi",
      "Jorge E. Leon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06556",
    "title": "DOMINO: Visual Causal Reasoning with Time-Dependent Phenomena",
    "abstract": "Current work on using visual analytics to determine causal relations among variables has mostly been based on the concept of counterfactuals. As such the derived static causal networks do not take into account the effect of time as an indicator. However, knowing the time delay of a causal relation can be crucial as it instructs how and when actions should be taken. Yet, similar to static causality, deriving causal relations from observational time-series data, as opposed to designed experiments, is not a straightforward process. It can greatly benefit from human insight to break ties and resolve errors. We hence propose a set of visual analytics methods that allow humans to participate in the discovery of causal relations associated with windows of time delay. Specifically, we leverage a well-established method, logic-based causality, to enable analysts to test the significance of potential causes and measure their influences toward a certain effect. Furthermore, since an effect can be a cause of other effects, we allow users to aggregate different temporal cause-effect relations found with our method into a visual flow diagram to enable the discovery of temporal causal networks. To demonstrate the effectiveness of our methods we constructed a prototype system named DOMINO and showcase it via a number of case studies using real-world datasets. Finally, we also used DOMINO to conduct several evaluations with human analysts from different science domains in order to gain feedback on the utility of our system in practical scenarios. ",
    "url": "https://arxiv.org/abs/2303.06556",
    "authors": [
      "Jun Wang",
      "Klaus Mueller"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06561",
    "title": "Phase Diagram of Initial Condensation for Two-layer Neural Networks",
    "abstract": "The phenomenon of distinct behaviors exhibited by neural networks under varying scales of initialization remains an enigma in deep learning research. In this paper, based on the earlier work by Luo et al.~\\cite{luo2021phase}, we present a phase diagram of initial condensation for two-layer neural networks. Condensation is a phenomenon wherein the weight vectors of neural networks concentrate on isolated orientations during the training process, and it is a feature in non-linear learning process that enables neural networks to possess better generalization abilities. Our phase diagram serves to provide a comprehensive understanding of the dynamical regimes of neural networks and their dependence on the choice of hyperparameters related to initialization. Furthermore, we demonstrate in detail the underlying mechanisms by which small initialization leads to condensation at the initial training stage. ",
    "url": "https://arxiv.org/abs/2303.06561",
    "authors": [
      "Zhengan Chen",
      "Yuqing Li",
      "Tao Luo",
      "Zhangchen Zhou",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.06565",
    "title": "Compressed Heterogeneous Graph for Abstractive Multi-Document  Summarization",
    "abstract": "Multi-document summarization (MDS) aims to generate a summary for a number of related documents. We propose HGSUM, an MDS model that extends an encoder-decoder architecture, to incorporate a heterogeneous graph to represent different semantic units (e.g., words and sentences) of the documents. This contrasts with existing MDS models which do not consider different edge types of graphs and as such do not capture the diversity of relationships in the documents. To preserve only key information and relationships of the documents in the heterogeneous graph, HGSUM uses graph pooling to compress the input graph. And to guide HGSUM to learn compression, we introduce an additional objective that maximizes the similarity between the compressed graph and the graph constructed from the ground-truth summary during training. HGSUM is trained end-to-end with graph similarity and standard cross-entropy objectives. Experimental results over MULTI-NEWS, WCEP-100, and ARXIV show that HGSUM outperforms state-of-the-art MDS models. The code for our model and experiments is available at: https://github.com/oaimli/HGSum. ",
    "url": "https://arxiv.org/abs/2303.06565",
    "authors": [
      "Miao Li",
      "Jianzhong Qi",
      "Jey Han Lau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06567",
    "title": "A Monkey Swing Counting Algorithm Based on Object Detection",
    "abstract": "This paper focuses on proposing a deep learning-based monkey swing counting algorithm. Nowadays, there are very few papers on monkey detection, and even fewer papers on monkey swing counting. This research focuses on this gap and attempts to count the number of monkeys swinging their heads by deep learning. This paper further extends the traditional target detection algorithm. By analyzing the results of object detection, we localize the monkey's actions over a period of time. This paper analyzes the task of counting monkey head swings, and proposes the standard that accurately describes a monkey swinging its head. Under the guidance of this standard, the head-swing count in 50 monkey movement videos in this paper has achieved 94%. ",
    "url": "https://arxiv.org/abs/2303.06567",
    "authors": [
      "Hao Chen",
      "Zhe-Ming Lu",
      "Jie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06569",
    "title": "Throughput of Freeway Networks under Ramp Metering Subject to Vehicle  Safety Constraints",
    "abstract": "Ramp metering is one of the most effective tools to combat traffic congestion. In this paper, we present a ramp metering policy for a network of freeways with arbitrary number of on- and off-ramps, merge, and diverge junctions. The proposed policy is designed at the microscopic level and takes into account vehicle following safety constraints. In addition, each on-ramp operates in cycles during which it releases vehicles as long as the number of releases does not exceed its queue size at the start of the cycle. Moreover, each on-ramp dynamically adjusts its release rate based on the traffic condition. To evaluate the performance of the policy, we analyze its throughput, which is characterized by the set of arrival rates for which the queue sizes at all on-ramps remain bounded in expectation. We show that the proposed policy is able to maximize the throughput if the merging speed at all the on-ramps is equal to the free flow speed and the network has no merge junction. We provide simulations to illustrate the performance of our policy and compare it with a well-known policy from the literature. ",
    "url": "https://arxiv.org/abs/2303.06569",
    "authors": [
      "Milad Pooladsanj",
      "Ketan Savla",
      "Petros A. Ioannou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2303.06595",
    "title": "A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein  in Graph Data",
    "abstract": "In this work, we present the Bregman Alternating Projected Gradient (BAPG) method, a single-loop algorithm that offers an approximate solution to the Gromov-Wasserstein (GW) distance. We introduce a novel relaxation technique that balances accuracy and computational efficiency, albeit with some compromises in the feasibility of the coupling map. Our analysis is based on the observation that the GW problem satisfies the Luo-Tseng error bound condition, which relates to estimating the distance of a point to the critical point set of the GW problem based on the optimality residual. This observation allows us to provide an approximation bound for the distance between the fixed-point set of BAPG and the critical point set of GW. Moreover, under a mild technical assumption, we can show that BAPG converges to its fixed point set. The effectiveness of BAPG has been validated through comprehensive numerical experiments in graph alignment and partition tasks, where it outperforms existing methods in terms of both solution quality and wall-clock time. ",
    "url": "https://arxiv.org/abs/2303.06595",
    "authors": [
      "Jiajin Li",
      "Jianheng Tang",
      "Lemin Kong",
      "Huikang Liu",
      "Jia Li",
      "Anthony Man-Cho So",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.06607",
    "title": "Minimal Sleep Delay Driven Aggregation Tree Construction in IoT Sensor  Networks",
    "abstract": "Data aggregation is a fundamental technique in wireless sensor networks (WSNs) in which sensory data collected by intermediate nodes is merged by in-network computation using maximum, average, or sum functions. Because sensors run on batteries, energy conservation is a critical issue. Duty cycle is a well-known energy-saving mechanism in WSNs, but it causes data aggregation latency to increase. As a result, the use of multichannel technology allows more sensor nodes to send data simultaneously, reducing data aggregation latency. We investigate the minimum latency aggregation scheduling problem in multi-channel duty-cycled IoT sensor networks in this paper. We propose a scheduling scheme that first constructs an aggregation tree based on sensor node sleep delay, then improves parallel transmissions by scheduling all eligible nodes in the constructed aggregation tree to enhance data aggregation. Based on extensive simulation experiments, our proposed approach lowers the aggregation delay by at most 61% compared to a novel approach. ",
    "url": "https://arxiv.org/abs/2303.06607",
    "authors": [
      "Van-Vi Vo",
      "Duc-Tai Le",
      "Hyunseung Choo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.06609",
    "title": "Reconstructing Graphs from Connected Triples",
    "abstract": "We introduce a new model of indeterminacy in graphs: instead of specifying all the edges of the graph, the input contains all triples of vertices that form a connected subgraph. In general, different (labelled) graphs may have the same set of connected triples, making unique reconstruction of the original graph from the triples impossible. We identify some families of graphs (including triangle-free graphs) for which all graphs have a different set of connected triples. We also give algorithms that reconstruct a graph from a set of triples, and for testing if this reconstruction is unique. Finally, we study a possible extension of the model in which the subsets of size $k$ that induce a connected graph are given for larger (fixed) values of $k$. ",
    "url": "https://arxiv.org/abs/2303.06609",
    "authors": [
      "Paul Bastide",
      "Linda Cook",
      "Jeff Erickson",
      "Carla Groenland",
      "Marc van Kreveld",
      "Isja Mannens",
      "Jordi L. Vermeulen"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.06632",
    "title": "Focus on Change: Mood Prediction by Learning Emotion Changes via  Spatio-Temporal Attention",
    "abstract": "While emotion and mood interchangeably used, they differ in terms of duration, intensity and attributes. Even as multiple psychology studies examine the mood-emotion relationship, mood prediction has barely been studied. Recent machine learning advances such as the attention mechanism to focus on salient parts of the input data, have only been applied to infer emotions rather than mood. We perform mood prediction by incorporating both mood and emotion change information. We additionally explore spatial and temporal attention, and parallel/sequential arrangements of the spatial and temporal attention modules to improve mood prediction performance. To examine generalizability of the proposed method, we evaluate models trained on the AFEW dataset with EMMA. Experiments reveal that (a) emotion change information is inherently beneficial to mood prediction, and (b) prediction performance improves with the integration of sequential and parallel spatial-temporal attention modules. ",
    "url": "https://arxiv.org/abs/2303.06632",
    "authors": [
      "Soujanya Narayana",
      "Ramanathan Subramanian",
      "Ibrahim Radwan",
      "Roland Goecke"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.06640",
    "title": "Challenges facing the explainability of age prediction models: case  study for two modalities",
    "abstract": "The prediction of age is a challenging task with various practical applications in high-impact fields like the healthcare domain or criminology. Despite the growing number of models and their increasing performance, we still know little about how these models work. Numerous examples of failures of AI systems show that performance alone is insufficient, thus, new methods are needed to explore and explain the reasons for the model's predictions. In this paper, we investigate the use of Explainable Artificial Intelligence (XAI) for age prediction focusing on two specific modalities, EEG signal and lung X-rays. We share predictive models for age to facilitate further research on new techniques to explain models for these modalities. ",
    "url": "https://arxiv.org/abs/2303.06640",
    "authors": [
      "Mikolaj Spytek",
      "Weronika Hryniewska-Guzik",
      "Jaroslaw Zygierewicz",
      "Jacek Rogala",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.06641",
    "title": "Adaptive Local Adversarial Attacks on 3D Point Clouds for Augmented  Reality",
    "abstract": "As the key technology of augmented reality (AR), 3D recognition and tracking are always vulnerable to adversarial examples, which will cause serious security risks to AR systems. Adversarial examples are beneficial to improve the robustness of the 3D neural network model and enhance the stability of the AR system. At present, most 3D adversarial attack methods perturb the entire point cloud to generate adversarial examples, which results in high perturbation costs and difficulty in reconstructing the corresponding real objects in the physical world. In this paper, we propose an adaptive local adversarial attack method (AL-Adv) on 3D point clouds to generate adversarial point clouds. First, we analyze the vulnerability of the 3D network model and extract the salient regions of the input point cloud, namely the vulnerable regions. Second, we propose an adaptive gradient attack algorithm that targets vulnerable regions. The proposed attack algorithm adaptively assigns different disturbances in different directions of the three-dimensional coordinates of the point cloud. Experimental results show that our proposed method AL-Adv achieves a higher attack success rate than the global attack method. Specifically, the adversarial examples generated by the AL-Adv demonstrate good imperceptibility and small generation costs. ",
    "url": "https://arxiv.org/abs/2303.06641",
    "authors": [
      "Weiquan Liu",
      "Shijun Zheng",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06644",
    "title": "Mitigating the Effect of Class Imbalance in Fault Localization Using  Context-aware Generative Adversarial Network",
    "abstract": "Fault localization (FL) analyzes the execution information of a test suite to pinpoint the root cause of a failure. The class imbalance of a test suite, i.e., the imbalanced class proportion between passing test cases (i.e., majority class) and failing ones (i.e., minority class), adversely affects FL effectiveness. To mitigate the effect of class imbalance in FL, we propose CGAN4FL: a data augmentation approach using Context-aware Generative Adversarial Network for Fault Localization. Specifically, CGAN4FL uses program dependencies to construct a failure-inducing context showing how a failure is caused. Then, CGAN4FL leverages a generative adversarial network to analyze the failure-inducing context and synthesize the minority class of test cases (i.e., failing test cases). Finally, CGAN4FL augments the synthesized data into original test cases to acquire a class-balanced dataset for FL. Our experiments show that CGAN4FL significantly improves FL effectiveness, e.g., promoting MLP-FL by 200.00%, 25.49%, and 17.81% under the Top-1, Top-5, and Top-10 respectively. ",
    "url": "https://arxiv.org/abs/2303.06644",
    "authors": [
      "Yan Lei",
      "Tiantian Wen",
      "Huan Xie",
      "Lingfeng Fu",
      "Chunyan Liu",
      "Lei Xu",
      "Hongxia Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.06652",
    "title": "Interpreting Hidden Semantics in the Intermediate Layers of 3D Point  Cloud Classification Neural Network",
    "abstract": "Although 3D point cloud classification neural network models have been widely used, the in-depth interpretation of the activation of the neurons and layers is still a challenge. We propose a novel approach, named Relevance Flow, to interpret the hidden semantics of 3D point cloud classification neural networks. It delivers the class Relevance to the activated neurons in the intermediate layers in a back-propagation manner, and associates the activation of neurons with the input points to visualize the hidden semantics of each layer. Specially, we reveal that the 3D point cloud classification neural network has learned the plane-level and part-level hidden semantics in the intermediate layers, and utilize the normal and IoU to evaluate the consistency of both levels' hidden semantics. Besides, by using the hidden semantics, we generate the adversarial attack samples to attack 3D point cloud classifiers. Experiments show that our proposed method reveals the hidden semantics of the 3D point cloud classification neural network on ModelNet40 and ShapeNet, which can be used for the unsupervised point cloud part segmentation without labels and attacking the 3D point cloud classifiers. ",
    "url": "https://arxiv.org/abs/2303.06652",
    "authors": [
      "Weiquan Liu",
      "Minghao Liu",
      "Shijun Zheng",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06654",
    "title": "Twice Regularized Markov Decision Processes: The Equivalence between  Robustness and Regularization",
    "abstract": "Robust Markov decision processes (MDPs) aim to handle changing or partially known system dynamics. To solve them, one typically resorts to robust optimization methods. However, this significantly increases computational complexity and limits scalability in both learning and planning. On the other hand, regularized MDPs show more stability in policy learning without impairing time complexity. Yet, they generally do not encompass uncertainty in the model dynamics. In this work, we aim to learn robust MDPs using regularization. We first show that regularized MDPs are a particular instance of robust MDPs with uncertain reward. We thus establish that policy iteration on reward-robust MDPs can have the same time complexity as on regularized MDPs. We further extend this relationship to MDPs with uncertain transitions: this leads to a regularization term with an additional dependence on the value function. We then generalize regularized MDPs to twice regularized MDPs ($\\text{R}^2$ MDPs), i.e., MDPs with $\\textit{both}$ value and policy regularization. The corresponding Bellman operators enable us to derive planning and learning schemes with convergence and generalization guarantees, thus reducing robustness to regularization. We numerically show this two-fold advantage on tabular and physical domains, highlighting the fact that $\\text{R}^2$ preserves its efficacy in continuous environments. ",
    "url": "https://arxiv.org/abs/2303.06654",
    "authors": [
      "Esther Derman",
      "Yevgeniy Men",
      "Matthieu Geist",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06662",
    "title": "Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive  Machine Translation",
    "abstract": "Non-autoregressive translation (NAT) reduces the decoding latency but suffers from performance degradation due to the multi-modality problem. Recently, the structure of directed acyclic graph has achieved great success in NAT, which tackles the multi-modality problem by introducing dependency between vertices. However, training it with negative log-likelihood loss implicitly requires a strict alignment between reference tokens and vertices, weakening its ability to handle multiple translation modalities. In this paper, we hold the view that all paths in the graph are fuzzily aligned with the reference sentence. We do not require the exact alignment but train the model to maximize a fuzzy alignment score between the graph and reference, which takes captured translations in all modalities into account. Extensive experiments on major WMT benchmarks show that our method substantially improves translation performance and increases prediction confidence, setting a new state of the art for NAT on the raw training data. ",
    "url": "https://arxiv.org/abs/2303.06662",
    "authors": [
      "Zhengrui Ma",
      "Chenze Shao",
      "Shangtong Gui",
      "Min Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.06664",
    "title": "Adv-Bot: Realistic Adversarial Botnet Attacks against Network Intrusion  Detection Systems",
    "abstract": "Due to the numerous advantages of machine learning (ML) algorithms, many applications now incorporate them. However, many studies in the field of image classification have shown that MLs can be fooled by a variety of adversarial attacks. These attacks take advantage of ML algorithms' inherent vulnerability. This raises many questions in the cybersecurity field, where a growing number of researchers are recently investigating the feasibility of such attacks against machine learning-based security systems, such as intrusion detection systems. The majority of this research demonstrates that it is possible to fool a model using features extracted from a raw data source, but it does not take into account the real implementation of such attacks, i.e., the reverse transformation from theory to practice. The real implementation of these adversarial attacks would be influenced by various constraints that would make their execution more difficult. As a result, the purpose of this study was to investigate the actual feasibility of adversarial attacks, specifically evasion attacks, against network-based intrusion detection systems (NIDS), demonstrating that it is entirely possible to fool these ML-based IDSs using our proposed adversarial algorithm while assuming as many constraints as possible in a black-box setting. In addition, since it is critical to design defense mechanisms to protect ML-based IDSs against such attacks, a defensive scheme is presented. Realistic botnet traffic traces are used to assess this work. Our goal is to create adversarial botnet traffic that can avoid detection while still performing all of its intended malicious functionality. ",
    "url": "https://arxiv.org/abs/2303.06664",
    "authors": [
      "Islam Debicha",
      "Benjamin Cochez",
      "Tayeb Kenaza",
      "Thibault Debatty",
      "Jean-Michel Dricot",
      "Wim Mees"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06670",
    "title": "DINO-MC: Self-supervised Contrastive Learning for Remote Sensing Imagery  with Multi-sized Local Crops",
    "abstract": "Due to the costly nature of remote sensing image labeling and the large volume of available unlabeled imagery, self-supervised methods that can learn feature representations without manual annotation have received great attention. While prior works have explored self-supervised learning in remote sensing tasks, pretext tasks based on local-global view alignment remain underexplored. Inspired by DINO, which employs an effective representation learning structure with knowledge distillation based on global-local view alignment, we formulate two pretext tasks for use in self-supervised learning on remote sensing imagery (SSLRS). Using these tasks, we explore the effectiveness of positive temporal contrast as well as multi-sized views on SSLRS. Moreover, we extend DINO and propose DINO-MC which uses local views of various sized crops instead of a single fixed size. Our experiments demonstrate that even when pre-trained on only 10% of the dataset, DINO-MC performs on par or better than existing state of the art SSLRS methods on multiple remote sensing tasks, while using less computational resources. All codes, models and results are available at https://github.com/WennyXY/DINO-MC. ",
    "url": "https://arxiv.org/abs/2303.06670",
    "authors": [
      "Xinye Wanyan",
      "Sachith Seneviratne",
      "Shuchang Shen",
      "Michael Kirley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06671",
    "title": "An extension of the approximate component mode synthesis method to the  heterogeneous Helmholtz equation",
    "abstract": "An extension of the approximate component mode synthesis (ACMS) method to the heterogeneous Helmholtz equation is proposed. The ACMS method has originally been introduced by Hetmaniuk and Lehoucq as a multiscale method to solve elliptic partial differential equations. The ACMS method uses a domain decomposition to separate the numerical approximation by splitting the variational problem into two independent parts: local Helmholtz problems and a global interface problem. While the former are naturally local and decoupled such that they can be easily solved in parallel, the latter requires the construction of suitable local basis functions relying on local eigenmodes and suitable extensions. We carry out a full error analysis of this approach focusing on the case where the domain decomposition is kept fixed, but the number of eigenfunctions is increased. This complements related results for elliptic problems where the focus is on the refinement of the domain decomposition instead. The theoretical results in this work are supported by numerical experiments verifying algebraic convergence for the interface problems. In certain, practically relevant cases, even exponential convergence for the local Helmholtz problems can be achieved without oversampling. ",
    "url": "https://arxiv.org/abs/2303.06671",
    "authors": [
      "Elena Giammatteo",
      "Alexander Heinlein",
      "Matthias Schlottbom"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.06673",
    "title": "SSGD: A smartphone screen glass dataset for defect detection",
    "abstract": "Interactive devices with touch screen have become commonly used in various aspects of daily life, which raises the demand for high production quality of touch screen glass. While it is desirable to develop effective defect detection technologies to optimize the automatic touch screen production lines, the development of these technologies suffers from the lack of publicly available datasets. To address this issue, we in this paper propose a dedicated touch screen glass defect dataset which includes seven types of defects and consists of 2504 images captured in various scenarios.All data are captured with professional acquisition equipment on the fixed workstation. Additionally, we benchmark the CNN- and Transformer-based object detection frameworks on the proposed dataset to demonstrate the challenges of defect detection on high-resolution images. Dataset and related code will be available at https://github.com/Yangr116/SSGDataset. ",
    "url": "https://arxiv.org/abs/2303.06673",
    "authors": [
      "Haonan Han",
      "Rui Yang",
      "Shuyan Li",
      "Runze Hu",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06675",
    "title": "LUKE-Graph: A Transformer-based Approach with Gated Relational Graph  Attention for Cloze-style Reading Comprehension",
    "abstract": "Incorporating prior knowledge can improve existing pre-training models in cloze-style machine reading and has become a new trend in recent studies. Notably, most of the existing models have integrated external knowledge graphs (KG) and transformer-based models, such as BERT into a unified data structure. However, selecting the most relevant ambiguous entities in KG and extracting the best subgraph remains a challenge. In this paper, we propose the LUKE-Graph, a model that builds a heterogeneous graph based on the intuitive relationships between entities in a document without using any external KG. We then use a Relational Graph Attention (RGAT) network to fuse the graph's reasoning information and the contextual representation encoded by the pre-trained LUKE model. In this way, we can take advantage of LUKE, to derive an entity-aware representation; and a graph model - to exploit relation-aware representation. Moreover, we propose Gated-RGAT by augmenting RGAT with a gating mechanism that regulates the question information for the graph convolution operation. This is very similar to human reasoning processing because they always choose the best entity candidate based on the question information. Experimental results demonstrate that the LUKE-Graph achieves state-of-the-art performance on the ReCoRD dataset with commonsense reasoning. ",
    "url": "https://arxiv.org/abs/2303.06675",
    "authors": [
      "Shima Foolad",
      "Kourosh Kiani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06682",
    "title": "DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for  Hyperspectral Image Restoration",
    "abstract": "Diffusion models have recently received a surge of interest due to their impressive performance for image restoration, especially in terms of noise robustness. However, existing diffusion-based methods are trained on a large amount of training data and perform very well in-distribution, but can be quite susceptible to distribution shift. This is especially inappropriate for data-starved hyperspectral image (HSI) restoration. To tackle this problem, this work puts forth a self-supervised diffusion model for HSI restoration, namely Denoising Diffusion Spatio-Spectral Model (\\texttt{DDS2M}), which works by inferring the parameters of the proposed Variational Spatio-Spectral Module (VS2M) during the reverse diffusion process, solely using the degraded HSI without any extra training data. In VS2M, a variational inference-based loss function is customized to enable the untrained spatial and spectral networks to learn the posterior distribution, which serves as the transitions of the sampling chain to help reverse the diffusion process. Benefiting from its self-supervised nature and the diffusion process, \\texttt{DDS2M} enjoys stronger generalization ability to various HSIs compared to existing diffusion-based methods and superior robustness to noise compared to existing HSI restoration methods. Extensive experiments on HSI denoising, noisy HSI completion and super-resolution on a variety of HSIs demonstrate \\texttt{DDS2M}'s superiority over the existing task-specific state-of-the-arts. ",
    "url": "https://arxiv.org/abs/2303.06682",
    "authors": [
      "Yuchun Miao",
      "Lefei Zhang",
      "Liangpei Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06689",
    "title": "Self-planning Code Generation with Large Language Model",
    "abstract": "Although large language models have demonstrated impressive ability in code generation, they are still struggling to address the complicated intent provided by humans. It is widely acknowledged that humans typically employ planning to decompose complex problems and schedule the solution steps prior to implementation. Thus we introduce planning into code generation to help the model understand complex intent and reduce the difficulty of problem solving. This paper proposes a self-planning code generation method with large language model, which consists of two phases, namely planning phase and implementation phase. Specifically, in the planning phase, the language model plans out the solution steps from the intent combined with in-context learning. Then it enters the implementation phase, where the model generates code step by step, guided by the solution steps. The effectiveness of self-planning code generation has been rigorously evaluated on multiple code generation datasets and the results have demonstrated a marked superiority over naive direct generation approaches with language model. The improvement in performance is substantial, highlighting the significance of self-planning in code generation tasks. ",
    "url": "https://arxiv.org/abs/2303.06689",
    "authors": [
      "Xue Jiang",
      "Yihong Dong",
      "Lecheng Wang",
      "Qiwei Shang",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.06697",
    "title": "Traj-MAE: Masked Autoencoders for Trajectory Prediction",
    "abstract": "Trajectory prediction has been a crucial task in building a reliable autonomous driving system by anticipating possible dangers. One key issue is to generate consistent trajectory predictions without colliding. To overcome the challenge, we propose an efficient masked autoencoder for trajectory prediction (Traj-MAE) that better represents the complicated behaviors of agents in the driving environment. Specifically, our Traj-MAE employs diverse masking strategies to pre-train the trajectory encoder and map encoder, allowing for the capture of social and temporal information among agents while leveraging the effect of environment from multiple granularities. To address the catastrophic forgetting problem that arises when pre-training the network with multiple masking strategies, we introduce a continual pre-training framework, which can help Traj-MAE learn valuable and diverse information from various strategies efficiently. Our experimental results in both multi-agent and single-agent settings demonstrate that Traj-MAE achieves competitive results with state-of-the-art methods and significantly outperforms our baseline model. ",
    "url": "https://arxiv.org/abs/2303.06697",
    "authors": [
      "Hao Chen",
      "Jiaze Wang",
      "Kun Shao",
      "Furui Liu",
      "Jianye Hao",
      "Chenyong Guan",
      "Guangyong Chen",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06714",
    "title": "BCSSN: Bi-direction Compact Spatial Separable Network for Collision  Avoidance in Autonomous Driving",
    "abstract": "Autonomous driving has been an active area of research and development, with various strategies being explored for decision-making in autonomous vehicles. Rule-based systems, decision trees, Markov decision processes, and Bayesian networks have been some of the popular methods used to tackle the complexities of traffic conditions and avoid collisions. However, with the emergence of deep learning, many researchers have turned towards CNN-based methods to improve the performance of collision avoidance. Despite the promising results achieved by some CNN-based methods, the failure to establish correlations between sequential images often leads to more collisions. In this paper, we propose a CNN-based method that overcomes the limitation by establishing feature correlations between regions in sequential images using variants of attention. Our method combines the advantages of CNN in capturing regional features with a bi-directional LSTM to enhance the relationship between different local areas. Additionally, we use an encoder to improve computational efficiency. Our method takes \"Bird's Eye View\" graphs generated from camera and LiDAR sensors as input, simulates the position (x, y) and head offset angle (Yaw) to generate future trajectories. Experiment results demonstrate that our proposed method outperforms existing vision-based strategies, achieving an average of only 3.7 collisions per 1000 miles of driving distance on the L5kit test set. This significantly improves the success rate of collision avoidance and provides a promising solution for autonomous driving. ",
    "url": "https://arxiv.org/abs/2303.06714",
    "authors": [
      "Haichuan Li",
      "Liguo Zhou",
      "Alois Knoll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06744",
    "title": "Ensemble Learning of Myocardial Displacements for Myocardial Infarction  Detection in Echocardiography",
    "abstract": "Early detection and localization of myocardial infarction (MI) can reduce the severity of cardiac damage through timely treatment interventions. In recent years, deep learning techniques have shown promise for detecting MI in echocardiographic images. However, there has been no examination of how segmentation accuracy affects MI classification performance and the potential benefits of using ensemble learning approaches. Our study investigates this relationship and introduces a robust method that combines features from multiple segmentation models to improve MI classification performance by leveraging ensemble learning. Our method combines myocardial segment displacement features from multiple segmentation models, which are then input into a typical classifier to estimate the risk of MI. We validated the proposed approach on two datasets: the public HMC-QU dataset (109 echocardiograms) for training and validation, and an E-Hospital dataset (60 echocardiograms) from a local clinical site in Vietnam for independent testing. Model performance was evaluated based on accuracy, sensitivity, and specificity. The proposed approach demonstrated excellent performance in detecting MI. The results showed that the proposed approach outperformed the state-of-the-art feature-based method. Further research is necessary to determine its potential use in clinical settings as a tool to assist cardiologists and technicians with objective assessments and reduce dependence on operator subjectivity. Our research codes are available on GitHub at https://github.com/vinuni-vishc/mi-detection-echo. ",
    "url": "https://arxiv.org/abs/2303.06744",
    "authors": [
      "Nguyen Tuan",
      "Phi Nguyen",
      "Dai Tran",
      "Hung Pham",
      "Quang Nguyen",
      "Thanh Le",
      "Hanh Van",
      "Bach Do",
      "Phuong Tran",
      "Vinh Le",
      "Thuy Nguyen",
      "Long Tran",
      "Hieu Pham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06746",
    "title": "DNN-Alias: Deep Neural Network Protection Against Side-Channel Attacks  via Layer Balancing",
    "abstract": "Extracting the architecture of layers of a given deep neural network (DNN) through hardware-based side channels allows adversaries to steal its intellectual property and even launch powerful adversarial attacks on the target system. In this work, we propose DNN-Alias, an obfuscation method for DNNs that forces all the layers in a given network to have similar execution traces, preventing attack models from differentiating between the layers. Towards this, DNN-Alias performs various layer-obfuscation operations, e.g., layer branching, layer deepening, etc, to alter the run-time traces while maintaining the functionality. DNN-Alias deploys an evolutionary algorithm to find the best combination of obfuscation operations in terms of maximizing the security level while maintaining a user-provided latency overhead budget. We demonstrate the effectiveness of our DNN-Alias technique by obfuscating the architecture of 700 randomly generated and obfuscated DNNs running on multiple Nvidia RTX 2080 TI GPU-based machines. Our experiments show that state-of-the-art side-channel architecture stealing attacks cannot extract the original DNN accurately. Moreover, we obfuscate the architecture of various DNNs, such as the VGG-11, VGG-13, ResNet-20, and ResNet-32 networks. Training the DNNs using the standard CIFAR10 dataset, we show that our DNN-Alias maintains the functionality of the original DNNs by preserving the original inference accuracy. Further, the experiments highlight that adversarial attack on obfuscated DNNs is unsuccessful. ",
    "url": "https://arxiv.org/abs/2303.06746",
    "authors": [
      "Mahya Morid Ahmadi",
      "Lilas Alrahis",
      "Ozgur Sinanoglu",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.06753",
    "title": "Module-Wise Network Quantization for 6D Object Pose Estimation",
    "abstract": "Many edge applications, such as collaborative robotics and spacecraft rendezvous, can benefit from 6D object pose estimation, but must do so on embedded platforms. Unfortunately, existing 6D pose estimation networks are typically too large for deployment in such situations and must therefore be compressed, while maintaining reliable performance. In this work, we present an approach to doing so by quantizing such networks. More precisely, we introduce a module-wise quantization strategy that, in contrast to uniform and mixed-precision quantization, accounts for the modular structure of typical 6D pose estimation frameworks. We demonstrate that uniquely compressing these modules outperforms uniform and mixed-precision quantization techniques. Moreover, our experiments evidence that module-wise quantization can lead to a significant accuracy boost. We showcase the generality of our approach using different datasets, quantization methodologies, and network architectures, including the recent ZebraPose. ",
    "url": "https://arxiv.org/abs/2303.06753",
    "authors": [
      "Saqib Javed",
      "Andrew Price",
      "Yinlin Hu",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.06779",
    "title": "Study of Multiuser Scheduling with Enhanced Greedy Techniques for  Multicell and Cell-Free Massive MIMO Networks",
    "abstract": "In this work, we investigate the sum-rate performance of multicell and cell-free massive MIMO systems using linear precoding and multiuser scheduling algorithms. We consider the use of a network-centric clustering approach to reduce the computational complexity of the techniques applied to the cell-free system. We then develop a greedy algorithm that considers multiple candidates for the subset of users to be scheduled and that approaches the performance of the optimal exhaustive search. We assess the proposed and existing scheduling algorithms in both multicell and cell-free networks with the same coverage area. Numerical results illustrate the sum-rate performance of the proposed scheduling algorithm against existing approaches. ",
    "url": "https://arxiv.org/abs/2303.06779",
    "authors": [
      "S. Mashdour",
      "R. C. de Lamare",
      "J. P. Sales"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.06797",
    "title": "Orthogonal Transform Domain Approaches for the Convolutional Layer",
    "abstract": "In this paper, we propose a set of transform-based neural network layers as an alternative to the $3\\times3$ Conv2D layers in Convolutional Neural Networks (CNNs). The proposed layers can be implemented based on orthogonal transforms such as Discrete Cosine Transform (DCT) and Hadamard transform (HT), and the biorthogonal Block Wavelet Transform (BWT). Convolutional filtering operations are performed in the transform domain using element-wise multiplications by taking advantage of the convolution theorems. Trainable soft-thresholding layers that remove noise in the transform domain bring nonlinearity to the transform domain layers. Compared to the Conv2D layer which is spatial-agnostic and channel-specific, the proposed layers are location-specific and channel-specific. The proposed layers reduce the number of parameters and multiplications significantly while improving the accuracy results of regular ResNets on the ImageNet-1K classification task. Furthermore, the proposed layers can be inserted with a batch normalization layer before the global average pooling layer in the conventional ResNets as an additional layer to improve classification accuracy with a negligible increase in the number of parameters and computational cost. ",
    "url": "https://arxiv.org/abs/2303.06797",
    "authors": [
      "Hongyi Pan",
      "Xin Zhu",
      "Salih Atici",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.06808",
    "title": "Boosting Source Code Learning with Data Augmentation: An Empirical Study",
    "abstract": "The next era of program understanding is being propelled by the use of machine learning to solve software problems. Recent studies have shown surprising results of source code learning, which applies deep neural networks (DNNs) to various critical software tasks, e.g., bug detection and clone detection. This success can be greatly attributed to the utilization of massive high-quality training data, and in practice, data augmentation, which is a technique used to produce additional training data, has been widely adopted in various domains, such as computer vision. However, in source code learning, data augmentation has not been extensively studied, and existing practice is limited to simple syntax-preserved methods, such as code refactoring. Essentially, source code is often represented in two ways, namely, sequentially as text data and structurally as graph data, when it is used as training data in source code learning. Inspired by these analogy relations, we take an early step to investigate whether data augmentation methods that are originally used for text and graphs are effective in improving the training quality of source code learning. To that end, we first collect and categorize data augmentation methods in the literature. Second, we conduct a comprehensive empirical study on four critical tasks and 11 DNN architectures to explore the effectiveness of 12 data augmentation methods (including code refactoring and 11 other methods for text and graph data). Our results identify the data augmentation methods that can produce more accurate and robust models for source code learning, including those based on mixup (e.g., SenMixup for texts and Manifold-Mixup for graphs), and those that slightly break the syntax of source code (e.g., random swap and random deletion for texts). ",
    "url": "https://arxiv.org/abs/2303.06808",
    "authors": [
      "Zeming Dong",
      "Qiang Hu",
      "Yuejun Guo",
      "Zhenya Zhang",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06815",
    "title": "Provable Convergence of Tensor Decomposition-Based Neural Network  Training",
    "abstract": "Advanced tensor decomposition, such as tensor train (TT), has been widely studied for tensor decomposition-based neural network (NN) training, which is one of the most common model compression methods. However, training NN with tensor decomposition always suffers significant accuracy loss and convergence issues. In this paper, a holistic framework is proposed for tensor decomposition-based NN training by formulating TT decomposition-based NN training as a nonconvex optimization problem. This problem can be solved by the proposed tensor block coordinate descent (tenBCD) method, which is a gradient-free algorithm. The global convergence of tenBCD to a critical point at a rate of O(1/k) is established with the Kurdyka {\\L}ojasiewicz (K{\\L}) property, where k is the number of iterations. The theoretical results can be extended to the popular residual neural networks (ResNets). The effectiveness and efficiency of our proposed framework are verified through an image classification dataset, where our proposed method can converge efficiently in training and prevent overfitting. ",
    "url": "https://arxiv.org/abs/2303.06815",
    "authors": [
      "Chenyang Li",
      "Bo Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.06817",
    "title": "Transformation-Invariant Network for Few-Shot Object Detection in Remote  Sensing Images",
    "abstract": "Object detection in remote sensing images relies on a large amount of labeled data for training. The growing new categories and class imbalance render exhaustive annotation non-scalable. Few-shot object detection~(FSOD) tackles this issue by meta-learning on seen base classes and then fine-tuning on novel classes with few labeled samples. However, the object's scale and orientation variations are particularly large in remote sensing images, thus posing challenges to existing few-shot object detection methods. To tackle these challenges, we first propose to integrate a feature pyramid network and use prototype features to highlight query features to improve upon existing FSOD methods. We refer to the modified FSOD as a Strong Baseline which is demonstrated to perform significantly better than the original baselines. To improve the robustness of orientation variation, we further propose a transformation-invariant network (TINet) to allow the network to be invariant to geometric transformations. Extensive experiments on three widely used remote sensing object detection datasets, i.e., NWPU VHR-10.v2, DIOR, and HRRSD demonstrated the effectiveness of the proposed method. Finally, we reproduced multiple FSOD methods for remote sensing images to create an extensive benchmark for follow-up works. ",
    "url": "https://arxiv.org/abs/2303.06817",
    "authors": [
      "Nanqing Liu",
      "Xun Xu",
      "Turgay Celik",
      "Zongxin Gan",
      "Heng-Chao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06818",
    "title": "Backdoor Defense via Deconfounded Representation Learning",
    "abstract": "Deep neural networks (DNNs) are recently shown to be vulnerable to backdoor attacks, where attackers embed hidden backdoors in the DNN model by injecting a few poisoned examples into the training dataset. While extensive efforts have been made to detect and remove backdoors from backdoored DNNs, it is still not clear whether a backdoor-free clean model can be directly obtained from poisoned datasets. In this paper, we first construct a causal graph to model the generation process of poisoned data and find that the backdoor attack acts as the confounder, which brings spurious associations between the input images and target labels, making the model predictions less reliable. Inspired by the causal understanding, we propose the Causality-inspired Backdoor Defense (CBD), to learn deconfounded representations for reliable classification. Specifically, a backdoored model is intentionally trained to capture the confounding effects. The other clean model dedicates to capturing the desired causal effects by minimizing the mutual information with the confounding representations from the backdoored model and employing a sample-wise re-weighting scheme. Extensive experiments on multiple benchmark datasets against 6 state-of-the-art attacks verify that our proposed defense method is effective in reducing backdoor threats while maintaining high accuracy in predicting benign samples. Further analysis shows that CBD can also resist potential adaptive attacks. The code is available at \\url{https://github.com/zaixizhang/CBD}. ",
    "url": "https://arxiv.org/abs/2303.06818",
    "authors": [
      "Zaixi Zhang",
      "Qi Liu",
      "Zhicai Wang",
      "Zepu Lu",
      "Qingyong Hu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06819",
    "title": "TranSG: Transformer-Based Skeleton Graph Prototype Contrastive Learning  with Structure-Trajectory Prompted Reconstruction for Person  Re-Identification",
    "abstract": "Person re-identification (re-ID) via 3D skeleton data is an emerging topic with prominent advantages. Existing methods usually design skeleton descriptors with raw body joints or perform skeleton sequence representation learning. However, they typically cannot concurrently model different body-component relations, and rarely explore useful semantics from fine-grained representations of body joints. In this paper, we propose a generic Transformer-based Skeleton Graph prototype contrastive learning (TranSG) approach with structure-trajectory prompted reconstruction to fully capture skeletal relations and valuable spatial-temporal semantics from skeleton graphs for person re-ID. Specifically, we first devise the Skeleton Graph Transformer (SGT) to simultaneously learn body and motion relations within skeleton graphs, so as to aggregate key correlative node features into graph representations. Then, we propose the Graph Prototype Contrastive learning (GPC) to mine the most typical graph features (graph prototypes) of each identity, and contrast the inherent similarity between graph representations and different prototypes from both skeleton and sequence levels to learn discriminative graph representations. Last, a graph Structure-Trajectory Prompted Reconstruction (STPR) mechanism is proposed to exploit the spatial and temporal contexts of graph nodes to prompt skeleton graph reconstruction, which facilitates capturing more valuable patterns and graph semantics for person re-ID. Empirical evaluations demonstrate that TranSG significantly outperforms existing state-of-the-art methods. We further show its generality under different graph modeling, RGB-estimated skeletons, and unsupervised scenarios. ",
    "url": "https://arxiv.org/abs/2303.06819",
    "authors": [
      "Haocong Rao",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06837",
    "title": "Adversarial Attacks to Direct Data-driven Control for Destabilization",
    "abstract": "This study investigates the vulnerability of direct data-driven control to adversarial attacks in the form of a small but sophisticated perturbation added to the original data. The directed gradient sign method (DGSM) is developed as a specific attack method, based on the fast gradient sign method (FGSM), which has originally been considered in image classification. DGSM uses the gradient of the eigenvalues of the resulting closed-loop system and crafts a perturbation in the direction where the system becomes less stable. It is demonstrated that the system can be destabilized by the attack, even if the original closed-loop system with the clean data has a large margin of stability. To increase the robustness against the attack, regularization methods that have been developed to deal with random disturbances are considered. Their effectiveness is evaluated by numerical experiments using an inverted pendulum model. ",
    "url": "https://arxiv.org/abs/2303.06837",
    "authors": [
      "Hampei Sasahara"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.06842",
    "title": "Scene Graph Generation from Hierarchical Relationship Reasoning",
    "abstract": "This paper describes a novel approach to deducing relationships between objects in a visual scene. It explicitly exploits an informative hierarchical structure that can be imposed to divide the object and relationship categories into disjoint super-categories. Specifically, our proposed scheme implements a Bayes prediction head to jointly predict the super-category or type of relationship between the two objects, along with the detailed relationship within that super-category. This design reduces the impact of class imbalance problems. We present experimental results on the Visual Genome and OpenImage V6 datasets showing that this factorized approach allows a relatively simple model to achieve competitive performance, especially on predicate classification and zero-shot tasks. ",
    "url": "https://arxiv.org/abs/2303.06842",
    "authors": [
      "Bowen Jiang",
      "Camillo J. Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06852",
    "title": "One-Shot Segmentation of Novel White Matter Tracts via Extensive Data  Augmentation",
    "abstract": "Deep learning based methods have achieved state-of-the-art performance for automated white matter (WM) tract segmentation. In these methods, the segmentation model needs to be trained with a large number of manually annotated scans, which can be accumulated throughout time. When novel WM tracts, i.e., tracts not included in the existing annotated WM tracts, are to be segmented, additional annotations of these novel WM tracts need to be collected. Since tract annotation is time-consuming and costly, it is desirable to make only a few annotations of novel WM tracts for training the segmentation model, and previous work has addressed this problem by transferring the knowledge learned for segmenting existing WM tracts to the segmentation of novel WM tracts. However, accurate segmentation of novel WM tracts can still be challenging in the one-shot setting, where only one scan is annotated for the novel WM tracts. In this work, we explore the problem of one-shot segmentation of novel WM tracts. Since in the one-shot setting the annotated training data is extremely scarce, based on the existing knowledge transfer framework, we propose to further perform extensive data augmentation for the single annotated scan, where synthetic annotated training data is produced. We have designed several different strategies that mask out regions in the single annotated scan for data augmentation. Our method was evaluated on public and in-house datasets. The experimental results show that our method improves the accuracy of one-shot segmentation of novel WM tracts. ",
    "url": "https://arxiv.org/abs/2303.06852",
    "authors": [
      "Wan Liu",
      "Qi Lu",
      "ZhiZheng Zhuo",
      "Yaou Liu",
      "Chuyang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06853",
    "title": "Representation Learning for Stack Overflow Posts: How Far are We?",
    "abstract": "The tremendous success of Stack Overflow has accumulated an extensive corpus of software engineering knowledge, thus motivating researchers to propose various solutions for analyzing its content.The performance of such solutions hinges significantly on the selection of representation model for Stack Overflow posts. As the volume of literature on Stack Overflow continues to burgeon, it highlights the need for a powerful Stack Overflow post representation model and drives researchers' interest in developing specialized representation models that can adeptly capture the intricacies of Stack Overflow posts. The state-of-the-art (SOTA) Stack Overflow post representation models are Post2Vec and BERTOverflow, which are built upon trendy neural networks such as convolutional neural network (CNN) and Transformer architecture (e.g., BERT). Despite their promising results, these representation methods have not been evaluated in the same experimental setting. To fill the research gap, we first empirically compare the performance of the representation models designed specifically for Stack Overflow posts (Post2Vec and BERTOverflow) in a wide range of related tasks, i.e., tag recommendation, relatedness prediction, and API recommendation. To find more suitable representation models for the posts, we further explore a diverse set of BERT-based models, including (1) general domain language models (RoBERTa and Longformer) and (2) language models built with software engineering-related textual artifacts (CodeBERT, GraphCodeBERT, and seBERT). However, it also illustrates the ``No Silver Bullet'' concept, as none of the models consistently wins against all the others. Inspired by the findings, we propose SOBERT, which employs a simple-yet-effective strategy to improve the best-performing model by continuing the pre-training phase with the textual artifact from Stack Overflow. ",
    "url": "https://arxiv.org/abs/2303.06853",
    "authors": [
      "Junda He",
      "Zhou Xin",
      "Bowen Xu",
      "Ting Zhang",
      "Kisub Kim",
      "Zhou Yang",
      "Ferdian Thung",
      "Ivana Irsan",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.06854",
    "title": "Robust Contrastive Language-Image Pretraining against Adversarial  Attacks",
    "abstract": "Contrastive vision-language representation learning has achieved state-of-the-art performance for zero-shot classification, by learning from millions of image-caption pairs crawled from the internet. However, the massive data that powers large multimodal models such as CLIP, makes them extremely vulnerable to various types of adversarial attacks, including targeted and backdoor data poisoning attacks. Despite this vulnerability, robust contrastive vision-language pretraining against adversarial attacks has remained unaddressed. In this work, we propose RoCLIP, the first effective method for robust pretraining {and fine-tuning} multimodal vision-language models. RoCLIP effectively breaks the association between poisoned image-caption pairs by considering a pool of random examples, and (1) matching every image with the text that is most similar to its caption in the pool, and (2) matching every caption with the image that is most similar to its image in the pool. Our extensive experiments show that our method renders state-of-the-art targeted data poisoning and backdoor attacks ineffective during pre-training or fine-tuning of CLIP. In particular, RoCLIP decreases the poison and backdoor attack success rates down to 0\\% during pre-training and 1\\%-4\\% during fine-tuning, and effectively improves the model's performance. ",
    "url": "https://arxiv.org/abs/2303.06854",
    "authors": [
      "Wenhan Yang",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06856",
    "title": "Dynamic Neural Network for Multi-Task Learning Searching across Diverse  Network Topologies",
    "abstract": "In this paper, we present a new MTL framework that searches for structures optimized for multiple tasks with diverse graph topologies and shares features among tasks. We design a restricted DAG-based central network with read-in/read-out layers to build topologically diverse task-adaptive structures while limiting search space and time. We search for a single optimized network that serves as multiple task adaptive sub-networks using our three-stage training process. To make the network compact and discretized, we propose a flow-based reduction algorithm and a squeeze loss used in the training process. We evaluate our optimized network on various public MTL datasets and show ours achieves state-of-the-art performance. An extensive ablation study experimentally validates the effectiveness of the sub-module and schemes in our framework. ",
    "url": "https://arxiv.org/abs/2303.06856",
    "authors": [
      "Wonhyeok Choi",
      "Sunghoon Im"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06859",
    "title": "Learning Distortion Invariant Representation for Image Restoration from  A Causality Perspective",
    "abstract": "In recent years, we have witnessed the great advancement of Deep neural networks (DNNs) in image restoration. However, a critical limitation is that they cannot generalize well to real-world degradations with different degrees or types. In this paper, we are the first to propose a novel training strategy for image restoration from the causality perspective, to improve the generalization ability of DNNs for unknown degradations. Our method, termed Distortion Invariant representation Learning (DIL), treats each distortion type and degree as one specific confounder, and learns the distortion-invariant representation by eliminating the harmful confounding effect of each degradation. We derive our DIL with the back-door criterion in causality by modeling the interventions of different distortions from the optimization perspective. Particularly, we introduce counterfactual distortion augmentation to simulate the virtual distortion types and degrees as the confounders. Then, we instantiate the intervention of each distortion with a virtual model updating based on corresponding distorted images, and eliminate them from the meta-learning perspective. Extensive experiments demonstrate the effectiveness of our DIL on the generalization capability for unseen distortion types and degrees. Our code will be available at https://github.com/lixinustc/Casual-IRDIL. ",
    "url": "https://arxiv.org/abs/2303.06859",
    "authors": [
      "Xin Li",
      "Bingchen Li",
      "Xin Jin",
      "Cuiling Lan",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06860",
    "title": "View Adaptive Light Field Deblurring Networks with Depth Perception",
    "abstract": "The Light Field (LF) deblurring task is a challenging problem as the blur images are caused by different reasons like the camera shake and the object motion. The single image deblurring method is a possible way to solve this problem. However, since it deals with each view independently and cannot effectively utilize and maintain the LF structure, the restoration effect is usually not ideal. Besides, the LF blur is more complex because the degree is affected by the views and depth. Therefore, we carefully designed a novel LF deblurring network based on the LF blur characteristics. On one hand, since the blur degree varies a lot in different views, we design a novel view adaptive spatial convolution to deblur blurred LFs, which calculates the exclusive convolution kernel for each view. On the other hand, because the blur degree also varies with the depth of the object, a depth perception view attention is designed to deblur different depth areas by selectively integrating information from different views. Besides, we introduce an angular position embedding to maintain the LF structure better, which ensures the model correctly restores the view information. Quantitative and qualitative experimental results on synthetic and real images show that the deblurring effect of our method is better than other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2303.06860",
    "authors": [
      "Zeqi Shen",
      "Shuo Zhang",
      "Zhuhao Zhang",
      "Qihua Chen",
      "Xueyao Dong",
      "Youfang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06870",
    "title": "Three Guidelines You Should Know for Universally Slimmable  Self-Supervised Learning",
    "abstract": "We propose universally slimmable self-supervised learning (dubbed as US3L) to achieve better accuracy-efficiency trade-offs for deploying self-supervised models across different devices. We observe that direct adaptation of self-supervised learning (SSL) to universally slimmable networks misbehaves as the training process frequently collapses. We then discover that temporal consistent guidance is the key to the success of SSL for universally slimmable networks, and we propose three guidelines for the loss design to ensure this temporal consistency from a unified gradient perspective. Moreover, we propose dynamic sampling and group regularization strategies to simultaneously improve training efficiency and accuracy. Our US3L method has been empirically validated on both convolutional neural networks and vision transformers. With only once training and one copy of weights, our method outperforms various state-of-the-art methods (individually trained or not) on benchmarks including recognition, object detection and instance segmentation. Our code is available at https://github.com/megvii-research/US3L-CVPR2023. ",
    "url": "https://arxiv.org/abs/2303.06870",
    "authors": [
      "Yun-Hao Cao",
      "Peiqin Sun",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06879",
    "title": "Spacecraft Anomaly Detection with Attention Temporal Convolution Network",
    "abstract": "Spacecraft faces various situations when carrying out exploration missions in complex space, thus monitoring the anomaly status of spacecraft is crucial to the development of \\textcolor{blue}{the} aerospace industry. The time series telemetry data generated by on-orbit spacecraft \\textcolor{blue}{contains} important information about the status of spacecraft. However, traditional domain knowledge-based spacecraft anomaly detection methods are not effective due to high dimensionality and complex correlation among variables. In this work, we propose an anomaly detection framework for spacecraft multivariate time-series data based on temporal convolution networks (TCNs). First, we employ dynamic graph attention to model the complex correlation among variables and time series. Second, temporal convolution networks with parallel processing ability are used to extract multidimensional \\textcolor{blue}{features} for \\textcolor{blue}{the} downstream prediction task. Finally, many potential anomalies are detected by the best threshold. Experiments on real NASA SMAP/MSL spacecraft datasets show the superiority of our proposed model with respect to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2303.06879",
    "authors": [
      "Liang Liu",
      "Ling Tian",
      "Zhao Kang",
      "Tianqi Wan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06880",
    "title": "Uni3D: A Unified Baseline for Multi-dataset 3D Object Detection",
    "abstract": "Current 3D object detection models follow a single dataset-specific training and testing paradigm, which often faces a serious detection accuracy drop when they are directly deployed in another dataset. In this paper, we study the task of training a unified 3D detector from multiple datasets. We observe that this appears to be a challenging task, which is mainly due to that these datasets present substantial data-level differences and taxonomy-level variations caused by different LiDAR types and data acquisition standards. Inspired by such observation, we present a Uni3D which leverages a simple data-level correction operation and a designed semantic-level coupling-and-recoupling module to alleviate the unavoidable data-level and taxonomy-level differences, respectively. Our method is simple and easily combined with many 3D object detection baselines such as PV-RCNN and Voxel-RCNN, enabling them to effectively learn from multiple off-the-shelf 3D datasets to obtain more discriminative and generalizable representations. Experiments are conducted on many dataset consolidation settings including Waymo-nuScenes, nuScenes-KITTI, Waymo-KITTI, and Waymo-nuScenes-KITTI consolidations. Their results demonstrate that Uni3D exceeds a series of individual detectors trained on a single dataset, with a 1.04x parameter increase over a selected baseline detector. We expect this work will inspire the research of 3D generalization since it will push the limits of perceptual performance. ",
    "url": "https://arxiv.org/abs/2303.06880",
    "authors": [
      "Bo Zhang",
      "Jiakang Yuan",
      "Botian Shi",
      "Tao Chen",
      "Yikang Li",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06885",
    "title": "DR2: Diffusion-based Robust Degradation Remover for Blind Face  Restoration",
    "abstract": "Blind face restoration usually synthesizes degraded low-quality data with a pre-defined degradation model for training, while more complex cases could happen in the real world. This gap between the assumed and actual degradation hurts the restoration performance where artifacts are often observed in the output. However, it is expensive and infeasible to include every type of degradation to cover real-world cases in the training data. To tackle this robustness issue, we propose Diffusion-based Robust Degradation Remover (DR2) to first transform the degraded image to a coarse but degradation-invariant prediction, then employ an enhancement module to restore the coarse prediction to a high-quality image. By leveraging a well-performing denoising diffusion probabilistic model, our DR2 diffuses input images to a noisy status where various types of degradation give way to Gaussian noise, and then captures semantic information through iterative denoising steps. As a result, DR2 is robust against common degradation (e.g. blur, resize, noise and compression) and compatible with different designs of enhancement modules. Experiments in various settings show that our framework outperforms state-of-the-art methods on heavily degraded synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2303.06885",
    "authors": [
      "Zhixin Wang",
      "Xiaoyun Zhang",
      "Ziying Zhang",
      "Huangjie Zheng",
      "Mingyuan Zhou",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06919",
    "title": "NeRFLiX: High-Quality Neural View Synthesis by Learning a  Degradation-Driven Inter-viewpoint MiXer",
    "abstract": "Neural radiance fields (NeRF) show great success in novel view synthesis. However, in real-world scenes, recovering high-quality details from the source images is still challenging for the existing NeRF-based approaches, due to the potential imperfect calibration information and scene representation inaccuracy. Even with high-quality training frames, the synthetic novel views produced by NeRF models still suffer from notable rendering artifacts, such as noise, blur, etc. Towards to improve the synthesis quality of NeRF-based approaches, we propose NeRFLiX, a general NeRF-agnostic restorer paradigm by learning a degradation-driven inter-viewpoint mixer. Specially, we design a NeRF-style degradation modeling approach and construct large-scale training data, enabling the possibility of effectively removing NeRF-native rendering artifacts for existing deep neural networks. Moreover, beyond the degradation removal, we propose an inter-viewpoint aggregation framework that is able to fuse highly related high-quality training images, pushing the performance of cutting-edge NeRF models to entirely new levels and producing highly photo-realistic synthetic views. ",
    "url": "https://arxiv.org/abs/2303.06919",
    "authors": [
      "Kun Zhou",
      "Wenbo Li",
      "Yi Wang",
      "Tao Hu",
      "Nianjuan Jiang",
      "Xiaoguang Han",
      "Jiangbo Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06920",
    "title": "Pixel-wise Gradient Uncertainty for Convolutional Neural Networks  applied to Out-of-Distribution Segmentation",
    "abstract": "In recent years, deep neural networks have defined the state-of-the-art in semantic segmentation where their predictions are constrained to a predefined set of semantic classes. They are to be deployed in applications such as automated driving, although their categorically confined expressive power runs contrary to such open world scenarios. Thus, the detection and segmentation of objects from outside their predefined semantic space, i.e., out-of-distribution (OoD) objects, is of highest interest. Since uncertainty estimation methods like softmax entropy or Bayesian models are sensitive to erroneous predictions, these methods are a natural baseline for OoD detection. Here, we present a method for obtaining uncertainty scores from pixel-wise loss gradients which can be computed efficiently during inference. Our approach is simple to implement for a large class of models, does not require any additional training or auxiliary data and can be readily used on pre-trained segmentation models. Our experiments show the ability of our method to identify wrong pixel classifications and to estimate prediction quality. In particular, we observe superior performance in terms of OoD segmentation to comparable baselines on the SegmentMeIfYouCan benchmark, clearly outperforming methods which are similarly flexible to implement. ",
    "url": "https://arxiv.org/abs/2303.06920",
    "authors": [
      "Kira Maag",
      "Tobias Riedlinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06931",
    "title": "DeepVigor: Vulnerability Value Ranges and Factors for DNNs' Reliability  Assessment",
    "abstract": "Deep Neural Networks (DNNs) and their accelerators are being deployed ever more frequently in safety-critical applications leading to increasing reliability concerns. A traditional and accurate method for assessing DNNs' reliability has been resorting to fault injection, which, however, suffers from prohibitive time complexity. While analytical and hybrid fault injection-/analytical-based methods have been proposed, they are either inaccurate or specific to particular accelerator architectures. In this work, we propose a novel accurate, fine-grain, metric-oriented, and accelerator-agnostic method called DeepVigor that provides vulnerability value ranges for DNN neurons' outputs. An outcome of DeepVigor is an analytical model representing vulnerable and non-vulnerable ranges for each neuron that can be exploited to develop different techniques for improving DNNs' reliability. Moreover, DeepVigor provides reliability assessment metrics based on vulnerability factors for bits, neurons, and layers using the vulnerability ranges. The proposed method is not only faster than fault injection but also provides extensive and accurate information about the reliability of DNNs, independent from the accelerator. The experimental evaluations in the paper indicate that the proposed vulnerability ranges are 99.9% to 100% accurate even when evaluated on previously unseen test data. Also, it is shown that the obtained vulnerability factors represent the criticality of bits, neurons, and layers proficiently. DeepVigor is implemented in the PyTorch framework and validated on complex DNN benchmarks. ",
    "url": "https://arxiv.org/abs/2303.06931",
    "authors": [
      "Mohammad Hasan Ahmadilivani",
      "Mahdi Taheri",
      "Jaan Raik",
      "Masoud Daneshtalab",
      "Maksim Jenihhin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2303.06933",
    "title": "Distributionally Robust Chance-Constrained Optimization for Hierarchical  UAV-based MEC",
    "abstract": "Multi-access edge computing (MEC) is regarded as a promising technology in the sixth-generation communication. However, the antenna gain is always affected by the environment when unmanned aerial vehicles (UAVs) are served as MEC platforms, resulting in unexpected channel errors. In order to deal with the problem and reduce the power consumption in the UAV-based MEC, we jointly optimize the access scheme and power allocation in the hierarchical UAV-based MEC. Specifically, UAVs are deployed in the lower layer to collect data from ground users. Moreover, a UAV with powerful computation ability is deployed in the upper layer to assist with computing. The goal is to guarantee the quality of service and minimize the total power consumption. We consider the errors caused by various perturbations in realistic circumstances and formulate a distributionally robust chance-constrained optimization problem with an uncertainty set. The problem with chance constraints is intractable. To tackle this issue, we utilize the conditional value-at-risk method to reformulate the problem into a semidefinite programming form. Then, a joint algorithm for access scheme and power allocation is designed. Finally, we conduct simulations to demonstrate the efficiency of the proposed algorithm. ",
    "url": "https://arxiv.org/abs/2303.06933",
    "authors": [
      "Can Cui",
      "Ziye Jia",
      "Chao Dong",
      "Zhuang Ling",
      "Jiahao You",
      "Qihui Wu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.06935",
    "title": "Importance Filtering with Risk Models for Complex Driving Situations",
    "abstract": "Self-driving cars face complex driving situations with a large amount of agents when moving in crowded cities. However, some of the agents are actually not influencing the behavior of the self-driving car. Filtering out unimportant agents would inherently simplify the behavior or motion planning task for the system. The planning system can then focus on fewer agents to find optimal behavior solutions for the ego~agent. This is helpful especially in terms of computational efficiency. In this paper, therefore, the research topic of importance filtering with driving risk models is introduced. We give an overview of state-of-the-art risk models and present newly adapted risk models for filtering. Their capability to filter out surrounding unimportant agents is compared in a large-scale experiment. As it turns out, the novel trajectory distance balances performance, robustness and efficiency well. Based on the results, we can further derive a novel filter architecture with multiple filter steps, for which risk models are recommended for each step, to further improve the robustness. We are confident that this will enable current behavior planning systems to better solve complex situations in everyday driving. ",
    "url": "https://arxiv.org/abs/2303.06935",
    "authors": [
      "Tim Puphal",
      "Raphael Wenzel",
      "Benedict Flade",
      "Malte Probst",
      "Julian Eggert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06972",
    "title": "Leveraging Neural Koopman Operators to Learn Continuous Representations  of Dynamical Systems from Scarce Data",
    "abstract": "Over the last few years, several works have proposed deep learning architectures to learn dynamical systems from observation data with no or little knowledge of the underlying physics. A line of work relies on learning representations where the dynamics of the underlying phenomenon can be described by a linear operator, based on the Koopman operator theory. However, despite being able to provide reliable long-term predictions for some dynamical systems in ideal situations, the methods proposed so far have limitations, such as requiring to discretize intrinsically continuous dynamical systems, leading to data loss, especially when handling incomplete or sparsely sampled data. Here, we propose a new deep Koopman framework that represents dynamics in an intrinsically continuous way, leading to better performance on limited training data, as exemplified on several datasets arising from dynamical systems. ",
    "url": "https://arxiv.org/abs/2303.06972",
    "authors": [
      "Anthony Frion",
      "Lucas Drumetz",
      "Mauro Dalla Mura",
      "Guillaume Tochon",
      "Abdeldjalil Aissa El Bey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2303.06980",
    "title": "Self-supervised based general laboratory progress pretrained model for  cardiovascular event detection",
    "abstract": "Regular surveillance is an indispensable aspect of managing cardiovascular disorders. Patient recruitment for rare or specific diseases is often limited due to their small patient size and episodic observations, whereas prevalent cases accumulate longitudinal data easily due to regular follow-ups. These data, however, are notorious for their irregularity, temporality, sparsity, and absenteeism. In this study, we leveraged self-supervised learning (SSL) and transfer learning to overcome the above-mentioned barriers, transferring patient progress trends in cardiovascular laboratory parameters from prevalent cases to rare or specific cardiovascular events detection. We pretrained a general laboratory progress (GLP) pretrain model using hypertension patients (who were yet to be diabetic), and transferred their laboratory progress trend to assist in detecting target vessel revascularization (TVR) in percutaneous coronary intervention patients. GLP adopted a two-stage training process that utilized interpolated data, enhancing the performance of SSL. After pretraining GLP, we fine-tuned it for TVR prediction. The proposed two-stage training process outperformed SSL. Upon processing by GLP, the classification demonstrated a marked improvement, increasing from 0.63 to 0.90 in averaged accuracy. All metrics were significantly superior (p < 0.01) to the performance of prior GLP processing. The representation displayed distinct separability independent of algorithmic mechanisms, and diverse data distribution trend. Our approach effectively transferred the progression trends of cardiovascular laboratory parameters from prevalent cases to small-numbered cases, thereby demonstrating its efficacy in aiding the risk assessment of cardiovascular events without limiting to episodic observation. The potential for extending this approach to other laboratory tests and diseases is promising. ",
    "url": "https://arxiv.org/abs/2303.06980",
    "authors": [
      "Li-Chin Chen",
      "Kuo-Hsuan Hung",
      "Yi-Ju Tseng",
      "Hsin-Yao Wang",
      "Tse-Min Lu",
      "Wei-Chieh Huang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06982",
    "title": "Analysing the Masked predictive coding training criterion for  pre-training a Speech Representation Model",
    "abstract": "Recent developments in pre-trained speech representation utilizing self-supervised learning (SSL) have yielded exceptional results on a variety of downstream tasks. One such technique, known as masked predictive coding (MPC), has been employed by some of the most high-performing models. In this study, we investigate the impact of MPC loss on the type of information learnt at various layers in the HuBERT model, using nine probing tasks. Our findings indicate that the amount of content information learned at various layers of the HuBERT model has a positive correlation to the MPC loss. Additionally, it is also observed that any speaker-related information learned at intermediate layers of the model, is an indirect consequence of the learning process, and therefore cannot be controlled using the MPC loss. These findings may serve as inspiration for further research in the speech community, specifically in the development of new pre-training tasks or the exploration of new pre-training criterion's that directly preserves both speaker and content information at various layers of a learnt model. ",
    "url": "https://arxiv.org/abs/2303.06982",
    "authors": [
      "Hemant Yadav",
      "Sunayana Sitaram",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.06999",
    "title": "Identifying Label Errors in Object Detection Datasets by Loss Inspection",
    "abstract": "Labeling datasets for supervised object detection is a dull and time-consuming task. Errors can be easily introduced during annotation and overlooked during review, yielding inaccurate benchmarks and performance degradation of deep neural networks trained on noisy labels. In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines. We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets. For our label error detection method we assume a two-stage object detector to be given and consider the sum of both stages' classification and regression losses. The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter. We compare our method to three baselines: a naive one without deep learning, the object detector's score and the entropy of the classification softmax distribution. We outperform all baselines and demonstrate that among the considered methods, ours is the only one that detects label errors of all four types efficiently. Furthermore, we detect real label errors a) on commonly used test datasets in object detection and b) on a proprietary dataset. In both cases we achieve low false positives rates, i.e., when considering 200 proposals from our method, we detect label errors with a precision for a) of up to 71.5% and for b) with 97%. ",
    "url": "https://arxiv.org/abs/2303.06999",
    "authors": [
      "Marius Schubert",
      "Tobias Riedlinger",
      "Karsten Kahl",
      "Daniel Kr\u00f6ll",
      "Sebastian Schoenen",
      "Sini\u0161a \u0160egvi\u0107",
      "Matthias Rottmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07001",
    "title": "Neural Group Recommendation Based on a Probabilistic Semantic  Aggregation",
    "abstract": "Recommendation to groups of users is a challenging subfield of recommendation systems. Its key concept is how and where to make the aggregation of each set of user information into an individual entity, such as a ranked recommendation list, a virtual user, or a multi-hot input vector encoding. This paper proposes an innovative strategy where aggregation is made in the multi-hot vector that feeds the neural network model. The aggregation provides a probabilistic semantic, and the resulting input vectors feed a model that is able to conveniently generalize the group recommendation from the individual predictions. Furthermore, using the proposed architecture, group recommendations can be obtained by simply feedforwarding the pre-trained model with individual ratings; that is, without the need to obtain datasets containing group of user information, and without the need of running two separate trainings (individual and group). This approach also avoids maintaining two different models to support both individual and group learning. Experiments have tested the proposed architecture using three representative collaborative filtering datasets and a series of baselines; results show suitable accuracy improvements compared to the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2303.07001",
    "authors": [
      "Jorge Due\u00f1as-Ler\u00edn",
      "Ra\u00fal Lara-Cabrera",
      "Fernando Ortega",
      "Jes\u00fas Bobadilla"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.07003",
    "title": "Review on the Feasibility of Adversarial Evasion Attacks and Defenses  for Network Intrusion Detection Systems",
    "abstract": "Nowadays, numerous applications incorporate machine learning (ML) algorithms due to their prominent achievements. However, many studies in the field of computer vision have shown that ML can be fooled by intentionally crafted instances, called adversarial examples. These adversarial examples take advantage of the intrinsic vulnerability of ML models. Recent research raises many concerns in the cybersecurity field. An increasing number of researchers are studying the feasibility of such attacks on security systems based on ML algorithms, such as Intrusion Detection Systems (IDS). The feasibility of such adversarial attacks would be influenced by various domain-specific constraints. This can potentially increase the difficulty of crafting adversarial examples. Despite the considerable amount of research that has been done in this area, much of it focuses on showing that it is possible to fool a model using features extracted from the raw data but does not address the practical side, i.e., the reverse transformation from theory to practice. For this reason, we propose a review browsing through various important papers to provide a comprehensive analysis. Our analysis highlights some challenges that have not been addressed in the reviewed papers. ",
    "url": "https://arxiv.org/abs/2303.07003",
    "authors": [
      "Islam Debicha",
      "Benjamin Cochez",
      "Tayeb Kenaza",
      "Thibault Debatty",
      "Jean-Michel Dricot",
      "Wim Mees"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07011",
    "title": "OSIS: Efficient One-stage Network for 3D Instance Segmentation",
    "abstract": "Current 3D instance segmentation models generally use multi-stage methods to extract instance objects, including clustering, feature extraction, and post-processing processes. However, these multi-stage approaches rely on hyperparameter settings and hand-crafted processes, which restrict the inference speed of the model. In this paper, we propose a new 3D point cloud instance segmentation network, named OSIS. OSIS is a one-stage network, which directly segments instances from 3D point cloud data using neural network. To segment instances directly from the network, we propose an instance decoder, which decodes instance features from the network into instance segments. Our proposed OSIS realizes the end-to-end training by bipartite matching, therefore, our network does not require computationally expensive post-processing steps such as non maximum suppression (NMS) and clustering during inference. The results show that our network finally achieves excellent performance in the commonly used indoor scene instance segmentation dataset, and the inference speed of our network is only an average of 138ms per scene, which substantially exceeds the previous fastest method. ",
    "url": "https://arxiv.org/abs/2303.07011",
    "authors": [
      "Chuan Tang",
      "Xi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07035",
    "title": "FireRisk: A Remote Sensing Dataset for Fire Risk Assessment with  Benchmarks Using Supervised and Self-supervised Learning",
    "abstract": "In recent decades, wildfires, as widespread and extremely destructive natural disasters, have caused tremendous property losses and fatalities, as well as extensive damage to forest ecosystems. Many fire risk assessment projects have been proposed to prevent wildfires, but GIS-based methods are inherently challenging to scale to different geographic areas due to variations in data collection and local conditions. Inspired by the abundance of publicly available remote sensing projects and the burgeoning development of deep learning in computer vision, our research focuses on assessing fire risk using remote sensing imagery. In this work, we propose a novel remote sensing dataset, FireRisk, consisting of 7 fire risk classes with a total of 91872 labelled images for fire risk assessment. This remote sensing dataset is labelled with the fire risk classes supplied by the Wildfire Hazard Potential (WHP) raster dataset, and remote sensing images are collected using the National Agriculture Imagery Program (NAIP), a high-resolution remote sensing imagery program. On FireRisk, we present benchmark performance for supervised and self-supervised representations, with Masked Autoencoders (MAE) pre-trained on ImageNet1k achieving the highest classification accuracy, 65.29%. This remote sensing dataset, FireRisk, provides a new direction for fire risk assessment, and we make it publicly available on https://github.com/CharmonyShen/FireRisk. ",
    "url": "https://arxiv.org/abs/2303.07035",
    "authors": [
      "Shuchang Shen",
      "Sachith Seneviratne",
      "Xinye Wanyan",
      "Michael Kirley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07064",
    "title": "A Generalized Multi-Modal Fusion Detection Framework",
    "abstract": "LiDAR point clouds have become the most common data source in autonomous driving. However, due to the sparsity of point clouds, accurate and reliable detection cannot be achieved in specific scenarios. Because of their complementarity with point clouds, images are getting increasing attention. Although with some success, existing fusion methods either perform hard fusion or do not fuse in a direct manner. In this paper, we propose a generic 3D detection framework called MMFusion, using multi-modal features. The framework aims to achieve accurate fusion between LiDAR and images to improve 3D detection in complex scenes. Our framework consists of two separate streams: the LiDAR stream and the camera stream, which can be compatible with any single-modal feature extraction network. The Voxel Local Perception Module in the LiDAR stream enhances local feature representation, and then the Multi-modal Feature Fusion Module selectively combines feature output from different streams to achieve better fusion. Extensive experiments have shown that our framework not only outperforms existing benchmarks but also improves their detection, especially for detecting cyclists and pedestrians on KITTI benchmarks, with strong robustness and generalization capabilities. Hopefully, our work will stimulate more research into multi-modal fusion for autonomous driving tasks. ",
    "url": "https://arxiv.org/abs/2303.07064",
    "authors": [
      "Leichao Cui",
      "Xiuxian Li",
      "Min Meng",
      "Xiaoyu Mo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07067",
    "title": "Cross-device Federated Learning for Mobile Health Diagnostics: A First  Study on COVID-19 Detection",
    "abstract": "Federated learning (FL) aided health diagnostic models can incorporate data from a large number of personal edge devices (e.g., mobile phones) while keeping the data local to the originating devices, largely ensuring privacy. However, such a cross-device FL approach for health diagnostics still imposes many challenges due to both local data imbalance (as extreme as local data consists of a single disease class) and global data imbalance (the disease prevalence is generally low in a population). Since the federated server has no access to data distribution information, it is not trivial to solve the imbalance issue towards an unbiased model. In this paper, we propose FedLoss, a novel cross-device FL framework for health diagnostics. Here the federated server averages the models trained on edge devices according to the predictive loss on the local data, rather than using only the number of samples as weights. As the predictive loss better quantifies the data distribution at a device, FedLoss alleviates the impact of data imbalance. Through a real-world dataset on respiratory sound and symptom-based COVID-$19$ detection task, we validate the superiority of FedLoss. It achieves competitive COVID-$19$ detection performance compared to a centralised model with an AUC-ROC of $79\\%$. It also outperforms the state-of-the-art FL baselines in sensitivity and convergence speed. Our work not only demonstrates the promise of federated COVID-$19$ detection but also paves the way to a plethora of mobile health model development in a privacy-preserving fashion. ",
    "url": "https://arxiv.org/abs/2303.07067",
    "authors": [
      "Tong Xia",
      "Jing Han",
      "Abhirup Ghosh",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.07071",
    "title": "Correlates of Programmer Efficacy and Their Link to Experience: A  Combined EEG and Eye-Tracking Study",
    "abstract": "Background: Despite similar education and background, programmers can exhibit vast differences in efficacy. While research has identified some potential factors, such as programming experience and domain knowledge, the effect of these factors on programmers' efficacy is not well understood. Aims: We aim at unraveling the relationship between efficacy (speed and correctness) and measures of programming experience. We further investigate the correlates of programmer efficacy in terms of reading behavior and cognitive load. Method: For this purpose, we conducted a controlled experiment with 37~participants using electroencephalography (EEG) and eye tracking. We asked participants to comprehend up to 32 Java source-code snippets and observed their eye gaze and neural correlates of cognitive load. We analyzed the correlation of participants' efficacy with popular programming experience measures. Results: We found that programmers with high efficacy read source code more targeted and with lower cognitive load. Commonly used experience levels do not predict programmer efficacy well, but self-estimation and indicators of learning eagerness are fairly accurate. Implications: The identified correlates of programmer efficacy can be used for future research and practice (e.g., hiring). Future research should also consider efficacy as a group sampling method, rather than using simple experience measures. ",
    "url": "https://arxiv.org/abs/2303.07071",
    "authors": [
      "Norman Peitek",
      "Annabelle Bergum",
      "Maurice Rekrut",
      "Jonas Mucke",
      "Matthias Nadig",
      "Chris Parnin",
      "Janet Siegmund",
      "Sven Apel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.07080",
    "title": "Bag of Tricks with Quantized Convolutional Neural Networks for image  classification",
    "abstract": "Deep neural networks have been proven effective in a wide range of tasks. However, their high computational and memory costs make them impractical to deploy on resource-constrained devices. To address this issue, quantization schemes have been proposed to reduce the memory footprint and improve inference speed. While numerous quantization methods have been proposed, they lack systematic analysis for their effectiveness. To bridge this gap, we collect and improve existing quantization methods and propose a gold guideline for post-training quantization. We evaluate the effectiveness of our proposed method with two popular models, ResNet50 and MobileNetV2, on the ImageNet dataset. By following our guidelines, no accuracy degradation occurs even after directly quantizing the model to 8-bits without additional training. A quantization-aware training based on the guidelines can further improve the accuracy in lower-bits quantization. Moreover, we have integrated a multi-stage fine-tuning strategy that works harmoniously with existing pruning techniques to reduce costs even further. Remarkably, our results reveal that a quantized MobileNetV2 with 30\\% sparsity actually surpasses the performance of the equivalent full-precision model, underscoring the effectiveness and resilience of our proposed scheme. ",
    "url": "https://arxiv.org/abs/2303.07080",
    "authors": [
      "Jie Hu",
      "Mengze Zeng",
      "Enhua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07084",
    "title": "The challenge of representation learning: Improved accuracy in deep  vision models does not come with better predictions of perceptual similarity",
    "abstract": "Over the last years, advancements in deep learning models for computer vision have led to a dramatic improvement in their image classification accuracy. However, models with a higher accuracy in the task they were trained on do not necessarily develop better image representations that allow them to also perform better in other tasks they were not trained on. In order to investigate the representation learning capabilities of prominent high-performing computer vision models, we investigated how well they capture various indices of perceptual similarity from large-scale behavioral datasets. We find that higher image classification accuracy rates are not associated with a better performance on these datasets, and in fact we observe no improvement in performance since GoogLeNet (released 2015) and VGG-M (released 2014). We speculate that more accurate classification may result from hyper-engineering towards very fine-grained distinctions between highly similar classes, which does not incentivize the models to capture overall perceptual similarities. ",
    "url": "https://arxiv.org/abs/2303.07084",
    "authors": [
      "Fritz G\u00fcnther",
      "Marco Marelli",
      "Marco Alessandro Petilli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07096",
    "title": "Prototype-based Embedding Network for Scene Graph Generation",
    "abstract": "Current Scene Graph Generation (SGG) methods explore contextual information to predict relationships among entity pairs. However, due to the diverse visual appearance of numerous possible subject-object combinations, there is a large intra-class variation within each predicate category, e.g., \"man-eating-pizza, giraffe-eating-leaf\", and the severe inter-class similarity between different classes, e.g., \"man-holding-plate, man-eating-pizza\", in model's latent space. The above challenges prevent current SGG methods from acquiring robust features for reliable relation prediction. In this paper, we claim that the predicate's category-inherent semantics can serve as class-wise prototypes in the semantic space for relieving the challenges. To the end, we propose the Prototype-based Embedding Network (PE-Net), which models entities/predicates with prototype-aligned compact and distinctive representations and thereby establishes matching between entity pairs and predicates in a common embedding space for relation recognition. Moreover, Prototype-guided Learning (PL) is introduced to help PE-Net efficiently learn such entitypredicate matching, and Prototype Regularization (PR) is devised to relieve the ambiguous entity-predicate matching caused by the predicate's semantic overlap. Extensive experiments demonstrate that our method gains superior relation recognition capability on SGG, achieving new state-of-the-art performances on both Visual Genome and Open Images datasets. ",
    "url": "https://arxiv.org/abs/2303.07096",
    "authors": [
      "Chaofan Zheng",
      "Xinyu Lyu",
      "Lianli Gao",
      "Bo Dai",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07104",
    "title": "xASTNN: Improved Code Representations for Industrial Practice",
    "abstract": "The application of deep learning techniques in software engineering becomes increasingly popular. One key problem is developing high-quality and easy-to-use source code representations for code-related tasks. The research community has acquired impressive results in recent years. However, due to the deployment difficulties and performance bottlenecks, seldom these approaches are applied to the industry. In this paper, we present xASTNN, an eXtreme Abstract Syntax Tree (AST)-based Neural Network for source code representation, aiming to push this technique to industrial practice. The proposed xASTNN has three advantages. First, xASTNN is completely based on widely-used ASTs and does not require complicated data pre-processing, making it applicable to various programming languages and practical scenarios. Second, three closely-related designs are proposed to guarantee the effectiveness of xASTNN, including statement subtree sequence for code naturalness, gated recursive unit for syntactical information, and gated recurrent unit for sequential information. Third, a dynamic batching algorithm is introduced to significantly reduce the time complexity of xASTNN. Two code comprehension downstream tasks, code classification and code clone detection, are adopted for evaluation. The results demonstrate that our xASTNN can improve the state-of-the-art while being faster than the baselines. ",
    "url": "https://arxiv.org/abs/2303.07104",
    "authors": [
      "Zhiwei Xu",
      "Min Zhou",
      "Xibin Zhao",
      "Yang Chen",
      "Xi Cheng",
      "Hongyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07105",
    "title": "Measuring Multi-Source Redundancy in Factor Graphs",
    "abstract": "Factor graphs are a ubiquitous tool for multi-source inference in robotics and multi-sensor networks. They allow for heterogeneous measurements from many sources to be concurrently represented as factors in the state posterior distribution, so that inference can be conducted via sparse graphical methods. Adding measurements from many sources can supply robustness to state estimation, as seen in distributed pose graph optimization. However, adding excessive measurements to a factor graph can also quickly degrade their performance as more cycles are added to the graph. In both situations, the relevant quality is the redundancy of information. Drawing on recent work in information theory on partial information decomposition (PID), we articulate two potential definitions of redundancy in factor graphs, both within a common axiomatic framework for redundancy in factor graphs. This is the first application of PID to factor graphs, and only one of a few presenting quantitative measures of redundancy for them. ",
    "url": "https://arxiv.org/abs/2303.07105",
    "authors": [
      "Jesse Milzman",
      "Andre Harrison",
      "Carlos Nieto-Granda",
      "John Rogers"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07113",
    "title": "FedACK: Federated Adversarial Contrastive Knowledge Distillation for  Cross-Lingual and Cross-Model Social Bot Detection",
    "abstract": "Social bot detection is of paramount importance to the resilience and security of online social platforms. The state-of-the-art detection models are siloed and have largely overlooked a variety of data characteristics from multiple cross-lingual platforms. Meanwhile, the heterogeneity of data distribution and model architecture makes it intricate to devise an efficient cross-platform and cross-model detection framework. In this paper, we propose FedACK, a new federated adversarial contrastive knowledge distillation framework for social bot detection. We devise a GAN-based federated knowledge distillation mechanism for efficiently transferring knowledge of data distribution among clients. In particular, a global generator is used to extract the knowledge of global data distribution and distill it into each client's local model. We leverage local discriminator to enable customized model design and use local generator for data enhancement with hard-to-decide samples. Local training is conducted as multi-stage adversarial and contrastive learning to enable consistent feature spaces among clients and to constrain the optimization direction of local models, reducing the divergences between local and global models. Experiments demonstrate that FedACK outperforms the state-of-the-art approaches in terms of accuracy, communication efficiency, and feature space consistency. ",
    "url": "https://arxiv.org/abs/2303.07113",
    "authors": [
      "Yingguang Yang",
      "Renyu Yang",
      "Hao Peng",
      "Yangyang Li",
      "Tong Li",
      "Yong Liao",
      "Pengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07114",
    "title": "Uncertainty quantification in neural network classifiers -- a local  linear approach",
    "abstract": "Classifiers based on neural networks (NN) often lack a measure of uncertainty in the predicted class. We propose a method to estimate the probability mass function (PMF) of the different classes, as well as the covariance of the estimated PMF. First, a local linear approach is used during the training phase to recursively compute the covariance of the parameters in the NN. Secondly, in the classification phase another local linear approach is used to propagate the covariance of the learned NN parameters to the uncertainty in the output of the last layer of the NN. This allows for an efficient Monte Carlo (MC) approach for: (i) estimating the PMF; (ii) calculating the covariance of the estimated PMF; and (iii) proper risk assessment and fusion of multiple classifiers. Two classical image classification tasks, i.e., MNIST, and CFAR10, are used to demonstrate the efficiency the proposed method. ",
    "url": "https://arxiv.org/abs/2303.07114",
    "authors": [
      "Magnus Malmstr\u00f6m",
      "Isaac Skog",
      "Daniel Axehill",
      "Fredrik Gustafsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.07115",
    "title": "NeurEPDiff: Neural Operators to Predict Geodesics in Deformation Spaces",
    "abstract": "This paper presents NeurEPDiff, a novel network to fast predict the geodesics in deformation spaces generated by a well known Euler-Poincar\\'e differential equation (EPDiff). To achieve this, we develop a neural operator that for the first time learns the evolving trajectory of geodesic deformations parameterized in the tangent space of diffeomorphisms(a.k.a velocity fields). In contrast to previous methods that purely fit the training images, our proposed NeurEPDiff learns a nonlinear mapping function between the time-dependent velocity fields. A composition of integral operators and smooth activation functions is formulated in each layer of NeurEPDiff to effectively approximate such mappings. The fact that NeurEPDiff is able to rapidly provide the numerical solution of EPDiff (given any initial condition) results in a significantly reduced computational cost of geodesic shooting of diffeomorphisms in a high-dimensional image space. Additionally, the properties of discretiztion/resolution-invariant of NeurEPDiff make its performance generalizable to multiple image resolutions after being trained offline. We demonstrate the effectiveness of NeurEPDiff in registering two image datasets: 2D synthetic data and 3D brain resonance imaging (MRI). The registration accuracy and computational efficiency are compared with the state-of-the-art diffeomophic registration algorithms with geodesic shooting. ",
    "url": "https://arxiv.org/abs/2303.07115",
    "authors": [
      "Nian Wu",
      "Miaomiao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07122",
    "title": "Quantifying Causes of Arctic Amplification via Deep Learning based  Time-series Causal Inference",
    "abstract": "The warming of the Arctic, also known as Arctic amplification, is led by several atmospheric and oceanic drivers, however, the details of its underlying thermodynamic causes are still unknown. Inferring the causal effects of atmospheric processes on sea ice melt using fixed treatment effect strategies leads to unrealistic counterfactual estimations. Such models are also prone to bias due to time-varying confoundedness. In order to tackle these challenges, we propose TCINet - time-series causal inference model to infer causation under continuous treatment using recurrent neural networks. Through experiments on synthetic and observational data, we show how our research can substantially improve the ability to quantify the leading causes of Arctic sea ice melt. ",
    "url": "https://arxiv.org/abs/2303.07122",
    "authors": [
      "Sahara Ali",
      "Omar Faruque",
      "Jianwu Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.07125",
    "title": "Don't PANIC: Prototypical Additive Neural Network for Interpretable  Classification of Alzheimer's Disease",
    "abstract": "Alzheimer's disease (AD) has a complex and multifactorial etiology, which requires integrating information about neuroanatomy, genetics, and cerebrospinal fluid biomarkers for accurate diagnosis. Hence, recent deep learning approaches combined image and tabular information to improve diagnostic performance. However, the black-box nature of such neural networks is still a barrier for clinical applications, in which understanding the decision of a heterogeneous model is integral. We propose PANIC, a prototypical additive neural network for interpretable AD classification that integrates 3D image and tabular data. It is interpretable by design and, thus, avoids the need for post-hoc explanations that try to approximate the decision of a network. Our results demonstrate that PANIC achieves state-of-the-art performance in AD classification, while directly providing local and global explanations. Finally, we show that PANIC extracts biologically meaningful signatures of AD, and satisfies a set of desirable desiderata for trustworthy machine learning. Our implementation is available at \\url{https://github.com/ai-med/PANIC}. ",
    "url": "https://arxiv.org/abs/2303.07125",
    "authors": [
      "Tom Nuno Wolf",
      "Sebastian P\u00f6lster",
      "Christian Wachinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07127",
    "title": "Improving physics-informed neural networks with meta-learned  optimization",
    "abstract": "We show that the error achievable using physics-informed neural networks for solving systems of differential equations can be substantially reduced when these networks are trained using meta-learned optimization methods rather than to using fixed, hand-crafted optimizers as traditionally done. We choose a learnable optimization method based on a shallow multi-layer perceptron that is meta-trained for specific classes of differential equations. We illustrate meta-trained optimizers for several equations of practical relevance in mathematical physics, including the linear advection equation, Poisson's equation, the Korteweg--de Vries equation and Burgers' equation. We also illustrate that meta-learned optimizers exhibit transfer learning abilities, in that a meta-trained optimizer on one differential equation can also be successfully deployed on another differential equation. ",
    "url": "https://arxiv.org/abs/2303.07127",
    "authors": [
      "Alex Bihlo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.07128",
    "title": "VMCDL: Vulnerability Mining Based on Cascaded Deep Learning Under Source  Control Flow",
    "abstract": "With the rapid development of the computer industry and computer software, the risk of software vulnerabilities being exploited has greatly increased. However, there are still many shortcomings in the existing mining techniques for leakage source research, such as high false alarm rate, coarse-grained detection, and dependence on expert experience. In this paper, we mainly use the c/c++ source code data of the SARD dataset, process the source code of CWE476, CWE469, CWE516 and CWE570 vulnerability types, test the Joern vulnerability scanning function of the cutting-edge tool, and propose a new cascading deep learning model VMCDL based on source code control flow to effectively detect vulnerabilities. First, this paper uses joern to locate and extract sensitive functions and statements to form a sensitive statement library of vulnerable code. Then, the CFG flow vulnerability code snippets are generated by bidirectional breadth-first traversal, and then vectorized by Doc2vec. Finally, the cascade deep learning model based on source code control flow is used for classification to obtain the classification results. In the experimental evaluation, we give the test results of Joern on specific vulnerabilities, and give the confusion matrix and label data of the binary classification results of the model algorithm on single vulnerability type source code, and compare and verify the five indicators of FPR, FNR, ACC, P and F1, respectively reaching 10.30%, 5.20%, 92.50%,85.10% and 85.40%,which shows that it can effectively reduce the false alarm rate of static analysis. ",
    "url": "https://arxiv.org/abs/2303.07128",
    "authors": [
      "Wen Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07129",
    "title": "AdaptiveNet: Post-deployment Neural Architecture Adaptation for Diverse  Edge Environments",
    "abstract": "Deep learning models are increasingly deployed to edge devices for real-time applications. To ensure stable service quality across diverse edge environments, it is highly desirable to generate tailored model architectures for different conditions. However, conventional pre-deployment model generation approaches are not satisfactory due to the difficulty of handling the diversity of edge environments and the demand for edge information. In this paper, we propose to adapt the model architecture after deployment in the target environment, where the model quality can be precisely measured and private edge data can be retained. To achieve efficient and effective edge model generation, we introduce a pretraining-assisted on-cloud model elastification method and an edge-friendly on-device architecture search method. Model elastification generates a high-quality search space of model architectures with the guidance of a developer-specified oracle model. Each subnet in the space is a valid model with different environment affinity, and each device efficiently finds and maintains the most suitable subnet based on a series of edge-tailored optimizations. Extensive experiments on various edge devices demonstrate that our approach is able to achieve significantly better accuracy-latency tradeoffs (e.g. 46.74\\% higher on average accuracy with a 60\\% latency budget) than strong baselines with minimal overhead (13 GPU hours in the cloud and 2 minutes on the edge server). ",
    "url": "https://arxiv.org/abs/2303.07129",
    "authors": [
      "Hao Wen",
      "Yuanchun Li",
      "Zunshuai Zhang",
      "Shiqi Jiang",
      "Xiaozhou Ye",
      "Ye Ouyang",
      "Ya-Qin Zhang",
      "Yunxin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.07153",
    "title": "SA-CNN: Application to text categorization issues using simulated  annealing-based convolutional neural network optimization",
    "abstract": "Convolutional neural networks (CNNs) are a representative class of deep learning algorithms including convolutional computation that perform translation-invariant classification of input data based on their hierarchical architecture. However, classical convolutional neural network learning methods use the steepest descent algorithm for training, and the learning performance is greatly influenced by the initial weight settings of the convolutional and fully connected layers, requiring re-tuning to achieve better performance under different model structures and data. Combining the strengths of the simulated annealing algorithm in global search, we propose applying it to the hyperparameter search process in order to increase the effectiveness of convolutional neural networks (CNNs). In this paper, we introduce SA-CNN neural networks for text classification tasks based on Text-CNN neural networks and implement the simulated annealing algorithm for hyperparameter search. Experiments demonstrate that we can achieve greater classification accuracy than earlier models with manual tuning, and the improvement in time and space for exploration relative to human tuning is substantial. ",
    "url": "https://arxiv.org/abs/2303.07153",
    "authors": [
      "Zihao Guo",
      "Yueying Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07172",
    "title": "Evaluating Visual Number Discrimination in Deep Neural Networks",
    "abstract": "The ability to discriminate between large and small quantities is a core aspect of basic numerical competence in both humans and animals. In this work, we examine the extent to which the state-of-the-art neural networks designed for vision exhibit this basic ability. Motivated by studies in animal and infant numerical cognition, we use the numerical bisection procedure to test number discrimination in different families of neural architectures. Our results suggest that vision-specific inductive biases are helpful in numerosity discrimination, as models with such biases have lowest test errors on the task, and often have psychometric curves that qualitatively resemble those of humans and animals performing the task. However, even the strongest models, as measured on standard metrics of performance, fail to discriminate quantities in transfer experiments with differing training and testing conditions, indicating that such inductive biases might not be sufficient. ",
    "url": "https://arxiv.org/abs/2303.07172",
    "authors": [
      "Ivana Kaji\u0107",
      "Aida Nematzadeh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07182",
    "title": "Mobile Mapping Mesh Change Detection and Update",
    "abstract": "Mobile mapping, in particular, Mobile Lidar Scanning (MLS) is increasingly widespread to monitor and map urban scenes at city scale with unprecedented resolution and accuracy. The resulting point cloud sampling of the scene geometry can be meshed in order to create a continuous representation for different applications: visualization, simulation, navigation, etc. Because of the highly dynamic nature of these urban scenes, long term mapping should rely on frequent map updates. A trivial solution is to simply replace old data with newer data each time a new acquisition is made. However it has two drawbacks: 1) the old data may be of higher quality (resolution, precision) than the new and 2) the coverage of the scene might be different in various acquisitions, including varying occlusions. In this paper, we propose a fully automatic pipeline to address these two issues by formulating the problem of merging meshes with different quality, coverage and acquisition time. Our method is based on a combined distance and visibility based change detection, a time series analysis to assess the sustainability of changes, a mesh mosaicking based on a global boolean optimization and finally a stitching of the resulting mesh pieces boundaries with triangle strips. Finally, our method is demonstrated on Robotcar and Stereopolis datasets. ",
    "url": "https://arxiv.org/abs/2303.07182",
    "authors": [
      "Teng Wu",
      "Bruno Vallet",
      "C\u00e9dric Demonceaux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07184",
    "title": "Traffic Prediction with Transfer Learning: A Mutual Information-based  Approach",
    "abstract": "In modern traffic management, one of the most essential yet challenging tasks is accurately and timely predicting traffic. It has been well investigated and examined that deep learning-based Spatio-temporal models have an edge when exploiting Spatio-temporal relationships in traffic data. Typically, data-driven models require vast volumes of data, but gathering data in small cities can be difficult owing to constraints such as equipment deployment and maintenance costs. To resolve this problem, we propose TrafficTL, a cross-city traffic prediction approach that uses big data from other cities to aid data-scarce cities in traffic prediction. Utilizing a periodicity-based transfer paradigm, it identifies data similarity and reduces negative transfer caused by the disparity between two data distributions from distant cities. In addition, the suggested method employs graph reconstruction techniques to rectify defects in data from small data cities. TrafficTL is evaluated by comprehensive case studies on three real-world datasets and outperforms the state-of-the-art baseline by around 8 to 25 percent. ",
    "url": "https://arxiv.org/abs/2303.07184",
    "authors": [
      "Yunjie Huang",
      "Xiaozhuang Song",
      "Yuanshao Zhu",
      "Shiyao Zhang",
      "James J.Q. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07187",
    "title": "SOBO: A Feedback Bot to Nudge Code Quality in Programming Courses",
    "abstract": "Recent research has shown the great potential of automatic feedback in education. This paper presents SOBO, a bot we designed to automatically provide feedback on code quality to undergraduate students. SOBO has been deployed in a course at the KTH Royal Institute of Technology in Sweden with 130+ students. Overall, SOBO has analyzed 1687 GitHub repositories and produced 8443 tailored code quality feedback messages to students. The quantitative and qualitative results indicate that SOBO effectively nudges students into adopting code quality best practices without interfering with pedagogical objectives or adding a teaching burden. From this experience, we provide guidelines into how to design and deploy teaching bots in programming courses. ",
    "url": "https://arxiv.org/abs/2303.07187",
    "authors": [
      "Sofia Bobadilla",
      "Richard Glassey",
      "Alexandre Bergel",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.07194",
    "title": "Neural Partial Differential Equations with Functional Convolution",
    "abstract": "We present a lightweighted neural PDE representation to discover the hidden structure and predict the solution of different nonlinear PDEs. Our key idea is to leverage the prior of ``translational similarity'' of numerical PDE differential operators to drastically reduce the scale of learning model and training data. We implemented three central network components, including a neural functional convolution operator, a Picard forward iterative procedure, and an adjoint backward gradient calculator. Our novel paradigm fully leverages the multifaceted priors that stem from the sparse and smooth nature of the physical PDE solution manifold and the various mature numerical techniques such as adjoint solver, linearization, and iterative procedure to accelerate the computation. We demonstrate the efficacy of our method by robustly discovering the model and accurately predicting the solutions of various types of PDEs with small-scale networks and training sets. We highlight that all the PDE examples we showed were trained with up to 8 data samples and within 325 network parameters. ",
    "url": "https://arxiv.org/abs/2303.07194",
    "authors": [
      "Ziqian Wu",
      "Xingzhe He",
      "Yijun Li",
      "Cheng Yang",
      "Rui Liu",
      "Shiying Xiong",
      "Bo Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07195",
    "title": "Operating data of a specific Aquatic Center as a Benchmark for dynamic  model learning: search for a valid prediction model over an 8-hour horizon",
    "abstract": "This paper presents an identification repository based on data from a public swimming pool in operation. Such a system is both a complex process and easily understandable by all with regard to the issues. Ultimately, the aim is to reduce the energy bill while maintaining the level of quality of service. This objective is general in scope and not just limited to public swimming pools. It can be done efficiently through what is known as economic predictive control. This type of advanced control is based on a process model. It is the problem of this article and the benchmark considered to show that such a dynamic model can be obtained from operating data. For this, operational data is formatted and shared, and model quality indicators are proposed. On this basis, the first identification results illustrate the results obtained by a linear multivariable model on the one hand, and by a neural model on the other hand. They call for other proposals and results from control and data scientists for comparison. ",
    "url": "https://arxiv.org/abs/2303.07195",
    "authors": [
      "Fran\u00e7ois Gauthier-Clerc",
      "Hoel Le Capitaine",
      "Fabien Claveau",
      "Philippe Chevrel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.07196",
    "title": "A Comprehensive Empirical Evaluation of Existing Word Embedding  Approaches",
    "abstract": "Vector-based word representations help countless Natural Language Processing (NLP) tasks capture both semantic and syntactic regularities of the language. In this paper, we present the characteristics of existing word embedding approaches and analyze them with regards to many classification tasks. We categorize the methods into two main groups - Traditional approaches mostly use matrix factorization to produce word representations, and they are not able to capture the semantic and syntactic regularities of the language very well. Neural-Network based approaches, on the other hand, can capture sophisticated regularities of the language and preserve the word relationships in the generated word representations. We report experimental results on multiple classification tasks and highlight the scenarios where one approach performs better than the rest. ",
    "url": "https://arxiv.org/abs/2303.07196",
    "authors": [
      "Obaidullah Zaland",
      "Muhammad Abulaish",
      "Mohd. Fazil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.07199",
    "title": "BeamAttack: Generating High-quality Textual Adversarial Examples through  Beam Search and Mixed Semantic Spaces",
    "abstract": "Natural language processing models based on neural networks are vulnerable to adversarial examples. These adversarial examples are imperceptible to human readers but can mislead models to make the wrong predictions. In a black-box setting, attacker can fool the model without knowing model's parameters and architecture. Previous works on word-level attacks widely use single semantic space and greedy search as a search strategy. However, these methods fail to balance the attack success rate, quality of adversarial examples and time consumption. In this paper, we propose BeamAttack, a textual attack algorithm that makes use of mixed semantic spaces and improved beam search to craft high-quality adversarial examples. Extensive experiments demonstrate that BeamAttack can improve attack success rate while saving numerous queries and time, e.g., improving at most 7\\% attack success rate than greedy search when attacking the examples from MR dataset. Compared with heuristic search, BeamAttack can save at most 85\\% model queries and achieve a competitive attack success rate. The adversarial examples crafted by BeamAttack are highly transferable and can effectively improve model's robustness during adversarial training. Code is available at https://github.com/zhuhai-ustc/beamattack/tree/master ",
    "url": "https://arxiv.org/abs/2303.07199",
    "authors": [
      "Hai Zhu",
      "Qingyang Zhao",
      "Yuren Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.07200",
    "title": "Supervised Feature Selection with Neuron Evolution in Sparse Neural  Networks",
    "abstract": "This paper proposes a novel supervised feature selection method named NeuroFS. NeuroFS introduces dynamic neuron evolution in the training process of a sparse neural network to find an informative set of features. By evaluating NeuroFS on real-world benchmark datasets, we demonstrated that it achieves the highest ranking-based score among the considered state-of-the-art supervised feature selection models. However, due to the general lack of knowledge on optimally implementing sparse neural networks during training, NeuroFS does not take full advantage of its theoretical high computational and memory advantages. We let the development of this challenging research direction for future work, hopefully, in a greater joint effort of the community. ",
    "url": "https://arxiv.org/abs/2303.07200",
    "authors": [
      "Zahra Atashgahi",
      "Xuhao Zhang",
      "Neil Kichler",
      "Shiwei Liu",
      "Lu Yin",
      "Mykola Pechenizkiy",
      "Raymond Veldhuis",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07203",
    "title": "On the Robustness of Text Vectorizers",
    "abstract": "A fundamental issue in natural language processing is the robustness of the models with respect to changes in the input. One critical step in this process is the embedding of documents, which transforms sequences of words or tokens into vector representations. Our work formally proves that popular embedding schemes, such as concatenation, TF-IDF, and Paragraph Vector (a.k.a. doc2vec), exhibit robustness in the H\\\"older or Lipschitz sense with respect to the Hamming distance. We provide quantitative bounds for these schemes and demonstrate how the constants involved are affected by the length of the document. These findings are exemplified through a series of numerical examples. ",
    "url": "https://arxiv.org/abs/2303.07203",
    "authors": [
      "R\u00e9mi Catellier",
      "Samuel Vaiter",
      "Damien Garreau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07221",
    "title": "Generation-based Code Review Automation: How Far Are We?",
    "abstract": "Code review is an effective software quality assurance activity; however, it is labor-intensive and time-consuming. Thus, a number of generation-based automatic code review (ACR) approaches have been proposed recently, which leverage deep learning techniques to automate various activities in the code review process (e.g., code revision generation and review comment generation). We find the previous works carry three main limitations. First, the ACR approaches have been shown to be beneficial in each work, but those methods are not comprehensively compared with each other to show their superiority over their peer ACR approaches. Second, general-purpose pre-trained models such as CodeT5 are proven to be effective in a wide range of Software Engineering (SE) tasks. However, no prior work has investigated the effectiveness of these models in ACR tasks yet. Third, prior works heavily rely on the Exact Match (EM) metric which only focuses on the perfect predictions and ignores the positive progress made by incomplete answers. To fill such a research gap, we conduct a comprehensive study by comparing the effectiveness of recent ACR tools as well as the general-purpose pre-trained models. The results show that a general-purpose pre-trained model CodeT5 can outperform other models in most cases. Specifically, CodeT5 outperforms the prior state-of-the-art by 13.4\\%--38.9\\% in two code revision generation tasks. In addition, we introduce a new metric namely Edit Progress (EP) to quantify the partial progress made by ACR tools. The results show that the rankings of models for each task could be changed according to whether EM or EP is being utilized. Lastly, we derive several insightful lessons from the experimental results and reveal future research directions for generation-based code review automation. ",
    "url": "https://arxiv.org/abs/2303.07221",
    "authors": [
      "Xin Zhou",
      "Kisub Kim",
      "Bowen Xu",
      "DongGyun Han",
      "Junda He",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.07229",
    "title": "Optimal Square Detection Over General Alphabets",
    "abstract": "Squares (fragments of the form $xx$, for some string $x$) are arguably the most natural type of repetition in strings. The basic algorithmic question concerning squares is to check if a given string of length $n$ is square-free, that is, does not contain a fragment of such form. Main and Lorentz [J. Algorithms 1984] designed an $\\mathcal{O}(n\\log n)$ time algorithm for this problem, and proved a matching lower bound assuming the so-called general alphabet, meaning that the algorithm is only allowed to check if two characters are equal. However, their lower bound also assumes that there are $\\Omega(n)$ distinct symbols in the string. As an open question, they asked if there is a faster algorithm if one restricts the size of the alphabet. Crochemore [Theor. Comput. Sci. 1986] designed a linear-time algorithm for constant-size alphabets, and combined with more recent results his approach in fact implies such an algorithm for linearly-sortable alphabets. Very recently, Ellert and Fischer [ICALP 2021] significantly relaxed this assumption by designing a linear-time algorithm for general ordered alphabets, that is, assuming a linear order on the characters that permits constant time order comparisons. However, the open question of Main and Lorentz from 1984 remained unresolved for general (unordered) alphabets. In this paper, we show that testing square-freeness of a length-$n$ string over general alphabet of size $\\sigma$ can be done with $\\mathcal{O}(n\\log \\sigma)$ comparisons, and cannot be done with $o(n\\log \\sigma)$ comparisons. We complement this result with an $\\mathcal{O}(n\\log \\sigma)$ time algorithm in the Word RAM model. Finally, we extend the algorithm to reporting all the runs (maximal repetitions) in the same complexity. ",
    "url": "https://arxiv.org/abs/2303.07229",
    "authors": [
      "Jonas Ellert",
      "Pawe\u0142 Gawrychowski",
      "Garance Gourdel"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.07230",
    "title": "Systematic Evaluation of Deep Learning Models for Failure Prediction",
    "abstract": "With the increasing complexity and scope of software systems, their dependability is crucial. The analysis of log data recorded during system execution can enable engineers to automatically predict failures at run time. Several Machine Learning (ML) techniques, including traditional ML and Deep Learning (DL), have been proposed to automate such tasks. However, current empirical studies are limited in terms of covering all main DL types -- Recurrent Neural Network (RNN), Convolutional Neural network (CNN), and transformer -- as well as examining them on a wide range of diverse datasets. In this paper, we aim to address these issues by systematically investigating the combination of log data embedding strategies and DL types for failure prediction. To that end, we propose a modular architecture to accommodate various configurations of embedding strategies and DL-based encoders. To further investigate how dataset characteristics such as dataset size and failure percentage affect model accuracy, we synthesised 360 datasets, with varying characteristics, for three distinct system behavioral models, based on a systematic and automated generation approach. Using the F1 score metric, our results show that the best overall performing configuration is a CNN-based encoder with Logkey2vec. Additionally, we provide specific dataset conditions, namely a dataset size >350 or a failure percentage >7.5%, under which this configuration demonstrates high accuracy for failure prediction. ",
    "url": "https://arxiv.org/abs/2303.07230",
    "authors": [
      "Fatemeh Hadadi",
      "Joshua H. Dawes",
      "Donghwan Shin",
      "Domenico Bianculli",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.07264",
    "title": "A Surface-normal Based Neural Framework for Colonoscopy Reconstruction",
    "abstract": "Reconstructing a 3D surface from colonoscopy video is challenging due to illumination and reflectivity variation in the video frame that can cause defective shape predictions. Aiming to overcome this challenge, we utilize the characteristics of surface normal vectors and develop a two-step neural framework that significantly improves the colonoscopy reconstruction quality. The normal-based depth initialization network trained with self-supervised normal consistency loss provides depth map initialization to the normal-depth refinement module, which utilizes the relationship between illumination and surface normals to refine the frame-wise normal and depth predictions recursively. Our framework's depth accuracy performance on phantom colonoscopy data demonstrates the value of exploiting the surface normals in colonoscopy reconstruction, especially on en face views. Due to its low depth error, the prediction result from our framework will require limited post-processing to be clinically applicable for real-time colonoscopy reconstruction. ",
    "url": "https://arxiv.org/abs/2303.07264",
    "authors": [
      "Shuxian Wang",
      "Yubo Zhang",
      "Sarah K. McGill",
      "Julian G. Rosenman",
      "Jan-Michael Frahm",
      "Soumyadip Sengupta",
      "Stephen M. Pizer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07273",
    "title": "Control of synaptic plasticity in neural networks",
    "abstract": "The brain is a nonlinear and highly Recurrent Neural Network (RNN). This RNN is surprisingly plastic and supports our astonishing ability to learn and execute complex tasks. However, learning is incredibly complicated due to the brain's nonlinear nature and the obscurity of mechanisms for determining the contribution of each synapse to the output error. This issue is known as the Credit Assignment Problem (CAP) and is a fundamental challenge in neuroscience and Artificial Intelligence (AI). Nevertheless, in the current understanding of cognitive neuroscience, it is widely accepted that a feedback loop systems play an essential role in synaptic plasticity. With this as inspiration, we propose a computational model by combining Neural Networks (NN) and nonlinear optimal control theory. The proposed framework involves a new NN-based actor-critic method which is used to simulate the error feedback loop systems and projections on the NN's synaptic plasticity so as to ensure that the output error is minimized. ",
    "url": "https://arxiv.org/abs/2303.07273",
    "authors": [
      "Mohammad Modiri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07275",
    "title": "A Survey of Graph Prompting Methods: Techniques, Applications, and  Challenges",
    "abstract": "While deep learning has achieved great success on various tasks, the task-specific model training notoriously relies on a large volume of labeled data. Recently, a new training paradigm of ``pre-train, prompt, predict'' has been proposed to improve model generalization ability with limited labeled data. The main idea is that, based on a pre-trained model, the prompting function uses a template to augment input samples with indicative context and reformalizes the target task to one of the pre-training tasks. In this survey, we provide a unique review of prompting methods from the graph perspective. Graph data has served as structured knowledge repositories in various systems by explicitly modeling the interaction between entities. Compared with traditional methods, graph prompting functions could induce task-related context and apply templates with structured knowledge. The pre-trained model is then adaptively generalized for future samples. In particular, we introduce the basic concepts of graph prompt learning, organize the existing work of designing graph prompting functions, and describe their applications and challenges to a variety of machine learning problems. This survey attempts to bridge the gap between structured graphs and prompt design to facilitate future methodology development. ",
    "url": "https://arxiv.org/abs/2303.07275",
    "authors": [
      "Xuansheng Wu",
      "Kaixiong Zhou",
      "Mingchen Sun",
      "Xin Wang",
      "Ninghao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.07292",
    "title": "Transformer-based approaches to Sentiment Detection",
    "abstract": "The use of transfer learning methods is largely responsible for the present breakthrough in Natural Learning Processing (NLP) tasks across multiple domains. In order to solve the problem of sentiment detection, we examined the performance of four different types of well-known state-of-the-art transformer models for text classification. Models such as Bidirectional Encoder Representations from Transformers (BERT), Robustly Optimized BERT Pre-training Approach (RoBERTa), a distilled version of BERT (DistilBERT), and a large bidirectional neural network architecture (XLNet) were proposed. The performance of the four models that were used to detect disaster in the text was compared. All the models performed well enough, indicating that transformer-based models are suitable for the detection of disaster in text. The RoBERTa transformer model performs best on the test dataset with a score of 82.6% and is highly recommended for quality predictions. Furthermore, we discovered that the learning algorithms' performance was influenced by the pre-processing techniques, the nature of words in the vocabulary, unbalanced labeling, and the model parameters. ",
    "url": "https://arxiv.org/abs/2303.07292",
    "authors": [
      "Olumide Ebenezer Ojo",
      "Hoang Thang Ta",
      "Alexander Gelbukh",
      "Hiram Calvo",
      "Olaronke Oluwayemisi Adebanji",
      "Grigori Sidorov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.07305",
    "title": "Transformer Models for Acute Brain Dysfunction Prediction",
    "abstract": "Acute brain dysfunctions (ABD), which include coma and delirium, are prevalent in the ICU, especially among older patients. The current approach in manual assessment of ABD by care providers may be sporadic and subjective. Hence, there exists a need for a data-driven robust system automating the assessment and prediction of ABD. In this work, we develop a machine learning system for real-time prediction of ADB using Electronic Health Record (HER) data. Our data processing pipeline enables integration of static and temporal data, and extraction of features relevant to ABD. We train several state-of-the-art transformer models and baseline machine learning models including CatBoost and XGB on the data that was collected from patients admitted to the ICU at UF Shands Hospital. We demonstrate the efficacy of our system for tasks related to acute brain dysfunction including binary classification of brain acuity and multi-class classification (i.e., coma, delirium, death, or normal), achieving a mean AUROC of 0.953 on our Long-former implementation. Our system can then be deployed for real-time prediction of ADB in ICUs to reduce the number of incidents caused by ABD. Moreover, the real-time system has the potential to reduce costs, duration of patients stays in the ICU, and mortality among those afflicted. ",
    "url": "https://arxiv.org/abs/2303.07305",
    "authors": [
      "Brandon Silva",
      "Miguel Contreras",
      "Tezcan Ozrazgat Baslanti",
      "Yuanfang Ren",
      "Guan Ziyuan",
      "Kia Khezeli",
      "Azra Bihorac",
      "Parisa Rashidi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07308",
    "title": "NeuSE: Neural SE(3)-Equivariant Embedding for Consistent Spatial  Understanding with Objects",
    "abstract": "We present NeuSE, a novel Neural SE(3)-Equivariant Embedding for objects, and illustrate how it supports object SLAM for consistent spatial understanding with long-term scene changes. NeuSE is a set of latent object embeddings created from partial object observations. It serves as a compact point cloud surrogate for complete object models, encoding full shape information while transforming SE(3)-equivariantly in tandem with the object in the physical world. With NeuSE, relative frame transforms can be directly derived from inferred latent codes. Our proposed SLAM paradigm, using NeuSE for object shape and pose characterization, can operate independently or in conjunction with typical SLAM systems. It directly infers SE(3) camera pose constraints that are compatible with general SLAM pose graph optimization, while also maintaining a lightweight object-centric map that adapts to real-world changes. Our approach is evaluated on synthetic and real-world sequences featuring changed objects and shows improved localization accuracy and change-aware mapping capability, when working either standalone or jointly with a common SLAM pipeline. ",
    "url": "https://arxiv.org/abs/2303.07308",
    "authors": [
      "Jiahui Fu",
      "Yilun Du",
      "Kurran Singh",
      "Joshua B. Tenenbaum",
      "John J. Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07310",
    "title": "Learning Reduced-Order Models for Cardiovascular Simulations with Graph  Neural Networks",
    "abstract": "Reduced-order models based on physics are a popular choice in cardiovascular modeling due to their efficiency, but they may experience reduced accuracy when working with anatomies that contain numerous junctions or pathological conditions. We develop one-dimensional reduced-order models that simulate blood flow dynamics using a graph neural network trained on three-dimensional hemodynamic simulation data. Given the initial condition of the system, the network iteratively predicts the pressure and flow rate at the vessel centerline nodes. Our numerical results demonstrate the accuracy and generalizability of our method in physiological geometries comprising a variety of anatomies and boundary conditions. Our findings demonstrate that our approach can achieve errors below 2% and 3% for pressure and flow rate, respectively, provided there is adequate training data. As a result, our method exhibits superior performance compared to physics-based one-dimensional models, while maintaining high efficiency at inference time. ",
    "url": "https://arxiv.org/abs/2303.07310",
    "authors": [
      "Luca Pegolotti",
      "Martin R. Pfaller",
      "Natalia L. Rubio",
      "Ke Ding",
      "Rita Brugarolas Brufau",
      "Eric Darve",
      "Alison L. Marsden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.07313",
    "title": "A data-driven analysis of UK cyber defence",
    "abstract": "Our research addresses the question: What are the conditions of the UK's cyber threat landscape? In addressing this we focus on detectable, known and therefore potentially preventable cyber threats, specifically those that are identifiable by the types of malicious scanning activities they exhibit. We have chosen this approach for two reasons. First, as is evidenced herein, the vast majority of cyber threats affecting the lives and business endeavours of UK citizens are identifiable, preventable threats. Thus the potential exists to better improve UK cyber defence by improving how citizens are supported in preventing, detecting and responding to cyber threats. Achieving this requires an evidence base to inform policy makers. Second, it is potentially useful to build a quantifiable evidence base of the known threat space - that is to say detectable, identifiable and therefore potentially preventable cyber threats - to ascertain if this information may also be useful when attempting to detect the emergence of more novel cyber threats. This research presents an analysis of malicious internet scanning activity collected within the UK between 1st December 2020 and the 30th November 2021. The data was gathered via a custom automated system which collected and processed data from Greynoise, enriched this via Shodan, cross referencing it with data from the Office of National Statistics and proprietorial data on UK place names and geolocation. ",
    "url": "https://arxiv.org/abs/2303.07313",
    "authors": [
      "Justin McKeown"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.07320",
    "title": "Model-tuning Via Prompts Makes NLP Models Adversarially Robust",
    "abstract": "In recent years, NLP practitioners have converged on the following practice: (i) import an off-the-shelf pretrained (masked) language model; (ii) append a multilayer perceptron atop the CLS token's hidden representation (with randomly initialized weights); and (iii) fine-tune the entire model on a downstream task (MLP). This procedure has produced massive gains on standard NLP benchmarks, but these models remain brittle, even to mild adversarial perturbations, such as word-level synonym substitutions. In this work, we demonstrate surprising gains in adversarial robustness enjoyed by Model-tuning Via Prompts (MVP), an alternative method of adapting to downstream tasks. Rather than modifying the model (by appending an MLP head), MVP instead modifies the input (by appending a prompt template). Across three classification datasets, MVP improves performance against adversarial word-level synonym substitutions by an average of 8% over standard methods and even outperforms adversarial training-based state-of-art defenses by 3.5%. By combining MVP with adversarial training, we achieve further improvements in robust accuracy while maintaining clean accuracy. Finally, we conduct ablations to investigate the mechanism underlying these gains. Notably, we find that the main causes of vulnerability of MLP can be attributed to the misalignment between pre-training and fine-tuning tasks, and the randomly initialized MLP parameters. Code is available at https://github.com/acmi-lab/mvp ",
    "url": "https://arxiv.org/abs/2303.07320",
    "authors": [
      "Mrigank Raman",
      "Pratyush Maini",
      "J. Zico Kolter",
      "Zachary C. Lipton",
      "Danish Pruthi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07337",
    "title": "PoseExaminer: Automated Testing of Out-of-Distribution Robustness in  Human Pose and Shape Estimation",
    "abstract": "Human pose and shape (HPS) estimation methods achieve remarkable results. However, current HPS benchmarks are mostly designed to test models in scenarios that are similar to the training data. This can lead to critical situations in real-world applications when the observed data differs significantly from the training data and hence is out-of-distribution (OOD). It is therefore important to test and improve the OOD robustness of HPS methods. To address this fundamental problem, we develop a simulator that can be controlled in a fine-grained manner using interpretable parameters to explore the manifold of images of human pose, e.g. by varying poses, shapes, and clothes. We introduce a learning-based testing method, termed PoseExaminer, that automatically diagnoses HPS algorithms by searching over the parameter space of human pose images to find the failure modes. Our strategy for exploring this high-dimensional parameter space is a multi-agent reinforcement learning system, in which the agents collaborate to explore different parts of the parameter space. We show that our PoseExaminer discovers a variety of limitations in current state-of-the-art models that are relevant in real-world scenarios but are missed by current benchmarks. For example, it finds large regions of realistic human poses that are not predicted correctly, as well as reduced performance for humans with skinny and corpulent body shapes. In addition, we show that fine-tuning HPS methods by exploiting the failure modes found by PoseExaminer improve their robustness and even their performance on standard benchmarks by a significant margin. The code are available for research purposes. ",
    "url": "https://arxiv.org/abs/2303.07337",
    "authors": [
      "Qihao Liu",
      "Adam Kortylewski",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07347",
    "title": "TriDet: Temporal Action Detection with Relative Boundary Modeling",
    "abstract": "In this paper, we present a one-stage framework TriDet for temporal action detection. Existing methods often suffer from imprecise boundary predictions due to the ambiguous action boundaries in videos. To alleviate this problem, we propose a novel Trident-head to model the action boundary via an estimated relative probability distribution around the boundary. In the feature pyramid of TriDet, we propose an efficient Scalable-Granularity Perception (SGP) layer to mitigate the rank loss problem of self-attention that takes place in the video features and aggregate information across different temporal granularities. Benefiting from the Trident-head and the SGP-based feature pyramid, TriDet achieves state-of-the-art performance on three challenging benchmarks: THUMOS14, HACS and EPIC-KITCHEN 100, with lower computational costs, compared to previous methods. For example, TriDet hits an average mAP of $69.3\\%$ on THUMOS14, outperforming the previous best by $2.5\\%$, but with only $74.6\\%$ of its latency. The code is released to https://github.com/sssste/TriDet. ",
    "url": "https://arxiv.org/abs/2303.07347",
    "authors": [
      "Dingfeng Shi",
      "Yujie Zhong",
      "Qiong Cao",
      "Lin Ma",
      "Jia Li",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.06311",
    "title": "Generative Adversarial Networks for Scintillation Signal Simulation in  EXO-200",
    "abstract": "Generative Adversarial Networks trained on samples of simulated or actual events have been proposed as a way of generating large simulated datasets at a reduced computational cost. In this work, a novel approach to perform the simulation of photodetector signals from the time projection chamber of the EXO-200 experiment is demonstrated. The method is based on a Wasserstein Generative Adversarial Network - a deep learning technique allowing for implicit non-parametric estimation of the population distribution for a given set of objects. Our network is trained on real calibration data using raw scintillation waveforms as input. We find that it is able to produce high-quality simulated waveforms an order of magnitude faster than the traditional simulation approach and, importantly, generalize from the training sample and discern salient high-level features of the data. In particular, the network correctly deduces position dependency of scintillation light response in the detector and correctly recognizes dead photodetector channels. The network output is then integrated into the EXO-200 analysis framework to show that the standard EXO-200 reconstruction routine processes the simulated waveforms to produce energy distributions comparable to that of real waveforms. Finally, the remaining discrepancies and potential ways to improve the approach further are highlighted. ",
    "url": "https://arxiv.org/abs/2303.06311",
    "authors": [
      "S. Li",
      "I. Ostrovskiy",
      "Z. Li",
      "L. Yang",
      "S. Al Kharusi",
      "G. Anton",
      "I. Badhrees",
      "P.S. Barbeau",
      "D. Beck",
      "V. Belov",
      "T. Bhatta",
      "M. Breidenbach",
      "T. Brunner",
      "G.F. Cao",
      "W.R. Cen",
      "C. Chambers",
      "B. Cleveland",
      "M. Coon",
      "A. Craycraft",
      "T. Daniels",
      "L. Darroch",
      "S.J. Daugherty",
      "J. Davis",
      "S. Delaquis",
      "A. Der Mesrobian-Kabakian",
      "R. DeVoe",
      "J. Dilling",
      "A. Dolgolenko",
      "M.J. Dolinski",
      "J. Echevers",
      "W. Fairbank Jr.",
      "D. Fairbank",
      "J. Farine",
      "S. Feyzbakhsh",
      "P. Fierlinger",
      "Y.S. Fu",
      "D. Fudenberg",
      "P. Gautam",
      "R. Gornea",
      "G. Gratta",
      "C. Hall",
      "E.V. Hansen",
      "J. Hoessl",
      "P. Hufschmidt",
      "M. Hughes",
      "A. Iverson",
      "A. Jamil",
      "C. Jessiman",
      "M.J. Jewell",
      "A. Johnson",
      "A. Karelin",
      "L.J. Kaufman",
      "T. Koffas",
      "R. Kr\u00fccken",
      "A. Kuchenkov",
      "K.S. Kumar",
      "Y. Lan",
      "A. Larson",
      "B.G. Lenardo",
      "D.S. Leonard",
      "G.S. Li",
      "C. Licciardi",
      "Y.H. Lin",
      "R. MacLellan",
      "T. McElroy"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2303.06321",
    "title": "Finding large counterexamples by selectively exploring the Pachner graph",
    "abstract": "We often rely on censuses of triangulations to guide our intuition in $3$-manifold topology. However, this can lead to misplaced faith in conjectures if the smallest counterexamples are too large to appear in our census. Since the number of triangulations increases super-exponentially with size, there is no way to expand a census beyond relatively small triangulations; the current census only goes up to $10$ tetrahedra. Here, we show that it is feasible to search for large and hard-to-find counterexamples by using heuristics to selectively (rather than exhaustively) enumerate triangulations. We use this idea to find counterexamples to three conjectures which ask, for certain $3$-manifolds, whether one-vertex triangulations always have a \"distinctive\" edge that would allow us to recognise the $3$-manifold. ",
    "url": "https://arxiv.org/abs/2303.06321",
    "authors": [
      "Benjamin A. Burton",
      "Alexander He"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.06340",
    "title": "Intelligent diagnostic scheme for lung cancer screening with Raman  spectra data by tensor network machine learning",
    "abstract": "Artificial intelligence (AI) has brought tremendous impacts on biomedical sciences from academic researches to clinical applications, such as in biomarkers' detection and diagnosis, optimization of treatment, and identification of new therapeutic targets in drug discovery. However, the contemporary AI technologies, particularly deep machine learning (ML), severely suffer from non-interpretability, which might uncontrollably lead to incorrect predictions. Interpretability is particularly crucial to ML for clinical diagnosis as the consumers must gain necessary sense of security and trust from firm grounds or convincing interpretations. In this work, we propose a tensor-network (TN)-ML method to reliably predict lung cancer patients and their stages via screening Raman spectra data of Volatile organic compounds (VOCs) in exhaled breath, which are generally suitable as biomarkers and are considered to be an ideal way for non-invasive lung cancer screening. The prediction of TN-ML is based on the mutual distances of the breath samples mapped to the quantum Hilbert space. Thanks to the quantum probabilistic interpretation, the certainty of the predictions can be quantitatively characterized. The accuracy of the samples with high certainty is almost 100$\\%$. The incorrectly-classified samples exhibit obviously lower certainty, and thus can be decipherably identified as anomalies, which will be handled by human experts to guarantee high reliability. Our work sheds light on shifting the ``AI for biomedical sciences'' from the conventional non-interpretable ML schemes to the interpretable human-ML interactive approaches, for the purpose of high accuracy and reliability. ",
    "url": "https://arxiv.org/abs/2303.06340",
    "authors": [
      "Yu-Jia An",
      "Sheng-Chen Bai",
      "Lin Cheng",
      "Xiao-Guang Li",
      "Cheng-en Wang",
      "Xiao-Dong Han",
      "Gang Su",
      "Shi-Ju Ran",
      "Cong Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06376",
    "title": "Assessing gender fairness in EEG-based machine learning detection of  Parkinson's disease: A multi-center study",
    "abstract": "As the number of automatic tools based on machine learning (ML) and resting-state electroencephalography (rs-EEG) for Parkinson's disease (PD) detection keeps growing, the assessment of possible exacerbation of health disparities by means of fairness and bias analysis becomes more relevant. Protected attributes, such as gender, play an important role in PD diagnosis development. However, analysis of sub-group populations stemming from different genders is seldom taken into consideration in ML models' development or the performance assessment for PD detection. In this work, we perform a systematic analysis of the detection ability for gender sub-groups in a multi-center setting of a previously developed ML algorithm based on power spectral density (PSD) features of rs-EEG. We find significant differences in the PD detection ability for males and females at testing time (80.5% vs. 63.7% accuracy) and significantly higher activity for a set of parietal and frontal EEG channels and frequency sub-bands for PD and non-PD males that might explain the differences in the PD detection ability for the gender sub-groups. ",
    "url": "https://arxiv.org/abs/2303.06376",
    "authors": [
      "Anna Kurbatskaya",
      "Alberto Jaramillo-Jimenez",
      "John Fredy Ochoa-Gomez",
      "Kolbj\u00f8rn Br\u00f8nnick",
      "Alvaro Fernandez-Quilez"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06423",
    "title": "Learning interpretable causal networks from very large datasets,  application to 400,000 medical records of breast cancer patients",
    "abstract": "Discovering causal effects is at the core of scientific investigation but remains challenging when only observational data is available. In practice, causal networks are difficult to learn and interpret, and limited to relatively small datasets. We report a more reliable and scalable causal discovery method (iMIIC), based on a general mutual information supremum principle, which greatly improves the precision of inferred causal relations while distinguishing genuine causes from putative and latent causal effects. We showcase iMIIC on synthetic and real-life healthcare data from 396,179 breast cancer patients from the US Surveillance, Epidemiology, and End Results program. More than 90\\% of predicted causal effects appear correct, while the remaining unexpected direct and indirect causal effects can be interpreted in terms of diagnostic procedures, therapeutic timing, patient preference or socio-economic disparity. iMIIC's unique capabilities open up new avenues to discover reliable and interpretable causal networks across a range of research fields. ",
    "url": "https://arxiv.org/abs/2303.06423",
    "authors": [
      "Marcel da C\u00e2mara Ribeiro-Dantas",
      "Honghao Li",
      "Vincent Cabeli",
      "Louise Dupuis",
      "Franck Simon",
      "Liza Hettal",
      "Anne-Sophie Hamy",
      "Herv\u00e9 Isambert"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Molecular Networks (q-bio.MN)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.06438",
    "title": "On Neural Architectures for Deep Learning-based Source Separation of  Co-Channel OFDM Signals",
    "abstract": "We study the single-channel source separation problem involving orthogonal frequency-division multiplexing (OFDM) signals, which are ubiquitous in many modern-day digital communication systems. Related efforts have been pursued in monaural source separation, where state-of-the-art neural architectures have been adopted to train an end-to-end separator for audio signals (as 1-dimensional time series). In this work, through a prototype problem based on the OFDM source model, we assess -- and question -- the efficacy of using audio-oriented neural architectures in separating signals based on features pertinent to communication waveforms. Perhaps surprisingly, we demonstrate that in some configurations, where perfect separation is theoretically attainable, these audio-oriented neural architectures perform poorly in separating co-channel OFDM waveforms. Yet, we propose critical domain-informed modifications to the network parameterization, based on insights from OFDM structures, that can confer about 30 dB improvement in performance. ",
    "url": "https://arxiv.org/abs/2303.06438",
    "authors": [
      "Gary C.F. Lee",
      "Amir Weiss",
      "Alejandro Lancho",
      "Yury Polyanskiy",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06475",
    "title": "Transcription free filler word detection with Neural semi-CRFs",
    "abstract": "Non-linguistic filler words, such as \"uh\" or \"um\", are prevalent in spontaneous speech and serve as indicators for expressing hesitation or uncertainty. Previous works for detecting certain non-linguistic filler words are highly dependent on transcriptions from a well-established commercial automatic speech recognition (ASR) system. However, certain ASR systems are not universally accessible from many aspects, e.g., budget, target languages, and computational power. In this work, we investigate filler word detection system that does not depend on ASR systems. We show that, by using the structured state space sequence model (S4) and neural semi-Markov conditional random fields (semi-CRFs), we achieve an absolute F1 improvement of 6.4% (segment level) and 3.1% (event level) on the PodcastFillers dataset. We also conduct a qualitative analysis on the detected results to analyze the limitations of our proposed system. ",
    "url": "https://arxiv.org/abs/2303.06475",
    "authors": [
      "Ge Zhu",
      "Yujia Yan",
      "Juan-Pablo Caceres",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.06483",
    "title": "Biclique immersions in graphs with independence number 2",
    "abstract": "The analog of Hadwiger's conjecture for the immersion relation states that every graph $G$ contains an immersion of $K_{\\chi(G)}$. For graphs with independence number 2, this is equivalent to stating that every such $n$-vertex graph contains an immersion of $K_{\\lceil n/2 \\rceil}$. We show that every $n$-vertex graph with independence number 2 contains every complete bipartite graph on $\\lceil n/2 \\rceil$ vertices as an immersion. ",
    "url": "https://arxiv.org/abs/2303.06483",
    "authors": [
      "F. Botler",
      "A. Jim\u00e9nez",
      "C. N. Lintzmayer",
      "A. Pastine",
      "D. A. Quiroz",
      "M. Sambinelli"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.06550",
    "title": "Spatial Correspondence between Graph Neural Network-Segmented Images",
    "abstract": "Graph neural networks (GNNs) have been proposed for medical image segmentation, by predicting anatomical structures represented by graphs of vertices and edges. One such type of graph is predefined with fixed size and connectivity to represent a reference of anatomical regions of interest, thus known as templates. This work explores the potentials in these GNNs with common topology for establishing spatial correspondence, implicitly maintained during segmenting two or more images. With an example application of registering local vertebral sub-regions found in CT images, our experimental results showed that the GNN-based segmentation is capable of accurate and reliable localization of the same interventionally interesting structures between images, not limited to the segmentation classes. The reported average target registration errors of 2.2$\\pm$1.3 mm and 2.7$\\pm$1.4 mm, for aligning holdout test images with a reference and for aligning two test images, respectively, were by a considerable margin lower than those from the tested non-learning and learning-based registration algorithms. Further ablation studies assess the contributions towards the registration performance, from individual components in the originally segmentation-purposed network and its training algorithm. The results highlight that the proposed segmentation-in-lieu-of-registration approach shares methodological similarities with existing registration methods, such as the use of displacement smoothness constraint and point distance minimization albeit on non-grid graphs, which interestingly yielded benefits for both segmentation and registration. We, therefore, conclude that the template-based GNN segmentation can effectively establish spatial correspondence in our application, without any other dedicated registration algorithms. ",
    "url": "https://arxiv.org/abs/2303.06550",
    "authors": [
      "Qian Li",
      "Yunguan Fu",
      "Qianye Yang",
      "Zhijiang Du",
      "Hongjian Yu",
      "Yipeng Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06740",
    "title": "Fine-tuning Strategies for Faster Inference using Speech Self-Supervised  Models: A Comparative Study",
    "abstract": "Self-supervised learning (SSL) has allowed substantial progress in Automatic Speech Recognition (ASR) performance in low-resource settings. In this context, it has been demonstrated that larger self-supervised feature extractors are crucial for achieving lower downstream ASR error rates. Thus, better performance might be sanctioned with longer inferences. This article explores different approaches that may be deployed during the fine-tuning to reduce the computations needed in the SSL encoder, leading to faster inferences. We adapt a number of existing techniques to common ASR settings and benchmark them, displaying performance drops and gains in inference times. Interestingly, we found that given enough downstream data, a simple downsampling of the input sequences outperforms the other methods with both low performance drops and high computational savings, reducing computations by 61.3% with an WER increase of only 0.81. Finally, we analyze the robustness of the comparison to changes in dataset conditions, revealing sensitivity to dataset size. ",
    "url": "https://arxiv.org/abs/2303.06740",
    "authors": [
      "Salah Zaiem",
      "Robin Algayres",
      "Titouan Parcollet",
      "Slim Essid",
      "Mirco Ravanelli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06806",
    "title": "Neural Diarization with Non-autoregressive Intermediate Attractors",
    "abstract": "End-to-end neural diarization (EEND) with encoder-decoder-based attractors (EDA) is a promising method to handle the whole speaker diarization problem simultaneously with a single neural network. While the EEND model can produce all frame-level speaker labels simultaneously, it disregards output label dependency. In this work, we propose a novel EEND model that introduces the label dependency between frames. The proposed method generates non-autoregressive intermediate attractors to produce speaker labels at the lower layers and conditions the subsequent layers with these labels. While the proposed model works in a non-autoregressive manner, the speaker labels are refined by referring to the whole sequence of intermediate labels. The experiments with the two-speaker CALLHOME dataset show that the intermediate labels with the proposed non-autoregressive intermediate attractors boost the diarization performance. The proposed method with the deeper network benefits more from the intermediate labels, resulting in better performance and training throughput than EEND-EDA. ",
    "url": "https://arxiv.org/abs/2303.06806",
    "authors": [
      "Yusuke Fujita",
      "Tatsuya Komatsu",
      "Robin Scheibler",
      "Yusuke Kida",
      "Tetsuji Ogawa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.06902",
    "title": "Molecular Property Prediction by Semantic-invariant Contrastive Learning",
    "abstract": "Contrastive learning have been widely used as pretext tasks for self-supervised pre-trained molecular representation learning models in AI-aided drug design and discovery. However, exiting methods that generate molecular views by noise-adding operations for contrastive learning may face the semantic inconsistency problem, which leads to false positive pairs and consequently poor prediction performance. To address this problem, in this paper we first propose a semantic-invariant view generation method by properly breaking molecular graphs into fragment pairs. Then, we develop a Fragment-based Semantic-Invariant Contrastive Learning (FraSICL) model based on this view generation method for molecular property prediction. The FraSICL model consists of two branches to generate representations of views for contrastive learning, meanwhile a multi-view fusion and an auxiliary similarity loss are introduced to make better use of the information contained in different fragment-pair views. Extensive experiments on various benchmark datasets show that with the least number of pre-training samples, FraSICL can achieve state-of-the-art performance, compared with major existing counterpart models. ",
    "url": "https://arxiv.org/abs/2303.06902",
    "authors": [
      "Ziqiao Zhang",
      "Ailin Xie",
      "Jihong Guan",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06945",
    "title": "CoGANPPIS: Coevolution-enhanced Global Attention Neural Network for  Protein-Protein Interaction Site Prediction",
    "abstract": "Protein-protein interactions are essential in biochemical processes. Accurate prediction of the protein-protein interaction sites (PPIs) deepens our understanding of biological mechanism and is crucial for new drug design. However, conventional experimental methods for PPIs prediction are costly and time-consuming so that many computational approaches, especially ML-based methods, have been developed recently. Although these approaches have achieved gratifying results, there are still two limitations: (1) Most models have excavated some useful input features, but failed to take coevolutionary features into account, which could provide clues for inter-residue relationships; (2) The attention-based models only allocate attention weights for neighboring residues, instead of doing it globally, neglecting that some residues being far away from the target residues might also matter. We propose a coevolution-enhanced global attention neural network, a sequence-based deep learning model for PPIs prediction, called CoGANPPIS. It utilizes three layers in parallel for feature extraction: (1) Local-level representation aggregation layer, which aggregates the neighboring residues' features; (2) Global-level representation learning layer, which employs a novel coevolution-enhanced global attention mechanism to allocate attention weights to all the residues on the same protein sequences; (3) Coevolutionary information learning layer, which applies CNN & pooling to coevolutionary information to obtain the coevolutionary profile representation. Then, the three outputs are concatenated and passed into several fully connected layers for the final prediction. Application on two benchmark datasets demonstrated a state-of-the-art performance of our model. The source code is publicly available at https://github.com/Slam1423/CoGANPPIS_source_code. ",
    "url": "https://arxiv.org/abs/2303.06945",
    "authors": [
      "Jiaxing Guo",
      "Xuening Zhu",
      "Zixin Hu",
      "Xiaoxi Hu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07053",
    "title": "Bandit-supported care planning for older people with complex health and  care needs",
    "abstract": "Long-term care service for old people is in great demand in most of the aging societies. The number of nursing homes residents is increasing while the number of care providers is limited. Due to the care worker shortage, care to vulnerable older residents cannot be fully tailored to the unique needs and preference of each individual. This may bring negative impacts on health outcomes and quality of life among institutionalized older people. To improve care quality through personalized care planning and delivery with limited care workforce, we propose a new care planning model assisted by artificial intelligence. We apply bandit algorithms which optimize the clinical decision for care planning by adapting to the sequential feedback from the past decisions. We evaluate the proposed model on empirical data acquired from the Systems for Person-centered Elder Care (SPEC) study, a ICT-enhanced care management program. ",
    "url": "https://arxiv.org/abs/2303.07053",
    "authors": [
      "Gi-Soo Kim",
      "Young Suh Hong",
      "Tae Hoon Lee",
      "Myunghee Cho Paik",
      "Hongsoo Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07131",
    "title": "Evolutionary quantum feature selection",
    "abstract": "Effective feature selection is essential for enhancing the performance of artificial intelligence models. It involves identifying feature combinations that optimize a given metric, but this is a challenging task due to the problem's exponential time complexity. In this study, we present an innovative heuristic called Evolutionary Quantum Feature Selection (EQFS) that employs the Quantum Circuit Evolution (QCE) algorithm. Our approach harnesses the unique capabilities of QCE, which utilizes shallow depth circuits to generate sparse probability distributions. Our computational experiments demonstrate that EQFS can identify good feature combinations with quadratic scaling in the number of features. To evaluate EQFS's performance, we counted the number of times a given classical model assesses the cost function for a specific metric, as a function of the number of generations. ",
    "url": "https://arxiv.org/abs/2303.07131",
    "authors": [
      "Anton S. Albino",
      "Otto M. Pires",
      "Mauro Q. Nooblath",
      "Erick G. S. Nascimento"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.07148",
    "title": "The Topology of Causality",
    "abstract": "We provide a unified operational framework for the study of causality, non-locality and contextuality, in a fully device-independent and theory-independent setting. Our work has its roots in the sheaf-theoretic framework for contextuality by Abramsky and Brandenburger, which it extends to include arbitrary causal orders (be they definite, dynamical or indefinite). We define a notion of causal function for arbitrary spaces of input histories, and we show that the explicit imposition of causal constraints on joint outputs is equivalent to the free assignment of local outputs to the tip events of input histories. We prove factorisation results for causal functions over parallel, sequential, and conditional sequential compositions of the underlying spaces. We prove that causality is equivalent to continuity with respect to the lowerset topology on the underlying spaces, and we show that partial causal functions defined on open sub-spaces can be bundled into a presheaf. In a striking departure from the Abramsky-Brandenburger setting, however, we show that causal functions fail, under certain circumstances, to form a sheaf. We define empirical models as compatible families in the presheaf of probability distributions on causal functions, for arbitrary open covers of the underlying space of input histories. We show the existence of causally-induced contextuality, a phenomenon arising when the causal constraints themselves become context-dependent, and we prove a no-go result for non-locality on total orders, both static and dynamical. ",
    "url": "https://arxiv.org/abs/2303.07148",
    "authors": [
      "Stefano Gogioso",
      "Nicola Pinzani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ]
  },
  {
    "id": "arXiv:2303.07157",
    "title": "An elementary method to compute equivariant convolutional kernels on  homogeneous spaces for geometric deep learning",
    "abstract": "We develop an elementary method to compute spaces of equivariant maps from a homogeneous space of a Lie group to a module of this group. The Lie group is not required to be compact. More generally we study spaces of invariant sections in homogeneous vector bundles, and take a special interest in the case where the fibres are algebras. This latter case has a natural global algebra structure. We classify the resulting automorphic algebras for the case where the homogeneous space has compact stabilisers. This work has applications in the theoretical development of geometric deep learning and also in the theory of automorphic Lie algebras. ",
    "url": "https://arxiv.org/abs/2303.07157",
    "authors": [
      "Vincent Knibbeler"
    ],
    "subjectives": [
      "Representation Theory (math.RT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07189",
    "title": "Optimizing Convolutional Neural Networks for Chronic Obstructive  Pulmonary Disease Detection in Clinical Computed Tomography Imaging",
    "abstract": "Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of death worldwide, yet early detection and treatment can prevent the progression of the disease. In contrast to the conventional method of detecting COPD with spirometry tests, X-ray Computed Tomography (CT) scans of the chest provide a measure of morphological changes in the lung. It has been shown that automated detection of COPD can be performed with deep learning models. However, the potential of incorporating optimal window setting selection, typically carried out by clinicians during examination of CT scans for COPD, is generally overlooked in deep learning approaches. We aim to optimize the binary classification of COPD with densely connected convolutional neural networks (DenseNets) through implementation of manual and automated Window-Setting Optimization (WSO) steps. Our dataset consisted of 78 CT scans from the Klinikum rechts der Isar research hospital. Repeated inference on the test set showed that without WSO, the plain DenseNet resulted in a mean slice-level AUC of 0.80$\\pm$0.05. With input images manually adjusted to the emphysema window setting, the plain DenseNet model predicted COPD with a mean AUC of 0.86$\\pm$0.04. By automating the WSO through addition of a customized layer to the DenseNet, an optimal window setting in the proximity of the emphysema window setting was learned and a mean AUC of 0.82$\\pm$0.04 was achieved. Detection of COPD with DenseNet models was optimized by WSO of CT data to the emphysema window setting range, demonstrating the importance of implementing optimal window setting selection in the deep learning pipeline. ",
    "url": "https://arxiv.org/abs/2303.07189",
    "authors": [
      "Tina Dorosti",
      "Manuel Schultheiss",
      "Felix Hofmann",
      "Luisa Kirchner",
      "Theresa Urban",
      "Franz Pfeiffer",
      "Johannes Thalhammer",
      "Florian Schaff",
      "Tobias Lasser",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07208",
    "title": "Social network analysis of Japanese manga: similarities to real-world  social networks and trends over decades",
    "abstract": "Manga, Japanese comics, has been popular on a global scale. Social networks among characters, which are often called character networks, may be a significant contributor to their popularity. We collected data from 162 popular manga that span over 70 years and analyzed their character networks. First, we found that many of static and temporal properties of the character networks are similar to those of real human social networks. Second, the character networks of most manga are protagonist-centered such that a single protagonist interacts with the majority of other characters. Third, the character networks for manga mainly targeting boys have shifted to denser and less protagonist-centered networks and with fewer characters over decades. Manga mainly targeting girls showed the opposite trend except for the downward trend in the number of characters. The present study, which relies on manga data sampled on an unprecedented scale, paves the way for further population studies of character networks and other aspects of comics. ",
    "url": "https://arxiv.org/abs/2303.07208",
    "authors": [
      "Kashin Sugishita",
      "Naoki Masuda"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2003.12163",
    "title": "Using constraint structure and an improved object detection network to  detect the 12^{th} Vertebra from CT images with a limited field of view for  image-guided radiotherapy",
    "abstract": " Comments: 10 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2003.12163",
    "authors": [
      "Yunhe Xie",
      "Kongbin Kang",
      "Gregory Sharp",
      "David P. Gierga",
      "Theodore S. Hong",
      "Thomas Bortfeld"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2008.02144",
    "title": "FRMDN: Flow-based Recurrent Mixture Density Network",
    "abstract": " Title: FRMDN: Flow-based Recurrent Mixture Density Network ",
    "url": "https://arxiv.org/abs/2008.02144",
    "authors": [
      "Seyedeh Fatemeh Razavi",
      "Reshad Hosseini",
      "Tina Behzad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.08915",
    "title": "LOCUS: A Novel Decomposition Method for Brain Network Connectivity  Matrices using Low-rank Structure with Uniform Sparsity",
    "abstract": " Title: LOCUS: A Novel Decomposition Method for Brain Network Connectivity  Matrices using Low-rank Structure with Uniform Sparsity ",
    "url": "https://arxiv.org/abs/2008.08915",
    "authors": [
      "Yikai Wang",
      "Ying Guo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.03386",
    "title": "SoK: Training Machine Learning Models over Multiple Sources with Privacy  Preservation",
    "abstract": " Comments: 19pages, 4 figures ",
    "url": "https://arxiv.org/abs/2012.03386",
    "authors": [
      "Lushan Song",
      "Guopeng Lin",
      "Jiaxuan Wang",
      "Haoqi Wu",
      "Wenqiang Ruan",
      "Weili Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.00311",
    "title": "Disclosure Risk from Homogeneity Attack in Differentially Private  Frequency Distribution",
    "abstract": " Title: Disclosure Risk from Homogeneity Attack in Differentially Private  Frequency Distribution ",
    "url": "https://arxiv.org/abs/2101.00311",
    "authors": [
      "Fang Liu",
      "Xingyuan Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2102.00473",
    "title": "The impact of prior knowledge on causal structure learning",
    "abstract": " Title: The impact of prior knowledge on causal structure learning ",
    "url": "https://arxiv.org/abs/2102.00473",
    "authors": [
      "Anthony C. Constantinou",
      "Zhigao Guo",
      "Neville K. Kitson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.13640",
    "title": "NOMU: Neural Optimization-based Model Uncertainty",
    "abstract": " Comments: 9 pages + appendix ",
    "url": "https://arxiv.org/abs/2102.13640",
    "authors": [
      "Jakob Heiss",
      "Jakob Weissteiner",
      "Hanna Wutte",
      "Sven Seuken",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2105.11115",
    "title": "Self-Attention Networks Can Process Bounded Hierarchical Languages",
    "abstract": " Comments: ACL 2021. 19 pages with extended appendix. Fixed a small typo in the formula at the end of page 5 (thank to Gabriel Faria). Code: this https URL ",
    "url": "https://arxiv.org/abs/2105.11115",
    "authors": [
      "Shunyu Yao",
      "Binghui Peng",
      "Christos Papadimitriou",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2105.15010",
    "title": "Query Attack by Multi-Identity Surrogates",
    "abstract": " Comments: IEEE TRANSACTIONS ON ARTIFICIAL INTELLIGENCE ",
    "url": "https://arxiv.org/abs/2105.15010",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.01902",
    "title": "Joint Multi-Channel Dereverberation and Noise Reduction Using a Unified  Convolutional Beamformer With Sparse Priors",
    "abstract": " Comments: ITG Conference on Speech Communication ",
    "url": "https://arxiv.org/abs/2106.01902",
    "authors": [
      "Henri Gode",
      "Marvin Tammen",
      "Simon Doclo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2106.03393",
    "title": "Adversarially Regularized Graph Attention Networks for Inductive  Learning on Partially Labeled Graphs",
    "abstract": " Title: Adversarially Regularized Graph Attention Networks for Inductive  Learning on Partially Labeled Graphs ",
    "url": "https://arxiv.org/abs/2106.03393",
    "authors": [
      "Jiaren Xiao",
      "Quanyu Dai",
      "Xiaochen Xie",
      "James Lam",
      "Ka-Wai Kwok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2106.07513",
    "title": "CodeLabeller: A Web-based Code Annotation Tool for Java Design Patterns  and Summaries",
    "abstract": " Comments: 15 pages, 5 Figures, 6 Tables ",
    "url": "https://arxiv.org/abs/2106.07513",
    "authors": [
      "Najam Nazar",
      "Norman Chen",
      "Chun Yong Chong"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2108.11673",
    "title": "Why Adversarial Reprogramming Works, When It Fails, and How to Tell the  Difference",
    "abstract": " Title: Why Adversarial Reprogramming Works, When It Fails, and How to Tell the  Difference ",
    "url": "https://arxiv.org/abs/2108.11673",
    "authors": [
      "Yang Zheng",
      "Xiaoyi Feng",
      "Zhaoqiang Xia",
      "Xiaoyue Jiang",
      "Ambra Demontis",
      "Maura Pintor",
      "Battista Biggio",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.15117",
    "title": "Monotone-Value Neural Networks: Exploiting Preference Monotonicity in  Combinatorial Assignment",
    "abstract": " Title: Monotone-Value Neural Networks: Exploiting Preference Monotonicity in  Combinatorial Assignment ",
    "url": "https://arxiv.org/abs/2109.15117",
    "authors": [
      "Jakob Weissteiner",
      "Jakob Heiss",
      "Julien Siems",
      "Sven Seuken"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2110.06804",
    "title": "A comprehensive review of Binary Neural Network",
    "abstract": " Comments: accepted by journal of Artificial Intelligence Review ",
    "url": "https://arxiv.org/abs/2110.06804",
    "authors": [
      "Chunyu Yuan",
      "Sos S. Agaian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2110.10423",
    "title": "ProxyBO: Accelerating Neural Architecture Search via Bayesian  Optimization with Zero-cost Proxies",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2110.10423",
    "authors": [
      "Yu Shen",
      "Yang Li",
      "Jian Zheng",
      "Wentao Zhang",
      "Peng Yao",
      "Jixiang Li",
      "Sen Yang",
      "Ji Liu",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.01906",
    "title": "A trained humanoid robot can perform human-like crossmodal social  attention and conflict resolution",
    "abstract": " Comments: accepted for publication in the International Journal of Social Robotics ",
    "url": "https://arxiv.org/abs/2111.01906",
    "authors": [
      "Di Fu",
      "Fares Abawi",
      "Hugo Carneiro",
      "Matthias Kerzel",
      "Ziwei Chen",
      "Erik Strahl",
      "Xun Liu",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2112.09231",
    "title": "Two-view Graph Neural Networks for Knowledge Graph Completion",
    "abstract": " Comments: To appear in Proceedings of ESWC 2023; 17 pages; 4 tables; 4 figures ",
    "url": "https://arxiv.org/abs/2112.09231",
    "authors": [
      "Vinh Tong",
      "Dai Quoc Nguyen",
      "Dinh Phung",
      "Dat Quoc Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.10885",
    "title": "PRONTO: Preamble Overhead Reduction with Neural Networks for Coarse  Synchronization",
    "abstract": " Title: PRONTO: Preamble Overhead Reduction with Neural Networks for Coarse  Synchronization ",
    "url": "https://arxiv.org/abs/2112.10885",
    "authors": [
      "Nasim Soltani",
      "Debashri Roy",
      "Kaushik Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.11191",
    "title": "Developing a Trusted Human-AI Network for Humanitarian Benefit",
    "abstract": " Comments: 34 pages, 7 figures, 3 boxes, submitted for peer review to the Journal of Digital War, My War Special Issue ",
    "url": "https://arxiv.org/abs/2112.11191",
    "authors": [
      "Susannah Kate Devitt",
      "Jason Scholz",
      "Timo Schless",
      "Larry Lewis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.06164",
    "title": "Synthesis and Reconstruction of Fingerprints using Generative  Adversarial Networks",
    "abstract": " Title: Synthesis and Reconstruction of Fingerprints using Generative  Adversarial Networks ",
    "url": "https://arxiv.org/abs/2201.06164",
    "authors": [
      "Rafael Bouzaglo",
      "Yosi Keller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.06837",
    "title": "Landslide Susceptibility Modeling by Interpretable Neural Network",
    "abstract": " Comments: 79 pages (including SI section); 8 main figures; 12 supplementary figures; 9 supplementary tables ",
    "url": "https://arxiv.org/abs/2201.06837",
    "authors": [
      "Khaled Youssef",
      "Kevin Shao",
      "Seulgi Moon",
      "Louis-Serge Bouchard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2201.09635",
    "title": "State-Conditioned Adversarial Subgoal Generation",
    "abstract": " Title: State-Conditioned Adversarial Subgoal Generation ",
    "url": "https://arxiv.org/abs/2201.09635",
    "authors": [
      "Vivienne Huiling Wang",
      "Joni Pajarinen",
      "Tinghuai Wang",
      "Joni-Kristian K\u00e4m\u00e4r\u00e4inen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.00395",
    "title": "Is the Performance of My Deep Network Too Good to Be True? A Direct  Approach to Estimating the Bayes Error in Binary Classification",
    "abstract": " Comments: ICLR 2023 (notable-top-5%) ",
    "url": "https://arxiv.org/abs/2202.00395",
    "authors": [
      "Takashi Ishida",
      "Ikko Yamane",
      "Nontawat Charoenphakdee",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03861",
    "title": "Towards Making a Trojan-horse Attack on Text-to-Image Retrieval",
    "abstract": " Comments: Accepted by ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2202.03861",
    "authors": [
      "Fan Hu",
      "Aozhu Chen",
      "Xirong Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2202.04110",
    "title": "PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and  Loopy Belief Propagation in JAX",
    "abstract": " Comments: Update authors list ",
    "url": "https://arxiv.org/abs/2202.04110",
    "authors": [
      "Guangyao Zhou",
      "Antoine Dedieu",
      "Nishanth Kumar",
      "Miguel L\u00e1zaro-Gredilla",
      "Shrinu Kushagra",
      "Dileep George"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07861",
    "title": "Practical Network Acceleration with Tiny Sets",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2202.07861",
    "authors": [
      "Guo-Hua Wang",
      "Jianxin Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.09253",
    "title": "Sketching Distances in Monotone Graph Classes",
    "abstract": " Comments: 38 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2202.09253",
    "authors": [
      "Louis Esperet",
      "Nathaniel Harms",
      "Andrey Kupavskii"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.00049",
    "title": "Towards Targeted Change Detection with Heterogeneous Remote Sensing  Images for Forest Mortality Mapping",
    "abstract": " Comments: 46 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2203.00049",
    "authors": [
      "J\u00f8rgen A. Agersborg",
      "Luigi T. Luppino",
      "Stian Normann Anfinsen",
      "Jane Uhd Jepsen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00373",
    "title": "On a faithful representation of Sturmian morphisms",
    "abstract": " Comments: 26 pages ",
    "url": "https://arxiv.org/abs/2203.00373",
    "authors": [
      "Jana Lep\u0161ov\u00e1",
      "Edita Pelantov\u00e1",
      "\u0160t\u011bp\u00e1n Starosta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2203.03179",
    "title": "Detecting data-driven robust statistical arbitrage strategies with deep  neural networks",
    "abstract": " Title: Detecting data-driven robust statistical arbitrage strategies with deep  neural networks ",
    "url": "https://arxiv.org/abs/2203.03179",
    "authors": [
      "Ariel Neufeld",
      "Julian Sester",
      "Daiying Yin"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Statistical Finance (q-fin.ST)",
      "Trading and Market Microstructure (q-fin.TR)"
    ]
  },
  {
    "id": "arXiv:2203.04865",
    "title": "A Unified Network Equilibrium for E-Hailing Platform Operation and  Customer Mode Choice",
    "abstract": " Title: A Unified Network Equilibrium for E-Hailing Platform Operation and  Customer Mode Choice ",
    "url": "https://arxiv.org/abs/2203.04865",
    "authors": [
      "Xu Chen",
      "Xuan Di"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.08972",
    "title": "Extensive Threat Analysis of Vein Attack Databases and Attack Detection  by Fusion of Comparison Scores",
    "abstract": " Comments: This is a preprint of a chapter published in Handbook of Biometric Anti-Spoofing Third Edition: Presentation Attack Detection and Vulnerability Assessment, edited by Marcel, S., Fierrez, J., Evans, N., 2023, Springer, Singapore reproduced with permission of Springer Nature Singapore Pte Ltd ",
    "url": "https://arxiv.org/abs/2203.08972",
    "authors": [
      "Johannes Schuiki",
      "Michael Linortner",
      "Georg Wimmer",
      "Andreas Uhl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.00497",
    "title": "Separate and conquer heuristic allows robust mining of contrast sets in  classification, regression, and survival data",
    "abstract": " Comments: 36 pages, 6 figures, 3 tables, 3 algorithms ",
    "url": "https://arxiv.org/abs/2204.00497",
    "authors": [
      "Adam Gudy\u015b",
      "Marek Sikora",
      "\u0141ukasz Wr\u00f3bel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.01682",
    "title": "Deep Feature Screening: Feature Selection for Ultra High-Dimensional  Data via Deep Neural Networks",
    "abstract": " Title: Deep Feature Screening: Feature Selection for Ultra High-Dimensional  Data via Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2204.01682",
    "authors": [
      "Kexuan Li",
      "Fangfang Wang",
      "Lingli Yang",
      "Ruiqi Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04788",
    "title": "Representation Learning by Detecting Incorrect Location Embeddings",
    "abstract": " Comments: accepted at AAAI2023, this https URL ",
    "url": "https://arxiv.org/abs/2204.04788",
    "authors": [
      "Sepehr Sameni",
      "Simon Jenni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05727",
    "title": "LiDAR Road-Atlas: An Efficient Map Representation for General 3D Urban  Environment",
    "abstract": " Title: LiDAR Road-Atlas: An Efficient Map Representation for General 3D Urban  Environment ",
    "url": "https://arxiv.org/abs/2204.05727",
    "authors": [
      "Banghe Wu",
      "Chengzhong Xu",
      "Hui Kong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.09804",
    "title": "Weighted Bayesian Gaussian Mixture Model for Roadside LiDAR Object  Detection",
    "abstract": " Title: Weighted Bayesian Gaussian Mixture Model for Roadside LiDAR Object  Detection ",
    "url": "https://arxiv.org/abs/2204.09804",
    "authors": [
      "Tianya Zhang",
      "Yi Ge",
      "Peter J. Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.13096",
    "title": "3D Magic Mirror: Clothing Reconstruction from a Single Image via a  Causal Perspective",
    "abstract": " Comments: Update results. Report person re-id performance. Add details in Appendix ",
    "url": "https://arxiv.org/abs/2204.13096",
    "authors": [
      "Zhedong Zheng",
      "Jiayin Zhu",
      "Wei Ji",
      "Yi Yang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.04783",
    "title": "Matrix and graph representations of vine copula structures",
    "abstract": " Comments: 23 pages, 27 figures ",
    "url": "https://arxiv.org/abs/2205.04783",
    "authors": [
      "D\u00e1niel Pfeifer",
      "Edith Alice Kov\u00e1cs"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09435",
    "title": "Adversarial random forests for density estimation and generative  modeling",
    "abstract": " Comments: Camera ready version (AISTATS 2023) ",
    "url": "https://arxiv.org/abs/2205.09435",
    "authors": [
      "David S. Watson",
      "Kristin Blesch",
      "Jan Kapar",
      "Marvin N. Wright"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2205.12706",
    "title": "Maximum Mean Discrepancy on Exponential Windows for Online Change  Detection",
    "abstract": " Title: Maximum Mean Discrepancy on Exponential Windows for Online Change  Detection ",
    "url": "https://arxiv.org/abs/2205.12706",
    "authors": [
      "Florian Kalinke",
      "Marco Heyden",
      "Edouard Fouch\u00e9",
      "Klemens B\u00f6hm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07331",
    "title": "ETMA: Efficient Transformer Based Multilevel Attention framework for  Multimodal Fake News Detection",
    "abstract": " Comments: Accepted for publication in IEEE Transactions on Computational Social Systems ",
    "url": "https://arxiv.org/abs/2206.07331",
    "authors": [
      "Ashima Yadav",
      "Shivani Gaba",
      "Haneef Khan",
      "Ishan Budhiraja",
      "Akansha Singh",
      "Krishan Kant Singh"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2206.12276",
    "title": "Multi-Frequency Joint Community Detection and Phase Synchronization",
    "abstract": " Comments: Accepted by IEEE Transactions on Signal and Information Processing over Networks ",
    "url": "https://arxiv.org/abs/2206.12276",
    "authors": [
      "Lingda Wang",
      "Zhizhen Zhao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.09088",
    "title": "XG-BoT: An Explainable Deep Graph Neural Network for Botnet Detection  and Forensics",
    "abstract": " Comments: Accepted by Internet of Things, Elsevier ",
    "url": "https://arxiv.org/abs/2207.09088",
    "authors": [
      "Wai Weng Lo",
      "Gayan K. Kulatilleke",
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.00982",
    "title": "Dominant Eigenvalue-Eigenvector Pair Estimation via Graph Infection",
    "abstract": " Comments: 17 pages, 8 figures, 3 tables. GitHub source code: this https URL ",
    "url": "https://arxiv.org/abs/2208.00982",
    "authors": [
      "Kaiyuan Yang",
      "Li Xia",
      "Y.C. Tay"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2208.02785",
    "title": "Notions, Stability, Existence, and Robustness of Limit Cycles in Hybrid  Systems",
    "abstract": " Comments: 29 pages. Version submitted for review ",
    "url": "https://arxiv.org/abs/2208.02785",
    "authors": [
      "Xuyang Lou",
      "Yuchun Li",
      "Ricardo G. Sanfelice"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.07441",
    "title": "WatchPed: Pedestrian Crossing Intention Prediction Using Embedded  Sensors of Smartwatch",
    "abstract": " Title: WatchPed: Pedestrian Crossing Intention Prediction Using Embedded  Sensors of Smartwatch ",
    "url": "https://arxiv.org/abs/2208.07441",
    "authors": [
      "Jibran Ali Abbasi",
      "Navid Mohammad Imran",
      "Myounggyu Won"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.11489",
    "title": "A Generalization of the Shortest Path Problem to Graphs with Multiple  Edge-Cost Estimates",
    "abstract": " Title: A Generalization of the Shortest Path Problem to Graphs with Multiple  Edge-Cost Estimates ",
    "url": "https://arxiv.org/abs/2208.11489",
    "authors": [
      "Eyal Weiss",
      "Ariel Felner",
      "Gal A. Kaminka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2208.12506",
    "title": "EGFR Mutation Prediction of Lung Biopsy Images using Deep Learning",
    "abstract": " Comments: We need to improve ",
    "url": "https://arxiv.org/abs/2208.12506",
    "authors": [
      "Ravi Kant Gupta",
      "Shivani Nandgaonkar",
      "Nikhil Cherian Kurian",
      "Swapnil Rane",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.12700",
    "title": "Epistemic Parity: Reproducibility as an Evaluation Metric for  Differential Privacy",
    "abstract": " Comments: Preprint. 14 pages ",
    "url": "https://arxiv.org/abs/2208.12700",
    "authors": [
      "Lucas Rosenblatt",
      "Bernease Herman",
      "Anastasia Holovenko",
      "Wonkwon Lee",
      "Joshua Loftus",
      "Elizabeth McKinnie Taras Rumezhak",
      "Andrii Stadnik",
      "Bill Howe",
      "Julia Stoyanovich"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2209.01851",
    "title": "Recognizing Geometric Intersection Graphs Stabbed by a Line",
    "abstract": " Comments: 18 pages, 11 Figures ",
    "url": "https://arxiv.org/abs/2209.01851",
    "authors": [
      "Dibyayan Chakraborty",
      "Kshitij Gajjar",
      "Irena Rusu"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2209.03485",
    "title": "Energy Optimization of Wind Turbines via a Neural Control Policy Based  on Reinforcement Learning Markov Chain Monte Carlo Algorithm",
    "abstract": " Title: Energy Optimization of Wind Turbines via a Neural Control Policy Based  on Reinforcement Learning Markov Chain Monte Carlo Algorithm ",
    "url": "https://arxiv.org/abs/2209.03485",
    "authors": [
      "Vahid Tavakol Aghaei",
      "Arda A\u011fababao\u011flu",
      "Biram Bawo",
      "Peiman Naseradinmousavi",
      "Sinan Y\u0131ld\u0131r\u0131m",
      "Serhat Ye\u015filyurt",
      "Ahmet Onat"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.08993",
    "title": "On the design of multiplex control to reject disturbances in nonlinear  network systems affected by heterogeneous delays",
    "abstract": " Comments: Accepted for presentation at ACC 2023 ",
    "url": "https://arxiv.org/abs/2209.08993",
    "authors": [
      "Shihao Xie",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.13679",
    "title": "V2XP-ASG: Generating Adversarial Scenes for Vehicle-to-Everything  Perception",
    "abstract": " Comments: ICRA 2023, see this https URL ",
    "url": "https://arxiv.org/abs/2209.13679",
    "authors": [
      "Hao Xiang",
      "Runsheng Xu",
      "Xin Xia",
      "Zhaoliang Zheng",
      "Bolei Zhou",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14074",
    "title": "Recipro-CAM: Fast gradient-free visual explanations for convolutional  neural networks",
    "abstract": " Title: Recipro-CAM: Fast gradient-free visual explanations for convolutional  neural networks ",
    "url": "https://arxiv.org/abs/2209.14074",
    "authors": [
      "Seok-Yong Byun",
      "Wonju Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00465",
    "title": "Assessing the impact of contextual information in hate speech detection",
    "abstract": " Title: Assessing the impact of contextual information in hate speech detection ",
    "url": "https://arxiv.org/abs/2210.00465",
    "authors": [
      "Juan Manuel P\u00e9rez",
      "Franco Luque",
      "Demian Zayat",
      "Mart\u00edn Kondratzky",
      "Agust\u00edn Moro",
      "Pablo Serrati",
      "Joaqu\u00edn Zajac",
      "Paula Miguel",
      "Natalia Debandi",
      "Agust\u00edn Gravano",
      "Viviana Cotik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00520",
    "title": "Periodic orbits in deterministic discrete-time evolutionary game  dynamics: An information-theoretic perspective",
    "abstract": " Comments: 10 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2210.00520",
    "authors": [
      "Sayak Bhattacharjee",
      "Vikash Kumar Dubey",
      "Archan Mukhopadhyay",
      "Sagar Chakraborty"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Information Theory (cs.IT)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2210.00638",
    "title": "What shapes the loss landscape of self-supervised learning?",
    "abstract": " Comments: Published at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.00638",
    "authors": [
      "Liu Ziyin",
      "Ekdeep Singh Lubana",
      "Masahito Ueda",
      "Hidenori Tanaka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2210.02992",
    "title": "COVID-19 Detection Using Segmentation, Region Extraction and  Classification Pipeline",
    "abstract": " Title: COVID-19 Detection Using Segmentation, Region Extraction and  Classification Pipeline ",
    "url": "https://arxiv.org/abs/2210.02992",
    "authors": [
      "Kenan Morani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04087",
    "title": "Symmetry Defense Against CNN Adversarial Perturbation Attacks",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2210.04087",
    "authors": [
      "Blerta Lindqvist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05333",
    "title": "Routing Schemes for Hybrid Communication Networks",
    "abstract": " Title: Routing Schemes for Hybrid Communication Networks ",
    "url": "https://arxiv.org/abs/2210.05333",
    "authors": [
      "Sam Coy",
      "Artur Czumaj",
      "Christian Scheideler",
      "Philipp Schneider",
      "Julian Werthmann"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.06006",
    "title": "BEV-LaneDet: a Simple and Effective 3D Lane Detection Baseline",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2210.06006",
    "authors": [
      "Ruihao Wang",
      "Jian Qin",
      "Kaiying Li",
      "Yaochen Li",
      "Dong Cao",
      "Jintao Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07199",
    "title": "Self-Supervised Geometric Correspondence for Category-Level 6D Object  Pose Estimation in the Wild",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2210.07199",
    "authors": [
      "Kaifeng Zhang",
      "Yang Fu",
      "Shubhankar Borse",
      "Hong Cai",
      "Fatih Porikli",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.09420",
    "title": "Differentiable Physics Simulation of Dynamics-Augmented Neural Objects",
    "abstract": " Title: Differentiable Physics Simulation of Dynamics-Augmented Neural Objects ",
    "url": "https://arxiv.org/abs/2210.09420",
    "authors": [
      "Simon Le Cleac'h",
      "Hong-Xing Yu",
      "Michelle Guo",
      "Taylor A. Howell",
      "Ruohan Gao",
      "Jiajun Wu",
      "Zachary Manchester",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10488",
    "title": "Attribution and Obfuscation of Neural Text Authorship: A Data Mining  Perspective",
    "abstract": " Comments: Accepted at ACM SIGKDD Explorations, Vol. 25, June 2023 ",
    "url": "https://arxiv.org/abs/2210.10488",
    "authors": [
      "Adaku Uchendu",
      "Thai Le",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11588",
    "title": "Anchored Speech Recognition with Neural Transducers",
    "abstract": " Comments: To appear at IEEE ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.11588",
    "authors": [
      "Desh Raj",
      "Junteng Jia",
      "Jay Mahadeokar",
      "Chunyang Wu",
      "Niko Moritz",
      "Xiaohui Zhang",
      "Ozlem Kalinli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.11768",
    "title": "Augmentation with Projection: Towards an Effective and Efficient Data  Augmentation Paradigm for Distillation",
    "abstract": " Comments: 20 pages, 5 figures. Accepted by ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.11768",
    "authors": [
      "Ziqi Wang",
      "Yuexin Wu",
      "Frederick Liu",
      "Daogao Liu",
      "Le Hou",
      "Hongkun Yu",
      "Jing Li",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11981",
    "title": "Named Entity Detection and Injection for Direct Speech Translation",
    "abstract": " Comments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2210.11981",
    "authors": [
      "Marco Gaido",
      "Yun Tang",
      "Ilia Kulikov",
      "Rongqing Huang",
      "Hongyu Gong",
      "Hirofumi Inaguma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.16622",
    "title": "Discriminative Speaker Representation via Contrastive Learning with  Class-Aware Attention in Angular Space",
    "abstract": " Comments: Accepted by ICASSP 2023, 5 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2210.16622",
    "authors": [
      "Zhe Li",
      "Man-Wai Mak",
      "Helen Mei-Ling Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.16943",
    "title": "ViTASD: Robust Vision Transformer Baselines for Autism Spectrum Disorder  Facial Diagnosis",
    "abstract": " Comments: 5 pages, 3 figures, Accepted by the ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.16943",
    "authors": [
      "Xu Cao",
      "Wenqian Ye",
      "Elena Sizikova",
      "Xue Bai",
      "Megan Coffee",
      "Hongwu Zeng",
      "Jianguo Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00147",
    "title": "A Machine Learning Tutorial for Operational Meteorology, Part II: Neural  Networks and Deep Learning",
    "abstract": " Title: A Machine Learning Tutorial for Operational Meteorology, Part II: Neural  Networks and Deep Learning ",
    "url": "https://arxiv.org/abs/2211.00147",
    "authors": [
      "Randy J. Chase",
      "David R. Harrison",
      "Gary Lackmann",
      "Amy McGovern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2211.01539",
    "title": "Conformal Prediction for STL Runtime Verification",
    "abstract": " Title: Conformal Prediction for STL Runtime Verification ",
    "url": "https://arxiv.org/abs/2211.01539",
    "authors": [
      "Lars Lindemann",
      "Xin Qin",
      "Jyotirmoy V. Deshmukh",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.01704",
    "title": "Cutting Through the Noise: An Empirical Comparison of Psychoacoustic and  Envelope-based Features for Machinery Fault Detection",
    "abstract": " Comments: the final published version at ICASSP 2023 include small additional content as well as some minor revisions ",
    "url": "https://arxiv.org/abs/2211.01704",
    "authors": [
      "Peter Wi\u00dfbrock",
      "Yvonne Richter",
      "David Pelkmann",
      "Zhao Ren",
      "Gregory Palmer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.02641",
    "title": "Graph Neural Networks on SPD Manifolds for Motor Imagery Classification:  A Perspective from the Time-Frequency Analysis",
    "abstract": " Comments: 17 pages, 5 figures, 11 Tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2211.02641",
    "authors": [
      "Ce Ju",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.02678",
    "title": "Efficient ECG-based Atrial Fibrillation Detection via Parameterised  Hypercomplex Neural Networks",
    "abstract": " Comments: Revised paper organisation. Further experiments to emphasise flexible model compression and comparison with other baselines ",
    "url": "https://arxiv.org/abs/2211.02678",
    "authors": [
      "Leonie Basso",
      "Zhao Ren",
      "Wolfgang Nejdl"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.03177",
    "title": "Measurement-Consistent Networks via a Deep Implicit Layer for Solving  Inverse Problems",
    "abstract": " Title: Measurement-Consistent Networks via a Deep Implicit Layer for Solving  Inverse Problems ",
    "url": "https://arxiv.org/abs/2211.03177",
    "authors": [
      "Rahul Mourya",
      "Jo\u00e3o F. C. Mota"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.04086",
    "title": "Does an ensemble of GANs lead to better performance when training  segmentation networks with synthetic images?",
    "abstract": " Comments: 5 pages, submitted to ISBI 2023 ",
    "url": "https://arxiv.org/abs/2211.04086",
    "authors": [
      "M\u00e5ns Larsson",
      "Muhammad Usman Akbar",
      "Anders Eklund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.05020",
    "title": "Duality for Neural Networks through Reproducing Kernel Banach Spaces",
    "abstract": " Title: Duality for Neural Networks through Reproducing Kernel Banach Spaces ",
    "url": "https://arxiv.org/abs/2211.05020",
    "authors": [
      "Len Spek",
      "Tjeerd Jan Heeringa",
      "Felix Schwenninger",
      "Christoph Brune"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05103",
    "title": "Accidental Learners: Spoken Language Identification in Multilingual  Self-Supervised Models",
    "abstract": " Comments: Submitted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.05103",
    "authors": [
      "Travis M. Bartley",
      "Fei Jia",
      "Krishna C. Puvvada",
      "Samuel Kriman",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.05762",
    "title": "Efficient brain age prediction from 3D MRI volumes using 2D projections",
    "abstract": " Title: Efficient brain age prediction from 3D MRI volumes using 2D projections ",
    "url": "https://arxiv.org/abs/2211.05762",
    "authors": [
      "Johan J\u00f6nemo",
      "Muhammad Usman Akbar",
      "Robin K\u00e4mpe",
      "J Paul Hamilton",
      "Anders Eklund"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10999",
    "title": "LA-VocE: Low-SNR Audio-visual Speech Enhancement using Neural Vocoders",
    "abstract": " Comments: accepted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.10999",
    "authors": [
      "Rodrigo Mira",
      "Buye Xu",
      "Jacob Donley",
      "Anurag Kumar",
      "Stavros Petridis",
      "Vamsi Krishna Ithapu",
      "Maja Pantic"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.11208",
    "title": "Next3D: Generative Neural Texture Rasterization for 3D-Aware Head  Avatars",
    "abstract": " Comments: Accepted by CVPR 2023. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.11208",
    "authors": [
      "Jingxiang Sun",
      "Xuan Wang",
      "Lizhen Wang",
      "Xiaoyu Li",
      "Yong Zhang",
      "Hongwen Zhang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12048",
    "title": "Boundary-aware Camouflaged Object Detection via Deformable Point  Sampling",
    "abstract": " Title: Boundary-aware Camouflaged Object Detection via Deformable Point  Sampling ",
    "url": "https://arxiv.org/abs/2211.12048",
    "authors": [
      "Minhyeok Lee",
      "Suhwan Cho",
      "Chaewon Park",
      "Dogyoon Lee",
      "Jungho Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12353",
    "title": "U-Flow: A U-shaped Normalizing Flow for Anomaly Detection with  Unsupervised Threshold",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2211.12353",
    "authors": [
      "Mat\u00edas Tailanian",
      "\u00c1lvaro Pardo",
      "Pablo Mus\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12590",
    "title": "Deep Neural Mel-Subband Beamformer for In-car Speech Separation",
    "abstract": " Comments: Accepted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.12590",
    "authors": [
      "Vinay Kothapally",
      "Yong Xu",
      "Meng Yu",
      "Shi-Xiong Zhang",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.16270",
    "title": "Neural Transducer Training: Reduced Memory Consumption with Sample-wise  Computation",
    "abstract": " Comments: 5 pages, 4 figures, 1 table, 1 algorithm ",
    "url": "https://arxiv.org/abs/2211.16270",
    "authors": [
      "Stefan Braun",
      "Erik McDermott",
      "Roger Hsiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.17042",
    "title": "Spatio-Temporal Crop Aggregation for Video Representation Learning",
    "abstract": " Title: Spatio-Temporal Crop Aggregation for Video Representation Learning ",
    "url": "https://arxiv.org/abs/2211.17042",
    "authors": [
      "Sepehr Sameni",
      "Simon Jenni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00935",
    "title": "Dunhuang murals contour generation network based on convolution and  self-attention fusion",
    "abstract": " Title: Dunhuang murals contour generation network based on convolution and  self-attention fusion ",
    "url": "https://arxiv.org/abs/2212.00935",
    "authors": [
      "Baokai Liu",
      "Fengjie He",
      "Shiqiang Du",
      "Kaiwu Zhang",
      "Jianhua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.07652",
    "title": "Body-Part Joint Detection and Association via Extended Object  Representation",
    "abstract": " Comments: accepted by ICME2023 ",
    "url": "https://arxiv.org/abs/2212.07652",
    "authors": [
      "Huayi Zhou",
      "Fei Jiang",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08966",
    "title": "Graph Learning and Its Applications: A Holistic Survey",
    "abstract": " Comments: 20 pages, 7 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2212.08966",
    "authors": [
      "Shaopeng Wei",
      "Yu Zhao",
      "Xingyan Chen",
      "Qing Li",
      "Fuzhen Zhuang",
      "Ji Liu",
      "Gang Kou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.01123",
    "title": "MGTAB: A Multi-Relational Graph-Based Twitter Account Detection  Benchmark",
    "abstract": " Comments: 14 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2301.01123",
    "authors": [
      "Shuhao Shi",
      "Kai Qiao",
      "Jian Chen",
      "Shuai Yang",
      "Jie Yang",
      "Baojie Song",
      "Linyuan Wang",
      "Bin Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01283",
    "title": "Cross Modal Transformer: Towards Fast and Robust 3D Object Detection",
    "abstract": " Title: Cross Modal Transformer: Towards Fast and Robust 3D Object Detection ",
    "url": "https://arxiv.org/abs/2301.01283",
    "authors": [
      "Junjie Yan",
      "Yingfei Liu",
      "Jianjian Sun",
      "Fan Jia",
      "Shuailin Li",
      "Tiancai Wang",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02830",
    "title": "Image Data Augmentation Approaches: A Comprehensive Survey and Future  directions",
    "abstract": " Comments: We need to make a lot changes to make its quality better ",
    "url": "https://arxiv.org/abs/2301.02830",
    "authors": [
      "Teerath Kumar",
      "Alessandra Mileo",
      "Rob Brennan",
      "Malika Bendechache"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.03196",
    "title": "Near-optimal stochastic MIMO signal detection with a mixture of  t-distribution prior",
    "abstract": " Comments: to be published in the 2023 IEEE Global Communications Conference (GLOBECOM) ",
    "url": "https://arxiv.org/abs/2301.03196",
    "authors": [
      "Junichiro Hagiwara",
      "Kazushi Matsumura",
      "Hiroki Asumi",
      "Yukiko Kasuga",
      "Toshihiko Nishimura",
      "Takanori Sato",
      "Yasutaka Ogawa",
      "Takeo Ohgane"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.07074",
    "title": "SegViz: A federated-learning based framework for multi-organ  segmentation on heterogeneous data sets with partial annotations",
    "abstract": " Title: SegViz: A federated-learning based framework for multi-organ  segmentation on heterogeneous data sets with partial annotations ",
    "url": "https://arxiv.org/abs/2301.07074",
    "authors": [
      "Adway U. Kanhere",
      "Pranav Kulkarni",
      "Paul H. Yi",
      "Vishwa S. Parekh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.09245",
    "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural  Networks",
    "abstract": " Title: Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural  Networks ",
    "url": "https://arxiv.org/abs/2301.09245",
    "authors": [
      "Feng-Lei Fan",
      "Yingxin Li",
      "Hanchuan Peng",
      "Tieyong Zeng",
      "Fei Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2302.01843",
    "title": "MorDIFF: Recognition Vulnerability and Attack Detectability of Face  Morphing Attacks Created by Diffusion Autoencoders",
    "abstract": " Comments: Accepted at the 11th International Workshop on Biometrics and Forensics 2023 (IWBF 2023) ",
    "url": "https://arxiv.org/abs/2302.01843",
    "authors": [
      "Naser Damer",
      "Meiling Fang",
      "Patrick Siebke",
      "Jan Niklas Kolf",
      "Marco Huber",
      "Fadi Boutros"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05045",
    "title": "Exploiting Sparsity in Pruned Neural Networks to Optimize Large Model  Training",
    "abstract": " Title: Exploiting Sparsity in Pruned Neural Networks to Optimize Large Model  Training ",
    "url": "https://arxiv.org/abs/2302.05045",
    "authors": [
      "Siddharth Singh",
      "Abhinav Bhatele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2302.07416",
    "title": "Deep Convolutional Neural Network for Plume Rise Measurements in  Industrial Environments",
    "abstract": " Title: Deep Convolutional Neural Network for Plume Rise Measurements in  Industrial Environments ",
    "url": "https://arxiv.org/abs/2302.07416",
    "authors": [
      "Mohammad Koushafar",
      "Gunho Sohn",
      "Mark Gordon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.08774",
    "title": "Vision, Deduction and Alignment: An Empirical Study on Multi-modal  Knowledge Graph Alignment",
    "abstract": " Comments: Accepted by ICASSP2023 ",
    "url": "https://arxiv.org/abs/2302.08774",
    "authors": [
      "Yangning Li",
      "Jiaoyan Chen",
      "Yinghui Li",
      "Yuejia Xiang",
      "Xi Chen",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.08888",
    "title": "Multimodal Federated Learning via Contrastive Representation Ensemble",
    "abstract": " Comments: ICLR 2023. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2302.08888",
    "authors": [
      "Qiying Yu",
      "Yang Liu",
      "Yimu Wang",
      "Ke Xu",
      "Jingjing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10420",
    "title": "HCGMNET: A Hierarchical Change Guiding Map Network For Change Detection",
    "abstract": " Title: HCGMNET: A Hierarchical Change Guiding Map Network For Change Detection ",
    "url": "https://arxiv.org/abs/2302.10420",
    "authors": [
      "Chengxi Han",
      "Chen Wu",
      "Bo Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.11205",
    "title": "Contrastive Representation Learning for Acoustic Parameter Estimation",
    "abstract": " Comments: Accepted for ICASSP 2023, Camera-ready version ",
    "url": "https://arxiv.org/abs/2302.11205",
    "authors": [
      "Philipp G\u00f6tz",
      "Cagdas Tuna",
      "Andreas Walther",
      "Emanu\u00ebl A. P. Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2302.12538",
    "title": "UnbiasedNets: A Dataset Diversification Framework for Robustness Bias  Alleviation in Neural Networks",
    "abstract": " Comments: Springer Machine Learning 2023 ",
    "url": "https://arxiv.org/abs/2302.12538",
    "authors": [
      "Mahum Naseer",
      "Bharath Srinivas Prabakaran",
      "Osman Hasan",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.13452",
    "title": "Euclidean Contractivity of Neural Networks with Symmetric Weights",
    "abstract": " Comments: 16 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2302.13452",
    "authors": [
      "Veronica Centorrino",
      "Anand Gokhale",
      "Alexander Davydov",
      "Giovanni Russo",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.13693",
    "title": "Learning Topology-Specific Experts for Molecular Property Prediction",
    "abstract": " Comments: 11 pages with 8 figures ",
    "url": "https://arxiv.org/abs/2302.13693",
    "authors": [
      "Su Kim",
      "Dongha Lee",
      "SeongKu Kang",
      "Seonghyeon Lee",
      "Hwanjo Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.14096",
    "title": "A Dataset for Learning Graph Representations to Predict Customer Returns  in Fashion Retail",
    "abstract": " Comments: The ASOS GraphReturns dataset can be found at this https URL Accepted at FashionXRecSys 2022 workshop. Published Version ",
    "url": "https://arxiv.org/abs/2302.14096",
    "authors": [
      "Jamie McGowan",
      "Elizabeth Guest",
      "Ziyang Yan",
      "Cong Zheng",
      "Neha Patel",
      "Mason Cusack",
      "Charlie Donaldson",
      "Sofie de Cnudde",
      "Gabriel Facini",
      "Fabon Dzogang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.14485",
    "title": "Memory-aided Contrastive Consensus Learning for Co-salient Object  Detection",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2302.14485",
    "authors": [
      "Peng Zheng",
      "Jie Qin",
      "Shuo Wang",
      "Tian-Zhu Xiang",
      "Huan Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.00308",
    "title": "Event Fusion Photometric Stereo Network",
    "abstract": " Comments: 33 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2303.00308",
    "authors": [
      "Wonjeong Ryoo",
      "Giljoo Nam",
      "Jae-Sang Hyun",
      "Sangpil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.02353",
    "title": "Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling",
    "abstract": " Comments: Accepted by AAAI 2023. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.02353",
    "authors": [
      "Jinhai Yang",
      "Mengxi Guo",
      "Shijie Zhao",
      "Junlin Li",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.02665",
    "title": "Heterogeneous Graph Learning for Acoustic Event Classification",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2207.07935 ",
    "url": "https://arxiv.org/abs/2303.02665",
    "authors": [
      "Amir Shirian",
      "Mona Ahmadian",
      "Krishna Somandepalli",
      "Tanaya Guha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.03634",
    "title": "PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation",
    "abstract": " Title: PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation ",
    "url": "https://arxiv.org/abs/2303.03634",
    "authors": [
      "Tin-Han Chi",
      "Kai-Chun Liu",
      "Chia-Yeh Hsieh",
      "Yu Tsao",
      "Chia-Tai Chan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04683",
    "title": "Optimizing Utility-Energy Efficiency for the Metaverse over Wireless  Networks under Physical Layer Security",
    "abstract": " Title: Optimizing Utility-Energy Efficiency for the Metaverse over Wireless  Networks under Physical Layer Security ",
    "url": "https://arxiv.org/abs/2303.04683",
    "authors": [
      "Jun Zhao",
      "Xinyu Zhou",
      "Yang Li",
      "Liangxin Qian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.04942",
    "title": "A Study of Variable-Role-based Feature Enrichment in Neural Models of  Code",
    "abstract": " Comments: Accepted in the 1st International Workshop on Interpretability and Robustness in Neural Software Engineering (InteNSE'23), Co-located with ICSE ",
    "url": "https://arxiv.org/abs/2303.04942",
    "authors": [
      "Aftab Hussain",
      "Md Rafiqul Islam Rabin",
      "Bowen Xu",
      "David Lo",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.06088",
    "title": "Improving Domain-Invariance in Self-Supervised Learning via Batch Styles  Standardization",
    "abstract": " Title: Improving Domain-Invariance in Self-Supervised Learning via Batch Styles  Standardization ",
    "url": "https://arxiv.org/abs/2303.06088",
    "authors": [
      "Marin Scalbert",
      "Maria Vakalopoulou",
      "Florent Couzini\u00e9-Devy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06120",
    "title": "Measuring and Detecting Virality on Social Media: The Case of Twitter's  Viral Tweets Topic",
    "abstract": " Comments: 2023 ACM Web Conference Poster Track Short Paper ",
    "url": "https://arxiv.org/abs/2303.06120",
    "authors": [
      "Tu\u011frulcan Elmas",
      "Stephane Selim",
      "C\u00e9lia Houssiaux"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  }
]