[
  {
    "id": "arXiv:2303.05546",
    "title": "Weakly-Supervised HOI Detection from Interaction Labels Only and  Language/Vision-Language Priors",
    "abstract": "Human-object interaction (HOI) detection aims to extract interacting human-object pairs and their interaction categories from a given natural image. Even though the labeling effort required for building HOI detection datasets is inherently more extensive than for many other computer vision tasks, weakly-supervised directions in this area have not been sufficiently explored due to the difficulty of learning human-object interactions with weak supervision, rooted in the combinatorial nature of interactions over the object and predicate space. In this paper, we tackle HOI detection with the weakest supervision setting in the literature, using only image-level interaction labels, with the help of a pretrained vision-language model (VLM) and a large language model (LLM). We first propose an approach to prune non-interacting human and object proposals to increase the quality of positive pairs within the bag, exploiting the grounding capability of the vision-language model. Second, we use a large language model to query which interactions are possible between a human and a given object category, in order to force the model not to put emphasis on unlikely interactions. Lastly, we use an auxiliary weakly-supervised preposition prediction task to make our model explicitly reason about space. Extensive experiments and ablations show that all of our contributions increase HOI detection performance. ",
    "url": "https://arxiv.org/abs/2303.05546",
    "authors": [
      "Mesut Erhan Unal",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05556",
    "title": "An Evaluation of Non-Contrastive Self-Supervised Learning for Federated  Medical Image Analysis",
    "abstract": "Privacy and annotation bottlenecks are two major issues that profoundly affect the practicality of machine learning-based medical image analysis. Although significant progress has been made in these areas, these issues are not yet fully resolved. In this paper, we seek to tackle these concerns head-on and systematically explore the applicability of non-contrastive self-supervised learning (SSL) algorithms under federated learning (FL) simulations for medical image analysis. We conduct thorough experimentation of recently proposed state-of-the-art non-contrastive frameworks under standard FL setups. With the SoTA Contrastive Learning algorithm, SimCLR as our comparative baseline, we benchmark the performances of our 4 chosen non-contrastive algorithms under non-i.i.d. data conditions and with a varying number of clients. We present a holistic evaluation of these techniques on 6 standardized medical imaging datasets. We further analyse different trends inferred from the findings of our research, with the aim to find directions for further research based on ours. To the best of our knowledge, ours is the first to perform such a thorough analysis of federated self-supervised learning for medical imaging. All of our source code will be made public upon acceptance of the paper. ",
    "url": "https://arxiv.org/abs/2303.05556",
    "authors": [
      "Soumitri Chattopadhyay",
      "Soham Ganguly",
      "Sreejit Chaudhury",
      "Sayan Nag",
      "Samiran Chattopadhyay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05575",
    "title": "Evaluating the Robustness of Conversational Recommender Systems by  Adversarial Examples",
    "abstract": "Conversational recommender systems (CRSs) are improving rapidly, according to the standard recommendation accuracy metrics. However, it is essential to make sure that these systems are robust in interacting with users including regular and malicious users who want to attack the system by feeding the system modified input data. In this paper, we propose an adversarial evaluation scheme including four scenarios in two categories and automatically generate adversarial examples to evaluate the robustness of these systems in the face of different input data. By executing these adversarial examples we can compare the ability of different conversational recommender systems to satisfy the user's preferences. We evaluate three CRSs by the proposed adversarial examples on two datasets. Our results show that none of these systems are robust and reliable to the adversarial examples. ",
    "url": "https://arxiv.org/abs/2303.05575",
    "authors": [
      "Ali Montazeralghaem",
      "James Allan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05576",
    "title": "Characterizing bearing equivalence in directed graphs",
    "abstract": "In this paper, we study bearing equivalence in directed graphs. We first give a strengthened definition of bearing equivalence based on the \\textit{kernel equivalence} relationship between bearing rigidity matrix and bearing Laplacian matrix. We then present several conditions to characterize bearing equivalence for both directed acyclic and cyclic graphs. These conditions involve the spectrum and null space of the associated bearing Laplacian matrix for a directed bearing formation. For directed acyclic graphs, all eigenvalues of the associated bearing Laplacian are real and nonnegative, while for directed graphs containing cycles, the bearing Laplacian can have eigenvalues with negative real parts. Several examples of bearing equivalent and bearing non-equivalent formations are given to illustrate these conditions. ",
    "url": "https://arxiv.org/abs/2303.05576",
    "authors": [
      "Zhiyong Sun",
      "Shiyu Zhao",
      "Daniel Zelazo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Discrete Mathematics (cs.DM)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.05582",
    "title": "Generalization analysis of an unfolding network for analysis-based  Compressed Sensing",
    "abstract": "Unfolding networks have shown promising results in the Compressed Sensing (CS) field. Yet, the investigation of their generalization ability is still in its infancy. In this paper, we perform generalization analysis of a state-of-the-art ADMM-based unfolding network, which jointly learns a decoder for CS and a sparsifying redundant analysis operator. To this end, we first impose a structural constraint on the learnable sparsifier, which parametrizes the network's hypothesis class. For the latter, we estimate its Rademacher complexity. With this estimate in hand, we deliver generalization error bounds for the examined network. Finally, the validity of our theory is assessed and numerical comparisons to a state-of-the-art unfolding network are made, on synthetic and real-world datasets. Our experimental results demonstrate that our proposed framework complies with our theoretical findings and outperforms the baseline, consistently for all datasets. ",
    "url": "https://arxiv.org/abs/2303.05582",
    "authors": [
      "Vicky Kouni",
      "Yannis Panagakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.05584",
    "title": "SOCIALGYM 2.0: Simulator for Multi-Agent Social Robot Navigation in  Shared Human Spaces",
    "abstract": "We present SocialGym 2, a multi-agent navigation simulator for social robot research. Our simulator models multiple autonomous agents, replicating real-world dynamics in complex environments, including doorways, hallways, intersections, and roundabouts. Unlike traditional simulators that concentrate on single robots with basic kinematic constraints in open spaces, SocialGym 2 employs multi-agent reinforcement learning (MARL) to develop optimal navigation policies for multiple robots with diverse, dynamic constraints in complex environments. Built on the PettingZoo MARL library and Stable Baselines3 API, SocialGym 2 offers an accessible python interface that integrates with a navigation stack through ROS messaging. SocialGym 2 can be easily installed and is packaged in a docker container, and it provides the capability to swap and evaluate different MARL algorithms, as well as customize observation and reward functions. We also provide scripts to allow users to create their own environments and have conducted benchmarks using various social navigation algorithms, reporting a broad range of social navigation metrics. Projected hosted at: https://amrl.cs.utexas.edu/social_gym/index.html ",
    "url": "https://arxiv.org/abs/2303.05584",
    "authors": [
      "Zayne Sprague",
      "Rohan Chandra",
      "Jarrett Holtz",
      "Joydeep Biswas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.05596",
    "title": "Distributed Design of Controllable and Robust Networks using Zero  Forcing and Graph Grammars",
    "abstract": "This paper studies the problem of designing networks that are strong structurally controllable, and robust simultaneously. For given network specifications, including the number of nodes $N$, the number of leaders $N_L$, and diameter $D$, where $2 \\le D \\le N/N_L$, we propose graph constructions generating strong structurally controllable networks. We also compute the number of edges in graphs, which are maximal for improved robustness measured by the algebraic connectivity and Kirchhoff index. For the controllability analysis, we utilize the notion of zero forcing sets in graphs. Additionally, we present graph grammars, which are sets of rules that agents apply in a distributed manner to construct the graphs mentioned above. We also numerically evaluate our methods. This work exploits the trade-off between network controllability and robustness and generates networks satisfying multiple design criteria. ",
    "url": "https://arxiv.org/abs/2303.05596",
    "authors": [
      "Priyanshkumar I. Patel",
      "Johir Suresh",
      "Waseem Abbas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.05606",
    "title": "Variance-aware robust reinforcement learning with linear function  approximation with heavy-tailed rewards",
    "abstract": "This paper presents two algorithms, AdaOFUL and VARA, for online sequential decision-making in the presence of heavy-tailed rewards with only finite variances. For linear stochastic bandits, we address the issue of heavy-tailed rewards by modifying the adaptive Huber regression and proposing AdaOFUL. AdaOFUL achieves a state-of-the-art regret bound of $\\widetilde{\\mathcal{O}}\\big(d\\big(\\sum_{t=1}^T \\nu_{t}^2\\big)^{1/2}+d\\big)$ as if the rewards were uniformly bounded, where $\\nu_{t}^2$ is the observed conditional variance of the reward at round $t$, $d$ is the feature dimension, and $\\widetilde{\\mathcal{O}}(\\cdot)$ hides logarithmic dependence. Building upon AdaOFUL, we propose VARA for linear MDPs, which achieves a tighter variance-aware regret bound of $\\widetilde{\\mathcal{O}}(d\\sqrt{H\\mathcal{G}^*K})$. Here, $H$ is the length of episodes, $K$ is the number of episodes, and $\\mathcal{G}^*$ is a smaller instance-dependent quantity that can be bounded by other instance-dependent quantities when additional structural conditions on the MDP are satisfied. Our regret bound is superior to the current state-of-the-art bounds in three ways: (1) it depends on a tighter instance-dependent quantity and has optimal dependence on $d$ and $H$, (2) we can obtain further instance-dependent bounds of $\\mathcal{G}^*$ under additional structural conditions on the MDP, and (3) our regret bound is valid even when rewards have only finite variances, achieving a level of generality unmatched by previous works. Overall, our modified adaptive Huber regression algorithm may serve as a useful building block in the design of algorithms for online problems with heavy-tailed rewards. ",
    "url": "https://arxiv.org/abs/2303.05606",
    "authors": [
      "Xiang Li",
      "Qiang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05607",
    "title": "An Improved Data Augmentation Scheme for Model Predictive Control Policy  Approximation",
    "abstract": "This paper considers the problem of data generation for MPC policy approximation. Learning an approximate MPC policy from expert demonstrations requires a large data set consisting of optimal state-action pairs, sampled across the feasible state space. Yet, the key challenge of efficiently generating the training samples has not been studied widely. Recently, a sensitivity-based data augmentation framework for MPC policy approximation was proposed, where the parametric sensitivities are exploited to cheaply generate several additional samples from a single offline MPC computation. The error due to augmenting the training data set with inexact samples was shown to increase with the size of the neighborhood around each sample used for data augmentation. Building upon this work, this letter paper presents an improved data augmentation scheme based on predictor-corrector steps that enforces a user-defined level of accuracy, and shows that the error bound of the augmented samples are independent of the size of the neighborhood used for data augmentation. ",
    "url": "https://arxiv.org/abs/2303.05607",
    "authors": [
      "Dinesh Krishnamoorthy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.05617",
    "title": "KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF  Grasp Pose Synthesis on RGB-D input",
    "abstract": "We propose a new 6-DoF grasp pose synthesis approach from 2D/2.5D input based on keypoints. Keypoint-based grasp detector from image input has demonstrated promising results in the previous study, where the additional visual information provided by color images compensates for the noisy depth perception. However, it relies heavily on accurately predicting the location of keypoints in the image space. In this paper, we devise a new grasp generation network that reduces the dependency on precise keypoint estimation. Given an RGB-D input, our network estimates both the grasp pose from keypoint detection as well as scale towards the camera. We further re-design the keypoint output space in order to mitigate the negative impact of keypoint prediction noise to Perspective-n-Point (PnP) algorithm. Experiments show that the proposed method outperforms the baseline by a large margin, validating the efficacy of our approach. Finally, despite trained on simple synthetic objects, our method demonstrate sim-to-real capacity by showing competitive results in real-world robot experiments. ",
    "url": "https://arxiv.org/abs/2303.05617",
    "authors": [
      "Yiye Chen",
      "Ruinian Xu",
      "Yunzhi Lin",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05621",
    "title": "Social networks in COVID-19 America: Americans remotely together but  politically apart",
    "abstract": "The COVID-19 pandemic has presented a social dilemma; \"social distancing\" was required to stop the spread of disease, but close social contacts were needed more than ever to collectively overcome the unprecedented challenges of the crisis. How did Americans mobilize their social ties in response to the pandemic? Drawing from a nation-wide daily online survey of 36,345 Americans from April 2020 through April 2021, we examine the characteristics of Americans' core networks within which people discuss \"important matters.\" Comparing the COVID-19 networks to those previously collected in eight national core network surveys from 1985 to 2016, we observe remarkable stability in the size and relationship composition of core networks during COVID-19. In contrast to the robust nature of core networks, we discover a significant rise in racial homophily among kin ties, and political homophily among non-kin ties. Simultaneously, our study reveals a significant surge in the adoption of remote communication technology to connect with individuals who are geographically distant. We demonstrate that the changing mode of communication contributes to increases in racial and political homophily. These results suggest that the COVID-19 pandemic may bring people remotely together but only with the like-minded, deepening social divides in American society. ",
    "url": "https://arxiv.org/abs/2303.05621",
    "authors": [
      "Byungkyu Lee",
      "Kangsan Lee",
      "Benjamin Hartmann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.05634",
    "title": "Fusarium head blight detection, spikelet estimation, and severity  assessment in wheat using 3D convolutional neural networks",
    "abstract": "Fusarium head blight (FHB) is one of the most significant diseases affecting wheat and other small grain cereals worldwide. The development of resistant varieties requires the laborious task of field and greenhouse phenotyping. The applications considered in this work are the automated detection of FHB disease symptoms expressed on a wheat plant, the automated estimation of the total number of spikelets and the total number of infected spikelets on a wheat head, and the automated assessment of the FHB severity in infected wheat. The data used to generate the results are 3-dimensional (3D) multispectral point clouds (PC), which are 3D collections of points - each associated with a red, green, blue (RGB), and near-infrared (NIR) measurement. Over 300 wheat plant images were collected using a multispectral 3D scanner, and the labelled UW-MRDC 3D wheat dataset was created. The data was used to develop novel and efficient 3D convolutional neural network (CNN) models for FHB detection, which achieved 100% accuracy. The influence of the multispectral information on performance was evaluated, and our results showed the dominance of the RGB channels over both the NIR and the NIR plus RGB channels combined. Furthermore, novel and efficient 3D CNNs were created to estimate the total number of spikelets and the total number of infected spikelets on a wheat head, and our best models achieved mean absolute errors (MAE) of 1.13 and 1.56, respectively. Moreover, 3D CNN models for FHB severity estimation were created, and our best model achieved 8.6 MAE. A linear regression analysis between the visual FHB severity assessment and the FHB severity predicted by our 3D CNN was performed, and the results showed a significant correlation between the two variables with a 0.0001 P-value and 0.94 R-squared. ",
    "url": "https://arxiv.org/abs/2303.05634",
    "authors": [
      "Oumaima Hamila",
      "Christopher J. Henry",
      "Oscar I. Molina",
      "Christopher P. Bidinosti",
      "Maria Antonia Henriquez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.05639",
    "title": "Self-Supervised One-Shot Learning for Automatic Segmentation of StyleGAN  Images",
    "abstract": "We propose in this paper a framework for automatic one-shot segmentation of synthetic images generated using StyleGANs. As to the need for `one-shot segmentation', we want the network to carry out a semantic segmentation of the images on the fly, that is, as they are being produced at inference time. The implementation of our framework is based on the observation that the multi-scale hidden features produced by a GAN during image synthesis hold useful semantic information that can be utilized for automatic segmentation. Using these features, our proposed framework learns to segment synthetic images using a novel self-supervised, contrastive clustering algorithm that projects the hidden features in the generator onto a compact feature space for per-pixel classification. This contrastive learner uses a swapped prediction loss for image segmentation that is computed using pixel-wise cluster assignments for the image and its transformed variants. Using the hidden features from an already pre-trained GAN for clustering, this leads to a much faster learning of the pixel-wise feature vectors for one-shot segmentation. We have tested our implementation on a number of standard benchmarks (CelebA, LSUN, PASCAL-Part) for object and part segmentation. The results of our experiments yield a segmentation performance that not only outperforms the semi-supervised baseline methods with an average wIoU margin of 1.02 % but also improves the inference speeds by a peak factor of 4.5. Finally, we also show the results of using the proposed framework in the implementation of BagGAN, a GAN-based framework for the production of annotated synthetic baggage X-ray scans for threat detection. This one-shot learning framework was trained and tested on the PIDRay baggage screening benchmark for 5 different threat categories to yield a segmentation performance which stands close to its baseline segmenter. ",
    "url": "https://arxiv.org/abs/2303.05639",
    "authors": [
      "Ankit Manerikar",
      "Avinash C. Kak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05653",
    "title": "Direct Robot Configuration Space Construction using Convolutional  Encoder-Decoders",
    "abstract": "Intelligent robots must be able to perform safe and efficient motion planning in their environments. Central to modern motion planning is the configuration space. Configuration spaces define the set of configurations of a robot that result in collisions with obstacles in the workspace, C-clsn, and the set of configurations that do not, C-free. Modern approaches to motion planning first compute the configuration space and then perform motion planning using the calculated configuration space. Real-time motion planning requires accurate and efficient construction of configuration spaces. We are the first to apply a convolutional encoder-decoder framework for calculating highly accurate approximations to configuration spaces. Our model achieves an average 97.5% F1-score for predicting C-free and C-clsn for 2-D robotic workspaces with a dual-arm robot. Our method limits undetected collisions to less than 2.5% on robotic workspaces that involve translation, rotation, and removal of obstacles. Our model learns highly transferable features between robotic workspaces, requiring little to no fine-tuning to adapt to new transformations of obstacles in the workspace. ",
    "url": "https://arxiv.org/abs/2303.05653",
    "authors": [
      "Christopher Benka",
      "Carl Gross",
      "Riya Gupta",
      "Hod Lipson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05678",
    "title": "Improving Weakly Supervised Sound Event Detection with Causal  Intervention",
    "abstract": "Existing weakly supervised sound event detection (WSSED) work has not explored both types of co-occurrences simultaneously, i.e., some sound events often co-occur, and their occurrences are usually accompanied by specific background sounds, so they would be inevitably entangled, causing misclassification and biased localization results with only clip-level supervision. To tackle this issue, we first establish a structural causal model (SCM) to reveal that the context is the main cause of co-occurrence confounders that mislead the model to learn spurious correlations between frames and clip-level labels. Based on the causal analysis, we propose a causal intervention (CI) method for WSSED to remove the negative impact of co-occurrence confounders by iteratively accumulating every possible context of each class and then re-projecting the contexts to the frame-level features for making the event boundary clearer. Experiments show that our method effectively improves the performance on multiple datasets and can generalize to various baseline models. ",
    "url": "https://arxiv.org/abs/2303.05678",
    "authors": [
      "Yifei Xin",
      "Dongchao Yang",
      "Fan Cui",
      "Yujun Wang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.05689",
    "title": "Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing  Mistake Severity",
    "abstract": "There is a recently discovered and intriguing phenomenon called Neural Collapse: at the terminal phase of training a deep neural network for classification, the within-class penultimate feature means and the associated classifier vectors of all flat classes collapse to the vertices of a simplex Equiangular Tight Frame (ETF). Recent work has tried to exploit this phenomenon by fixing the related classifier weights to a pre-computed ETF to induce neural collapse and maximize the separation of the learned features when training with imbalanced data. In this work, we propose to fix the linear classifier of a deep neural network to a Hierarchy-Aware Frame (HAFrame), instead of an ETF, and use a cosine similarity-based auxiliary loss to learn hierarchy-aware penultimate features that collapse to the HAFrame. We demonstrate that our approach reduces the mistake severity of the model's predictions while maintaining its top-1 accuracy on several datasets of varying scales with hierarchies of heights ranging from 3 to 12. We will release our code on GitHub in the near future. ",
    "url": "https://arxiv.org/abs/2303.05689",
    "authors": [
      "Tong Liang",
      "Jim Davis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05692",
    "title": "Semantic-Preserving Augmentation for Robust Image-Text Retrieval",
    "abstract": "Image text retrieval is a task to search for the proper textual descriptions of the visual world and vice versa. One challenge of this task is the vulnerability to input image and text corruptions. Such corruptions are often unobserved during the training, and degrade the retrieval model decision quality substantially. In this paper, we propose a novel image text retrieval technique, referred to as robust visual semantic embedding (RVSE), which consists of novel image-based and text-based augmentation techniques called semantic preserving augmentation for image (SPAugI) and text (SPAugT). Since SPAugI and SPAugT change the original data in a way that its semantic information is preserved, we enforce the feature extractors to generate semantic aware embedding vectors regardless of the corruption, improving the model robustness significantly. From extensive experiments using benchmark datasets, we show that RVSE outperforms conventional retrieval schemes in terms of image-text retrieval performance. ",
    "url": "https://arxiv.org/abs/2303.05692",
    "authors": [
      "Sunwoo Kim",
      "Kyuhong Shim",
      "Luong Trung Nguyen",
      "Byonghyo Shim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05695",
    "title": "Mode-locking Theory for Long-Range Interaction in Artificial Neural  Networks",
    "abstract": "Visual long-range interaction refers to modeling dependencies between distant feature points or blocks within an image, which can significantly enhance the model's robustness. Both CNN and Transformer can establish long-range interactions through layering and patch calculations. However, the underlying mechanism of long-range interaction in visual space remains unclear. We propose the mode-locking theory as the underlying mechanism, which constrains the phase and wavelength relationship between waves to achieve mode-locked interference waveform. We verify this theory through simulation experiments and demonstrate the mode-locking pattern in real-world scene models. Our proposed theory of long-range interaction provides a comprehensive understanding of the mechanism behind this phenomenon in artificial neural networks. This theory can inspire the integration of the mode-locking pattern into models to enhance their robustness. ",
    "url": "https://arxiv.org/abs/2303.05695",
    "authors": [
      "Xiuxiu Bai",
      "Shuaishuai Zhao",
      "Yao Gao",
      "Zhe Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05698",
    "title": "Fairness-enhancing deep learning for ride-hailing demand prediction",
    "abstract": "Short-term demand forecasting for on-demand ride-hailing services is one of the fundamental issues in intelligent transportation systems. However, previous travel demand forecasting research predominantly focused on improving prediction accuracy, ignoring fairness issues such as systematic underestimations of travel demand in disadvantaged neighborhoods. This study investigates how to measure, evaluate, and enhance prediction fairness between disadvantaged and privileged communities in spatial-temporal demand forecasting of ride-hailing services. A two-pronged approach is taken to reduce the demand prediction bias. First, we develop a novel deep learning model architecture, named socially aware neural network (SA-Net), to integrate the socio-demographics and ridership information for fair demand prediction through an innovative socially-aware convolution operation. Second, we propose a bias-mitigation regularization method to mitigate the mean percentage prediction error gap between different groups. The experimental results, validated on the real-world Chicago Transportation Network Company (TNC) data, show that the de-biasing SA-Net can achieve better predictive performance in both prediction accuracy and fairness. Specifically, the SA-Net improves prediction accuracy for both the disadvantaged and privileged groups compared with the state-of-the-art models. When coupled with the bias mitigation regularization method, the de-biasing SA-Net effectively bridges the mean percentage prediction error gap between the disadvantaged and privileged groups, and also protects the disadvantaged regions against systematic underestimation of TNC demand. Our proposed de-biasing method can be adopted in many existing short-term travel demand estimation models, and can be utilized for various other spatial-temporal prediction tasks such as crime incidents predictions. ",
    "url": "https://arxiv.org/abs/2303.05698",
    "authors": [
      "Yunhan Zheng",
      "Qingyi Wang",
      "Dingyi Zhuang",
      "Shenhao Wang",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.05708",
    "title": "Self-supervised Facial Action Unit Detection with Region and Relation  Learning",
    "abstract": "Facial action unit (AU) detection is a challenging task due to the scarcity of manual annotations. Recent works on AU detection with self-supervised learning have emerged to address this problem, aiming to learn meaningful AU representations from numerous unlabeled data. However, most existing AU detection works with self-supervised learning utilize global facial features only, while AU-related properties such as locality and relevance are not fully explored. In this paper, we propose a novel self-supervised framework for AU detection with the region and relation learning. In particular, AU related attention map is utilized to guide the model to focus more on AU-specific regions to enhance the integrity of AU local features. Meanwhile, an improved Optimal Transport (OT) algorithm is introduced to exploit the correlation characteristics among AUs. In addition, Swin Transformer is exploited to model the long-distance dependencies within each AU region during feature learning. The evaluation results on BP4D and DISFA demonstrate that our proposed method is comparable or even superior to the state-of-the-art self-supervised learning methods and supervised AU detection methods. ",
    "url": "https://arxiv.org/abs/2303.05708",
    "authors": [
      "Juan Song",
      "Zhilei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05719",
    "title": "Boosting Adversarial Attacks by Leveraging Decision Boundary Information",
    "abstract": "Due to the gap between a substitute model and a victim model, the gradient-based noise generated from a substitute model may have low transferability for a victim model since their gradients are different. Inspired by the fact that the decision boundaries of different models do not differ much, we conduct experiments and discover that the gradients of different models are more similar on the decision boundary than in the original position. Moreover, since the decision boundary in the vicinity of an input image is flat along most directions, we conjecture that the boundary gradients can help find an effective direction to cross the decision boundary of the victim models. Based on it, we propose a Boundary Fitting Attack to improve transferability. Specifically, we introduce a method to obtain a set of boundary points and leverage the gradient information of these points to update the adversarial examples. Notably, our method can be combined with existing gradient-based methods. Extensive experiments prove the effectiveness of our method, i.e., improving the success rate by 5.6% against normally trained CNNs and 14.9% against defense CNNs on average compared to state-of-the-art transfer-based attacks. Further we compare transformers with CNNs, the results indicate that transformers are more robust than CNNs. However, our method still outperforms existing methods when attacking transformers. Specifically, when using CNNs as substitute models, our method obtains an average attack success rate of 58.2%, which is 10.8% higher than other state-of-the-art transfer-based attacks. ",
    "url": "https://arxiv.org/abs/2303.05719",
    "authors": [
      "Boheng Zeng",
      "LianLi Gao",
      "QiLong Zhang",
      "ChaoQun Li",
      "JingKuan Song",
      "ShuaiQi Jing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05728",
    "title": "On the effectiveness of neural priors in modeling dynamical systems",
    "abstract": "Modelling dynamical systems is an integral component for understanding the natural world. To this end, neural networks are becoming an increasingly popular candidate owing to their ability to learn complex functions from large amounts of data. Despite this recent progress, there has not been an adequate discussion on the architectural regularization that neural networks offer when learning such systems, hindering their efficient usage. In this paper, we initiate a discussion in this direction using coordinate networks as a test bed. We interpret dynamical systems and coordinate networks from a signal processing lens, and show that simple coordinate networks with few layers can be used to solve multiple problems in modelling dynamical systems, without any explicit regularizers. ",
    "url": "https://arxiv.org/abs/2303.05728",
    "authors": [
      "Sameera Ramasinghe",
      "Hemanth Saratchandran",
      "Violetta Shevchenko",
      "Simon Lucey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.05730",
    "title": "IC classifier: a classifier for 3D industrial components based on  geometric prior using GNN",
    "abstract": "In this paper, we propose an approach to address the problem of classifying 3D industrial components by introducing a novel framework named IC-classifier (Industrial Component classifier). Our framework is designed to focus on the object's local and global structures, emphasizing the former by incorporating specific local features for embedding the model. By utilizing graphical neural networks and embedding derived from geometric properties, IC-classifier facilitates the exploration of the local structures of the object while using geometric attention for the analysis of global structures. Furthermore, the framework uses point clouds to circumvent the heavy computation workload. The proposed framework's performance is benchmarked against state-of-the-art models, demonstrating its potential to compete in the field. ",
    "url": "https://arxiv.org/abs/2303.05730",
    "authors": [
      "Zipeng Lin",
      "Zhenguo Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05734",
    "title": "Generative Model Based Noise Robust Training for Unsupervised Domain  Adaptation",
    "abstract": "Target domain pseudo-labelling has shown effectiveness in unsupervised domain adaptation (UDA). However, pseudo-labels of unlabeled target domain data are inevitably noisy due to the distribution shift between source and target domains. This paper proposes a Generative model-based Noise-Robust Training method (GeNRT), which eliminates domain shift while mitigating label noise. GeNRT incorporates a Distribution-based Class-wise Feature Augmentation (D-CFA) and a Generative-Discriminative classifier Consistency (GDC), both based on the class-wise target distributions modelled by generative models. D-CFA minimizes the domain gap by augmenting the source data with distribution-sampled target features, and trains a noise-robust discriminative classifier by using target domain knowledge from the generative models. GDC regards all the class-wise generative models as generative classifiers and enforces a consistency regularization between the generative and discriminative classifiers. It exploits an ensemble of target knowledge from all the generative models to train a noise-robust discriminative classifier and eventually gets theoretically linked to the Ben-David domain adaptation theorem for reducing the domain gap. Extensive experiments on Office-Home, PACS, and Digit-Five show that our GeNRT achieves comparable performance to state-of-the-art methods under single-source and multi-source UDA settings. ",
    "url": "https://arxiv.org/abs/2303.05734",
    "authors": [
      "Zhongying Deng",
      "Da Li",
      "Junjun He",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05735",
    "title": "Hardware Acceleration of Neural Graphics",
    "abstract": "Rendering and inverse-rendering algorithms that drive conventional computer graphics have recently been superseded by neural representations (NR). NRs have recently been used to learn the geometric and the material properties of the scenes and use the information to synthesize photorealistic imagery, thereby promising a replacement for traditional rendering algorithms with scalable quality and predictable performance. In this work we ask the question: Does neural graphics (NG) need hardware support? We studied representative NG applications showing that, if we want to render 4k res. at 60FPS there is a gap of 1.5X-55X in the desired performance on current GPUs. For AR/VR applications, there is an even larger gap of 2-4 OOM between the desired performance and the required system power. We identify that the input encoding and the MLP kernels are the performance bottlenecks, consuming 72%,60% and 59% of application time for multi res. hashgrid, multi res. densegrid and low res. densegrid encodings, respectively. We propose a NG processing cluster, a scalable and flexible hardware architecture that directly accelerates the input encoding and MLP kernels through dedicated engines and supports a wide range of NG applications. We also accelerate the rest of the kernels by fusing them together in Vulkan, which leads to 9.94X kernel-level performance improvement compared to un-fused implementation of the pre-processing and the post-processing kernels. Our results show that, NGPC gives up to 58X end-to-end application-level performance improvement, for multi res. hashgrid encoding on average across the four NG applications, the performance benefits are 12X,20X,33X and 39X for the scaling factor of 8,16,32 and 64, respectively. Our results show that with multi res. hashgrid encoding, NGPC enables the rendering of 4k res. at 30FPS for NeRF and 8k res. at 120FPS for all our other NG applications. ",
    "url": "https://arxiv.org/abs/2303.05735",
    "authors": [
      "Muhammad Husnain Mubarik",
      "Ramakrishna Kanungo",
      "Tobias Zirr",
      "Rakesh Kumar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05739",
    "title": "Boosting Semi-Supervised Few-Shot Object Detection with SoftER Teacher",
    "abstract": "Few-shot object detection is an emerging problem aimed at detecting novel concepts from few exemplars. Existing approaches to few-shot detection assume abundant base labels to adapt to novel objects. This paper explores the task of semi-supervised few-shot detection by considering a realistic scenario which lacks abundant labels for both base and novel objects. Motivated by this unique problem, we introduce SoftER Teacher, a robust detector combining the advantages of pseudo-labeling with representation learning on region proposals. SoftER Teacher harnesses unlabeled data to jointly optimize for semi-supervised few-shot detection without explicitly relying on abundant base labels. Extensive experiments show that SoftER Teacher matches the novel class performance of a strong supervised detector using only 10% of base labels. Our work also sheds insight into a previously unknown relationship between semi-supervised and few-shot detection to suggest that a stronger semi-supervised detector leads to a more label-efficient few-shot detector. Code and models are available at https://github.com/lexisnexis-risk-open-source/ledetection ",
    "url": "https://arxiv.org/abs/2303.05739",
    "authors": [
      "Phi Vu Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05758",
    "title": "MIXPGD: Hybrid Adversarial Training for Speech Recognition Systems",
    "abstract": "Automatic speech recognition (ASR) systems based on deep neural networks are weak against adversarial perturbations. We propose mixPGD adversarial training method to improve the robustness of the model for ASR systems. In standard adversarial training, adversarial samples are generated by leveraging supervised or unsupervised methods. We merge the capabilities of both supervised and unsupervised approaches in our method to generate new adversarial samples which aid in improving model robustness. Extensive experiments and comparison across various state-of-the-art defense methods and adversarial attacks have been performed to show that mixPGD gains 4.1% WER of better performance than previous best performing models under white-box adversarial attack setting. We tested our proposed defense method against both white-box and transfer based black-box attack settings to ensure that our defense strategy is robust against various types of attacks. Empirical results on several adversarial attacks validate the effectiveness of our proposed approach. ",
    "url": "https://arxiv.org/abs/2303.05758",
    "authors": [
      "Aminul Huq",
      "Weiyi Zhang",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.05760",
    "title": "GameFormer: Game-theoretic Modeling and Learning of Transformer-based  Interactive Prediction and Planning for Autonomous Driving",
    "abstract": "Autonomous vehicles operating in complex real-world environments require accurate predictions of interactive behaviors between traffic participants. While existing works focus on modeling agent interactions based on their past trajectories, their future interactions are often ignored. This paper addresses the interaction prediction problem by formulating it with hierarchical game theory and proposing the GameFormer framework to implement it. Specifically, we present a novel Transformer decoder structure that uses the prediction results from the previous level together with the common environment background to iteratively refine the interaction process. Moreover, we propose a learning process that regulates an agent's behavior at the current level to respond to other agents' behaviors from the last level. Through experiments on a large-scale real-world driving dataset, we demonstrate that our model can achieve state-of-the-art prediction accuracy on the interaction prediction task. We also validate the model's capability to jointly reason about the ego agent's motion plans and other agents' behaviors in both open-loop and closed-loop planning tests, outperforming a variety of baseline methods. ",
    "url": "https://arxiv.org/abs/2303.05760",
    "authors": [
      "Zhiyu Huang",
      "Haochen Liu",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05762",
    "title": "TrojDiff: Trojan Attacks on Diffusion Models with Diverse Targets",
    "abstract": "Diffusion models have achieved great success in a range of tasks, such as image synthesis and molecule design. As such successes hinge on large-scale training data collected from diverse sources, the trustworthiness of these collected data is hard to control or audit. In this work, we aim to explore the vulnerabilities of diffusion models under potential training data manipulations and try to answer: How hard is it to perform Trojan attacks on well-trained diffusion models? What are the adversarial targets that such Trojan attacks can achieve? To answer these questions, we propose an effective Trojan attack against diffusion models, TrojDiff, which optimizes the Trojan diffusion and generative processes during training. In particular, we design novel transitions during the Trojan diffusion process to diffuse adversarial targets into a biased Gaussian distribution and propose a new parameterization of the Trojan generative process that leads to an effective training objective for the attack. In addition, we consider three types of adversarial targets: the Trojaned diffusion models will always output instances belonging to a certain class from the in-domain distribution (In-D2D attack), out-of-domain distribution (Out-D2D-attack), and one specific instance (D2I attack). We evaluate TrojDiff on CIFAR-10 and CelebA datasets against both DDPM and DDIM diffusion models. We show that TrojDiff always achieves high attack performance under different adversarial targets using different types of triggers, while the performance in benign environments is preserved. The code is available at https://github.com/chenweixin107/TrojDiff. ",
    "url": "https://arxiv.org/abs/2303.05762",
    "authors": [
      "Weixin Chen",
      "Dawn Song",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05763",
    "title": "Automatic Detection and Rectification of Paper Receipts on Smartphones",
    "abstract": "We describe the development of a real-time smartphone app that allows the user to digitize paper receipts in a novel way by \"waving\" their phone over the receipts and letting the app automatically detect and rectify the receipts for subsequent text recognition. We show that traditional computer vision algorithms for edge and corner detection do not robustly detect the non-linear and discontinuous edges and corners of a typical paper receipt in real-world settings. This is particularly the case when the colors of the receipt and background are similar, or where other interfering rectangular objects are present. Inaccurate detection of a receipt's corner positions then results in distorted images when using an affine projective transformation to rectify the perspective. We propose an innovative solution to receipt corner detection by treating each of the four corners as a unique \"object\", and training a Single Shot Detection MobileNet object detection model. We use a small amount of real data and a large amount of automatically generated synthetic data that is designed to be similar to real-world imaging scenarios. We show that our proposed method robustly detects the four corners of a receipt, giving a receipt detection accuracy of 85.3% on real-world data, compared to only 36.9% with a traditional edge detection-based approach. Our method works even when the color of the receipt is virtually indistinguishable from the background. Moreover, our method is trained to detect only the corners of the central target receipt and implicitly learns to ignore other receipts, and other rectangular objects. Including synthetic data allows us to train an even better model. These factors are a major advantage over traditional edge detection-based approaches, allowing us to deliver a much better experience to the user. ",
    "url": "https://arxiv.org/abs/2303.05763",
    "authors": [
      "Edward Whittaker",
      "Masashi Tanaka",
      "Ikuo Kitagishi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.05768",
    "title": "Learning Global-Local Correspondence with Semantic Bottleneck for  Logical Anomaly Detection",
    "abstract": "This paper presents a novel framework, named Global-Local Correspondence Framework (GLCF), for visual anomaly detection with logical constraints. Visual anomaly detection has become an active research area in various real-world applications, such as industrial anomaly detection and medical disease diagnosis. However, most existing methods focus on identifying local structural degeneration anomalies and often fail to detect high-level functional anomalies that involve logical constraints. To address this issue, we propose a two-branch approach that consists of a local branch for detecting structural anomalies and a global branch for detecting logical anomalies. To facilitate local-global feature correspondence, we introduce a novel semantic bottleneck enabled by the visual Transformer. Moreover, we develop feature estimation networks for each branch separately to detect anomalies. Our proposed framework is validated using various benchmarks, including industrial datasets, Mvtec AD, Mvtec Loco AD, and the Retinal-OCT medical dataset. Experimental results show that our method outperforms existing methods, particularly in detecting logical anomalies. ",
    "url": "https://arxiv.org/abs/2303.05768",
    "authors": [
      "Haiming Yao",
      "Wenyong Yu",
      "Wei Luo",
      "Zhenfeng Qiang",
      "Donghao Luo",
      "Xiaotian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05772",
    "title": "Sufficient Control of Complex Networks",
    "abstract": "In this paper, we propose to study on sufficient control of complex networks which is to control a sufficiently large portion of the network, where only the quantity of controllable nodes matters. To the best of our knowledge, this is the first time that such a problem is investigated. We prove that the sufficient controllability problem can be converted into a minimum cost flow problem, for which an algorithm can be easily devised with polynomial complexity. Further, we study the problem of minimum-cost sufficient control, which is to drive a sufficiently large subset of the network nodes to any predefined state with the minimum cost using a given number of controllers. It is proved that the problem is NP-hard. We propose an ``extended $L_{\\mathrm{0}}$-norm-constraint-based Projected Gradient Method\" (eLPGM) algorithm which may achieve suboptimal solutions for the problems at small or medium sizes. To tackle the large-scale problems, we propose to convert the control problem into a graph algorithm problem, and devise an efficient low-complexity ``Evenly Divided Control Paths\" (EDCP) algorithm to tackle the graph problem. Simulation results on both synthetic and real-life networks are provided, demonstrating the satisfactory performance of the proposed methods. ",
    "url": "https://arxiv.org/abs/2303.05772",
    "authors": [
      "Xiang Li",
      "Guoqi Li",
      "Leitao Gao",
      "Beibei Li",
      "Gaoxi Xiao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.05775",
    "title": "Self-NeRF: A Self-Training Pipeline for Few-Shot Neural Radiance Fields",
    "abstract": "Recently, Neural Radiance Fields (NeRF) have emerged as a potent method for synthesizing novel views from a dense set of images. Despite its impressive performance, NeRF is plagued by its necessity for numerous calibrated views and its accuracy diminishes significantly in a few-shot setting. To address this challenge, we propose Self-NeRF, a self-evolved NeRF that iteratively refines the radiance fields with very few number of input views, without incorporating additional priors. Basically, we train our model under the supervision of reference and unseen views simultaneously in an iterative procedure. In each iteration, we label unseen views with the predicted colors or warped pixels generated by the model from the preceding iteration. However, these expanded pseudo-views are afflicted by imprecision in color and warping artifacts, which degrades the performance of NeRF. To alleviate this issue, we construct an uncertainty-aware NeRF with specialized embeddings. Some techniques such as cone entropy regularization are further utilized to leverage the pseudo-views in the most efficient manner. Through experiments under various settings, we verified that our Self-NeRF is robust to input with uncertainty and surpasses existing methods when trained on limited training data. ",
    "url": "https://arxiv.org/abs/2303.05775",
    "authors": [
      "Jiayang Bai",
      "Letian Huang",
      "Wen Gong",
      "Jie Guo",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.05786",
    "title": "Vertical Federated Graph Neural Network for Recommender System",
    "abstract": "Conventional recommender systems are required to train the recommendation model using a centralized database. However, due to data privacy concerns, this is often impractical when multi-parties are involved in recommender system training. Federated learning appears as an excellent solution to the data isolation and privacy problem. Recently, Graph neural network (GNN) is becoming a promising approach for federated recommender systems. However, a key challenge is to conduct embedding propagation while preserving the privacy of the graph structure. Few studies have been conducted on the federated GNN-based recommender system. Our study proposes the first vertical federated GNN-based recommender system, called VerFedGNN. We design a framework to transmit: (i) the summation of neighbor embeddings using random projection, and (ii) gradients of public parameter perturbed by ternary quantization mechanism. Empirical studies show that VerFedGNN has competitive prediction accuracy with existing privacy preserving GNN frameworks while enhanced privacy protection for users' interaction information. ",
    "url": "https://arxiv.org/abs/2303.05786",
    "authors": [
      "Peihua Mai",
      "Yan Pang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.05809",
    "title": "Distributionally Robust Optimization with Probabilistic Group",
    "abstract": "Modern machine learning models may be susceptible to learning spurious correlations that hold on average but not for the atypical group of samples. To address the problem, previous approaches minimize the empirical worst-group risk. Despite the promise, they often assume that each sample belongs to one and only one group, which does not allow expressing the uncertainty in group labeling. In this paper, we propose a novel framework PG-DRO, which explores the idea of probabilistic group membership for distributionally robust optimization. Key to our framework, we consider soft group membership instead of hard group annotations. The group probabilities can be flexibly generated using either supervised learning or zero-shot approaches. Our framework accommodates samples with group membership ambiguity, offering stronger flexibility and generality than the prior art. We comprehensively evaluate PG-DRO on both image classification and natural language processing benchmarks, establishing superior performance ",
    "url": "https://arxiv.org/abs/2303.05809",
    "authors": [
      "Soumya Suvra Ghosal",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05812",
    "title": "Semi-supervised Adversarial Learning for Complementary Item  Recommendation",
    "abstract": "Complementary item recommendations are a ubiquitous feature of modern e-commerce sites. Such recommendations are highly effective when they are based on collaborative signals like co-purchase statistics. In certain online marketplaces, however, e.g., on online auction sites, constantly new items are added to the catalog. In such cases, complementary item recommendations are often based on item side-information due to a lack of interaction data. In this work, we propose a novel approach that can leverage both item side-information and labeled complementary item pairs to generate effective complementary recommendations for cold items, i.e., for items for which no co-purchase statistics yet exist. Given that complementary items typically have to be of a different category than the seed item, we technically maintain a latent space for each item category. Simultaneously, we learn to project distributed item representations into these category spaces to determine suitable recommendations. The main learning process in our architecture utilizes labeled pairs of complementary items. In addition, we adopt ideas from Cycle Generative Adversarial Networks (CycleGAN) to leverage available item information even in case no labeled data exists for a given item and category. Experiments on three e-commerce datasets show that our method is highly effective. ",
    "url": "https://arxiv.org/abs/2303.05812",
    "authors": [
      "Koby Bibas",
      "Oren Sar Shalom",
      "Dietmar Jannach"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05835",
    "title": "You Only Train Once: Multi-Identity Free-Viewpoint Neural Human  Rendering from Monocular Videos",
    "abstract": "We introduce You Only Train Once (YOTO), a dynamic human generation framework, which performs free-viewpoint rendering of different human identities with distinct motions, via only one-time training from monocular videos. Most prior works for the task require individualized optimization for each input video that contains a distinct human identity, leading to a significant amount of time and resources for the deployment, thereby impeding the scalability and the overall application potential of the system. In this paper, we tackle this problem by proposing a set of learnable identity codes to expand the capability of the framework for multi-identity free-viewpoint rendering, and an effective pose-conditioned code query mechanism to finely model the pose-dependent non-rigid motions. YOTO optimizes neural radiance fields (NeRF) by utilizing designed identity codes to condition the model for learning various canonical T-pose appearances in a single shared volumetric representation. Besides, our joint learning of multiple identities within a unified model incidentally enables flexible motion transfer in high-quality photo-realistic renderings for all learned appearances. This capability expands its potential use in important applications, including Virtual Reality. We present extensive experimental results on ZJU-MoCap and PeopleSnapshot to clearly demonstrate the effectiveness of our proposed model. YOTO shows state-of-the-art performance on all evaluation metrics while showing significant benefits in training and inference efficiency as well as rendering quality. The code and model will be made publicly available soon. ",
    "url": "https://arxiv.org/abs/2303.05835",
    "authors": [
      "Jaehyeok Kim",
      "Dongyoon Wee",
      "Dan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05871",
    "title": "Accurate Real-time Polyp Detection in Videos from Concatenation of  Latent Features Extracted from Consecutive Frames",
    "abstract": "An efficient deep learning model that can be implemented in real-time for polyp detection is crucial to reducing polyp miss-rate during screening procedures. Convolutional neural networks (CNNs) are vulnerable to small changes in the input image. A CNN-based model may miss the same polyp appearing in a series of consecutive frames and produce unsubtle detection output due to changes in camera pose, lighting condition, light reflection, etc. In this study, we attempt to tackle this problem by integrating temporal information among neighboring frames. We propose an efficient feature concatenation method for a CNN-based encoder-decoder model without adding complexity to the model. The proposed method incorporates extracted feature maps of previous frames to detect polyps in the current frame. The experimental results demonstrate that the proposed method of feature concatenation improves the overall performance of automatic polyp detection in videos. The following results are obtained on a public video dataset: sensitivity 90.94\\%, precision 90.53\\%, and specificity 92.46% ",
    "url": "https://arxiv.org/abs/2303.05871",
    "authors": [
      "Hemin Ali Qadir",
      "Younghak Shin",
      "Jacob Bergsland",
      "Ilangko Balasingham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05886",
    "title": "Bi3D: Bi-domain Active Learning for Cross-domain 3D Object Detection",
    "abstract": "Unsupervised Domain Adaptation (UDA) technique has been explored in 3D cross-domain tasks recently. Though preliminary progress has been made, the performance gap between the UDA-based 3D model and the supervised one trained with fully annotated target domain is still large. This motivates us to consider selecting partial-yet-important target data and labeling them at a minimum cost, to achieve a good trade-off between high performance and low annotation cost. To this end, we propose a Bi-domain active learning approach, namely Bi3D, to solve the cross-domain 3D object detection task. The Bi3D first develops a domainness-aware source sampling strategy, which identifies target-domain-like samples from the source domain to avoid the model being interfered by irrelevant source data. Then a diversity-based target sampling strategy is developed, which selects the most informative subset of target domain to improve the model adaptability to the target domain using as little annotation budget as possible. Experiments are conducted on typical cross-domain adaptation scenarios including cross-LiDAR-beam, cross-country, and cross-sensor, where Bi3D achieves a promising target-domain detection accuracy (89.63% on KITTI) compared with UDAbased work (84.29%), even surpassing the detector trained on the full set of the labeled target domain (88.98%). Our code is available at: https://github.com/PJLabADG/3DTrans. ",
    "url": "https://arxiv.org/abs/2303.05886",
    "authors": [
      "Jiakang Yuan",
      "Bo Zhang",
      "Xiangchao Yan",
      "Tao Chen",
      "Botian Shi",
      "Yikang Li",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05892",
    "title": "Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection",
    "abstract": "Open-vocabulary object detection aims to provide object detectors trained on a fixed set of object categories with the generalizability to detect objects described by arbitrary text queries. Previous methods adopt knowledge distillation to extract knowledge from Pretrained Vision-and-Language Models (PVLMs) and transfer it to detectors. However, due to the non-adaptive proposal cropping and single-level feature mimicking processes, they suffer from information destruction during knowledge extraction and inefficient knowledge transfer. To remedy these limitations, we propose an Object-Aware Distillation Pyramid (OADP) framework, including an Object-Aware Knowledge Extraction (OAKE) module and a Distillation Pyramid (DP) mechanism. When extracting object knowledge from PVLMs, the former adaptively transforms object proposals and adopts object-aware mask attention to obtain precise and complete knowledge of objects. The latter introduces global and block distillation for more comprehensive knowledge transfer to compensate for the missing relation information in object distillation. Extensive experiments show that our method achieves significant improvement compared to current methods. Especially on the MS-COCO dataset, our OADP framework reaches $35.6$ mAP$^{\\text{N}}_{50}$, surpassing the current state-of-the-art method by $3.3$ mAP$^{\\text{N}}_{50}$. Code is released at https://github.com/LutingWang/OADP. ",
    "url": "https://arxiv.org/abs/2303.05892",
    "authors": [
      "Luting Wang",
      "Yi Liu",
      "Penghui Du",
      "Zihan Ding",
      "Yue Liao",
      "Qiaosong Qi",
      "Biaolong Chen",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05904",
    "title": "Deep Anomaly Detection on Tennessee Eastman Process Data",
    "abstract": "This paper provides the first comprehensive evaluation and analysis of modern (deep-learning) unsupervised anomaly detection methods for chemical process data. We focus on the Tennessee Eastman process dataset, which has been a standard litmus test to benchmark anomaly detection methods for nearly three decades. Our extensive study will facilitate choosing appropriate anomaly detection methods in industrial applications. ",
    "url": "https://arxiv.org/abs/2303.05904",
    "authors": [
      "Fabian Hartung",
      "Billy Joe Franks",
      "Tobias Michels",
      "Dennis Wagner",
      "Philipp Liznerski",
      "Steffen Reithermann",
      "Sophie Fellenz",
      "Fabian Jirasek",
      "Maja Rudolph",
      "Daniel Neider",
      "Heike Leitte",
      "Chen Song",
      "Benjamin Kloepper",
      "Stephan Mandt",
      "Michael Bortz",
      "Jakob Burger",
      "Hans Hasse",
      "Marius Kloft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05915",
    "title": "Convolutional Cross-View Pose Estimation",
    "abstract": "We propose a novel end-to-end method for cross-view pose estimation. Given a ground-level query image and an aerial image that covers the query's local neighborhood, the 3 Degrees-of-Freedom camera pose of the query is estimated by matching its image descriptor to descriptors of local regions within the aerial image. The orientation-aware descriptors are obtained by using a translational equivariant convolutional ground image encoder and contrastive learning. The Localization Decoder produces a dense probability distribution in a coarse-to-fine manner with a novel Localization Matching Upsampling module. A smaller Orientation Decoder produces a vector field to condition the orientation estimate on the localization. Our method is validated on the VIGOR and KITTI datasets, where it surpasses the state-of-the-art baseline by 72% and 36% in median localization error for comparable orientation estimation accuracy. The predicted probability distribution can represent localization ambiguity, and enables rejecting possible erroneous predictions. Without re-training, the model can infer on ground images with different field of views and utilize orientation priors if available. On the Oxford RobotCar dataset, our method can reliably estimate the ego-vehicle's pose over time, achieving a median localization error under 1 meter and a median orientation error of around 1 degree at 14 FPS. ",
    "url": "https://arxiv.org/abs/2303.05915",
    "authors": [
      "Zimin Xia",
      "Olaf Booij",
      "Julian F. P. Kooij"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05937",
    "title": "Structural Multiplane Image: Bridging Neural View Synthesis and 3D  Reconstruction",
    "abstract": "The Multiplane Image (MPI), containing a set of fronto-parallel RGBA layers, is an effective and efficient representation for view synthesis from sparse inputs. Yet, its fixed structure limits the performance, especially for surfaces imaged at oblique angles. We introduce the Structural MPI (S-MPI), where the plane structure approximates 3D scenes concisely. Conveying RGBA contexts with geometrically-faithful structures, the S-MPI directly bridges view synthesis and 3D reconstruction. It can not only overcome the critical limitations of MPI, i.e., discretization artifacts from sloped surfaces and abuse of redundant layers, and can also acquire planar 3D reconstruction. Despite the intuition and demand of applying S-MPI, great challenges are introduced, e.g., high-fidelity approximation for both RGBA layers and plane poses, multi-view consistency, non-planar regions modeling, and efficient rendering with intersected planes. Accordingly, we propose a transformer-based network based on a segmentation model. It predicts compact and expressive S-MPI layers with their corresponding masks, poses, and RGBA contexts. Non-planar regions are inclusively handled as a special case in our unified framework. Multi-view consistency is ensured by sharing global proxy embeddings, which encode plane-level features covering the complete 3D scenes with aligned coordinates. Intensive experiments show that our method outperforms both previous state-of-the-art MPI-based view synthesis methods and planar reconstruction methods. ",
    "url": "https://arxiv.org/abs/2303.05937",
    "authors": [
      "Mingfang Zhang",
      "Jinglu Wang",
      "Xiao Li",
      "Yifei Huang",
      "Yoichi Sato",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05952",
    "title": "Understanding and Constructing Latent Modality Structures in Multi-modal  Representation Learning",
    "abstract": "Contrastive loss has been increasingly used in learning representations from multiple modalities. In the limit, the nature of the contrastive loss encourages modalities to exactly match each other in the latent space. Yet it remains an open question how the modality alignment affects the downstream task performance. In this paper, based on an information-theoretic argument, we first prove that exact modality alignment is sub-optimal in general for downstream prediction tasks. Hence we advocate that the key of better performance lies in meaningful latent modality structures instead of perfect modality alignment. To this end, we propose three general approaches to construct latent modality structures. Specifically, we design 1) a deep feature separation loss for intra-modality regularization; 2) a Brownian-bridge loss for inter-modality regularization; and 3) a geometric consistency loss for both intra- and inter-modality regularization. Extensive experiments are conducted on two popular multi-modal representation learning frameworks: the CLIP-based two-tower model and the ALBEF-based fusion model. We test our model on a variety of tasks including zero/few-shot image classification, image-text retrieval, visual question answering, visual reasoning, and visual entailment. Our method achieves consistent improvements over existing methods, demonstrating the effectiveness and generalizability of our proposed approach on latent modality structure regularization. ",
    "url": "https://arxiv.org/abs/2303.05952",
    "authors": [
      "Qian Jiang",
      "Changyou Chen",
      "Han Zhao",
      "Liqun Chen",
      "Qing Ping",
      "Son Dinh Tran",
      "Yi Xu",
      "Belinda Zeng",
      "Trishul Chilimbi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05957",
    "title": "Automated crack propagation measurement on asphalt concrete specimens  using an optical flow-based deep neural network",
    "abstract": "This article proposes a deep neural network, namely CrackPropNet, to measure crack propagation on asphalt concrete (AC) specimens. It offers an accurate, flexible, efficient, and low-cost solution for crack propagation measurement using images collected during cracking tests. CrackPropNet significantly differs from traditional deep learning networks, as it involves learning to locate displacement field discontinuities by matching features at various locations in the reference and deformed images. An image library representing the diversified cracking behavior of AC was developed for supervised training. CrackPropNet achieved an optimal dataset scale F-1 of 0.755 and optimal image scale F-1 of 0.781 on the testing dataset at a running speed of 26 frame-per-second. Experiments demonstrated that low to medium-level Gaussian noises had a limited impact on the measurement accuracy of CrackPropNet. Moreover, the model showed promising generalization on fundamentally different images. As a crack measurement technique, the CrackPropNet can detect complex crack patterns accurately and efficiently in AC cracking tests. It can be applied to characterize the cracking phenomenon, evaluate AC cracking potential, validate test protocols, and verify theoretical models. ",
    "url": "https://arxiv.org/abs/2303.05957",
    "authors": [
      "Zehui Zhu",
      "Imad L. Al-Qadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05958",
    "title": "Robust Knowledge Distillation from RNN-T Models With Noisy Training  Labels Using Full-Sum Loss",
    "abstract": "This work studies knowledge distillation (KD) and addresses its constraints for recurrent neural network transducer (RNN-T) models. In hard distillation, a teacher model transcribes large amounts of unlabelled speech to train a student model. Soft distillation is another popular KD method that distills the output logits of the teacher model. Due to the nature of RNN-T alignments, applying soft distillation between RNN-T architectures having different posterior distributions is challenging. In addition, bad teachers having high word-error-rate (WER) reduce the efficacy of KD. We investigate how to effectively distill knowledge from variable quality ASR teachers, which has not been studied before to the best of our knowledge. We show that a sequence-level KD, full-sum distillation, outperforms other distillation methods for RNN-T models, especially for bad teachers. We also propose a variant of full-sum distillation that distills the sequence discriminative knowledge of the teacher leading to further improvement in WER. We conduct experiments on public datasets namely SpeechStew and LibriSpeech, and on in-house production data. ",
    "url": "https://arxiv.org/abs/2303.05958",
    "authors": [
      "Mohammad Zeineldeen",
      "Kartik Audhkhasi",
      "Murali Karthick Baskar",
      "Bhuvana Ramabhadran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05972",
    "title": "Classifying the evolution of COVID-19 severity on patients with combined  dynamic Bayesian networks and neural networks",
    "abstract": "When we face patients arriving to a hospital suffering from the effects of some illness, one of the main problems we can encounter is evaluating whether or not said patients are going to require intensive care in the near future. This intensive care requires allotting valuable and scarce resources, and knowing beforehand the severity of a patients illness can improve both its treatment and the organization of resources. We illustrate this issue in a dataset consistent of Spanish COVID-19 patients from the sixth epidemic wave where we label patients as critical when they either had to enter the intensive care unit or passed away. We then combine the use of dynamic Bayesian networks, to forecast the vital signs and the blood analysis results of patients over the next 40 hours, and neural networks, to evaluate the severity of a patients disease in that interval of time. Our empirical results show that the transposition of the current state of a patient to future values with the DBN for its subsequent use in classification obtains better the accuracy and g-mean score than a direct application with a classifier. ",
    "url": "https://arxiv.org/abs/2303.05972",
    "authors": [
      "David Quesada",
      "Pedro Larra\u00f1aga",
      "Concha Bielza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05978",
    "title": "Neural Gromov-Wasserstein Optimal Transport",
    "abstract": "We present a scalable neural method to solve the Gromov-Wasserstein (GW) Optimal Transport (OT) problem with the inner product cost. In this problem, given two distributions supported on (possibly different) spaces, one has to find the most isometric map between them. Our proposed approach uses neural networks and stochastic mini-batch optimization which allows to overcome the limitations of existing GW methods such as their poor scalability with the number of samples and the lack of out-of-sample estimation. To demonstrate the effectiveness of our proposed method, we conduct experiments on the synthetic data and explore the practical applicability of our method to the popular task of the unsupervised alignment of word embeddings. ",
    "url": "https://arxiv.org/abs/2303.05978",
    "authors": [
      "Maksim Nekrashevich",
      "Alexander Korotin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06018",
    "title": "Hierarchical Neural Program Synthesis",
    "abstract": "Program synthesis aims to automatically construct human-readable programs that satisfy given task specifications, such as input/output pairs or demonstrations. Recent works have demonstrated encouraging results in a variety of domains, such as string transformation, tensor manipulation, and describing behaviors of embodied agents. Most existing program synthesis methods are designed to synthesize programs from scratch, generating a program token by token, line by line. This fundamentally prevents these methods from scaling up to synthesize programs that are longer or more complex. In this work, we present a scalable program synthesis framework that instead synthesizes a program by hierarchically composing programs. Specifically, we first learn a task embedding space and a program decoder that can decode a task embedding into a program. Then, we train a high-level module to comprehend the task specification (e.g., input/output pairs or demonstrations) from long programs and produce a sequence of task embeddings, which are then decoded by the program decoder and composed to yield the synthesized program. We extensively evaluate our proposed framework in a string transformation domain with input/output pairs. The experimental results demonstrate that the proposed framework can synthesize programs that are significantly longer and more complex than the programs considered in prior program synthesis works. Website at https://thoughtp0lice.github.io/hnps_web/ ",
    "url": "https://arxiv.org/abs/2303.06018",
    "authors": [
      "Linghan Zhong",
      "Ryan Lindeborg",
      "Jesse Zhang",
      "Joseph J. Lim",
      "Shao-Hua Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2303.06024",
    "title": "A hybrid deep-learning-metaheuristic framework to approximate discrete  road network design problems",
    "abstract": "This study proposes a hybrid deep-learning-metaheuristic framework with a bi-level architecture to solve road network design problems (NDPs). We train a graph neural network (GNN) to approximate the solution of the user equilibrium (UE) traffic assignment problem, and use inferences made by the trained model to calculate fitness function evaluations of a genetic algorithm (GA) to approximate solutions for NDPs. Using two NDP variants and an exact solver as benchmark, we show that our proposed framework can provide solutions within 5% gap of the global optimum results given less than 1% of the time required for finding the optimal results. Moreover, we observe many interesting future directions, thus we propose a brief research agenda for this topic. The key observation inspiring influential future research was that fitness function evaluation time using the inferences made by the GNN model for the genetic algorithm was in the order of milliseconds, which points to an opportunity and a need for novel heuristics that 1) can cope well with noisy fitness function values provided by neural networks, and 2) can use the significantly higher computation time provided to them to explore the search space effectively (rather than efficiently). This opens a new avenue for a modern class of metaheuristics that are crafted for use with AI-powered predictors. ",
    "url": "https://arxiv.org/abs/2303.06024",
    "authors": [
      "Bahman Madadi",
      "Goncalo Homem de Almeida Correia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.06032",
    "title": "Exploring Adversarial Attacks on Neural Networks: An Explainable  Approach",
    "abstract": "Deep Learning (DL) is being applied in various domains, especially in safety-critical applications such as autonomous driving. Consequently, it is of great significance to ensure the robustness of these methods and thus counteract uncertain behaviors caused by adversarial attacks. In this paper, we use gradient heatmaps to analyze the response characteristics of the VGG-16 model when the input images are mixed with adversarial noise and statistically similar Gaussian random noise. In particular, we compare the network response layer by layer to determine where errors occurred. Several interesting findings are derived. First, compared to Gaussian random noise, intentionally generated adversarial noise causes severe behavior deviation by distracting the area of concentration in the networks. Second, in many cases, adversarial examples only need to compromise a few intermediate blocks to mislead the final decision. Third, our experiments revealed that specific blocks are more vulnerable and easier to exploit by adversarial examples. Finally, we demonstrate that the layers $Block4\\_conv1$ and $Block5\\_cov1$ of the VGG-16 model are more susceptible to adversarial attacks. Our work could provide valuable insights into developing more reliable Deep Neural Network (DNN) models. ",
    "url": "https://arxiv.org/abs/2303.06032",
    "authors": [
      "Justus Renkhoff",
      "Wenkai Tan",
      "Alvaro Velasquez",
      "illiam Yichen Wang",
      "Yongxin Liu",
      "Jian Wang",
      "Shuteng Niu",
      "Lejla Begic Fazlic",
      "Guido Dartmann",
      "Houbing Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06088",
    "title": "Improving Domain-Invariance in Self-Supervised Learning via Batch Styles  Standardization",
    "abstract": "The recent rise of Self-Supervised Learning (SSL) as one of the preferred strategies for learning with limited labeled data, and abundant unlabeled data has led to the widespread use of these models. They are usually pretrained, finetuned, and evaluated on the same data distribution, i.e., within an in-distribution setting. However, they tend to perform poorly in out-of-distribution evaluation scenarios, a challenge that Unsupervised Domain Generalization (UDG) seeks to address. This paper introduces a novel method to standardize the styles of images in a batch. Batch styles standardization, relying on Fourier-based augmentations, promotes domain invariance in SSL by preventing spurious correlations from leaking into the features. The combination of batch styles standardization with the well-known contrastive-based method SimCLR leads to a novel UDG method named CLaSSy ($\\textbf{C}$ontrastive $\\textbf{L}$e$\\textbf{a}$rning with $\\textbf{S}$tandardized $\\textbf{S}$t$\\textbf{y}$les). CLaSSy offers serious advantages over prior methods, as it does not rely on domain labels and is scalable to handle a large number of domains. Experimental results on various UDG datasets demonstrate the superior performance of CLaSSy compared to existing UDG methods. Finally, the versatility of the proposed batch styles standardization is demonstrated by extending respectively the contrastive-based and non-contrastive-based SSL methods, SWaV and MSN, while considering different backbone architectures (convolutional-based, transformers-based). ",
    "url": "https://arxiv.org/abs/2303.06088",
    "authors": [
      "Marin Scalbert",
      "Maria Vakalopoulou",
      "Florent Couzini\u00e9-Devy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06090",
    "title": "Simple and efficient four-cycle counting on sparse graphs",
    "abstract": "We consider the problem of counting 4-cycles ($C_4$) in a general undirected graph $G$ of $n$ vertices and $m$ edges (in bipartite graphs, 4-cycles are also often referred to as $\\textit{butterflies}$). There have been a number of previous algorithms for this problem; some of these are based on fast matrix multiplication, which is attractive theoretically but not practical, and some of these are based on randomized hash tables. We develop a new simpler algorithm for counting $C_4$, which has several practical improvements over previous algorithms; for example, it is fully deterministic and avoids any expensive arithmetic in its inner loops. The algorithm can also be adapted to count 4-cycles incident to each vertex and edge. Our algorithm runs in $O(m\\bar\\delta(G))$ time and $O(n)$ space, where $\\bar \\delta(G) \\leq O(\\sqrt{m})$ is the $\\textit{average degeneracy}$ parameter introduced by Burkhardt, Faber & Harris (2020). ",
    "url": "https://arxiv.org/abs/2303.06090",
    "authors": [
      "Paul Burkhardt",
      "David G. Harris"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.06114",
    "title": "Optimal Design of Validation Experiments for the Prediction of  Quantities of Interest",
    "abstract": "Numerical predictions of quantities of interest measured within physical systems rely on the use of mathematical models that should be validated, or at best, not invalidated. Model validation usually involves the comparison of experimental data (outputs from the system of interest) and model predictions, both obtained at a specific validation scenario. The design of this validation experiment should be directly relevant to the objective of the model, that of predicting a quantity of interest at a prediction scenario. In this paper, we address two specific issues arising when designing validation experiments. The first issue consists in determining an appropriate validation scenario in cases where the prediction scenario cannot be carried out in a controlled environment. The second issue concerns the selection of observations when the quantity of interest cannot be readily observed. The proposed methodology involves the computation of influence matrices that characterize the response surface of given model functionals. Minimization of the distance between influence matrices allow one for selecting a validation experiment most representative of the prediction scenario. We illustrate our approach on two numerical examples. The first example considers the validation of a simple model based on an ordinary differential equation governing an object in free fall to put in evidence the importance of the choice of the validation experiment. The second numerical experiment focuses on the transport of a pollutant and demonstrates the impact that the choice of the quantity of interest has on the validation experiment to be performed. ",
    "url": "https://arxiv.org/abs/2303.06114",
    "authors": [
      "Antonin Paquette-Rufiange",
      "Serge Prudhomme",
      "Marc Laforest"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2303.06120",
    "title": "Measuring and Detecting Virality on Social Media: The Case of Twitter's  Viral Tweets Topic",
    "abstract": "Social media posts may go viral and reach large numbers of people within a short period of time. Such posts may threaten the public dialogue if they contain misleading content such as fake news. As such, early detection of viral posts may be crucial for tasks such as fact-checking. Previous works proposed their own metrics to measure virality. However, such metrics may not accurately represent viral tweets or may introduce too many false positives. In this work, we use the ground truth data provided by Twitter's \"Viral Tweets\" topic. We propose a dataset of tweets that are labeled by Twitter as viral and a dataset of all tweets from users who authored a viral tweet. We review the proposed metrics to represent the viral tweets and propose our own metric. We also propose a transformers-based model to predict viral tweets. The code and the tweet ids are publicly available at: https://github.com/tugrulz/ViralTweets ",
    "url": "https://arxiv.org/abs/2303.06120",
    "authors": [
      "Tu\u011frulcan Elmas",
      "Stephane Selim",
      "C\u00e9lia Houssiaux"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.06121",
    "title": "Ignorance is Bliss: Robust Control via Information Gating",
    "abstract": "Informational parsimony -- i.e., using the minimal information required for a task, -- provides a useful inductive bias for learning representations that achieve better generalization by being robust to noise and spurious correlations. We propose information gating in the pixel space as a way to learn more parsimonious representations. Information gating works by learning masks that capture only the minimal information required to solve a given task. Intuitively, our models learn to identify which visual cues actually matter for a given task. We gate information using a differentiable parameterization of the signal-to-noise ratio, which can be applied to arbitrary values in a network, e.g.~masking out pixels at the input layer. We apply our approach, which we call InfoGating, to various objectives such as: multi-step forward and inverse dynamics, Q-learning, behavior cloning, and standard self-supervised tasks. Our experiments show that learning to identify and use minimal information can improve generalization in downstream tasks -- e.g., policies based on info-gated images are considerably more robust to distracting/irrelevant visual features. ",
    "url": "https://arxiv.org/abs/2303.06121",
    "authors": [
      "Manan Tomar",
      "Riashat Islam",
      "Sergey Levine",
      "Philip Bachman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06124",
    "title": "Self-supervised Training Sample Difficulty Balancing for Local  Descriptor Learning",
    "abstract": "In the case of an imbalance between positive and negative samples, hard negative mining strategies have been shown to help models learn more subtle differences between positive and negative samples, thus improving recognition performance. However, if too strict mining strategies are promoted in the dataset, there may be a risk of introducing false negative samples. Meanwhile, the implementation of the mining strategy disrupts the difficulty distribution of samples in the real dataset, which may cause the model to over-fit these difficult samples. Therefore, in this paper, we investigate how to trade off the difficulty of the mined samples in order to obtain and exploit high-quality negative samples, and try to solve the problem in terms of both the loss function and the training strategy. The proposed balance loss provides an effective discriminant for the quality of negative samples by combining a self-supervised approach to the loss function, and uses a dynamic gradient modulation strategy to achieve finer gradient adjustment for samples of different difficulties. The proposed annealing training strategy then constrains the difficulty of the samples drawn from negative sample mining to provide data sources with different difficulty distributions for the loss function, and uses samples of decreasing difficulty to train the model. Extensive experiments show that our new descriptors outperform previous state-of-the-art descriptors for patch validation, matching, and retrieval tasks. ",
    "url": "https://arxiv.org/abs/2303.06124",
    "authors": [
      "Jiahan Zhang",
      "Dayong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06129",
    "title": "Single-branch Network for Multimodal Training",
    "abstract": "With the rapid growth of social media platforms, users are sharing billions of multimedia posts containing audio, images, and text. Researchers have focused on building autonomous systems capable of processing such multimedia data to solve challenging multimodal tasks including cross-modal retrieval, matching, and verification. Existing works use separate networks to extract embeddings of each modality to bridge the gap between them. The modular structure of their branched networks is fundamental in creating numerous multimodal applications and has become a defacto standard to handle multiple modalities. In contrast, we propose a novel single-branch network capable of learning discriminative representation of unimodal as well as multimodal tasks without changing the network. An important feature of our single-branch network is that it can be trained either using single or multiple modalities without sacrificing performance. We evaluated our proposed single-branch network on the challenging multimodal problem (face-voice association) for cross-modal verification and matching tasks with various loss formulations. Experimental results demonstrate the superiority of our proposed single-branch network over the existing methods in a wide range of experiments. Code: https://github.com/msaadsaeed/SBNet ",
    "url": "https://arxiv.org/abs/2303.06129",
    "authors": [
      "Muhammad Saad Saeed",
      "Shah Nawaz",
      "Muhammad Haris Khan",
      "Muhammad Zaigham Zaheer",
      "Karthik Nandakumar",
      "Muhammad Haroon Yousaf",
      "Arif Mahmood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06138",
    "title": "Learning Object-Centric Neural Scattering Functions for Free-viewpoint  Relighting and Scene Composition",
    "abstract": "Photorealistic object appearance modeling from 2D images is a constant topic in vision and graphics. While neural implicit methods (such as Neural Radiance Fields) have shown high-fidelity view synthesis results, they cannot relight the captured objects. More recent neural inverse rendering approaches have enabled object relighting, but they represent surface properties as simple BRDFs, and therefore cannot handle translucent objects. We propose Object-Centric Neural Scattering Functions (OSFs) for learning to reconstruct object appearance from only images. OSFs not only support free-viewpoint object relighting, but also can model both opaque and translucent objects. While accurately modeling subsurface light transport for translucent objects can be highly complex and even intractable for neural methods, OSFs learn to approximate the radiance transfer from a distant light to an outgoing direction at any spatial location. This approximation avoids explicitly modeling complex subsurface scattering, making learning a neural implicit model tractable. Experiments on real and synthetic data show that OSFs accurately reconstruct appearances for both opaque and translucent objects, allowing faithful free-viewpoint relighting as well as scene composition. ",
    "url": "https://arxiv.org/abs/2303.06138",
    "authors": [
      "Hong-Xing Yu",
      "Michelle Guo",
      "Alireza Fathi",
      "Yen-Yu Chang",
      "Eric Ryan Chan",
      "Ruohan Gao",
      "Thomas Funkhouser",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.06147",
    "title": "Exphormer: Sparse Transformers for Graphs",
    "abstract": "Graph transformers have emerged as a promising architecture for a variety of graph learning and representation tasks. Despite their successes, though, it remains challenging to scale graph transformers to large graphs while maintaining accuracy competitive with message-passing networks. In this paper, we introduce Exphormer, a framework for building powerful and scalable graph transformers. Exphormer consists of a sparse attention mechanism based on two mechanisms: virtual global nodes and expander graphs, whose mathematical characteristics, such as spectral expansion, pseduorandomness, and sparsity, yield graph transformers with complexity only linear in the size of the graph, while allowing us to prove desirable theoretical properties of the resulting transformer models. We show that incorporating \\textsc{Exphormer} into the recently-proposed GraphGPS framework produces models with competitive empirical results on a wide variety of graph datasets, including state-of-the-art results on three datasets. We also show that \\textsc{Exphormer} can scale to datasets on larger graphs than shown in previous graph transformer architectures. Code can be found at https://github.com/hamed1375/Exphormer. ",
    "url": "https://arxiv.org/abs/2303.06147",
    "authors": [
      "Hamed Shirzad",
      "Ameya Velingker",
      "Balaji Venkatachalam",
      "Danica J. Sutherland",
      "Ali Kemal Sinop"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05577",
    "title": "Target Defense against Periodically Arriving Intruders",
    "abstract": "We consider a variant of pursuit-evasion games where a single defender is tasked to defend a static target from a sequence of periodically arriving intruders. The intruders' objective is to breach the boundary of a circular target without being captured and the defender's objective is to capture as many intruders as possible. At the beginning of each period, a new intruder appears at a random location on the perimeter of a fixed circle surrounding the target and moves radially towards the target center to breach the target. The intruders are slower in speed compared to the defender and they have their own sensing footprint through which they can perfectly detect the defender if it is within their sensing range. Considering the speed and sensing limitations of the agents, we analyze the entire game by dividing it into partial information and full information phases. We address the defender's capturability using the notions of engagement surface and capture circle. We develop and analyze three efficient strategies for the defender and derive a lower bound on the capture fraction. Finally, we conduct a series of simulations and numerical experiments to compare and contrast the three proposed approaches. ",
    "url": "https://arxiv.org/abs/2303.05577",
    "authors": [
      "Arman Pourghorban",
      "Dipankar Maity"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05583",
    "title": "Embedded graph 3-coloring and flows",
    "abstract": "A graph drawn in a surface is a near-quadrangulation if the sum of the lengths of the faces different from 4-faces is bounded by a fixed constant. We leverage duality between colorings and flows to design an efficient algorithm for 3-precoloring-extension in near-quadrangulations of orientable surfaces. Furthermore, we use this duality to strengthen previously known sufficient conditions for 3-colorability of triangle-free graphs drawn in orientable surfaces. ",
    "url": "https://arxiv.org/abs/2303.05583",
    "authors": [
      "Caroline Bang",
      "Zden\u011bk Dvo\u0159\u00e1k",
      "Emily Heath",
      "Bernard Lidick\u00fd"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.05660",
    "title": "Towards better traffic volume estimation: Tackling both underdetermined  and non-equilibrium problems via a correlation adaptive graph convolution  network",
    "abstract": "Traffic volume is an indispensable ingredient to provide fine-grained information for traffic management and control. However, due to limited deployment of traffic sensors, obtaining full-scale volume information is far from easy. Existing works on this topic primarily focus on improving the overall estimation accuracy of a particular method and ignore the underlying challenges of volume estimation, thereby having inferior performances on some critical tasks. This paper studies two key problems with regard to traffic volume estimation: (1) underdetermined traffic flows caused by undetected movements, and (2) non-equilibrium traffic flows arise from congestion propagation. Here we demonstrate a graph-based deep learning method that can offer a data-driven, model-free and correlation adaptive approach to tackle the above issues and perform accurate network-wide traffic volume estimation. Particularly, in order to quantify the dynamic and nonlinear relationships between traffic speed and volume for the estimation of underdetermined flows, a speed patternadaptive adjacent matrix based on graph attention is developed and integrated into the graph convolution process, to capture non-local correlations between sensors. To measure the impacts of non-equilibrium flows, a temporal masked and clipped attention combined with a gated temporal convolution layer is customized to capture time-asynchronous correlations between upstream and downstream sensors. We then evaluate our model on a real-world highway traffic volume dataset and compare it with several benchmark models. It is demonstrated that the proposed model achieves high estimation accuracy even under 20% sensor coverage rate and outperforms other baselines significantly, especially on underdetermined and non-equilibrium flow locations. Furthermore, comprehensive quantitative model analysis are also carried out to justify the model designs. ",
    "url": "https://arxiv.org/abs/2303.05660",
    "authors": [
      "Tong Nie",
      "Guoyang Qin",
      "Yunpeng Wang",
      "Jian Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05682",
    "title": "A dual basis approach to multidimensional scaling: spectral analysis and  graph regularity",
    "abstract": "Classical multidimensional scaling (CMDS) is a technique that aims to embed a set of objects in a Euclidean space given their pairwise Euclidean distance matrix. The main part of CMDS is based on double centering a squared distance matrix and employing a truncated eigendecomposition to recover the point coordinates. A central result in CMDS connects the squared Euclidean matrix to a Gram matrix derived from the set of points. In this paper, we study a dual basis approach to classical multidimensional scaling. We give an explicit formula for the dual basis and fully characterize the spectrum of an essential matrix in the dual basis framework. We make connections to a related problem in metric nearness. ",
    "url": "https://arxiv.org/abs/2303.05682",
    "authors": [
      "Samuel Lichtenberg",
      "Abiy Tasissa"
    ],
    "subjectives": [
      "Spectral Theory (math.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05723",
    "title": "New Results on Edge-coloring and Total-coloring of Split Graphs",
    "abstract": "A split graph is a graph whose vertex set can be partitioned into a clique and an independent set. A connected graph $G$ is said to be $t$-admissible if admits a special spanning tree in which the distance between any two adjacent vertices is at most $t$. Given a graph $G$, determining the smallest $t$ for which $G$ is $t$-admissible, i.e. the stretch index of $G$ denoted by $\\sigma(G)$, is the goal of the $t$-admissibility problem. Split graphs are $3$-admissible and can be partitioned into three subclasses: split graphs with $\\sigma=1, 2 $ or $3$. In this work we consider such a partition while dealing with the problem of coloring a split graph. Vizing proved that any graph can have its edges colored with $\\Delta$ or $\\Delta+1$ colors, and thus can be classified as Class 1 or Class 2, respectively. When both, edges and vertices, are simultaneously colored, i.e., a total coloring of $G$, it is conjectured that any graph can be total colored with $\\Delta+1$ or $\\Delta+2$ colors, and thus can be classified as Type 1 or Type 2. These both variants are still open for split graphs. In this paper, using the partition of split graphs presented above, we consider the edge coloring problem and the total coloring problem for split graphs with $\\sigma=2$. For this class, we characterize Class 2 and Type 2 graphs and we provide polynomial-time algorithms to color any Class 1 or Type 1 graph. ",
    "url": "https://arxiv.org/abs/2303.05723",
    "authors": [
      "Fernanda Couto",
      "Diego Amaro Ferraz",
      "Sulamita Klein"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.05777",
    "title": "Self-Supervised CSF Inpainting with Synthetic Atrophy for Improved  Accuracy Validation of Cortical Surface Analyses",
    "abstract": "Accuracy validation of cortical thickness measurement is a difficult problem due to the lack of ground truth data. To address this need, many methods have been developed to synthetically induce gray matter (GM) atrophy in an MRI via deformable registration, creating a set of images with known changes in cortical thickness. However, these methods often cause blurring in atrophied regions, and cannot simulate realistic atrophy within deep sulci where cerebrospinal fluid (CSF) is obscured or absent. In this paper, we present a solution using a self-supervised inpainting model to generate CSF in these regions and create images with more plausible GM/CSF boundaries. Specifically, we introduce a novel, 3D GAN model that incorporates patch-based dropout training, edge map priors, and sinusoidal positional encoding, all of which are established methods previously limited to 2D domains. We show that our framework significantly improves the quality of the resulting synthetic images and is adaptable to unseen data with fine-tuning. We also demonstrate that our resulting dataset can be employed for accuracy validation of cortical segmentation and thickness measurement. ",
    "url": "https://arxiv.org/abs/2303.05777",
    "authors": [
      "Jiacheng Wang",
      "Kathleen E. Larson",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05789",
    "title": "AnoMalNet: Outlier Detection based Malaria Cell Image Classification  Method Leveraging Deep Autoencoder",
    "abstract": "Class imbalance is a pervasive issue in the field of disease classification from medical images. It is necessary to balance out the class distribution while training a model for decent results. However, in the case of rare medical diseases, images from affected patients are much harder to come by compared to images from non-affected patients, resulting in unwanted class imbalance. Various processes of tackling class imbalance issues have been explored so far, each having its fair share of drawbacks. In this research, we propose an outlier detection based binary medical image classification technique which can handle even the most extreme case of class imbalance. We have utilized a dataset of malaria parasitized and uninfected cells. An autoencoder model titled AnoMalNet is trained with only the uninfected cell images at the beginning and then used to classify both the affected and non-affected cell images by thresholding a loss value. We have achieved an accuracy, precision, recall, and F1 score of 98.49%, 97.07%, 100%, and 98.52% respectively, performing better than large deep learning models and other published works. As our proposed approach can provide competitive results without needing the disease-positive samples during training, it should prove to be useful in binary disease classification on imbalanced datasets. ",
    "url": "https://arxiv.org/abs/2303.05789",
    "authors": [
      "Aminul Huq",
      "Md Tanzim Reza",
      "Shahriar Hossain",
      "Shakib Mahmud Dipto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05860",
    "title": "Variational Quantum Neural Networks (VQNNS) in Image Classification",
    "abstract": "Quantum machine learning has established as an interdisciplinary field to overcome limitations of classical machine learning and neural networks. This is a field of research which can prove that quantum computers are able to solve problems with complex correlations between inputs that can be hard for classical computers. This suggests that learning models made on quantum computers may be more powerful for applications, potentially faster computation and better generalization on less data. The objective of this paper is to investigate how training of quantum neural network (QNNs) can be done using quantum optimization algorithms for improving the performance and time complexity of QNNs. A classical neural network can be partially quantized to create a hybrid quantum-classical neural network which is used mainly in classification and image recognition. In this paper, a QNN structure is made where a variational parameterized circuit is incorporated as an input layer named as Variational Quantum Neural Network (VQNNs). We encode the cost function of QNNs onto relative phases of a superposition state in the Hilbert space of the network parameters. The parameters are tuned with an iterative quantum approximate optimisation (QAOA) mixer and problem hamiltonians. VQNNs is experimented with MNIST digit recognition (less complex) and crack image classification datasets (more complex) which converges the computation in lesser time than QNN with decent training accuracy. ",
    "url": "https://arxiv.org/abs/2303.05860",
    "authors": [
      "Meghashrita Das",
      "Tirupati Bolisetti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05912",
    "title": "DACov: A Deeper Analysis of Data Augmentation on the Computed Tomography  Segmentation Problem",
    "abstract": "Due to the COVID-19 global pandemic, computer-assisted diagnoses of medical images have gained much attention, and robust methods of semantic segmentation of Computed Tomography (CT) images have become highly desirable. In this work, we present a deeper analysis of how data augmentation techniques improve segmentation performance on this problem. We evaluate 20 traditional augmentation techniques on five public datasets. Six different probabilities of applying each augmentation technique on an image were evaluated. We also assess a different training methodology where the training subsets are combined into a single larger set. All networks were evaluated through a 5-fold cross-validation strategy, resulting in over 4,600 experiments. We also propose a novel data augmentation technique based on Generative Adversarial Networks (GANs) to create new healthy and unhealthy lung CT images, evaluating four variations of our approach with the same six probabilities of the traditional methods. Our findings show that GAN-based techniques and spatial-level transformations are the most promising for improving the learning of deep models on this problem, with the StarGANv2 + F with a probability of 0.3 achieving the highest F-score value on the Ricord1a dataset in the unified training strategy. Our code is publicly available at https://github.com/VRI-UFPR/DACov2022 ",
    "url": "https://arxiv.org/abs/2303.05912",
    "authors": [
      "Bruno A. Krinski",
      "Daniel V. Ruiz",
      "Rayson Laroca",
      "Eduardo Todt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06028",
    "title": "Sleep Quality Prediction from Wearables using Convolution Neural  Networks and Ensemble Learning",
    "abstract": "Sleep is among the most important factors affecting one's daily performance, well-being, and life quality. Nevertheless, it became possible to measure it in daily life in an unobtrusive manner with wearable devices. Rather than camera recordings and extraction of the state from the images, wrist-worn devices can measure directly via accelerometer, heart rate, and heart rate variability sensors. Some measured features can be as follows: time to bed, time out of bed, bedtime duration, minutes to fall asleep, and minutes after wake-up. There are several studies in the literature regarding sleep quality and stage prediction. However, they use only wearable data to predict or focus on the sleep stage. In this study, we use the NetHealth dataset, which is collected from 698 college students' via wearables, as well as surveys. Recently, there has been an advancement in deep learning algorithms, and they generally perform better than conventional machine learning techniques. Among them, Convolutional Neural Networks (CNN) have high performances. Thus, in this study, we apply different CNN architectures that have already performed well in the human activity recognition domain and compare their results. We also apply Random Forest (RF) since it performs best among the conventional methods. In future studies, we will compare them with other deep learning algorithms. ",
    "url": "https://arxiv.org/abs/2303.06028",
    "authors": [
      "Ozan K\u0131l\u0131\u00e7",
      "Berrenur Saylam",
      "\u00d6zlem Durmaz \u0130ncel"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06033",
    "title": "Depression Diagnosis and Drug Response Prediction via Recurrent Neural  Networks and Transformers Utilizing EEG Signals",
    "abstract": "The Early diagnosis and treatment of depression is essential for effective treatment. Depression, while being one of the most common mental illnesses, is still poorly understood in both research and clinical practice. Among different treatments, drug prescription is widely used, however the drug treatment is not effective for many patients. In this work, we propose a method for major depressive disorder (MDD) diagnosis as well as a method for predicting the drug response in patient with MDD using EEG signals. Method: We employ transformers, which are modified recursive neural networks with novel architecture to evaluate the time dependency of time series effectively. We also compare the model to the well-known deep learning schemes such as CNN, LSTM and CNN-LSTM. Results: The transformer achieves an average recall of 99.41% and accuracy of 97.14% for classifying normal and MDD subjects. Furthermore, the transformer also performed well in classifying responders and non-responders to the drug, resulting in 97.01% accuracy and 97.76% Recall. Conclusion: Outperforming other methods on a similar number of parameters, the suggested technique, as a screening tool, seems to have the potential to assist health care professionals in assessing MDD patients for early diagnosis and treatment. Significance: Analyzing EEG signal analysis using transformers, which have replaced the recursive models as a new structure to examine the time dependence of time series, is the main novelty of this research. ",
    "url": "https://arxiv.org/abs/2303.06033",
    "authors": [
      "Abdolkarim Saeedi",
      "Arash Maghsoudi",
      "Fereidoun Nowshiravan Rahatabad"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06047",
    "title": "Toward NeuroDM: Where Computational Neuroscience Meets Data Mining",
    "abstract": "At the intersection of computational neuroscience (CN) and data mining (DM), we advocate a holistic view toward their rich connections. On the one hand, fundamental concepts in neuroscience such as saliency, memory, and emotion can find novel applications in data mining. On the other hand, multimodal imaging has opened the door for data mining to facilitate the extraction of important cognitive and behavioral information from multimodal neural data. By NeuroDM, we advocate for more collaboration between CN and DM to expedite the advances in two well-established fields. The analogy between the over-parameterization of biological and artificial neural networks might suggest a unifying perspective of advancing both fields. ",
    "url": "https://arxiv.org/abs/2303.06047",
    "authors": [
      "Xin Li",
      "Bin Liu",
      "Shuo Wang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.06060",
    "title": "Deep Spiking Neural Networks with High Representation Similarity Model  Visual Pathways of Macaque and Mouse",
    "abstract": "Deep artificial neural networks (ANNs) play a major role in modeling the visual pathways of primate and rodent. However, they highly simplify the computational properties of neurons compared to their biological counterparts. Instead, Spiking Neural Networks (SNNs) are more biologically plausible models since spiking neurons encode information with time sequences of spikes, just like biological neurons do. However, there is a lack of studies on visual pathways with deep SNNs models. In this study, we model the visual cortex with deep SNNs for the first time, and also with a wide range of state-of-the-art deep CNNs and ViTs for comparison. Using three similarity metrics, we conduct neural representation similarity experiments on three neural datasets collected from two species under three types of stimuli. Based on extensive similarity analyses, we further investigate the functional hierarchy and mechanisms across species. Almost all similarity scores of SNNs are higher than their counterparts of CNNs with an average of 6.6%. Depths of the layers with the highest similarity scores exhibit little differences across mouse cortical regions, but vary significantly across macaque regions, suggesting that the visual processing structure of mice is more regionally homogeneous than that of macaques. Besides, the multi-branch structures observed in some top mouse brain-like neural networks provide computational evidence of parallel processing streams in mice, and the different performance in fitting macaque neural representations under different stimuli exhibits the functional specialization of information processing in macaques. Taken together, our study demonstrates that SNNs could serve as promising candidates to better model and explain the functional hierarchy and mechanisms of the visual system. ",
    "url": "https://arxiv.org/abs/2303.06060",
    "authors": [
      "Liwei Huang",
      "Zhengyu Ma",
      "Liutao Yu",
      "Huihui Zhou",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.06070",
    "title": "Thinness and its variations on some graph families and coloring graphs  of bounded thinness",
    "abstract": "Interval graphs and proper interval graphs are well known graph classes, for which there have been proposed several generalizations in the literature. In this work, we study the (proper) $k$-thin graphs and its variations for the classes of cographs, crown graphs and grid graphs. We provide the exact values for several variants of thinness (proper, independent, complete, precedence, and combinations of them) for the crown graphs $CR_n$. For cographs, we prove that the precedence thinness can be determined in polynomial time. We also improve known bounds for the thinness of $n \\times n$ grids $GR_n$ and $m \\times n$ grids $GR_{m,n}$, proving that $\\left \\lceil \\frac{n-1}{3} \\right \\rceil \\leq \\mbox{thin}(GR_n) \\leq \\left \\lceil \\frac{n+1}{2} \\right \\rceil$. Regarding the precedence thinness, we prove that $\\mbox{prec-thin}(GR_{n,2}) = \\left \\lceil \\frac{n+1}{2} \\right \\rceil$ and that $\\left \\lceil \\frac{n-1}{3} \\right \\rceil \\left \\lceil\\frac{n-1}{2} \\right \\rceil + 1 \\leq \\mbox{prec-thin}(GR_n) \\leq \\left \\lceil\\frac{n-1}{2} \\right \\rceil^2+1$. As applications, we show that the $k$-coloring problem is NP-complete for precedence $2$-thin graphs and for proper $2$-thin graphs, when $k$ is part of the input. On the positive side, it is polynomially solvable for precedence proper 2-thin graphs, given the order and partition. ",
    "url": "https://arxiv.org/abs/2303.06070",
    "authors": [
      "Flavia Bonomo-Braberman",
      "Eric Brandwein",
      "Fabiano S. Oliveira",
      "Moys\u00e9s S. Sampaio Jr.",
      "Agustin Sansone",
      "Jayme L. Szwarcfiter"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.06078",
    "title": "An End-to-End Neural Network for Image-to-Audio Transformation",
    "abstract": "This paper describes an end-to-end (E2E) neural architecture for the audio rendering of small portions of display content on low resource personal computing devices. It is intended to address the problem of accessibility for vision-impaired or vision-distracted users at the hardware level. Neural image-to-text (ITT) and text-to-speech (TTS) approaches are reviewed and a new technique is introduced to efficiently integrate them in a way that is both efficient and back-propagate-able, leading to a non-autoregressive E2E image-to-speech (ITS) neural network that is efficient and trainable. Experimental results are presented showing that, compared with the non-E2E approach, the proposed E2E system is 29% faster and uses 19% fewer parameters with a 2% reduction in phone accuracy. A future direction to address accuracy is presented. ",
    "url": "https://arxiv.org/abs/2303.06078",
    "authors": [
      "Liu Chen",
      "Michael Deisher",
      "Munir Georges"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:1904.05351",
    "title": "RawNet: Fast End-to-End Neural Vocoder",
    "abstract": " Title: RawNet: Fast End-to-End Neural Vocoder ",
    "url": "https://arxiv.org/abs/1904.05351",
    "authors": [
      "Yunchao He",
      "Yujun Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1905.13543",
    "title": "DDPNAS: Efficient Neural Architecture Search via Dynamic Distribution  Pruning",
    "abstract": " Comments: A update version of this work. 19 pages ",
    "url": "https://arxiv.org/abs/1905.13543",
    "authors": [
      "Xiawu Zheng",
      "Chenyi Yang",
      "Shaokun Zhang",
      "Yan Wang",
      "Baochang Zhang",
      "Yongjian Wu",
      "Yunsheng Wu",
      "Ling Shao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.15465",
    "title": "Accelerating ODE-Based Neural Networks on Low-Cost FPGAs",
    "abstract": " Comments: RAW'21 ",
    "url": "https://arxiv.org/abs/2012.15465",
    "authors": [
      "Hirohisa Watanabe",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.11115",
    "title": "Self-Attention Networks Can Process Bounded Hierarchical Languages",
    "abstract": " Comments: ACL 2021. 19 pages with extended appendix. v2 fixed a small typo in the formula at the end of page 5 (thank to Gabriel Faria). Code: this https URL ",
    "url": "https://arxiv.org/abs/2105.11115",
    "authors": [
      "Shunyu Yao",
      "Binghui Peng",
      "Christos Papadimitriou",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2108.05318",
    "title": "Composing games into complex institutions",
    "abstract": " Comments: ~4000 words, 6 figures ",
    "url": "https://arxiv.org/abs/2108.05318",
    "authors": [
      "Seth Frey",
      "Jules Hedges",
      "Joshua Tan",
      "Philipp Zahn"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2111.12664",
    "title": "MIO : Mutual Information Optimization using Self-Supervised Binary  Contrastive Learning",
    "abstract": " Title: MIO : Mutual Information Optimization using Self-Supervised Binary  Contrastive Learning ",
    "url": "https://arxiv.org/abs/2111.12664",
    "authors": [
      "Siladittya Manna",
      "Umapada Pal",
      "Saumik Bhattacharya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.08954",
    "title": "Advancing Spiking Neural Networks towards Deep Residual Learning",
    "abstract": " Title: Advancing Spiking Neural Networks towards Deep Residual Learning ",
    "url": "https://arxiv.org/abs/2112.08954",
    "authors": [
      "Yifan Hu",
      "Lei Deng",
      "Yujie Wu",
      "Man Yao",
      "Guoqi Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09727",
    "title": "Online Platforms and the Fair Exposure Problem Under Homophily",
    "abstract": " Comments: 37th AAAI Conference on Artificial Intelligence (AAAI-23) ",
    "url": "https://arxiv.org/abs/2202.09727",
    "authors": [
      "Jakob Schoeffer",
      "Alexander Ritchie",
      "Keziah Naggita",
      "Faidra Monachou",
      "Jessie Finocchiaro",
      "Marc Juarez"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.12373",
    "title": "Learning POD of Complex Dynamics Using Heavy-ball Neural ODEs",
    "abstract": " Comments: 31 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2202.12373",
    "authors": [
      "Justin Baker",
      "Elena Cherkaev",
      "Akil Narayan",
      "Bao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.16711",
    "title": "An analytic theory for the dynamics of wide quantum neural networks",
    "abstract": " Comments: 37 pages, many figures. v2: adding learning supervised perspectives and new results, close to published version ",
    "url": "https://arxiv.org/abs/2203.16711",
    "authors": [
      "Junyu Liu",
      "Khadijeh Najafi",
      "Kunal Sharma",
      "Francesco Tacchino",
      "Liang Jiang",
      "Antonio Mezzacapo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.17056",
    "title": "Weakly toll convexity and proper interval graphs",
    "abstract": " Comments: 17 pages ",
    "url": "https://arxiv.org/abs/2203.17056",
    "authors": [
      "Mitre C. Dourado",
      "Marisa Gutierrez",
      "F\u00e1bio Protti",
      "Silvia Tondato"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.10766",
    "title": "From Books to Knowledge Graphs",
    "abstract": " Title: From Books to Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2204.10766",
    "authors": [
      "Natallia Kokash",
      "Matteo Romanello",
      "Ernest Suyver",
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2205.01142",
    "title": "Cost-Aware Evaluation and Model Scaling for LiDAR-Based 3D Object  Detection",
    "abstract": " Comments: ICRA 2023 ",
    "url": "https://arxiv.org/abs/2205.01142",
    "authors": [
      "Xiaofang Wang",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11782",
    "title": "Fine-grained Poisoning Attack to Local Differential Privacy Protocols  for Mean and Variance Estimation",
    "abstract": " Title: Fine-grained Poisoning Attack to Local Differential Privacy Protocols  for Mean and Variance Estimation ",
    "url": "https://arxiv.org/abs/2205.11782",
    "authors": [
      "Xiaoguang Li",
      "Ninghui Li",
      "Wenhai Sun",
      "Neil Zhenqiang Gong",
      "Hui Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.04530",
    "title": "DORA: Exploring outlier representations in Deep Neural Networks",
    "abstract": " Comments: 15 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2206.04530",
    "authors": [
      "Kirill Bykov",
      "Mayukh Deb",
      "Dennis Grinwald",
      "Klaus-Robert M\u00fcller",
      "Marina M.-C. H\u00f6hne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.10143",
    "title": "A Contrastive Approach to Online Change Point Detection",
    "abstract": " Comments: Accepted for presentation at AISTATS 2023; 28 pages ",
    "url": "https://arxiv.org/abs/2206.10143",
    "authors": [
      "Nikita Puchkin",
      "Valeriia Shcherbakova"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.11793",
    "title": "Using a Bayesian approach to reconstruct graph statistics after edge  sampling",
    "abstract": " Comments: Extended version of the paper accepted in Complex Networks 2022 ",
    "url": "https://arxiv.org/abs/2207.11793",
    "authors": [
      "Naomi A. Arnold",
      "Raul J. Mondragon",
      "Richard G. Clegg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.00262",
    "title": "Energy-Aware, Collision-Free Information Gathering for Heterogeneous  Robot Teams",
    "abstract": " Comments: To appear in Transactions on Robotics; 18 pages and 16 figures. arXiv admin note: text overlap with arXiv:2101.11093 ",
    "url": "https://arxiv.org/abs/2208.00262",
    "authors": [
      "Xiaoyi Cai",
      "Brent Schlotfeldt",
      "Kasra Khosoussi",
      "Nikolay Atanasov",
      "George J. Pappas",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.04438",
    "title": "Occlusion-Aware Instance Segmentation via BiLayer Network Architectures",
    "abstract": " Comments: Extended version of \"Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers\", CVPR 2021 (arXiv:2103.12340) ",
    "url": "https://arxiv.org/abs/2208.04438",
    "authors": [
      "Lei Ke",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.09478",
    "title": "Communication Size Reduction of Federated Learning using Neural ODE  Models",
    "abstract": " Title: Communication Size Reduction of Federated Learning using Neural ODE  Models ",
    "url": "https://arxiv.org/abs/2208.09478",
    "authors": [
      "Yuto Hoshino",
      "Hiroki Kawakami",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2208.10588",
    "title": "Widely-Linear MMSE Estimation of Complex-Valued Graph Signals",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2208.10588",
    "authors": [
      "Alon Amar",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.12787",
    "title": "Non-Markovian models of opinion dynamics on temporal networks",
    "abstract": " Comments: 24 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2208.12787",
    "authors": [
      "Weiqi Chu",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Probability (math.PR)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2208.13898",
    "title": "Conjugate Natural Selection: Fisher-Rao Natural Gradient Descent  Optimally Approximates Evolutionary Dynamics and Continuous Bayesian  Inference",
    "abstract": " Comments: 13 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2208.13898",
    "authors": [
      "Reilly Raab",
      "Luca de Alfaro",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.14105",
    "title": "Exploring the Relationship between Architecture and Adversarially Robust  Generalization",
    "abstract": " Title: Exploring the Relationship between Architecture and Adversarially Robust  Generalization ",
    "url": "https://arxiv.org/abs/2209.14105",
    "authors": [
      "Aishan Liu",
      "Shiyu Tang",
      "Siyuan Liang",
      "Ruihao Gong",
      "Boxi Wu",
      "Xianglong Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08057",
    "title": "Pishgu: Universal Path Prediction Network Architecture for Real-time  Cyber-physical Edge Systems",
    "abstract": " Title: Pishgu: Universal Path Prediction Network Architecture for Real-time  Cyber-physical Edge Systems ",
    "url": "https://arxiv.org/abs/2210.08057",
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Vinit Katariya",
      "Armin Danesh Pazho",
      "Christopher Neff",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.08185",
    "title": "GFlowCausal: Generative Flow Networks for Causal Discovery",
    "abstract": " Title: GFlowCausal: Generative Flow Networks for Causal Discovery ",
    "url": "https://arxiv.org/abs/2210.08185",
    "authors": [
      "Wenqian Li",
      "Yinchuan Li",
      "Shengyu Zhu",
      "Yunfeng Shao",
      "Jianye Hao",
      "Yan Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10108",
    "title": "Parallel Inversion of Neural Radiance Fields for Robust Pose Estimation",
    "abstract": " Comments: ICRA 2023. Project page at this https URL ",
    "url": "https://arxiv.org/abs/2210.10108",
    "authors": [
      "Yunzhi Lin",
      "Thomas M\u00fcller",
      "Jonathan Tremblay",
      "Bowen Wen",
      "Stephen Tyree",
      "Alex Evans",
      "Patricio A. Vela",
      "Stan Birchfield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.14457",
    "title": "Implicit Identity Leakage: The Stumbling Block to Improving Deepfake  Detection Generalization",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2210.14457",
    "authors": [
      "Shichao Dong",
      "Jin Wang",
      "Renhe Ji",
      "Jiajun Liang",
      "Haoqiang Fan",
      "Zheng Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14755",
    "title": "Multitask Detection of Speaker Changes, Overlapping Speech and Voice  Activity Using wav2vec 2.0",
    "abstract": " Comments: To appear at ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.14755",
    "authors": [
      "Marie Kune\u0161ov\u00e1",
      "Zbyn\u011bk Zaj\u00edc"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.15305",
    "title": "Deformable Temporal Convolutional Networks for Monaural Noisy  Reverberant Speech Separation",
    "abstract": " Comments: Accepted for ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.15305",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15415",
    "title": "Exact Gradient Computation for Spiking Neural Networks Through Forward  Propagation",
    "abstract": " Title: Exact Gradient Computation for Spiking Neural Networks Through Forward  Propagation ",
    "url": "https://arxiv.org/abs/2210.15415",
    "authors": [
      "Jane H. Lee",
      "Saeid Haghighatshoar",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.01340",
    "title": "POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural  Networks",
    "abstract": " Title: POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural  Networks ",
    "url": "https://arxiv.org/abs/2211.01340",
    "authors": [
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.06368",
    "title": "Phase-Shifting Coder: Predicting Accurate Orientation in Oriented Object  Detection",
    "abstract": " Comments: Accepted to CVPR 2023, 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2211.06368",
    "authors": [
      "Yi Yu",
      "Feipeng Da"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10257",
    "title": "Model-based Causal Bayesian Optimization",
    "abstract": " Comments: 24 pages, 8 figures, accepted at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2211.10257",
    "authors": [
      "Scott Sussex",
      "Anastasiia Makarova",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.16290",
    "title": "LocPoseNet: Robust Location Prior for Unseen Object Pose Estimation",
    "abstract": " Title: LocPoseNet: Robust Location Prior for Unseen Object Pose Estimation ",
    "url": "https://arxiv.org/abs/2211.16290",
    "authors": [
      "Chen Zhao",
      "Yinlin Hu",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.00767",
    "title": "Exploiting Proximity-Aware Tasks for Embodied Social Navigation",
    "abstract": " Title: Exploiting Proximity-Aware Tasks for Embodied Social Navigation ",
    "url": "https://arxiv.org/abs/2212.00767",
    "authors": [
      "Enrico Cancelli",
      "Tommaso Campari",
      "Luciano Serafini",
      "Angel X. Chang",
      "Lamberto Ballan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.00351",
    "title": "Skew Class-balanced Re-weighting for Unbiased Scene Graph Generation",
    "abstract": " Title: Skew Class-balanced Re-weighting for Unbiased Scene Graph Generation ",
    "url": "https://arxiv.org/abs/2301.00351",
    "authors": [
      "Haeyong Kang",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01630",
    "title": "Equalization of a 10 Gbps IMDD signal by a small silicon photonics time  delayed neural network",
    "abstract": " Comments: 14 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2301.01630",
    "authors": [
      "Emiliano Staffoli",
      "Mattia Mancinelli",
      "Paolo Bettotti",
      "Lorenzo Pavesi"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2301.04312",
    "title": "Word-Graph2vec: An efficient word embedding approach on word  co-occurrence graph using random walk sampling",
    "abstract": " Title: Word-Graph2vec: An efficient word embedding approach on word  co-occurrence graph using random walk sampling ",
    "url": "https://arxiv.org/abs/2301.04312",
    "authors": [
      "Wenting Li",
      "Yuanzhe Cai",
      "Jiahong Xue",
      "Xi Zhang",
      "Huacan Chen",
      "Zeyu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11573",
    "title": "On the optimality of Kalman Filter for Fault Detection",
    "abstract": " Title: On the optimality of Kalman Filter for Fault Detection ",
    "url": "https://arxiv.org/abs/2301.11573",
    "authors": [
      "Jinming Zhou",
      "Yucai Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.13060",
    "title": "Zero-One Laws of Graph Neural Networks",
    "abstract": " Comments: 8 pages + references + 9 pages appendices, 2 figures ",
    "url": "https://arxiv.org/abs/2301.13060",
    "authors": [
      "Sam Adam-Day",
      "Theodor Mihai Iliant",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.14402",
    "title": "Neural Video Compression with Diverse Contexts",
    "abstract": " Comments: Accepted by CVPR 2023. Codes are at this https URL ",
    "url": "https://arxiv.org/abs/2302.14402",
    "authors": [
      "Jiahao Li",
      "Bin Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.01498",
    "title": "ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit  Detection & Emotional Reaction Intensity Estimation Challenges",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2202.10659 ",
    "url": "https://arxiv.org/abs/2303.01498",
    "authors": [
      "Dimitrios Kollias",
      "Panagiotis Tzirakis",
      "Alice Baird",
      "Alan Cowen",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02204",
    "title": "Linked Data Science Powered by Knowledge Graphs",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2303.02204",
    "authors": [
      "Mossad Helali",
      "Shubham Vashisth",
      "Philippe Carrier",
      "Katja Hose",
      "Essam Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02262",
    "title": "Locally Regularized Neural Differential Equations: Some Black Boxes Were  Meant to Remain Closed!",
    "abstract": " Title: Locally Regularized Neural Differential Equations: Some Black Boxes Were  Meant to Remain Closed! ",
    "url": "https://arxiv.org/abs/2303.02262",
    "authors": [
      "Avik Pal",
      "Alan Edelman",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.03012",
    "title": "On the Feasibility of Specialized Ability Stealing for Large Language  Code Models",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2303.03012",
    "authors": [
      "Zongjie Li",
      "Chaozheng Wang",
      "Pingchuan Ma",
      "Chaowei Liu",
      "Shuai Wang",
      "Daoyuan Wu",
      "Cuiyun Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.03361",
    "title": "Nerflets: Local Radiance Fields for Efficient Structure-Aware 3D Scene  Representation from 2D Supervision",
    "abstract": " Comments: accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.03361",
    "authors": [
      "Xiaoshuai Zhang",
      "Abhijit Kundu",
      "Thomas Funkhouser",
      "Leonidas Guibas",
      "Hao Su",
      "Kyle Genova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.03387",
    "title": "CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a  Context Synergized Hyperbolic Network",
    "abstract": " Comments: Under review at IJCAI 2023 ",
    "url": "https://arxiv.org/abs/2303.03387",
    "authors": [
      "Sreyan Ghosh",
      "Manan Suri",
      "Purva Chiniya",
      "Utkarsh Tyagi",
      "Sonal Kumar",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.03916",
    "title": "A survey on automated detection and classification of acute leukemia and  WBCs in microscopic blood cells",
    "abstract": " Title: A survey on automated detection and classification of acute leukemia and  WBCs in microscopic blood cells ",
    "url": "https://arxiv.org/abs/2303.03916",
    "authors": [
      "Mohammad Zolfaghari",
      "Hedieh Sajedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04150",
    "title": "Evolutionary Reinforcement Learning: A Survey",
    "abstract": " Title: Evolutionary Reinforcement Learning: A Survey ",
    "url": "https://arxiv.org/abs/2303.04150",
    "authors": [
      "Hui Bai",
      "Ran Cheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04909",
    "title": "Robotic Fabric Flattening with Wrinkle Direction Detection",
    "abstract": " Title: Robotic Fabric Flattening with Wrinkle Direction Detection ",
    "url": "https://arxiv.org/abs/2303.04909",
    "authors": [
      "Yulei Qiu",
      "Jihong Zhu",
      "Cosimo Della Santina",
      "Michael Gienger",
      "Jens Kober"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05079",
    "title": "DDS3D: Dense Pseudo-Labels with Dynamic Threshold for Semi-Supervised 3D  Object Detection",
    "abstract": " Comments: Accepted for publication in 2023 IEEE International Conference on Robotics and Automation (ICRA) ",
    "url": "https://arxiv.org/abs/2303.05079",
    "authors": [
      "Jingyu Li",
      "Zhe Liu",
      "Jinghua Hou",
      "Dingkang Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05203",
    "title": "RMMDet: Road-Side Multitype and Multigroup Sensor Detection System for  Autonomous Driving",
    "abstract": " Comments: The version is wrong, we need to review ",
    "url": "https://arxiv.org/abs/2303.05203",
    "authors": [
      "Xiuyu Yang",
      "Zhuangyan Zhang",
      "Haikuo Du",
      "Sui Yang",
      "Fengping Sun",
      "Yanbo Liu",
      "Ling Pei",
      "Wenchao Xu",
      "Weiqi Sun",
      "Zhengyu Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.05499",
    "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set  Object Detection",
    "abstract": " Comments: Code will be available at this https URL ",
    "url": "https://arxiv.org/abs/2303.05499",
    "authors": [
      "Shilong Liu",
      "Zhaoyang Zeng",
      "Tianhe Ren",
      "Feng Li",
      "Hao Zhang",
      "Jie Yang",
      "Chunyuan Li",
      "Jianwei Yang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]