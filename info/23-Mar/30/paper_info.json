[
  {
    "id": "arXiv:2303.16211",
    "title": "Combinatorial Convolutional Neural Networks for Words",
    "abstract": "The paper discusses the limitations of deep learning models in identifying and utilizing features that remain invariant under a bijective transformation on the data entries, which we refer to as combinatorial patterns. We argue that the identification of such patterns may be important for certain applications and suggest providing neural networks with information that fully describes the combinatorial patterns of input entries and allows the network to determine what is relevant for prediction. To demonstrate the feasibility of this approach, we present a combinatorial convolutional neural network for word classification. ",
    "url": "https://arxiv.org/abs/2303.16211",
    "authors": [
      "Karen Sargsyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16214",
    "title": "Tetra-AML: Automatic Machine Learning via Tensor Networks",
    "abstract": "Neural networks have revolutionized many aspects of society but in the era of huge models with billions of parameters, optimizing and deploying them for commercial applications can require significant computational and financial resources. To address these challenges, we introduce the Tetra-AML toolbox, which automates neural architecture search and hyperparameter optimization via a custom-developed black-box Tensor train Optimization algorithm, TetraOpt. The toolbox also provides model compression through quantization and pruning, augmented by compression using tensor networks. Here, we analyze a unified benchmark for optimizing neural networks in computer vision tasks and show the superior performance of our approach compared to Bayesian optimization on the CIFAR-10 dataset. We also demonstrate the compression of ResNet-18 neural networks, where we use 14.5 times less memory while losing just 3.2% of accuracy. The presented framework is generic, not limited by computer vision problems, supports hardware acceleration (such as with GPUs and TPUs) and can be further extended to quantum hardware and to hybrid quantum machine learning models. ",
    "url": "https://arxiv.org/abs/2303.16214",
    "authors": [
      "A. Naumov",
      "Ar. Melnikov",
      "V. Abronin",
      "F. Oxanichenko",
      "K. Izmailov",
      "M. Pflitsch",
      "A. Melnikov",
      "M. Perelshtein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2303.16235",
    "title": "Spatiotemporal Self-supervised Learning for Point Clouds in the Wild",
    "abstract": "Self-supervised learning (SSL) has the potential to benefit many applications, particularly those where manually annotating data is cumbersome. One such situation is the semantic segmentation of point clouds. In this context, existing methods employ contrastive learning strategies and define positive pairs by performing various augmentation of point clusters in a single frame. As such, these methods do not exploit the temporal nature of LiDAR data. In this paper, we introduce an SSL strategy that leverages positive pairs in both the spatial and temporal domain. To this end, we design (i) a point-to-cluster learning strategy that aggregates spatial information to distinguish objects; and (ii) a cluster-to-cluster learning strategy based on unsupervised object tracking that exploits temporal correspondences. We demonstrate the benefits of our approach via extensive experiments performed by self-supervised training on two large-scale LiDAR datasets and transferring the resulting models to other point cloud segmentation benchmarks. Our results evidence that our method outperforms the state-of-the-art point cloud SSL methods. ",
    "url": "https://arxiv.org/abs/2303.16235",
    "authors": [
      "Yanhao Wu",
      "Tong Zhang",
      "Wei Ke",
      "Sabine S\u00fcsstrunk",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16254",
    "title": "CryoFormer: Continuous Reconstruction of 3D Structures from Cryo-EM Data  using Transformer-based Neural Representations",
    "abstract": "High-resolution heterogeneous reconstruction of 3D structures of proteins and other biomolecules using cryo-electron microscopy (cryo-EM) is essential for understanding fundamental processes of life. However, it is still challenging to reconstruct the continuous motions of 3D structures from hundreds of thousands of noisy and randomly oriented 2D cryo-EM images. Existing methods based on coordinate-based neural networks show compelling results to model continuous conformations of 3D structures in the Fourier domain, but they suffer from a limited ability to model local flexible regions and lack interpretability. We propose a novel approach, cryoFormer, that utilizes a transformer-based network architecture for continuous heterogeneous cryo-EM reconstruction. We for the first time directly reconstruct continuous conformations of 3D structures using an implicit feature volume in the 3D spatial domain. A novel deformation transformer decoder further improves reconstruction quality and, more importantly, locates and robustly tackles flexible 3D regions caused by conformations. In experiments, our method outperforms current approaches on three public datasets (1 synthetic and 2 experimental) and a new synthetic dataset of PEDV spike protein. The code and new synthetic dataset will be released for better reproducibility of our results. Project page: https://cryoformer.github.io. ",
    "url": "https://arxiv.org/abs/2303.16254",
    "authors": [
      "Xinhang Liu",
      "Yan Zeng",
      "Yifan Qin",
      "Hao Li",
      "Jiakai Zhang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16275",
    "title": "Writing Assistants Should Model Social Factors of Language",
    "abstract": "Intelligent writing assistants powered by large language models (LLMs) are more popular today than ever before, but their further widespread adoption is precluded by sub-optimal performance. In this position paper, we argue that a major reason for this sub-optimal performance and adoption is a singular focus on the information content of language while ignoring its social aspects. We analyze the different dimensions of these social factors in the context of writing assistants and propose their incorporation into building smarter, more effective, and truly personalized writing assistants that would enrich the user experience and contribute to increased user adoption. ",
    "url": "https://arxiv.org/abs/2303.16275",
    "authors": [
      "Vivek Kulkarni",
      "Vipul Raheja"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.16308",
    "title": "Provable Robustness for Streaming Models with a Sliding Window",
    "abstract": "The literature on provable robustness in machine learning has primarily focused on static prediction problems, such as image classification, in which input samples are assumed to be independent and model performance is measured as an expectation over the input distribution. Robustness certificates are derived for individual input instances with the assumption that the model is evaluated on each instance separately. However, in many deep learning applications such as online content recommendation and stock market analysis, models use historical data to make predictions. Robustness certificates based on the assumption of independent input samples are not directly applicable in such scenarios. In this work, we focus on the provable robustness of machine learning models in the context of data streams, where inputs are presented as a sequence of potentially correlated items. We derive robustness certificates for models that use a fixed-size sliding window over the input stream. Our guarantees hold for the average model performance across the entire stream and are independent of stream size, making them suitable for large data streams. We perform experiments on speech detection and human activity recognition tasks and show that our certificates can produce meaningful performance guarantees against adversarial perturbations. ",
    "url": "https://arxiv.org/abs/2303.16308",
    "authors": [
      "Aounon Kumar",
      "Vinu Sankar Sadasivan",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.16310",
    "title": "Crime Prediction Using Machine Learning and Deep Learning: A Systematic  Review and Future Directions",
    "abstract": "Predicting crime using machine learning and deep learning techniques has gained considerable attention from researchers in recent years, focusing on identifying patterns and trends in crime occurrences. This review paper examines over 150 articles to explore the various machine learning and deep learning algorithms applied to predict crime. The study provides access to the datasets used for crime prediction by researchers and analyzes prominent approaches applied in machine learning and deep learning algorithms to predict crime, offering insights into different trends and factors related to criminal activities. Additionally, the paper highlights potential gaps and future directions that can enhance the accuracy of crime prediction. Finally, the comprehensive overview of research discussed in this paper on crime prediction using machine learning and deep learning approaches serves as a valuable reference for researchers in this field. By gaining a deeper understanding of crime prediction techniques, law enforcement agencies can develop strategies to prevent and respond to criminal activities more effectively. ",
    "url": "https://arxiv.org/abs/2303.16310",
    "authors": [
      "Varun Mandalapu",
      "Lavanya Elluri",
      "Piyush Vyas",
      "Nirmalya Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2303.16362",
    "title": "Benchmarking Software Vulnerability Detection Techniques: A Survey",
    "abstract": "Software vulnerabilities can have serious consequences, which is why many techniques have been proposed to defend against them. Among these, vulnerability detection techniques are a major area of focus. However, there is a lack of a comprehensive approach for benchmarking these proposed techniques. In this paper, we present the first survey that comprehensively investigates and summarizes the current state of software vulnerability detection benchmarking. We review the current literature on benchmarking vulnerability detection, including benchmarking approaches in technique-proposing papers and empirical studies. We also separately discuss the benchmarking approaches for traditional and deep learning-based vulnerability detection techniques. Our survey analyzes the challenges of benchmarking software vulnerability detection techniques and the difficulties involved. We summarize the challenges of benchmarking software vulnerability detection techniques and describe possible solutions for addressing these challenges. ",
    "url": "https://arxiv.org/abs/2303.16362",
    "authors": [
      "Yingzhou Bi",
      "Jiangtao Huang",
      "Penghui Liu",
      "Lianmei Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.16376",
    "title": "A Unified Single-stage Learning Model for Estimating Fiber Orientation  Distribution Functions on Heterogeneous Multi-shell Diffusion-weighted MRI",
    "abstract": "Diffusion-weighted (DW) MRI measures the direction and scale of the local diffusion process in every voxel through its spectrum in q-space, typically acquired in one or more shells. Recent developments in micro-structure imaging and multi-tissue decomposition have sparked renewed attention to the radial b-value dependence of the signal. Applications in tissue classification and micro-architecture estimation, therefore, require a signal representation that extends over the radial as well as angular domain. Multiple approaches have been proposed that can model the non-linear relationship between the DW-MRI signal and biological microstructure. In the past few years, many deep learning-based methods have been developed towards faster inference speed and higher inter-scan consistency compared with traditional model-based methods (e.g., multi-shell multi-tissue constrained spherical deconvolution). However, a multi-stage learning strategy is typically required since the learning process relied on various middle representations, such as simple harmonic oscillator reconstruction (SHORE) representation. In this work, we present a unified dynamic network with a single-stage spherical convolutional neural network, which allows efficient fiber orientation distribution function (fODF) estimation through heterogeneous multi-shell diffusion MRI sequences. We study the Human Connectome Project (HCP) young adults with test-retest scans. From the experimental results, the proposed single-stage method outperforms prior multi-stage approaches in repeated fODF estimation with shell dropoff and single-shell DW-MRI sequences. ",
    "url": "https://arxiv.org/abs/2303.16376",
    "authors": [
      "Tianyuan Yao",
      "Nancy Newlin",
      "Praitayini Kanakaraj",
      "Vishwesh nath",
      "Leon Y Cai",
      "Karthik Ramadass",
      "Kurt Schilling",
      "Bennett A. Landman",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16378",
    "title": "A Pilot Study of Query-Free Adversarial Attack against Stable Diffusion",
    "abstract": "Despite the record-breaking performance in Text-to-Image (T2I) generation by Stable Diffusion, less research attention is paid to its adversarial robustness. In this work, we study the problem of adversarial attack generation for Stable Diffusion and ask if an adversarial text prompt can be obtained even in the absence of end-to-end model queries. We call the resulting problem 'query-free attack generation'. To resolve this problem, we show that the vulnerability of T2I models is rooted in the lack of robustness of text encoders, e.g., the CLIP text encoder used for attacking Stable Diffusion. Based on such insight, we propose both untargeted and targeted query-free attacks, where the former is built on the most influential dimensions in the text embedding space, which we call steerable key dimensions. By leveraging the proposed attacks, we empirically show that only a five-character perturbation to the text prompt is able to cause the significant content shift of synthesized images using Stable Diffusion. Moreover, we show that the proposed target attack can precisely steer the diffusion model to scrub the targeted image content without causing much change in untargeted image content. ",
    "url": "https://arxiv.org/abs/2303.16378",
    "authors": [
      "Haomin Zhuang",
      "Yihua Zhang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16390",
    "title": "Are Data-driven Explanations Robust against Out-of-distribution Data?",
    "abstract": "As black-box models increasingly power high-stakes applications, a variety of data-driven explanation methods have been introduced. Meanwhile, machine learning models are constantly challenged by distributional shifts. A question naturally arises: Are data-driven explanations robust against out-of-distribution data? Our empirical results show that even though predict correctly, the model might still yield unreliable explanations under distributional shifts. How to develop robust explanations against out-of-distribution data? To address this problem, we propose an end-to-end model-agnostic learning framework Distributionally Robust Explanations (DRE). The key idea is, inspired by self-supervised learning, to fully utilizes the inter-distribution information to provide supervisory signals for the learning of explanations without human annotation. Can robust explanations benefit the model's generalization capability? We conduct extensive experiments on a wide range of tasks and data types, including classification and regression on image and scientific tabular data. Our results demonstrate that the proposed method significantly improves the model's performance in terms of explanation and prediction robustness against distributional shifts. ",
    "url": "https://arxiv.org/abs/2303.16390",
    "authors": [
      "Tang Li",
      "Fengchun Qiao",
      "Mengmeng Ma",
      "Xi Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16404",
    "title": "Robust Andrew's sine estimate adaptive filtering",
    "abstract": "The Andrew's sine function is a robust estimator, which has been used in outlier rejection and robust statistics. However, the performance of such estimator does not receive attention in the field of adaptive filtering techniques. Two Andrew's sine estimator (ASE)-based robust adaptive filtering algorithms are proposed in this brief. Specifically, to achieve improved performance and reduced computational complexity, the iterative Wiener filter (IWF) is an attractive choice. A novel IWF based on ASE (IWF-ASE) is proposed for impulsive noises. To further reduce the computational complexity, the leading dichotomous coordinate descent (DCD) algorithm is combined with the ASE, developing DCD-ASE algorithm. Simulations on system identification demonstrate that the proposed algorithms can achieve smaller misalignment as compared to the conventional IWF, recursive maximum correntropy criterion (RMCC), and DCD-RMCC algorithms in impulsive noise. Furthermore, the proposed algorithms exhibit improved performance in partial discharge (PD) denoising. ",
    "url": "https://arxiv.org/abs/2303.16404",
    "authors": [
      "Lu Lu",
      "Yi Yu",
      "Zongsheng Zheng",
      "Guangya Zhu",
      "Xiaomin Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.16407",
    "title": "LMDA-Net:A lightweight multi-dimensional attention network for general  EEG-based brain-computer interface paradigms and interpretability",
    "abstract": "EEG-based recognition of activities and states involves the use of prior neuroscience knowledge to generate quantitative EEG features, which may limit BCI performance. Although neural network-based methods can effectively extract features, they often encounter issues such as poor generalization across datasets, high predicting volatility, and low model interpretability. Hence, we propose a novel lightweight multi-dimensional attention network, called LMDA-Net. By incorporating two novel attention modules designed specifically for EEG signals, the channel attention module and the depth attention module, LMDA-Net can effectively integrate features from multiple dimensions, resulting in improved classification performance across various BCI tasks. LMDA-Net was evaluated on four high-impact public datasets, including motor imagery (MI) and P300-Speller paradigms, and was compared with other representative models. The experimental results demonstrate that LMDA-Net outperforms other representative methods in terms of classification accuracy and predicting volatility, achieving the highest accuracy in all datasets within 300 training epochs. Ablation experiments further confirm the effectiveness of the channel attention module and the depth attention module. To facilitate an in-depth understanding of the features extracted by LMDA-Net, we propose class-specific neural network feature interpretability algorithms that are suitable for event-related potentials (ERPs) and event-related desynchronization/synchronization (ERD/ERS). By mapping the output of the specific layer of LMDA-Net to the time or spatial domain through class activation maps, the resulting feature visualizations can provide interpretable analysis and establish connections with EEG time-spatial analysis in neuroscience. In summary, LMDA-Net shows great potential as a general online decoding model for various EEG tasks. ",
    "url": "https://arxiv.org/abs/2303.16407",
    "authors": [
      "Zhengqing Miao",
      "Xin Zhang",
      "Meirong Zhao",
      "Dong Ming"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2303.16438",
    "title": "Random Weights Networks Work as Loss Prior Constraint for Image  Restoration",
    "abstract": "In this paper, orthogonal to the existing data and model studies, we instead resort our efforts to investigate the potential of loss function in a new perspective and present our belief ``Random Weights Networks can Be Acted as Loss Prior Constraint for Image Restoration''. Inspired by Functional theory, we provide several alternative solutions to implement our belief in the strict mathematical manifolds including Taylor's Unfolding Network, Invertible Neural Network, Central Difference Convolution and Zero-order Filtering as ``random weights network prototype'' with respect of the following four levels: 1) the different random weights strategies; 2) the different network architectures, \\emph{eg,} pure convolution layer or transformer; 3) the different network architecture depths; 4) the different numbers of random weights network combination. Furthermore, to enlarge the capability of the randomly initialized manifolds, we devise the manner of random weights in the following two variants: 1) the weights are randomly initialized only once during the whole training procedure; 2) the weights are randomly initialized at each training iteration epoch. Our propose belief can be directly inserted into existing networks without any training and testing computational cost. Extensive experiments across multiple image restoration tasks, including image de-noising, low-light image enhancement, guided image super-resolution demonstrate the consistent performance gains obtained by introducing our belief. To emphasize, our main focus is to spark the realms of loss function and save their current neglected status. Code will be publicly available. ",
    "url": "https://arxiv.org/abs/2303.16438",
    "authors": [
      "Man Zhou",
      "Naishan Zheng",
      "Jie Huang",
      "Xiangyu Rui",
      "Chunle Guo",
      "Deyu Meng",
      "Chongyi Li",
      "Jinwei Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16454",
    "title": "Conductivity Imaging from Internal Measurements with Mixed Least-Squares  Deep Neural Networks",
    "abstract": "In this work we develop a novel approach using deep neural networks to reconstruct the conductivity distribution in elliptic problems from one internal measurement. The approach is based on a mixed reformulation of the governing equation and utilizes the standard least-squares objective to approximate the conductivity and flux simultaneously, with deep neural networks as ansatz functions. We provide a thorough analysis of the neural network approximations for both continuous and empirical losses, including rigorous error estimates that are explicit in terms of the noise level, various penalty parameters and neural network architectural parameters (depth, width and parameter bound). We also provide extensive numerical experiments in two- and multi-dimensions to illustrate distinct features of the approach, e.g., excellent stability with respect to data noise and capability of solving high-dimensional problems. ",
    "url": "https://arxiv.org/abs/2303.16454",
    "authors": [
      "Bangti Jin",
      "Xiyao Li",
      "Qimeng Quan",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16458",
    "title": "When to Pre-Train Graph Neural Networks? An Answer from Data Generation  Perspective!",
    "abstract": "Recently, graph pre-training has attracted wide research attention, which aims to learn transferable knowledge from unlabeled graph data so as to improve downstream performance. Despite these recent attempts, the negative transfer is a major issue when applying graph pre-trained models to downstream tasks. Existing works made great efforts on the issue of what to pre-train and how to pre-train by designing a number of graph pre-training and fine-tuning strategies. However, there are indeed cases where no matter how advanced the strategy is, the \"pre-train and fine-tune\" paradigm still cannot achieve clear benefits. This paper introduces a generic framework W2PGNN to answer the crucial question of when to pre-train (i.e., in what situations could we take advantage of graph pre-training) before performing effortful pre-training or fine-tuning. We start from a new perspective to explore the complex generative mechanisms from the pre-training data to downstream data. In particular, W2PGNN first fits the pre-training data into graphon bases, each element of graphon basis (i.e., a graphon) identifies a fundamental transferable pattern shared by a collection of pre-training graphs. All convex combinations of graphon bases give rise to a generator space, from which graphs generated form the solution space for those downstream data that can benefit from pre-training. In this manner, the feasibility of pre-training can be quantified as the generation probability of the downstream data from any generator in the generator space. W2PGNN provides three broad applications, including providing the application scope of graph pre-trained models, quantifying the feasibility of performing pre-training, and helping select pre-training data to enhance downstream performance. We give a theoretically sound solution for the first application and extensive empirical justifications for the latter two applications. ",
    "url": "https://arxiv.org/abs/2303.16458",
    "authors": [
      "Yuxuan Cao",
      "Jiarong Xu",
      "Carl Yang",
      "Jiaan Wang",
      "Yunchao Zhang",
      "Chunping Wang",
      "Lei Chen",
      "Yang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16459",
    "title": "GNNBuilder: An Automated Framework for Generic Graph Neural Network  Accelerator Generation, Simulation, and Optimization",
    "abstract": "There are plenty of graph neural network (GNN) accelerators being proposed. However, they highly rely on users' hardware expertise and are usually optimized for one specific GNN model, making them challenging for practical use . Therefore, in this work, we propose GNNBuilder, the first automated, generic, end-to-end GNN accelerator generation framework. It features four advantages: (1) GNNBuilder can automatically generate GNN accelerators for a wide range of GNN models arbitrarily defined by users; (2) GNNBuilder takes standard PyTorch programming interface, introducing zero overhead for algorithm developers; (3) GNNBuilder supports end-to-end code generation, simulation, accelerator optimization, and hardware deployment, realizing a push-button fashion for GNN accelerator design; (4) GNNBuilder is equipped with accurate performance models of its generated accelerator, enabling fast and flexible design space exploration (DSE). In the experiments, first, we show that our accelerator performance model has errors within $36\\%$ for latency prediction and $18\\%$ for BRAM count prediction. Second, we show that our generated accelerators can outperform CPU by $6.33\\times$ and GPU by $6.87\\times$. This framework is open-source, and the code is available at https://anonymous.4open.science/r/gnn-builder-83B4/. ",
    "url": "https://arxiv.org/abs/2303.16459",
    "authors": [
      "Stefan Abi-Karam",
      "Cong Hao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16464",
    "title": "Lipschitzness Effect of a Loss Function on Generalization Performance of  Deep Neural Networks Trained by Adam and AdamW Optimizers",
    "abstract": "The generalization performance of deep neural networks with regard to the optimization algorithm is one of the major concerns in machine learning. This performance can be affected by various factors. In this paper, we theoretically prove that the Lipschitz constant of a loss function is an important factor to diminish the generalization error of the output model obtained by Adam or AdamW. The results can be used as a guideline for choosing the loss function when the optimization algorithm is Adam or AdamW. In addition, to evaluate the theoretical bound in a practical setting, we choose the human age estimation problem in computer vision. For assessing the generalization better, the training and test datasets are drawn from different distributions. Our experimental evaluation shows that the loss function with lower Lipschitz constant and maximum value improves the generalization of the model trained by Adam or AdamW. ",
    "url": "https://arxiv.org/abs/2303.16464",
    "authors": [
      "Mohammad Lashkari",
      "Amin Gheibi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16465",
    "title": "NerVE: Neural Volumetric Edges for Parametric Curve Extraction from  Point Cloud",
    "abstract": "Extracting parametric edge curves from point clouds is a fundamental problem in 3D vision and geometry processing. Existing approaches mainly rely on keypoint detection, a challenging procedure that tends to generate noisy output, making the subsequent edge extraction error-prone. To address this issue, we propose to directly detect structured edges to circumvent the limitations of the previous point-wise methods. We achieve this goal by presenting NerVE, a novel neural volumetric edge representation that can be easily learned through a volumetric learning framework. NerVE can be seamlessly converted to a versatile piece-wise linear (PWL) curve representation, enabling a unified strategy for learning all types of free-form curves. Furthermore, as NerVE encodes rich structural information, we show that edge extraction based on NerVE can be reduced to a simple graph search problem. After converting NerVE to the PWL representation, parametric curves can be obtained via off-the-shelf spline fitting algorithms. We evaluate our method on the challenging ABC dataset. We show that a simple network based on NerVE can already outperform the previous state-of-the-art methods by a great margin. Project page: https://dongdu3.github.io/projects/2023/NerVE/. ",
    "url": "https://arxiv.org/abs/2303.16465",
    "authors": [
      "Xiangyu Zhu",
      "Dong Du",
      "Weikai Chen",
      "Zhiyou Zhao",
      "Yinyu Nie",
      "Xiaoguang Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16482",
    "title": "Point2Pix: Photo-Realistic Point Cloud Rendering via Neural Radiance  Fields",
    "abstract": "Synthesizing photo-realistic images from a point cloud is challenging because of the sparsity of point cloud representation. Recent Neural Radiance Fields and extensions are proposed to synthesize realistic images from 2D input. In this paper, we present Point2Pix as a novel point renderer to link the 3D sparse point clouds with 2D dense image pixels. Taking advantage of the point cloud 3D prior and NeRF rendering pipeline, our method can synthesize high-quality images from colored point clouds, generally for novel indoor scenes. To improve the efficiency of ray sampling, we propose point-guided sampling, which focuses on valid samples. Also, we present Point Encoding to build Multi-scale Radiance Fields that provide discriminative 3D point features. Finally, we propose Fusion Encoding to efficiently synthesize high-quality images. Extensive experiments on the ScanNet and ArkitScenes datasets demonstrate the effectiveness and generalization. ",
    "url": "https://arxiv.org/abs/2303.16482",
    "authors": [
      "Tao Hu",
      "Xiaogang Xu",
      "Shu Liu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16493",
    "title": "AnyFlow: Arbitrary Scale Optical Flow with Implicit Neural  Representation",
    "abstract": "To apply optical flow in practice, it is often necessary to resize the input to smaller dimensions in order to reduce computational costs. However, downsizing inputs makes the estimation more challenging because objects and motion ranges become smaller. Even though recent approaches have demonstrated high-quality flow estimation, they tend to fail to accurately model small objects and precise boundaries when the input resolution is lowered, restricting their applicability to high-resolution inputs. In this paper, we introduce AnyFlow, a robust network that estimates accurate flow from images of various resolutions. By representing optical flow as a continuous coordinate-based representation, AnyFlow generates outputs at arbitrary scales from low-resolution inputs, demonstrating superior performance over prior works in capturing tiny objects with detail preservation on a wide range of scenes. We establish a new state-of-the-art performance of cross-dataset generalization on the KITTI dataset, while achieving comparable accuracy on the online benchmarks to other SOTA methods. ",
    "url": "https://arxiv.org/abs/2303.16493",
    "authors": [
      "Hyunyoung Jung",
      "Zhuo Hui",
      "Lei Luo",
      "Haitao Yang",
      "Feng Liu",
      "Sungjoo Yoo",
      "Rakesh Ranjan",
      "Denis Demandolx"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16500",
    "title": "AirLine: Efficient Learnable Line Detection with Local Edge Voting",
    "abstract": "Line detection is widely used in many robotic tasks such as scene recognition, 3D reconstruction, and simultaneous localization and mapping (SLAM). Compared to points, lines can provide both low-level and high-level geometrical information for downstream tasks. In this paper, we propose a novel edge-based line detection algorithm, AirLine, which can be applied to various tasks. In contrast to existing learnable endpoint-based methods which are sensitive to the geometrical condition of environments, AirLine can extract line segments directly from edges, resulting in a better generalization ability for unseen environments. Also to balance efficiency and accuracy, we introduce a region-grow algorithm and local edge voting scheme for line parameterization. To the best of our knowledge, AirLine is one of the first learnable edge-based line detection methods. Our extensive experiments show that it retains state-of-the-art-level precision yet with a 3-80 times runtime acceleration compared to other learning-based methods, which is critical for low-power robots. ",
    "url": "https://arxiv.org/abs/2303.16500",
    "authors": [
      "Xiao Lin",
      "Chen Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.16507",
    "title": "Improving Object Detection in Medical Image Analysis through Multiple  Expert Annotators: An Empirical Investigation",
    "abstract": "The work discusses the use of machine learning algorithms for anomaly detection in medical image analysis and how the performance of these algorithms depends on the number of annotators and the quality of labels. To address the issue of subjectivity in labeling with a single annotator, we introduce a simple and effective approach that aggregates annotations from multiple annotators with varying levels of expertise. We then aim to improve the efficiency of predictive models in abnormal detection tasks by estimating hidden labels from multiple annotations and using a re-weighted loss function to improve detection performance. Our method is evaluated on a real-world medical imaging dataset and outperforms relevant baselines that do not consider disagreements among annotators. ",
    "url": "https://arxiv.org/abs/2303.16507",
    "authors": [
      "Hieu H. Pham",
      "Khiem H. Le",
      "Tuan V. Tran",
      "Ha Q. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16519",
    "title": "From axioms over graphs to vectors, and back again: evaluating the  properties of graph-based ontology embeddings",
    "abstract": "Several approaches have been developed that generate embeddings for Description Logic ontologies and use these embeddings in machine learning. One approach of generating ontologies embeddings is by first embedding the ontologies into a graph structure, i.e., introducing a set of nodes and edges for named entities and logical axioms, and then applying a graph embedding to embed the graph in $\\mathbb{R}^n$. Methods that embed ontologies in graphs (graph projections) have different formal properties related to the type of axioms they can utilize, whether the projections are invertible or not, and whether they can be applied to asserted axioms or their deductive closure. We analyze, qualitatively and quantitatively, several graph projection methods that have been used to embed ontologies, and we demonstrate the effect of the properties of graph projections on the performance of predicting axioms from ontology embeddings. We find that there are substantial differences between different projection methods, and both the projection of axioms into nodes and edges as well ontological choices in representing knowledge will impact the success of using ontology embeddings to predict axioms. ",
    "url": "https://arxiv.org/abs/2303.16519",
    "authors": [
      "Fernando Zhapa-Camacho",
      "Robert Hoehndorf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2303.16521",
    "title": "Hard Regularization to Prevent Collapse in Online Deep Clustering  without Data Augmentation",
    "abstract": "Online deep clustering refers to the joint use of a feature extraction network and a clustering model to assign cluster labels to each new data point or batch as it is processed. While faster and more versatile than offline methods, online clustering can easily reach the collapsed solution where the encoder maps all inputs to the same point and all are put into a single cluster. Successful existing models have employed various techniques to avoid this problem, most of which require data augmentation or which aim to make the average soft assignment across the dataset the same for each cluster. We propose a method that does not require data augmentation, and that, differently from existing methods, regularizes the hard assignments. Using a Bayesian framework, we derive an intuitive optimization objective that can be straightforwardly included in the training of the encoder network. Tested on four image datasets, we show that it consistently avoids collapse more robustly than other methods and that it leads to more accurate clustering. We also conduct further experiments and analyses justifying our choice to regularize the hard cluster assignments. ",
    "url": "https://arxiv.org/abs/2303.16521",
    "authors": [
      "Louis Mahon",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16524",
    "title": "Ensemble Learning Model on Artificial Neural Network-Backpropagation  (ANN-BP) Architecture for Coal Pillar Stability Classification",
    "abstract": "Pillars are important structural units used to ensure mining safety in underground hard rock mines. Therefore, precise predictions regarding the stability of underground pillars are required. One common index that is often used to assess pillar stability is the Safety Factor (SF). Unfortunately, such crisp boundaries in pillar stability assessment using SF are unreliable. This paper presents a novel application of Artificial Neural Network-Backpropagation (ANN-BP) and Deep Ensemble Learning for pillar stability classification. There are three types of ANN-BP used for the classification of pillar stability distinguished by their activation functions: ANN-BP ReLU, ANN-BP ELU, and ANN-BP GELU. This research also presents a new labeling alternative for pillar stability by considering its suitability with the SF. Thus, pillar stability is expanded into four categories: failed with a suitable safety factor, intact with a suitable safety factor, failed without a suitable safety factor, and intact without a suitable safety factor. There are five inputs used for each model: pillar width, mining height, bord width, depth to floor, and ratio. The results showed that the ANN-BP model with Ensemble Learning could improve ANN-BP performance with an average accuracy of 86.48% and an F_2-score of 96.35% for the category of failed with a suitable safety factor. ",
    "url": "https://arxiv.org/abs/2303.16524",
    "authors": [
      "G. Aileen Mendrofa",
      "Gatot Fatwanto Hertono",
      "Bevina Desjwiandara Handari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16528",
    "title": "Building a Knowledge Graph of Distributed Ledger Technologies",
    "abstract": "Distributed ledger systems have become more prominent and successful in recent years, with a focus on blockchains and cryptocurrency. This has led to various misunderstandings about both the technology itself and its capabilities, as in many cases blockchain and cryptocurrency is used synonymously and other applications are often overlooked. Therefore, as a whole, the view of distributed ledger technology beyond blockchains and cryptocurrencies is very limited. Existing vocabularies and ontologies often focus on single aspects of the technology, or in some cases even just on one product. This potentially leads to other types of distributed ledgers and their possible use cases being neglected. In this paper, we present a knowledge graph and an ontology for distributed ledger technologies, which includes security considerations to model aspects such as threats and vulnerabilities, application domains, as well as relevant standards and regulations. Such a knowledge graph improves the overall understanding of distributed ledgers, reveals their strengths, and supports the work of security personnel, i.e. analysts and system architects. We discuss potential uses and follow semantic web best practices to evaluate and publish the ontology and knowledge graph. ",
    "url": "https://arxiv.org/abs/2303.16528",
    "authors": [
      "Lukas K\u00f6nig",
      "Sebastian Neumaier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.16529",
    "title": "Importance Sampling for Stochastic Gradient Descent in Deep Neural  Networks",
    "abstract": "Stochastic gradient descent samples uniformly the training set to build an unbiased gradient estimate with a limited number of samples. However, at a given step of the training process, some data are more helpful than others to continue learning. Importance sampling for training deep neural networks has been widely studied to propose sampling schemes yielding better performance than the uniform sampling scheme. After recalling the theory of importance sampling for deep learning, this paper reviews the challenges inherent to this research area. In particular, we propose a metric allowing the assessment of the quality of a given sampling scheme; and we study the interplay between the sampling scheme and the optimizer used. ",
    "url": "https://arxiv.org/abs/2303.16529",
    "authors": [
      "Thibault Lahire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16532",
    "title": "Futures Quantitative Investment with Heterogeneous Continual Graph  Neural Network",
    "abstract": "It is a challenging problem to predict trends of futures prices with traditional econometric models as one needs to consider not only futures' historical data but also correlations among different futures. Spatial-temporal graph neural networks (STGNNs) have great advantages in dealing with such kind of spatial-temporal data. However, we cannot directly apply STGNNs to high-frequency future data because future investors have to consider both the long-term and short-term characteristics when doing decision-making. To capture both the long-term and short-term features, we exploit more label information by designing four heterogeneous tasks: price regression, price moving average regression, price gap regression (within a short interval), and change-point detection, which involve both long-term and short-term scenes. To make full use of these labels, we train our model in a continual manner. Traditional continual GNNs define the gradient of prices as the parameter important to overcome catastrophic forgetting (CF). Unfortunately, the losses of the four heterogeneous tasks lie in different spaces. Hence it is improper to calculate the parameter importance with their losses. We propose to calculate parameter importance with mutual information between original observations and the extracted features. The empirical results based on 49 commodity futures demonstrate that our model has higher prediction performance on capturing long-term or short-term dynamic change. ",
    "url": "https://arxiv.org/abs/2303.16532",
    "authors": [
      "Zhizhong Tan",
      "Min Hu",
      "Yixuan Wang",
      "Lu Wei",
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2303.16533",
    "title": "Robust Tumor Detection from Coarse Annotations via Multi-Magnification  Ensembles",
    "abstract": "Cancer detection and classification from gigapixel whole slide images of stained tissue specimens has recently experienced enormous progress in computational histopathology. The limitation of available pixel-wise annotated scans shifted the focus from tumor localization to global slide-level classification on the basis of (weakly-supervised) multiple-instance learning despite the clinical importance of local cancer detection. However, the worse performance of these techniques in comparison to fully supervised methods has limited their usage until now for diagnostic interventions in domains of life-threatening diseases such as cancer. In this work, we put the focus back on tumor localization in form of a patch-level classification task and take up the setting of so-called coarse annotations, which provide greater training supervision while remaining feasible from a clinical standpoint. To this end, we present a novel ensemble method that not only significantly improves the detection accuracy of metastasis on the open CAMELYON16 data set of sentinel lymph nodes of breast cancer patients, but also considerably increases its robustness against noise while training on coarse annotations. Our experiments show that better results can be achieved with our technique making it clinically feasible to use for cancer diagnosis and opening a new avenue for translational and clinical research. ",
    "url": "https://arxiv.org/abs/2303.16533",
    "authors": [
      "Mehdi Naouar",
      "Gabriel Kalweit",
      "Ignacio Mastroleo",
      "Philipp Poxleitner",
      "Marc Metzger",
      "Joschka Boedecker",
      "Maria Kalweit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16552",
    "title": "Visual Content Privacy Protection: A Survey",
    "abstract": "Vision is the most important sense for people, and it is also one of the main ways of cognition. As a result, people tend to utilize visual content to capture and share their life experiences, which greatly facilitates the transfer of information. Meanwhile, it also increases the risk of privacy violations, e.g., an image or video can reveal different kinds of privacy-sensitive information. Researchers have been working continuously to develop targeted privacy protection solutions, and there are several surveys to summarize them from certain perspectives. However, these surveys are either problem-driven, scenario-specific, or technology-specific, making it difficult for them to summarize the existing solutions in a macroscopic way. In this survey, a framework that encompasses various concerns and solutions for visual privacy is proposed, which allows for a macro understanding of privacy concerns from a comprehensive level. It is based on the fact that privacy concerns have corresponding adversaries, and divides privacy protection into three categories, based on computer vision (CV) adversary, based on human vision (HV) adversary, and based on CV \\& HV adversary. For each category, we analyze the characteristics of the main approaches to privacy protection, and then systematically review representative solutions. Open challenges and future directions for visual privacy protection are also discussed. ",
    "url": "https://arxiv.org/abs/2303.16552",
    "authors": [
      "Ruoyu Zhao",
      "Yushu Zhang",
      "Tao Wang",
      "Wenying Wen",
      "Yong Xiang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.16561",
    "title": "Exploring placement of intrusion detection systems in rpl-based internet  of things",
    "abstract": "Intrusion detection is an indispensable part of RPL security due to its nature opening to attacks from insider attackers. While there are a good deal of studies that analyze different types of attack and propose intrusion detection systems based on various techniques that are proposed in the literature, how to place such intrusion detection systems on RPL topology is not investigated. This is the main contribution of this study, and three intrusion detection architectures based on central and distributed placement of intrusion detection nodes are analyzed rigorously against different types of attacks and attackers at various locations in the RPL topology and evaluated from different aspects including their effectiveness, cost, and security. ",
    "url": "https://arxiv.org/abs/2303.16561",
    "authors": [
      "Selim Yilmaz",
      "Emre Aydogan",
      "Sevil Sen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.16564",
    "title": "Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a  Bayesian Neural Network",
    "abstract": "The fairness of a deep neural network is strongly affected by dataset bias and spurious correlations, both of which are usually present in modern feature-rich and complex visual datasets. Due to the difficulty and variability of the task, no single de-biasing method has been universally successful. In particular, implicit methods not requiring explicit knowledge of bias variables are especially relevant for real-world applications. We propose a novel implicit mitigation method using a Bayesian neural network, allowing us to leverage the relationship between epistemic uncertainties and the presence of bias or spurious correlations in a sample. Our proposed posterior estimate sharpening procedure encourages the network to focus on core features that do not contribute to high uncertainties. Experimental results on three benchmark datasets demonstrate that Bayesian networks with sharpened posterior estimates perform comparably to prior existing methods and show potential worthy of further exploration. ",
    "url": "https://arxiv.org/abs/2303.16564",
    "authors": [
      "Rebecca S Stone",
      "Nishant Ravikumar",
      "Andrew J Bulpitt",
      "David C Hogg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.16570",
    "title": "Point2Vec for Self-Supervised Representation Learning on Point Clouds",
    "abstract": "Recently, the self-supervised learning framework data2vec has shown inspiring performance for various modalities using a masked student-teacher approach. However, it remains open whether such a framework generalizes to the unique challenges of 3D point clouds. To answer this question, we extend data2vec to the point cloud domain and report encouraging results on several downstream tasks. In an in-depth analysis, we discover that the leakage of positional information reveals the overall object shape to the student even under heavy masking and thus hampers data2vec to learn strong representations for point clouds. We address this 3D-specific shortcoming by proposing point2vec, which unleashes the full potential of data2vec-like pre-training on point clouds. Our experiments show that point2vec outperforms other self-supervised methods on shape classification and few-shot learning on ModelNet40 and ScanObjectNN, while achieving competitive results on part segmentation on ShapeNetParts. These results suggest that the learned representations are strong and transferable, highlighting point2vec as a promising direction for self-supervised learning of point cloud representations. ",
    "url": "https://arxiv.org/abs/2303.16570",
    "authors": [
      "Karim Abou Zeid",
      "Jonas Schult",
      "Alexander Hermans",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16574",
    "title": "FEND: A Future Enhanced Distribution-Aware Contrastive Learning  Framework for Long-tail Trajectory Prediction",
    "abstract": "Predicting the future trajectories of the traffic agents is a gordian technique in autonomous driving. However, trajectory prediction suffers from data imbalance in the prevalent datasets, and the tailed data is often more complicated and safety-critical. In this paper, we focus on dealing with the long-tail phenomenon in trajectory prediction. Previous methods dealing with long-tail data did not take into account the variety of motion patterns in the tailed data. In this paper, we put forward a future enhanced contrastive learning framework to recognize tail trajectory patterns and form a feature space with separate pattern clusters. Furthermore, a distribution aware hyper predictor is brought up to better utilize the shaped feature space. Our method is a model-agnostic framework and can be plugged into many well-known baselines. Experimental results show that our framework outperforms the state-of-the-art long-tail prediction method on tailed samples by 9.5% on ADE and 8.5% on FDE, while maintaining or slightly improving the averaged performance. Our method also surpasses many long-tail techniques on trajectory prediction task. ",
    "url": "https://arxiv.org/abs/2303.16574",
    "authors": [
      "Yuning Wang",
      "Pu Zhang",
      "Lei Bai",
      "Jianru Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16583",
    "title": "On the use of chaotic dynamics for mobile network design and analysis:  towards a trace data generator",
    "abstract": "With the constant increase of the number of autonomous vehicles and connected objects, tools to understand and reproduce their mobility models are required. We focus on chaotic dynamics and review their applications in the design of mobility models. We also provide a review of the nonlinear tools used to characterize mobility models, as it can be found in the literature. Finally, we propose a method to generate traces for a given scenario involving moving people, using tools from the nonlinear analysis domain usually dedicated to topological analysis of chaotic attractors. ",
    "url": "https://arxiv.org/abs/2303.16583",
    "authors": [
      "Martin Rosalie",
      "Serge Chaumette"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2303.16589",
    "title": "Poster: Link between Bias, Node Sensitivity and Long-Tail Distribution  in trained DNNs",
    "abstract": "Owing to their remarkable learning (and relearning) capabilities, deep neural networks (DNNs) find use in numerous real-world applications. However, the learning of these data-driven machine learning models is generally as good as the data available to them for training. Hence, training datasets with long-tail distribution pose a challenge for DNNs, since the DNNs trained on them may provide a varying degree of classification performance across different output classes. While the overall bias of such networks is already highlighted in existing works, this work identifies the node bias that leads to a varying sensitivity of the nodes for different output classes. To the best of our knowledge, this is the first work highlighting this unique challenge in DNNs, discussing its probable causes, and providing open challenges for this new research direction. We support our reasoning using an empirical case study of the networks trained on a real-world dataset. ",
    "url": "https://arxiv.org/abs/2303.16589",
    "authors": [
      "Mahum Naseer",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16591",
    "title": "An AST-based Code Change Representation and its Performance in  Just-in-time Vulnerability Prediction",
    "abstract": "The presence of software vulnerabilities is an ever-growing issue in software development. In most cases, it is desirable to detect vulnerabilities as early as possible, preferably in a just-in-time manner, when the vulnerable piece is added to the code base. The industry has a hard time combating this problem as manual inspection is costly and traditional means, such as rule-based bug detection, are not robust enough to follow the pace of the emergence of new vulnerabilities. The actively researched field of machine learning could help in such situations as models can be trained to detect vulnerable patterns. However, machine learning models work well only if the data is appropriately represented. In our work, we propose a novel way of representing changes in source code (i.e. code commits), the Code Change Tree, a form that is designed to keep only the differences between two abstract syntax trees of Java source code. We compared its effectiveness in predicting if a code change introduces a vulnerability against multiple representation types and evaluated them by a number of machine learning models as a baseline. The evaluation is done on a novel dataset that we published as part of our contributions using a 2-phase dataset generator method. Based on our evaluation we concluded that using Code Change Tree is a valid and effective choice to represent source code changes as it improves performance. ",
    "url": "https://arxiv.org/abs/2303.16591",
    "authors": [
      "Tam\u00e1s Aladics",
      "P\u00e9ter Heged\u0171s",
      "Rudolf Ferenc"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.16601",
    "title": "An Efficient Online Prediction of Host Workloads Using Pruned GRU Neural  Nets",
    "abstract": "Host load prediction is essential for dynamic resource scaling and job scheduling in a cloud computing environment. In this context, workload prediction is challenging because of several issues. First, it must be accurate to enable precise scheduling decisions. Second, it must be fast to schedule at the right time. Third, a model must be able to account for new patterns of workloads so it can perform well on the latest and old patterns. Not being able to make an accurate and fast prediction or the inability to predict new usage patterns can result in severe outcomes such as service level agreement (SLA) misses. Our research trains a fast model with the ability of online adaptation based on the gated recurrent unit (GRU) to mitigate the mentioned issues. We use a multivariate approach using several features, such as memory usage, CPU usage, disk I/O usage, and disk space, to perform the predictions accurately. Moreover, we predict multiple steps ahead, which is essential for making scheduling decisions in advance. Furthermore, we use two pruning methods: L1 norm and random, to produce a sparse model for faster forecasts. Finally, online learning is used to create a model that can adapt over time to new workload patterns. ",
    "url": "https://arxiv.org/abs/2303.16601",
    "authors": [
      "Amin Setayesh",
      "Hamid Hadian",
      "Radu Prodan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.16616",
    "title": "Nearest Neighbor Based Out-of-Distribution Detection in Remote Sensing  Scene Classification",
    "abstract": "Deep learning models for image classification are typically trained under the \"closed-world\" assumption with a predefined set of image classes. However, when the models are deployed they may be faced with input images not belonging to the classes encountered during training. This type of scenario is common in remote sensing image classification where images come from different geographic areas, sensors, and imaging conditions. In this paper we deal with the problem of detecting remote sensing images coming from a different distribution compared to the training data - out of distribution images. We propose a benchmark for out of distribution detection in remote sensing scene classification and evaluate detectors based on maximum softmax probability and nearest neighbors. The experimental results show convincing advantages of the method based on nearest neighbors. ",
    "url": "https://arxiv.org/abs/2303.16616",
    "authors": [
      "Dajana Dimitri\u0107",
      "Mitar Simi\u0107",
      "Vladimir Risojevi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16628",
    "title": "DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object  Detection and Tracking",
    "abstract": "Recent multi-camera 3D object detectors usually leverage temporal information to construct multi-view stereo that alleviates the ill-posed depth estimation. However, they typically assume all the objects are static and directly aggregate features across frames. This work begins with a theoretical and empirical analysis to reveal that ignoring the motion of moving objects can result in serious localization bias. Therefore, we propose to model Dynamic Objects in RecurrenT (DORT) to tackle this problem. In contrast to previous global Bird-Eye-View (BEV) methods, DORT extracts object-wise local volumes for motion estimation that also alleviates the heavy computational burden. By iteratively refining the estimated object motion and location, the preceding features can be precisely aggregated to the current frame to mitigate the aforementioned adverse effects. The simple framework has two significant appealing properties. It is flexible and practical that can be plugged into most camera-based 3D object detectors. As there are predictions of object motion in the loop, it can easily track objects across frames according to their nearest center distances. Without bells and whistles, DORT outperforms all the previous methods on the nuScenes detection and tracking benchmarks with 62.5\\% NDS and 57.6\\% AMOTA, respectively. The source code will be released. ",
    "url": "https://arxiv.org/abs/2303.16628",
    "authors": [
      "Qing Lian",
      "Tai Wang",
      "Dahua Lin",
      "Jiangmiao Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16633",
    "title": "Targeted Adversarial Attacks on Wind Power Forecasts",
    "abstract": "In recent years, researchers proposed a variety of deep learning models for wind power forecasting. These models predict the wind power generation of wind farms or entire regions more accurately than traditional machine learning algorithms or physical models. However, latest research has shown that deep learning models can often be manipulated by adversarial attacks. Since wind power forecasts are essential for the stability of modern power systems, it is important to protect them from this threat. In this work, we investigate the vulnerability of two different forecasting models to targeted, semitargeted, and untargeted adversarial attacks. We consider a Long Short-Term Memory (LSTM) network for predicting the power generation of a wind farm and a Convolutional Neural Network (CNN) for forecasting the wind power generation throughout Germany. Moreover, we propose the Total Adversarial Robustness Score (TARS), an evaluation metric for quantifying the robustness of regression models to targeted and semi-targeted adversarial attacks. It assesses the impact of attacks on the model's performance, as well as the extent to which the attacker's goal was achieved, by assigning a score between 0 (very vulnerable) and 1 (very robust). In our experiments, the LSTM forecasting model was fairly robust and achieved a TARS value of over 0.81 for all adversarial attacks investigated. The CNN forecasting model only achieved TARS values below 0.06 when trained ordinarily, and was thus very vulnerable. Yet, its robustness could be significantly improved by adversarial training, which always resulted in a TARS above 0.46. ",
    "url": "https://arxiv.org/abs/2303.16633",
    "authors": [
      "Ren\u00e9 Heinrich",
      "Christoph Scholz",
      "Stephan Vogt",
      "Malte Lehna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.16637",
    "title": "MuRAL: Multi-Scale Region-based Active Learning for Object Detection",
    "abstract": "Obtaining large-scale labeled object detection dataset can be costly and time-consuming, as it involves annotating images with bounding boxes and class labels. Thus, some specialized active learning methods have been proposed to reduce the cost by selecting either coarse-grained samples or fine-grained instances from unlabeled data for labeling. However, the former approaches suffer from redundant labeling, while the latter methods generally lead to training instability and sampling bias. To address these challenges, we propose a novel approach called Multi-scale Region-based Active Learning (MuRAL) for object detection. MuRAL identifies informative regions of various scales to reduce annotation costs for well-learned objects and improve training performance. The informative region score is designed to consider both the predicted confidence of instances and the distribution of each object category, enabling our method to focus more on difficult-to-detect classes. Moreover, MuRAL employs a scale-aware selection strategy that ensures diverse regions are selected from different scales for labeling and downstream finetuning, which enhances training stability. Our proposed method surpasses all existing coarse-grained and fine-grained baselines on Cityscapes and MS COCO datasets, and demonstrates significant improvement in difficult category performance. ",
    "url": "https://arxiv.org/abs/2303.16637",
    "authors": [
      "Yi-Syuan Liou",
      "Tsung-Han Wu",
      "Jia-Fong Yeh",
      "Wen-Chin Chen",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16641",
    "title": "A Hierarchical Game-Theoretic Decision-Making for Cooperative  Multi-Agent Systems Under the Presence of Adversarial Agents",
    "abstract": "Underlying relationships among Multi-Agent Systems (MAS) in hazardous scenarios can be represented as Game-theoretic models. This paper proposes a new hierarchical network-based model called Game-theoretic Utility Tree (GUT), which decomposes high-level strategies into executable low-level actions for cooperative MAS decisions. It combines with a new payoff measure based on agent needs for real-time strategy games. We present an Explore game domain, where we measure the performance of MAS achieving tasks from the perspective of balancing the success probability and system costs. We evaluate the GUT approach against state-of-the-art methods that greedily rely on rewards of the composite actions. Conclusive results on extensive numerical simulations indicate that GUT can organize more complex relationships among MAS cooperation, helping the group achieve challenging tasks with lower costs and higher winning rates. Furthermore, we demonstrated the applicability of the GUT using the simulator-hardware testbed - Robotarium. The performances verified the effectiveness of the GUT in the real robot application and validated that the GUT could effectively organize MAS cooperation strategies, helping the group with fewer advantages achieve higher performance. ",
    "url": "https://arxiv.org/abs/2303.16641",
    "authors": [
      "Qin Yang",
      "Ramviyas Parasuraman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.16675",
    "title": "A Subset of the CERN Virtual Machine File System: Fast Delivering of  Complex Software Stacks for Supercomputing Resources",
    "abstract": "Delivering a reproducible environment along with complex and up-to-date software stacks on thousands of distributed and heterogeneous worker nodes is a critical task. The CernVM-File System (CVMFS) has been designed to help various communities to deploy software on worldwide distributed computing infrastructures by decoupling the software from the Operating System. However, the installation of this file system depends on a collaboration with system administrators of the remote resources and an HTTP connectivity to fetch dependencies from external sources. Supercomputers, which offer tremendous computing power, generally have more restrictive policies than grid sites and do not easily provide the mandatory conditions to exploit CVMFS. Different solutions have been developed to tackle the issue, but they are often specific to a scientific community and do not deal with the problem in its globality. In this paper, we provide a generic utility to assist any community in the installation of complex software dependencies on supercomputers with no external connectivity. The approach consists in capturing dependencies of applications of interests, building a subset of dependencies, testing it in a given environment, and deploying it to a remote computing resource. We experiment this proposal with a real use case by exporting Gauss-a Monte-Carlo simulation program from the LHCb experiment-on Mare Nostrum, one of the top supercomputers of the world. We provide steps to encapsulate the minimum required files and deliver a light and easy-to-update subset of CVMFS: 12.4 Gigabytes instead of 5.2 Terabytes for the whole LHCb repository. ",
    "url": "https://arxiv.org/abs/2303.16675",
    "authors": [
      "Alexandre F Boyer",
      "Christophe Haen",
      "Federico Stagni",
      "David R C Hill"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2303.16690",
    "title": "Graph Neural Networks for Hardware Vulnerability Analysis -- Can you  Trust your GNN?",
    "abstract": "The participation of third-party entities in the globalized semiconductor supply chain introduces potential security vulnerabilities, such as intellectual property piracy and hardware Trojan (HT) insertion. Graph neural networks (GNNs) have been employed to address various hardware security threats, owing to their superior performance on graph-structured data, such as circuits. However, GNNs are also susceptible to attacks. This work examines the use of GNNs for detecting hardware threats like HTs and their vulnerability to attacks. We present BadGNN, a backdoor attack on GNNs that can hide HTs and evade detection with a 100% success rate through minor circuit perturbations. Our findings highlight the need for further investigation into the security and robustness of GNNs before they can be safely used in security-critical applications. ",
    "url": "https://arxiv.org/abs/2303.16690",
    "authors": [
      "Lilas Alrahis",
      "Ozgur Sinanoglu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.16694",
    "title": "Using Semantic Similarity and Text Embedding to Measure the Social Media  Echo of Strategic Communications",
    "abstract": "Online discourse covers a wide range of topics and many actors tailor their content to impact online discussions through carefully crafted messages and targeted campaigns. Yet the scale and diversity of online media content make it difficult to evaluate the impact of a particular message. In this paper, we present a new technique that leverages semantic similarity to quantify the change in the discussion after a particular message has been published. We use a set of press releases from environmental organisations and tweets from the climate change debate to show that our novel approach reveals a heavy-tailed distribution of response in online discourse to strategic communications. ",
    "url": "https://arxiv.org/abs/2303.16694",
    "authors": [
      "Tristan J.B. Cann",
      "Ben Dennes",
      "Travis Coan",
      "Saffron O'Neill",
      "Hywel T.P. Williams"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.16697",
    "title": "Latent Feature Relation Consistency for Adversarial Robustness",
    "abstract": "Deep neural networks have been applied in many computer vision tasks and achieved state-of-the-art performance. However, misclassification will occur when DNN predicts adversarial examples which add human-imperceptible adversarial noise to natural examples. This limits the application of DNN in security-critical fields. To alleviate this problem, we first conducted an empirical analysis of the latent features of both adversarial and natural examples and found the similarity matrix of natural examples is more compact than those of adversarial examples. Motivated by this observation, we propose \\textbf{L}atent \\textbf{F}eature \\textbf{R}elation \\textbf{C}onsistency (\\textbf{LFRC}), which constrains the relation of adversarial examples in latent space to be consistent with the natural examples. Importantly, our LFRC is orthogonal to the previous method and can be easily combined with them to achieve further improvement. To demonstrate the effectiveness of LFRC, we conduct extensive experiments using different neural networks on benchmark datasets. For instance, LFRC can bring 0.78\\% further improvement compared to AT, and 1.09\\% improvement compared to TRADES, against AutoAttack on CIFAR10. Code is available at https://github.com/liuxingbin/LFRC. ",
    "url": "https://arxiv.org/abs/2303.16697",
    "authors": [
      "Xingbin Liu",
      "Huafeng Kuang",
      "Hong Liu",
      "Xianming Lin",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16734",
    "title": "Predictive Resource Allocation in mmWave Systems with Rotation Detection",
    "abstract": "Millimeter wave (MmWave) has been regarded as a promising technology to support high-capacity communications in 5G era. However, its high-layer performance such as latency and packet drop rate in the long term highly depends on resource allocation because mmWave channel suffers significant fluctuation with rotating users due to mmWave sparse channel property and limited field-of-view (FoV) of antenna arrays. In this paper, downlink transmission scheduling considering rotation of user equipments (UE) and limited antenna FoV in an mmWave system is optimized via a novel approximate Markov decision process (MDP) method. Specifically, we consider the joint downlink UE selection and power allocation in a number of frames where future orientations of rotating UEs can be predicted via embedded motion sensors. The problem is formulated as a finite-horizon MDP with non-stationary state transition probabilities. A novel low-complexity solution framework is proposed via one iteration step over a base policy whose average future cost can be predicted with analytical expressions. It is demonstrated by simulations that compared with existing benchmarks, the proposed scheme can schedule the downlink transmission and suppress the packet drop rate efficiently in non-stationary mmWave links. ",
    "url": "https://arxiv.org/abs/2303.16734",
    "authors": [
      "Yifei Sun",
      "Bojie Lv",
      "Rui Wang",
      "Haisheng Tan",
      "Francis C. M. Lau"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.16741",
    "title": "Who You Play Affects How You Play: Predicting Sports Performance Using  Graph Attention Networks With Temporal Convolution",
    "abstract": "This study presents a novel deep learning method, called GATv2-GCN, for predicting player performance in sports. To construct a dynamic player interaction graph, we leverage player statistics and their interactions during gameplay. We use a graph attention network to capture the attention that each player pays to each other, allowing for more accurate modeling of the dynamic player interactions. To handle the multivariate player statistics time series, we incorporate a temporal convolution layer, which provides the model with temporal predictive power. We evaluate the performance of our model using real-world sports data, demonstrating its effectiveness in predicting player performance. Furthermore, we explore the potential use of our model in a sports betting context, providing insights into profitable strategies that leverage our predictive power. The proposed method has the potential to advance the state-of-the-art in player performance prediction and to provide valuable insights for sports analytics and betting industries. ",
    "url": "https://arxiv.org/abs/2303.16741",
    "authors": [
      "Rui Luo",
      "Vikram Krishnamurthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.16749",
    "title": "Improving Code Generation by Training with Natural Language Feedback",
    "abstract": "The potential for pre-trained large language models (LLMs) to use natural language feedback at inference time has been an exciting recent development. We build upon this observation by formalizing an algorithm for learning from natural language feedback at training time instead, which we call Imitation learning from Language Feedback (ILF). ILF requires only a small amount of human-written feedback during training and does not require the same feedback at test time, making it both user-friendly and sample-efficient. We further show that ILF can be seen as a form of minimizing the KL divergence to the ground truth distribution and demonstrate a proof-of-concept on a neural program synthesis task. We use ILF to improve a Codegen-Mono 6.1B model's pass@1 rate by 38% relative (and 10% absolute) on the Mostly Basic Python Problems (MBPP) benchmark, outperforming both fine-tuning on MBPP and fine-tuning on repaired programs written by humans. Overall, our results suggest that learning from human-written natural language feedback is both more effective and sample-efficient than training exclusively on demonstrations for improving an LLM's performance on code generation tasks. ",
    "url": "https://arxiv.org/abs/2303.16749",
    "authors": [
      "Angelica Chen",
      "J\u00e9r\u00e9my Scheurer",
      "Tomasz Korbak",
      "Jon Ander Campos",
      "Jun Shern Chan",
      "Samuel R. Bowman",
      "Kyunghyun Cho",
      "Ethan Perez"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16756",
    "title": "LLM for Patient-Trial Matching: Privacy-Aware Data Augmentation Towards  Better Performance and Generalizability",
    "abstract": "The process of matching patients with suitable clinical trials is essential for advancing medical research and providing optimal care. However, current approaches face challenges such as data standardization, ethical considerations, and a lack of interoperability between Electronic Health Records (EHRs) and clinical trial criteria. In this paper, we explore the potential of large language models (LLMs) to address these challenges by leveraging their advanced natural language generation capabilities to improve compatibility between EHRs and clinical trial descriptions. We propose an innovative privacy-aware data augmentation approach for LLM-based patient-trial matching (LLM-PTM), which balances the benefits of LLMs while ensuring the security and confidentiality of sensitive patient data. Our experiments demonstrate a 7.32% average improvement in performance using the proposed LLM-PTM method, and the generalizability to new data is improved by 12.12%. Additionally, we present case studies to further illustrate the effectiveness of our approach and provide a deeper understanding of its underlying principles. ",
    "url": "https://arxiv.org/abs/2303.16756",
    "authors": [
      "Jiayi Yuan",
      "Ruixiang Tang",
      "Xiaoqian Jiang",
      "Xia Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.16759",
    "title": "Exploring celebrity influence on public attitude towards the COVID-19  pandemic: social media shared sentiment analysis",
    "abstract": "The COVID-19 pandemic has introduced new opportunities for health communication, including an increase in the public use of online outlets for health-related emotions. People have turned to social media networks to share sentiments related to the impacts of the COVID-19 pandemic. In this paper we examine the role of social messaging shared by Persons in the Public Eye (i.e. athletes, politicians, news personnel) in determining overall public discourse direction. We harvested approximately 13 million tweets ranging from 1 January 2020 to 1 March 2022. The sentiment was calculated for each tweet using a fine-tuned DistilRoBERTa model, which was used to compare COVID-19 vaccine-related Twitter posts (tweets) that co-occurred with mentions of People in the Public Eye. Our findings suggest the presence of consistent patterns of emotional content co-occurring with messaging shared by Persons in the Public Eye for the first two years of the COVID-19 pandemic influenced public opinion and largely stimulated online public discourse. We demonstrate that as the pandemic progressed, public sentiment shared on social networks was shaped by risk perceptions, political ideologies and health-protective behaviours shared by Persons in the Public Eye, often in a negative light. ",
    "url": "https://arxiv.org/abs/2303.16759",
    "authors": [
      "Brianna M White",
      "Chad A Melton",
      "Parya Zareie",
      "Robert L Davis",
      "Robert A Bednarczyk",
      "Arash Shaban-Nejad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.16763",
    "title": "Meeting Action Item Detection with Regularized Context Modeling",
    "abstract": "Meetings are increasingly important for collaborations. Action items in meeting transcripts are crucial for managing post-meeting to-do tasks, which usually are summarized laboriously. The Action Item Detection task aims to automatically detect meeting content associated with action items. However, datasets manually annotated with action item detection labels are scarce and in small scale. We construct and release the first Chinese meeting corpus with manual action item annotations. In addition, we propose a Context-Drop approach to utilize both local and global contexts by contrastive learning, and achieve better accuracy and robustness for action item detection. We also propose a Lightweight Model Ensemble method to exploit different pre-trained models. Experimental results on our Chinese meeting corpus and the English AMI corpus demonstrate the effectiveness of the proposed approaches. ",
    "url": "https://arxiv.org/abs/2303.16763",
    "authors": [
      "Jiaqing Liu",
      "Chong Deng",
      "Qinglin Zhang",
      "Qian Chen",
      "Wen Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.16772",
    "title": "Maximin Headway Control of Automated Vehicles for System Optimal Dynamic  Traffic Assignment in General Networks",
    "abstract": "This study develops the headway control framework in a fully automated road network, as we believe headway of Automated Vehicles (AVs) is another influencing factor to traffic dynamics in addition to conventional vehicle behaviors (e.g. route and departure time choices). Specifically, we aim to search for the optimal time headway between AVs on each link that achieves the network-wide system optimal dynamic traffic assignment (SO-DTA). To this end, the headway-dependent fundamental diagram (HFD) and headway-dependent double queue model (HDQ) are developed to model the effect of dynamic headway on roads, and a dynamic network model is built. It is rigorously proved that the minimum headway could always achieve SO-DTA, yet the optimal headway is non-unique. Motivated by these two findings, this study defines a novel concept of maximin headway, which is the largest headway that still achieves SO-DTA in the network. Mathematical properties regarding maximin headway are analyzed and an efficient solution algorithm is developed. Numerical experiments on both a small and large network verify the effectiveness of the maximin headway control framework as well as the properties of maximin headway. This study sheds light on deriving the desired solution among the non-unique solutions in SO-DTA and provides implications regarding the safety margin of AVs under SO-DTA. ",
    "url": "https://arxiv.org/abs/2303.16772",
    "authors": [
      "Jinxiao Du",
      "Wei Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.16776",
    "title": "Supervised Learning for Table Tennis Match Prediction",
    "abstract": "Machine learning, classification and prediction models have applications across a range of fields. Sport analytics is an increasingly popular application, but most existing work is focused on automated refereeing in mainstream sports and injury prevention. Research on other sports, such as table tennis, has only recently started gaining more traction. This paper proposes the use of machine learning to predict the outcome of table tennis single matches. We use player and match statistics as features and evaluate their relative importance in an ablation study. In terms of models, a number of popular models were explored. We found that 5-fold cross-validation and hyperparameter tuning was crucial to improve model performance. We investigated different feature aggregation strategies in our ablation study to demonstrate the robustness of the models. Different models performed comparably, with the accuracy of the results (61-70%) matching state-of-the-art models in comparable sports, such as tennis. The results can serve as a baseline for future table tennis prediction models, and can feed back to prediction research in similar ball sports. ",
    "url": "https://arxiv.org/abs/2303.16776",
    "authors": [
      "Sophie Chiang",
      "Gyorgy Denes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16781",
    "title": "GRAF: Graph Attention-aware Fusion Networks",
    "abstract": "A large number of real-world networks include multiple types of nodes and edges. Graph Neural Network (GNN) emerged as a deep learning framework to utilize node features on graph-structured data showing superior performance. However, popular GNN-based architectures operate on one homogeneous network. Enabling them to work on multiple networks brings additional challenges due to the heterogeneity of the networks and the multiplicity of the existing associations. In this study, we present a computational approach named GRAF utilizing GNN-based approaches on multiple networks with the help of attention mechanisms and network fusion. Using attention-based neighborhood aggregation, GRAF learns the importance of each neighbor per node (called node-level attention) followed by the importance of association (called association-level attention) in a hierarchical way. Then, GRAF processes a network fusion step weighing each edge according to learned node- and association-level attention, which results in a fused enriched network. Considering that the fused network could be a highly dense network with many weak edges depending on the given input networks, we included an edge elimination step with respect to edges' weights. Finally, GRAF utilizes Graph Convolutional Network (GCN) on the fused network and incorporates the node features on the graph-structured data for the prediction task or any other downstream analysis. Our extensive evaluations of prediction tasks from different domains showed that GRAF outperformed the state-of-the-art methods. Utilization of learned node-level and association-level attention allowed us to prioritize the edges properly. The source code for our tool is publicly available at https://github.com/bozdaglab/GRAF. ",
    "url": "https://arxiv.org/abs/2303.16781",
    "authors": [
      "Ziynet Nesibe Kesimoglu",
      "Serdar Bozdag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16783",
    "title": "Exploring Asymmetric Tunable Blind-Spots for Self-supervised Denoising  in Real-World Scenarios",
    "abstract": "Self-supervised denoising has attracted widespread attention due to its ability to train without clean images. However, noise in real-world scenarios is often spatially correlated, which causes many self-supervised algorithms based on the pixel-wise independent noise assumption to perform poorly on real-world images. Recently, asymmetric pixel-shuffle downsampling (AP) has been proposed to disrupt the spatial correlation of noise. However, downsampling introduces aliasing effects, and the post-processing to eliminate these effects can destroy the spatial structure and high-frequency details of the image, in addition to being time-consuming. In this paper, we systematically analyze downsampling-based methods and propose an Asymmetric Tunable Blind-Spot Network (AT-BSN) to address these issues. We design a blind-spot network with a freely tunable blind-spot size, using a large blind-spot during training to suppress local spatially correlated noise while minimizing damage to the global structure, and a small blind-spot during inference to minimize information loss. Moreover, we propose blind-spot self-ensemble and distillation of non-blind-spot network to further improve performance and reduce computational complexity. Experimental results demonstrate that our method achieves state-of-the-art results while comprehensively outperforming other self-supervised methods in terms of image texture maintaining, parameter count, computation cost, and inference time. ",
    "url": "https://arxiv.org/abs/2303.16783",
    "authors": [
      "Shiyan Chen",
      "Jiyuan Zhang",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16818",
    "title": "BEVSimDet: Simulated Multi-modal Distillation in Bird's-Eye View for  Multi-view 3D Object Detection",
    "abstract": "Multi-view camera-based 3D object detection has gained popularity due to its low cost. But accurately inferring 3D geometry solely from camera data remains challenging, which impacts model performance. One promising approach to address this issue is to distill precise 3D geometry knowledge from LiDAR data. However, transferring knowledge between different sensor modalities is hindered by the significant modality gap. In this paper, we approach this challenge from the perspective of both architecture design and knowledge distillation and present a new simulated multi-modal 3D object detection method named BEVSimDet. We first introduce a novel framework that includes a LiDAR and camera fusion-based teacher and a simulated multi-modal student, where the student simulates multi-modal features with image-only input. To facilitate effective distillation, we propose a simulated multi-modal distillation scheme that supports intra-modal, cross-modal, and multi-modal distillation simultaneously. By combining them together, BEVSimDet can learn better feature representations for 3D object detection while enjoying cost-effective camera-only deployment. Experimental results on the challenging nuScenes benchmark demonstrate the effectiveness and superiority of BEVSimDet over recent representative methods. The source code will be released. ",
    "url": "https://arxiv.org/abs/2303.16818",
    "authors": [
      "Haimei Zhao",
      "Qiming Zhang",
      "Shanshan Zhao",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16821",
    "title": "Decision Making for Autonomous Driving in Interactive Merge Scenarios  via Learning-based Prediction",
    "abstract": "Autonomous agents that drive on roads shared with human drivers must reason about the nuanced interactions among traffic participants. This poses a highly challenging decision making problem since human behavior is influenced by a multitude of factors (e.g., human intentions and emotions) that are hard to model. This paper presents a decision making approach for autonomous driving, focusing on the complex task of merging into moving traffic where uncertainty emanates from the behavior of other drivers and imperfect sensor measurements. We frame the problem as a partially observable Markov decision process (POMDP) and solve it online with Monte Carlo tree search. The solution to the POMDP is a policy that performs high-level driving maneuvers, such as giving way to an approaching car, keeping a safe distance from the vehicle in front or merging into traffic. Our method leverages a model learned from data to predict the future states of traffic while explicitly accounting for interactions among the surrounding agents. From these predictions, the autonomous vehicle can anticipate the future consequences of its actions on the environment and optimize its trajectory accordingly. We thoroughly test our approach in simulation, showing that the autonomous vehicle can adapt its behavior to different situations. We also compare against other methods, demonstrating an improvement with respect to the considered performance metrics. ",
    "url": "https://arxiv.org/abs/2303.16821",
    "authors": [
      "Salar Arbabi",
      "Davide Tavernini",
      "Saber Fallah",
      "Richard Bowden"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16832",
    "title": "Uniting General-Graph and Geometric-Based Radio Networks via  Independence Number Parametrization",
    "abstract": "In the study of radio networks, the tasks of broadcasting (propagating a message throughout the network) and leader election (having the network agree on a node to designate `leader') are two of the most fundamental global problems, and have a long history of work devoted to them. This work has two divergent strands: some works focus on exploiting the geometric properties of wireless networks based in physical space, while others consider general graphs. Algorithmic results in each of these avenues have often used quite different techniques, and produced bounds using incomparable parametrizations. In this work, we unite the study of general-graph and geometric-based radio networks, by adapting the broadcast and leader election algorithm of Czumaj and Davies (JACM '21) to achieve a running-time parametrized by the independence number of the network (i.e., the size of the maximum independent set). This parametrization preserves the running time on general graphs, matching the best known, but also improves running times to near-optimality across a wide range of geometric-based graph classes. As part of this algorithm, we also provide the first algorithm for computing a maximal independent set in general-graph radio networks. This algorithm runs in $O(\\log^3 n)$ time-steps, only a $\\log n$ factor away from the $\\Omega(\\log^2 n)$ lower bound. ",
    "url": "https://arxiv.org/abs/2303.16832",
    "authors": [
      "Peter Davies"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.16855",
    "title": "Peer Prediction for Peer Review: Designing a Marketplace for Ideas",
    "abstract": "The paper describes a potential platform to facilitate academic peer review with emphasis on early-stage research. This platform aims to make peer review more accurate and timely by rewarding reviewers on the basis of peer prediction algorithms. The algorithm uses a variation of Peer Truth Serum for Crowdsourcing (Radanovic et al., 2016) with human raters competing against a machine learning benchmark. We explain how our approach addresses two large productive inefficiencies in science: mismatch between research questions and publication bias. Better peer review for early research creates additional incentives for sharing it, which simplifies matching ideas to teams and makes negative results and p-hacking more visible. ",
    "url": "https://arxiv.org/abs/2303.16855",
    "authors": [
      "Alexander Ugarov"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.16856",
    "title": "Robust Dancer: Long-term 3D Dance Synthesis Using Unpaired Data",
    "abstract": "How to automatically synthesize natural-looking dance movements based on a piece of music is an incrementally popular yet challenging task. Most existing data-driven approaches require hard-to-get paired training data and fail to generate long sequences of motion due to error accumulation of autoregressive structure. We present a novel 3D dance synthesis system that only needs unpaired data for training and could generate realistic long-term motions at the same time. For the unpaired data training, we explore the disentanglement of beat and style, and propose a Transformer-based model free of reliance upon paired data. For the synthesis of long-term motions, we devise a new long-history attention strategy. It first queries the long-history embedding through an attention computation and then explicitly fuses this embedding into the generation pipeline via multimodal adaptation gate (MAG). Objective and subjective evaluations show that our results are comparable to strong baseline methods, despite not requiring paired training data, and are robust when inferring long-term music. To our best knowledge, we are the first to achieve unpaired data training - an ability that enables to alleviate data limitations effectively. Our code is released on https://github.com/BFeng14/RobustDancer ",
    "url": "https://arxiv.org/abs/2303.16856",
    "authors": [
      "Bin Feng",
      "Tenglong Ao",
      "Zequn Liu",
      "Wei Ju",
      "Libin Liu",
      "Ming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.16861",
    "title": "Beyond Empirical Risk Minimization: Local Structure Preserving  Regularization for Improving Adversarial Robustness",
    "abstract": "It is broadly known that deep neural networks are susceptible to being fooled by adversarial examples with perturbations imperceptible by humans. Various defenses have been proposed to improve adversarial robustness, among which adversarial training methods are most effective. However, most of these methods treat the training samples independently and demand a tremendous amount of samples to train a robust network, while ignoring the latent structural information among these samples. In this work, we propose a novel Local Structure Preserving (LSP) regularization, which aims to preserve the local structure of the input space in the learned embedding space. In this manner, the attacking effect of adversarial samples lying in the vicinity of clean samples can be alleviated. We show strong empirical evidence that with or without adversarial training, our method consistently improves the performance of adversarial robustness on several image classification datasets compared to the baselines and some state-of-the-art approaches, thus providing promising direction for future research. ",
    "url": "https://arxiv.org/abs/2303.16861",
    "authors": [
      "Wei Wei",
      "Jiahuan Zhou",
      "Ying Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16866",
    "title": "ALUM: Adversarial Data Uncertainty Modeling from Latent Model  Uncertainty Compensation",
    "abstract": "It is critical that the models pay attention not only to accuracy but also to the certainty of prediction. Uncertain predictions of deep models caused by noisy data raise significant concerns in trustworthy AI areas. To explore and handle uncertainty due to intrinsic data noise, we propose a novel method called ALUM to simultaneously handle the model uncertainty and data uncertainty in a unified scheme. Rather than solely modeling data uncertainty in the ultimate layer of a deep model based on randomly selected training data, we propose to explore mined adversarial triplets to facilitate data uncertainty modeling and non-parametric uncertainty estimations to compensate for the insufficiently trained latent model layers. Thus, the critical data uncertainty and model uncertainty caused by noisy data can be readily quantified for improving model robustness. Our proposed ALUM is model-agnostic which can be easily implemented into any existing deep model with little extra computation overhead. Extensive experiments on various noisy learning tasks validate the superior robustness and generalization ability of our method. The code is released at https://github.com/wwzjer/ALUM. ",
    "url": "https://arxiv.org/abs/2303.16866",
    "authors": [
      "Wei Wei",
      "Jiahuan Zhou",
      "Hongze Li",
      "Ying Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16874",
    "title": "CheckerPose: Progressive Dense Keypoint Localization for Object Pose  Estimation with Graph Neural Network",
    "abstract": "Estimating the 6-DoF pose of a rigid object from a single RGB image is a crucial yet challenging task. Recent studies have shown the great potential of dense correspondence-based solutions, yet improvements are still needed to reach practical deployment. In this paper, we propose a novel pose estimation algorithm named CheckerPose, which improves on three main aspects. Firstly, CheckerPose densely samples 3D keypoints from the surface of the 3D object and finds their 2D correspondences progressively in the 2D image. Compared to previous solutions that conduct dense sampling in the image space, our strategy enables the correspondence searching in a 2D grid (i.e., pixel coordinate). Secondly, for our 3D-to-2D correspondence, we design a compact binary code representation for 2D image locations. This representation not only allows for progressive correspondence refinement but also converts the correspondence regression to a more efficient classification problem. Thirdly, we adopt a graph neural network to explicitly model the interactions among the sampled 3D keypoints, further boosting the reliability and accuracy of the correspondences. Together, these novel components make our CheckerPose a strong pose estimation algorithm. When evaluated on the popular Linemod, Linemod-O, and YCB-V object pose estimation benchmarks, CheckerPose clearly boosts the accuracy of correspondence-based methods and achieves state-of-the-art performances. ",
    "url": "https://arxiv.org/abs/2303.16874",
    "authors": [
      "Ruyi Lian",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16884",
    "title": "Instant Neural Radiance Fields Stylization",
    "abstract": "We present Instant Neural Radiance Fields Stylization, a novel approach for multi-view image stylization for the 3D scene. Our approach models a neural radiance field based on neural graphics primitives, which use a hash table-based position encoder for position embedding. We split the position encoder into two parts, the content and style sub-branches, and train the network for normal novel view image synthesis with the content and style targets. In the inference stage, we execute AdaIN to the output features of the position encoder, with content and style voxel grid features as reference. With the adjusted features, the stylization of novel view images could be obtained. Our method extends the style target from style images to image sets of scenes and does not require additional network training for stylization. Given a set of images of 3D scenes and a style target(a style image or another set of 3D scenes), our method can generate stylized novel views with a consistent appearance at various view angles in less than 10 minutes on modern GPU hardware. Extensive experimental results demonstrate the validity and superiority of our method. ",
    "url": "https://arxiv.org/abs/2303.16884",
    "authors": [
      "Shaoxu Li",
      "Ye Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16890",
    "title": "DPF: Learning Dense Prediction Fields with Weak Supervision",
    "abstract": "Nowadays, many visual scene understanding problems are addressed by dense prediction networks. But pixel-wise dense annotations are very expensive (e.g., for scene parsing) or impossible (e.g., for intrinsic image decomposition), motivating us to leverage cheap point-level weak supervision. However, existing pointly-supervised methods still use the same architecture designed for full supervision. In stark contrast to them, we propose a new paradigm that makes predictions for point coordinate queries, as inspired by the recent success of implicit representations, like distance or radiance fields. As such, the method is named as dense prediction fields (DPFs). DPFs generate expressive intermediate features for continuous sub-pixel locations, thus allowing outputs of an arbitrary resolution. DPFs are naturally compatible with point-level supervision. We showcase the effectiveness of DPFs using two substantially different tasks: high-level semantic parsing and low-level intrinsic image decomposition. In these two cases, supervision comes in the form of single-point semantic category and two-point relative reflectance, respectively. As benchmarked by three large-scale public datasets PASCALContext, ADE20K and IIW, DPFs set new state-of-the-art performance on all of them with significant margins. Code can be accessed at https://github.com/cxx226/DPF. ",
    "url": "https://arxiv.org/abs/2303.16890",
    "authors": [
      "Xiaoxue Chen",
      "Yuhang Zheng",
      "Yupeng Zheng",
      "Qiang Zhou",
      "Hao Zhao",
      "Guyue Zhou",
      "Ya-Qin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16206",
    "title": "Learning Iterative Neural Optimizers for Image Steganography",
    "abstract": "Image steganography is the process of concealing secret information in images through imperceptible changes. Recent work has formulated this task as a classic constrained optimization problem. In this paper, we argue that image steganography is inherently performed on the (elusive) manifold of natural images, and propose an iterative neural network trained to perform the optimization steps. In contrast to classical optimization methods like L-BFGS or projected gradient descent, we train the neural network to also stay close to the manifold of natural images throughout the optimization. We show that our learned neural optimization is faster and more reliable than classical optimization approaches. In comparison to previous state-of-the-art encoder-decoder-based steganography methods, it reduces the recovery error rate by multiple orders of magnitude and achieves zero error up to 3 bits per pixel (bpp) without the need for error-correcting codes. ",
    "url": "https://arxiv.org/abs/2303.16206",
    "authors": [
      "Xiangyu Chen",
      "Varsha Kishore",
      "Kilian Q Weinberger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.16242",
    "title": "CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image  Arbitrary-Scale Super Resolution",
    "abstract": "Medical image arbitrary-scale super-resolution (MIASSR) has recently gained widespread attention, aiming to super sample medical volumes at arbitrary scales via a single model. However, existing MIASSR methods face two major limitations: (i) reliance on high-resolution (HR) volumes and (ii) limited generalization ability, which restricts their application in various scenarios. To overcome these limitations, we propose Cube-based Neural Radiance Field (CuNeRF), a zero-shot MIASSR framework that can yield medical images at arbitrary scales and viewpoints in a continuous domain. Unlike existing MIASSR methods that fit the mapping between low-resolution (LR) and HR volumes, CuNeRF focuses on building a coordinate-intensity continuous representation from LR volumes without the need for HR references. This is achieved by the proposed differentiable modules: including cube-based sampling, isotropic volume rendering, and cube-based hierarchical rendering. Through extensive experiments on magnetic resource imaging (MRI) and computed tomography (CT) modalities, we demonstrate that CuNeRF outperforms state-of-the-art MIASSR methods. CuNeRF yields better visual verisimilitude and reduces aliasing artifacts at various upsampling factors. Moreover, our CuNeRF does not need any LR-HR training pairs, which is more flexible and easier to be used than others. Our code will be publicly available soon. ",
    "url": "https://arxiv.org/abs/2303.16242",
    "authors": [
      "Zixuan Chen",
      "Jianhuang Lai",
      "Lingxiao Yang",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16251",
    "title": "Function Approximation with Randomly Initialized Neural Networks for  Approximate Model Reference Adaptive Control",
    "abstract": "Classical results in neural network approximation theory show how arbitrary continuous functions can be approximated by networks with a single hidden layer, under mild assumptions on the activation function. However, the classical theory does not give a constructive means to generate the network parameters that achieve a desired accuracy. Recent results have demonstrated that for specialized activation functions, such as ReLUs and some classes of analytic functions, high accuracy can be achieved via linear combinations of randomly initialized activations. These recent works utilize specialized integral representations of target functions that depend on the specific activation functions used. This paper defines mollified integral representations, which provide a means to form integral representations of target functions using activations for which no direct integral representation is currently known. The new construction enables approximation guarantees for randomly initialized networks for a variety of widely used activation functions. ",
    "url": "https://arxiv.org/abs/2303.16251",
    "authors": [
      "Tyler Lekang",
      "Andrew Lamperski"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16355",
    "title": "Assessing the impact of Byzantine attacks on coupled phase oscillators",
    "abstract": "For many coupled dynamical systems, the interaction is the outcome of the measurement that each unit has of the others or of physical flows e.g. modern inverter-based power grids, autonomous vehicular platoons or swarms of drones. Synchronization among all the components of these systems is of primal importance to avoid failures. The overall operational state of these systems therefore crucially depends on the correct and reliable functioning of the individual elements as well as the information they transmit through the network. Here we investigate the effect of Byzantine attacks where one unit does not behave as expected, but is controlled by an external attacker. For such attacks, we assess the impact on the global collective behavior of nonlinearly coupled phase oscillators. We relate the synchronization error induced by the input signal to the properties of the attacked node. This allows to anticipate the potential of an attacker and identify which network components to secure. ",
    "url": "https://arxiv.org/abs/2303.16355",
    "authors": [
      "Melvyn Tyloo"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.16361",
    "title": "Dynamical Modularity in Automata Models of Biochemical Networks",
    "abstract": "Given the large size and complexity of most biochemical regulation and signaling networks, there is a non-trivial relationship between the micro-level logic of component interactions and the observed macro-dynamics. Here we address this issue by formalizing the existing concept of pathway modules, which are sequences of state updates that are guaranteed to occur (barring outside interference) in the dynamics of automata networks after the perturbation of a subset of driver nodes. We present a novel algorithm to automatically extract pathway modules from networks and we characterize the interactions that may take place between modules. This methodology uses only the causal logic of individual node variables (micro-dynamics) without the need to compute the dynamical landscape of the networks (macro-dynamics). Specifically, we identify complex modules, which maximize pathway length and require synergy between their components. This allows us to propose a new take on dynamical modularity that partitions complex networks into causal pathways of variables that are guaranteed to transition to specific states given a perturbation to a set of driver nodes. Thus, the same node variable can take part in distinct modules depending on the state it takes. Our measure of dynamical modularity of a network is then inversely proportional to the overlap among complex modules and maximal when complex modules are completely decouplable from one another in the network dynamics. We estimate dynamical modularity for several genetic regulatory networks, including the Drosophila melanogaster segment-polarity network. We discuss how identifying complex modules and the dynamical modularity portrait of networks explains the macro-dynamics of biological networks, such as uncovering the (more or less) decouplable building blocks of emergent computation (or collective behavior) in biochemical regulation and signaling. ",
    "url": "https://arxiv.org/abs/2303.16361",
    "authors": [
      "Thomas Parmer",
      "Luis M. Rocha"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.16609",
    "title": "Modified watershed approach for segmentation of complex optical  coherence tomographic images",
    "abstract": "Watershed segmentation method has been used in various applications. But many a times, due to its over-segmentation attributes, it underperforms in several tasks where noise is a dominant source. In this study, Optical Coherence Tomography images have been acquired, and segmentation has been performed to analyse the different regions of fluid filled sacs in a lemon. A modified watershed algorithm has been proposed which gives promising results for segmentation of internal lemon structures. ",
    "url": "https://arxiv.org/abs/2303.16609",
    "authors": [
      "Maryam Viqar",
      "Violeta Madjarova",
      "Elena Stoykova"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2303.16774",
    "title": "Polarization and multiscale structural balance in signed networks",
    "abstract": "Polarization is a common feature of social systems. Structural Balance Theory studies polarization of positive in-group and negative out-group ties in terms of semicycles within signed networks. However, enumerating semicycles is computationally expensive, so approximations are often needed to assess balance. Here we introduce Multiscale Semiwalk Balance (MSB) approach for quantifying the degree of balance (DoB) in (un)directed, (un)weighted signed networks by approximating semicycles with closed semiwalks. MSB allows principled selection of a range of cycle lengths appropriate for assessing DoB and interpretable under the Locality Principle (which posits that patterns in shorter cycles are crucial for balance). This flexibility overcomes several limitations affecting walk-based approximations and enables efficient, interpretable methods for measuring DoB and clustering signed networks. We demonstrate the effectiveness of our approach by applying it to real-world social systems. For instance, our methods capture increasing polarization in the U.S. Congress, which may go undetected with other methods. ",
    "url": "https://arxiv.org/abs/2303.16774",
    "authors": [
      "Szymon Talaga",
      "Massimo Stella",
      "Trevor James Swanson",
      "Andreia Sofia Teixeira"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.16813",
    "title": "Optimal approximation of $C^k$-functions using shallow complex-valued  neural networks",
    "abstract": "We prove a quantitative result for the approximation of functions of regularity $C^k$ (in the sense of real variables) defined on the complex cube $\\Omega_n := [-1,1]^n +i[-1,1]^n\\subseteq \\mathbb{C}^n$ using shallow complex-valued neural networks. Precisely, we consider neural networks with a single hidden layer and $m$ neurons, i.e., networks of the form $z \\mapsto \\sum_{j=1}^m \\sigma_j \\cdot \\phi\\big(\\rho_j^T z + b_j\\big)$ and show that one can approximate every function in $C^k \\left( \\Omega_n; \\mathbb{C}\\right)$ using a function of that form with error of the order $m^{-k/(2n)}$ as $m \\to \\infty$, provided that the activation function $\\phi: \\mathbb{C} \\to \\mathbb{C}$ is smooth but not polyharmonic on some non-empty open set. Furthermore, we show that the selection of the weights $\\sigma_j, b_j \\in \\mathbb{C}$ and $\\rho_j \\in \\mathbb{C}^n$ is continuous with respect to $f$ and prove that the derived rate of approximation is optimal under this continuity assumption. We also discuss the optimality of the result for a possibly discontinuous choice of the weights. ",
    "url": "https://arxiv.org/abs/2303.16813",
    "authors": [
      "Paul Geuchen",
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1705.01450",
    "title": "Gabor Convolutional Networks",
    "abstract": " Title: Gabor Convolutional Networks ",
    "url": "https://arxiv.org/abs/1705.01450",
    "authors": [
      "Shangzhen Luan",
      "Baochang Zhang",
      "Chen Chen",
      "Xianbin Cao",
      "Jungong Han",
      "Jianzhuang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1807.10108",
    "title": "Effects of Degradations on Deep Neural Network Architectures",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/1807.10108",
    "authors": [
      "Prasun Roy",
      "Subhankar Ghosh",
      "Saumik Bhattacharya",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:1903.01192",
    "title": "STEFANN: Scene Text Editor using Font Adaptive Neural Network",
    "abstract": " Comments: Accepted in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2020 ",
    "url": "https://arxiv.org/abs/1903.01192",
    "authors": [
      "Prasun Roy",
      "Saumik Bhattacharya",
      "Subhankar Ghosh",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2006.13726",
    "title": "Imbalanced Gradients: A Subtle Cause of Overestimated Adversarial  Robustness",
    "abstract": " Comments: To appear in Machine Learning ",
    "url": "https://arxiv.org/abs/2006.13726",
    "authors": [
      "Xingjun Ma",
      "Linxi Jiang",
      "Hanxun Huang",
      "Zejia Weng",
      "James Bailey",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.07213",
    "title": "Synchronization of Complex Network Systems with Stochastic Disturbances",
    "abstract": " Comments: 21 pages, 1 figures,2 tables ",
    "url": "https://arxiv.org/abs/2201.07213",
    "authors": [
      "Kaihua Xi",
      "Zhen Wang",
      "Aijie Cheng",
      "Hai Xiang Lin",
      "Jan H. van Schuppen",
      "Chenghui Zhang"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.12577",
    "title": "Volley Revolver: A Novel Matrix-Encoding Method for Privacy-Preserving  Neural Networks (Inference)",
    "abstract": " Comments: The encoding method we proposed in this work, $\\texttt{Volley Revolver}$, is particularly tailored for privacy-preserving neural networks. There is a good chance that it can be used to assist the private neural networks training, in which case for the backpropagation algorithm of the fully-connected layer the first matrix $A$ is revolved while the second matrix $B$ is settled to be still ",
    "url": "https://arxiv.org/abs/2201.12577",
    "authors": [
      "John Chiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.02194",
    "title": "Rethinking Reconstruction Autoencoder-Based Out-of-Distribution  Detection",
    "abstract": " Comments: Accepted('Poster' presentation) as main conference paper of CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.02194",
    "authors": [
      "Yibo Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.12613",
    "title": "Hybrid Mesh-neural Representation for 3D Transparent Object  Reconstruction",
    "abstract": " Title: Hybrid Mesh-neural Representation for 3D Transparent Object  Reconstruction ",
    "url": "https://arxiv.org/abs/2203.12613",
    "authors": [
      "Jiamin Xu",
      "Zihan Zhu",
      "Hujun Bao",
      "Weiwei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06424",
    "title": "Look, Radiate, and Learn: Self-Supervised Localisation via Radio-Visual  Correspondence",
    "abstract": " Comments: To appear in IEEE/CVF CVPR '23 ",
    "url": "https://arxiv.org/abs/2206.06424",
    "authors": [
      "Mohammed Alloulah",
      "Maximilian Arnold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.11736",
    "title": "NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds",
    "abstract": " Comments: Published in Transactions on Machine Learning Research (03/2023) ",
    "url": "https://arxiv.org/abs/2206.11736",
    "authors": [
      "Patrick Feeney",
      "Sarah Schneider",
      "Panagiotis Lymperopoulos",
      "Li-Ping Liu",
      "Matthias Scheutz",
      "Michael C. Hughes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.12815",
    "title": "What Does the Gradient Tell When Attacking the Graph Structure",
    "abstract": " Title: What Does the Gradient Tell When Attacking the Graph Structure ",
    "url": "https://arxiv.org/abs/2208.12815",
    "authors": [
      "Zihan Liu",
      "Ge Wang",
      "Yun Luo",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.05299",
    "title": "Deep Convolutional Pooling Transformer for Deepfake Detection",
    "abstract": " Comments: Accepted to be published in ACM TOMM ",
    "url": "https://arxiv.org/abs/2209.05299",
    "authors": [
      "Tianyi Wang",
      "Harry Cheng",
      "Kam Pui Chow",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.15323",
    "title": "SmallCap: Lightweight Image Captioning Prompted with Retrieval  Augmentation",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2209.15323",
    "authors": [
      "Rita Ramos",
      "Bruno Martins",
      "Desmond Elliott",
      "Yova Kementchedjhieva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.02992",
    "title": "COVID-19 Detection Using Segmentation, Region Extraction and  Classification Pipeline",
    "abstract": " Title: COVID-19 Detection Using Segmentation, Region Extraction and  Classification Pipeline ",
    "url": "https://arxiv.org/abs/2210.02992",
    "authors": [
      "Kenan Morani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14868",
    "title": "Multi-lingual Evaluation of Code Generation Models",
    "abstract": " Comments: Code and data release: this https URL ",
    "url": "https://arxiv.org/abs/2210.14868",
    "authors": [
      "Ben Athiwaratkun",
      "Sanjay Krishna Gouda",
      "Zijian Wang",
      "Xiaopeng Li",
      "Yuchen Tian",
      "Ming Tan",
      "Wasi Uddin Ahmad",
      "Shiqi Wang",
      "Qing Sun",
      "Mingyue Shang",
      "Sujan Kumar Gonugondla",
      "Hantian Ding",
      "Varun Kumar",
      "Nathan Fulton",
      "Arash Farahani",
      "Siddhartha Jain",
      "Robert Giaquinto",
      "Haifeng Qian",
      "Murali Krishna Ramanathan",
      "Ramesh Nallapati",
      "Baishakhi Ray",
      "Parminder Bhatia",
      "Sudipta Sengupta",
      "Dan Roth",
      "Bing Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.16117",
    "title": "Improving the Transferability of Adversarial Attacks on Face Recognition  with Beneficial Perturbation Feature Augmentation",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2210.16117",
    "authors": [
      "Fengfan Zhou",
      "Hefei Ling",
      "Yuxuan Shi",
      "Jiazhong Chen",
      "Zongyi Li",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.03883",
    "title": "Approximating Nash Social Welfare by Matching and Local Search",
    "abstract": " Comments: 28 pages, 1 figure. To appear in STOC 2023 ",
    "url": "https://arxiv.org/abs/2211.03883",
    "authors": [
      "Jugal Garg",
      "Edin Husi\u0107",
      "Wenzheng Li",
      "L\u00e1szl\u00f3 A. V\u00e9gh",
      "Jan Vondr\u00e1k"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.08540",
    "title": "VGFlow: Visibility guided Flow Network for Human Reposing",
    "abstract": " Comments: Selected for publication in CVPR2023 ",
    "url": "https://arxiv.org/abs/2211.08540",
    "authors": [
      "Rishabh Jain",
      "Krishna Kumar Singh",
      "Mayur Hemani",
      "Jingwan Lu",
      "Mausoom Sarkar",
      "Duygu Ceylan",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10381",
    "title": "Environmental Sensor Placement with Convolutional Gaussian Neural  Processes",
    "abstract": " Comments: In review for the Climate Informatics 2023 special issue of Environmental Data Science ",
    "url": "https://arxiv.org/abs/2211.10381",
    "authors": [
      "Tom R. Andersson",
      "Wessel P. Bruinsma",
      "Stratis Markou",
      "James Requeima",
      "Alejandro Coca-Castro",
      "Anna Vaughan",
      "Anna-Louise Ellis",
      "Matthew A. Lazzara",
      "Daniel C. Jones",
      "J. Scott Hosking",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10890",
    "title": "Single-Pass Contrastive Learning Can Work for Both Homophilic and  Heterophilic Graph",
    "abstract": " Comments: 21 pages, 5 figures, 8 tables. arXiv admin note: substantial text overlap with arXiv:2204.04874. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2211.10890",
    "authors": [
      "Haonan Wang",
      "Jieyu Zhang",
      "Qi Zhu",
      "Wei Huang",
      "Kenji Kawaguchi",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.13123",
    "title": "Motif-aware temporal GCN for fraud detection in signed cryptocurrency  trust networks",
    "abstract": " Title: Motif-aware temporal GCN for fraud detection in signed cryptocurrency  trust networks ",
    "url": "https://arxiv.org/abs/2211.13123",
    "authors": [
      "Song Li",
      "Jiandong Zhou",
      "Chong MO",
      "Jin LI",
      "Geoffrey K. F. Tso",
      "Yuxing Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Trading and Market Microstructure (q-fin.TR)"
    ]
  },
  {
    "id": "arXiv:2211.14394",
    "title": "Link Prediction with Non-Contrastive Learning",
    "abstract": " Comments: ICLR 2023. 19 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2211.14394",
    "authors": [
      "William Shiao",
      "Zhichun Guo",
      "Tong Zhao",
      "Evangelos E. Papalexakis",
      "Yozen Liu",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.01117",
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2212.01117",
    "authors": [
      "Hongzhan Lin",
      "Pengyao Yi",
      "Jing Ma",
      "Haiyun Jiang",
      "Ziyang Luo",
      "Shuming Shi",
      "Ruifang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.03491",
    "title": "\"It would work for me too\": How Online Communities Shape Software  Developers' Trust in AI-Powered Code Generation Tools",
    "abstract": " Title: \"It would work for me too\": How Online Communities Shape Software  Developers' Trust in AI-Powered Code Generation Tools ",
    "url": "https://arxiv.org/abs/2212.03491",
    "authors": [
      "Ruijia Cheng",
      "Ruotong Wang",
      "Thomas Zimmermann",
      "Denae Ford"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2212.04692",
    "title": "Attention in a family of Boltzmann machines emerging from modern  Hopfield networks",
    "abstract": " Comments: 15 pages, 3 figures. v2: added figures and various corrections/improvements especially in Introduction and Section 3. Published version ",
    "url": "https://arxiv.org/abs/2212.04692",
    "authors": [
      "Toshihiro Ota",
      "Ryo Karakida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.04823",
    "title": "GazeNeRF: 3D-Aware Gaze Redirection with Neural Radiance Fields",
    "abstract": " Comments: Accepted at CVPR 2023. Github page: this https URL ",
    "url": "https://arxiv.org/abs/2212.04823",
    "authors": [
      "Alessandro Ruzzi",
      "Xiangwei Shi",
      "Xi Wang",
      "Gengyan Li",
      "Shalini De Mello",
      "Hyung Jin Chang",
      "Xucong Zhang",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08542",
    "title": "Context-aware Fine-tuning of Self-supervised Speech Models",
    "abstract": " Title: Context-aware Fine-tuning of Self-supervised Speech Models ",
    "url": "https://arxiv.org/abs/2212.08542",
    "authors": [
      "Suwon Shon",
      "Felix Wu",
      "Kwangyoun Kim",
      "Prashant Sridhar",
      "Karen Livescu",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.09749",
    "title": "Statistical Comparison among Brain Networks with Popular Network  Measurement Algorithms",
    "abstract": " Comments: 22 pages, 38 figures, 19 tables ",
    "url": "https://arxiv.org/abs/2212.09749",
    "authors": [
      "Rakib Hassan Pran"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2212.10878",
    "title": "Automatic Network Adaptation for Ultra-Low Uniform-Precision  Quantization",
    "abstract": " Comments: Accepted as a full paper by the TinyML Research Symposium 2023 ",
    "url": "https://arxiv.org/abs/2212.10878",
    "authors": [
      "Seongmin Park",
      "Beomseok Kwon",
      "Jieun Lim",
      "Kyuyoung Sim",
      "Tae-Ho Kim",
      "Jungwook Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.12130",
    "title": "Learning to Detect and Segment for Open Vocabulary Object Detection",
    "abstract": " Comments: Accepted to CVPR2023, code will be available later ",
    "url": "https://arxiv.org/abs/2212.12130",
    "authors": [
      "Tao Wang",
      "Nan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.12440",
    "title": "HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for  Highly Accurate Protein-Ligand Binding Affinity Prediction",
    "abstract": " Title: HAC-Net: A Hybrid Attention-Based Convolutional Neural Network for  Highly Accurate Protein-Ligand Binding Affinity Prediction ",
    "url": "https://arxiv.org/abs/2212.12440",
    "authors": [
      "Gregory W. Kyro",
      "Rafael I. Brent",
      "Victor S. Batista"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.05489",
    "title": "A Residual Diffusion Model for High Perceptual Quality Codec  Augmentation",
    "abstract": " Comments: v1: 26 pages, 13 figures v2: corrected typo in first author name in arxiv metadata v3: major paper update to add base codecs and lpips loss ",
    "url": "https://arxiv.org/abs/2301.05489",
    "authors": [
      "Noor Fathima Ghouse",
      "Jens Petersen",
      "Auke Wiggers",
      "Tianlin Xu",
      "Guillaume Sauti\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.12912",
    "title": "A PBPO+ Graph Rewriting Tutorial",
    "abstract": " Comments: In Proceedings TERMGRAPH 2022, arXiv:2303.14219 ",
    "url": "https://arxiv.org/abs/2301.12912",
    "authors": [
      "Roy Overbeek",
      "J\u00f6rg Endrullis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2302.09311",
    "title": "Temporal Interpolation Is All You Need for Dynamic Neural Radiance  Fields",
    "abstract": " Comments: CVPR 2023. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2302.09311",
    "authors": [
      "Sungheon Park",
      "Minjung Son",
      "Seokhwan Jang",
      "Young Chun Ahn",
      "Ji-Yeon Kim",
      "Nahyup Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.12095",
    "title": "On the Robustness of ChatGPT: An Adversarial and Out-of-distribution  Perspective",
    "abstract": " Comments: Technical report; code is at: this https URL ",
    "url": "https://arxiv.org/abs/2302.12095",
    "authors": [
      "Jindong Wang",
      "Xixu Hu",
      "Wenxin Hou",
      "Hao Chen",
      "Runkai Zheng",
      "Yidong Wang",
      "Linyi Yang",
      "Haojun Huang",
      "Wei Ye",
      "Xiubo Geng",
      "Binxin Jiao",
      "Yue Zhang",
      "Xing Xie"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.00859",
    "title": "FuNVol: A Multi-Asset Implied Volatility Market Simulator using  Functional Principal Components and Neural SDEs",
    "abstract": " Comments: 30 pages, 12 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2303.00859",
    "authors": [
      "Vedant Choudhary",
      "Sebastian Jaimungal",
      "Maxime Bergeron"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.02304",
    "title": "Coupled Multiwavelet Neural Operator Learning for Coupled Partial  Differential Equations",
    "abstract": " Comments: Accepted to ICLR 2023 ",
    "url": "https://arxiv.org/abs/2303.02304",
    "authors": [
      "Xiongye Xiao",
      "Defu Cao",
      "Ruochen Yang",
      "Gaurav Gupta",
      "Gengshuo Liu",
      "Chenzhong Yin",
      "Radu Balan",
      "Paul Bogdan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03634",
    "title": "PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation",
    "abstract": " Title: PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation ",
    "url": "https://arxiv.org/abs/2303.03634",
    "authors": [
      "Tin-Han Chi",
      "Kai-Chun Liu",
      "Chia-Yeh Hsieh",
      "Yu Tsao",
      "Chia-Tai Chan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05768",
    "title": "Learning Global-Local Correspondence with Semantic Bottleneck for  Logical Anomaly Detection",
    "abstract": " Comments: Submission to IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY ",
    "url": "https://arxiv.org/abs/2303.05768",
    "authors": [
      "Haiming Yao",
      "Wenyong Yu",
      "Wei Luo",
      "Zhenfeng Qiang",
      "Donghao Luo",
      "Xiaotian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06335",
    "title": "Just Flip: Flipped Observation Generation and Optimization for Neural  Radiance Fields to Cover Unobserved View",
    "abstract": " Title: Just Flip: Flipped Observation Generation and Optimization for Neural  Radiance Fields to Cover Unobserved View ",
    "url": "https://arxiv.org/abs/2303.06335",
    "authors": [
      "Minjae Lee",
      "Kyeongsu Kang",
      "Hyeonwoo Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07634",
    "title": "I$^2$-SDF: Intrinsic Indoor Scene Reconstruction and Editing via  Raytracing in Neural SDFs",
    "abstract": " Comments: Accepted by CVPR 2023, project page: this https URL ",
    "url": "https://arxiv.org/abs/2303.07634",
    "authors": [
      "Jingsen Zhu",
      "Yuchi Huo",
      "Qi Ye",
      "Fujun Luan",
      "Jifan Li",
      "Dianbing Xi",
      "Lisha Wang",
      "Rui Tang",
      "Wei Hua",
      "Hujun Bao",
      "Rui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.09234",
    "title": "NAISR: A 3D Neural Additive Model for Interpretable Shape Representation",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2303.09234",
    "authors": [
      "Yining Jiao",
      "Carlton Zdanski",
      "Julia Kimbell",
      "Andrew Prince",
      "Cameron Worden",
      "Samuel Kirse",
      "Christopher Rutter",
      "Benjamin Shields",
      "William Dunn",
      "Jisan Mahmud",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09287",
    "title": "Semitopology: a new topological model of heterogeneous consensus",
    "abstract": " Title: Semitopology: a new topological model of heterogeneous consensus ",
    "url": "https://arxiv.org/abs/2303.09287",
    "authors": [
      "Murdoch Gabbay",
      "Giuliano Losa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "General Topology (math.GN)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2303.09607",
    "title": "A Novel Scholar Embedding Model for Interdisciplinary Collaboration",
    "abstract": " Comments: 9 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2303.09607",
    "authors": [
      "Yitong Hu",
      "Zixuan Zhu",
      "Yizhe Wang",
      "Junxiang Wang",
      "Zehao Xing"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.13351",
    "title": "DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly  Knowledge Graph",
    "abstract": " Comments: 12 pages ceur-ws 1 column accepted at International Bibliometric Information Retrieval Workshp @ ECIR 2023 ",
    "url": "https://arxiv.org/abs/2303.13351",
    "authors": [
      "Debayan Banerjee",
      "Sushil Awale",
      "Ricardo Usbeck",
      "Chris Biemann"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.13654",
    "title": "NEWTON: Neural View-Centric Mapping for On-the-Fly Large-Scale SLAM",
    "abstract": " Title: NEWTON: Neural View-Centric Mapping for On-the-Fly Large-Scale SLAM ",
    "url": "https://arxiv.org/abs/2303.13654",
    "authors": [
      "Hidenobu Matsuki",
      "Keisuke Tateno",
      "Michael Niemeyer",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.13767",
    "title": "Learning Spatial-Temporal Implicit Neural Representations for  Event-Guided Video Super-Resolution",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.13767",
    "authors": [
      "Yunfan Lu",
      "Zipeng Wang",
      "Minjie Liu",
      "Hongjian Wang",
      "Lin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14961",
    "title": "Diffusion Denoised Smoothing for Certified and Adversarial Robust  Out-Of-Distribution Detection",
    "abstract": " Title: Diffusion Denoised Smoothing for Certified and Adversarial Robust  Out-Of-Distribution Detection ",
    "url": "https://arxiv.org/abs/2303.14961",
    "authors": [
      "Nicola Franco",
      "Daniel Korth",
      "Jeanette Miriam Lorenz",
      "Karsten Roscher",
      "Stephan Guennemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15161",
    "title": "Data Augmentation for Environmental Sound Classification Using Diffusion  Probabilistic Model with Top-k Selection Discriminator",
    "abstract": " Title: Data Augmentation for Environmental Sound Classification Using Diffusion  Probabilistic Model with Top-k Selection Discriminator ",
    "url": "https://arxiv.org/abs/2303.15161",
    "authors": [
      "Yunhao Chen",
      "Yunjie Zhu",
      "Zihui Yan",
      "Jianlu Shen",
      "Zhen Ren",
      "Yifan Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.15214",
    "title": "Generalizable Denoising of Microscopy Images using Generative  Adversarial Networks and Contrastive Learning",
    "abstract": " Title: Generalizable Denoising of Microscopy Images using Generative  Adversarial Networks and Contrastive Learning ",
    "url": "https://arxiv.org/abs/2303.15214",
    "authors": [
      "Felix Fuentes-Hurtado",
      "Jean-Baptiste Sibarita",
      "Virgile Viasnoff"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15364",
    "title": "Inflation forecasting with attention based transformer neural networks",
    "abstract": " Comments: Paper was rejected and we want to switch to a new dataset. So there will not be a simple resubmit with minor changes but some bigger changes in 1. Dataset and 2. Discussion. We would later resubmit again. Thank you! ",
    "url": "https://arxiv.org/abs/2303.15364",
    "authors": [
      "Maximilian Tschuchnig",
      "Petra Tschuchnig",
      "Cornelia Ferner",
      "Michael Gadermayr"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15786",
    "title": "HOICLIP: Efficient Knowledge Transfer for HOI Detection with  Vision-Language Models",
    "abstract": " Comments: CVPR 2023.Open sourced, Code and Model Available ",
    "url": "https://arxiv.org/abs/2303.15786",
    "authors": [
      "Shan Ning",
      "Longtian Qiu",
      "Yongfei Liu",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16166",
    "title": "Reproducibility is Nothing without Correctness: The Importance of  Testing Code in NLP",
    "abstract": " Title: Reproducibility is Nothing without Correctness: The Importance of  Testing Code in NLP ",
    "url": "https://arxiv.org/abs/2303.16166",
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Andrea Pilzer",
      "Matteo Negri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.16191",
    "title": "Hard Nominal Example-aware Template Mutual Matching for Industrial  Anomaly Detection",
    "abstract": " Title: Hard Nominal Example-aware Template Mutual Matching for Industrial  Anomaly Detection ",
    "url": "https://arxiv.org/abs/2303.16191",
    "authors": [
      "Zixuan Chen",
      "Xiaohua Xie",
      "Lingxiao Yang",
      "jianhuang Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]