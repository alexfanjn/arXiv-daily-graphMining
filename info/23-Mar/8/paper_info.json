[
  {
    "id": "arXiv:2303.03387",
    "title": "CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a  Context Synergized Hyperbolic Network",
    "abstract": "The tremendous growth of social media users interacting in online conversations has also led to significant growth in hate speech. Most of the prior works focus on detecting explicit hate speech, which is overt and leverages hateful phrases, with very little work focusing on detecting hate speech that is implicit or denotes hatred through indirect or coded language. In this paper, we present CoSyn, a user- and conversational-context synergized network for detecting implicit hate speech in online conversation trees. CoSyn first models the user's personal historical and social context using a novel hyperbolic Fourier attention mechanism and hyperbolic graph convolution network. Next, we jointly model the user's personal context and the conversational context using a novel context interaction mechanism in the hyperbolic space that clearly captures the interplay between the two and makes independent assessments on the amounts of information to be retrieved from both contexts. CoSyn performs all operations in the hyperbolic space to account for the scale-free dynamics of social media. We demonstrate the effectiveness of CoSyn both qualitatively and quantitatively on an open-source hate speech dataset with Twitter conversations and show that CoSyn outperforms all our baselines in detecting implicit hate speech with absolute improvements in the range of 8.15% - 19.50%. ",
    "url": "https://arxiv.org/abs/2303.03387",
    "authors": [
      "Sreyan Ghosh",
      "Manan Suri",
      "Purva Chiniya",
      "Utkarsh Tyagi",
      "Sonal Kumar",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.03388",
    "title": "Multi-modal Multi-kernel Graph Learning for Autism Prediction and  Biomarker Discovery",
    "abstract": "Multi-modal integration and classification based on graph learning is among the most challenging obstacles in disease prediction due to its complexity. Several recent works on the basis of attentional mechanisms have been proposed to disentangle the problem of multi-modal integration. However, there are certain limitations to these techniques. Primarily, these works focus on explicitly integrating at the feature level using weight scores, which cannot effectively address the negative impact between modalities. Next, a majority of them utilize single-sized filters to extract graph features, ignoring the heterogeneous information over graphs. To overcome these drawbacks, we propose MMKGL (Multi-modal Multi-Kernel Graph Learning). For the problem of negative impact between modalities, we use the multi-modal graph embedding module to construct a multi-modal graph. Different from the traditional manual construction of static graphs, a separate graph is generated for each modality by graph adaptive learning, where a function graph and a supervision graph are introduced for optimiztion during the multi-graph fusion embedding process. We then apply the multi-kernel graph learning module to extract heterogeneous information from the multi-modal graph. The information in the multi-modal graph at different levels is aggregated by convolutional kernels with different receptive field sizes, followed by generating a cross-kernel discovery tensor for disease prediction. Our method is evaluated on the benchmark Autism Brain Imaging Data Exchange (ABIDE) dataset and outperforms the state-of-the-art methods. In addition, discriminative brain regions associated with autism are identified by our model, providing guidance for the study of autism pathology. ",
    "url": "https://arxiv.org/abs/2303.03388",
    "authors": [
      "Junbin Mao",
      "Jin Liu",
      "Hanhe Lin",
      "Hulin Kuang",
      "Yi Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03393",
    "title": "Interpretable Architecture Neural Networks for Function Visualization",
    "abstract": "In many scientific research fields, understanding and visualizing a black-box function in terms of the effects of all the input variables is of great importance. Existing visualization tools do not allow one to visualize the effects of all the input variables simultaneously. Although one can select one or two of the input variables to visualize via a 2D or 3D plot while holding other variables fixed, this presents an oversimplified and incomplete picture of the model. To overcome this shortcoming, we present a new visualization approach using an interpretable architecture neural network (IANN) to visualize the effects of all the input variables directly and simultaneously. We propose two interpretable structures, each of which can be conveniently represented by a specific IANN, and we discuss a number of possible extensions. We also provide a Python package to implement our proposed method. The supplemental materials are available online. ",
    "url": "https://arxiv.org/abs/2303.03393",
    "authors": [
      "Shengtong Zhang",
      "Daniel W. Apley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03395",
    "title": "Demonstration-guided Deep Reinforcement Learning for Coordinated Ramp  Metering and Perimeter Control in Large Scale Networks",
    "abstract": "Effective traffic control methods have great potential in alleviating network congestion. Existing literature generally focuses on a single control approach, while few studies have explored the effectiveness of integrated and coordinated control approaches. This study considers two representative control approaches: ramp metering for freeways and perimeter control for homogeneous urban roads, and we aim to develop a deep reinforcement learning (DRL)-based coordinated control framework for large-scale networks. The main challenges are 1) there is a lack of efficient dynamic models for both freeways and urban roads; 2) the standard DRL method becomes ineffective due to the complex and non-stationary network dynamics. In view of this, we propose a novel meso-macro dynamic network model and first time develop a demonstration-guided DRL method to achieve large-scale coordinated ramp metering and perimeter control. The dynamic network model hybridizes the link and generalized bathtub models to depict the traffic dynamics of freeways and urban roads, respectively. For the DRL method, we incorporate demonstration to guide the DRL method for better convergence by introducing the concept of \"teacher\" and \"student\" models. The teacher models are traditional controllers (e.g., ALINEA, Gating), which provide control demonstrations. The student models are DRL methods, which learn from the teacher and aim to surpass the teacher's performance. To validate the proposed framework, we conduct two case studies in a small-scale network and a real-world large-scale traffic network in Hong Kong. The research outcome reveals the great potential of combining traditional controllers with DRL for coordinated control in large-scale networks. ",
    "url": "https://arxiv.org/abs/2303.03395",
    "authors": [
      "Zijian Hu",
      "Wei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.03398",
    "title": "Acceleration of a production Solar MHD code with Fortran standard  parallelism: From OpenACC to `do concurrent'",
    "abstract": "There is growing interest in using standard language constructs for accelerated computing, avoiding the need for (often vendor-specific) external APIs. These constructs hold the potential to be more portable and much more `future-proof'. For Fortran codes, the current focus is on the {\\tt do concurrent} (DC) loop. While there have been some successful examples of GPU-acceleration using DC for benchmark and/or small codes, its widespread adoption will require demonstrations of its use in full-size applications. Here, we look at the current capabilities and performance of using DC in a production application called Magnetohydrodynamic Algorithm outside a Sphere (MAS). MAS is a state-of-the-art model for studying coronal and heliospheric dynamics, is over 70,000 lines long, and has previously been ported to GPUs using MPI+OpenACC. We attempt to eliminate as many of its OpenACC directives as possible in favor of DC. We show that using the NVIDIA {\\tt nvfortran} compiler's Fortran 202X preview implementation, unified managed memory, and modified MPI launch methods, we can achieve GPU acceleration across multiple GPUs without using a single OpenACC directive. However, doing so results in a slowdown between 1.25x and 3x. We discuss what future improvements are needed to avoid this loss, and show how we can still retain close ",
    "url": "https://arxiv.org/abs/2303.03398",
    "authors": [
      "Ronald M. Caplan",
      "Miko M. Stulajter",
      "Jon A. Linker"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2303.03400",
    "title": "Testing the Channels of Convolutional Neural Networks",
    "abstract": "Neural networks have complex structures, and thus it is hard to understand their inner workings and ensure correctness. To understand and debug convolutional neural networks (CNNs) we propose techniques for testing the channels of CNNs. We design FtGAN, an extension to GAN, that can generate test data with varying the intensity (i.e., sum of the neurons) of a channel of a target CNN. We also proposed a channel selection algorithm to find representative channels for testing. To efficiently inspect the target CNN's inference computations, we define unexpectedness score, which estimates how similar the inference computation of the test data is to that of the training data. We evaluated FtGAN with five public datasets and showed that our techniques successfully identify defective channels in five different CNN models. ",
    "url": "https://arxiv.org/abs/2303.03400",
    "authors": [
      "Kang Choi",
      "Donghyun Son",
      "Younghoon Kim",
      "Jiwon Seo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.03402",
    "title": "A comparative study on different neural network architectures to model  inelasticity",
    "abstract": "The mathematical formulation of constitutive models to describe the path-dependent, i.e., inelastic, behavior of materials is a challenging task and has been a focus in mechanics research for several decades. There have been increased efforts to facilitate or automate this task through data-driven techniques, impelled in particular by the recent revival of neural networks (NNs) in computational mechanics. However, it seems questionable to simply not consider fundamental findings of constitutive modeling originating from the last decades research within NN-based approaches. Herein, we propose a comparative study on different feedforward and recurrent neural network architectures to model inelasticity. Within this study, we divide the models into three basic classes: black box NNs, NNs enforcing physics in a weak form, and NNs enforcing physics in a strong form. Thereby, the first class of networks can learn constitutive relations from data while the underlying physics are completely ignored, whereas the latter two are constructed such that they can account for fundamental physics, where special attention is paid to the second law of thermodynamics in this work. Conventional linear and nonlinear viscoelastic as well as elastoplastic models are used for training data generation and, later on, as reference. After training with random walk time sequences containing information on stress, strain, and, for some models, internal variables, the NN-based models are compared to the reference solution, whereby interpolation and extrapolation are considered. Besides the quality of the stress prediction, the related free energy and dissipation rate are analyzed to evaluate the models. Overall, the presented study enables a clear recording of the advantages and disadvantages of different NN architectures to model inelasticity and gives guidance on how to train and apply these models. ",
    "url": "https://arxiv.org/abs/2303.03402",
    "authors": [
      "Max Rosenkranz",
      "Karl A. Kalina",
      "J\u00f6rg Brummund",
      "Markus K\u00e4stner"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.03405",
    "title": "Neural Style Transfer for Vector Graphics",
    "abstract": "Neural style transfer draws researchers' attention, but the interest focuses on bitmap images. Various models have been developed for bitmap image generation both online and offline with arbitrary and pre-trained styles. However, the style transfer between vector images has not almost been considered. Our research shows that applying standard content and style losses insignificantly changes the vector image drawing style because the structure of vector primitives differs a lot from pixels. To handle this problem, we introduce new loss functions. We also develop a new method based on differentiable rasterization that uses these loss functions and can change the color and shape parameters of the content image corresponding to the drawing of the style image. Qualitative experiments demonstrate the effectiveness of the proposed VectorNST method compared with the state-of-the-art neural style transfer approaches for bitmap images and the only existing approach for stylizing vector images, DiffVG. Although the proposed model does not achieve the quality and smoothness of style transfer between bitmap images, we consider our work an important early step in this area. VectorNST code and demo service are available at https://github.com/IzhanVarsky/VectorNST. ",
    "url": "https://arxiv.org/abs/2303.03405",
    "authors": [
      "Valeria Efimova",
      "Artyom Chebykin",
      "Ivan Jarsky",
      "Evgenii Prosvirnin",
      "Andrey Filchenkov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03457",
    "title": "Spelling convention sensitivity in neural language models",
    "abstract": "We examine whether large neural language models, trained on very large collections of varied English text, learn the potentially long-distance dependency of British versus American spelling conventions, i.e., whether spelling is consistently one or the other within model-generated strings. In contrast to long-distance dependencies in non-surface underlying structure (e.g., syntax), spelling consistency is easier to measure both in LMs and the text corpora used to train them, which can provide additional insight into certain observed model behaviors. Using a set of probe words unique to either British or American English, we first establish that training corpora exhibit substantial (though not total) consistency. A large T5 language model does appear to internalize this consistency, though only with respect to observed lexical items (not nonce words with British/American spelling patterns). We further experiment with correcting for biases in the training data by fine-tuning T5 on synthetic data that has been debiased, and find that finetuned T5 remains only somewhat sensitive to spelling consistency. Further experiments show GPT2 to be similarly limited. ",
    "url": "https://arxiv.org/abs/2303.03457",
    "authors": [
      "Elizabeth Nielsen",
      "Christo Kirov",
      "Brian Roark"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.03470",
    "title": "Securing Autonomous Vehicles Under Partial-Information Cyber Attacks on  LiDAR Data",
    "abstract": "Safety is paramount in autonomous vehicles (AVs). Auto manufacturers have spent millions of dollars and driven billions of miles to prove AVs are safe. However, this is ill-suited to answer: what happens to an AV if its data are adversarially compromised? We design a framework built on security-relevant metrics to benchmark AVs on longitudinal datasets. We establish the capabilities of a cyber-level attacker with only access to LiDAR datagrams and from them derive novel attacks on LiDAR. We demonstrate that even though the attacker has minimal knowledge and only access to raw datagrams, the attacks compromise perception and tracking in multi-sensor AVs and lead to objectively unsafe scenarios. To mitigate vulnerabilities and advance secure architectures in AVs, we present two improvements for security-aware fusion -- a data-asymmetry monitor and a scalable track-to-track fusion of 3D LiDAR and monocular detections (T2T-3DLM); we demonstrate that the approaches significantly reduce the attack effectiveness. ",
    "url": "https://arxiv.org/abs/2303.03470",
    "authors": [
      "R. Spencer Hallyburton",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.03487",
    "title": "Two-stage Pipeline for Multilingual Dialect Detection",
    "abstract": "Dialect Identification is a crucial task for localizing various Large Language Models. This paper outlines our approach to the VarDial 2023 shared task. Here we have to identify three or two dialects from three languages each which results in a 9-way classification for Track-1 and 6-way classification for Track-2 respectively. Our proposed approach consists of a two-stage system and outperforms other participants' systems and previous works in this domain. We achieve a score of 58.54% for Track-1 and 85.61% for Track-2. Our codebase is available publicly (https://github.com/ankit-vaidya19/EACL_VarDial2023). ",
    "url": "https://arxiv.org/abs/2303.03487",
    "authors": [
      "Ankit Vaidya",
      "Aditya Kane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03488",
    "title": "A Comparison of Methods for Neural Network Aggregation",
    "abstract": "Deep learning has been successful in the theoretical aspect. For deep learning to succeed in industry, we need to have algorithms capable of handling many inconsistencies appearing in real data. These inconsistencies can have large effects on the implementation of a deep learning algorithm. Artificial Intelligence is currently changing the medical industry. However, receiving authorization to use medical data for training machine learning algorithms is a huge hurdle. A possible solution is sharing the data without sharing the patient information. We propose a multi-party computation protocol for the deep learning algorithm. The protocol enables to conserve both the privacy and the security of the training data. Three approaches of neural networks assembly are analyzed: transfer learning, average ensemble learning, and series network learning. The results are compared to approaches based on data-sharing in different experiments. We analyze the security issues of the proposed protocol. Although the analysis is based on medical data, the results of multi-party computation of machine learning training are theoretical and can be implemented in multiple research areas. ",
    "url": "https://arxiv.org/abs/2303.03488",
    "authors": [
      "John Pomerat",
      "Aviv Segev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03492",
    "title": "A Security-aware Network Function Sharing Model for 5G Slicing",
    "abstract": "Sharing Virtualized Network Functions (VNFs) among different slices in Fifth Generation (5G) is a potential strategy to simplify the system implementation and utilize 5G resources efficiently. In this paper, we propose a security-aware VNF sharing model for 5G networks. The proposed optimization model satisfies the service requirements of various slices, enhances slice security by isolating their critical VNFs, and enhances resource utilization of the underlying physical infrastructure. The model tries to systematically decide on sharing a particular VNF based on two groups of constraints; the first group of constraints is common assignment constraints used in the existing literature. The second group is the novel security constraints that we propose in this work; the maximum traffic allowed to be processed by the VNF and the exposure of the VNF to procedures sourced via untrusted users or access networks. This sharing problem is formalized to allow for procedure-level modeling that satisfies the requirements of slice requests in 5G systems. The model is tested using standard VNFs and procedures of the 5G system rather than generic ones. The numerical results of the model show the benefits and costs of applying the security constraints along with the network performance in terms of different metrics. ",
    "url": "https://arxiv.org/abs/2303.03492",
    "authors": [
      "Mohammed Mahyoub",
      "AbdulAziz AbdulGhaffar",
      "Emmanuel Alalade",
      "Ashraf Matrawy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.03496",
    "title": "Wind Turbine Gearbox Fault Detection Based on Sparse Filtering and Graph  Neural Networks",
    "abstract": "The wind energy industry has been experiencing tremendous growth and confronting the failures of wind turbine components. Wind turbine gearbox malfunctions are particularly prevalent and lead to the most prolonged downtime and highest cost. This paper presents a data-driven gearbox fault detection algorithm base on high frequency vibration data using graph neural network (GNN) models and sparse filtering (SF). The approach can take advantage of the comprehensive data sources and the complicated sensing networks. The GNN models, including basic graph neural networks, gated graph neural networks, and gated graph sequential neural networks, are used to detect gearbox condition from knowledge-based graphs formed using wind turbine information. Sparse filtering is used as an unsupervised feature learning method to accelerate the training of the GNN models. The effectiveness of the proposed method was verified on practical experimental data. ",
    "url": "https://arxiv.org/abs/2303.03496",
    "authors": [
      "Jinsong Wang",
      "Kenneth A. Loparo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.03508",
    "title": "Memory Maps for Video Object Detection and Tracking on UAVs",
    "abstract": "This paper introduces a novel approach to video object detection detection and tracking on Unmanned Aerial Vehicles (UAVs). By incorporating metadata, the proposed approach creates a memory map of object locations in actual world coordinates, providing a more robust and interpretable representation of object locations in both, image space and the real world. We use this representation to boost confidences, resulting in improved performance for several temporal computer vision tasks, such as video object detection, short and long-term single and multi-object tracking, and video anomaly detection. These findings confirm the benefits of metadata in enhancing the capabilities of UAVs in the field of temporal computer vision and pave the way for further advancements in this area. ",
    "url": "https://arxiv.org/abs/2303.03508",
    "authors": [
      "Benjamin Kiefer",
      "Yitong Quan",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.03510",
    "title": "Guilt Detection in Text: A Step Towards Understanding Complex Emotions",
    "abstract": "We introduce a novel Natural Language Processing (NLP) task called Guilt detection, which focuses on detecting guilt in text. We identify guilt as a complex and vital emotion that has not been previously studied in NLP, and we aim to provide a more fine-grained analysis of it. To address the lack of publicly available corpora for guilt detection, we created VIC, a dataset containing 4622 texts from three existing emotion detection datasets that we binarized into guilt and no-guilt classes. We experimented with traditional machine learning methods using bag-of-words and term frequency-inverse document frequency features, achieving a 72% f1 score with the highest-performing model. Our study provides a first step towards understanding guilt in text and opens the door for future research in this area. ",
    "url": "https://arxiv.org/abs/2303.03510",
    "authors": [
      "Abdul Gafar Manuel Meque",
      "Nisar Hussain",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.03535",
    "title": "Exploration of For-Purpose Decentralized Algorithmic Cyber Attacks in EV  Charging Control",
    "abstract": "Distributed and decentralized multi-agent optimization (DMAO) algorithms enable the control of large-scale grid-edge resources, such as electric vehicles (EV), to provide power grid services. Despite its great scalability, DMAO is fundamentally prone to cyber attacks as it is highly dependent on frequent peer-to-peer communications. Existing cyber-security research in this regard mainly focuses on \\emph{broad-spectrum} attacks aiming at jeopardizing the entire control system while losing the possibility of achieving specific attacking purposes. This paper, for the first time, explores novel \\emph{for-purpose} algorithmic attacks that are launched by participating agents and interface with DMAO to achieve self-interest attack purposes. A decentralized EV charging control problem is formulated as an illustrative use case. Theoretical \\emph{for-purpose} attack vectors with and without the stealthy feature are devised. Simulations on EV charging control show the practicability of the proposed algorithmic \\emph{for-purpose} attacks and the impacts of such attacks on distribution networks. ",
    "url": "https://arxiv.org/abs/2303.03535",
    "authors": [
      "Mahan Fakouri Fard",
      "Xiang Hou",
      "Mingxi Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.03538",
    "title": "Evolutionary Deep Nets for Non-Intrusive Load Monitoring",
    "abstract": "Non-Intrusive Load Monitoring (NILM) is an energy efficiency technique to track electricity consumption of an individual appliance in a household by one aggregated single, such as building level meter readings. The goal of NILM is to disaggregate the appliance from the aggregated singles by computational method. In this work, deep learning approaches are implemented to operate the desegregations. Deep neural networks, convolutional neural networks, and recurrent neural networks are employed for this operation. Additionally, sparse evolutionary training is applied to accelerate training efficiency of each deep learning model. UK-Dale dataset is used for this work. ",
    "url": "https://arxiv.org/abs/2303.03538",
    "authors": [
      "Jinsong Wang",
      "Kenneth A. Loparo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.03544",
    "title": "Expressivity of Shallow and Deep Neural Networks for Polynomial  Approximation",
    "abstract": "We analyze the number of neurons that a ReLU neural network needs to approximate multivariate monomials. We establish an exponential lower bound for the complexity of any shallow network that approximates the product function $\\vec{x} \\to \\prod_{i=1}^d x_i$ on a general compact domain. Furthermore, we prove that this lower bound does not hold for normalized O(1)-Lipschitz monomials (or equivalently, by restricting to the unit cube). These results suggest shallow ReLU networks suffer from the curse of dimensionality when expressing functions with a Lipschitz parameter scaling with the dimension of the input, and that the expressive power of neural networks lies in their depth rather than the overall complexity. ",
    "url": "https://arxiv.org/abs/2303.03544",
    "authors": [
      "Itai Shapira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03549",
    "title": "Optimal Engagement-Diversity Tradeoffs in Social Media",
    "abstract": "Social media platforms are known to optimize user engagement with the help of algorithms. It is widely understood that this practice gives rise to echo chambers\\emdash users are mainly exposed to opinions that are similar to their own. In this paper, we ask whether echo chambers are an inevitable result of high engagement; we address this question in a novel model. Our main theoretical results establish bounds on the maximum engagement achievable under a diversity constraint, for suitable measures of engagement and diversity; we can therefore quantify the worst-case tradeoff between these two objectives. Our empirical results, based on real data from Twitter, chart the Pareto frontier of the engagement-diversity tradeoff. ",
    "url": "https://arxiv.org/abs/2303.03549",
    "authors": [
      "Fabian Baumann",
      "Daniel Halpern",
      "Ariel D. Procaccia",
      "Iyad Rahwan",
      "Itai Shapira",
      "Manuel Wuthrich"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2303.03553",
    "title": "Robust Dominant Periodicity Detection for Time Series with Missing Data",
    "abstract": "Periodicity detection is an important task in time series analysis, but still a challenging problem due to the diverse characteristics of time series data like abrupt trend change, outlier, noise, and especially block missing data. In this paper, we propose a robust and effective periodicity detection algorithm for time series with block missing data. We first design a robust trend filter to remove the interference of complicated trend patterns under missing data. Then, we propose a robust autocorrelation function (ACF) that can handle missing values and outliers effectively. We rigorously prove that the proposed robust ACF can still work well when the length of the missing block is less than $1/3$ of the period length. Last, by combining the time-frequency information, our algorithm can generate the period length accurately. The experimental results demonstrate that our algorithm outperforms existing periodicity detection algorithms on real-world time series datasets. ",
    "url": "https://arxiv.org/abs/2303.03553",
    "authors": [
      "Qingsong Wen",
      "Linxiao Yang",
      "Liang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2303.03565",
    "title": "CLIP-Layout: Style-Consistent Indoor Scene Synthesis with Semantic  Furniture Embedding",
    "abstract": "Indoor scene synthesis involves automatically picking and placing furniture appropriately on a floor plan, so that the scene looks realistic and is functionally plausible. Such scenes can serve as a home for immersive 3D experiences, or be used to train embodied agents. Existing methods for this task rely on labeled categories of furniture, e.g. bed, chair or table, to generate contextually relevant combinations of furniture. Whether heuristic or learned, these methods ignore instance-level attributes of objects such as color and style, and as a result may produce visually less coherent scenes. In this paper, we introduce an auto-regressive scene model which can output instance-level predictions, making use of general purpose image embedding based on CLIP. This allows us to learn visual correspondences such as matching color and style, and produce more plausible and aesthetically pleasing scenes. Evaluated on the 3D-FRONT dataset, our model achieves SOTA results in scene generation and improves auto-completion metrics by over 50%. Moreover, our embedding-based approach enables zero-shot text-guided scene generation and editing, which easily generalizes to furniture not seen at training time. ",
    "url": "https://arxiv.org/abs/2303.03565",
    "authors": [
      "Jingyu Liu",
      "Wenhan Xiong",
      "Ian Jones",
      "Yixin Nie",
      "Anchit Gupta",
      "Barlas O\u011fuz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03572",
    "title": "Learning When to Treat Business Processes: Prescriptive Process  Monitoring with Causal Inference and Reinforcement Learning",
    "abstract": "Increasing the success rate of a process, i.e. the percentage of cases that end in a positive outcome, is a recurrent process improvement goal. At runtime, there are often certain actions (a.k.a. treatments) that workers may execute to lift the probability that a case ends in a positive outcome. For example, in a loan origination process, a possible treatment is to issue multiple loan offers to increase the probability that the customer takes a loan. Each treatment has a cost. Thus, when defining policies for prescribing treatments to cases, managers need to consider the net gain of the treatments. Also, the effect of a treatment varies over time: treating a case earlier may be more effective than later in a case. This paper presents a prescriptive monitoring method that automates this decision-making task. The method combines causal inference and reinforcement learning to learn treatment policies that maximize the net gain. The method leverages a conformal prediction technique to speed up the convergence of the reinforcement learning mechanism by separating cases that are likely to end up in a positive or negative outcome, from uncertain cases. An evaluation on two real-life datasets shows that the proposed method outperforms a state-of-the-art baseline. ",
    "url": "https://arxiv.org/abs/2303.03572",
    "authors": [
      "Zahra Dasht Bozorgi",
      "Marlon Dumas",
      "Marcello La Rosa",
      "Artem Polyvyanyy",
      "Mahmoud Shoush",
      "Irene Teinemaa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.03581",
    "title": "Neural Compositional Rule Learning for Knowledge Graph Reasoning",
    "abstract": "Learning logical rules is critical to improving reasoning in KGs. This is due to their ability to provide logical and interpretable explanations when used for predictions, as well as their ability to generalize to other tasks, domains, and data. While recent methods have been proposed to learn logical rules, the majority of these methods are either restricted by their computational complexity and can not handle the large search space of large-scale KGs, or show poor generalization when exposed to data outside the training set. In this paper, we propose an end-to-end neural model for learning compositional logical rules called NCRL. NCRL detects the best compositional structure of a rule body, and breaks it into small compositions in order to infer the rule head. By recurrently merging compositions in the rule body with a recurrent attention unit, NCRL finally predicts a single rule head. Experimental results show that NCRL learns high-quality rules, as well as being generalizable. Specifically, we show that NCRL is scalable, efficient, and yields state-of-the-art results for knowledge graph completion on large-scale KGs. Moreover, we test NCRL for systematic generalization by learning to reason on small-scale observed graphs and evaluating on larger unseen ones. ",
    "url": "https://arxiv.org/abs/2303.03581",
    "authors": [
      "Kewei Cheng",
      "Nesreen K. Ahmed",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03583",
    "title": "Calibration-free BEV Representation for Infrastructure Perception",
    "abstract": "Effective BEV object detection on infrastructure can greatly improve traffic scenes understanding and vehicle-toinfrastructure (V2I) cooperative perception. However, cameras installed on infrastructure have various postures, and previous BEV detection methods rely on accurate calibration, which is difficult for practical applications due to inevitable natural factors (e.g., wind and snow). In this paper, we propose a Calibration-free BEV Representation (CBR) network, which achieves 3D detection based on BEV representation without calibration parameters and additional depth supervision. Specifically, we utilize two multi-layer perceptrons for decoupling the features from perspective view to front view and birdeye view under boxes-induced foreground supervision. Then, a cross-view feature fusion module matches features from orthogonal views according to similarity and conducts BEV feature enhancement with front view features. Experimental results on DAIR-V2X demonstrate that CBR achieves acceptable performance without any camera parameters and is naturally not affected by calibration noises. We hope CBR can serve as a baseline for future research addressing practical challenges of infrastructure perception. ",
    "url": "https://arxiv.org/abs/2303.03583",
    "authors": [
      "Siqi Fan",
      "Zhe Wang",
      "Xiaoliang Huo",
      "Yan Wang",
      "Jingjing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03591",
    "title": "Approach to Learning Generalized Audio Representation Through Batch  Embedding Covariance Regularization and Constant-Q Transforms",
    "abstract": "General-purpose embedding is highly desirable for few-shot even zero-shot learning in many application scenarios, including audio tasks. In order to understand representations better, we conducted a thorough error analysis and visualization of HEAR 2021 submission results. Inspired by the analysis, this work experiments with different front-end audio preprocessing methods, including Constant-Q Transform (CQT) and Short-time Fourier transform (STFT), and proposes a Batch Embedding Covariance Regularization (BECR) term to uncover a more holistic simulation of the frequency information received by the human auditory system. We tested the models on the suite of HEAR 2021 tasks, which encompass a broad category of tasks. Preliminary results show (1) the proposed BECR can incur a more dispersed embedding on the test set, (2) BECR improves the PaSST model without extra computation complexity, and (3) STFT preprocessing outperforms CQT in all tasks we tested. Github:https://github.com/ankitshah009/general_audio_embedding_hear_2021 ",
    "url": "https://arxiv.org/abs/2303.03591",
    "authors": [
      "Ankit Shah",
      "Shuyi Chen",
      "Kejun Zhou",
      "Yue Chen",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.03592",
    "title": "Exploring the Limits of Indiscriminate Data Poisoning Attacks",
    "abstract": "Indiscriminate data poisoning attacks aim to decrease a model's test accuracy by injecting a small amount of corrupted training data. Despite significant interest, existing attacks remain relatively ineffective against modern machine learning (ML) architectures. In this work, we introduce the notion of model poisonability as a technical tool to explore the intrinsic limits of data poisoning attacks. We derive an easily computable threshold to establish and quantify a surprising phase transition phenomenon among popular ML models: data poisoning attacks become effective only when the poisoning ratio exceeds our threshold. Building on existing parameter corruption attacks and refining the Gradient Canceling attack, we perform extensive experiments to confirm our theoretical findings, test the predictability of our transition threshold, and significantly improve existing data poisoning baselines over a range of datasets and models. Our work highlights the critical role played by the poisoning ratio, and sheds new insights on existing empirical results, attacks and mitigation strategies in data poisoning. ",
    "url": "https://arxiv.org/abs/2303.03592",
    "authors": [
      "Yiwei Lu",
      "Gautam Kamth",
      "Yaoliang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.03595",
    "title": "LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global  Cross-Modal Fusion",
    "abstract": "LiDAR-camera fusion methods have shown impressive performance in 3D object detection. Recent advanced multi-modal methods mainly perform global fusion, where image features and point cloud features are fused across the whole scene. Such practice lacks fine-grained region-level information, yielding suboptimal fusion performance. In this paper, we present the novel Local-to-Global fusion network (LoGoNet), which performs LiDAR-camera fusion at both local and global levels. Concretely, the Global Fusion (GoF) of LoGoNet is built upon previous literature, while we exclusively use point centroids to more precisely represent the position of voxel features, thus achieving better cross-modal alignment. As to the Local Fusion (LoF), we first divide each proposal into uniform grids and then project these grid centers to the images. The image features around the projected grid points are sampled to be fused with position-decorated point cloud features, maximally utilizing the rich contextual information around the proposals. The Feature Dynamic Aggregation (FDA) module is further proposed to achieve information interaction between these locally and globally fused features, thus producing more informative multi-modal features. Extensive experiments on both Waymo Open Dataset (WOD) and KITTI datasets show that LoGoNet outperforms all state-of-the-art 3D detection methods. Notably, LoGoNet ranks 1st on Waymo 3D object detection leaderboard and obtains 81.02 mAPH (L2) detection performance. It is noteworthy that, for the first time, the detection performance on three classes surpasses 80 APH (L2) simultaneously. Code will be available at \\url{https://github.com/sankin97/LoGoNet}. ",
    "url": "https://arxiv.org/abs/2303.03595",
    "authors": [
      "Xin Li",
      "Tao Ma",
      "Yuenan Hou",
      "Botian Shi",
      "Yucheng Yang",
      "Youquan Liu",
      "Xingjiao Wu",
      "Qin Chen",
      "Yikang Li",
      "Yu Qiao",
      "Liang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03611",
    "title": "TinyAD: Memory-efficient anomaly detection for time series data in  Industrial IoT",
    "abstract": "Monitoring and detecting abnormal events in cyber-physical systems is crucial to industrial production. With the prevalent deployment of the Industrial Internet of Things (IIoT), an enormous amount of time series data is collected to facilitate machine learning models for anomaly detection, and it is of the utmost importance to directly deploy the trained models on the IIoT devices. However, it is most challenging to deploy complex deep learning models such as Convolutional Neural Networks (CNNs) on these memory-constrained IIoT devices embedded with microcontrollers (MCUs). To alleviate the memory constraints of MCUs, we propose a novel framework named Tiny Anomaly Detection (TinyAD) to efficiently facilitate onboard inference of CNNs for real-time anomaly detection. First, we conduct a comprehensive analysis of depthwise separable CNNs and regular CNNs for anomaly detection and find that the depthwise separable convolution operation can reduce the model size by 50-90% compared with the traditional CNNs. Then, to reduce the peak memory consumption of CNNs, we explore two complementary strategies, in-place, and patch-by-patch memory rescheduling, and integrate them into a unified framework. The in-place method decreases the peak memory of the depthwise convolution by sparing a temporary buffer to transfer the activation results, while the patch-by-patch method further reduces the peak memory of layer-wise execution by slicing the input data into corresponding receptive fields and executing in order. Furthermore, by adjusting the dimension of convolution filters, these strategies apply to both univariate time series and multidomain time series features. Extensive experiments on real-world industrial datasets show that our framework can reduce peak memory consumption by 2-5x with negligible computation overhead. ",
    "url": "https://arxiv.org/abs/2303.03611",
    "authors": [
      "Yuting Sun",
      "Tong Chen",
      "Quoc Viet Hung Nguyen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03614",
    "title": "A Fast Insertion Operator for Ridesharing over Time-Dependent Road  Networks",
    "abstract": "Ridesharing has become a promising travel mode recently due to the economic and social benefits. As an essential operator, \"insertion operator\" has been extensively studied over static road networks. When a new request appears, the insertion operator is used to find the optimal positions of a worker's current route to insert the origin and destination of this request and minimize the travel time of this worker. Previous works study how to conduct the insertion operation efficiently in static road networks, however, in reality, the route planning should be addressed by considering the dynamic traffic scenario (i.e., a time-dependent road network). Unfortunately, existing solutions to the insertion operator become in efficient under this setting. Thus, this paper studies the insertion operator over time-dependent road networks. Specially, to reduce the high time complexity $O(n^3)$ of existing solution, we calculate the compound travel time functions along the route to speed up the calculation of the travel time between vertex pairs belonging to the route, as a result time complexity of an insertion can be reduced to $O(n^2)$. Finally, we further improve the method to a linear-time insertion algorithm by showing that it only needs $O(1)$ time to find the best position of current route to insert the origin when linearly enumerating each possible position for the new request's destination. Evaluations on two real-world and large-scale datasets show that our methods can accelerate the existing insertion algorithm by up to 25 times. ",
    "url": "https://arxiv.org/abs/2303.03614",
    "authors": [
      "Zengyang Gong",
      "Yuxiang Zeng",
      "Lei Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2303.03616",
    "title": "Geometry-Aware Coverage Path Planning on Complex 3D Surfaces",
    "abstract": "This paper presents a new approach to obtaining nearly complete coverage paths (CP) with low overlapping on 3D general surfaces using mesh models given or reconstructed from actual scenes. The CP is obtained by segmenting the mesh model into a given number of clusters using constrained centroidal Voronoi tessellation (CCVT) and finding the shortest path from cluster centroids using the geodesic metric efficiently. We introduce a new cost function to harmoniously achieve uniform areas of the obtained clusters and a restriction on the variation of triangle normals during the construction of CCVTs. The obtained clusters can be used to construct high-quality viewpoints (VP) for visual coverage tasks. Here, we utilize the planned VPs as cleaning configurations to perform residual powder removal in additive manufacturing using manipulator robots. The self-occlusion of VPs and ensuring collision-free robot configurations are addressed by integrating a proposed optimization-based strategy to find a set of candidate rays for each VP into the motion planning phase. CP planning benchmarks and physical experiments are conducted to demonstrate the effectiveness of the proposed approach. We show that our approach can compute the CPs and VPs of various mesh models with a massive number of triangles within a reasonable time. ",
    "url": "https://arxiv.org/abs/2303.03616",
    "authors": [
      "Van-Thach Do",
      "Quang-Cuong Pham"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.03617",
    "title": "Computing Effective Resistances on Large Graphs Based on Approximate  Inverse of Cholesky Factor",
    "abstract": "Effective resistance, which originates from the field of circuits analysis, is an important graph distance in spectral graph theory. It has found numerous applications in various areas, such as graph data mining, spectral graph sparsification, circuits simulation, etc. However, computing effective resistances accurately can be intractable and we still lack efficient methods for estimating effective resistances on large graphs. In this work, we propose an efficient algorithm to compute effective resistances on general weighted graphs, based on a sparse approximate inverse technique. Compared with a recent competitor, the proposed algorithm shows several hundreds of speedups and also one to two orders of magnitude improvement in the accuracy of results. Incorporating the proposed algorithm with the graph sparsification based power grid (PG) reduction framework, we develop a fast PG reduction method, which achieves an average 6.4X speedup in the reduction time without loss of reduction accuracy. In the applications of power grid transient analysis and DC incremental analysis, the proposed method enables 1.7X and 2.5X speedup of overall time compared to using the PG reduction based on accurate effective resistances, without increase in the error of solution. ",
    "url": "https://arxiv.org/abs/2303.03617",
    "authors": [
      "Zhiqiang Liu",
      "Wenjian Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.03654",
    "title": "MPool: Motif-Based Graph Pooling",
    "abstract": "Graph Neural networks (GNNs) have recently become a powerful technique for many graph-related tasks including graph classification. Current GNN models apply different graph pooling methods that reduce the number of nodes and edges to learn the higher-order structure of the graph in a hierarchical way. All these methods primarily rely on the one-hop neighborhood. However, they do not consider the higher- order structure of the graph. In this work, we propose a multi-channel Motif-based Graph Pooling method named (MPool) captures the higher-order graph structure with motif and local and global graph structure with a combination of selection and clustering-based pooling operations. As the first channel, we develop node selection-based graph pooling by designing a node ranking model considering the motif adjacency of nodes. As the second channel, we develop cluster-based graph pooling by designing a spectral clustering model using motif adjacency. As the final layer, the result of each channel is aggregated into the final graph representation. We perform extensive experiments on eight benchmark datasets and show that our proposed method shows better accuracy than the baseline methods for graph classification tasks. ",
    "url": "https://arxiv.org/abs/2303.03654",
    "authors": [
      "Muhammad Ifte Khairul Islam",
      "Max Khanov",
      "Esra Akbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.03667",
    "title": "Run, Don't Walk: Chasing Higher FLOPS for Faster Neural Networks",
    "abstract": "To design fast neural networks, many works have been focusing on reducing the number of floating-point operations (FLOPs). We observe that such reduction in FLOPs, however, does not necessarily lead to a similar level of reduction in latency. This mainly stems from inefficiently low floating-point operations per second (FLOPS). To achieve faster networks, we revisit popular operators and demonstrate that such low FLOPS is mainly due to frequent memory access of the operators, especially the depthwise convolution. We hence propose a novel partial convolution (PConv) that extracts spatial features more efficiently, by cutting down redundant computation and memory access simultaneously. Building upon our PConv, we further propose FasterNet, a new family of neural networks, which attains substantially higher running speed than others on a wide range of devices, without compromising on accuracy for various vision tasks. For example, on ImageNet-1k, our tiny FasterNet-T0 is $3.1\\times$, $3.1\\times$, and $2.5\\times$ faster than MobileViT-XXS on GPU, CPU, and ARM processors, respectively, while being $2.9\\%$ more accurate. Our large FasterNet-L achieves impressive $83.5\\%$ top-1 accuracy, on par with the emerging Swin-B, while having $49\\%$ higher inference throughput on GPU, as well as saving $42\\%$ compute time on CPU. Code is available at \\url{https://github.com/JierunChen/FasterNet}. ",
    "url": "https://arxiv.org/abs/2303.03667",
    "authors": [
      "Jierun Chen",
      "Shiu-hong Kao",
      "Hao He",
      "Weipeng Zhuo",
      "Song Wen",
      "Chul-Ho Lee",
      "S.-H. Gary Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03679",
    "title": "MAST: Masked Augmentation Subspace Training for Generalizable  Self-Supervised Priors",
    "abstract": "Recent Self-Supervised Learning (SSL) methods are able to learn feature representations that are invariant to different data augmentations, which can then be transferred to downstream tasks of interest. However, different downstream tasks require different invariances for their best performance, so the optimal choice of augmentations for SSL depends on the target task. In this paper, we aim to learn self-supervised features that generalize well across a variety of downstream tasks (e.g., object classification, detection and instance segmentation) without knowing any task information beforehand. We do so by Masked Augmentation Subspace Training (or MAST) to encode in the single feature space the priors from different data augmentations in a factorized way. Specifically, we disentangle the feature space into separate subspaces, each induced by a learnable mask that selects relevant feature dimensions to model invariance to a specific augmentation. We show the success of MAST in jointly capturing generalizable priors from different augmentations, using both unique and shared features across the subspaces. We further show that MAST benefits from uncertainty modeling to reweight ambiguous samples from strong augmentations that may cause similarity mismatch in each subspace. Experiments demonstrate that MAST consistently improves generalization on various downstream tasks, while being task-agnostic and efficient during SSL. We also provide interesting insights about how different augmentations are related and how uncertainty reflects learning difficulty. ",
    "url": "https://arxiv.org/abs/2303.03679",
    "authors": [
      "Chen Huang",
      "Hanlin Goh",
      "Jiatao Gu",
      "Josh Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03680",
    "title": "Logit Margin Matters: Improving Transferable Targeted Adversarial Attack  by Logit Calibration",
    "abstract": "Previous works have extensively studied the transferability of adversarial samples in untargeted black-box scenarios. However, it still remains challenging to craft targeted adversarial examples with higher transferability than non-targeted ones. Recent studies reveal that the traditional Cross-Entropy (CE) loss function is insufficient to learn transferable targeted adversarial examples due to the issue of vanishing gradient. In this work, we provide a comprehensive investigation of the CE loss function and find that the logit margin between the targeted and untargeted classes will quickly obtain saturation in CE, which largely limits the transferability. Therefore, in this paper, we devote to the goal of continually increasing the logit margin along the optimization to deal with the saturation issue and propose two simple and effective logit calibration methods, which are achieved by downscaling the logits with a temperature factor and an adaptive margin, respectively. Both of them can effectively encourage optimization to produce a larger logit margin and lead to higher transferability. Besides, we show that minimizing the cosine distance between the adversarial examples and the classifier weights of the target class can further improve the transferability, which is benefited from downscaling logits via L2-normalization. Experiments conducted on the ImageNet dataset validate the effectiveness of the proposed methods, which outperform the state-of-the-art methods in black-box targeted attacks. The source code is available at \\href{https://github.com/WJJLL/Target-Attack/}{Link} ",
    "url": "https://arxiv.org/abs/2303.03680",
    "authors": [
      "Juanjuan Weng",
      "Zhiming Luo",
      "Zhun Zhong",
      "Shaozi Li",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03684",
    "title": "MOSO: Decomposing MOtion, Scene and Object for Video Prediction",
    "abstract": "Motion, scene and object are three primary visual components of a video. In particular, objects represent the foreground, scenes represent the background, and motion traces their dynamics. Based on this insight, we propose a two-stage MOtion, Scene and Object decomposition framework (MOSO) for video prediction, consisting of MOSO-VQVAE and MOSO-Transformer. In the first stage, MOSO-VQVAE decomposes a previous video clip into the motion, scene and object components, and represents them as distinct groups of discrete tokens. Then, in the second stage, MOSO-Transformer predicts the object and scene tokens of the subsequent video clip based on the previous tokens and adds dynamic motion at the token level to the generated object and scene tokens. Our framework can be easily extended to unconditional video generation and video frame interpolation tasks. Experimental results demonstrate that our method achieves new state-of-the-art performance on five challenging benchmarks for video prediction and unconditional video generation: BAIR, RoboNet, KTH, KITTI and UCF101. In addition, MOSO can produce realistic videos by combining objects and scenes from different videos. ",
    "url": "https://arxiv.org/abs/2303.03684",
    "authors": [
      "Mingzhen Sun",
      "Weining Wang",
      "Xinxin Zhu",
      "Jing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03697",
    "title": "Stylometric Detection of AI-Generated Text in Twitter Timelines",
    "abstract": "Recent advancements in pre-trained language models have enabled convenient methods for generating human-like text at a large scale. Though these generation capabilities hold great potential for breakthrough applications, it can also be a tool for an adversary to generate misinformation. In particular, social media platforms like Twitter are highly susceptible to AI-generated misinformation. A potential threat scenario is when an adversary hijacks a credible user account and incorporates a natural language generator to generate misinformation. Such threats necessitate automated detectors for AI-generated tweets in a given user's Twitter timeline. However, tweets are inherently short, thus making it difficult for current state-of-the-art pre-trained language model-based detectors to accurately detect at what point the AI starts to generate tweets in a given Twitter timeline. In this paper, we present a novel algorithm using stylometric signals to aid detecting AI-generated tweets. We propose models corresponding to quantifying stylistic changes in human and AI tweets in two related tasks: Task 1 - discriminate between human and AI-generated tweets, and Task 2 - detect if and when an AI starts to generate tweets in a given Twitter timeline. Our extensive experiments demonstrate that the stylometric features are effective in augmenting the state-of-the-art AI-generated text detectors. ",
    "url": "https://arxiv.org/abs/2303.03697",
    "authors": [
      "Tharindu Kumarage",
      "Joshua Garland",
      "Amrita Bhattacharjee",
      "Kirill Trapeznikov",
      "Scott Ruston",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03698",
    "title": "FIT: Frequency-based Image Translation for Domain Adaptive Object  Detection",
    "abstract": "Domain adaptive object detection (DAOD) aims to adapt the detector from a labelled source domain to an unlabelled target domain. In recent years, DAOD has attracted massive attention since it can alleviate performance degradation due to the large shift of data distributions in the wild. To align distributions between domains, adversarial learning is widely used in existing DAOD methods. However, the decision boundary for the adversarial domain discriminator may be inaccurate, causing the model biased towards the source domain. To alleviate this bias, we propose a novel Frequency-based Image Translation (FIT) framework for DAOD. First, by keeping domain-invariant frequency components and swapping domain-specific ones, we conduct image translation to reduce domain shift at the input level. Second, hierarchical adversarial feature learning is utilized to further mitigate the domain gap at the feature level. Finally, we design a joint loss to train the entire network in an end-to-end manner without extra training to obtain translated images. Extensive experiments on three challenging DAOD benchmarks demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2303.03698",
    "authors": [
      "Siqi Zhang",
      "Lu Zhang",
      "Zhiyong Liu",
      "Hangtao Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03699",
    "title": "CAE-CNNLoc: An Edge-based WiFi Fingerprinting Indoor Localization Using  Convolutional Neural Network and Convolutional Auto-Encoder",
    "abstract": "With the ongoing development of Indoor Location-Based Services, accurate location information of users in indoor environments has been a challenging issue in recent years. Due to the widespread use of WiFi networks, WiFi fingerprinting has become one of the most practical methods of locating mobile users. In addition to localization accuracy, some other critical factors such as cost, latency, and users' privacy should be considered in indoor localization systems. In this study, we propose a lightweight Convolutional Neural Network (CNN)-based method for edge devices (such as smartphones) to overcome the above issues by eliminating the need for a cloud/server in the localization system. To enable the use of the proposed model on resource-constraint edge devices, post-training optimization techniques including quantization, pruning and clustering are used to compress the network model. The proposed method is evaluated for three different open datasets, i.e., UJIIndoorLoc, Tampere and UTSIndoorLoc, as well as for our collected dataset named SBUK-D to verify its scalability. The results demonstrate the superiority of the proposed method compared to state-of-the-art studies. We also evaluate performance efficiency of our localization method on an android smartphone to demonstrate its applicability to edge devices. For UJIIndoorLoc dataset, our model with post-training optimizations obtains approximately 99% building accuracy, over 98% floor accuracy, and 4 m positioning mean error with the model size and inference time of 60 KB and 270 us, respectively, which demonstrate high accuracy as well as amenability to the resource-constrained edge devices. ",
    "url": "https://arxiv.org/abs/2303.03699",
    "authors": [
      "Amin Kargar-Barzi",
      "Ebrahim Farahmand",
      "Ali Mahani",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.03705",
    "title": "Fairness-aware Maximal Biclique Enumeration on Bipartite Graphs",
    "abstract": "Maximal biclique enumeration is a fundamental problem in bipartite graph data analysis. Existing biclique enumeration methods mainly focus on non-attributed bipartite graphs and also ignore the \\emph{fairness} of graph attributes. In this paper, we introduce the concept of fairness into the biclique model for the first time and study the problem of fairness-aware biclique enumeration. Specifically, we propose two fairness-aware biclique models, called \\nonesidebc~and \\ntwosidebc~respectively. To efficiently enumerate all {\\nonesidebc}s, we first present two non-trivial pruning techniques, called fair $\\alpha$-$\\beta$ core pruning and colorful fair $\\alpha$-$\\beta$ core pruning, to reduce the graph size without losing accuracy. Then, we develop a branch and bound algorithm, called \\onesideFBCEM, to enumerate all single-side fair bicliques on the reduced bipartite graph. To further improve the efficiency, we propose an efficient branch and bound algorithm with a carefully-designed combinatorial enumeration technique. Note that all of our techniques can also be extended to enumerate all bi-side fair bicliques. We also extend the two fairness-aware biclique models by constraining the ratio of the number of vertices of each attribute to the total number of vertices and present corresponding enumeration algorithms. Extensive experimental results on five large real-world datasets demonstrate our methods' efficiency, effectiveness, and scalability. ",
    "url": "https://arxiv.org/abs/2303.03705",
    "authors": [
      "Ziqi Yin",
      "Qi Zhang",
      "Wentao Zhang",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2303.03711",
    "title": "SCRAMBLE-CFI: Mitigating Fault-Induced Control-Flow Attacks on OpenTitan",
    "abstract": "Secure elements physically exposed to adversaries are frequently targeted by fault attacks. These attacks can be utilized to hijack the control-flow of software allowing the attacker to bypass security measures, extract sensitive data, or gain full code execution. In this paper, we systematically analyze the threat vector of fault-induced control-flow manipulations on the open-source OpenTitan secure element. Our thorough analysis reveals that current countermeasures of this chip either induce large area overheads or still cannot prevent the attacker from exploiting the identified threats. In this context, we introduce SCRAMBLE-CFI, an encryption-based control-flow integrity scheme utilizing existing hardware features of OpenTitan. SCRAMBLE-CFI confines, with minimal hardware overhead, the impact of fault-induced control-flow attacks by encrypting each function with a different encryption tweak at load-time. At runtime, code only can be successfully decrypted when the correct decryption tweak is active. We open-source our hardware changes and release our LLVM toolchain automatically protecting programs. Our analysis shows that SCRAMBLE-CFI complementarily enhances security guarantees of OpenTitan with a negligible hardware overhead of less than 3.97 % and a runtime overhead of 7.02 % for the Embench-IoT benchmarks. ",
    "url": "https://arxiv.org/abs/2303.03711",
    "authors": [
      "Pascal Nasahl",
      "Stefan Mangard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.03717",
    "title": "Improving Self-Supervised Learning for Audio Representations by Feature  Diversity and Decorrelation",
    "abstract": "Self-supervised learning (SSL) has recently shown remarkable results in closing the gap between supervised and unsupervised learning. The idea is to learn robust features that are invariant to distortions of the input data. Despite its success, this idea can suffer from a collapsing issue where the network produces a constant representation. To this end, we introduce SELFIE, a novel Self-supervised Learning approach for audio representation via Feature Diversity and Decorrelation. SELFIE avoids the collapsing issue by ensuring that the representation (i) maintains a high diversity among embeddings and (ii) decorrelates the dependencies between dimensions. SELFIE is pre-trained on the large-scale AudioSet dataset and its embeddings are validated on nine audio downstream tasks, including speech, music, and sound event recognition. Experimental results show that SELFIE outperforms existing SSL methods in several tasks. ",
    "url": "https://arxiv.org/abs/2303.03717",
    "authors": [
      "Bac Nguyen",
      "Stefan Uhlich",
      "Fabien Cardinaux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.03720",
    "title": "Querying Shortest Path on Large Time-Dependent Road Networks with  Shortcuts",
    "abstract": "Querying the shortest path between two vertexes is a fundamental operation in a variety of applications, which has been extensively studied over static road networks. However, in reality, the travel costs of road segments evolve over time, and hence the road network can be modeled as a time-dependent graph. In this paper, we study the shortest path query over large-scale time-dependent road networks. Existing work focuses on a hierarchical partition structure, which makes the index construction and travel cost query inefficient. To improve the efficiency of such queries, we propose a novel index by decomposing a road network into a tree structure and selecting a set of shortcuts on the tree to speed up the query processing. Specifically, we first formally define a shortcut selection problem over the tree decomposition of the time-dependent road network. This problem, which is proven to be NP-hard, aims to select and build the most effective shortcut set. We first devise a dynamic programming method with exact results to solve the selection problem. To obtain the optimal shortcut set quickly, we design an approximation algorithm that guarantees a 0.5-approximation ratio. Based on the novel tree structure, we devise a shortcut-based algorithm to answer the shortest path query over time-dependent road networks. Finally, we conduct extensive performance studies using large-scale real-world road networks. The results demonstrate that our method can achieve better efficiency and scalability than the state-of-the-art method. ",
    "url": "https://arxiv.org/abs/2303.03720",
    "authors": [
      "Zengyang Gong",
      "Yuxiang Zeng",
      "Lei Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2303.03728",
    "title": "Refined Pseudo labeling for Source-free Domain Adaptive Object Detection",
    "abstract": "Domain adaptive object detection (DAOD) assumes that both labeled source data and unlabeled target data are available for training, but this assumption does not always hold in real-world scenarios. Thus, source-free DAOD is proposed to adapt the source-trained detectors to target domains with only unlabeled target data. Existing source-free DAOD methods typically utilize pseudo labeling, where the performance heavily relies on the selection of confidence threshold. However, most prior works adopt a single fixed threshold for all classes to generate pseudo labels, which ignore the imbalanced class distribution, resulting in biased pseudo labels. In this work, we propose a refined pseudo labeling framework for source-free DAOD. First, to generate unbiased pseudo labels, we present a category-aware adaptive threshold estimation module, which adaptively provides the appropriate threshold for each category. Second, to alleviate incorrect box regression, a localization-aware pseudo label assignment strategy is introduced to divide labels into certain and uncertain ones and optimize them separately. Finally, extensive experiments on four adaptation tasks demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2303.03728",
    "authors": [
      "Siqi Zhang",
      "Lu Zhang",
      "Zhiyong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03730",
    "title": "LORE: Logical Location Regression Network for Table Structure  Recognition",
    "abstract": "Table structure recognition (TSR) aims at extracting tables in images into machine-understandable formats. Recent methods solve this problem by predicting the adjacency relations of detected cell boxes, or learning to generate the corresponding markup sequences from the table images. However, they either count on additional heuristic rules to recover the table structures, or require a huge amount of training data and time-consuming sequential decoders. In this paper, we propose an alternative paradigm. We model TSR as a logical location regression problem and propose a new TSR framework called LORE, standing for LOgical location REgression network, which for the first time combines logical location regression together with spatial location regression of table cells. Our proposed LORE is conceptually simpler, easier to train and more accurate than previous TSR models of other paradigms. Experiments on standard benchmarks demonstrate that LORE consistently outperforms prior arts. Code is available at https:// github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LORE-TSR. ",
    "url": "https://arxiv.org/abs/2303.03730",
    "authors": [
      "Hangdi Xing",
      "Feiyu Gao",
      "Rujiao Long",
      "Jiajun Bu",
      "Qi Zheng",
      "Liangcheng Li",
      "Cong Yao",
      "Zhi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03747",
    "title": "Graph Decision Transformer",
    "abstract": "Offline reinforcement learning (RL) is a challenging task, whose objective is to learn policies from static trajectory data without interacting with the environment. Recently, offline RL has been viewed as a sequence modeling problem, where an agent generates a sequence of subsequent actions based on a set of static transition experiences. However, existing approaches that use transformers to attend to all tokens naively can overlook the dependencies between different tokens and limit long-term dependency learning. In this paper, we propose the Graph Decision Transformer (GDT), a novel offline RL approach that models the input sequence into a causal graph to capture potential dependencies between fundamentally different concepts and facilitate temporal and causal relationship learning. GDT uses a graph transformer to process the graph inputs with relation-enhanced mechanisms, and an optional sequence transformer to handle fine-grained spatial information in visual tasks. Our experiments show that GDT matches or surpasses the performance of state-of-the-art offline RL methods on image-based Atari and OpenAI Gym. ",
    "url": "https://arxiv.org/abs/2303.03747",
    "authors": [
      "Shengchao Hu",
      "Li Shen",
      "Ya Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03761",
    "title": "Graph Neural Networks in Vision-Language Image Understanding: A Survey",
    "abstract": "2D image understanding is a complex problem within Computer Vision, but it holds the key to providing human level scene comprehension. It goes further than identifying the objects in an image, and instead it attempts to understand the scene. Solutions to this problem form the underpinning of a range of tasks, including image captioning, Visual Question Answering (VQA), and image retrieval. Graphs provide a natural way to represent the relational arrangement between objects in an image, and thus in recent years Graph Neural Networks (GNNs) have become a standard component of many 2D image understanding pipelines, becoming a core architectural component especially in the VQA group of tasks. In this survey, we review this rapidly evolving field and we provide a taxonomy of graph types used in 2D image understanding approaches, a comprehensive list of the GNN models used in this domain, and a roadmap of future potential developments. To the best of our knowledge, this is the first comprehensive survey that covers image captioning, visual question answering, and image retrieval techniques that focus on using GNNs as the main part of their architecture. ",
    "url": "https://arxiv.org/abs/2303.03761",
    "authors": [
      "Henry Senior",
      "Gregory Slabaugh",
      "Shanxin Yuan",
      "Luca Rossi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03789",
    "title": "Fast and Multi-aspect Mining of Complex Time-stamped Event Streams",
    "abstract": "Given a huge, online stream of time-evolving events with multiple attributes, such as online shopping logs: (item, price, brand, time), and local mobility activities: (pick-up and drop-off locations, time), how can we summarize large, dynamic high-order tensor streams? How can we see any hidden patterns, rules, and anomalies? Our answer is to focus on two types of patterns, i.e., ''regimes'' and ''components'', for which we present CubeScope, an efficient and effective method over high-order tensor streams. Specifically, it identifies any sudden discontinuity and recognizes distinct dynamical patterns, ''regimes'' (e.g., weekday/weekend/holiday patterns). In each regime, it also performs multi-way summarization for all attributes (e.g., item, price, brand, and time) and discovers hidden ''components'' representing latent groups (e.g., item/brand groups) and their relationship. Thanks to its concise but effective summarization, CubeScope can also detect the sudden appearance of anomalies and identify the types of anomalies that occur in practice. Our proposed method has the following properties: (a) Effective: it captures dynamical multi-aspect patterns, i.e., regimes and components, and statistically summarizes all the events; (b) General: it is practical for successful application to data compression, pattern discovery, and anomaly detection on various types of tensor streams; (c) Scalable: our algorithm does not depend on the length of the data stream and its dimensionality. Extensive experiments on real datasets demonstrate that CubeScope finds meaningful patterns and anomalies correctly, and consistently outperforms the state-of-the-art methods as regards accuracy and execution speed. ",
    "url": "https://arxiv.org/abs/2303.03789",
    "authors": [
      "Kota Nakamura",
      "Yasuko Matsubara",
      "Koki Kawabata",
      "Yuhei Umeda",
      "Yuichiro Wada",
      "Yasushi Sakurai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.03817",
    "title": "Region and Spatial Aware Anomaly Detection for Fundus Images",
    "abstract": "Recently anomaly detection has drawn much attention in diagnosing ocular diseases. Most existing anomaly detection research in fundus images has relatively large anomaly scores in the salient retinal structures, such as blood vessels, optical cups and discs. In this paper, we propose a Region and Spatial Aware Anomaly Detection (ReSAD) method for fundus images, which obtains local region and long-range spatial information to reduce the false positives in the normal structure. ReSAD transfers a pre-trained model to extract the features of normal fundus images and applies the Region-and-Spatial-Aware feature Combination module (ReSC) for pixel-level features to build a memory bank. In the testing phase, ReSAD uses the memory bank to determine out-of-distribution samples as abnormalities. Our method significantly outperforms the existing anomaly detection methods for fundus images on two publicly benchmark datasets. ",
    "url": "https://arxiv.org/abs/2303.03817",
    "authors": [
      "Jingqi Niu",
      "Shiwen Dong",
      "Qinji Yu",
      "Kang Dang",
      "Xiaowei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03829",
    "title": "Can Decentralized Learning be more robust than Federated Learning?",
    "abstract": "Decentralized Learning (DL) is a peer--to--peer learning approach that allows a group of users to jointly train a machine learning model. To ensure correctness, DL should be robust, i.e., Byzantine users must not be able to tamper with the result of the collaboration. In this paper, we introduce two \\textit{new} attacks against DL where a Byzantine user can: make the network converge to an arbitrary model of their choice, and exclude an arbitrary user from the learning process. We demonstrate our attacks' efficiency against Self--Centered Clipping, the state--of--the--art robust DL protocol. Finally, we show that the capabilities decentralization grants to Byzantine users result in decentralized learning \\emph{always} providing less robustness than federated learning. ",
    "url": "https://arxiv.org/abs/2303.03829",
    "authors": [
      "Mathilde Raynal",
      "Dario Pasquini",
      "Carmela Troncoso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.03848",
    "title": "Parareal with a physics-informed neural network as coarse propagator",
    "abstract": "Parallel-in-time algorithms provide an additional layer of concurrency for the numerical integration of models based on time-dependent differential equations. Methods like Parareal, which parallelize across multiple time steps, rely on a computationally cheap and coarse integrator to propagate information forward in time, while a parallelizable expensive fine propagator provides accuracy. Typically, the coarse method is a numerical integrator using lower resolution, reduced order or a simplified model. Our paper proposes to use a physics-informed neural network (PINN) instead. We demonstrate for the Black-Scholes equation, a partial differential equation from computational finance, that Parareal with a PINN coarse propagator provides better speedup than a numerical coarse propagator. Training and evaluating a neural network are both tasks whose computing patterns are well suited for GPUs. By contrast, mesh-based algorithms with their low computational intensity struggle to perform well. We show that moving the coarse propagator PINN to a GPU while running the numerical fine propagator on the CPU further improves Parareal's single-node performance. This suggests that integrating machine learning techniques into parallel-in-time integration methods and exploiting their differences in computing patterns might offer a way to better utilize heterogeneous architectures. ",
    "url": "https://arxiv.org/abs/2303.03848",
    "authors": [
      "Abdul Qadir Ibrahim",
      "Sebastian G\u00f6tschel",
      "Daniel Ruprecht"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.03851",
    "title": "Parsing Line Segments of Floor Plan Images Using Graph Neural Networks",
    "abstract": "In this paper, we present a GNN-based Line Segment Parser (GLSP), which uses a junction heatmap to predict line segments' endpoints, and graph neural networks to extract line segments and their categories. Different from previous floor plan recognition methods, which rely on semantic segmentation, our proposed method is able to output vectorized line segment and requires less post-processing steps to be put into practical use. Our experiments show that the methods outperform state-of-the-art line segment detection models on multi-class line segment detection tasks with floor plan images. In the paper, we use our floor plan dataset named Large-scale Residential Floor Plan data (LRFP). The dataset contains a total of 271,035 floor plan images. The label corresponding to each picture contains the scale information, the categories and outlines of rooms, and the endpoint positions of line segments such as doors, windows, and walls. Our augmentation method makes the dataset adaptable to the drawing styles of as many countries and regions as possible. ",
    "url": "https://arxiv.org/abs/2303.03851",
    "authors": [
      "Mingxiang Chen",
      "Cihui Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03856",
    "title": "Event Voxel Set Transformer for Spatiotemporal Representation Learning  on Event Streams",
    "abstract": "Event cameras are neuromorphic vision sensors representing visual information as sparse and asynchronous event streams. Most state-of-the-art event-based methods project events into dense frames and process them with conventional learning models. However, these approaches sacrifice the sparsity and high temporal resolution of event data, resulting in a large model size and high computational complexity. To fit the sparse nature of events and sufficiently explore their implicit relationship, we develop a novel attention-aware framework named Event Voxel Set Transformer (EVSTr) for spatiotemporal representation learning on event streams. It first converts the event stream into a voxel set and then hierarchically aggregates voxel features to obtain robust representations. The core of EVSTr is an event voxel transformer encoder to extract discriminative spatiotemporal features, which consists of two well-designed components, including a multi-scale neighbor embedding layer (MNEL) for local information aggregation and a voxel self-attention layer (VSAL) for global representation modeling. Enabling the framework to incorporate a long-term temporal structure, we introduce a segmental consensus strategy for modeling motion patterns over a sequence of segmented voxel sets. We evaluate the proposed framework on two event-based tasks: object classification and action recognition. Comprehensive experiments show that EVSTr achieves state-of-the-art performance while maintaining low model complexity. Additionally, we present a new dataset (NeuroHAR) recorded in challenging visual scenarios to address the lack of real-world event-based datasets for action recognition. ",
    "url": "https://arxiv.org/abs/2303.03856",
    "authors": [
      "Bochen Xie",
      "Yongjian Deng",
      "Zhanpeng Shao",
      "Hai Liu",
      "Qingsong Xu",
      "Youfu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03881",
    "title": "Spatial, Social and Data Gaps in On-Demand Mobility Services: Towards a  Supply-Oriented MaaS",
    "abstract": "After a decade of on-demand mobility services that change spatial behaviors in metropolitan areas, the Shared Autonomous Vehicle (SAV) service is expected to increase traffic congestion and unequal access to transport services. A paradigm of scheduled supply that is aware of demand but not on-demand is proposed, introducing coordination and social and behavioral understanding, urban cognition and empowerment of agents, into a novel informational framework. Daily routines and other patterns of spatial behaviors outline a fundamental demand layer in a supply-oriented paradigm that captures urban dynamics and spatial-temporal behaviors, mostly in groups. Rather than real-time requests and instant responses that reward unplanned actions, and beyond just reservation of travels in timetables, the intention is to capture mobility flows in scheduled travels along the day considering time of day, places, passengers etc. Regulating goal-directed behaviors and caring for service resources and the overall system welfare is proposed to minimize uncertainty, considering the capacity of mobility interactions to hold value, i.e., Motility as a Service (MaaS). The principal-agent problem in the smart city is a problem of collective action among service providers and users that create expectations based on previous actions and reactions in mutual systems. Planned behavior that accounts for service coordination is expected to stabilize excessive rides and traffic load, and to induce a cognitive gain, thus balancing information load and facilitating cognitive effort. ",
    "url": "https://arxiv.org/abs/2303.03881",
    "authors": [
      "Ronit Purian",
      "Daniel Polani"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2303.03889",
    "title": "A nearly optimal explicitly-sparse representation for oscillatory  kernels with curvelet-like functions",
    "abstract": "A nearly optimal explicitly-sparse representation for oscillatory kernels is presented in this work by developing a curvelet based method. Multilevel curvelet-like functions are constructed as the transform of the original nodal basis. Then the system matrix in a new non-standard form is derived with respect to the curvelet basis, which would be nearly optimally sparse due to the directional low rank property of the oscillatory kernel. Its sparsity is further enhanced via a-posteriori compression. Finally its nearly optimial log-linear computational complexity with controllable accuracy is demonstrated with numerical results. This explicitly-sparse representation is expected to lay ground to future work related to fast direct solvers and effective preconditioners for high frequency problems. It may also be viewed as the generalization of wavelet based methods to high frequency cases, and used as a new wideband fast algorithm for wave problems. ",
    "url": "https://arxiv.org/abs/2303.03889",
    "authors": [
      "Yanchuang Cao",
      "Jun Liu",
      "Dawei Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.03912",
    "title": "Document-level Relation Extraction with Cross-sentence Reasoning Graph",
    "abstract": "Relation extraction (RE) has recently moved from the sentence-level to document-level, which requires aggregating document information and using entities and mentions for reasoning. Existing works put entity nodes and mention nodes with similar representations in a document-level graph, whose complex edges may incur redundant information. Furthermore, existing studies only focus on entity-level reasoning paths without considering global interactions among entities cross-sentence. To these ends, we propose a novel document-level RE model with a GRaph information Aggregation and Cross-sentence Reasoning network (GRACR). Specifically, a simplified document-level graph is constructed to model the semantic information of all mentions and sentences in a document, and an entity-level graph is designed to explore relations of long-distance cross-sentence entity pairs. Experimental results show that GRACR achieves excellent performance on two public datasets of document-level RE. It is especially effective in extracting potential relations of cross-sentence entity pairs. Our code is available at https://github.com/UESTC-LHF/GRACR. ",
    "url": "https://arxiv.org/abs/2303.03912",
    "authors": [
      "Hongfei Liu",
      "Zhao Kang",
      "Lizong Zhang",
      "Ling Tian",
      "Fujun Hua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.03916",
    "title": "A survey on automated detection and classification of acute leukemia and  WBCs in microscopic blood cells",
    "abstract": "Leukemia (blood cancer) is an unusual spread of White Blood Cells or Leukocytes (WBCs) in the bone marrow and blood. Pathologists can diagnose leukemia by looking at a person's blood sample under a microscope. They identify and categorize leukemia by counting various blood cells and morphological features. This technique is time-consuming for the prediction of leukemia. The pathologist's professional skills and experiences may be affecting this procedure, too. In computer vision, traditional machine learning and deep learning techniques are practical roadmaps that increase the accuracy and speed in diagnosing and classifying medical images such as microscopic blood cells. This paper provides a comprehensive analysis of the detection and classification of acute leukemia and WBCs in the microscopic blood cells. First, we have divided the previous works into six categories based on the output of the models. Then, we describe various steps of detection and classification of acute leukemia and WBCs, including Data Augmentation, Preprocessing, Segmentation, Feature Extraction, Feature Selection (Reduction), Classification, and focus on classification step in the methods. Finally, we divide automated detection and classification of acute leukemia and WBCs into three categories, including traditional, Deep Neural Network (DNN), and mixture (traditional and DNN) methods based on the type of classifier in the classification step and analyze them. The results of this study show that in the diagnosis and classification of acute leukemia and WBCs, the Support Vector Machine (SVM) classifier in traditional machine learning models and Convolutional Neural Network (CNN) classifier in deep learning models have widely employed. The performance metrics of the models that use these classifiers compared to the others model are higher. ",
    "url": "https://arxiv.org/abs/2303.03916",
    "authors": [
      "Mohammad Zolfaghari",
      "Hedieh Sajedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03922",
    "title": "Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer",
    "abstract": "Knowledge graphs (KG) are essential background knowledge providers in many tasks. When designing models for KG-related tasks, one of the key tasks is to devise the Knowledge Representation and Fusion (KRF) module that learns the representation of elements from KGs and fuses them with task representations. While due to the difference of KGs and perspectives to be considered during fusion across tasks, duplicate and ad hoc KRF modules design are conducted among tasks. In this paper, we propose a novel knowledge graph pretraining model KGTransformer that could serve as a uniform KRF module in diverse KG-related tasks. We pretrain KGTransformer with three self-supervised tasks with sampled sub-graphs as input. For utilization, we propose a general prompt-tuning mechanism regarding task data as a triple prompt to allow flexible interactions between task KGs and task data. We evaluate pretrained KGTransformer on three tasks, triple classification, zero-shot image classification, and question answering. KGTransformer consistently achieves better results than specifically designed task models. Through experiments, we justify that the pretrained KGTransformer could be used off the shelf as a general and effective KRF module across KG-related tasks. The code and datasets are available at https://github.com/zjukg/KGTransformer. ",
    "url": "https://arxiv.org/abs/2303.03922",
    "authors": [
      "Wen Zhang",
      "Yushan Zhu",
      "Mingyang Chen",
      "Yuxia Geng",
      "Yufeng Huang",
      "Yajing Xu",
      "Wenting Song",
      "Huajun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.03925",
    "title": "Robust Semi-Supervised Anomaly Detection via Adversarially Learned  Continuous Noise Corruption",
    "abstract": "Anomaly detection is the task of recognising novel samples which deviate significantly from pre-establishednormality. Abnormal classes are not present during training meaning that models must learn effective rep-resentations solely across normal class data samples. Deep Autoencoders (AE) have been widely used foranomaly detection tasks, but suffer from overfitting to a null identity function. To address this problem, weimplement a training scheme applied to a Denoising Autoencoder (DAE) which introduces an efficient methodof producing Adversarially Learned Continuous Noise (ALCN) to maximally globally corrupt the input priorto denoising. Prior methods have applied similar approaches of adversarial training to increase the robustnessof DAE, however they exhibit limitations such as slow inference speed reducing their real-world applicabilityor producing generalised obfuscation which is more trivial to denoise. We show through rigorous evaluationthat our ALCN method of regularisation during training improves AUC performance during inference whileremaining efficient over both classical, leave-one-out novelty detection tasks with the variations-: 9 (normal)vs. 1 (abnormal) & 1 (normal) vs. 9 (abnormal); MNIST - AUCavg: 0.890 & 0.989, CIFAR-10 - AUCavg: 0.670& 0.742, in addition to challenging real-world anomaly detection tasks: industrial inspection (MVTEC-AD -AUCavg: 0.780) and plant disease detection (Plant Village - AUC: 0.770) when compared to prior approaches. ",
    "url": "https://arxiv.org/abs/2303.03925",
    "authors": [
      "Jack W Barker",
      "Neelanjan Bhowmik",
      "Yona Falinie A Gaus",
      "Toby P Breckon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03926",
    "title": "Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec  Language Modeling",
    "abstract": "We propose a cross-lingual neural codec language model, VALL-E X, for cross-lingual speech synthesis. Specifically, we extend VALL-E and train a multi-lingual conditional codec language model to predict the acoustic token sequences of the target language speech by using both the source language speech and the target language text as prompts. VALL-E X inherits strong in-context learning capabilities and can be applied for zero-shot cross-lingual text-to-speech synthesis and zero-shot speech-to-speech translation tasks. Experimental results show that it can generate high-quality speech in the target language via just one speech utterance in the source language as a prompt while preserving the unseen speaker's voice, emotion, and acoustic environment. Moreover, VALL-E X effectively alleviates the foreign accent problems, which can be controlled by a language ID. Audio samples are available at \\url{https://aka.ms/vallex}. ",
    "url": "https://arxiv.org/abs/2303.03926",
    "authors": [
      "Ziqiang Zhang",
      "Long Zhou",
      "Chengyi Wang",
      "Sanyuan Chen",
      "Yu Wu",
      "Shujie Liu",
      "Zhuo Chen",
      "Yanqing Liu",
      "Huaming Wang",
      "Jinyu Li",
      "Lei He",
      "Sheng Zhao",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.03933",
    "title": "DEDGAT: Dual Embedding of Directed Graph Attention Networks for  Detecting Financial Risk",
    "abstract": "Graph representation plays an important role in the field of financial risk control, where the relationship among users can be constructed in a graph manner. In practical scenarios, the relationships between nodes in risk control tasks are bidirectional, e.g., merchants having both revenue and expense behaviors. Graph neural networks designed for undirected graphs usually aggregate discriminative node or edge representations with an attention strategy, but cannot fully exploit the out-degree information when used for the tasks built on directed graph, which leads to the problem of a directional bias. To tackle this problem, we propose a Directed Graph ATtention network called DGAT, which explicitly takes out-degree into attention calculation. In addition to having directional requirements, the same node might have different representations of its input and output, and thus we further propose a dual embedding of DGAT, referred to as DEDGAT. Specifically, DEDGAT assigns in-degree and out-degree representations to each node and uses these two embeddings to calculate the attention weights of in-degree and out-degree nodes, respectively. Experiments performed on the benchmark datasets show that DGAT and DEDGAT obtain better classification performance compared to undirected GAT. Also,the visualization results demonstrate that our methods can fully use both in-degree and out-degree information. ",
    "url": "https://arxiv.org/abs/2303.03933",
    "authors": [
      "Jiafu Wu",
      "Mufeng Yao",
      "Dong Wu",
      "Mingmin Chi",
      "Baokun Wang",
      "Ruofan Wu",
      "Xin Fu",
      "Changhua Meng",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.03950",
    "title": "On the existence of optimal shallow feedforward networks with ReLU  activation",
    "abstract": "We prove existence of global minima in the loss landscape for the approximation of continuous target functions using shallow feedforward artificial neural networks with ReLU activation. This property is one of the fundamental artifacts separating ReLU from other commonly used activation functions. We propose a kind of closure of the search space so that in the extended space minimizers exist. In a second step, we show under mild assumptions that the newly added functions in the extension perform worse than appropriate representable ReLU networks. This then implies that the optimal response in the extended target space is indeed the response of a ReLU network. ",
    "url": "https://arxiv.org/abs/2303.03950",
    "authors": [
      "Steffen Dereich",
      "Sebastian Kassing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03951",
    "title": "Probing Graph Representations",
    "abstract": "Today we have a good theoretical understanding of the representational power of Graph Neural Networks (GNNs). For example, their limitations have been characterized in relation to a hierarchy of Weisfeiler-Lehman (WL) isomorphism tests. However, we do not know what is encoded in the learned representations. This is our main question. We answer it using a probing framework to quantify the amount of meaningful information captured in graph representations. Our findings on molecular datasets show the potential of probing for understanding the inductive biases of graph-based models. We compare different families of models and show that transformer-based models capture more chemically relevant information compared to models based on message passing. We also study the effect of different design choices such as skip connections and virtual nodes. We advocate for probing as a useful diagnostic tool for evaluating graph-based models. ",
    "url": "https://arxiv.org/abs/2303.03951",
    "authors": [
      "Mohammad Sadegh Akhondzadeh",
      "Vijay Lingam",
      "Aleksandar Bojchevski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03961",
    "title": "An End-to-End Approach for Online Decision Mining and Decision Drift  Analysis in Process-Aware Information Systems: Extended Version",
    "abstract": "Decision mining enables the discovery of decision rules from event logs or streams, and constitutes an important part of in-depth analysis and optimisation of business processes. So far, decision mining has been merely applied in an ex-post way resulting in a snapshot of decision rules for the given chunk of log data. Online decision mining, by contrast, enables continuous monitoring of decision rule evolution and decision drift. Hence this paper presents an end-to-end approach for the discovery as well as monitoring of decision points and the corresponding decision rules during runtime, bridging the gap between online control flow discovery and decision mining. The approach provides automatic decision support for process-aware information systems with efficient decision drift discovery and monitoring. For monitoring, not only the performance, in terms of accuracy, of decision rules is taken into account, but also the occurrence of data elements and changes in branching frequency. The paper provides two algorithms, which are evaluated on four synthetic and one real-life data set, showing feasibility and applicability of the approach. Overall, the approach fosters the understanding of decisions in business processes and hence contributes to an improved human-process interaction. ",
    "url": "https://arxiv.org/abs/2303.03961",
    "authors": [
      "Beate Scheibel",
      "Stefanie Rinderle-Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03964",
    "title": "Force-Directed Graph Layouts Revisited: A New Force Based on the  T-Distribution",
    "abstract": "In this paper, we propose the t-FDP model, a force-directed placement method based on a novel bounded short-range force (t-force) defined by Student's t-distribution. Our formulation is flexible, exerts limited repulsive forces for nearby nodes and can be adapted separately in its short- and long-range effects. Using such forces in force-directed graph layouts yields better neighborhood preservation than current methods, while maintaining low stress errors. Our efficient implementation using a Fast Fourier Transform is one order of magnitude faster than state-of-the-art methods and two orders faster on the GPU, enabling us to perform parameter tuning by globally and locally adjusting the t-force in real-time for complex graphs. We demonstrate the quality of our approach by numerical evaluation against state-of-the-art approaches and extensions for interactive exploration. ",
    "url": "https://arxiv.org/abs/2303.03964",
    "authors": [
      "Fahai Zhong",
      "Mingliang Xue",
      "Jian Zhang",
      "Fan Zhang",
      "Rui Ban",
      "Oliver Deussen",
      "Yunhai Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.03965",
    "title": "Comparing 3D deformations between longitudinal daily CBCT acquisitions  using CNN for head and neck radiotherapy toxicity prediction",
    "abstract": "Adaptive radiotherapy is a growing field of study in cancer treatment due to it's objective in sparing healthy tissue. The standard of care in several institutions includes longitudinal cone-beam computed tomography (CBCT) acquisitions to monitor changes, but have yet to be used to improve tumor control while managing side-effects. The aim of this study is to demonstrate the clinical value of pre-treatment CBCT acquired daily during radiation therapy treatment for head and neck cancers for the downstream task of predicting severe toxicity occurrence: reactive feeding tube (NG), hospitalization and radionecrosis. For this, we propose a deformable 3D classification pipeline that includes a component analyzing the Jacobian matrix of the deformation between planning CT and longitudinal CBCT, as well as clinical data. The model is based on a multi-branch 3D residual convolutional neural network, while the CT to CBCT registration is based on a pair of VoxelMorph architectures. Accuracies of 85.8% and 75.3% was found for radionecrosis and hospitalization, respectively, with similar performance as early as after the first week of treatment. For NG tube risk, performance improves with increasing the timing of the CBCT fraction, reaching 83.1% after the $5_{th}$ week of treatment. ",
    "url": "https://arxiv.org/abs/2303.03965",
    "authors": [
      "William Trung Le",
      "Chulmin Bang",
      "Philippine Cordelle",
      "Daniel Markel",
      "Phuc Felix Nguyen-Tan",
      "Houda Bahig",
      "Samuel Kadoury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03966",
    "title": "Semantic-aware Occlusion Filtering Neural Radiance Fields in the Wild",
    "abstract": "We present a learning framework for reconstructing neural scene representations from a small number of unconstrained tourist photos. Since each image contains transient occluders, decomposing the static and transient components is necessary to construct radiance fields with such in-the-wild photographs where existing methods require a lot of training data. We introduce SF-NeRF, aiming to disentangle those two components with only a few images given, which exploits semantic information without any supervision. The proposed method contains an occlusion filtering module that predicts the transient color and its opacity for each pixel, which enables the NeRF model to solely learn the static scene representation. This filtering module learns the transient phenomena guided by pixel-wise semantic features obtained by a trainable image encoder that can be trained across multiple scenes to learn the prior of transient objects. Furthermore, we present two techniques to prevent ambiguous decomposition and noisy results of the filtering module. We demonstrate that our method outperforms state-of-the-art novel view synthesis methods on Phototourism dataset in a few-shot setting. ",
    "url": "https://arxiv.org/abs/2303.03966",
    "authors": [
      "Jaewon Lee",
      "Injae Kim",
      "Hwan Heo",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03986",
    "title": "Multiplexed gradient descent: Fast online training of modern datasets on  hardware neural networks without backpropagation",
    "abstract": "We present multiplexed gradient descent (MGD), a gradient descent framework designed to easily train analog or digital neural networks in hardware. MGD utilizes zero-order optimization techniques for online training of hardware neural networks. We demonstrate its ability to train neural networks on modern machine learning datasets, including CIFAR-10 and Fashion-MNIST, and compare its performance to backpropagation. Assuming realistic timescales and hardware parameters, our results indicate that these optimization techniques can train a network on emerging hardware platforms orders of magnitude faster than the wall-clock time of training via backpropagation on a standard GPU, even in the presence of imperfect weight updates or device-to-device variations in the hardware. We additionally describe how it can be applied to existing hardware as part of chip-in-the-loop training, or integrated directly at the hardware level. Crucially, the MGD framework is highly flexible, and its gradient descent process can be optimized to compensate for specific hardware limitations such as slow parameter-update speeds or limited input bandwidth. ",
    "url": "https://arxiv.org/abs/2303.03986",
    "authors": [
      "Adam N. McCaughan",
      "Bakhrom G. Oripov",
      "Natesh Ganesh",
      "Sae Woo Nam",
      "Andrew Dienstfrey",
      "Sonia M. Buckley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.03988",
    "title": "DINet: Deformation Inpainting Network for Realistic Face Visually  Dubbing on High Resolution Video",
    "abstract": "For few-shot learning, it is still a critical challenge to realize photo-realistic face visually dubbing on high-resolution videos. Previous works fail to generate high-fidelity dubbing results. To address the above problem, this paper proposes a Deformation Inpainting Network (DINet) for high-resolution face visually dubbing. Different from previous works relying on multiple up-sample layers to directly generate pixels from latent embeddings, DINet performs spatial deformation on feature maps of reference images to better preserve high-frequency textural details. Specifically, DINet consists of one deformation part and one inpainting part. In the first part, five reference facial images adaptively perform spatial deformation to create deformed feature maps encoding mouth shapes at each frame, in order to align with the input driving audio and also the head poses of the input source images. In the second part, to produce face visually dubbing, a feature decoder is responsible for adaptively incorporating mouth movements from the deformed feature maps and other attributes (i.e., head pose and upper facial expression) from the source feature maps together. Finally, DINet achieves face visually dubbing with rich textural details. We conduct qualitative and quantitative comparisons to validate our DINet on high-resolution videos. The experimental results show that our method outperforms state-of-the-art works. ",
    "url": "https://arxiv.org/abs/2303.03988",
    "authors": [
      "Zhimeng Zhang",
      "Zhipeng Hu",
      "Wenjin Deng",
      "Changjie Fan",
      "Tangjie Lv",
      "Yu Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04001",
    "title": "ELODIN: Naming Concepts in Embedding Spaces",
    "abstract": "Despite recent advancements, the field of text-to-image synthesis still suffers from lack of fine-grained control. Using only text, it remains challenging to deal with issues such as concept coherence and concept contamination. We propose a method to enhance control by generating specific concepts that can be reused throughout multiple images, effectively expanding natural language with new words that can be combined much like a painter's palette. Unlike previous contributions, our method does not copy visuals from input data and can generate concepts through text alone. We perform a set of comparisons that finds our method to be a significant improvement over text-only prompts. ",
    "url": "https://arxiv.org/abs/2303.04001",
    "authors": [
      "Rodrigo Mello",
      "Filipe Calegario",
      "Geber Ramalho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04011",
    "title": "One-4-All: Neural Potential Fields for Embodied Navigation",
    "abstract": "A fundamental task in robotics is to navigate between two locations. In particular, real-world navigation can require long-horizon planning using high-dimensional RGB images, which poses a substantial challenge for end-to-end learning-based approaches. Current semi-parametric methods instead achieve long-horizon navigation by combining learned modules with a topological memory of the environment, often represented as a graph over previously collected images. However, using these graphs in practice typically involves tuning a number of pruning heuristics to avoid spurious edges, limit runtime memory usage and allow reasonably fast graph queries. In this work, we present One-4-All (O4A), a method leveraging self-supervised and manifold learning to obtain a graph-free, end-to-end navigation pipeline in which the goal is specified as an image. Navigation is achieved by greedily minimizing a potential function defined continuously over the O4A latent space. Our system is trained offline on non-expert exploration sequences of RGB data and controls, and does not require any depth or pose measurements. We show that O4A can reach long-range goals in 8 simulated Gibson indoor environments, and further demonstrate successful real-world navigation using a Jackal UGV platform. ",
    "url": "https://arxiv.org/abs/2303.04011",
    "authors": [
      "Sacha Morin",
      "Miguel Saavedra-Ruiz",
      "Liam Paull"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.04038",
    "title": "Root Cause Identification for Collective Anomalies in Time Series given  an Acyclic Summary Causal Graph with Loops",
    "abstract": "This paper presents an approach for identifying the root causes of collective anomalies given observational time series and an acyclic summary causal graph which depicts an abstraction of causal relations present in a dynamic system at its normal regime. The paper first shows how the problem of root cause identification can be divided into many independent subproblems by grouping related anomalies using d-separation. Further, it shows how, under this setting, some root causes can be found directly from the graph and from the time of appearance of anomalies. Finally, it shows, how the rest of the root causes can be found by comparing direct causal effects in the normal and in the anomalous regime. To this end, temporal adaptations of the back-door and the single-door criterions are introduced. Extensive experiments conducted on both simulated and real-world datasets demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2303.04038",
    "authors": [
      "Charles K. Assaad",
      "Imad Ez-zejjari",
      "Lei Zan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04040",
    "title": "Uncertainty Quantification of Spatiotemporal Travel Demand with  Probabilistic Graph Neural Networks",
    "abstract": "Recent studies have significantly improved the prediction accuracy of travel demand using graph neural networks. However, these studies largely ignored uncertainty that inevitably exists in travel demand prediction. To fill this gap, this study proposes a framework of probabilistic graph neural networks (Prob-GNN) to quantify the spatiotemporal uncertainty of travel demand. This Prob-GNN framework is substantiated by deterministic and probabilistic assumptions, and empirically applied to the task of predicting the transit and ridesharing demand in Chicago. We found that the probabilistic assumptions (e.g. distribution tail, support) have a greater impact on uncertainty prediction than the deterministic ones (e.g. deep modules, depth). Among the family of Prob-GNNs, the GNNs with truncated Gaussian and Laplace distributions achieve the highest performance in transit and ridesharing data. Even under significant domain shifts, Prob-GNNs can predict the ridership uncertainty in a stable manner, when the models are trained on pre-COVID data and tested across multiple periods during and after the COVID-19 pandemic. Prob-GNNs also reveal the spatiotemporal pattern of uncertainty, which is concentrated on the afternoon peak hours and the areas with large travel volumes. Overall, our findings highlight the importance of incorporating randomness into deep learning for spatiotemporal ridership prediction. Future research should continue to investigate versatile probabilistic assumptions to capture behavioral randomness, and further develop methods to quantify uncertainty to build resilient cities. ",
    "url": "https://arxiv.org/abs/2303.04040",
    "authors": [
      "Qingyi Wang",
      "Shenhao Wang",
      "Dingyi Zhuang",
      "Haris Koutsopoulos",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.04086",
    "title": "NEPHELE: A Neural Platform for Highly Realistic Cloud Radiance Rendering",
    "abstract": "We have recently seen tremendous progress in neural rendering (NR) advances, i.e., NeRF, for photo-real free-view synthesis. Yet, as a local technique based on a single computer/GPU, even the best-engineered Instant-NGP or i-NGP cannot reach real-time performance when rendering at a high resolution, and often requires huge local computing resources. In this paper, we resort to cloud rendering and present NEPHELE, a neural platform for highly realistic cloud radiance rendering. In stark contrast with existing NR approaches, our NEPHELE allows for more powerful rendering capabilities by combining multiple remote GPUs and facilitates collaboration by allowing multiple people to view the same NeRF scene simultaneously. We introduce i-NOLF to employ opacity light fields for ultra-fast neural radiance rendering in a one-query-per-ray manner. We further resemble the Lumigraph with geometry proxies for fast ray querying and subsequently employ a small MLP to model the local opacity lumishperes for high-quality rendering. We also adopt Perfect Spatial Hashing in i-NOLF to enhance cache coherence. As a result, our i-NOLF achieves an order of magnitude performance gain in terms of efficiency than i-NGP, especially for the multi-user multi-viewpoint setting under cloud rendering scenarios. We further tailor a task scheduler accompanied by our i-NOLF representation and demonstrate the advance of our methodological design through a comprehensive cloud platform, consisting of a series of cooperated modules, i.e., render farms, task assigner, frame composer, and detailed streaming strategies. Using such a cloud platform compatible with neural rendering, we further showcase the capabilities of our cloud radiance rendering through a series of applications, ranging from cloud VR/AR rendering. ",
    "url": "https://arxiv.org/abs/2303.04086",
    "authors": [
      "Haimin Luo",
      "Siyuan Zhang",
      "Fuqiang Zhao",
      "Haotian Jing",
      "Penghao Wang",
      "Zhenxiao Yu",
      "Dongxue Yan",
      "Junran Ding",
      "Boyuan Zhang",
      "Qiang Hu",
      "Shu Yin",
      "Lan Xu",
      "JIngyi Yu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.04096",
    "title": "Mastering Strategy Card Game (Legends of Code and Magic) via End-to-End  Policy and Optimistic Smooth Fictitious Play",
    "abstract": "Deep Reinforcement Learning combined with Fictitious Play shows impressive results on many benchmark games, most of which are, however, single-stage. In contrast, real-world decision making problems may consist of multiple stages, where the observation spaces and the action spaces can be completely different across stages. We study a two-stage strategy card game Legends of Code and Magic and propose an end-to-end policy to address the difficulties that arise in multi-stage game. We also propose an optimistic smooth fictitious play algorithm to find the Nash Equilibrium for the two-player game. Our approach wins double championships of COG2022 competition. Extensive studies verify and show the advancement of our approach. ",
    "url": "https://arxiv.org/abs/2303.04096",
    "authors": [
      "Wei Xi",
      "Yongxin Zhang",
      "Changnan Xiao",
      "Xuefeng Huang",
      "Shihong Deng",
      "Haowei Liang",
      "Jie Chen",
      "Peng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2303.04115",
    "title": "Predicted Embedding Power Regression for Large-Scale Out-of-Distribution  Detection",
    "abstract": "Out-of-distribution (OOD) inputs can compromise the performance and safety of real world machine learning systems. While many methods exist for OOD detection and work well on small scale datasets with lower resolution and few classes, few methods have been developed for large-scale OOD detection. Existing large-scale methods generally depend on maximum classification probability, such as the state-of-the-art grouped softmax method. In this work, we develop a novel approach that calculates the probability of the predicted class label based on label distributions learned during the training process. Our method performs better than current state-of-the-art methods with only a negligible increase in compute cost. We evaluate our method against contemporary methods across $14$ datasets and achieve a statistically significant improvement with respect to AUROC (84.2 vs 82.4) and AUPR (96.2 vs 93.7). ",
    "url": "https://arxiv.org/abs/2303.04115",
    "authors": [
      "Hong Yang",
      "William Gebhardt",
      "Alexander G. Ororbia",
      "Travis Desell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04116",
    "title": "TrafficBots: Towards World Models for Autonomous Driving Simulation and  Motion Prediction",
    "abstract": "Data-driven simulation has become a favorable way to train and test autonomous driving algorithms. The idea of replacing the actual environment with a learned simulator has also been explored in model-based reinforcement learning in the context of world models. In this work, we show data-driven traffic simulation can be formulated as a world model. We present TrafficBots, a multi-agent policy built upon motion prediction and end-to-end driving, and based on TrafficBots we obtain a world model tailored for the planning module of autonomous vehicles. Existing data-driven traffic simulators are lacking configurability and scalability. To generate configurable behaviors, for each agent we introduce a destination as navigational information, and a time-invariant latent personality that specifies the behavioral style. To improve the scalability, we present a new scheme of positional encoding for angles, allowing all agents to share the same vectorized context and the use of an architecture based on dot-product attention. As a result, we can simulate all traffic participants seen in dense urban scenarios. Experiments on the Waymo open motion dataset show TrafficBots can simulate realistic multi-agent behaviors and achieve good performance on the motion prediction task. ",
    "url": "https://arxiv.org/abs/2303.04116",
    "authors": [
      "Zhejun Zhang",
      "Alexander Liniger",
      "Dengxin Dai",
      "Fisher Yu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04134",
    "title": "A Hybrid Architecture for Out of Domain Intent Detection and Intent  Discovery",
    "abstract": "Intent Detection is one of the tasks of the Natural Language Understanding (NLU) unit in task-oriented dialogue systems. Out of Scope (OOS) and Out of Domain (OOD) inputs may run these systems into a problem. On the other side, a labeled dataset is needed to train a model for Intent Detection in task-oriented dialogue systems. The creation of a labeled dataset is time-consuming and needs human resources. The purpose of this article is to address mentioned problems. The task of identifying OOD/OOS inputs is named OOD/OOS Intent Detection. Also, discovering new intents and pseudo-labeling of OOD inputs is well known by Intent Discovery. In OOD intent detection part, we make use of a Variational Autoencoder to distinguish between known and unknown intents independent of input data distribution. After that, an unsupervised clustering method is used to discover different unknown intents underlying OOD/OOS inputs. We also apply a non-linear dimensionality reduction on OOD/OOS representations to make distances between representations more meaning full for clustering. Our results show that the proposed model for both OOD/OOS Intent Detection and Intent Discovery achieves great results and passes baselines in English and Persian languages. ",
    "url": "https://arxiv.org/abs/2303.04134",
    "authors": [
      "Masoud Akbari",
      "Ali Mohades",
      "M. Hassan Shirali-Shahreza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.04145",
    "title": "Benign Overfitting for Two-layer ReLU Networks",
    "abstract": "Modern deep learning models with great expressive power can be trained to overfit the training data but still generalize well. This phenomenon is referred to as benign overfitting. Recently, a few studies have attempted to theoretically understand benign overfitting in neural networks. However, these works are either limited to neural networks with smooth activation functions or to the neural tangent kernel regime. How and when benign overfitting can occur in ReLU neural networks remains an open problem. In this work, we seek to answer this question by establishing algorithm-dependent risk bounds for learning two-layer ReLU convolutional neural networks with label-flipping noise. We show that, under mild conditions, the neural network trained by gradient descent can achieve near-zero training loss and Bayes optimal test risk. Our result also reveals a sharp transition between benign and harmful overfitting under different conditions on data distribution in terms of test risk. Experiments on synthetic data back up our theory. ",
    "url": "https://arxiv.org/abs/2303.04145",
    "authors": [
      "Yiwen Kou",
      "Zixiang Chen",
      "Yuanzhou Chen",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03432",
    "title": "Polar Prediction of Natural Videos",
    "abstract": "Observer motion and continuous deformations of objects and surfaces imbue natural videos with distinct temporal structures, enabling partial prediction of future frames from past ones. Conventional methods first estimate local motion, or optic flow, and then use it to predict future frames by warping or copying content. Here, we explore a more direct methodology, in which each frame is mapped into a learned representation space where the structure of temporal evolution is more readily accessible. Motivated by the geometry of the Fourier shift theorem and its group-theoretic generalization, we formulate a simple architecture that represents video frames in learned local polar coordinates. Specifically, we construct networks in which pairs of convolutional channel coefficients are treated as complex-valued, and are optimized to evolve with slowly varying amplitudes and linearly advancing phases. We train these models on next-frame prediction in natural videos, and compare their performance with that of conventional methods using optic flow as well as predictive neural networks. We find that the polar predictor achieves better performance while remaining interpretable and fast, thereby demonstrating the potential of a flow-free video processing methodology that is trained end-to-end to predict natural video content. ",
    "url": "https://arxiv.org/abs/2303.03432",
    "authors": [
      "Pierre-\u00c9tienne H. Fiquet",
      "Eero P. Simoncelli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03543",
    "title": "3D Equivariant Diffusion for Target-Aware Molecule Generation and  Affinity Prediction",
    "abstract": "Rich data and powerful machine learning models allow us to design drugs for a specific protein target \\textit{in silico}. Recently, the inclusion of 3D structures during targeted drug design shows superior performance to other target-free models as the atomic interaction in the 3D space is explicitly modeled. However, current 3D target-aware models either rely on the voxelized atom densities or the autoregressive sampling process, which are not equivariant to rotation or easily violate geometric constraints resulting in unrealistic structures. In this work, we develop a 3D equivariant diffusion model to solve the above challenges. To achieve target-aware molecule design, our method learns a joint generative process of both continuous atom coordinates and categorical atom types with a SE(3)-equivariant network. Moreover, we show that our model can serve as an unsupervised feature extractor to estimate the binding affinity under proper parameterization, which provides an effective way for drug screening. To evaluate our model, we propose a comprehensive framework to evaluate the quality of sampled molecules from different dimensions. Empirical studies show our model could generate molecules with more realistic 3D structures and better affinities towards the protein targets, and improve binding affinity ranking and prediction without retraining. ",
    "url": "https://arxiv.org/abs/2303.03543",
    "authors": [
      "Jiaqi Guan",
      "Wesley Wei Qian",
      "Xingang Peng",
      "Yufeng Su",
      "Jian Peng",
      "Jianzhu Ma"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03625",
    "title": "SGDA: Towards 3D Universal Pulmonary Nodule Detection via Slice Grouped  Domain Attention",
    "abstract": "Lung cancer is the leading cause of cancer death worldwide. The best solution for lung cancer is to diagnose the pulmonary nodules in the early stage, which is usually accomplished with the aid of thoracic computed tomography (CT). As deep learning thrives, convolutional neural networks (CNNs) have been introduced into pulmonary nodule detection to help doctors in this labor-intensive task and demonstrated to be very effective. However, the current pulmonary nodule detection methods are usually domain-specific, and cannot satisfy the requirement of working in diverse real-world scenarios. To address this issue, we propose a slice grouped domain attention (SGDA) module to enhance the generalization capability of the pulmonary nodule detection networks. This attention module works in the axial, coronal, and sagittal directions. In each direction, we divide the input feature into groups, and for each group, we utilize a universal adapter bank to capture the feature subspaces of the domains spanned by all pulmonary nodule datasets. Then the bank outputs are combined from the perspective of domain to modulate the input group. Extensive experiments demonstrate that SGDA enables substantially better multi-domain pulmonary nodule detection performance compared with the state-of-the-art multi-domain learning methods. ",
    "url": "https://arxiv.org/abs/2303.03625",
    "authors": [
      "Rui Xu",
      "Zhi Liu",
      "Yong Luo",
      "Han Hu",
      "Li Shen",
      "Bo Du",
      "Kaiming Kuang",
      "Jiancheng Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03634",
    "title": "PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation",
    "abstract": "Fall accidents are critical issues in an aging and aged society. Recently, many researchers developed pre-impact fall detection systems using deep learning to support wearable-based fall protection systems for preventing severe injuries. However, most works only employed simple neural network models instead of complex models considering the usability in resource-constrained mobile devices and strict latency requirements. In this work, we propose a novel pre-impact fall detection via CNN-ViT knowledge distillation, namely PreFallKD, to strike a balance between detection performance and computational complexity. The proposed PreFallKD transfers the detection knowledge from the pre-trained teacher model (vision transformer) to the student model (lightweight convolutional neural networks). Additionally, we apply data augmentation techniques to tackle issues of data imbalance. We conduct the experiment on the KFall public dataset and compare PreFallKD with other state-of-the-art models. The experiment results show that PreFallKD could boost the student model during the testing phase and achieves reliable F1-score (92.66%) and lead time (551.3 ms). ",
    "url": "https://arxiv.org/abs/2303.03634",
    "authors": [
      "Tin-Han Chi",
      "Kai-Chun Liu",
      "Chia-Yeh Hsieh",
      "Yu-Tsao",
      "Chia-Tai Chan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03660",
    "title": "ECG Classification System for Arrhythmia Detection Using Convolutional  Neural Networks",
    "abstract": "Arrhythmia is just one of the many cardiovascular illnesses that have been extensively studied throughout the years. Using a multi-lead ECG data, this research describes a deep learning (DL) technique based on a convolutional neural network (CNN) algorithm to detect cardiovascular arrhythmia in patients. The suggested CNN model has six layers total, two convolution layers, two pooling layers, and two fully linked layers within a residual block, in addition to the input and output layers. In this study, the classification of the ECG signals into five groups, Left Bundle Branch Block (LBBB), Right Bundle Branch Block (RBBB), Atrial Premature Contraction (APC), Premature Ventricular Contraction (PVC), and Normal Beat is the main goal (N). Using the MIT-BIH arrhythmia dataset, we assessed the suggested technique. The findings show that our suggested strategy classified 15000 cases with an average accuracy of 98.2%. ",
    "url": "https://arxiv.org/abs/2303.03660",
    "authors": [
      "Aryan Odugoudar",
      "Jaskaran Singh Walia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.03670",
    "title": "Weakly Supervised Caveline Detection For AUV Navigation Inside  Underwater Caves",
    "abstract": "Underwater caves are challenging environments that are crucial for water resource management, and for our understanding of hydro-geology and history. Mapping underwater caves is a time-consuming, labor-intensive, and hazardous operation. For autonomous cave mapping by underwater robots, the major challenge lies in vision-based estimation in the complete absence of ambient light, which results in constantly moving shadows due to the motion of the camera-light setup. Thus, detecting and following the caveline as navigation guidance is paramount for robots in autonomous cave mapping missions. In this paper, we present a computationally light caveline detection model based on a novel Vision Transformer (ViT)-based learning pipeline. We address the problem of scarce annotated training data by a weakly supervised formulation where the learning is reinforced through a series of noisy predictions from intermediate sub-optimal models. We validate the utility and effectiveness of such weak supervision for caveline detection and tracking in three different cave locations: USA, Mexico, and Spain. Experimental results demonstrate that our proposed model, CL-ViT, balances the robustness-efficiency trade-off, ensuring good generalization performance while offering 10+ FPS on single-board (Jetson TX2) devices. ",
    "url": "https://arxiv.org/abs/2303.03670",
    "authors": [
      "Boxiao Yu",
      "Reagan Tibbetts",
      "Titon Barua",
      "Ailani Morales",
      "Ioannis Rekleitis",
      "Md Jahidul Islam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.03678",
    "title": "A Comparative Study of Deep Learning and Iterative Algorithms for Joint  Channel Estimation and Signal Detection",
    "abstract": "Joint channel estimation and signal detection (JCESD) is crucial in wireless communication systems, but traditional algorithms perform poorly in low signal-to-noise ratio (SNR) scenarios. Deep learning (DL) methods have been investigated, but concerns regarding computational expense and lack of validation in low-SNR settings remain. Hence, the development of a robust and low-complexity model that can deliver excellent performance across a wide range of SNRs is highly desirable. In this paper, we aim to establish a benchmark where traditional algorithms and DL methods are validated on different channel models, Doppler, and SNR settings. In particular, we propose a new DL model where the backbone network is formed by unrolling the iterative algorithm, and the hyperparameters are estimated by hypernetworks. Additionally, we adapt a lightweight DenseNet to the task of JCESD for comparison. We evaluate different methods in three aspects: generalization in terms of bit error rate (BER), robustness, and complexity. Our results indicate that DL approaches outperform traditional algorithms in the challenging low-SNR setting, while the iterative algorithm performs better in highSNR settings. Furthermore, the iterative algorithm is more robust in the presence of carrier frequency offset, whereas DL methods excel when signals are corrupted by asymmetric Gaussian noise. ",
    "url": "https://arxiv.org/abs/2303.03678",
    "authors": [
      "Haocheng Ju",
      "Haimiao Zhang",
      "Lin Li",
      "Xiao Li",
      "Bin Dong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03689",
    "title": "AST-SED: An Effective Sound Event Detection Method Based on Audio  Spectrogram Transformer",
    "abstract": "In this paper, we propose an effective sound event detection (SED) method based on the audio spectrogram transformer (AST) model, pretrained on the large-scale AudioSet for audio tagging (AT) task, termed AST-SED. Pretrained AST models have recently shown promise on DCASE2022 challenge task4 where they help mitigate a lack of sufficient real annotated data. However, mainly due to differences between the AT and SED tasks, it is suboptimal to directly utilize outputs from a pretrained AST model. Hence the proposed AST-SED adopts an encoder-decoder architecture to enable effective and efficient fine-tuning without needing to redesign or retrain the AST model. Specifically, the Frequency-wise Transformer Encoder (FTE) consists of transformers with self attention along the frequency axis to address multiple overlapped audio events issue in a single clip. The Local Gated Recurrent Units Decoder (LGD) consists of nearest-neighbor interpolation (NNI) and Bidirectional Gated Recurrent Units (Bi-GRU) to compensate for temporal resolution loss in the pretrained AST model output. Experimental results on DCASE2022 task4 development set have demonstrated the superiority of the proposed AST-SED with FTE-LGD architecture. Specifically, the Event-Based F1-score (EB-F1) of 59.60% and Polyphonic Sound detection Score scenario1 (PSDS1) score of 0.5140 significantly outperform CRNN and other pretrained AST-based systems. ",
    "url": "https://arxiv.org/abs/2303.03689",
    "authors": [
      "Kang Li",
      "Yan Song",
      "Li-Rong Dai",
      "Ian McLoughlin",
      "Xin Fang",
      "Lin Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.03707",
    "title": "Hybrid quantum-classical convolutional neural network for phytoplankton  classification",
    "abstract": "The taxonomic composition and abundance of phytoplankton, having direct impact on marine ecosystem dynamic and global environment change, are listed as essential ocean variables. Phytoplankton classification is very crucial for Phytoplankton analysis, but it is very difficult because of the huge amount and tiny volume of Phytoplankton. Machine learning is the principle way of performing phytoplankton image classification automatically. When carrying out large-scale research on the marine phytoplankton, the volume of data increases overwhelmingly and more powerful computational resources are required for the success of machine learning algorithms. Recently, quantum machine learning has emerged as the potential solution for large-scale data processing by harnessing the exponentially computational power of quantum computer. Here, for the first time, we demonstrate the feasibility of quantum deep neural networks for phytoplankton classification. Hybrid quantum-classical convolutional and residual neural networks are developed based on the classical architectures. These models make a proper balance between the limited function of the current quantum devices and the large size of phytoplankton images, which make it possible to perform phytoplankton classification on the near-term quantum computers. Better performance is obtained by the quantum-enhanced models against the classical counterparts. In particular, quantum models converge much faster than classical ones. The present quantum models are versatile, and can be applied for various tasks of image classification in the field of marine science. ",
    "url": "https://arxiv.org/abs/2303.03707",
    "authors": [
      "Shangshang Shi",
      "Zhimin Wang",
      "Ruimin Shang",
      "Yanan Li",
      "Jiaxin Li",
      "Guoqiang Zhong",
      "Yongjian Gu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03758",
    "title": "Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI",
    "abstract": "The use of supervised deep learning techniques to detect pathologies in brain MRI scans can be challenging due to the diversity of brain anatomy and the need for annotated data sets. An alternative approach is to use unsupervised anomaly detection, which only requires sample-level labels of healthy brains to create a reference representation. This reference representation can then be compared to unhealthy brain anatomy in a pixel-wise manner to identify abnormalities. To accomplish this, generative models are needed to create anatomically consistent MRI scans of healthy brains. While recent diffusion models have shown promise in this task, accurately generating the complex structure of the human brain remains a challenge. In this paper, we propose a method that reformulates the generation task of diffusion models as a patch-based estimation of healthy brain anatomy, using spatial context to guide and improve reconstruction. We evaluate our approach on data of tumors and multiple sclerosis lesions and demonstrate a relative improvement of 25.1% compared to existing baselines. ",
    "url": "https://arxiv.org/abs/2303.03758",
    "authors": [
      "Finn Behrendt",
      "Debayan Bhattacharya",
      "Julia Kr\u00fcger",
      "Roland Opfer",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03900",
    "title": "New Perspectives on Regularization and Computation in Optimal  Transport-Based Distributionally Robust Optimization",
    "abstract": "We study optimal transport-based distributionally robust optimization problems where a fictitious adversary, often envisioned as nature, can choose the distribution of the uncertain problem parameters by reshaping a prescribed reference distribution at a finite transportation cost. In this framework, we show that robustification is intimately related to various forms of variation and Lipschitz regularization even if the transportation cost function fails to be (some power of) a metric. We also derive conditions for the existence and the computability of a Nash equilibrium between the decision-maker and nature, and we demonstrate numerically that nature's Nash strategy can be viewed as a distribution that is supported on remarkably deceptive adversarial samples. Finally, we identify practically relevant classes of optimal transport-based distributionally robust optimization problems that can be addressed with efficient gradient descent algorithms even if the loss function or the transportation cost function are nonconvex (but not both at the same time). ",
    "url": "https://arxiv.org/abs/2303.03900",
    "authors": [
      "Soroosh Shafieezadeh-Abadeh",
      "Liviu Aolaritei",
      "Florian D\u00f6rfler",
      "Daniel Kuhn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03962",
    "title": "Cops and Robbers on Multi-Layer Graphs",
    "abstract": "We generalise the popular cops and robbers game to multi-layer graphs, where each cop and the robber are restricted to a single layer (or set of edges). We show that initial intuition about the best way to allocate cops to layers is not always correct, and prove that the multi-layer cop number is neither bounded from above nor below by any function of the cop numbers of the individual layers. We determine that it is NP-hard to decide if k cops are sufficient to catch the robber, even if all cop layers are trees. However, we give a polynomial time algorithm to determine if k cops can win when the robber layer is a tree. Additionally, we investigate a question of worst-case division of a simple graph into layers: given a simple graph G, what is the maximum number of cops required to catch a robber over all multi-layer graphs where each edge of G is in at least one layer and all layers are connected? For cliques, suitably dense random graphs, and graphs of bounded treewidth, we determine this parameter up to multiplicative constants. Lastly we consider a multi-layer variant of Meyniel's Conjecture, and show the existence of an infinite family of graphs whose multi-layer cop number is bounded from below by a constant times n / log n, where n is the number of vertices in the graph. ",
    "url": "https://arxiv.org/abs/2303.03962",
    "authors": [
      "Jessica Enright",
      "Kitty Meeks",
      "William Pettersson",
      "John Sylvester"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:1606.00494",
    "title": "The average singular value of a complex random matrix decreases with  dimension",
    "abstract": " Comments: The estimate in Lemma 1 is wrong. This invalidates the result. Quoting v1, the error is in the substitution of the first entry of the hypergeometric 3F2, formula (3.3)). Proposition 1 is correct (the - sign is a typo, see (2.1)) and reduces the estimation to only two integrals, but despite several attempts I could not find the required estimate. This has not been published ",
    "url": "https://arxiv.org/abs/1606.00494",
    "authors": [
      "Lu\u00eds Daniel Abreu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Classical Analysis and ODEs (math.CA)"
    ]
  },
  {
    "id": "arXiv:2003.06267",
    "title": "Causal Unfoldings and Disjunctive Causes",
    "abstract": " Comments: 30 pages, no figures, submitted for publication in the special issue of the Journal Logical Methods in Computer Science devoted to the best contributions of CALCO 2019. arXiv admin note: text overlap with arXiv:1607.03747 ",
    "url": "https://arxiv.org/abs/2003.06267",
    "authors": [
      "Marc de Visme",
      "Glynn Winskel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2003.06665",
    "title": "Complementarity in Complex Networks",
    "abstract": " Title: Complementarity in Complex Networks ",
    "url": "https://arxiv.org/abs/2003.06665",
    "authors": [
      "Gabriel Budel",
      "Maksim Kitsak"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2101.02919",
    "title": "A Four-Stage Data Augmentation Approach to ResNet-Conformer Based  Acoustic Modeling for Sound Event Localization and Detection",
    "abstract": " Comments: 13 pages, 8 figures, Accepted by Transactions on Audio, Speech and Language Processing ",
    "url": "https://arxiv.org/abs/2101.02919",
    "authors": [
      "Qing Wang",
      "Jun Du",
      "Hua-Xin Wu",
      "Jia Pan",
      "Feng Ma",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2102.13392",
    "title": "Unifying Remote Sensing Image Retrieval and Classification with Robust  Fine-tuning",
    "abstract": " Comments: Performance margin with the proposed method is not statistically significant. Please refer to this http URL if you are interested in the dataset ",
    "url": "https://arxiv.org/abs/2102.13392",
    "authors": [
      "Dimitri Gominski",
      "Val\u00e9rie Gouet-Brunet",
      "Liming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2106.12735",
    "title": "Multi-Modal 3D Object Detection in Autonomous Driving: a Survey",
    "abstract": " Comments: Accepted by International Journal of Computer Vision (IJCV) ",
    "url": "https://arxiv.org/abs/2106.12735",
    "authors": [
      "Yingjie Wang",
      "Qiuyu Mao",
      "Hanqi Zhu",
      "Jiajun Deng",
      "Yu Zhang",
      "Jianmin Ji",
      "Houqiang Li",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.04100",
    "title": "Taming Self-Supervised Learning for Presentation Attack Detection:  In-Image De-Folding and Out-of-Image De-Mixing",
    "abstract": " Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS) ",
    "url": "https://arxiv.org/abs/2109.04100",
    "authors": [
      "Zhe Kong",
      "Wentian Zhang",
      "Feng Liu",
      "Wenhan Luo",
      "Haozhe Liu",
      "Linlin Shen",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.01005",
    "title": "Cerberus: Query-driven Scalable Vulnerability Detection in OAuth Service  Provider Implementations",
    "abstract": " Comments: ACM Conference on Computer and Communications Security (CCS 2022) ",
    "url": "https://arxiv.org/abs/2110.01005",
    "authors": [
      "Tamjid Al Rahat",
      "Yu Feng",
      "Yuan Tian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.06482",
    "title": "Parallel Deep Neural Networks Have Zero Duality Gap",
    "abstract": " Title: Parallel Deep Neural Networks Have Zero Duality Gap ",
    "url": "https://arxiv.org/abs/2110.06482",
    "authors": [
      "Yifei Wang",
      "Tolga Ergen",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2111.07620",
    "title": "Fingerprint Presentation Attack Detection by Channel-wise Feature  Denoising",
    "abstract": " Comments: 15 pages, 8 figures, Accepted by TIFS ",
    "url": "https://arxiv.org/abs/2111.07620",
    "authors": [
      "Feng Liu",
      "Zhe Kong",
      "Haozhe Liu",
      "Wentian Zhang",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.11485",
    "title": "A Free Lunch from the Noise: Provable and Practical Exploration for  Representation Learning",
    "abstract": " Comments: UAI 2022. The first two authors contribute equally ",
    "url": "https://arxiv.org/abs/2111.11485",
    "authors": [
      "Tongzheng Ren",
      "Tianjun Zhang",
      "Csaba Szepesv\u00e1ri",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.01565",
    "title": "User Evaluation of Culture-to-Culture Image Translation with Generative  Adversarial Nets",
    "abstract": " Comments: 40 pages (bibliography excluded), 5 figures, 6 Tables ",
    "url": "https://arxiv.org/abs/2201.01565",
    "authors": [
      "Giulia Zaino",
      "Carmine Tommaso Recchiuto",
      "Antonio Sgorbissa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.02478",
    "title": "Bayesian Neural Networks for Reversible Steganography",
    "abstract": " Title: Bayesian Neural Networks for Reversible Steganography ",
    "url": "https://arxiv.org/abs/2201.02478",
    "authors": [
      "Ching-Chun Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2202.00182",
    "title": "Semi-supervised 3D Object Detection via Temporal Graph Neural Networks",
    "abstract": " Comments: 3DV 2021 ",
    "url": "https://arxiv.org/abs/2202.00182",
    "authors": [
      "Jianren Wang",
      "Haiming Gang",
      "Siddharth Ancha",
      "Yi-Ting Chen",
      "David Held"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.09418",
    "title": "Uniting Control and Data Parallelism: Towards Scalable Memory-Driven  Dynamic Graph Processing",
    "abstract": " Comments: The paper did not publish and we are working on a new paper that is very different than this one but contains some information that is in this paper ",
    "url": "https://arxiv.org/abs/2202.09418",
    "authors": [
      "Bibrak Qamar Chandio",
      "Thomas Sterling",
      "Prateek Srivastava"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.09657",
    "title": "Survey of Machine Learning Based Intrusion Detection Methods for  Internet of Medical Things",
    "abstract": " Comments: 40 pages, 3 figures, and 6 tables ",
    "url": "https://arxiv.org/abs/2202.09657",
    "authors": [
      "Ayoub Si-Ahmed",
      "Mohammed Ali Al-Garadi",
      "Narhimene Boustia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01821",
    "title": "Intention Aware Robot Crowd Navigation with Attention-Based Interaction  Graph",
    "abstract": " Comments: Published as a conference paper in IEEE International Conference on Robotics and Automation (ICRA), 2023 ",
    "url": "https://arxiv.org/abs/2203.01821",
    "authors": [
      "Shuijing Liu",
      "Peixin Chang",
      "Zhe Huang",
      "Neeloy Chakraborty",
      "Kaiwen Hong",
      "Weihang Liang",
      "D. Livingston McPherson",
      "Junyi Geng",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.05869",
    "title": "View Synthesis with Sculpted Neural Points",
    "abstract": " Title: View Synthesis with Sculpted Neural Points ",
    "url": "https://arxiv.org/abs/2205.05869",
    "authors": [
      "Yiming Zuo",
      "Jia Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01288",
    "title": "Decentralized Training of Foundation Models in Heterogeneous  Environments",
    "abstract": " Title: Decentralized Training of Foundation Models in Heterogeneous  Environments ",
    "url": "https://arxiv.org/abs/2206.01288",
    "authors": [
      "Binhang Yuan",
      "Yongjun He",
      "Jared Quincy Davis",
      "Tianyi Zhang",
      "Tri Dao",
      "Beidi Chen",
      "Percy Liang",
      "Christopher Re",
      "Ce Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01299",
    "title": "Fine-tuning Language Models over Slow Networks using Activation  Compression with Guarantees",
    "abstract": " Title: Fine-tuning Language Models over Slow Networks using Activation  Compression with Guarantees ",
    "url": "https://arxiv.org/abs/2206.01299",
    "authors": [
      "Jue Wang",
      "Binhang Yuan",
      "Luka Rimanic",
      "Yongjun He",
      "Tri Dao",
      "Beidi Chen",
      "Christopher Re",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2207.00378",
    "title": "Rapid training of quantum recurrent neural networks",
    "abstract": " Title: Rapid training of quantum recurrent neural networks ",
    "url": "https://arxiv.org/abs/2207.00378",
    "authors": [
      "Micha\u0142 Siemaszko",
      "Adam Buraczewski",
      "Bertrand Le Saux",
      "Magdalena Stobi\u0144ska"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08773",
    "title": "Having your Privacy Cake and Eating it Too: Platform-supported Auditing  of Social Media Algorithms for Public Interest",
    "abstract": " Title: Having your Privacy Cake and Eating it Too: Platform-supported Auditing  of Social Media Algorithms for Public Interest ",
    "url": "https://arxiv.org/abs/2207.08773",
    "authors": [
      "Basileal Imana",
      "Aleksandra Korolova",
      "John Heidemann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.09339",
    "title": "Vision Transformers: From Semantic Segmentation to Dense Prediction",
    "abstract": " Comments: Extended version of CVPR 2021 paper arXiv:2012.15840 ",
    "url": "https://arxiv.org/abs/2207.09339",
    "authors": [
      "Li Zhang",
      "Jiachen Lu",
      "Sixiao Zheng",
      "Xinxuan Zhao",
      "Xiatian Zhu",
      "Yanwei Fu",
      "Tao Xiang",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.07750",
    "title": "Asymmetric Dual-Mode Constellation and Protograph LDPC Code Design for  Generalized Spatial MPPM Systems",
    "abstract": " Comments: accepted by IEEE transactions on communications ",
    "url": "https://arxiv.org/abs/2208.07750",
    "authors": [
      "Liang Lv",
      "Yi Fang",
      "Lin Dai",
      "Yonghui Li",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.09515",
    "title": "Spectral Decomposition Representation for Reinforcement Learning",
    "abstract": " Comments: ICLR 2023. The first two authors contribute equally ",
    "url": "https://arxiv.org/abs/2208.09515",
    "authors": [
      "Tongzheng Ren",
      "Tianjun Zhang",
      "Lisa Lee",
      "Joseph E. Gonzalez",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.11274",
    "title": "Revisiting Code Search in a Two-Stage Paradigm",
    "abstract": " Comments: Accepted by WSDM 2023 ",
    "url": "https://arxiv.org/abs/2208.11274",
    "authors": [
      "Fan Hu",
      "Yanlin Wang",
      "Lun Du",
      "Xirong Li",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2209.02772",
    "title": "Semi-supervised Invertible Neural Operators for Bayesian Inverse  Problems",
    "abstract": " Title: Semi-supervised Invertible Neural Operators for Bayesian Inverse  Problems ",
    "url": "https://arxiv.org/abs/2209.02772",
    "authors": [
      "Sebastian Kaltenbach",
      "Paris Perdikaris",
      "Phaedon-Stelios Koutsourelakis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2209.02890",
    "title": "Data-Driven Target Localization Using Adaptive Radar Processing and  Convolutional Neural Networks",
    "abstract": " Comments: 34 pages, 22 figures. Submitted to IEEE Transactions on Aerospace and Electronic Systems ",
    "url": "https://arxiv.org/abs/2209.02890",
    "authors": [
      "Shyam Venkatasubramanian",
      "Sandeep Gogineni",
      "Bosung Kang",
      "Ali Pezeshki",
      "Muralidhar Rangaswamy",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.06896",
    "title": "Persistently Feasible Robust Safe Control by Safety Index Synthesis and  Convex Semi-Infinite Programming",
    "abstract": " Title: Persistently Feasible Robust Safe Control by Safety Index Synthesis and  Convex Semi-Infinite Programming ",
    "url": "https://arxiv.org/abs/2209.06896",
    "authors": [
      "Tianhao Wei",
      "Shucheng Kang",
      "Weiye Zhao",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.10802",
    "title": "Robust Forecasting for Robotic Control: A Game-Theoretic Approach",
    "abstract": " Title: Robust Forecasting for Robotic Control: A Game-Theoretic Approach ",
    "url": "https://arxiv.org/abs/2209.10802",
    "authors": [
      "Shubhankar Agarwal",
      "David Fridovich-Keil",
      "Sandeep P. Chinchali"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11367",
    "title": "Towards Robust Autonomous Grasping with Reflexes Using High-Bandwidth  Sensing and Actuation",
    "abstract": " Comments: 6 pages, 1 page of references, supplementary video at this https URL Appearing at ICRA 2023 ",
    "url": "https://arxiv.org/abs/2209.11367",
    "authors": [
      "Andrew SaLoutos",
      "Hongmin Kim",
      "Elijah Stanger-Jones",
      "Menglong Guo",
      "Sangbae Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.12878",
    "title": "Learning and Deploying Robust Locomotion Policies with Minimal Dynamics  Randomization",
    "abstract": " Comments: 8 pages, 5 figures. Under review. Supplementary video: this https URL Project website: this https URL ",
    "url": "https://arxiv.org/abs/2209.12878",
    "authors": [
      "Luigi Campanaro",
      "Siddhant Gangapurwala",
      "Wolfgang Merkt",
      "Ioannis Havoutis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00030",
    "title": "VIP: Towards Universal Visual Reward and Representation via  Value-Implicit Pre-Training",
    "abstract": " Comments: ICLR 2023, Notable-Top-25% (Spotlight). Project website: this https URL ",
    "url": "https://arxiv.org/abs/2210.00030",
    "authors": [
      "Yecheng Jason Ma",
      "Shagun Sodhani",
      "Dinesh Jayaraman",
      "Osbert Bastani",
      "Vikash Kumar",
      "Amy Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00102",
    "title": "MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP  Initialization",
    "abstract": " Comments: Accepted by ICLR2023 ",
    "url": "https://arxiv.org/abs/2210.00102",
    "authors": [
      "Xiaotian Han",
      "Tong Zhao",
      "Yozen Liu",
      "Xia Hu",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.00305",
    "title": "LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph  Embeddings",
    "abstract": " Comments: Work in progress and the project website is this https URL ",
    "url": "https://arxiv.org/abs/2210.00305",
    "authors": [
      "Xin Xie",
      "Zhoubo Li",
      "Xiaohan Wang",
      "Yuqi Zhu",
      "Ningyu Zhang",
      "Jintian Zhang",
      "Siyuan Cheng",
      "Bozhong Tian",
      "Shumin Deng",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06575",
    "title": "GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and  Specular Objects Using Generalizable NeRF",
    "abstract": " Comments: IEEE International Conference on Robotics and Automation (ICRA), 2023 ",
    "url": "https://arxiv.org/abs/2210.06575",
    "authors": [
      "Qiyu Dai",
      "Yan Zhu",
      "Yiran Geng",
      "Ciyu Ruan",
      "Jiazhao Zhang",
      "He Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06983",
    "title": "Denoising Masked AutoEncoders Help Robust Classification",
    "abstract": " Comments: ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.06983",
    "authors": [
      "Quanlin Wu",
      "Hang Ye",
      "Yuntian Gu",
      "Huishuai Zhang",
      "Liwei Wang",
      "Di He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10243",
    "title": "CLUTR: Curriculum Learning via Unsupervised Task Representation Learning",
    "abstract": " Comments: Preprint, Currently Under Review ",
    "url": "https://arxiv.org/abs/2210.10243",
    "authors": [
      "Abdus Salam Azad",
      "Izzeddin Gur",
      "Jasper Emhoff",
      "Nathaniel Alexis",
      "Aleksandra Faust",
      "Pieter Abbeel",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.00608",
    "title": "ReachLipBnB: A branch-and-bound method for reachability analysis of  neural autonomous systems using Lipschitz bounds",
    "abstract": " Title: ReachLipBnB: A branch-and-bound method for reachability analysis of  neural autonomous systems using Lipschitz bounds ",
    "url": "https://arxiv.org/abs/2211.00608",
    "authors": [
      "Taha Entesari",
      "Sina Sharifi",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.05385",
    "title": "GANStrument: Adversarial Instrument Sound Synthesis with Pitch-invariant  Instance Conditioning",
    "abstract": " Comments: 5 pages, 4 figures, Accepted to 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Audio examples: this https URL ",
    "url": "https://arxiv.org/abs/2211.05385",
    "authors": [
      "Gaku Narita",
      "Junichi Shimizu",
      "Taketo Akama"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.08405",
    "title": "Using multimodal learning and deep generative models for corporate  bankruptcy prediction",
    "abstract": " Title: Using multimodal learning and deep generative models for corporate  bankruptcy prediction ",
    "url": "https://arxiv.org/abs/2211.08405",
    "authors": [
      "Rogelio A. Mancisidor"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.12046",
    "title": "DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors",
    "abstract": " Comments: To be appeared at CVPR 2023, Code: this https URL, Project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.12046",
    "authors": [
      "Dogyoon Lee",
      "Minhyeok Lee",
      "Chajin Shin",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14085",
    "title": "Positive unlabeled learning with tensor networks",
    "abstract": " Comments: 12 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2211.14085",
    "authors": [
      "Bojan \u017dunkovi\u010d"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17244",
    "title": "Tight Certification of Adversarially Trained Neural Networks via  Nonconvex Low-Rank Semidefinite Relaxations",
    "abstract": " Title: Tight Certification of Adversarially Trained Neural Networks via  Nonconvex Low-Rank Semidefinite Relaxations ",
    "url": "https://arxiv.org/abs/2211.17244",
    "authors": [
      "Hong-Ming Chiu",
      "Richard Y. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.04500",
    "title": "Masked Video Distillation: Rethinking Masked Feature Modeling for  Self-supervised Video Representation Learning",
    "abstract": " Comments: CVPR 2023, code will be available at this https URL ",
    "url": "https://arxiv.org/abs/2212.04500",
    "authors": [
      "Rui Wang",
      "Dongdong Chen",
      "Zuxuan Wu",
      "Yinpeng Chen",
      "Xiyang Dai",
      "Mengchen Liu",
      "Lu Yuan",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08765",
    "title": "Latent Variable Representation for Reinforcement Learning",
    "abstract": " Comments: ICLR 2023. The first two authors contribute equally. Project Website: this https URL ",
    "url": "https://arxiv.org/abs/2212.08765",
    "authors": [
      "Tongzheng Ren",
      "Chenjun Xiao",
      "Tianjun Zhang",
      "Na Li",
      "Zhaoran Wang",
      "Sujay Sanghavi",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.04314",
    "title": "ML-FEED: Machine Learning Framework for Efficient Exploit Detection",
    "abstract": " Comments: This paper has been published in The Fourth IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications, 2022 ",
    "url": "https://arxiv.org/abs/2301.04314",
    "authors": [
      "Tanujay Saha",
      "Tamjid Al-Rahat",
      "Najwa Aaraj",
      "Yuan Tian",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.04388",
    "title": "Perceive and predict: self-supervised speech representation based loss  functions for speech enhancement",
    "abstract": " Comments: 4 pages, accepted at ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2301.04388",
    "authors": [
      "George Close",
      "William Ravenscroft",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2301.06986",
    "title": "General Index Reduction by Embedding for Integro-differential-algebraic  Equations",
    "abstract": " Comments: 11 pages, 7 figures, conference. arXiv admin note: text overlap with arXiv:2210.16707 ",
    "url": "https://arxiv.org/abs/2301.06986",
    "authors": [
      "Wenqiang Yang",
      "Wenyuan Wu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.08987",
    "title": "Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors",
    "abstract": " Title: Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors ",
    "url": "https://arxiv.org/abs/2301.08987",
    "authors": [
      "Zeyu Tang",
      "Yatong Chen",
      "Yang Liu",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12355",
    "title": "Semantics-enhanced Temporal Graph Networks for Content Caching and  Energy Saving",
    "abstract": " Title: Semantics-enhanced Temporal Graph Networks for Content Caching and  Energy Saving ",
    "url": "https://arxiv.org/abs/2301.12355",
    "authors": [
      "Jianhang Zhu",
      "Rongpeng Li",
      "Xianfu Chen",
      "Shiwen Mao",
      "Jianjun Wu",
      "Zhifeng Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.12739",
    "title": "FractalAD: A simple industrial anomaly detection method using fractal  anomaly generation and backbone knowledge distillation",
    "abstract": " Comments: 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2301.12739",
    "authors": [
      "Xuan Xia",
      "Weijie Lv",
      "Xing He",
      "Nan Li",
      "Chuanqi Liu",
      "Ning Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03573",
    "title": "Local Neural Descriptor Fields: Locally Conditioned Object  Representations for Manipulation",
    "abstract": " Comments: ICRA 2023, Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2302.03573",
    "authors": [
      "Ethan Chun",
      "Yilun Du",
      "Anthony Simeonov",
      "Tomas Lozano-Perez",
      "Leslie Kaelbling"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04031",
    "title": "FR-LIO: Fast and Robust Lidar-Inertial Odometry by Tightly-Coupled  Iterated Kalman Smoother and Robocentric Voxels",
    "abstract": " Title: FR-LIO: Fast and Robust Lidar-Inertial Odometry by Tightly-Coupled  Iterated Kalman Smoother and Robocentric Voxels ",
    "url": "https://arxiv.org/abs/2302.04031",
    "authors": [
      "Xiaoyu Zhao",
      "Xiaolong Qian",
      "Yunzhou Zhang",
      "Yuezhang Lv",
      "Shiwen Liang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.06650",
    "title": "Surround-View Vision-based 3D Detection for Autonomous Driving: A Survey",
    "abstract": " Title: Surround-View Vision-based 3D Detection for Autonomous Driving: A Survey ",
    "url": "https://arxiv.org/abs/2302.06650",
    "authors": [
      "Apoorv Singh",
      "Varun Bankiti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.07372",
    "title": "Same Same, But Different: Conditional Multi-Task Learning for  Demographic-Specific Toxicity Detection",
    "abstract": " Title: Same Same, But Different: Conditional Multi-Task Learning for  Demographic-Specific Toxicity Detection ",
    "url": "https://arxiv.org/abs/2302.07372",
    "authors": [
      "Soumyajit Gupta",
      "Sooyong Lee",
      "Maria De-Arteaga",
      "Matthew Lease"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.08220",
    "title": "Dialogue State Distillation Network with Inter-slot Contrastive Learning  for Dialogue State Tracking",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2302.08220",
    "authors": [
      "Jing Xu",
      "Dandan Song",
      "Chong Liu",
      "Siu Cheung Hui",
      "Fei Li",
      "Qiang Ju",
      "Xiaonan He",
      "Jian Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.08231",
    "title": "3M3D: Multi-view, Multi-path, Multi-representation for 3D Object  Detection",
    "abstract": " Title: 3M3D: Multi-view, Multi-path, Multi-representation for 3D Object  Detection ",
    "url": "https://arxiv.org/abs/2302.08231",
    "authors": [
      "Jongwoo Park",
      "Apoorv Singh",
      "Varun Bankiti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.08261",
    "title": "Knowledge-augmented Graph Machine Learning for Drug Discovery: A Survey  from Precision to Interpretability",
    "abstract": " Title: Knowledge-augmented Graph Machine Learning for Drug Discovery: A Survey  from Precision to Interpretability ",
    "url": "https://arxiv.org/abs/2302.08261",
    "authors": [
      "Zhiqiang Zhong",
      "Anastasia Barkova",
      "Davide Mottin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.09051",
    "title": "Complex QA and language models hybrid architectures, Survey",
    "abstract": " Title: Complex QA and language models hybrid architectures, Survey ",
    "url": "https://arxiv.org/abs/2302.09051",
    "authors": [
      "Xavier Daull",
      "Patrice Bellot",
      "Emmanuel Bruno",
      "Vincent Martin",
      "Elisabeth Murisasco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11864",
    "title": "Grounding Graph Network Simulators using Physical Sensor Observations",
    "abstract": " Comments: Accepted as a poster at the 11th International Conference on Learning Representations (ICLR), 2023 ",
    "url": "https://arxiv.org/abs/2302.11864",
    "authors": [
      "Jonas Linkerh\u00e4gner",
      "Niklas Freymuth",
      "Paul Maria Scheikl",
      "Franziska Mathis-Ullrich",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.13149",
    "title": "STACC: Code Comment Classification using SentenceTransformers",
    "abstract": " Title: STACC: Code Comment Classification using SentenceTransformers ",
    "url": "https://arxiv.org/abs/2302.13149",
    "authors": [
      "Ali Al-Kaswan",
      "Maliheh Izadi",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.14311",
    "title": "Towards Memory- and Time-Efficient Backpropagation for Training Spiking  Neural Networks",
    "abstract": " Title: Towards Memory- and Time-Efficient Backpropagation for Training Spiking  Neural Networks ",
    "url": "https://arxiv.org/abs/2302.14311",
    "authors": [
      "Qingyan Meng",
      "Mingqing Xiao",
      "Shen Yan",
      "Yisen Wang",
      "Zhouchen Lin",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.00628",
    "title": "MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition  and Robust Speech-to-Text Translation",
    "abstract": " Title: MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition  and Robust Speech-to-Text Translation ",
    "url": "https://arxiv.org/abs/2303.00628",
    "authors": [
      "Mohamed Anwar",
      "Bowen Shi",
      "Vedanuj Goswami",
      "Wei-Ning Hsu",
      "Juan Pino",
      "Changhan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.02219",
    "title": "NSGA-PINN: A Multi-Objective Optimization Method for Physics-Informed  Neural Network Training",
    "abstract": " Comments: 13 pages, 35 figures ",
    "url": "https://arxiv.org/abs/2303.02219",
    "authors": [
      "Binghang Lu",
      "Christian B. Moya",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02673",
    "title": "Time-frequency Network for Robust Speaker Recognition",
    "abstract": " Comments: 5pages, 3 figures ",
    "url": "https://arxiv.org/abs/2303.02673",
    "authors": [
      "Jiguo Li",
      "Tianzi Zhang",
      "Xiaobin Liu",
      "Lirong Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.02698",
    "title": "Robust affine feature matching via quadratic assignment on Grassmannians",
    "abstract": " Comments: 12 pages, 18 figures; GitHub repository at (this https URL) ",
    "url": "https://arxiv.org/abs/2303.02698",
    "authors": [
      "Alexander Kolpakov",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03003",
    "title": "Efficient Large-scale Scene Representation with a Hybrid of  High-resolution Grid and Plane Features",
    "abstract": " Title: Efficient Large-scale Scene Representation with a Hybrid of  High-resolution Grid and Plane Features ",
    "url": "https://arxiv.org/abs/2303.03003",
    "authors": [
      "Yuqi Zhang",
      "Guanying Chen",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]