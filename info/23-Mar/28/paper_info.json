[
  {
    "id": "arXiv:2303.14197",
    "title": "Optimal Smoothing Distribution Exploration for Backdoor Neutralization  in Deep Learning-based Traffic Systems",
    "abstract": "Deep Reinforcement Learning (DRL) enhances the efficiency of Autonomous Vehicles (AV), but also makes them susceptible to backdoor attacks that can result in traffic congestion or collisions. Backdoor functionality is typically incorporated by contaminating training datasets with covert malicious data to maintain high precision on genuine inputs while inducing the desired (malicious) outputs for specific inputs chosen by adversaries. Current defenses against backdoors mainly focus on image classification using image-based features, which cannot be readily transferred to the regression task of DRL-based AV controllers since the inputs are continuous sensor data, i.e., the combinations of velocity and distance of AV and its surrounding vehicles. Our proposed method adds well-designed noise to the input to neutralize backdoors. The approach involves learning an optimal smoothing (noise) distribution to preserve the normal functionality of genuine inputs while neutralizing backdoors. By doing so, the resulting model is expected to be more resilient against backdoor attacks while maintaining high accuracy on genuine inputs. The effectiveness of the proposed method is verified on a simulated traffic system based on a microscopic traffic simulator, where experimental results showcase that the smoothed traffic controller can neutralize all trigger samples and maintain the performance of relieving traffic congestion ",
    "url": "https://arxiv.org/abs/2303.14197",
    "authors": [
      "Yue Wang",
      "Wending Li",
      "Michail Maniatakos",
      "Saif Eddin Jabari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.14207",
    "title": "DiffuScene: Scene Graph Denoising Diffusion Probabilistic Model for  Generative Indoor Scene Synthesis",
    "abstract": "We present DiffuScene for indoor 3D scene synthesis based on a novel scene graph denoising diffusion probabilistic model, which generates 3D instance properties stored in a fully-connected scene graph and then retrieves the most similar object geometry for each graph node i.e. object instance which is characterized as a concatenation of different attributes, including location, size, orientation, semantic, and geometry features. Based on this scene graph, we designed a diffusion model to determine the placements and types of 3D instances. Our method can facilitate many downstream applications, including scene completion, scene arrangement, and text-conditioned scene synthesis. Experiments on the 3D-FRONT dataset show that our method can synthesize more physically plausible and diverse indoor scenes than state-of-the-art methods. Extensive ablation studies verify the effectiveness of our design choice in scene diffusion models. ",
    "url": "https://arxiv.org/abs/2303.14207",
    "authors": [
      "Jiapeng Tang",
      "Yinyu Nie",
      "Lev Markhasin",
      "Angela Dai",
      "Justus Thies",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14213",
    "title": "The Influence of Social User Knowledge Level and Active Communication  Channel Control on Rumor Spread",
    "abstract": "This research examines the propagation of rumors on social networks during public health emergencies and explores strategies to effectively manage false information in cyberspace. Using a simulation model, the study analyzes the impact of factors such as communication channel control, government intervention, and individual personalities on the spread of rumors. The results suggest that enhancing netizens' knowledge and capacity to recognize and resist rumors, developing rumor-debunking platforms, and promoting a \"clear\" ecology of network information content are effective strategies for controlling false information in cyberspace. However, the complexity and scale of actual networks present challenges to the development of a comprehensive cyberspace governance system. The findings offer practical guidelines for improving the effectiveness of governance in managing the spread of rumors on social networks. ",
    "url": "https://arxiv.org/abs/2303.14213",
    "authors": [
      "Yixuan Zhao",
      "Rohitha Settipalli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2303.14219",
    "title": "Proceedings Twelfth International Workshop on Computing with Terms and  Graphs",
    "abstract": "The workshop TERMGRAPH 2022 took place at Technion in Haifa, Israel, on August 1, 2022, in the Pre-FLoC workshop block (July 31--August 1) of FLoC 2022 (Federated Logic Conference 2022, July 31--August 12). As such, TERMGRAPH 2022 was a one-day satellite event of the conference FSCD 2022 (Formal Structures of Computation and Deduction 2020, August 2--5). ",
    "url": "https://arxiv.org/abs/2303.14219",
    "authors": [
      "Clemens Grabmayer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2303.14227",
    "title": "Causality Detection for Efficient Multi-Agent Reinforcement Learning",
    "abstract": "When learning a task as a team, some agents in Multi-Agent Reinforcement Learning (MARL) may fail to understand their true impact in the performance of the team. Such agents end up learning sub-optimal policies, demonstrating undesired lazy behaviours. To investigate this problem, we start by formalising the use of temporal causality applied to MARL problems. We then show how causality can be used to penalise such lazy agents and improve their behaviours. By understanding how their local observations are causally related to the team reward, each agent in the team can adjust their individual credit based on whether they helped to cause the reward or not. We show empirically that using causality estimations in MARL improves not only the holistic performance of the team, but also the individual capabilities of each agent. We observe that the improvements are consistent in a set of different environments. ",
    "url": "https://arxiv.org/abs/2303.14227",
    "authors": [
      "Rafael Pina",
      "Varuna De Silva",
      "Corentin Artaud"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.14240",
    "title": "Adaptive Base-class Suppression and Prior Guidance Network for One-Shot  Object Detection",
    "abstract": "One-shot object detection (OSOD) aims to detect all object instances towards the given category specified by a query image. Most existing studies in OSOD endeavor to explore effective cross-image correlation and alleviate the semantic feature misalignment, however, ignoring the phenomenon of the model bias towards the base classes and the generalization degradation on the novel classes. Observing this, we propose a novel framework, namely Base-class Suppression and Prior Guidance (BSPG) network to overcome the problem. Specifically, the objects of base categories can be explicitly detected by a base-class predictor and adaptively eliminated by our base-class suppression module. Moreover, a prior guidance module is designed to calculate the correlation of high-level features in a non-parametric manner, producing a class-agnostic prior map to provide the target features with rich semantic cues and guide the subsequent detection process. Equipped with the proposed two modules, we endow the model with a strong discriminative ability to distinguish the target objects from distractors belonging to the base classes. Extensive experiments show that our method outperforms the previous techniques by a large margin and achieves new state-of-the-art performance under various evaluation settings. ",
    "url": "https://arxiv.org/abs/2303.14240",
    "authors": [
      "Wenwen Zhang",
      "Xinyu Xiao",
      "Hangguan Shan",
      "Eryun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14241",
    "title": "Core-based Trend Detection in Blockchain Networks",
    "abstract": "Blockchains are now significantly easing trade finance, with billions of dollars worth of assets being transacted daily. However, analyzing these networks remains challenging due to the large size and complexity of the data. We introduce a scalable approach called \"InnerCore\" for identifying key actors in blockchain-based networks and providing a sentiment indicator for the networks using data depth-based core decomposition and centered-motif discovery. InnerCore is a computationally efficient, unsupervised approach suitable for analyzing large temporal graphs. We demonstrate its effectiveness through case studies on the recent collapse of LunaTerra and the Proof-of-Stake (PoS) switch of Ethereum, using external ground truth collected by a leading blockchain analysis company. Our experiments show that InnerCore can match the qualified analysis accurately without human involvement, automating blockchain analysis and its trend detection in a scalable manner. ",
    "url": "https://arxiv.org/abs/2303.14241",
    "authors": [
      "Jason Zhu",
      "Arijit Khan",
      "Cuneyt Gurcan Akcora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.14243",
    "title": "DyLiN: Making Light Field Networks Dynamic",
    "abstract": "Light Field Networks, the re-formulations of radiance fields to oriented rays, are magnitudes faster than their coordinate network counterparts, and provide higher fidelity with respect to representing 3D structures from 2D observations. They would be well suited for generic scene representation and manipulation, but suffer from one problem: they are limited to holistic and static scenes. In this paper, we propose the Dynamic Light Field Network (DyLiN) method that can handle non-rigid deformations, including topological changes. We learn a deformation field from input rays to canonical rays, and lift them into a higher dimensional space to handle discontinuities. We further introduce CoDyLiN, which augments DyLiN with controllable attribute inputs. We train both models via knowledge distillation from pretrained dynamic radiance fields. We evaluated DyLiN using both synthetic and real world datasets that include various non-rigid deformations. DyLiN qualitatively outperformed and quantitatively matched state-of-the-art methods in terms of visual fidelity, while being 25 - 71x computationally faster. We also tested CoDyLiN on attribute annotated data and it surpassed its teacher model. Project page: https://dylin2023.github.io . ",
    "url": "https://arxiv.org/abs/2303.14243",
    "authors": [
      "Heng Yu",
      "Joel Julin",
      "Zoltan A. Milacski",
      "Koichiro Niinuma",
      "Laszlo A. Jeni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14254",
    "title": "Towards Diverse and Coherent Augmentation for Time-Series Forecasting",
    "abstract": "Time-series data augmentation mitigates the issue of insufficient training data for deep learning models. Yet, existing augmentation methods are mainly designed for classification, where class labels can be preserved even if augmentation alters the temporal dynamics. We note that augmentation designed for forecasting requires diversity as well as coherence with the original temporal dynamics. As time-series data generated by real-life physical processes exhibit characteristics in both the time and frequency domains, we propose to combine Spectral and Time Augmentation (STAug) for generating more diverse and coherent samples. Specifically, in the frequency domain, we use the Empirical Mode Decomposition to decompose a time series and reassemble the subcomponents with random weights. This way, we generate diverse samples while being coherent with the original temporal relationships as they contain the same set of base components. In the time domain, we adapt a mix-up strategy that generates diverse as well as linearly in-between coherent samples. Experiments on five real-world time-series datasets demonstrate that STAug outperforms the base models without data augmentation as well as state-of-the-art augmentation methods. ",
    "url": "https://arxiv.org/abs/2303.14254",
    "authors": [
      "Xiyuan Zhang",
      "Ranak Roy Chowdhury",
      "Jingbo Shang",
      "Rajesh Gupta",
      "Dezhi Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14256",
    "title": "Automated Identification of Performance Changes at Code Level",
    "abstract": "To develop software with optimal performance, even small performance changes need to be identified. Identifying performance changes is challenging since the performance of software is influenced by non-deterministic factors. Therefore, not every performance change is measurable with reasonable effort. In this work, we discuss which performance changes are measurable at code level with reasonable measurement effort and how to identify them. We present (1) an analysis of the boundaries of measuring performance changes, (2) an approach for determining a configuration for reproducible performance change identification, and (3) an evaluation comparing of how well our approach is able to identify performance changes in the application server Jetty compared with the usage of Jetty's own performance regression benchmarks. Thereby, we find (1) that small performance differences are only measurable by fine-grained measurement workloads, (2) that performance changes caused by the change of one operation can be identified using a unit-test-sized workload definition and a suitable configuration, and (3) that using our approach identifies small performance regressions more efficiently than using Jetty's performance regression benchmarks. ",
    "url": "https://arxiv.org/abs/2303.14256",
    "authors": [
      "David Georg Reichelt",
      "Stefan K\u00fchne",
      "Wilhelm Hasselbring"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.14267",
    "title": "A Self-supervised Framework for Improved Data-Driven Monitoring of  Stress via Multi-modal Passive Sensing",
    "abstract": "Recent advances in remote health monitoring systems have significantly benefited patients and played a crucial role in improving their quality of life. However, while physiological health-focused solutions have demonstrated increasing success and maturity, mental health-focused applications have seen comparatively limited success in spite of the fact that stress and anxiety disorders are among the most common issues people deal with in their daily lives. In the hopes of furthering progress in this domain through the development of a more robust analytic framework for the measurement of indicators of mental health, we propose a multi-modal semi-supervised framework for tracking physiological precursors of the stress response. Our methodology enables utilizing multi-modal data of differing domains and resolutions from wearable devices and leveraging them to map short-term episodes to semantically efficient embeddings for a given task. Additionally, we leverage an inter-modality contrastive objective, with the advantages of rendering our framework both modular and scalable. The focus on optimizing both local and global aspects of our embeddings via a hierarchical structure renders transferring knowledge and compatibility with other devices easier to achieve. In our pipeline, a task-specific pooling based on an attention mechanism, which estimates the contribution of each modality on an instance level, computes the final embeddings for observations. This additionally provides a thorough diagnostic insight into the data characteristics and highlights the importance of signals in the broader view of predicting episodes annotated per mental health status. We perform training experiments using a corpus of real-world data on perceived stress, and our results demonstrate the efficacy of the proposed approach in performance improvements. ",
    "url": "https://arxiv.org/abs/2303.14267",
    "authors": [
      "Shayan Fazeli",
      "Lionel Levine",
      "Mehrab Beikzadeh",
      "Baharan Mirzasoleiman",
      "Bita Zadeh",
      "Tara Peris",
      "Majid Sarrafzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14276",
    "title": "How to generate a fault-resilient network at a lower cost",
    "abstract": "Blockchains facilitate decentralization, security, identity, and data management in cyber-physical systems. However, consensus protocols used in blockchains are prone to high message and computational complexity costs and are not suitable to be used in IoT. One way to reduce message complexity is to randomly assign network nodes into committees or shards. Keeping committee sizes small is then desirable in order to achieve lower message complexity, but this comes with a penalty of reduced reliability as there is a higher probability that a large number of faulty nodes will end up in a committee. In this work, we study the problem of estimating a probability of a failure in randomly sharded networks. We provide new results and improve existing bounds on the failure probability. Thus, our framework also paves the way to reduce committee sizes without reducing reliability. ",
    "url": "https://arxiv.org/abs/2303.14276",
    "authors": [
      "Alexander Mozeika",
      "Mohammad M. Jalalzai",
      "Marcin P. Pawlowski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2303.14279",
    "title": "Depression detection in social media posts using affective and social  norm features",
    "abstract": "We propose a deep architecture for depression detection from social media posts. The proposed architecture builds upon BERT to extract language representations from social media posts and combines these representations using an attentive bidirectional GRU network. We incorporate affective information, by augmenting the text representations with features extracted from a pretrained emotion classifier. Motivated by psychological literature we propose to incorporate profanity and morality features of posts and words in our architecture using a late fusion scheme. Our analysis indicates that morality and profanity can be important features for depression detection. We apply our model for depression detection on Reddit posts on the Pirina dataset, and further consider the setting of detecting depressed users, given multiple posts per user, proposed in the Reddit RSDD dataset. The inclusion of the proposed features yields state-of-the-art results in both settings, namely 2.65% and 6.73% absolute improvement in F1 score respectively. Index Terms: Depression detection, BERT, Feature fusion, Emotion recognition, profanity, morality ",
    "url": "https://arxiv.org/abs/2303.14279",
    "authors": [
      "Ilias Triantafyllopoulos",
      "Georgios Paraskevopoulos",
      "Alexandros Potamianos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.14286",
    "title": "Voice-Based Conversational Agents and Knowledge Graphs for Improving  News Search in Assisted Living",
    "abstract": "As the healthcare sector is facing major challenges, such as aging populations, staff shortages, and common chronic diseases, delivering high-quality care to individuals has become very difficult. Conversational agents have shown to be a promising technology to alleviate some of these issues. In the form of digital health assistants, they have the potential to improve the everyday life of the elderly and chronically ill people. This includes, for example, medication reminders, routine checks, or social chit-chat. In addition, conversational agents can satisfy the fundamental need of having access to information about daily news or local events, which enables individuals to stay informed and connected with the world around them. However, finding relevant news sources and navigating the plethora of news articles available online can be overwhelming, particularly for those who may have limited technological literacy or health-related impairments. To address this challenge, we propose an innovative solution that combines knowledge graphs and conversational agents for news search in assisted living. By leveraging graph databases to semantically structure news data and implementing an intuitive voice-based interface, our system can help care-dependent people to easily discover relevant news articles and give personalized recommendations. We explain our design choices, provide a system architecture, share insights of an initial user test, and give an outlook on planned future work. ",
    "url": "https://arxiv.org/abs/2303.14286",
    "authors": [
      "Phillip Schneider",
      "Nils Rehtanz",
      "Kristiina Jokinen",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.14304",
    "title": "Ensemble-based Blackbox Attacks on Dense Prediction",
    "abstract": "We propose an approach for adversarial attacks on dense prediction models (such as object detectors and segmentation). It is well known that the attacks generated by a single surrogate model do not transfer to arbitrary (blackbox) victim models. Furthermore, targeted attacks are often more challenging than the untargeted attacks. In this paper, we show that a carefully designed ensemble can create effective attacks for a number of victim models. In particular, we show that normalization of the weights for individual models plays a critical role in the success of the attacks. We then demonstrate that by adjusting the weights of the ensemble according to the victim model can further improve the performance of the attacks. We performed a number of experiments for object detectors and segmentation to highlight the significance of the our proposed methods. Our proposed ensemble-based method outperforms existing blackbox attack methods for object detection and segmentation. Finally we show that our proposed method can also generate a single perturbation that can fool multiple blackbox detection and segmentation models simultaneously. Code is available at https://github.com/CSIPlab/EBAD. ",
    "url": "https://arxiv.org/abs/2303.14304",
    "authors": [
      "Zikui Cai",
      "Yaoteng Tan",
      "M. Salman Asif"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14311",
    "title": "Learned Two-Plane Perspective Prior based Image Resampling for Efficient  Object Detection",
    "abstract": "Real-time efficient perception is critical for autonomous navigation and city scale sensing. Orthogonal to architectural improvements, streaming perception approaches have exploited adaptive sampling improving real-time detection performance. In this work, we propose a learnable geometry-guided prior that incorporates rough geometry of the 3D scene (a ground plane and a plane above) to resample images for efficient object detection. This significantly improves small and far-away object detection performance while also being more efficient both in terms of latency and memory. For autonomous navigation, using the same detector and scale, our approach improves detection rate by +4.1 $AP_{S}$ or +39% and in real-time performance by +5.3 $sAP_{S}$ or +63% for small objects over state-of-the-art (SOTA). For fixed traffic cameras, our approach detects small objects at image scales other methods cannot. At the same scale, our approach improves detection of small objects by 195% (+12.5 $AP_{S}$) over naive-downsampling and 63% (+4.2 $AP_{S}$) over SOTA. ",
    "url": "https://arxiv.org/abs/2303.14311",
    "authors": [
      "Anurag Ghosh",
      "N. Dinesh Reddy",
      "Christoph Mertz",
      "Srinivasa G. Narasimhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14317",
    "title": "Adaptive Bi-Recommendation and Self-Improving Network for Heterogeneous  Domain Adaptation-Assisted IoT Intrusion Detection",
    "abstract": "As Internet of Things devices become prevalent, using intrusion detection to protect IoT from malicious intrusions is of vital importance. However, the data scarcity of IoT hinders the effectiveness of traditional intrusion detection methods. To tackle this issue, in this paper, we propose the Adaptive Bi-Recommendation and Self-Improving Network (ABRSI) based on unsupervised heterogeneous domain adaptation (HDA). The ABRSI transfers enrich intrusion knowledge from a data-rich network intrusion source domain to facilitate effective intrusion detection for data-scarce IoT target domains. The ABRSI achieves fine-grained intrusion knowledge transfer via adaptive bi-recommendation matching. Matching the bi-recommendation interests of two recommender systems and the alignment of intrusion categories in the shared feature space form a mutual-benefit loop. Besides, the ABRSI uses a self-improving mechanism, autonomously improving the intrusion knowledge transfer from four ways. A hard pseudo label voting mechanism jointly considers recommender system decision and label relationship information to promote more accurate hard pseudo label assignment. To promote diversity and target data participation during intrusion knowledge transfer, target instances failing to be assigned with a hard pseudo label will be assigned with a probabilistic soft pseudo label, forming a hybrid pseudo-labelling strategy. Meanwhile, the ABRSI also makes soft pseudo-labels globally diverse and individually certain. Finally, an error knowledge learning mechanism is utilised to adversarially exploit factors that causes detection ambiguity and learns through both current and previous error knowledge, preventing error knowledge forgetfulness. Holistically, these mechanisms form the ABRSI model that boosts IoT intrusion detection accuracy via HDA-assisted intrusion knowledge transfer. ",
    "url": "https://arxiv.org/abs/2303.14317",
    "authors": [
      "Jiashu Wu",
      "Yang Wang",
      "Hao Dai",
      "Chengzhong Xu",
      "Kenneth B. Kent"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.14322",
    "title": "Spatio-Temporal driven Attention Graph Neural Network with Block  Adjacency matrix (STAG-NN-BA)",
    "abstract": "Despite the recent advances in deep neural networks, standard convolutional kernels limit the applications of these networks to the Euclidean domain only. Considering the geodesic nature of the measurement of the earth's surface, remote sensing is one such area that can benefit from non-Euclidean and spherical domains. For this purpose, we propose a novel Graph Neural Network architecture for spatial and spatio-temporal classification using satellite imagery. We propose a hybrid attention method to learn the relative importance of irregular neighbors in remote sensing data. Instead of classifying each pixel, we propose a method based on Simple Linear Iterative Clustering (SLIC) image segmentation and Graph Attention GAT. The superpixels obtained from SLIC become the nodes of our Graph Convolution Network (GCN). We then construct a region adjacency graph (RAG) where each superpixel is connected to every other adjacent superpixel in the image, enabling information to propagate globally. Finally, we propose a Spatially driven Attention Graph Neural Network (SAG-NN) to classify each RAG. We also propose an extension to our SAG-NN for spatio-temporal data. Unlike regular grids of pixels in images, superpixels are irregular in nature and cannot be used to create spatio-temporal graphs. We introduce temporal bias by combining unconnected RAGs from each image into one supergraph. This is achieved by introducing block adjacency matrices resulting in novel Spatio-Temporal driven Attention Graph Neural Network with Block Adjacency matrix (STAG-NN-BA). We evaluate our proposed methods on two remote sensing datasets namely Asia14 and C2D2. In comparison with both non-graph and graph-based approaches our SAG-NN and STAG-NN-BA achieved superior accuracy on all the datasets while incurring less computation cost. The code and dataset will be made public via our GitHub repository. ",
    "url": "https://arxiv.org/abs/2303.14322",
    "authors": [
      "U. Nazir",
      "W. Islam",
      "M. Taj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14325",
    "title": "Backdoor Attacks with Input-unique Triggers in NLP",
    "abstract": "Backdoor attack aims at inducing neural models to make incorrect predictions for poison data while keeping predictions on the clean dataset unchanged, which creates a considerable threat to current natural language processing (NLP) systems. Existing backdoor attacking systems face two severe issues:firstly, most backdoor triggers follow a uniform and usually input-independent pattern, e.g., insertion of specific trigger words, synonym replacement. This significantly hinders the stealthiness of the attacking model, leading the trained backdoor model being easily identified as malicious by model probes. Secondly, trigger-inserted poisoned sentences are usually disfluent, ungrammatical, or even change the semantic meaning from the original sentence, making them being easily filtered in the pre-processing stage. To resolve these two issues, in this paper, we propose an input-unique backdoor attack(NURA), where we generate backdoor triggers unique to inputs. IDBA generates context-related triggers by continuing writing the input with a language model like GPT2. The generated sentence is used as the backdoor trigger. This strategy not only creates input-unique backdoor triggers, but also preserves the semantics of the original input, simultaneously resolving the two issues above. Experimental results show that the IDBA attack is effective for attack and difficult to defend: it achieves high attack success rate across all the widely applied benchmarks, while is immune to existing defending methods. In addition, it is able to generate fluent, grammatical, and diverse backdoor inputs, which can hardly be recognized through human inspection. ",
    "url": "https://arxiv.org/abs/2303.14325",
    "authors": [
      "Xukun Zhou",
      "Jiwei Li",
      "Tianwei Zhang",
      "Lingjuan Lyu",
      "Muqiao Yang",
      "Jun He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.14351",
    "title": "Hierarchical Multi-Agent Multi-Armed Bandit for Resource Allocation in  Multi-LEO Satellite Constellation Networks",
    "abstract": "Low Earth orbit (LEO) satellite constellation is capable of providing global coverage area with high-rate services in the next sixth-generation (6G) non-terrestrial network (NTN). Due to limited onboard resources of operating power, beams, and channels, resilient and efficient resource management has become compellingly imperative under complex interference cases. However, different from conventional terrestrial base stations, LEO is deployed at considerable height and under high mobility, inducing substantially long delay and interference during transmission. As a result, acquiring the accurate channel state information between LEOs and ground users is challenging. Therefore, we construct a framework with a two-way transmission under unknown channel information and no data collected at long-delay ground gateway. In this paper, we propose hierarchical multi-agent multi-armed bandit resource allocation for LEO constellation (mmRAL) by appropriately assigning available radio resources. LEOs are considered as collaborative multiple macro-agents attempting unknown trials of various actions of micro-agents of respective resources, asymptotically achieving suitable allocation with only throughput information. In simulations, we evaluate mmRAL in various cases of LEO deployment, serving numbers of users and LEOs, hardware cost and outage probability. Benefited by efficient and resilient allocation, the proposed mmRAL system is capable of operating in homogeneous or heterogeneous orbital planes or constellations, achieving the highest throughput performance compared to the existing benchmarks in open literature. ",
    "url": "https://arxiv.org/abs/2303.14351",
    "authors": [
      "Li-Hsiang Shen",
      "Yun Ho",
      "Kai-Ten Feng",
      "Lie-Liang Yang",
      "Sau-Hsuan Wu",
      "Jen-Ming Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.14369",
    "title": "Video-Text as Game Players: Hierarchical Banzhaf Interaction for  Cross-Modal Representation Learning",
    "abstract": "Contrastive learning-based video-language representation learning approaches, e.g., CLIP, have achieved outstanding performance, which pursue semantic interaction upon pre-defined video-text pairs. To clarify this coarse-grained global interaction and move a step further, we have to encounter challenging shell-breaking interactions for fine-grained cross-modal learning. In this paper, we creatively model video-text as game players with multivariate cooperative game theory to wisely handle the uncertainty during fine-grained semantic interaction with diverse granularity, flexible combination, and vague intensity. Concretely, we propose Hierarchical Banzhaf Interaction (HBI) to value possible correspondence between video frames and text words for sensitive and explainable cross-modal contrast. To efficiently realize the cooperative game of multiple video frames and multiple text words, the proposed method clusters the original video frames (text words) and computes the Banzhaf Interaction between the merged tokens. By stacking token merge modules, we achieve cooperative games at different semantic levels. Extensive experiments on commonly used text-video retrieval and video-question answering benchmarks with superior performances justify the efficacy of our HBI. More encouragingly, it can also serve as a visualization tool to promote the understanding of cross-modal interaction, which have a far-reaching impact on the community. Project page is available at https://jpthu17.github.io/HBI/. ",
    "url": "https://arxiv.org/abs/2303.14369",
    "authors": [
      "Peng Jin",
      "Jinfa Huang",
      "Pengfei Xiong",
      "Shangxuan Tian",
      "Chang Liu",
      "Xiangyang Ji",
      "Li Yuan",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.14372",
    "title": "An AI-driven intelligent traffic management model for 6G cloud radio  access networks",
    "abstract": "This letter proposes a novel Cloud Radio Access Network (C-RAN) traffic analysis and management model that estimates probable RAN traffic congestion and mitigate its effect by adopting a suitable handling mechanism. A computation approach is introduced to classify heterogeneous RAN traffic into distinct traffic states based on bandwidth consumption and execution time of various job requests. Further, a cloud-based traffic management is employed to schedule and allocate resources among user job requests according to the associated traffic states to minimize latency and maximize bandwidth utilization. The experimental evaluation and comparison of the proposed model with state-of-the-art methods reveal that it is effective in minimizing the worse effect of traffic congestion and improves bandwidth utilization and reduces job execution latency up to 17.07% and 18%, respectively. ",
    "url": "https://arxiv.org/abs/2303.14372",
    "authors": [
      "Smruti Rekha Swain",
      "Deepika Saxena",
      "Jatinder Kumar",
      "Ashutosh Kumar Singh",
      "Chung-Nan Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.14373",
    "title": "DoNet: Deep De-overlapping Network for Cytology Instance Segmentation",
    "abstract": "Cell instance segmentation in cytology images has significant importance for biology analysis and cancer screening, while remains challenging due to 1) the extensive overlapping translucent cell clusters that cause the ambiguous boundaries, and 2) the confusion of mimics and debris as nuclei. In this work, we proposed a De-overlapping Network (DoNet) in a decompose-and-recombined strategy. A Dual-path Region Segmentation Module (DRM) explicitly decomposes the cell clusters into intersection and complement regions, followed by a Semantic Consistency-guided Recombination Module (CRM) for integration. To further introduce the containment relationship of the nucleus in the cytoplasm, we design a Mask-guided Region Proposal Strategy (MRP) that integrates the cell attention maps for inner-cell instance prediction. We validate the proposed approach on ISBI2014 and CPS datasets. Experiments show that our proposed DoNet significantly outperforms other state-of-the-art (SOTA) cell instance segmentation methods. The code is available at https://github.com/DeepDoNet/DoNet. ",
    "url": "https://arxiv.org/abs/2303.14373",
    "authors": [
      "Hao Jiang",
      "Rushan Zhang",
      "Yanning Zhou",
      "Yumeng Wang",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14378",
    "title": "Instant Domain Augmentation for LiDAR Semantic Segmentation",
    "abstract": "Despite the increasing popularity of LiDAR sensors, perception algorithms using 3D LiDAR data struggle with the 'sensor-bias problem'. Specifically, the performance of perception algorithms significantly drops when an unseen specification of LiDAR sensor is applied at test time due to the domain discrepancy. This paper presents a fast and flexible LiDAR augmentation method for the semantic segmentation task, called 'LiDomAug'. It aggregates raw LiDAR scans and creates a LiDAR scan of any configurations with the consideration of dynamic distortion and occlusion, resulting in instant domain augmentation. Our on-demand augmentation module runs at 330 FPS, so it can be seamlessly integrated into the data loader in the learning framework. In our experiments, learning-based approaches aided with the proposed LiDomAug are less affected by the sensor-bias issue and achieve new state-of-the-art domain adaptation performances on SemanticKITTI and nuScenes dataset without the use of the target domain data. We also present a sensor-agnostic model that faithfully works on the various LiDAR configurations. ",
    "url": "https://arxiv.org/abs/2303.14378",
    "authors": [
      "Kwonyoung Ryu",
      "Soonmin Hwang",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14384",
    "title": "Reliability-Hierarchical Memory Network for Scribble-Supervised Video  Object Segmentation",
    "abstract": "This paper aims to solve the video object segmentation (VOS) task in a scribble-supervised manner, in which VOS models are not only trained by the sparse scribble annotations but also initialized with the sparse target scribbles for inference. Thus, the annotation burdens for both training and initialization can be substantially lightened. The difficulties of scribble-supervised VOS lie in two aspects. On the one hand, it requires the powerful ability to learn from the sparse scribble annotations during training. On the other hand, it demands strong reasoning capability during inference given only a sparse initial target scribble. In this work, we propose a Reliability-Hierarchical Memory Network (RHMNet) to predict the target mask in a step-wise expanding strategy w.r.t. the memory reliability level. To be specific, RHMNet first only uses the memory in the high-reliability level to locate the region with high reliability belonging to the target, which is highly similar to the initial target scribble. Then it expands the located high-reliability region to the entire target conditioned on the region itself and the memories in all reliability levels. Besides, we propose a scribble-supervised learning mechanism to facilitate the learning of our model to predict dense results. It mines the pixel-level relation within the single frame and the frame-level relation within the sequence to take full advantage of the scribble annotations in sequence training samples. The favorable performance on two popular benchmarks demonstrates that our method is promising. ",
    "url": "https://arxiv.org/abs/2303.14384",
    "authors": [
      "Zikun Zhou",
      "Kaige Mao",
      "Wenjie Pei",
      "Hongpeng Wang",
      "Yaowei Wang",
      "Zhenyu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14386",
    "title": "Prompt-Guided Transformers for End-to-End Open-Vocabulary Object  Detection",
    "abstract": "Prompt-OVD is an efficient and effective framework for open-vocabulary object detection that utilizes class embeddings from CLIP as prompts, guiding the Transformer decoder to detect objects in both base and novel classes. Additionally, our novel RoI-based masked attention and RoI pruning techniques help leverage the zero-shot classification ability of the Vision Transformer-based CLIP, resulting in improved detection performance at minimal computational cost. Our experiments on the OV-COCO and OVLVIS datasets demonstrate that Prompt-OVD achieves an impressive 21.2 times faster inference speed than the first end-to-end open-vocabulary detection method (OV-DETR), while also achieving higher APs than four two-stage-based methods operating within similar inference time ranges. Code will be made available soon. ",
    "url": "https://arxiv.org/abs/2303.14386",
    "authors": [
      "Hwanjun Song",
      "Jihwan Bang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14390",
    "title": "Aggregated (Bi-)Simulation of Finite Valued Networks",
    "abstract": "The paper provides a method to approximate a large-scale finite-valued network by a smaller model called the aggregated simulation, which is a combination of aggregation and (bi-)simulation. First, the algebraic state space representation (ASSR) of a transition system is presented. Under output equivalence, the quotient system is obtained, which is called the simulation of the original transition system. The ASSR of the quotient system is obtained. The aggregated (bi-)simulation is execueted in several steps: a large scale finite-valued network is firstly aggregated into several blocks, each of which is considered as a network where the in-degree nodes and out-degree nodes are considered as the block inputs and block outputs respectively. Then the dynamics of each block is converted into its quotient system, called its simulation. Then the overall network can be approximated by the quotient systems of each blocks, which is called the aggregated simulation. If the simulation of a block is a bi-simulation, the approximation becomes a lossless transformation. Otherwise, the quotient system is only a (non-deterministic) transition system, and it can be replaced by a probabilistic networks. Aggregated simulation can reduce the dimension of the original network, while a tradeoff between computation complexity and approximation error need to be decided. ",
    "url": "https://arxiv.org/abs/2303.14390",
    "authors": [
      "Zhengping Ji",
      "Xiao Zhang",
      "Daizhan Cheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.14395",
    "title": "MDQE: Mining Discriminative Query Embeddings to Segment Occluded  Instances on Challenging Videos",
    "abstract": "While impressive progress has been achieved, video instance segmentation (VIS) methods with per-clip input often fail on challenging videos with occluded objects and crowded scenes. This is mainly because instance queries in these methods cannot encode well the discriminative embeddings of instances, making the query-based segmenter difficult to distinguish those `hard' instances. To address these issues, we propose to mine discriminative query embeddings (MDQE) to segment occluded instances on challenging videos. First, we initialize the positional embeddings and content features of object queries by considering their spatial contextual information and the inter-frame object motion. Second, we propose an inter-instance mask repulsion loss to distance each instance from its nearby non-target instances. The proposed MDQE is the first VIS method with per-clip input that achieves state-of-the-art results on challenging videos and competitive performance on simple videos. In specific, MDQE with ResNet50 achieves 33.0\\% and 44.5\\% mask AP on OVIS and YouTube-VIS 2021, respectively. Code of MDQE can be found at \\url{https://github.com/MinghanLi/MDQE_CVPR2023}. ",
    "url": "https://arxiv.org/abs/2303.14395",
    "authors": [
      "Minghan Li",
      "Shuai Li",
      "Wangmeng Xiang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14404",
    "title": "Bridging Precision and Confidence: A Train-Time Loss for Calibrating  Object Detection",
    "abstract": "Deep neural networks (DNNs) have enabled astounding progress in several vision-based problems. Despite showing high predictive accuracy, recently, several works have revealed that they tend to provide overconfident predictions and thus are poorly calibrated. The majority of the works addressing the miscalibration of DNNs fall under the scope of classification and consider only in-domain predictions. However, there is little to no progress in studying the calibration of DNN-based object detection models, which are central to many vision-based safety-critical applications. In this paper, inspired by the train-time calibration methods, we propose a novel auxiliary loss formulation that explicitly aims to align the class confidence of bounding boxes with the accurateness of predictions (i.e. precision). Since the original formulation of our loss depends on the counts of true positives and false positives in a minibatch, we develop a differentiable proxy of our loss that can be used during training with other application-specific loss functions. We perform extensive experiments on challenging in-domain and out-domain scenarios with six benchmark datasets including MS-COCO, Cityscapes, Sim10k, and BDD100k. Our results reveal that our train-time loss surpasses strong calibration baselines in reducing calibration error for both in and out-domain scenarios. Our source code and pre-trained models are available at https://github.com/akhtarvision/bpc_calibration ",
    "url": "https://arxiv.org/abs/2303.14404",
    "authors": [
      "Muhammad Akhtar Munir",
      "Muhammad Haris Khan",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14408",
    "title": "VL-SAT: Visual-Linguistic Semantics Assisted Training for 3D Semantic  Scene Graph Prediction in Point Cloud",
    "abstract": "The task of 3D semantic scene graph (3DSSG) prediction in the point cloud is challenging since (1) the 3D point cloud only captures geometric structures with limited semantics compared to 2D images, and (2) long-tailed relation distribution inherently hinders the learning of unbiased prediction. Since 2D images provide rich semantics and scene graphs are in nature coped with languages, in this study, we propose Visual-Linguistic Semantics Assisted Training (VL-SAT) scheme that can significantly empower 3DSSG prediction models with discrimination about long-tailed and ambiguous semantic relations. The key idea is to train a powerful multi-modal oracle model to assist the 3D model. This oracle learns reliable structural representations based on semantics from vision, language, and 3D geometry, and its benefits can be heterogeneously passed to the 3D model during the training stage. By effectively utilizing visual-linguistic semantics in training, our VL-SAT can significantly boost common 3DSSG prediction models, such as SGFN and SGGpoint, only with 3D inputs in the inference stage, especially when dealing with tail relation triplets. Comprehensive evaluations and ablation studies on the 3DSSG dataset have validated the effectiveness of the proposed scheme. Code is available at https://github.com/wz7in/CVPR2023-VLSAT. ",
    "url": "https://arxiv.org/abs/2303.14408",
    "authors": [
      "Ziqin Wang",
      "Bowen Cheng",
      "Lichen Zhao",
      "Dong Xu",
      "Yang Tang",
      "Lu Sheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14421",
    "title": "Spatially-Aware Car-Sharing Demand Prediction",
    "abstract": "In recent years, car-sharing services have emerged as viable alternatives to private individual mobility, promising more sustainable and resource-efficient, but still comfortable transportation. Research on short-term prediction and optimization methods has improved operations and fleet control of car-sharing services; however, long-term projections and spatial analysis are sparse in the literature. We propose to analyze the average monthly demand in a station-based car-sharing service with spatially-aware learning algorithms that offer high predictive performance as well as interpretability. In particular, we compare the spatially-implicit Random Forest model with spatially-aware methods for predicting average monthly per-station demand. The study utilizes a rich set of socio-demographic, location-based (e.g., POIs), and car-sharing-specific features as input, extracted from a large proprietary car-sharing dataset and publicly available datasets. We show that the global Random Forest model with geo-coordinates as an input feature achieves the highest predictive performance with an R-squared score of 0.87, while local methods such as Geographically Weighted Regression perform almost on par and additionally yield exciting insights into the heterogeneous spatial distributions of factors influencing car-sharing behaviour. Additionally, our study offers effective as well as highly interpretable methods for diagnosing and planning the placement of car-sharing stations. ",
    "url": "https://arxiv.org/abs/2303.14421",
    "authors": [
      "Dominik J. M\u00fchlematter",
      "Nina Wiedemann",
      "Yanan Xin",
      "Martin Raubal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14425",
    "title": "Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph For  Language Model Synonym-Aware Pretraining",
    "abstract": "The model's ability to understand synonymous expression is crucial in many kinds of downstream tasks. It will make the model to better understand the similarity between context, and more robust to the synonym substitution attack. However, many Pretrained Language Model (PLM) lack synonym knowledge due to limitation of small-scale synsets and PLM's pretraining objectives. In this paper, we propose a framework called Sem4SAP to mine synsets from Open Knowledge Graph (Open-KG) and using the mined synsets to do synonym-aware pretraining for language models. We propose to coarsly filter the content in Open-KG and use the frequency information to better help the clustering process under low-resource unsupervised conditions. We expand the mined synsets by migrating core semantics between synonymous expressions.We also propose two novel and effective synonym-aware pre-training methods for injecting synonym knowledge into PLMs.Extensive experiments demonstrate that Sem4SAP can dramatically outperform the original PLMs and other baselines on ten different tasks. ",
    "url": "https://arxiv.org/abs/2303.14425",
    "authors": [
      "Zhouhong Gu",
      "Sihang Jiang",
      "Wenhao Huang",
      "Jiaqing Liang",
      "Hongwei Feng",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14429",
    "title": "Shot Noise Reduction in Radiographic and Tomographic Multi-Channel  Imaging with Self-Supervised Deep Learning",
    "abstract": "Noise is an important issue for radiographic and tomographic imaging techniques. It becomes particularly critical in applications where additional constraints force a strong reduction of the Signal-to-Noise Ratio (SNR) per image. These constraints may result from limitations on the maximum available flux or permissible dose and the associated restriction on exposure time. Often, a high SNR per image is traded for the ability to distribute a given total exposure capacity per pixel over multiple channels, thus obtaining additional information about the object by the same total exposure time. These can be energy channels in the case of spectroscopic imaging or time channels in the case of time-resolved imaging. In this paper, we report on a method for improving the quality of noisy multi-channel (time or energy-resolved) imaging datasets. The method relies on the recent Noise2Noise (N2N) self-supervised denoising approach that learns to predict a noise-free signal without access to noise-free data. N2N in turn requires drawing pairs of samples from a data distribution sharing identical signals while being exposed to different samples of random noise. The method is applicable if adjacent channels share enough information to provide images with similar enough information but independent noise. We demonstrate several representative case studies, namely spectroscopic (k-edge) X-ray tomography, in vivo X-ray cine-radiography, and energy-dispersive (Bragg edge) neutron tomography. In all cases, the N2N method shows dramatic improvement and outperforms conventional denoising methods. For such imaging techniques, the method can therefore significantly improve image quality, or maintain image quality with further reduced exposure time per image. ",
    "url": "https://arxiv.org/abs/2303.14429",
    "authors": [
      "Yaroslav Zharov",
      "Evelina Ametova",
      "Rebecca Spiecker",
      "Tilo Baumbach",
      "Genoveva Burca",
      "Vincent Heuveline"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14435",
    "title": "NeRF-DS: Neural Radiance Fields for Dynamic Specular Objects",
    "abstract": "Dynamic Neural Radiance Field (NeRF) is a powerful algorithm capable of rendering photo-realistic novel view images from a monocular RGB video of a dynamic scene. Although it warps moving points across frames from the observation spaces to a common canonical space for rendering, dynamic NeRF does not model the change of the reflected color during the warping. As a result, this approach often fails drastically on challenging specular objects in motion. We address this limitation by reformulating the neural radiance field function to be conditioned on surface position and orientation in the observation space. This allows the specular surface at different poses to keep the different reflected colors when mapped to the common canonical space. Additionally, we add the mask of moving objects to guide the deformation field. As the specular surface changes color during motion, the mask mitigates the problem of failure to find temporal correspondences with only RGB supervision. We evaluate our model based on the novel view synthesis quality with a self-collected dataset of different moving specular objects in realistic environments. The experimental results demonstrate that our method significantly improves the reconstruction quality of moving specular objects from monocular RGB videos compared to the existing NeRF models. Our code and data are available at the project website https://github.com/JokerYan/NeRF-DS. ",
    "url": "https://arxiv.org/abs/2303.14435",
    "authors": [
      "Zhiwen Yan",
      "Chen Li",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.14441",
    "title": "A User-Based Authentication and DoS Mitigation Scheme for Wearable  Wireless Body Sensor Networks",
    "abstract": "Wireless Body Sensor Networks (WBSNs) is one of the greatest growing technology for sensing and performing various tasks. The information transmitted in the WBSNs is vulnerable to cyber-attacks, therefore security is very important. Denial of Service (DoS) attacks are considered one of the major threats against WBSNs security. In DoS attacks, an adversary targets to degrade and shut down the efficient use of the network and disrupt the services in the network causing them inaccessible to its intended users. If sensitive information of patients in WBSNs, such as the medical history is accessed by unauthorized users, the patient may suffer much more than the disease itself, it may result in loss of life. This paper proposes a User-Based authentication scheme to mitigate DoS attacks in WBSNs. A five-phase User-Based authentication DoS mitigation scheme for WBSNs is designed by integrating Elliptic Curve Cryptography (ECC) with Rivest Cipher 4 (RC4) to ensure a strong authentication process that will only allow authorized users to access nodes on WBSNs. ",
    "url": "https://arxiv.org/abs/2303.14441",
    "authors": [
      "Nombulelo Zulu",
      "Deon P. Du Plessis",
      "Topside E. Mathonsi",
      "Tshimangadzo M. Tshilongamulenzhe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.14443",
    "title": "No more Reviewer #2: Subverting Automatic Paper-Reviewer Assignment  using Adversarial Learning",
    "abstract": "The number of papers submitted to academic conferences is steadily rising in many scientific disciplines. To handle this growth, systems for automatic paper-reviewer assignments are increasingly used during the reviewing process. These systems use statistical topic models to characterize the content of submissions and automate the assignment to reviewers. In this paper, we show that this automation can be manipulated using adversarial learning. We propose an attack that adapts a given paper so that it misleads the assignment and selects its own reviewers. Our attack is based on a novel optimization strategy that alternates between the feature space and problem space to realize unobtrusive changes to the paper. To evaluate the feasibility of our attack, we simulate the paper-reviewer assignment of an actual security conference (IEEE S&P) with 165 reviewers on the program committee. Our results show that we can successfully select and remove reviewers without access to the assignment system. Moreover, we demonstrate that the manipulated papers remain plausible and are often indistinguishable from benign submissions. ",
    "url": "https://arxiv.org/abs/2303.14443",
    "authors": [
      "Thorsten Eisenhofer",
      "Erwin Quiring",
      "Jonas M\u00f6ller",
      "Doreen Riepel",
      "Thorsten Holz",
      "Konrad Rieck"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14445",
    "title": "A Hybrid Algorithm to Enhance Wireless Sensor Networks security on the  IoT",
    "abstract": "The Internet of Things (IoT) is a futuristic technology that promises to connect tons of devices via the internet. As more individuals connect to the internet, it is believed that communication will generate mountains of data. IoT is currently leveraging Wireless Sensor Networks (WSNs) to collect, monitor, and transmit data and sensitive data across wireless networks using sensor nodes. WSNs encounter a variety of threats posed by attackers, including unauthorized access and data security. Especially in the context of the Internet of Things, where small embedded devices with limited computational capabilities, such as sensor nodes, are expected to connect to a larger network. As a result, WSNs are vulnerable to a variety of attacks. Furthermore, implementing security is time-consuming and selective, as traditional security algorithms degrade network performance due to their computational complexity and inherent delays. This paper describes an encryption algorithm that combines the Secure IoT (SIT) algorithm with the Security Protocols for Sensor Networks (SPINS) security protocol to create the Lightweight Security Algorithm (LSA), which addresses data security concerns while reducing power consumption in WSNs without sacrificing performance. ",
    "url": "https://arxiv.org/abs/2303.14445",
    "authors": [
      "Ntebatseng Mahlake",
      "Topside E. Mathonsi",
      "Tonderai Muchenje",
      "Deon Du Plessis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.14460",
    "title": "CFA: Class-wise Calibrated Fair Adversarial Training",
    "abstract": "Adversarial training has been widely acknowledged as the most effective method to improve the adversarial robustness against adversarial examples for Deep Neural Networks (DNNs). So far, most existing works focus on enhancing the overall model robustness, treating each class equally in both the training and testing phases. Although revealing the disparity in robustness among classes, few works try to make adversarial training fair at the class level without sacrificing overall robustness. In this paper, we are the first to theoretically and empirically investigate the preference of different classes for adversarial configurations, including perturbation margin, regularization, and weight averaging. Motivated by this, we further propose a \\textbf{C}lass-wise calibrated \\textbf{F}air \\textbf{A}dversarial training framework, named CFA, which customizes specific training configurations for each class automatically. Experiments on benchmark datasets demonstrate that our proposed CFA can improve both overall robustness and fairness notably over other state-of-the-art methods. Code is available at \\url{https://github.com/PKU-ML/CFA}. ",
    "url": "https://arxiv.org/abs/2303.14460",
    "authors": [
      "Zeming Wei",
      "Yifei Wang",
      "Yiwen Guo",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14470",
    "title": "Compacting Binary Neural Networks by Sparse Kernel Selection",
    "abstract": "Binary Neural Network (BNN) represents convolution weights with 1-bit values, which enhances the efficiency of storage and computation. This paper is motivated by a previously revealed phenomenon that the binary kernels in successful BNNs are nearly power-law distributed: their values are mostly clustered into a small number of codewords. This phenomenon encourages us to compact typical BNNs and obtain further close performance through learning non-repetitive kernels within a binary kernel subspace. Specifically, we regard the binarization process as kernel grouping in terms of a binary codebook, and our task lies in learning to select a smaller subset of codewords from the full codebook. We then leverage the Gumbel-Sinkhorn technique to approximate the codeword selection process, and develop the Permutation Straight-Through Estimator (PSTE) that is able to not only optimize the selection process end-to-end but also maintain the non-repetitive occupancy of selected codewords. Experiments verify that our method reduces both the model size and bit-wise computational costs, and achieves accuracy improvements compared with state-of-the-art BNNs under comparable budgets. ",
    "url": "https://arxiv.org/abs/2303.14470",
    "authors": [
      "Yikai Wang",
      "Wenbing Huang",
      "Yinpeng Dong",
      "Fuchun Sun",
      "Anbang Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14478",
    "title": "DBARF: Deep Bundle-Adjusting Generalizable Neural Radiance Fields",
    "abstract": "Recent works such as BARF and GARF can bundle adjust camera poses with neural radiance fields (NeRF) which is based on coordinate-MLPs. Despite the impressive results, these methods cannot be applied to Generalizable NeRFs (GeNeRFs) which require image feature extractions that are often based on more complicated 3D CNN or transformer architectures. In this work, we first analyze the difficulties of jointly optimizing camera poses with GeNeRFs, and then further propose our DBARF to tackle these issues. Our DBARF which bundle adjusts camera poses by taking a cost feature map as an implicit cost function can be jointly trained with GeNeRFs in a self-supervised manner. Unlike BARF and its follow-up works, which can only be applied to per-scene optimized NeRFs and need accurate initial camera poses with the exception of forward-facing scenes, our method can generalize across scenes and does not require any good initialization. Experiments show the effectiveness and generalization ability of our DBARF when evaluated on real-world datasets. Our code is available at \\url{https://aibluefisher.github.io/dbarf}. ",
    "url": "https://arxiv.org/abs/2303.14478",
    "authors": [
      "Yu Chen",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14480",
    "title": "GANTEE: Generative Adversatial Network for Taxonomy Entering Evaluation",
    "abstract": "Taxonomy is formulated as directed acyclic concepts graphs or trees that support many downstream tasks. Many new coming concepts need to be added to an existing taxonomy. The traditional taxonomy expansion task aims only at finding the best position for new coming concepts in the existing taxonomy. However, they have two drawbacks when being applied to the real-scenarios. The previous methods suffer from low-efficiency since they waste much time when most of the new coming concepts are indeed noisy concepts. They also suffer from low-effectiveness since they collect training samples only from the existing taxonomy, which limits the ability of the model to mine more hypernym-hyponym relationships among real concepts. This paper proposes a pluggable framework called Generative Adversarial Network for Taxonomy Entering Evaluation (GANTEE) to alleviate these drawbacks. A generative adversarial network is designed in this framework by discriminative models to alleviate the first drawback and the generative model to alleviate the second drawback. Two discriminators are used in GANTEE to provide long-term and short-term rewards, respectively. Moreover, to further improve the efficiency, pre-trained language models are used to retrieve the representation of the concepts quickly. The experiments on three real-world large-scale datasets with two different languages show that GANTEE improves the performance of the existing taxonomy expansion methods in both effectiveness and efficiency. ",
    "url": "https://arxiv.org/abs/2303.14480",
    "authors": [
      "Zhouhong Gu",
      "Sihang Jiang",
      "Jingping Liu",
      "Yanghua Xiao",
      "Hongwei Feng",
      "Zhixu Li",
      "Jiaqing Liang",
      "Jian Zhong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.14481",
    "title": "Diverse Embedding Expansion Network and Low-Light Cross-Modality  Benchmark for Visible-Infrared Person Re-identification",
    "abstract": "For the visible-infrared person re-identification (VIReID) task, one of the major challenges is the modality gaps between visible (VIS) and infrared (IR) images. However, the training samples are usually limited, while the modality gaps are too large, which leads that the existing methods cannot effectively mine diverse cross-modality clues. To handle this limitation, we propose a novel augmentation network in the embedding space, called diverse embedding expansion network (DEEN). The proposed DEEN can effectively generate diverse embeddings to learn the informative feature representations and reduce the modality discrepancy between the VIS and IR images. Moreover, the VIReID model may be seriously affected by drastic illumination changes, while all the existing VIReID datasets are captured under sufficient illumination without significant light changes. Thus, we provide a low-light cross-modality (LLCM) dataset, which contains 46,767 bounding boxes of 1,064 identities captured by 9 RGB/IR cameras. Extensive experiments on the SYSU-MM01, RegDB and LLCM datasets show the superiority of the proposed DEEN over several other state-of-the-art methods. The code and dataset are released at: https://github.com/ZYK100/LLCM ",
    "url": "https://arxiv.org/abs/2303.14481",
    "authors": [
      "Yukang Zhang",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14483",
    "title": "Spatio-Temporal Graph Neural Networks for Predictive Learning in Urban  Computing: A Survey",
    "abstract": "With the development of sophisticated sensors and large database technologies, more and more spatio-temporal data in urban systems are recorded and stored. Predictive learning for the evolution patterns of these spatio-temporal data is a basic but important loop in urban computing, which can better support urban intelligent management decisions, especially in the fields of transportation, environment, security, public health, etc. Since traditional statistical learning and deep learning methods can hardly capture the complex correlations in the urban spatio-temporal data, the framework of spatio-temporal graph neural network (STGNN) has been proposed in recent years. STGNNs enable the extraction of complex spatio-temporal dependencies by integrating graph neural networks (GNNs) and various temporal learning methods. However, for different predictive learning tasks, it is a challenging problem to effectively design the spatial dependencies learning modules, temporal dependencies learning modules and spatio-temporal dependencies fusion methods in STGNN framework. In this paper, we provide a comprehensive survey on recent progress on STGNN technologies for predictive learning in urban computing. We first briefly introduce the construction methods of spatio-temporal graph data and popular deep learning models that are employed in STGNNs. Then we sort out the main application domains and specific predictive learning tasks from the existing literature. Next we analyze the design approaches of STGNN framework and the combination with some advanced technologies in recent years. Finally, we conclude the limitations of the existing research and propose some potential directions. ",
    "url": "https://arxiv.org/abs/2303.14483",
    "authors": [
      "Guangyin Jin",
      "Yuxuan Liang",
      "Yuchen Fang",
      "Jincai Huang",
      "Junbo Zhang",
      "Yu Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14488",
    "title": "Adaptive Sparse Convolutional Networks with Global Context Enhancement  for Faster Object Detection on Drone Images",
    "abstract": "Object detection on drone images with low-latency is an important but challenging task on the resource-constrained unmanned aerial vehicle (UAV) platform. This paper investigates optimizing the detection head based on the sparse convolution, which proves effective in balancing the accuracy and efficiency. Nevertheless, it suffers from inadequate integration of contextual information of tiny objects as well as clumsy control of the mask ratio in the presence of foreground with varying scales. To address the issues above, we propose a novel global context-enhanced adaptive sparse convolutional network (CEASC). It first develops a context-enhanced group normalization (CE-GN) layer, by replacing the statistics based on sparsely sampled features with the global contextual ones, and then designs an adaptive multi-layer masking strategy to generate optimal mask ratios at distinct scales for compact foreground coverage, promoting both the accuracy and efficiency. Extensive experimental results on two major benchmarks, i.e. VisDrone and UAVDT, demonstrate that CEASC remarkably reduces the GFLOPs and accelerates the inference procedure when plugging into the typical state-of-the-art detection frameworks (e.g. RetinaNet and GFL V1) with competitive performance. Code is available at https://github.com/Cuogeihong/CEASC. ",
    "url": "https://arxiv.org/abs/2303.14488",
    "authors": [
      "Bowei Du",
      "Yecheng Huang",
      "Jiaxin Chen",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14495",
    "title": "Preconditioned Algorithm for Difference of Convex Functions with  applications to Graph Ginzburg-Landau Model",
    "abstract": "In this work, we propose and study a preconditioned framework with a graphic Ginzburg-Landau functional for image segmentation and data clustering by parallel computing. Solving nonlocal models is usually challenging due to the huge computation burden. For the nonconvex and nonlocal variational functional, we propose several damped Jacobi and generalized Richardson preconditioners for the large-scale linear systems within a difference of convex functions algorithms framework. They are efficient for parallel computing with GPU and can leverage the computational cost. Our framework also provides flexible step sizes with a global convergence guarantee. Numerical experiments show the proposed algorithms are very competitive compared to the singular value decomposition based spectral method. ",
    "url": "https://arxiv.org/abs/2303.14495",
    "authors": [
      "Xinhua Shen",
      "Hongpeng Sun",
      "Xuecheng Tai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.14501",
    "title": "Link Prediction for Flow-Driven Spatial Networks",
    "abstract": "Link prediction algorithms predict the existence of connections between nodes in network-structured data and are typically applied to refine the connectivity among nodes by proposing meaningful new links. In this work, we focus on link prediction for flow-driven spatial networks, which are embedded in a Euclidean space and relate to physical exchange and transportation processes (e.g., blood flow in vessels or traffic flow in road networks). To this end, we propose the Graph Attentive Vectors (GAV) link prediction framework. GAV models simplified dynamics of physical flow in spatial networks via an attentive, neighborhood-aware message-passing paradigm, updating vector embeddings in a constrained manner. We evaluate GAV on eight flow-driven spatial networks given by whole-brain vessel graphs and road networks. GAV demonstrates superior performances across all datasets and metrics and outperforms the current state-of-the-art on the ogbl-vessel benchmark by more than 18% (98.38 vs. 83.07 AUC). ",
    "url": "https://arxiv.org/abs/2303.14501",
    "authors": [
      "Bastian Wittmann",
      "Johannes C. Paetzold",
      "Chinmay Prabhakar",
      "Daniel Rueckert",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14510",
    "title": "Targeted Mining of Top-k High Utility Itemsets",
    "abstract": "Finding high-importance patterns in data is an emerging data mining task known as High-utility itemset mining (HUIM). Given a minimum utility threshold, a HUIM algorithm extracts all the high-utility itemsets (HUIs) whose utility values are not less than the threshold. This can reveal a wealth of useful information, but the precise needs of users are not well taken into account. In particular, users often want to focus on patterns that have some specific items rather than find all patterns. To overcome that difficulty, targeted mining has emerged, focusing on user preferences, but only preliminary work has been conducted. For example, the targeted high-utility itemset querying algorithm (TargetUM) was proposed, which uses a lexicographic tree to query itemsets containing a target pattern. However, selecting the minimum utility threshold is difficult when the user is not familiar with the processed database. As a solution, this paper formulates the task of targeted mining of the top-k high-utility itemsets and proposes an efficient algorithm called TMKU based on the TargetUM algorithm to discover the top-k target high-utility itemsets (top-k THUIs). At the same time, several pruning strategies are used to reduce memory consumption and execution time. Extensive experiments show that the proposed TMKU algorithm has good performance on real and synthetic datasets. ",
    "url": "https://arxiv.org/abs/2303.14510",
    "authors": [
      "Shan Huang",
      "Wensheng Gan",
      "Jinbao Miao",
      "Xuming Han",
      "Philippe Fournier-Viger"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2303.14516",
    "title": "OVeNet: Offset Vector Network for Semantic Segmentation",
    "abstract": "Semantic segmentation is a fundamental task in visual scene understanding. We focus on the supervised setting, where ground-truth semantic annotations are available. Based on knowledge about the high regularity of real-world scenes, we propose a method for improving class predictions by learning to selectively exploit information from neighboring pixels. In particular, our method is based on the prior that for each pixel, there is a seed pixel in its close neighborhood sharing the same prediction with the former. Motivated by this prior, we design a novel two-head network, named Offset Vector Network (OVeNet), which generates both standard semantic predictions and a dense 2D offset vector field indicating the offset from each pixel to the respective seed pixel, which is used to compute an alternative, seed-based semantic prediction. The two predictions are adaptively fused at each pixel using a learnt dense confidence map for the predicted offset vector field. We supervise offset vectors indirectly via optimizing the seed-based prediction and via a novel loss on the confidence map. Compared to the baseline state-of-the-art architectures HRNet and HRNet+OCR on which OVeNet is built, the latter achieves significant performance gains on two prominent benchmarks for semantic segmentation of driving scenes, namely Cityscapes and ACDC. Code is available at https://github.com/stamatisalex/OVeNet ",
    "url": "https://arxiv.org/abs/2303.14516",
    "authors": [
      "Stamatis Alexandropoulos",
      "Christos Sakaridis",
      "Petros Maragos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.14519",
    "title": "Stochastic Model Predictive Control Utilizing Bayesian Neural Networks",
    "abstract": "Integrating measurements and historical data can enhance control systems through learning-based techniques, but ensuring performance and safety is challenging. Robust model predictive control strategies, like stochastic model predictive control, can address this by accounting for uncertainty. Gaussian processes are often used but have limitations with larger models and data sets. We explore Bayesian neural networks for stochastic learning-assisted control, comparing their performance to Gaussian processes on a wastewater treatment plant model. Results show Bayesian neural networks achieve similar performance, highlighting their potential as an alternative for control designs, particularly when handling extensive data sets. ",
    "url": "https://arxiv.org/abs/2303.14519",
    "authors": [
      "J. Pohlodek",
      "H. Alsmeier",
      "B. Morabito",
      "C. Schlauch",
      "A. Savchenko",
      "R. Findeisen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14521",
    "title": "Waste Detection and Change Analysis based on Multispectral Satellite  Imagery",
    "abstract": "One of the biggest environmental problems of our time is the increase in illegal landfills in forests, rivers, on river banks and other secluded places. In addition, waste in rivers causes damage not only locally, but also downstream, both in the water and washed ashore. Large islands of waste can also form at hydroelectric power stations and dams, and if they continue to flow, they can cause further damage to the natural environment along the river. Recent studies have also proved that rivers are the main source of plastic pollution in marine environments. Monitoring potential sources of danger is therefore highly important for effective waste collection for related organizations. In our research we analyze two possible forms of waste detection: identification of hot-spots (i.e. illegal waste dumps) and identification of water-surface river blockages. We used medium to high-resolution multispectral satellite imagery as our data source, especially focusing on the Tisza river as our study area. We found that using satellite imagery and machine learning are viable to locate and to monitor the change of the previously detected waste. ",
    "url": "https://arxiv.org/abs/2303.14521",
    "authors": [
      "D\u00e1vid Magyar",
      "M\u00e1t\u00e9 Cser\u00e9p",
      "Zolt\u00e1n Vincell\u00e9r",
      "Attila D. Moln\u00e1r"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14531",
    "title": "SIO: Synthetic In-Distribution Data Benefits Out-of-Distribution  Detection",
    "abstract": "Building up reliable Out-of-Distribution (OOD) detectors is challenging, often requiring the use of OOD data during training. In this work, we develop a data-driven approach which is distinct and complementary to existing works: Instead of using external OOD data, we fully exploit the internal in-distribution (ID) training set by utilizing generative models to produce additional synthetic ID images. The classifier is then trained using a novel objective that computes weighted loss on real and synthetic ID samples together. Our training framework, which is termed SIO, serves as a \"plug-and-play\" technique that is designed to be compatible with existing and future OOD detection algorithms, including the ones that leverage available OOD training data. Our experiments on CIFAR-10, CIFAR-100, and ImageNet variants demonstrate that SIO consistently improves the performance of nearly all state-of-the-art (SOTA) OOD detection algorithms. For instance, on the challenging CIFAR-10 v.s. CIFAR-100 detection problem, SIO improves the average OOD detection AUROC of 18 existing methods from 86.25\\% to 89.04\\% and achieves a new SOTA of 92.94\\% according to the OpenOOD benchmark. Code is available at https://github.com/zjysteven/SIO. ",
    "url": "https://arxiv.org/abs/2303.14531",
    "authors": [
      "Jingyang Zhang",
      "Nathan Inkawhich",
      "Randolph Linderman",
      "Ryan Luley",
      "Yiran Chen",
      "Hai Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14535",
    "title": "EfficientAD: Accurate Visual Anomaly Detection at Millisecond-Level  Latencies",
    "abstract": "Detecting anomalies in images is an important task, especially in real-time computer vision applications. In this work, we focus on computational efficiency and propose a lightweight feature extractor that processes an image in less than a millisecond on a modern GPU. We then use a student-teacher approach to detect anomalous features. We train a student network to predict the extracted features of normal, i.e., anomaly-free training images. The detection of anomalies at test time is enabled by the student failing to predict their features. We propose a training loss that hinders the student from imitating the teacher feature extractor beyond the normal images. It allows us to drastically reduce the computational cost of the student-teacher model, while improving the detection of anomalous features. We furthermore address the detection of challenging logical anomalies that involve invalid combinations of normal local features, for example, a wrong ordering of objects. We detect these anomalies by efficiently incorporating an autoencoder that analyzes images globally. We evaluate our method, called EfficientAD, on 32 datasets from three industrial anomaly detection dataset collections. EfficientAD sets new standards for both the detection and the localization of anomalies. At a latency of two milliseconds and a throughput of six hundred images per second, it enables a fast handling of anomalies. Together with its low error rate, this makes it an economical solution for real-world applications and a fruitful basis for future research. ",
    "url": "https://arxiv.org/abs/2303.14535",
    "authors": [
      "Kilian Batzner",
      "Lars Heckler",
      "Rebecca K\u00f6nig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14537",
    "title": "Deep Augmentation: Enhancing Self-Supervised Learning through  Transformations in Higher Activation Space",
    "abstract": "We introduce Deep Augmentation, an approach to data augmentation using dropout to dynamically transform a targeted layer within a neural network, with the option to use the stop-gradient operation, offering significant improvements in model performance and generalization. We demonstrate the efficacy of Deep Augmentation through extensive experiments on contrastive learning tasks in computer vision and NLP domains, where we observe substantial performance gains with ResNets and Transformers as the underlying models. Our experimentation reveals that targeting deeper layers with Deep Augmentation outperforms augmenting the input data, and the simple network- and data-agnostic nature of this approach enables its seamless integration into computer vision and NLP pipelines. ",
    "url": "https://arxiv.org/abs/2303.14537",
    "authors": [
      "Rickard Br\u00fcel-Gabrielsson",
      "Tongzhou Wang",
      "Manel Baradad",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14542",
    "title": "Combining Contexts from Multiple Sources for Documentation-Specific Code  Example Generation",
    "abstract": "Code example is a crucial part of good documentation. It helps the developers to understand the documentation easily and use the corresponding code unit (e.g., method) properly. However, many official documentation still lacks (good) code example and it is one of the common documentation issues as found by several studies. Hence in this paper, we consider automatic code example generation for documentation, a direction less explored by the existing research. We employ Codex, a GPT-3 based model, pre-trained on both natural and programming languages to generate code examples from source code and documentation given as input. Our preliminary investigation on 40 scikit-learn methods reveals that this approach is able to generate good code examples where 72.5% code examples were executed without error (passability) and 82.5% properly dealt with the target method and documentation (relevance). We also find that incorporation of error logs (produced by the compiler while executing a failed code example) in the input further improves the passability from 72.5% to 87.5%. Thus, our investigation sets the base of documentation-specific code example generation and warrants in-depth future studies. ",
    "url": "https://arxiv.org/abs/2303.14542",
    "authors": [
      "Junaed Younus Khan",
      "Gias Uddin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.14543",
    "title": "Topological Pooling on Graphs",
    "abstract": "Graph neural networks (GNNs) have demonstrated a significant success in various graph learning tasks, from graph classification to anomaly detection. There recently has emerged a number of approaches adopting a graph pooling operation within GNNs, with a goal to preserve graph attributive and structural features during the graph representation learning. However, most existing graph pooling operations suffer from the limitations of relying on node-wise neighbor weighting and embedding, which leads to insufficient encoding of rich topological structures and node attributes exhibited by real-world networks. By invoking the machinery of persistent homology and the concept of landmarks, we propose a novel topological pooling layer and witness complex-based topological embedding mechanism that allow us to systematically integrate hidden topological information at both local and global levels. Specifically, we design new learnable local and global topological representations Wit-TopoPool which allow us to simultaneously extract rich discriminative topological information from graphs. Experiments on 11 diverse benchmark datasets against 18 baseline models in conjunction with graph classification tasks indicate that Wit-TopoPool significantly outperforms all competitors across all datasets. ",
    "url": "https://arxiv.org/abs/2303.14543",
    "authors": [
      "Yuzhou Chen",
      "Yulia R. Gel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14548",
    "title": "Viewpoint Equivariance for Multi-View 3D Object Detection",
    "abstract": "3D object detection from visual sensors is a cornerstone capability of robotic systems. State-of-the-art methods focus on reasoning and decoding object bounding boxes from multi-view camera input. In this work we gain intuition from the integral role of multi-view consistency in 3D scene understanding and geometric learning. To this end, we introduce VEDet, a novel 3D object detection framework that exploits 3D multi-view geometry to improve localization through viewpoint awareness and equivariance. VEDet leverages a query-based transformer architecture and encodes the 3D scene by augmenting image features with positional encodings from their 3D perspective geometry. We design view-conditioned queries at the output level, which enables the generation of multiple virtual frames during training to learn viewpoint equivariance by enforcing multi-view consistency. The multi-view geometry injected at the input level as positional encodings and regularized at the loss level provides rich geometric cues for 3D object detection, leading to state-of-the-art performance on the nuScenes benchmark. The code and model are made available at https://github.com/TRI-ML/VEDet. ",
    "url": "https://arxiv.org/abs/2303.14548",
    "authors": [
      "Dian Chen",
      "Jie Li",
      "Vitor Guizilini",
      "Rares Ambrus",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.14550",
    "title": "Theoretical bounds on the network community profile from low-rank  semi-definite programming",
    "abstract": "We study a new connection between a technical measure called $\\mu$-conductance that arises in the study of Markov chains for sampling convex bodies and the network community profile that characterizes size-resolved properties of clusters and communities in social and information networks. The idea of $\\mu$-conductance is similar to the traditional graph conductance, but disregards sets with small volume. We derive a sequence of optimization problems including a low-rank semi-definite program from which we can derive a lower bound on the optimal $\\mu$-conductance value. These ideas give the first theoretically sound bound on the behavior of the network community profile for a wide range of cluster sizes. The algorithm scales up to graphs with hundreds of thousands of nodes and we demonstrate how our framework validates the predicted structures of real-world graphs. ",
    "url": "https://arxiv.org/abs/2303.14550",
    "authors": [
      "Yufan Huang",
      "C. Seshadhri",
      "David F. Gleich"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.14552",
    "title": "Spatial Latent Representations in Generative Adversarial Networks for  Image Generation",
    "abstract": "In the majority of GAN architectures, the latent space is defined as a set of vectors of given dimensionality. Such representations are not easily interpretable and do not capture spatial information of image content directly. In this work, we define a family of spatial latent spaces for StyleGAN2, capable of capturing more details and representing images that are out-of-sample in terms of the number and arrangement of object parts, such as an image of multiple faces or a face with more than two eyes. We propose a method for encoding images into our spaces, together with an attribute model capable of performing attribute editing in these spaces. We show that our spaces are effective for image manipulation and encode semantic information well. Our approach can be used on pre-trained generator models, and attribute edition can be done using pre-generated direction vectors making the barrier to entry for experimentation and use extremely low. We propose a regularization method for optimizing latent representations, which equalizes distributions of parts of latent spaces, making representations much closer to generated ones. We use it for encoding images into spatial spaces to obtain significant improvement in quality while keeping semantics and ability to use our attribute model for edition purposes. In total, using our methods gives encoding quality boost even as high as 30% in terms of LPIPS score comparing to standard methods, while keeping semantics. Additionally, we propose a StyleGAN2 training procedure on our spatial latent spaces, together with a custom spatial latent representation distribution to make spatially closer elements in the representation more dependent on each other than farther elements. Such approach improves the FID score by 29% on SpaceNet, and is able to generate consistent images of arbitrary sizes on spatially homogeneous datasets, like satellite imagery. ",
    "url": "https://arxiv.org/abs/2303.14552",
    "authors": [
      "Maciej Sypetkowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.14564",
    "title": "Compositional Neural Certificates for Networked Dynamical Systems",
    "abstract": "Developing stable controllers for large-scale networked dynamical systems is crucial but has long been challenging due to two key obstacles: certifiability and scalability. In this paper, we present a general framework to solve these challenges using compositional neural certificates based on ISS (Input-to-State Stability) Lyapunov functions. Specifically, we treat a large networked dynamical system as an interconnection of smaller subsystems and develop methods that can find each subsystem a decentralized controller and an ISS Lyapunov function; the latter can be collectively composed to prove the global stability of the system. To ensure the scalability of our approach, we develop generalizable and robust ISS Lyapunov functions where a single function can be used across different subsystems and the certificates we produced for small systems can be generalized to be used on large systems with similar structures. We encode both ISS Lyapunov functions and controllers as neural networks and propose a novel training methodology to handle the logic in ISS Lyapunov conditions that encodes the interconnection with neighboring subsystems. We demonstrate our approach in systems including Platoon, Drone formation control, and Power systems. Experimental results show that our framework can reduce the tracking error up to 75% compared with RL algorithms when applied to large-scale networked systems. ",
    "url": "https://arxiv.org/abs/2303.14564",
    "authors": [
      "Songyuan Zhang",
      "Yumeng Xiu",
      "Guannan Qu",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.14565",
    "title": "Saihu: A Common Interface of Worst-Case Delay Analysis Tools for  Time-Sensitive Networks",
    "abstract": "Time-sensitive networks, as in the context of IEEE-TSN and IETF-Detnet, require bounds on worst-case delays. Various network analysis tools compute such bounds, but these tools are based on different methods and provide different valid delay bounds. Hence, it is essential to identify the best, smallest bounds. As of today, users must implement multiple pieces of code with different syntaxes for each tool, as each tool is implemented by different groups and uses different programming languages and syntaxes. This results in a significant amount of mechanical actions from users and being error-prone. In this paper, we present Saihu, a Python interface that integrates xTFA (supports TFA), DiscoDNC (supports LUDB, PMOO, SFA), and Panco (supports PLP and ELP), the three most frequently used worst-case network analysis tools. Saihu provides a general interface that enables defining the networks in a single XML or JSON file and executing all tools simultaneously without any adjustment for individual tools. Saihu also exports analysis results into formatted reports automatically, and it offers automatic network generation for certain types of networks. Therefore, with its straightforward syntax and ease of execution, Saihu reduces the burden on users and makes it a valuable tool for anyone working with time-sensitive networks. Lastly, we modularize the package to incorporate more tools in the future. ",
    "url": "https://arxiv.org/abs/2303.14565",
    "authors": [
      "Chun-Tso Tsai",
      "Seyed Mohammadhossein Tabatabaee",
      "St\u00e9phan Plassart",
      "Jean-Yves Le Boudec"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.14584",
    "title": "Learning video embedding space with Natural Language Supervision",
    "abstract": "The recent success of the CLIP model has shown its potential to be applied to a wide range of vision and language tasks. However this only establishes embedding space relationship of language to images, not to the video domain. In this paper, we propose a novel approach to map video embedding space to natural langugage. We propose a two-stage approach that first extracts visual features from each frame of a video using a pre-trained CNN, and then uses the CLIP model to encode the visual features for the video domain, along with the corresponding text descriptions. We evaluate our method on two benchmark datasets, UCF101 and HMDB51, and achieve state-of-the-art performance on both tasks. ",
    "url": "https://arxiv.org/abs/2303.14584",
    "authors": [
      "Phani Krishna Uppala",
      "Shriti Priya",
      "Vaidehi Joshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14591",
    "title": "FairGAT: Fairness-aware Graph Attention Networks",
    "abstract": "Graphs can facilitate modeling various complex systems such as gene networks and power grids, as well as analyzing the underlying relations within them. Learning over graphs has recently attracted increasing attention, particularly graph neural network-based (GNN) solutions, among which graph attention networks (GATs) have become one of the most widely utilized neural network structures for graph-based tasks. Although it is shown that the use of graph structures in learning results in the amplification of algorithmic bias, the influence of the attention design in GATs on algorithmic bias has not been investigated. Motivated by this, the present study first carries out a theoretical analysis in order to demonstrate the sources of algorithmic bias in GAT-based learning for node classification. Then, a novel algorithm, FairGAT, that leverages a fairness-aware attention design is developed based on the theoretical findings. Experimental results on real-world networks demonstrate that FairGAT improves group fairness measures while also providing comparable utility to the fairness-aware baselines for node classification and link prediction. ",
    "url": "https://arxiv.org/abs/2303.14591",
    "authors": [
      "O. Deniz Kose",
      "Yanning Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.14601",
    "title": "PORE: Provably Robust Recommender Systems against Data Poisoning Attacks",
    "abstract": "Data poisoning attacks spoof a recommender system to make arbitrary, attacker-desired recommendations via injecting fake users with carefully crafted rating scores into the recommender system. We envision a cat-and-mouse game for such data poisoning attacks and their defenses, i.e., new defenses are designed to defend against existing attacks and new attacks are designed to break them. To prevent such a cat-and-mouse game, we propose PORE, the first framework to build provably robust recommender systems in this work. PORE can transform any existing recommender system to be provably robust against any untargeted data poisoning attacks, which aim to reduce the overall performance of a recommender system. Suppose PORE recommends top-$N$ items to a user when there is no attack. We prove that PORE still recommends at least $r$ of the $N$ items to the user under any data poisoning attack, where $r$ is a function of the number of fake users in the attack. Moreover, we design an efficient algorithm to compute $r$ for each user. We empirically evaluate PORE on popular benchmark datasets. ",
    "url": "https://arxiv.org/abs/2303.14601",
    "authors": [
      "Jinyuan Jia",
      "Yupei Liu",
      "Yuepeng Hu",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14608",
    "title": "Analyzing Effects of Mixed Sample Data Augmentation on Model  Interpretability",
    "abstract": "Data augmentation strategies are actively used when training deep neural networks (DNNs). Recent studies suggest that they are effective at various tasks. However, the effect of data augmentation on DNNs' interpretability is not yet widely investigated. In this paper, we explore the relationship between interpretability and data augmentation strategy in which models are trained with different data augmentation methods and are evaluated in terms of interpretability. To quantify the interpretability, we devise three evaluation methods based on alignment with humans, faithfulness to the model, and the number of human-recognizable concepts in the model. Comprehensive experiments show that models trained with mixed sample data augmentation show lower interpretability, especially for CutMix and SaliencyMix augmentations. This new finding suggests that it is important to carefully adopt mixed sample data augmentation due to the impact on model interpretability, especially in mission-critical applications. ",
    "url": "https://arxiv.org/abs/2303.14608",
    "authors": [
      "Soyoun Won",
      "Sung-Ho Bae",
      "Seong Tae Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14615",
    "title": "Explainable Artificial Intelligence Architecture for Melanoma Diagnosis  Using Indicator Localization and Self-Supervised Learning",
    "abstract": "Melanoma is a prevalent lethal type of cancer that is treatable if diagnosed at early stages of development. Skin lesions are a typical indicator for diagnosing melanoma but they often led to delayed diagnosis due to high similarities of cancerous and benign lesions at early stages of melanoma. Deep learning (DL) can be used as a solution to classify skin lesion pictures with a high accuracy, but clinical adoption of deep learning faces a significant challenge. The reason is that the decision processes of deep learning models are often uninterpretable which makes them black boxes that are challenging to trust. We develop an explainable deep learning architecture for melanoma diagnosis which generates clinically interpretable visual explanations for its decisions. Our experiments demonstrate that our proposed architectures matches clinical explanations significantly better than existing architectures. ",
    "url": "https://arxiv.org/abs/2303.14615",
    "authors": [
      "Ruitong Sun",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14617",
    "title": "Neural Graph Reasoning: Complex Logical Query Answering Meets Graph  Databases",
    "abstract": "Complex logical query answering (CLQA) is a recently emerged task of graph machine learning that goes beyond simple one-hop link prediction and solves a far more complex task of multi-hop logical reasoning over massive, potentially incomplete graphs in a latent space. The task received a significant traction in the community; numerous works expanded the field along theoretical and practical axes to tackle different types of complex queries and graph modalities with efficient systems. In this paper, we provide a holistic survey of CLQA with a detailed taxonomy studying the field from multiple angles, including graph types (modality, reasoning domain, background semantics), modeling aspects (encoder, processor, decoder), supported queries (operators, patterns, projected variables), datasets, evaluation metrics, and applications. Refining the CLQA task, we introduce the concept of Neural Graph Databases (NGDBs). Extending the idea of graph databases (graph DBs), NGDB consists of a Neural Graph Storage and a Neural Graph Engine. Inside Neural Graph Storage, we design a graph store, a feature store, and further embed information in a latent embedding store using an encoder. Given a query, Neural Query Engine learns how to perform query planning and execution in order to efficiently retrieve the correct results by interacting with the Neural Graph Storage. Compared with traditional graph DBs, NGDBs allow for a flexible and unified modeling of features in diverse modalities using the embedding store. Moreover, when the graph is incomplete, they can provide robust retrieval of answers which a normal graph DB cannot recover. Finally, we point out promising directions, unsolved problems and applications of NGDB for future research. ",
    "url": "https://arxiv.org/abs/2303.14617",
    "authors": [
      "Hongyu Ren",
      "Mikhail Galkin",
      "Michael Cochez",
      "Zhaocheng Zhu",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14626",
    "title": "MRCN: A Novel Modality Restitution and Compensation Network for  Visible-Infrared Person Re-identification",
    "abstract": "Visible-infrared person re-identification (VI-ReID), which aims to search identities across different spectra, is a challenging task due to large cross-modality discrepancy between visible and infrared images. The key to reduce the discrepancy is to filter out identity-irrelevant interference and effectively learn modality-invariant person representations. In this paper, we propose a novel Modality Restitution and Compensation Network (MRCN) to narrow the gap between the two modalities. Specifically, we first reduce the modality discrepancy by using two Instance Normalization (IN) layers. Next, to reduce the influence of IN layers on removing discriminative information and to reduce modality differences, we propose a Modality Restitution Module (MRM) and a Modality Compensation Module (MCM) to respectively distill modality-irrelevant and modality-relevant features from the removed information. Then, the modality-irrelevant features are used to restitute to the normalized visible and infrared features, while the modality-relevant features are used to compensate for the features of the other modality. Furthermore, to better disentangle the modality-relevant features and the modality-irrelevant features, we propose a novel Center-Quadruplet Causal (CQC) loss to encourage the network to effectively learn the modality-relevant features and the modality-irrelevant features. Extensive experiments are conducted to validate the superiority of our method on the challenging SYSU-MM01 and RegDB datasets. More remarkably, our method achieves 95.1% in terms of Rank-1 and 89.2% in terms of mAP on the RegDB dataset. ",
    "url": "https://arxiv.org/abs/2303.14626",
    "authors": [
      "Yukang Zhang",
      "Yan Yan",
      "Jie Li",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14628",
    "title": "Multi-Frame Self-Supervised Depth Estimation with Multi-Scale Feature  Fusion in Dynamic Scenes",
    "abstract": "Multi-frame methods improve monocular depth estimation over single-frame approaches by aggregating spatial-temporal information via feature matching. However, the spatial-temporal feature leads to accuracy degradation in dynamic scenes. To enhance the performance, recent methods tend to propose complex architectures for feature matching and dynamic scenes. In this paper, we show that a simple learning framework, together with designed feature augmentation, leads to superior performance. (1) A novel dynamic objects detecting method with geometry explainability is proposed. The detected dynamic objects are excluded during training, which guarantees the static environment assumption and relieves the accuracy degradation problem of the multi-frame depth estimation. (2) Multi-scale feature fusion is proposed for feature matching in the multi-frame depth network, which improves feature matching, especially between frames with large camera motion. (3) The robust knowledge distillation with a robust teacher network and reliability guarantee is proposed, which improves the multi-frame depth estimation without computation complexity increase during the test. The experiments show that our proposed methods achieve great performance improvement on the multi-frame depth estimation. ",
    "url": "https://arxiv.org/abs/2303.14628",
    "authors": [
      "Jiquan Zhong",
      "Xiaolin Huang",
      "Xiao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.14634",
    "title": "Resource Efficiency vs Performance Isolation Tradeoff in Network Slicing",
    "abstract": "We consider the tradeoff between resource efficiency and performance isolation that emerges when multiplexing the resource demands of Network Slices (NSs). On the one hand, multiplexing allows the use of idle resources, which increases resource efficiency. On the other hand, the performance of each NS becomes susceptible to traffic surges in other NSs, which degrades performance isolation. The analysis of this tradeoff enables network operators to determine the effect of performance isolation on the operating cost of each NS. To study the tradeoff, we solve an optimization problem where we find the multiplexing policy that requires the least provisioned resources to honor the Service Level Agreements (SLAs) of all NSs. The SLA of each NS i states that its resource demand should be met for $P^H_i$ fraction of time, and for $P^L_i \\leq P^H_i$ fraction of time, it should be met regardless of the demands of other NSs. For resource demands that follow ergodic Markov chains, we show that the well-known Max-Weight scheduler is an optimal multiplexing policy. Since the Max-Weight scheduler does not require any knowledge of the statistics of the resource demands, we also propose its use in non-markovian settings. For resource demands obtained in the LTE module of ns-3, we show that the Max-Weight scheduler reduces the provisioned bandwidth by 36.2% when no performance isolation is required. Lastly, for these non-markovian resource demands, the Max-Weight scheduler maintains its optimality since it requires as much provisioned bandwidth as the best non-causal scheduler. ",
    "url": "https://arxiv.org/abs/2303.14634",
    "authors": [
      "Panagiotis Nikolaidis",
      "Asim Zoulkarni",
      "John Baras"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.14639",
    "title": "CRRS: Concentric Rectangles Regression Strategy for Multi-point  Representation on Fisheye Images",
    "abstract": "Modern object detectors take advantage of rectangular bounding boxes as a conventional way to represent objects. When it comes to fisheye images, rectangular boxes involve more background noise rather than semantic information. Although multi-point representation has been proposed, both the regression accuracy and convergence still perform inferior to the widely used rectangular boxes. In order to further exploit the advantages of multi-point representation for distorted images, Concentric Rectangles Regression Strategy(CRRS) is proposed in this work. We adopt smoother mean loss to allocate weights and discuss the effect of hyper-parameter to prediction results. Moreover, an accurate pixel-level method is designed to obtain irregular IoU for estimating detector performance. Compared with the previous work for muti-point representation, the experiments show that CRRS can improve the training performance both in accurate and stability. We also prove that multi-task weighting strategy facilitates regression process in this design. ",
    "url": "https://arxiv.org/abs/2303.14639",
    "authors": [
      "Xihan Wang",
      "Xi Xu",
      "Yu Gao",
      "Yi Yang",
      "Yufeng Yue",
      "Mengyin Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14645",
    "title": "Sector Patch Embedding: An Embedding Module Conforming to The Distortion  Pattern of Fisheye Image",
    "abstract": "Fisheye cameras suffer from image distortion while having a large field of view(LFOV). And this fact leads to poor performance on some fisheye vision tasks. One of the solutions is to optimize the current vision algorithm for fisheye images. However, most of the CNN-based methods and the Transformer-based methods lack the capability of leveraging distortion information efficiently. In this work, we propose a novel patch embedding method called Sector Patch Embedding(SPE), conforming to the distortion pattern of the fisheye image. Furthermore, we put forward a synthetic fisheye dataset based on the ImageNet-1K and explore the performance of several Transformer models on the dataset. The classification top-1 accuracy of ViT and PVT is improved by 0.75% and 2.8% with SPE respectively. The experiments show that the proposed sector patch embedding method can better perceive distortion and extract features on the fisheye images. Our method can be easily adopted to other Transformer-based models. Source code is at https://github.com/IN2-ViAUn/Sector-Patch-Embedding. ",
    "url": "https://arxiv.org/abs/2303.14645",
    "authors": [
      "Dianyi Yang",
      "Jiadong Tang",
      "Yu Gao",
      "Yi Yang",
      "Mengyin Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.14647",
    "title": "Farspredict: A benchmark dataset for link prediction",
    "abstract": "Link prediction with knowledge graph embedding (KGE) is a popular method for knowledge graph completion. Furthermore, training KGEs on non-English knowledge graph promote knowledge extraction and knowledge graph reasoning in the context of these languages. However, many challenges in non-English KGEs pose to learning a low-dimensional representation of a knowledge graph's entities and relations. This paper proposes \"Farspredict\" a Persian knowledge graph based on Farsbase (the most comprehensive knowledge graph in Persian). It also explains how the knowledge graph structure affects link prediction accuracy in KGE. To evaluate Farspredict, we implemented the popular models of KGE on it and compared the results with Freebase. Given the analysis results, some optimizations on the knowledge graph are carried out to improve its functionality in the KGE. As a result, a new Persian knowledge graph is achieved. Implementation results in the KGE models on Farspredict outperforming Freebases in many cases. At last, we discuss what improvements could be effective in enhancing the quality of Farspredict and how much it improves. ",
    "url": "https://arxiv.org/abs/2303.14647",
    "authors": [
      "Najmeh Torabian",
      "Behrouz Minaei-Bidgoli",
      "Mohsen Jahanshahi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.14665",
    "title": "Achieving Counterfactual Fairness with Imperfect Structural Causal Model",
    "abstract": "Counterfactual fairness alleviates the discrimination between the model prediction toward an individual in the actual world (observational data) and that in counterfactual world (i.e., what if the individual belongs to other sensitive groups). The existing studies need to pre-define the structural causal model that captures the correlations among variables for counterfactual inference; however, the underlying causal model is usually unknown and difficult to be validated in real-world scenarios. Moreover, the misspecification of the causal model potentially leads to poor performance in model prediction and thus makes unfair decisions. In this research, we propose a novel minimax game-theoretic model for counterfactual fairness that can produce accurate results meanwhile achieve a counterfactually fair decision with the relaxation of strong assumptions of structural causal models. In addition, we also theoretically prove the error bound of the proposed minimax model. Empirical experiments on multiple real-world datasets illustrate our superior performance in both accuracy and fairness. Source code is available at \\url{https://github.com/tridungduong16/counterfactual_fairness_game_theoretic}. ",
    "url": "https://arxiv.org/abs/2303.14665",
    "authors": [
      "Tri Dung Duong",
      "Qian Li",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.14668",
    "title": "CeFlow: A Robust and Efficient Counterfactual Explanation Framework for  Tabular Data using Normalizing Flows",
    "abstract": "Counterfactual explanation is a form of interpretable machine learning that generates perturbations on a sample to achieve the desired outcome. The generated samples can act as instructions to guide end users on how to observe the desired results by altering samples. Although state-of-the-art counterfactual explanation methods are proposed to use variational autoencoder (VAE) to achieve promising improvements, they suffer from two major limitations: 1) the counterfactuals generation is prohibitively slow, which prevents algorithms from being deployed in interactive environments; 2) the counterfactual explanation algorithms produce unstable results due to the randomness in the sampling procedure of variational autoencoder. In this work, to address the above limitations, we design a robust and efficient counterfactual explanation framework, namely CeFlow, which utilizes normalizing flows for the mixed-type of continuous and categorical features. Numerical experiments demonstrate that our technique compares favorably to state-of-the-art methods. We release our source at https://github.com/tridungduong16/fairCE.git for reproducing the results. ",
    "url": "https://arxiv.org/abs/2303.14668",
    "authors": [
      "Tri Dung Duong",
      "Qian Li",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14703",
    "title": "Biologically-primed deep neural network improves colorectal Cancer  Molecular subtypes prediction from H&E stained images",
    "abstract": "Colorectal cancer (CRC) molecular subtypes play a crucial role in determining treatment options. Immunotherapy is effective for the microsatellite instability (MSI) subtype of CRC, but not for the microsatellite stability (MSS) subtype. Recently, convolutional neural networks (CNNs) have been proposed for automated determination of CRC subtypes from H\\&E stained histopathological images. However, previous CNN architectures only consider binary outcomes of MSI or MSS, and do not account for additional biological cues that may affect the histopathological imaging phenotype. In this study, we propose a biologically-primed CNN (BP-CNN) architecture for CRC subtype classification from H\\&E stained images. Our BP-CNN accounts for additional biological cues by casting the binary classification outcome into a biologically-informed multi-class outcome. We evaluated the BP-CNN approach using a 5-fold cross-validation experimental setup for model development on the TCGA-CRC-DX cohort, comparing it to a baseline binary classification CNN. Our BP-CNN achieved superior performance when using either single-nucleotide-polymorphism (SNP) molecular features (AUC: 0.824$\\pm$0.02 vs. 0.761$\\pm$0.04, paired t-test, p$<$0.05) or CpG-Island methylation phenotype (CIMP) molecular features (AUC: 0.834$\\pm$0.01 vs. 0.787$\\pm$0.03, paired t-test, p$<$0.05). A combination of CIMP and SNP models further improved classification accuracy (AUC: 0.847$\\pm$0.01 vs. 0.787$\\pm$0.03, paired t-test, p$=$0.01). Our BP-CNN approach has the potential to provide insight into the biological cues that influence cancer histopathological imaging phenotypes and to improve the accuracy of deep-learning-based methods for determining cancer subtypes from histopathological imaging data. ",
    "url": "https://arxiv.org/abs/2303.14703",
    "authors": [
      "Hadar Hezi",
      "Daniel Shats",
      "Daniel Gurevich",
      "Yosef E. Maruvka",
      "Moti Freiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14705",
    "title": "Control of synaptic plasticity via the fusion of reinforcement learning  and unsupervised learning in neural networks",
    "abstract": "The brain can learn to execute a wide variety of tasks quickly and efficiently. Nevertheless, most of the mechanisms that enable us to learn are unclear or incredibly complicated. Recently, considerable efforts have been made in neuroscience and artificial intelligence to understand and model the structure and mechanisms behind the amazing learning capability of the brain. However, in the current understanding of cognitive neuroscience, it is widely accepted that synaptic plasticity plays an essential role in our amazing learning capability. This mechanism is also known as the Credit Assignment Problem (CAP) and is a fundamental challenge in neuroscience and Artificial Intelligence (AI). The observations of neuroscientists clearly confirm the role of two important mechanisms including the error feedback system and unsupervised learning in synaptic plasticity. With this inspiration, a new learning rule is proposed via the fusion of reinforcement learning (RL) and unsupervised learning (UL). In the proposed computational model, the nonlinear optimal control theory is used to resemble the error feedback loop systems and project the output error to neurons membrane potential (neurons state), and an unsupervised learning rule based on neurons membrane potential or neurons activity are utilized to simulate synaptic plasticity dynamics to ensure that the output error is minimized. ",
    "url": "https://arxiv.org/abs/2303.14705",
    "authors": [
      "Mohammad Modiri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.14710",
    "title": "Asymptotic analysis and efficient random sampling of directed ordered  acyclic graphs",
    "abstract": "Directed acyclic graphs (DAGs) are directed graphs in which there is no path from a vertex to itself. DAGs are an omnipresent data structure in computer science and the problem of counting the DAGs of given number of vertices and to sample them uniformly at random has been solved respectively in the 70's and the 00's. In this paper, we propose to explore a new variation of this model where DAGs are endowed with an independent ordering of the out-edges of each vertex, thus allowing to model a wide range of existing data structures. We provide efficient algorithms for sampling objects of this new class, both with or without control on the number of edges, and obtain an asymptotic equivalent of their number. We also show the applicability of our method by providing an effective algorithm for the random generation of classical labelled DAGs with a prescribed number of vertices and edges, based on a similar approach. This is the first known algorithm for sampling labelled DAGs with full control on the number of edges, and it meets a need in terms of applications, that had already been acknowledged in the literature. ",
    "url": "https://arxiv.org/abs/2303.14710",
    "authors": [
      "Martin P\u00e9pin",
      "Alfredo Viola"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.14730",
    "title": "Semantic Neural Decoding via Cross-Modal Generation",
    "abstract": "Semantic neural decoding aims to elucidate the cognitive processes of the human brain by reconstructing observed images from brain recordings. Although recent works have utilized deep generative models to generate images conditioned on fMRI signals, achieving high-quality generation with consistent semantics has proven to be a formidable challenge. To address this issue, we propose an end-to-end framework, SemanSig, which directly encodes fMRI signals and extracts semantic information. SemanSig leverages a deep generative model to decode the semantic information into high-quality images. To enhance the effectiveness of our framework, we use the ImageNet class prototype space as the internal representation space of fMRI signals, thereby reducing signal redundancy and learning difficulty. Consequently, this forms a semantic-rich and visually-friendly internal representation for generative models to decode. Notably, SemanSig does not require pre-training on a large fMRI dataset, and performs remarkably well when trained from scratch, even when the fMRI signal is limited. Our experimental results validate the effectiveness of SemanSig in achieving high-quality image generation with consistent semantics. ",
    "url": "https://arxiv.org/abs/2303.14730",
    "authors": [
      "Xuelin Qian",
      "Yikai Wang",
      "Yanwei Fu",
      "Xiangyang Xue",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14744",
    "title": "Mind the Backbone: Minimizing Backbone Distortion for Robust Object  Detection",
    "abstract": "Building object detectors that are robust to domain shifts is critical for real-world applications. Prior approaches fine-tune a pre-trained backbone and risk overfitting it to in-distribution (ID) data and distorting features useful for out-of-distribution (OOD) generalization. We propose to use Relative Gradient Norm (RGN) as a way to measure the vulnerability of a backbone to feature distortion, and show that high RGN is indeed correlated with lower OOD performance. Our analysis of RGN yields interesting findings: some backbones lose OOD robustness during fine-tuning, but others gain robustness because their architecture prevents the parameters from changing too much from the initial model. Given these findings, we present recipes to boost OOD robustness for both types of backbones. Specifically, we investigate regularization and architectural choices for minimizing gradient updates so as to prevent the tuned backbone from losing generalizable features. Our proposed techniques complement each other and show substantial improvements over baselines on diverse architectures and datasets. ",
    "url": "https://arxiv.org/abs/2303.14744",
    "authors": [
      "Kuniaki Saito",
      "Donghyun Kim",
      "Piotr Teterwak",
      "Rogerio Feris",
      "Kate Saenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14745",
    "title": "Combining General and Personalized Models for Epilepsy Detection with  Hyperdimensional Computing",
    "abstract": "Epilepsy is a chronic neurological disorder with a significant prevalence. However, there is still no adequate technological support to enable epilepsy detection and continuous outpatient monitoring in everyday life. Hyperdimensional (HD) computing is an interesting alternative for wearable devices, characterized by a much simpler learning process and also lower memory requirements. In this work, we demonstrate a few additional aspects in which HD computing, and the way its models are built and stored, can be used for further understanding, comparing, and creating more advanced machine learning models for epilepsy detection. These possibilities are not feasible with other state-of-the-art models, such as random forests or neural networks. We compare inter-subject similarity of models per different classes (seizure and non-seizure), then study the process of creation of generalized models from personalized ones, and in the end, how to combine personalized and generalized models to create hybrid models. This results in improved epilepsy detection performance. We also tested knowledge transfer between models created on two different datasets. Finally, all those examples could be highly interesting not only from an engineering perspective to create better models for wearables, but also from a neurological perspective to better understand individual epilepsy patterns. ",
    "url": "https://arxiv.org/abs/2303.14745",
    "authors": [
      "Una Pale",
      "Tomas Teijeiro",
      "David Atienza"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14751",
    "title": "Matrix-Scaled Consensus over Undirected Networks",
    "abstract": "In this paper, we propose matrix-scaled consensus algorithms for linear dynamical agents interacted over an undirected network. The goal of these algorithms is making the matrix-scaled state vectors of all agents to asymptotically agree. Algebraic properties of the matrix-scaled Laplacian are firstly examined. Second, we propose matrix-scaled consensus algorithms for networks of single integrators with or without constant parametric uncertainties. Third, observer-based matrix-scaled synchronization algorithms for networks of homogeneous or heterogeneous linear agents are proposed. The effectiveness of each proposed algorithm is asserted by rigorous analysis and supported by numerical simulations. ",
    "url": "https://arxiv.org/abs/2303.14751",
    "authors": [
      "Minh Hoang Trinh",
      "Hoang Huy Vu",
      "Nhat-Minh Le-Phan",
      "Quyen Ngoc Nguyen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.14768",
    "title": "Collaborative Noisy Label Cleaner: Learning Scene-aware Trailers for  Multi-modal Highlight Detection in Movies",
    "abstract": "Movie highlights stand out of the screenplay for efficient browsing and play a crucial role on social media platforms. Based on existing efforts, this work has two observations: (1) For different annotators, labeling highlight has uncertainty, which leads to inaccurate and time-consuming annotations. (2) Besides previous supervised or unsupervised settings, some existing video corpora can be useful, e.g., trailers, but they are often noisy and incomplete to cover the full highlights. In this work, we study a more practical and promising setting, i.e., reformulating highlight detection as \"learning with noisy labels\". This setting does not require time-consuming manual annotations and can fully utilize existing abundant video corpora. First, based on movie trailers, we leverage scene segmentation to obtain complete shots, which are regarded as noisy labels. Then, we propose a Collaborative noisy Label Cleaner (CLC) framework to learn from noisy highlight moments. CLC consists of two modules: augmented cross-propagation (ACP) and multi-modality cleaning (MMC). The former aims to exploit the closely related audio-visual signals and fuse them to learn unified multi-modal representations. The latter aims to achieve cleaner highlight labels by observing the changes in losses among different modalities. To verify the effectiveness of CLC, we further collect a large-scale highlight dataset named MovieLights. Comprehensive experiments on MovieLights and YouTube Highlights datasets demonstrate the effectiveness of our approach. Code has been made available at: https://github.com/TencentYoutuResearch/HighlightDetection-CLC ",
    "url": "https://arxiv.org/abs/2303.14768",
    "authors": [
      "Bei Gan",
      "Xiujun Shu",
      "Ruizhi Qiao",
      "Haoqian Wu",
      "Keyu Chen",
      "Hanjun Li",
      "Bo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14773",
    "title": "BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning",
    "abstract": "With the surge of large-scale pre-trained models (PTMs), fine-tuning these models to numerous downstream tasks becomes a crucial problem. Consequently, parameter efficient transfer learning (PETL) of large models has grasped huge attention. While recent PETL methods showcase impressive performance, they rely on optimistic assumptions: 1) the entire parameter set of a PTM is available, and 2) a sufficiently large memory capacity for the fine-tuning is equipped. However, in most real-world applications, PTMs are served as a black-box API or proprietary software without explicit parameter accessibility. Besides, it is hard to meet a large memory requirement for modern PTMs. In this work, we propose black-box visual prompting (BlackVIP), which efficiently adapts the PTMs without knowledge about model architectures and parameters. BlackVIP has two components; 1) Coordinator and 2) simultaneous perturbation stochastic approximation with gradient correction (SPSA-GC). The Coordinator designs input-dependent image-shaped visual prompts, which improves few-shot adaptation and robustness on distribution/location shift. SPSA-GC efficiently estimates the gradient of a target model to update Coordinator. Extensive experiments on 16 datasets demonstrate that BlackVIP enables robust adaptation to diverse domains without accessing PTMs' parameters, with minimal memory requirements. Code: \\url{https://github.com/changdaeoh/BlackVIP} ",
    "url": "https://arxiv.org/abs/2303.14773",
    "authors": [
      "Changdae Oh",
      "Hyeji Hwang",
      "Hee-young Lee",
      "YongTaek Lim",
      "Geunyoung Jung",
      "Jiyoung Jung",
      "Hosik Choi",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14777",
    "title": "Query Generation based on Generative Adversarial Networks",
    "abstract": "Many problems in database systems, such as cardinality estimation, database testing and optimizer tuning, require a large query load as data. However, it is often difficult to obtain a large number of real queries from users due to user privacy restrictions or low frequency of database access. Query generation is one of the approaches to solve this problem. Existing query generation methods, such as random generation and template-based generation, do not consider the relationship between the generated queries and existing queries, or even generate semantically incorrect queries. In this paper, we propose a query generation framework based on generative adversarial networks (GAN) to generate query load that is similar to the given query load. In our framework, we use a syntax parser to transform the query into a parse tree and traverse the tree to obtain the sequence of production rules corresponding to the query. The generator of GAN takes a fixed distribution prior as input and outputs the query sequence, and the discriminator takes the real query and the fake query generated by the generator as input and outputs a gradient to guide the generator learning. In addition, we add context-free grammar and semantic rules to the generation process, which ensures that the generated queries are syntactically and semantically correct. We conduct experiments to evaluate our approach on real-world dataset, which show that our approach can generate new query loads with a similar distribution to a given query load, and that the generated queries are syntactically correct with no semantic errors. The generated query loads are used in downstream task, and the results show a significant improvement in the models trained with the expanded query loads using our approach. ",
    "url": "https://arxiv.org/abs/2303.14777",
    "authors": [
      "Weihua Sun",
      "Run-An Wang",
      "Zhaonian Zou"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2303.14810",
    "title": "Permutation Inequalities for Walks in Graphs",
    "abstract": "Using spectral graph theory, we show how to obtain inequalities for the number of walks in graphs from nonnegative polynomials and present a new family of such inequalities. ",
    "url": "https://arxiv.org/abs/2303.14810",
    "authors": [
      "Nadja Willenborg",
      "Sven Kosub"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Algebraic Geometry (math.AG)"
    ]
  },
  {
    "id": "arXiv:2303.14816",
    "title": "Feature Shrinkage Pyramid for Camouflaged Object Detection with  Transformers",
    "abstract": "Vision transformers have recently shown strong global context modeling capabilities in camouflaged object detection. However, they suffer from two major limitations: less effective locality modeling and insufficient feature aggregation in decoders, which are not conducive to camouflaged object detection that explores subtle cues from indistinguishable backgrounds. To address these issues, in this paper, we propose a novel transformer-based Feature Shrinkage Pyramid Network (FSPNet), which aims to hierarchically decode locality-enhanced neighboring transformer features through progressive shrinking for camouflaged object detection. Specifically, we propose a nonlocal token enhancement module (NL-TEM) that employs the non-local mechanism to interact neighboring tokens and explore graph-based high-order relations within tokens to enhance local representations of transformers. Moreover, we design a feature shrinkage decoder (FSD) with adjacent interaction modules (AIM), which progressively aggregates adjacent transformer features through a layer-bylayer shrinkage pyramid to accumulate imperceptible but effective cues as much as possible for object information decoding. Extensive quantitative and qualitative experiments demonstrate that the proposed model significantly outperforms the existing 24 competitors on three challenging COD benchmark datasets under six widely-used evaluation metrics. Our code is publicly available at https://github.com/ZhouHuang23/FSPNet. ",
    "url": "https://arxiv.org/abs/2303.14816",
    "authors": [
      "Zhou Huang",
      "Hang Dai",
      "Tian-Zhu Xiang",
      "Shuo Wang",
      "Huai-Xin Chen",
      "Jie Qin",
      "Huan Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14817",
    "title": "Frame Flexible Network",
    "abstract": "Existing video recognition algorithms always conduct different training pipelines for inputs with different frame numbers, which requires repetitive training operations and multiplying storage costs. If we evaluate the model using other frames which are not used in training, we observe the performance will drop significantly (see Fig.1), which is summarized as Temporal Frequency Deviation phenomenon. To fix this issue, we propose a general framework, named Frame Flexible Network (FFN), which not only enables the model to be evaluated at different frames to adjust its computation, but also reduces the memory costs of storing multiple models significantly. Concretely, FFN integrates several sets of training sequences, involves Multi-Frequency Alignment (MFAL) to learn temporal frequency invariant representations, and leverages Multi-Frequency Adaptation (MFAD) to further strengthen the representation abilities. Comprehensive empirical validations using various architectures and popular benchmarks solidly demonstrate the effectiveness and generalization of FFN (e.g., 7.08/5.15/2.17% performance gain at Frame 4/8/16 on Something-Something V1 dataset over Uniformer). Code is available at https://github.com/BeSpontaneous/FFN. ",
    "url": "https://arxiv.org/abs/2303.14817",
    "authors": [
      "Yitian Zhang",
      "Yue Bai",
      "Chang Liu",
      "Huan Wang",
      "Sheng Li",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14822",
    "title": "MGTBench: Benchmarking Machine-Generated Text Detection",
    "abstract": "Nowadays large language models (LLMs) have shown revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. In this way, detecting machine-generated texts (MGTs) is becoming increasingly important as LLMs become more advanced and prevalent. These models can generate human-like language that can be difficult to distinguish from text written by a human, which raises concerns about authenticity, accountability, and potential bias. However, existing detection methods against MGTs are evaluated under different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework across different methodologies In this paper, we fill this gap by proposing the first benchmark framework for MGT detection, named MGTBench. Extensive evaluations on public datasets with curated answers generated by ChatGPT (the most representative and powerful LLMs thus far) show that most of the current detection methods perform less satisfactorily against MGTs. An exceptional case is ChatGPT Detector, which is trained with ChatGPT-generated texts and shows great performance in detecting MGTs. Nonetheless, we note that only a small fraction of adversarial-crafted perturbations on MGTs can evade the ChatGPT Detector, thus highlighting the need for more robust MGT detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of state-of-the-art MGT detection methods on their respective datasets and the development of more advanced MGT detection methods. Our source code and datasets are available at https://github.com/xinleihe/MGTBench. ",
    "url": "https://arxiv.org/abs/2303.14822",
    "authors": [
      "Xinlei He",
      "Xinyue Shen",
      "Zeyuan Chen",
      "Michael Backes",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14836",
    "title": "Illuminati: Towards Explaining Graph Neural Networks for Cybersecurity  Analysis",
    "abstract": "Graph neural networks (GNNs) have been utilized to create multi-layer graph models for a number of cybersecurity applications from fraud detection to software vulnerability analysis. Unfortunately, like traditional neural networks, GNNs also suffer from a lack of transparency, that is, it is challenging to interpret the model predictions. Prior works focused on specific factor explanations for a GNN model. In this work, we have designed and implemented Illuminati, a comprehensive and accurate explanation framework for cybersecurity applications using GNN models. Given a graph and a pre-trained GNN model, Illuminati is able to identify the important nodes, edges, and attributes that are contributing to the prediction while requiring no prior knowledge of GNN models. We evaluate Illuminati in two cybersecurity applications, i.e., code vulnerability detection and smart contract vulnerability detection. The experiments show that Illuminati achieves more accurate explanation results than state-of-the-art methods, specifically, 87.6% of subgraphs identified by Illuminati are able to retain their original prediction, an improvement of 10.3% over others at 77.3%. Furthermore, the explanation of Illuminati can be easily understood by the domain experts, suggesting the significant usefulness for the development of cybersecurity applications. ",
    "url": "https://arxiv.org/abs/2303.14836",
    "authors": [
      "Haoyu He",
      "Yuede Ji",
      "H. Howie Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.14841",
    "title": "Driver Drowsiness Detection with Commercial EEG Headsets",
    "abstract": "Driver Drowsiness is one of the leading causes of road accidents. Electroencephalography (EEG) is highly affected by drowsiness; hence, EEG-based methods detect drowsiness with the highest accuracy. Developments in manufacturing dry electrodes and headsets have made recording EEG more convenient. Vehicle-based features used for detecting drowsiness are easy to capture but do not have the best performance. In this paper, we investigated the performance of EEG signals recorded in 4 channels with commercial headsets against the vehicle-based technique in drowsiness detection. We recorded EEG signals of 50 volunteers driving a simulator in drowsy and alert states by commercial devices. The observer rating of the drowsiness method was used to determine the drowsiness level of the subjects. The meaningful separation of vehicle-based features, recorded by the simulator, and EEG-based features of the two states of drowsiness and alertness have been investigated. The comparison results indicated that the EEG-based features are separated with lower p-values than the vehicle-based ones in the two states. It is concluded that EEG headsets can be feasible alternatives with better performance compared to vehicle-based methods for detecting drowsiness. ",
    "url": "https://arxiv.org/abs/2303.14841",
    "authors": [
      "Qazal Rezaee",
      "Mehdi Delrobaei",
      "Ashkan Giveki",
      "Nasireh Dayarian",
      "Sahar Javaher Haghighi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.14859",
    "title": "Mind the Label Shift of Augmentation-based Graph OOD Generalization",
    "abstract": "Out-of-distribution (OOD) generalization is an important issue for Graph Neural Networks (GNNs). Recent works employ different graph editions to generate augmented environments and learn an invariant GNN for generalization. However, the label shift usually occurs in augmentation since graph structural edition inevitably alters the graph label. This brings inconsistent predictive relationships among augmented environments, which is harmful to generalization. To address this issue, we propose \\textbf{LiSA}, which generates label-invariant augmentations to facilitate graph OOD generalization. Instead of resorting to graph editions, LiSA exploits \\textbf{L}abel-\\textbf{i}nvariant \\textbf{S}ubgraphs of the training graphs to construct \\textbf{A}ugmented environments. Specifically, LiSA first designs the variational subgraph generators to extract locally predictive patterns and construct multiple label-invariant subgraphs efficiently. Then, the subgraphs produced by different generators are collected to build different augmented environments. To promote diversity among augmented environments, LiSA further introduces a tractable energy-based regularization to enlarge pair-wise distances between the distributions of environments. In this manner, LiSA generates diverse augmented environments with a consistent predictive relationship and facilitates learning an invariant GNN. Extensive experiments on node-level and graph-level OOD benchmarks show that LiSA achieves impressive generalization performance with different GNN backbones. Code is available on \\url{https://github.com/Samyu0304/LiSA}. ",
    "url": "https://arxiv.org/abs/2303.14859",
    "authors": [
      "Junchi Yu",
      "Jian Liang",
      "Ran He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14863",
    "title": "DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion",
    "abstract": "We propose a new formulation of temporal action detection (TAD) with denoising diffusion, DiffTAD in short. Taking as input random temporal proposals, it can yield action proposals accurately given an untrimmed long video. This presents a generative modeling perspective, against previous discriminative learning manners. This capability is achieved by first diffusing the ground-truth proposals to random ones (i.e., the forward/noising process) and then learning to reverse the noising process (i.e., the backward/denoising process). Concretely, we establish the denoising process in the Transformer decoder (e.g., DETR) by introducing a temporal location query design with faster convergence in training. We further propose a cross-step selective conditioning algorithm for inference acceleration. Extensive evaluations on ActivityNet and THUMOS show that our DiffTAD achieves top performance compared to previous art alternatives. The code will be made available at https://github.com/sauradip/DiffusionTAD. ",
    "url": "https://arxiv.org/abs/2303.14863",
    "authors": [
      "Sauradip Nag",
      "Xiatian Zhu",
      "Jiankang Deng",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.14865",
    "title": "Revisiting Multimodal Representation in Contrastive Learning: From Patch  and Token Embeddings to Finite Discrete Tokens",
    "abstract": "Contrastive learning-based vision-language pre-training approaches, such as CLIP, have demonstrated great success in many vision-language tasks. These methods achieve cross-modal alignment by encoding a matched image-text pair with similar feature embeddings, which are generated by aggregating information from visual patches and language tokens. However, direct aligning cross-modal information using such representations is challenging, as visual patches and text tokens differ in semantic levels and granularities. To alleviate this issue, we propose a Finite Discrete Tokens (FDT) based multimodal representation. FDT is a set of learnable tokens representing certain visual-semantic concepts. Both images and texts are embedded using shared FDT by first grounding multimodal inputs to FDT space and then aggregating the activated FDT representations. The matched visual and semantic concepts are enforced to be represented by the same set of discrete tokens by a sparse activation constraint. As a result, the granularity gap between the two modalities is reduced. Through both quantitative and qualitative analyses, we demonstrate that using FDT representations in CLIP-style models improves cross-modal alignment and performance in visual recognition and vision-language downstream tasks. Furthermore, we show that our method can learn more comprehensive representations, and the learned FDT capture meaningful cross-modal correspondence, ranging from objects to actions and attributes. ",
    "url": "https://arxiv.org/abs/2303.14865",
    "authors": [
      "Yuxiao Chen",
      "Jianbo Yuan",
      "Yu Tian",
      "Shijie Geng",
      "Xinyu Li",
      "Ding Zhou",
      "Dimitris N. Metaxas",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14868",
    "title": "The Resource Problem of Using Linear Layer Leakage Attack in Federated  Learning",
    "abstract": "Secure aggregation promises a heightened level of privacy in federated learning, maintaining that a server only has access to a decrypted aggregate update. Within this setting, linear layer leakage methods are the only data reconstruction attacks able to scale and achieve a high leakage rate regardless of the number of clients or batch size. This is done through increasing the size of an injected fully-connected (FC) layer. However, this results in a resource overhead which grows larger with an increasing number of clients. We show that this resource overhead is caused by an incorrect perspective in all prior work that treats an attack on an aggregate update in the same way as an individual update with a larger batch size. Instead, by attacking the update from the perspective that aggregation is combining multiple individual updates, this allows the application of sparsity to alleviate resource overhead. We show that the use of sparsity can decrease the model size overhead by over 327$\\times$ and the computation time by 3.34$\\times$ compared to SOTA while maintaining equivalent total leakage rate, 77% even with $1000$ clients in aggregation. ",
    "url": "https://arxiv.org/abs/2303.14868",
    "authors": [
      "Joshua C. Zhao",
      "Ahmed Roushdy Elkordy",
      "Atul Sharma",
      "Yahya H. Ezzeldin",
      "Salman Avestimehr",
      "Saurabh Bagchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14878",
    "title": "GPT-PINN: Generative Pre-Trained Physics-Informed Neural Networks toward  non-intrusive Meta-learning of parametric PDEs",
    "abstract": "Physics-Informed Neural Network (PINN) has proven itself a powerful tool to obtain the numerical solutions of nonlinear partial differential equations (PDEs) leveraging the expressivity of deep neural networks and the computing power of modern heterogeneous hardware. However, its training is still time-consuming, especially in the multi-query and real-time simulation settings, and its parameterization often overly excessive. In this paper, we propose the Generative Pre-Trained PINN (GPT-PINN) to mitigate both challenges in the setting of parametric PDEs. GPT-PINN represents a brand-new meta-learning paradigm for parametric systems. As a network of networks, its outer-/meta-network is hyper-reduced with only one hidden layer having significantly reduced number of neurons. Moreover, its activation function at each hidden neuron is a (full) PINN pre-trained at a judiciously selected system configuration. The meta-network adaptively ``learns'' the parametric dependence of the system and ``grows'' this hidden layer one neuron at a time. In the end, by encompassing a very small number of networks trained at this set of adaptively-selected parameter values, the meta-network is capable of generating surrogate solutions for the parametric system across the entire parameter domain accurately and efficiently. ",
    "url": "https://arxiv.org/abs/2303.14878",
    "authors": [
      "Yanlai Chen",
      "Shawn Koohy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14880",
    "title": "Toward Human-Like Social Robot Navigation: A Large-Scale, Multi-Modal,  Social Human Navigation Dataset",
    "abstract": "Humans are well-adept at navigating public spaces shared with others, where current autonomous mobile robots still struggle: while safely and efficiently reaching their goals, humans communicate their intentions and conform to unwritten social norms on a daily basis; conversely, robots become clumsy in those daily social scenarios, getting stuck in dense crowds, surprising nearby pedestrians, or even causing collisions. While recent research on robot learning has shown promises in data-driven social robot navigation, good-quality training data is still difficult to acquire through either trial and error or expert demonstrations. In this work, we propose to utilize the body of rich, widely available, social human navigation data in many natural human-inhabited public spaces for robots to learn similar, human-like, socially compliant navigation behaviors. To be specific, we design an open-source egocentric data collection sensor suite wearable by walking humans to provide multi-modal robot perception data; we collect a large-scale (~50 km, 10 hours, 150 trials, 7 humans) dataset in a variety of public spaces which contain numerous natural social navigation interactions; we analyze our dataset, demonstrate its usability, and point out future research directions and use cases. ",
    "url": "https://arxiv.org/abs/2303.14880",
    "authors": [
      "Duc M. Nguyen",
      "Mohammad Nazeri",
      "Amirreza Payandeh",
      "Aniket Datar",
      "Xuesu Xiao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.14897",
    "title": "Seer: Language Instructed Video Prediction with Latent Diffusion Models",
    "abstract": "Imagining the future trajectory is the key for robots to make sound planning and successfully reach their goals. Therefore, text-conditioned video prediction (TVP) is an essential task to facilitate general robot policy learning, i.e., predicting future video frames with a given language instruction and reference frames. It is a highly challenging task to ground task-level goals specified by instructions and high-fidelity frames together, requiring large-scale data and computation. To tackle this task and empower robots with the ability to foresee the future, we propose a sample and computation-efficient model, named \\textbf{Seer}, by inflating the pretrained text-to-image (T2I) stable diffusion models along the temporal axis. We inflate the denoising U-Net and language conditioning model with two novel techniques, Autoregressive Spatial-Temporal Attention and Frame Sequential Text Decomposer, to propagate the rich prior knowledge in the pretrained T2I models across the frames. With the well-designed architecture, Seer makes it possible to generate high-fidelity, coherent, and instruction-aligned video frames by fine-tuning a few layers on a small amount of data. The experimental results on Something Something V2 (SSv2) and Bridgedata datasets demonstrate our superior video prediction performance with around 210-hour training on 4 RTX 3090 GPUs: decreasing the FVD of the current SOTA model from 290 to 200 on SSv2 and achieving at least 70\\% preference in the human evaluation. ",
    "url": "https://arxiv.org/abs/2303.14897",
    "authors": [
      "Xianfan Gu",
      "Chuan Wen",
      "Jiaming Song",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14898",
    "title": "Mutually-paced Knowledge Distillation for Cross-lingual Temporal  Knowledge Graph Reasoning",
    "abstract": "This paper investigates cross-lingual temporal knowledge graph reasoning problem, which aims to facilitate reasoning on Temporal Knowledge Graphs (TKGs) in low-resource languages by transfering knowledge from TKGs in high-resource ones. The cross-lingual distillation ability across TKGs becomes increasingly crucial, in light of the unsatisfying performance of existing reasoning methods on those severely incomplete TKGs, especially in low-resource languages. However, it poses tremendous challenges in two aspects. First, the cross-lingual alignments, which serve as bridges for knowledge transfer, are usually too scarce to transfer sufficient knowledge between two TKGs. Second, temporal knowledge discrepancy of the aligned entities, especially when alignments are unreliable, can mislead the knowledge distillation process. We correspondingly propose a mutually-paced knowledge distillation model MP-KD, where a teacher network trained on a source TKG can guide the training of a student network on target TKGs with an alignment module. Concretely, to deal with the scarcity issue, MP-KD generates pseudo alignments between TKGs based on the temporal information extracted by our representation module. To maximize the efficacy of knowledge transfer and control the noise caused by the temporal knowledge discrepancy, we enhance MP-KD with a temporal cross-lingual attention mechanism to dynamically estimate the alignment strength. The two procedures are mutually paced along with model training. Extensive experiments on twelve cross-lingual TKG transfer tasks in the EventKG benchmark demonstrate the effectiveness of the proposed MP-KD method. ",
    "url": "https://arxiv.org/abs/2303.14898",
    "authors": [
      "Ruijie Wang",
      "Zheng Li",
      "Jingfeng Yang",
      "Tianyu Cao",
      "Chao Zhang",
      "Bing Yin",
      "Tarek Abdelzaher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.14920",
    "title": "Adapting Pretrained Language Models for Solving Tabular Prediction  Problems in the Electronic Health Record",
    "abstract": "We propose an approach for adapting the DeBERTa model for electronic health record (EHR) tasks using domain adaptation. We pretrain a small DeBERTa model on a dataset consisting of MIMIC-III discharge summaries, clinical notes, radiology reports, and PubMed abstracts. We compare this model's performance with a DeBERTa model pre-trained on clinical texts from our institutional EHR (MeDeBERTa) and an XGBoost model. We evaluate performance on three benchmark tasks for emergency department outcomes using the MIMIC-IV-ED dataset. We preprocess the data to convert it into text format and generate four versions of the original datasets to compare data processing and data inclusion. The results show that our proposed approach outperforms the alternative models on two of three tasks (p<0.001) and matches performance on the third task, with the use of descriptive columns improving performance over the original column names. ",
    "url": "https://arxiv.org/abs/2303.14920",
    "authors": [
      "Christopher McMaster",
      "David FL Liew",
      "Douglas EV Pires"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14922",
    "title": "CAT:Collaborative Adversarial Training",
    "abstract": "Adversarial training can improve the robustness of neural networks. Previous methods focus on a single adversarial training strategy and do not consider the model property trained by different strategies. By revisiting the previous methods, we find different adversarial training methods have distinct robustness for sample instances. For example, a sample instance can be correctly classified by a model trained using standard adversarial training (AT) but not by a model trained using TRADES, and vice versa. Based on this observation, we propose a collaborative adversarial training framework to improve the robustness of neural networks. Specifically, we use different adversarial training methods to train robust models and let models interact with their knowledge during the training process. Collaborative Adversarial Training (CAT) can improve both robustness and accuracy. Extensive experiments on various networks and datasets validate the effectiveness of our method. CAT achieves state-of-the-art adversarial robustness without using any additional data on CIFAR-10 under the Auto-Attack benchmark. Code is available at https://github.com/liuxingbin/CAT. ",
    "url": "https://arxiv.org/abs/2303.14922",
    "authors": [
      "Xingbin Liu",
      "Huafeng Kuang",
      "Xianming Lin",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14930",
    "title": "Addressing the Challenges of Open-World Object Detection",
    "abstract": "We address the challenging problem of open world object detection (OWOD), where object detectors must identify objects from known classes while also identifying and continually learning to detect novel objects. Prior work has resulted in detectors that have a relatively low ability to detect novel objects, and a high likelihood of classifying a novel object as one of the known classes. We approach the problem by identifying the three main challenges that OWOD presents and introduce OW-RCNN, an open world object detector that addresses each of these three challenges. OW-RCNN establishes a new state of the art using the open-world evaluation protocol on MS-COCO, showing a drastically increased ability to detect novel objects (16-21% absolute increase in U-Recall), to avoid their misclassification as one of the known classes (up to 52% reduction in A-OSE), and to incrementally learn to detect them while maintaining performance on previously known classes (1-6% absolute increase in mAP). ",
    "url": "https://arxiv.org/abs/2303.14930",
    "authors": [
      "David Pershouse",
      "Feras Dayoub",
      "Dimity Miller",
      "Niko S\u00fcnderhauf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14934",
    "title": "Spatially Adaptive Self-Supervised Learning for Real-World Image  Denoising",
    "abstract": "Significant progress has been made in self-supervised image denoising (SSID) in the recent few years. However, most methods focus on dealing with spatially independent noise, and they have little practicality on real-world sRGB images with spatially correlated noise. Although pixel-shuffle downsampling has been suggested for breaking the noise correlation, it breaks the original information of images, which limits the denoising performance. In this paper, we propose a novel perspective to solve this problem, i.e., seeking for spatially adaptive supervision for real-world sRGB image denoising. Specifically, we take into account the respective characteristics of flat and textured regions in noisy images, and construct supervisions for them separately. For flat areas, the supervision can be safely derived from non-adjacent pixels, which are much far from the current pixel for excluding the influence of the noise-correlated ones. And we extend the blind-spot network to a blind-neighborhood network (BNN) for providing supervision on flat areas. For textured regions, the supervision has to be closely related to the content of adjacent pixels. And we present a locally aware network (LAN) to meet the requirement, while LAN itself is selectively supervised with the output of BNN. Combining these two supervisions, a denoising network (e.g., U-Net) can be well-trained. Extensive experiments show that our method performs favorably against state-of-the-art SSID methods on real-world sRGB photographs. The code is available at https://github.com/nagejacob/SpatiallyAdaptiveSSID. ",
    "url": "https://arxiv.org/abs/2303.14934",
    "authors": [
      "Junyi Li",
      "Zhilu Zhang",
      "Xiaoyu Liu",
      "Chaoyu Feng",
      "Xiaotao Wang",
      "Lei Lei",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.14937",
    "title": "LEURN: Learning Explainable Univariate Rules with Neural Networks",
    "abstract": "In this paper, we propose LEURN: a neural network architecture that learns univariate decision rules. LEURN is a white-box algorithm that results into univariate trees and makes explainable decisions in every stage. In each layer, LEURN finds a set of univariate rules based on an embedding of the previously checked rules and their corresponding responses. Both rule finding and final decision mechanisms are weighted linear combinations of these embeddings, hence contribution of all rules are clearly formulated and explainable. LEURN can select features, extract feature importance, provide semantic similarity between a pair of samples, be used in a generative manner and can give a confidence score. Thanks to a smoothness parameter, LEURN can also controllably behave like decision trees or vanilla neural networks. Besides these advantages, LEURN achieves comparable performance to state-of-the-art methods across 30 tabular datasets for classification and regression problems. ",
    "url": "https://arxiv.org/abs/2303.14937",
    "authors": [
      "Caglar Aytekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14957",
    "title": "unarXive 2022: All arXiv Publications Pre-Processed for NLP, Including  Structured Full-Text and Citation Network",
    "abstract": "Large-scale data sets on scholarly publications are the basis for a variety of bibliometric analyses and natural language processing (NLP) applications. Especially data sets derived from publication's full-text have recently gained attention. While several such data sets already exist, we see key shortcomings in terms of their domain and time coverage, citation network completeness, and representation of full-text content. To address these points, we propose a new version of the data set unarXive. We base our data processing pipeline and output format on two existing data sets, and improve on each of them. Our resulting data set comprises 1.9 M publications spanning multiple disciplines and 32 years. It furthermore has a more complete citation network than its predecessors and retains a richer representation of document structure as well as non-textual publication content such as mathematical notation. In addition to the data set, we provide ready-to-use training/test data for citation recommendation and IMRaD classification. All data and source code is publicly available at https://github.com/IllDepence/unarXive. ",
    "url": "https://arxiv.org/abs/2303.14957",
    "authors": [
      "Tarek Saier",
      "Johan Krause",
      "Michael F\u00e4rber"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.14960",
    "title": "Ambiguity-Resistant Semi-Supervised Learning for Dense Object Detection",
    "abstract": "With basic Semi-Supervised Object Detection (SSOD) techniques, one-stage detectors generally obtain limited promotions compared with two-stage clusters. We experimentally find that the root lies in two kinds of ambiguities: (1) Selection ambiguity that selected pseudo labels are less accurate, since classification scores cannot properly represent the localization quality. (2) Assignment ambiguity that samples are matched with improper labels in pseudo-label assignment, as the strategy is misguided by missed objects and inaccurate pseudo boxes. To tackle these problems, we propose a Ambiguity-Resistant Semi-supervised Learning (ARSL) for one-stage detectors. Specifically, to alleviate the selection ambiguity, Joint-Confidence Estimation (JCE) is proposed to jointly quantifies the classification and localization quality of pseudo labels. As for the assignment ambiguity, Task-Separation Assignment (TSA) is introduced to assign labels based on pixel-level predictions rather than unreliable pseudo boxes. It employs a \"divide-and-conquer\" strategy and separately exploits positives for the classification and localization task, which is more robust to the assignment ambiguity. Comprehensive experiments demonstrate that ARSL effectively mitigates the ambiguities and achieves state-of-the-art SSOD performance on MS COCO and PASCAL VOC. Codes can be found at https://github.com/PaddlePaddle/PaddleDetection. ",
    "url": "https://arxiv.org/abs/2303.14960",
    "authors": [
      "Chang Liu",
      "Weiming Zhang",
      "Xiangru Lin",
      "Wei Zhang",
      "Xiao Tan",
      "Junyu Han",
      "Xiaomao Li",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14961",
    "title": "Diffusion Denoised Smoothing for Certified and Adversarial Robust  Out-Of-Distribution Detection",
    "abstract": "As the use of machine learning continues to expand, the importance of ensuring its safety cannot be overstated. A key concern in this regard is the ability to identify whether a given sample is from the training distribution, or is an \"Out-Of-Distribution\" (OOD) sample. In addition, adversaries can manipulate OOD samples in ways that lead a classifier to make a confident prediction. In this study, we present a novel approach for certifying the robustness of OOD detection within a $\\ell_2$-norm around the input, regardless of network architecture and without the need for specific components or additional training. Further, we improve current techniques for detecting adversarial attacks on OOD samples, while providing high levels of certified and adversarial robustness on in-distribution samples. The average of all OOD detection metrics on CIFAR10/100 shows an increase of $\\sim 13 \\% / 5\\%$ relative to previous approaches. ",
    "url": "https://arxiv.org/abs/2303.14961",
    "authors": [
      "Nicola Franco",
      "Daniel Korth",
      "Jeanette Miriam Lorenz",
      "Karsten Roscher",
      "Stephan Guennemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14963",
    "title": "Variation and Instability in Dialect-Based Embedding Spaces",
    "abstract": "This paper measures variation in embedding spaces which have been trained on different regional varieties of English while controlling for instability in the embeddings. While previous work has shown that it is possible to distinguish between similar varieties of a language, this paper experiments with two follow-up questions: First, does the variety represented in the training data systematically influence the resulting embedding space after training? This paper shows that differences in embeddings across varieties are significantly higher than baseline instability. Second, is such dialect-based variation spread equally throughout the lexicon? This paper shows that specific parts of the lexicon are particularly subject to variation. Taken together, these experiments confirm that embedding spaces are significantly influenced by the dialect represented in the training data. This finding implies that there is semantic variation across dialects, in addition to previously-studied lexical and syntactic variation. ",
    "url": "https://arxiv.org/abs/2303.14963",
    "authors": [
      "Jonathan Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.14969",
    "title": "Universal Few-shot Learning of Dense Prediction Tasks with Visual Token  Matching",
    "abstract": "Dense prediction tasks are a fundamental class of problems in computer vision. As supervised methods suffer from high pixel-wise labeling cost, a few-shot learning solution that can learn any dense task from a few labeled images is desired. Yet, current few-shot learning methods target a restricted set of tasks such as semantic segmentation, presumably due to challenges in designing a general and unified model that is able to flexibly and efficiently adapt to arbitrary tasks of unseen semantics. We propose Visual Token Matching (VTM), a universal few-shot learner for arbitrary dense prediction tasks. It employs non-parametric matching on patch-level embedded tokens of images and labels that encapsulates all tasks. Also, VTM flexibly adapts to any task with a tiny amount of task-specific parameters that modulate the matching algorithm. We implement VTM as a powerful hierarchical encoder-decoder architecture involving ViT backbones where token matching is performed at multiple feature hierarchies. We experiment VTM on a challenging variant of Taskonomy dataset and observe that it robustly few-shot learns various unseen dense prediction tasks. Surprisingly, it is competitive with fully supervised baselines using only 10 labeled examples of novel tasks (0.004% of full supervision) and sometimes outperforms using 0.1% of full supervision. Codes are available at https://github.com/GitGyun/visual_token_matching. ",
    "url": "https://arxiv.org/abs/2303.14969",
    "authors": [
      "Donggyun Kim",
      "Jinwoo Kim",
      "Seongwoong Cho",
      "Chong Luo",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14977",
    "title": "A novel Multi to Single Module for small object detection",
    "abstract": "Small object detection presents a significant challenge in computer vision and object detection. The performance of small object detectors is often compromised by a lack of pixels and less significant features. This issue stems from information misalignment caused by variations in feature scale and information loss during feature processing. In response to this challenge, this paper proposes a novel the Multi to Single Module (M2S), which enhances a specific layer through improving feature extraction and refining features. Specifically, M2S includes the proposed Cross-scale Aggregation Module (CAM) and explored Dual Relationship Module (DRM) to improve information extraction capabilities and feature refinement effects. Moreover, this paper enhances the accuracy of small object detection by utilizing M2S to generate an additional detection head. The effectiveness of the proposed method is evaluated on two datasets, VisDrone2021-DET and SeaDronesSeeV2. The experimental results demonstrate its improved performance compared with existing methods. Compared to the baseline model (YOLOv5s), M2S improves the accuracy by about 1.1\\% on the VisDrone2021-DET testing dataset and 15.68\\% on the SeaDronesSeeV2 validation set. ",
    "url": "https://arxiv.org/abs/2303.14977",
    "authors": [
      "Xiaohui Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14979",
    "title": "Lexicon-Enhanced Self-Supervised Training for Multilingual Dense  Retrieval",
    "abstract": "Recent multilingual pre-trained models have shown better performance in various multilingual tasks. However, these models perform poorly on multilingual retrieval tasks due to lacking multilingual training data. In this paper, we propose to mine and generate self-supervised training data based on a large-scale unlabeled corpus. We carefully design a mining method which combines the sparse and dense models to mine the relevance of unlabeled queries and passages. And we introduce a query generator to generate more queries in target languages for unlabeled passages. Through extensive experiments on Mr. TYDI dataset and an industrial dataset from a commercial search engine, we demonstrate that our method performs better than baselines based on various pre-trained multilingual models. Our method even achieves on-par performance with the supervised method on the latter dataset. ",
    "url": "https://arxiv.org/abs/2303.14979",
    "authors": [
      "Houxing Ren",
      "Linjun Shou",
      "Jian Pei",
      "Ning Wu",
      "Ming Gong",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.14996",
    "title": "Hyperlink prediction via local random walks and Jensen-Shannon  divergence",
    "abstract": "Many real-world systems involving higher-order interactions can be modeled by hypergraphs, where vertices represent the systemic units and hyperedges describe the interactions among them. In this paper, we focus on the problem of hyperlink prediction which aims at inferring missing hyperlinks based on observed hyperlinks. We propose three similarity indices for hyperlink prediction based on local random walks and Jensen-Shannon divergence. Numerical experiments show that the proposed indices outperform the state-of-the-art methods on a broad range of datasets. ",
    "url": "https://arxiv.org/abs/2303.14996",
    "authors": [
      "Xin-Jian Xu",
      "Chong Deng",
      "Li-Jie Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ]
  },
  {
    "id": "arXiv:2303.14999",
    "title": "Transformer-based Multi-Instance Learning for Weakly Supervised Object  Detection",
    "abstract": "Weakly Supervised Object Detection (WSOD) enables the training of object detection models using only image-level annotations. State-of-the-art WSOD detectors commonly rely on multi-instance learning (MIL) as the backbone of their detectors and assume that the bounding box proposals of an image are independent of each other. However, since such approaches only utilize the highest score proposal and discard the potentially useful information from other proposals, their independent MIL backbone often limits models to salient parts of an object or causes them to detect only one object per class. To solve the above problems, we propose a novel backbone for WSOD based on our tailored Vision Transformer named Weakly Supervised Transformer Detection Network (WSTDN). Our algorithm is not only the first to demonstrate that self-attention modules that consider inter-instance relationships are effective backbones for WSOD, but also we introduce a novel bounding box mining method (BBM) integrated with a memory transfer refinement (MTR) procedure to utilize the instance dependencies for facilitating instance refinements. Experimental results on PASCAL VOC2007 and VOC2012 benchmarks demonstrate the effectiveness of our proposed WSTDN and modified instance refinement modules. ",
    "url": "https://arxiv.org/abs/2303.14999",
    "authors": [
      "Zhaofei Wang",
      "Weijia Zhang",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15005",
    "title": "Architecturing Binarized Neural Networks for Traffic Sign Recognition",
    "abstract": "Traffic signs support road safety and managing the flow of traffic, hence are an integral part of any vision system for autonomous driving. While the use of deep learning is well-known in traffic signs classification due to the high accuracy results obtained using convolutional neural networks (CNNs) (state of the art is 99.46\\%), little is known about binarized neural networks (BNNs). Compared to CNNs, BNNs reduce the model size and simplify convolution operations and have shown promising results in computationally limited and energy-constrained devices which appear in the context of autonomous driving. This work presents a bottom-up approach for architecturing BNNs by studying characteristics of the constituent layers. These constituent layers (binarized convolutional layers, max pooling, batch normalization, fully connected layers) are studied in various combinations and with different values of kernel size, number of filters and of neurons by using the German Traffic Sign Recognition Benchmark (GTSRB) for training. As a result, we propose BNNs architectures which achieve more than $90\\%$ for GTSRB (the maximum is $96.45\\%$) and an average greater than $80\\%$ (the maximum is $88.99\\%$) considering also the Belgian and Chinese datasets for testing. The number of parameters of these architectures varies from 100k to less than 2M. The accompanying material of this paper is publicly available at https://github.com/apostovan21/BinarizedNeuralNetwork. ",
    "url": "https://arxiv.org/abs/2303.15005",
    "authors": [
      "Andreea Postovan",
      "M\u0103d\u0103lina Era\u015fcu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15015",
    "title": "Towards Open Temporal Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) for temporal graphs have recently attracted increasing attentions, where a common assumption is that the class set for nodes is closed. However, in real-world scenarios, it often faces the open set problem with the dynamically increased class set as the time passes by. This will bring two big challenges to the existing dynamic GNN methods: (i) How to dynamically propagate appropriate information in an open temporal graph, where new class nodes are often linked to old class nodes. This case will lead to a sharp contradiction. This is because typical GNNs are prone to make the embeddings of connected nodes become similar, while we expect the embeddings of these two interactive nodes to be distinguishable since they belong to different classes. (ii) How to avoid catastrophic knowledge forgetting over old classes when learning new classes occurred in temporal graphs. In this paper, we propose a general and principled learning approach for open temporal graphs, called OTGNet, with the goal of addressing the above two challenges. We assume the knowledge of a node can be disentangled into class-relevant and class-agnostic one, and thus explore a new message passing mechanism by extending the information bottleneck principle to only propagate class-agnostic knowledge between nodes of different classes, avoiding aggregating conflictive information. Moreover, we devise a strategy to select both important and diverse triad sub-graph structures for effective class-incremental learning. Extensive experiments on three real-world datasets of different domains demonstrate the superiority of our method, compared to the baselines. ",
    "url": "https://arxiv.org/abs/2303.15015",
    "authors": [
      "Kaituo Feng",
      "Changsheng Li",
      "Xiaolu Zhang",
      "Jun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15016",
    "title": "Borrowing Human Senses: Comment-Aware Self-Training for Social Media  Multimodal Classification",
    "abstract": "Social media is daily creating massive multimedia content with paired image and text, presenting the pressing need to automate the vision and language understanding for various multimodal classification tasks. Compared to the commonly researched visual-lingual data, social media posts tend to exhibit more implicit image-text relations. To better glue the cross-modal semantics therein, we capture hinting features from user comments, which are retrieved via jointly leveraging visual and lingual similarity. Afterwards, the classification tasks are explored via self-training in a teacher-student framework, motivated by the usually limited labeled data scales in existing benchmarks. Substantial experiments are conducted on four multimodal social media benchmarks for image text relation classification, sarcasm detection, sentiment classification, and hate speech detection. The results show that our method further advances the performance of previous state-of-the-art models, which do not employ comment modeling or self-training. ",
    "url": "https://arxiv.org/abs/2303.15016",
    "authors": [
      "Chunpu Xu",
      "Jing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.15024",
    "title": "An End-to-End Framework For Universal Lesion Detection With Missing  Annotations",
    "abstract": "Fully annotated large-scale medical image datasets are highly valuable. However, because labeling medical images is tedious and requires specialized knowledge, the large-scale datasets available often have missing annotation issues. For instance, DeepLesion, a large-scale CT image dataset with labels for various kinds of lesions, is reported to have a missing annotation rate of 50\\%. Directly training a lesion detector on it would suffer from false negative supervision caused by unannotated lesions. To address this issue, previous works have used sophisticated multi-stage strategies to switch between lesion mining and detector training. In this work, we present a novel end-to-end framework for mining unlabeled lesions while simultaneously training the detector. Our framework follows the teacher-student paradigm. In each iteration, the teacher model infers the input data and creates a set of predictions. High-confidence predictions are combined with partially-labeled ground truth for training the student model. On the DeepLesion dataset, using the original partially labeled training set, our model can outperform all other more complicated methods and surpass the previous best method by 2.3\\% on average sensitivity and 2.7\\% on average precision, achieving state-of-the-art universal lesion detection results. ",
    "url": "https://arxiv.org/abs/2303.15024",
    "authors": [
      "Xiaoyu Bai",
      "Yong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15027",
    "title": "A Survey on Causal Discovery Methods for Temporal and Non-Temporal Data",
    "abstract": "Causal Discovery (CD) is the process of identifying the cause-effect relationships among the variables from data. Over the years, several methods have been developed primarily based on the statistical properties of data to uncover the underlying causal mechanism. In this study we introduce the common terminologies in causal discovery, and provide a comprehensive discussion of the approaches designed to identify the causal edges in different settings. We further discuss some of the benchmark datasets available for evaluating the performance of the causal discovery algorithms, available tools to perform causal discovery readily, and the common metrics used to evaluate these methods. Finally, we conclude by presenting the common challenges involved in CD and also, discuss the applications of CD in multiple areas of interest. ",
    "url": "https://arxiv.org/abs/2303.15027",
    "authors": [
      "Uzma Hasan",
      "Emam Hossain",
      "Md Osman Gani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.15035",
    "title": "Can Few Lines of Code Change Society ? Beyond fack-checking and  moderation : how recommender systems toxifies social networking sites",
    "abstract": "As the last few years have seen an increase in online hostility and polarization both, we need to move beyond the fack-checking reflex or the praise for better moderation on social networking sites (SNS) and investigate their impact on social structures and social cohesion. In particular, the role of recommender systems deployed at large scale by digital platforms such as Facebook or Twitter has been overlooked. This paper draws on the literature on cognitive science, digital media, and opinion dynamics to propose a faithful replica of the entanglement between recommender systems, opinion dynamics and users' cognitive biais on SNSs like Twitter that is calibrated over a large scale longitudinal database of tweets from political activists. This model makes it possible to compare the consequences of various recommendation algorithms on the social fabric and to quantify their interaction with some major cognitive bias. In particular, we demonstrate that the recommender systems that seek to solely maximize users' engagement necessarily lead to an overexposure of users to negative content (up to 300\\% for some of them), a phenomenon called algorithmic negativity bias, to a polarization of the opinion landscape, and to a concentration of social power in the hands of the most toxic users. The latter are more than twice as numerous in the top 1\\% of the most influential users than in the overall population. Overall, our findings highlight the urgency to identify harmful implementations of recommender systems to individuals and society in order better regulate their deployment on systemic SNSs. ",
    "url": "https://arxiv.org/abs/2303.15035",
    "authors": [
      "David Chavalarias",
      "Paul Bouchaud",
      "Maziyar Panahi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.15057",
    "title": "Meta-Calibration Regularized Neural Networks",
    "abstract": "Miscalibration-the mismatch between predicted probability and the true correctness likelihood-has been frequently identified in modern deep neural networks. Recent work in the field aims to address this problem by training calibrated models directly by optimizing a proxy of the calibration error alongside the conventional objective. Recently, Meta-Calibration (MC) showed the effectiveness of using meta-learning for learning better calibrated models. In this work, we extend MC with two main components: (1) gamma network (gamma-net), a meta network to learn a sample-wise gamma at a continuous space for focal loss for optimizing backbone network; (2) smooth expected calibration error (SECE), a Gaussian-kernel based unbiased and differentiable ECE which aims to smoothly optimizing gamma-net. The proposed method regularizes neural network towards better calibration meanwhile retain predictive performance. Our experiments show that (a) learning sample-wise gamma at continuous space can effectively perform calibration; (b) SECE smoothly optimise gamma-net towards better robustness to binning schemes; (c) the combination of gamma-net and SECE achieve the best calibration performance across various calibration metrics and retain very competitive predictive performance as compared to multiple recently proposed methods on three datasets. ",
    "url": "https://arxiv.org/abs/2303.15057",
    "authors": [
      "Cheng Wang",
      "Jacek Golebiowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15062",
    "title": "The Devil is in the Points: Weakly Semi-Supervised Instance Segmentation  via Point-Guided Mask Representation",
    "abstract": "In this paper, we introduce a novel learning scheme named weakly semi-supervised instance segmentation (WSSIS) with point labels for budget-efficient and high-performance instance segmentation. Namely, we consider a dataset setting consisting of a few fully-labeled images and a lot of point-labeled images. Motivated by the main challenge of semi-supervised approaches mainly derives from the trade-off between false-negative and false-positive instance proposals, we propose a method for WSSIS that can effectively leverage the budget-friendly point labels as a powerful weak supervision source to resolve the challenge. Furthermore, to deal with the hard case where the amount of fully-labeled data is extremely limited, we propose a MaskRefineNet that refines noise in rough masks. We conduct extensive experiments on COCO and BDD100K datasets, and the proposed method achieves promising results comparable to those of the fully-supervised model, even with 50% of the fully labeled COCO data (38.8% vs. 39.7%). Moreover, when using as little as 5% of fully labeled COCO data, our method shows significantly superior performance over the state-of-the-art semi-supervised learning method (33.7% vs. 24.9%). The code is available at https://github.com/clovaai/PointWSSIS. ",
    "url": "https://arxiv.org/abs/2303.15062",
    "authors": [
      "Beomyoung Kim",
      "Joonhyun Jeong",
      "Dongyoon Han",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15083",
    "title": "UniDistill: A Universal Cross-Modality Knowledge Distillation Framework  for 3D Object Detection in Bird's-Eye View",
    "abstract": "In the field of 3D object detection for autonomous driving, the sensor portfolio including multi-modality and single-modality is diverse and complex. Since the multi-modal methods have system complexity while the accuracy of single-modal ones is relatively low, how to make a tradeoff between them is difficult. In this work, we propose a universal cross-modality knowledge distillation framework (UniDistill) to improve the performance of single-modality detectors. Specifically, during training, UniDistill projects the features of both the teacher and the student detector into Bird's-Eye-View (BEV), which is a friendly representation for different modalities. Then, three distillation losses are calculated to sparsely align the foreground features, helping the student learn from the teacher without introducing additional cost during inference. Taking advantage of the similar detection paradigm of different detectors in BEV, UniDistill easily supports LiDAR-to-camera, camera-to-LiDAR, fusion-to-LiDAR and fusion-to-camera distillation paths. Furthermore, the three distillation losses can filter the effect of misaligned background information and balance between objects of different sizes, improving the distillation effectiveness. Extensive experiments on nuScenes demonstrate that UniDistill effectively improves the mAP and NDS of student detectors by 2.0%~3.2%. ",
    "url": "https://arxiv.org/abs/2303.15083",
    "authors": [
      "Shengchao Zhou",
      "Weizhou Liu",
      "Chen Hu",
      "Shuchang Zhou",
      "Chao Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15087",
    "title": "Prediction of Time and Distance of Trips Using Explainable  Attention-based LSTMs",
    "abstract": "In this paper, we propose machine learning solutions to predict the time of future trips and the possible distance the vehicle will travel. For this prediction task, we develop and investigate four methods. In the first method, we use long short-term memory (LSTM)-based structures specifically designed to handle multi-dimensional historical data of trip time and distances simultaneously. Using it, we predict the future trip time and forecast the distance a vehicle will travel by concatenating the outputs of LSTM networks through fully connected layers. The second method uses attention-based LSTM networks (At-LSTM) to perform the same tasks. The third method utilizes two LSTM networks in parallel, one for forecasting the time of the trip and the other for predicting the distance. The output of each LSTM is then concatenated through fully connected layers. Finally, the last model is based on two parallel At-LSTMs, where similarly, each At-LSTM predicts time and distance separately through fully connected layers. Among the proposed methods, the most advanced one, i.e., parallel At-LSTM, predicts the next trip's distance and time with 3.99% error margin where it is 23.89% better than LSTM, the first method. We also propose TimeSHAP as an explainability method for understanding how the networks perform learning and model the sequence of information. ",
    "url": "https://arxiv.org/abs/2303.15087",
    "authors": [
      "Ebrahim Balouji",
      "Jonas Sj\u00f6blom",
      "Nikolce Murgovski",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.15092",
    "title": "Defect detection using weakly supervised learning",
    "abstract": "In many real-world scenarios, obtaining large amounts of labeled data can be a daunting task. Weakly supervised learning techniques have gained significant attention in recent years as an alternative to traditional supervised learning, as they enable training models using only a limited amount of labeled data. In this paper, the performance of a weakly supervised classifier to its fully supervised counterpart is compared on the task of defect detection. Experiments are conducted on a dataset of images containing defects, and evaluate the two classifiers based on their accuracy, precision, and recall. Our results show that the weakly supervised classifier achieves comparable performance to the supervised classifier, while requiring significantly less labeled data. ",
    "url": "https://arxiv.org/abs/2303.15092",
    "authors": [
      "Vasileios Sevetlidis",
      "George Pavlidis",
      "Vasiliki Balaska",
      "Athanasios Psomoulis",
      "Spyridon Mouroutsos",
      "Antonios Gasteratos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15101",
    "title": "DANI-Net: Uncalibrated Photometric Stereo by Differentiable Shadow  Handling, Anisotropic Reflectance Modeling, and Neural Inverse Rendering",
    "abstract": "Uncalibrated photometric stereo (UPS) is challenging due to the inherent ambiguity brought by the unknown light. Although the ambiguity is alleviated on non-Lambertian objects, the problem is still difficult to solve for more general objects with complex shapes introducing irregular shadows and general materials with complex reflectance like anisotropic reflectance. To exploit cues from shadow and reflectance to solve UPS and improve performance on general materials, we propose DANI-Net, an inverse rendering framework with differentiable shadow handling and anisotropic reflectance modeling. Unlike most previous methods that use non-differentiable shadow maps and assume isotropic material, our network benefits from cues of shadow and anisotropic reflectance through two differentiable paths. Experiments on multiple real-world datasets demonstrate our superior and robust performance. ",
    "url": "https://arxiv.org/abs/2303.15101",
    "authors": [
      "Zongrui Li",
      "Qian Zheng",
      "Boxin Shi",
      "Gang Pan",
      "Xudong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15103",
    "title": "Contrastive Learning Is Spectral Clustering On Similarity Graph",
    "abstract": "Contrastive learning is a powerful self-supervised learning method, but we have a limited theoretical understanding of how it works and why it works. In this paper, we prove that contrastive learning with the standard InfoNCE loss is equivalent to spectral clustering on the similarity graph. Using this equivalence as the building block, we extend our analysis to the CLIP model and rigorously characterize how similar multi-modal objects are embedded together. Motivated by our theoretical insights, we introduce the kernel mixture loss, incorporating novel kernel functions that outperform the standard Gaussian kernel on several vision datasets. ",
    "url": "https://arxiv.org/abs/2303.15103",
    "authors": [
      "Zhiquan Tan",
      "Yifan Zhang",
      "Jingqin Yang",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15109",
    "title": "Improving the Transferability of Adversarial Examples via Direction  Tuning",
    "abstract": "In the transfer-based adversarial attacks, adversarial examples are only generated by the surrogate models and achieve effective perturbation in the victim models. Although considerable efforts have been developed on improving the transferability of adversarial examples generated by transfer-based adversarial attacks, our investigation found that, the big deviation between the actual and steepest update directions of the current transfer-based adversarial attacks is caused by the large update step length, resulting in the generated adversarial examples can not converge well. However, directly reducing the update step length will lead to serious update oscillation so that the generated adversarial examples also can not achieve great transferability to the victim models. To address these issues, a novel transfer-based attack, namely direction tuning attack, is proposed to not only decrease the update deviation in the large step length, but also mitigate the update oscillation in the small sampling step length, thereby making the generated adversarial examples converge well to achieve great transferability on victim models. In addition, a network pruning method is proposed to smooth the decision boundary, thereby further decreasing the update oscillation and enhancing the transferability of the generated adversarial examples. The experiment results on ImageNet demonstrate that the average attack success rate (ASR) of the adversarial examples generated by our method can be improved from 87.9\\% to 94.5\\% on five victim models without defenses, and from 69.1\\% to 76.2\\% on eight advanced defense methods, in comparison with that of latest gradient-based attacks. ",
    "url": "https://arxiv.org/abs/2303.15109",
    "authors": [
      "Xiangyuan Yang",
      "Jie Lin",
      "Hanlin Zhang",
      "Xinyu Yang",
      "Peng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15110",
    "title": "Beyond Toxic: Toxicity Detection Datasets are Not Enough for Brand  Safety",
    "abstract": "The rapid growth in user generated content on social media has resulted in a significant rise in demand for automated content moderation. Various methods and frameworks have been proposed for the tasks of hate speech detection and toxic comment classification. In this work, we combine common datasets to extend these tasks to brand safety. Brand safety aims to protect commercial branding by identifying contexts where advertisements should not appear and covers not only toxicity, but also other potentially harmful content. As these datasets contain different label sets, we approach the overall problem as a binary classification task. We demonstrate the need for building brand safety specific datasets via the application of common toxicity detection datasets to a subset of brand safety and empirically analyze the effects of weighted sampling strategies in text classification. ",
    "url": "https://arxiv.org/abs/2303.15110",
    "authors": [
      "Elizaveta Korotkova",
      "Isaac Kwan Yin Chung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.15114",
    "title": "Automatic breach detection during spine pedicle drilling based on  vibroacoustic sensing",
    "abstract": "Pedicle drilling is a complex and critical spinal surgery task. Detecting breach or penetration of the surgical tool to the cortical wall during pilot-hole drilling is essential to avoid damage to vital anatomical structures adjacent to the pedicle, such as the spinal cord, blood vessels, and nerves. Currently, the guidance of pedicle drilling is done using image-guided methods that are radiation intensive and limited to the preoperative information. This work proposes a new radiation-free breach detection algorithm leveraging a non-visual sensor setup in combination with deep learning approach. Multiple vibroacoustic sensors, such as a contact microphone, a free-field microphone, a tri-axial accelerometer, a uni-axial accelerometer, and an optical tracking system were integrated into the setup. Data were collected on four cadaveric human spines, ranging from L5 to T10. An experienced spine surgeon drilled the pedicles relying on optical navigation. A new automatic labeling method based on the tracking data was introduced. Labeled data was subsequently fed to the network in mel-spectrograms, classifying the data into breach and non-breach. Different sensor types, sensor positioning, and their combinations were evaluated. The best results in breach recall for individual sensors could be achieved using contact microphones attached to the dorsal skin (85.8\\%) and uni-axial accelerometers clamped to the spinous process of the drilled vertebra (81.0\\%). The best-performing data fusion model combined the latter two sensors with a breach recall of 98\\%. The proposed method shows the great potential of non-visual sensor fusion for avoiding screw misplacement and accidental bone breaches during pedicle drilling and could be extended to further surgical applications. ",
    "url": "https://arxiv.org/abs/2303.15114",
    "authors": [
      "Aidana Massalimova",
      "Maikel Timmermans",
      "Nicola Cavalcanti",
      "Daniel Suter",
      "Matthias Seibold",
      "Fabio Carrillo",
      "Christoph J. Laux",
      "Reto Sutter",
      "Mazda Farshad",
      "Kathleen Denis",
      "Philipp F\u00fcrnstahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15115",
    "title": "Ensemble Latent Space Roadmap for Improved Robustness in Visual Action  Planning",
    "abstract": "Planning in learned latent spaces helps to decrease the dimensionality of raw observations. In this work, we propose to leverage the ensemble paradigm to enhance the robustness of latent planning systems. We rely on our Latent Space Roadmap (LSR) framework, which builds a graph in a learned structured latent space to perform planning. Given multiple LSR framework instances, that differ either on their latent spaces or on the parameters for constructing the graph, we use the action information as well as the embedded nodes of the produced plans to define similarity measures. These are then utilized to select the most promising plans. We validate the performance of our Ensemble LSR (ENS-LSR) on simulated box stacking and grape harvesting tasks as well as on a real-world robotic T-shirt folding experiment. ",
    "url": "https://arxiv.org/abs/2303.15115",
    "authors": [
      "Martina Lippi",
      "Michael C. Welle",
      "Andrea Gasparri",
      "Danica Kragic"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.15122",
    "title": "Parameter Efficient Local Implicit Image Function Network for Face  Segmentation",
    "abstract": "Face parsing is defined as the per-pixel labeling of images containing human faces. The labels are defined to identify key facial regions like eyes, lips, nose, hair, etc. In this work, we make use of the structural consistency of the human face to propose a lightweight face-parsing method using a Local Implicit Function network, FP-LIIF. We propose a simple architecture having a convolutional encoder and a pixel MLP decoder that uses 1/26th number of parameters compared to the state-of-the-art models and yet matches or outperforms state-of-the-art models on multiple datasets, like CelebAMask-HQ and LaPa. We do not use any pretraining, and compared to other works, our network can also generate segmentation at different resolutions without any changes in the input resolution. This work enables the use of facial segmentation on low-compute or low-bandwidth devices because of its higher FPS and smaller model size. ",
    "url": "https://arxiv.org/abs/2303.15122",
    "authors": [
      "Mausoom Sarkar",
      "Nikitha SR",
      "Mayur Hemani",
      "Rishabh Jain",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15126",
    "title": "NeuralPCI: Spatio-temporal Neural Field for 3D Point Cloud Multi-frame  Non-linear Interpolation",
    "abstract": "In recent years, there has been a significant increase in focus on the interpolation task of computer vision. Despite the tremendous advancement of video interpolation, point cloud interpolation remains insufficiently explored. Meanwhile, the existence of numerous nonlinear large motions in real-world scenarios makes the point cloud interpolation task more challenging. In light of these issues, we present NeuralPCI: an end-to-end 4D spatio-temporal Neural field for 3D Point Cloud Interpolation, which implicitly integrates multi-frame information to handle nonlinear large motions for both indoor and outdoor scenarios. Furthermore, we construct a new multi-frame point cloud interpolation dataset called NL-Drive for large nonlinear motions in autonomous driving scenes to better demonstrate the superiority of our method. Ultimately, NeuralPCI achieves state-of-the-art performance on both DHB (Dynamic Human Bodies) and NL-Drive datasets. Beyond the interpolation task, our method can be naturally extended to point cloud extrapolation, morphing, and auto-labeling, which indicates its substantial potential in other domains. Codes are available at https://github.com/ispc-lab/NeuralPCI. ",
    "url": "https://arxiv.org/abs/2303.15126",
    "authors": [
      "Zehan Zheng",
      "Danni Wu",
      "Ruisi Lu",
      "Fan Lu",
      "Guang Chen",
      "Changjun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15127",
    "title": "Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable  Example Attacks",
    "abstract": "Unlearnable example attacks are data poisoning techniques that can be used to safeguard public data against unauthorized use for training deep learning models. These methods add stealthy perturbations to the original image, thereby making it difficult for deep learning models to learn from these training data effectively. Current research suggests that adversarial training can, to a certain degree, mitigate the impact of unlearnable example attacks, while common data augmentation methods are not effective against such poisons. Adversarial training, however, demands considerable computational resources and can result in non-trivial accuracy loss. In this paper, we introduce the UEraser method, which outperforms current defenses against different types of state-of-the-art unlearnable example attacks through a combination of effective data augmentation policies and loss-maximizing adversarial augmentations. In stark contrast to the current SOTA adversarial training methods, UEraser uses adversarial augmentations, which extends beyond the confines of $ \\ell_p $ perturbation budget assumed by current unlearning attacks and defenses. It also helps to improve the model's generalization ability, thus protecting against accuracy loss. UEraser wipes out the unlearning effect with error-maximizing data augmentations, thus restoring trained model accuracies. Interestingly, UEraser-Lite, a fast variant without adversarial augmentations, is also highly effective in preserving clean accuracies. On challenging unlearnable CIFAR-10, CIFAR-100, SVHN, and ImageNet-subset datasets produced with various attacks, it achieves results that are comparable to those obtained during clean training. We also demonstrate its efficacy against possible adaptive attacks. Our code is open source and available to the deep learning community: https://github.com/lafeat/ueraser. ",
    "url": "https://arxiv.org/abs/2303.15127",
    "authors": [
      "Tianrui Qin",
      "Xitong Gao",
      "Juanjuan Zhao",
      "Kejiang Ye",
      "Cheng-Zhong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15131",
    "title": "LQG Control Over SWIPT-enabled Wireless Communication Network",
    "abstract": "In this paper, we consider using simultaneous wireless information and power transfer (SWIPT) to recharge the sensor in the LQG control, which provides a new approach to prolonging the network lifetime. We analyze the stability of the proposed system model and show that there exist two critical values for the power splitting ratio {\\alpha}. Then, we propose an optimization problem to derive the optimal value of {\\alpha}. This problem is non-convex but its numerical solution can be derived by our proposed algorithm efficiently. Moreover, we provide the feasible condition of the proposed optimization problem. Finally, simulation results are presented to verify and illustrate the main theoretical results. ",
    "url": "https://arxiv.org/abs/2303.15131",
    "authors": [
      "Huiwen Yang",
      "Lingying Huang",
      "Yuzhe Li",
      "Subhrakanti Dey",
      "Ling Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.15140",
    "title": "SimpleNet: A Simple Network for Image Anomaly Detection and Localization",
    "abstract": "We propose a simple and application-friendly network (called SimpleNet) for detecting and localizing anomalies. SimpleNet consists of four components: (1) a pre-trained Feature Extractor that generates local features, (2) a shallow Feature Adapter that transfo local features towards target domain, (3) a simple Anomaly Feature Generator that counterfeits anomaly features by adding Gaussian noise to normal features, and (4) a binary Anomaly Discriminator that distinguishes anomaly features from normal features. During inference, the Anomaly Feature Generator would be discarded. Our approach is based on three intuitions. First, transforming pre-trained features to target-oriented features helps avoid domain bias. Second, generating synthetic anomalies in feature space is more effective, as defects may not have much commonality in the image space. Third, a simple discriminator is much efficient and practical. In spite of simplicity, SimpleNet outperforms previous methods quantitatively and qualitatively. On the MVTec AD benchmark, SimpleNet achieves an anomaly detection AUROC of 99.6%, reducing the error by 55.5% compared to the next best performing model. Furthermore, SimpleNet is faster than existing methods, with a high frame rate of 77 FPS on a 3080ti GPU. Additionally, SimpleNet demonstrates significant improvements in performance on the One-Class Novelty Detection task. Code: https://github.com/DonaldRR/SimpleNet. ",
    "url": "https://arxiv.org/abs/2303.15140",
    "authors": [
      "Zhikang Liu",
      "Yiming Zhou",
      "Yuansheng Xu",
      "Zilei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15161",
    "title": "Data Augmentation for Environmental Sound Classification Using Diffusion  Probabilistic Model with Top-k Selection Discriminator",
    "abstract": "Despite consistent advancement in powerful deep learning techniques in recent years, large amounts of training data are still necessary for the models to avoid overfitting. Synthetic datasets using generative adversarial networks (GAN) have recently been generated to overcome this problem. Nevertheless, despite advancements, GAN-based methods are usually hard to train or fail to generate high-quality data samples. In this paper, we propose an environmental sound classification augmentation technique based on the diffusion probabilistic model with DPM-Solver$++$ for fast sampling. In addition, to ensure the quality of the generated spectrograms, we train a top-k selection discriminator on the dataset. According to the experiment results, the synthesized spectrograms have similar features to the original dataset and can significantly increase the classification accuracy of different state-of-the-art models compared with traditional data augmentation techniques. The public code is available on \\url{https://github.com/JNAIC/DPMs-for-Audio-Data-Augmentation}. ",
    "url": "https://arxiv.org/abs/2303.15161",
    "authors": [
      "Yunhao Chen",
      "Yunjie Zhu",
      "Zihui Yan",
      "Jianlu Shen",
      "Zhen Ren",
      "Yifan Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.15168",
    "title": "Personalized Federated Learning on Long-Tailed Data via Adversarial  Feature Augmentation",
    "abstract": "Personalized Federated Learning (PFL) aims to learn personalized models for each client based on the knowledge across all clients in a privacy-preserving manner. Existing PFL methods generally assume that the underlying global data across all clients are uniformly distributed without considering the long-tail distribution. The joint problem of data heterogeneity and long-tail distribution in the FL environment is more challenging and severely affects the performance of personalized models. In this paper, we propose a PFL method called Federated Learning with Adversarial Feature Augmentation (FedAFA) to address this joint problem in PFL. FedAFA optimizes the personalized model for each client by producing a balanced feature set to enhance the local minority classes. The local minority class features are generated by transferring the knowledge from the local majority class features extracted by the global model in an adversarial example learning manner. The experimental results on benchmarks under different settings of data heterogeneity and long-tail distribution demonstrate that FedAFA significantly improves the personalized performance of each client compared with the state-of-the-art PFL algorithm. The code is available at https://github.com/pxqian/FedAFA. ",
    "url": "https://arxiv.org/abs/2303.15168",
    "authors": [
      "Yang Lu",
      "Pinxin Qian",
      "Gang Huang",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15178",
    "title": "Robust Path Following on Rivers Using Bootstrapped Reinforcement  Learning",
    "abstract": "This paper develops a Deep Reinforcement Learning (DRL)-agent for navigation and control of autonomous surface vessels (ASV) on inland waterways. Spatial restrictions due to waterway geometry and the resulting challenges, such as high flow velocities or shallow banks, require controlled and precise movement of the ASV. A state-of-the-art bootstrapped Q-learning algorithm in combination with a versatile training environment generator leads to a robust and accurate rudder controller. To validate our results, we compare the path-following capabilities of the proposed approach to a vessel-specific PID controller on real-world river data from the lower- and middle Rhine, indicating that the DRL algorithm could effectively prove generalizability even in never-seen scenarios while simultaneously attaining high navigational accuracy. ",
    "url": "https://arxiv.org/abs/2303.15178",
    "authors": [
      "Niklas Paulig",
      "Ostap Ohkrin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.15182",
    "title": "Hybrid Augmented Automated Graph Contrastive Learning",
    "abstract": "Graph augmentations are essential for graph contrastive learning. Most existing works use pre-defined random augmentations, which are usually unable to adapt to different input graphs and fail to consider the impact of different nodes and edges on graph semantics. To address this issue, we propose a framework called Hybrid Augmented Automated Graph Contrastive Learning (HAGCL). HAGCL consists of a feature-level learnable view generator and an edge-level learnable view generator. The view generators are end-to-end differentiable to learn the probability distribution of views conditioned on the input graph. It insures to learn the most semantically meaningful structure in terms of features and topology, respectively. Furthermore, we propose an improved joint training strategy, which can achieve better results than previous works without resorting to any weak label information in the downstream tasks and extensive evaluation of additional work. ",
    "url": "https://arxiv.org/abs/2303.15182",
    "authors": [
      "Yifu Chen",
      "Qianqian Ren",
      "Liu Yong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15196",
    "title": "Probing optimisation in physics-informed neural networks",
    "abstract": "A novel comparison is presented of the effect of optimiser choice on the accuracy of physics-informed neural networks (PINNs). To give insight into why some optimisers are better, a new approach is proposed that tracks the training trajectory curvature and can be evaluated on the fly at a low computational cost. The linear advection equation is studied for several advective velocities, and we show that the optimiser choice substantially impacts PINNs model performance and accuracy. Furthermore, using the curvature measure, we found a negative correlation between the convergence error and the curvature in the optimiser local reference frame. It is concluded that, in this case, larger local curvature values result in better solutions. Consequently, optimisation of PINNs is made more difficult as minima are in highly curved regions. ",
    "url": "https://arxiv.org/abs/2303.15196",
    "authors": [
      "Nayara Fonseca",
      "Veronica Guidetti",
      "Will Trojak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2303.15206",
    "title": "Perceptual Quality Assessment of NeRF and Neural View Synthesis Methods  for Front-Facing Views",
    "abstract": "Neural view synthesis (NVS) is one of the most successful techniques for synthesizing free viewpoint videos, capable of achieving high fidelity from only a sparse set of captured images. This success has led to many variants of the techniques, each evaluated on a set of test views typically using image quality metrics such as PSNR, SSIM, or LPIPS. There has been a lack of research on how NVS methods perform with respect to perceived video quality. We present the first study on perceptual evaluation of NVS and NeRF variants. For this study, we collected two datasets of scenes captured in a controlled lab environment as well as in-the-wild. In contrast to existing datasets, these scenes come with reference video sequences, allowing us to test for temporal artifacts and subtle distortions that are easily overlooked when viewing only static images. We measured the quality of videos synthesized by several NVS methods in a well-controlled perceptual quality assessment experiment as well as with many existing state-of-the-art image/video quality metrics. We present a detailed analysis of the results and recommendations for dataset and metric selection for NVS evaluation. ",
    "url": "https://arxiv.org/abs/2303.15206",
    "authors": [
      "Hanxue Liang",
      "Tianhao Wu",
      "Param Hanji",
      "Francesco Banterle",
      "Hongyun Gao",
      "Rafal Mantiuk",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.15218",
    "title": "Evaluating XGBoost for Balanced and Imbalanced Data: Application to  Fraud Detection",
    "abstract": "This paper evaluates XGboost's performance given different dataset sizes and class distributions, from perfectly balanced to highly imbalanced. XGBoost has been selected for evaluation, as it stands out in several benchmarks due to its detection performance and speed. After introducing the problem of fraud detection, the paper reviews evaluation metrics for detection systems or binary classifiers, and illustrates with examples how different metrics work for balanced and imbalanced datasets. Then, it examines the principles of XGBoost. It proposes a pipeline for data preparation and compares a Vanilla XGBoost against a random search-tuned XGBoost. Random search fine-tuning provides consistent improvement for large datasets of 100 thousand samples, not so for medium and small datasets of 10 and 1 thousand samples, respectively. Besides, as expected, XGBoost recognition performance improves as more data is available, and deteriorates detection performance as the datasets become more imbalanced. Tests on distributions with 50, 45, 25, and 5 percent positive samples show that the largest drop in detection performance occurs for the distribution with only 5 percent positive samples. Sampling to balance the training set does not provide consistent improvement. Therefore, future work will include a systematic study of different techniques to deal with data imbalance and evaluating other approaches, including graphs, autoencoders, and generative adversarial methods, to deal with the lack of labels. ",
    "url": "https://arxiv.org/abs/2303.15218",
    "authors": [
      "Gissel Velarde",
      "Anindya Sudhir",
      "Sanjay Deshmane",
      "Anuj Deshmunkh",
      "Khushboo Sharma",
      "Vaibhav Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.15221",
    "title": "Digital Twin of a Network and Operating Environment Using Augmented  Reality",
    "abstract": "We demonstrate the digital twin of a network, network elements, and operating environment using machine learning. We achieve network card failure localization and remote collaboration over 86 km of fiber using augmented reality. ",
    "url": "https://arxiv.org/abs/2303.15221",
    "authors": [
      "Haoshuo Chen",
      "Xiaonan Xu",
      "Jesse E. Simsarian",
      "Mijail Szczerban",
      "Rob Harby",
      "Roland Ryf",
      "Mikael Mazur",
      "Lauren Dallachiesa",
      "Nicolas K. Fontaine",
      "John Cloonan",
      "Jim Sandoz",
      "David T. Neilson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.15223",
    "title": "How far generated data can impact Neural Networks performance?",
    "abstract": "The success of deep learning models depends on the size and quality of the dataset to solve certain tasks. Here, we explore how far generated data can aid real data in improving the performance of Neural Networks. In this work, we consider facial expression recognition since it requires challenging local data generation at the level of local regions such as mouth, eyebrows, etc, rather than simple augmentation. Generative Adversarial Networks (GANs) provide an alternative method for generating such local deformations but they need further validation. To answer our question, we consider noncomplex Convolutional Neural Networks (CNNs) based classifiers for recognizing Ekman emotions. For the data generation process, we consider generating facial expressions (FEs) by relying on two GANs. The first generates a random identity while the second imposes facial deformations on top of it. We consider training the CNN classifier using FEs from: real-faces, GANs-generated, and finally using a combination of real and GAN-generated faces. We determine an upper bound regarding the data generation quantity to be mixed with the real one which contributes the most to enhancing FER accuracy. In our experiments, we find out that 5-times more synthetic data to the real FEs dataset increases accuracy by 16%. ",
    "url": "https://arxiv.org/abs/2303.15223",
    "authors": [
      "Sayeh Gholipour Picha",
      "Dawood AL Chanti",
      "Alice Caplier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15245",
    "title": "Comparison between layer-to-layer network training and conventional  network training using Convolutional Neural Networks",
    "abstract": "Title: Comparison between layer-to-layer network training and conventional network training using Convolutional Neural Networks Abstract: Convolutional neural networks (CNNs) are widely used in various applications due to their effectiveness in extracting features from data. However, the performance of a CNN heavily depends on its architecture and training process. In this study, we propose a layer-to-layer training method and compare its performance with the conventional training method. In the layer-to-layer training approach, we treat a portion of the early layers as a student network and the later layers as a teacher network. During each training step, we incrementally train the student network to learn from the output of the teacher network, and vice versa. We evaluate this approach on a VGG16 network without pre-trained ImageNet weights and a regular CNN model. Our experiments show that the layer-to-layer training method outperforms the conventional training method for both models. Specifically, we achieve higher accuracy on the test set for the VGG16 network and the CNN model using layer-to-layer training compared to the conventional training method. Overall, our study highlights the importance of layer-wise training in CNNs and suggests that layer-to-layer training can be a promising approach for improving the accuracy of CNNs. ",
    "url": "https://arxiv.org/abs/2303.15245",
    "authors": [
      "Kiran Kumar Ashish Bhyravabhottla",
      "WonSook Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15256",
    "title": "Active Self-Supervised Learning: A Few Low-Cost Relationships Are All  You Need",
    "abstract": "Self-Supervised Learning (SSL) has emerged as the solution of choice to learn transferable representations from unlabeled data. However, SSL requires to build samples that are known to be semantically akin, i.e. positive views. Requiring such knowledge is the main limitation of SSL and is often tackled by ad-hoc strategies e.g. applying known data-augmentations to the same input. In this work, we generalize and formalize this principle through Positive Active Learning (PAL) where an oracle queries semantic relationships between samples. PAL achieves three main objectives. First, it unveils a theoretically grounded learning framework beyond SSL, that can be extended to tackle supervised and semi-supervised learning depending on the employed oracle. Second, it provides a consistent algorithm to embed a priori knowledge, e.g. some observed labels, into any SSL losses without any change in the training pipeline. Third, it provides a proper active learning framework yielding low-cost solutions to annotate datasets, arguably bringing the gap between theory and practice of active learning that is based on simple-to-answer-by-non-experts queries of semantic relationships between inputs. ",
    "url": "https://arxiv.org/abs/2303.15256",
    "authors": [
      "Vivien Cabannes",
      "Leon Bottou",
      "Yann Lecun",
      "Randall Balestriero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.15263",
    "title": "Joint Person Identity, Gender and Age Estimation from Hand Images using  Deep Multi-Task Representation Learning",
    "abstract": "In this paper, we propose a multi-task representation learning framework to jointly estimate the identity, gender and age of individuals from their hand images for the purpose of criminal investigations since the hand images are often the only available information in cases of serious crime such as sexual abuse. We investigate different up-to-date deep learning architectures and compare their performance for joint estimation of identity, gender and age from hand images of perpetrators of serious crime. To overcome the data imbalance and simplify the age prediction, we create age groups for the age estimation. We make extensive evaluations and comparisons of both convolution-based and transformer-based deep learning architectures on a publicly available 11k hands dataset. Our experimental analysis shows that it is possible to efficiently estimate not only identity but also other attributes such as gender and age of suspects jointly from hand images for criminal investigations, which is crucial in assisting international police forces in the court to identify and convict abusers. ",
    "url": "https://arxiv.org/abs/2303.15263",
    "authors": [
      "Nathanael L. Baisa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15265",
    "title": "Bilex Rx: Lexical Data Augmentation for Massively Multilingual Machine  Translation",
    "abstract": "Neural machine translation (NMT) has progressed rapidly over the past several years, and modern models are able to achieve relatively high quality using only monolingual text data, an approach dubbed Unsupervised Machine Translation (UNMT). However, these models still struggle in a variety of ways, including aspects of translation that for a human are the easiest - for instance, correctly translating common nouns. This work explores a cheap and abundant resource to combat this problem: bilingual lexica. We test the efficacy of bilingual lexica in a real-world set-up, on 200-language translation models trained on web-crawled text. We present several findings: (1) using lexical data augmentation, we demonstrate sizable performance gains for unsupervised translation; (2) we compare several families of data augmentation, demonstrating that they yield similar improvements, and can be combined for even greater improvements; (3) we demonstrate the importance of carefully curated lexica over larger, noisier ones, especially with larger models; and (4) we compare the efficacy of multilingual lexicon data versus human-translated parallel data. Finally, we open-source GATITOS (available at https://github.com/google-research/url-nlp/tree/main/gatitos), a new multilingual lexicon for 26 low-resource languages, which had the highest performance among lexica in our experiments. ",
    "url": "https://arxiv.org/abs/2303.15265",
    "authors": [
      "Alex Jones",
      "Isaac Caswell",
      "Ishank Saxena",
      "Orhan Firat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15266",
    "title": "Multi-Granularity Archaeological Dating of Chinese Bronze Dings Based on  a Knowledge-Guided Relation Graph",
    "abstract": "The archaeological dating of bronze dings has played a critical role in the study of ancient Chinese history. Current archaeology depends on trained experts to carry out bronze dating, which is time-consuming and labor-intensive. For such dating, in this study, we propose a learning-based approach to integrate advanced deep learning techniques and archaeological knowledge. To achieve this, we first collect a large-scale image dataset of bronze dings, which contains richer attribute information than other existing fine-grained datasets. Second, we introduce a multihead classifier and a knowledge-guided relation graph to mine the relationship between attributes and the ding era. Third, we conduct comparison experiments with various existing methods, the results of which show that our dating method achieves a state-of-the-art performance. We hope that our data and applied networks will enrich fine-grained classification research relevant to other interdisciplinary areas of expertise. The dataset and source code used are included in our supplementary materials, and will be open after submission owing to the anonymity policy. Source codes and data are available at: https://github.com/zhourixin/bronze-Ding. ",
    "url": "https://arxiv.org/abs/2303.15266",
    "authors": [
      "Rixin Zhou",
      "Jiafu Wei",
      "Qian Zhang",
      "Ruihua Qi",
      "Xi Yang",
      "Chuntao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15274",
    "title": "Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed  Human Attention",
    "abstract": "Predicting human gaze is important in Human-Computer Interaction (HCI). However, to practically serve HCI applications, gaze prediction models must be scalable, fast, and accurate in their spatial and temporal gaze predictions. Recent scanpath prediction models focus on goal-directed attention (search). Such models are limited in their application due to a common approach relying on trained target detectors for all possible objects, and the availability of human gaze data for their training (both not scalable). In response, we pose a new task called ZeroGaze, a new variant of zero-shot learning where gaze is predicted for never-before-searched objects, and we develop a novel model, Gazeformer, to solve the ZeroGaze problem. In contrast to existing methods using object detector modules, Gazeformer encodes the target using a natural language model, thus leveraging semantic similarities in scanpath prediction. We use a transformer-based encoder-decoder architecture because transformers are particularly useful for generating contextual representations. Gazeformer surpasses other models by a large margin on the ZeroGaze setting. It also outperforms existing target-detection models on standard gaze prediction for both target-present and target-absent search tasks. In addition to its improved performance, Gazeformer is more than five times faster than the state-of-the-art target-present visual search model. ",
    "url": "https://arxiv.org/abs/2303.15274",
    "authors": [
      "Sounak Mondal",
      "Zhibo Yang",
      "Seoyoung Ahn",
      "Dimitris Samaras",
      "Gregory Zelinsky",
      "Minh Hoai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15275",
    "title": "An Analytical Representation of the 2d Generalized Balanced Power  Diagram",
    "abstract": "Tessellations are an important tool to model the microstructure of cellular and polycrystalline materials. Classical tessellation models include the Voronoi diagram and Laguerre tessellation whose cells are polyhedra. Due to the convexity of their cells, those models may be too restrictive to describe data that includes possibly anisotropic grains with curved boundaries. Several generalizations exist. The cells of the generalized balanced power diagram are induced by elliptic distances leading to more diverse structures. So far, methods for computing the generalized balanced power diagram are restricted to discretized versions in the form of label images. In this work, we derive an analytic representation of the vertices and edges of the generalized balanced power diagram in 2d. Based on that, we propose a novel algorithm to compute the whole diagram. ",
    "url": "https://arxiv.org/abs/2303.15275",
    "authors": [
      "Christian Jung",
      "Claudia Redenbach"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.15299",
    "title": "Resilient Output Consensus Control of Heterogeneous Multi-agent Systems  against Byzantine Attacks: A Twin Layer Approach",
    "abstract": "This paper studies the problem of cooperative control of heterogeneous multi-agent systems (MASs) against Byzantine attacks. The agent affected by Byzantine attacks sends different wrong values to all neighbors while applying wrong input signals for itself, which is aggressive and difficult to be defended. Inspired by the concept of Digital Twin, a new hierarchical protocol equipped with a virtual twin layer (TL) is proposed, which decouples the above problems into the defense scheme against Byzantine edge attacks on the TL and the defense scheme against Byzantine node attacks on the cyber-physical layer (CPL). On the TL, we propose a resilient topology reconfiguration strategy by adding a minimum number of key edges to improve network resilience. It is strictly proved that the control strategy is sufficient to achieve asymptotic consensus in finite time with the topology on the TL satisfying strongly $(2f+1)$-robustness. On the CPL, decentralized chattering-free controllers are proposed to guarantee the resilient output consensus for the heterogeneous MASs against Byzantine node attacks. Moreover, the obtained controller shows exponential convergence. The effectiveness and practicality of the theoretical results are verified by numerical examples. ",
    "url": "https://arxiv.org/abs/2303.15299",
    "authors": [
      "Xin Gong",
      "Yiwen Liang",
      "Yukang Cui",
      "Shi Liang",
      "Tingwen Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.15311",
    "title": "Improving Dual-Encoder Training through Dynamic Indexes for Negative  Mining",
    "abstract": "Dual encoder models are ubiquitous in modern classification and retrieval. Crucial for training such dual encoders is an accurate estimation of gradients from the partition function of the softmax over the large output space; this requires finding negative targets that contribute most significantly (\"hard negatives\"). Since dual encoder model parameters change during training, the use of traditional static nearest neighbor indexes can be sub-optimal. These static indexes (1) periodically require expensive re-building of the index, which in turn requires (2) expensive re-encoding of all targets using updated model parameters. This paper addresses both of these challenges. First, we introduce an algorithm that uses a tree structure to approximate the softmax with provable bounds and that dynamically maintains the tree. Second, we approximate the effect of a gradient update on target encodings with an efficient Nystrom low-rank approximation. In our empirical study on datasets with over twenty million targets, our approach cuts error by half in relation to oracle brute-force negative mining. Furthermore, our method surpasses prior state-of-the-art while using 150x less accelerator memory. ",
    "url": "https://arxiv.org/abs/2303.15311",
    "authors": [
      "Nicholas Monath",
      "Manzil Zaheer",
      "Kelsey Allen",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15334",
    "title": "ByteTrackV2: 2D and 3D Multi-Object Tracking by Associating Every  Detection Box",
    "abstract": "Multi-object tracking (MOT) aims at estimating bounding boxes and identities of objects across video frames. Detection boxes serve as the basis of both 2D and 3D MOT. The inevitable changing of detection scores leads to object missing after tracking. We propose a hierarchical data association strategy to mine the true objects in low-score detection boxes, which alleviates the problems of object missing and fragmented trajectories. The simple and generic data association strategy shows effectiveness under both 2D and 3D settings. In 3D scenarios, it is much easier for the tracker to predict object velocities in the world coordinate. We propose a complementary motion prediction strategy that incorporates the detected velocities with a Kalman filter to address the problem of abrupt motion and short-term disappearing. ByteTrackV2 leads the nuScenes 3D MOT leaderboard in both camera (56.4% AMOTA) and LiDAR (70.1% AMOTA) modalities. Furthermore, it is nonparametric and can be integrated with various detectors, making it appealing in real applications. The source code is released at https://github.com/ifzhang/ByteTrack-V2. ",
    "url": "https://arxiv.org/abs/2303.15334",
    "authors": [
      "Yifu Zhang",
      "Xinggang Wang",
      "Xiaoqing Ye",
      "Wei Zhang",
      "Jincheng Lu",
      "Xiao Tan",
      "Errui Ding",
      "Peize Sun",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15350",
    "title": "Improving Neural Topic Models with Wasserstein Knowledge Distillation",
    "abstract": "Topic modeling is a dominant method for exploring document collections on the web and in digital libraries. Recent approaches to topic modeling use pretrained contextualized language models and variational autoencoders. However, large neural topic models have a considerable memory footprint. In this paper, we propose a knowledge distillation framework to compress a contextualized topic model without loss in topic quality. In particular, the proposed distillation objective is to minimize the cross-entropy of the soft labels produced by the teacher and the student models, as well as to minimize the squared 2-Wasserstein distance between the latent distributions learned by the two models. Experiments on two publicly available datasets show that the student trained with knowledge distillation achieves topic coherence much higher than that of the original student model, and even surpasses the teacher while containing far fewer parameters than the teacher's. The distilled model also outperforms several other competitive topic models on topic coherence. ",
    "url": "https://arxiv.org/abs/2303.15350",
    "authors": [
      "Suman Adhya",
      "Debarshi Kumar Sanyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15377",
    "title": "AIR-DA: Adversarial Image Reconstruction for Unsupervised Domain  Adaptive Object Detection",
    "abstract": "Unsupervised domain adaptive object detection is a challenging vision task where object detectors are adapted from a label-rich source domain to an unlabeled target domain. Recent advances prove the efficacy of the adversarial based domain alignment where the adversarial training between the feature extractor and domain discriminator results in domain-invariance in the feature space. However, due to the domain shift, domain discrimination, especially on low-level features, is an easy task. This results in an imbalance of the adversarial training between the domain discriminator and the feature extractor. In this work, we achieve a better domain alignment by introducing an auxiliary regularization task to improve the training balance. Specifically, we propose Adversarial Image Reconstruction (AIR) as the regularizer to facilitate the adversarial training of the feature extractor. We further design a multi-level feature alignment module to enhance the adaptation performance. Our evaluations across several datasets of challenging domain shifts demonstrate that the proposed method outperforms all previous methods, of both one- and two-stage, in most settings. ",
    "url": "https://arxiv.org/abs/2303.15377",
    "authors": [
      "Kunyang Sun",
      "Wei Lin",
      "Haoqin Shi",
      "Zhengming Zhang",
      "Yongming Huang",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15381",
    "title": "Causal schema induction for knowledge discovery",
    "abstract": "Making sense of familiar yet new situations typically involves making generalizations about causal schemas, stories that help humans reason about event sequences. Reasoning about events includes identifying cause and effect relations shared across event instances, a process we refer to as causal schema induction. Statistical schema induction systems may leverage structural knowledge encoded in discourse or the causal graphs associated with event meaning, however resources to study such causal structure are few in number and limited in size. In this work, we investigate how to apply schema induction models to the task of knowledge discovery for enhanced search of English-language news texts. To tackle the problem of data scarcity, we present Torquestra, a manually curated dataset of text-graph-schema units integrating temporal, event, and causal structures. We benchmark our dataset on three knowledge discovery tasks, building and evaluating models for each. Results show that systems that harness causal structure are effective at identifying texts sharing similar causal meaning components rather than relying on lexical cues alone. We make our dataset and models available for research purposes. ",
    "url": "https://arxiv.org/abs/2303.15381",
    "authors": [
      "Michael Regan",
      "Jena D. Hwang",
      "Keisuke Sakaguchi",
      "James Pustejovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.15386",
    "title": "Robustness of Dynamics in Games: A Contraction Mapping Decomposition  Approach",
    "abstract": "A systematic framework for analyzing dynamical attributes of games has not been well-studied except for the special class of potential or near-potential games. In particular, the existing results have shortcomings in determining the asymptotic behavior of a given dynamic in a designated game. Although there is a large body literature on developing convergent dynamics to the Nash equilibrium (NE) of a game, in general, the asymptotic behavior of an underlying dynamic may not be even close to a NE. In this paper, we initiate a new direction towards game dynamics by studying the fundamental properties of the map of dynamics in games. To this aim, we first decompose the map of a given dynamic into contractive and non-contractive parts and then explore the asymptotic behavior of those dynamics using the proximity of such decomposition to contraction mappings. In particular, we analyze the non-contractive behavior for better/best response dynamics in discrete-action space sequential/repeated games and show that the non-contractive part of those dynamics is well-behaved in a certain sense. That allows us to estimate the asymptotic behavior of such dynamics using a neighborhood around the fixed point of their contractive part proxy. Finally, we demonstrate the practicality of our framework via an example from duopoly Cournot games. ",
    "url": "https://arxiv.org/abs/2303.15386",
    "authors": [
      "Sina Arefizadeh",
      "Sadegh Arefizadeh",
      "S. Rasoul Etesami",
      "Sadegh Bolouki"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2303.15387",
    "title": "Generalizable Neural Voxels for Fast Human Radiance Fields",
    "abstract": "Rendering moving human bodies at free viewpoints only from a monocular video is quite a challenging problem. The information is too sparse to model complicated human body structures and motions from both view and pose dimensions. Neural radiance fields (NeRF) have shown great power in novel view synthesis and have been applied to human body rendering. However, most current NeRF-based methods bear huge costs for both training and rendering, which impedes the wide applications in real-life scenarios. In this paper, we propose a rendering framework that can learn moving human body structures extremely quickly from a monocular video. The framework is built by integrating both neural fields and neural voxels. Especially, a set of generalizable neural voxels are constructed. With pretrained on various human bodies, these general voxels represent a basic skeleton and can provide strong geometric priors. For the fine-tuning process, individual voxels are constructed for learning differential textures, complementary to general voxels. Thus learning a novel body can be further accelerated, taking only a few minutes. Our method shows significantly higher training efficiency compared with previous methods, while maintaining similar rendering quality. The project page is at https://taoranyi.com/gneuvox . ",
    "url": "https://arxiv.org/abs/2303.15387",
    "authors": [
      "Taoran Yi",
      "Jiemin Fang",
      "Xinggang Wang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.15404",
    "title": "Chromatic Community Structure Detection",
    "abstract": "The detection of community structure is probably one of the hottest trends in complex network research as it reveals the internal organization of people, molecules or processes behind social, biological or computer networks\\dots The issue is to provide a network partition representative of this organization so that each community presumably gathers nodes sharing a common mission, purpose or property. Usually the identification is based on the difference between the connectivity density of the interior and the boundary of a community. Indeed, nodes sharing a common purpose or property are expected to interact closely. Although this rule appears mostly relevant, some fundamental scientific problems like disease module detection highlight the inability to determine significantly the communities under this connectivity rule. The main reason is that the connectivity density is not correlated to a shared property or purpose. Therefore, another paradigm is required for properly formalize this issue in order to meaningfully detect these communities. In this article we study the community formation from this new principle. Considering colors formally figures the shared properties, the issue is thus to maximize group of nodes with the same color within communities.. We study this novel community framework by introducing new measurement called \\emph{chromarity} assessing the quality of the community structure regarding this constraint. Next we propose an algorithm solving the community structure detection based on this new community formation paradigm. ",
    "url": "https://arxiv.org/abs/2303.15404",
    "authors": [
      "Franck Delaplace"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.15409",
    "title": "Classifier Robustness Enhancement Via Test-Time Transformation",
    "abstract": "It has been recently discovered that adversarially trained classifiers exhibit an intriguing property, referred to as perceptually aligned gradients (PAG). PAG implies that the gradients of such classifiers possess a meaningful structure, aligned with human perception. Adversarial training is currently the best-known way to achieve classification robustness under adversarial attacks. The PAG property, however, has yet to be leveraged for further improving classifier robustness. In this work, we introduce Classifier Robustness Enhancement Via Test-Time Transformation (TETRA) -- a novel defense method that utilizes PAG, enhancing the performance of trained robust classifiers. Our method operates in two phases. First, it modifies the input image via a designated targeted adversarial attack into each of the dataset's classes. Then, it classifies the input image based on the distance to each of the modified instances, with the assumption that the shortest distance relates to the true class. We show that the proposed method achieves state-of-the-art results and validate our claim through extensive experiments on a variety of defense methods, classifier architectures, and datasets. We also empirically demonstrate that TETRA can boost the accuracy of any differentiable adversarial training classifier across a variety of attacks, including ones unseen at training. Specifically, applying TETRA leads to substantial improvement of up to $+23\\%$, $+20\\%$, and $+26\\%$ on CIFAR10, CIFAR100, and ImageNet, respectively. ",
    "url": "https://arxiv.org/abs/2303.15409",
    "authors": [
      "Tsachi Blau",
      "Roy Ganz",
      "Chaim Baskin",
      "Michael Elad",
      "Alex Bronstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15413",
    "title": "Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D  Generation",
    "abstract": "The view inconsistency problem in score-distilling text-to-3D generation, also known as the Janus problem, arises from the intrinsic bias of 2D diffusion models, which leads to the unrealistic generation of 3D objects. In this work, we explore score-distilling text-to-3D generation and identify the main causes of the Janus problem. Based on these findings, we propose two approaches to debias the score-distillation frameworks for robust text-to-3D generation. Our first approach, called score debiasing, involves gradually increasing the truncation value for the score estimated by 2D diffusion models throughout the optimization process. Our second approach, called prompt debiasing, identifies conflicting words between user prompts and view prompts utilizing a language model and adjusts the discrepancy between view prompts and object-space camera poses. Our experimental results show that our methods improve realism by significantly reducing artifacts and achieve a good trade-off between faithfulness to the 2D diffusion models and 3D consistency with little overhead. ",
    "url": "https://arxiv.org/abs/2303.15413",
    "authors": [
      "Susung Hong",
      "Donghoon Ahn",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15414",
    "title": "Learnable Graph Matching: A Practical Paradigm for Data Association",
    "abstract": "Data association is at the core of many computer vision tasks, e.g., multiple object tracking, image matching, and point cloud registration. Existing methods usually solve the data association problem by network flow optimization, bipartite matching, or end-to-end learning directly. Despite their popularity, we find some defects of the current solutions: they mostly ignore the intra-view context information; besides, they either train deep association models in an end-to-end way and hardly utilize the advantage of optimization-based assignment methods, or only use an off-the-shelf neural network to extract features. In this paper, we propose a general learnable graph matching method to address these issues. Especially, we model the intra-view relationships as an undirected graph. Then data association turns into a general graph matching problem between graphs. Furthermore, to make optimization end-to-end differentiable, we relax the original graph matching problem into continuous quadratic programming and then incorporate training into a deep graph neural network with KKT conditions and implicit function theorem. In MOT task, our method achieves state-of-the-art performance on several MOT datasets. For image matching, our method outperforms state-of-the-art methods with half training data and iterations on a popular indoor dataset, ScanNet. Code will be available at https://github.com/jiaweihe1996/GMTracker. ",
    "url": "https://arxiv.org/abs/2303.15414",
    "authors": [
      "Jiawei He",
      "Zehao Huang",
      "Naiyan Wang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15416",
    "title": "3D Video Object Detection with Learnable Object-Centric Global  Optimization",
    "abstract": "We explore long-term temporal visual correspondence-based optimization for 3D video object detection in this work. Visual correspondence refers to one-to-one mappings for pixels across multiple images. Correspondence-based optimization is the cornerstone for 3D scene reconstruction but is less studied in 3D video object detection, because moving objects violate multi-view geometry constraints and are treated as outliers during scene reconstruction. We address this issue by treating objects as first-class citizens during correspondence-based optimization. In this work, we propose BA-Det, an end-to-end optimizable object detector with object-centric temporal correspondence learning and featuremetric object bundle adjustment. Empirically, we verify the effectiveness and efficiency of BA-Det for multiple baseline 3D detectors under various setups. Our BA-Det achieves SOTA performance on the large-scale Waymo Open Dataset (WOD) with only marginal computation cost. Our code is available at https://github.com/jiaweihe1996/BA-Det. ",
    "url": "https://arxiv.org/abs/2303.15416",
    "authors": [
      "Jiawei He",
      "Yuntao Chen",
      "Naiyan Wang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15421",
    "title": "ACAT: Adversarial Counterfactual Attention for Classification and  Detection in Medical Imaging",
    "abstract": "In some medical imaging tasks and other settings where only small parts of the image are informative for the classification task, traditional CNNs can sometimes struggle to generalise. Manually annotated Regions of Interest (ROI) are sometimes used to isolate the most informative parts of the image. However, these are expensive to collect and may vary significantly across annotators. To overcome these issues, we propose a framework that employs saliency maps to obtain soft spatial attention masks that modulate the image features at different scales. We refer to our method as Adversarial Counterfactual Attention (ACAT). ACAT increases the baseline classification accuracy of lesions in brain CT scans from 71.39% to 72.55% and of COVID-19 related findings in lung CT scans from 67.71% to 70.84% and exceeds the performance of competing methods. We investigate the best way to generate the saliency maps employed in our architecture and propose a way to obtain them from adversarially generated counterfactual images. They are able to isolate the area of interest in brain and lung CT scans without using any manual annotations. In the task of localising the lesion location out of 6 possible regions, they obtain a score of 65.05% on brain CT scans, improving the score of 61.29% obtained with the best competing method. ",
    "url": "https://arxiv.org/abs/2303.15421",
    "authors": [
      "Alessandro Fontanella",
      "Antreas Antoniou",
      "Wenwen Li",
      "Joanna Wardlaw",
      "Grant Mair",
      "Emanuele Trucco",
      "Amos Storkey"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15427",
    "title": "JAWS: Just A Wild Shot for Cinematic Transfer in Neural Radiance Fields",
    "abstract": "This paper presents JAWS, an optimization-driven approach that achieves the robust transfer of visual cinematic features from a reference in-the-wild video clip to a newly generated clip. To this end, we rely on an implicit-neural-representation (INR) in a way to compute a clip that shares the same cinematic features as the reference clip. We propose a general formulation of a camera optimization problem in an INR that computes extrinsic and intrinsic camera parameters as well as timing. By leveraging the differentiability of neural representations, we can back-propagate our designed cinematic losses measured on proxy estimators through a NeRF network to the proposed cinematic parameters directly. We also introduce specific enhancements such as guidance maps to improve the overall quality and efficiency. Results display the capacity of our system to replicate well known camera sequences from movies, adapting the framing, camera parameters and timing of the generated video clip to maximize the similarity with the reference clip. ",
    "url": "https://arxiv.org/abs/2303.15427",
    "authors": [
      "Xi Wang",
      "Robin Courant",
      "Jinglei Shi",
      "Eric Marchand",
      "Marc Christie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.15437",
    "title": "FaceLit: Neural 3D Relightable Faces",
    "abstract": "We propose a generative framework, FaceLit, capable of generating a 3D face that can be rendered at various user-defined lighting conditions and views, learned purely from 2D images in-the-wild without any manual annotation. Unlike existing works that require careful capture setup or human labor, we rely on off-the-shelf pose and illumination estimators. With these estimates, we incorporate the Phong reflectance model in the neural volume rendering framework. Our model learns to generate shape and material properties of a face such that, when rendered according to the natural statistics of pose and illumination, produces photorealistic face images with multiview 3D and illumination consistency. Our method enables photorealistic generation of faces with explicit illumination and view controls on multiple datasets - FFHQ, MetFaces and CelebA-HQ. We show state-of-the-art photorealism among 3D aware GANs on FFHQ dataset achieving an FID score of 3.5. ",
    "url": "https://arxiv.org/abs/2303.15437",
    "authors": [
      "Anurag Ranjan",
      "Kwang Moo Yi",
      "Jen-Hao Rick Chang",
      "Oncel Tuzel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15438",
    "title": "On the stepwise nature of self-supervised learning",
    "abstract": "We present a simple picture of the training process of self-supervised learning methods with joint embedding networks. We find that these methods learn their high-dimensional embeddings one dimension at a time in a sequence of discrete, well-separated steps. We arrive at this conclusion via the study of a linearized model of Barlow Twins applicable to the case in which the trained network is infinitely wide. We solve the training dynamics of this model from small initialization, finding that the model learns the top eigenmodes of a certain contrastive kernel in a stepwise fashion, and obtain a closed-form expression for the final learned representations. Remarkably, we then see the same stepwise learning phenomenon when training deep ResNets using the Barlow Twins, SimCLR, and VICReg losses. Our theory suggests that, just as kernel regression can be thought of as a model of supervised learning, \\textit{kernel PCA} may serve as a useful model of self-supervised learning. ",
    "url": "https://arxiv.org/abs/2303.15438",
    "authors": [
      "James B. Simon",
      "Maksis Knutins",
      "Liu Ziyin",
      "Daniel Geisz",
      "Abraham J. Fetterman",
      "Joshua Albrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15440",
    "title": "EFEM: Equivariant Neural Field Expectation Maximization for 3D Object  Segmentation Without Scene Supervision",
    "abstract": "We introduce Equivariant Neural Field Expectation Maximization (EFEM), a simple, effective, and robust geometric algorithm that can segment objects in 3D scenes without annotations or training on scenes. We achieve such unsupervised segmentation by exploiting single object shape priors. We make two novel steps in that direction. First, we introduce equivariant shape representations to this problem to eliminate the complexity induced by the variation in object configuration. Second, we propose a novel EM algorithm that can iteratively refine segmentation masks using the equivariant shape prior. We collect a novel real dataset Chairs and Mugs that contains various object configurations and novel scenes in order to verify the effectiveness and robustness of our method. Experimental results demonstrate that our method achieves consistent and robust performance across different scenes where the (weakly) supervised methods may fail. Code and data available at https://www.cis.upenn.edu/~leijh/projects/efem ",
    "url": "https://arxiv.org/abs/2303.15440",
    "authors": [
      "Jiahui Lei",
      "Congyue Deng",
      "Karl Schmeckpeper",
      "Leonidas Guibas",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14193",
    "title": "Quadratic Graph Attention Network (Q-GAT) for Robust Construction of  Gene Regulatory Networks",
    "abstract": "Gene regulatory relationships can be abstracted as a gene regulatory network (GRN), which plays a key role in characterizing complex cellular processes and pathways. Recently, graph neural networks (GNNs), as a class of deep learning models, have emerged as a useful tool to infer gene regulatory relationships from gene expression data. However, deep learning models have been found to be vulnerable to noise, which greatly hinders the adoption of deep learning in constructing GRNs, because high noise is often unavoidable in the process of gene expression measurement. Can we preferably prototype a robust GNN for constructing GRNs? In this paper, we give a positive answer by proposing a Quadratic Graph Attention Network (Q-GAT) with a dual attention mechanism. We study the changes in the predictive accuracy of Q-GAT and 9 state-of-the-art baselines by introducing different levels of adversarial perturbations. Experiments in the E. coli and S. cerevisiae datasets suggest that Q-GAT outperforms the state-of-the-art models in robustness. Lastly, we dissect why Q-GAT is robust through the signal-to-noise ratio (SNR) and interpretability analyses. The former informs that nonlinear aggregation of quadratic neurons can amplify useful signals and suppress unwanted noise, thereby facilitating robustness, while the latter reveals that Q-GAT can leverage more features in prediction thanks to the dual attention mechanism, which endows Q-GAT with the ability to confront adversarial perturbation. We have shared our code in https://github.com/Minorway/Q-GAT_for_Robust_Construction_of_GRN for readers' evaluation. ",
    "url": "https://arxiv.org/abs/2303.14193",
    "authors": [
      "Hui Zhang",
      "Xuexin An",
      "Qiang He",
      "Yudong Yao",
      "Feng-Lei Fan",
      "Yueyang Teng"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.14226",
    "title": "Synthetic Combinations: A Causal Inference Framework for Combinatorial  Interventions",
    "abstract": "We consider a setting with $N$ heterogeneous units and $p$ interventions. Our goal is to learn unit-specific potential outcomes for any combination of these $p$ interventions, i.e., $N \\times 2^p$ causal parameters. Choosing combinations of interventions is a problem that naturally arises in many applications such as factorial design experiments, recommendation engines (e.g., showing a set of movies that maximizes engagement for users), combination therapies in medicine, selecting important features for ML models, etc. Running $N \\times 2^p$ experiments to estimate the various parameters is infeasible as $N$ and $p$ grow. Further, with observational data there is likely confounding, i.e., whether or not a unit is seen under a combination is correlated with its potential outcome under that combination. To address these challenges, we propose a novel model that imposes latent structure across both units and combinations. We assume latent similarity across units (i.e., the potential outcomes matrix is rank $r$) and regularity in how combinations interact (i.e., the coefficients in the Fourier expansion of the potential outcomes is $s$ sparse). We establish identification for all causal parameters despite unobserved confounding. We propose an estimation procedure, Synthetic Combinations, and establish finite-sample consistency under precise conditions on the observation pattern. Our results imply Synthetic Combinations consistently estimates unit-specific potential outcomes given $\\text{poly}(r) \\times (N + s^2p)$ observations. In comparison, previous methods that do not exploit structure across both units and combinations have sample complexity scaling as $\\min(N \\times s^2p, \\ \\ r \\times (N + 2^p))$. We use Synthetic Combinations to propose a data-efficient experimental design mechanism for combinatorial causal inference. We corroborate our theoretical findings with numerical simulations. ",
    "url": "https://arxiv.org/abs/2303.14226",
    "authors": [
      "Abhineet Agarwal",
      "Anish Agarwal",
      "Suhas Vijaykumar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.14229",
    "title": "Sharp threshold for embedding balanced spanning trees in random  geometric graphs",
    "abstract": "A rooted tree is balanced if the degree of a vertex depends only on its distance to the root. In this paper we determine the sharp threshold for the appearance of a large family of balanced spanning trees in the random geometric graph $\\mathcal{G}(n,r,d)$. In particular, we find the sharp threshold for balanced binary trees. More generally, we show that all sequences of balanced trees with uniformly bounded degrees and height tending to infinity appear above a sharp threshold, and none of these appears below the same value. Our results hold more generally for geometric graphs satisfying a mild condition on the distribution of their vertex set, and we provide a polynomial time algorithm to find such trees. ",
    "url": "https://arxiv.org/abs/2303.14229",
    "authors": [
      "Alberto Espuny D\u00edaz",
      "Lyuben Lichev",
      "Dieter Mitsche",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.14313",
    "title": "Cores in multiway networks",
    "abstract": "The notion of a core is generalized to multiway networks. To determine the multiway cores, we adapted already-known algorithms for determining the generalized cores in one-mode and two-mode networks. A new node property, node diversity has been introduced. The newly introduced notions are illustrated with application on the multiway networks of European airports and airlines and Summer Olympic medals till 2016. For the interactive inspection of the results, their 3D layout in X3D is supported. ",
    "url": "https://arxiv.org/abs/2303.14313",
    "authors": [
      "Vladimir Batagelj"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2303.14349",
    "title": "Causal Image Synthesis of Brain MR in 3D",
    "abstract": "Clinical decision making requires counterfactual reasoning based on a factual medical image and thus necessitates causal image synthesis. To this end, we present a novel method for modeling the causality between demographic variables, clinical indices and brain MR images for Alzheimer's Diseases. Specifically, we leverage a structural causal model to depict the causality and a styled generator to synthesize the image. Furthermore, as a crucial step to reduce modeling complexity and make learning tractable, we propose the use of low dimensional latent feature representation of a high-dimensional 3D image, together with exogenous noise, to build causal relationship between the image and non image variables. We experiment the proposed method based on 1586 subjects and 3683 3D images and synthesize counterfactual brain MR images intervened on certain attributes, such as age, brain volume and cognitive test score. Quantitative metrics and qualitative evaluation of counterfactual images demonstrates the superiority of our generated images. ",
    "url": "https://arxiv.org/abs/2303.14349",
    "authors": [
      "Yujia Li",
      "Jiong Shi",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14357",
    "title": "Dealing With Heterogeneous 3D MR Knee Images: A Federated Few-Shot  Learning Method With Dual Knowledge Distillation",
    "abstract": "Federated Learning has gained popularity among medical institutions since it enables collaborative training between clients (e.g., hospitals) without aggregating data. However, due to the high cost associated with creating annotations, especially for large 3D image datasets, clinical institutions do not have enough supervised data for training locally. Thus, the performance of the collaborative model is subpar under limited supervision. On the other hand, large institutions have the resources to compile data repositories with high-resolution images and labels. Therefore, individual clients can utilize the knowledge acquired in the public data repositories to mitigate the shortage of private annotated images. In this paper, we propose a federated few-shot learning method with dual knowledge distillation. This method allows joint training with limited annotations across clients without jeopardizing privacy. The supervised learning of the proposed method extracts features from limited labeled data in each client, while the unsupervised data is used to distill both feature and response-based knowledge from a national data repository to further improve the accuracy of the collaborative model and reduce the communication cost. Extensive evaluations are conducted on 3D magnetic resonance knee images from a private clinical dataset. Our proposed method shows superior performance and less training time than other semi-supervised federated learning methods. Codes and additional visualization results are available at https://github.com/hexiaoxiao-cs/fedml-knee. ",
    "url": "https://arxiv.org/abs/2303.14357",
    "authors": [
      "Xiaoxiao He",
      "Chaowei Tan",
      "Bo Liu",
      "Liping Si",
      "Weiwu Yao",
      "Liang Zhao",
      "Di Liu",
      "Qilong Zhangli",
      "Qi Chang",
      "Kang Li",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14391",
    "title": "Multi-pooling 3D Convolutional Neural Network for fMRI Classification of  Visual Brain States",
    "abstract": "Neural decoding of visual object classification via functional magnetic resonance imaging (fMRI) data is challenging and is vital to understand underlying brain mechanisms. This paper proposed a multi-pooling 3D convolutional neural network (MP3DCNN) to improve fMRI classification accuracy. MP3DCNN is mainly composed of a three-layer 3DCNN, where the first and second layers of 3D convolutions each have a branch of pooling connection. The results showed that this model can improve the classification accuracy for categorical (face vs. object), face sub-categorical (male face vs. female face), and object sub-categorical (natural object vs. artificial object) classifications from 1.684% to 14.918% over the previous study in decoding brain mechanisms. ",
    "url": "https://arxiv.org/abs/2303.14391",
    "authors": [
      "Zhen Zhang",
      "Masaki Takeda",
      "Makoto Iwata"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14468",
    "title": "Autoregressive Conditional Neural Processes",
    "abstract": "Conditional neural processes (CNPs; Garnelo et al., 2018a) are attractive meta-learning models which produce well-calibrated predictions and are trainable via a simple maximum likelihood procedure. Although CNPs have many advantages, they are unable to model dependencies in their predictions. Various works propose solutions to this, but these come at the cost of either requiring approximate inference or being limited to Gaussian predictions. In this work, we instead propose to change how CNPs are deployed at test time, without any modifications to the model or training procedure. Instead of making predictions independently for every target point, we autoregressively define a joint predictive distribution using the chain rule of probability, taking inspiration from the neural autoregressive density estimator (NADE) literature. We show that this simple procedure allows factorised Gaussian CNPs to model highly dependent, non-Gaussian predictive distributions. Perhaps surprisingly, in an extensive range of tasks with synthetic and real data, we show that CNPs in autoregressive (AR) mode not only significantly outperform non-AR CNPs, but are also competitive with more sophisticated models that are significantly more computationally expensive and challenging to train. This performance is remarkable given that AR CNPs are not trained to model joint dependencies. Our work provides an example of how ideas from neural distribution estimation can benefit neural processes, and motivates research into the AR deployment of other neural process models. ",
    "url": "https://arxiv.org/abs/2303.14468",
    "authors": [
      "Wessel P. Bruinsma",
      "Stratis Markou",
      "James Requiema",
      "Andrew Y. K. Foong",
      "Tom R. Andersson",
      "Anna Vaughan",
      "Anthony Buonomo",
      "J. Scott Hosking",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14500",
    "title": "Formalization of Quantum Intermediate Representations for Code Safety",
    "abstract": "Quantum Intermediate Representation (QIR) is a Microsoft-developed, LLVM-based intermediate representation for quantum program compilers. QIR aims to provide a general solution for quantum program compilers independent of front-end languages and back-end hardware, thus avoiding duplicate development of intermediate representations and compilers. Since it is still under development, QIR is described in natural language and lacks a formal definition, leading to ambiguity in its interpretation and a lack of rigor in implementing quantum functions. In this paper, we provide formal definitions for the data types and instruction sets of QIR, aiming to provide correctness and security guarantees for operations and intermediate code conversions in QIR. To validate our design, we show some samples of unsafe QIR code where errors can be detected by our formal approach. ",
    "url": "https://arxiv.org/abs/2303.14500",
    "authors": [
      "Junjie Luo",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2303.14511",
    "title": "Improving robustness of jet tagging algorithms with adversarial  training: exploring the loss surface",
    "abstract": "In the field of high-energy physics, deep learning algorithms continue to gain in relevance and provide performance improvements over traditional methods, for example when identifying rare signals or finding complex patterns. From an analyst's perspective, obtaining highest possible performance is desirable, but recently, some attention has been shifted towards studying robustness of models to investigate how well these perform under slight distortions of input features. Especially for tasks that involve many (low-level) inputs, the application of deep neural networks brings new challenges. In the context of jet flavor tagging, adversarial attacks are used to probe a typical classifier's vulnerability and can be understood as a model for systematic uncertainties. A corresponding defense strategy, adversarial training, improves robustness, while maintaining high performance. Investigating the loss surface corresponding to the inputs and models in question reveals geometric interpretations of robustness, taking correlations into account. ",
    "url": "https://arxiv.org/abs/2303.14511",
    "authors": [
      "Annika Stein"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2303.14688",
    "title": "Uniqueness of BP fixed point for the Potts model and applications to  community detection",
    "abstract": "In the study of sparse stochastic block model (SBM) one needs to analyze a distributional recursion, known as belief propagation (BP) on a tree. Uniqueness of the fixed point of this recursion implies several results about the SBM, including optimal recovery algorithms for SBM (Mossel et al. (2016)) and SBM with side information (Mossel and Xu (2016)), and a formula for SBM mutual information (Abbe et al. (2021)). The 2-community case corresponds to an Ising model, for which Yu and Polyanskiy (2022) established uniqueness for all cases. Here, we analyze broadcasting of $q$-ary spins on a Galton-Watson tree with expected offspring degree $d$ and Potts channels with second-largest eigenvalue $\\lambda$. We allow for the intermediate vertices to be observed through noisy channels (side information) We prove BP uniqueness holds with and without side information when $d\\lambda^2 \\ge 1 + C \\max\\{\\lambda, q^{-1}\\}\\log q$ for some absolute constant $C>0$ independent of $q,d,\\lambda$. For large $q$ and $\\lambda = o(1/\\log q)$, this is asymptotically achieving the Kesten-Stigum threshold $d\\lambda^2=1$. These results imply mutual information formula and optimal recovery algorithms for the $q$-community SBM in the corresponding ranges. For $q\\ge 4$, Sly (2011); Mossel et al. (2022) shows that there exist choices of $q,d,\\lambda$ below Kesten-Stigum (i.e. $d\\lambda^2 < 1$) but reconstruction is possible. Somewhat surprisingly, we show that in such regimes BP uniqueness \\textit{does not hold} at least in the presence of weak side information. Our technical tool is a theory of q-ary symmetric channels, that we initiate here, generalizing the classical and widely-utilized information-theoretic characterization of BMS (binary memoryless symmetric) channels. ",
    "url": "https://arxiv.org/abs/2303.14688",
    "authors": [
      "Yuzhou Gu",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.14711",
    "title": "Unsupervised detection of small hyperreflective features in ultrahigh  resolution optical coherence tomography",
    "abstract": "Recent advances in optical coherence tomography such as the development of high speed ultrahigh resolution scanners and corresponding signal processing techniques may reveal new potential biomarkers in retinal diseases. Newly visible features are, for example, small hyperreflective specks in age-related macular degeneration. Identifying these new markers is crucial to investigate potential association with disease progression and treatment outcomes. Therefore, it is necessary to reliably detect these features in 3D volumetric scans. Because manual labeling of entire volumes is infeasible a need for automatic detection arises. Labeled datasets are often not publicly available and there are usually large variations in scan protocols and scanner types. Thus, this work focuses on an unsupervised approach that is based on local peak-detection and random walker segmentation to detect small features on each B-scan of the volume. ",
    "url": "https://arxiv.org/abs/2303.14711",
    "authors": [
      "Marcel Reimann",
      "Jungeun Won",
      "Hiroyuki Takahashi",
      "Antonio Yaghy",
      "Yunchan Hwang",
      "Stefan Ploner",
      "Junhong Lin",
      "Jessica Girgis",
      "Kenneth Lam",
      "Siyu Chen",
      "Nadia K. Waheed",
      "Andreas Maier",
      "James G. Fujimoto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14720",
    "title": "Driver Profiling and Bayesian Workload Estimation Using Naturalistic  Peripheral Detection Study Data",
    "abstract": "Monitoring drivers' mental workload facilitates initiating and maintaining safe interactions with in-vehicle information systems, and thus delivers adaptive human machine interaction with reduced impact on the primary task of driving. In this paper, we tackle the problem of workload estimation from driving performance data. First, we present a novel on-road study for collecting subjective workload data via a modified peripheral detection task in naturalistic settings. Key environmental factors that induce a high mental workload are identified via video analysis, e.g. junctions and behaviour of vehicle in front. Second, a supervised learning framework using state-of-the-art time series classifiers (e.g. convolutional neural network and transform techniques) is introduced to profile drivers based on the average workload they experience during a journey. A Bayesian filtering approach is then proposed for sequentially estimating, in (near) real-time, the driver's instantaneous workload. This computationally efficient and flexible method can be easily personalised to a driver (e.g. incorporate their inferred average workload profile), adapted to driving/environmental contexts (e.g. road type) and extended with data streams from new sources. The efficacy of the presented profiling and instantaneous workload estimation approaches are demonstrated using the on-road study data, showing $F_{1}$ scores of up to 92% and 81%, respectively. ",
    "url": "https://arxiv.org/abs/2303.14720",
    "authors": [
      "Nermin Caber",
      "Jiaming Liang",
      "Bashar I. Ahmad",
      "Simon Godsill",
      "Alexandra Bremers",
      "Philip Thomas",
      "David Oxtoby",
      "Lee Skrypchuk"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.14844",
    "title": "Analyzing Convergence in Quantum Neural Networks: Deviations from Neural  Tangent Kernels",
    "abstract": "A quantum neural network (QNN) is a parameterized mapping efficiently implementable on near-term Noisy Intermediate-Scale Quantum (NISQ) computers. It can be used for supervised learning when combined with classical gradient-based optimizers. Despite the existing empirical and theoretical investigations, the convergence of QNN training is not fully understood. Inspired by the success of the neural tangent kernels (NTKs) in probing into the dynamics of classical neural networks, a recent line of works proposes to study over-parameterized QNNs by examining a quantum version of tangent kernels. In this work, we study the dynamics of QNNs and show that contrary to popular belief it is qualitatively different from that of any kernel regression: due to the unitarity of quantum operations, there is a non-negligible deviation from the tangent kernel regression derived at the random initialization. As a result of the deviation, we prove the at-most sublinear convergence for QNNs with Pauli measurements, which is beyond the explanatory power of any kernel regression dynamics. We then present the actual dynamics of QNNs in the limit of over-parameterization. The new dynamics capture the change of convergence rate during training and implies that the range of measurements is crucial to the fast QNN convergence. ",
    "url": "https://arxiv.org/abs/2303.14844",
    "authors": [
      "Xuchen You",
      "Shouvanik Chakrabarti",
      "Boyang Chen",
      "Xiaodi Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14965",
    "title": "Disruption Precursor Onset Time Study Based on Semi-supervised Anomaly  Detection",
    "abstract": "The full understanding of plasma disruption in tokamaks is currently lacking, and data-driven methods are extensively used for disruption prediction. However, most existing data-driven disruption predictors employ supervised learning techniques, which require labeled training data. The manual labeling of disruption precursors is a tedious and challenging task, as some precursors are difficult to accurately identify, limiting the potential of machine learning models. To address this issue, commonly used labeling methods assume that the precursor onset occurs at a fixed time before the disruption, which may not be consistent for different types of disruptions or even the same type of disruption, due to the different speeds at which plasma instabilities escalate. This leads to mislabeled samples and suboptimal performance of the supervised learning predictor. In this paper, we present a disruption prediction method based on anomaly detection that overcomes the drawbacks of unbalanced positive and negative data samples and inaccurately labeled disruption precursor samples. We demonstrate the effectiveness and reliability of anomaly detection predictors based on different algorithms on J-TEXT and EAST to evaluate the reliability of the precursor onset time inferred by the anomaly detection predictor. The precursor onset times inferred by these predictors reveal that the labeling methods have room for improvement as the onset times of different shots are not necessarily the same. Finally, we optimize precursor labeling using the onset times inferred by the anomaly detection predictor and test the optimized labels on supervised learning disruption predictors. The results on J-TEXT and EAST show that the models trained on the optimized labels outperform those trained on fixed onset time labels. ",
    "url": "https://arxiv.org/abs/2303.14965",
    "authors": [
      "Xinkun Ai",
      "Wei Zheng",
      "Ming Zhang",
      "Dalong Chen",
      "Chengshuo Shen",
      "Bihao Guo",
      "Bingjia Xiao",
      "Yu Zhong",
      "Nengchao Wang",
      "Zhoujun Yang",
      "Zhipeng Chen",
      "Zhongyong Chen",
      "Yonghua Ding",
      "Yuan Pan",
      "J-TEXT team"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14986",
    "title": "mSPD-NN: A Geometrically Aware Neural Framework for Biomarker Discovery  from Functional Connectomics Manifolds",
    "abstract": "Connectomics has emerged as a powerful tool in neuroimaging and has spurred recent advancements in statistical and machine learning methods for connectivity data. Despite connectomes inhabiting a matrix manifold, most analytical frameworks ignore the underlying data geometry. This is largely because simple operations, such as mean estimation, do not have easily computable closed-form solutions. We propose a geometrically aware neural framework for connectomes, i.e., the mSPD-NN, designed to estimate the geodesic mean of a collections of symmetric positive definite (SPD) matrices. The mSPD-NN is comprised of bilinear fully connected layers with tied weights and utilizes a novel loss function to optimize the matrix-normal equation arising from Fr\\'echet mean estimation. Via experiments on synthetic data, we demonstrate the efficacy of our mSPD-NN against common alternatives for SPD mean estimation, providing competitive performance in terms of scalability and robustness to noise. We illustrate the real-world flexibility of the mSPD-NN in multiple experiments on rs-fMRI data and demonstrate that it uncovers stable biomarkers associated with subtle network differences among patients with ADHD-ASD comorbidities and healthy controls. ",
    "url": "https://arxiv.org/abs/2303.14986",
    "authors": [
      "Niharika S. D'Souza",
      "Archana Venkataraman"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2303.15065",
    "title": "Multi-contrast MRI Super-resolution via Implicit Neural Representations",
    "abstract": "Clinical routine and retrospective cohorts commonly include multi-parametric Magnetic Resonance Imaging; however, they are mostly acquired in different anisotropic 2D views due to signal-to-noise-ratio and scan-time constraints. Thus acquired views suffer from poor out-of-plane resolution and affect downstream volumetric image analysis that typically requires isotropic 3D scans. Combining different views of multi-contrast scans into high-resolution isotropic 3D scans is challenging due to the lack of a large training cohort, which calls for a subject-specific framework.This work proposes a novel solution to this problem leveraging Implicit Neural Representations (INR). Our proposed INR jointly learns two different contrasts of complementary views in a continuous spatial function and benefits from exchanging anatomical information between them. Trained within minutes on a single commodity GPU, our model provides realistic super-resolution across different pairs of contrasts in our experiments with three datasets. Using Mutual Information (MI) as a metric, we find that our model converges to an optimum MI amongst sequences, achieving anatomically faithful reconstruction. Code is available at: https://github.com/jqmcginnis/multi_contrast_inr. ",
    "url": "https://arxiv.org/abs/2303.15065",
    "authors": [
      "Julian McGinnis",
      "Suprosanna Shit",
      "Hongwei Bran Li",
      "Vasiliki Sideri-Lampretsa",
      "Robert Graf",
      "Maik Dannecker",
      "Jiazhen Pan",
      "Nil Stolt Ans\u00f3",
      "Mark M\u00fchlau",
      "Jan S. Kirschke",
      "Daniel Rueckert",
      "Benedikt Wiestler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15082",
    "title": "Optimal control for port-Hamiltonian systems and a new perspective on  dynamic network flow problems",
    "abstract": "We formulate open-loop optimal control problems for general port-Hamiltonian systems with possibly state-dependent system matrices and prove their well-posedness. The optimal controls are characterized by the first-order optimality system, which is the starting point for the derivation of an adjoint-based gradient descent algorithm. Moreover, we discuss the relationship of port-Hamiltonian dynamics and minimum cost network flow problems. Our analysis is underpinned by a proof of concept, where we apply the proposed algorithm to static minimum cost flow problems and dynamic minimum cost flow problems with a simple directed acyclic graph. The numerical results validate the approach. ",
    "url": "https://arxiv.org/abs/2303.15082",
    "authors": [
      "Onur Tanil Doganay",
      "Kathrin Klamroth",
      "Bruno Lang",
      "Michael Stiglmayr",
      "Claudia Totzeck"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.15163",
    "title": "How creative versus technical constraints affect individual learning in  an online innovation community",
    "abstract": "Online innovation communities allow for a search for novel solutions within a design space bounded by constraints. Past research has focused on the effect of creative constraints on individual projects, but less is known about how constraints affect learning from repeated design submissions and the effect of the technical constraints that are integral to online platforms. How do creative versus technical constraints affect individual learning in exploring a design space in online communities? We analyzed ten years of data from an online innovation community that crowdsourced 136,989 design submissions from 33,813 individuals. We leveraged data from two types of design contests-creatively constrained and unconstrained-running in parallel on the platform, and we evaluated a natural experiment where a platform change reduced technical constraints. We find that creative constraints lead to high rates of learning only if technical constraints are sufficiently relaxed. Our findings have implications for the management of creative design work and the downstream effects of the technical constraints of the information systems that support online innovation communities. ",
    "url": "https://arxiv.org/abs/2303.15163",
    "authors": [
      "Victor P. Seidel",
      "Christoph Riedl"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.15216",
    "title": "Robust Risk-Aware Option Hedging",
    "abstract": "The objectives of option hedging/trading extend beyond mere protection against downside risks, with a desire to seek gains also driving agent's strategies. In this study, we showcase the potential of robust risk-aware reinforcement learning (RL) in mitigating the risks associated with path-dependent financial derivatives. We accomplish this by leveraging the Jaimungal, Pesenti, Wang, Tatsat (2022) and their policy gradient approach, which optimises robust risk-aware performance criteria. We specifically apply this methodology to the hedging of barrier options, and highlight how the optimal hedging strategy undergoes distortions as the agent moves from being risk-averse to risk-seeking. As well as how the agent robustifies their strategy. We further investigate the performance of the hedge when the data generating process (DGP) varies from the training DGP, and demonstrate that the robust strategies outperform the non-robust ones. ",
    "url": "https://arxiv.org/abs/2303.15216",
    "authors": [
      "David Wu",
      "Sebastian Jaimungal"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2303.15319",
    "title": "Automated visual inspection of CMS HGCAL silicon sensor surface using an  ensemble of a deep convolutional autoencoder and classifier",
    "abstract": "More than a thousand 8\" silicon sensors will be visually inspected to look for anomalies on their surface during the quality control preceding assembly into the High-Granularity Calorimeter for the CMS experiment at CERN. A deep learning-based algorithm that pre-selects potentially anomalous images of the sensor surface in real time has been developed to automate the visual inspection. The anomaly detection is done by an ensemble of independent deep convolutional neural networks: an autoencoder and a classifier. The performance is evaluated on images acquired in production. The pre-selection reduces the number of images requiring human inspection by 85%, with recall of 97%. Data gathered in production can be used for continuous learning to improve the accuracy incrementally. ",
    "url": "https://arxiv.org/abs/2303.15319",
    "authors": [
      "Sonja Gr\u00f6nroos",
      "Maurizio Pierini",
      "Nadezda Chernyavskaya"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15356",
    "title": "Hypergraphx: a library for higher-order network analysis",
    "abstract": "From social to biological systems, many real-world systems are characterized by higher-order, non-dyadic interactions. Such systems are conveniently described by hypergraphs, where hyperedges encode interactions among an arbitrary number of units. Here, we present an open-source python library, hypergraphx (HGX), providing a comprehensive collection of algorithms and functions for the analysis of higher-order networks. These include different ways to convert data across distinct higher-order representations, a large variety of measures of higher-order organization at the local and the mesoscale, statistical filters to sparsify higher-order data, a wide array of static and dynamic generative models, and an implementation of different dynamical processes with higher-order interactions. Our computational framework is general, and allows to analyse hypergraphs with weighted, directed, signed, temporal and multiplex group interactions. We provide visual insights on higher-order data through a variety of different visualization tools. We accompany our code with an extended higher-order data repository, and demonstrate the ability of HGX to analyse real-world systems through a systematic analysis of a social network with higher-order interactions. The library is conceived as an evolving, community-based effort, which will further extend its functionalities over the years. Our software is available at https://github.com/HGX-Team/hypergraphx ",
    "url": "https://arxiv.org/abs/2303.15356",
    "authors": [
      "Quintino Francesco Lotito",
      "Martina Contisciani",
      "Caterina De Bacco",
      "Leonardo Di Gaetano",
      "Luca Gallo",
      "Alberto Montresor",
      "Federico Musciotto",
      "Nicol\u00f2 Ruggeri",
      "Federico Battiston"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.15364",
    "title": "Inflation forecasting with attention based transformer neural networks",
    "abstract": "Inflation is a major determinant for allocation decisions and its forecast is a fundamental aim of governments and central banks. However, forecasting inflation is not a trivial task, as its prediction relies on low frequency, highly fluctuating data with unclear explanatory variables. While classical models show some possibility of predicting inflation, reliably beating the random walk benchmark remains difficult. Recently, (deep) neural networks have shown impressive results in a multitude of applications, increasingly setting the new state-of-the-art. This paper investigates the potential of the transformer deep neural network architecture to forecast different inflation rates. The results are compared to a study on classical time series and machine learning models. We show that our adapted transformer, on average, outperforms the baseline in 6 out of 16 experiments, showing best scores in two out of four investigated inflation rates. Our results demonstrate that a transformer based neural network can outperform classical regression and machine learning models in certain inflation rates and forecasting horizons. ",
    "url": "https://arxiv.org/abs/2303.15364",
    "authors": [
      "Maximilian Tschuchnig",
      "Petra Tschuchnig",
      "Cornelia Ferner",
      "Michael Gadermayr"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15367",
    "title": "Uniformly Random Colourings of Sparse Graphs",
    "abstract": "We analyse uniformly random proper $k$-colourings of sparse graphs with maximum degree $\\Delta$ in the regime $\\Delta < k\\ln k $. This regime corresponds to the lower side of the shattering threshold for random graph colouring, a paradigmatic example of the shattering threshold for random Constraint Satisfaction Problems. We prove a variety of results about the solution space geometry of colourings of fixed graphs, generalising work of Achlioptas, Coja-Oghlan, and Molloy on random graphs, and justifying the performance of stochastic local search algorithms in this regime. Our central proof relies only on elementary techniques, namely the first-moment method and a quantitative induction, yet it strengthens list-colouring results due to Vu, and more recently Davies, Kang, P., and Sereni, and generalises state-of-the-art bounds from Ramsey theory in the context of sparse graphs. It further yields an approximately tight lower bound on the number of colourings, also known as the partition function of the Potts model, with implications for efficient approximate counting. ",
    "url": "https://arxiv.org/abs/2303.15367",
    "authors": [
      "Eoin Hurley",
      "Fran\u00e7ois Pirot"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1707.02612",
    "title": "Ramsey expansions of metrically homogeneous graphs",
    "abstract": " Comments: 59 pages, 14 figures. Minor revision, updated open problems ",
    "url": "https://arxiv.org/abs/1707.02612",
    "authors": [
      "Andr\u00e9s Aranda",
      "David Bradley-Williams",
      "Jan Hubi\u010dka",
      "Miltiadis Karamanlis",
      "Michael Kompatscher",
      "Mat\u011bj Kone\u010dn\u00fd",
      "Micheal Pawliuk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2002.12520",
    "title": "Utilizing Network Properties to Detect Erroneous Inputs",
    "abstract": " Title: Utilizing Network Properties to Detect Erroneous Inputs ",
    "url": "https://arxiv.org/abs/2002.12520",
    "authors": [
      "Matt Gorbett",
      "Nathaniel Blanchard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.07231",
    "title": "Theoretical Analyses of Multiobjective Evolutionary Algorithms on  Multimodal Objectives",
    "abstract": " Title: Theoretical Analyses of Multiobjective Evolutionary Algorithms on  Multimodal Objectives ",
    "url": "https://arxiv.org/abs/2012.07231",
    "authors": [
      "Weijie Zheng",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.02864",
    "title": "Self-Supervised Learning for Gastritis Detection with Gastric X-ray  Images",
    "abstract": " Comments: Published as a journal paper at Springer IJCARS ",
    "url": "https://arxiv.org/abs/2104.02864",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.14818",
    "title": "Traceability Technology Adoption in Supply Chain Networks",
    "abstract": " Title: Traceability Technology Adoption in Supply Chain Networks ",
    "url": "https://arxiv.org/abs/2104.14818",
    "authors": [
      "Philippe Blaettchen",
      "Andre P. Calmon",
      "Georgina Hall"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2106.10918",
    "title": "On the Impact of Multiple Source Code Representations on Software  Engineering Tasks -- An Empirical Study",
    "abstract": " Title: On the Impact of Multiple Source Code Representations on Software  Engineering Tasks -- An Empirical Study ",
    "url": "https://arxiv.org/abs/2106.10918",
    "authors": [
      "Karthik Chandra Swarna",
      "Noble Saji Mathews",
      "Dheeraj Vagavolu",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2109.12772",
    "title": "Distributionally Robust Multiclass Classification and Applications in  Deep Image Classifiers",
    "abstract": " Comments: 9 pages; Previously this version appeared as arXiv:2210.08198 which was submitted as a new work by accident ",
    "url": "https://arxiv.org/abs/2109.12772",
    "authors": [
      "Ruidi Chen",
      "Boran Hao",
      "Ioannis Paschalidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.13495",
    "title": "SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2111.13495",
    "authors": [
      "Tiange Xiang",
      "Yixiao Zhang",
      "Yongyi Lu",
      "Alan L. Yuille",
      "Chaoyi Zhang",
      "Weidong Cai",
      "Zongwei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.14944",
    "title": "Effective and Efficient PageRank-based Positioning for Graph  Visualization",
    "abstract": " Comments: The technical report of the paper entitled 'Effective and Efficient PageRank-based Positioning for Graph Visualization' in SIGMOD'23 ",
    "url": "https://arxiv.org/abs/2112.14944",
    "authors": [
      "Shiqi Zhang",
      "Renchi Yang",
      "Xiaokui Xiao",
      "Xiao Yan",
      "Bo Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.02822",
    "title": "AnomMAN: Detect Anomaly on Multi-view Attributed Networks",
    "abstract": " Comments: Accepted by the Information Sciences Journal ",
    "url": "https://arxiv.org/abs/2201.02822",
    "authors": [
      "Ling-Hao Chen",
      "He Li",
      "Wanyuan Zhang",
      "Jianbin Huang",
      "Xiaoke Ma",
      "Jiangtao Cui",
      "Ning Li",
      "Jaesoo Yoo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.07513",
    "title": "Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image  Encoders",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2201.07513",
    "authors": [
      "Zeyang Sha",
      "Xinlei He",
      "Ning Yu",
      "Michael Backes",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.07916",
    "title": "PROMPT: Learning Dynamic Resource Allocation Policies for Network  Applications",
    "abstract": " Comments: Accepted in Future Generation Computer Systems (FGCS) ",
    "url": "https://arxiv.org/abs/2201.07916",
    "authors": [
      "Drew Penney",
      "Bin Li",
      "Jaroslaw Sydir",
      "Lizhong Chen",
      "Charlie Tai",
      "Stefan Lee",
      "Eoin Walsh",
      "Thomas Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.04110",
    "title": "PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and  Loopy Belief Propagation in JAX",
    "abstract": " Comments: Update authors list ",
    "url": "https://arxiv.org/abs/2202.04110",
    "authors": [
      "Guangyao Zhou",
      "Antoine Dedieu",
      "Nishanth Kumar",
      "Wolfgang Lehrach",
      "Miguel L\u00e1zaro-Gredilla",
      "Shrinu Kushagra",
      "Dileep George"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.10543",
    "title": "Don't be a Victim During a Pandemic! Analysing Security and Privacy  Threats in Twitter During COVID-19",
    "abstract": " Comments: Paper has been accepted for publication in IEEE Access. Currently available on IEEE ACCESS early access (see DOI) ",
    "url": "https://arxiv.org/abs/2202.10543",
    "authors": [
      "Bibhas Sharma",
      "Ishan Karunanayake",
      "Rahat Masood",
      "Muhammad Ikram"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.13589",
    "title": "Unsupervised Point Cloud Representation Learning with Deep Neural  Networks: A Survey",
    "abstract": " Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence ",
    "url": "https://arxiv.org/abs/2202.13589",
    "authors": [
      "Aoran Xiao",
      "Jiaxing Huang",
      "Dayan Guan",
      "Xiaoqin Zhang",
      "Shijian Lu",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.02194",
    "title": "Rethinking Reconstruction Autoencoder-Based Out-of-Distribution  Detection",
    "abstract": " Comments: Accepted('Poster' presentation) as main conference paper of CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.02194",
    "authors": [
      "Yibo Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03407",
    "title": "Convergence of physics-informed neural networks applied to linear  second-order elliptic interface problems",
    "abstract": " Title: Convergence of physics-informed neural networks applied to linear  second-order elliptic interface problems ",
    "url": "https://arxiv.org/abs/2203.03407",
    "authors": [
      "Sidi Wu",
      "Aiqing Zhu",
      "Yifa Tang",
      "Benzhuo Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.06184",
    "title": "GSDA: A Generative Adversarial Network-based Semi-Supervised Data  Augmentation Method",
    "abstract": " Comments: 22 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2203.06184",
    "authors": [
      "Zhaoshan Liu",
      "Qiujie Lv",
      "Chau Hung Lee",
      "Lei Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09375",
    "title": "Neural Part Priors: Learning to Optimize Part-Based Object Completion in  RGB-D Scans",
    "abstract": " Comments: CVPR 2023 alexeybokhovkin.github.io/neural-part-priors/ ",
    "url": "https://arxiv.org/abs/2203.09375",
    "authors": [
      "Alexey Bokhovkin",
      "Angela Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.01150",
    "title": "Practical exponential stability of a robust data-driven nonlinear  predictive control scheme",
    "abstract": " Comments: This technical report serves as a supplementary material to our recent paper \"Data-driven Nonlinear Predictive Control for Feedback Linearizable Systems\" ",
    "url": "https://arxiv.org/abs/2204.01150",
    "authors": [
      "Mohammad Alsalti",
      "Victor G. Lopez",
      "Julian Berberich",
      "Frank Allg\u00f6wer",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.07234",
    "title": "PARC: Physics-Aware Recurrent Convolutional Neural Networks to  Assimilate Meso-scale Reactive Mechanics of Energetic Materials",
    "abstract": " Title: PARC: Physics-Aware Recurrent Convolutional Neural Networks to  Assimilate Meso-scale Reactive Mechanics of Energetic Materials ",
    "url": "https://arxiv.org/abs/2204.07234",
    "authors": [
      "Phong C.H. Nguyen",
      "Yen-Thi Nguyen",
      "Joseph B. Choi",
      "Pradeep K. Seshadri",
      "H.S. Udaykumar",
      "Stephen Baek"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.07841",
    "title": "Multi-Modal Few-Shot Object Detection with Meta-Learning-Based  Cross-Modal Prompting",
    "abstract": " Comments: 17 pages ",
    "url": "https://arxiv.org/abs/2204.07841",
    "authors": [
      "Guangxing Han",
      "Long Chen",
      "Jiawei Ma",
      "Shiyuan Huang",
      "Rama Chellappa",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2204.08504",
    "title": "CGC: Contrastive Graph Clustering for Community Detection and Tracking",
    "abstract": " Comments: TheWebConf 2022 Research Track ",
    "url": "https://arxiv.org/abs/2204.08504",
    "authors": [
      "Namyong Park",
      "Ryan Rossi",
      "Eunyee Koh",
      "Iftikhar Ahamath Burhanuddin",
      "Sungchul Kim",
      "Fan Du",
      "Nesreen Ahmed",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.10588",
    "title": "A Note on the Regularity of Images Generated by Convolutional Neural  Networks",
    "abstract": " Title: A Note on the Regularity of Images Generated by Convolutional Neural  Networks ",
    "url": "https://arxiv.org/abs/2204.10588",
    "authors": [
      "Andreas Habring",
      "Martin Holler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.10965",
    "title": "CLIP-Dissect: Automatic Description of Neuron Representations in Deep  Vision Networks",
    "abstract": " Comments: Published in ICLR 2023 Conference (Spotlight) ",
    "url": "https://arxiv.org/abs/2204.10965",
    "authors": [
      "Tuomas Oikarinen",
      "Tsui-Wei Weng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.12900",
    "title": "Cross-Camera Trajectories Help Person Retrieval in a Camera Network",
    "abstract": " Title: Cross-Camera Trajectories Help Person Retrieval in a Camera Network ",
    "url": "https://arxiv.org/abs/2204.12900",
    "authors": [
      "Xin Zhang",
      "Xiaohua Xie",
      "Jianhuang Lai",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13673",
    "title": "Diffusion of Community Fact-Checked Misinformation on Twitter",
    "abstract": " Comments: Accepted at CSCW 23 ",
    "url": "https://arxiv.org/abs/2205.13673",
    "authors": [
      "Chiara Drolsbach",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.15531",
    "title": "itKD: Interchange Transfer-based Knowledge Distillation for 3D Object  Detection",
    "abstract": " Comments: Accepted at CVPR 2023 ",
    "url": "https://arxiv.org/abs/2205.15531",
    "authors": [
      "Hyeon Cho",
      "Junyong Choi",
      "Geonwoo Baek",
      "Wonjun Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05751",
    "title": "Consistent Attack: Universal Adversarial Perturbation on Embodied Vision  Navigation",
    "abstract": " Title: Consistent Attack: Universal Adversarial Perturbation on Embodied Vision  Navigation ",
    "url": "https://arxiv.org/abs/2206.05751",
    "authors": [
      "Chengyang Ying",
      "You Qiaoben",
      "Xinning Zhou",
      "Hang Su",
      "Wenbo Ding",
      "Jianyong Ai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.06561",
    "title": "FreeKD: Free-direction Knowledge Distillation for Graph Neural Networks",
    "abstract": " Comments: Accepted to KDD 2022 ",
    "url": "https://arxiv.org/abs/2206.06561",
    "authors": [
      "Kaituo Feng",
      "Changsheng Li",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.13508",
    "title": "Data Augmentation techniques in time series domain: A survey and  taxonomy",
    "abstract": " Comments: 33 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2206.13508",
    "authors": [
      "Edgar Talavera",
      "Guillermo Iglesias",
      "\u00c1ngel Gonz\u00e1lez-Prieto",
      "Alberto Mozo",
      "Sandra G\u00f3mez-Canaval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.15025",
    "title": "On the Convergence of Distributed Stochastic Bilevel Optimization  Algorithms over a Network",
    "abstract": " Title: On the Convergence of Distributed Stochastic Bilevel Optimization  Algorithms over a Network ",
    "url": "https://arxiv.org/abs/2206.15025",
    "authors": [
      "Hongchang Gao",
      "Bin Gu",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04183",
    "title": "Learning Robust Representation for Joint Grading of Ophthalmic Diseases  via Adaptive Curriculum and Feature Disentanglement",
    "abstract": " Comments: Accepted by MICCAI22 ",
    "url": "https://arxiv.org/abs/2207.04183",
    "authors": [
      "Haoxuan Che",
      "Haibo Jin",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09644",
    "title": "Hierarchically Self-Supervised Transformer for Human Skeleton  Representation Learning",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.09644",
    "authors": [
      "Yuxiao Chen",
      "Long Zhao",
      "Jianbo Yuan",
      "Yu Tian",
      "Zhaoyang Xia",
      "Shijie Geng",
      "Ligong Han",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09655",
    "title": "Investigating the contribution of author- and publication-specific  features to scholars' h-index prediction",
    "abstract": " Comments: 14 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2207.09655",
    "authors": [
      "Fakhri Momeni",
      "Philipp Mayr",
      "Stefan Dietze"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2208.00339",
    "title": "GraphMFT: A Graph Network based Multimodal Fusion Technique for Emotion  Recognition in Conversation",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2208.00339",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.01647",
    "title": "AI-driven Hypergraph Network of Organic Chemistry: Network Statistics  and Applications in Reaction Classification",
    "abstract": " Title: AI-driven Hypergraph Network of Organic Chemistry: Network Statistics  and Applications in Reaction Classification ",
    "url": "https://arxiv.org/abs/2208.01647",
    "authors": [
      "Vipul Mann",
      "Venkat Venkatasubramanian"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2208.11682",
    "title": "Data-Driven Approach to form Energy Resilient Smart Microgrids with  Identification of Vulnerable Nodes in Active Electrical Distribution Network",
    "abstract": " Title: Data-Driven Approach to form Energy Resilient Smart Microgrids with  Identification of Vulnerable Nodes in Active Electrical Distribution Network ",
    "url": "https://arxiv.org/abs/2208.11682",
    "authors": [
      "D Maneesh Reddy",
      "Divyanshi Dwivedi",
      "Pradeep Kumar Yemula",
      "Mayukha Pal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.14558",
    "title": "Augraphy: A Data Augmentation Library for Document Images",
    "abstract": " Title: Augraphy: A Data Augmentation Library for Document Images ",
    "url": "https://arxiv.org/abs/2208.14558",
    "authors": [
      "Alexander Groleau",
      "Kok Wei Chee",
      "Stefan Larson",
      "Samay Maini",
      "Jonathan Boarman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.02792",
    "title": "Side-channel attack analysis on in-memory computing architectures",
    "abstract": " Title: Side-channel attack analysis on in-memory computing architectures ",
    "url": "https://arxiv.org/abs/2209.02792",
    "authors": [
      "Ziyu Wang",
      "Fan-hsuan Meng",
      "Yongmo Park",
      "Jason K. Eshraghian",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2209.08938",
    "title": "Accelerating Neural Network Inference with Processing-in-DRAM: From the  Edge to the Cloud",
    "abstract": " Comments: This is an extended and updated version of a paper published in IEEE Micro, pp. 1-14, 29 Aug. 2022. arXiv admin note: text overlap with arXiv:2109.14320 ",
    "url": "https://arxiv.org/abs/2209.08938",
    "authors": [
      "Geraldo F. Oliveira",
      "Juan G\u00f3mez-Luna",
      "Saugata Ghose",
      "Amirali Boroumand",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01781",
    "title": "COPILOT: Human-Environment Collision Prediction and Localization from  Egocentric Videos",
    "abstract": " Title: COPILOT: Human-Environment Collision Prediction and Localization from  Egocentric Videos ",
    "url": "https://arxiv.org/abs/2210.01781",
    "authors": [
      "Boxiao Pan",
      "Bokui Shen",
      "Davis Rempe",
      "Despoina Paschalidou",
      "Kaichun Mo",
      "Yanchao Yang",
      "Leonidas J. Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.07453",
    "title": "Using Graph Algorithms to Pretrain Graph Completion Transformers",
    "abstract": " Title: Using Graph Algorithms to Pretrain Graph Completion Transformers ",
    "url": "https://arxiv.org/abs/2210.07453",
    "authors": [
      "Jonathan Pilault",
      "Michael Galkin",
      "Bahare Fatemi",
      "Perouz Taslakian",
      "David Vasquez",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08198",
    "title": "Distributionally Robust Multiclass Classification and Applications in  Deep Image Classifiers",
    "abstract": " Comments: This work was intended as a replacement of arXiv:2109.12772 and any subsequent updates will appear there ",
    "url": "https://arxiv.org/abs/2210.08198",
    "authors": [
      "Ruidi Chen",
      "Boran Hao",
      "Ioannis Ch. Paschalidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09693",
    "title": "TFAD: A Decomposition Time Series Anomaly Detection Architecture with  Time-Frequency Analysis",
    "abstract": " Comments: Accepted by the ACM International Conference on Information and Knowledge Management (CIKM 2022) ",
    "url": "https://arxiv.org/abs/2210.09693",
    "authors": [
      "Chaoli Zhang",
      "Tian Zhou",
      "Qingsong Wen",
      "Liang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10260",
    "title": "End-to-End Entity Detection with Proposer and Regressor",
    "abstract": " Title: End-to-End Entity Detection with Proposer and Regressor ",
    "url": "https://arxiv.org/abs/2210.10260",
    "authors": [
      "Xueru Wen",
      "Changjiang Zhou",
      "Haotian Tang",
      "Luguang Liang",
      "Yu Jiang",
      "Hong Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.10535",
    "title": "Stability of Entropic Wasserstein Barycenters and application to random  geometric graphs",
    "abstract": " Title: Stability of Entropic Wasserstein Barycenters and application to random  geometric graphs ",
    "url": "https://arxiv.org/abs/2210.10535",
    "authors": [
      "Marc Theveneau",
      "Nicolas Keriven"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Other Statistics (stat.OT)"
    ]
  },
  {
    "id": "arXiv:2210.11620",
    "title": "LOT: Layer-wise Orthogonal Training on Improving $\\ell_2$ Certified  Robustness",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.11620",
    "authors": [
      "Xiaojun Xu",
      "Linyi Li",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.12101",
    "title": "Neural Network Approximations of PDEs Beyond Linearity: A  Representational Perspective",
    "abstract": " Title: Neural Network Approximations of PDEs Beyond Linearity: A  Representational Perspective ",
    "url": "https://arxiv.org/abs/2210.12101",
    "authors": [
      "Tanya Marwah",
      "Zachary C. Lipton",
      "Jianfeng Lu",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.16046",
    "title": "Rawgment: Noise-Accounted RAW Augmentation Enables Recognition in a Wide  Variety of Environments",
    "abstract": " Comments: Accepted to CVPR2023 ",
    "url": "https://arxiv.org/abs/2210.16046",
    "authors": [
      "Masakazu Yoshimura",
      "Junji Otsuka",
      "Atsushi Irie",
      "Takeshi Ohashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.04154",
    "title": "Russian propaganda on social media during the 2022 invasion of Ukraine",
    "abstract": " Title: Russian propaganda on social media during the 2022 invasion of Ukraine ",
    "url": "https://arxiv.org/abs/2211.04154",
    "authors": [
      "Dominique Geissler",
      "Dominik B\u00e4r",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.04188",
    "title": "DepthFormer: Multimodal Positional Encodings and Cross-Input Attention  for Transformer-Based Segmentation Networks",
    "abstract": " Comments: Accepted at ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.04188",
    "authors": [
      "Francesco Barbato",
      "Giulia Rizzoli",
      "Pietro Zanuttigh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05975",
    "title": "From RDMA to RDCA: Toward High-Speed Last Mile of Data Center Networks  Using Remote Direct Cache Access",
    "abstract": " Title: From RDMA to RDCA: Toward High-Speed Last Mile of Data Center Networks  Using Remote Direct Cache Access ",
    "url": "https://arxiv.org/abs/2211.05975",
    "authors": [
      "Qiang Li",
      "Qiao Xiang",
      "Derui Liu",
      "Yuxin Wang",
      "Haonan Qiu",
      "Xiaoliang Wang",
      "Jie Zhang",
      "Ridi Wen",
      "Haohao Song",
      "Gexiao Tian",
      "Chenyang Huang",
      "Lulu Chen",
      "Shaozong Liu",
      "Yaohui Wu",
      "Zhiwu Wu",
      "Zicheng Luo",
      "Yuchao Shao",
      "Chao Han",
      "Zhongjie Wu",
      "Jianbo Dong",
      "Zheng Cao",
      "Jinbo Wu",
      "Jiwu Shu",
      "Jiesheng Wu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.06315",
    "title": "Fraudulent User Detection Via Behavior Information Aggregation Network  (BIAN) On Large-Scale Financial Social Network",
    "abstract": " Comments: 6 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2211.06315",
    "authors": [
      "Hanyi Hu",
      "Long Zhang",
      "Shuan Li",
      "Zhi Liu",
      "Yao Yang",
      "Chongning Na"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.06885",
    "title": "SCOTCH and SODA: A Transformer Video Shadow Detection Framework",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2211.06885",
    "authors": [
      "Lihao Liu",
      "Jean Prost",
      "Lei Zhu",
      "Nicolas Papadakis",
      "Pietro Li\u00f2",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Angelica I Aviles-Rivero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.07341",
    "title": "Stability and Robustness of Distributed Suboptimal Model Predictive  Control",
    "abstract": " Title: Stability and Robustness of Distributed Suboptimal Model Predictive  Control ",
    "url": "https://arxiv.org/abs/2211.07341",
    "authors": [
      "Giuseppe Belgioioso",
      "Dominic Liao-McPherson",
      "Mathias Hudoba de Badyn",
      "Nicolas Pelzmann",
      "John Lygeros",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.07717",
    "title": "Deep Temporal Modelling of Clinical Depression through Social Media Text",
    "abstract": " Comments: Typos and minor errors fixed from earlier versions and corresponding PhD thesis chapter ",
    "url": "https://arxiv.org/abs/2211.07717",
    "authors": [
      "Nawshad Farruque",
      "Randy Goebel",
      "Sudhakar Sivapalan",
      "Osmar R. Za\u00efane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11177",
    "title": "NeuMap: Neural Coordinate Mapping by Auto-Transdecoder for Camera  Localization",
    "abstract": " Comments: CVPR2023 ",
    "url": "https://arxiv.org/abs/2211.11177",
    "authors": [
      "Shitao Tang",
      "Sicong Tang",
      "Andrea Tagliasacchi",
      "Ping Tan",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11646",
    "title": "NeRF-RPN: A general framework for object detection in NeRFs",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2211.11646",
    "authors": [
      "Benran Hu",
      "Junkai Huang",
      "Yichen Liu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12018",
    "title": "Level-S$^2$fM: Structure from Motion on Neural Level Set of Implicit  Surfaces",
    "abstract": " Comments: camera-ready version (CVPR 2023). Project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.12018",
    "authors": [
      "Yuxi Xiao",
      "Nan Xue",
      "Tianfu Wu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12285",
    "title": "Exact-NeRF: An Exploration of a Precise Volumetric Parameterization for  Neural Radiance Fields",
    "abstract": " Comments: 15 pages,10 figures ",
    "url": "https://arxiv.org/abs/2211.12285",
    "authors": [
      "Brian K. S. Isaac-Medina",
      "Chris G. Willcocks",
      "Toby P. Breckon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.13769",
    "title": "On Designing Light-Weight Object Trackers through Network Pruning: Use  CNNs or Transformers?",
    "abstract": " Comments: Accepted at IEEE ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.13769",
    "authors": [
      "Saksham Aggarwal",
      "Taneesh Gupta",
      "Pawan Kumar Sahu",
      "Arnav Chavan",
      "Rishabh Tiwari",
      "Dilip K. Prasad",
      "Deepak K. Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14905",
    "title": "Multi-Modal Few-Shot Temporal Action Detection",
    "abstract": " Comments: Technical Report ",
    "url": "https://arxiv.org/abs/2211.14905",
    "authors": [
      "Sauradip Nag",
      "Mengmeng Xu",
      "Xiatian Zhu",
      "Juan-Manuel Perez-Rua",
      "Bernard Ghanem",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.15069",
    "title": "FeatureBooster: Boosting Feature Descriptors with a Lightweight Neural  Network",
    "abstract": " Comments: Accept by CVPR2023; 15 pages, 8 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2211.15069",
    "authors": [
      "Xinjiang Wang",
      "Zeyu Liu",
      "Yu Hu",
      "Wei Xi",
      "Wenxian Yu",
      "Danping Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15608",
    "title": "Representation with Incomplete Votes",
    "abstract": " Title: Representation with Incomplete Votes ",
    "url": "https://arxiv.org/abs/2211.15608",
    "authors": [
      "Daniel Halpern",
      "Gregory Kehne",
      "Ariel D. Procaccia",
      "Jamie Tucker-Foltz",
      "Manuel W\u00fcthrich"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2211.15755",
    "title": "Confidence-Aware Graph Neural Networks for Learning Reliability  Assessment Commitments",
    "abstract": " Comments: Submitted to IEEE Transactions on Power Systems ",
    "url": "https://arxiv.org/abs/2211.15755",
    "authors": [
      "Seonho Park",
      "Wenbo Chen",
      "Dahye Han",
      "Mathieu Tanneau",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.17174",
    "title": "Optimizing Explanations by Network Canonization and Hyperparameter  Search",
    "abstract": " Title: Optimizing Explanations by Network Canonization and Hyperparameter  Search ",
    "url": "https://arxiv.org/abs/2211.17174",
    "authors": [
      "Frederik Pahde",
      "Galip \u00dcmit Yolcu",
      "Alexander Binder",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01117",
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2212.01117",
    "authors": [
      "Hongzhan Lin",
      "Pengyao Yi",
      "Jing Ma",
      "Haiyun Jiang",
      "Ziyang Luo",
      "Shuming Shi",
      "Ruifang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.01985",
    "title": "ObjectMatch: Robust Registration using Canonical Object Correspondences",
    "abstract": " Comments: Project Page: this http URL Video: this https URL ",
    "url": "https://arxiv.org/abs/2212.01985",
    "authors": [
      "Can G\u00fcmeli",
      "Angela Dai",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05189",
    "title": "Expanding Knowledge Graphs with Humans in the Loop",
    "abstract": " Title: Expanding Knowledge Graphs with Humans in the Loop ",
    "url": "https://arxiv.org/abs/2212.05189",
    "authors": [
      "Emaad Manzoor",
      "Jordan Tong",
      "Sriniketh Vijayaraghavan",
      "Rui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.06344",
    "title": "DA Wand: Distortion-Aware Selection using Neural Mesh Parameterization",
    "abstract": " Comments: Project page: this https URL Code: this https URL ",
    "url": "https://arxiv.org/abs/2212.06344",
    "authors": [
      "Richard Liu",
      "Noam Aigerman",
      "Vladimir G. Kim",
      "Rana Hanocka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.07048",
    "title": "PD-Quant: Post-Training Quantization based on Prediction Difference  Metric",
    "abstract": " Title: PD-Quant: Post-Training Quantization based on Prediction Difference  Metric ",
    "url": "https://arxiv.org/abs/2212.07048",
    "authors": [
      "Jiawei Liu",
      "Lin Niu",
      "Zhihang Yuan",
      "Dawei Yang",
      "Xinggang Wang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.10066",
    "title": "RepMode: Learning to Re-parameterize Diverse Experts for Subcellular  Structure Prediction",
    "abstract": " Comments: Accepted by CVPR2023 (Highlight) ",
    "url": "https://arxiv.org/abs/2212.10066",
    "authors": [
      "Donghao Zhou",
      "Chunbin Gu",
      "Junde Xu",
      "Furui Liu",
      "Qiong Wang",
      "Guangyong Chen",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.12130",
    "title": "Learning to Detect and Segment for Open Vocabulary Object Detection",
    "abstract": " Comments: code will be available later ",
    "url": "https://arxiv.org/abs/2212.12130",
    "authors": [
      "Tao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.12380",
    "title": "Towards Scalable Physically Consistent Neural Networks: an Application  to Data-driven Multi-zone Thermal Building Models",
    "abstract": " Comments: Submitted to Applied Energy ",
    "url": "https://arxiv.org/abs/2212.12380",
    "authors": [
      "Loris Di Natale",
      "Bratislav Svetozarevic",
      "Philipp Heer",
      "Colin Neil Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.14694",
    "title": "Machine Learning as an Accurate Predictor for Percolation Threshold of  Diverse Networks",
    "abstract": " Title: Machine Learning as an Accurate Predictor for Percolation Threshold of  Diverse Networks ",
    "url": "https://arxiv.org/abs/2212.14694",
    "authors": [
      "Siddharth Patwardhan",
      "Utso Majumder",
      "Aditya Das Sarma",
      "Mayukha Pal",
      "Divyanshi Dwivedi",
      "Prasanta K. Panigrahi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.00896",
    "title": "Efficient Robustness Assessment via Adversarial Spatial-Temporal Focus  on Videos",
    "abstract": " Comments: accepted by TPAMI2023 ",
    "url": "https://arxiv.org/abs/2301.00896",
    "authors": [
      "Wei Xingxing",
      "Wang Songping",
      "Yan Huanqian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.06077",
    "title": "MN-Pair Contrastive Damage Representation and Clustering for Prognostic  Explanation",
    "abstract": " Comments: 8 pages, 10 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2301.06077",
    "authors": [
      "Takato Yasuno",
      "Masahiro Okano",
      "Junichiro Fujii"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.06287",
    "title": "A Multi-Platform Collection of Social Media Posts about the 2022 U.S.  Midterm Elections",
    "abstract": " Comments: 8 pages, 3 figures, forthcoming in ICWSM23 ",
    "url": "https://arxiv.org/abs/2301.06287",
    "authors": [
      "Rachith Aiyappa",
      "Matthew R. DeVerna",
      "Manita Pote",
      "Bao Tran Truong",
      "Wanying Zhao",
      "David Axelrod",
      "Aria Pessianzadeh",
      "Zoher Kachwala",
      "Munjung Kim",
      "Ozgur Can Seckin",
      "Minsuk Kim",
      "Sunny Gandhi",
      "Amrutha Manikonda",
      "Francesco Pierri",
      "Filippo Menczer",
      "Kai-Cheng Yang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.09632",
    "title": "HexPlane: A Fast Representation for Dynamic Scenes",
    "abstract": " Comments: CVPR 2023, Camera Ready Project page: this https URL ",
    "url": "https://arxiv.org/abs/2301.09632",
    "authors": [
      "Ang Cao",
      "Justin Johnson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.10034",
    "title": "Open-World Multi-Task Control Through Goal-Aware Representation Learning  and Adaptive Horizon Prediction",
    "abstract": " Comments: This paper is accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2301.10034",
    "authors": [
      "Shaofei Cai",
      "Zihao Wang",
      "Xiaojian Ma",
      "Anji Liu",
      "Yitao Liang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.10405",
    "title": "Editing Language Model-based Knowledge Graph Embeddings",
    "abstract": " Comments: Work in progress and the project website is this https URL ",
    "url": "https://arxiv.org/abs/2301.10405",
    "authors": [
      "Siyuan Cheng",
      "Ningyu Zhang",
      "Bozhong Tian",
      "Zelin Dai",
      "Feiyu Xiong",
      "Wei Guo",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11517",
    "title": "Task-Agnostic Graph Neural Network Evaluation via Adversarial  Collaboration",
    "abstract": " Comments: 11th International Conference on Learning Representations (ICLR 2023) Machine Learning for Drug Discovery (MLDD) Workshop. 17 pages, 6 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2301.11517",
    "authors": [
      "Xiangyu Zhao",
      "Hannes St\u00e4rk",
      "Dominique Beaini",
      "Yiren Zhao",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12896",
    "title": "Identifying Adversarially Attackable and Robust Samples",
    "abstract": " Title: Identifying Adversarially Attackable and Robust Samples ",
    "url": "https://arxiv.org/abs/2301.12896",
    "authors": [
      "Vyas Raina",
      "Mark Gales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.03665",
    "title": "HumanMAC: Masked Motion Completion for Human Motion Prediction",
    "abstract": " Title: HumanMAC: Masked Motion Completion for Human Motion Prediction ",
    "url": "https://arxiv.org/abs/2302.03665",
    "authors": [
      "Ling-Hao Chen",
      "Jiawei Zhang",
      "Yewen Li",
      "Yiren Pang",
      "Xiaobo Xia",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.03744",
    "title": "3D Neural Embedding Likelihood for Robust Probabilistic Inverse Graphics",
    "abstract": " Title: 3D Neural Embedding Likelihood for Robust Probabilistic Inverse Graphics ",
    "url": "https://arxiv.org/abs/2302.03744",
    "authors": [
      "Guangyao Zhou",
      "Nishad Gothoskar",
      "Lirui Wang",
      "Joshua B. Tenenbaum",
      "Dan Gutfreund",
      "Miguel L\u00e1zaro-Gredilla",
      "Dileep George",
      "Vikash K. Mansinghka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.06086",
    "title": "Reliability Assurance for Deep Neural Network Architectures Against  Numerical Defects",
    "abstract": " Comments: To appear at 45th International Conference on Software Engineering (ICSE 2023), camera-ready version ",
    "url": "https://arxiv.org/abs/2302.06086",
    "authors": [
      "Linyi Li",
      "Yuhao Zhang",
      "Luyao Ren",
      "Yingfei Xiong",
      "Tao Xie"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2302.07106",
    "title": "Normalizing Flow based Feature Synthesis for Outlier-Aware Object  Detection",
    "abstract": " Comments: Accepted as CVPR 2023 Highlight (Top 10% of all acceptance) ",
    "url": "https://arxiv.org/abs/2302.07106",
    "authors": [
      "Nishant Kumar",
      "Sini\u0161a \u0160egvi\u0107",
      "Abouzar Eslami",
      "Stefan Gumhold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.13056",
    "title": "SATBA: An Invisible Backdoor Attack Based On Spatial Attention",
    "abstract": " Comments: 15 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2302.13056",
    "authors": [
      "Huasong Zhou",
      "Xiaowei Xu",
      "Xiaodong Wang",
      "Leon Bevan Bullock"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.14348",
    "title": "Im2Hands: Learning Attentive Implicit Representation of Interacting  Two-Hand Shapes",
    "abstract": " Comments: 6 figures, 14 pages, accepted to CVPR 2023, project page: this https URL ",
    "url": "https://arxiv.org/abs/2302.14348",
    "authors": [
      "Jihyun Lee",
      "Minhyuk Sung",
      "Honggyu Choi",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.00246",
    "title": "ISBNet: a 3D Point Cloud Instance Segmentation Network with  Instance-aware Sampling and Box-aware Dynamic Convolution",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.00246",
    "authors": [
      "Tuan Duc Ngo",
      "Binh-Son Hua",
      "Khoi Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.00917",
    "title": "Enhancing General Face Forgery Detection via Vision Transformer with  Low-Rank Adaptation",
    "abstract": " Title: Enhancing General Face Forgery Detection via Vision Transformer with  Low-Rank Adaptation ",
    "url": "https://arxiv.org/abs/2303.00917",
    "authors": [
      "Chenqi Kong",
      "Haoliang Li",
      "Shiqi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.02375",
    "title": "NeuDA: Neural Deformable Anchor for High-Fidelity Implicit Surface  Reconstruction",
    "abstract": " Comments: Accepted to CVPR 2023, project page: this https URL ",
    "url": "https://arxiv.org/abs/2303.02375",
    "authors": [
      "Bowen Cai",
      "Jinchi Huang",
      "Rongfei Jia",
      "Chengfei Lv",
      "Huan Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04643",
    "title": "Robust Adaptive Control of STATCOMs to Mitigate Inverter-Based-Resource  (IBR)-Induced Oscillations",
    "abstract": " Title: Robust Adaptive Control of STATCOMs to Mitigate Inverter-Based-Resource  (IBR)-Induced Oscillations ",
    "url": "https://arxiv.org/abs/2303.04643",
    "authors": [
      "Hui Yuan",
      "Huanhai Xin",
      "Linbin Huang",
      "Huisheng Gao",
      "Jikui Xing",
      "Di Zheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.06060",
    "title": "Deep Spiking Neural Networks with High Representation Similarity Model  Visual Pathways of Macaque and Mouse",
    "abstract": " Comments: Accepted by Proceedings of the 37th AAAI Conference on Artificial Intelligence (AAAI-23) ",
    "url": "https://arxiv.org/abs/2303.06060",
    "authors": [
      "Liwei Huang",
      "Zhengyu Ma",
      "Liutao Yu",
      "Huihui Zhou",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.08435",
    "title": "Physics-Informed Optical Kernel Regression Using Complex-valued Neural  Fields",
    "abstract": " Comments: Accepted by DAC23 ",
    "url": "https://arxiv.org/abs/2303.08435",
    "authors": [
      "Guojin Chen",
      "Zehua Pei",
      "Haoyu Yang",
      "Yuzhe Ma",
      "Bei Yu",
      "Martin D. F. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.09495",
    "title": "Among Us: Adversarially Robust Collaborative Perception by Consensus",
    "abstract": " Title: Among Us: Adversarially Robust Collaborative Perception by Consensus ",
    "url": "https://arxiv.org/abs/2303.09495",
    "authors": [
      "Yiming Li",
      "Qi Fang",
      "Jiamu Bai",
      "Siheng Chen",
      "Felix Juefei-Xu",
      "Chen Feng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.09632",
    "title": "Conflict Optimization for Binary CSP Applied to Minimum Partition into  Plane Subgraphs and Graph Coloring",
    "abstract": " Comments: To appear at ACM Journal of Experimental Algorithmics ",
    "url": "https://arxiv.org/abs/2303.09632",
    "authors": [
      "Lo\u00efc Crombez",
      "Guilherme D. da Fonseca",
      "Florian Fontan",
      "Yan Gerard",
      "Aldo Gonzalez-Lorenzo",
      "Pascal Lafourcade",
      "Luc Libralesso",
      "Benjamin Mom\u00e8ge",
      "Jack Spalding-Jamieson",
      "Brandon Zhang",
      "Da Wei Zheng"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.10276",
    "title": "Unleashing the Potential of Spiking Neural Networks by Dynamic  Confidence",
    "abstract": " Title: Unleashing the Potential of Spiking Neural Networks by Dynamic  Confidence ",
    "url": "https://arxiv.org/abs/2303.10276",
    "authors": [
      "Chen Li",
      "Edward Jones",
      "Steve Furber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.10312",
    "title": "EGTSyn: Edge-based Graph Transformer for Anti-Cancer Drug Combination  Synergy Prediction",
    "abstract": " Comments: 15 pages,4 figures,6 tables ",
    "url": "https://arxiv.org/abs/2303.10312",
    "authors": [
      "Jie Hu",
      "Xiaozhi Zhang",
      "Desi Shang",
      "Lijun Ouyang",
      "Yue Li",
      "Dongping Xiong"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.10644",
    "title": "Spatio-Temporal AU Relational Graph Representation Learning For Facial  Action Units Detection",
    "abstract": " Title: Spatio-Temporal AU Relational Graph Representation Learning For Facial  Action Units Detection ",
    "url": "https://arxiv.org/abs/2303.10644",
    "authors": [
      "Zihan Wang",
      "Siyang Song",
      "Cheng Luo",
      "Yuzhi Zhou",
      "Shiling Wu",
      "Weicheng Xie",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10752",
    "title": "Fully Self-Supervised Depth Estimation from Defocus Clue",
    "abstract": " Comments: CVPR 2023 camera-ready version. The code is released at this https URL ",
    "url": "https://arxiv.org/abs/2303.10752",
    "authors": [
      "Haozhe Si",
      "Bin Zhao",
      "Dong Wang",
      "Yunpeng Gao",
      "Mulin Chen",
      "Zhigang Wang",
      "Xuelong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10876",
    "title": "EqMotion: Equivariant Multi-agent Motion Prediction with Invariant  Interaction Reasoning",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.10876",
    "authors": [
      "Chenxin Xu",
      "Robby T. Tan",
      "Yuhong Tan",
      "Siheng Chen",
      "Yu Guang Wang",
      "Xinchao Wang",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.10953",
    "title": "An Error-Correction Model for Information Transmissions of Social  Networks",
    "abstract": " Comments: 13 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2303.10953",
    "authors": [
      "Daqi",
      "Fang",
      "Pin-Chieh Tseng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.10967",
    "title": "Real-time 3D Semantic Scene Completion Via Feature Aggregation and  Conditioned Prediction",
    "abstract": " Comments: Accepted by ICIP ",
    "url": "https://arxiv.org/abs/2303.10967",
    "authors": [
      "Xiaokang Chen",
      "Yajie Xing",
      "Gang Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11207",
    "title": "Investigating Topological Order using Recurrent Neural Networks",
    "abstract": " Comments: 14 pages, 7 figures, 1 table. A version with new corrections ",
    "url": "https://arxiv.org/abs/2303.11207",
    "authors": [
      "Mohamed Hibat-Allah",
      "Roger G. Melko",
      "Juan Carrasquilla"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2303.11231",
    "title": "Bounded twin-width graphs are polynomially $\u03c7$-bounded",
    "abstract": " Title: Bounded twin-width graphs are polynomially $\u03c7$-bounded ",
    "url": "https://arxiv.org/abs/2303.11231",
    "authors": [
      "Romain Bourneuf",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.11511",
    "title": "STDLens: Model Hijacking-Resilient Federated Learning for Object  Detection",
    "abstract": " Comments: CVPR 2023. Source Code: this https URL ",
    "url": "https://arxiv.org/abs/2303.11511",
    "authors": [
      "Ka-Ho Chow",
      "Ling Liu",
      "Wenqi Wei",
      "Fatih Ilhan",
      "Yanzhao Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11749",
    "title": "Detecting Everything in the Open World: Towards Universal Object  Detection",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.11749",
    "authors": [
      "Zhenyu Wang",
      "Yali Li",
      "Xi Chen",
      "Ser-Nam Lim",
      "Antonio Torralba",
      "Hengshuang Zhao",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11754",
    "title": "Projections of Model Spaces for Latent Graph Inference",
    "abstract": " Comments: Accepted at the ICLR 2023 Workshop on Physics for Machine Learning ",
    "url": "https://arxiv.org/abs/2303.11754",
    "authors": [
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "\u00c1lvaro Arroyo",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11969",
    "title": "Explain To Me: Salience-Based Explainability for Synthetic Face  Detection Models",
    "abstract": " Comments: 13 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2303.11969",
    "authors": [
      "Colton Crum",
      "Patrick Tinsley",
      "Aidan Boyd",
      "Jacob Piland",
      "Christopher Sweet",
      "Timothy Kelley",
      "Kevin Bowyer",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12054",
    "title": "Influencer Backdoor Attack on Semantic Segmentation",
    "abstract": " Title: Influencer Backdoor Attack on Semantic Segmentation ",
    "url": "https://arxiv.org/abs/2303.12054",
    "authors": [
      "Haoheng Lan",
      "Jindong Gu",
      "Philip Torr",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12313",
    "title": "Distribution Aligned Diffusion and Prototype-guided network for  Unsupervised Domain Adaptive Segmentation",
    "abstract": " Title: Distribution Aligned Diffusion and Prototype-guided network for  Unsupervised Domain Adaptive Segmentation ",
    "url": "https://arxiv.org/abs/2303.12313",
    "authors": [
      "Haipeng Zhou",
      "Lei Zhu",
      "Yuyin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12398",
    "title": "Multiscale Attention via Wavelet Neural Operators for Vision  Transformers",
    "abstract": " Title: Multiscale Attention via Wavelet Neural Operators for Vision  Transformers ",
    "url": "https://arxiv.org/abs/2303.12398",
    "authors": [
      "Anahita Nekoozadeh",
      "Mohammad Reza Ahmadzadeh",
      "Zahra Mardani",
      "Morteza Mardani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12423",
    "title": "Text with Knowledge Graph Augmented Transformer for Video Captioning",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.12423",
    "authors": [
      "Xin Gu",
      "Guang Chen",
      "Yufei Wang",
      "Libo Zhang",
      "Tiejian Luo",
      "Longyin Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12848",
    "title": "Test-time Defense against Adversarial Attacks: Detection and  Reconstruction of Adversarial Examples via Masked Autoencoder",
    "abstract": " Title: Test-time Defense against Adversarial Attacks: Detection and  Reconstruction of Adversarial Examples via Masked Autoencoder ",
    "url": "https://arxiv.org/abs/2303.12848",
    "authors": [
      "Yun-Yun Tsai",
      "Ju-Chin Chao",
      "Albert Wen",
      "Zhaoyuan Yang",
      "Chengzhi Mao",
      "Tapan Shah",
      "Junfeng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.13818",
    "title": "Prior-RadGraphFormer: A Prior-Knowledge-Enhanced Transformer for  Generating Radiology Graphs from X-Rays",
    "abstract": " Comments: 12 pages, 4 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2303.13818",
    "authors": [
      "Yiheng Xiong",
      "Jingsong Liu",
      "Kamilia Zaripova",
      "Sahand Sharifzadeh",
      "Matthias Keicher",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.13937",
    "title": "Topological Reconstruction of Particle Physics Processes using Graph  Neural Networks",
    "abstract": " Comments: 24 pages, 24 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2303.13937",
    "authors": [
      "Lukas Ehrke",
      "John Andrew Raine",
      "Knut Zoch",
      "Manuel Guth",
      "Tobias Golling"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2303.13992",
    "title": "Physical Backdoor Trigger Activation of Autonomous Vehicle using  Reachability Analysis",
    "abstract": " Title: Physical Backdoor Trigger Activation of Autonomous Vehicle using  Reachability Analysis ",
    "url": "https://arxiv.org/abs/2303.13992",
    "authors": [
      "Wenqing Li",
      "Yue Wang",
      "Muhammad Shafique",
      "Saif Eddin Jabari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.14077",
    "title": "Improved Adversarial Training Through Adaptive Instance-wise Loss  Smoothing",
    "abstract": " Comments: 12 pages, work in submission ",
    "url": "https://arxiv.org/abs/2303.14077",
    "authors": [
      "Lin Li",
      "Michael Spratling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14092",
    "title": "NeuFace: Realistic 3D Neural Face Rendering from Multi-view Images",
    "abstract": " Comments: Accepted to CVPR 2023, code is released at this https URL ",
    "url": "https://arxiv.org/abs/2303.14092",
    "authors": [
      "Mingwu Zheng",
      "Haiyu Zhang",
      "Hongyu Yang",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]