[
  {
    "id": "arXiv:2303.09590",
    "title": "Visual Analytics of Multivariate Networks with Representation Learning  and Composite Variable Construction",
    "abstract": "Multivariate networks are commonly found in real-world data-driven applications. Uncovering and understanding the relations of interest in multivariate networks is not a trivial task. This paper presents a visual analytics workflow for studying multivariate networks to extract associations between different structural and semantic characteristics of the networks (e.g., what are the combinations of attributes largely relating to the density of a social network?). The workflow consists of a neural-network-based learning phase to classify the data based on the chosen input and output attributes, a dimensionality reduction and optimization phase to produce a simplified set of results for examination, and finally an interpreting phase conducted by the user through an interactive visualization interface. A key part of our design is a composite variable construction step that remodels nonlinear features obtained by neural networks into linear features that are intuitive to interpret. We demonstrate the capabilities of this workflow with multiple case studies on networks derived from social media usage and also evaluate the workflow through an expert interview. ",
    "url": "https://arxiv.org/abs/2303.09590",
    "authors": [
      "Hsiao-Ying Lu",
      "Takanori Fujiwara",
      "Ming-Yi Chang",
      "Yang-chih Fu",
      "Anders Ynnerman",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09599",
    "title": "cito: An R package for training neural networks using torch",
    "abstract": "1. Deep neural networks (DNN) have become a central class of algorithms for regression and classification tasks. Although some packages exist that allow users to specify DNN in R, those are rather limited in their functionality. Most current deep learning applications therefore rely on one of the major deep learning frameworks, PyTorch or TensorFlow, to build and train DNN. However, using these frameworks requires substantially more training and time than comparable regression or machine learning packages in the R environment. 2. Here, we present cito, an user-friendly R package for deep learning. cito allows R users to specify deep neural networks in the familiar formula syntax used by most modeling functions in R. In the background, cito uses torch to fit the models, taking advantage of all the numerical optimizations of the torch library, including the ability to switch between training models on CPUs or GPUs. Moreover, cito includes many user-friendly functions for predictions and an explainable Artificial Intelligence (xAI) pipeline for the fitted models. 3. We showcase a typical analysis pipeline using cito, including its built-in xAI features to explore the trained DNN, by building a species distribution model of the African elephant. 4. In conclusion, cito provides a user-friendly R framework to specify, deploy and interpret deep neural networks based on torch. The current stable CRAN version mainly supports fully connected DNNs, but it is planned that future versions will also include CNNs and RNNs. ",
    "url": "https://arxiv.org/abs/2303.09599",
    "authors": [
      "Christian Amesoeder",
      "Florian Hartig",
      "Maximilian Pichler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09607",
    "title": "A Novel Scholar Embedding Model for Interdisciplinary Collaboration",
    "abstract": "Interdisciplinary collaboration has become a driving force for scientific breakthroughs, and evaluating scholars' performance in interdisciplinary researches is essential for promoting such collaborations.However, traditional scholar evaluation methods based solely on individual achievements do not consider interdisciplinary cooperation, creating a challenge for interdisciplinary scholar evaluation and recommendation. To address this issue, we propose a scholar embedding model that quantifies and represents scholars based on global semantic information and social influence, enabling real-time tracking of scholars' research trends. Our model incorporates semantic information and social influence for interdisciplinary scholar evaluation, laying the foundation for future interdisciplinary collaboration discovery and recommendation projects. We demonstrate the effectiveness of our model on a sample of scholars from the Beijing University of Posts and Telecommunications. ",
    "url": "https://arxiv.org/abs/2303.09607",
    "authors": [
      "Yitong Hu",
      "Zixuan Zhu",
      "Yizhe Wang",
      "Junxiang Wang",
      "Zehao Xing",
      "Binzhu Xie"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.09608",
    "title": "VEIL: Vetting Extracted Image Labels from In-the-Wild Captions for  Weakly-Supervised Object Detection",
    "abstract": "The use of large-scale vision-language datasets is limited for object detection due to the negative impact of label noise on localization. Prior methods have shown how such large-scale datasets can be used for pretraining, which can provide initial signal for localization, but is insufficient without clean bounding-box data for at least some categories. We propose a technique to \"vet\" labels extracted from noisy captions. Our method trains a classifier that predicts if an extracted label is actually present in the image or not. Our classifier generalizes across dataset boundaries and shows promise for generalizing across categories as well. We compare the classifier to eleven baselines on five datasets, and demonstrate that it can improve weakly-supervised detection without label vetting by 80% (16.0 to 29.1 mAP when evaluated on PASCAL VOC). ",
    "url": "https://arxiv.org/abs/2303.09608",
    "authors": [
      "Arushi Rai",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09617",
    "title": "Measuring Improvement of F$_1$-Scores in Detection of Self-Admitted  Technical Debt",
    "abstract": "Artificial Intelligence and Machine Learning have witnessed rapid, significant improvements in Natural Language Processing (NLP) tasks. Utilizing Deep Learning, researchers have taken advantage of repository comments in Software Engineering to produce accurate methods for detecting Self-Admitted Technical Debt (SATD) from 20 open-source Java projects' code. In this work, we improve SATD detection with a novel approach that leverages the Bidirectional Encoder Representations from Transformers (BERT) architecture. For comparison, we re-evaluated previous deep learning methods and applied stratified 10-fold cross-validation to report reliable F$_1$-scores. We examine our model in both cross-project and intra-project contexts. For each context, we use re-sampling and duplication as augmentation strategies to account for data imbalance. We find that our trained BERT model improves over the best performance of all previous methods in 19 of the 20 projects in cross-project scenarios. However, the data augmentation techniques were not sufficient to overcome the lack of data present in the intra-project scenarios, and existing methods still perform better. Future research will look into ways to diversify SATD datasets in order to maximize the latent power in large BERT models. ",
    "url": "https://arxiv.org/abs/2303.09617",
    "authors": [
      "William Aiken",
      "Paul K. Mvula",
      "Paula Branco",
      "Guy-Vincent Jourdan",
      "Mehrdad Sabetzadeh",
      "Herna Viktor"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09632",
    "title": "Conflict Optimization for Binary CSP Applied to Minimum Partition into  Plane Subgraphs and Graph Coloring",
    "abstract": "CG:SHOP is an annual geometric optimization challenge and the 2022 edition proposed the problem of coloring a certain geometric graph defined by line segments. Surprisingly, the top three teams used the same technique, called conflict optimization. This technique has been introduced in the 2021 edition of the challenge, to solve a coordinated motion planning problem. In this paper, we present the technique in the more general framework of binary constraint satisfaction problems (binary CSP). Then, the top three teams describe their different implementations of the same underlying strategy. We evaluate the performance of those implementations to vertex color not only geometric graphs, but also other types of graphs. ",
    "url": "https://arxiv.org/abs/2303.09632",
    "authors": [
      "Lo\u00efc Crombez",
      "Guilherme D. da Fonseca",
      "Florian Fontan",
      "Yan Gerard",
      "Aldo Gonzalez-Lorenzo",
      "Pascal Lafourcade",
      "Luc Libralesso",
      "Benjamin Mom\u00e8ge",
      "Jack Spalding-Jamieso",
      "Brandon Zhang",
      "Da Wei Zheng"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.09634",
    "title": "Causal Temporal Graph Convolutional Neural Networks (CTGCN)",
    "abstract": "Many large-scale applications can be elegantly represented using graph structures. Their scalability, however, is often limited by the domain knowledge required to apply them. To address this problem, we propose a novel Causal Temporal Graph Convolutional Neural Network (CTGCN). Our CTGCN architecture is based on a causal discovery mechanism, and is capable of discovering the underlying causal processes. The major advantages of our approach stem from its ability to overcome computational scalability problems with a divide and conquer technique, and from the greater explainability of predictions made using a causal model. We evaluate the scalability of our CTGCN on two datasets to demonstrate that our method is applicable to large scale problems, and show that the integration of causality into the TGCN architecture improves prediction performance up to 40% over typical TGCN approach. Our results are obtained without requiring additional domain knowledge, making our approach adaptable to various domains, specifically when little contextual knowledge is available. ",
    "url": "https://arxiv.org/abs/2303.09634",
    "authors": [
      "Abigail Langbridge",
      "Fearghal O'Donncha",
      "Amadou Ba",
      "Fabio Lorenzi",
      "Christopher Lohse",
      "Joern Ploennigs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09639",
    "title": "Neural Architecture Search for Effective Teacher-Student Knowledge  Transfer in Language Models",
    "abstract": "Large pre-trained language models have achieved state-of-the-art results on a variety of downstream tasks. Knowledge Distillation (KD) of a smaller student model addresses their inefficiency, allowing for deployment in resource-constraint environments. KD however remains ineffective, as the student is manually selected from a set of existing options already pre-trained on large corpora, a sub-optimal choice within the space of all possible student architectures. This paper proposes KD-NAS, the use of Neural Architecture Search (NAS) guided by the Knowledge Distillation process to find the optimal student model for distillation from a teacher, for a given natural language task. In each episode of the search process, a NAS controller predicts a reward based on a combination of accuracy on the downstream task and latency of inference. The top candidate architectures are then distilled from the teacher on a small proxy set. Finally the architecture(s) with the highest reward is selected, and distilled on the full downstream task training set. When distilling on the MNLI task, our KD-NAS model produces a 2 point improvement in accuracy on GLUE tasks with equivalent GPU latency with respect to a hand-crafted student architecture available in the literature. Using Knowledge Distillation, this model also achieves a 1.4x speedup in GPU Latency (3.2x speedup on CPU) with respect to a BERT-Base Teacher, while maintaining 97% performance on GLUE Tasks (without CoLA). We also obtain an architecture with equivalent performance as the hand-crafted student model on the GLUE benchmark, but with a 15% speedup in GPU latency (20% speedup in CPU latency) and 0.8 times the number of parameters ",
    "url": "https://arxiv.org/abs/2303.09639",
    "authors": [
      "Aashka Trivedi",
      "Takuma Udagawa",
      "Michele Merler",
      "Rameswar Panda",
      "Yousef El-Kurdi",
      "Bishwaranjan Bhattacharjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.09648",
    "title": "Shifted-Windows Transformers for the Detection of Cerebral Aneurysms in  Microsurgery",
    "abstract": "Purpose: Microsurgical Aneurysm Clipping Surgery (MACS) carries a high risk for intraoperative aneurysm rupture. Automated recognition of instances when the aneurysm is exposed in the surgical video would be a valuable reference point for neuronavigation, indicating phase transitioning and more importantly designating moments of high risk for rupture. This article introduces the MACS dataset containing 16 surgical videos with frame-level expert annotations and proposes a learning methodology for surgical scene understanding identifying video frames with the aneurysm present in the operating microscope's field-of-view. Methods: Despite the dataset imbalance (80% no presence, 20% presence) and developed without explicit annotations, we demonstrate the applicability of Transformer-based deep learning architectures (MACSSwin-T, vidMACSSwin-T) to detect the aneurysm and classify MACS frames accordingly. We evaluate the proposed models in multiple-fold cross-validation experiments with independent sets and in an unseen set of 15 images against 10 human experts (neurosurgeons). Results: Average (across folds) accuracy of 80.8% (range 78.5%-82.4%) and 87.1% (range 85.1%-91.3%) is obtained for the image- and video-level approach respectively, demonstrating that the models effectively learn the classification task. Qualitative evaluation of the models' class activation maps show these to be localized on the aneurysm's actual location. Depending on the decision threshold, MACSWin-T achieves 66.7% to 86.7% accuracy in the unseen images, compared to 82% of human raters, with moderate to strong correlation. ",
    "url": "https://arxiv.org/abs/2303.09648",
    "authors": [
      "Jinfan Zhou",
      "William Muirhead",
      "Simon C. Williams",
      "Danail Stoyanov",
      "Hani J. Marcus",
      "Evangelos B. Mazomenos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09656",
    "title": "Adult readers evaluating the credibility of social media posts: Prior  belief consistency and source's expertise matter most",
    "abstract": "The present study investigates the role of source characteristics, the quality of evidence, and prior beliefs of the topic in adult readers' credibility evaluations of short health-related social media posts. The researchers designed content for the posts concerning five health topics by manipulating the source characteristics (source's expertise, gender, and ethnicity), the accuracy of the claims, and the quality of evidence (research evidence, testimony, consensus, and personal experience) of the posts. After this, accurate and inaccurate social media posts varying in the other manipulated aspects were programmatically generated. The crowdworkers (N = 844) recruited from two platforms were asked to evaluate the credibility of up to ten social media posts, resulting in 8380 evaluations. Before credibility evaluation, participants' prior beliefs on the topics of the posts were assessed. The results showed that prior belief consistency and the source's expertise affected the perceived credibility of the accurate and inaccurate social media posts the most after controlling for the topic of the post and the crowdworking platform. In contrast, the quality of evidence supporting the health claim mattered relatively little. The source's gender and ethnicity did not have any effect. The results are discussed in terms of first- and second-hand evaluation strategies. ",
    "url": "https://arxiv.org/abs/2303.09656",
    "authors": [
      "Miikka Kuutila",
      "Carita Kiili",
      "Reijo Kupiainen",
      "Eetu Huusko",
      "Li Junhao",
      "Simo Hosio",
      "Mika M\u00e4ntyl\u00e4",
      "Kristian Kiili"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.09660",
    "title": "Explainable GeoAI: Can saliency maps help interpret artificial  intelligence's learning process? An empirical study on natural feature  detection",
    "abstract": "Improving the interpretability of geospatial artificial intelligence (GeoAI) models has become critically important to open the \"black box\" of complex AI models, such as deep learning. This paper compares popular saliency map generation techniques and their strengths and weaknesses in interpreting GeoAI and deep learning models' reasoning behaviors, particularly when applied to geospatial analysis and image processing tasks. We surveyed two broad classes of model explanation methods: perturbation-based and gradient-based methods. The former identifies important image areas, which help machines make predictions by modifying a localized area of the input image. The latter evaluates the contribution of every single pixel of the input image to the model's prediction results through gradient backpropagation. In this study, three algorithms-the occlusion method, the integrated gradients method, and the class activation map method-are examined for a natural feature detection task using deep learning. The algorithms' strengths and weaknesses are discussed, and the consistency between model-learned and human-understandable concepts for object recognition is also compared. The experiments used two GeoAI-ready datasets to demonstrate the generalizability of the research findings. ",
    "url": "https://arxiv.org/abs/2303.09660",
    "authors": [
      "Chia-Yu Hsu",
      "Wenwen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09668",
    "title": "Rt-Track: Robust Tricks for Multi-Pedestrian Tracking",
    "abstract": "Object tracking is divided into single-object tracking (SOT) and multi-object tracking (MOT). MOT aims to maintain the identities of multiple objects across a series of continuous video sequences. In recent years, MOT has made rapid progress. However, modeling the motion and appearance models of objects in complex scenes still faces various challenging issues. In this paper, we design a novel direction consistency method for smooth trajectory prediction (STP-DC) to increase the modeling of motion information and overcome the lack of robustness in previous methods in complex scenes. Existing methods use pedestrian re-identification (Re-ID) to model appearance, however, they extract more background information which lacks discriminability in occlusion and crowded scenes. We propose a hyper-grain feature embedding network (HG-FEN) to enhance the modeling of appearance models, thus generating robust appearance descriptors. We also proposed other robustness techniques, including CF-ECM for storing robust appearance information and SK-AS for improving association accuracy. To achieve state-of-the-art performance in MOT, we propose a robust tracker named Rt-track, incorporating various tricks and techniques. It achieves 79.5 MOTA, 76.0 IDF1 and 62.1 HOTA on the test set of MOT17.Rt-track also achieves 77.9 MOTA, 78.4 IDF1 and 63.3 HOTA on MOT20, surpassing all published methods. ",
    "url": "https://arxiv.org/abs/2303.09668",
    "authors": [
      "Yukuan Zhang",
      "Yunhua Jia",
      "Housheng Xie",
      "Mengzhen Li",
      "Limin Zhao",
      "Yang Yang",
      "Shan Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09674",
    "title": "DiGeo: Discriminative Geometry-Aware Learning for Generalized Few-Shot  Object Detection",
    "abstract": "Generalized few-shot object detection aims to achieve precise detection on both base classes with abundant annotations and novel classes with limited training data. Existing approaches enhance few-shot generalization with the sacrifice of base-class performance, or maintain high precision in base-class detection with limited improvement in novel-class adaptation. In this paper, we point out the reason is insufficient Discriminative feature learning for all of the classes. As such, we propose a new training framework, DiGeo, to learn Geometry-aware features of inter-class separation and intra-class compactness. To guide the separation of feature clusters, we derive an offline simplex equiangular tight frame (ETF) classifier whose weights serve as class centers and are maximally and equally separated. To tighten the cluster for each class, we include adaptive class-specific margins into the classification loss and encourage the features close to the class centers. Experimental studies on two few-shot benchmark datasets (VOC, COCO) and one long-tail dataset (LVIS) demonstrate that, with a single model, our method can effectively improve generalization on novel classes without hurting the detection of base classes. ",
    "url": "https://arxiv.org/abs/2303.09674",
    "authors": [
      "Jiawei Ma",
      "Yulei Niu",
      "Jincheng Xu",
      "Shiyuan Huang",
      "Guangxing Han",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09677",
    "title": "Instance-Conditioned GAN Data Augmentation for Representation Learning",
    "abstract": "Data augmentation has become a crucial component to train state-of-the-art visual representation models. However, handcrafting combinations of transformations that lead to improved performances is a laborious task, which can result in visually unrealistic samples. To overcome these limitations, recent works have explored the use of generative models as learnable data augmentation tools, showing promising results in narrow application domains, e.g., few-shot learning and low-data medical imaging. In this paper, we introduce a data augmentation module, called DA_IC-GAN, which leverages instance-conditioned GAN generations and can be used off-the-shelf in conjunction with most state-of-the-art training recipes. We showcase the benefits of DA_IC-GAN by plugging it out-of-the-box into the supervised training of ResNets and DeiT models on the ImageNet dataset, and achieving accuracy boosts up to between 1%p and 2%p with the highest capacity models. Moreover, the learnt representations are shown to be more robust than the baselines when transferred to a handful of out-of-distribution datasets, and exhibit increased invariance to variations of instance and viewpoints. We additionally couple DA_IC-GAN with a self-supervised training recipe and show that we can also achieve an improvement of 1%p in accuracy in some settings. With this work, we strengthen the evidence on the potential of learnable data augmentations to improve visual representation learning, paving the road towards non-handcrafted augmentations in model training. ",
    "url": "https://arxiv.org/abs/2303.09677",
    "authors": [
      "Pietro Astolfi",
      "Arantxa Casanova",
      "Jakob Verbeek",
      "Pascal Vincent",
      "Adriana Romero-Soriano",
      "Michal Drozdzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09678",
    "title": "Neural Lyapunov Control for Nonlinear Systems with Unstructured  Uncertainties",
    "abstract": "Stabilizing controller design and region of attraction (RoA) estimation are essential in nonlinear control. Moreover, it is challenging to implement a control Lyapunov function (CLF) in practice when only partial knowledge of the system is available. We propose a learning framework that can synthesize state-feedback controllers and a CLF for control-affine nonlinear systems with unstructured uncertainties. Based on a regularity condition on these uncertainties, we model them as bounded disturbances and prove that a CLF for the nominal system (estimate of the true system) is an input-to-state stable control Lyapunov function (ISS-CLF) for the true system when the CLF's gradient is bounded. We integrate the robust Lyapunov analysis with the learning of both the control law and CLF. We demonstrate the effectiveness of our learning framework on several examples, such as an inverted pendulum system, a strict-feedback system, and a cart-pole system. ",
    "url": "https://arxiv.org/abs/2303.09678",
    "authors": [
      "Shiqing Wei",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.09700",
    "title": "Delayed and Indirect Impacts of Link Recommendations",
    "abstract": "The impacts of link recommendations on social networks are challenging to evaluate, and so far they have been studied in limited settings. Observational studies are restricted in the kinds of causal questions they can answer and naive A/B tests often lead to biased evaluations due to unaccounted network interference. Furthermore, evaluations in simulation settings are often limited to static network models that do not take into account the potential feedback loops between link recommendation and organic network evolution. To this end, we study the impacts of recommendations on social networks in dynamic settings. Adopting a simulation-based approach, we consider an explicit dynamic formation model -- an extension of the celebrated Jackson-Rogers model -- and investigate how link recommendations affect network evolution over time. Empirically, we find that link recommendations have surprising delayed and indirect effects on the structural properties of networks. Specifically, we find that link recommendations can exhibit considerably different impacts in the immediate term and in the long term. For instance, we observe that friend-of-friend recommendations can have an immediate effect in decreasing degree inequality, but in the long term, they can make the degree distribution substantially more unequal. Moreover, we show that the effects of recommendations can persist in networks, in part due to their indirect impacts on natural dynamics even after recommendations are turned off. We show that, in counterfactual simulations, removing the indirect effects of link recommendations can make the network trend faster toward what it would have been under natural growth dynamics. ",
    "url": "https://arxiv.org/abs/2303.09700",
    "authors": [
      "Han Zhang",
      "Shangen Lu",
      "Yixin Wang",
      "Mihaela Curmei"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2303.09703",
    "title": "A Bi-LSTM Autoencoder Framework for Anomaly Detection -- A Case Study of  a Wind Power Dataset",
    "abstract": "Anomalies refer to data points or events that deviate from normal and homogeneous events, which can include fraudulent activities, network infiltrations, equipment malfunctions, process changes, or other significant but infrequent events. Prompt detection of such events can prevent potential losses in terms of finances, information, and human resources. With the advancement of computational capabilities and the availability of large datasets, anomaly detection has become a major area of research. Among these, anomaly detection in time series has gained more attention recently due to the added complexity imposed by the time dimension. This study presents a novel framework for time series anomaly detection using a combination of Bidirectional Long Short Term Memory (Bi-LSTM) architecture and Autoencoder. The Bi-LSTM network, which comprises two unidirectional LSTM networks, can analyze the time series data from both directions and thus effectively discover the long-term dependencies hidden in the sequential data. Meanwhile, the Autoencoder mechanism helps to establish the optimal threshold beyond which an event can be classified as an anomaly. To demonstrate the effectiveness of the proposed framework, it is applied to a real-world multivariate time series dataset collected from a wind farm. The Bi-LSTM Autoencoder model achieved a classification accuracy of 96.79% and outperformed more commonly used LSTM Autoencoder models. ",
    "url": "https://arxiv.org/abs/2303.09703",
    "authors": [
      "Ahmed Shoyeb Raihan",
      "Imtiaz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09706",
    "title": "Unsupervised Self-Driving Attention Prediction via Uncertainty Mining  and Knowledge Embedding",
    "abstract": "Predicting attention regions of interest is an important yet challenging task for self-driving systems. Existing methodologies rely on large-scale labeled traffic datasets that are labor-intensive to obtain. Besides, the huge domain gap between natural scenes and traffic scenes in current datasets also limits the potential for model training. To address these challenges, we are the first to introduce an unsupervised way to predict self-driving attention by uncertainty modeling and driving knowledge integration. Our approach's Uncertainty Mining Branch (UMB) discovers commonalities and differences from multiple generated pseudo-labels achieved from models pre-trained on natural scenes by actively measuring the uncertainty. Meanwhile, our Knowledge Embedding Block (KEB) bridges the domain gap by incorporating driving knowledge to adaptively refine the generated pseudo-labels. Quantitative and qualitative results with equivalent or even more impressive performance compared to fully-supervised state-of-the-art approaches across all three public datasets demonstrate the effectiveness of the proposed method and the potential of this direction. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2303.09706",
    "authors": [
      "Pengfei Zhu",
      "Mengshi Qi",
      "Xia Li",
      "Weijian Li",
      "Huadong Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09719",
    "title": "Learning towards Selective Data Augmentation for Dialogue Generation",
    "abstract": "As it is cumbersome and expensive to acquire a huge amount of data for training neural dialog models, data augmentation is proposed to effectively utilize existing training samples. However, current data augmentation techniques on the dialog generation task mostly augment all cases in the training dataset without considering the intrinsic attributes between different cases. We argue that not all cases are beneficial for augmentation task, and the cases suitable for augmentation should obey the following two attributes: (1) low-quality (the dialog model cannot generate a high-quality response for the case), (2) representative (the case should represent the property of the whole dataset). Herein, we explore this idea by proposing a Selective Data Augmentation framework (SDA) for the response generation task. SDA employs a dual adversarial network to select the lowest quality and most representative data points for augmentation in one stage. Extensive experiments conducted on two publicly available datasets, \\ie DailyDialog and OpenSubtitles, show that our framework can improve the response generation performance with respect to various metrics. ",
    "url": "https://arxiv.org/abs/2303.09719",
    "authors": [
      "Xiuying Chen",
      "Mingzhe Li",
      "Jiayi Zhang",
      "Xiaoqiang Xia",
      "Chen Wei",
      "Jianwei Cui",
      "Xin Gao",
      "Xiangliang Zhang",
      "Rui Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.09728",
    "title": "The Cascaded Forward Algorithm for Neural Network Training",
    "abstract": "Backpropagation algorithm has been widely used as a mainstream learning procedure for neural networks in the past decade, and has played a significant role in the development of deep learning. However, there exist some limitations associated with this algorithm, such as getting stuck in local minima and experiencing vanishing/exploding gradients, which have led to questions about its biological plausibility. To address these limitations, alternative algorithms to backpropagation have been preliminarily explored, with the Forward-Forward (FF) algorithm being one of the most well-known. In this paper we propose a new learning framework for neural networks, namely Cascaded Forward (CaFo) algorithm, which does not rely on BP optimization as that in FF. Unlike FF, our framework directly outputs label distributions at each cascaded block, which does not require generation of additional negative samples and thus leads to a more efficient process at both training and testing. Moreover, in our framework each block can be trained independently, so it can be easily deployed into parallel acceleration systems. The proposed method is evaluated on four public image classification benchmarks, and the experimental results illustrate significant improvement in prediction accuracy in comparison with the baseline. ",
    "url": "https://arxiv.org/abs/2303.09728",
    "authors": [
      "Gongpei Zhao",
      "Tao Wang",
      "Yidong Li",
      "Yi Jin",
      "Congyan Lang",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09731",
    "title": "Exorcising ''Wraith'': Protecting LiDAR-based Object Detector in  Automated Driving System from Appearing Attacks",
    "abstract": "Automated driving systems rely on 3D object detectors to recognize possible obstacles from LiDAR point clouds. However, recent works show the adversary can forge non-existent cars in the prediction results with a few fake points (i.e., appearing attack). By removing statistical outliers, existing defenses are however designed for specific attacks or biased by predefined heuristic rules. Towards more comprehensive mitigation, we first systematically inspect the mechanism of recent appearing attacks: Their common weaknesses are observed in crafting fake obstacles which (i) have obvious differences in the local parts compared with real obstacles and (ii) violate the physical relation between depth and point density. In this paper, we propose a novel plug-and-play defensive module which works by side of a trained LiDAR-based object detector to eliminate forged obstacles where a major proportion of local parts have low objectness, i.e., to what degree it belongs to a real object. At the core of our module is a local objectness predictor, which explicitly incorporates the depth information to model the relation between depth and point density, and predicts each local part of an obstacle with an objectness score. Extensive experiments show, our proposed defense eliminates at least 70% cars forged by three known appearing attacks in most cases, while, for the best previous defense, less than 30% forged cars are eliminated. Meanwhile, under the same circumstance, our defense incurs less overhead for AP/precision on cars compared with existing defenses. Furthermore, We validate the effectiveness of our proposed defense on simulation-based closed-loop control driving tests in the open-source system of Baidu's Apollo. ",
    "url": "https://arxiv.org/abs/2303.09731",
    "authors": [
      "Qifan Xiao",
      "Xudong Pan",
      "Yifan Lu",
      "Mi Zhang",
      "Jiarun Dai",
      "Min Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09732",
    "title": "Rethinking White-Box Watermarks on Deep Learning Models under Neural  Structural Obfuscation",
    "abstract": "Copyright protection for deep neural networks (DNNs) is an urgent need for AI corporations. To trace illegally distributed model copies, DNN watermarking is an emerging technique for embedding and verifying secret identity messages in the prediction behaviors or the model internals. Sacrificing less functionality and involving more knowledge about the target DNN, the latter branch called \\textit{white-box DNN watermarking} is believed to be accurate, credible and secure against most known watermark removal attacks, with emerging research efforts in both the academy and the industry. In this paper, we present the first systematic study on how the mainstream white-box DNN watermarks are commonly vulnerable to neural structural obfuscation with \\textit{dummy neurons}, a group of neurons which can be added to a target model but leave the model behavior invariant. Devising a comprehensive framework to automatically generate and inject dummy neurons with high stealthiness, our novel attack intensively modifies the architecture of the target model to inhibit the success of watermark verification. With extensive evaluation, our work for the first time shows that nine published watermarking schemes require amendments to their verification procedures. ",
    "url": "https://arxiv.org/abs/2303.09732",
    "authors": [
      "Yifan Yan",
      "Xudong Pan",
      "Mi Zhang",
      "Min Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09733",
    "title": "Scribble-Supervised RGB-T Salient Object Detection",
    "abstract": "Salient object detection segments attractive objects in scenes. RGB and thermal modalities provide complementary information and scribble annotations alleviate large amounts of human labor. Based on the above facts, we propose a scribble-supervised RGB-T salient object detection model. By a four-step solution (expansion, prediction, aggregation, and supervision), label-sparse challenge of scribble-supervised method is solved. To expand scribble annotations, we collect the superpixels that foreground scribbles pass through in RGB and thermal images, respectively. The expanded multi-modal labels provide the coarse object boundary. To further polish the expanded labels, we propose a prediction module to alleviate the sharpness of boundary. To play the complementary roles of two modalities, we combine the two into aggregated pseudo labels. Supervised by scribble annotations and pseudo labels, our model achieves the state-of-the-art performance on the relabeled RGBT-S dataset. Furthermore, the model is applied to RGB-D and video scribble-supervised applications, achieving consistently excellent performance. ",
    "url": "https://arxiv.org/abs/2303.09733",
    "authors": [
      "Zhengyi Liu",
      "Xiaoshen Huang",
      "Guanghui Zhang",
      "Xianyong Fang",
      "Linbo Wang",
      "Bin Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09757",
    "title": "Video Dehazing via a Multi-Range Temporal Alignment Network with  Physical Prior",
    "abstract": "Video dehazing aims to recover haze-free frames with high visibility and contrast. This paper presents a novel framework to effectively explore the physical haze priors and aggregate temporal information. Specifically, we design a memory-based physical prior guidance module to encode the prior-related features into long-range memory. Besides, we formulate a multi-range scene radiance recovery module to capture space-time dependencies in multiple space-time ranges, which helps to effectively aggregate temporal information from adjacent frames. Moreover, we construct the first large-scale outdoor video dehazing benchmark dataset, which contains videos in various real-world scenarios. Experimental results on both synthetic and real conditions show the superiority of our proposed method. ",
    "url": "https://arxiv.org/abs/2303.09757",
    "authors": [
      "Jiaqi Xu",
      "Xiaowei Hu",
      "Lei Zhu",
      "Qi Dou",
      "Jifeng Dai",
      "Yu Qiao",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09758",
    "title": "Hierarchical Prior Mining for Non-local Multi-View Stereo",
    "abstract": "As a fundamental problem in computer vision, multi-view stereo (MVS) aims at recovering the 3D geometry of a target from a set of 2D images. Recent advances in MVS have shown that it is important to perceive non-local structured information for recovering geometry in low-textured areas. In this work, we propose a Hierarchical Prior Mining for Non-local Multi-View Stereo (HPM-MVS). The key characteristics are the following techniques that exploit non-local information to assist MVS: 1) A Non-local Extensible Sampling Pattern (NESP), which is able to adaptively change the size of sampled areas without becoming snared in locally optimal solutions. 2) A new approach to leverage non-local reliable points and construct a planar prior model based on K-Nearest Neighbor (KNN), to obtain potential hypotheses for the regions where prior construction is challenging. 3) A Hierarchical Prior Mining (HPM) framework, which is used to mine extensive non-local prior information at different scales to assist 3D model recovery, this strategy can achieve a considerable balance between the reconstruction of details and low-textured areas. Experimental results on the ETH3D and Tanks \\& Temples have verified the superior performance and strong generalization capability of our method. Our code will be released. ",
    "url": "https://arxiv.org/abs/2303.09758",
    "authors": [
      "Chunlin Ren",
      "Qingshan Xu",
      "Shikun Zhang",
      "Jiaqi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09761",
    "title": "Goldfish: Peer selection using Matrix completion in unstructured P2P  network",
    "abstract": "Peer-to-peer (P2P) networks underlie a variety of decentralized paradigms including blockchains, distributed file storage and decentralized domain name systems. A central primitive in P2P networks is the peer selection algorithm, which decides how a node should select a fixed number of neighbors to connect with. In this paper, we consider the design of a peer-selection algorithm for unstructured P2P networks with the goal of minimizing the broadcast latency. We propose Goldfish, a novel solution that dynamically decides the neighbor set by exploiting the past experiences as well as exploring new neighbors. The key technical contributions come from bringing ideas of matrix completion for estimating message delivery times for every possible message for every peer ever connected, and a streaming algorithm to efficiently perform the estimation while achieving good performance. The matrix completion interpolates the delivery times to all virtual connections in order to select the best combination of neighbors. Goldfish employs a streaming algorithm that only uses a short recent memory to finish matrix interpolation. When the number of publishing source is equal to a node's maximal number of connections, Goldfish found the global optimal solution with 92.7% probability by exploring every node only once. In more complex situations where nodes are publishing based on exponential distribution and adjusting connection in real time, we compare Goldfish with a baseline peer selection system, and show Goldfish saves approximately 14.5% less time under real world geolocation and propagation latency. ",
    "url": "https://arxiv.org/abs/2303.09761",
    "authors": [
      "Bowen Xue",
      "Yifan Mao",
      "Shaileshh Bojja Venkatakrishnan",
      "Sreeram Kannan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.09767",
    "title": "It Is All About Data: A Survey on the Effects of Data on Adversarial  Robustness",
    "abstract": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to confuse the model into making a mistake. Such examples pose a serious threat to the applicability of machine-learning-based systems, especially in life- and safety-critical domains. To address this problem, the area of adversarial robustness investigates mechanisms behind adversarial attacks and defenses against these attacks. This survey reviews literature that focuses on the effects of data used by a model on the model's adversarial robustness. It systematically identifies and summarizes the state-of-the-art research in this area and further discusses gaps of knowledge and promising future research directions. ",
    "url": "https://arxiv.org/abs/2303.09767",
    "authors": [
      "Peiyu Xiong",
      "Michael Tegegn",
      "Jaskeerat Singh Sarin",
      "Shubhraneel Pal",
      "Julia Rubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.09769",
    "title": "Denoising Diffusion Autoencoders are Unified Self-supervised Learners",
    "abstract": "Inspired by recent advances in diffusion models, which are reminiscent of denoising autoencoders, we investigate whether they can acquire discriminative representations for classification via generative pre-training. This paper shows that the networks in diffusion models, namely denoising diffusion autoencoders (DDAE), are unified self-supervised learners: by pre-training on unconditional image generation, DDAE has already learned strongly linear-separable representations at its intermediate layers without auxiliary encoders, thus making diffusion pre-training emerge as a general approach for self-supervised generative and discriminative learning. To verify this, we perform linear probe and fine-tuning evaluations on multi-class datasets. Our diffusion-based approach achieves 95.9% and 50.0% linear probe accuracies on CIFAR-10 and Tiny-ImageNet, respectively, and is comparable to masked autoencoders and contrastive learning for the first time. Additionally, transfer learning from ImageNet confirms DDAE's suitability for latent-space Vision Transformers, suggesting the potential for scaling DDAEs as unified foundation models. ",
    "url": "https://arxiv.org/abs/2303.09769",
    "authors": [
      "Weilai Xiang",
      "Hongyu Yang",
      "Di Huang",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09778",
    "title": "SE-GSL: A General and Effective Graph Structure Learning Framework  through Structural Entropy Optimization",
    "abstract": "Graph Neural Networks (GNNs) are de facto solutions to structural data learning. However, it is susceptible to low-quality and unreliable structure, which has been a norm rather than an exception in real-world graphs. Existing graph structure learning (GSL) frameworks still lack robustness and interpretability. This paper proposes a general GSL framework, SE-GSL, through structural entropy and the graph hierarchy abstracted in the encoding tree. Particularly, we exploit the one-dimensional structural entropy to maximize embedded information content when auxiliary neighbourhood attributes are fused to enhance the original graph. A new scheme of constructing optimal encoding trees is proposed to minimize the uncertainty and noises in the graph whilst assuring proper community partition in hierarchical abstraction. We present a novel sample-based mechanism for restoring the graph structure via node structural entropy distribution. It increases the connectivity among nodes with larger uncertainty in lower-level communities. SE-GSL is compatible with various GNN models and enhances the robustness towards noisy and heterophily structures. Extensive experiments show significant improvements in the effectiveness and robustness of structure learning and node representation learning. ",
    "url": "https://arxiv.org/abs/2303.09778",
    "authors": [
      "Dongcheng Zou",
      "Hao Peng",
      "Xiang Huang",
      "Renyu Yang",
      "Jianxin Li",
      "Jia Wu",
      "Chunyang Liu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09782",
    "title": "High Accurate and Explainable Multi-Pill Detection Framework with Graph  Neural Network-Assisted Multimodal Data Fusion",
    "abstract": "Due to the significant resemblance in visual appearance, pill misuse is prevalent and has become a critical issue, responsible for one-third of all deaths worldwide. Pill identification, thus, is a crucial concern needed to be investigated thoroughly. Recently, several attempts have been made to exploit deep learning to tackle the pill identification problem. However, most published works consider only single-pill identification and fail to distinguish hard samples with identical appearances. Also, most existing pill image datasets only feature single pill images captured in carefully controlled environments under ideal lighting conditions and clean backgrounds. In this work, we are the first to tackle the multi-pill detection problem in real-world settings, aiming at localizing and identifying pills captured by users in a pill intake. Moreover, we also introduce a multi-pill image dataset taken in unconstrained conditions. To handle hard samples, we propose a novel method for constructing heterogeneous a priori graphs incorporating three forms of inter-pill relationships, including co-occurrence likelihood, relative size, and visual semantic correlation. We then offer a framework for integrating a priori with pills' visual features to enhance detection accuracy. Our experimental results have proved the robustness, reliability, and explainability of the proposed framework. Experimentally, it outperforms all detection benchmarks in terms of all evaluation metrics. Specifically, our proposed framework improves COCO mAP metrics by 9.4% over Faster R-CNN and 12.0% compared to vanilla YOLOv5. Our study opens up new opportunities for protecting patients from medication errors using an AI-based pill identification solution. ",
    "url": "https://arxiv.org/abs/2303.09782",
    "authors": [
      "Anh Duy Nguyen",
      "Huy Hieu Pham",
      "Huynh Thanh Trung",
      "Quoc Viet Hung Nguyen",
      "Thao Nguyen Truong",
      "Phi Le Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09789",
    "title": "Urban Regional Function Guided Traffic Flow Prediction",
    "abstract": "The prediction of traffic flow is a challenging yet crucial problem in spatial-temporal analysis, which has recently gained increasing interest. In addition to spatial-temporal correlations, the functionality of urban areas also plays a crucial role in traffic flow prediction. However, the exploration of regional functional attributes mainly focuses on adding additional topological structures, ignoring the influence of functional attributes on regional traffic patterns. Different from the existing works, we propose a novel module named POI-MetaBlock, which utilizes the functionality of each region (represented by Point of Interest distribution) as metadata to further mine different traffic characteristics in areas with different functions. Specifically, the proposed POI-MetaBlock employs a self-attention architecture and incorporates POI and time information to generate dynamic attention parameters for each region, which enables the model to fit different traffic patterns of various areas at different times. Furthermore, our lightweight POI-MetaBlock can be easily integrated into conventional traffic flow prediction models. Extensive experiments demonstrate that our module significantly improves the performance of traffic flow prediction and outperforms state-of-the-art methods that use metadata. ",
    "url": "https://arxiv.org/abs/2303.09789",
    "authors": [
      "Kuo Wang",
      "Lingbo Liu",
      "Yang Liu",
      "Guanbin Li",
      "Fan Zhou",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09800",
    "title": "GOOD: General Optimization-based Fusion for 3D Object Detection via  LiDAR-Camera Object Candidates",
    "abstract": "3D object detection serves as the core basis of the perception tasks in autonomous driving. Recent years have seen the rapid progress of multi-modal fusion strategies for more robust and accurate 3D object detection. However, current researches for robust fusion are all learning-based frameworks, which demand a large amount of training data and are inconvenient to implement in new scenes. In this paper, we propose GOOD, a general optimization-based fusion framework that can achieve satisfying detection without training additional models and is available for any combinations of 2D and 3D detectors to improve the accuracy and robustness of 3D detection. First we apply the mutual-sided nearest-neighbor probability model to achieve the 3D-2D data association. Then we design an optimization pipeline that can optimize different kinds of instances separately based on the matching result. Apart from this, the 3D MOT method is also introduced to enhance the performance aided by previous frames. To the best of our knowledge, this is the first optimization-based late fusion framework for multi-modal 3D object detection which can be served as a baseline for subsequent research. Experiments on both nuScenes and KITTI datasets are carried out and the results show that GOOD outperforms by 9.1\\% on mAP score compared with PointPillars and achieves competitive results with the learning-based late fusion CLOCs. ",
    "url": "https://arxiv.org/abs/2303.09800",
    "authors": [
      "Bingqi Shen",
      "Shuwei Dai",
      "Yuyin Chen",
      "Rong Xiong",
      "Yue Wang",
      "Yanmei Jiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.09801",
    "title": "Adaptive Graph Convolution Module for Salient Object Detection",
    "abstract": "Salient object detection (SOD) is a task that involves identifying and segmenting the most visually prominent object in an image. Existing solutions can accomplish this use a multi-scale feature fusion mechanism to detect the global context of an image. However, as there is no consideration of the structures in the image nor the relations between distant pixels, conventional methods cannot deal with complex scenes effectively. In this paper, we propose an adaptive graph convolution module (AGCM) to overcome these limitations. Prototype features are initially extracted from the input image using a learnable region generation layer that spatially groups features in the image. The prototype features are then refined by propagating information between them based on a graph architecture, where each feature is regarded as a node. Experimental results show that the proposed AGCM dramatically improves the SOD performance both quantitatively and quantitatively. ",
    "url": "https://arxiv.org/abs/2303.09801",
    "authors": [
      "Yongwoo Lee",
      "Minhyeok Lee",
      "Suhwan Cho",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09806",
    "title": "DexRepNet: Learning Dexterous Robotic Grasping Network with Geometric  and Spatial Hand-Object Representations",
    "abstract": "Robotic dexterous grasping is a challenging problem due to the high degree of freedom (DoF) and complex contacts of multi-fingered robotic hands. Existing deep reinforcement learning (DRL) based methods leverage human demonstrations to reduce sample complexity due to the high dimensional action space with dexterous grasping. However, less attention has been paid to hand-object interaction representations for high-level generalization. In this paper, we propose a novel geometric and spatial hand-object interaction representation, named DexRep, to capture dynamic object shape features and the spatial relations between hands and objects during grasping. DexRep comprises Occupancy Feature for rough shapes within sensing range by moving hands, Surface Feature for changing hand-object surface distances, and Local-Geo Feature for local geometric surface features most related to potential contacts. Based on the new representation, we propose a dexterous deep reinforcement learning method to learn a generalizable grasping policy DexRepNet. Experimental results show that our method outperforms baselines using existing representations for robotic grasping dramatically both in grasp success rate and convergence speed. It achieves a 93\\% grasping success rate on seen objects and higher than 80\\% grasping success rates on diverse objects of unseen categories in both simulation and real-world experiments. ",
    "url": "https://arxiv.org/abs/2303.09806",
    "authors": [
      "Qingtao Liu",
      "Yu Cui",
      "Zhengnan Sun",
      "Haoming Li",
      "Gaofeng Li",
      "Lin Shao",
      "Jiming Chen",
      "Qi Ye"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.09807",
    "title": "TKN: Transformer-based Keypoint Prediction Network For Real-time Video  Prediction",
    "abstract": "Video prediction is a complex time-series forecasting task with great potential in many use cases. However, conventional methods overemphasize accuracy while ignoring the slow prediction speed caused by complicated model structures that learn too much redundant information with excessive GPU memory consumption. Furthermore, conventional methods mostly predict frames sequentially (frame-by-frame) and thus are hard to accelerate. Consequently, valuable use cases such as real-time danger prediction and warning cannot achieve fast enough inference speed to be applicable in reality. Therefore, we propose a transformer-based keypoint prediction neural network (TKN), an unsupervised learning method that boost the prediction process via constrained information extraction and parallel prediction scheme. TKN is the first real-time video prediction solution to our best knowledge, while significantly reducing computation costs and maintaining other performance. Extensive experiments on KTH and Human3.6 datasets demonstrate that TKN predicts 11 times faster than existing methods while reducing memory consumption by 17.4% and achieving state-of-the-art prediction performance on average. ",
    "url": "https://arxiv.org/abs/2303.09807",
    "authors": [
      "Haoran Li",
      "Pengyuan Zhou",
      "Yihang Lin",
      "Yanbin Hao",
      "Haiyong Xie",
      "Yong Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09817",
    "title": "Hospital Length of Stay Prediction Based on Multi-modal Data towards  Trustworthy Human-AI Collaboration in Radiomics",
    "abstract": "To what extent can the patient's length of stay in a hospital be predicted using only an X-ray image? We answer this question by comparing the performance of machine learning survival models on a novel multi-modal dataset created from 1235 images with textual radiology reports annotated by humans. Although black-box models predict better on average than interpretable ones, like Cox proportional hazards, they are not inherently understandable. To overcome this trust issue, we introduce time-dependent model explanations into the human-AI decision making process. Explaining models built on both: human-annotated and algorithm-extracted radiomics features provides valuable insights for physicians working in a hospital. We believe the presented approach to be general and widely applicable to other time-to-event medical use cases. For reproducibility, we open-source code and the TLOS dataset at https://github.com/mi2datalab/xlungs-trustworthy-los-prediction. ",
    "url": "https://arxiv.org/abs/2303.09817",
    "authors": [
      "Hubert Baniecki",
      "Bartlomiej Sobieski",
      "Przemys\u0142aw Bombi\u0144ski",
      "Patryk Szatkowski",
      "Przemys\u0142aw Biecek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2303.09823",
    "title": "Transformers and Ensemble methods: A solution for Hate Speech Detection  in Arabic languages",
    "abstract": "This paper describes our participation in the shared task of hate speech detection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our experiments evaluate the performance of six transformer models and their combination using 2 ensemble approaches. The best results on the training set, in a five-fold cross validation scenario, were obtained by using the ensemble approach based on the majority vote. The evaluation of this approach on the test set resulted in an F1-score of 0.60 and an Accuracy of 0.86. ",
    "url": "https://arxiv.org/abs/2303.09823",
    "authors": [
      "Angel Felipe Magnoss\u00e3o de Paula",
      "Imene Bensalem",
      "Paolo Rosso",
      "Wajdi Zaghouani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09827",
    "title": "DORIC : Domain Robust Fine-Tuning for Open Intent Clustering through  Dependency Parsing",
    "abstract": "We present our work on Track 2 in the Dialog System Technology Challenges 11 (DSTC11). DSTC11-Track2 aims to provide a benchmark for zero-shot, cross-domain, intent-set induction. In the absence of in-domain training dataset, robust utterance representation that can be used across domains is necessary to induce users' intentions. To achieve this, we leveraged a multi-domain dialogue dataset to fine-tune the language model and proposed extracting Verb-Object pairs to remove the artifacts of unnecessary information. Furthermore, we devised the method that generates each cluster's name for the explainability of clustered results. Our approach achieved 3rd place in the precision score and showed superior accuracy and normalized mutual information (NMI) score than the baseline model on various domain datasets. ",
    "url": "https://arxiv.org/abs/2303.09827",
    "authors": [
      "Jihyun Lee",
      "Seungyeon Seo",
      "Yunsu Kim",
      "Gary Geunbae Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09841",
    "title": "GADFormer: An Attention-based Model for Group Anomaly Detection on  Trajectories",
    "abstract": "Group Anomaly Detection (GAD) reveals anomalous behavior among groups consisting of multiple member instances, which are, individually considered, not necessarily anomalous. This task is of major importance across multiple disciplines, in which also sequences like trajectories can be considered as a group. However, with increasing amount and heterogenity of group members, actual abnormal groups get harder to detect, especially in an unsupervised or semi-supervised setting. Recurrent Neural Networks are well established deep sequence models, but recent works have shown that their performance can decrease with increasing sequence lengths. Hence, we introduce with this paper GADFormer, a GAD specific BERT architecture, capable to perform attention-based Group Anomaly Detection on trajectories in an unsupervised and semi-supervised setting. We show formally and experimentally how trajectory outlier detection can be realized as an attention-based Group Anomaly Detection problem. Furthermore, we introduce a Block Attention-anomaly Score (BAS) to improve the interpretability of transformer encoder blocks for GAD. In addition to that, synthetic trajectory generation allows us to optimize the training for domain-specific GAD. In extensive experiments we investigate our approach versus GRU in their robustness for trajectory noise and novelties on synthetic and real world datasets. ",
    "url": "https://arxiv.org/abs/2303.09841",
    "authors": [
      "Andreas Lohrer",
      "Darpan Malik",
      "Peer Kr\u00f6ger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09870",
    "title": "TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation",
    "abstract": "Most recent test-time adaptation methods focus on only classification tasks, use specialized network architectures, destroy model calibration or rely on lightweight information from the source domain. To tackle these issues, this paper proposes a novel Test-time Self-Learning method with automatic Adversarial augmentation dubbed TeSLA for adapting a pre-trained source model to the unlabeled streaming test data. In contrast to conventional self-learning methods based on cross-entropy, we introduce a new test-time loss function through an implicitly tight connection with the mutual information and online knowledge distillation. Furthermore, we propose a learnable efficient adversarial augmentation module that further enhances online knowledge distillation by simulating high entropy augmented images. Our method achieves state-of-the-art classification and segmentation results on several benchmarks and types of domain shifts, particularly on challenging measurement shifts of medical images. TeSLA also benefits from several desirable properties compared to competing methods in terms of calibration, uncertainty metrics, insensitivity to model architectures, and source training strategies, all supported by extensive ablations. Our code and models are available on GitHub. ",
    "url": "https://arxiv.org/abs/2303.09870",
    "authors": [
      "Devavrat Tomar",
      "Guillaume Vray",
      "Behzad Bozorgtabar",
      "Jean-Philippe Thiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09874",
    "title": "Disentangling the Link Between Image Statistics and Human Perception",
    "abstract": "In the 1950s Horace Barlow and Fred Attneave suggested a connection between sensory systems and how they are adapted to the environment: early vision evolved to maximise the information it conveys about incoming signals. Following Shannon's definition, this information was described using the probability of the images taken from natural scenes. Previously, direct accurate predictions of image probabilities were not possible due to computational limitations. Despite the exploration of this idea being indirect, mainly based on oversimplified models of the image density or on system design methods, these methods had success in reproducing a wide range of physiological and psychophysical phenomena. In this paper, we directly evaluate the probability of natural images and analyse how it may determine perceptual sensitivity. We employ image quality metrics that correlate well with human opinion as a surrogate of human vision, and an advanced generative model to directly estimate the probability. Specifically, we analyse how the sensitivity of full-reference image quality metrics can be predicted from quantities derived directly from the probability distribution of natural images. First, we compute the mutual information between a wide range of probability surrogates and the sensitivity of the metrics and find that the most influential factor is the probability of the noisy image. Then we explore how these probability surrogates can be combined using a simple model to predict the metric sensitivity, giving an upper bound for the correlation of 0.85 between the model predictions and the actual perceptual sensitivity. Finally, we explore how to combine the probability surrogates using simple expressions, and obtain two functional forms (using one or two surrogates) that can be used to predict the sensitivity of the human visual system given a particular pair of images. ",
    "url": "https://arxiv.org/abs/2303.09874",
    "authors": [
      "Alexander Hepburn",
      "Valero Laparra",
      "Raul Santos-Rodriguez",
      "Jes\u00fas Malo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2303.09875",
    "title": "A Dynamic Multi-Scale Voxel Flow Network for Video Prediction",
    "abstract": "The performance of video prediction has been greatly boosted by advanced deep neural networks. However, most of the current methods suffer from large model sizes and require extra inputs, e.g., semantic/depth maps, for promising performance. For efficiency consideration, in this paper, we propose a Dynamic Multi-scale Voxel Flow Network (DMVFN) to achieve better video prediction performance at lower computational costs with only RGB images, than previous methods. The core of our DMVFN is a differentiable routing module that can effectively perceive the motion scales of video frames. Once trained, our DMVFN selects adaptive sub-networks for different inputs at the inference stage. Experiments on several benchmarks demonstrate that our DMVFN is an order of magnitude faster than Deep Voxel Flow and surpasses the state-of-the-art iterative-based OPT on generated image quality. Our code and demo are available at https://huxiaotaostasy.github.io/DMVFN/. ",
    "url": "https://arxiv.org/abs/2303.09875",
    "authors": [
      "Xiaotao Hu",
      "Zhewei Huang",
      "Ailin Huang",
      "Jun Xu",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09893",
    "title": "Moving Target Defense for Service-oriented Mission-critical Networks",
    "abstract": "Modern mission-critical systems (MCS) are increasingly softwarized and interconnected. As a result, their complexity increased, and so their vulnerability against cyber-attacks. The current adoption of virtualization and service-oriented architectures (SOA) in MCSs provides additional flexibility that can be leveraged to withstand and mitigate attacks, e.g., by moving critical services or data flows. This enables the deployment of strategies for moving target defense (MTD), which allows stripping attackers of their asymmetric advantage from the long reconnaissance of MCSs. However, it is challenging to design MTD strategies, given the diverse threat landscape, resource limitations, and potential degradation in service availability. In this paper, we combine two optimization models to explore feasible service configurations for SOA-based systems and to derive subsequent MTD actions with their time schedule based on an attacker-defender game. Our results indicate that even for challenging and diverse attack scenarios, our models can defend the system by up to 90% of the system operation time with a limited MTD defender budget. ",
    "url": "https://arxiv.org/abs/2303.09893",
    "authors": [
      "Do\u011fanalp Ergen\u00e7",
      "Florian Schneider",
      "Peter Kling",
      "Mathias Fischer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.09901",
    "title": "mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive  Pre-Training of Transformers for Few- and Zero-shot Framing Detection",
    "abstract": "This paper presents the winning system for the zero-shot Spanish framing detection task, which also achieves competitive places in eight additional languages. The challenge of the framing detection task lies in identifying a set of 14 frames when only a few or zero samples are available, i.e., a multilingual multi-label few- or zero-shot setting. Our developed solution employs a pre-training procedure based on multilingual Transformers using a label-aware contrastive loss function. In addition to describing the system, we perform an embedding space analysis and ablation study to demonstrate how our pre-training procedure supports framing detection to advance computational framing analysis. ",
    "url": "https://arxiv.org/abs/2303.09901",
    "authors": [
      "Markus Reiter-Haas",
      "Alexander Ertl",
      "Kevin Innerhofer",
      "Elisabeth Lex"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09902",
    "title": "Contrastive Self-supervised Learning in Recommender Systems: A Survey",
    "abstract": "Deep learning-based recommender systems have achieved remarkable success in recent years. However, these methods usually heavily rely on labeled data (i.e., user-item interactions), suffering from problems such as data sparsity and cold-start. Self-supervised learning, an emerging paradigm that extracts information from unlabeled data, provides insights into addressing these problems. Specifically, contrastive self-supervised learning, due to its flexibility and promising performance, has attracted considerable interest and recently become a dominant branch in self-supervised learning-based recommendation methods. In this survey, we provide an up-to-date and comprehensive review of current contrastive self-supervised learning-based recommendation methods. Firstly, we propose a unified framework for these methods. We then introduce a taxonomy based on the key components of the framework, including view generation strategy, contrastive task, and contrastive objective. For each component, we provide detailed descriptions and discussions to guide the choice of the appropriate method. Finally, we outline open issues and promising directions for future research. ",
    "url": "https://arxiv.org/abs/2303.09902",
    "authors": [
      "Mengyuan Jing",
      "Yanmin Zhu",
      "Tianzi Zang",
      "Ke Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.09905",
    "title": "More Robust Schema-Guided Dialogue State Tracking via Tree-Based  Paraphrase Ranking",
    "abstract": "The schema-guided paradigm overcomes scalability issues inherent in building task-oriented dialogue (TOD) agents with static ontologies. Instead of operating on dialogue context alone, agents have access to hierarchical schemas containing task-relevant natural language descriptions. Fine-tuned language models excel at schema-guided dialogue state tracking (DST) but are sensitive to the writing style of the schemas. We explore methods for improving the robustness of DST models. We propose a framework for generating synthetic schemas which uses tree-based ranking to jointly optimise lexical diversity and semantic faithfulness. The generalisation of strong baselines is improved when augmenting their training data with prompts generated by our framework, as demonstrated by marked improvements in average joint goal accuracy (JGA) and schema sensitivity (SS) on the SGD-X benchmark. ",
    "url": "https://arxiv.org/abs/2303.09905",
    "authors": [
      "A. Coca",
      "B.H. Tseng",
      "W. Lin",
      "B. Byrne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.09906",
    "title": "Discovering mesoscopic descriptions of collective movement with neural  stochastic modelling",
    "abstract": "Collective motion is an ubiquitous phenomenon in nature, inspiring engineers, physicists and mathematicians to develop mathematical models and bio-inspired designs. Collective motion at small to medium group sizes ($\\sim$10-1000 individuals, also called the `mesoscale'), can show nontrivial features due to stochasticity. Therefore, characterizing both the deterministic and stochastic aspects of the dynamics is crucial in the study of mesoscale collective phenomena. Here, we use a physics-inspired, neural-network based approach to characterize the stochastic group dynamics of interacting individuals, through a stochastic differential equation (SDE) that governs the collective dynamics of the group. We apply this technique on both synthetic and real-world datasets, and identify the deterministic and stochastic aspects of the dynamics using drift and diffusion fields, enabling us to make novel inferences about the nature of order in these systems. ",
    "url": "https://arxiv.org/abs/2303.09906",
    "authors": [
      "Utkarsh Pratiush",
      "Arshed Nabeel",
      "Vishwesha Guttal",
      "Prathosh AP"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.09913",
    "title": "Short: Basal-Adjust: Trend Prediction Alerts and Adjusted Basal Rates  for Hyperglycemia Prevention",
    "abstract": "Significant advancements in type 1 diabetes treatment have been made in the development of state-of-the-art Artificial Pancreas Systems (APS). However, lapses currently exist in the timely treatment of unsafe blood glucose (BG) levels, especially in the case of rebound hyperglycemia. We propose a machine learning (ML) method for predictive BG scenario categorization that outputs messages alerting the patient to upcoming BG trends to allow for earlier, educated treatment. In addition to standard notifications of predicted hypoglycemia and hyperglycemia, we introduce BG scenario-specific alert messages and the preliminary steps toward precise basal suggestions for the prevention of rebound hyperglycemia. Experimental evaluation on the DCLP3 clinical dataset achieves >98% accuracy and >79% precision for predicting rebound high events for patient alerts. ",
    "url": "https://arxiv.org/abs/2303.09913",
    "authors": [
      "Chloe Smith",
      "Maxfield Kouzel",
      "Xugui Zhou",
      "Homa Alemzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09917",
    "title": "Vision Transformer for Action Units Detection",
    "abstract": "Facial Action Units detection (FAUs) represents a fine-grained classification problem that involves identifying different units on the human face, as defined by the Facial Action Coding System. In this paper, we present a simple yet efficient Vision Transformer-based approach for addressing the task of Action Units (AU) detection in the context of Affective Behavior Analysis in-the-wild (ABAW) competition. We employ the Video Vision Transformer(ViViT) Network to capture the temporal facial change in the video. Besides, to reduce massive size of the Vision Transformers model, we replace the ViViT feature extraction layers with the CNN backbone (Regnet). Our model outperform the baseline model of ABAW 2023 challenge, with a notable 14\\% difference in result. Furthermore, the achieved results are comparable to those of the top three teams in the previous ABAW 2022 challenge. ",
    "url": "https://arxiv.org/abs/2303.09917",
    "authors": [
      "Tu Vu",
      "Van Thong Huynh",
      "Soo Hyung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09919",
    "title": "Dual Memory Aggregation Network for Event-Based Object Detection with  Learnable Representation",
    "abstract": "Event-based cameras are bio-inspired sensors that capture brightness change of every pixel in an asynchronous manner. Compared with frame-based sensors, event cameras have microsecond-level latency and high dynamic range, hence showing great potential for object detection under high-speed motion and poor illumination conditions. Due to sparsity and asynchronism nature with event streams, most of existing approaches resort to hand-crafted methods to convert event data into 2D grid representation. However, they are sub-optimal in aggregating information from event stream for object detection. In this work, we propose to learn an event representation optimized for event-based object detection. Specifically, event streams are divided into grids in the x-y-t coordinates for both positive and negative polarity, producing a set of pillars as 3D tensor representation. To fully exploit information with event streams to detect objects, a dual-memory aggregation network (DMANet) is proposed to leverage both long and short memory along event streams to aggregate effective information for object detection. Long memory is encoded in the hidden state of adaptive convLSTMs while short memory is modeled by computing spatial-temporal correlation between event pillars at neighboring time intervals. Extensive experiments on the recently released event-based automotive detection dataset demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2303.09919",
    "authors": [
      "Dongsheng Wang",
      "Xu Jia",
      "Yang Zhang",
      "Xinyu Zhang",
      "Yaoyuan Wang",
      "Ziyang Zhang",
      "Dong Wang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09920",
    "title": "High-Degree Splines from Discrete Fourier Transforms: Robust Methods to  Obtain the Boundary Conditions",
    "abstract": "Computing accurate splines of degree greater than three is still a challenging task in today's applications. In this type of interpolation, high-order derivatives are needed on the given mesh. As these derivatives are rarely known and are often not easy to approximate accurately, high-degree splines are difficult to obtain using standard approaches. In Beaudoin (1998), Beaudoin and Beauchemin (2003), and Pepin et al. (2019), a new method to compute spline approximations of low or high degree from equidistant interpolation nodes based on the discrete Fourier transform is analyzed. The accuracy of this method greatly depends on the accuracy of the boundary conditions. An algorithm for the computation of the boundary conditions can be found in Beaudoin (1998), and Beaudoin and Beauchemin (2003). However, this algorithm lacks robustness since the approximation of the boundary conditions is strongly dependant on the choice of $\\theta$ arbitrary parameters, $\\theta$ being the degree of the spline. The goal of this paper is therefore to propose two new robust algorithms, independent of arbitrary parameters, for the computation of the boundary conditions in order to obtain accurate splines of any degree. Numerical results will be presented to show the efficiency of these new approaches. ",
    "url": "https://arxiv.org/abs/2303.09920",
    "authors": [
      "A. Pepin",
      "S. L\u00e9ger",
      "N. Beaudoin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.09930",
    "title": "Robust Semi-Supervised Learning for Histopathology Images through  Self-Supervision Guided Out-of-Distribution Scoring",
    "abstract": "Semi-supervised learning (semi-SL) is a promising alternative to supervised learning for medical image analysis when obtaining good quality supervision for medical imaging is difficult. However, semi-SL assumes that the underlying distribution of unaudited data matches that of the few labeled samples, which is often violated in practical settings, particularly in medical images. The presence of out-of-distribution (OOD) samples in the unlabeled training pool of semi-SL is inevitable and can reduce the efficiency of the algorithm. Common preprocessing methods to filter out outlier samples may not be suitable for medical images that involve a wide range of anatomical structures and rare morphologies. In this paper, we propose a novel pipeline for addressing open-set supervised learning challenges in digital histology images. Our pipeline efficiently estimates an OOD score for each unlabelled data point based on self-supervised learning to calibrate the knowledge needed for a subsequent semi-SL framework. The outlier score derived from the OOD detector is used to modulate sample selection for the subsequent semi-SL stage, ensuring that samples conforming to the distribution of the few labeled samples are more frequently exposed to the subsequent semi-SL framework. Our framework is compatible with any semi-SL framework, and we base our experiments on the popular Mixmatch semi-SL framework. We conduct extensive studies on two digital pathology datasets, Kather colorectal histology dataset and a dataset derived from TCGA-BRCA whole slide images, and establish the effectiveness of our method by comparing with popular methods and frameworks in semi-SL algorithms through various experiments. ",
    "url": "https://arxiv.org/abs/2303.09930",
    "authors": [
      "Nikhil Cherian Kurian",
      "Varsha S",
      "Abhijit Patil",
      "Shashikant Khade",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09935",
    "title": "Alternate Loss Functions Can Improve the Performance of Artificial  Neural Networks",
    "abstract": "All machine learning algorithms use a loss, cost, utility or reward function to encode the learning objective and oversee the learning process. This function that supervises learning is a frequently unrecognized hyperparameter that determines how incorrect outputs are penalized and can be tuned to improve performance. This paper shows that training speed and final accuracy of neural networks can significantly depend on the loss function used to train neural networks. In particular derivative values can be significantly different with different loss functions leading to significantly different performance after gradient descent based Backpropagation (BP) training. This paper explores the effect on performance of new loss functions that are more liberal or strict compared to the popular Cross-entropy loss in penalizing incorrect outputs. Eight new loss functions are proposed and a comparison of performance with different loss functions is presented. The new loss functions presented in this paper are shown to outperform Cross-entropy loss on computer vision and NLP benchmarks. ",
    "url": "https://arxiv.org/abs/2303.09935",
    "authors": [
      "Mathew Mithra Noel",
      "Arindam Banerjee",
      "Geraldine Bessie Amali D"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.09939",
    "title": "Comprehensive Analysis of Maximum Power Association Policy for Cellular  Networks Using Distance and Angular Coordinates",
    "abstract": "A novel stochastic geometry framework is proposed in this paper to study the downlink coverage performance in a millimeter wave (mmWave) cellular network by jointly considering the polar coordinates of the Base Stations (BSs) with respect to the typical user located at the origin. Specifically, both the Euclidean and the angular distances of the BSs in a maximum power-based association policy for the UE are considered to account for realistic beam management considerations, which have been largely ignored in the literature, especially in the cell association phase. For completeness, two other association schemes are considered and exact-form expressions for the coverage probability are derived. Subsequently, the key role of angular distances is highlighted by defining the dominant interferer using angular distance-based criteria instead of Euclidean distance-based, and conducting a dominant interferer-based coverage probability analysis. Among others, the numerical results revealed that considering angular distance-based criteria for determining both the serving and the dominant interfering BS, can approximate the coverage performance more accurately as compared to utilizing Euclidean distance-based criteria. To the best of the authors$'$ knowledge, this is the first work that rigorously explores the role of angular distances in the association policy and analysis of cellular networks. ",
    "url": "https://arxiv.org/abs/2303.09939",
    "authors": [
      "Charalampos K. Armeniakos",
      "Athanasios G. Kanatas",
      "Harpreet S. Dhillon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.09950",
    "title": "Deep Graph-based Spatial Consistency for Robust Non-rigid Point Cloud  Registration",
    "abstract": "We study the problem of outlier correspondence pruning for non-rigid point cloud registration. In rigid registration, spatial consistency has been a commonly used criterion to discriminate outliers from inliers. It measures the compatibility of two correspondences by the discrepancy between the respective distances in two point clouds. However, spatial consistency no longer holds in non-rigid cases and outlier rejection for non-rigid registration has not been well studied. In this work, we propose Graph-based Spatial Consistency Network (GraphSCNet) to filter outliers for non-rigid registration. Our method is based on the fact that non-rigid deformations are usually locally rigid, or local shape preserving. We first design a local spatial consistency measure over the deformation graph of the point cloud, which evaluates the spatial compatibility only between the correspondences in the vicinity of a graph node. An attention-based non-rigid correspondence embedding module is then devised to learn a robust representation of non-rigid correspondences from local spatial consistency. Despite its simplicity, GraphSCNet effectively improves the quality of the putative correspondences and attains state-of-the-art performance on three challenging benchmarks. Our code and models are available at https://github.com/qinzheng93/GraphSCNet. ",
    "url": "https://arxiv.org/abs/2303.09950",
    "authors": [
      "Zheng Qin",
      "Hao Yu",
      "Changjian Wang",
      "Yuxing Peng",
      "Kai Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09952",
    "title": "Single-view Neural Radiance Fields with Depth Teacher",
    "abstract": "Neural Radiance Fields (NeRF) have been proposed for photorealistic novel view rendering. However, it requires many different views of one scene for training. Moreover, it has poor generalizations to new scenes and requires retraining or fine-tuning on each scene. In this paper, we develop a new NeRF model for novel view synthesis using only a single image as input. We propose to combine the (coarse) planar rendering and the (fine) volume rendering to achieve higher rendering quality and better generalizations. We also design a depth teacher net that predicts dense pseudo depth maps to supervise the joint rendering mechanism and boost the learning of consistent 3D geometry. We evaluate our method on three challenging datasets. It outperforms state-of-the-art single-view NeRFs by achieving 5$\\sim$20\\% improvements in PSNR and reducing 20$\\sim$50\\% of the errors in the depth rendering. It also shows excellent generalization abilities to unseen data without the need to fine-tune on each new scene. ",
    "url": "https://arxiv.org/abs/2303.09952",
    "authors": [
      "Yurui Chen",
      "Chun Gu",
      "Feihu Zhang",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09962",
    "title": "Adversarial Counterfactual Visual Explanations",
    "abstract": "Counterfactual explanations and adversarial attacks have a related goal: flipping output labels with minimal perturbations regardless of their characteristics. Yet, adversarial attacks cannot be used directly in a counterfactual explanation perspective, as such perturbations are perceived as noise and not as actionable and understandable image modifications. Building on the robust learning literature, this paper proposes an elegant method to turn adversarial attacks into semantically meaningful perturbations, without modifying the classifiers to explain. The proposed approach hypothesizes that Denoising Diffusion Probabilistic Models are excellent regularizers for avoiding high-frequency and out-of-distribution perturbations when generating adversarial attacks. The paper's key idea is to build attacks through a diffusion model to polish them. This allows studying the target model regardless of its robustification level. Extensive experimentation shows the advantages of our counterfactual explanation approach over current State-of-the-Art in multiple testbeds. ",
    "url": "https://arxiv.org/abs/2303.09962",
    "authors": [
      "Guillaume Jeanneret",
      "Lo\u00efc Simon",
      "Fr\u00e9d\u00e9ric Jurie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09968",
    "title": "Using causal inference and Bayesian statistics to explain the capability  of a test suite in exposing software faults",
    "abstract": "Test effectiveness refers to the capability of a test suite in exposing faults in software. It is crucial to be aware of factors that influence this capability. We aim at inferring the causal relationship between the two factors (i.e., Cover/Exec) and the capability of a test suite to expose and discover faults in software. Cover refers to the number of distinct test cases covering the statement and Exec equals the number of times a test suite executes a statement. We analyzed 459166 software faults from {12} Java programs. Bayesian statistics along with the back-door criterion was exploited for the purpose of causal inference. Furthermore, we examined the common pitfall measuring association, the mixture of causal and noncausal relationships, instead of causal association. The results show that Cover is of more causal association as against \\textit{Exec}, and the causal association and noncausal one for those variables are statistically different. Software developers could exploit the results to design and write more effective test cases, which lead to discovering more bugs hidden in software. ",
    "url": "https://arxiv.org/abs/2303.09968",
    "authors": [
      "Alireza Aghamohammadi",
      "Seyed-Hassan Mirian-Hosseinabadi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.09998",
    "title": "TBP-Former: Learning Temporal Bird's-Eye-View Pyramid for Joint  Perception and Prediction in Vision-Centric Autonomous Driving",
    "abstract": "Vision-centric joint perception and prediction (PnP) has become an emerging trend in autonomous driving research. It predicts the future states of the traffic participants in the surrounding environment from raw RGB images. However, it is still a critical challenge to synchronize features obtained at multiple camera views and timestamps due to inevitable geometric distortions and further exploit those spatial-temporal features. To address this issue, we propose a temporal bird's-eye-view pyramid transformer (TBP-Former) for vision-centric PnP, which includes two novel designs. First, a pose-synchronized BEV encoder is proposed to map raw image inputs with any camera pose at any time to a shared and synchronized BEV space for better spatial-temporal synchronization. Second, a spatial-temporal pyramid transformer is introduced to comprehensively extract multi-scale BEV features and predict future BEV states with the support of spatial-temporal priors. Extensive experiments on nuScenes dataset show that our proposed framework overall outperforms all state-of-the-art vision-based prediction methods. ",
    "url": "https://arxiv.org/abs/2303.09998",
    "authors": [
      "Shaoheng Fang",
      "Zi Wang",
      "Yiqi Zhong",
      "Junhao Ge",
      "Siheng Chen",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10021",
    "title": "Coverage Analysis of Hybrid RF/THz Networks With Best Relay Selection",
    "abstract": "Utilizing terahertz (THz) transmission to enhance coverage has proven various benefits compared to traditional radio frequency (RF) counterparts. This letter proposes a dual-hop decode-and-forward (DF) routing protocol in a hybrid RF and THz relay network named hybrid relay selection (HRS). The coverage probability of the HRS protocol is derived. The HRS protocol prioritizes THz relays for higher data rates or short source-destination distances; and RF relays for lower data rates or large source-destination distances. The proposed HRS protocol offers nearly the same performance as the optimal selection protocol, which requires complete instantaneous channel state information (CSI) of all the nodes. ",
    "url": "https://arxiv.org/abs/2303.10021",
    "authors": [
      "Zhengying Lou",
      "Baha Eddine Youcef Belmekki",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.10027",
    "title": "From positional representation of numbers to positional representation  of vectors",
    "abstract": "To represent real $m$-dimensional vectors, a positional vector system given by a non-singular matrix $M \\in \\Z^{m \\times m}$ and a digit set $\\D \\subset \\Z^m$ is used. If $m = 1$, the system coincides with the well known numeration system used to represent real numbers. We study some properties of the vector systems which are transformable from the case $m = 1$ to higher dimensions. We focus on algorithm for parallel addition and on systems allowing an eventually periodic representation of vectors with rational coordinates. ",
    "url": "https://arxiv.org/abs/2303.10027",
    "authors": [
      "Izabella Ingrid Farkas",
      "Edita Pelantov\u00e1",
      "Milena Svobodov\u00e1"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.10030",
    "title": "How robust is randomized blind deconvolution via nuclear norm  minimization against adversarial noise?",
    "abstract": "In this paper, we study the problem of recovering two unknown signals from their convolution, which is commonly referred to as blind deconvolution. Reformulation of blind deconvolution as a low-rank recovery problem has led to multiple theoretical recovery guarantees in the past decade due to the success of the nuclear norm minimization heuristic. In particular, in the absence of noise, exact recovery has been established for sufficiently incoherent signals contained in lower-dimensional subspaces. However, if the convolution is corrupted by additive bounded noise, the stability of the recovery problem remains much less understood. In particular, existing reconstruction bounds involve large dimension factors and therefore fail to explain the empirical evidence for dimension-independent robustness of nuclear norm minimization. Recently, theoretical evidence has emerged for ill-posed behavior of low-rank matrix recovery for sufficiently small noise levels. In this work, we develop improved recovery guarantees for blind deconvolution with adversarial noise which exhibit square-root scaling in the noise level. Hence, our results are consistent with existing counterexamples which speak against linear scaling in the noise level as demonstrated for related low-rank matrix recovery problems. ",
    "url": "https://arxiv.org/abs/2303.10030",
    "authors": [
      "Julia Kostin",
      "Felix Krahmer",
      "Dominik St\u00f6ger"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.10058",
    "title": "No Fear of Classifier Biases: Neural Collapse Inspired Federated  Learning with Synthetic and Fixed Classifier",
    "abstract": "Data heterogeneity is an inherent challenge that hinders the performance of federated learning (FL). Recent studies have identified the biased classifiers of local models as the key bottleneck. Previous attempts have used classifier calibration after FL training, but this approach falls short in improving the poor feature representations caused by training-time classifier biases. Resolving the classifier bias dilemma in FL requires a full understanding of the mechanisms behind the classifier. Recent advances in neural collapse have shown that the classifiers and feature prototypes under perfect training scenarios collapse into an optimal structure called simplex equiangular tight frame (ETF). Building on this neural collapse insight, we propose a solution to the FL's classifier bias problem by utilizing a synthetic and fixed ETF classifier during training. The optimal classifier structure enables all clients to learn unified and optimal feature representations even under extremely heterogeneous data. We devise several effective modules to better adapt the ETF structure in FL, achieving both high generalization and personalization. Extensive experiments demonstrate that our method achieves state-of-the-art performances on CIFAR-10, CIFAR-100, and Tiny-ImageNet. ",
    "url": "https://arxiv.org/abs/2303.10058",
    "authors": [
      "Zexi Li",
      "Xinyi Shang",
      "Rui He",
      "Tao Lin",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10078",
    "title": "Fuzziness-tuned: Improving the Transferability of Adversarial Examples",
    "abstract": "With the development of adversarial attacks, adversairal examples have been widely used to enhance the robustness of the training models on deep neural networks. Although considerable efforts of adversarial attacks on improving the transferability of adversarial examples have been developed, the attack success rate of the transfer-based attacks on the surrogate model is much higher than that on victim model under the low attack strength (e.g., the attack strength $\\epsilon=8/255$). In this paper, we first systematically investigated this issue and found that the enormous difference of attack success rates between the surrogate model and victim model is caused by the existence of a special area (known as fuzzy domain in our paper), in which the adversarial examples in the area are classified wrongly by the surrogate model while correctly by the victim model. Then, to eliminate such enormous difference of attack success rates for improving the transferability of generated adversarial examples, a fuzziness-tuned method consisting of confidence scaling mechanism and temperature scaling mechanism is proposed to ensure the generated adversarial examples can effectively skip out of the fuzzy domain. The confidence scaling mechanism and the temperature scaling mechanism can collaboratively tune the fuzziness of the generated adversarial examples through adjusting the gradient descent weight of fuzziness and stabilizing the update direction, respectively. Specifically, the proposed fuzziness-tuned method can be effectively integrated with existing adversarial attacks to further improve the transferability of adverarial examples without changing the time complexity. Extensive experiments demonstrated that fuzziness-tuned method can effectively enhance the transferability of adversarial examples in the latest transfer-based attacks. ",
    "url": "https://arxiv.org/abs/2303.10078",
    "authors": [
      "Xiangyuan Yang",
      "Jie Lin",
      "Hanlin Zhang",
      "Xinyu Yang",
      "Peng Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10087",
    "title": "Refinement for Absolute Pose Regression with Neural Feature Synthesis",
    "abstract": "Absolute Pose Regression (APR) methods use deep neural networks to directly regress camera poses from RGB images. Despite their advantages in inference speed and simplicity, these methods still fall short of the accuracy achieved by geometry-based techniques. To address this issue, we propose a new model called the Neural Feature Synthesizer (NeFeS). Our approach encodes 3D geometric features during training and renders dense novel view features at test time to refine estimated camera poses from arbitrary APR methods. Unlike previous APR works that require additional unlabeled training data, our method leverages implicit geometric constraints during test time using a robust feature field. To enhance the robustness of our NeFeS network, we introduce a feature fusion module and a progressive training strategy. Our proposed method improves the state-of-the-art single-image APR accuracy by as much as 54.9% on indoor and outdoor benchmark datasets without additional time-consuming unlabeled data training. ",
    "url": "https://arxiv.org/abs/2303.10087",
    "authors": [
      "Shuai Chen",
      "Yash Bhalgat",
      "Xinghui Li",
      "Jiawang Bian",
      "Kejie Li",
      "Zirui Wang",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10093",
    "title": "Enhancing the Role of Context in Region-Word Alignment for Object  Detection",
    "abstract": "Vision-language pretraining to learn a fine-grained, region-word alignment between image-caption pairs has propelled progress in open-vocabulary object detection. We observe that region-word alignment methods are typically used in detection with respect to only object nouns, and the impact of other rich context in captions, such as attributes, is unclear. In this study, we explore how language context affects downstream object detection and propose to enhance the role of context. In particular, we show how to strategically contextualize the grounding pretraining objective for improved alignment. We further hone in on attributes as especially useful object context and propose a novel adjective and noun-based negative sampling strategy for increasing their focus in contrastive learning. Overall, our methods enhance object detection when compared to the state-of-the-art in region-word pretraining. We also highlight the fine-grained utility of an attribute-sensitive model through text-region retrieval and phrase grounding analysis. ",
    "url": "https://arxiv.org/abs/2303.10093",
    "authors": [
      "Kyle Buettner",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10100",
    "title": "Unified Mask Embedding and Correspondence Learning for Self-Supervised  Video Segmentation",
    "abstract": "The objective of this paper is self-supervised learning of video object segmentation. We develop a unified framework which simultaneously models cross-frame dense correspondence for locally discriminative feature learning and embeds object-level context for target-mask decoding. As a result, it is able to directly learn to perform mask-guided sequential segmentation from unlabeled videos, in contrast to previous efforts usually relying on an oblique solution - cheaply \"copying\" labels according to pixel-wise correlations. Concretely, our algorithm alternates between i) clustering video pixels for creating pseudo segmentation labels ex nihilo; and ii) utilizing the pseudo labels to learn mask encoding and decoding for VOS. Unsupervised correspondence learning is further incorporated into this self-taught, mask embedding scheme, so as to ensure the generic nature of the learnt representation and avoid cluster degeneracy. Our algorithm sets state-of-the-arts on two standard benchmarks (i.e., DAVIS17 and YouTube-VOS), narrowing the gap between self- and fully-supervised VOS, in terms of both performance and network architecture design. ",
    "url": "https://arxiv.org/abs/2303.10100",
    "authors": [
      "Liulei Li",
      "Wenguan Wang",
      "Tianfei Zhou",
      "Jianwu Li",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10108",
    "title": "Data-Centric Learning from Unlabeled Graphs with Diffusion Model",
    "abstract": "Graph property prediction tasks are important and numerous. While each task offers a small size of labeled examples, unlabeled graphs have been collected from various sources and at a large scale. A conventional approach is training a model with the unlabeled graphs on self-supervised tasks and then fine-tuning the model on the prediction tasks. However, the self-supervised task knowledge could not be aligned or sometimes conflicted with what the predictions needed. In this paper, we propose to extract the knowledge underlying the large set of unlabeled graphs as a specific set of useful data points to augment each property prediction model. We use a diffusion model to fully utilize the unlabeled graphs and design two new objectives to guide the model's denoising process with each task's labeled data to generate task-specific graph examples and their labels. Experiments demonstrate that our data-centric approach performs significantly better than fourteen existing various methods on fifteen tasks. The performance improvement brought by unlabeled data is visible as the generated labeled examples unlike self-supervised learning. ",
    "url": "https://arxiv.org/abs/2303.10108",
    "authors": [
      "Gang Liu",
      "Eric Inae",
      "Tong Zhao",
      "Jiaxin Xu",
      "Tengfei Luo",
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10112",
    "title": "Causal Discovery from Temporal Data: An Overview and New Perspectives",
    "abstract": "Temporal data, representing chronological observations of complex systems, has always been a typical data structure that can be widely generated by many domains, such as industry, medicine and finance. Analyzing this type of data is extremely valuable for various applications. Thus, different temporal data analysis tasks, eg, classification, clustering and prediction, have been proposed in the past decades. Among them, causal discovery, learning the causal relations from temporal data, is considered an interesting yet critical task and has attracted much research attention. Existing casual discovery works can be divided into two highly correlated categories according to whether the temporal data is calibrated, ie, multivariate time series casual discovery, and event sequence casual discovery. However, most previous surveys are only focused on the time series casual discovery and ignore the second category. In this paper, we specify the correlation between the two categories and provide a systematical overview of existing solutions. Furthermore, we provide public datasets, evaluation metrics and new perspectives for temporal data casual discovery. ",
    "url": "https://arxiv.org/abs/2303.10112",
    "authors": [
      "Chang Gong",
      "Di Yao",
      "Chuzhe Zhang",
      "Wenbin Li",
      "Jingping Bi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.10135",
    "title": "Efficient and Feasible Robotic Assembly Sequence Planning via Graph  Representation Learning",
    "abstract": "Automatic Robotic Assembly Sequence Planning (RASP) can significantly improve productivity and resilience in modern manufacturing along with the growing need for greater product customization. One of the main challenges in realizing such automation resides in efficiently finding solutions from a growing number of potential sequences for increasingly complex assemblies. Besides, costly feasibility checks are always required for the robotic system. To address this, we propose a holistic graphical approach including a graph representation called Assembly Graph for product assemblies and a policy architecture, Graph Assembly Processing Network, dubbed GRACE for assembly sequence generation. Secondly, we use GRACE to extract meaningful information from the graph input and predict assembly sequences in a step-by-step manner. In experiments, we show that our approach can predict feasible assembly sequences across product variants of aluminum profiles based on data collected in simulation of a dual-armed robotic system. We further demonstrate that our method is capable of detecting infeasible assemblies, substantially alleviating the undesirable impacts from false predictions, and hence facilitating real-world deployment soon. Code and training data will be open-sourced. ",
    "url": "https://arxiv.org/abs/2303.10135",
    "authors": [
      "Matan Atad",
      "Jianxiang Feng",
      "Ismael Rodr\u00edguez",
      "Maximilian Durner",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10139",
    "title": "Distill n' Explain: explaining graph neural networks using simple  surrogates",
    "abstract": "Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n' Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faithfulness of explanations. ",
    "url": "https://arxiv.org/abs/2303.10139",
    "authors": [
      "Tamara Pereira",
      "Erik Nasciment",
      "Lucas E. Resck",
      "Diego Mesquita",
      "Amauri Souza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10145",
    "title": "Spectrum-inspired Low-light Image Translation for Saliency Detection",
    "abstract": "Saliency detection methods are central to several real-world applications such as robot navigation and satellite imagery. However, the performance of existing methods deteriorate under low-light conditions because training datasets mostly comprise of well-lit images. One possible solution is to collect a new dataset for low-light conditions. This involves pixel-level annotations, which is not only tedious and time-consuming but also infeasible if a huge training corpus is required. We propose a technique that performs classical band-pass filtering in the Fourier space to transform well-lit images to low-light images and use them as a proxy for real low-light images. Unlike popular deep learning approaches which require learning thousands of parameters and enormous amounts of training data, the proposed transformation is fast and simple and easy to extend to other tasks such as low-light depth estimation. Our experiments show that the state-of-the-art saliency detection and depth estimation networks trained on our proxy low-light images perform significantly better on real low-light images than networks trained using existing strategies. ",
    "url": "https://arxiv.org/abs/2303.10145",
    "authors": [
      "Kitty Varghese",
      "Sudarshan Rajagopalan",
      "Mohit Lamba",
      "Kaushik Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.09683",
    "title": "Three dimensional chaos game representation of protein sequences",
    "abstract": "A new three dimensional approach to the chaos game representation of protein sequences is explored in this thesis. The basics of DNA, the synthesis of proteins from DNA, protein structure and functionality and sequence alignment techniques are presented. The mathematical background needed for understanding the chaos game representation and fractal analysis are briefly discussed. An account of the existing literature on the chaos game representation of DNA sequences and a detailed account of the chaos game representation of protein sequences in two dimensions with its advantages and limitations are presented. We explore a new three dimensional approach to the chaos game representation of protein sequences (3D-CGR) and study its ability a) to determine protein sequence similarity and differences, b) to study the effect of dinucleotide biases at amino acid level on the 3D-CGR derived protein homology, and c) to identify sequence similarity based on shuffled motifs that could be used for studying protein evolution due to exon shuffling. ",
    "url": "https://arxiv.org/abs/2303.09683",
    "authors": [
      "Annie Thomas"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2303.09684",
    "title": "A centrality measure for quantifying spread on weighted, directed  networks",
    "abstract": "While many centrality measures for complex networks have been proposed, relatively few have been developed specifically for weighted, directed (WD) networks. Here we propose a centrality measure for spread (of information, pathogens, etc.) through WD networks based on the independent cascade model (ICM). While deriving exact results for the ICM requires Monte Carlo simulations, we show that our centrality measure (Viral Centrality) provides excellent approximation to ICM results for networks in which the weighted strength of cycles is not too large. We show this can be quantified with the leading eigenvalue of the weighted adjacency matrix, and we show that Viral Centrality outperforms other common centrality measures in both simulated and empirical WD networks. ",
    "url": "https://arxiv.org/abs/2303.09684",
    "authors": [
      "Christian G. Fink",
      "Kelly Fullin",
      "Guillermo Gutierrez",
      "Nathan Omodt",
      "Sydney Zinnecker",
      "Gina Sprint",
      "Sean McCulloch"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.09858",
    "title": "MedLocker: A Transferable Adversarial Watermarking for Preventing  Unauthorized Analysis of Medical Image Dataset",
    "abstract": "The collection of medical image datasets is a demanding and laborious process that requires significant resources. Furthermore, these medical datasets may contain personally identifiable information, necessitating measures to ensure that unauthorized access is prevented. Failure to do so could violate the intellectual property rights of the dataset owner and potentially compromise the privacy of patients. As a result, safeguarding medical datasets and preventing unauthorized usage by AI diagnostic models is a pressing challenge. To address this challenge, we propose a novel visible adversarial watermarking method for medical image copyright protection, called MedLocker. Our approach involves continuously optimizing the position and transparency of a watermark logo, which reduces the performance of the target model, leading to incorrect predictions. Importantly, we ensure that our method minimizes the impact on clinical visualization by constraining watermark positions using semantical masks (WSM), which are bounding boxes of lesion regions based on semantic segmentation. To ensure the transferability of the watermark across different models, we verify the cross-model transferability of the watermark generated on a single model. Additionally, we generate a unique watermark parameter list each time, which can be used as a certification to verify the authorization. We evaluate the performance of MedLocker on various mainstream backbones and validate the feasibility of adversarial watermarking for copyright protection on two widely-used diabetic retinopathy detection datasets. Our results demonstrate that MedLocker can effectively protect the copyright of medical datasets and prevent unauthorized users from analyzing medical images with AI diagnostic models. ",
    "url": "https://arxiv.org/abs/2303.09858",
    "authors": [
      "Bangzheng Pu",
      "Xingxing Wei",
      "Shiji Zha",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.09863",
    "title": "Deep Nonparametric Estimation of Intrinsic Data Structures by Chart  Autoencoders: Generalization Error and Robustness",
    "abstract": "Autoencoders have demonstrated remarkable success in learning low-dimensional latent features of high-dimensional data across various applications. Assuming that data are sampled near a low-dimensional manifold, we employ chart autoencoders, which encode data into low-dimensional latent features on a collection of charts, preserving the topology and geometry of the data manifold. Our paper establishes statistical guarantees on the generalization error of chart autoencoders, and we demonstrate their denoising capabilities by considering $n$ noisy training samples, along with their noise-free counterparts, on a $d$-dimensional manifold. By training autoencoders, we show that chart autoencoders can effectively denoise the input data with normal noise. We prove that, under proper network architectures, chart autoencoders achieve a squared generalization error in the order of $\\displaystyle n^{-\\frac{2}{d+2}}\\log^4 n$, which depends on the intrinsic dimension of the manifold and only weakly depends on the ambient dimension and noise level. We further extend our theory on data with noise containing both normal and tangential components, where chart autoencoders still exhibit a denoising effect for the normal component. As a special case, our theory also applies to classical autoencoders, as long as the data manifold has a global parametrization. Our results provide a solid theoretical foundation for the effectiveness of autoencoders, which is further validated through several numerical experiments. ",
    "url": "https://arxiv.org/abs/2303.09863",
    "authors": [
      "Hao Liu",
      "Alex Havrilla",
      "Rongjie Lai",
      "Wenjing Liao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09934",
    "title": "Decidability of modal logics of non-$k$-colorable graphs",
    "abstract": "We consider the bimodal language, where the first modality is interpreted by a binary relation in the standard way, and the second is interpreted by the relation of inequality. It follows from Hughes (1990), that in this language, non-$k$-colorability of a graph is expressible for every finite $k$. We show that modal logics of classes of non-$k$-colorable graphs (directed or non-directed), and some of their extensions, are decidable. ",
    "url": "https://arxiv.org/abs/2303.09934",
    "authors": [
      "Ilya Shapirovsky"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2303.09949",
    "title": "Towards a Foundation Model for Neural Network Wavefunctions",
    "abstract": "Deep neural networks have become a highly accurate and powerful wavefunction ansatz in combination with variational Monte Carlo methods for solving the electronic Schr\\\"odinger equation. However, despite their success and favorable scaling, these methods are still computationally too costly for wide adoption. A significant obstacle is the requirement to optimize the wavefunction from scratch for each new system, thus requiring long optimization. In this work, we propose a novel neural network ansatz, which effectively maps uncorrelated, computationally cheap Hartree-Fock orbitals, to correlated, high-accuracy neural network orbitals. This ansatz is inherently capable of learning a single wavefunction across multiple compounds and geometries, as we demonstrate by successfully transferring a wavefunction model pre-trained on smaller fragments to larger compounds. Furthermore, we provide ample experimental evidence to support the idea that extensive pre-training of a such a generalized wavefunction model across different compounds and geometries could lead to a foundation wavefunction model. Such a model could yield high-accuracy ab-initio energies using only minimal computational effort for fine-tuning and evaluation of observables. ",
    "url": "https://arxiv.org/abs/2303.09949",
    "authors": [
      "Michael Scherbela",
      "Leon Gerard",
      "Philipp Grohs"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09987",
    "title": "Breast Cancer Histopathology Image based Gene Expression Prediction  using Spatial Transcriptomics data and Deep Learning",
    "abstract": "Tumour heterogeneity in breast cancer poses challenges in predicting outcome and response to therapy. Spatial transcriptomics technologies may address these challenges, as they provide a wealth of information about gene expression at the cell level, but they are expensive, hindering their use in large-scale clinical oncology studies. Predicting gene expression from hematoxylin and eosin stained histology images provides a more affordable alternative for such studies. Here we present BrST-Net, a deep learning framework for predicting gene expression from histopathology images using spatial transcriptomics data. Using this framework, we trained and evaluated 10 state-of-the-art deep learning models without utilizing pretrained weights for the prediction of 250 genes. To enhance the generalisation performance of the main network, we introduce an auxiliary network into the framework. Our methodology outperforms previous studies, with 237 genes identified with positive correlation, including 24 genes with a median correlation coefficient greater than 0.50. This is a notable improvement over previous studies, which could predict only 102 genes with positive correlation, with the highest correlation values ranging from 0.29 to 0.34. ",
    "url": "https://arxiv.org/abs/2303.09987",
    "authors": [
      "Md Mamunur Rahaman",
      "Ewan K. A. Millar",
      "Erik Meijering"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2303.10008",
    "title": "Configurable EBEN: Extreme Bandwidth Extension Network to enhance  body-conducted speech capture",
    "abstract": "This paper presents a configurable version of Extreme Bandwidth Extension Network (EBEN), a Generative Adversarial Network (GAN) designed to improve audio captured with body-conduction microphones. We show that these microphones significantly reduce environmental noise. However, this insensitivity to ambient noise is at the expense of the bandwidth of the voice signal acquired from the wearer of the devices. The obtained captured signals therefore require the use of signal enhancement techniques to recover the full-bandwidth speech. EBEN leverages a configurable multiband decomposition of the raw captured signal. This decomposition allows the data time domain dimensions to be reduced and the full band signal to be better controlled. The multiband representation of the captured signal is processed through a U-Net-like model, which combines feature and adversarial losses to generate an enhanced speech signal. We also benefit from this original representation in the proposed configurable discriminator architecture. The configurable EBEN approach can achieve state-of-the-art enhancement results on synthetic data with a lightweight generator that allows real-time processing. ",
    "url": "https://arxiv.org/abs/2303.10008",
    "authors": [
      "Julien Hauret",
      "Thomas Joubaud",
      "V\u00e9ronique Zimpfer",
      "\u00c9ric Bavu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.10036",
    "title": "Individual differences in knowledge network navigation",
    "abstract": "As online information accumulates at an unprecedented rate, it is becoming increasingly important and difficult to navigate the web efficiently. To create an easily navigable cyberspace for individuals across different age groups, genders, and other characteristics, we first need to understand how they navigate the web differently. Previous studies have revealed individual differences in spatial navigation, yet very little is known about their differences in knowledge space navigation. To close this gap, we conducted an online experiment where participants played a navigation game on Wikipedia and filled in questionnaires about their personal information. Our analysis shows that participants' navigation performance in the knowledge space declines with age and increases with foreign language skills. The difference between male and female performance is, however, not significant in our experiment. Participants' characteristics that predict success in finding routes to the target do not necessarily indicate their ability to find innovative routes. ",
    "url": "https://arxiv.org/abs/2303.10036",
    "authors": [
      "Manran Zhu",
      "Taha Yasseri",
      "J\u00e1nos Kert\u00e9sz"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.10081",
    "title": "Verification and Synthesis of Robust Control Barrier Functions:  Multilevel Polynomial Optimization and Semidefinite Relaxation",
    "abstract": "We study the problem of verification and synthesis of robust control barrier functions (CBF) for control-affine polynomial systems with bounded additive uncertainty and convex polynomial constraints on the control. We first formulate robust CBF verification and synthesis as multilevel polynomial optimization problems (POP), where verification optimizes -- in three levels -- the uncertainty, control, and state, while synthesis additionally optimizes the parameter of a chosen parametric CBF candidate. We then show that, by invoking the KKT conditions of the inner optimizations over uncertainty and control, the verification problem can be simplified as a single-level POP and the synthesis problem reduces to a min-max POP. This reduction leads to multilevel semidefinite relaxations. For the verification problem, we apply Lasserre's hierarchy of moment relaxations. For the synthesis problem, we draw connections to existing relaxation techniques for robust min-max POP, which first use sum-of-squares programming to find increasingly tight polynomial lower bounds to the unknown value function of the verification POP, and then call Lasserre's hierarchy again to maximize the lower bounds. Both semidefinite relaxations guarantee asymptotic global convergence to optimality. We provide an in-depth study of our framework on the controlled Van der Pol Oscillator, both with and without additive uncertainty. ",
    "url": "https://arxiv.org/abs/2303.10081",
    "authors": [
      "Shucheng Kang",
      "Yuxiao Chen",
      "Heng Yang",
      "Marco Pavone"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.10085",
    "title": "Robust probabilistic inference via a constrained transport metric",
    "abstract": "Flexible Bayesian models are typically constructed using limits of large parametric models with a multitude of parameters that are often uninterpretable. In this article, we offer a novel alternative by constructing an exponentially tilted empirical likelihood carefully designed to concentrate near a parametric family of distributions of choice with respect to a novel variant of the Wasserstein metric, which is then combined with a prior distribution on model parameters to obtain a robustified posterior. The proposed approach finds applications in a wide variety of robust inference problems, where we intend to perform inference on the parameters associated with the centering distribution in presence of outliers. Our proposed transport metric enjoys great computational simplicity, exploiting the Sinkhorn regularization for discrete optimal transport problems, and being inherently parallelizable. We demonstrate superior performance of our methodology when compared against state-of-the-art robust Bayesian inference methods. We also demonstrate equivalence of our approach with a nonparametric Bayesian formulation under a suitable asymptotic framework, testifying to its flexibility. The constrained entropy maximization that sits at the heart of our likelihood formulation finds its utility beyond robust Bayesian inference; an illustration is provided in a trustworthy machine learning application. ",
    "url": "https://arxiv.org/abs/2303.10085",
    "authors": [
      "Abhisek Chakraborty",
      "Anirban Bhattacharya",
      "Debdeep Pati"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.10096",
    "title": "Efficient Neural Generation of 4K Masks for Homogeneous Diffusion  Inpainting",
    "abstract": "With well-selected data, homogeneous diffusion inpainting can reconstruct images from sparse data with high quality. While 4K colour images of size 3840 x 2160 can already be inpainted in real time, optimising the known data for applications like image compression remains challenging: Widely used stochastic strategies can take days for a single 4K image. Recently, a first neural approach for this so-called mask optimisation problem offered high speed and good quality for small images. It trains a mask generation network with the help of a neural inpainting surrogate. However, these mask networks can only output masks for the resolution and mask density they were trained for. We solve these problems and enable mask optimisation for high-resolution images through a neuroexplicit coarse-to-fine strategy. Additionally, we improve the training and interpretability of mask networks by including a numerical inpainting solver directly into the network. This allows to generate masks for 4K images in around 0.6 seconds while exceeding the quality of stochastic methods on practically relevant densities. Compared to popular existing approaches, this is an acceleration of up to four orders of magnitude. ",
    "url": "https://arxiv.org/abs/2303.10096",
    "authors": [
      "Karl Schrader",
      "Pascal Peter",
      "Niklas K\u00e4mper",
      "Joachim Weickert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10116",
    "title": "Stack and Queue Numbers of Graphs Revisited",
    "abstract": "A long-standing question of the mutual relation between the stack and queue numbers of a graph, explicitly emphasized by Dujmovi\\'c and Wood in 2005, was \"half-answered\" by Dujmovi\\'c, Eppstein, Hickingbotham, Morin and Wood in 2022; they proved the existence of a graph family with the queue number at most 4 but unbounded stack number. We give an alternative very short, and still elementary, proof of the same fact. ",
    "url": "https://arxiv.org/abs/2303.10116",
    "authors": [
      "Petr Hlin\u011bn\u00fd",
      "Adam Straka"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.10127",
    "title": "Semicontraction and Synchronization of Kuramoto-Sakaguchi Oscillator  Networks",
    "abstract": "This paper studies the celebrated Kuramoto-Sakaguchi model of coupled oscillators adopting two recent concepts. First, we consider appropriately-defined subsets of the $n$-torus called winding cells. Second, we analyze the semicontractivity of the model, i.e., the property that the distance between trajectories decreases when measured according to a seminorm. This paper establishes the local semicontractivity of the Kuramoto-Sakaguchi model, which is equivalent to the local contractivity for the reduced model. The reduced model is defined modulo the rotational symmetry. The domains where the system is semicontracting are convex phase-cohesive subsets of winding cells. Our sufficient conditions and estimates of the semicontracting domains are less conservative and more explicit than in previous works. Based on semicontraction on phase-cohesive subsets, we establish the \"at most uniqueness\" of synchronous states within these domains, thereby characterizing the multistability of this model. ",
    "url": "https://arxiv.org/abs/2303.10127",
    "authors": [
      "Robin Delabays",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2303.10140",
    "title": "Geometric Deep Learning for Molecular Crystal Structure Prediction",
    "abstract": "We develop and test new machine learning strategies for accelerating molecular crystal structure ranking and crystal property prediction using tools from geometric deep learning on molecular graphs. Leveraging developments in graph-based learning and the availability of large molecular crystal datasets, we train models for density prediction and stability ranking which are accurate, fast to evaluate, and applicable to molecules of widely varying size and composition. Our density prediction model, MolXtalNet-D, achieves state of the art performance, with lower than 2% mean absolute error on a large and diverse test dataset. Our crystal ranking tool, MolXtalNet-S, correctly discriminates experimental samples from synthetically generated fakes and is further validated through analysis of the submissions to the Cambridge Structural Database Blind Tests 5 and 6. Our new tools are computationally cheap and flexible enough to be deployed within an existing crystal structure prediction pipeline both to reduce the search space and score/filter crystal candidates. ",
    "url": "https://arxiv.org/abs/2303.10140",
    "authors": [
      "Michael Kilgour",
      "Jutta Rogal",
      "Mark Tuckerman"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2003.09642",
    "title": "An Online Framework to Interact and Efficiently Compute Linear Layouts  of Graphs",
    "abstract": " Title: An Online Framework to Interact and Efficiently Compute Linear Layouts  of Graphs ",
    "url": "https://arxiv.org/abs/2003.09642",
    "authors": [
      "Michael A. Bekos",
      "Mirco Haug",
      "Michael Kaufmann",
      "Julia M\u00e4nnecke"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.03228",
    "title": "Distributional Reinforcement Learning with Unconstrained Monotonic  Neural Networks",
    "abstract": " Comments: Research paper accepted for publication in the peer-reviewed Neurocomputing journal edited by Elsevier ",
    "url": "https://arxiv.org/abs/2106.03228",
    "authors": [
      "Thibaut Th\u00e9ate",
      "Antoine Wehenkel",
      "Adrien Bolland",
      "Gilles Louppe",
      "Damien Ernst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.07217",
    "title": "Over-Fit: Noisy-Label Detection based on the Overfitted Model Property",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2106.07217",
    "authors": [
      "Seulki Park",
      "Hwanjun Song",
      "Daeho Um",
      "Dae Ung Jo",
      "Sangdoo Yun",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.12824",
    "title": "A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge  Domain Adaptation on FPGAs",
    "abstract": " Title: A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge  Domain Adaptation on FPGAs ",
    "url": "https://arxiv.org/abs/2107.12824",
    "authors": [
      "Hiroki Kawakami",
      "Hirohisa Watanabe",
      "Keisuke Sugiura",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2109.01636",
    "title": "Empirical Study of Named Entity Recognition Performance Using  Distribution-aware Word Embedding",
    "abstract": " Comments: Want to correct ",
    "url": "https://arxiv.org/abs/2109.01636",
    "authors": [
      "Xin Chen",
      "Qi Zhao",
      "Xinyang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.04248",
    "title": "Observations on K-image Expansion of Image-Mixing Augmentation for  Classification",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2110.04248",
    "authors": [
      "Joonhyun Jeong",
      "Sungmin Cha",
      "Youngjoon Yoo",
      "Sangdoo Yun",
      "Taesup Moon",
      "Jongwon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.03251",
    "title": "Computing a Link Diagram from its Exterior",
    "abstract": " Comments: 34 pages, 29 figures; V2 as appeared in \"Proceedings of the 38th International Symposium on Computational Geometry (SoCG 2022)\"; V3 restructured journal version, to appear in \"Discrete & Computational Geometry\" ",
    "url": "https://arxiv.org/abs/2112.03251",
    "authors": [
      "Nathan M. Dunfield",
      "Malik Obeidin",
      "Cameron Gates Rudd"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2201.09391",
    "title": "Partition-Based Active Learning for Graph Neural Networks",
    "abstract": " Comments: Accepted to Transactions on Machine Learning Research (TMLR). Code available at: this https URL ",
    "url": "https://arxiv.org/abs/2201.09391",
    "authors": [
      "Jiaqi Ma",
      "Ziqiao Ma",
      "Joyce Chai",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.11316",
    "title": "Transformer Module Networks for Systematic Generalization in Visual  Question Answering",
    "abstract": " Title: Transformer Module Networks for Systematic Generalization in Visual  Question Answering ",
    "url": "https://arxiv.org/abs/2201.11316",
    "authors": [
      "Moyuru Yamada",
      "Vanessa D'Amario",
      "Kentaro Takemoto",
      "Xavier Boix",
      "Tomotake Sasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08213",
    "title": "HUMUS-Net: Hybrid unrolled multi-scale network architecture for  accelerated MRI reconstruction",
    "abstract": " Comments: 18 pages, 11 figures, NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2203.08213",
    "authors": [
      "Zalan Fabian",
      "Berk Tinaz",
      "Mahdi Soltanolkotabi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.11700",
    "title": "ClusterGNN: Cluster-based Coarse-to-Fine Graph Neural Network for  Efficient Feature Matching",
    "abstract": " Comments: Has been accepted by IEEE Conference on Computer Vision and Pattern Recognition 2022,(modified some typos) ",
    "url": "https://arxiv.org/abs/2204.11700",
    "authors": [
      "Yan Shi",
      "Jun-Xiong Cai",
      "Yoli Shavit",
      "Tai-Jiang Mu",
      "Wensen Feng",
      "Kai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01420",
    "title": "Bridging Causal Reversibility and Time Reversibility: A Stochastic  Process Algebraic Approach",
    "abstract": " Title: Bridging Causal Reversibility and Time Reversibility: A Stochastic  Process Algebraic Approach ",
    "url": "https://arxiv.org/abs/2205.01420",
    "authors": [
      "Marco Bernardo",
      "Claudio A. Mezzina"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.11459",
    "title": "CELEST: Federated Learning for Globally Coordinated Threat Detection",
    "abstract": " Title: CELEST: Federated Learning for Globally Coordinated Threat Detection ",
    "url": "https://arxiv.org/abs/2205.11459",
    "authors": [
      "Talha Ongun",
      "Simona Boboila",
      "Alina Oprea",
      "Tina Eliassi-Rad",
      "Jason Hiser",
      "Jack Davidson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08101",
    "title": "Towards More Objective Evaluation of Class Incremental Learning:  Representation Learning Perspective",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2206.08101",
    "authors": [
      "Sungmin Cha",
      "Jihwan Kwak",
      "Dongsub Shim",
      "Hyunwoo Kim",
      "Moontae Lee",
      "Honglak Lee",
      "Taesup Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05205",
    "title": "Scaling Novel Object Detection with Weakly Supervised Detection  Transformers",
    "abstract": " Comments: WACV 2023. Preliminary version appeared in CVPR 2022 Workshop on Transformers for Vision ",
    "url": "https://arxiv.org/abs/2207.05205",
    "authors": [
      "Tyler LaBonte",
      "Yale Song",
      "Xin Wang",
      "Vibhav Vineet",
      "Neel Joshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.08162",
    "title": "Uncertainty Quantification of Collaborative Detection for Self-Driving",
    "abstract": " Comments: This paper has been accepted by the 2023 IEEE International Conference on Robotics and Automation (ICRA 2023) ",
    "url": "https://arxiv.org/abs/2209.08162",
    "authors": [
      "Sanbao Su",
      "Yiming Li",
      "Sihong He",
      "Songyang Han",
      "Chen Feng",
      "Caiwen Ding",
      "Fei Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11943",
    "title": "Planning for Multi-Object Manipulation with Graph Neural Network  Relational Classifiers",
    "abstract": " Comments: 10 pages, 7 figures, to be published in the proceedings of the IEEE Conference on Robotics and Automation (ICRA) 2023. Robot Demos: this https URL ",
    "url": "https://arxiv.org/abs/2209.11943",
    "authors": [
      "Yixuan Huang",
      "Adam Conkey",
      "Tucker Hermans"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.12849",
    "title": "AirTrack: Onboard Deep Learning Framework for Long-Range Aircraft  Detection and Tracking",
    "abstract": " Comments: 7 pages, 5 figures, ICRA 2023 ",
    "url": "https://arxiv.org/abs/2209.12849",
    "authors": [
      "Sourish Ghosh",
      "Jay Patrikar",
      "Brady Moon",
      "Milad Moghassem Hamidi",
      "and Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.13606",
    "title": "On the Adversarial Convex Body Chasing Problem",
    "abstract": " Title: On the Adversarial Convex Body Chasing Problem ",
    "url": "https://arxiv.org/abs/2209.13606",
    "authors": [
      "Yue Guan",
      "Longxu Pan",
      "Daigo Shishika",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.15042",
    "title": "EW-Tune: A Framework for Privately Fine-Tuning Large Language Models  with Differential Privacy",
    "abstract": " Comments: Publised at IEEE ICDM Workshop on Machine Learning for Cybersecurity (MLC) 2022 ",
    "url": "https://arxiv.org/abs/2210.15042",
    "authors": [
      "Rouzbeh Behnia",
      "Mohamamdreza Ebrahimi",
      "Jason Pacheco",
      "balaji Padmanabhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.16114",
    "title": "Towards Reliable Neural Specifications",
    "abstract": " Comments: 19 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2210.16114",
    "authors": [
      "Chuqin Geng",
      "Nham Le",
      "Xiaojie Xu",
      "Zhaoyue Wang",
      "Arie Gurfinkel",
      "Xujie Si"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.00313",
    "title": "RGMIM: Region-Guided Masked Image Modeling for COVID-19 Detection",
    "abstract": " Comments: Submitted as a journal paper at Springer IJCARS ",
    "url": "https://arxiv.org/abs/2211.00313",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.03929",
    "title": "Comparative layer-wise analysis of self-supervised speech models",
    "abstract": " Comments: Accepted to ICASSP 2023. Code: this https URL ",
    "url": "https://arxiv.org/abs/2211.03929",
    "authors": [
      "Ankita Pasad",
      "Bowen Shi",
      "Karen Livescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.14158",
    "title": "An Isolation-Aware Online Virtual Network Embedding via Deep  Reinforcement Learning",
    "abstract": " Comments: 7 pages, 9 figures, 3 tables, 2 algorithms ",
    "url": "https://arxiv.org/abs/2211.14158",
    "authors": [
      "Ali Gohar",
      "Chunming Rong",
      "Sanghwan Lee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14710",
    "title": "3DPPE: 3D Point Positional Encoding for Multi-Camera 3D Object Detection  Transformers",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2211.14710",
    "authors": [
      "Changyong Shu",
      "JIajun Deng",
      "Fisher Yu",
      "Yifan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05925",
    "title": "CausalEGM: a general causal inference framework by encoding generative  modeling",
    "abstract": " Title: CausalEGM: a general causal inference framework by encoding generative  modeling ",
    "url": "https://arxiv.org/abs/2212.05925",
    "authors": [
      "Qiao Liu",
      "Zhongren Chen",
      "Wing Hung Wong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.07766",
    "title": "DeepLSD: Line Segment Detection and Refinement with Deep Image Gradients",
    "abstract": " Comments: Accepted at CVPR 2023 ",
    "url": "https://arxiv.org/abs/2212.07766",
    "authors": [
      "R\u00e9mi Pautrat",
      "Daniel Barath",
      "Viktor Larsson",
      "Martin R. Oswald",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08756",
    "title": "Multi-Scales Data Augmentation Approach In Natural Language Inference  For Artifacts Mitigation And Pre-Trained Model Optimization",
    "abstract": " Title: Multi-Scales Data Augmentation Approach In Natural Language Inference  For Artifacts Mitigation And Pre-Trained Model Optimization ",
    "url": "https://arxiv.org/abs/2212.08756",
    "authors": [
      "Zhenyuan Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2301.00810",
    "title": "SIRL: Similarity-based Implicit Representation Learning",
    "abstract": " Comments: 12 pages, 6 figures, HRI 2023 ",
    "url": "https://arxiv.org/abs/2301.00810",
    "authors": [
      "Andreea Bobu",
      "Yi Liu",
      "Rohin Shah",
      "Daniel S. Brown",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.08771",
    "title": "Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt  Learning for Automatic Scoring in Science Education",
    "abstract": " Comments: 10+3 pages ",
    "url": "https://arxiv.org/abs/2301.08771",
    "authors": [
      "Xuansheng Wu",
      "Xinyu He",
      "Tianming Liu",
      "Ninghao Liu",
      "Xiaoming Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02614",
    "title": "A Pre-training Framework for Knowledge Graph Completion",
    "abstract": " Title: A Pre-training Framework for Knowledge Graph Completion ",
    "url": "https://arxiv.org/abs/2302.02614",
    "authors": [
      "Kuan Xu",
      "Kuo Yang",
      "Hanyang Dong",
      "Xinyan Wang",
      "Jian Yu",
      "Xuezhong Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.06175",
    "title": "Learning and Aggregating Lane Graphs for Urban Automated Driving",
    "abstract": " Comments: 22 pages, 17 figures ",
    "url": "https://arxiv.org/abs/2302.06175",
    "authors": [
      "Martin B\u00fcchner",
      "Jannik Z\u00fcrn",
      "Ion-George Todoran",
      "Abhinav Valada",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.00055",
    "title": "Learning time-scales in two-layers neural networks",
    "abstract": " Comments: 54 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2303.00055",
    "authors": [
      "Rapha\u00ebl Berthier",
      "Andrea Montanari",
      "Kangjie Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.00556",
    "title": "A linear bound for the Colin de Verdi\u00e8re parameter $\u03bc$ for graphs  embedded on surfaces",
    "abstract": " Title: A linear bound for the Colin de Verdi\u00e8re parameter $\u03bc$ for graphs  embedded on surfaces ",
    "url": "https://arxiv.org/abs/2303.00556",
    "authors": [
      "Camille Lanuel",
      "Francis Lazarus",
      "Rudi Pendavingh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.00575",
    "title": "IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint  Multi-Agent Trajectory Prediction",
    "abstract": " Comments: CVPR 2023 accepted ",
    "url": "https://arxiv.org/abs/2303.00575",
    "authors": [
      "Dekai Zhu",
      "Guangyao Zhai",
      "Yan Di",
      "Fabian Manhardt",
      "Hendrik Berkemeyer",
      "Tuan Tran",
      "Nassir Navab",
      "Federico Tombari",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.01979",
    "title": "ACL-SPC: Adaptive Closed-Loop system for Self-Supervised Point Cloud  Completion",
    "abstract": " Comments: Published at CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.01979",
    "authors": [
      "Sangmin Hong",
      "Mohsen Yavartanoo",
      "Reyhaneh Neshatavar",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.02735",
    "title": "Scalable Object Detection on Embedded Devices Using Weight Pruning and  Singular Value Decomposition",
    "abstract": " Comments: 8 pages, 3 figures. A report of the project done as part of the Yonsei-Roboin project for the 2nd semester, 2022 ",
    "url": "https://arxiv.org/abs/2303.02735",
    "authors": [
      "Dohyun Ham",
      "Jaeyeop Jeong",
      "June-Kyoo Park",
      "Raehyeon Jeong",
      "Seungmin Jeon",
      "Hyeongjun Jeon",
      "Yewon Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05617",
    "title": "KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF  Grasp Synthesis on RGB-D input",
    "abstract": " Comments: Submitted to IROS2023 ",
    "url": "https://arxiv.org/abs/2303.05617",
    "authors": [
      "Yiye Chen",
      "Ruinian Xu",
      "Yunzhi Lin",
      "Hongyi Chen",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06280",
    "title": "Investigating Stateful Defenses Against Black-Box Adversarial Examples",
    "abstract": " Title: Investigating Stateful Defenses Against Black-Box Adversarial Examples ",
    "url": "https://arxiv.org/abs/2303.06280",
    "authors": [
      "Ryan Feng",
      "Ashish Hooda",
      "Neal Mangaokar",
      "Kassem Fawaz",
      "Somesh Jha",
      "Atul Prakash"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06550",
    "title": "Spatial Correspondence between Graph Neural Network-Segmented Images",
    "abstract": " Comments: Accepted at MIDL 2023 (The Medical Imaging with Deep Learning conference, 2023) ",
    "url": "https://arxiv.org/abs/2303.06550",
    "authors": [
      "Qian Li",
      "Yunguan Fu",
      "Qianye Yang",
      "Zhijiang Du",
      "Hongjian Yu",
      "Yipeng Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08455",
    "title": "On the uncertainty analysis of the data-enabled physics-informed neural  network for solving neutron diffusion eigenvalue problem",
    "abstract": " Comments: The experiments in Figures 6 and 10 in the article have errors that need to be corrected. Moreover, we intend to make massive changes to the content of the article, and therefore need to withdraw the article ",
    "url": "https://arxiv.org/abs/2303.08455",
    "authors": [
      "Yu Yang",
      "Helin Gong",
      "Qihong Yang",
      "Yangtao Deng",
      "Qiaolin He",
      "Shiquan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2303.08874",
    "title": "Bayesian Quadrature for Neural Ensemble Search",
    "abstract": " Title: Bayesian Quadrature for Neural Ensemble Search ",
    "url": "https://arxiv.org/abs/2303.08874",
    "authors": [
      "Saad Hamid",
      "Xingchen Wan",
      "Martin J\u00f8rgensen",
      "Binxin Ru",
      "Michael Osborne"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09026",
    "title": "Commonsense Knowledge Assisted Deep Learning for Resource-constrained  and Fine-grained Object Detection",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2303.09026",
    "authors": [
      "Pu Zhang",
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09306",
    "title": "BanglaCoNER: Towards Robust Bangla Complex Named Entity Recognition",
    "abstract": " Comments: Winning Solution for the Bangla Complex Named Entity Recognition Challenge ",
    "url": "https://arxiv.org/abs/2303.09306",
    "authors": [
      "HAZ Sameen Shahgir",
      "Ramisa Alam",
      "Md. Zarif Ul Alam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09375",
    "title": "DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human  Avatars",
    "abstract": " Title: DINAR: Diffusion Inpainting of Neural Textures for One-Shot Human  Avatars ",
    "url": "https://arxiv.org/abs/2303.09375",
    "authors": [
      "David Svitov",
      "Dmitrii Gudkov",
      "Renat Bashirov",
      "Victor Lempitsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]