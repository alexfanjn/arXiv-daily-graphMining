[
  {
    "id": "arXiv:2303.10174",
    "title": "Visual Studio Code in Introductory Computer Science Course: An  Experience Report",
    "abstract": "Involving integrated development environments (IDEs) in introductory-level (CS1) programming courses is critical. However, it is difficult for instructors to find a suitable IDE that is beginner friendly and supports strong functionality. In this paper, we report the experience of using Visual Studio Code (VS Code) in a CS1 programming course. We describe our motivation for choosing VS Code and how we introduce it to students. We create comprehensive guidance with hierarchical indexing to help students with diverse programming backgrounds. We perform an experimental evaluation of students' programming experience of using VS Code and validate the VS Code together with guidance as a promising solution for CS1 programming courses. ",
    "url": "https://arxiv.org/abs/2303.10174",
    "authors": [
      "Jialiang Tan",
      "Yu Chen",
      "Shuyin Jiao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2303.10179",
    "title": "QUBO-inspired Molecular Fingerprint for Chemical Property Prediction",
    "abstract": "Molecular fingerprints are widely used for predicting chemical properties, and selecting appropriate fingerprints is important. We generate new fingerprints based on the assumption that a performance of prediction using a more effective fingerprint is better. We generate effective interaction fingerprints that are the product of multiple base fingerprints. It is difficult to evaluate all combinations of interaction fingerprints because of computational limitations. Against this problem, we transform a problem of searching more effective interaction fingerprints into a quadratic unconstrained binary optimization problem. In this study, we found effective interaction fingerprints using QM9 dataset. ",
    "url": "https://arxiv.org/abs/2303.10179",
    "authors": [
      "Koichiro Yawata",
      "Yoshihiro Osakabe",
      "Takuya Okuyama",
      "Akinori Asahara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2303.10183",
    "title": "A machine learning and feature engineering approach for the prediction  of the uncontrolled re-entry of space objects",
    "abstract": "The continuously growing number of objects orbiting around the Earth is expected to be accompanied by an increasing frequency of objects re-entering the Earth's atmosphere. Many of these re-entries will be uncontrolled, making their prediction challenging and subject to several uncertainties. Traditionally, re-entry predictions are based on the propagation of the object's dynamics using state-of-the-art modelling techniques for the forces acting on the object. However, modelling errors, particularly related to the prediction of atmospheric drag may result in poor prediction accuracies. In this context, we explore the possibility to perform a paradigm shift, from a physics-based approach to a data-driven approach. To this aim, we present the development of a deep learning model for the re-entry prediction of uncontrolled objects in Low Earth Orbit (LEO). The model is based on a modified version of the Sequence-to-Sequence architecture and is trained on the average altitude profile as derived from a set of Two-Line Element (TLE) data of over 400 bodies. The novelty of the work consists in introducing in the deep learning model, alongside the average altitude, three new input features: a drag-like coefficient (B*), the average solar index, and the area-to-mass ratio of the object. The developed model is tested on a set of objects studied in the Inter-Agency Space Debris Coordination Committee (IADC) campaigns. The results show that the best performances are obtained on bodies characterised by the same drag-like coefficient and eccentricity distribution as the training set. ",
    "url": "https://arxiv.org/abs/2303.10183",
    "authors": [
      "Francesco Salmaso",
      "Mirko Trisolini",
      "Camilla Colombo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.10209",
    "title": "CAPE: Camera View Position Embedding for Multi-View 3D Object Detection",
    "abstract": "In this paper, we address the problem of detecting 3D objects from multi-view images. Current query-based methods rely on global 3D position embeddings (PE) to learn the geometric correspondence between images and 3D space. We claim that directly interacting 2D image features with global 3D PE could increase the difficulty of learning view transformation due to the variation of camera extrinsics. Thus we propose a novel method based on CAmera view Position Embedding, called CAPE. We form the 3D position embeddings under the local camera-view coordinate system instead of the global coordinate system, such that 3D position embedding is free of encoding camera extrinsic parameters. Furthermore, we extend our CAPE to temporal modeling by exploiting the object queries of previous frames and encoding the ego-motion for boosting 3D object detection. CAPE achieves state-of-the-art performance (61.0% NDS and 52.5% mAP) among all LiDAR-free methods on nuScenes dataset. Codes and models are available on \\href{https://github.com/PaddlePaddle/Paddle3D}{Paddle3D} and \\href{https://github.com/kaixinbear/CAPE}{PyTorch Implementation}. ",
    "url": "https://arxiv.org/abs/2303.10209",
    "authors": [
      "Kaixin Xiong",
      "Shi Gong",
      "Xiaoqing Ye",
      "Xiao Tan",
      "Ji Wan",
      "Errui Ding",
      "Jingdong Wang",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10211",
    "title": "ASymReg: Robust symmetric image registration using anti-symmetric  formulation and deformation inversion layers",
    "abstract": "Deep learning based deformable medical image registration methods have emerged as a strong alternative for classical iterative registration methods. However, the currently published deep learning methods do not fulfill as strict symmetry properties with respect to the inputs as some classical registration methods, for which the registration outcome is the same regardless of the order of the inputs. While some deep learning methods label themselves as symmetric, they are either symmetric only a priori, which does not guarantee symmetry for any given input pair, or they do not generate accurate explicit inverses. In this work, we propose a novel registration architecture which by construction makes the registration network anti-symmetric with respect to its inputs. We demonstrate on two datasets that the proposed method achieves state-of-the-art results in terms of registration accuracy and that the generated deformations have accurate explicit inverses. ",
    "url": "https://arxiv.org/abs/2303.10211",
    "authors": [
      "Joel Honkamaa",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10214",
    "title": "BotShape: A Novel Social Bots Detection Approach via Behavioral Patterns",
    "abstract": "An essential topic in online social network security is how to accurately detect bot accounts and relieve their harmful impacts (e.g., misinformation, rumor, and spam) on genuine users. Based on a real-world data set, we construct behavioral sequences from raw event logs. After extracting critical characteristics from behavioral time series, we observe differences between bots and genuine users and similar patterns among bot accounts. We present a novel social bot detection system BotShape, to automatically catch behavioral sequences and characteristics as features for classifiers to detect bots. We evaluate the detection performance of our system in ground-truth instances, showing an average accuracy of 98.52% and an average f1-score of 96.65% on various types of classifiers. After comparing it with other research, we conclude that BotShape is a novel approach to profiling an account, which could improve performance for most methods by providing significant behavioral features. ",
    "url": "https://arxiv.org/abs/2303.10214",
    "authors": [
      "Jun Wu",
      "Xuesong Ye",
      "Chengjie Mou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10220",
    "title": "Synchronisation in TCP networks with Drop-Tail Queues",
    "abstract": "The design of transport protocols, embedded in end-systems, and the choice of buffer sizing strategies, within network routers, play an important role in performance analysis of the Internet. In this paper, we take a dynamical systems perspective on the interplay between fluid models for transport protocols and some router buffer sizing regimes. Among the flavours of TCP, we analyse Compound, as well as Reno and Illinois. The models for these TCP variants are coupled with a Drop-Tail policy, currently deployed in routers, in two limiting regimes: a small and an intermediate buffer regime. The topology we consider has two sets of long-lived TCP flows, each passing through separate edge routers, which merge at a common core router. Our analysis is inspired by time delayed coupled oscillators, where we obtain analytical conditions under which the sets of TCP flows synchronise. These conditions are made explicit in terms of coupling strengths, which depend on protocol parameters, and on network parameters like feedback delay, link capacity and buffer sizes. We find that variations in the coupling strengths can lead to limit cycles in the queue size. Packet-level simulations corroborate the analytical insights. For design, small Drop-Tail buffers are preferable over intermediate buffers as they can ensure both low latency and stable queues. ",
    "url": "https://arxiv.org/abs/2303.10220",
    "authors": [
      "Nizar Malangadan",
      "Gaurav Raina",
      "Debayani Ghosh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2303.10225",
    "title": "Robust Mode Connectivity-Oriented Adversarial Defense: Enhancing Neural  Network Robustness Against Diversified $\\ell_p$ Attacks",
    "abstract": "Adversarial robustness is a key concept in measuring the ability of neural networks to defend against adversarial attacks during the inference phase. Recent studies have shown that despite the success of improving adversarial robustness against a single type of attack using robust training techniques, models are still vulnerable to diversified $\\ell_p$ attacks. To achieve diversified $\\ell_p$ robustness, we propose a novel robust mode connectivity (RMC)-oriented adversarial defense that contains two population-based learning phases. The first phase, RMC, is able to search the model parameter space between two pre-trained models and find a path containing points with high robustness against diversified $\\ell_p$ attacks. In light of the effectiveness of RMC, we develop a second phase, RMC-based optimization, with RMC serving as the basic unit for further enhancement of neural network diversified $\\ell_p$ robustness. To increase computational efficiency, we incorporate learning with a self-robust mode connectivity (SRMC) module that enables the fast proliferation of the population used for endpoints of RMC. Furthermore, we draw parallels between SRMC and the human immune system. Experimental results on various datasets and model architectures demonstrate that the proposed defense methods can achieve high diversified $\\ell_p$ robustness against $\\ell_\\infty$, $\\ell_2$, $\\ell_1$, and hybrid attacks. Codes are available at \\url{https://github.com/wangren09/MCGR}. ",
    "url": "https://arxiv.org/abs/2303.10225",
    "authors": [
      "Ren Wang",
      "Yuxuan Li",
      "Sijia Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.10231",
    "title": "An Input-to-State Stability Perspective on Robust Locomotion",
    "abstract": "Uneven terrain necessarily transforms periodic walking into a non-periodic motion. As such, traditional stability analysis tools no longer adequately capture the ability of a bipedal robot to locomote in the presence of such disturbances. This motivates the need for analytical tools aimed at generalized notions of stability -- robustness. Towards this, we propose a novel definition of robustness, termed \\emph{$\\delta$-robustness}, to characterize the domain on which a nominal periodic orbit remains stable despite uncertain terrain. This definition is derived by treating perturbations in ground height as disturbances in the context of the input-to-state-stability (ISS) of the extended Poincar\\'{e} map associated with a periodic orbit. The main theoretic result is the formulation of robust Lyapunov functions that certify $\\delta$-robustness of periodic orbits. This yields an optimization framework for verifying $\\delta$-robustness, which is demonstrated in simulation with a bipedal robot walking on uneven terrain. ",
    "url": "https://arxiv.org/abs/2303.10231",
    "authors": [
      "Maegan Tucker",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.10236",
    "title": "Prevalence of Code Smells in Reinforcement Learning Projects",
    "abstract": "Reinforcement Learning (RL) is being increasingly used to learn and adapt application behavior in many domains, including large-scale and safety critical systems, as for example, autonomous driving. With the advent of plug-n-play RL libraries, its applicability has further increased, enabling integration of RL algorithms by users. We note, however, that the majority of such code is not developed by RL engineers, which as a consequence, may lead to poor program quality yielding bugs, suboptimal performance, maintainability, and evolution problems for RL-based projects. In this paper we begin the exploration of this hypothesis, specific to code utilizing RL, analyzing different projects found in the wild, to assess their quality from a software engineering perspective. Our study includes 24 popular RL-based Python projects, analyzed with standard software engineering metrics. Our results, aligned with similar analyses for ML code in general, show that popular and widely reused RL repositories contain many code smells (3.95% of the code base on average), significantly affecting the projects' maintainability. The most common code smells detected are long method and long method chain, highlighting problems in the definition and interaction of agents. Detected code smells suggest problems in responsibility separation, and the appropriateness of current abstractions for the definition of RL algorithms. ",
    "url": "https://arxiv.org/abs/2303.10236",
    "authors": [
      "Nicol\u00e1s Cardozo",
      "Ivana Dusparic",
      "Christian Cabrera"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.10253",
    "title": "Pricing for Multi-modal Pickup and Delivery Problems with Heterogeneous  Users",
    "abstract": "In this paper we study the pickup and delivery problem with multiple transportation modalities, and address the challenge of efficiently allocating transportation resources while price matching users with their desired delivery modes. Precisely, we consider that orders are demanded by a heterogeneous population of users with varying trade-offs between price and latency. To capture how prices affect the behavior of heterogeneous selfish users choosing between multiple delivery modes, we construct a congestion game taking place over a star network with independent sub-networks composed of parallel links connecting users with their preferred delivery method. Using the unique geometry of this network we prove that one can define prices explicitly to induce any desired network flow, i.e, given a desired allocation strategy we have a closed-form solution for the delivery prices. In connection with prior works that consider non-atomic congestion games, our result shows that one can simplify the Linear Program formulations used to solve for edge prices by first finding the path prices combinatorially. We conclude by performing a case study on a meal delivery problem with multiple courier modalities using data from real world instances. ",
    "url": "https://arxiv.org/abs/2303.10253",
    "authors": [
      "Mark Beliaev",
      "Negar Mehr",
      "Ramtin Pedarsani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.10254",
    "title": "Multi-Task Model Personalization for Federated Supervised SVM in  Heterogeneous Networks",
    "abstract": "In this paper, we design an efficient distributed iterative learning method based on support vector machines (SVMs), which tackles federated classification and regression. The proposed method supports efficient computations and model exchange in a network of heterogeneous nodes and allows personalization of the learning model in the presence of non-i.i.d. data. To further enhance privacy, we introduce a random mask procedure that helps avoid data inversion. Finally, we analyze the impact of the proposed privacy mechanisms and the heterogeneity of participant hardware and data on the system performance. ",
    "url": "https://arxiv.org/abs/2303.10254",
    "authors": [
      "Aleksei Ponomarenko-Timofeev",
      "Olga Galinina",
      "Ravikumar Balakrishnan",
      "Nageen Himayat",
      "Sergey Andreev",
      "Yevgeni Koucheryavy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10256",
    "title": "Solving Differential-Algebraic Equations in Power Systems Dynamics with  Neural Networks and Spatial Decomposition",
    "abstract": "The dynamics of the power system are described by a system of differential-algebraic equations. Time-domain simulations are used to understand the evolution of the system dynamics. These simulations can be computationally expensive due to the stiffness of the system which requires the use of finely discretized time-steps. By increasing the allowable time-step size, we aim to accelerate such simulations. In this paper, we use the observation that even though the individual components are described using both algebraic and differential equations, their coupling only involves algebraic equations. Following this observation, we use Neural Networks (NNs) to approximate the components' state evolution, leading to fast, accurate, and numerically stable approximators, which enable larger time-steps. To account for effects of the network on the components and vice-versa, the NNs take the temporal evolution of the coupling algebraic variables as an input for their prediction. We initially estimate this temporal evolution and then update it in an iterative fashion using the Newton-Raphson algorithm. The involved Jacobian matrix is calculated with Automatic Differentiation and its size depends only on the network size but not on the component dynamics. We demonstrate this NN-based simulator on the IEEE 9-bus test case with 3 generators. ",
    "url": "https://arxiv.org/abs/2303.10256",
    "authors": [
      "Jochen Stiasny",
      "Spyros Chatzivasileiadis",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.10262",
    "title": "Estimation of Unknown Payoff Parameters in Large Network Games",
    "abstract": "We consider network games where a large number of agents interact according to a network sampled from a random network model, represented by a graphon. By exploiting previous results on convergence of such large network games to graphon games, we examine a procedure for estimating unknown payoff parameters, from observations of equilibrium actions, without the need for exact network information. We prove smoothness and local convexity of the optimization problem involved in computing the proposed estimator. Additionally, under a notion of graphon parameter identifiability, we show that the optimal estimator is globally unique. We present several examples of identifiable homogeneous and heterogeneous parameters in different classes of linear quadratic network games with numerical simulations to validate the proposed estimator. ",
    "url": "https://arxiv.org/abs/2303.10262",
    "authors": [
      "Feras Al Taha",
      "Francesca Parise"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.10276",
    "title": "Unleashing the Potential of Spiking Neural Networks by Dynamic  Confidence",
    "abstract": "This paper presents a new methodology to alleviate the fundamental trade-off between accuracy and latency in spiking neural networks (SNNs). The approach involves decoding confidence information over time from the SNN outputs and using it to develop a decision-making agent that can dynamically determine when to terminate each inference. The proposed method, Dynamic Confidence, provides several significant benefits to SNNs. 1. It can effectively optimize latency dynamically at runtime, setting it apart from many existing low-latency SNN algorithms. Our experiments on CIFAR-10 and ImageNet datasets have demonstrated an average 40% speedup across eight different settings after applying Dynamic Confidence. 2. The decision-making agent in Dynamic Confidence is straightforward to construct and highly robust in parameter space, making it extremely easy to implement. 3. The proposed method enables visualizing the potential of any given SNN, which sets a target for current SNNs to approach. For instance, if an SNN can terminate at the most appropriate time point for each input sample, a ResNet-50 SNN can achieve an accuracy as high as 82.47% on ImageNet within just 4.71 time steps on average. Unlocking the potential of SNNs needs a highly-reliable decision-making agent to be constructed and fed with a high-quality estimation of ground truth. In this regard, Dynamic Confidence represents a meaningful step toward realizing the potential of SNNs. ",
    "url": "https://arxiv.org/abs/2303.10276",
    "authors": [
      "Chen Li",
      "Edward Jones",
      "Steve Furber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.10288",
    "title": "Mobile Edge Adversarial Detection for Digital Twinning to the Metaverse  with Deep Reinforcement Learning",
    "abstract": "Real-time Digital Twinning of physical world scenes onto the Metaverse is necessary for a myriad of applications such as augmented-reality (AR) assisted driving. In AR assisted driving, physical environment scenes are first captured by Internet of Vehicles (IoVs) and are uploaded to the Metaverse. A central Metaverse Map Service Provider (MMSP) will aggregate information from all IoVs to develop a central Metaverse Map. Information from the Metaverse Map can then be downloaded into individual IoVs on demand and be delivered as AR scenes to the driver. However, the growing interest in developing AR assisted driving applications which relies on digital twinning invites adversaries. These adversaries may place physical adversarial patches on physical world objects such as cars, signboards, or on roads, seeking to contort the virtual world digital twin. Hence, there is a need to detect these physical world adversarial patches. Nevertheless, as real-time, accurate detection of adversarial patches is compute-intensive, these physical world scenes have to be offloaded to the Metaverse Map Base Stations (MMBS) for computation. Hence in our work, we considered an environment with moving Internet of Vehicles (IoV), uploading real-time physical world scenes to the MMBSs. We formulated a realistic joint variable optimization problem where the MMSPs' objective is to maximize adversarial patch detection mean average precision (mAP), while minimizing the computed AR scene up-link transmission latency and IoVs' up-link transmission idle count, through optimizing the IoV-MMBS allocation and IoV up-link scene resolution selection. We proposed a Heterogeneous Action Proximal Policy Optimization (HAPPO) (discrete-continuous) algorithm to tackle the proposed problem. Extensive experiments shows HAPPO outperforms baseline models when compared against key metrics. ",
    "url": "https://arxiv.org/abs/2303.10288",
    "authors": [
      "Terence Jie Chua",
      "Wenhan Yu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10291",
    "title": "Detection of Uncertainty in Exceedance of Threshold (DUET): An  Adversarial Patch Localizer",
    "abstract": "Development of defenses against physical world attacks such as adversarial patches is gaining traction within the research community. We contribute to the field of adversarial patch detection by introducing an uncertainty-based adversarial patch localizer which localizes adversarial patch on an image, permitting post-processing patch-avoidance or patch-reconstruction. We quantify our prediction uncertainties with the development of \\textit{\\textbf{D}etection of \\textbf{U}ncertainties in the \\textbf{E}xceedance of \\textbf{T}hreshold} (DUET) algorithm. This algorithm provides a framework to ascertain confidence in the adversarial patch localization, which is essential for safety-sensitive applications such as self-driving cars and medical imaging. We conducted experiments on localizing adversarial patches and found our proposed DUET model outperforms baseline models. We then conduct further analyses on our choice of model priors and the adoption of Bayesian Neural Networks in different layers within our model architecture. We found that isometric gaussian priors in Bayesian Neural Networks are suitable for patch localization tasks and the presence of Bayesian layers in the earlier neural network blocks facilitates top-end localization performance, while Bayesian layers added in the later neural network blocks contribute to better model generalization. We then propose two different well-performing models to tackle different use cases. ",
    "url": "https://arxiv.org/abs/2303.10291",
    "authors": [
      "Terence Jie Chua",
      "Wenhan Yu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10311",
    "title": "On the rise of fear speech in online social media",
    "abstract": "Recently, social media platforms are heavily moderated to prevent the spread of online hate speech, which is usually fertile in toxic words and is directed toward an individual or a community. Owing to such heavy moderation, newer and more subtle techniques are being deployed. One of the most striking among these is fear speech. Fear speech, as the name suggests, attempts to incite fear about a target community. Although subtle, it might be highly effective, often pushing communities toward a physical conflict. Therefore, understanding their prevalence in social media is of paramount importance. This article presents a large-scale study to understand the prevalence of 400K fear speech and over 700K hate speech posts collected from Gab.com. Remarkably, users posting a large number of fear speech accrue more followers and occupy more central positions in social networks than users posting a large number of hate speech. They can also reach out to benign users more effectively than hate speech users through replies, reposts, and mentions. This connects to the fact that, unlike hate speech, fear speech has almost zero toxic content, making it look plausible. Moreover, while fear speech topics mostly portray a community as a perpetrator using a (fake) chain of argumentation, hate speech topics hurl direct multitarget insults, thus pointing to why general users could be more gullible to fear speech. Our findings transcend even to other platforms (Twitter and Facebook) and thus necessitate using sophisticated moderation policies and mass awareness to combat fear speech. ",
    "url": "https://arxiv.org/abs/2303.10311",
    "authors": [
      "Punyajoy Saha",
      "Kiran Garimella",
      "Narla Komal Kalyan",
      "Saurabh Kumar Pandey",
      "Pauras Mangesh Meher",
      "Binny Mathew",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.10312",
    "title": "EGTSyn: Edge-based Graph Transformer for Anti-Cancer Drug Combination  Synergy Prediction",
    "abstract": "Combination therapy with multiple drugs is a potent therapy strategy for complex diseases such as cancer, due to its therapeutic efficacy and potential for reducing side effects. However, the extensive search space of drug combinations makes it challenging to screen all combinations experimentally. To address this issue, computational methods have been developed to identify prioritized drug combinations. Recently, Convolutional Neural Networks based deep learning methods have shown great potential in this community. Although the significant progress has been achieved by existing computational models, they have overlooked the important high-level semantic information and significant chemical bond features of drugs. It is worth noting that such information is rich and it can be represented by the edges of graphs in drug combination predictions. In this work, we propose a novel Edge-based Graph Transformer, named EGTSyn, for effective anti-cancer drug combination synergy prediction. In EGTSyn, a special Edge-based Graph Neural Network (EGNN) is designed to capture the global structural information of chemicals and the important information of chemical bonds, which have been neglected by most previous studies. Furthermore, we design a Graph Transformer for drugs (GTD) that combines the EGNN module with a Transformer-architecture encoder to extract high-level semantic information of drugs. The proposed EGTSyn is highly capable of capturing the global chemical information and corresponding carcinoma cell line gene profiles for more accurate synergetic judgement of drug combinations. We compare the EGTSyn with classical machine learning based-models and state-of-the-art deep learning-based models, and the experiment results demonstrate that the EGTSyn outperforms these competitive methods. ",
    "url": "https://arxiv.org/abs/2303.10312",
    "authors": [
      "Jie Hu",
      "Xiaozhi Zhang",
      "Desi Shang",
      "Lijun Ouyang",
      "Yue Li",
      "Dongping Xiong"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.10321",
    "title": "ABC: Attention with Bilinear Correlation for Infrared Small Target  Detection",
    "abstract": "Infrared small target detection (ISTD) has a wide range of applications in early warning, rescue, and guidance. However, CNN based deep learning methods are not effective at segmenting infrared small target (IRST) that it lack of clear contour and texture features, and transformer based methods also struggle to achieve significant results due to the absence of convolution induction bias. To address these issues, we propose a new model called attention with bilinear correlation (ABC), which is based on the transformer architecture and includes a convolution linear fusion transformer (CLFT) module with a novel attention mechanism for feature extraction and fusion, which effectively enhances target features and suppresses noise. Additionally, our model includes a u-shaped convolution-dilated convolution (UCDC) module located deeper layers of the network, which takes advantage of the smaller resolution of deeper features to obtain finer semantic information. Experimental results on public datasets demonstrate that our approach achieves state-of-the-art performance. Code is available at https://github.com/PANPEIWEN/ABC ",
    "url": "https://arxiv.org/abs/2303.10321",
    "authors": [
      "Peiwen Pan",
      "Huan Wang",
      "Chenyi Wang",
      "Chang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10323",
    "title": "Dynamic Graph Enhanced Contrastive Learning for Chest X-ray Report  Generation",
    "abstract": "Automatic radiology reporting has great clinical potential to relieve radiologists from heavy workloads and improve diagnosis interpretation. Recently, researchers have enhanced data-driven neural networks with medical knowledge graphs to eliminate the severe visual and textual bias in this task. The structures of such graphs are exploited by using the clinical dependencies formed by the disease topic tags via general knowledge and usually do not update during the training process. Consequently, the fixed graphs can not guarantee the most appropriate scope of knowledge and limit the effectiveness. To address the limitation, we propose a knowledge graph with Dynamic structure and nodes to facilitate medical report generation with Contrastive Learning, named DCL. In detail, the fundamental structure of our graph is pre-constructed from general knowledge. Then we explore specific knowledge extracted from the retrieved reports to add additional nodes or redefine their relations in a bottom-up manner. Each image feature is integrated with its very own updated graph before being fed into the decoder module for report generation. Finally, this paper introduces Image-Report Contrastive and Image-Report Matching losses to better represent visual features and textual information. Evaluated on IU-Xray and MIMIC-CXR datasets, our DCL outperforms previous state-of-the-art models on these two benchmarks. ",
    "url": "https://arxiv.org/abs/2303.10323",
    "authors": [
      "Mingjie Li",
      "Bingqian Lin",
      "Zicong Chen",
      "Haokun Lin",
      "Xiaodan Liang",
      "Xiaojun Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10327",
    "title": "Hybrid Systems Neural Control with Region-of-Attraction Planner",
    "abstract": "Hybrid systems are prevalent in robotics. However, ensuring the stability of hybrid systems is challenging due to sophisticated continuous and discrete dynamics. A system with all its system modes stable can still be unstable. Hence special treatments are required at mode switchings to stabilize the system. In this work, we propose a hierarchical, neural network (NN)-based method to control general hybrid systems. For each system mode, we first learn an NN Lyapunov function and an NN controller to ensure the states within the region of attraction (RoA) can be stabilized. Then an RoA NN estimator is learned across different modes. Upon mode switching, we propose a differentiable planner to ensure the states after switching can land in next mode's RoA, hence stabilizing the hybrid system. We provide novel theoretical stability guarantees and conduct experiments in car tracking control, pogobot navigation, and bipedal walker locomotion. Our method only requires 0.25X of the training time as needed by other learning-based methods. With low running time (10-50X faster than model predictive control (MPC)), our controller achieves a higher stability/success rate over other baselines such as MPC, reinforcement learning (RL), common Lyapunov methods (CLF), linear quadratic regulator (LQR), quadratic programming (QP) and Hamilton-Jacobian-based methods (HJB). The project page is on https://mit-realm.github.io/hybrid-clf. ",
    "url": "https://arxiv.org/abs/2303.10327",
    "authors": [
      "Yue Meng",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.10336",
    "title": "Recognizing Complex Gestures on Minimalistic Knitted Sensors: Toward  Real-World Interactive Systems",
    "abstract": "Developments in touch-sensitive textiles have enabled many novel interactive techniques and applications. Our digitally-knitted capacitive active sensors can be manufactured at scale with little human intervention. Their sensitive areas are created from a single conductive yarn, and they require only few connections to external hardware. This technique increases their robustness and usability, while shifting the complexity of enabling interactivity from the hardware to computational models. This work advances the capabilities of such sensors by creating the foundation for an interactive gesture recognition system. It uses a novel sensor design, and a neural network-based recognition model to classify 12 relatively complex, single touch point gesture classes with 89.8% accuracy, unfolding many possibilities for future applications. We also demonstrate the system's applicability and robustness to real-world conditions through its performance while being worn and the impact of washing and drying on the sensor's resistance. ",
    "url": "https://arxiv.org/abs/2303.10336",
    "authors": [
      "Denisa Qori McDonald",
      "Richard Valett",
      "Lev Saunders",
      "Genevieve Dion",
      "Ali Shokoufandeh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10340",
    "title": "3D Data Augmentation for Driving Scenes on Camera",
    "abstract": "Driving scenes are extremely diverse and complicated that it is impossible to collect all cases with human effort alone. While data augmentation is an effective technique to enrich the training data, existing methods for camera data in autonomous driving applications are confined to the 2D image plane, which may not optimally increase data diversity in 3D real-world scenarios. To this end, we propose a 3D data augmentation approach termed Drive-3DAug, aiming at augmenting the driving scenes on camera in the 3D space. We first utilize Neural Radiance Field (NeRF) to reconstruct the 3D models of background and foreground objects. Then, augmented driving scenes can be obtained by placing the 3D objects with adapted location and orientation at the pre-defined valid region of backgrounds. As such, the training database could be effectively scaled up. However, the 3D object modeling is constrained to the image quality and the limited viewpoints. To overcome these problems, we modify the original NeRF by introducing a geometric rectified loss and a symmetric-aware training strategy. We evaluate our method for the camera-only monocular 3D detection task on the Waymo and nuScences datasets. The proposed data augmentation approach contributes to a gain of 1.7% and 1.4% in terms of detection accuracy, on Waymo and nuScences respectively. Furthermore, the constructed 3D models serve as digital driving assets and could be recycled for different detectors or other 3D perception tasks. ",
    "url": "https://arxiv.org/abs/2303.10340",
    "authors": [
      "Wenwen Tong",
      "Jiangwei Xie",
      "Tianyu Li",
      "Hanming Deng",
      "Xiangwei Geng",
      "Ruoyi Zhou",
      "Dingchen Yang",
      "Bo Dai",
      "Lewei Lu",
      "Hongyang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10343",
    "title": "LossMix: Simplify and Generalize Mixup for Object Detection and Beyond",
    "abstract": "The success of data mixing augmentations in image classification tasks has been well-received. However, these techniques cannot be readily applied to object detection due to challenges such as spatial misalignment, foreground/background distinction, and plurality of instances. To tackle these issues, we first introduce a novel conceptual framework called Supervision Interpolation, which offers a fresh perspective on interpolation-based augmentations by relaxing and generalizing Mixup. Building on this framework, we propose LossMix, a simple yet versatile and effective regularization that enhances the performance and robustness of object detectors and more. Our key insight is that we can effectively regularize the training on mixed data by interpolating their loss errors instead of ground truth labels. Empirical results on the PASCAL VOC and MS COCO datasets demonstrate that LossMix consistently outperforms currently popular mixing strategies. Furthermore, we design a two-stage domain mixing method that leverages LossMix to surpass Adaptive Teacher (CVPR 2022) and set a new state of the art for unsupervised domain adaptation. ",
    "url": "https://arxiv.org/abs/2303.10343",
    "authors": [
      "Thanh Vu",
      "Baochen Sun",
      "Bodi Yuan",
      "Alex Ngai",
      "Yueqi Li",
      "Jan-Michael Frahm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10344",
    "title": "Local-to-Global Panorama Inpainting for Locale-Aware Indoor Lighting  Prediction",
    "abstract": "Predicting panoramic indoor lighting from a single perspective image is a fundamental but highly ill-posed problem in computer vision and graphics. To achieve locale-aware and robust prediction, this problem can be decomposed into three sub-tasks: depth-based image warping, panorama inpainting and high-dynamic-range (HDR) reconstruction, among which the success of panorama inpainting plays a key role. Recent methods mostly rely on convolutional neural networks (CNNs) to fill the missing contents in the warped panorama. However, they usually achieve suboptimal performance since the missing contents occupy a very large portion in the panoramic space while CNNs are plagued by limited receptive fields. The spatially-varying distortion in the spherical signals further increases the difficulty for conventional CNNs. To address these issues, we propose a local-to-global strategy for large-scale panorama inpainting. In our method, a depth-guided local inpainting is first applied on the warped panorama to fill small but dense holes. Then, a transformer-based network, dubbed PanoTransformer, is designed to hallucinate reasonable global structures in the large holes. To avoid distortion, we further employ cubemap projection in our design of PanoTransformer. The high-quality panorama recovered at any locale helps us to capture spatially-varying indoor illumination with physically-plausible global structures and fine details. ",
    "url": "https://arxiv.org/abs/2303.10344",
    "authors": [
      "Jiayang Bai",
      "Zhen He",
      "Shan Yang",
      "Jie Guo",
      "Zhenyu Chen",
      "Yan Zhang",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10349",
    "title": "Uncertainty-aware U-Net for Medical Landmark Detection",
    "abstract": "Heatmap-based methods play an important role in anatomical landmark detection. However, most current heatmap-based methods assume that the distributions of all landmarks are the same and the distribution of each landmark is isotropic, which may not be in line with reality. For example, the landmark on the jaw is more likely to be located along the edge and less likely to be located inside or outside the jaw. Manually annotating tends to follow similar rules, resulting in an anisotropic distribution for annotated landmarks, which represents the uncertainty in the annotation. To estimate the uncertainty, we propose a module named Pyramid Covariance Predictor to predict the covariance matrices of the target Gaussian distributions, which determine the distributions of landmarks and represent the uncertainty of landmark annotation. Specifically, the Pyramid Covariance Predictor utilizes the pyramid features extracted by the encoder of the backbone U-Net and predicts the Cholesky decomposition of the covariance matrix of the landmark location distribution. Experimental results show that the proposed Pyramid Covariance Predictor can accurately predict the distributions and improve the performance of anatomical landmark detection. ",
    "url": "https://arxiv.org/abs/2303.10349",
    "authors": [
      "Ziyang Ye",
      "Haiyang Yu",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10351",
    "title": "Weight-sharing Supernet for Searching Specialized Acoustic Event  Classification Networks Across Device Constraints",
    "abstract": "Acoustic Event Classification (AEC) has been widely used in devices such as smart speakers and mobile phones for home safety or accessibility support. As AEC models run on more and more devices with diverse computation resource constraints, it became increasingly expensive to develop models that are tuned to achieve optimal accuracy/computation trade-off for each given computation resource constraint. In this paper, we introduce a Once-For-All (OFA) Neural Architecture Search (NAS) framework for AEC. Specifically, we first train a weight-sharing supernet that supports different model architectures, followed by automatically searching for a model given specific computational resource constraints. Our experimental results showed that by just training once, the resulting model from NAS significantly outperforms both models trained individually from scratch and knowledge distillation (25.4% and 7.3% relative improvement). We also found that the benefit of weight-sharing supernet training of ultra-small models comes not only from searching but from optimization. ",
    "url": "https://arxiv.org/abs/2303.10351",
    "authors": [
      "Guan-Ting Lin",
      "Qingming Tang",
      "Chieh-Chi Kao",
      "Viktor Rozgic",
      "Chao Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.10357",
    "title": "Integrated Photonic Accelerator Based on Optical Spectrum Slicing for  Convolutional Neural Networks",
    "abstract": "In this work we numerically analyze a passive photonic integrated neuromorphic accelerator based on hardware-friendly optical spectrum slicing nodes. The proposed scheme can act as a fully analogue convolutional layer, preprocessing information directly in the optical domain. The proposed scheme allows the extraction of meaningful spatio-temporal features from the incoming data, thus when used prior to a simple fully connected digital single layer network it can boost performance with negligible power consumption. Numerical simulations using the MNIST dataset confirmed the acceleration properties of the proposed scheme, where 10 neuromorphic nodes can replace the convolutional layers of a sophisticated LeNet-5 network, thus reducing the number of total floating point operations per second (FLOPS) by 98% while offering a 97.2% classification accuracy. ",
    "url": "https://arxiv.org/abs/2303.10357",
    "authors": [
      "Aris Tsirigotis",
      "George Sarantoglou",
      "Stavros Deligiannidis",
      "Kostas Sozos",
      "Adonis Bogris",
      "Charis Mesaritakis"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2303.10358",
    "title": "Neural Frailty Machine: Beyond proportional hazard assumption in neural  survival regressions",
    "abstract": "We present neural frailty machine (NFM), a powerful and flexible neural modeling framework for survival regressions. The NFM framework utilizes the classical idea of multiplicative frailty in survival analysis to capture unobserved heterogeneity among individuals, at the same time being able to leverage the strong approximation power of neural architectures for handling nonlinear covariate dependence. Two concrete models are derived under the framework that extends neural proportional hazard models and nonparametric hazard regression models. Both models allow efficient training under the likelihood objective. Theoretically, for both proposed models, we establish statistical guarantees of neural function approximation with respect to nonparametric components via characterizing their rate of convergence. Empirically, we provide synthetic experiments that verify our theoretical statements. We also conduct experimental evaluations over $6$ benchmark datasets of different scales, showing that the proposed NFM models outperform state-of-the-art survival models in terms of predictive performance. Our code is publicly availabel at https://github.com/Rorschach1989/nfm ",
    "url": "https://arxiv.org/abs/2303.10358",
    "authors": [
      "Ruofan Wu",
      "Jiawei Qiao",
      "Mingzhe Wu",
      "Wen Yu",
      "Ming Zheng",
      "Tengfei Liu",
      "Tianyi Zhang",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2303.10368",
    "title": "An Empirical Study of Pre-trained Language Models in Simple Knowledge  Graph Question Answering",
    "abstract": "Large-scale pre-trained language models (PLMs) such as BERT have recently achieved great success and become a milestone in natural language processing (NLP). It is now the consensus of the NLP community to adopt PLMs as the backbone for downstream tasks. In recent works on knowledge graph question answering (KGQA), BERT or its variants have become necessary in their KGQA models. However, there is still a lack of comprehensive research and comparison of the performance of different PLMs in KGQA. To this end, we summarize two basic KGQA frameworks based on PLMs without additional neural network modules to compare the performance of nine PLMs in terms of accuracy and efficiency. In addition, we present three benchmarks for larger-scale KGs based on the popular SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks and two other popular datasets, WebQuestionSP and FreebaseQA, and find that knowledge distillation techniques and knowledge enhancement methods in PLMs are promising for KGQA. Furthermore, we test ChatGPT, which has drawn a great deal of attention in the NLP community, demonstrating its impressive capabilities and limitations in zero-shot KGQA. We have released the code and benchmarks to promote the use of PLMs on KGQA. ",
    "url": "https://arxiv.org/abs/2303.10368",
    "authors": [
      "Nan Hu",
      "Yike Wu",
      "Guilin Qi",
      "Dehai Min",
      "Jiaoyan Chen",
      "Jeff Z. Pan",
      "Zafar Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.10370",
    "title": "How to Model Privacy Threats in the Automotive Domain",
    "abstract": "This paper questions how to approach threat modelling in the automotive domain at both an abstract level that features no domain-specific entities such as the CAN bus and, separately, at a detailed level. It addresses such questions by contributing a systematic method that is currently affected by the analyst's subjectivity because most of its inner operations are only defined informally. However, this potential limitation is overcome when candidate threats are identified and left to everyone's scrutiny. The systematic method is demonstrated on the established LINDDUN threat modelling methodology with respect to 4 pivotal works on privacy threat modelling in automotive. As a result, 8 threats that the authors deem not representable in LINDDUN are identified and suggested as possible candidate extensions to LINDDUN. Also, 56 threats are identified providing a detailed, automotive-specific model of threats. ",
    "url": "https://arxiv.org/abs/2303.10370",
    "authors": [
      "Mario Raciti",
      "Giampaolo Bella"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.10382",
    "title": "Interpretable Reinforcement Learning via Neural Additive Models for  Inventory Management",
    "abstract": "The COVID-19 pandemic has highlighted the importance of supply chains and the role of digital management to react to dynamic changes in the environment. In this work, we focus on developing dynamic inventory ordering policies for a multi-echelon, i.e. multi-stage, supply chain. Traditional inventory optimization methods aim to determine a static reordering policy. Thus, these policies are not able to adjust to dynamic changes such as those observed during the COVID-19 crisis. On the other hand, conventional strategies offer the advantage of being interpretable, which is a crucial feature for supply chain managers in order to communicate decisions to their stakeholders. To address this limitation, we propose an interpretable reinforcement learning approach that aims to be as interpretable as the traditional static policies while being as flexible and environment-agnostic as other deep learning-based reinforcement learning solutions. We propose to use Neural Additive Models as an interpretable dynamic policy of a reinforcement learning agent, showing that this approach is competitive with a standard full connected policy. Finally, we use the interpretability property to gain insights into a complex ordering strategy for a simple, linear three-echelon inventory supply chain. ",
    "url": "https://arxiv.org/abs/2303.10382",
    "authors": [
      "Julien Siems",
      "Maximilian Schambach",
      "Sebastian Schulze",
      "Johannes S. Otterbach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.10385",
    "title": "Social Occlusion Inference with Vectorized Representation for Autonomous  Driving",
    "abstract": "Autonomous vehicles must be capable of handling the occlusion of the environment to ensure safe and efficient driving. In urban environment, occlusion often arises due to other vehicles obscuring the perception of the ego vehicle. Since the occlusion condition can impact the trajectories of vehicles, the behavior of other vehicles is helpful in making inferences about the occlusion as a remedy for perceptual deficiencies. This paper introduces a novel social occlusion inference approach that learns a mapping from agent trajectories and scene context to an occupancy grid map (OGM) representing the view of ego vehicle. Specially, vectorized features are encoded through the polyline encoder to aggregate features of vectors into features of polylines. A transformer module is then utilized to model the high-order interactions of polylines. Importantly, occlusion queries are proposed to fuse polyline features and generate the OGM without the input of visual modality. To verify the performance of vectorized representation, we design a baseline based on a fully transformer encoder-decoder architecture mapping the OGM with occlusion and historical trajectories information to the ground truth OGM. We evaluate our approach on an unsignalized intersection in the INTERACTION dataset, which outperforms the state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2303.10385",
    "authors": [
      "Bochao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10394",
    "title": "Explorable families of graphs",
    "abstract": "Graph exploration is one of the fundamental tasks performed by a mobile agent in a graph. An $n$-node graph has unlabeled nodes, and all ports at any node of degree $d$ are arbitrarily numbered $0,\\dots, d-1$. A mobile agent, initially situated at some starting node $v$, has to visit all nodes of the graph and stop. In the absence of any initial knowledge of the graph the task of deterministic exploration is often impossible. On the other hand, for some families of graphs it is possible to design deterministic exploration algorithms working for any graph of the family. We call such families of graphs {\\em explorable}. Examples of explorable families are all finite families of graphs, as well as the family of all trees. In this paper we study the problem of which families of graphs are explorable. We characterize all such families, and then ask the question whether there exists a universal deterministic algorithm that, given an explorable family of graphs, explores any graph of this family, without knowing which graph of the family is being explored. The answer to this question turns out to depend on how the explorable family is given to the hypothetical universal algorithm. If the algorithm can get the answer to any yes/no question about the family, then such a universal algorithm can be constructed. If, on the other hand, the algorithm can be only given an algorithmic description of the input explorable family, then such a universal deterministic algorithm does not exist. ",
    "url": "https://arxiv.org/abs/2303.10394",
    "authors": [
      "Andrzej Pelc"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.10396",
    "title": "Towards Diverse Binary Segmentation via A Simple yet General Gated  Network",
    "abstract": "In many binary segmentation tasks, most CNNs-based methods use a U-shape encoder-decoder network as their basic structure. They ignore two key problems when the encoder exchanges information with the decoder: one is the lack of interference control mechanism between them, the other is without considering the disparity of the contributions from different encoder levels. In this work, we propose a simple yet general gated network (GateNet) to tackle them all at once. With the help of multi-level gate units, the valuable context information from the encoder can be selectively transmitted to the decoder. In addition, we design a gated dual branch structure to build the cooperation among the features of different levels and improve the discrimination ability of the network. Furthermore, we introduce a ``Fold'' operation to improve the atrous convolution and form a novel folded atrous convolution, which can be flexibly embedded in ASPP or DenseASPP to accurately localize foreground objects of various scales. GateNet can be easily generalized to many binary segmentation tasks, including general and specific object segmentation and multi-modal segmentation. Without bells and whistles, our network consistently performs favorably against the state-of-the-art methods under 10 metrics on 33 datasets of 10 binary segmentation tasks. ",
    "url": "https://arxiv.org/abs/2303.10396",
    "authors": [
      "Xiaoqi Zhao",
      "Youwei Pang",
      "Lihe Zhang",
      "Huchuan Lu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10404",
    "title": "MotionTrack: Learning Robust Short-term and Long-term Motions for  Multi-Object Tracking",
    "abstract": "The main challenge of Multi-Object Tracking~(MOT) lies in maintaining a continuous trajectory for each target. Existing methods often learn reliable motion patterns to match the same target between adjacent frames and discriminative appearance features to re-identify the lost targets after a long period. However, the reliability of motion prediction and the discriminability of appearances can be easily hurt by dense crowds and extreme occlusions in the tracking process. In this paper, we propose a simple yet effective multi-object tracker, i.e., MotionTrack, which learns robust short-term and long-term motions in a unified framework to associate trajectories from a short to long range. For dense crowds, we design a novel Interaction Module to learn interaction-aware motions from short-term trajectories, which can estimate the complex movement of each target. For extreme occlusions, we build a novel Refind Module to learn reliable long-term motions from the target's history trajectory, which can link the interrupted trajectory with its corresponding detection. Our Interaction Module and Refind Module are embedded in the well-known tracking-by-detection paradigm, which can work in tandem to maintain superior performance. Extensive experimental results on MOT17 and MOT20 datasets demonstrate the superiority of our approach in challenging scenarios, and it achieves state-of-the-art performances at various MOT metrics. ",
    "url": "https://arxiv.org/abs/2303.10404",
    "authors": [
      "Zheng Qin",
      "Sanping Zhou",
      "Le Wang",
      "Jinghai Duan",
      "Gang Hua",
      "Wei Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10408",
    "title": "ExplainFix: Explainable Spatially Fixed Deep Networks",
    "abstract": "Is there an initialization for deep networks that requires no learning? ExplainFix adopts two design principles: the \"fixed filters\" principle that all spatial filter weights of convolutional neural networks can be fixed at initialization and never learned, and the \"nimbleness\" principle that only few network parameters suffice. We contribute (a) visual model-based explanations, (b) speed and accuracy gains, and (c) novel tools for deep convolutional neural networks. ExplainFix gives key insights that spatially fixed networks should have a steered initialization, that spatial convolution layers tend to prioritize low frequencies, and that most network parameters are not necessary in spatially fixed models. ExplainFix models have up to 100x fewer spatial filter kernels than fully learned models and matching or improved accuracy. Our extensive empirical analysis confirms that ExplainFix guarantees nimbler models (train up to 17\\% faster with channel pruning), matching or improved predictive performance (spanning 13 distinct baseline models, four architectures and two medical image datasets), improved robustness to larger learning rate, and robustness to varying model size. We are first to demonstrate that all spatial filters in state-of-the-art convolutional deep networks can be fixed at initialization, not learned. ",
    "url": "https://arxiv.org/abs/2303.10408",
    "authors": [
      "Alex Gaudio",
      "Christos Faloutsos",
      "Asim Smailagic",
      "Pedro Costa",
      "Aurelio Campilho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10411",
    "title": "Multi-Semantic Interactive Learning for Object Detection",
    "abstract": "Single-branch object detection methods use shared features for localization and classification, yet the shared features are not fit for the two different tasks simultaneously. Multi-branch object detection methods usually use different features for localization and classification separately, ignoring the relevance between different tasks. Therefore, we propose multi-semantic interactive learning (MSIL) to mine the semantic relevance between different branches and extract multi-semantic enhanced features of objects. MSIL first performs semantic alignment of regression and classification branches, then merges the features of different branches by semantic fusion, finally extracts relevant information by semantic separation and passes it back to the regression and classification branches respectively. More importantly, MSIL can be integrated into existing object detection nets as a plug-and-play component. Experiments on the MS COCO, and Pascal VOC datasets show that the integration of MSIL with existing algorithms can utilize the relevant information between semantics of different tasks and achieve better performance. ",
    "url": "https://arxiv.org/abs/2303.10411",
    "authors": [
      "Shuxin Wang",
      "Zhichao Zheng",
      "Yanhui Gu",
      "Junsheng Zhou",
      "Yi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10422",
    "title": "Identification of Novel Classes for Improving Few-Shot Object Detection",
    "abstract": "Conventional training of deep neural networks requires a large number of the annotated image which is a laborious and time-consuming task, particularly for rare objects. Few-shot object detection (FSOD) methods offer a remedy by realizing robust object detection using only a few training samples per class. An unexplored challenge for FSOD is that instances from unlabeled novel classes that do not belong to the fixed set of training classes appear in the background. These objects behave similarly to label noise, leading to FSOD performance degradation. We develop a semi-supervised algorithm to detect and then utilize these unlabeled novel objects as positive samples during training to improve FSOD performance. Specifically, we propose a hierarchical ternary classification region proposal network (HTRPN) to localize the potential unlabeled novel objects and assign them new objectness labels. Our improved hierarchical sampling strategy for the region proposal network (RPN) also boosts the perception ability of the object detection model for large objects. Our experimental results indicate that our method is effective and outperforms the existing state-of-the-art (SOTA) FSOD methods. ",
    "url": "https://arxiv.org/abs/2303.10422",
    "authors": [
      "Zeyu Shangguan",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10432",
    "title": "Robust two-degrees-of-freedom control of hydraulic drive with remote  wireless operation",
    "abstract": "In this paper, a controller design targeting the remotely operated hydraulic drive system is presented. A two-degrees-of-freedom PID position controller is used, which is designed so that to maximize the integral action under robust constraint. A linearized model of the system plant, affected by the parameters uncertainties such as variable communication time-delay and overall system gain, is formulated and serves for the control design and analysis. The performed control synthesis and evaluation are targeting the remote operation where the wireless communication channel cannot secure a deterministic real-time of the control loop. The provided analysis of uncertainties makes it possible to ensure system stability under proper conditions. The theoretically expected results are confirmed through laboratory experiments on the standard industrial hydraulic components. ",
    "url": "https://arxiv.org/abs/2303.10432",
    "authors": [
      "Riccardo Checchin",
      "Michael Ruderman",
      "Roberto Oboe"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.10435",
    "title": "Modeling the Trade-off of Privacy Preservation and Activity Recognition  on Low-Resolution Images",
    "abstract": "A computer vision system using low-resolution image sensors can provide intelligent services (e.g., activity recognition) but preserve unnecessary visual privacy information from the hardware level. However, preserving visual privacy and enabling accurate machine recognition have adversarial needs on image resolution. Modeling the trade-off of privacy preservation and machine recognition performance can guide future privacy-preserving computer vision systems using low-resolution image sensors. In this paper, using the at-home activity of daily livings (ADLs) as the scenario, we first obtained the most important visual privacy features through a user survey. Then we quantified and analyzed the effects of image resolution on human and machine recognition performance in activity recognition and privacy awareness tasks. We also investigated how modern image super-resolution techniques influence these effects. Based on the results, we proposed a method for modeling the trade-off of privacy preservation and activity recognition on low-resolution images. ",
    "url": "https://arxiv.org/abs/2303.10435",
    "authors": [
      "Yuntao Wang",
      "Zirui Cheng",
      "Xin Yi",
      "Yan Kong",
      "Xueyang Wang",
      "Xuhai Xu",
      "Yukang Yan",
      "Chun Yu",
      "Shwetak Patel",
      "Yuanchun Shi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10444",
    "title": "Stall Number Detection of Cow Teats Key Frames",
    "abstract": "In this paper, we present a small cow stall number dataset named CowStallNumbers, which is extracted from cow teat videos with the goal of advancing cow stall number detection. This dataset contains 1042 training images and 261 test images with the stall number ranging from 0 to 60. In addition, we fine-tuned a ResNet34 model and augmented the dataset with the random crop, center crop, and random rotation. The experimental result achieves a 92% accuracy in stall number recognition and a 40.1% IoU score in stall number position prediction. ",
    "url": "https://arxiv.org/abs/2303.10444",
    "authors": [
      "Youshan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10445",
    "title": "EarCough: Enabling Continuous Subject Cough Event Detection on Hearables",
    "abstract": "Cough monitoring can enable new individual pulmonary health applications. Subject cough event detection is the foundation for continuous cough monitoring. Recently, the rapid growth in smart hearables has opened new opportunities for such needs. This paper proposes EarCough, which enables continuous subject cough event detection on edge computing hearables by leveraging the always-on active noise cancellation (ANC) microphones. Specifically, we proposed a lightweight end-to-end neural network model -- EarCoughNet. To evaluate the effectiveness of our method, we constructed a synchronous motion and audio dataset through a user study. Results show that EarCough achieved an accuracy of 95.4% and an F1-score of 92.9% with a space requirement of only 385 kB. We envision EarCough as a low-cost add-on for future hearables to enable continuous subject cough event detection. ",
    "url": "https://arxiv.org/abs/2303.10445",
    "authors": [
      "Xiyuxing Zhang",
      "Yuntao Wang",
      "Jingru Zhang",
      "Yaqing Yang",
      "Shwetak Patel",
      "Yuanchun Shi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.10446",
    "title": "A Content Adaptive Learnable Time-Frequency Representation For Audio  Signal Processing",
    "abstract": "We propose a learnable content adaptive front end for audio signal processing. Before the modern advent of deep learning, we used fixed representation non-learnable front-ends like spectrogram or mel-spectrogram with/without neural architectures. With convolutional architectures supporting various applications such as ASR and acoustic scene understanding, a shift to a learnable front ends occurred in which both the type of basis functions and the weight were learned from scratch and optimized for the particular task of interest. With the shift to transformer-based architectures with no convolutional blocks present, a linear layer projects small waveform patches onto a small latent dimension before feeding them to a transformer architecture. In this work, we propose a way of computing a content-adaptive learnable time-frequency representation. We pass each audio signal through a bank of convolutional filters, each giving a fixed-dimensional vector. It is akin to learning a bank of finite impulse-response filterbanks and passing the input signal through the optimum filter bank depending on the content of the input signal. A content-adaptive learnable time-frequency representation may be more broadly applicable, beyond the experiments in this paper. ",
    "url": "https://arxiv.org/abs/2303.10446",
    "authors": [
      "Prateek Verma",
      "Chris Chafe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.10449",
    "title": "Uncertainty-Aware Optimal Transport for Semantically Coherent  Out-of-Distribution Detection",
    "abstract": "Semantically coherent out-of-distribution (SCOOD) detection aims to discern outliers from the intended data distribution with access to unlabeled extra set. The coexistence of in-distribution and out-of-distribution samples will exacerbate the model overfitting when no distinction is made. To address this problem, we propose a novel uncertainty-aware optimal transport scheme. Our scheme consists of an energy-based transport (ET) mechanism that estimates the fluctuating cost of uncertainty to promote the assignment of semantic-agnostic representation, and an inter-cluster extension strategy that enhances the discrimination of semantic property among different clusters by widening the corresponding margin distance. Furthermore, a T-energy score is presented to mitigate the magnitude gap between the parallel transport and classifier branches. Extensive experiments on two standard SCOOD benchmarks demonstrate the above-par OOD detection performance, outperforming the state-of-the-art methods by a margin of 27.69% and 34.4% on FPR@95, respectively. ",
    "url": "https://arxiv.org/abs/2303.10449",
    "authors": [
      "Fan Lu",
      "Kai Zhu",
      "Wei Zhai",
      "Kecheng Zheng",
      "Yang Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10454",
    "title": "Performance Analysis and Optimization of Multi-RIS-Aided UAV Networks",
    "abstract": "In this paper, we study the performance of multiple reconfigurable intelligent surfaces (RISs)-aided unmanned aerial vehicle (UAV) communication networks over Nakagami-$m$ fading channels. For that purpose, we used accurate closed-form approximations for the channel distributions to derive closed-form approximations for the outage probability (OP), average symbol error probability (ASEP), and the average channel capacity assuming independent non-identically distributed (i.ni.d.) channels. Furthermore, we derive the asymptotic OP at the high signal-to-noise ratio (SNR) regime to get more insights into the system performance. We also study some practical scenarios related to RISs, UAV, and destination locations and illustrate their impact on the system performance through simulations. Finally, we provide an optimization problem on the transmit power of each channel. ",
    "url": "https://arxiv.org/abs/2303.10454",
    "authors": [
      "Khaled Alshehri",
      "Anas M. Salhab",
      "Ali Arshad Nasir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.10455",
    "title": "Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural  Networks",
    "abstract": "Deep neural networks (DNNs) are often trained on the premise that the complete training data set is provided ahead of time. However, in real-world scenarios, data often arrive in chunks over time. This leads to important considerations about the optimal strategy for training DNNs, such as whether to fine-tune them with each chunk of incoming data (warm-start) or to retrain them from scratch with the entire corpus of data whenever a new chunk is available. While employing the latter for training can be resource-intensive, recent work has pointed out the lack of generalization in warm-start models. Therefore, to strike a balance between efficiency and generalization, we introduce Learn, Unlearn, and Relearn (LURE) an online learning paradigm for DNNs. LURE interchanges between the unlearning phase, which selectively forgets the undesirable information in the model through weight reinitialization in a data-dependent manner, and the relearning phase, which emphasizes learning on generalizable features. We show that our training paradigm provides consistent performance gains across datasets in both classification and few-shot settings. We further show that it leads to more robust and well-calibrated models. ",
    "url": "https://arxiv.org/abs/2303.10455",
    "authors": [
      "Vijaya Raghavan T. Ramkumar",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10506",
    "title": "Neural Operators of Backstepping Controller and Observer Gain Functions  for Reaction-Diffusion PDEs",
    "abstract": "Unlike ODEs, whose models involve system matrices and whose controllers involve vector or matrix gains, PDE models involve functions in those roles functional coefficients, dependent on the spatial variables, and gain functions dependent on space as well. The designs of gains for controllers and observers for PDEs, such as PDE backstepping, are mappings of system model functions into gain functions. These infinite dimensional nonlinear operators are given in an implicit form through PDEs, in spatial variables, which need to be solved to determine the gain function for each new functional coefficient of the PDE. The need for solving such PDEs can be eliminated by learning and approximating the said design mapping in the form of a neural operator. Learning the neural operator requires a sufficient number of prior solutions for the design PDEs, offline, as well as the training of the operator. In recent work, we developed the neural operators for PDE backstepping designs for first order hyperbolic PDEs. Here we extend this framework to the more complex class of parabolic PDEs. The key theoretical question is whether the controllers are still stabilizing, and whether the observers are still convergent, if they employ the approximate functional gains generated by the neural operator. We provide affirmative answers to these questions, namely, we prove stability in closed loop under gains produced by neural operators. We illustrate the theoretical results with numerical tests and publish our code on github. The neural operators are three orders of magnitude faster in generating gain functions than PDE solvers for such gain functions. This opens up the opportunity for the use of this neural operator methodology in adaptive control and in gain scheduling control for nonlinear PDEs. ",
    "url": "https://arxiv.org/abs/2303.10506",
    "authors": [
      "Miroslav Krstic",
      "Luke Bhan",
      "Yuanyuan Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2303.10511",
    "title": "Exploring Expression-related Self-supervised Learning for Affective  Behaviour Analysis",
    "abstract": "This paper explores an expression-related self-supervised learning (SSL) method (ContraWarping) to perform expression classification in the 5th Affective Behavior Analysis in-the-wild (ABAW) competition. Affective datasets are expensive to annotate, and SSL methods could learn from large-scale unlabeled data, which is more suitable for this task. By evaluating on the Aff-Wild2 dataset, we demonstrate that ContraWarping outperforms most existing supervised methods and shows great application potential in the affective analysis area. Codes will be released on: https://github.com/youqingxiaozhua/ABAW5. ",
    "url": "https://arxiv.org/abs/2303.10511",
    "authors": [
      "Fanglei Xue",
      "Yifan Sun",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10517",
    "title": "Evolution of Automated Weakness Detection in Ethereum Bytecode: a  Comprehensive Study",
    "abstract": "Blockchain programs manage valuable assets like crypto-currencies and tokens, and implement protocols for decentralized finance (DeFi), logistics and logging, where security is important. To find potential issues, numerous tools support developers and analysts. Being a recent technology, blockchain technology and programs still evolve fast, making it challenging for tools and developers to keep up with the changes. In this work, we study the evolution of tools and patterns detected. We focus on Ethereum, the crypto ecosystem with most developers and most contracts, by far. We investigate the changes in the tools' behavior in terms of detected weaknesses, quality and behavior, and agreements between the tools. We are the first to fully cover the entire body of deployed bytecode on the Ethereum mainchain. We achieve full coverage by considering bytecodes as equivalent if they share the same skeleton. The skeleton of a bytecode is obtained by omitting functionally irrelevant parts. This reduces the 48 million contracts deployed on Ethereum to 248,328 contracts with distinct skeletons. For bulk execution, we utilize the open-source framework SmartBugs that facilitates the analysis of Solidity smart contracts, and enhance it to also accept bytecode as the only input. Moreover, we integrate six further tools that accept bytecode. The execution of the 13 included tools took 31 years in total. While the tools are reporting a total of 1,307,486 potential weaknesses, over time we observe a decreasing number of reported vulnerabilities and tools degrading to varying degrees. ",
    "url": "https://arxiv.org/abs/2303.10517",
    "authors": [
      "Monika di Angelo",
      "Thomas Durieux",
      "Jo\u00e3o F. Ferreira",
      "Gernot Salzer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.10528",
    "title": "LNO: Laplace Neural Operator for Solving Differential Equations",
    "abstract": "We introduce the Laplace neural operator (LNO), which leverages the Laplace transform to decompose the input space. Unlike the Fourier Neural Operator (FNO), LNO can handle non-periodic signals, account for transient responses, and exhibit exponential convergence. LNO incorporates the pole-residue relationship between the input and the output space, enabling greater interpretability and improved generalization ability. Herein, we demonstrate the superior approximation accuracy of a single Laplace layer in LNO over four Fourier modules in FNO in approximating the solutions of three ODEs (Duffing oscillator, driven gravity pendulum, and Lorenz system) and three PDEs (Euler-Bernoulli beam, diffusion equation, and reaction-diffusion system). Notably, LNO outperforms FNO in capturing transient responses in undamped scenarios. For the linear Euler-Bernoulli beam and diffusion equation, LNO's exact representation of the pole-residue formulation yields significantly better results than FNO. For the nonlinear reaction-diffusion system, LNO's errors are smaller than those of FNO, demonstrating the effectiveness of using system poles and residues as network parameters for operator learning. Overall, our results suggest that LNO represents a promising new approach for learning neural operators that map functions between infinite-dimensional spaces. ",
    "url": "https://arxiv.org/abs/2303.10528",
    "authors": [
      "Qianying Cao",
      "Somdatta Goswami",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10535",
    "title": "A Decision Making Approach for Chemotherapy Planning based on  Evolutionary Processing",
    "abstract": "The problem of chemotherapy treatment optimization can be defined in order to minimize the size of the tumor without endangering the patient's health; therefore, chemotherapy requires to achieve a number of objectives, simultaneously. For this reason, the optimization problem turns to a multi-objective problem. In this paper, a multi-objective meta-heuristic method is provided for cancer chemotherapy with the aim of balancing between two objectives: the amount of toxicity and the number of cancerous cells. The proposed method uses mathematical models in order to measure the drug concentration, tumor growth and the amount of toxicity. This method utilizes a Multi-Objective Particle Swarm Optimization (MOPSO) algorithm to optimize cancer chemotherapy plan using cell-cycle specific drugs. The proposed method can be a good model for personalized medicine as it returns a set of solutions as output that have balanced between different objectives and provided the possibility to choose the most appropriate therapeutic plan based on some information about the status of the patient. Experimental results confirm that the proposed method is able to explore the search space efficiently in order to find out the suitable treatment plan with minimal side effects. This main objective is provided using a desirable designing of chemotherapy drugs and controlling the injection dose. Moreover, results show that the proposed method achieve to a better therapeutic performance compared to a more recent similar method [1]. ",
    "url": "https://arxiv.org/abs/2303.10535",
    "authors": [
      "Mina Jafari",
      "Behnam Ghavami",
      "Vahid Sattari Naeini"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.10542",
    "title": "Wheat Head Counting by Estimating a Density Map with Convolutional  Neural Networks",
    "abstract": "Wheat is one of the most significant crop species with an annual worldwide grain production of 700 million tonnes. Assessing the production of wheat spikes can help us measure the grain production. Thus, detecting and characterizing spikes from images of wheat fields is an essential component in a wheat breeding process. In this study, we propose three wheat head counting networks (WHCNet\\_1, WHCNet\\_2 and WHCNet\\_3) to accurately estimate the wheat head count from an individual image and construct high quality density map, which illustrates the distribution of wheat heads in the image. The WHCNets are composed of two major components: a convolutional neural network (CNN) as the front-end for wheat head image feature extraction and a CNN with skip connections for the back-end to generate high-quality density maps. The dataset used in this study is the Global Wheat Head Detection (GWHD) dataset, which is a large, diverse, and well-labelled dataset of wheat images and built by a joint international collaborative effort. We compare our methods with CSRNet, a deep learning method which developed for highly congested scenes understanding and performing accurate count estimation as well as presenting high quality density maps. By taking the advantage of the skip connections between CNN layers, WHCNets integrate features from low CNN layers to high CNN layers, thus, the output density maps have both high spatial resolution and detailed representations of the input images. The experiments showed that our methods outperformed CSRNet in terms of the evaluation metrics, mean absolute error (MAE) and the root mean squared error (RMSE) with smaller model sizes. The code has been deposited on GitHub (\\url{https://github.com/hyguozz}). ",
    "url": "https://arxiv.org/abs/2303.10542",
    "authors": [
      "Hongyu Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10547",
    "title": "Event-triggered privacy preserving consensus control with edge-based  additive noise",
    "abstract": "In this article, we investigate the distributed privacy preserving weighted consensus control problem for linear continuous-time multi-agent systems under the event-triggering communication mode. A novel event-triggered privacy preserving consensus scheme is proposed, which can be divided into three phases. First, for each agent, an event-triggered mechanism is designed to determine whether the current state is transmitted to the corresponding neighbor agents, which avoids the frequent real-time communication. Then, to protect the privacy of initial states from disclosure, the edge-based mutually independent standard white noise is added to each communication channel. Further, to attenuate the effect of noise on consensus control, we propose a stochastic approximation type protocol for each agent. By using the tools of stochastic analysis and graph theory, the asymptotic property and convergence accuracy of consensus error is analyzed. Finally, a numerical simulation is given to illustrate the effectiveness of the proposed scheme. ",
    "url": "https://arxiv.org/abs/2303.10547",
    "authors": [
      "Limei Liang",
      "Ruiqi Ding",
      "Shuai Liu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.10552",
    "title": "Vehicle-Infrastructure Cooperative 3D Object Detection via Feature Flow  Prediction",
    "abstract": "Cooperatively utilizing both ego-vehicle and infrastructure sensor data can significantly enhance autonomous driving perception abilities. However, temporal asynchrony and limited wireless communication in traffic environments can lead to fusion misalignment and impact detection performance. This paper proposes Feature Flow Net (FFNet), a novel cooperative detection framework that uses a feature flow prediction module to address these issues in vehicle-infrastructure cooperative 3D object detection. Rather than transmitting feature maps extracted from still-images, FFNet transmits feature flow, which leverages the temporal coherence of sequential infrastructure frames to predict future features and compensate for asynchrony. Additionally, we introduce a self-supervised approach to enable FFNet to generate feature flow with feature prediction ability. Experimental results demonstrate that our proposed method outperforms existing cooperative detection methods while requiring no more than 1/10 transmission cost of raw data on the DAIR-V2X dataset when temporal asynchrony exceeds 200$ms$. The code is available at \\href{https://github.com/haibao-yu/FFNet-VIC3D}{https://github.com/haibao-yu/FFNet-VIC3D}. ",
    "url": "https://arxiv.org/abs/2303.10552",
    "authors": [
      "Haibao Yu",
      "Yingjuan Tang",
      "Enze Xie",
      "Jilei Mao",
      "Jirui Yuan",
      "Ping Luo",
      "Zaiqing Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10555",
    "title": "Revisiting LiDAR Spoofing Attack Capabilities against Object Detection:  Improvements, Measurement, and New Attack",
    "abstract": "LiDAR (Light Detection And Ranging) is an indispensable sensor for precise long- and wide-range 3D sensing, which directly benefited the recent rapid deployment of autonomous driving (AD). Meanwhile, such a safety-critical application strongly motivates its security research. A recent line of research demonstrates that one can manipulate the LiDAR point cloud and fool object detection by firing malicious lasers against LiDAR. However, these efforts face 3 critical research gaps: (1) evaluating only on a specific LiDAR (VLP-16); (2) assuming unvalidated attack capabilities; and (3) evaluating with models trained on limited datasets. To fill these critical research gaps, we conduct the first large-scale measurement study on LiDAR spoofing attack capabilities on object detectors with 9 popular LiDARs in total and 3 major types of object detectors. To perform this measurement, we significantly improved the LiDAR spoofing capability with more careful optics and functional electronics, which allows us to be the first to clearly demonstrate and quantify key attack capabilities assumed in prior works. However, we further find that such key assumptions actually can no longer hold for all the other (8 out of 9) LiDARs that are more recent than VLP-16 due to various recent LiDAR features. To this end, we further identify a new type of LiDAR spoofing attack that can improve on this and be applicable to a much more general and recent set of LiDARs. We find that its attack capability is enough to (1) cause end-to-end safety hazards in simulated AD scenarios, and (2) remove real vehicles in the physical world. We also discuss the defense side. ",
    "url": "https://arxiv.org/abs/2303.10555",
    "authors": [
      "Takami Sato",
      "Yuki Hayakawa",
      "Ryo Suzuki",
      "Yohsuke Shiiki",
      "Kentaro Yoshioka",
      "Qi Alfred Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10576",
    "title": "Efficiently Counting Substructures by Subgraph GNNs without Running GNN  on Subgraphs",
    "abstract": "Using graph neural networks (GNNs) to approximate specific functions such as counting graph substructures is a recent trend in graph learning. Among these works, a popular way is to use subgraph GNNs, which decompose the input graph into a collection of subgraphs and enhance the representation of the graph by applying GNN to individual subgraphs. Although subgraph GNNs are able to count complicated substructures, they suffer from high computational and memory costs. In this paper, we address a non-trivial question: can we count substructures efficiently with GNNs? To answer the question, we first theoretically show that the distance to the rooted nodes within subgraphs is key to boosting the counting power of subgraph GNNs. We then encode such information into structural embeddings, and precompute the embeddings to avoid extracting information over all subgraphs via GNNs repeatedly. Experiments on various benchmarks show that the proposed model can preserve the counting power of subgraph GNNs while running orders of magnitude faster. ",
    "url": "https://arxiv.org/abs/2303.10576",
    "authors": [
      "Zuoyu Yan",
      "Junru Zhou",
      "Liangcai Gao",
      "Zhi Tang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10580",
    "title": "Hierarchical Personalized Federated Learning Over Massive Mobile Edge  Computing Networks",
    "abstract": "Personalized Federated Learning (PFL) is a new Federated Learning (FL) paradigm, particularly tackling the heterogeneity issues brought by various mobile user equipments (UEs) in mobile edge computing (MEC) networks. However, due to the ever-increasing number of UEs and the complicated administrative work it brings, it is desirable to switch the PFL algorithm from its conventional two-layer framework to a multiple-layer one. In this paper, we propose hierarchical PFL (HPFL), an algorithm for deploying PFL over massive MEC networks. The UEs in HPFL are divided into multiple clusters, and the UEs in each cluster forward their local updates to the edge server (ES) synchronously for edge model aggregation, while the ESs forward their edge models to the cloud server semi-asynchronously for global model aggregation. The above training manner leads to a tradeoff between the training loss in each round and the round latency. HPFL combines the objectives of training loss minimization and round latency minimization while jointly determining the optimal bandwidth allocation as well as the ES scheduling policy in the hierarchical learning framework. Extensive experiments verify that HPFL not only guarantees convergence in hierarchical aggregation frameworks but also has advantages in round training loss maximization and round latency minimization. ",
    "url": "https://arxiv.org/abs/2303.10580",
    "authors": [
      "Chaoqun You",
      "Kun Guo",
      "Howard H. Yang",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.10585",
    "title": "Label Name is Mantra: Unifying Point Cloud Segmentation across  Heterogeneous Datasets",
    "abstract": "Point cloud segmentation is a fundamental task in 3D vision that serves a wide range of applications. Although great progresses have been made these years, its practical usability is still limited by the availability of training data. Existing approaches cannot make full use of multiple datasets on hand due to the label mismatch among different datasets. In this paper, we propose a principled approach that supports learning from heterogeneous datasets with different label sets. Our idea is to utilize a pre-trained language model to embed discrete labels to a continuous latent space with the help of their label names. This unifies all labels of different datasets, so that joint training is doable. Meanwhile, classifying points in the continuous 3D space by their vocabulary tokens significantly increase the generalization ability of the model in comparison with existing approaches that have fixed decoder architecture. Besides, we also integrate prompt learning in our framework to alleviate data shifts among different data sources. Extensive experiments demonstrate that our model outperforms the state-of-the-art by a large margin. ",
    "url": "https://arxiv.org/abs/2303.10585",
    "authors": [
      "Yixun Liang",
      "Hao He",
      "Shishi Xiao",
      "Hao Lu",
      "Yingcong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10590",
    "title": "Multi-modal Facial Action Unit Detection with Large Pre-trained Models  for the 5th Competition on Affective Behavior Analysis in-the-wild",
    "abstract": "Facial action unit detection has emerged as an important task within facial expression analysis, aimed at detecting specific pre-defined, objective facial expressions, such as lip tightening and cheek raising. This paper presents our submission to the Affective Behavior Analysis in-the-wild (ABAW) 2023 Competition for AU detection. We propose a multi-modal method for facial action unit detection with visual, acoustic, and lexical features extracted from the large pre-trained models. To provide high-quality details for visual feature extraction, we apply super-resolution and face alignment to the training data and show potential performance gain. Our approach achieves the F1 score of 52.3\\% on the official validation set of the 5th ABAW Challenge. ",
    "url": "https://arxiv.org/abs/2303.10590",
    "authors": [
      "Yufeng Yin",
      "Minh Tran",
      "Di Chang",
      "Xinrui Wang",
      "Mohammad Soleymani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10594",
    "title": "AdaptGuard: Defending Against Universal Attacks for Model Adaptation",
    "abstract": "Model adaptation aims at solving the domain transfer problem under the constraint of only accessing the pretrained source models. With the increasing considerations of data privacy and transmission efficiency, this paradigm has been gaining recent popularity. This paper studies the vulnerability to universal attacks transferred from the source domain during model adaptation algorithms due to the existence of the malicious providers. We explore both universal adversarial perturbations and backdoor attacks as loopholes on the source side and discover that they still survive in the target models after adaptation. To address this issue, we propose a model preprocessing framework, named AdaptGuard, to improve the security of model adaptation algorithms. AdaptGuard avoids direct use of the risky source parameters through knowledge distillation and utilizes the pseudo adversarial samples under adjusted radius to enhance the robustness. AdaptGuard is a plug-and-play module that requires neither robust pretrained models nor any changes for the following model adaptation algorithms. Extensive results on three commonly used datasets and two popular adaptation methods validate that AdaptGuard can effectively defend against universal attacks and maintain clean accuracy in the target domain simultaneously. We hope this research will shed light on the safety and robustness of transfer learning. ",
    "url": "https://arxiv.org/abs/2303.10594",
    "authors": [
      "Lijun Sheng",
      "Jian Liang",
      "Ran He",
      "Zilei Wang",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10597",
    "title": "Partial Network Cloning",
    "abstract": "In this paper, we study a novel task that enables partial knowledge transfer from pre-trained models, which we term as Partial Network Cloning (PNC). Unlike prior methods that update all or at least part of the parameters in the target network throughout the knowledge transfer process, PNC conducts partial parametric \"cloning\" from a source network and then injects the cloned module to the target, without modifying its parameters. Thanks to the transferred module, the target network is expected to gain additional functionality, such as inference on new classes; whenever needed, the cloned module can be readily removed from the target, with its original parameters and competence kept intact. Specifically, we introduce an innovative learning scheme that allows us to identify simultaneously the component to be cloned from the source and the position to be inserted within the target network, so as to ensure the optimal performance. Experimental results on several datasets demonstrate that, our method yields a significant improvement of 5% in accuracy and 50% in locality when compared with parameter-tuning based methods. Our code is available at https://github.com/JngwenYe/PNCloning. ",
    "url": "https://arxiv.org/abs/2303.10597",
    "authors": [
      "Jingwen Ye",
      "Songhua Liu",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10598",
    "title": "StyleRF: Zero-shot 3D Style Transfer of Neural Radiance Fields",
    "abstract": "3D style transfer aims to render stylized novel views of a 3D scene with multi-view consistency. However, most existing work suffers from a three-way dilemma over accurate geometry reconstruction, high-quality stylization, and being generalizable to arbitrary new styles. We propose StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field. StyleRF employs an explicit grid of high-level features to represent 3D scenes, with which high-fidelity geometry can be reliably restored via volume rendering. In addition, it transforms the grid features according to the reference style which directly leads to high-quality zero-shot style transfer. StyleRF consists of two innovative designs. The first is sampling-invariant content transformation that makes the transformation invariant to the holistic statistics of the sampled 3D points and accordingly ensures multi-view consistency. The second is deferred style transformation of 2D feature maps which is equivalent to the transformation of 3D points but greatly reduces memory footprint without degrading multi-view consistency. Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner. ",
    "url": "https://arxiv.org/abs/2303.10598",
    "authors": [
      "Kunhao Liu",
      "Fangneng Zhan",
      "Yiwen Chen",
      "Jiahui Zhang",
      "Yingchen Yu",
      "Abdulmotaleb El Saddik",
      "Shijian Lu",
      "Eric Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10606",
    "title": "CTRAN: CNN-Transformer-based Network for Natural Language Understanding",
    "abstract": "Intent-detection and slot-filling are the two main tasks in natural language understanding. In this study, we propose CTRAN, a novel encoder-decoder CNN-Transformer-based architecture for intent-detection and slot-filling. In the encoder, we use BERT, followed by several convolutional layers, and rearrange the output using window feature sequence. We use stacked Transformer encoders after the window feature sequence. For the intent-detection decoder, we utilize self-attention followed by a linear layer. In the slot-filling decoder, we introduce the aligned Transformer decoder, which utilizes a zero diagonal mask, aligning output tags with input tokens. We apply our network on ATIS and SNIPS, and surpass the current state-of-the-art in slot-filling on both datasets. Furthermore, we incorporate the language model as word embeddings, and show that this strategy yields a better result when compared to the language model as an encoder. ",
    "url": "https://arxiv.org/abs/2303.10606",
    "authors": [
      "Mehrdad Rafiepour",
      "Javad Salimi Sartakhti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.10610",
    "title": "DiffMIC: Dual-Guidance Diffusion Network for Medical Image  Classification",
    "abstract": "Diffusion Probabilistic Models have recently shown remarkable performance in generative image modeling, attracting significant attention in the computer vision community. However, while a substantial amount of diffusion-based research has focused on generative tasks, few studies have applied diffusion models to general medical image classification. In this paper, we propose the first diffusion-based model (named DiffMIC) to address general medical image classification by eliminating unexpected noise and perturbations in medical images and robustly capturing semantic representation. To achieve this goal, we devise a dual conditional guidance strategy that conditions each diffusion step with multiple granularities to improve step-wise regional attention. Furthermore, we propose learning the mutual information in each granularity by enforcing Maximum-Mean Discrepancy regularization during the diffusion forward process. We evaluate the effectiveness of our DiffMIC on three medical classification tasks with different image modalities, including placental maturity grading on ultrasound images, skin lesion classification using dermatoscopic images, and diabetic retinopathy grading using fundus images. Our experimental results demonstrate that DiffMIC outperforms state-of-the-art methods by a significant margin, indicating the universality and effectiveness of the proposed model. ",
    "url": "https://arxiv.org/abs/2303.10610",
    "authors": [
      "Yijun Yang",
      "Huazhu Fu",
      "Angelica Aviles-Rivero",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Lei Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10612",
    "title": "Bangla Grammatical Error Detection Using T5 Transformer Model",
    "abstract": "This paper presents a method for detecting grammatical errors in Bangla using a Text-to-Text Transfer Transformer (T5) Language Model, using the small variant of BanglaT5, fine-tuned on a corpus of 9385 sentences where errors were bracketed by the dedicated demarcation symbol. The T5 model was primarily designed for translation and is not specifically designed for this task, so extensive post-processing was necessary to adapt it to the task of error detection. Our experiments show that the T5 model can achieve low Levenshtein Distance in detecting grammatical errors in Bangla, but post-processing is essential to achieve optimal performance. The final average Levenshtein Distance after post-processing the output of the fine-tuned model was 1.0394 on a test set of 5000 sentences. This paper also presents a detailed analysis of the errors detected by the model and discusses the challenges of adapting a translation model for grammar. Our approach can be extended to other languages, demonstrating the potential of T5 models for detecting grammatical errors in a wide range of languages. ",
    "url": "https://arxiv.org/abs/2303.10612",
    "authors": [
      "H.A.Z. Sameen Shahgir",
      "Khondker Salman Sayeed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10613",
    "title": "SECAD-Net: Self-Supervised CAD Reconstruction by Learning Sketch-Extrude  Operations",
    "abstract": "Reverse engineering CAD models from raw geometry is a classic but strenuous research problem. Previous learning-based methods rely heavily on labels due to the supervised design patterns or reconstruct CAD shapes that are not easily editable. In this work, we introduce SECAD-Net, an end-to-end neural network aimed at reconstructing compact and easy-to-edit CAD models in a self-supervised manner. Drawing inspiration from the modeling language that is most commonly used in modern CAD software, we propose to learn 2D sketches and 3D extrusion parameters from raw shapes, from which a set of extrusion cylinders can be generated by extruding each sketch from a 2D plane into a 3D body. By incorporating the Boolean operation (i.e., union), these cylinders can be combined to closely approximate the target geometry. We advocate the use of implicit fields for sketch representation, which allows for creating CAD variations by interpolating latent codes in the sketch latent space. Extensive experiments on both ABC and Fusion 360 datasets demonstrate the effectiveness of our method, and show superiority over state-of-the-art alternatives including the closely related method for supervised CAD reconstruction. We further apply our approach to CAD editing and single-view CAD reconstruction. The code is released at https://github.com/BunnySoCrazy/SECAD-Net. ",
    "url": "https://arxiv.org/abs/2303.10613",
    "authors": [
      "Pu Li",
      "Jianwei Guo",
      "Xiaopeng Zhang",
      "Dong-ming Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10623",
    "title": "Active hypothesis testing in unknown environments using recurrent neural  networks and model free reinforcement learning",
    "abstract": "A combination of deep reinforcement learning and supervised learning is proposed for the problem of active sequential hypothesis testing in completely unknown environments. We make no assumptions about the prior probability, the action and observation sets, and the observation generating process. Our method can be used in any environment even if it has continuous observations or actions, and performs competitively and sometimes better than the Chernoff test, in both finite and infinite horizon problems, despite not having access to the environment dynamics. ",
    "url": "https://arxiv.org/abs/2303.10623",
    "authors": [
      "George Stamatelis",
      "Nicholas Kalouptsidis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.10624",
    "title": "PFSL: Personalized & Fair Split Learning with Data & Label Privacy for  thin clients",
    "abstract": "The traditional framework of federated learning (FL) requires each client to re-train their models in every iteration, making it infeasible for resource-constrained mobile devices to train deep-learning (DL) models. Split learning (SL) provides an alternative by using a centralized server to offload the computation of activations and gradients for a subset of the model but suffers from problems of slow convergence and lower accuracy. In this paper, we implement PFSL, a new framework of distributed split learning where a large number of thin clients perform transfer learning in parallel, starting with a pre-trained DL model without sharing their data or labels with a central server. We implement a lightweight step of personalization of client models to provide high performance for their respective data distributions. Furthermore, we evaluate performance fairness amongst clients under a work fairness constraint for various scenarios of non-i.i.d. data distributions and unequal sample sizes. Our accuracy far exceeds that of current SL algorithms and is very close to that of centralized learning on several real-life benchmarks. It has a very low computation cost compared to FL variants and promises to deliver the full benefits of DL to extremely thin, resource-constrained clients. ",
    "url": "https://arxiv.org/abs/2303.10624",
    "authors": [
      "Manas Wadhwa",
      "Gagan Raj Gupta",
      "Ashutosh Sahu",
      "Rahul Saini",
      "Vidhi Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.10625",
    "title": "Finite element discretization of a biological network formation system:  a preliminary study",
    "abstract": "A finite element discretization is developed for the Cai-Hu model, describing the formation of biological networks. The model consists of a non linear elliptic equation for the pressure $p$ and a non linear reaction-diffusion equation for the conductivity tensor $\\mathbb{C}$. The problem requires high resolution due to the presence of multiple scales, the stiffness in all its components and the non linearities. We propose a low order finite element discretization in space coupled with a semi-implicit time advancing scheme. The code is validated with several numerical tests performed with various choices for the parameters involved in the system. In absence of the exact solution, we apply Richardson extrapolation technique to estimate the order of the method. ",
    "url": "https://arxiv.org/abs/2303.10625",
    "authors": [
      "Clarissa Astuto",
      "Daniele Boffi",
      "Fabio Credali"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.10632",
    "title": "Training a spiking neural network on an event-based label-free flow  cytometry dataset",
    "abstract": "Imaging flow cytometry systems aim to analyze a huge number of cells or micro-particles based on their physical characteristics. The vast majority of current systems acquire a large amount of images which are used to train deep artificial neural networks. However, this approach increases both the latency and power consumption of the final apparatus. In this work-in-progress, we combine an event-based camera with a free-space optical setup to obtain spikes for each particle passing in a microfluidic channel. A spiking neural network is trained on the collected dataset, resulting in 97.7% mean training accuracy and 93.5% mean testing accuracy for the fully event-based classification pipeline. ",
    "url": "https://arxiv.org/abs/2303.10632",
    "authors": [
      "Muhammed Gouda",
      "Steven Abreu",
      "Alessio Lugnan",
      "Peter Bienstman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2303.10644",
    "title": "Spatio-Temporal AU Relational Graph Representation Learning For Facial  Action Units Detection",
    "abstract": "This paper presents our Facial Action Units (AUs) recognition submission to the fifth Affective Behavior Analysis in-the-wild Competition (ABAW). Our approach consists of three main modules: (i) a pre-trained facial representation encoder which produce a strong facial representation from each input face image in the input sequence; (ii) an AU-specific feature generator that specifically learns a set of AU features from each facial representation; and (iii) a spatio-temporal graph learning module that constructs a spatio-temporal graph representation. This graph representation describes AUs contained in all frames and predicts the occurrence of each AU based on both the modeled spatial information within the corresponding face and the learned temporal dynamics among frames. The experimental results show that our approach outperformed the baseline and the spatio-temporal graph representation learning allows the model to generate the best results among all ablation systems. ",
    "url": "https://arxiv.org/abs/2303.10644",
    "authors": [
      "Zihan Wang",
      "Siyang Song",
      "Cheng Luo",
      "Yuzhi Zhou",
      "shiling Wu",
      "Weicheng Xie",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10646",
    "title": "Metric dimension parameterized by treewidth in chordal graphs",
    "abstract": "The metric dimension has been introduced independently by Harary, Melter and Slater in 1975 to identify vertices of a graph G using its distances to a subset of vertices of G. A resolving set X of a graph G is a subset of vertices such that, for every pair (u,v) of vertices of G, there is a vertex x in X such that the distance between x and u and the distance between x and v are distinct. The metric dimension of the graph is the minimum size of a resolving set. Computing the metric dimension of a graph is NP-hard even on split graphs and interval graphs. Bonnet and Purohit proved that the metric dimension problem is W[1]-hard parameterized by treewidth. Li and Pilipczuk strenghtened this result by showing that it is NP-hard for graphs of treewidth. In this article, we prove that that metric dimension is FPT parameterized by treewidth in chordal graphs. ",
    "url": "https://arxiv.org/abs/2303.10646",
    "authors": [
      "Nicolas Bousquet",
      "Quentin Deschamps",
      "Aline Parreau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.10653",
    "title": "Randomized Adversarial Training via Taylor Expansion",
    "abstract": "In recent years, there has been an explosion of research into developing more robust deep neural networks against adversarial examples. Adversarial training appears as one of the most successful methods. To deal with both the robustness against adversarial examples and the accuracy over clean examples, many works develop enhanced adversarial training methods to achieve various trade-offs between them. Leveraging over the studies that smoothed update on weights during training may help find flat minima and improve generalization, we suggest reconciling the robustness-accuracy trade-off from another perspective, i.e., by adding random noise into deterministic weights. The randomized weights enable our design of a novel adversarial training method via Taylor expansion of a small Gaussian noise, and we show that the new adversarial training method can flatten loss landscape and find flat minima. With PGD, CW, and Auto Attacks, an extensive set of experiments demonstrate that our method enhances the state-of-the-art adversarial training methods, boosting both robustness and clean accuracy. The code is available at https://github.com/Alexkael/Randomized-Adversarial-Training. ",
    "url": "https://arxiv.org/abs/2303.10653",
    "authors": [
      "Gaojie Jin",
      "Xinping Yi",
      "Dengyu Wu",
      "Ronghui Mu",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10681",
    "title": "Generative Adversarial Classification Network with Application to  Network Traffic Classification",
    "abstract": "Large datasets in machine learning often contain missing data, which necessitates the imputation of missing data values. In this work, we are motivated by network traffic classification, where traditional data imputation methods do not perform well. We recognize that no existing method directly accounts for classification accuracy during data imputation. Therefore, we propose a joint data imputation and data classification method, termed generative adversarial classification network (GACN), whose architecture contains a generator network, a discriminator network, and a classification network, which are iteratively optimized toward the ultimate objective of classification accuracy. For the scenario where some data samples are unlabeled, we further propose an extension termed semi-supervised GACN (SSGACN), which is able to use the partially labeled data to improve classification accuracy. We conduct experiments with real-world network traffic data traces, which demonstrate that GACN and SS-GACN can more accurately impute data features that are more important for classification, and they outperform existing methods in terms of classification accuracy. ",
    "url": "https://arxiv.org/abs/2303.10681",
    "authors": [
      "Rozhina Ghanavi",
      "Ben Liang",
      "Ali Tizghadam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.10699",
    "title": "FVQA 2.0: Introducing Adversarial Samples into Fact-based Visual  Question Answering",
    "abstract": "The widely used Fact-based Visual Question Answering (FVQA) dataset contains visually-grounded questions that require information retrieval using common sense knowledge graphs to answer. It has been observed that the original dataset is highly imbalanced and concentrated on a small portion of its associated knowledge graph. We introduce FVQA 2.0 which contains adversarial variants of test questions to address this imbalance. We show that systems trained with the original FVQA train sets can be vulnerable to adversarial samples and we demonstrate an augmentation scheme to reduce this vulnerability without human annotations. ",
    "url": "https://arxiv.org/abs/2303.10699",
    "authors": [
      "Weizhe Lin",
      "Zhilin Wang",
      "Bill Byrne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10702",
    "title": "Evaluation of Convolution Primitives for Embedded Neural Networks on  32-bit Microcontrollers",
    "abstract": "Deploying neural networks on constrained hardware platforms such as 32-bit microcontrollers is a challenging task because of the large memory, computing and energy requirements of their inference process. To tackle these issues, several convolution primitives have been proposed to make the standard convolution more computationally efficient. However, few of these primitives are really implemented for 32-bit microcontrollers. In this work, we collect different state-of-the-art convolutional primitives and propose an implementation for ARM Cortex-M processor family with an open source deployment platform (NNoM). Then, we carry out experimental characterization tests on these implementations. Our benchmark reveals a linear relationship between theoretical MACs and energy consumption. Thus showing the advantages of using computationally efficient primitives like shift convolution. We discuss about the significant reduction in latency and energy consumption due to the use of SIMD instructions and highlight the importance of data reuse in those performance gains. For reproducibility purpose and further experiments, codes and experiments are publicly available. ",
    "url": "https://arxiv.org/abs/2303.10702",
    "authors": [
      "Baptiste Nguyen",
      "Pierre-Alain Moellic",
      "Sylvain Blayac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2303.10703",
    "title": "CCTV-Gun: Benchmarking Handgun Detection in CCTV Images",
    "abstract": "Gun violence is a critical security problem, and it is imperative for the computer vision community to develop effective gun detection algorithms for real-world scenarios, particularly in Closed Circuit Television (CCTV) surveillance data. Despite significant progress in visual object detection, detecting guns in real-world CCTV images remains a challenging and under-explored task. Firearms, especially handguns, are typically very small in size, non-salient in appearance, and often severely occluded or indistinguishable from other small objects. Additionally, the lack of principled benchmarks and difficulty collecting relevant datasets further hinder algorithmic development. In this paper, we present a meticulously crafted and annotated benchmark, called \\textbf{CCTV-Gun}, which addresses the challenges of detecting handguns in real-world CCTV images. Our contribution is three-fold. Firstly, we carefully select and analyze real-world CCTV images from three datasets, manually annotate handguns and their holders, and assign each image with relevant challenge factors such as blur and occlusion. Secondly, we propose a new cross-dataset evaluation protocol in addition to the standard intra-dataset protocol, which is vital for gun detection in practical settings. Finally, we comprehensively evaluate both classical and state-of-the-art object detection algorithms, providing an in-depth analysis of their generalizing abilities. The benchmark will facilitate further research and development on this topic and ultimately enhance security. Code, annotations, and trained models are available at https://github.com/srikarym/CCTV-Gun. ",
    "url": "https://arxiv.org/abs/2303.10703",
    "authors": [
      "Srikar Yellapragada",
      "Zhenghong Li",
      "Kevin Bhadresh Doshi",
      "Purva Makarand Mhasakar",
      "Heng Fan",
      "Jie Wei",
      "Erik Blasch",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10709",
    "title": "NeRF-LOAM: Neural Implicit Representation for Large-Scale Incremental  LiDAR Odometry and Mapping",
    "abstract": "Simultaneously odometry and mapping using LiDAR data is an important task for mobile systems to achieve full autonomy in large-scale environments. However, most existing LiDAR-based methods prioritize tracking quality over reconstruction quality. Although the recently developed neural radiance fields (NeRF) have shown promising advances in implicit reconstruction for indoor environments, the problem of simultaneous odometry and mapping for large-scale scenarios using incremental LiDAR data remains unexplored. To bridge this gap, in this paper, we propose a novel NeRF-based LiDAR odometry and mapping approach, NeRF-LOAM, consisting of three modules neural odometry, neural mapping, and mesh reconstruction. All these modules utilize our proposed neural signed distance function, which separates LiDAR points into ground and non-ground points to reduce Z-axis drift, optimizes odometry and voxel embeddings concurrently, and in the end generates dense smooth mesh maps of the environment. Moreover, this joint optimization allows our NeRF-LOAM to be pre-trained free and exhibit strong generalization abilities when applied to different environments. Extensive evaluations on three publicly available datasets demonstrate that our approach achieves state-of-the-art odometry and mapping performance, as well as a strong generalization in large-scale environments utilizing LiDAR data. Furthermore, we perform multiple ablation studies to validate the effectiveness of our network design. The implementation of our approach will be made available at https://github.com/JunyuanDeng/NeRF-LOAM. ",
    "url": "https://arxiv.org/abs/2303.10709",
    "authors": [
      "Junyuan Deng",
      "Xieyuanli Chen",
      "Songpengcheng Xia",
      "Zhen Sun",
      "Guoqing Liu",
      "Wenxian Yu",
      "Ling Pei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10720",
    "title": "Trainable Projected Gradient Method for Robust Fine-tuning",
    "abstract": "Recent studies on transfer learning have shown that selectively fine-tuning a subset of layers or customizing different learning rates for each layer can greatly improve robustness to out-of-distribution (OOD) data and retain generalization capability in the pre-trained models. However, most of these methods employ manually crafted heuristics or expensive hyper-parameter searches, which prevent them from scaling up to large datasets and neural networks. To solve this problem, we propose Trainable Projected Gradient Method (TPGM) to automatically learn the constraint imposed for each layer for a fine-grained fine-tuning regularization. This is motivated by formulating fine-tuning as a bi-level constrained optimization problem. Specifically, TPGM maintains a set of projection radii, i.e., distance constraints between the fine-tuned model and the pre-trained model, for each layer, and enforces them through weight projections. To learn the constraints, we propose a bi-level optimization to automatically learn the best set of projection radii in an end-to-end manner. Theoretically, we show that the bi-level optimization formulation is the key to learning different constraints for each layer. Empirically, with little hyper-parameter search cost, TPGM outperforms existing fine-tuning methods in OOD performance while matching the best in-distribution (ID) performance. For example, when fine-tuned on DomainNet-Real and ImageNet, compared to vanilla fine-tuning, TPGM shows $22\\%$ and $10\\%$ relative OOD improvement respectively on their sketch counterparts. Code is available at \\url{https://github.com/PotatoTian/TPGM}. ",
    "url": "https://arxiv.org/abs/2303.10720",
    "authors": [
      "Junjiao Tian",
      "Xiaoliang Dai",
      "Chih-Yao Ma",
      "Zecheng He",
      "Yen-Cheng Liu",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10722",
    "title": "Q-RBSA: High-Resolution 3D EBSD Map Generation Using An Efficient  Quaternion Transformer Network",
    "abstract": "Gathering 3D material microstructural information is time-consuming, expensive, and energy-intensive. Acquisition of 3D data has been accelerated by developments in serial sectioning instrument capabilities; however, for crystallographic information, the electron backscatter diffraction (EBSD) imaging modality remains rate limiting. We propose a physics-based efficient deep learning framework to reduce the time and cost of collecting 3D EBSD maps. Our framework uses a quaternion residual block self-attention network (QRBSA) to generate high-resolution 3D EBSD maps from sparsely sectioned EBSD maps. In QRBSA, quaternion-valued convolution effectively learns local relations in orientation space, while self-attention in the quaternion domain captures long-range correlations. We apply our framework to 3D data collected from commercially relevant titanium alloys, showing both qualitatively and quantitatively that our method can predict missing samples (EBSD information between sparsely sectioned mapping points) as compared to high-resolution ground truth 3D EBSD maps. ",
    "url": "https://arxiv.org/abs/2303.10722",
    "authors": [
      "Devendra K. Jangid",
      "Neal R. Brodnik",
      "McLean P. Echlin",
      "Tresa M. Pollock",
      "Samantha H. Daly",
      "B.S. Manjunath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10727",
    "title": "ERSAM: Neural Architecture Search For Energy-Efficient and Real-Time  Social Ambiance Measurement",
    "abstract": "Social ambiance describes the context in which social interactions happen, and can be measured using speech audio by counting the number of concurrent speakers. This measurement has enabled various mental health tracking and human-centric IoT applications. While on-device Socal Ambiance Measure (SAM) is highly desirable to ensure user privacy and thus facilitate wide adoption of the aforementioned applications, the required computational complexity of state-of-the-art deep neural networks (DNNs) powered SAM solutions stands at odds with the often constrained resources on mobile devices. Furthermore, only limited labeled data is available or practical when it comes to SAM under clinical settings due to various privacy constraints and the required human effort, further challenging the achievable accuracy of on-device SAM solutions. To this end, we propose a dedicated neural architecture search framework for Energy-efficient and Real-time SAM (ERSAM). Specifically, our ERSAM framework can automatically search for DNNs that push forward the achievable accuracy vs. hardware efficiency frontier of mobile SAM solutions. For example, ERSAM-delivered DNNs only consume 40 mW x 12 h energy and 0.05 seconds processing latency for a 5 seconds audio segment on a Pixel 3 phone, while only achieving an error rate of 14.3% on a social ambiance dataset generated by LibriSpeech. We can expect that our ERSAM framework can pave the way for ubiquitous on-device SAM solutions which are in growing demand. ",
    "url": "https://arxiv.org/abs/2303.10727",
    "authors": [
      "Chaojian Li",
      "Wenwan Chen",
      "Jiayi Yuan",
      "Yingyan",
      "Ashutosh Sabharwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.10728",
    "title": "Training Deep Boltzmann Networks with Sparse Ising Machines",
    "abstract": "The slowing down of Moore's law has driven the development of unconventional computing paradigms, such as specialized Ising machines tailored to solve combinatorial optimization problems. In this paper, we show a new application domain for probabilistic bit (p-bit) based Ising machines by training deep generative AI models with them. Using sparse, asynchronous, and massively parallel Ising machines we train deep Boltzmann networks in a hybrid probabilistic-classical computing setup. We use the full MNIST dataset without any downsampling or reduction in hardware-aware network topologies implemented in moderately sized Field Programmable Gate Arrays (FPGA). Our machine, which uses only 4,264 nodes (p-bits) and about 30,000 parameters, achieves the same classification accuracy (90%) as an optimized software-based restricted Boltzmann Machine (RBM) with approximately 3.25 million parameters. Additionally, the sparse deep Boltzmann network can generate new handwritten digits, a task the 3.25 million parameter RBM fails at despite achieving the same accuracy. Our hybrid computer takes a measured 50 to 64 billion probabilistic flips per second, which is at least an order of magnitude faster than superficially similar Graphics and Tensor Processing Unit (GPU/TPU) based implementations. The massively parallel architecture can comfortably perform the contrastive divergence algorithm (CD-n) with up to n = 10 million sweeps per update, beyond the capabilities of existing software implementations. These results demonstrate the potential of using Ising machines for traditionally hard-to-train deep generative Boltzmann networks, with further possible improvement in nanodevice-based realizations. ",
    "url": "https://arxiv.org/abs/2303.10728",
    "authors": [
      "Shaila Niazi",
      "Navid Anjum Aadit",
      "Masoud Mohseni",
      "Shuvro Chowdhury",
      "Yao Qin",
      "Kerem Y. Camsari"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.10753",
    "title": "Fr\u00e9chet Statistics Based Change Point Detection in Dynamic Social  Networks",
    "abstract": "This paper proposes a method to detect change points in dynamic social networks using Fr\\'echet statistics. We address two main questions: (1) what metric can quantify the distances between graph Laplacians in a dynamic network and enable efficient computation, and (2) how can the Fr\\'echet statistics be extended to detect multiple change points while maintaining the significance level of the hypothesis test? Our solution defines a metric space for graph Laplacians using the Log-Euclidean metric, enabling a closed-form formula for Fr\\'echet mean and variance. We present a framework for change point detection using Fr\\'echet statistics and extend it to multiple change points with binary segmentation. The proposed algorithm uses incremental computation for Fr\\'echet mean and variance to improve efficiency and is validated on simulated and two real-world datasets, namely the UCI message dataset and the Enron email dataset. ",
    "url": "https://arxiv.org/abs/2303.10753",
    "authors": [
      "Rui Luo",
      "Vikram Krishnamurthy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.10761",
    "title": "Calibration of Neural Networks",
    "abstract": "Neural networks solving real-world problems are often required not only to make accurate predictions but also to provide a confidence level in the forecast. The calibration of a model indicates how close the estimated confidence is to the true probability. This paper presents a survey of confidence calibration problems in the context of neural networks and provides an empirical comparison of calibration methods. We analyze problem statement, calibration definitions, and different approaches to evaluation: visualizations and scalar measures that estimate whether the model is well-calibrated. We review modern calibration techniques: based on post-processing or requiring changes in training. Empirical experiments cover various datasets and models, comparing calibration methods according to different criteria. ",
    "url": "https://arxiv.org/abs/2303.10761",
    "authors": [
      "Ruslan Vasilev",
      "Alexander D'yakonov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.10770",
    "title": "RetinaNet: Reservoir-Enabled Time Integrated Attention Network for  Event-based Video Processing",
    "abstract": "Event-based cameras are inspired by the sparse and asynchronous spike representation of the biological visual system. However, processing the even data requires either using expensive feature descriptors to transform spikes into frames, or using spiking neural networks that are difficult to train. In this work, we propose a neural network architecture based on simple convolution layers integrated with dynamic temporal encoding reservoirs with low hardware and training costs. The Reservoir-enabled Time Integrated Attention Network (RetinaNet) allows the network to efficiently process asynchronous temporal features, and achieves the highest accuracy of 99.2% for DVS128 Gesture reported to date, and one of the highest accuracy of 67.5% for DVS Lip dataset at a much smaller network size. By leveraging the internal dynamics of memristors, asynchronous temporal feature encoding can be implemented at very low hardware cost without preprocessing or dedicated memory and arithmetic units. The use of simple DNN blocks and backpropagation based training rules further reduces its implementation cost. Code will be publicly available. ",
    "url": "https://arxiv.org/abs/2303.10770",
    "authors": [
      "Sangmin Yoo",
      "Eric Yeu-Jer Lee",
      "Ziyu Wang",
      "Xinxin Wang",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.10780",
    "title": "A Comprehensive Review of Spiking Neural Networks: Interpretation,  Optimization, Efficiency, and Best Practices",
    "abstract": "Biological neural networks continue to inspire breakthroughs in neural network performance. And yet, one key area of neural computation that has been under-appreciated and under-investigated is biologically plausible, energy-efficient spiking neural networks, whose potential is especially attractive for low-power, mobile, or otherwise hardware-constrained settings. We present a literature review of recent developments in the interpretation, optimization, efficiency, and accuracy of spiking neural networks. Key contributions include identification, discussion, and comparison of cutting-edge methods in spiking neural network optimization, energy-efficiency, and evaluation, starting from first principles so as to be accessible to new practitioners. ",
    "url": "https://arxiv.org/abs/2303.10780",
    "authors": [
      "Kai Malcom",
      "Josue Casco-Rodriguez"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.10782",
    "title": "On the Importance of Signer Overlap for Sign Language Detection",
    "abstract": "Sign language detection, identifying if someone is signing or not, is becoming crucially important for its applications in remote conferencing software and for selecting useful sign data for training sign language recognition or translation tasks. We argue that the current benchmark data sets for sign language detection estimate overly positive results that do not generalize well due to signer overlap between train and test partitions. We quantify this with a detailed analysis of the effect of signer overlap on current sign detection benchmark data sets. Comparing accuracy with and without overlap on the DGS corpus and Signing in the Wild, we observed a relative decrease in accuracy of 4.17% and 6.27%, respectively. Furthermore, we propose new data set partitions that are free of overlap and allow for more realistic performance assessment. We hope this work will contribute to improving the accuracy and generalization of sign language detection systems. ",
    "url": "https://arxiv.org/abs/2303.10782",
    "authors": [
      "Abhilash Pal",
      "Stephan Huber",
      "Cyrine Chaabani",
      "Alessandro Manzotti",
      "Oscar Koller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10794",
    "title": "PheME: A deep ensemble framework for improving phenotype prediction from  multi-modal data",
    "abstract": "Detailed phenotype information is fundamental to accurate diagnosis and risk estimation of diseases. As a rich source of phenotype information, electronic health records (EHRs) promise to empower diagnostic variant interpretation. However, how to accurately and efficiently extract phenotypes from the heterogeneous EHR data remains a challenge. In this work, we present PheME, an Ensemble framework using Multi-modality data of structured EHRs and unstructured clinical notes for accurate Phenotype prediction. Firstly, we employ multiple deep neural networks to learn reliable representations from the sparse structured EHR data and redundant clinical notes. A multi-modal model then aligns multi-modal features onto the same latent space to predict phenotypes. Secondly, we leverage ensemble learning to combine outputs from single-modal models and multi-modal models to improve phenotype predictions. We choose seven diseases to evaluate the phenotyping performance of the proposed framework. Experimental results show that using multi-modal data significantly improves phenotype prediction in all diseases, the proposed ensemble learning framework can further boost the performance. ",
    "url": "https://arxiv.org/abs/2303.10794",
    "authors": [
      "Shenghan Zhang",
      "Haoxuan Li",
      "Ruixiang Tang",
      "Sirui Ding",
      "Laila Rasmy",
      "Degui Zhi",
      "Na Zou",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.10800",
    "title": "A Global Model Approach to Robust Few-Shot SAR Automatic Target  Recognition",
    "abstract": "In real-world scenarios, it may not always be possible to collect hundreds of labeled samples per class for training deep learning-based SAR Automatic Target Recognition (ATR) models. This work specifically tackles the few-shot SAR ATR problem, where only a handful of labeled samples may be available to support the task of interest. Our approach is composed of two stages. In the first, a global representation model is trained via self-supervised learning on a large pool of diverse and unlabeled SAR data. In the second stage, the global model is used as a fixed feature extractor and a classifier is trained to partition the feature space given the few-shot support samples, while simultaneously being calibrated to detect anomalous inputs. Unlike competing approaches which require a pristine labeled dataset for pretraining via meta-learning, our approach learns highly transferable features from unlabeled data that have little-to-no relation to the downstream task. We evaluate our method in standard and extended MSTAR operating conditions and find it to achieve high accuracy and robust out-of-distribution detection in many different few-shot settings. Our results are particularly significant because they show the merit of a global model approach to SAR ATR, which makes minimal assumptions, and provides many axes for extendability. ",
    "url": "https://arxiv.org/abs/2303.10800",
    "authors": [
      "Nathan Inkawhich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10816",
    "title": "IMF: Interactive Multimodal Fusion Model for Link Prediction",
    "abstract": "Link prediction aims to identify potential missing triples in knowledge graphs. To get better results, some recent studies have introduced multimodal information to link prediction. However, these methods utilize multimodal information separately and neglect the complicated interaction between different modalities. In this paper, we aim at better modeling the inter-modality information and thus introduce a novel Interactive Multimodal Fusion (IMF) model to integrate knowledge from different modalities. To this end, we propose a two-stage multimodal fusion framework to preserve modality-specific knowledge as well as take advantage of the complementarity between different modalities. Instead of directly projecting different modalities into a unified space, our multimodal fusion module limits the representations of different modalities independent while leverages bilinear pooling for fusion and incorporates contrastive learning as additional constraints. Furthermore, the decision fusion module delivers the learned weighted average over the predictions of all modalities to better incorporate the complementarity of different modalities. Our approach has been demonstrated to be effective through empirical evaluations on several real-world datasets. The implementation code is available online at https://github.com/HestiaSky/IMF-Pytorch. ",
    "url": "https://arxiv.org/abs/2303.10816",
    "authors": [
      "Xinhang Li",
      "Xiangyu Zhao",
      "Jiaxing Xu",
      "Yong Zhang",
      "Chunxiao Xing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.10840",
    "title": "Ref-NeuS: Ambiguity-Reduced Neural Implicit Surface Learning for  Multi-View Reconstruction with Reflection",
    "abstract": "Neural implicit surface learning has shown significant progress in multi-view 3D reconstruction, where an object is represented by multilayer perceptrons that provide continuous implicit surface representation and view-dependent radiance. However, current methods often fail to accurately reconstruct reflective surfaces, leading to severe ambiguity. To overcome this issue, we propose Ref-NeuS, which aims to reduce ambiguity by attenuating the importance of reflective surfaces. Specifically, we utilize an anomaly detector to estimate an explicit reflection score with the guidance of multi-view context to localize reflective surfaces. Afterward, we design a reflection-aware photometric loss that adaptively reduces ambiguity by modeling rendered color as a Gaussian distribution, with the reflection score representing the variance. We show that together with a reflection direction-dependent radiance, our model achieves high-quality surface reconstruction on reflective surfaces and outperforms the state-of-the-arts by a large margin. Besides, our model is also comparable on general surfaces. ",
    "url": "https://arxiv.org/abs/2303.10840",
    "authors": [
      "Wenhang Ge",
      "Tao Hu",
      "Haoyu Zhao",
      "Shu Liu",
      "Ying-Cong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10845",
    "title": "PanGu-\u03a3: Towards Trillion Parameter Language Model with Sparse  Heterogeneous Computing",
    "abstract": "The scaling of large language models has greatly improved natural language understanding, generation, and reasoning. In this work, we develop a system that trained a trillion-parameter language model on a cluster of Ascend 910 AI processors and MindSpore framework, and present the language model with 1.085T parameters named PanGu-{\\Sigma}. With parameter inherent from PanGu-{\\alpha}, we extend the dense Transformer model to sparse one with Random Routed Experts (RRE), and efficiently train the model over 329B tokens by using Expert Computation and Storage Separation(ECSS). This resulted in a 6.3x increase in training throughput through heterogeneous computing. Our experimental findings show that PanGu-{\\Sigma} provides state-of-the-art performance in zero-shot learning of various Chinese NLP downstream tasks. Moreover, it demonstrates strong abilities when fine-tuned in application data of open-domain dialogue, question answering, machine translation and code generation. ",
    "url": "https://arxiv.org/abs/2303.10845",
    "authors": [
      "Xiaozhe Ren",
      "Pingyi Zhou",
      "Xinfan Meng",
      "Xinjing Huang",
      "Yadao Wang",
      "Weichao Wang",
      "Pengfei Li",
      "Xiaoda Zhang",
      "Alexander Podolskiy",
      "Grigory Arshinov",
      "Andrey Bout",
      "Irina Piontkovskaya",
      "Jiansheng Wei",
      "Xin Jiang",
      "Teng Su",
      "Qun Liu",
      "Jun Yao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.10863",
    "title": "Decomposed Prototype Learning for Few-Shot Scene Graph Generation",
    "abstract": "Today's scene graph generation (SGG) models typically require abundant manual annotations to learn new predicate types. Thus, it is difficult to apply them to real-world applications with a long-tailed distribution of predicates. In this paper, we focus on a new promising task of SGG: few-shot SGG (FSSGG). FSSGG encourages models to be able to quickly transfer previous knowledge and recognize novel predicates well with only a few examples. Although many advanced approaches have achieved great success on few-shot learning (FSL) tasks, straightforwardly extending them into FSSGG is not applicable due to two intrinsic characteristics of predicate concepts: 1) Each predicate category commonly has multiple semantic meanings under different contexts. 2) The visual appearance of relation triplets with the same predicate differs greatly under different subject-object pairs. Both issues make it hard to model conventional latent representations for predicate categories with state-of-the-art FSL methods. To this end, we propose a novel Decomposed Prototype Learning (DPL). Specifically, we first construct a decomposable prototype space to capture intrinsic visual patterns of subjects and objects for predicates, and enhance their feature representations with these decomposed prototypes. Then, we devise an intelligent metric learner to assign adaptive weights to each support sample by considering the relevance of their subject-object pairs. We further re-split the VG dataset and compare DPL with various FSL methods to benchmark this task. Extensive results show that DPL achieves excellent performance in both base and novel categories. ",
    "url": "https://arxiv.org/abs/2303.10863",
    "authors": [
      "Xingchen Li",
      "Long Chen",
      "Guikun Chen",
      "Yinfu Feng",
      "Yi Yang",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10871",
    "title": "NASA Science Mission Directorate Knowledge Graph Discovery",
    "abstract": "The size of the National Aeronautics and Space Administration (NASA) Science Mission Directorate (SMD) is growing exponentially, allowing researchers to make discoveries. However, making discoveries is challenging and time-consuming due to the size of the data catalogs, and as many concepts and data are indirectly connected. This paper proposes a pipeline to generate knowledge graphs (KGs) representing different NASA SMD domains. These KGs can be used as the basis for dataset search engines, saving researchers time and supporting them in finding new connections. We collected textual data and used several modern natural language processing (NLP) methods to create the nodes and the edges of the KGs. We explore the cross-domain connections, discuss our challenges, and provide future directions to inspire researchers working on similar challenges. ",
    "url": "https://arxiv.org/abs/2303.10871",
    "authors": [
      "Roelien C. Timmer",
      "Fech Scen Khoo",
      "Megan Mark",
      "Marcella Scoczynski Ribeiro Martins",
      "Anamaria Berea",
      "Gregory Renard",
      "Kaylin Bugbee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10875",
    "title": "Hardware-Aware Graph Neural Network Automated Design for Edge Computing  Platforms",
    "abstract": "Graph neural networks (GNNs) have emerged as a popular strategy for handling non-Euclidean data due to their state-of-the-art performance. However, most of the current GNN model designs mainly focus on task accuracy, lacking in considering hardware resources limitation and real-time requirements of edge application scenarios. Comprehensive profiling of typical GNN models indicates that their execution characteristics are significantly affected across different computing platforms, which demands hardware awareness for efficient GNN designs. In this work, HGNAS is proposed as the first Hardware-aware Graph Neural Architecture Search framework targeting resource constraint edge devices. By decoupling the GNN paradigm, HGNAS constructs a fine-grained design space and leverages an efficient multi-stage search strategy to explore optimal architectures within a few GPU hours. Moreover, HGNAS achieves hardware awareness during the GNN architecture design by leveraging a hardware performance predictor, which could balance the GNN model accuracy and efficiency corresponding to the characteristics of targeted devices. Experimental results show that HGNAS can achieve about $10.6\\times$ speedup and $88.2\\%$ peak memory reduction with a negligible accuracy loss compared to DGCNN on various edge devices, including Nvidia RTX3080, Jetson TX2, Intel i7-8700K and Raspberry Pi 3B+. ",
    "url": "https://arxiv.org/abs/2303.10875",
    "authors": [
      "Ao Zhou",
      "Jianlei Yang",
      "Yingjie Qi",
      "Yumeng Shi",
      "Tong Qiao",
      "Weisheng Zhao",
      "Chunming Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10876",
    "title": "EqMotion: Equivariant Multi-agent Motion Prediction with Invariant  Interaction Reasoning",
    "abstract": "Learning to predict agent motions with relationship reasoning is important for many applications. In motion prediction tasks, maintaining motion equivariance under Euclidean geometric transformations and invariance of agent interaction is a critical and fundamental principle. However, such equivariance and invariance properties are overlooked by most existing methods. To fill this gap, we propose EqMotion, an efficient equivariant motion prediction model with invariant interaction reasoning. To achieve motion equivariance, we propose an equivariant geometric feature learning module to learn a Euclidean transformable feature through dedicated designs of equivariant operations. To reason agent's interactions, we propose an invariant interaction reasoning module to achieve a more stable interaction modeling. To further promote more comprehensive motion features, we propose an invariant pattern feature learning module to learn an invariant pattern feature, which cooperates with the equivariant geometric feature to enhance network expressiveness. We conduct experiments for the proposed model on four distinct scenarios: particle dynamics, molecule dynamics, human skeleton motion prediction and pedestrian trajectory prediction. Experimental results show that our method is not only generally applicable, but also achieves state-of-the-art prediction performances on all the four tasks, improving by 24.0/30.1/8.6/9.2%. Code is available at https://github.com/MediaBrain-SJTU/EqMotion. ",
    "url": "https://arxiv.org/abs/2303.10876",
    "authors": [
      "Chenxin Xu",
      "Robby T. Tan",
      "Yuhong Tan",
      "Siheng Chen",
      "Yu Guang Wang",
      "Xinchao Wang",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.10894",
    "title": "M$^{2}$SNet: Multi-scale in Multi-scale Subtraction Network for Medical  Image Segmentation",
    "abstract": "Accurate medical image segmentation is critical for early medical diagnosis. Most existing methods are based on U-shape structure and use element-wise addition or concatenation to fuse different level features progressively in decoder. However, both the two operations easily generate plenty of redundant information, which will weaken the complementarity between different level features, resulting in inaccurate localization and blurred edges of lesions. To address this challenge, we propose a general multi-scale in multi-scale subtraction network (M$^{2}$SNet) to finish diverse segmentation from medical image. Specifically, we first design a basic subtraction unit (SU) to produce the difference features between adjacent levels in encoder. Next, we expand the single-scale SU to the intra-layer multi-scale SU, which can provide the decoder with both pixel-level and structure-level difference information. Then, we pyramidally equip the multi-scale SUs at different levels with varying receptive fields, thereby achieving the inter-layer multi-scale feature aggregation and obtaining rich multi-scale difference information. In addition, we build a training-free network ``LossNet'' to comprehensively supervise the task-aware features from bottom layer to top layer, which drives our multi-scale subtraction network to capture the detailed and structural cues simultaneously. Without bells and whistles, our method performs favorably against most state-of-the-art methods under different evaluation metrics on eleven datasets of four different medical image segmentation tasks of diverse image modalities, including color colonoscopy imaging, ultrasound imaging, computed tomography (CT), and optical coherence tomography (OCT). The source code can be available at \\url{https://github.com/Xiaoqi-Zhao-DLUT/MSNet}. ",
    "url": "https://arxiv.org/abs/2303.10894",
    "authors": [
      "Xiaoqi Zhao",
      "Hongpeng Jia",
      "Youwei Pang",
      "Long Lv",
      "Feng Tian",
      "Lihe Zhang",
      "Weibing Sun",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10895",
    "title": "Leapfrog Diffusion Model for Stochastic Trajectory Prediction",
    "abstract": "To model the indeterminacy of human behaviors, stochastic trajectory prediction requires a sophisticated multi-modal distribution of future trajectories. Emerging diffusion models have revealed their tremendous representation capacities in numerous generation tasks, showing potential for stochastic trajectory prediction. However, expensive time consumption prevents diffusion models from real-time prediction, since a large number of denoising steps are required to assure sufficient representation ability. To resolve the dilemma, we present LEapfrog Diffusion model (LED), a novel diffusion-based trajectory prediction model, which provides real-time, precise, and diverse predictions. The core of the proposed LED is to leverage a trainable leapfrog initializer to directly learn an expressive multi-modal distribution of future trajectories, which skips a large number of denoising steps, significantly accelerating inference speed. Moreover, the leapfrog initializer is trained to appropriately allocate correlated samples to provide a diversity of predicted future trajectories, significantly improving prediction performances. Extensive experiments on four real-world datasets, including NBA/NFL/SDD/ETH-UCY, show that LED consistently improves performance and achieves 23.7%/21.9% ADE/FDE improvement on NFL. The proposed LED also speeds up the inference 19.3/30.8/24.3/25.1 times compared to the standard diffusion model on NBA/NFL/SDD/ETH-UCY, satisfying real-time inference needs. Code is available at https://github.com/MediaBrain-SJTU/LED. ",
    "url": "https://arxiv.org/abs/2303.10895",
    "authors": [
      "Weibo Mao",
      "Chenxin Xu",
      "Qi Zhu",
      "Siheng Chen",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10897",
    "title": "Relate auditory speech to EEG by shallow-deep attention-based network",
    "abstract": "Electroencephalography (EEG) plays a vital role in detecting how brain responses to different stimulus. In this paper, we propose a novel Shallow-Deep Attention-based Network (SDANet) to classify the correct auditory stimulus evoking the EEG signal. It adopts the Attention-based Correlation Module (ACM) to discover the connection between auditory speech and EEG from global aspect, and the Shallow-Deep Similarity Classification Module (SDSCM) to decide the classification result via the embeddings learned from the shallow and deep layers. Moreover, various training strategies and data augmentation are used to boost the model robustness. Experiments are conducted on the dataset provided by Auditory EEG challenge (ICASSP Signal Processing Grand Challenge 2023). Results show that the proposed model has a significant gain over the baseline on the match-mismatch track. ",
    "url": "https://arxiv.org/abs/2303.10897",
    "authors": [
      "Fan Cui",
      "Liyong Guo",
      "Lang He",
      "Jiyao Liu",
      "ErCheng Pei",
      "Yujun Wang",
      "Dongmei Jiang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2303.10901",
    "title": "E2C: A Visual Simulator to Reinforce Education of Heterogeneous  Computing Systems",
    "abstract": "With the increasing popularity of accelerator technologies (e.g., GPUs and TPUs) and the emergence of domain-specific computing via ASICs and FPGA, the matter of heterogeneity and understanding its ramifications on the performance has become more critical than ever before. However, it is challenging to effectively educate students about the potential impacts of heterogeneity on the performance of distributed systems; and on the logic of resource allocation methods to efficiently utilize the resources. Making use of the real infrastructure for benchmarking the performance of heterogeneous machines, for different applications, with respect to different objectives, and under various workload intensities is cost- and time-prohibitive. To reinforce the quality of learning about various dimensions of heterogeneity, and to decrease the widening gap in education, we develop an open-source simulation tool, called E2C, that can help students researchers to study any type of heterogeneous (or homogeneous) computing system and measure its performance under various configurations. E2C is equipped with an intuitive graphical user interface (GUI) that enables its users to easily examine system-level solutions (scheduling, load balancing, scalability, etc.) in a controlled environment within a short time. E2C is a discrete event simulator that offers the following features: (i) simulating a heterogeneous computing system; (ii) implementing a newly developed scheduling method and plugging it into the system, (iii) measuring energy consumption and other output-related metrics; and (iv) powerful visual aspects to ease the learning curve for students. We used E2C as an assignment in the Distributed and Cloud Computing course. Our anonymous survey study indicates that students rated E2C with the score of 8.7 out of 10 for its usefulness in understanding the concepts of scheduling in heterogeneous computing. ",
    "url": "https://arxiv.org/abs/2303.10901",
    "authors": [
      "Ali Mokhtari",
      "Drake Rawls",
      "Tony Huynh",
      "Jeremiah Green",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2303.10909",
    "title": "Graph Neural Rough Differential Equations for Traffic Forecasting",
    "abstract": "Traffic forecasting is one of the most popular spatio-temporal tasks in the field of machine learning. A prevalent approach in the field is to combine graph convolutional networks and recurrent neural networks for the spatio-temporal processing. There has been fierce competition and many novel methods have been proposed. In this paper, we present the method of spatio-temporal graph neural rough differential equation (STG-NRDE). Neural rough differential equations (NRDEs) are a breakthrough concept for processing time-series data. Their main concept is to use the log-signature transform to convert a time-series sample into a relatively shorter series of feature vectors. We extend the concept and design two NRDEs: one for the temporal processing and the other for the spatial processing. After that, we combine them into a single framework. We conduct experiments with 6 benchmark datasets and 21 baselines. STG-NRDE shows the best accuracy in all cases, outperforming all those 21 baselines by non-trivial margins. ",
    "url": "https://arxiv.org/abs/2303.10909",
    "authors": [
      "Jeongwhan Choi",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10912",
    "title": "Exploring Representation Learning for Small-Footprint Keyword Spotting",
    "abstract": "In this paper, we investigate representation learning for low-resource keyword spotting (KWS). The main challenges of KWS are limited labeled data and limited available device resources. To address those challenges, we explore representation learning for KWS by self-supervised contrastive learning and self-training with pretrained model. First, local-global contrastive siamese networks (LGCSiam) are designed to learn similar utterance-level representations for similar audio samplers by proposed local-global contrastive loss without requiring ground-truth. Second, a self-supervised pretrained Wav2Vec 2.0 model is applied as a constraint module (WVC) to force the KWS model to learn frame-level acoustic representations. By the LGCSiam and WVC modules, the proposed small-footprint KWS model can be pretrained with unlabeled data. Experiments on speech commands dataset show that the self-training WVC module and the self-supervised LGCSiam module significantly improve accuracy, especially in the case of training on a small labeled dataset. ",
    "url": "https://arxiv.org/abs/2303.10912",
    "authors": [
      "Fan Cui",
      "Liyong Guo",
      "Quandong Wang",
      "Peng Gao",
      "Yujun Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.10913",
    "title": "Bi-orthogonal fPINN: A physics-informed neural network method for  solving time-dependent stochastic fractional PDEs",
    "abstract": "Fractional partial differential equations (FPDEs) can effectively represent anomalous transport and nonlocal interactions. However, inherent uncertainties arise naturally in real applications due to random forcing or unknown material properties. Mathematical models considering nonlocal interactions with uncertainty quantification can be formulated as stochastic fractional partial differential equations (SFPDEs). There are many challenges in solving SFPDEs numerically, especially for long-time integration since such problems are high-dimensional and nonlocal. Here, we combine the bi-orthogonal (BO) method for representing stochastic processes with physics-informed neural networks (PINNs) for solving partial differential equations to formulate the bi-orthogonal PINN method (BO-fPINN) for solving time-dependent SFPDEs. Specifically, we introduce a deep neural network for the stochastic solution of the time-dependent SFPDEs, and include the BO constraints in the loss function following a weak formulation. Since automatic differentiation is not currently applicable to fractional derivatives, we employ discretization on a grid to to compute the fractional derivatives of the neural network output. The weak formulation loss function of the BO-fPINN method can overcome some drawbacks of the BO methods and thus can be used to solve SFPDEs with eigenvalue crossings. Moreover, the BO-fPINN method can be used for inverse SFPDEs with the same framework and same computational complexity as for forward problems. We demonstrate the effectiveness of the BO-fPINN method for different benchmark problems. The results demonstrate the flexibility and efficiency of the proposed method, especially for inverse problems. ",
    "url": "https://arxiv.org/abs/2303.10913",
    "authors": [
      "Lei Ma",
      "Rong xin Li",
      "Fanhai Zeng",
      "Ling Guo",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.10937",
    "title": "Boosting Weakly Supervised Object Detection using Fusion and Priors from  Hallucinated Depth",
    "abstract": "Despite recent attention and exploration of depth for various tasks, it is still an unexplored modality for weakly-supervised object detection (WSOD). We propose an amplifier method for enhancing the performance of WSOD by integrating depth information. Our approach can be applied to any WSOD method based on multiple-instance learning, without necessitating additional annotations or inducing large computational expenses. Our proposed method employs a monocular depth estimation technique to obtain hallucinated depth information, which is then incorporated into a Siamese WSOD network using contrastive loss and fusion. By analyzing the relationship between language context and depth, we calculate depth priors to identify the bounding box proposals that may contain an object of interest. These depth priors are then utilized to update the list of pseudo ground-truth boxes, or adjust the confidence of per-box predictions. Our proposed method is evaluated on six datasets (COCO, PASCAL VOC, Conceptual Captions, Clipart1k, Watercolor2k, and Comic2k) by implementing it on top of two state-of-the-art WSOD methods, and we demonstrate a substantial enhancement in performance. ",
    "url": "https://arxiv.org/abs/2303.10937",
    "authors": [
      "Cagri Gungor",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10944",
    "title": "Location-Free Scene Graph Generation",
    "abstract": "Scene Graph Generation (SGG) is a challenging visual understanding task. It combines the detection of entities and relationships between them in a scene. Both previous works and existing evaluation metrics rely on bounding box labels, even though many downstream scene graph applications do not need location information. The need for localization labels significantly increases the annotation cost and hampers the creation of more and larger scene graph datasets. We suggest breaking the dependency of scene graphs on bounding box labels by proposing location-free scene graph generation (LF-SGG). This new task aims at predicting instances of entities, as well as their relationships, without spatial localization. To objectively evaluate the task, the predicted and ground truth scene graphs need to be compared. We solve this NP-hard problem through an efficient algorithm using branching. Additionally, we design the first LF-SGG method, Pix2SG, using autoregressive sequence modeling. Our proposed method is evaluated on Visual Genome and 4D-OR. Although using significantly fewer labels during training, we achieve 74.12\\% of the location-supervised SOTA performance on Visual Genome and even outperform the best method on 4D-OR. ",
    "url": "https://arxiv.org/abs/2303.10944",
    "authors": [
      "Ege \u00d6zsoy",
      "Felix Holm",
      "Tobias Czempiel",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10953",
    "title": "An Error-Correction Model for Information Transmissions of Social  Networks",
    "abstract": "We study the error-correction problem of the communication between two vertices in a social network. By applying the concepts of coding theory into the Social Network Analysis (SNA), we develop the code social network model, which can offer an efficient way to ensure the correctness of the message transmission within the social netwoks. The result of this study could apply in vary of social science studies. ",
    "url": "https://arxiv.org/abs/2303.10953",
    "authors": [
      "Daqi",
      "Fang",
      "Pin-Chieh Tseng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.10954",
    "title": "Uncertainty-aware deep learning for digital twin-driven monitoring:  Application to fault detection in power lines",
    "abstract": "Deep neural networks (DNNs) are often coupled with physics-based models or data-driven surrogate models to perform fault detection and health monitoring of systems in the low data regime. These models serve as digital twins to generate large quantities of data to train DNNs which would otherwise be difficult to obtain from the real-life system. However, such models can exhibit parametric uncertainty that propagates to the generated data. In addition, DNNs exhibit uncertainty in the parameters learnt during training. In such a scenario, the performance of the DNN model will be influenced by the uncertainty in the physics-based model as well as the parameters of the DNN. In this article, we quantify the impact of both these sources of uncertainty on the performance of the DNN. We perform explicit propagation of uncertainty in input data through all layers of the DNN, as well as implicit prediction of output uncertainty to capture the former. Furthermore, we adopt Monte Carlo dropout to capture uncertainty in DNN parameters. We demonstrate the approach for fault detection of power lines with a physics-based model, two types of input data and three different neural network architectures. We compare the performance of such uncertainty-aware probabilistic models with their deterministic counterparts. The results show that the probabilistic models provide important information regarding the confidence of predictions, while also delivering an improvement in performance over deterministic models. ",
    "url": "https://arxiv.org/abs/2303.10954",
    "authors": [
      "Laya Das",
      "Blazhe Gjorgiev",
      "Giovanni Sansavini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.10955",
    "title": "Attacks Against Security Context in 5G Network",
    "abstract": "The security context used in 5G authentication is generated during the Authentication and Key Agreement (AKA) procedure and stored in both the user equipment (UE) and the network sides for the subsequent fast registration procedure. Given its importance, it is imperative to formally analyze the security mechanism of the security context. The security context in the UE can be stored in the Universal Subscriber Identity Module (USIM) card or in the baseband chip. In this work, we present a comprehensive and formal verification of the fast registration procedure based on the security context under the two scenarios in ProVerif. Our analysis identifies two vulnerabilities, including one that has not been reported before. Specifically, the security context stored in the USIM card can be read illegally, and the validity checking mechanism of the security context in the baseband chip can be bypassed. Moreover, these vulnerabilities also apply to 4G networks. As a consequence, an attacker can exploit these vulnerabilities to register to the network with the victim's identity and then launch other attacks, including one-tap authentication bypass leading to privacy disclosure, location spoofing, etc. To ensure that these attacks are indeed realizable in practice, we have responsibly confirmed them through experimentation in three operators. Our analysis reveals that these vulnerabilities stem from design flaws of the standard and unsafe practices by operators. We finally propose several potential countermeasures to prevent these attacks. We have reported our findings to the GSMA and received a coordinated vulnerability disclosure (CVD) number CVD-2022-0057. ",
    "url": "https://arxiv.org/abs/2303.10955",
    "authors": [
      "Zhiwei Cui",
      "Baojiang Cui",
      "Li Su",
      "Haitao Du",
      "Hongxin Wang",
      "Junsong Fu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.10962",
    "title": "Neural Implicit Vision-Language Feature Fields",
    "abstract": "Recently, groundbreaking results have been presented on open-vocabulary semantic image segmentation. Such methods segment each pixel in an image into arbitrary categories provided at run-time in the form of text prompts, as opposed to a fixed set of classes defined at training time. In this work, we present a zero-shot volumetric open-vocabulary semantic scene segmentation method. Our method builds on the insight that we can fuse image features from a vision-language model into a neural implicit representation. We show that the resulting feature field can be segmented into different classes by assigning points to natural language text prompts. The implicit volumetric representation enables us to segment the scene both in 3D and 2D by rendering feature maps from any given viewpoint of the scene. We show that our method works on noisy real-world data and can run in real-time on live sensor data dynamically adjusting to text prompts. We also present quantitative comparisons on the ScanNet dataset. ",
    "url": "https://arxiv.org/abs/2303.10962",
    "authors": [
      "Kenneth Blomqvist",
      "Francesco Milano",
      "Jen Jen Chung",
      "Lionel Ott",
      "Roland Siegwart"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10966",
    "title": "Towards Reliable Neural Machine Translation with Consistency-Aware  Meta-Learning",
    "abstract": "Neural machine translation (NMT) has achieved remarkable success in producing high-quality translations. However, current NMT systems suffer from a lack of reliability, as their outputs that are often affected by lexical or syntactic changes in inputs, resulting in large variations in quality. This limitation hinders the practicality and trustworthiness of NMT. A contributing factor to this problem is that NMT models trained with the one-to-one paradigm struggle to handle the source diversity phenomenon, where inputs with the same meaning can be expressed differently. In this work, we treat this problem as a bilevel optimization problem and present a consistency-aware meta-learning (CAML) framework derived from the model-agnostic meta-learning (MAML) algorithm to address it. Specifically, the NMT model with CAML (named CoNMT) first learns a consistent meta representation of semantically equivalent sentences in the outer loop. Subsequently, a mapping from the meta representation to the output sentence is learned in the inner loop, allowing the NMT model to translate semantically equivalent sentences to the same target sentence. We conduct experiments on the NIST Chinese to English task, three WMT translation tasks, and the TED M2O task. The results demonstrate that CoNMT effectively improves overall translation quality and reliably handles diverse inputs. ",
    "url": "https://arxiv.org/abs/2303.10966",
    "authors": [
      "Rongxiang Weng",
      "Qiang Wang",
      "Wensen Cheng",
      "Changfeng Zhu",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.10967",
    "title": "Real-time Semantic Scene Completion Via Feature Aggregation and  Conditioned Prediction",
    "abstract": "Semantic Scene Completion (SSC) aims to simultaneously predict the volumetric occupancy and semantic category of a 3D scene. In this paper, we propose a real-time semantic scene completion method with a feature aggregation strategy and conditioned prediction module. Feature aggregation fuses feature with different receptive fields and gathers context to improve scene completion performance. And the conditioned prediction module adopts a two-step prediction scheme that takes volumetric occupancy as a condition to enhance semantic completion prediction. We conduct experiments on three recognized benchmarks NYU, NYUCAD, and SUNCG. Our method achieves competitive performance at a speed of 110 FPS on one GTX 1080 Ti GPU. ",
    "url": "https://arxiv.org/abs/2303.10967",
    "authors": [
      "Xiaokang Chen",
      "Yajie Xing",
      "Gang Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10971",
    "title": "Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching",
    "abstract": "The matching of 3D shapes has been extensively studied for shapes represented as surface meshes, as well as for shapes represented as point clouds. While point clouds are a common representation of raw real-world 3D data (e.g. from laser scanners), meshes encode rich and expressive topological information, but their creation typically requires some form of (often manual) curation. In turn, methods that purely rely on point clouds are unable to meet the matching quality of mesh-based methods that utilise the additional topological structure. In this work we close this gap by introducing a self-supervised multimodal learning strategy that combines mesh-based functional map regularisation with a contrastive loss that couples mesh and point cloud data. Our shape matching approach allows to obtain intramodal correspondences for triangle meshes, complete point clouds, and partially observed point clouds, as well as correspondences across these data modalities. We demonstrate that our method achieves state-of-the-art results on several challenging benchmark datasets even in comparison to recent supervised methods, and that our method reaches previously unseen cross-dataset generalisation ability. ",
    "url": "https://arxiv.org/abs/2303.10971",
    "authors": [
      "Dongliang Cao",
      "Florian Bernard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.10974",
    "title": "Translate your gibberish: black-box adversarial attack on machine  translation systems",
    "abstract": "Neural networks are deployed widely in natural language processing tasks on the industrial scale, and perhaps the most often they are used as compounds of automatic machine translation systems. In this work, we present a simple approach to fool state-of-the-art machine translation tools in the task of translation from Russian to English and vice versa. Using a novel black-box gradient-free tensor-based optimizer, we show that many online translation tools, such as Google, DeepL, and Yandex, may both produce wrong or offensive translations for nonsensical adversarial input queries and refuse to translate seemingly benign input phrases. This vulnerability may interfere with understanding a new language and simply worsen the user's experience while using machine translation systems, and, hence, additional improvements of these tools are required to establish better translation. ",
    "url": "https://arxiv.org/abs/2303.10974",
    "authors": [
      "Andrei Chertkov",
      "Olga Tsymboi",
      "Mikhail Pautov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10975",
    "title": "VIMI: Vehicle-Infrastructure Multi-view Intermediate Fusion for  Camera-based 3D Object Detection",
    "abstract": "In autonomous driving, Vehicle-Infrastructure Cooperative 3D Object Detection (VIC3D) makes use of multi-view cameras from both vehicles and traffic infrastructure, providing a global vantage point with rich semantic context of road conditions beyond a single vehicle viewpoint. Two major challenges prevail in VIC3D: 1) inherent calibration noise when fusing multi-view images, caused by time asynchrony across cameras; 2) information loss when projecting 2D features into 3D space. To address these issues, We propose a novel 3D object detection framework, Vehicles-Infrastructure Multi-view Intermediate fusion (VIMI). First, to fully exploit the holistic perspectives from both vehicles and infrastructure, we propose a Multi-scale Cross Attention (MCA) module that fuses infrastructure and vehicle features on selective multi-scales to correct the calibration noise introduced by camera asynchrony. Then, we design a Camera-aware Channel Masking (CCM) module that uses camera parameters as priors to augment the fused features. We further introduce a Feature Compression (FC) module with channel and spatial compression blocks to reduce the size of transmitted features for enhanced efficiency. Experiments show that VIMI achieves 15.61% overall AP_3D and 21.44% AP_BEV on the new VIC3D dataset, DAIR-V2X-C, significantly outperforming state-of-the-art early fusion and late fusion methods with comparable transmission cost. ",
    "url": "https://arxiv.org/abs/2303.10975",
    "authors": [
      "Zhe Wang",
      "Siqi Fan",
      "Xiaoliang Huo",
      "Tongda Xu",
      "Yan Wang",
      "Jingjing Liu",
      "Yilun Chen",
      "Ya-Qin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10976",
    "title": "Attention Disturbance and Dual-Path Constraint Network for Occluded  Person Re-Identification",
    "abstract": "Occluded person re-identification (Re-ID) aims to address the potential occlusion problem when matching occluded or holistic pedestrians from different camera views. Many methods use the background as artificial occlusion and rely on attention networks to exclude noisy interference. However, the significant discrepancy between simple background occlusion and realistic occlusion can negatively impact the generalization of the network.To address this issue, we propose a novel transformer-based Attention Disturbance and Dual-Path Constraint Network (ADP) to enhance the generalization of attention networks. Firstly, to imitate real-world obstacles, we introduce an Attention Disturbance Mask (ADM) module that generates an offensive noise, which can distract attention like a realistic occluder, as a more complex form of occlusion.Secondly, to fully exploit these complex occluded images, we develop a Dual-Path Constraint Module (DPC) that can obtain preferable supervision information from holistic images through dual-path interaction. With our proposed method, the network can effectively circumvent a wide variety of occlusions using the basic ViT baseline. Comprehensive experimental evaluations conducted on person re-ID benchmarks demonstrate the superiority of ADP over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2303.10976",
    "authors": [
      "Jiaer Xia",
      "Lei Tan",
      "Pingyang Dai",
      "Mingbo Zhao",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10988",
    "title": "This Was (Not) Intended: How Intent Communication and Biometrics Can  Enhance Social Interactions With Robots",
    "abstract": "Socially Assistive Robots (SARs) are robots that are designed to replicate the role of a caregiver, coach, or teacher, providing emotional, cognitive, and social cues to support a specific group. SARs are becoming increasingly prevalent, especially in elderly care. Effective communication, both explicit and implicit, is a critical aspect of human-robot interaction involving SARs. Intent communication is necessary for SARs to engage in effective communication with humans. Biometrics can provide crucial information about a person's identity or emotions. By linking these biometric signals to the communication of intent, SARs can gain a profound understanding of their users and tailor their interactions accordingly. The development of reliable and robust biometric sensing and analysis systems is critical to the success of SARs. In this work, we focus on four different aspects to evaluate the communication of intent involving SARs, existing works, and our outlook on future works and applications. ",
    "url": "https://arxiv.org/abs/2303.10988",
    "authors": [
      "Khaled Kassem",
      "Alia Saad"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.10992",
    "title": "Pressure and convection robust bounds for continuous interior penalty  divergence-free finite element methods for the incompressible Navier-Stokes  equations",
    "abstract": "In this paper we analyze a pressure-robust method based on divergence-free mixed finite element methods with continuous interior penalty stabilization. The main goal is to prove an $O(h^{k+1/2})$ error estimate for the $L^2$ norm of the velocity in the convection dominated regime. This bound is pressure robust (the error bound of the velocity does not depend on the pressure) and also convection robust (the constants in the error bounds are independent of the Reynolds number). ",
    "url": "https://arxiv.org/abs/2303.10992",
    "authors": [
      "Bosco Garc\u00eda-Archilla",
      "Julia Novo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.10993",
    "title": "A Survey on Oversmoothing in Graph Neural Networks",
    "abstract": "Node features of graph neural networks (GNNs) tend to become more similar with the increase of the network depth. This effect is known as over-smoothing, which we axiomatically define as the exponential convergence of suitable similarity measures on the node features. Our definition unifies previous approaches and gives rise to new quantitative measures of over-smoothing. Moreover, we empirically demonstrate this behavior for several over-smoothing measures on different graphs (small-, medium-, and large-scale). We also review several approaches for mitigating over-smoothing and empirically test their effectiveness on real-world graph datasets. Through illustrative examples, we demonstrate that mitigating over-smoothing is a necessary but not sufficient condition for building deep GNNs that are expressive on a wide range of graph learning tasks. Finally, we extend our definition of over-smoothing to the rapidly emerging field of continuous-time GNNs. ",
    "url": "https://arxiv.org/abs/2303.10993",
    "authors": [
      "T. Konstantin Rusch",
      "Michael M. Bronstein",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11000",
    "title": "Late Meta-learning Fusion Using Representation Learning for Time Series  Forecasting",
    "abstract": "Meta-learning, decision fusion, hybrid models, and representation learning are topics of investigation with significant traction in time-series forecasting research. Of these two specific areas have shown state-of-the-art results in forecasting: hybrid meta-learning models such as Exponential Smoothing - Recurrent Neural Network (ES-RNN) and Neural Basis Expansion Analysis (N-BEATS) and feature-based stacking ensembles such as Feature-based FORecast Model Averaging (FFORMA). However, a unified taxonomy for model fusion and an empirical comparison of these hybrid and feature-based stacking ensemble approaches is still missing. This study presents a unified taxonomy encompassing these topic areas. Furthermore, the study empirically evaluates several model fusion approaches and a novel combination of hybrid and feature stacking algorithms called Deep-learning FORecast Model Averaging (DeFORMA). The taxonomy contextualises the considered methods. Furthermore, the empirical analysis of the results shows that the proposed model, DeFORMA, can achieve state-of-the-art results in the M4 data set. DeFORMA, increases the mean Overall Weighted Average (OWA) in the daily, weekly and yearly subsets with competitive results in the hourly, monthly and quarterly subsets. The taxonomy and empirical results lead us to argue that significant progress is still to be made by continuing to explore the intersection of these research areas. ",
    "url": "https://arxiv.org/abs/2303.11000",
    "authors": [
      "Terence L. van Zyl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11019",
    "title": "A Dual-branch Self-supervised Representation Learning Framework for  Tumour Segmentation in Whole Slide Images",
    "abstract": "Supervised deep learning methods have achieved considerable success in medical image analysis, owing to the availability of large-scale and well-annotated datasets. However, creating such datasets for whole slide images (WSIs) in histopathology is a challenging task due to their gigapixel size. In recent years, self-supervised learning (SSL) has emerged as an alternative solution to reduce the annotation overheads in WSIs, as it does not require labels for training. These SSL approaches, however, are not designed for handling multi-resolution WSIs, which limits their performance in learning discriminative image features. In this paper, we propose a Dual-branch SSL Framework for WSI tumour segmentation (DSF-WSI) that can effectively learn image features from multi-resolution WSIs. Our DSF-WSI connected two branches and jointly learnt low and high resolution WSIs in a self-supervised manner. Moreover, we introduced a novel Context-Target Fusion Module (CTFM) and a masked jigsaw pretext task to align the learnt multi-resolution features. Furthermore, we designed a Dense SimSiam Learning (DSL) strategy to maximise the similarity of different views of WSIs, enabling the learnt representations to be more efficient and discriminative. We evaluated our method using two public datasets on breast and liver cancer segmentation tasks. The experiment results demonstrated that our DSF-WSI can effectively extract robust and efficient representations, which we validated through subsequent fine-tuning and semi-supervised settings. Our proposed method achieved better accuracy than other state-of-the-art approaches. Code is available at https://github.com/Dylan-H-Wang/dsf-wsi. ",
    "url": "https://arxiv.org/abs/2303.11019",
    "authors": [
      "Hao Wang",
      "Euijoon Ahn",
      "Jinman Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11020",
    "title": "Dual-stream Time-Delay Neural Network with Dynamic Global Filter for  Speaker Verification",
    "abstract": "The time-delay neural network (TDNN) is one of the state-of-the-art models for text-independent speaker verification. However, it is difficult for conventional TDNN to capture global context that has been proven critical for robust speaker representations and long-duration speaker verification in many recent works. Besides, the common solutions, e.g., self-attention, have quadratic complexity for input tokens, which makes them computationally unaffordable when applied to the feature maps with large sizes in TDNN. To address these issues, we propose the Global Filter for TDNN, which applies log-linear complexity FFT/IFFT and a set of differentiable frequency-domain filters to efficiently model the long-term dependencies in speech. Besides, a dynamic filtering strategy, and a sparse regularization method are specially designed to enhance the performance of the global filter and prevent it from overfitting. Furthermore, we construct a dual-stream TDNN (DS-TDNN), which splits the basic channels for complexity reduction and employs the global filter to increase recognition performance. Experiments on Voxceleb and SITW databases show that the DS-TDNN achieves approximate 10% improvement with a decline over 28% and 15% in complexity and parameters compared with the ECAPA-TDNN. Besides, it has the best trade-off between efficiency and effectiveness compared with other popular baseline systems when facing long-duration speech. Finally, visualizations and a detailed ablation study further reveal the advantages of the DS-TDNN. ",
    "url": "https://arxiv.org/abs/2303.11020",
    "authors": [
      "Yangfu Li",
      "Xiaodan Lin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.11021",
    "title": "Once upon a time step: A closed-loop approach to robust MPC design",
    "abstract": "A novel perspective on the design of robust model predictive control (MPC) methods is presented, whereby closed-loop constraint satisfaction is ensured using recursive feasibility of the MPC optimization. Necessary and sufficient conditions are derived for recursive feasibility, based on the effects of model perturbations and disturbances occurring at one time step. Using these conditions and Farkas' lemma, sufficient conditions suitable for design are formulated. The proposed method is called a closed-loop design, as only the existence of feasible inputs at the next time step is enforced by design. This is in contrast to most existing formulations, which compute control policies that are feasible under the worst-case realizations of all model perturbations and exogenous disturbances in the MPC prediction horizon. The proposed method has an online computational complexity similar to nominal MPC methods while preserving guarantees of constraint satisfaction, recursive feasibility and stability. Numerical simulations demonstrate the efficacy of our proposed approach. ",
    "url": "https://arxiv.org/abs/2303.11021",
    "authors": [
      "Anilkumar Parsi",
      "Marcell Bartos",
      "Amber Srivastava",
      "Sebastien Gros",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.11034",
    "title": "Internal Structure Attention Network for Fingerprint Presentation Attack  Detection from Optical Coherence Tomography",
    "abstract": "As a non-invasive optical imaging technique, optical coherence tomography (OCT) has proven promising for automatic fingerprint recognition system (AFRS) applications. Diverse approaches have been proposed for OCT-based fingerprint presentation attack detection (PAD). However, considering the complexity and variety of PA samples, it is extremely challenging to increase the generalization ability with the limited PA dataset. To solve the challenge, this paper presents a novel supervised learning-based PAD method, denoted as ISAPAD, which applies prior knowledge to guide network training and enhance the generalization ability. The proposed dual-branch architecture can not only learns global features from the OCT image, but also concentrate on layered structure feature which comes from the internal structure attention module (ISAM). The simple yet effective ISAM enables the proposed network to obtain layered segmentation features belonging only to Bonafide from noisy OCT volume data directly. Combined with effective training strategies and PAD score generation rules, ISAPAD obtains optimal PAD performance in limited training data. Domain generalization experiments and visualization analysis validate the effectiveness of the proposed method for OCT PAD. ",
    "url": "https://arxiv.org/abs/2303.11034",
    "authors": [
      "Haohao Sun",
      "Yilong Zhang",
      "Peng Chen",
      "Haixia Wang",
      "Ronghua Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11040",
    "title": "Benchmarking Robustness of 3D Object Detection to Common Corruptions in  Autonomous Driving",
    "abstract": "3D object detection is an important task in autonomous driving to perceive the surroundings. Despite the excellent performance, the existing 3D detectors lack the robustness to real-world corruptions caused by adverse weathers, sensor noises, etc., provoking concerns about the safety and reliability of autonomous driving systems. To comprehensively and rigorously benchmark the corruption robustness of 3D detectors, in this paper we design 27 types of common corruptions for both LiDAR and camera inputs considering real-world driving scenarios. By synthesizing these corruptions on public datasets, we establish three corruption robustness benchmarks -- KITTI-C, nuScenes-C, and Waymo-C. Then, we conduct large-scale experiments on 24 diverse 3D object detection models to evaluate their corruption robustness. Based on the evaluation results, we draw several important findings, including: 1) motion-level corruptions are the most threatening ones that lead to significant performance drop of all models; 2) LiDAR-camera fusion models demonstrate better robustness; 3) camera-only models are extremely vulnerable to image corruptions, showing the indispensability of LiDAR point clouds. We release the benchmarks and codes at https://github.com/kkkcx/3D_Corruptions_AD. We hope that our benchmarks and findings can provide insights for future research on developing robust 3D object detection models. ",
    "url": "https://arxiv.org/abs/2303.11040",
    "authors": [
      "Yinpeng Dong",
      "Caixin Kang",
      "Jinlai Zhang",
      "Zijian Zhu",
      "Yikai Wang",
      "Xiao Yang",
      "Hang Su",
      "Xingxing Wei",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.11042",
    "title": "Hospitalization Length of Stay Prediction using Patient Event Sequences",
    "abstract": "Predicting patients hospital length of stay (LOS) is essential for improving resource allocation and supporting decision-making in healthcare organizations. This paper proposes a novel approach for predicting LOS by modeling patient information as sequences of events. Specifically, we present a transformer-based model, termed Medic-BERT (M-BERT), for LOS prediction using the unique features describing patients medical event sequences. We performed empirical experiments on a cohort of more than 45k emergency care patients from a large Danish hospital. Experimental results show that M-BERT can achieve high accuracy on a variety of LOS problems and outperforms traditional nonsequence-based machine learning approaches. ",
    "url": "https://arxiv.org/abs/2303.11042",
    "authors": [
      "Emil Riis Hansen",
      "Thomas Dyhre Nielsen",
      "Thomas Mulvad",
      "Mads Nibe Strausholm",
      "Tomer Sagi",
      "Katja Hose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11048",
    "title": "Revisiting Transformer for Point Cloud-based 3D Scene Graph Generation",
    "abstract": "In this paper, we propose the semantic graph Transformer (SGT) for the 3D scene graph generation. The task aims to parse a cloud point-based scene into a semantic structural graph, with the core challenge of modeling the complex global structure. Existing methods based on graph convolutional networks (GCNs) suffer from the over-smoothing dilemma and could only propagate information from limited neighboring nodes. In contrast, our SGT uses Transformer layers as the base building block to allow global information passing, with two types of proposed Transformer layers tailored for the 3D scene graph generation task. Specifically, we introduce the graph embedding layer to best utilize the global information in graph edges while maintaining comparable computation costs. Additionally, we propose the semantic injection layer to leverage categorical text labels and visual object knowledge. We benchmark our SGT on the established 3DSSG benchmark and achieve a 35.9% absolute improvement in relationship prediction's R@50 and an 80.40% boost on the subset with complex scenes over the state-of-the-art. Our analyses further show SGT's superiority in the long-tailed and zero-shot scenarios. We will release the code and model. ",
    "url": "https://arxiv.org/abs/2303.11048",
    "authors": [
      "Changsheng Lv",
      "Mengshi Qi",
      "Xia Li",
      "Zhengyuan Yang",
      "Huadong Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11052",
    "title": "ContraNeRF: Generalizable Neural Radiance Fields for Synthetic-to-real  Novel View Synthesis via Contrastive Learning",
    "abstract": "Although many recent works have investigated generalizable NeRF-based novel view synthesis for unseen scenes, they seldom consider the synthetic-to-real generalization, which is desired in many practical applications. In this work, we first investigate the effects of synthetic data in synthetic-to-real novel view synthesis and surprisingly observe that models trained with synthetic data tend to produce sharper but less accurate volume densities. For pixels where the volume densities are correct, fine-grained details will be obtained. Otherwise, severe artifacts will be produced. To maintain the advantages of using synthetic data while avoiding its negative effects, we propose to introduce geometry-aware contrastive learning to learn multi-view consistent features with geometric constraints. Meanwhile, we adopt cross-view attention to further enhance the geometry perception of features by querying features across input views. Experiments demonstrate that under the synthetic-to-real setting, our method can render images with higher quality and better fine-grained details, outperforming existing generalizable novel view synthesis methods in terms of PSNR, SSIM, and LPIPS. When trained on real data, our method also achieves state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2303.11052",
    "authors": [
      "Hao Yang",
      "Lanqing Hong",
      "Aoxue Li",
      "Tianyang Hu",
      "Zhenguo Li",
      "Gim Hee Lee",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11081",
    "title": "Provably Convergent Subgraph-wise Sampling for Fast GNN Training",
    "abstract": "Subgraph-wise sampling -- a promising class of mini-batch training techniques for graph neural networks (GNNs -- is critical for real-world applications. During the message passing (MP) in GNNs, subgraph-wise sampling methods discard messages outside the mini-batches in backward passes to avoid the well-known neighbor explosion problem, i.e., the exponentially increasing dependencies of nodes with the number of MP iterations. However, discarding messages may sacrifice the gradient estimation accuracy, posing significant challenges to their convergence analysis and convergence speeds. To address this challenge, we propose a novel subgraph-wise sampling method with a convergence guarantee, namely Local Message Compensation (LMC). To the best of our knowledge, LMC is the first subgraph-wise sampling method with provable convergence. The key idea is to retrieve the discarded messages in backward passes based on a message passing formulation of backward passes. By efficient and effective compensations for the discarded messages in both forward and backward passes, LMC computes accurate mini-batch gradients and thus accelerates convergence. Moreover, LMC is applicable to various MP-based GNN architectures, including convolutional GNNs (finite message passing iterations with different layers) and recurrent GNNs (infinite message passing iterations with a shared layer). Experiments on large-scale benchmarks demonstrate that LMC is significantly faster than state-of-the-art subgraph-wise sampling methods. ",
    "url": "https://arxiv.org/abs/2303.11081",
    "authors": [
      "Jie Wang",
      "Zhihao Shi",
      "Xize Liang",
      "Shuiwang Ji",
      "Bin Li",
      "Feng Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11090",
    "title": "Scene Graph Based Fusion Network For Image-Text Retrieval",
    "abstract": "A critical challenge to image-text retrieval is how to learn accurate correspondences between images and texts. Most existing methods mainly focus on coarse-grained correspondences based on co-occurrences of semantic objects, while failing to distinguish the fine-grained local correspondences. In this paper, we propose a novel Scene Graph based Fusion Network (dubbed SGFN), which enhances the images'/texts' features through intra- and cross-modal fusion for image-text retrieval. To be specific, we design an intra-modal hierarchical attention fusion to incorporate semantic contexts, such as objects, attributes, and relationships, into images'/texts' feature vectors via scene graphs, and a cross-modal attention fusion to combine the contextual semantics and local fusion via contextual vectors. Extensive experiments on public datasets Flickr30K and MSCOCO show that our SGFN performs better than quite a few SOTA image-text retrieval methods. ",
    "url": "https://arxiv.org/abs/2303.11090",
    "authors": [
      "Guoliang Wang",
      "Yanlei Shang",
      "Yong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11101",
    "title": "Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning",
    "abstract": "Deep learning in general domains has constantly been extended to domain-specific tasks requiring the recognition of fine-grained characteristics. However, real-world applications for fine-grained tasks suffer from two challenges: a high reliance on expert knowledge for annotation and necessity of a versatile model for various downstream tasks in a specific domain (e.g., prediction of categories, bounding boxes, or pixel-wise annotations). Fortunately, the recent self-supervised learning (SSL) is a promising approach to pretrain a model without annotations, serving as an effective initialization for any downstream tasks. Since SSL does not rely on the presence of annotation, in general, it utilizes the large-scale unlabeled dataset, referred to as an open-set. In this sense, we introduce a novel Open-Set Self-Supervised Learning problem under the assumption that a large-scale unlabeled open-set is available, as well as the fine-grained target dataset, during a pretraining phase. In our problem setup, it is crucial to consider the distribution mismatch between the open-set and target dataset. Hence, we propose SimCore algorithm to sample a coreset, the subset of an open-set that has a minimum distance to the target dataset in the latent space. We demonstrate that SimCore significantly improves representation learning performance through extensive experimental settings, including eleven fine-grained datasets and seven open-sets in various downstream tasks. ",
    "url": "https://arxiv.org/abs/2303.11101",
    "authors": [
      "Sungnyun Kim",
      "Sangmin Bae",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11127",
    "title": "MT-SNN: Enhance Spiking Neural Network with Multiple Thresholds",
    "abstract": "Spiking neural networks (SNNs), as a biology-inspired method mimicking the spiking nature of brain neurons, is a promising energy-efficient alternative to the traditional artificial neural networks (ANNs). The energy saving of SNNs is mainly from multiplication free property brought by binarized intermediate activations. In this paper, we proposed a Multiple Threshold (MT) approach to alleviate the precision loss brought by the binarized activations, such that SNNs can reach higher accuracy at fewer steps. We evaluate the approach on CIFAR10, CIFAR100 and DVS-CIFAR10, and demonstrate that MT can promote SNNs extensively, especially at early steps. For example, With MT, Parametric-Leaky-Integrate-Fire(PLIF) based VGG net can even outperform the ANN counterpart with 1 step. ",
    "url": "https://arxiv.org/abs/2303.11127",
    "authors": [
      "Xiaoting Wang",
      "Yanxiang Zhang",
      "Yongzhe Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11131",
    "title": "Cocktail HuBERT: Generalized Self-Supervised Pre-training for Mixture  and Single-Source Speech",
    "abstract": "Self-supervised learning leverages unlabeled data effectively, improving label efficiency and generalization to domains without labeled data. While recent work has studied generalization to more acoustic/linguistic domains, languages, and modalities, these investigations are limited to single-source speech with one primary speaker in the recording. This paper presents Cocktail HuBERT, a self-supervised learning framework that generalizes to mixture speech using a masked pseudo source separation objective. This objective encourages the model to identify the number of sources, separate and understand the context, and infer the content of masked regions represented as discovered units. Cocktail HuBERT outperforms state-of-the-art results with 69% lower WER on multi-speaker ASR, 31% lower DER on diarization, and is competitive on single- and multi-speaker tasks from SUPERB. ",
    "url": "https://arxiv.org/abs/2303.11131",
    "authors": [
      "Maryam Fazel-Zarandi",
      "Wei-Ning Hsu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.11135",
    "title": "TWINS: A Fine-Tuning Framework for Improved Transferability of  Adversarial Robustness and Generalization",
    "abstract": "Recent years have seen the ever-increasing importance of pre-trained models and their downstream training in deep learning research and applications. At the same time, the defense for adversarial examples has been mainly investigated in the context of training from random initialization on simple classification tasks. To better exploit the potential of pre-trained models in adversarial robustness, this paper focuses on the fine-tuning of an adversarially pre-trained model in various classification tasks. Existing research has shown that since the robust pre-trained model has already learned a robust feature extractor, the crucial question is how to maintain the robustness in the pre-trained model when learning the downstream task. We study the model-based and data-based approaches for this goal and find that the two common approaches cannot achieve the objective of improving both generalization and adversarial robustness. Thus, we propose a novel statistics-based approach, Two-WIng NormliSation (TWINS) fine-tuning framework, which consists of two neural networks where one of them keeps the population means and variances of pre-training data in the batch normalization layers. Besides the robust information transfer, TWINS increases the effective learning rate without hurting the training stability since the relationship between a weight norm and its gradient norm in standard batch normalization layer is broken, resulting in a faster escape from the sub-optimal initialization and alleviating the robust overfitting. Finally, TWINS is shown to be effective on a wide range of image classification datasets in terms of both generalization and robustness. Our code is available at https://github.com/ziquanliu/CVPR2023-TWINS. ",
    "url": "https://arxiv.org/abs/2303.11135",
    "authors": [
      "Ziquan Liu",
      "Yi Xu",
      "Xiangyang Ji",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11143",
    "title": "Adversarial Attacks against Binary Similarity Systems",
    "abstract": "In recent years, binary analysis gained traction as a fundamental approach to inspect software and guarantee its security. Due to the exponential increase of devices running software, much research is now moving towards new autonomous solutions based on deep learning models, as they have been showing state-of-the-art performances in solving binary analysis problems. One of the hot topics in this context is binary similarity, which consists in determining if two functions in assembly code are compiled from the same source code. However, it is unclear how deep learning models for binary similarity behave in an adversarial context. In this paper, we study the resilience of binary similarity models against adversarial examples, showing that they are susceptible to both targeted and untargeted attacks (w.r.t. similarity goals) performed by black-box and white-box attackers. In more detail, we extensively test three current state-of-the-art solutions for binary similarity against two black-box greedy attacks, including a new technique that we call Spatial Greedy, and one white-box attack in which we repurpose a gradient-guided strategy used in attacks to image classifiers. ",
    "url": "https://arxiv.org/abs/2303.11143",
    "authors": [
      "Gianluca Capozzi",
      "Daniele Cono D'Elia",
      "Giuseppe Antonio Di Luna",
      "Leonardo Querzoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11147",
    "title": "The Systemic Impact of Deplatforming on Social Media",
    "abstract": "Deplatforming, or banning malicious accounts from social media, is a key tool for moderating online harms. However, the consequences of deplatforming for the wider social media ecosystem have been largely overlooked so far, due to the difficulty of tracking banned users. Here, we address this gap by studying the ban-induced platform migration from Twitter to Gettr. With a matched dataset of 15M Gettr posts and 12M Twitter tweets, we show that users active on both platforms post similar content as users active on Gettr but banned from Twitter, but the latter have higher retention and are 5 times more active. Then, we reveal that matched users are more toxic on Twitter, where they can engage in abusive cross-ideological interactions, than Gettr. Our analysis shows that the matched cohort are ideologically aligned with the far-right, and that the ability to interact with political opponents may be part of the appeal of Twitter to these users. Finally, we identify structural changes in the Gettr network preceding the 2023 Brasilia insurrections, highlighting how deplatforming from mainstream social media can fuel poorly-regulated alternatives that may pose a risk to democratic life. ",
    "url": "https://arxiv.org/abs/2303.11147",
    "authors": [
      "Amin Mekacher",
      "Max Falkenberg",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.11169",
    "title": "Self-supervised Geometric Features Discovery via Interpretable Attentio  for Vehicle Re-Identification and Beyond (Complete Version)",
    "abstract": "To learn distinguishable patterns, most of recent works in vehicle re-identification (ReID) struggled to redevelop official benchmarks to provide various supervisions, which requires prohibitive human labors. In this paper, we seek to achieve the similar goal but do not involve more human efforts. To this end, we introduce a novel framework, which successfully encodes both geometric local features and global representations to distinguish vehicle instances, optimized only by the supervision from official ID labels. Specifically, given our insight that objects in ReID share similar geometric characteristics, we propose to borrow self-supervised representation learning to facilitate geometric features discovery. To condense these features, we introduce an interpretable attention module, with the core of local maxima aggregation instead of fully automatic learning, whose mechanism is completely understandable and whose response map is physically reasonable. To the best of our knowledge, we are the first that perform self-supervised learning to discover geometric features. We conduct comprehensive experiments on three most popular datasets for vehicle ReID, i.e., VeRi-776, CityFlow-ReID, and VehicleID. We report our state-of-the-art (SOTA) performances and promising visualization results. We also show the excellent scalability of our approach on other ReID related tasks, i.e., person ReID and multi-target multi-camera (MTMC) vehicle tracking. The code is available at https://github.com/ ming1993li/Self-supervised-Geometric. ",
    "url": "https://arxiv.org/abs/2303.11169",
    "authors": [
      "Ming Li",
      "Xinming Huang",
      "Ziming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11170",
    "title": "A Pervasive Framework for Human Detection and Tracking",
    "abstract": "The advent of the Edge Computing (EC) leads to a huge ecosystem where numerous nodes can interact with data collection devices located close to end users. Human detection and tracking can be realized at edge nodes that perform the surveillance of an area under consideration through the assistance of a set of sensors (e.g., cameras). Our target is to incorporate the discussed functionalities to embedded devices present at the edge keeping their size limited while increasing their processing capabilities. In this paper, we propose two models for human detection accompanied by algorithms for tracing the corresponding trajectories. We provide the description of the proposed models and extend them to meet the challenges of the problem. Our evaluation aims at identifying models' accuracy while presenting their requirements to have them executed in embedded devices. ",
    "url": "https://arxiv.org/abs/2303.11170",
    "authors": [
      "Fesatidis Georgios",
      "Bratsos Dimitrios",
      "Kostas Kolomvatsos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11198",
    "title": "A set of semantic data flow diagrams and its security analysis based on  ontologies and knowledge graphs",
    "abstract": "For a long time threat modeling was treated as a manual, complicated process. However modern agile development methodologies and cloud computing technologies require adding automatic threat modeling approaches. This work considers two challenges: creating a set of machine-readable data flow diagrams that represent real cloud based applications; and usage domain specific knowledge for automatic analysis of the security aspects of such applications. The set of 180 semantic diagrams (ontologies and knowledge graphs) is created based on cloud configurations (Docker Compose); the set includes a manual taxonomy that allows to define the design and functional aspects of the web based and data processing applications; the set can be used for various research in the threat modeling field. This work also evaluates how ontologies and knowledge graphs can be used to automatically recognize patterns (mapped to security threats) in diagrams. A pattern represents features of a diagram in form of a request to a knowledge base, what enables its recognition in a semantic representation of a diagram. In an experiment four groups of the patterns are created (web applications, data processing, network, and docker specific), and the diagrams are examined by the patterns. Automatic results, received for the web applications and data processing patterns, are compared with the manual taxonomy in order to study challenges of automatic threat modeling. ",
    "url": "https://arxiv.org/abs/2303.11198",
    "authors": [
      "Andrei Brazhuk"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11205",
    "title": "Entropy-dissipation Informed Neural Network for McKean-Vlasov Type PDEs",
    "abstract": "We extend the concept of self-consistency for the Fokker-Planck equation (FPE) to the more general McKean-Vlasov equation (MVE). While FPE describes the macroscopic behavior of particles under drift and diffusion, MVE accounts for the additional inter-particle interactions, which are often highly singular in physical systems. Two important examples considered in this paper are the MVE with Coulomb interactions and the vorticity formulation of the 2D Navier-Stokes equation. We show that a generalized self-consistency potential controls the KL-divergence between a hypothesis solution to the ground truth, through entropy dissipation. Built on this result, we propose to solve the MVEs by minimizing this potential function, while utilizing the neural networks for function approximation. We validate the empirical performance of our approach by comparing with state-of-the-art NN-based PDE solvers on several example problems. ",
    "url": "https://arxiv.org/abs/2303.11205",
    "authors": [
      "Zebang Shen",
      "Zhenfu Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2303.11230",
    "title": "Fitting Low-rank Models on Egocentrically Sampled Partial Networks",
    "abstract": "The statistical modeling of random networks has been widely used to uncover interaction mechanisms in complex systems and to predict unobserved links in real-world networks. In many applications, network connections are collected via egocentric sampling: a subset of nodes is sampled first, after which all links involving this subset are recorded; all other information is missing. Compared with the assumption of ``uniformly missing at random\", egocentrically sampled partial networks require specially designed modeling strategies. Current statistical methods are either computationally infeasible or based on intuitive designs without theoretical justification. Here, we propose an approach to fit general low-rank models for egocentrically sampled networks, which include several popular network models. This method is based on graph spectral properties and is computationally efficient for large-scale networks. It results in consistent recovery of missing subnetworks due to egocentric sampling for sparse networks. To our knowledge, this method offers the first theoretical guarantee for egocentric partial network estimation in the scope of low-rank models. We evaluate the technique on several synthetic and real-world networks and show that it delivers competitive performance in link prediction tasks. ",
    "url": "https://arxiv.org/abs/2303.11230",
    "authors": [
      "Angus Chan",
      "Tianxi Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.11231",
    "title": "Bounded twin-width graphs are polynomially $\u03c7$-bounded",
    "abstract": "We show that every graph with twin-width $t$ has chromatic number $O(\\omega ^{k_t})$ for some integer $k_t$, where $\\omega$ denotes the clique number. This extends a quasi-polynomial bound from Pilipczuk and Soko{\\l}owski and generalizes a result for bounded clique-width graphs by Bonamy and Pilipczuk. The proof uses the main ideas of the quasi-polynomial approach, with a different treatment of the decomposition tree. In particular, we identify two types of extensions of a class of graphs: the delayed-extension (which preserves polynomial $\\chi$-boundedness) and the right-extension (which preserves polynomial $\\chi$-boundedness under bounded twin-width condition). Our main result is that every bounded twin-width graph is a delayed extension of simpler classes of graphs, each expressed as a bounded union of right extensions of lower twin-width graphs. ",
    "url": "https://arxiv.org/abs/2303.11231",
    "authors": [
      "Romain Bourneuf",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.11239",
    "title": "Training Invertible Neural Networks as Autoencoders",
    "abstract": "Autoencoders are able to learn useful data representations in an unsupervised matter and have been widely used in various machine learning and computer vision tasks. In this work, we present methods to train Invertible Neural Networks (INNs) as (variational) autoencoders which we call INN (variational) autoencoders. Our experiments on MNIST, CIFAR and CelebA show that for low bottleneck sizes our INN autoencoder achieves results similar to the classical autoencoder. However, for large bottleneck sizes our INN autoencoder outperforms its classical counterpart. Based on the empirical results, we hypothesize that INN autoencoders might not have any intrinsic information loss and thereby are not bounded to a maximal number of layers (depth) after which only suboptimal results can be achieved. ",
    "url": "https://arxiv.org/abs/2303.11239",
    "authors": [
      "The-Gia Leo Nguyen",
      "Lynton Ardizzone",
      "Ullrich Koethe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11240",
    "title": "Truth Social Dataset",
    "abstract": "Formally announced to the public following former President Donald Trump's bans and suspensions from mainstream social networks in early 2022 after his role in the January 6 Capitol Riots, Truth Social was launched as an \"alternative\" social media platform that claims to be a refuge for free speech, offering a platform for those disaffected by the content moderation policies of the existing, mainstream social networks. The subsequent rise of Truth Social has been driven largely by hard-line supporters of the former president as well as those affected by the content moderation of other social networks. These distinct qualities combined with its status as the main mouthpiece of the former president positions Truth Social as a particularly influential social media platform and give rise to several research questions. However, outside of a handful of news reports, little is known about the new social media platform partially due to a lack of well-curated data. In the current work, we describe a dataset of over 823,000 posts to Truth Social and and social network with over 454,000 distinct users. In addition to the dataset itself, we also present some basic analysis of its content, certain temporal features, and its network. ",
    "url": "https://arxiv.org/abs/2303.11240",
    "authors": [
      "Patrick Gerard",
      "Nicholas Botzer",
      "Tim Weninger"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.11243",
    "title": "Augment and Criticize: Exploring Informative Samples for Semi-Supervised  Monocular 3D Object Detection",
    "abstract": "In this paper, we improve the challenging monocular 3D object detection problem with a general semi-supervised framework. Specifically, having observed that the bottleneck of this task lies in lacking reliable and informative samples to train the detector, we introduce a novel, simple, yet effective `Augment and Criticize' framework that explores abundant informative samples from unlabeled data for learning more robust detection models. In the `Augment' stage, we present the Augmentation-based Prediction aGgregation (APG), which aggregates detections from various automatically learned augmented views to improve the robustness of pseudo label generation. Since not all pseudo labels from APG are beneficially informative, the subsequent `Criticize' phase is presented. In particular, we introduce the Critical Retraining Strategy (CRS) that, unlike simply filtering pseudo labels using a fixed threshold (e.g., classification score) as in 2D semi-supervised tasks, leverages a learnable network to evaluate the contribution of unlabeled images at different training timestamps. This way, the noisy samples prohibitive to model evolution could be effectively suppressed. To validate our framework, we apply it to MonoDLE and MonoFlex. The two new detectors, dubbed 3DSeMo_DLE and 3DSeMo_FLEX, achieve state-of-the-art results with remarkable improvements for over 3.5% AP_3D/BEV (Easy) on KITTI, showing its effectiveness and generality. Code and models will be released. ",
    "url": "https://arxiv.org/abs/2303.11243",
    "authors": [
      "Zhenyu Li",
      "Zhipeng Zhang",
      "Heng Fan",
      "Yuan He",
      "Ke Wang",
      "Xianming Liu",
      "Junjun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11247",
    "title": "Memorization Capacity of Neural Networks with Conditional Computation",
    "abstract": "Many empirical studies have demonstrated the performance benefits of conditional computation in neural networks, including reduced inference time and power consumption. We study the fundamental limits of neural conditional computation from the perspective of memorization capacity. For Rectified Linear Unit (ReLU) networks without conditional computation, it is known that memorizing a collection of $n$ input-output relationships can be accomplished via a neural network with $O(\\sqrt{n})$ neurons. Calculating the output of this neural network can be accomplished using $O(\\sqrt{n})$ elementary arithmetic operations of additions, multiplications and comparisons for each input. Using a conditional ReLU network, we show that the same task can be accomplished using only $O(\\log n)$ operations per input. This represents an almost exponential improvement as compared to networks without conditional computation. We also show that the $\\Theta(\\log n)$ rate is the best possible. Our achievability result utilizes a general methodology to synthesize a conditional network out of an unconditional network in a computationally-efficient manner, bridging the gap between unconditional and conditional architectures. ",
    "url": "https://arxiv.org/abs/2303.11247",
    "authors": [
      "Erdem Koyuncu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11249",
    "title": "What Makes Data Suitable for a Locally Connected Neural Network? A  Necessary and Sufficient Condition Based on Quantum Entanglement",
    "abstract": "The question of what makes a data distribution suitable for deep learning is a fundamental open problem. Focusing on locally connected neural networks (a prevalent family of architectures that includes convolutional and recurrent neural networks as well as local self-attention models), we address this problem by adopting theoretical tools from quantum physics. Our main theoretical result states that a certain locally connected neural network is capable of accurate prediction over a data distribution if and only if the data distribution admits low quantum entanglement under certain canonical partitions of features. As a practical application of this result, we derive a preprocessing method for enhancing the suitability of a data distribution to locally connected neural networks. Experiments with widespread models over various datasets demonstrate our findings. We hope that our use of quantum entanglement will encourage further adoption of tools from physics for formally reasoning about the relation between deep learning and real-world data. ",
    "url": "https://arxiv.org/abs/2303.11249",
    "authors": [
      "Yotam Alexander",
      "Nimrod De La Vega",
      "Noam Razin",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2303.11267",
    "title": "Rethinking the backbone architecture for tiny object detection",
    "abstract": "Tiny object detection has become an active area of research because images with tiny targets are common in several important real-world scenarios. However, existing tiny object detection methods use standard deep neural networks as their backbone architecture. We argue that such backbones are inappropriate for detecting tiny objects as they are designed for the classification of larger objects, and do not have the spatial resolution to identify small targets. Specifically, such backbones use max-pooling or a large stride at early stages in the architecture. This produces lower resolution feature-maps that can be efficiently processed by subsequent layers. However, such low-resolution feature-maps do not contain information that can reliably discriminate tiny objects. To solve this problem we design 'bottom-heavy' versions of backbones that allocate more resources to processing higher-resolution features without introducing any additional computational burden overall. We also investigate if pre-training these backbones on images of appropriate size, using CIFAR100 and ImageNet32, can further improve performance on tiny object detection. Results on TinyPerson and WiderFace show that detectors with our proposed backbones achieve better results than the current state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2303.11267",
    "authors": [
      "Jinlai Ning",
      "Haoyan Guan",
      "Michael Spratling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11274",
    "title": "Cascading Hierarchical Networks with Multi-task Balanced Loss for  Fine-grained hashing",
    "abstract": "With the explosive growth in the number of fine-grained images in the Internet era, it has become a challenging problem to perform fast and efficient retrieval from large-scale fine-grained images. Among the many retrieval methods, hashing methods are widely used due to their high efficiency and small storage space occupation. Fine-grained hashing is more challenging than traditional hashing problems due to the difficulties such as low inter-class variances and high intra-class variances caused by the characteristics of fine-grained images. To improve the retrieval accuracy of fine-grained hashing, we propose a cascaded network to learn compact and highly semantic hash codes, and introduce an attention-guided data augmentation method. We refer to this network as a cascaded hierarchical data augmentation network. We also propose a novel approach to coordinately balance the loss of multi-task learning. We do extensive experiments on some common fine-grained visual classification datasets. The experimental results demonstrate that our proposed method outperforms several state-of-art hashing methods and can effectively improve the accuracy of fine-grained retrieval. The source code is publicly available: https://github.com/kaiba007/FG-CNET. ",
    "url": "https://arxiv.org/abs/2303.11274",
    "authors": [
      "Xianxian Zeng",
      "Yanjun Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11279",
    "title": "Distributed Timed Elastic Band (DTEB) Planner: Trajectory Sharing and  Collision Prediction for Multi-Robot Systems",
    "abstract": "Autonomous navigation of mobile robots is a well studied problem in robotics. However, the navigation task becomes challenging when multi-robot systems have to cooperatively navigate dynamic environments with deadlock-prone layouts. We present a Distributed Timed Elastic Band (DTEB) Planner that combines Prioritized Planning with the online TEB trajectory Planner, in order to extend the capabilities of the latter to multi-robot systems. The proposed planner is able to reactively avoid imminent collisions as well as predictively resolve potential deadlocks among a team of robots, while navigating in a complex environment. The results of our simulation demonstrate the reliable performance and the versatility of the planner in different environment settings. The code and tests for our approach are available online. ",
    "url": "https://arxiv.org/abs/2303.11279",
    "authors": [
      "Yiu Ming Chung",
      "Hazem Youssef",
      "Moritz Roidl"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.11288",
    "title": "Rethinking SO(3)-equivariance with Bilinear Tensor Networks",
    "abstract": "Many datasets in scientific and engineering applications are comprised of objects which have specific geometric structure. A common example is data which inhabits a representation of the group SO$(3)$ of 3D rotations: scalars, vectors, tensors, \\textit{etc}. One way for a neural network to exploit prior knowledge of this structure is to enforce SO$(3)$-equivariance throughout its layers, and several such architectures have been proposed. While general methods for handling arbitrary SO$(3)$ representations exist, they computationally intensive and complicated to implement. We show that by judicious symmetry breaking, we can efficiently increase the expressiveness of a network operating only on vector and order-2 tensor representations of SO$(2)$. We demonstrate the method on an important problem from High Energy Physics known as \\textit{b-tagging}, where particle jets originating from b-meson decays must be discriminated from an overwhelming QCD background. In this task, we find that augmenting a standard architecture with our method results in a \\ensuremath{2.3\\times} improvement in rejection score. ",
    "url": "https://arxiv.org/abs/2303.11288",
    "authors": [
      "Chase Shimmin",
      "Zhelun Li",
      "Ema Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ]
  },
  {
    "id": "arXiv:2303.11293",
    "title": "Advancing Network Securing Strategies with Network Algorithms for  Integrated Air Defense System (IADS) Missile Batteries",
    "abstract": "Recently, the Integrated Air Defense System (IADS) has become vital for the defense system as the military defense system is vital for national security. Placing Integrated Air Defense System batteries among locations to protect locations assets is a crucial problem because optimal solutions are needed for interceptor missiles to intercept attacker missiles for maximizing protection of assets across locations or places. In this research, the procedures of using network algorithms along with developing several network algorithms are going to be demonstrated to develop a model for sequential development of seven network securing strategies of placing Surface to Air Missile (SAM) batteries to maximize the protection of assets across locations (based on given asset values) by generating optimal solutions through computation to destroy maximum attacker missiles by using minimum interceptor missiles with given intercept probability. This network securing strategies can be implemented not only for Integrated Air Defense System (IADS) planning but also Counter Air (CA) planning as Integrated Air Defense System (IADS) is conducted with defensive counter air supported by attack operations in offensive counter air. ",
    "url": "https://arxiv.org/abs/2303.11293",
    "authors": [
      "Rakib Hassan Pran"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2303.11296",
    "title": "Attribute-preserving Face Dataset Anonymization via Latent Code  Optimization",
    "abstract": "This work addresses the problem of anonymizing the identity of faces in a dataset of images, such that the privacy of those depicted is not violated, while at the same time the dataset is useful for downstream task such as for training machine learning models. To the best of our knowledge, we are the first to explicitly address this issue and deal with two major drawbacks of the existing state-of-the-art approaches, namely that they (i) require the costly training of additional, purpose-trained neural networks, and/or (ii) fail to retain the facial attributes of the original images in the anonymized counterparts, the preservation of which is of paramount importance for their use in downstream tasks. We accordingly present a task-agnostic anonymization procedure that directly optimizes the images' latent representation in the latent space of a pre-trained GAN. By optimizing the latent codes directly, we ensure both that the identity is of a desired distance away from the original (with an identity obfuscation loss), whilst preserving the facial attributes (using a novel feature-matching loss in FaRL's deep feature space). We demonstrate through a series of both qualitative and quantitative experiments that our method is capable of anonymizing the identity of the images whilst -- crucially -- better-preserving the facial attributes. We make the code and the pre-trained models publicly available at: https://github.com/chi0tzp/FALCO. ",
    "url": "https://arxiv.org/abs/2303.11296",
    "authors": [
      "Simone Barattin",
      "Christos Tzelepis",
      "Ioannis Patras",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11301",
    "title": "VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking",
    "abstract": "3D object detectors usually rely on hand-crafted proxies, e.g., anchors or centers, and translate well-studied 2D frameworks to 3D. Thus, sparse voxel features need to be densified and processed by dense prediction heads, which inevitably costs extra computation. In this paper, we instead propose VoxelNext for fully sparse 3D object detection. Our core insight is to predict objects directly based on sparse voxel features, without relying on hand-crafted proxies. Our strong sparse convolutional network VoxelNeXt detects and tracks 3D objects through voxel features entirely. It is an elegant and efficient framework, with no need for sparse-to-dense conversion or NMS post-processing. Our method achieves a better speed-accuracy trade-off than other mainframe detectors on the nuScenes dataset. For the first time, we show that a fully sparse voxel-based representation works decently for LIDAR 3D object detection and tracking. Extensive experiments on nuScenes, Waymo, and Argoverse2 benchmarks validate the effectiveness of our approach. Without bells and whistles, our model outperforms all existing LIDAR methods on the nuScenes tracking test benchmark. ",
    "url": "https://arxiv.org/abs/2303.11301",
    "authors": [
      "Yukang Chen",
      "Jianhui Liu",
      "Xiangyu Zhang",
      "Xiaojuan Qi",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11307",
    "title": "DIME-Net: Neural Network-Based Dynamic Intrinsic Parameter Rectification  for Cameras with Optical Image Stabilization System",
    "abstract": "Optical Image Stabilization (OIS) system in mobile devices reduces image blurring by steering lens to compensate for hand jitters. However, OIS changes intrinsic camera parameters (i.e. $\\mathrm{K}$ matrix) dynamically which hinders accurate camera pose estimation or 3D reconstruction. Here we propose a novel neural network-based approach that estimates $\\mathrm{K}$ matrix in real-time so that pose estimation or scene reconstruction can be run at camera native resolution for the highest accuracy on mobile devices. Our network design takes gratified projection model discrepancy feature and 3D point positions as inputs and employs a Multi-Layer Perceptron (MLP) to approximate $f_{\\mathrm{K}}$ manifold. We also design a unique training scheme for this network by introducing a Back propagated PnP (BPnP) layer so that reprojection error can be adopted as the loss function. The training process utilizes precise calibration patterns for capturing accurate $f_{\\mathrm{K}}$ manifold but the trained network can be used anywhere. We name the proposed Dynamic Intrinsic Manifold Estimation network as DIME-Net and have it implemented and tested on three different mobile devices. In all cases, DIME-Net can reduce reprojection error by at least $64\\%$ indicating that our design is successful. ",
    "url": "https://arxiv.org/abs/2303.11307",
    "authors": [
      "Shu-Hao Yeh",
      "Shuangyu Xie",
      "Di Wang",
      "Wei Yan",
      "Dezhen Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.11310",
    "title": "How Robust are Timely Gossip Networks to Jamming Attacks?",
    "abstract": "We consider a semantics-aware communication system, where timeliness is the semantic measure, with a source which maintains the most current version of a file, and a network of $n$ user nodes with the goal to acquire the latest version of the file. The source gets updated with newer file versions as a point process, and forwards them to the user nodes, which further forward them to their neighbors using a memoryless gossip protocol. We study the average version age of the network in the presence of $\\tilde{n}$ jammers that disrupt inter-node communications, for the connectivity-constrained ring topology and the connectivity-rich fully connected topology. For the ring topology, we construct an alternate system model of mini-rings and prove that the version age of the original model can be sandwiched between constant multiples of the version age of the alternate model. We show in a ring network that when the number of jammers scales as a fractional power of the network size, i.e., $\\tilde n= cn^\\alpha$, the version age scales as $\\sqrt{n}$ when $\\alpha < \\frac{1}{2}$, and as $n^{\\alpha}$ when $\\alpha \\geq \\frac{1}{2}$. As version age of a ring network without any jammers scales as $\\sqrt{n}$, our result implies that version age with gossiping is robust against upto $\\sqrt{n}$ jammers in a ring network. We then study the connectivity-rich fully connected topology, where we derive a greedy approach to place $\\tilde{n}$ jammers to maximize age of the resultant network, which uses jammers to isolate as many nodes as possible, thereby consolidating all links into a single mini-fully connected network. We show in this network that version age scales as $\\log{n}$ when $\\tilde{n}=cn\\log{n}$ and as $n^{\\alpha-1}$, $1<\\alpha\\leq2$ when $\\tilde{n}=cn^{\\alpha}$, implying the network is robust against $n\\log{n}$ jammers, since the age in a fully connected network without jammers scales as $\\log{n}$. ",
    "url": "https://arxiv.org/abs/2303.11310",
    "authors": [
      "Priyanka Kaswan",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.11324",
    "title": "Open-vocabulary Panoptic Segmentation with Embedding Modulation",
    "abstract": "Open-vocabulary image segmentation is attracting increasing attention due to its critical applications in the real world. Traditional closed-vocabulary segmentation methods are not able to characterize novel objects, whereas several recent open-vocabulary attempts obtain unsatisfactory results, i.e., notable performance reduction on the closed vocabulary and massive demand for extra data. To this end, we propose OPSNet, an omnipotent and data-efficient framework for Open-vocabulary Panoptic Segmentation. Specifically, the exquisitely designed Embedding Modulation module, together with several meticulous components, enables adequate embedding enhancement and information exchange between the segmentation model and the visual-linguistic well-aligned CLIP encoder, resulting in superior segmentation performance under both open- and closed-vocabulary settings with much fewer need of additional data. Extensive experimental evaluations are conducted across multiple datasets (e.g., COCO, ADE20K, Cityscapes, and PascalContext) under various circumstances, where the proposed OPSNet achieves state-of-the-art results, which demonstrates the effectiveness and generality of the proposed approach. The code and trained models will be made publicly available. ",
    "url": "https://arxiv.org/abs/2303.11324",
    "authors": [
      "Xi Chen",
      "Shuang Li",
      "Ser-Nam Lim",
      "Antonio Torralba",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11331",
    "title": "EVA-02: A Visual Representation for Neon Genesis",
    "abstract": "We launch EVA-02, a next-generation Transformer-based visual representation pre-trained to reconstruct strong and robust language-aligned vision features via masked image modeling. With an updated plain Transformer architecture as well as extensive pre-training from an open & accessible giant CLIP vision encoder, EVA-02 demonstrates superior performance compared to prior state-of-the-art approaches across various representative vision tasks, while utilizing significantly fewer parameters and compute budgets. Notably, using exclusively publicly accessible training data, EVA-02 with only 304M parameters achieves a phenomenal 90.0 fine-tuning top-1 accuracy on ImageNet-1K val set. Additionally, our EVA-02-CLIP can reach up to 80.4 zero-shot top-1 on ImageNet-1K, outperforming the previous largest & best open-sourced CLIP with only ~1/6 parameters and ~1/6 image-text training data. We offer four EVA-02 variants in various model sizes, ranging from 6M to 304M parameters, all with impressive performance. To facilitate open access and open research, we release the complete suite of EVA-02 to the community at https://github.com/baaivision/EVA/tree/master/EVA-02. ",
    "url": "https://arxiv.org/abs/2303.11331",
    "authors": [
      "Yuxin Fang",
      "Quan Sun",
      "Xinggang Wang",
      "Tiejun Huang",
      "Xinlong Wang",
      "Yue Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.10191",
    "title": "Unsupervised Domain Transfer with Conditional Invertible Neural Networks",
    "abstract": "Synthetic medical image generation has evolved as a key technique for neural network training and validation. A core challenge, however, remains in the domain gap between simulations and real data. While deep learning-based domain transfer using Cycle Generative Adversarial Networks and similar architectures has led to substantial progress in the field, there are use cases in which state-of-the-art approaches still fail to generate training images that produce convincing results on relevant downstream tasks. Here, we address this issue with a domain transfer approach based on conditional invertible neural networks (cINNs). As a particular advantage, our method inherently guarantees cycle consistency through its invertible architecture, and network training can efficiently be conducted with maximum likelihood training. To showcase our method's generic applicability, we apply it to two spectral imaging modalities at different scales, namely hyperspectral imaging (pixel-level) and photoacoustic tomography (image-level). According to comprehensive experiments, our method enables the generation of realistic spectral data and outperforms the state of the art on two downstream classification tasks (binary and multi-class). cINN-based domain transfer could thus evolve as an important method for realistic synthetic data generation in the field of spectral imaging and beyond. ",
    "url": "https://arxiv.org/abs/2303.10191",
    "authors": [
      "Kris K. Dreher",
      "Leonardo Ayala",
      "Melanie Schellenberg",
      "Marco H\u00fcbner",
      "Jan-Hinrich N\u00f6lke",
      "Tim J. Adler",
      "Silvia Seidlitz",
      "Jan Sellner",
      "Alexander Studier-Fischer",
      "Janek Gr\u00f6hl",
      "Felix Nickel",
      "Ullrich K\u00f6the",
      "Alexander Seitel",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10326",
    "title": "Diff-UNet: A Diffusion Embedded Network for Volumetric Segmentation",
    "abstract": "In recent years, Denoising Diffusion Models have demonstrated remarkable success in generating semantically valuable pixel-wise representations for image generative modeling. In this study, we propose a novel end-to-end framework, called Diff-UNet, for medical volumetric segmentation. Our approach integrates the diffusion model into a standard U-shaped architecture to extract semantic information from the input volume effectively, resulting in excellent pixel-level representations for medical volumetric segmentation. To enhance the robustness of the diffusion model's prediction results, we also introduce a Step-Uncertainty based Fusion (SUF) module during inference to combine the outputs of the diffusion models at each step. We evaluate our method on three datasets, including multimodal brain tumors in MRI, liver tumors, and multi-organ CT volumes, and demonstrate that Diff-UNet outperforms other state-of-the-art methods significantly. Our experimental results also indicate the universality and effectiveness of the proposed model. The proposed framework has the potential to facilitate the accurate diagnosis and treatment of medical conditions by enabling more precise segmentation of anatomical structures. The codes of Diff-UNet are available at https://github.com/ge-xing/Diff-UNet ",
    "url": "https://arxiv.org/abs/2303.10326",
    "authors": [
      "Zhaohu Xing",
      "Liang Wan",
      "Huazhu Fu",
      "Guang Yang",
      "Lei Zhu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10342",
    "title": "Whole-slide-imaging Cancer Metastases Detection and Localization with  Limited Tumorous Data",
    "abstract": "Recently, various deep learning methods have shown significant successes in medical image analysis, especially in the detection of cancer metastases in hematoxylin and eosin (H&E) stained whole-slide images (WSIs). However, in order to obtain good performance, these research achievements rely on hundreds of well-annotated WSIs. In this study, we tackle the tumor localization and detection problem under the setting of few labeled whole slide images and introduce a patch-based analysis pipeline based on the latest reverse knowledge distillation architecture. To address the extremely unbalanced normal and tumorous samples in training sample collection, we applied the focal loss formula to the representation similarity metric for model optimization. Compared with prior arts, our method achieves similar performance by less than ten percent of training samples on the public Camelyon16 dataset. In addition, this is the first work that show the great potential of the knowledge distillation models in computational histopathology. ",
    "url": "https://arxiv.org/abs/2303.10342",
    "authors": [
      "Yinsheng He",
      "Xingyu Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10401",
    "title": "Smart ROI Detection for Alzheimer's disease prediction using explainable  AI",
    "abstract": "Purpose Predicting the progression of MCI to Alzheimer's disease is an important step in reducing the progression of the disease. Therefore, many methods have been introduced for this task based on deep learning. Among these approaches, the methods based on ROIs are in a good position in terms of accuracy and complexity. In these techniques, some specific parts of the brain are extracted as ROI manually for all of the patients. Extracting ROI manually is time-consuming and its results depend on human expertness and precision. Method To overcome these limitations, we propose a novel smart method for detecting ROIs automatically based on Explainable AI using Grad-Cam and a 3DCNN model that extracts ROIs per patient. After extracting the ROIs automatically, Alzheimer's disease is predicted using extracted ROI-based 3D CNN. Results We implement our method on 176 MCI patients of the famous ADNI dataset and obtain remarkable results compared to the state-of-the-art methods. The accuracy acquired using 5-fold cross-validation is 98.6 and the AUC is 1. We also compare the results of the ROI-based method with the whole brain-based method. The results show that the performance is impressively increased. Conclusion The experimental results show that the proposed smart ROI extraction, which extracts the ROIs automatically, performs well for Alzheimer's disease prediction. The proposed method can also be used for Alzheimer's disease classification and diagnosis. ",
    "url": "https://arxiv.org/abs/2303.10401",
    "authors": [
      "Atefe Aghaei",
      "Mohsen Ebrahimi Moghaddam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10417",
    "title": "On the Benefit of Nonlinear Control for Robust Logarithmic Growth: Coin  Flipping Games as a Demonstration Case",
    "abstract": "The takeoff point for this paper is the voluminous body of literature addressing recursive betting games with expected logarithmic growth of wealth being the performance criterion. Whereas almost all existing papers involve use of linear feedback, the use of nonlinear control is conspicuously absent. This is epitomized by the large subset of this literature dealing with Kelly Betting. With this as the high-level motivation, we study the potential for use of nonlinear control in this framework. To this end, we consider a ``demonstration case'' which is one of the simplest scenarios encountered in this line of research: repeated flips of a biased coin with probability of heads~$p$ and even-money payoff on each flip. First, we formulate a new robust nonlinear control problem which we believe is both simple to understand and apropos for dealing with concerns about distributional robustness; i.e., instead of assuming that~$p$ is perfectly known as in the case of the classical Kelly formulation, we begin with a bounding set for this probability. Then, we provide a theorem, our main result, which gives a closed-form description of the optimal robust nonlinear controller and a corollary which establishes that it robustly outperforms linear controllers such as those found in the literature. A second contribution of this paper bears upon the computability of our solution. For an $n$-flip game, whereas an admissible controller has~$2^n-1$ parameters, at the optimum only~$O(n^2)$ of them turn out to be distinct. Finally, we provide some illustrations comparing robust performance with what is possible when working with the so-called perfect-information Kelly optimum. ",
    "url": "https://arxiv.org/abs/2303.10417",
    "authors": [
      "Anton V. Proskurnikov",
      "B. Ross Barmish"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Mathematical Finance (q-fin.MF)"
    ]
  },
  {
    "id": "arXiv:2303.10513",
    "title": "Backward Reachability Analysis of Neural Feedback Systems Using Hybrid  Zonotopes",
    "abstract": "The proliferation of neural networks in safety-critical applications necessitates the development of effective methods to ensure their safety. This letter presents a novel approach for computing the exact backward reachable sets of neural feedback systems based on hybrid zonotopes. It is shown that the input-output relationship imposed by a ReLU-activated neural network can be exactly described by a hybrid zonotope-represented graph set. Based on that, the one-step exact backward reachable set of a neural feedback system is computed as a hybrid zonotope in the closed form. In addition, a necessary and sufficient condition is formulated as a mixed-integer linear program to certify whether the trajectories of a neural feedback system can avoid unsafe regions in finite time. Numerical examples are provided to demonstrate the efficiency of the proposed approach. ",
    "url": "https://arxiv.org/abs/2303.10513",
    "authors": [
      "Yuhao Zhang",
      "Hang Zhang",
      "Xiangru Xu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.10556",
    "title": "The Graph feature fusion technique for speaker recognition based on  wav2vec2.0 framework",
    "abstract": "Pre-trained wav2vec2.0 model has been proved its effectiveness for speaker recognition. However, current feature processing methods are focusing on classical pooling on the output features of the pre-trained wav2vec2.0 model, such as mean pooling, max pooling etc. That methods take the features as the independent and irrelevant units, ignoring the inter-relationship among all the features, and do not take the features as an overall representation of a speaker. Gated Recurrent Unit (GRU), as a feature fusion method, can also be considered as a complicated pooling technique, mainly focuses on the temporal information, which may show poor performance in some situations that the main information is not on the temporal dimension. In this paper, we investigate the graph neural network (GNN) as a backend processing module based on wav2vec2.0 framework to provide a solution for the mentioned matters. The GNN takes all the output features as the graph signal data and extracts the related graph structure information of features for speaker recognition. Specifically, we first give a simple proof that the GNN feature fusion method can outperform than the mean, max, random pooling methods and so on theoretically. Then, we model the output features of wav2vec2.0 as the vertices of a graph, and construct the graph adjacency matrix by graph attention network (GAT). Finally, we follow the message passing neural network (MPNN) to design our message function, vertex update function and readout function to transform the speaker features into the graph features. The experiments show our performance can provide a relative improvement compared to the baseline methods. Code is available at xxx. ",
    "url": "https://arxiv.org/abs/2303.10556",
    "authors": [
      "Zirui Ge",
      "Haiyan Guo",
      "Zhen Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.10566",
    "title": "Dynamical Hyperspectral Unmixing with Variational Recurrent Neural  Networks",
    "abstract": "Multitemporal hyperspectral unmixing (MTHU) is a fundamental tool in the analysis of hyperspectral image sequences. It reveals the dynamical evolution of the materials (endmembers) and of their proportions (abundances) in a given scene. However, adequately accounting for the spatial and temporal variability of the endmembers in MTHU is challenging, and has not been fully addressed so far in unsupervised frameworks. In this work, we propose an unsupervised MTHU algorithm based on variational recurrent neural networks. First, a stochastic model is proposed to represent both the dynamical evolution of the endmembers and their abundances, as well as the mixing process. Moreover, a new model based on a low-dimensional parametrization is used to represent spatial and temporal endmember variability, significantly reducing the amount of variables to be estimated. We propose to formulate MTHU as a Bayesian inference problem. However, the solution to this problem does not have an analytical solution due to the nonlinearity and non-Gaussianity of the model. Thus, we propose a solution based on deep variational inference, in which the posterior distribution of the estimated abundances and endmembers is represented by using a combination of recurrent neural networks and a physically motivated model. The parameters of the model are learned using stochastic backpropagation. Experimental results show that the proposed method outperforms state of the art MTHU algorithms. ",
    "url": "https://arxiv.org/abs/2303.10566",
    "authors": [
      "Ricardo Augusto Borsoi",
      "Tales Imbiriba",
      "Pau Closas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10568",
    "title": "The non-monotonicity of growth rate of viscous fingers in heterogeneous  porous media",
    "abstract": "The paper presents a stochastic analysis of the growth rate of viscous fingers in miscible displacement in a heterogeneous porous medium. The statistical parameters characterizing the permeability distribution of a reservoir vary over a wide range. The formation of fingers is provided by the mixing of different-viscosity fluids -- water and polymer solution. The distribution functions of the growth rate of viscous fingers are numerically determined and visualized. Careful data processing reveals the non-monotonic nature of the dependence of the front end of the mixing zone on the correlation length of the permeability (describing the medium graininess) of the reservoir formation. It is demonstrated that an increase in graininess up to a certain value causes an expansion of the distribution shape and a shift of the distribution maximum to the region of higher velocities. In addition, an increase in the standard deviation of permeability leads to a slight change in the shape and characteristics of the density distribution of the growth rates of viscous fingers. The theoretical predictions within the framework of the transverse flow equilibrium approximation and the Koval model are contrasted with the numerically computed velocity distributions. ",
    "url": "https://arxiv.org/abs/2303.10568",
    "authors": [
      "I.A. Starkov",
      "D.A. Pavlov",
      "S.B. Tikhomirov",
      "F.L. Bakharev"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.10656",
    "title": "More From Less: Self-Supervised Knowledge Distillation for  Information-Sparse Histopathology Data",
    "abstract": "Medical imaging technologies are generating increasingly large amounts of high-quality, information-dense data. Despite the progress, practical use of advanced imaging technologies for research and diagnosis remains limited by cost and availability, so information-sparse data such as H\\&E stains are relied on in practice. The study of diseased tissue requires methods which can leverage these information-dense data to extract more value from routine, information-sparse data. Using self-supervised deep learning, we demonstrate that it is possible to distil knowledge during training from information-dense data into models which only require information-sparse data for inference. This improves downstream classification accuracy on information-sparse data, making it comparable with the fully-supervised baseline. We find substantial effects on the learned representations, and this training process identifies subtle features which otherwise go undetected. This approach enables the design of models which require only routine images, but contain insights from state-of-the-art data, allowing better use of the available resources. ",
    "url": "https://arxiv.org/abs/2303.10656",
    "authors": [
      "Lucas Farndale",
      "Robert Insall",
      "Ke Yuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10683",
    "title": "Entanglement Distribution and Quantum Teleportation in Higher Dimension  over the Superposition of Causal Orders of Quantum Channels",
    "abstract": "Multiple photonic degrees of freedom can be explored to generate high-dimensional quantum states; commonly referred to as `qudits'. Qudits offer several advantages for quantum communications, including higher information capacity, noise resilience and data throughput, and lower information loss over different propagation mediums (free space, optical fibre, underwater) as compared to conventional qubits based communication system. However, qudits have been little exploited in literature, owing to their difficulty in transmission and detection. In this paper, for the first time, we develop and formulate the theoretical framework for transmission of classical information through entanglement distribution of qudits over two quantum channels in superposition of alternative causal order. For the first time we i) engineer quantum switch operation for 2-qudit systems and ii) formulate theoretical system model for entanglement distribution of qudits via quantum switch. Results show that entanglement distribution of a qudit provides a considerable gain in fidelity even with increase in noise. ",
    "url": "https://arxiv.org/abs/2303.10683",
    "authors": [
      "Indrakshi Dey",
      "Nicola Marchetti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.10706",
    "title": "Intersecting balls induced by a geometric graph II",
    "abstract": "For a graph whose vertices are points in $\\mathbb R^d$, consider the closed balls with diameters induced by its edges. The graph is called a Tverberg graph if these closed balls intersect. A max-sum tree of a finite point set $X \\subset \\mathbb R^d$ is a tree with vertex set $X$ that maximizes the sum of Euclidean distances of its edges among all trees with vertex set $X$. Similarly, a max-sum matching of an even set $X \\subset \\mathbb R^d$ is a perfect matching of $X$ maximizing the sum of Euclidean distances between the matched points among all perfect matchings of $X$. We prove that a max-sum tree of any finite point set in $\\mathbb R^d$ is a Tverberg graph, which generalizes a recent result of Abu-Affash et al., who established this claim in the plane. Additionally, we provide a new proof of a theorem by Bereg et al., which states that a max-sum matching of any even point set in the plane is a Tverberg graph. Moreover, we proved a slightly stronger version of this theorem. ",
    "url": "https://arxiv.org/abs/2303.10706",
    "authors": [
      "Polina Barabanshchikova",
      "Alexandr Polyanskii"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Metric Geometry (math.MG)"
    ]
  },
  {
    "id": "arXiv:2303.10738",
    "title": "MIA-3DCNN: COVID-19 Detection Based on a 3D CNN",
    "abstract": "Early and accurate diagnosis of COVID-19 is essential to control the rapid spread of the pandemic and mitigate sequelae in the population. Current diagnostic methods, such as RT-PCR, are effective but require time to provide results and can quickly overwhelm clinics, requiring individual laboratory analysis. Automatic detection methods have the potential to significantly reduce diagnostic time. To this end, learning-based methods using lung imaging have been explored. Although they require specialized hardware, automatic evaluation methods can be performed simultaneously, making diagnosis faster. Convolutional neural networks have been widely used to detect pneumonia caused by COVID-19 in lung images. This work describes an architecture based on 3D convolutional neural networks for detecting COVID-19 in computed tomography images. Despite the challenging scenario present in the dataset, the results obtained with our architecture demonstrated to be quite promising. ",
    "url": "https://arxiv.org/abs/2303.10738",
    "authors": [
      "Igor Kenzo Ishikawa Oshiro Nakashima",
      "Giovanna Vendramini",
      "Helio Pedrini"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10752",
    "title": "Fully Self-Supervised Depth Estimation from Defocus Clue",
    "abstract": "Depth-from-defocus (DFD), modeling the relationship between depth and defocus pattern in images, has demonstrated promising performance in depth estimation. Recently, several self-supervised works try to overcome the difficulties in acquiring accurate depth ground-truth. However, they depend on the all-in-focus (AIF) images, which cannot be captured in real-world scenarios. Such limitation discourages the applications of DFD methods. To tackle this issue, we propose a completely self-supervised framework that estimates depth purely from a sparse focal stack. We show that our framework circumvents the needs for the depth and AIF image ground-truth, and receives superior predictions, thus closing the gap between the theoretical success of DFD works and their applications in the real world. In particular, we propose (i) a more realistic setting for DFD tasks, where no depth or AIF image ground-truth is available; (ii) a novel self-supervision framework that provides reliable predictions of depth and AIF image under the challenging setting. The proposed framework uses a neural model to predict the depth and AIF image, and utilizes an optical model to validate and refine the prediction. We verify our framework on three benchmark datasets with rendered focal stacks and real focal stacks. Qualitative and quantitative evaluations show that our method provides a strong baseline for self-supervised DFD tasks. ",
    "url": "https://arxiv.org/abs/2303.10752",
    "authors": [
      "Haozhe Si",
      "Bin Zhao",
      "Dong Wang",
      "Yupeng Gao",
      "Mulin Chen",
      "Zhigang Wang",
      "Xuelong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10806",
    "title": "On Robustness of Double Linear Policy with Time-Varying Weights",
    "abstract": "In this paper, we extend the existing double linear policy by incorporating time-varying weights instead of constant weights and study a certain robustness property, called robust positive expectation (RPE), in a discrete-time setting. We prove that the RPE property holds by employing a novel elementary symmetric polynomials characterization approach and derive an explicit expression for both the expected cumulative gain-loss function and its variance. To validate our theory, we perform extensive Monte Carlo simulations using various weighting functions. Furthermore, we demonstrate how this policy can be effectively incorporated with standard technical analysis techniques, using the moving average as a trading signal. ",
    "url": "https://arxiv.org/abs/2303.10806",
    "authors": [
      "Xin-Yu Wang",
      "Chung-Han Hsieh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2303.10931",
    "title": "Approaching an unknown communication system by latent space exploration  and causal inference",
    "abstract": "This paper proposes a methodology for discovering meaningful properties in data by exploring the latent space of unsupervised deep generative models. We combine manipulation of individual latent variables to extreme values outside the training range with methods inspired by causal inference into an approach we call causal disentanglement with extreme values (CDEV) and show that this approach yields insights for model interpretability. Using this technique, we can infer what properties of unknown data the model encodes as meaningful. We apply the methodology to test what is meaningful in the communication system of sperm whales, one of the most intriguing and understudied animal communication systems. We train a network that has been shown to learn meaningful representations of speech and test whether we can leverage such unsupervised learning to decipher the properties of another vocal communication system for which we have no ground truth. The proposed technique suggests that sperm whales encode information using the number of clicks in a sequence, the regularity of their timing, and audio properties such as the spectral mean and the acoustic regularity of the sequences. Some of these findings are consistent with existing hypotheses, while others are proposed for the first time. We also argue that our models uncover rules that govern the structure of communication units in the sperm whale communication system and apply them while generating innovative data not shown during training. This paper suggests that an interpretation of the outputs of deep neural networks with causal methodology can be a viable strategy for approaching data about which little is known and presents another case of how deep learning can limit the hypothesis space. Finally, the proposed approach combining latent space manipulation and causal inference can be extended to other architectures and arbitrary datasets. ",
    "url": "https://arxiv.org/abs/2303.10931",
    "authors": [
      "Ga\u0161per Begu\u0161",
      "Andrej Leban",
      "Shane Gero"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.10934",
    "title": "EMC2-Net: Joint Equalization and Modulation Classification based on  Constellation Network",
    "abstract": "Modulation classification (MC) is the first step performed at the receiver side unless the modulation type is explicitly indicated by the transmitter. Machine learning techniques have been widely used for MC recently. In this paper, we propose a novel MC technique dubbed as Joint Equalization and Modulation Classification based on Constellation Network (EMC2-Net). Unlike prior works that considered the constellation points as an image, the proposed EMC2-Net directly uses a set of 2D constellation points to perform MC. In order to obtain clear and concrete constellation despite multipath fading channels, the proposed EMC2-Net consists of equalizer and classifier having separate and explainable roles via novel three-phase training and noise-curriculum pretraining. Numerical results with linear modulation types under different channel models show that the proposed EMC2-Net achieves the performance of state-of-the-art MC techniques with significantly less complexity. ",
    "url": "https://arxiv.org/abs/2303.10934",
    "authors": [
      "Hyun Ryu",
      "Junil Choi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11060",
    "title": "Quantile and moment neural networks for learning functionals of  distributions",
    "abstract": "We study news neural networks to approximate function of distributions in a probability space. Two classes of neural networks based on quantile and moment approximation are proposed to learn these functions and are theoretically supported by universal approximation theorems. By mixing the quantile and moment features in other new networks, we develop schemes that outperform existing networks on numerical test cases involving univariate distributions. For bivariate distributions, the moment neural network outperforms all other networks. ",
    "url": "https://arxiv.org/abs/2303.11060",
    "authors": [
      "Xavier Warin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11138",
    "title": "Fault Detection via Occupation Kernel Principal Component Analysis",
    "abstract": "The reliable operation of automatic systems is heavily dependent on the ability to detect faults in the underlying dynamical system. While traditional model-based methods have been widely used for fault detection, data-driven approaches have garnered increasing attention due to their ease of deployment and minimal need for expert knowledge. In this paper, we present a novel principal component analysis (PCA) method that uses occupation kernels. Occupation kernels result in feature maps that are tailored to the measured data, have inherent noise-robustness due to the use of integration, and can utilize irregularly sampled system trajectories of variable lengths for PCA. The occupation kernel PCA method is used to develop a reconstruction error approach to fault detection and its efficacy is validated using numerical simulations. ",
    "url": "https://arxiv.org/abs/2303.11138",
    "authors": [
      "Zachary Morrison",
      "Benjamin P. Russo",
      "Yingzhao Lian",
      "Rushikesh Kamalapurkar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11207",
    "title": "Investigating Topological Order using Recurrent Neural Networks",
    "abstract": "Recurrent neural networks (RNNs), originally developed for natural language processing, hold great promise for accurately describing strongly correlated quantum many-body systems. Here, we employ 2D RNNs to investigate two prototypical quantum many-body Hamiltonians exhibiting topological order. Specifically, we demonstrate that RNN wave functions can effectively capture the topological order of the toric code and a Bose-Hubbard spin liquid on the kagome lattice by estimating their topological entanglement entropies. We also find that RNNs favor coherent superpositions of minimally-entangled states over minimally-entangled states themselves. Overall, our findings demonstrate that RNN wave functions constitute a powerful tool to study phases of matter beyond Landau's symmetry-breaking paradigm. ",
    "url": "https://arxiv.org/abs/2303.11207",
    "authors": [
      "Mohamed Hibat-Allah",
      "Roger G. Melko",
      "Juan Carrasquilla"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2303.11214",
    "title": "Accurate Detection of Mediastinal Lesions with nnDetection",
    "abstract": "The accurate detection of mediastinal lesions is one of the rarely explored medical object detection problems. In this work, we applied a modified version of the self-configuring method nnDetection to the Mediastinal Lesion Analysis (MELA) Challenge 2022. By incorporating automatically generated pseudo masks, training high capacity models with large patch sizes in a multi GPU setup and an adapted augmentation scheme to reduce localization errors caused by rotations, our method achieved an excellent FROC score of 0.9922 at IoU 0.10 and 0.9880 at IoU 0.3 in our cross-validation experiments. The submitted ensemble ranked third in the competition with a FROC score of 0.9897 on the MELA challenge leaderboard. ",
    "url": "https://arxiv.org/abs/2303.11214",
    "authors": [
      "Michael Baumgartner",
      "Peter M. Full",
      "Klaus H. Maier-Hein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11323",
    "title": "Tangent Bundle Convolutional Learning: from Manifolds to Cellular  Sheaves and Back",
    "abstract": "In this work we introduce a convolution operation over the tangent bundle of Riemann manifolds in terms of exponentials of the Connection Laplacian operator. We define tangent bundle filters and tangent bundle neural networks (TNNs) based on this convolution operation, which are novel continuous architectures operating on tangent bundle signals, i.e. vector fields over the manifolds. Tangent bundle filters admit a spectral representation that generalizes the ones of scalar manifold filters, graph filters and standard convolutional filters in continuous time. We then introduce a discretization procedure, both in the space and time domains, to make TNNs implementable, showing that their discrete counterpart is a novel principled variant of the very recently introduced sheaf neural networks. We formally prove that this discretized architecture converges to the underlying continuous TNN. Finally, we numerically evaluate the effectiveness of the proposed architecture on various learning tasks, both on synthetic and real data. ",
    "url": "https://arxiv.org/abs/2303.11323",
    "authors": [
      "Claudio Battiloro",
      "Zhiyang Wang",
      "Hans Riess",
      "Paolo Di Lorenzo",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2007.00691",
    "title": "Falsification-Based Robust Adversarial Reinforcement Learning",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2007.00691",
    "authors": [
      "Xiao Wang",
      "Saasha Nair",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2009.03884",
    "title": "Edge Selection in Bilinear Dynamical Networks",
    "abstract": " Comments: 8 pages, 7 figures, technical note ",
    "url": "https://arxiv.org/abs/2009.03884",
    "authors": [
      "Arthur Castello B. de Oliveira",
      "Milad Siami",
      "Eduardo D. Sontag"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2102.01800",
    "title": "Optimal Intervention in Economic Networks using Influence Maximization  Methods",
    "abstract": " Title: Optimal Intervention in Economic Networks using Influence Maximization  Methods ",
    "url": "https://arxiv.org/abs/2102.01800",
    "authors": [
      "Ariah Klages-Mundt",
      "Andreea Minca"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2106.05087",
    "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion  Attacks in Deep RL",
    "abstract": " Comments: In the 10th International Conference on Learning Representations (ICLR 2022) ",
    "url": "https://arxiv.org/abs/2106.05087",
    "authors": [
      "Yanchao Sun",
      "Ruijie Zheng",
      "Yongyuan Liang",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.03789",
    "title": "Knowledge Sheaves: A Sheaf-Theoretic Framework for Knowledge Graph  Embedding",
    "abstract": " Comments: AISTATS 2023 ",
    "url": "https://arxiv.org/abs/2110.03789",
    "authors": [
      "Thomas Gebhart",
      "Jakob Hansen",
      "Paul Schrater"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.04019",
    "title": "Multi-Fake Evolutionary Generative Adversarial Networks for Imbalance  Hyperspectral Image Classification",
    "abstract": " Title: Multi-Fake Evolutionary Generative Adversarial Networks for Imbalance  Hyperspectral Image Classification ",
    "url": "https://arxiv.org/abs/2111.04019",
    "authors": [
      "Tanmoy Dam",
      "Nidhi Swami",
      "Sreenatha G. Anavatti",
      "Hussein A. Abbass"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03073",
    "title": "Active Learning for Event Extraction with Memory-based Loss Prediction  Model",
    "abstract": " Title: Active Learning for Event Extraction with Memory-based Loss Prediction  Model ",
    "url": "https://arxiv.org/abs/2112.03073",
    "authors": [
      "Shirong Shen",
      "Zhen Li",
      "Guilin Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.14838",
    "title": "Analysis and Control of Input-Affine Dynamical Systems using  Infinite-Dimensional Robust Counterparts",
    "abstract": " Comments: 33 pages, 13 figures, 1 table ",
    "url": "https://arxiv.org/abs/2112.14838",
    "authors": [
      "Jared Miller",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.09548",
    "title": "Consistent 3D Hand Reconstruction in Video via self-supervised Learning",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2103.11703 ",
    "url": "https://arxiv.org/abs/2201.09548",
    "authors": [
      "Zhigang Tu",
      "Zhisheng Huang",
      "Yujin Chen",
      "Di Kang",
      "Linchao Bao",
      "Bisheng Yang",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02467",
    "title": "Group Testing with Correlation under Edge-Faulty Graphs",
    "abstract": " Title: Group Testing with Correlation under Edge-Faulty Graphs ",
    "url": "https://arxiv.org/abs/2202.02467",
    "authors": [
      "Hesam Nikpey",
      "Jungyeol Kim",
      "Xingran Chen",
      "Saswati Sarkar",
      "Shirin Saeedi Bidokhti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2202.02669",
    "title": "SRPCN: Structure Retrieval based Point Completion Network",
    "abstract": " Comments: I think the proposed method has some defects ",
    "url": "https://arxiv.org/abs/2202.02669",
    "authors": [
      "Kaiyi Zhang",
      "Ximing Yang",
      "Yuan Wu",
      "Cheng Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03104",
    "title": "SimGRACE: A Simple Framework for Graph Contrastive Learning without Data  Augmentation",
    "abstract": " Comments: Accepted by The Web Conference 2022 (WWW 2022) ",
    "url": "https://arxiv.org/abs/2202.03104",
    "authors": [
      "Jun Xia",
      "Lirong Wu",
      "Jintao Chen",
      "Bozhen Hu",
      "Stan Z.Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.03376",
    "title": "Message Passing Neural PDE Solvers",
    "abstract": " Comments: Published at ICLR 2022 (Spotlight paper), Github: this https URL ",
    "url": "https://arxiv.org/abs/2202.03376",
    "authors": [
      "Johannes Brandstetter",
      "Daniel Worrall",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.07728",
    "title": "Don't Lie to Me! Robust and Efficient Explainability with Verified  Perturbation Analysis",
    "abstract": " Title: Don't Lie to Me! Robust and Efficient Explainability with Verified  Perturbation Analysis ",
    "url": "https://arxiv.org/abs/2202.07728",
    "authors": [
      "Thomas Fel",
      "Melanie Ducoffe",
      "David Vigouroux",
      "Remi Cadene",
      "Mikael Capelle",
      "Claire Nicodeme",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.09791",
    "title": "Contextual Semantic Embeddings for Ontology Subsumption Prediction",
    "abstract": " Comments: Accepted by World Wide Web Journal ",
    "url": "https://arxiv.org/abs/2202.09791",
    "authors": [
      "Jiaoyan Chen",
      "Yuan He",
      "Yuxia Geng",
      "Ernesto Jimenez-Ruiz",
      "Hang Dong",
      "Ian Horrocks"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.08787",
    "title": "Exploring Variational Graph Auto-Encoders for Extract Class Refactoring  Recommendation",
    "abstract": " Title: Exploring Variational Graph Auto-Encoders for Extract Class Refactoring  Recommendation ",
    "url": "https://arxiv.org/abs/2203.08787",
    "authors": [
      "Pritom Saha Akash",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11852",
    "title": "Representation Bias in Data: A Survey on Identification and Resolution  Techniques",
    "abstract": " Comments: Just Accepted ACM Comput. Surv. (March 2023) ",
    "url": "https://arxiv.org/abs/2203.11852",
    "authors": [
      "Nima Shahbazi",
      "Yin Lin",
      "Abolfazl Asudeh",
      "H. V. Jagadish"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.14328",
    "title": "On the Neural Tangent Kernel Analysis of Randomly Pruned Neural Networks",
    "abstract": " Comments: Upload the AISTATS camera-ready version ",
    "url": "https://arxiv.org/abs/2203.14328",
    "authors": [
      "Hongru Yang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16861",
    "title": "On Reconfiguration Graphs of Independent Sets under Token Sliding",
    "abstract": " Comments: 17 pages, 12 figures, accepted to Graphs and Combinatorics ",
    "url": "https://arxiv.org/abs/2203.16861",
    "authors": [
      "David Avis",
      "Duc A. Hoang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.03316",
    "title": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "abstract": " Title: Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion ",
    "url": "https://arxiv.org/abs/2204.03316",
    "authors": [
      "HanQin Cai",
      "Jian-Feng Cai",
      "Juntao You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.03652",
    "title": "PlutoNet: An Efficient Polyp Segmentation Network with Modified Partial  Decoder and Decoder Consistency Training",
    "abstract": " Comments: 10 pages, 2 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2204.03652",
    "authors": [
      "Tugberk Erol",
      "Duygu Sarikaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.06601",
    "title": "Causal Confusion and Reward Misidentification in Preference-Based Reward  Learning",
    "abstract": " Comments: In the proceedings of the Eleventh International Conference on Learning Representations (ICLR 2023). this https URL ",
    "url": "https://arxiv.org/abs/2204.06601",
    "authors": [
      "Jeremy Tien",
      "Jerry Zhi-Yang He",
      "Zackory Erickson",
      "Anca D. Dragan",
      "Daniel S. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.13386",
    "title": "Self-supervised Contrastive Learning for Audio-Visual Action Recognition",
    "abstract": " Comments: 6 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2204.13386",
    "authors": [
      "Yang Liu",
      "Ying Tan",
      "Haoyuan Lan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11083",
    "title": "Deep Digging into the Generalization of Self-Supervised Monocular Depth  Estimation",
    "abstract": " Comments: Accepted to AAAI 2023 ",
    "url": "https://arxiv.org/abs/2205.11083",
    "authors": [
      "Jinwoo Bae",
      "Sungho Moon",
      "Sunghoon Im"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11346",
    "title": "Spatial Attention-based Implicit Neural Representation for Arbitrary  Reduction of MRI Slice Spacing",
    "abstract": " Title: Spatial Attention-based Implicit Neural Representation for Arbitrary  Reduction of MRI Slice Spacing ",
    "url": "https://arxiv.org/abs/2205.11346",
    "authors": [
      "Xin Wang",
      "Sheng Wang",
      "Honglin Xiong",
      "Kai Xuan",
      "Zixu Zhuang",
      "Mengjun Liu",
      "Zhenrong Shen",
      "Xiangyu Zhao",
      "Lichi Zhang",
      "Qian Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11765",
    "title": "Byzantine-Robust Federated Learning with Optimal Statistical Rates and  Privacy Guarantees",
    "abstract": " Title: Byzantine-Robust Federated Learning with Optimal Statistical Rates and  Privacy Guarantees ",
    "url": "https://arxiv.org/abs/2205.11765",
    "authors": [
      "Banghua Zhu",
      "Lun Wang",
      "Qi Pang",
      "Shuai Wang",
      "Jiantao Jiao",
      "Dawn Song",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11857",
    "title": "Comprehensive Privacy Analysis on Federated Recommender System against  Attribute Inference Attacks",
    "abstract": " Title: Comprehensive Privacy Analysis on Federated Recommender System against  Attribute Inference Attacks ",
    "url": "https://arxiv.org/abs/2205.11857",
    "authors": [
      "Shijie Zhang",
      "Wei Yuan",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.00792",
    "title": "Channel Codes for Relayless Networks with General Message Access  Structure",
    "abstract": " Comments: (v1) 26 pages, to submitted to IEEE ITW2023, (v2) 27 pages, Remark 1 and Lemma 9 in v1 is deleted, Lemma 7 in v2 is added, Eq. (13) and the proof of Lemma 7 in v1 (Eq. (14) and the proof of Lemma 8 in v2) are revised ",
    "url": "https://arxiv.org/abs/2206.00792",
    "authors": [
      "Jun Muramatsu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.01685",
    "title": "Toward a realistic model of speech processing in the brain with  self-supervised learning",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.01685",
    "authors": [
      "Juliette Millet",
      "Charlotte Caucheteux",
      "Pierre Orhan",
      "Yves Boubenec",
      "Alexandre Gramfort",
      "Ewan Dunbar",
      "Christophe Pallier",
      "Jean-Remi King"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.02670",
    "title": "Robust Adversarial Attacks Detection based on Explainable Deep  Reinforcement Learning For UAV Guidance and Planning",
    "abstract": " Comments: 13 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2206.02670",
    "authors": [
      "Thomas Hickling",
      "Nabil Aouf",
      "Phillippa Spencer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.11241",
    "title": "Concentration inequalities and optimal number of layers for stochastic  deep neural networks",
    "abstract": " Title: Concentration inequalities and optimal number of layers for stochastic  deep neural networks ",
    "url": "https://arxiv.org/abs/2206.11241",
    "authors": [
      "Michele Caprio",
      "Sayan Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.06606",
    "title": "Encoding, decoding, and causality between complex networks",
    "abstract": " Title: Encoding, decoding, and causality between complex networks ",
    "url": "https://arxiv.org/abs/2207.06606",
    "authors": [
      "Yang Tian",
      "Hedong Hou",
      "Guangzheng Xu",
      "Ziyang Zhang",
      "Pei Sun"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.08536",
    "title": "UniFusion: Unified Multi-view Fusion Transformer for Spatial-Temporal  Representation in Bird's-Eye-View",
    "abstract": " Title: UniFusion: Unified Multi-view Fusion Transformer for Spatial-Temporal  Representation in Bird's-Eye-View ",
    "url": "https://arxiv.org/abs/2207.08536",
    "authors": [
      "Zequn Qin",
      "Jingyu Chen",
      "Chao Chen",
      "Xiaozhi Chen",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.11983",
    "title": "Distributed Coordination of Charging Stations with Shared Energy Storage  in a Distribution Network",
    "abstract": " Comments: 17 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2207.11983",
    "authors": [
      "Dongxiang Yan",
      "Yue Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.12261",
    "title": "GraphCFC: A Directed Graph based Cross-modal Feature Complementation  Approach for Multimodal Conversational Emotion Recognition",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2207.12261",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.08780",
    "title": "GraVoS: Voxel Selection for 3D Point-Cloud Detection",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2208.08780",
    "authors": [
      "Oren Shrout",
      "Yizhak Ben-Shabat",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03416",
    "title": "Bispectral Neural Networks",
    "abstract": " Title: Bispectral Neural Networks ",
    "url": "https://arxiv.org/abs/2209.03416",
    "authors": [
      "Sophia Sanborn",
      "Christian Shewmake",
      "Bruno Olshausen",
      "Christopher Hillar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.08543",
    "title": "A Decoupled and Linear Framework for Global Outlier Rejection over  Planar Pose Graph",
    "abstract": " Comments: 7 pages, 4 figures. To appear in ICRA 2023 ",
    "url": "https://arxiv.org/abs/2209.08543",
    "authors": [
      "Tianyue Wu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.09419",
    "title": "Multi-armed Bandit Learning on a Graph",
    "abstract": " Title: Multi-armed Bandit Learning on a Graph ",
    "url": "https://arxiv.org/abs/2209.09419",
    "authors": [
      "Tianpeng Zhang",
      "Kasper Johansson",
      "Na Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.11929",
    "title": "Higher-Order error estimates for physics-informed neural networks  approximating the primitive equations",
    "abstract": " Comments: 30 pages ",
    "url": "https://arxiv.org/abs/2209.11929",
    "authors": [
      "Ruimeng Hu",
      "Quyuan Lin",
      "Alan Raydan",
      "Sui Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.00173",
    "title": "Predictive Inference with Feature Conformal Prediction",
    "abstract": " Comments: Published as a conference paper at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.00173",
    "authors": [
      "Jiaye Teng",
      "Chuan Wen",
      "Dinghuai Zhang",
      "Yoshua Bengio",
      "Yang Gao",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.04227",
    "title": "Dual-distribution discrepancy with self-supervised refinement for  anomaly detection in medical images",
    "abstract": " Comments: Accepted to Medical Image Analysis, 2023 ",
    "url": "https://arxiv.org/abs/2210.04227",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Xin Yang",
      "Yu Zhou",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07316",
    "title": "MTEB: Massive Text Embedding Benchmark",
    "abstract": " Comments: 24 pages, 14 tables, 6 figures ",
    "url": "https://arxiv.org/abs/2210.07316",
    "authors": [
      "Niklas Muennighoff",
      "Nouamane Tazi",
      "Lo\u00efc Magne",
      "Nils Reimers"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12035",
    "title": "BlanketGen - A synthetic blanket occlusion augmentation pipeline for  MoCap datasets",
    "abstract": " Comments: 4 pages, Code and further information to generate the dataset is available at: this https URL ",
    "url": "https://arxiv.org/abs/2210.12035",
    "authors": [
      "Jo\u00e3o Carmona",
      "Tam\u00e1s Kar\u00e1csony",
      "Jo\u00e3o Paulo Silva Cunha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15042",
    "title": "Privately Fine-Tuning Large Language Models with Differential Privacy",
    "abstract": " Comments: Publised at IEEE ICDM Workshop on Machine Learning for Cybersecurity (MLC) 2022 ",
    "url": "https://arxiv.org/abs/2210.15042",
    "authors": [
      "Rouzbeh Behnia",
      "Mohamamdreza Ebrahimi",
      "Jason Pacheco",
      "Balaji Padmanabhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.00288",
    "title": "Self-supervised Character-to-Character Distillation for Text Recognition",
    "abstract": " Title: Self-supervised Character-to-Character Distillation for Text Recognition ",
    "url": "https://arxiv.org/abs/2211.00288",
    "authors": [
      "Tongkun Guan",
      "Wei Shen",
      "Xue Yang",
      "Qi Feng",
      "Zekun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00692",
    "title": "Towards Better Out-of-Distribution Generalization of Neural Algorithmic  Reasoning Tasks",
    "abstract": " Comments: Transactions on Machine Learning Research (TMLR), 2023 ",
    "url": "https://arxiv.org/abs/2211.00692",
    "authors": [
      "Sadegh Mahdavi",
      "Kevin Swersky",
      "Thomas Kipf",
      "Milad Hashemi",
      "Christos Thrampoulidis",
      "Renjie Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00943",
    "title": "Adversarial Guitar Amplifier Modelling With Unpaired Data",
    "abstract": " Comments: Accepted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.00943",
    "authors": [
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Lauri Juvela"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.01646",
    "title": "Adversarial Data Augmentation Using VAE-GAN for Disordered Speech  Recognition",
    "abstract": " Comments: Submitted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.01646",
    "authors": [
      "Zengrui Jin",
      "Xurong Xie",
      "Mengzhe Geng",
      "Tianzi Wang",
      "Shujie Hu",
      "Jiajun Deng",
      "Guinan Li",
      "Xunying Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.01696",
    "title": "An Empirical Bayes Analysis of Object Trajectory Representation Models",
    "abstract": " Title: An Empirical Bayes Analysis of Object Trajectory Representation Models ",
    "url": "https://arxiv.org/abs/2211.01696",
    "authors": [
      "Yue Yao",
      "Daniel Goehring",
      "Joerg Reichardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.02642",
    "title": "A Meta-GNN approach to personalized seizure detection and classification",
    "abstract": " Title: A Meta-GNN approach to personalized seizure detection and classification ",
    "url": "https://arxiv.org/abs/2211.02642",
    "authors": [
      "Abdellah Rahmani",
      "Arun Venkitaraman",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.03295",
    "title": "Efficient Multi-order Gated Aggregation Network",
    "abstract": " Comments: Preprint V2 (15 pages + 10 pages), updating the models and more experiment results ",
    "url": "https://arxiv.org/abs/2211.03295",
    "authors": [
      "Siyuan Li",
      "Zedong Wang",
      "Zicheng Liu",
      "Cheng Tan",
      "Haitao Lin",
      "Di Wu",
      "Zhiyuan Chen",
      "Jiangbin Zheng",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.06841",
    "title": "Point-MA2E: Masked and Affine Transformed AutoEncoder for  Self-supervised Point Cloud Learning",
    "abstract": " Title: Point-MA2E: Masked and Affine Transformed AutoEncoder for  Self-supervised Point Cloud Learning ",
    "url": "https://arxiv.org/abs/2211.06841",
    "authors": [
      "Yabin Zhang",
      "Jiehong Lin",
      "Ruihuang Li",
      "Kui Jia",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.07866",
    "title": "Efficient Estimation for Longitudinal Network via Adaptive Merging",
    "abstract": " Comments: 26 pages and 2 figures; the appendix including technical proof will be uploaded later ",
    "url": "https://arxiv.org/abs/2211.07866",
    "authors": [
      "Haoran Zhang",
      "Junhui Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14305",
    "title": "SpaText: Spatio-Textual Representation for Controllable Image Generation",
    "abstract": " Comments: CVPR 2023. Project page available at: this https URL ",
    "url": "https://arxiv.org/abs/2211.14305",
    "authors": [
      "Omri Avrahami",
      "Thomas Hayes",
      "Oran Gafni",
      "Sonal Gupta",
      "Yaniv Taigman",
      "Devi Parikh",
      "Dani Lischinski",
      "Ohad Fried",
      "Xi Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15046",
    "title": "PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial  Networks for Radar-Based Precipitation Nowcasting",
    "abstract": " Title: PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial  Networks for Radar-Based Precipitation Nowcasting ",
    "url": "https://arxiv.org/abs/2211.15046",
    "authors": [
      "Jaeho Choi",
      "Yura Kim",
      "Kwang-Ho Kim",
      "Sung-Hwa Jung",
      "Ikhyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15444",
    "title": "DAMO-YOLO : A Report on Real-Time Object Detection Design",
    "abstract": " Title: DAMO-YOLO : A Report on Real-Time Object Detection Design ",
    "url": "https://arxiv.org/abs/2211.15444",
    "authors": [
      "Xianzhe Xu",
      "Yiqi Jiang",
      "Weihua Chen",
      "Yilun Huang",
      "Yuan Zhang",
      "Xiuyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16433",
    "title": "On Robust Observer Design for System Motion on SE(3) Using Onboard  Visual Sensors",
    "abstract": " Comments: We need to make more explore on this manuscript ",
    "url": "https://arxiv.org/abs/2211.16433",
    "authors": [
      "Tong Zhang",
      "Ying Tan",
      "Xiang Chen",
      "Zike Lei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.04646",
    "title": "DRIP: Domain Refinement Iteration with Polytopes for Backward  Reachability Analysis of Neural Feedback Loops",
    "abstract": " Title: DRIP: Domain Refinement Iteration with Polytopes for Backward  Reachability Analysis of Neural Feedback Loops ",
    "url": "https://arxiv.org/abs/2212.04646",
    "authors": [
      "Michael Everett",
      "Rudy Bunel",
      "Shayegan Omidshafiei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04689",
    "title": "Non-equispaced Fourier Neural Solvers for PDEs",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2212.04689",
    "authors": [
      "Haitao Lin",
      "Lirong Wu",
      "Yongjie Xu",
      "Yufei Huang",
      "Siyuan Li",
      "Guojiang Zhao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.08174",
    "title": "Non-IID Transfer Learning on Graphs",
    "abstract": " Comments: Accepted by AAAI-23 ",
    "url": "https://arxiv.org/abs/2212.08174",
    "authors": [
      "Jun Wu",
      "Jingrui He",
      "Elizabeth Ainsworth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09107",
    "title": "A Framework for Generalizing Critical Heat Flux Detection Models Using  Unsupervised Image-to-Image Translation",
    "abstract": " Comments: This work has been submitted to the Expert Systems With Applications Journal on Sep 25, 2022 ",
    "url": "https://arxiv.org/abs/2212.09107",
    "authors": [
      "Firas Al-Hindawi",
      "Tejaswi Soori",
      "Han Hu",
      "Md Mahfuzur Rahman Siddiquee",
      "Hyunsoo Yoon",
      "Teresa Wu",
      "Ying Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.11771",
    "title": "Few-shot human motion prediction for heterogeneous sensors",
    "abstract": " Title: Few-shot human motion prediction for heterogeneous sensors ",
    "url": "https://arxiv.org/abs/2212.11771",
    "authors": [
      "Rafael Rego Drumond",
      "Lukas Brinkmeyer",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01104",
    "title": "KoopmanLab: machine learning for solving complex physics equations",
    "abstract": " Title: KoopmanLab: machine learning for solving complex physics equations ",
    "url": "https://arxiv.org/abs/2301.01104",
    "authors": [
      "Wei Xiong",
      "Muyuan Ma",
      "Xiaomeng Huang",
      "Ziyang Zhang",
      "Pei Sun",
      "Yang Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2301.04631",
    "title": "Deep Residual Axial Networks",
    "abstract": " Title: Deep Residual Axial Networks ",
    "url": "https://arxiv.org/abs/2301.04631",
    "authors": [
      "Nazmul Shahadat",
      "Anthony S. Maida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.05871",
    "title": "Dyna-DepthFormer: Multi-frame Transformer for Self-Supervised Depth  Estimation in Dynamic Scenes",
    "abstract": " Comments: ICRA 2023 ",
    "url": "https://arxiv.org/abs/2301.05871",
    "authors": [
      "Songchun Zhang",
      "Chunhui Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.09489",
    "title": "Contracting Skeletal Kinematic Embeddings for Anomaly Detection",
    "abstract": " Comments: Submitted to Pattern Recognition Journal ",
    "url": "https://arxiv.org/abs/2301.09489",
    "authors": [
      "Alessandro Flaborea",
      "Guido D'Amely",
      "Stefano D'Arrigo",
      "Marco Aurelio Sterpa",
      "Alessio Sampieri",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.10862",
    "title": "Learning Gradients of Convex Functions with Monotone Gradient Networks",
    "abstract": " Comments: ICASSP 2023 Camera-Ready Version ",
    "url": "https://arxiv.org/abs/2301.10862",
    "authors": [
      "Shreyas Chaudhari",
      "Srinivasa Pranav",
      "Jos\u00e9 M. F. Moura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.10941",
    "title": "GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency",
    "abstract": " Title: GeCoNeRF: Few-shot Neural Radiance Fields via Geometric Consistency ",
    "url": "https://arxiv.org/abs/2301.10941",
    "authors": [
      "Minseop Kwak",
      "Jiuhn Song",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12457",
    "title": "EvoX: A Distributed GPU-accelerated Library towards Scalable  Evolutionary Computation",
    "abstract": " Title: EvoX: A Distributed GPU-accelerated Library towards Scalable  Evolutionary Computation ",
    "url": "https://arxiv.org/abs/2301.12457",
    "authors": [
      "Beichen Huang",
      "Ran Cheng",
      "Yaochu Jin",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.13428",
    "title": "Contrast and Clustering: Learning Neighborhood Pair Representation for  Source-free Domain Adaptation",
    "abstract": " Comments: Journal articles ",
    "url": "https://arxiv.org/abs/2301.13428",
    "authors": [
      "Yuqi Chen",
      "Xiangbin Zhu",
      "Yonggang Li",
      "Yingjian Li",
      "Haojie Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02013",
    "title": "IoT Botnet Detection Using an Economic Deep Learning Model",
    "abstract": " Comments: Under review in the IEEE/ACIS SERA 2023 conference ",
    "url": "https://arxiv.org/abs/2302.02013",
    "authors": [
      "Nelly Elsayed",
      "Zag ElSayed",
      "Magdy Bayoumi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06405",
    "title": "An Optical XNOR-Bitcount Based Accelerator for Efficient Inference of  Binary Neural Networks",
    "abstract": " Comments: To Appear at IEEE ISQED 2023 ",
    "url": "https://arxiv.org/abs/2302.06405",
    "authors": [
      "Sairam Sri Vatsavai",
      "Venkata Sai Praneeth Karempudi",
      "Ishan Thakkar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.07145",
    "title": "Practical Cross-System Shilling Attacks with Limited Access to Data",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2302.07145",
    "authors": [
      "Meifang Zeng",
      "Ke Li",
      "Bingchuan Jiang",
      "Liujuan Cao",
      "Hui Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.07419",
    "title": "Spatially heterogeneous learning by a deep student machine",
    "abstract": " Comments: 34 page, 18 figures (revised version with normalized squared overlaps) ",
    "url": "https://arxiv.org/abs/2302.07419",
    "authors": [
      "Hajime Yoshino"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.09330",
    "title": "Practical Flaky Test Prediction using Common Code Evolution and Test  History Data",
    "abstract": " Comments: 12 pages, to be published in the Proceedings of the IEEE International Conference on Software Testing, Verification and Validation (ICST 2023) ",
    "url": "https://arxiv.org/abs/2302.09330",
    "authors": [
      "Martin Gruber",
      "Michael Heine",
      "Norbert Oster",
      "Michael Philippsen",
      "Gordon Fraser"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.09465",
    "title": "Stochastic Generative Flow Networks",
    "abstract": " Title: Stochastic Generative Flow Networks ",
    "url": "https://arxiv.org/abs/2302.09465",
    "authors": [
      "Ling Pan",
      "Dinghuai Zhang",
      "Moksh Jain",
      "Longbo Huang",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10681",
    "title": "FrankenSplit: Saliency Guided Neural Feature Compression with Shallow  Variational Bottleneck Injection",
    "abstract": " Comments: 14 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2302.10681",
    "authors": [
      "Alireza Furutanpey",
      "Philipp Raith",
      "Schahram Dustdar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.13007",
    "title": "AugGPT: Leveraging ChatGPT for Text Data Augmentation",
    "abstract": " Title: AugGPT: Leveraging ChatGPT for Text Data Augmentation ",
    "url": "https://arxiv.org/abs/2302.13007",
    "authors": [
      "Haixing Dai",
      "Zhengliang Liu",
      "Wenxiong Liao",
      "Xiaoke Huang",
      "Yihan Cao",
      "Zihao Wu",
      "Lin Zhao",
      "Shaochen Xu",
      "Wei Liu",
      "Ninghao Liu",
      "Sheng Li",
      "Dajiang Zhu",
      "Hongmin Cai",
      "Lichao Sun",
      "Quanzheng Li",
      "Dinggang Shen",
      "Tianming Liu",
      "Xiang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.13519",
    "title": "CBA: Contextual Background Attack against Optical Aerial Detection in  the Physical World",
    "abstract": " Title: CBA: Contextual Background Attack against Optical Aerial Detection in  the Physical World ",
    "url": "https://arxiv.org/abs/2302.13519",
    "authors": [
      "Jiawei Lian",
      "Xiaofei Wang",
      "Yuru Su",
      "Mingyang Ma",
      "Shaohui Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.14146",
    "title": "Markov Conditions and Factorization in Logical Credal Networks",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2302.14146",
    "authors": [
      "Fabio Gagliardi Cozman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.00554",
    "title": "CausIL: Causal Graph for Instance Level Microservice Data",
    "abstract": " Comments: Accepted to the Proceedings of the ACM Web Conference 2023 (WWW '23) ",
    "url": "https://arxiv.org/abs/2303.00554",
    "authors": [
      "Sarthak Chakraborty",
      "Shaddy Garg",
      "Shubham Agarwal",
      "Ayush Chauhan",
      "Shiv Kumar Saini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.01242",
    "title": "Distributed Optimization in Sensor Network for Scalable Multi-Robot  Relative State Estimation",
    "abstract": " Title: Distributed Optimization in Sensor Network for Scalable Multi-Robot  Relative State Estimation ",
    "url": "https://arxiv.org/abs/2303.01242",
    "authors": [
      "Tianyue Wu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.01498",
    "title": "ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit  Detection & Emotional Reaction Intensity Estimation Challenges",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2202.10659 ",
    "url": "https://arxiv.org/abs/2303.01498",
    "authors": [
      "Dimitrios Kollias",
      "Panagiotis Tzirakis",
      "Alice Baird",
      "Alan Cowen",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02384",
    "title": "Hierarchical Training of Deep Neural Networks Using Early Exiting",
    "abstract": " Comments: 12 pages, 9 figures, 1 Table ",
    "url": "https://arxiv.org/abs/2303.02384",
    "authors": [
      "Yamin Sepehri",
      "Pedram Pad",
      "Ahmet Caner Y\u00fcz\u00fcg\u00fcler",
      "Pascal Frossard",
      "L. Andrea Dunbar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.02393",
    "title": "Seq-HyGAN: Sequence Classification via Hypergraph Attention Network",
    "abstract": " Title: Seq-HyGAN: Sequence Classification via Hypergraph Attention Network ",
    "url": "https://arxiv.org/abs/2303.02393",
    "authors": [
      "Khaled Mohammed Saifuddin",
      "Corey May",
      "Farhan Tanvir",
      "Muhammad Ifte Khairul Islam",
      "Esra Akbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.02725",
    "title": "Local Environment Poisoning Attacks on Federated Reinforcement Learning",
    "abstract": " Title: Local Environment Poisoning Attacks on Federated Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2303.02725",
    "authors": [
      "Evelyn Ma",
      "Tiancheng Qin",
      "Rasoul Etesami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.03202",
    "title": "Continuous Sign Language Recognition with Correlation Network",
    "abstract": " Comments: CVPR2023, Camera ready version. code: this https URL Made few modifications on explanations. arXiv admin note: text overlap with arXiv:2211.17081 ",
    "url": "https://arxiv.org/abs/2303.03202",
    "authors": [
      "Lianyu Hu",
      "Liqing Gao",
      "Zekang Liu",
      "Wei Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04414",
    "title": "Next-Generation URLLC with Massive Devices: A Unified Semi-Blind  Detection Framework for Sourced and Unsourced Random Access",
    "abstract": " Comments: This paper has been accepted by IEEE JSAC special issue on next-generation URLLC in 6G ",
    "url": "https://arxiv.org/abs/2303.04414",
    "authors": [
      "Malong Ke",
      "Zhen Gao",
      "Mingyu Zhou",
      "Dezhi Zheng",
      "Derrick Wing Kwan Ng",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.05367",
    "title": "Rethinking Range View Representation for LiDAR Segmentation",
    "abstract": " Comments: 22 pages, 10 figures, 14 tables, project page at this https URL ",
    "url": "https://arxiv.org/abs/2303.05367",
    "authors": [
      "Lingdong Kong",
      "Youquan Liu",
      "Runnan Chen",
      "Yuexin Ma",
      "Xinge Zhu",
      "Yikang Li",
      "Yuenan Hou",
      "Yu Qiao",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05499",
    "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set  Object Detection",
    "abstract": " Comments: Code will be available at this https URL ",
    "url": "https://arxiv.org/abs/2303.05499",
    "authors": [
      "Shilong Liu",
      "Zhaoyang Zeng",
      "Tianhe Ren",
      "Feng Li",
      "Hao Zhang",
      "Jie Yang",
      "Chunyuan Li",
      "Jianwei Yang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05639",
    "title": "Self-Supervised One-Shot Learning for Automatic Segmentation of StyleGAN  Images",
    "abstract": " Title: Self-Supervised One-Shot Learning for Automatic Segmentation of StyleGAN  Images ",
    "url": "https://arxiv.org/abs/2303.05639",
    "authors": [
      "Ankit Manerikar",
      "Avinash C. Kak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06152",
    "title": "Why is That a Good or Not a Good Frying Pan? -- Knowledge Representation  for Functions of Objects and Tools for Design Understanding, Improvement, and  Generation for Design Understanding, Improvement, and Generation",
    "abstract": " Comments: 11 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2303.06152",
    "authors": [
      "Seng-Beng Ho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06682",
    "title": "DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for  Hyperspectral Image Restoration",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2303.06682",
    "authors": [
      "Yuchun Miao",
      "Lefei Zhang",
      "Liangpei Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.06885",
    "title": "DR2: Diffusion-based Robust Degradation Remover for Blind Face  Restoration",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.06885",
    "authors": [
      "Zhixin Wang",
      "Xiaoyun Zhang",
      "Ziying Zhang",
      "Huangjie Zheng",
      "Mingyuan Zhou",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08131",
    "title": "A Simple Framework for Open-Vocabulary Segmentation and Detection",
    "abstract": " Comments: A Simple Framework for Open-Vocabulary Segmentation and Detection ",
    "url": "https://arxiv.org/abs/2303.08131",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Xueyan Zou",
      "Shilong Liu",
      "Chunyuan Li",
      "Jianfeng Gao",
      "Jianwei Yang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08416",
    "title": "Lung Nodule Segmentation and Low-Confidence Region Prediction with  Uncertainty-Aware Attention Mechanism",
    "abstract": " Comments: 10 pages, 10 figures. We have reported a preliminary version of this work in MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2303.08416",
    "authors": [
      "Han Yang",
      "Qiuli Wang",
      "Yue Zhang",
      "Zhulin An",
      "Chen Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08419",
    "title": "Multi Modal Facial Expression Recognition with Transformer-Based Fusion  Networks and Dynamic Sampling",
    "abstract": " Title: Multi Modal Facial Expression Recognition with Transformer-Based Fusion  Networks and Dynamic Sampling ",
    "url": "https://arxiv.org/abs/2303.08419",
    "authors": [
      "Jun-Hwa Kim",
      "Namho Kim",
      "Chee Sun Won"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08536",
    "title": "Watch or Listen: Robust Audio-Visual Speech Recognition with Visual  Corruption Modeling and Reliability Scoring",
    "abstract": " Comments: Accepted at CVPR 2023. Implementation available: this https URL ",
    "url": "https://arxiv.org/abs/2303.08536",
    "authors": [
      "Joanna Hong",
      "Minsu Kim",
      "Jeongsoo Choi",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.08545",
    "title": "Local Region Perception and Relationship Learning Combined with Feature  Fusion for Facial Action Unit Detection",
    "abstract": " Title: Local Region Perception and Relationship Learning Combined with Feature  Fusion for Facial Action Unit Detection ",
    "url": "https://arxiv.org/abs/2303.08545",
    "authors": [
      "Jun Yu",
      "Renda Li",
      "Zhongpeng Cai",
      "Gongpeng Zhao",
      "Guochen Xie",
      "Jichao Zhu",
      "Wangyuan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08730",
    "title": "DiffusionAD: Denoising Diffusion for Anomaly Detection",
    "abstract": " Comments: 12 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2303.08730",
    "authors": [
      "Hui Zhang",
      "Zheng Wang",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09030",
    "title": "Large Selective Kernel Network for Remote Sensing Object Detection",
    "abstract": " Comments: Preprint, under review ",
    "url": "https://arxiv.org/abs/2303.09030",
    "authors": [
      "Yuxuan Li",
      "Qibin Hou",
      "Zhaohui Zheng",
      "Ming-Ming Cheng",
      "Jian Yang",
      "Xiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09232",
    "title": "Generative Adversarial Network for Personalized Art Therapy in Melanoma  Disease Management",
    "abstract": " Title: Generative Adversarial Network for Personalized Art Therapy in Melanoma  Disease Management ",
    "url": "https://arxiv.org/abs/2303.09232",
    "authors": [
      "Lennart J\u00fctte",
      "Ning Wang",
      "Bernhard Roth"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09234",
    "title": "NAISR: A 3D Neural Additive Model for Interpretable Shape Representation",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2303.09234",
    "authors": [
      "Yining Jiao",
      "Carlton Zdanski",
      "Julia Kimbell",
      "Andrew Prince",
      "Cameron Worden",
      "Samuel Kirse",
      "Christopher Rutter",
      "Benjamin Shields",
      "William Dunn",
      "Jisan Mahmud",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09293",
    "title": "A transformer-based approach to video frame-level prediction in  Affective Behaviour Analysis In-the-wild",
    "abstract": " Comments: 3 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2303.09293",
    "authors": [
      "Dang-Khanh Nguyen",
      "Ngoc-Huynh Ho",
      "Sudarshan Pant",
      "Hyung-Jeong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.09440",
    "title": "Enhanced detection of the presence and severity of COVID-19 from CT  scans using lung segmentation",
    "abstract": " Comments: Added extra results. Edited the text ",
    "url": "https://arxiv.org/abs/2303.09440",
    "authors": [
      "Robert Turnbull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09789",
    "title": "Urban Regional Function Guided Traffic Flow Prediction",
    "abstract": " Comments: 15 pages, 8 figures.This work has been accepted by Information Sciences ",
    "url": "https://arxiv.org/abs/2303.09789",
    "authors": [
      "Kuo Wang",
      "Lingbo Liu",
      "Yang Liu",
      "Guanbin Li",
      "Fan Zhou",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09806",
    "title": "DexRepNet: Learning Dexterous Robotic Grasping Network with Geometric  and Spatial Hand-Object Representations",
    "abstract": " Comments: IROS2023(Under Review) ",
    "url": "https://arxiv.org/abs/2303.09806",
    "authors": [
      "Qingtao Liu",
      "Yu Cui",
      "Zhengnan Sun",
      "Haoming Li",
      "Gaofeng Li",
      "Lin Shao",
      "Jiming Chen",
      "Qi Ye"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.09807",
    "title": "TKN: Transformer-based Keypoint Prediction Network For Real-time Video  Prediction",
    "abstract": " Title: TKN: Transformer-based Keypoint Prediction Network For Real-time Video  Prediction ",
    "url": "https://arxiv.org/abs/2303.09807",
    "authors": [
      "Haoran Li",
      "Pengyuan Zhou",
      "Yihang Lin",
      "Yanbin Hao",
      "Haiyong Xie",
      "Yong Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09858",
    "title": "MedLocker: A Transferable Adversarial Watermarking for Preventing  Unauthorized Analysis of Medical Image Dataset",
    "abstract": " Title: MedLocker: A Transferable Adversarial Watermarking for Preventing  Unauthorized Analysis of Medical Image Dataset ",
    "url": "https://arxiv.org/abs/2303.09858",
    "authors": [
      "Bangzheng Pu",
      "Xingxing Wei",
      "Shiji Zhao",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.09863",
    "title": "Deep Nonparametric Estimation of Intrinsic Data Structures by Chart  Autoencoders: Generalization Error and Robustness",
    "abstract": " Title: Deep Nonparametric Estimation of Intrinsic Data Structures by Chart  Autoencoders: Generalization Error and Robustness ",
    "url": "https://arxiv.org/abs/2303.09863",
    "authors": [
      "Hao Liu",
      "Alex Havrilla",
      "Rongjie Lai",
      "Wenjing Liao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09917",
    "title": "Vision Transformer for Action Units Detection",
    "abstract": " Comments: Will be updated ",
    "url": "https://arxiv.org/abs/2303.09917",
    "authors": [
      "Tu Vu",
      "Van Thong Huynh",
      "Soo Hyung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]