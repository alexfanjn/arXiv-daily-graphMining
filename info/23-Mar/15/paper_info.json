[
  {
    "id": "arXiv:2303.07352",
    "title": "Sequential Spatial Network for Collision Avoidance in Autonomous Driving",
    "abstract": "Several autonomous driving strategies have been applied to autonomous vehicles, especially in the collision avoidance area. The purpose of collision avoidance is achieved by adjusting the trajectory of autonomous vehicles (AV) to avoid intersection or overlap with the trajectory of surrounding vehicles. A large number of sophisticated vision algorithms have been designed for target inspection, classification, and other tasks, such as ResNet, YOLO, etc., which have achieved excellent performance in vision tasks because of their ability to accurately and quickly capture regional features. However, due to the variability of different tasks, the above models achieve good performance in capturing small regions but are still insufficient in correlating the regional features of the input image with each other. In this paper, we aim to solve this problem and develop an algorithm that takes into account the advantages of CNN in capturing regional features while establishing feature correlation between regions using variants of attention. Finally, our model achieves better performance in the test set of L5Kit compared to the other vision models. The average number of collisions is 19.4 per 10000 frames of driving distance, which greatly improves the success rate of collision avoidance. ",
    "url": "https://arxiv.org/abs/2303.07352",
    "authors": [
      "Haichuan Li",
      "Liguo Zhou",
      "Zhenshan Bing",
      "Marzana Khatun",
      "Rolf Jung",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07354",
    "title": "MetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer  Adapters",
    "abstract": "State-sponsored trolls are the main actors of influence campaigns on social media and automatic troll detection is important to combat misinformation at scale. Existing troll detection models are developed based on training data for known campaigns (e.g.\\ the influence campaign by Russia's Internet Research Agency on the 2016 US Election), and they fall short when dealing with {\\em novel} campaigns with new targets. We propose MetaTroll, a text-based troll detection model based on the meta-learning framework that enables high portability and parameter-efficient adaptation to new campaigns using only a handful of labelled samples for few-shot transfer. We introduce \\textit{campaign-specific} transformer adapters to MetaTroll to ``memorise'' campaign-specific knowledge so as to tackle catastrophic forgetting, where a model ``forgets'' how to detect trolls from older campaigns due to continual adaptation. Our experiments demonstrate that MetaTroll substantially outperforms baselines and state-of-the-art few-shot text classification models. Lastly, we explore simple approaches to extend MetaTroll to multilingual and multimodal detection. Source code for MetaTroll is available at: https://github.com/ltian678/metatroll-code.git. ",
    "url": "https://arxiv.org/abs/2303.07354",
    "authors": [
      "Lin Tian",
      "Xiuzhen Zhang",
      "Jey Han Lau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.07397",
    "title": "Fast exploration and learning of latent graphs with aliased observations",
    "abstract": "Consider this scenario: an agent navigates a latent graph by performing actions that take it from one node to another. The chosen action determines the probability distribution over the next visited node. At each node, the agent receives an observation, but this observation is not unique, so it does not identify the node, making the problem aliased. The purpose of this work is to provide a policy that approximately maximizes exploration efficiency (i.e., how well the graph is recovered for a given exploration budget). In the unaliased case, we show improved performance w.r.t. state-of-the-art reinforcement learning baselines. For the aliased case we are not aware of suitable baselines and instead show faster recovery w.r.t. a random policy for a wide variety of topologies, and exponentially faster recovery than a random policy for challenging topologies. We dub the algorithm eFeX (from eFficient eXploration). ",
    "url": "https://arxiv.org/abs/2303.07397",
    "authors": [
      "Miguel Lazaro-Gredilla",
      "Ishan Deshpande",
      "Sivaramakrishnan Swaminathan",
      "Meet Dave",
      "Dileep George"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07401",
    "title": "Drawings of Complete Multipartite Graphs Up to Triangle Flips",
    "abstract": "For a drawing of a labeled graph, the rotation of a vertex or crossing is the cyclic order of its incident edges, represented by the labels of their other endpoints. The extended rotation system (ERS) of the drawing is the collection of the rotations of all vertices and crossings. A drawing is simple if each pair of edges has at most one common point. Gioan's Theorem states that for any two simple drawings of the complete graph $K_n$ with the same crossing edge pairs, one drawing can be transformed into the other by a sequence of triangle flips (a.k.a. Reidemeister moves of Type 3). This operation refers to the act of moving one edge of a triangular cell formed by three pairwise crossing edges over the opposite crossing of the cell, via a local transformation. We investigate to what extent Gioan-type theorems can be obtained for wider classes of graphs. A necessary (but in general not sufficient) condition for two drawings of a graph to be transformable into each other by a sequence of triangle flips is that they have the same ERS. As our main result, we show that for the large class of complete multipartite graphs, this necessary condition is in fact also sufficient. We present two different proofs of this result, one of which is shorter, while the other one yields a polynomial time algorithm for which the number of needed triangle flips for graphs on $n$ vertices is bounded by $O(n^{16})$. The latter proof uses a Carath\\'eodory-type theorem for simple drawings of complete multipartite graphs, which we believe to be of independent interest. Moreover, we show that our Gioan-type theorem for complete multipartite graphs is essentially tight in the sense that having the same ERS does not remain sufficient when removing or adding very few edges. ",
    "url": "https://arxiv.org/abs/2303.07401",
    "authors": [
      "Oswin Aichholzer",
      "Man-Kwun Chiu",
      "Hung P. Hoang",
      "Michael Hoffmann",
      "Jan Kyn\u010dl",
      "Yannic Maus",
      "Birgit Vogtenhuber",
      "Alexandra Weinberger"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.07402",
    "title": "Designing Deep Networks for Scene Recognition",
    "abstract": "Most deep learning backbones are evaluated on ImageNet. Using scenery images as an example, we conducted extensive experiments to demonstrate the widely accepted principles in network design may result in dramatic performance differences when the data is altered. Exploratory experiments are engaged to explain the underlining cause of the differences. Based on our observation, this paper presents a novel network design methodology: data-oriented network design. In other words, instead of designing universal backbones, the scheming of the networks should treat the characteristics of data as a crucial component. We further proposed a Deep-Narrow Network and Dilated Pooling module, which improved the scene recognition performance using less than half of the computational resources compared to the benchmark network architecture ResNets. The source code is publicly available on https://github.com/ZN-Qiao/Deep-Narrow-Network. ",
    "url": "https://arxiv.org/abs/2303.07402",
    "authors": [
      "Zhinan Qiao",
      "Xiaohui Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07418",
    "title": "FreeNeRF: Improving Few-shot Neural Rendering with Free Frequency  Regularization",
    "abstract": "Novel view synthesis with sparse inputs is a challenging problem for neural radiance fields (NeRF). Recent efforts alleviate this challenge by introducing external supervision, such as pre-trained models and extra depth signals, and by non-trivial patch-based rendering. In this paper, we present Frequency regularized NeRF (FreeNeRF), a surprisingly simple baseline that outperforms previous methods with minimal modifications to the plain NeRF. We analyze the key challenges in few-shot neural rendering and find that frequency plays an important role in NeRF's training. Based on the analysis, we propose two regularization terms. One is to regularize the frequency range of NeRF's inputs, while the other is to penalize the near-camera density fields. Both techniques are ``free lunches'' at no additional computational cost. We demonstrate that even with one line of code change, the original NeRF can achieve similar performance as other complicated methods in the few-shot setting. FreeNeRF achieves state-of-the-art performance across diverse datasets, including Blender, DTU, and LLFF. We hope this simple baseline will motivate a rethinking of the fundamental role of frequency in NeRF's training under the low-data regime and beyond. ",
    "url": "https://arxiv.org/abs/2303.07418",
    "authors": [
      "Jiawei Yang",
      "Marco Pavone",
      "Yue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07429",
    "title": "FAIR Begins at home: Implementing FAIR via the Community Data Driven  Insights",
    "abstract": "Arguments for the FAIR principles have mostly been based on appeals to values. However, the work of onboarding diverse researchers to make efficient and effective implementations of FAIR requires different appeals. In our recent effort to transform the institution into a FAIR University by 2025, here we report on the experiences of the Community of Data Driven Insights (CDDI). We describe these experiences from the perspectives of a data steward in social sciences and a data scientist, both of whom have been working in parallel to provide research data management and data science support to different research groups. We initially identified 5 challenges for FAIR implementation. These perspectives show the complex dimensions of FAIR implementation to researchers across disciplines in a single university. ",
    "url": "https://arxiv.org/abs/2303.07429",
    "authors": [
      "Carlos Utrilla Guerrero",
      "Maria Vivas Romero",
      "Marc Dolman",
      "Michel Dumontier"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.07432",
    "title": "End-to-end Deformable Attention Graph Neural Network for Single-view  Liver Mesh Reconstruction",
    "abstract": "Intensity modulated radiotherapy (IMRT) is one of the most common modalities for treating cancer patients. One of the biggest challenges is precise treatment delivery that accounts for varying motion patterns originating from free-breathing. Currently, image-guided solutions for IMRT is limited to 2D guidance due to the complexity of 3D tracking solutions. We propose a novel end-to-end attention graph neural network model that generates in real-time a triangular shape of the liver based on a reference segmentation obtained at the preoperative phase and a 2D MRI coronal slice taken during the treatment. Graph neural networks work directly with graph data and can capture hidden patterns in non-Euclidean domains. Furthermore, contrary to existing methods, it produces the shape entirely in a mesh structure and correctly infers mesh shape and position based on a surrogate image. We define two on-the-fly approaches to make the correspondence of liver mesh vertices with 2D images obtained during treatment. Furthermore, we introduce a novel task-specific identity loss to constrain the deformation of the liver in the graph neural network to limit phenomenons such as flying vertices or mesh holes. The proposed method achieves results with an average error of 3.06 +- 0.7 mm and Chamfer distance with L2 norm of 63.14 +- 27.28. ",
    "url": "https://arxiv.org/abs/2303.07432",
    "authors": [
      "Matej Gazda",
      "Peter Drotar",
      "Liset Vazquez Romaguera",
      "Samuel Kadoury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07437",
    "title": "Unsupervised Representation Learning in Partially Observable Atari Games",
    "abstract": "State representation learning aims to capture latent factors of an environment. Contrastive methods have performed better than generative models in previous state representation learning research. Although some researchers realize the connections between masked image modeling and contrastive representation learning, the effort is focused on using masks as an augmentation technique to represent the latent generative factors better. Partially observable environments in reinforcement learning have not yet been carefully studied using unsupervised state representation learning methods. In this article, we create an unsupervised state representation learning scheme for partially observable states. We conducted our experiment on a previous Atari 2600 framework designed to evaluate representation learning models. A contrastive method called Spatiotemporal DeepInfomax (ST-DIM) has shown state-of-the-art performance on this benchmark but remains inferior to its supervised counterpart. Our approach improves ST-DIM when the environment is not fully observable and achieves higher F1 scores and accuracy scores than the supervised learning counterpart. The mean accuracy score averaged over categories of our approach is ~66%, compared to ~38% of supervised learning. The mean F1 score is ~64% to ~33%. ",
    "url": "https://arxiv.org/abs/2303.07437",
    "authors": [
      "Li Meng",
      "Morten Goodwin",
      "Anis Yazidi",
      "Paal Engelstad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07444",
    "title": "Polynomial-Time Approximation Schemes for Independent Packing Problems  on Fractionally Tree-Independence-Number-Fragile Graphs",
    "abstract": "We investigate a relaxation of the notion of treewidth-fragility, namely tree-independence-number-fragility. In particular, we obtain polynomial-time approximation schemes for independent packing problems on fractionally tree-independence-number-fragile graph classes. Our approach unifies and extends several known polynomial-time approximation schemes on seemingly unrelated graph classes, such as classes of intersection graphs of fat objects in a fixed dimension or proper minor-closed classes. We also study the related notion of layered tree-independence number, a relaxation of layered treewidth. ",
    "url": "https://arxiv.org/abs/2303.07444",
    "authors": [
      "Esther Galby",
      "Andrea Munaro",
      "Shizhou Yang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.07452",
    "title": "Network Anomaly Detection Using Federated Learning",
    "abstract": "Due to the veracity and heterogeneity in network traffic, detecting anomalous events is challenging. The computational load on global servers is a significant challenge in terms of efficiency, accuracy, and scalability. Our primary motivation is to introduce a robust and scalable framework that enables efficient network anomaly detection. We address the issue of scalability and efficiency for network anomaly detection by leveraging federated learning, in which multiple participants train a global model jointly. Unlike centralized training architectures, federated learning does not require participants to upload their training data to the server, preventing attackers from exploiting the training data. Moreover, most prior works have focused on traditional centralized machine learning, making federated machine learning under-explored in network anomaly detection. Therefore, we propose a deep neural network framework that could work on low to mid-end devices detecting network anomalies while checking if a request from a specific IP address is malicious or not. Compared to multiple traditional centralized machine learning models, the deep neural federated model reduces training time overhead. The proposed method performs better than baseline machine learning techniques on the UNSW-NB15 data set as measured by experiments conducted with an accuracy of 97.21% and a faster computation time. ",
    "url": "https://arxiv.org/abs/2303.07452",
    "authors": [
      "William Marfo",
      "Deepak K. Tosh",
      "Shirley V. Moore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.07474",
    "title": "Can Adversarial Examples Be Parsed to Reveal Victim Model Information?",
    "abstract": "Numerous adversarial attack methods have been developed to generate imperceptible image perturbations that can cause erroneous predictions of state-of-the-art machine learning (ML) models, in particular, deep neural networks (DNNs). Despite intense research on adversarial attacks, little effort was made to uncover 'arcana' carried in adversarial attacks. In this work, we ask whether it is possible to infer data-agnostic victim model (VM) information (i.e., characteristics of the ML model or DNN used to generate adversarial attacks) from data-specific adversarial instances. We call this 'model parsing of adversarial attacks' - a task to uncover 'arcana' in terms of the concealed VM information in attacks. We approach model parsing via supervised learning, which correctly assigns classes of VM's model attributes (in terms of architecture type, kernel size, activation function, and weight sparsity) to an attack instance generated from this VM. We collect a dataset of adversarial attacks across 7 attack types generated from 135 victim models (configured by 5 architecture types, 3 kernel size setups, 3 activation function types, and 3 weight sparsity ratios). We show that a simple, supervised model parsing network (MPN) is able to infer VM attributes from unseen adversarial attacks if their attack settings are consistent with the training setting (i.e., in-distribution generalization assessment). We also provide extensive experiments to justify the feasibility of VM parsing from adversarial attacks, and the influence of training and evaluation factors in the parsing performance (e.g., generalization challenge raised in out-of-distribution evaluation). We further demonstrate how the proposed MPN can be used to uncover the source VM attributes from transfer attacks, and shed light on a potential connection between model parsing and attack transferability. ",
    "url": "https://arxiv.org/abs/2303.07474",
    "authors": [
      "Yuguang Yao",
      "Jiancheng Liu",
      "Yifan Gong",
      "Xiaoming Liu",
      "Yanzhi Wang",
      "Xue Lin",
      "Sijia Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07477",
    "title": "Efficient Self-supervised Continual Learning with Progressive  Task-correlated Layer Freezing",
    "abstract": "Inspired by the success of Self-supervised learning (SSL) in learning visual representations from unlabeled data, a few recent works have studied SSL in the context of continual learning (CL), where multiple tasks are learned sequentially, giving rise to a new paradigm, namely self-supervised continual learning (SSCL). It has been shown that the SSCL outperforms supervised continual learning (SCL) as the learned representations are more informative and robust to catastrophic forgetting. However, if not designed intelligently, the training complexity of SSCL may be prohibitively high due to the inherent training cost of SSL. In this work, by investigating the task correlations in SSCL setup first, we discover an interesting phenomenon that, with the SSL-learned background model, the intermediate features are highly correlated between tasks. Based on this new finding, we propose a new SSCL method with layer-wise freezing which progressively freezes partial layers with the highest correlation ratios for each task to improve training computation efficiency and memory efficiency. Extensive experiments across multiple datasets are performed, where our proposed method shows superior performance against the SoTA SSCL methods under various SSL frameworks. For example, compared to LUMP, our method achieves 12\\%/14\\%/12\\% GPU training time reduction, 23\\%/26\\%/24\\% memory reduction, 35\\%/34\\%/33\\% backward FLOPs reduction, and 1.31\\%/1.98\\%/1.21\\% forgetting reduction without accuracy degradation on three datasets, respectively. ",
    "url": "https://arxiv.org/abs/2303.07477",
    "authors": [
      "Li Yang",
      "Sen Lin",
      "Fan Zhang",
      "Junshan Zhang",
      "Deliang Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07484",
    "title": "Deep Learning Approach for Classifying the Aggressive Comments on Social  Media: Machine Translated Data Vs Real Life Data",
    "abstract": "Aggressive comments on social media negatively impact human life. Such offensive contents are responsible for depression and suicidal-related activities. Since online social networking is increasing day by day, the hate content is also increasing. Several investigations have been done on the domain of cyberbullying, cyberaggression, hate speech, etc. The majority of the inquiry has been done in the English language. Some languages (Hindi and Bangla) still lack proper investigations due to the lack of a dataset. This paper particularly worked on the Hindi, Bangla, and English datasets to detect aggressive comments and have shown a novel way of generating machine-translated data to resolve data unavailability issues. A fully machine-translated English dataset has been analyzed with the models such as the Long Short term memory model (LSTM), Bidirectional Long-short term memory model (BiLSTM), LSTM-Autoencoder, word2vec, Bidirectional Encoder Representations from Transformers (BERT), and generative pre-trained transformer (GPT-2) to make an observation on how the models perform on a machine-translated noisy dataset. We have compared the performance of using the noisy data with two more datasets such as raw data, which does not contain any noises, and semi-noisy data, which contains a certain amount of noisy data. We have classified both the raw and semi-noisy data using the aforementioned models. To evaluate the performance of the models, we have used evaluation metrics such as F1-score,accuracy, precision, and recall. We have achieved the highest accuracy on raw data using the gpt2 model, semi-noisy data using the BERT model, and fully machine-translated data using the BERT model. Since many languages do not have proper data availability, our approach will help researchers create machine-translated datasets for several analysis purposes. ",
    "url": "https://arxiv.org/abs/2303.07484",
    "authors": [
      "Mst Shapna Akter",
      "Hossain Shahriar",
      "Nova Ahmed",
      "Alfredo Cuzzocrea"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07510",
    "title": "Schr\u00f6dinger's Camera: First Steps Towards a Quantum-Based Privacy  Preserving Camera",
    "abstract": "Privacy-preserving vision must overcome the dual challenge of utility and privacy. Too much anonymity renders the images useless, but too little privacy does not protect sensitive data. We propose a novel design for privacy preservation, where the imagery is stored in quantum states. In the future, this will be enabled by quantum imaging cameras, and, currently, storing very low resolution imagery in quantum states is possible. Quantum state imagery has the advantage of being both private and non-private till the point of measurement. This occurs even when images are manipulated, since every quantum action is fully reversible. We propose a control algorithm, based on double deep Q-learning, to learn how to anonymize the image before measurement. After learning, the RL weights are fixed, and new attack neural networks are trained from scratch to break the system's privacy. Although all our results are in simulation, we demonstrate, with these first steps, that it is possible to control both privacy and utility in a quantum-based manner. ",
    "url": "https://arxiv.org/abs/2303.07510",
    "authors": [
      "Hannah Kirkland",
      "Sanjeev J. Koppal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2303.07520",
    "title": "Multi-class Skin Cancer Classification Architecture Based on Deep  Convolutional Neural Network",
    "abstract": "Skin cancer detection is challenging since different types of skin lesions share high similarities. This paper proposes a computer-based deep learning approach that will accurately identify different kinds of skin lesions. Deep learning approaches can detect skin cancer very accurately since the models learn each pixel of an image. Sometimes humans can get confused by the similarities of the skin lesions, which we can minimize by involving the machine. However, not all deep learning approaches can give better predictions. Some deep learning models have limitations, leading the model to a false-positive result. We have introduced several deep learning models to classify skin lesions to distinguish skin cancer from different types of skin lesions. Before classifying the skin lesions, data preprocessing and data augmentation methods are used. Finally, a Convolutional Neural Network (CNN) model and six transfer learning models such as Resnet-50, VGG-16, Densenet, Mobilenet, Inceptionv3, and Xception are applied to the publically available benchmark HAM10000 dataset to classify seven classes of skin lesions and to conduct a comparative analysis. The models will detect skin cancer by differentiating the cancerous cell from the non-cancerous ones. The models performance is measured using performance metrics such as precision, recall, f1 score, and accuracy. We receive accuracy of 90, 88, 88, 87, 82, and 77 percent for inceptionv3, Xception, Densenet, Mobilenet, Resnet, CNN, and VGG16, respectively. Furthermore, we develop five different stacking models such as inceptionv3-inceptionv3, Densenet-mobilenet, inceptionv3-Xception, Resnet50-Vgg16, and stack-six for classifying the skin lesions and found that the stacking models perform poorly. We achieve the highest accuracy of 78 percent among all the stacking models. ",
    "url": "https://arxiv.org/abs/2303.07520",
    "authors": [
      "Mst Shapna Akter",
      "Hossain Shahriar",
      "Sweta Sneha",
      "Alfredo Cuzzocrea"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07525",
    "title": "Automated Vulnerability Detection in Source Code Using Quantum Natural  Language Processing",
    "abstract": "One of the most important challenges in the field of software code audit is the presence of vulnerabilities in software source code. These flaws are highly likely ex-ploited and lead to system compromise, data leakage, or denial of ser-vice. C and C++ open source code are now available in order to create a large-scale, classical machine-learning and quantum machine-learning system for function-level vulnerability identification. We assembled a siz-able dataset of millions of open-source functions that point to poten-tial exploits. We created an efficient and scalable vulnerability detection method based on a deep neural network model Long Short Term Memory (LSTM), and quantum machine learning model Long Short Term Memory (QLSTM), that can learn features extracted from the source codes. The source code is first converted into a minimal intermediate representation to remove the pointless components and shorten the de-pendency. Therefore, We keep the semantic and syntactic information using state of the art word embedding algorithms such as Glove and fastText. The embedded vectors are subsequently fed into the classical and quantum convolutional neural networks to classify the possible vulnerabilities. To measure the performance, we used evaluation metrics such as F1 score, precision, re-call, accuracy, and total execution time. We made a comparison between the results derived from the classical LSTM and quantum LSTM using basic feature representation as well as semantic and syntactic represen-tation. We found that the QLSTM with semantic and syntactic features detects significantly accurate vulnerability and runs faster than its classical counterpart. ",
    "url": "https://arxiv.org/abs/2303.07525",
    "authors": [
      "Mst Shapna Akter",
      "Hossain Shahriar",
      "Zakirul Alam Bhuiya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07537",
    "title": "Fractional dynamics foster deep learning of COPD stage prediction",
    "abstract": "Chronic obstructive pulmonary disease (COPD) is one of the leading causes of death worldwide. Current COPD diagnosis (i.e., spirometry) could be unreliable because the test depends on an adequate effort from the tester and testee. Moreover, the early diagnosis of COPD is challenging. We address COPD detection by constructing two novel physiological signals datasets (4432 records from 54 patients in the WestRo COPD dataset and 13824 medical records from 534 patients in the WestRo Porti COPD dataset). The authors demonstrate their complex coupled fractal dynamical characteristics and perform a fractional-order dynamics deep learning analysis to diagnose COPD. The authors found that the fractional-order dynamical modeling can extract distinguishing signatures from the physiological signals across patients with all COPD stages from stage 0 (healthy) to stage 4 (very severe). They use the fractional signatures to develop and train a deep neural network that predicts COPD stages based on the input features (such as thorax breathing effort, respiratory rate, or oxygen saturation). The authors show that the fractional dynamic deep learning model (FDDLM) achieves a COPD prediction accuracy of 98.66% and can serve as a robust alternative to spirometry. The FDDLM also has high accuracy when validated on a dataset with different physiological signals. ",
    "url": "https://arxiv.org/abs/2303.07537",
    "authors": [
      "Chenzhong Yin",
      "Mihai Udrescu",
      "Gaurav Gupta",
      "Mingxi Cheng",
      "Andrei Lihu",
      "Lucretia Udrescu",
      "Paul Bogdan",
      "David M Mannino",
      "Stefan Mihaicuta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.07538",
    "title": "HiSSNet: Sound Event Detection and Speaker Identification via  Hierarchical Prototypical Networks for Low-Resource Headphones",
    "abstract": "Modern noise-cancelling headphones have significantly improved users' auditory experiences by removing unwanted background noise, but they can also block out sounds that matter to users. Machine learning (ML) models for sound event detection (SED) and speaker identification (SID) can enable headphones to selectively pass through important sounds; however, implementing these models for a user-centric experience presents several unique challenges. First, most people spend limited time customizing their headphones, so the sound detection should work reasonably well out of the box. Second, the models should be able to learn over time the specific sounds that are important to users based on their implicit and explicit interactions. Finally, such models should have a small memory footprint to run on low-power headphones with limited on-chip memory. In this paper, we propose addressing these challenges using HiSSNet (Hierarchical SED and SID Network). HiSSNet is an SEID (SED and SID) model that uses a hierarchical prototypical network to detect both general and specific sounds of interest and characterize both alarm-like and speech sounds. We show that HiSSNet outperforms an SEID model trained using non-hierarchical prototypical networks by 6.9 - 8.6 percent. When compared to state-of-the-art (SOTA) models trained specifically for SED or SID alone, HiSSNet achieves similar or better performance while reducing the memory footprint required to support multiple capabilities on-device. ",
    "url": "https://arxiv.org/abs/2303.07538",
    "authors": [
      "N Shashaank",
      "Berker Banar",
      "Mohammad Rasool Izadi",
      "Jeremy Kemmerer",
      "Shuo Zhang",
      "Chuan-Che",
      "Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.07540",
    "title": "Tensor-based Multimodal Learning for Prediction of Pulmonary Arterial  Wedge Pressure from Cardiac MRI",
    "abstract": "Heart failure is a serious and life-threatening condition that can lead to elevated pressure in the left ventricle. Pulmonary Arterial Wedge Pressure (PAWP) is an important surrogate marker indicating high pressure in the left ventricle. PAWP is determined by Right Heart Catheterization (RHC) but it is an invasive procedure. A non-invasive method is useful in quickly identifying high-risk patients from a large population. In this work, we develop a tensor learning-based pipeline for identifying PAWP from multimodal cardiac Magnetic Resonance Imaging (MRI). This pipeline extracts spatial and temporal features from high-dimensional scans. For quality control, we incorporate an epistemic uncertainty-based binning strategy to identify poor-quality training samples. To improve the performance, we learn complementary information by integrating features from multimodal data: cardiac MRI with short-axis and four-chamber views, and Electronic Health Records. The experimental analysis on a large cohort of $1346$ subjects who underwent the RHC procedure for PAWP estimation indicates that the proposed pipeline has a diagnostic value and can produce promising performance with significant improvement over the baseline in clinical practice (i.e., $\\Delta$AUC $=0.10$, $\\Delta$Accuracy $=0.06$, and $\\Delta$MCC $=0.39$). The decision curve analysis further confirms the clinical utility of our method. ",
    "url": "https://arxiv.org/abs/2303.07540",
    "authors": [
      "Prasun C. Tripathi",
      "Mohammod N. I. Suvon",
      "Lawrence Schobs",
      "Shuo Zhou",
      "Samer Alabed",
      "Andrew J. Swift",
      "Haiping Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.07541",
    "title": "Young Humans Make Change, Young Users Click: Creating Youth-Centered  Networked Social Movements",
    "abstract": "From the urbanists' perspective, the everyday experience of young people, as an underrepresented group in the design of public spaces, includes tactics they use to challenge the strategies which rule over urban spaces. In this regard, youth led social movements are a set of collective tactics which groups of young people use to resist power structures. Social informational streams have revolutionized the way youth organize and mobilize for social movements throughout the world, especially in urban areas. However, just like public spaces, these algorithm based platforms have been developed with a great power imbalance between the developers and users which results in the creation of non inclusive social informational streams for young activists. Social activism grows agency and confidence in youth which is critical to their development. This paper employs a youth centric lens, which is used in designing public spaces, for designing algorithmic spaces that can improve bottom up youth led movements. By reviewing the structure of these spaces and how young people interact with these structures in the different cultural contexts of Iran and the US, we propose a humanistic approach to designing social informational streams which can enhance youth activism. ",
    "url": "https://arxiv.org/abs/2303.07541",
    "authors": [
      "Mina Rezaei",
      "Patsy Eubanks Owens"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.07543",
    "title": "WDiscOOD: Out-of-Distribution Detection via Whitened Linear  Discriminative Analysis",
    "abstract": "Deep neural networks are susceptible to generating overconfident yet erroneous predictions when presented with data beyond known concepts. This challenge underscores the importance of detecting out-of-distribution (OOD) samples in the open world. In this work, we propose a novel feature-space OOD detection score that jointly reasons with both class-specific and class-agnostic information. Specifically, our approach utilizes Whitened Linear Discriminative Analysis to project features into two subspaces - the discriminative and residual subspaces - in which the ID classes are maximally separated and closely clustered, respectively. The OOD score is then determined by combining the deviation from the input data to the ID distribution in both subspaces. The efficacy of our method, named WDiscOOD, is verified on the large-scale ImageNet-1k benchmark, with six OOD datasets that covers a variety of distribution shifts. WDiscOOD demonstrates superior performance on deep classifiers with diverse backbone architectures, including CNN and vision transformer. Furthermore, we also show that our method can more effectively detect novel concepts in representation space trained with contrastive objectives, including supervised contrastive loss and multi-modality contrastive loss. ",
    "url": "https://arxiv.org/abs/2303.07543",
    "authors": [
      "Yiye Chen",
      "Yunzhi Lin",
      "Ruinian Xu",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07546",
    "title": "Constrained Adversarial Learning and its applicability to Automated  Software Testing: a systematic review",
    "abstract": "Every novel technology adds hidden vulnerabilities ready to be exploited by a growing number of cyber-attacks. Automated software testing can be a promising solution to quickly analyze thousands of lines of code by generating and slightly modifying function-specific testing data to encounter a multitude of vulnerabilities and attack vectors. This process draws similarities to the constrained adversarial examples generated by adversarial learning methods, so there could be significant benefits to the integration of these methods in automated testing tools. Therefore, this systematic review is focused on the current state-of-the-art of constrained data generation methods applied for adversarial learning and software testing, aiming to guide researchers and developers to enhance testing tools with adversarial learning methods and improve the resilience and robustness of their digital systems. The found constrained data generation applications for adversarial machine learning were systematized, and the advantages and limitations of approaches specific for software testing were thoroughly analyzed, identifying research gaps and opportunities to improve testing tools with adversarial attack methods. ",
    "url": "https://arxiv.org/abs/2303.07546",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Tiago Dias",
      "Tiago Fonseca",
      "Eva Maia",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07547",
    "title": "HazardNet: Road Debris Detection by Augmentation of Synthetic Models",
    "abstract": "We present an algorithm to detect unseen road debris using a small set of synthetic models. Early detection of road debris is critical for safe autonomous or assisted driving, yet the development of a robust road debris detection model has not been widely discussed. There are two main challenges to building a road debris detector: first, data collection of road debris is challenging since hazardous objects on the road are rare to encounter in real driving scenarios; second, the variability of road debris is broad, ranging from a very small brick to a large fallen tree. To overcome these challenges, we propose a novel approach to few-shot learning of road debris that uses semantic augmentation and domain randomization to augment real road images with synthetic models. We constrain the problem domain to uncommon objects on the road and allow the deep neural network, HazardNet, to learn the semantic meaning of road debris to eventually detect unseen road debris. Our results demonstrate that HazardNet is able to accurately detect real road debris when only trained on synthetic objects in augmented images. ",
    "url": "https://arxiv.org/abs/2303.07547",
    "authors": [
      "Tae Eun Choe",
      "Jane Wu",
      "Xiaolin Lin",
      "Karen Kwon",
      "Minwoo Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07555",
    "title": "Deep Masked Graph Matching for Correspondence Identification in  Collaborative Perception",
    "abstract": "Correspondence identification (CoID) is an essential component for collaborative perception in multi-robot systems, such as connected autonomous vehicles. The goal of CoID is to identify the correspondence of objects observed by multiple robots in their own field of view in order for robots to consistently refer to the same objects. CoID is challenging due to perceptual aliasing, object non-covisibility, and noisy sensing. In this paper, we introduce a novel deep masked graph matching approach to enable CoID and address the challenges. Our approach formulates CoID as a graph matching problem and we design a masked neural network to integrate the multimodal visual, spatial, and GPS information to perform CoID. In addition, we design a new technique to explicitly address object non-covisibility caused by occlusion and the vehicle's limited field of view. We evaluate our approach in a variety of street environments using a high-fidelity simulation that integrates the CARLA and SUMO simulators. The experimental results show that our approach outperforms the previous approaches and achieves state-of-the-art CoID performance in connected autonomous driving applications. Our work is available at: https://github.com/gaopeng5/DMGM.git. ",
    "url": "https://arxiv.org/abs/2303.07555",
    "authors": [
      "Peng Gao",
      "Qingzhao Zhu",
      "Hongsheng Lu",
      "Chuang Gan",
      "Hao Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07582",
    "title": "Calibrated Teacher for Sparsely Annotated Object Detection",
    "abstract": "Fully supervised object detection requires training images in which all instances are annotated. This is actually impractical due to the high labor and time costs and the unavoidable missing annotations. As a result, the incomplete annotation in each image could provide misleading supervision and harm the training. Recent works on sparsely annotated object detection alleviate this problem by generating pseudo labels for the missing annotations. Such a mechanism is sensitive to the threshold of the pseudo label score. However, the effective threshold is different in different training stages and among different object detectors. Therefore, the current methods with fixed thresholds have sub-optimal performance, and are difficult to be applied to other detectors. In order to resolve this obstacle, we propose a Calibrated Teacher, of which the confidence estimation of the prediction is well calibrated to match its real precision. In this way, different detectors in different training stages would share a similar distribution of the output confidence, so that multiple detectors could share the same fixed threshold and achieve better performance. Furthermore, we present a simple but effective Focal IoU Weight (FIoU) for the classification loss. FIoU aims at reducing the loss weight of false negative samples caused by the missing annotation, and thus works as the complement of the teacher-student paradigm. Extensive experiments show that our methods set new state-of-the-art under all different sparse settings in COCO. Code will be available at https://github.com/Whileherham/CalibratedTeacher. ",
    "url": "https://arxiv.org/abs/2303.07582",
    "authors": [
      "Haohan Wang",
      "Liang Liu",
      "Boshen Zhang",
      "Jiangning Zhang",
      "Wuhao Zhang",
      "Zhenye Gan",
      "Yabiao Wang",
      "Chengjie Wang",
      "Haoqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07584",
    "title": "An Adaptive Decision-Making Approach for Better Selection of a  Blockchain Platform for Health Insurance Frauds Detection with Smart  Contracts: Development and Performance Evaluation",
    "abstract": "Blockchain technology has piqued the interest of businesses of all types, while consistently improving and adapting to developers and business owners requirements. Therefore, several blockchain platforms have emerged, making it challenging to select a suitable one for a specific type of business. This paper presents a classification of over one hundred blockchain platforms. We develop smart contracts for detecting healthcare insurance frauds using two blockchain platforms selected based on our proposed decision-making map approach for the selection of the top two suitable platforms for healthcare insurance frauds detection application, followed by an evaluation of their performances. Our classification shows that the largest percentage of blockchain platforms could be used for all types of application domains, and the second biggest percentage is to develop financial services only, even though generic platforms can be used, while a small number is for developing in other specific application domains. Our decision-making map revealed that Hyperledger Fabric is the best blockchain platform for detecting healthcare insurance frauds. The performance evaluation of the top two selected platforms indicates that Fabric surpassed Neo in all metrics. ",
    "url": "https://arxiv.org/abs/2303.07584",
    "authors": [
      "Rima Kaafarani",
      "Leila Ismail",
      "Oussama Zahwe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.07589",
    "title": "Sequential three-way decisions with a single hidden layer feedforward  neural network",
    "abstract": "The three-way decisions strategy has been employed to construct network topology in a single hidden layer feedforward neural network (SFNN). However, this model has a general performance, and does not consider the process costs, since it has fixed threshold parameters. Inspired by the sequential three-way decisions (STWD), this paper proposes STWD with an SFNN (STWD-SFNN) to enhance the performance of networks on structured datasets. STWD-SFNN adopts multi-granularity levels to dynamically learn the number of hidden layer nodes from coarse to fine, and set the sequential threshold parameters. Specifically, at the coarse granular level, STWD-SFNN handles easy-to-classify instances by applying strict threshold conditions, and with the increasing number of hidden layer nodes at the fine granular level, STWD-SFNN focuses more on disposing of the difficult-to-classify instances by applying loose threshold conditions, thereby realizing the classification of instances. Moreover, STWD-SFNN considers and reports the process cost produced from each granular level. The experimental results verify that STWD-SFNN has a more compact network on structured datasets than other SFNN models, and has better generalization performance than the competitive models. All models and datasets can be downloaded from https://github.com/wuc567/Machine-learning/tree/main/STWD-SFNN. ",
    "url": "https://arxiv.org/abs/2303.07589",
    "authors": [
      "Youxi Wu",
      "Shuhui Cheng",
      "Yan Li",
      "Rongjie Lv",
      "Fan Min"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07593",
    "title": "Improving Java Deserialization Gadget Chain Mining via Overriding-Guided  Object Generation",
    "abstract": "Java (de)serialization is prone to causing security-critical vulnerabilities that attackers can invoke existing methods (gadgets) on the application's classpath to construct a gadget chain to perform malicious behaviors. Several techniques have been proposed to statically identify suspicious gadget chains and dynamically generate injection objects for fuzzing. However, due to their incomplete support for dynamic program features (e.g., Java runtime polymorphism) and ineffective injection object generation for fuzzing, the existing techniques are still far from satisfactory. In this paper, we first performed an empirical study to investigate the characteristics of Java deserialization vulnerabilities based on our manually collected 86 publicly known gadget chains. The empirical results show that 1) Java deserialization gadgets are usually exploited by abusing runtime polymorphism, which enables attackers to reuse serializable overridden methods; and 2) attackers usually invoke exploitable overridden methods (gadgets) via dynamic binding to generate injection objects for gadget chain construction. Based on our empirical findings, we propose a novel gadget chain mining approach, \\emph{GCMiner}, which captures both explicit and implicit method calls to identify more gadget chains, and adopts an overriding-guided object generation approach to generate valid injection objects for fuzzing. The evaluation results show that \\emph{GCMiner} significantly outperforms the state-of-the-art techniques, and discovers 56 unique gadget chains that cannot be identified by the baseline approaches. ",
    "url": "https://arxiv.org/abs/2303.07593",
    "authors": [
      "Sicong Cao",
      "Xiaobing Sun",
      "Xiaoxue Wu",
      "Lili Bo",
      "Bin Li",
      "Rongxin Wu",
      "Wei Liu",
      "Biao He",
      "Yu Ouyang",
      "Jiajia Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.07598",
    "title": "AdPE: Adversarial Positional Embeddings for Pretraining Vision  Transformers via MAE+",
    "abstract": "Unsupervised learning of vision transformers seeks to pretrain an encoder via pretext tasks without labels. Among them is the Masked Image Modeling (MIM) aligned with pretraining of language transformers by predicting masked patches as a pretext task. A criterion in unsupervised pretraining is the pretext task needs to be sufficiently hard to prevent the transformer encoder from learning trivial low-level features not generalizable well to downstream tasks. For this purpose, we propose an Adversarial Positional Embedding (AdPE) approach -- It distorts the local visual structures by perturbing the position encodings so that the learned transformer cannot simply use the locally correlated patches to predict the missing ones. We hypothesize that it forces the transformer encoder to learn more discriminative features in a global context with stronger generalizability to downstream tasks. We will consider both absolute and relative positional encodings, where adversarial positions can be imposed both in the embedding mode and the coordinate mode. We will also present a new MAE+ baseline that brings the performance of the MIM pretraining to a new level with the AdPE. The experiments demonstrate that our approach can improve the fine-tuning accuracy of MAE by $0.8\\%$ and $0.4\\%$ over 1600 epochs of pretraining ViT-B and ViT-L on Imagenet1K. For the transfer learning task, it outperforms the MAE with the ViT-B backbone by $2.6\\%$ in mIoU on ADE20K, and by $3.2\\%$ in AP$^{bbox}$ and $1.6\\%$ in AP$^{mask}$ on COCO, respectively. These results are obtained with the AdPE being a pure MIM approach that does not use any extra models or external datasets for pretraining. The code is available at https://github.com/maple-research-lab/AdPE. ",
    "url": "https://arxiv.org/abs/2303.07598",
    "authors": [
      "Xiao Wang",
      "Ying Wang",
      "Ziwei Xuan",
      "Guo-Jun Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07609",
    "title": "Training Robust Spiking Neural Networks with ViewPoint Transform and  SpatioTemporal Stretching",
    "abstract": "Neuromorphic vision sensors (event cameras) simulate biological visual perception systems and have the advantages of high temporal resolution, less data redundancy, low power consumption, and large dynamic range. Since both events and spikes are modeled from neural signals, event cameras are inherently suitable for spiking neural networks (SNNs), which are considered promising models for artificial intelligence (AI) and theoretical neuroscience. However, the unconventional visual signals of these cameras pose a great challenge to the robustness of spiking neural networks. In this paper, we propose a novel data augmentation method, ViewPoint Transform and SpatioTemporal Stretching (VPT-STS). It improves the robustness of SNNs by transforming the rotation centers and angles in the spatiotemporal domain to generate samples from different viewpoints. Furthermore, we introduce the spatiotemporal stretching to avoid potential information loss in viewpoint transformation. Extensive experiments on prevailing neuromorphic datasets demonstrate that VPT-STS is broadly effective on multi-event representations and significantly outperforms pure spatial geometric transformations. Notably, the SNNs model with VPT-STS achieves a state-of-the-art accuracy of 84.4\\% on the DVS-CIFAR10 dataset. ",
    "url": "https://arxiv.org/abs/2303.07609",
    "authors": [
      "Haibo Shen",
      "Juyu Xiao",
      "Yihao Luo",
      "Xiang Cao",
      "Liangqi Zhang",
      "Tianjiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07626",
    "title": "CAT: Causal Audio Transformer for Audio Classification",
    "abstract": "The attention-based Transformers have been increasingly applied to audio classification because of their global receptive field and ability to handle long-term dependency. However, the existing frameworks which are mainly extended from the Vision Transformers are not perfectly compatible with audio signals. In this paper, we introduce a Causal Audio Transformer (CAT) consisting of a Multi-Resolution Multi-Feature (MRMF) feature extraction with an acoustic attention block for more optimized audio modeling. In addition, we propose a causal module that alleviates over-fitting, helps with knowledge transfer, and improves interpretability. CAT obtains higher or comparable state-of-the-art classification performance on ESC50, AudioSet and UrbanSound8K datasets, and can be easily generalized to other Transformer-based models. ",
    "url": "https://arxiv.org/abs/2303.07626",
    "authors": [
      "Xiaoyu Liu",
      "Hanlin Lu",
      "Jianbo Yuan",
      "Xinyu Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.07634",
    "title": "I$^2$-SDF: Intrinsic Indoor Scene Reconstruction and Editing via  Raytracing in Neural SDFs",
    "abstract": "In this work, we present I$^2$-SDF, a new method for intrinsic indoor scene reconstruction and editing using differentiable Monte Carlo raytracing on neural signed distance fields (SDFs). Our holistic neural SDF-based framework jointly recovers the underlying shapes, incident radiance and materials from multi-view images. We introduce a novel bubble loss for fine-grained small objects and error-guided adaptive sampling scheme to largely improve the reconstruction quality on large-scale indoor scenes. Further, we propose to decompose the neural radiance field into spatially-varying material of the scene as a neural field through surface-based, differentiable Monte Carlo raytracing and emitter semantic segmentations, which enables physically based and photorealistic scene relighting and editing applications. Through a number of qualitative and quantitative experiments, we demonstrate the superior quality of our method on indoor scene reconstruction, novel view synthesis, and scene editing compared to state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2303.07634",
    "authors": [
      "Jingsen Zhu",
      "Yuchi Huo",
      "Qi Ye",
      "Fujun Luan",
      "Jifan Li",
      "Dianbing Xi",
      "Lisha Wang",
      "Rui Tang",
      "Wei Hua",
      "Hujun Bao",
      "Rui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.07645",
    "title": "Finding a Maximum Clique in a Disk Graph",
    "abstract": "A disk graph is an intersection graph of disks in the Euclidean plane, where the disks correspond to the vertices of the graph and a pair of vertices are adjacent if and only if their corresponding disks intersect. The problem of determining the time complexity of computing a maximum clique in a disk graph is a long-standing open question. The problem is known to be open even when the radii of all the disks are in the interval $[1,(1+\\varepsilon)]$, where $\\varepsilon>0$. However, the maximum clique problem is known to be APX-hard for the intersection graphs of many other convex objects such as intersection graphs of ellipses, triangles, and a combination of unit disks and axis-parallel rectangles. Furthermore, there exists an $O(n^3\\log n)$-time algorithm to compute a maximum clique for unit disks. Here we obtain the following results. - We give an algorithm to compute a maximum clique in a unit disk graph in $O(n^{2.5}\\log n)$-time, which improves the previously best known running time of $O(n^3\\log n)$ [Eppstein '09]. - We extend a widely used `co-2-subdivision approach' to prove that computing a maximum clique in a combination of unit disks and axis-parallel rectangles is NP-hard to approximate within $4448/4449 \\approx 0.9997 $. The use of a `co-2-subdivision approach' was previously thought to be unlikely in this setting [Bonnet et al. '20]. Our result improves the previously known inapproximability factor of $7633010347/7633010348\\approx 0.9999$. - We show that the parameter minimum lens width of the disk arrangement may be used to make progress in the case when disk radii are in $[1,(1+\\varepsilon)]$. For example, if the minimum lens width is at least $0.265$ and $ \\varepsilon\\le 0.0001$, which still allows for non-Helly triples in the arrangement, then one can find a maximum clique in polynomial time. ",
    "url": "https://arxiv.org/abs/2303.07645",
    "authors": [
      "Jared Espenant",
      "J. Mark Keil",
      "Debajyoti Mondal"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2303.07648",
    "title": "SimFLE: Simple Facial Landmark Encoding for Self-Supervised Facial  Expression Recognition in the Wild",
    "abstract": "One of the key issues in facial expression recognition in the wild (FER-W) is that curating large-scale labeled facial images is challenging due to the inherent complexity and ambiguity of facial images. Therefore, in this paper, we propose a self-supervised simple facial landmark encoding (SimFLE) method that can learn effective encoding of facial landmarks, which are important features for improving the performance of FER-W, without expensive labels. Specifically, we introduce novel FaceMAE module for this purpose. FaceMAE reconstructs masked facial images with elaborately designed semantic masking. Unlike previous random masking, semantic masking is conducted based on channel information processed in the backbone, so rich semantics of channels can be explored. Additionally, the semantic masking process is fully trainable, enabling FaceMAE to guide the backbone to learn spatial details and contextual properties of fine-grained facial landmarks. Experimental results on several FER-W benchmarks prove that the proposed SimFLE is superior in facial landmark localization and noticeably improved performance compared to the supervised baseline and other self-supervised methods. ",
    "url": "https://arxiv.org/abs/2303.07648",
    "authors": [
      "Jiyong Moon",
      "Seongsik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07650",
    "title": "Cross-lingual Alzheimer's Disease detection based on paralinguistic and  pre-trained features",
    "abstract": "We present our submission to the ICASSP-SPGC-2023 ADReSS-M Challenge Task, which aims to investigate which acoustic features can be generalized and transferred across languages for Alzheimer's Disease (AD) prediction. The challenge consists of two tasks: one is to classify the speech of AD patients and healthy individuals, and the other is to infer Mini Mental State Examination (MMSE) score based on speech only. The difficulty is mainly embodied in the mismatch of the dataset, in which the training set is in English while the test set is in Greek. We extract paralinguistic features using openSmile toolkit and acoustic features using XLSR-53. In addition, we extract linguistic features after transcribing the speech into text. These features are used as indicators for AD detection in our method. Our method achieves an accuracy of 69.6% on the classification task and a root mean squared error (RMSE) of 4.788 on the regression task. The results show that our proposed method is expected to achieve automatic multilingual Alzheimer's Disease detection through spontaneous speech. ",
    "url": "https://arxiv.org/abs/2303.07650",
    "authors": [
      "Xuchu Chen",
      "Yu Pu",
      "Jinpeng Li",
      "Wei-Qiang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.07651",
    "title": "Context Normalization for Robust Image Classification",
    "abstract": "Normalization is a pre-processing step that converts the data into a more usable representation. As part of the deep neural networks (DNNs), the batch normalization (BN) technique uses normalization to address the problem of internal covariate shift. It can be packaged as general modules, which have been extensively integrated into various DNNs, to stabilize and accelerate training, presumably leading to improved generalization. However, the effect of BN is dependent on the mini-batch size and it does not take into account any groups or clusters that may exist in the dataset when estimating population statistics. This study proposes a new normalization technique, called context normalization, for image data. This approach adjusts the scaling of features based on the characteristics of each sample, which improves the model's convergence speed and performance by adapting the data values to the context of the target task. The effectiveness of context normalization is demonstrated on various datasets, and its performance is compared to other standard normalization techniques. ",
    "url": "https://arxiv.org/abs/2303.07651",
    "authors": [
      "Bilal Faye",
      "Mohamed-Djallel Dilmi",
      "Hanane Azzag",
      "Mustapha Lebbah",
      "Fangchen Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07653",
    "title": "NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from  Multi-view Images",
    "abstract": "We study the problem of reconstructing 3D feature curves of an object from a set of calibrated multi-view images. To do so, we learn a neural implicit field representing the density distribution of 3D edges which we refer to as Neural Edge Field (NEF). Inspired by NeRF, NEF is optimized with a view-based rendering loss where a 2D edge map is rendered at a given view and is compared to the ground-truth edge map extracted from the image of that view. The rendering-based differentiable optimization of NEF fully exploits 2D edge detection, without needing a supervision of 3D edges, a 3D geometric operator or cross-view edge correspondence. Several technical designs are devised to ensure learning a range-limited and view-independent NEF for robust edge extraction. The final parametric 3D curves are extracted from NEF with an iterative optimization method. On our benchmark with synthetic data, we demonstrate that NEF outperforms existing state-of-the-art methods on all metrics. Project page: https://yunfan1202.github.io/NEF/. ",
    "url": "https://arxiv.org/abs/2303.07653",
    "authors": [
      "Yunfan Ye",
      "Renjiao Yi",
      "Zhirui Gao",
      "Chenyang Zhu",
      "Zhiping Cai",
      "Kai Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07655",
    "title": "Simultaneous Action Recognition and Human Whole-Body Motion and Dynamics  Prediction from Wearable Sensors",
    "abstract": "This paper presents a novel approach to solve simultaneously the problems of human activity recognition and whole-body motion and dynamics prediction for real-time applications. Starting from the dynamics of human motion and motor system theory, the notion of mixture of experts from deep learning has been extended to address this problem. In the proposed approach, experts are modelled as a sequence-to-sequence recurrent neural networks (RNN) architecture. Experiments show the results of 66-DoF real-world human motion prediction and action recognition during different tasks like walking and rotating. The code associated with this paper is available at: \\url{github.com/ami-iit/paper_darvish_2022_humanoids_action-kindyn-predicition} ",
    "url": "https://arxiv.org/abs/2303.07655",
    "authors": [
      "Kourosh Darvish",
      "Serena Ivaldi",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07657",
    "title": "Code Will Tell: Visual Identification of Ponzi Schemes on Ethereum",
    "abstract": "Ethereum has become a popular blockchain with smart contracts for investors nowadays. Due to the decentralization and anonymity of Ethereum, Ponzi schemes have been easily deployed and caused significant losses to investors. However, there are still no explainable and effective methods to help investors easily identify Ponzi schemes and validate whether a smart contract is actually a Ponzi scheme. To fill the research gap, we propose PonziLens, a novel visualization approach to help investors achieve early identification of Ponzi schemes by investigating the operation codes of smart contracts. Specifically, we conduct symbolic execution of opcode and extract the control flow for investing and rewarding with critical opcode instructions. Then, an intuitive directed-graph based visualization is proposed to display the investing and rewarding flows and the crucial execution paths, enabling easy identification of Ponzi schemes on Ethereum. Two usage scenarios involving both Ponzi and non-Ponzi schemes demonstrate the effectiveness of PonziLens. ",
    "url": "https://arxiv.org/abs/2303.07657",
    "authors": [
      "Xiaolin Wen",
      "Kim Siang Yeo",
      "Yong Wang",
      "Ling Cheng",
      "Feida Zhu",
      "Min Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.07669",
    "title": "AutoTransfer: AutoML with Knowledge Transfer -- An Application to Graph  Neural Networks",
    "abstract": "AutoML has demonstrated remarkable success in finding an effective neural architecture for a given machine learning task defined by a specific dataset and an evaluation metric. However, most present AutoML techniques consider each task independently from scratch, which requires exploring many architectures, leading to high computational cost. Here we propose AutoTransfer, an AutoML solution that improves search efficiency by transferring the prior architectural design knowledge to the novel task of interest. Our key innovation includes a task-model bank that captures the model performance over a diverse set of GNN architectures and tasks, and a computationally efficient task embedding that can accurately measure the similarity among different tasks. Based on the task-model bank and the task embeddings, we estimate the design priors of desirable models of the novel task, by aggregating a similarity-weighted sum of the top-K design distributions on tasks that are similar to the task of interest. The computed design priors can be used with any AutoML search algorithm. We evaluate AutoTransfer on six datasets in the graph machine learning domain. Experiments demonstrate that (i) our proposed task embedding can be computed efficiently, and that tasks with similar embeddings have similar best-performing architectures; (ii) AutoTransfer significantly improves search efficiency with the transferred design priors, reducing the number of explored architectures by an order of magnitude. Finally, we release GNN-Bank-101, a large-scale dataset of detailed GNN training information of 120,000 task-model combinations to facilitate and inspire future research. ",
    "url": "https://arxiv.org/abs/2303.07669",
    "authors": [
      "Kaidi Cao",
      "Jiaxuan You",
      "Jiaju Liu",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07670",
    "title": "Co-Salient Object Detection with Co-Representation Purification",
    "abstract": "Co-salient object detection (Co-SOD) aims at discovering the common objects in a group of relevant images. Mining a co-representation is essential for locating co-salient objects. Unfortunately, the current Co-SOD method does not pay enough attention that the information not related to the co-salient object is included in the co-representation. Such irrelevant information in the co-representation interferes with its locating of co-salient objects. In this paper, we propose a Co-Representation Purification (CoRP) method aiming at searching noise-free co-representation. We search a few pixel-wise embeddings probably belonging to co-salient regions. These embeddings constitute our co-representation and guide our prediction. For obtaining purer co-representation, we use the prediction to iteratively reduce irrelevant embeddings in our co-representation. Experiments on three datasets demonstrate that our CoRP achieves state-of-the-art performances on the benchmark datasets. Our source code is available at https://github.com/ZZY816/CoRP. ",
    "url": "https://arxiv.org/abs/2303.07670",
    "authors": [
      "Ziyue Zhu",
      "Zhao Zhang",
      "Zheng Lin",
      "Xing Sun",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07685",
    "title": "FPTN: Fast Pure Transformer Network for Traffic Flow Forecasting",
    "abstract": "Traffic flow forecasting is challenging due to the intricate spatio-temporal correlations in traffic flow data. Existing Transformer-based methods usually treat traffic flow forecasting as multivariate time series (MTS) forecasting. However, too many sensors can cause a vector with a dimension greater than 800, which is difficult to process without information loss. In addition, these methods design complex mechanisms to capture spatial dependencies in MTS, resulting in slow forecasting speed. To solve the abovementioned problems, we propose a Fast Pure Transformer Network (FPTN) in this paper. First, the traffic flow data are divided into sequences along the sensor dimension instead of the time dimension. Then, to adequately represent complex spatio-temporal correlations, Three types of embeddings are proposed for projecting these vectors into a suitable vector space. After that, to capture the complex spatio-temporal correlations simultaneously in these vectors, we utilize Transformer encoder and stack it with several layers. Extensive experiments are conducted with 4 real-world datasets and 13 baselines, which demonstrate that FPTN outperforms the state-of-the-art on two metrics. Meanwhile, the computational time of FPTN spent is less than a quarter of other state-of-the-art Transformer-based models spent, and the requirements for computing resources are significantly reduced. ",
    "url": "https://arxiv.org/abs/2303.07685",
    "authors": [
      "Junhao Zhang",
      "Junjie Tang",
      "Juncheng Jin",
      "Zehui Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07702",
    "title": "Carbon-Neutralized Joint User Association and Base Station Switching for  Green Cellular Networks",
    "abstract": "Mitigating climate change and its impacts is one of the sustainable development goals (SDGs) required by United Nations for an urgent action. Increasing carbon emissions due to human activities is the root cause to climate change. Telecommunication networks that provide service connectivity to mobile users contribute great amount of carbon emissions by consuming lots of non-renewable energy sources. Beyond the improvement on energy efficiency, to reduce the carbon footprint, telecom operators are increasing their adoption of renewable energy (e.g., wind power). The high variability of renewable energy in time and location; however, creates difficulties for operators when utilizing renewables for the reduction of carbon emissions. In this paper, we consider a heterogeneous network consisted of one macro base station (MBS) and multiple small base stations (SBSs) where each base station (BS) is powered by both of renewable and non-renewable energy. Different from the prior works that target on the total power consumption, we propose a novel scheme to minimize the carbon footprint of networks by dynamically switching the ON/OFF modes of SBSs and adjusting the association between users and BSs to access renewables as much as possible. Our numerical analysis shows that the proposed scheme significantly reduces up to 86% of the nonrenewable energy consumption compared to two representative baselines. ",
    "url": "https://arxiv.org/abs/2303.07702",
    "authors": [
      "Chien-Sheng Yang",
      "Carlson Lin",
      "I-Kang Fu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.07722",
    "title": "Does Cyclomatic or Cognitive Complexity Better Represents Code  Understandability? An Empirical Investigation on the Developers Perception",
    "abstract": "Background. Code understandability is fundamental. Developers need to clearly understand the code they are modifying. A low understandability can increase the amount of coding effort and misinterpretation of code has impact on the entire development process. Ideally, developers should write clear and understandable code with the least possible effort. Objective. The goal of this work is to investigate if the McCabe Cyclomatic Complexity or the Cognitive Complexity can be a good predictor for the developers' perceived code understandability to understand which of the two complexities can be used as criteria to evaluate if a piece of code is understandable. Method. We designed and conducted an empirical study among 216 junior developers with professional experience ranging from one to four years. We asked them to manually inspect and rate the understandability of 12 Java classes that exhibit different levels of Cyclomatic and Cognitive Complexity. Results. Cognitive Complexity slightly outperforms the Cyclomatic Complexity to predict the developers' perceived understandability. Conclusion. The identification of a clear and validated measure for Code Complexity is still an open issue. Neither the old fashioned McCabe Cyclomatic Complexity and the most recent Cognitive Complexity are good predictors for code understandability, at least when considering the complexity perceived by junior developers. ",
    "url": "https://arxiv.org/abs/2303.07722",
    "authors": [
      "Valentina Lenarduzzi",
      "Terhi Kilamo",
      "Andrea Janes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.07735",
    "title": "Can neural networks do arithmetic? A survey on the elementary numerical  skills of state-of-the-art deep learning models",
    "abstract": "Creating learning models that can exhibit sophisticated reasoning skills is one of the greatest challenges in deep learning research, and mathematics is rapidly becoming one of the target domains for assessing scientific progress in this direction. In the past few years there has been an explosion of neural network architectures, data sets, and benchmarks specifically designed to tackle mathematical problems, reporting notable success in disparate fields such as automated theorem proving, numerical integration, and discovery of new conjectures or matrix multiplication algorithms. However, despite these impressive achievements it is still unclear whether deep learning models possess an elementary understanding of quantities and symbolic numbers. In this survey we critically examine the recent literature, concluding that even state-of-the-art architectures often fall short when probed with relatively simple tasks designed to test basic numerical and arithmetic knowledge. ",
    "url": "https://arxiv.org/abs/2303.07735",
    "authors": [
      "Alberto Testolin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07747",
    "title": "LoG-CAN: local-global Class-aware Network for semantic segmentation of  remote sensing images",
    "abstract": "Remote sensing images are known of having complex backgrounds, high intra-class variance and large variation of scales, which bring challenge to semantic segmentation. We present LoG-CAN, a multi-scale semantic segmentation network with a global class-aware (GCA) module and local class-aware (LCA) modules to remote sensing images. Specifically, the GCA module captures the global representations of class-wise context modeling to circumvent background interference; the LCA modules generate local class representations as intermediate aware elements, indirectly associating pixels with global class representations to reduce variance within a class; and a multi-scale architecture with GCA and LCA modules yields effective segmentation of objects at different scales via cascaded refinement and fusion of features. Through the evaluation on the ISPRS Vaihingen dataset and the ISPRS Potsdam dataset, experimental results indicate that LoG-CAN outperforms the state-of-the-art methods for general semantic segmentation, while significantly reducing network parameters and computation. Code is available at~\\href{https://github.com/xwmaxwma/rssegmentation}{https://github.com/xwmaxwma/rssegmentation}. ",
    "url": "https://arxiv.org/abs/2303.07747",
    "authors": [
      "Xiaowen Ma",
      "Mengting Ma",
      "Chenlu Hu",
      "Zhiyuan Song",
      "Ziyan Zhao",
      "Tian Feng",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07748",
    "title": "Generation-Guided Multi-Level Unified Network for Video Grounding",
    "abstract": "Video grounding aims to locate the timestamps best matching the query description within an untrimmed video. Prevalent methods can be divided into moment-level and clip-level frameworks. Moment-level approaches directly predict the probability of each transient moment to be the boundary in a global perspective, and they usually perform better in coarse grounding. On the other hand, clip-level ones aggregate the moments in different time windows into proposals and then deduce the most similar one, leading to its advantage in fine-grained grounding. In this paper, we propose a multi-level unified framework to enhance performance by leveraging the merits of both moment-level and clip-level methods. Moreover, a novel generation-guided paradigm in both levels is adopted. It introduces a multi-modal generator to produce the implicit boundary feature and clip feature, later regarded as queries to calculate the boundary scores by a discriminator. The generation-guided solution enhances video grounding from a two-unique-modals' match task to a cross-modal attention task, which steps out of the previous framework and obtains notable gains. The proposed Generation-guided Multi-level Unified network (GMU) surpasses previous methods and reaches State-Of-The-Art on various benchmarks with disparate features, e.g., Charades-STA, ActivityNet captions. ",
    "url": "https://arxiv.org/abs/2303.07748",
    "authors": [
      "Xing Cheng",
      "Xiangyu Wu",
      "Dong Shen",
      "Hezheng Lin",
      "Fan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.07758",
    "title": "Traffic4cast at NeurIPS 2022 -- Predict Dynamics along Graph Edges from  Sparse Node Data: Whole City Traffic and ETA from Stationary Vehicle  Detectors",
    "abstract": "The global trends of urbanization and increased personal mobility force us to rethink the way we live and use urban space. The Traffic4cast competition series tackles this problem in a data-driven way, advancing the latest methods in machine learning for modeling complex spatial systems over time. In this edition, our dynamic road graph data combine information from road maps, $10^{12}$ probe data points, and stationary vehicle detectors in three cities over the span of two years. While stationary vehicle detectors are the most accurate way to capture traffic volume, they are only available in few locations. Traffic4cast 2022 explores models that have the ability to generalize loosely related temporal vertex data on just a few nodes to predict dynamic future traffic states on the edges of the entire road graph. In the core challenge, participants are invited to predict the likelihoods of three congestion classes derived from the speed levels in the GPS data for the entire road graph in three cities 15 min into the future. We only provide vehicle count data from spatially sparse stationary vehicle detectors in these three cities as model input for this task. The data are aggregated in 15 min time bins for one hour prior to the prediction time. For the extended challenge, participants are tasked to predict the average travel times on super-segments 15 min into the future - super-segments are longer sequences of road segments in the graph. The competition results provide an important advance in the prediction of complex city-wide traffic states just from publicly available sparse vehicle data and without the need for large amounts of real-time floating vehicle data. ",
    "url": "https://arxiv.org/abs/2303.07758",
    "authors": [
      "Moritz Neun",
      "Christian Eichenberger",
      "Henry Martin",
      "Markus Spanring",
      "Rahul Siripurapu",
      "Daniel Springer",
      "Leyan Deng",
      "Chenwang Wu",
      "Defu Lian",
      "Min Zhou",
      "Martin Lumiste",
      "Andrei Ilie",
      "Xinhua Wu",
      "Cheng Lyu",
      "Qing-Long Lu",
      "Vishal Mahajan",
      "Yichao Lu",
      "Jiezhang Li",
      "Junjun Li",
      "Yue-Jiao Gong",
      "Florian Gr\u00f6tschla",
      "Jo\u00ebl Mathys",
      "Ye Wei",
      "He Haitao",
      "Hui Fang",
      "Kevin Malm",
      "Fei Tang",
      "Michael Kopp",
      "David Kreil",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.07771",
    "title": "Imbalanced Domain Generalization for Robust Single Cell Classification  in Hematological Cytomorphology",
    "abstract": "Accurate morphological classification of white blood cells (WBCs) is an important step in the diagnosis of leukemia, a disease in which nonfunctional blast cells accumulate in the bone marrow. Recently, deep convolutional neural networks (CNNs) have been successfully used to classify leukocytes by training them on single-cell images from a specific domain. Most CNN models assume that the distributions of the training and test data are similar, i.e., that the data are independently and identically distributed. Therefore, they are not robust to different staining protocols, magnifications, resolutions, scanners, or imaging protocols, as well as variations in clinical centers or patient cohorts. In addition, domain-specific data imbalances affect the generalization performance of classifiers. Here, we train a robust CNN for WBC classification by addressing cross-domain data imbalance and domain shifts. To this end, we use two loss functions and demonstrate the effectiveness on out-of-distribution (OOD) generalization. Our approach achieves the best F1 macro score compared to other existing methods, and is able to consider rare cell types. This is the first demonstration of imbalanced domain generalization in hematological cytomorphology and paves the way for robust single cell classification methods for the application in laboratories and clinics. ",
    "url": "https://arxiv.org/abs/2303.07771",
    "authors": [
      "Rao Muhammad Umer",
      "Armin Gruber",
      "Sayedali Shetab Boushehri",
      "Christian Metak",
      "Carsten Marr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07774",
    "title": "Testing Causality for High Dimensional Data",
    "abstract": "Determining causal relationship between high dimensional observations are among the most important tasks in scientific discoveries. In this paper, we revisited the \\emph{linear trace method}, a technique proposed in~\\citep{janzing2009telling,zscheischler2011testing} to infer the causal direction between two random variables of high dimensions. We strengthen the existing results significantly by providing an improved tail analysis in addition to extending the results to nonlinear trace functionals with sharper confidence bounds under certain distributional assumptions. We obtain our results by interpreting the trace estimator in the causal regime as a function over random orthogonal matrices, where the concentration of Lipschitz functions over such space could be applied. We additionally propose a novel ridge-regularized variant of the estimator in \\cite{zscheischler2011testing}, and give provable bounds relating the ridge-estimated terms to their ground-truth counterparts. We support our theoretical results with encouraging experiments on synthetic datasets, more prominently, under high-dimension low sample size regime. ",
    "url": "https://arxiv.org/abs/2303.07774",
    "authors": [
      "Arun Jambulapati",
      "Hilaf Hasson",
      "Youngsuk Park",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.07778",
    "title": "GANN: Graph Alignment Neural Network for Semi-Supervised Learning",
    "abstract": "Graph neural networks (GNNs) have been widely investigated in the field of semi-supervised graph machine learning. Most methods fail to exploit adequate graph information when labeled data is limited, leading to the problem of oversmoothing. To overcome this issue, we propose the Graph Alignment Neural Network (GANN), a simple and effective graph neural architecture. A unique learning algorithm with three alignment rules is proposed to thoroughly explore hidden information for insufficient labels. Firstly, to better investigate attribute specifics, we suggest the feature alignment rule to align the inner product of both the attribute and embedding matrices. Secondly, to properly utilize the higher-order neighbor information, we propose the cluster center alignment rule, which involves aligning the inner product of the cluster center matrix with the unit matrix. Finally, to get reliable prediction results with few labels, we establish the minimum entropy alignment rule by lining up the prediction probability matrix with its sharpened result. Extensive studies on graph benchmark datasets demonstrate that GANN can achieve considerable benefits in semi-supervised node classification and outperform state-of-the-art competitors. ",
    "url": "https://arxiv.org/abs/2303.07778",
    "authors": [
      "Linxuan Song",
      "Wenxuan Tu",
      "Sihang Zhou",
      "Xinwang Liu",
      "En Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07782",
    "title": "Inferential Privacy: From Impossibility to Database Privacy",
    "abstract": "We investigate the possibility of guaranteeing inferential privacy for mechanisms that release useful information about some data containing sensitive information, denoted by $X$. We describe a general model of utility and privacy in which utility is achieved by disclosing the value of low-entropy features of $X$, while privacy is maintained by keeping high-entropy features of $X$ secret. Adopting this model, we prove that meaningful inferential privacy guarantees can be obtained, even though this is commonly considered to be impossible by the well-known result of Dwork and Naor. Then, we specifically discuss a privacy measure called pointwise maximal leakage (PML) whose guarantees are of the inferential type. We use PML to show that differential privacy admits an inferential formulation: it describes the information leaking about a single entry in a database assuming that every other entry is known, and considering the worst-case distribution on the data. Moreover, we define inferential instance privacy (IIP) as a bound on the (non-conditional) information leaking about a single entry in the database under the worst-case distribution, and show that it is equivalent to free-lunch privacy. Overall, our approach to privacy unifies, formalizes, and explains many existing ideas, e.g., why the informed adversary assumption may lead to underestimating the information leaking about each entry in the database. Furthermore, insights obtained from our results suggest general methods for improving privacy analyses; for example, we argue that smaller privacy parameters can be obtained by excluding low-entropy prior distributions from protection. ",
    "url": "https://arxiv.org/abs/2303.07782",
    "authors": [
      "Sara Saeidian",
      "Giulia Cervia",
      "Tobias J. Oechtering",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.07790",
    "title": "Object Detection During Newborn Resuscitation Activities",
    "abstract": "Birth asphyxia is a major newborn mortality problem in low-resource countries. International guideline provides treatment recommendations; however, the importance and effect of the different treatments are not fully explored. The available data is collected in Tanzania, during newborn resuscitation, for analysis of the resuscitation activities and the response of the newborn. An important step in the analysis is to create activity timelines of the episodes, where activities include ventilation, suction, stimulation etc. Methods: The available recordings are noisy real-world videos with large variations. We propose a two-step process in order to detect activities possibly overlapping in time. The first step is to detect and track the relevant objects, like bag-mask resuscitator, heart rate sensors etc., and the second step is to use this information to recognize the resuscitation activities. The topic of this paper is the first step, and the object detection and tracking are based on convolutional neural networks followed by post processing. Results: The performance of the object detection during activities were 96.97 % (ventilations), 100 % (attaching/removing heart rate sensor) and 75 % (suction) on a test set of 20 videos. The system also estimate the number of health care providers present with a performance of 71.16 %. Conclusion: The proposed object detection and tracking system provides promising results in noisy newborn resuscitation videos. Significance: This is the first step in a thorough analysis of newborn resuscitation episodes, which could provide important insight about the importance and effect of different newborn resuscitation activities ",
    "url": "https://arxiv.org/abs/2303.07790",
    "authors": [
      "\u00d8yvind Meinich-Bache",
      "Kjersti Engan",
      "Ivar Austvoll",
      "Trygve Eftest\u00f8l",
      "Helge Myklebust",
      "Ladislaus Blacy Yarrot",
      "Hussein Kidanto",
      "Hege Ersdal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07797",
    "title": "Automated Self-Supervised Learning for Recommendation",
    "abstract": "Graph neural networks (GNNs) have emerged as the state-of-the-art paradigm for collaborative filtering (CF). To improve the representation quality over limited labeled data, contrastive learning has attracted attention in recommendation and benefited graph-based CF model recently. However, the success of most contrastive methods heavily relies on manually generating effective contrastive views for heuristic-based data augmentation. This does not generalize across different datasets and downstream recommendation tasks, which is difficult to be adaptive for data augmentation and robust to noise perturbation. To fill this crucial gap, this work proposes a unified Automated Collaborative Filtering (AutoCF) to automatically perform data augmentation for recommendation. Specifically, we focus on the generative self-supervised learning framework with a learnable augmentation paradigm that benefits the automated distillation of important self-supervised signals. To enhance the representation discrimination ability, our masked graph autoencoder is designed to aggregate global information during the augmentation via reconstructing the masked subgraph structures. Experiments and ablation studies are performed on several public datasets for recommending products, venues, and locations. Results demonstrate the superiority of AutoCF against various baseline methods. We release the model implementation at https://github.com/HKUDS/AutoCF. ",
    "url": "https://arxiv.org/abs/2303.07797",
    "authors": [
      "Lianghao Xia",
      "Chao Huang",
      "Chunzhen Huang",
      "Kangyi Lin",
      "Tao Yu",
      "Ben Kao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.07810",
    "title": "Disentangled Graph Social Recommendation",
    "abstract": "Social recommender systems have drawn a lot of attention in many online web services, because of the incorporation of social information between users in improving recommendation results. Despite the significant progress made by existing solutions, we argue that current methods fall short in two limitations: (1) Existing social-aware recommendation models only consider collaborative similarity between items, how to incorporate item-wise semantic relatedness is less explored in current recommendation paradigms. (2) Current social recommender systems neglect the entanglement of the latent factors over heterogeneous relations (e.g., social connections, user-item interactions). Learning the disentangled representations with relation heterogeneity poses great challenge for social recommendation. In this work, we design a Disentangled Graph Neural Network (DGNN) with the integration of latent memory units, which empowers DGNN to maintain factorized representations for heterogeneous types of user and item connections. Additionally, we devise new memory-augmented message propagation and aggregation schemes under the graph neural architecture, allowing us to recursively distill semantic relatedness into the representations of users and items in a fully automatic manner. Extensive experiments on three benchmark datasets verify the effectiveness of our model by achieving great improvement over state-of-the-art recommendation techniques. The source code is publicly available at: https://github.com/HKUDS/DGNN. ",
    "url": "https://arxiv.org/abs/2303.07810",
    "authors": [
      "Lianghao Xia",
      "Yizhen Shao",
      "Chao Huang",
      "Yong Xu",
      "Huance Xu",
      "Jian Pei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.07812",
    "title": "Termination of Graph Transformation Systems using Weighted Subgraph  Counting",
    "abstract": "We introduce a termination method for the algebraic graph transformation framework PBPO+, in which we weigh objects by summing a class of weighted morphisms targeting them. The method is well defined in rm-adhesive quasitoposes (which includes toposes), and is applicable to non-linear rules. The method is also defined for other frameworks, including DPO and SqPO, because we have previously shown that they are naturally encodable into PBPO+ in the quasitopos setting. ",
    "url": "https://arxiv.org/abs/2303.07812",
    "authors": [
      "Roy Overbeek",
      "J\u00f6rg Endrullis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2303.07820",
    "title": "Adaptive Rotated Convolution for Rotated Object Detection",
    "abstract": "Rotated object detection aims to identify and locate objects in images with arbitrary orientation. In this scenario, the oriented directions of objects vary considerably across different images, while multiple orientations of objects exist within an image. This intrinsic characteristic makes it challenging for standard backbone networks to extract high-quality features of these arbitrarily orientated objects. In this paper, we present Adaptive Rotated Convolution (ARC) module to handle the aforementioned challenges. In our ARC module, the convolution kernels rotate adaptively to extract object features with varying orientations in different images, and an efficient conditional computation mechanism is introduced to accommodate the large orientation variations of objects within an image. The two designs work seamlessly in rotated object detection problem. Moreover, ARC can conveniently serve as a plug-and-play module in various vision backbones to boost their representation ability to detect oriented objects accurately. Experiments on commonly used benchmarks (DOTA and HRSC2016) demonstrate that equipped with our proposed ARC module in the backbone network, the performance of multiple popular oriented object detectors is significantly improved (e.g. +3.03% mAP on Rotated RetinaNet and +4.16% on CFA). Combined with the highly competitive method Oriented R-CNN, the proposed approach achieves state-of-the-art performance on the DOTA dataset with 81.77% mAP. ",
    "url": "https://arxiv.org/abs/2303.07820",
    "authors": [
      "Yifan Pu",
      "Yiru Wang",
      "Zhuofan Xia",
      "Yizeng Han",
      "Yulin Wang",
      "Weihao Gan",
      "Zidong Wang",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07821",
    "title": "Self-attention for Enhanced OAMP Detection in MIMO Systems",
    "abstract": "Multiple-Input Multiple-Output (MIMO) systems are essential for wireless communications. Sinceclassical algorithms for symbol detection in MIMO setups require large computational resourcesor provide poor results, data-driven algorithms are becoming more popular. Most of the proposedalgorithms, however, introduce approximations leading to degraded performance for realistic MIMOsystems. In this paper, we introduce a neural-enhanced hybrid model, augmenting the analyticbackbone algorithm with state-of-the-art neural network components. In particular, we introduce aself-attention model for the enhancement of the iterative Orthogonal Approximate Message Passing(OAMP)-based decoding algorithm. In our experiments, we show that the proposed model canoutperform existing data-driven approaches for OAMP while having improved generalization to otherSNR values at limited computational overhead. ",
    "url": "https://arxiv.org/abs/2303.07821",
    "authors": [
      "Alexander Fuchs",
      "Christian Knoll",
      "Nima N. Moghadam",
      "Alexey Pak Jinliang Huang",
      "Erik Leitinger",
      "Franz Pernkopf"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.07826",
    "title": "Implant Global and Local Hierarchy Information to Sequence based Code  Representation Models",
    "abstract": "Source code representation with deep learning techniques is an important research field. There have been many studies that learn sequential or structural information for code representation. But sequence-based models and non-sequence-models both have their limitations. Researchers attempt to incorporate structural information to sequence-based models, but they only mine part of token-level hierarchical structure information. In this paper, we analyze how the complete hierarchical structure influences the tokens in code sequences and abstract this influence as a property of code tokens called hierarchical embedding. The hierarchical embedding is further divided into statement-level global hierarchy and token-level local hierarchy. Furthermore, we propose the Hierarchy Transformer (HiT), a simple but effective sequence model to incorporate the complete hierarchical embeddings of source code into a Transformer model. We demonstrate the effectiveness of hierarchical embedding on learning code structure with an experiment on variable scope detection task. Further evaluation shows that HiT outperforms SOTA baseline models and show stable training efficiency on three source code-related tasks involving classification and generation tasks across 8 different datasets. ",
    "url": "https://arxiv.org/abs/2303.07826",
    "authors": [
      "Kechi Zhang",
      "Zhuo Li",
      "Zhi Jin",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07828",
    "title": "Prioritized Planning for Target-Oriented Manipulation via Hierarchical  Stacking Relationship Prediction",
    "abstract": "In scenarios involving the grasping of multiple targets, the learning of stacking relationships between objects is fundamental for robots to execute safely and efficiently. However, current methods lack subdivision for the hierarchy of stacking relationship types. In scenes where objects are mostly stacked in an orderly manner, they are incapable of performing human-like and high-efficient grasping decisions. This paper proposes a perception-planning method to distinguish different stacking types between objects and generate prioritized manipulation order decisions based on given target designations. We utilize a Hierarchical Stacking Relationship Network (HSRN) to discriminate the hierarchy of stacking and generate a refined Stacking Relationship Tree (SRT) for relationship description. Considering that objects with high stacking stability can be grasped together if necessary, we introduce an elaborate decision-making planner based on the Partially Observable Markov Decision Process (POMDP), which leverages observations and generates the least grasp-consuming decision chain with robustness and is suitable for simultaneously specifying multiple targets. To verify our work, we set the scene to the dining table and augment the REGRAD dataset with a set of common tableware models for network training. Experiments show that our method effectively generates grasping decisions that conform to human requirements, and improves the implementation efficiency compared with existing methods on the basis of guaranteeing the success rate. ",
    "url": "https://arxiv.org/abs/2303.07828",
    "authors": [
      "Zewen Wu",
      "Jian Tang",
      "Xingyu Chen",
      "Chengzhong Ma",
      "Xuguang Lan",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07836",
    "title": "Robust Fusion for Bayesian Semantic Mapping",
    "abstract": "The integration of semantic information in a map allows robots to understand better their environment and make high-level decisions. In the last few years, neural networks have shown enormous progress in their perception capabilities. However, when fusing multiple observations from a neural network in a semantic map, its inherent overconfidence with unknown data gives too much weight to the outliers and decreases the robustness of the resulting map. In this work, we propose a novel robust fusion method to combine multiple Bayesian semantic predictions. Our method uses the uncertainty estimation provided by a Bayesian neural network to calibrate the way in which the measurements are fused. This is done by regularizing the observations to mitigate the problem of overconfident outlier predictions and using the epistemic uncertainty to weigh their influence in the fusion, resulting in a different formulation of the probability distributions. We validate our robust fusion strategy by performing experiments on photo-realistic simulated environments and real scenes. In both cases, we use a network trained on different data to expose the model to varying data distributions. The results show that considering the model's uncertainty and regularizing the probability distribution of the observations distribution results in a better semantic segmentation performance and more robustness to outliers, compared with other methods. ",
    "url": "https://arxiv.org/abs/2303.07836",
    "authors": [
      "David Morilla-Cabello",
      "Lorenzo Mur-Labadia",
      "Ruben Martinez-Cantin",
      "Eduardo Montijano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07839",
    "title": "ChatGPT Prompt Patterns for Improving Code Quality, Refactoring,  Requirements Elicitation, and Software Design",
    "abstract": "This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented. This paper provides two contributions to research on using LLMs for software engineering. First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve. Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design. ",
    "url": "https://arxiv.org/abs/2303.07839",
    "authors": [
      "Jules White",
      "Sam Hays",
      "Quchen Fu",
      "Jesse Spencer-Smith",
      "Douglas C. Schmidt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07840",
    "title": "Precise Facial Landmark Detection by Reference Heatmap Transformer",
    "abstract": "Most facial landmark detection methods predict landmarks by mapping the input facial appearance features to landmark heatmaps and have achieved promising results. However, when the face image is suffering from large poses, heavy occlusions and complicated illuminations, they cannot learn discriminative feature representations and effective facial shape constraints, nor can they accurately predict the value of each element in the landmark heatmap, limiting their detection accuracy. To address this problem, we propose a novel Reference Heatmap Transformer (RHT) by introducing reference heatmap information for more precise facial landmark detection. The proposed RHT consists of a Soft Transformation Module (STM) and a Hard Transformation Module (HTM), which can cooperate with each other to encourage the accurate transformation of the reference heatmap information and facial shape constraints. Then, a Multi-Scale Feature Fusion Module (MSFFM) is proposed to fuse the transformed heatmap features and the semantic features learned from the original face images to enhance feature representations for producing more accurate target heatmaps. To the best of our knowledge, this is the first study to explore how to enhance facial landmark detection by transforming the reference heatmap information. The experimental results from challenging benchmark datasets demonstrate that our proposed method outperforms the state-of-the-art methods in the literature. ",
    "url": "https://arxiv.org/abs/2303.07840",
    "authors": [
      "Jun Wan",
      "Jun Liu",
      "Jie Zhou",
      "Zhihui Lai",
      "Linlin Shen",
      "Hang Sun",
      "Ping Xiong",
      "Wenwen Min"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07846",
    "title": "Sample-efficient Adversarial Imitation Learning",
    "abstract": "Imitation learning, in which learning is performed by demonstration, has been studied and advanced for sequential decision-making tasks in which a reward function is not predefined. However, imitation learning methods still require numerous expert demonstration samples to successfully imitate an expert's behavior. To improve sample efficiency, we utilize self-supervised representation learning, which can generate vast training signals from the given data. In this study, we propose a self-supervised representation-based adversarial imitation learning method to learn state and action representations that are robust to diverse distortions and temporally predictive, on non-image control tasks. In particular, in comparison with existing self-supervised learning methods for tabular data, we propose a different corruption method for state and action representations that is robust to diverse distortions. We theoretically and empirically observe that making an informative feature manifold with less sample complexity significantly improves the performance of imitation learning. The proposed method shows a 39% relative improvement over existing adversarial imitation learning methods on MuJoCo in a setting limited to 100 expert state-action pairs. Moreover, we conduct comprehensive ablations and additional experiments using demonstrations with varying optimality to provide insights into a range of factors. ",
    "url": "https://arxiv.org/abs/2303.07846",
    "authors": [
      "Dahuin Jung",
      "Hyungyu Lee",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07847",
    "title": "Transfer Learning for Real-time Deployment of a Screening Tool for  Depression Detection Using Actigraphy",
    "abstract": "Automated depression screening and diagnosis is a highly relevant problem today. There are a number of limitations of the traditional depression detection methods, namely, high dependence on clinicians and biased self-reporting. In recent years, research has suggested strong potential in machine learning (ML) based methods that make use of the user's passive data collected via wearable devices. However, ML is data hungry. Especially in the healthcare domain primary data collection is challenging. In this work, we present an approach based on transfer learning, from a model trained on a secondary dataset, for the real time deployment of the depression screening tool based on the actigraphy data of users. This approach enables machine learning modelling even with limited primary data samples. A modified version of leave one out cross validation approach performed on the primary set resulted in mean accuracy of 0.96, where in each iteration one subject's data from the primary set was set aside for testing. ",
    "url": "https://arxiv.org/abs/2303.07847",
    "authors": [
      "Rajanikant Ghate",
      "Nayan Kalnad",
      "Rahee Walambe",
      "Ketan Kotecha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.07849",
    "title": "Implicit Stacked Autoregressive Model for Video Prediction",
    "abstract": "Future frame prediction has been approached through two primary methods: autoregressive and non-autoregressive. Autoregressive methods rely on the Markov assumption and can achieve high accuracy in the early stages of prediction when errors are not yet accumulated. However, their performance tends to decline as the number of time steps increases. In contrast, non-autoregressive methods can achieve relatively high performance but lack correlation between predictions for each time step. In this paper, we propose an Implicit Stacked Autoregressive Model for Video Prediction (IAM4VP), which is an implicit video prediction model that applies a stacked autoregressive method. Like non-autoregressive methods, stacked autoregressive methods use the same observed frame to estimate all future frames. However, they use their own predictions as input, similar to autoregressive methods. As the number of time steps increases, predictions are sequentially stacked in the queue. To evaluate the effectiveness of IAM4VP, we conducted experiments on three common future frame prediction benchmark datasets and weather\\&climate prediction benchmark datasets. The results demonstrate that our proposed model achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2303.07849",
    "authors": [
      "Minseok Seo",
      "Hakjin Lee",
      "Doyi Kim",
      "Junghoon Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07858",
    "title": "Efficient Yao Graph Construction",
    "abstract": "Yao graphs are geometric spanners that connect each point of a given point set to its nearest neighbor in each of $k$ cones drawn around it. Yao graphs were introduced to construct minimum spanning trees in $d$ dimensional spaces. Moreover, they are used for instance in topology control in wireless networks. An optimal \\Onlogn time algorithm to construct Yao graphs for given point set has been proposed in the literature but -- to the best of our knowledge -- never been implemented. Instead, algorithms with a quadratic complexity are used in popular packages to construct these graphs. In this paper we present the first implementation of the optimal Yao graph algorithm. We develop and tune the data structures required to achieve the O(n log n) bound and detail algorithmic adaptions necessary to take the original algorithm from theory to practice. We propose a priority queue data structure that separates static and dynamic events and might be of independent interest for other sweepline algorithms. Additionally, we propose a new Yao graph algorithm based on a uniform grid data structure that performs well for medium-sized inputs. We evaluate our implementations on a wide variety synthetic and real-world datasets and show that our implementation outperforms current publicly available implementations by at least an order of magnitude. ",
    "url": "https://arxiv.org/abs/2303.07858",
    "authors": [
      "Daniel Funke",
      "Peter Sanders"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.07864",
    "title": "DualMix: Unleashing the Potential of Data Augmentation for Online  Class-Incremental Learning",
    "abstract": "Online Class-Incremental (OCI) learning has sparked new approaches to expand the previously trained model knowledge from sequentially arriving data streams with new classes. Unfortunately, OCI learning can suffer from catastrophic forgetting (CF) as the decision boundaries for old classes can become inaccurate when perturbated by new ones. Existing literature have applied the data augmentation (DA) to alleviate the model forgetting, while the role of DA in OCI has not been well understood so far. In this paper, we theoretically show that augmented samples with lower correlation to the original data are more effective in preventing forgetting. However, aggressive augmentation may also reduce the consistency between data and corresponding labels, which motivates us to exploit proper DA to boost the OCI performance and prevent the CF problem. We propose the Enhanced Mixup (EnMix) method that mixes the augmented samples and their labels simultaneously, which is shown to enhance the sample diversity while maintaining strong consistency with corresponding labels. Further, to solve the class imbalance problem, we design an Adaptive Mixup (AdpMix) method to calibrate the decision boundaries by mixing samples from both old and new classes and dynamically adjusting the label mixing ratio. Our approach is demonstrated to be effective on several benchmark datasets through extensive experiments, and it is shown to be compatible with other replay-based techniques. ",
    "url": "https://arxiv.org/abs/2303.07864",
    "authors": [
      "Yunfeng Fan",
      "Wenchao Xu",
      "Haozhao Wang",
      "Jiaqi Zhu",
      "Junxiao Wang",
      "Song Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07875",
    "title": "Solar Power Prediction Using Machine Learning",
    "abstract": "This paper presents a machine learning-based approach for predicting solar power generation with high accuracy using a 99% AUC (Area Under the Curve) metric. The approach includes data collection, pre-processing, feature selection, model selection, training, evaluation, and deployment. High-quality data from multiple sources, including weather data, solar irradiance data, and historical solar power generation data, are collected and pre-processed to remove outliers, handle missing values, and normalize the data. Relevant features such as temperature, humidity, wind speed, and solar irradiance are selected for model training. Support Vector Machines (SVM), Random Forest, and Gradient Boosting are used as machine learning algorithms to produce accurate predictions. The models are trained on a large dataset of historical solar power generation data and other relevant features. The performance of the models is evaluated using AUC and other metrics such as precision, recall, and F1-score. The trained machine learning models are then deployed in a production environment, where they can be used to make real-time predictions about solar power generation. The results show that the proposed approach achieves a 99% AUC for solar power generation prediction, which can help energy companies better manage their solar power systems, reduce costs, and improve energy efficiency. ",
    "url": "https://arxiv.org/abs/2303.07875",
    "authors": [
      "E. Subramanian",
      "M. Mithun Karthik",
      "G Prem Krishna",
      "D. Vaisnav Prasath",
      "V. Sukesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07884",
    "title": "Distributed least square solution method to linear algebraic equations  over multiagent networks",
    "abstract": "This paper designs a distributed least square solution method for a linear algebraic equation over a multiagent network. The coefficient matrix is divided into multiple blocks, and each agent only knows a subset of these blocks. The designed method is discrete-time and based on a proximal ADMM algorithm. By applying the designed method, each agent can find its corresponding part in one least square solution of the considered linear algebraic equation while using only its information and communicating with its neighbors. Numerical simulations verify the effectiveness of the designed method in MATLAB. ",
    "url": "https://arxiv.org/abs/2303.07884",
    "authors": [
      "Viet Hoang Pham",
      "Hyo-Sung Ahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.07917",
    "title": "Reachability Analysis of Neural Networks with Uncertain Parameters",
    "abstract": "The literature on reachability analysis methods for neural networks currently only focuses on uncertainties on the network's inputs. In this paper, we introduce two new approaches for the reachability analysis of neural networks with additional uncertainties on their internal parameters (weight matrices and bias vectors of each layer), which may open the field of formal methods on neural networks to new topics, such as safe training or network repair. The first and main method that we propose relies on existing reachability analysis approach based on mixed monotonicity (initially introduced for dynamical systems). The second proposed approach extends the ESIP (Error-based Symbolic Interval Propagation) approach which was first implemented in the verification tool Neurify, and first mentioned in the publication of the tool VeriNet. Although the ESIP approach has been shown to often outperform the mixed-monotonicity reachability analysis in the classical case with uncertainties only on the network's inputs, we show in this paper through numerical simulations that the situation is greatly reversed (in terms of precision, computation time, memory usage, and broader applicability) when dealing with uncertainties on the weights and biases. ",
    "url": "https://arxiv.org/abs/2303.07917",
    "authors": [
      "Pierre-Jean Meyer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07927",
    "title": "Examining the impacts of privacy awareness on user's self-disclosure on  social media",
    "abstract": "This research aims to investigate the impact of users' privacy awareness on their self-disclosing behavior. Our primary research question is to investigate how young social media users feel about the benefits and risks of disclosing them-selves on social media and how risk-benefit awareness influences the assess-ment of their self-disclosure. Based on the data we recorded, the factor analysis, and three-way ANOVA, we conclude that users who know more about privacy benefits share more on social media (F= 36.291; df 1; sig < .001) while those who know less about the benefits disclose less on social media. According to the analysis, users who know more about self-disclosure risks share less on so-cial media (F= 7.001; df 1; sig < .001). Users disclose less information on so-cial media platforms based on the different levels of their risk perceptions (df 3, F=.715, sig < 0.5). This indicates that risks on social media platforms vary to some degree. We saw that people's sharing habits based on their levels of risk, benefits, and social media platforms can vary. One thing that remained certain was users' main benefit for engaging and disclosing on social media is their need to stay in touch with friends and their need for community. On the flip side, the main risk was the need not to be impersonated and misunderstood by people. Based on a simple frequency analysis of the open-ended questions we asked In our data collection, the most highlighted words in our responses were \"people\" and \"friends\". These were the two main words that stood out in all the data we collected concerning the benefits, risks, and intention to self-disclose. ",
    "url": "https://arxiv.org/abs/2303.07927",
    "authors": [
      "Kijung Lee",
      "Prudence Attablayo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.07929",
    "title": "DAA: A Delta Age AdaIN operation for age estimation via binary code  transformer",
    "abstract": "Naked eye recognition of age is usually based on comparison with the age of others. However, this idea is ignored by computer tasks because it is difficult to obtain representative contrast images of each age. Inspired by the transfer learning, we designed the Delta Age AdaIN (DAA) operation to obtain the feature difference with each age, which obtains the style map of each age through the learned values representing the mean and standard deviation. We let the input of transfer learning as the binary code of age natural number to obtain continuous age feature information. The learned two groups of values in Binary code mapping are corresponding to the mean and standard deviation of the comparison ages. In summary, our method consists of four parts: FaceEncoder, DAA operation, Binary code mapping, and AgeDecoder modules. After getting the delta age via AgeDecoder, we take the average value of all comparison ages and delta ages as the predicted age. Compared with state-of-the-art methods, our method achieves better performance with fewer parameters on multiple facial age datasets. ",
    "url": "https://arxiv.org/abs/2303.07929",
    "authors": [
      "Ping Chen",
      "Xingpeng Zhang",
      "Ye Li",
      "Ju Tao",
      "Bin Xiao",
      "Bing Wang",
      "Zongjie Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07937",
    "title": "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D  Generation",
    "abstract": "Text-to-3D generation has shown rapid progress in recent days with the advent of score distillation, a methodology of using pretrained text-to-2D diffusion models to optimize neural radiance field (NeRF) in the zero-shot setting. However, the lack of 3D awareness in the 2D diffusion models destabilizes score distillation-based methods from reconstructing a plausible 3D scene. To address this issue, we propose \\ours, a novel framework that incorporates 3D awareness into pretrained 2D diffusion models, enhancing the robustness and 3D consistency of score distillation-based methods. We realize this by first constructing a coarse 3D structure of a given text prompt and then utilizing projected, view-specific depth map as a condition for the diffusion model. Additionally, we introduce a training strategy that enables the 2D diffusion model learns to handle the errors and sparsity within the coarse 3D structure for robust generation, as well as a method for ensuring semantic consistency throughout all viewpoints of the scene. Our framework surpasses the limitations of prior arts, and has significant implications for 3D consistent generation of 2D diffusion models. ",
    "url": "https://arxiv.org/abs/2303.07937",
    "authors": [
      "Junyoung Seo",
      "Wooseok Jang",
      "Min-Seop Kwak",
      "Jaehoon Ko",
      "Hyeonsu Kim",
      "Junho Kim",
      "Jin-Hwa Kim",
      "Jiyoung Lee",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07957",
    "title": "Automatic summarisation of Instagram social network posts Combining  semantic and statistical approaches",
    "abstract": "The proliferation of data and text documents such as articles, web pages, books, social network posts, etc. on the Internet has created a fundamental challenge in various fields of text processing under the title of \"automatic text summarisation\". Manual processing and summarisation of large volumes of textual data is a very difficult, expensive, time-consuming and impossible process for human users. Text summarisation systems are divided into extractive and abstract categories. In the extractive summarisation method, the final summary of a text document is extracted from the important sentences of the same document without any modification. In this method, it is possible to repeat a series of sentences and to interfere with pronouns. However, in the abstract summarisation method, the final summary of a textual document is extracted from the meaning and significance of the sentences and words of the same document or other documents. Many of the works carried out have used extraction methods or abstracts to summarise the collection of web documents, each of which has advantages and disadvantages in the results obtained in terms of similarity or size. In this work, a crawler has been developed to extract popular text posts from the Instagram social network with appropriate preprocessing, and a set of extraction and abstraction algorithms have been combined to show how each of the abstraction algorithms can be used. Observations made on 820 popular text posts on the social network Instagram show the accuracy (80%) of the proposed system. ",
    "url": "https://arxiv.org/abs/2303.07957",
    "authors": [
      "Kazem Taghandiki",
      "Mohammad Hassan Ahmadi",
      "Elnaz Rezaei Ehsan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07960",
    "title": "Coloring and Recognizing Directed Interval Graphs",
    "abstract": "A mixed interval graph is an interval graph that has, for every pair of intersecting intervals, either an arc (directed arbitrarily) or an (undirected) edge. We are interested in mixed interval graphs where the type of connection of two vertices is determined by geometry. In a proper coloring of a mixed interval graph G, an interval u receives a lower (different) color than an interval v if G contains arc (u, v) (edge {u, v}). We introduce a new natural class of mixed interval graphs, which we call containment interval graphs. In such a graph, there is an arc (u, v) if interval u contains interval v, and there is an edge {u, v} if u and v overlap. We show that these graphs can be recognized in polynomial time, that coloring them with the minimum number of colors is NP-hard, and that there is a 2-approximation algorithm for coloring. For coloring general mixed interval graphs, we present a min{{\\omega}(G), {\\lambda}(G)}-approximation algorithm, where {\\omega}(G) is the size of a largest clique and {\\lambda}(G) is the length of a longest induced directed path in G. For the subclass of bidirectional interval graphs (introduced recently), we show that optimal coloring is NP-hard. ",
    "url": "https://arxiv.org/abs/2303.07960",
    "authors": [
      "Grzegorz Gutowski",
      "Konstanty Junosza-Szaniawski",
      "Felix Klesen",
      "Pawe\u0142 Rz\u0105\u017cewski",
      "Alexander Wolff",
      "Johannes Zink"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.07963",
    "title": "RoCNet: 3D Robust Registration of Point-Clouds using Deep Learning",
    "abstract": "This paper introduces a new method for 3D point cloud registration based on deep learning. The architecture is composed of three distinct blocs: (i) an encoder composed of a convolutional graph-based descriptor that encodes the immediate neighbourhood of each point and an attention mechanism that encodes the variations of the surface normals. Such descriptors are refined by highlighting attention between the points of the same set and then between the points of the two sets. (ii) a matching process that estimates a matrix of correspondences using the Sinkhorn algorithm. (iii) Finally, the rigid transformation between the two point clouds is calculated by RANSAC using the Kc best scores from the correspondence matrix. We conduct experiments on the ModelNet40 dataset, and our proposed architecture shows very promising results, outperforming state-of-the-art methods in most of the simulated configurations, including partial overlap and data augmentation with Gaussian noise. ",
    "url": "https://arxiv.org/abs/2303.07963",
    "authors": [
      "Karim Slimani",
      "Brahim Tamadazte",
      "Catherine Achard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07972",
    "title": "GoNet: An Approach-Constrained Generative Grasp Sampling Network",
    "abstract": "Constraining the approach direction of grasps is important when picking objects in confined spaces, such as when emptying a shelf. Yet, such capabilities are not available in state-of-the-art data-driven grasp sampling methods that sample grasps all around the object. In this work, we address the specific problem of training approach-constrained data-driven grasp samplers and how to generate good grasping directions automatically. Our solution is GoNet: a generative grasp sampler that can constrain the grasp approach direction to lie close to a specified direction. This is achieved by discretizing SO(3) into bins and training GoNet to generate grasps from those bins. At run-time, the bin aligning with the second largest principal component of the observed point cloud is selected. GoNet is benchmarked against GraspNet, a state-of-the-art unconstrained grasp sampler, in an unconfined grasping experiment in simulation and on an unconfined and confined grasping experiment in the real world. The results demonstrate that GoNet achieves higher success-over-coverage in simulation and a 12%-18% higher success rate in real-world table-picking and shelf-picking tasks than the baseline. ",
    "url": "https://arxiv.org/abs/2303.07972",
    "authors": [
      "Zehang Weng",
      "Haofei Lu",
      "Jens Lundell",
      "Danica Kragic"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07982",
    "title": "A Structural Approach to Tree Decompositions of Knots and Spatial Graphs",
    "abstract": "Knots are commonly represented and manipulated via diagrams, which are decorated planar graphs. When such a knot diagram has low treewidth, parameterized graph algorithms can be leveraged to ensure the fast computation of many invariants and properties of the knot. It was recently proved that there exist knots which do not admit any diagram of low treewidth, and the proof relied on intricate low-dimensional topology techniques. In this work, we initiate a thorough investigation of tree decompositions of knot diagrams (or more generally, diagrams of spatial graphs) using ideas from structural graph theory. We define an obstruction on spatial embeddings that forbids low tree width diagrams, and we prove that it is optimal with respect to a related width invariant. We then show the existence of this obstruction for knots of high representativity, which include for example torus knots, providing a new and self-contained proof that those do not admit diagrams of low treewidth. This last step is inspired by a result of Pardon on knot distortion. ",
    "url": "https://arxiv.org/abs/2303.07982",
    "authors": [
      "Corentin Lunel",
      "Arnaud de Mesmay"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2303.07987",
    "title": "Practically Solving LPN in High Noise Regimes Faster Using Neural  Networks",
    "abstract": "We conduct a systematic study of solving the learning parity with noise problem (LPN) using neural networks. Our main contribution is designing families of two-layer neural networks that practically outperform classical algorithms in high-noise, low-dimension regimes. We consider three settings where the numbers of LPN samples are abundant, very limited, and in between. In each setting we provide neural network models that solve LPN as fast as possible. For some settings we are also able to provide theories that explain the rationale of the design of our models. Comparing with the previous experiments of Esser, Kubler, and May (CRYPTO 2017), for dimension $n = 26$, noise rate $\\tau = 0.498$, the ''Guess-then-Gaussian-elimination'' algorithm takes 3.12 days on 64 CPU cores, whereas our neural network algorithm takes 66 minutes on 8 GPUs. Our algorithm can also be plugged into the hybrid algorithms for solving middle or large dimension LPN instances. ",
    "url": "https://arxiv.org/abs/2303.07987",
    "authors": [
      "Haozhe Jiang",
      "Kaiyue Wen",
      "Yilei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.07988",
    "title": "Partial Neural Optimal Transport",
    "abstract": "We propose a novel neural method to compute partial optimal transport (OT) maps, i.e., OT maps between parts of measures of the specified masses. We test our partial neural optimal transport algorithm on synthetic examples. ",
    "url": "https://arxiv.org/abs/2303.07988",
    "authors": [
      "Milena Gazdieva",
      "Alexander Korotin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07992",
    "title": "Evaluation of ChatGPT as a Question Answering System for Answering  Complex Questions",
    "abstract": "ChatGPT is a powerful large language model (LLM) that has made remarkable progress in natural language understanding. Nevertheless, the performance and limitations of the model still need to be extensively evaluated. As ChatGPT covers resources such as Wikipedia and supports natural language question answering, it has garnered attention as a potential replacement for traditional knowledge based question answering (KBQA) models. Complex question answering is a challenge task of KBQA, which comprehensively tests the ability of models in semantic parsing and reasoning. To assess the performance of ChatGPT as a question answering system (QAS) using its own knowledge, we present a framework that evaluates its ability to answer complex questions. Our approach involves categorizing the potential features of complex questions and describing each test question with multiple labels to identify combinatorial reasoning. Following the black-box testing specifications of CheckList proposed by Ribeiro et.al, we develop an evaluation method to measure the functionality and reliability of ChatGPT in reasoning for answering complex questions. We use the proposed framework to evaluate the performance of ChatGPT in question answering on 8 real-world KB-based CQA datasets, including 6 English and 2 multilingual datasets, with a total of approximately 190,000 test cases. We compare the evaluation results of ChatGPT, GPT-3.5, GPT-3, and FLAN-T5 to identify common long-term problems in LLMs. The dataset and code are available at https://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-ChatGPT. ",
    "url": "https://arxiv.org/abs/2303.07992",
    "authors": [
      "Yiming Tan",
      "Dehai Min",
      "Yu Li",
      "Wenbo Li",
      "Nan Hu",
      "Yongrui Chen",
      "Guilin Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.07994",
    "title": "Learning for Precision Motion of an Interventional X-ray System: Add-on  Physics-Guided Neural Network Feedforward Control",
    "abstract": "Tracking performance of physical-model-based feedforward control for interventional X-ray systems is limited by hard-to-model parasitic nonlinear dynamics, such as cable forces and nonlinear friction. In this paper, these nonlinear dynamics are compensated using a physics-guided neural network (PGNN), consisting of a physical model, embedding prior knowledge of the dynamics, in parallel with a neural network to learn hard-to-model dynamics. To ensure that the neural network learns only unmodelled effects, the neural network output in the subspace spanned by the physical model is regularized via an orthogonal projection-based approach, resulting in complementary physical model and neural network contributions. The PGNN feedforward controller reduces the tracking error of an interventional X-ray system by a factor of 5 compared to an optimally tuned physical model, successfully compensating the unmodeled parasitic dynamics. ",
    "url": "https://arxiv.org/abs/2303.07994",
    "authors": [
      "Johan Kon",
      "Naomi de Vos",
      "Dennis Bruijnen",
      "Jeroen van de Wijdeven",
      "Marcel Heertjes",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.08003",
    "title": "Multi-agent Attention Actor-Critic Algorithm for Load Balancing in  Cellular Networks",
    "abstract": "In cellular networks, User Equipment (UE) handoff from one Base Station (BS) to another, giving rise to the load balancing problem among the BSs. To address this problem, BSs can work collaboratively to deliver a smooth migration (or handoff) and satisfy the UEs' service requirements. This paper formulates the load balancing problem as a Markov game and proposes a Robust Multi-agent Attention Actor-Critic (Robust-MA3C) algorithm that can facilitate collaboration among the BSs (i.e., agents). In particular, to solve the Markov game and find a Nash equilibrium policy, we embrace the idea of adopting a nature agent to model the system uncertainty. Moreover, we utilize the self-attention mechanism, which encourages high-performance BSs to assist low-performance BSs. In addition, we consider two types of schemes, which can facilitate load balancing for both active UEs and idle UEs. We carry out extensive evaluations by simulations, and simulation results illustrate that, compared to the state-of-the-art MARL methods, Robust-\\ours~scheme can improve the overall performance by up to 45%. ",
    "url": "https://arxiv.org/abs/2303.08003",
    "authors": [
      "Jikun Kang",
      "Di Wu",
      "Ju Wang",
      "Ekram Hossain",
      "Xue Liu",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.08016",
    "title": "Detection of Abuse in Financial Transaction Descriptions Using Machine  Learning",
    "abstract": "Since introducing changes to the New Payments Platform (NPP) to include longer messages as payment descriptions, it has been identified that people are now using it for communication, and in some cases, the system was being used as a targeted form of domestic and family violence. This type of tech-assisted abuse poses new challenges in terms of identification, actions and approaches to rectify this behaviour. Commonwealth Bank of Australia's Artificial Intelligence Labs team (CBA AI Labs) has developed a new system using advances in deep learning models for natural language processing (NLP) to create a powerful abuse detector that periodically scores all the transactions, and identifies cases of high-risk abuse in millions of records. In this paper, we describe the problem of tech-assisted abuse in the context of banking services, outline the developed model and its performance, and the operating framework more broadly. ",
    "url": "https://arxiv.org/abs/2303.08016",
    "authors": [
      "Anna Leontjeva",
      "Genevieve Richards",
      "Kaavya Sriskandaraja",
      "Jessica Perchman",
      "Luiz Pizzato"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08017",
    "title": "Reliable Beamforming at Terahertz Bands: Are Causal Representations the  Way Forward?",
    "abstract": "Future wireless services, such as the metaverse require high information rate, reliability, and low latency. Multi-user wireless systems can meet such requirements by utilizing the abundant terahertz bandwidth with a massive number of antennas, creating narrow beamforming solutions. However, existing solutions lack proper modeling of channel dynamics, resulting in inaccurate beamforming solutions in high-mobility scenarios. Herein, a dynamic, semantically aware beamforming solution is proposed for the first time, utilizing novel artificial intelligence algorithms in variational causal inference to compute the time-varying dynamics of the causal representation of multi-modal data and the beamforming. Simulations show that the proposed causality-guided approach for Terahertz (THz) beamforming outperforms classical MIMO beamforming techniques. ",
    "url": "https://arxiv.org/abs/2303.08017",
    "authors": [
      "Christo Kurisummoottil Thomas",
      "Walid Saad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.08028",
    "title": "EdgeServe: An Execution Layer for Decentralized Prediction",
    "abstract": "The relevant features for a machine learning task may be aggregated from data sources collected on different nodes in a network. This problem, which we call decentralized prediction, creates a number of interesting systems challenges in managing data routing, placing computation, and time-synchronization. This paper presents EdgeServe, a machine learning system that can serve decentralized predictions. EdgeServe relies on a low-latency message broker to route data through a network to nodes that can serve predictions. EdgeServe relies on a series of novel optimizations that can tradeoff computation, communication, and accuracy. We evaluate EdgeServe on three decentralized prediction tasks: (1) multi-camera object tracking, (2) network intrusion detection, and (3) human activity recognition. ",
    "url": "https://arxiv.org/abs/2303.08028",
    "authors": [
      "Ted Shaowang",
      "Sanjay Krishnan"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08029",
    "title": "Class-level Multiple Distributions Representation are Necessary for  Semantic Segmentation",
    "abstract": "Existing approaches focus on using class-level features to improve semantic segmentation performance. How to characterize the relationships of intra-class pixels and inter-class pixels is the key to extract the discriminative representative class-level features. In this paper, we introduce for the first time to describe intra-class variations by multiple distributions. Then, multiple distributions representation learning(\\textbf{MDRL}) is proposed to augment the pixel representations for semantic segmentation. Meanwhile, we design a class multiple distributions consistency strategy to construct discriminative multiple distribution representations of embedded pixels. Moreover, we put forward a multiple distribution semantic aggregation module to aggregate multiple distributions of the corresponding class to enhance pixel semantic information. Our approach can be seamlessly integrated into popular segmentation frameworks FCN/PSPNet/CCNet and achieve 5.61\\%/1.75\\%/0.75\\% mIoU improvements on ADE20K. Extensive experiments on the Cityscapes, ADE20K datasets have proved that our method can bring significant performance improvement. ",
    "url": "https://arxiv.org/abs/2303.08029",
    "authors": [
      "Jianjian Yin",
      "Zhichao Zheng",
      "Yanhui Gu",
      "Junsheng Zhou",
      "Yi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08032",
    "title": "BODEGA: Benchmark for Adversarial Example Generation in Credibility  Assessment",
    "abstract": "Text classification methods have been widely investigated as a way to detect content of low credibility: fake news, social media bots, propaganda, etc. Quite accurate models (likely based on deep neural networks) help in moderating public electronic platforms and often cause content creators to face rejection of their submissions or removal of already published texts. Having the incentive to evade further detection, content creators try to come up with a slightly modified version of the text (known as an attack with an adversarial example) that exploit the weaknesses of classifiers and result in a different output. Here we introduce BODEGA: a benchmark for testing both victim models and attack methods on four misinformation detection tasks in an evaluation framework designed to simulate real use-cases of content moderation. We also systematically test the robustness of popular text classifiers against available attacking techniques and discover that, indeed, in some cases barely significant changes in input text can mislead the models. We openly share the BODEGA code and data in hope of enhancing the comparability and replicability of further research in this area. ",
    "url": "https://arxiv.org/abs/2303.08032",
    "authors": [
      "Piotr Przyby\u0142a",
      "Alexander Shvets",
      "Horacio Saggion"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08033",
    "title": "Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions  about Code",
    "abstract": "We analyzed effectiveness of three generative pre-trained transformer (GPT) models in answering multiple-choice question (MCQ) assessments, often involving short snippets of code, from introductory and intermediate programming courses at the postsecondary level. This emerging technology stirs countless discussions of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming education (e.g., cheating). However, the capabilities of GPT models and their limitations to reason about and/or analyze code in educational settings have been under-explored. We evaluated several OpenAI's GPT models on formative and summative MCQ assessments from three Python courses (530 questions). We found that MCQs containing code snippets are not answered as successfully as those that only contain natural language. While questions requiring to fill-in a blank in the code or completing a natural language statement about the snippet are handled rather successfully, MCQs that require analysis and/or reasoning about the code (e.g., what is true/false about the snippet, or what is its output) appear to be the most challenging. These findings can be leveraged by educators to adapt their instructional practices and assessments in programming courses, so that GPT becomes a valuable assistant for a learner as opposed to a source of confusion and/or potential hindrance in the learning process. ",
    "url": "https://arxiv.org/abs/2303.08033",
    "authors": [
      "Jaromir Savelka",
      "Arav Agarwal",
      "Christopher Bogart",
      "Majd Sakr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08035",
    "title": "ISimDL: Importance Sampling-Driven Acceleration of Fault Injection  Simulations for Evaluating the Robustness of Deep Learning",
    "abstract": "Deep Learning (DL) systems have proliferated in many applications, requiring specialized hardware accelerators and chips. In the nano-era, devices have become increasingly more susceptible to permanent and transient faults. Therefore, we need an efficient methodology for analyzing the resilience of advanced DL systems against such faults, and understand how the faults in neural accelerator chips manifest as errors at the DL application level, where faults can lead to undetectable and unrecoverable errors. Using fault injection, we can perform resilience investigations of the DL system by modifying neuron weights and outputs at the software-level, as if the hardware had been affected by a transient fault. Existing fault models reduce the search space, allowing faster analysis, but requiring a-priori knowledge on the model, and not allowing further analysis of the filtered-out search space. Therefore, we propose ISimDL, a novel methodology that employs neuron sensitivity to generate importance sampling-based fault-scenarios. Without any a-priori knowledge of the model-under-test, ISimDL provides an equivalent reduction of the search space as existing works, while allowing long simulations to cover all the possible faults, improving on existing model requirements. Our experiments show that the importance sampling provides up to 15x higher precision in selecting critical faults than the random uniform sampling, reaching such precision in less than 100 faults. Additionally, we showcase another practical use-case for importance sampling for reliable DNN design, namely Fault Aware Training (FAT). By using ISimDL to select the faults leading to errors, we can insert the faults during the DNN training process to harden the DNN against such faults. Using importance sampling in FAT reduces the overhead required for finding faults that lead to a predetermined drop in accuracy by more than 12x. ",
    "url": "https://arxiv.org/abs/2303.08035",
    "authors": [
      "Alessio Colucci",
      "Andreas Steininger",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08039",
    "title": "TQ-Net: Mixed Contrastive Representation Learning For Heterogeneous Test  Questions",
    "abstract": "Recently, more and more people study online for the convenience of access to massive learning materials (e.g. test questions/notes), thus accurately understanding learning materials became a crucial issue, which is essential for many educational applications. Previous studies focus on using language models to represent the question data. However, test questions (TQ) are usually heterogeneous and multi-modal, e.g., some of them may only contain text, while others half contain images with information beyond their literal description. In this context, both supervised and unsupervised methods are difficult to learn a fused representation of questions. Meanwhile, this problem cannot be solved by conventional methods such as image caption, as the images may contain information complementary rather than duplicate to the text. In this paper, we first improve previous text-only representation with a two-stage unsupervised instance level contrastive based pre-training method (MCL: Mixture Unsupervised Contrastive Learning). Then, TQ-Net was proposed to fuse the content of images to the representation of heterogeneous data. Finally, supervised contrastive learning was conducted on relevance prediction-related downstream tasks, which helped the model to learn the representation of questions effectively. We conducted extensive experiments on question-based tasks on large-scale, real-world datasets, which demonstrated the effectiveness of TQ-Net and improve the precision of downstream applications (e.g. similar questions +2.02% and knowledge point prediction +7.20%). Our code will be available, and we will open-source a subset of our data to promote the development of relative studies. ",
    "url": "https://arxiv.org/abs/2303.08039",
    "authors": [
      "He Zhu",
      "Xihua Li",
      "Xuemin Zhao",
      "Yunbo Cao",
      "Shan Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08060",
    "title": "Beyond Games: A Systematic Review of Neural Monte Carlo Tree Search  Applications",
    "abstract": "The advent of AlphaGo and its successors marked the beginning of a new paradigm in playing games using artificial intelligence. This was achieved by combining Monte Carlo tree search, a planning procedure, and deep learning. While the impact on the domain of games has been undeniable, it is less clear how useful similar approaches are in applications beyond games and how they need to be adapted from the original methodology. We review 129 peer-reviewed articles detailing the application of neural Monte Carlo tree search methods in domains other than games. Our goal is to systematically assess how such methods are structured in practice and if their success can be extended to other domains. We find applications in a variety of domains, many distinct ways of guiding the tree search using learned policy and value functions, and various training methods. Our review maps the current landscape of algorithms in the family of neural monte carlo tree search as they are applied to practical problems, which is a first step towards a more principled way of designing such algorithms for specific problems and their requirements. ",
    "url": "https://arxiv.org/abs/2303.08060",
    "authors": [
      "Marco Kemmerling",
      "Daniel L\u00fctticke",
      "Robert H. Schmitt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.08064",
    "title": "Online Neural Path Guiding with Normalized Anisotropic Spherical  Gaussians",
    "abstract": "The variance reduction speed of physically-based rendering is heavily affected by the adopted importance sampling technique. In this paper we propose a novel online framework to learn the spatial-varying density model with a single small neural network using stochastic ray samples. To achieve this task, we propose a novel closed-form density model called the normalized anisotropic spherical gaussian mixture, that can express complex irradiance fields with a small number of parameters. Our framework learns the distribution in a progressive manner and does not need any warm-up phases. Due to the compact and expressive representation of our density model, our framework can be implemented entirely on the GPU, allowing it produce high quality images with limited computational resources. ",
    "url": "https://arxiv.org/abs/2303.08064",
    "authors": [
      "Jiawei Huang",
      "Akito Iizuka",
      "Hajime Tanaka",
      "Taku Komura",
      "Yoshifumi Kitamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.08109",
    "title": "Vision-based route following by an embodied insect-inspired sparse  neural network",
    "abstract": "We compared the efficiency of the FlyHash model, an insect-inspired sparse neural network (Dasgupta et al., 2017), to similar but non-sparse models in an embodied navigation task. This requires a model to control steering by comparing current visual inputs to memories stored along a training route. We concluded the FlyHash model is more efficient than others, especially in terms of data encoding. ",
    "url": "https://arxiv.org/abs/2303.08109",
    "authors": [
      "Lu Yihe",
      "Rana Alkhoury Maroun",
      "Barbara Webb"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.08120",
    "title": "Blind Video Deflickering by Neural Filtering with a Flawed Atlas",
    "abstract": "Many videos contain flickering artifacts. Common causes of flicker include video processing algorithms, video generation algorithms, and capturing videos under specific situations. Prior work usually requires specific guidance such as the flickering frequency, manual annotations, or extra consistent videos to remove the flicker. In this work, we propose a general flicker removal framework that only receives a single flickering video as input without additional guidance. Since it is blind to a specific flickering type or guidance, we name this \"blind deflickering.\" The core of our approach is utilizing the neural atlas in cooperation with a neural filtering strategy. The neural atlas is a unified representation for all frames in a video that provides temporal consistency guidance but is flawed in many cases. To this end, a neural network is trained to mimic a filter to learn the consistent features (e.g., color, brightness) and avoid introducing the artifacts in the atlas. To validate our method, we construct a dataset that contains diverse real-world flickering videos. Extensive experiments show that our method achieves satisfying deflickering performance and even outperforms baselines that use extra guidance on a public benchmark. ",
    "url": "https://arxiv.org/abs/2303.08120",
    "authors": [
      "Chenyang Lei",
      "Xuanchi Ren",
      "Zhaoxiang Zhang",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08129",
    "title": "PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D  Object Detection",
    "abstract": "Masked Autoencoders learn strong visual representations and achieve state-of-the-art results in several independent modalities, yet very few works have addressed their capabilities in multi-modality settings. In this work, we focus on point cloud and RGB image data, two modalities that are often presented together in the real world, and explore their meaningful interactions. To improve upon the cross-modal synergy in existing works, we propose PiMAE, a self-supervised pre-training framework that promotes 3D and 2D interaction through three aspects. Specifically, we first notice the importance of masking strategies between the two sources and utilize a projection module to complementarily align the mask and visible tokens of the two modalities. Then, we utilize a well-crafted two-branch MAE pipeline with a novel shared decoder to promote cross-modality interaction in the mask tokens. Finally, we design a unique cross-modal reconstruction module to enhance representation learning for both modalities. Through extensive experiments performed on large-scale RGB-D scene understanding benchmarks (SUN RGB-D and ScannetV2), we discover it is nontrivial to interactively learn point-image features, where we greatly improve multiple 3D detectors, 2D detectors, and few-shot classifiers by 2.9%, 6.7%, and 2.4%, respectively. Code is available at https://github.com/BLVLab/PiMAE. ",
    "url": "https://arxiv.org/abs/2303.08129",
    "authors": [
      "Anthony Chen",
      "Kevin Zhang",
      "Renrui Zhang",
      "Zihan Wang",
      "Yuheng Lu",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.08131",
    "title": "A Simple Framework for Open-Vocabulary Segmentation and Detection",
    "abstract": "We present \\ourmodel{}, a simple Open-vocabulary Segmentation and Detection framework that jointly learns from different segmentation and detection datasets. To bridge the gap of vocabulary and annotation granularity, we first introduce a pre-trained text encoder to encode all the visual concepts in two tasks and learn a common semantic space for them. This gives us reasonably good results compared with the counterparts trained on segmentation task only. To further reconcile them, we locate two discrepancies: $i$) task discrepancy -- segmentation requires extracting masks for both foreground objects and background stuff, while detection merely cares about the former; $ii$) data discrepancy -- box and mask annotations are with different spatial granularity, and thus not directly interchangeable. To address these issues, we propose a decoupled decoding to reduce the interference between foreground/background and a conditioned mask decoding to assist in generating masks for given boxes. To this end, we develop a simple encoder-decoder model encompassing all three techniques and train it jointly on COCO and Objects365. After pre-training, our model exhibits competitive or stronger zero-shot transferability for both segmentation and detection. Specifically, \\ourmodel{} beats the state-of-the-art method for open-vocabulary instance and panoptic segmentation across 5 datasets, and outperforms previous work for open-vocabulary detection on LVIS and ODinW under similar settings. When transferred to specific tasks, our model achieves new SoTA for panoptic segmentation on COCO and ADE20K, and instance segmentation on ADE20K and Cityscapes. Finally, we note that \\ourmodel{} is the first to explore the potential of joint training on segmentation and detection, and hope it can be received as a strong baseline for developing a single model for both tasks in open world. ",
    "url": "https://arxiv.org/abs/2303.08131",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Xueyan Zou",
      "Shilong Liu",
      "Chunyuan Li",
      "Jianfeng Gao",
      "Jianwei Yang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08134",
    "title": "Parameter is Not All You Need: Starting from Non-Parametric Networks for  3D Point Cloud Analysis",
    "abstract": "We present a Non-parametric Network for 3D point cloud analysis, Point-NN, which consists of purely non-learnable components: farthest point sampling (FPS), k-nearest neighbors (k-NN), and pooling operations, with trigonometric functions. Surprisingly, it performs well on various 3D tasks, requiring no parameters or training, and even surpasses existing fully trained models. Starting from this basic non-parametric model, we propose two extensions. First, Point-NN can serve as a base architectural framework to construct Parametric Networks by simply inserting linear layers on top. Given the superior non-parametric foundation, the derived Point-PN exhibits a high performance-efficiency trade-off with only a few learnable parameters. Second, Point-NN can be regarded as a plug-and-play module for the already trained 3D models during inference. Point-NN captures the complementary geometric knowledge and enhances existing methods for different 3D benchmarks without re-training. We hope our work may cast a light on the community for understanding 3D point clouds with non-parametric methods. Code is available at https://github.com/ZrrSkywalker/Point-NN. ",
    "url": "https://arxiv.org/abs/2303.08134",
    "authors": [
      "Renrui Zhang",
      "Liuhui Wang",
      "Yali Wang",
      "Peng Gao",
      "Hongsheng Li",
      "Jianbo Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07392",
    "title": "Efficient Bayesian Physics Informed Neural Networks for Inverse Problems  via Ensemble Kalman Inversion",
    "abstract": "Bayesian Physics Informed Neural Networks (B-PINNs) have gained significant attention for inferring physical parameters and learning the forward solutions for problems based on partial differential equations. However, the overparameterized nature of neural networks poses a computational challenge for high-dimensional posterior inference. Existing inference approaches, such as particle-based or variance inference methods, are either computationally expensive for high-dimensional posterior inference or provide unsatisfactory uncertainty estimates. In this paper, we present a new efficient inference algorithm for B-PINNs that uses Ensemble Kalman Inversion (EKI) for high-dimensional inference tasks. We find that our proposed method can achieve inference results with informative uncertainty estimates comparable to Hamiltonian Monte Carlo (HMC)-based B-PINNs with a much reduced computational cost. These findings suggest that our proposed approach has great potential for uncertainty quantification in physics-informed machine learning for practical applications. ",
    "url": "https://arxiv.org/abs/2303.07392",
    "authors": [
      "Andrew Pensoneault",
      "Xueyu Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07428",
    "title": "TransNetR: Transformer-based Residual Network for Polyp Segmentation  with Multi-Center Out-of-Distribution Testing",
    "abstract": "Colonoscopy is considered the most effective screening test to detect colorectal cancer (CRC) and its precursor lesions, i.e., polyps. However, the procedure experiences high miss rates due to polyp heterogeneity and inter-observer dependency. Hence, several deep learning powered systems have been proposed considering the criticality of polyp detection and segmentation in clinical practices. Despite achieving improved outcomes, the existing automated approaches are inefficient in attaining real-time processing speed. Moreover, they suffer from a significant performance drop when evaluated on inter-patient data, especially those collected from different centers. Therefore, we intend to develop a novel real-time deep learning based architecture, Transformer based Residual network (TransNetR), for colon polyp segmentation and evaluate its diagnostic performance. The proposed architecture, TransNetR, is an encoder-decoder network that consists of a pre-trained ResNet50 as the encoder, three decoder blocks, and an upsampling layer at the end of the network. TransNetR obtains a high dice coefficient of 0.8706 and a mean Intersection over union of 0.8016 and retains a real-time processing speed of 54.60 on the Kvasir-SEG dataset. Apart from this, the major contribution of the work lies in exploring the generalizability of the TransNetR by testing the proposed algorithm on the out-of-distribution (test distribution is unknown and different from training distribution) dataset. As a use case, we tested our proposed algorithm on the PolypGen (6 unique centers) dataset and two other popular polyp segmentation benchmarking datasets. We obtained state-of-the-art performance on all three datasets during out-of-distribution testing. The source code of TransNetR will be made publicly available at https://github.com/DebeshJha. ",
    "url": "https://arxiv.org/abs/2303.07428",
    "authors": [
      "Debesh Jha",
      "Nikhil Kumar Tomar",
      "Vanshali Sharma",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07458",
    "title": "Online Binaural Speech Separation of Moving Speakers With a Wavesplit  Network",
    "abstract": "Binaural speech separation in real-world scenarios often involves moving speakers. Most current speech separation methods use utterance-level permutation invariant training (u-PIT) for training. In inference time, however, the order of outputs can be inconsistent over time particularly in long-form speech separation. This situation which is referred to as the speaker swap problem is even more problematic when speakers constantly move in space and therefore poses a challenge for consistent placement of speakers in output channels. Here, we describe a real-time binaural speech separation model based on a Wavesplit network to mitigate the speaker swap problem for moving speaker separation. Our model computes a speaker embedding for each speaker at each time frame from the mixed audio, aggregates embeddings using online clustering, and uses cluster centroids as speaker profiles to track each speaker throughout the long duration. Experimental results on reverberant, long-form moving multitalker speech separation show that the proposed method is less prone to speaker swap and achieves comparable performance with u-PIT based models with ground truth tracking in both separation accuracy and preserving the interaural cues. ",
    "url": "https://arxiv.org/abs/2303.07458",
    "authors": [
      "Cong Han",
      "Nima Mesgarani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.07486",
    "title": "Guided Speech Enhancement Network",
    "abstract": "High quality speech capture has been widely studied for both voice communication and human computer interface reasons. To improve the capture performance, we can often find multi-microphone speech enhancement techniques deployed on various devices. Multi-microphone speech enhancement problem is often decomposed into two decoupled steps: a beamformer that provides spatial filtering and a single-channel speech enhancement model that cleans up the beamformer output. In this work, we propose a speech enhancement solution that takes both the raw microphone and beamformer outputs as the input for an ML model. We devise a simple yet effective training scheme that allows the model to learn from the cues of the beamformer by contrasting the two inputs and greatly boost its capability in spatial rejection, while conducting the general tasks of denoising and dereverberation. The proposed solution takes advantage of classical spatial filtering algorithms instead of competing with them. By design, the beamformer module then could be selected separately and does not require a large amount of data to be optimized for a given form factor, and the network model can be considered as a standalone module which is highly transferable independently from the microphone array. We name the ML module in our solution as GSENet, short for Guided Speech Enhancement Network. We demonstrate its effectiveness on real world data collected on multi-microphone devices in terms of the suppression of noise and interfering speech. ",
    "url": "https://arxiv.org/abs/2303.07486",
    "authors": [
      "Yang Yang",
      "Shao-Fu Shih",
      "Hakan Erdogan",
      "Jamie Menjay Lin",
      "Chehung Lee",
      "Yunpeng Li",
      "George Sung",
      "Matthias Grundmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.07524",
    "title": "Integration of storage endpoints into a Rucio data lake, as an activity  to prototype a SKA Regional Centres Network",
    "abstract": "The Square Kilometre Array (SKA) infrastructure will consist of two radio telescopes that will be the most sensitive telescopes on Earth. The SKA community will have to process and manage near exascale data, which will be a technical challenge for the coming years. In this respect, the SKA Global Network of Regional Centres plays a key role in data distribution and management. The SRCNet will provide distributed computing and data storage capacity, as well as other important services for the network. Within the SRCNet, several teams have been set up for the research, design and development of 5 prototypes. One of these prototypes is related to data management and distribution, where a data lake has been deployed using Rucio. In this paper we focus on the tasks performed by several of the teams to deploy new storage endpoints within the SKAO data lake. In particular, we will describe the steps and deployment instructions for the services required to provide the Rucio data lake with a new Rucio Storage Element based on StoRM and WebDAV within the Spanish SRC prototype. ",
    "url": "https://arxiv.org/abs/2303.07524",
    "authors": [
      "Manuel Parra-Roy\u00f3n",
      "Jes\u00fas S\u00e1nchez-Casta\u00f1eda",
      "Juli\u00e1n Garrido",
      "Susana S\u00e1nchez-Exp\u00f3sito",
      "Rohini Joshi",
      "James Collinson",
      "Rob Barnsley",
      "Jes\u00fas Salgado",
      "Lourdes Verdes-Montenegro"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.07592",
    "title": "Lightweight feature encoder for wake-up word detection based on  self-supervised speech representation",
    "abstract": "Self-supervised learning method that provides generalized speech representations has recently received increasing attention. Wav2vec 2.0 is the most famous example, showing remarkable performance in numerous downstream speech processing tasks. Despite its success, it is challenging to use it directly for wake-up word detection on mobile devices due to its expensive computational cost. In this work, we propose LiteFEW, a lightweight feature encoder for wake-up word detection that preserves the inherent ability of wav2vec 2.0 with a minimum scale. In the method, the knowledge of the pre-trained wav2vec 2.0 is compressed by introducing an auto-encoder-based dimensionality reduction technique and distilled to LiteFEW. Experimental results on the open-source \"Hey Snips\" dataset show that the proposed method applied to various model structures significantly improves the performance, achieving over 20% of relative improvements with only 64k parameters. ",
    "url": "https://arxiv.org/abs/2303.07592",
    "authors": [
      "Hyungjun Lim",
      "Younggwan Kim",
      "Kiho Yeom",
      "Eunjoo Seo",
      "Hoodong Lee",
      "Stanley Jungkyu Choi",
      "Honglak Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.07621",
    "title": "Two-stage Neural Network for ICASSP 2023 Speech Signal Improvement  Challenge",
    "abstract": "In ICASSP 2023 speech signal improvement challenge, we developed a dual-stage neural model which improves speech signal quality induced by different distortions in a stage-wise divide-and-conquer fashion. Specifically, in the first stage, the speech improvement network focuses on recovering the missing components of the spectrum, while in the second stage, our model aims to further suppress noise, reverberation, and artifacts introduced by the first-stage model. Achieving 0.446 in the final score and 0.517 in the P.835 score, our system ranks 4th in the non-real-time track. ",
    "url": "https://arxiv.org/abs/2303.07621",
    "authors": [
      "Mingshuai Liu",
      "Shubo Lv",
      "Zihan Zhang",
      "Runduo Han",
      "Xiang Hao",
      "Xianjun Xia",
      "Li Chen",
      "Yijian Xiao",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.07739",
    "title": "Detecting post-stroke aphasia using EEG-based neural envelope tracking  of natural speech",
    "abstract": "[Objective]. After a stroke, one-third of patients suffer from aphasia, a language disorder that impairs communication ability. The standard behavioral tests used to diagnose aphasia are time-consuming and have low ecological validity. Neural tracking of the speech envelope is a promising tool for investigating brain responses to natural speech. The speech envelope is crucial for speech understanding, encompassing cues for processing linguistic units. In this study, we aimed to test the potential of the neural envelope tracking technique for detecting language impairments in individuals with aphasia (IWA). [Approach]. We recorded EEG from 27 IWA in the chronic phase after stroke and 22 controls while they listened to a story. We quantified neural envelope tracking in a broadband frequency range as well as in the delta, theta, alpha, beta, and gamma frequency bands using mutual information analysis. Besides group differences in neural tracking measures, we also tested its suitability for detecting aphasia using a Support Vector Machine (SVM) classifier. We further investigated the required recording length for the SVM to detect aphasia and to obtain reliable outcomes. [Results]. IWA displayed decreased neural envelope tracking compared to controls in the broad, delta, theta, and gamma band. Neural tracking in these frequency bands effectively captured aphasia at the individual level (SVM accuracy 84%, AUC 88%). High-accuracy and reliable detection could be obtained with 5-7 minutes of recording time. [Significance]. Our study shows that neural tracking of speech is an effective biomarker for aphasia. We demonstrated its potential as a diagnostic tool with high reliability, individual-level detection of aphasia, and time-efficient assessment. This work represents a significant step towards more automatic, objective, and ecologically valid assessments of language impairments in aphasia. ",
    "url": "https://arxiv.org/abs/2303.07739",
    "authors": [
      "Pieter De Clercq",
      "Jill Kries",
      "Ramtin Mehraram",
      "Jonas Vanthornhout",
      "Tom Francart",
      "Maaike Vandermosten"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.07830",
    "title": "Emergent Bio-Functional Similarities in a Cortical-Spike-Train-Decoding  Spiking Neural Network Facilitate Predictions of Neural Computation",
    "abstract": "Despite its better bio-plausibility, goal-driven spiking neural network (SNN) has not achieved applicable performance for classifying biological spike trains, and showed little bio-functional similarities compared to traditional artificial neural networks. In this study, we proposed the motorSRNN, a recurrent SNN topologically inspired by the neural motor circuit of primates. By employing the motorSRNN in decoding spike trains from the primary motor cortex of monkeys, we achieved a good balance between classification accuracy and energy consumption. The motorSRNN communicated with the input by capturing and cultivating more cosine-tuning, an essential property of neurons in the motor cortex, and maintained its stability during training. Such training-induced cultivation and persistency of cosine-tuning was also observed in our monkeys. Moreover, the motorSRNN produced additional bio-functional similarities at the single-neuron, population, and circuit levels, demonstrating biological authenticity. Thereby, ablation studies on motorSRNN have suggested long-term stable feedback synapses contribute to the training-induced cultivation in the motor cortex. Besides these novel findings and predictions, we offer a new framework for building authentic models of neural computation. ",
    "url": "https://arxiv.org/abs/2303.07830",
    "authors": [
      "Tengjun Liu",
      "Yansong Chua",
      "Yiwei Zhang",
      "Yuxiao Ning",
      "Pengfu Liu",
      "Guihua Wan",
      "Zijun Wan",
      "Shaomin Zhang",
      "Weidong Chen"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.07852",
    "title": "FPUS23: An Ultrasound Fetus Phantom Dataset with Deep Neural Network  Evaluations for Fetus Orientations, Fetal Planes, and Anatomical Features",
    "abstract": "Ultrasound imaging is one of the most prominent technologies to evaluate the growth, progression, and overall health of a fetus during its gestation. However, the interpretation of the data obtained from such studies is best left to expert physicians and technicians who are trained and well-versed in analyzing such images. To improve the clinical workflow and potentially develop an at-home ultrasound-based fetal monitoring platform, we present a novel fetus phantom ultrasound dataset, FPUS23, which can be used to identify (1) the correct diagnostic planes for estimating fetal biometric values, (2) fetus orientation, (3) their anatomical features, and (4) bounding boxes of the fetus phantom anatomies at 23 weeks gestation. The entire dataset is composed of 15,728 images, which are used to train four different Deep Neural Network models, built upon a ResNet34 backbone, for detecting aforementioned fetus features and use-cases. We have also evaluated the models trained using our FPUS23 dataset, to show that the information learned by these models can be used to substantially increase the accuracy on real-world ultrasound fetus datasets. We make the FPUS23 dataset and the pre-trained models publicly accessible at https://github.com/bharathprabakaran/FPUS23, which will further facilitate future research on fetal ultrasound imaging and analysis. ",
    "url": "https://arxiv.org/abs/2303.07852",
    "authors": [
      "Bharath Srinivas Prabakaran",
      "Paul Hamelmann",
      "Erik Ostrowski",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08005",
    "title": "Native Multi-Band Audio Coding within Hyper-Autoencoded Reconstruction  Propagation Networks",
    "abstract": "Spectral sub-bands do not portray the same perceptual relevance. In audio coding, it is therefore desirable to have independent control over each of the constituent bands so that bitrate assignment and signal reconstruction can be achieved efficiently. In this work, we present a novel neural audio coding network that natively supports a multi-band coding paradigm. Our model extends the idea of compressed skip connections in the U-Net-based codec, allowing for independent control over both core and high band-specific reconstructions and bit allocation. Our system reconstructs the full-band signal mainly from the condensed core-band code, therefore exploiting and showcasing its bandwidth extension capabilities to its fullest. Meanwhile, the low-bitrate high-band code helps the high-band reconstruction similarly to MPEG audio codecs' spectral bandwidth replication. MUSHRA tests show that the proposed model not only improves the quality of the core band by explicitly assigning more bits to it but retains a good quality in the high-band as well. ",
    "url": "https://arxiv.org/abs/2303.08005",
    "authors": [
      "Darius Petermann",
      "Inseon Jang",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.08019",
    "title": "Leveraging Pretrained Representations with Task-related Keywords for  Alzheimer's Disease Detection",
    "abstract": "With the global population aging rapidly, Alzheimer's disease (AD) is particularly prominent in older adults, which has an insidious onset and leads to a gradual, irreversible deterioration in cognitive domains (memory, communication, etc.). Speech-based AD detection opens up the possibility of widespread screening and timely disease intervention. Recent advances in pre-trained models motivate AD detection modeling to shift from low-level features to high-level representations. This paper presents several efficient methods to extract better AD-related cues from high-level acoustic and linguistic features. Based on these features, the paper also proposes a novel task-oriented approach by modeling the relationship between the participants' description and the cognitive task. Experiments are carried out on the ADReSS dataset in a binary classification setup, and models are evaluated on the unseen test set. Results and comparison with recent literature demonstrate the efficiency and superior performance of proposed acoustic, linguistic and task-oriented methods. The findings also show the importance of semantic and syntactic information, and feasibility of automation and generalization with the promising audio-only and task-oriented methods for the AD detection task. ",
    "url": "https://arxiv.org/abs/2303.08019",
    "authors": [
      "Jinchao Li",
      "Kaitao Song",
      "Junan Li",
      "Bo Zheng",
      "Dongsheng Li",
      "Xixin Wu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.08046",
    "title": "Ultra-High-Resolution Detector Simulation with Intra-Event Aware GAN and  Self-Supervised Relational Reasoning",
    "abstract": "Simulating high-resolution detector responses is a storage-costly and computationally intensive process that has long been challenging in particle physics. Despite the ability of deep generative models to make this process more cost-efficient, ultra-high-resolution detector simulation still proves to be difficult as it contains correlated and fine-grained mutual information within an event. To overcome these limitations, we propose Intra-Event Aware GAN (IEA-GAN), a novel fusion of Self-Supervised Learning and Generative Adversarial Networks. IEA-GAN presents a Relational Reasoning Module that approximates the concept of an ''event'' in detector simulation, allowing for the generation of correlated layer-dependent contextualized images for high-resolution detector responses with a proper relational inductive bias. IEA-GAN also introduces a new intra-event aware loss and a Uniformity loss, resulting in significant enhancements to image fidelity and diversity. We demonstrate IEA-GAN's application in generating sensor-dependent images for the high-granularity Pixel Vertex Detector (PXD), with more than 7.5M information channels and a non-trivial geometry, at the Belle II Experiment. Applications of this work include controllable simulation-based inference and event generation, high-granularity detector simulation such as at the HL-LHC (High Luminosity LHC), and fine-grained density estimation and sampling. To the best of our knowledge, IEA-GAN is the first algorithm for faithful ultra-high-resolution detector simulation with event-based reasoning. ",
    "url": "https://arxiv.org/abs/2303.08046",
    "authors": [
      "Hosein Hashemi",
      "Nikolai Hartmann",
      "Sahand Sharifzadeh",
      "James Kahn",
      "Thomas Kuhr"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2303.08052",
    "title": "Localizing Spatial Information in Neural Spatiospectral Filters",
    "abstract": "Beamforming for multichannel speech enhancement relies on the estimation of spatial characteristics of the acoustic scene. In its simplest form, the delay-and-sum beamformer (DSB) introduces a time delay to all channels to align the desired signal components for constructive superposition. Recent investigations of neural spatiospectral filtering revealed that these filters can be characterized by a beampattern similar to one of traditional beamformers, which shows that artificial neural networks can learn and explicitly represent spatial structure. Using the Complex-valued Spatial Autoencoder (COSPA) as an exemplary neural spatiospectral filter for multichannel speech enhancement, we investigate where and how such networks represent spatial information. We show via clustering that for COSPA the spatial information is represented by the features generated by a gated recurrent unit (GRU) layer that has access to all channels simultaneously and that these features are not source -- but only direction of arrival-dependent. ",
    "url": "https://arxiv.org/abs/2303.08052",
    "authors": [
      "Annika Briegleb",
      "Thomas Haubner",
      "Vasileios Belagiannis",
      "Walter Kellermann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.08107",
    "title": "Linking social network structure and function to social preferences",
    "abstract": "Social network structures play an important role in the lives of humans and non-human animals by affecting wellbeing, the spread of disease and information, and evolutionary processes. Nevertheless, we still lack a good understanding of how these structures emerge from individual behaviour. Here we present a general model for the emergence of social structures, which is based on a key aspect of real social systems observed across species, namely social preferences for traits (individual characteristics such as age, sex, etc.). We first show that the model can generate diverse artificial social structures, and consider its potential for being combined with real network data. We then use the model to gain fundamental insights into how two main categories of social preferences (similarity and popularity) affect social structure and function. The results show that the types of social preference, in combination with the types of trait they are used with, can have important consequences for the spread of information and disease, and the robustness of social structures against fragmentation. The results also suggest that symmetric degree distributions could be expected to be common in social networks. More generally, the study implies that trait-based social preferences can have consequences for social systems that go far beyond their effect on direct benefits from social partners. We discuss the implications of the results for social evolution. ",
    "url": "https://arxiv.org/abs/2303.08107",
    "authors": [
      "Josefine Bohr Brask",
      "Andreas Koher",
      "Darren P. Croft",
      "Sune Lehmann"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2010.12669",
    "title": "Position and Rotation Invariant Sign Language Recognition from 3D Kinect  Data with Recurrent Neural Networks",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2010.12669",
    "authors": [
      "Prasun Roy",
      "Saumik Bhattacharya",
      "Partha Pratim Roy",
      "Umapada Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2101.06397",
    "title": "To Understand Representation of Layer-aware Sequence Encoders as  Multi-order-graph",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2009.07489 ",
    "url": "https://arxiv.org/abs/2101.06397",
    "authors": [
      "Sufeng Duan",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2102.07725",
    "title": "Neural Network Compression for Noisy Storage Devices",
    "abstract": " Comments: Published at the ACM Transactions on Embedded Computing Systems (TECS), 2023 ",
    "url": "https://arxiv.org/abs/2102.07725",
    "authors": [
      "Berivan Isik",
      "Kristy Choi",
      "Xin Zheng",
      "Tsachy Weissman",
      "Stefano Ermon",
      "H.-S. Philip Wong",
      "Armin Alaghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.03076",
    "title": "Dynamic Efficient Adversarial Training Guided by Gradient Magnitude",
    "abstract": " Comments: 18 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2103.03076",
    "authors": [
      "Fu Wang",
      "Yanghao Zhang",
      "Yanbin Zheng",
      "Wenjie Ruan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.04831",
    "title": "Knowledge Graph Augmented Network Towards Multiview Representation  Learning for Aspect-based Sentiment Analysis",
    "abstract": " Comments: Accepted by IEEE TKDE 2023 ",
    "url": "https://arxiv.org/abs/2201.04831",
    "authors": [
      "Qihuang Zhong",
      "Liang Ding",
      "Juhua Liu",
      "Bo Du",
      "Hua Jin",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.04446",
    "title": "Self-Supervised Domain Calibration and Uncertainty Estimation for Place  Recognition",
    "abstract": " Title: Self-Supervised Domain Calibration and Uncertainty Estimation for Place  Recognition ",
    "url": "https://arxiv.org/abs/2203.04446",
    "authors": [
      "Pierre-Yves Lajoie",
      "Giovanni Beltrame"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.14360",
    "title": "Observation-Centric SORT: Rethinking SORT for Robust Multi-Object  Tracking",
    "abstract": " Comments: Accepted by CVPR 2023. 8 pages + 10 pages of appendix. Renamed OOS as Observation-centric Re-Update (ORU) ",
    "url": "https://arxiv.org/abs/2203.14360",
    "authors": [
      "Jinkun Cao",
      "Jiangmiao Pang",
      "Xinshuo Weng",
      "Rawal Khirodkar",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10852",
    "title": "Relphormer: Relational Graph Transformer for Knowledge Graph  Representations",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2205.10852",
    "authors": [
      "Zhen Bi",
      "Siyuan Cheng",
      "Jing Chen",
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Qiang Chen",
      "Feiyu Xiong",
      "Wei Guo",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07883",
    "title": "Combinatorial Pure Exploration of Causal Bandits",
    "abstract": " Title: Combinatorial Pure Exploration of Causal Bandits ",
    "url": "https://arxiv.org/abs/2206.07883",
    "authors": [
      "Nuoya Xiong",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.10696",
    "title": "Epicasting: An Ensemble Wavelet Neural Network (EWNet) for Forecasting  Epidemics",
    "abstract": " Title: Epicasting: An Ensemble Wavelet Neural Network (EWNet) for Forecasting  Epidemics ",
    "url": "https://arxiv.org/abs/2206.10696",
    "authors": [
      "Madhurima Panja",
      "Tanujit Chakraborty",
      "Uttam Kumar",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Populations and Evolution (q-bio.PE)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.03933",
    "title": "A law of adversarial risk, interpolation, and label noise",
    "abstract": " Comments: 22 pages, 8 figures. Accepted for ICLR 2023 ",
    "url": "https://arxiv.org/abs/2207.03933",
    "authors": [
      "Daniel Paleka",
      "Amartya Sanyal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11659",
    "title": "Training Robust Spiking Neural Networks on Neuromorphic Data with  Spatiotemporal Fragments",
    "abstract": " Comments: Accepted by ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2207.11659",
    "authors": [
      "Haibo Shen",
      "Yihao Luo",
      "Xiang Cao",
      "Liangqi Zhang",
      "Juyu Xiao",
      "Tianjiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.11670",
    "title": "Training Stronger Spiking Neural Networks with Biomimetic Adaptive  Internal Association Neurons",
    "abstract": " Comments: Accepted by ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2207.11670",
    "authors": [
      "Haibo Shen",
      "Yihao Luo",
      "Xiang Cao",
      "Liangqi Zhang",
      "Juyu Xiao",
      "Tianjiang Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2207.13307",
    "title": "Marker and source-marker reprogramming of Most Permissive Boolean  networks and ensembles with BoNesis",
    "abstract": " Comments: Notebook available at this https URL Peer-reviewed and recommended by Peer Community In \"Mathematical and Computational Biology\" (this https URL) ",
    "url": "https://arxiv.org/abs/2207.13307",
    "authors": [
      "Lo\u00efc Paulev\u00e9"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2209.11741",
    "title": "Adaptive-SpikeNet: Event-based Optical Flow Estimation using Spiking  Neural Networks with Learnable Neuronal Dynamics",
    "abstract": " Title: Adaptive-SpikeNet: Event-based Optical Flow Estimation using Spiking  Neural Networks with Learnable Neuronal Dynamics ",
    "url": "https://arxiv.org/abs/2209.11741",
    "authors": [
      "Adarsh Kumar Kosta",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12278",
    "title": "Neural inhibition during speech planning contributes to contrastive  hyperarticulation",
    "abstract": " Title: Neural inhibition during speech planning contributes to contrastive  hyperarticulation ",
    "url": "https://arxiv.org/abs/2209.12278",
    "authors": [
      "Michael C. Stern",
      "Jason A. Shaw"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.13388",
    "title": "Efficient Fault Detection Architecture of Bit-Parallel Multiplier in  Polynomial Basis of GF(2m) Using BCH Code",
    "abstract": " Comments: There are some errors in simulation results ",
    "url": "https://arxiv.org/abs/2209.13388",
    "authors": [
      "Saeideh Nabipour",
      "Javad Javidan",
      "Gholamreza Zare Fatin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2209.13679",
    "title": "V2XP-ASG: Generating Adversarial Scenes for Vehicle-to-Everything  Perception",
    "abstract": " Comments: ICRA 2023, see this https URL ",
    "url": "https://arxiv.org/abs/2209.13679",
    "authors": [
      "Hao Xiang",
      "Runsheng Xu",
      "Xin Xia",
      "Zhaoliang Zheng",
      "Bolei Zhou",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.09297",
    "title": "Neural Contact Fields: Tracking Extrinsic Contact with Tactile Sensing",
    "abstract": " Comments: 2023 International Conference on Robotics and Automation (ICRA) ",
    "url": "https://arxiv.org/abs/2210.09297",
    "authors": [
      "Carolina Higuera",
      "Siyuan Dong",
      "Byron Boots",
      "Mustafa Mukadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10272",
    "title": "Training set cleansing of backdoor poisoning by self-supervised  representation learning",
    "abstract": " Title: Training set cleansing of backdoor poisoning by self-supervised  representation learning ",
    "url": "https://arxiv.org/abs/2210.10272",
    "authors": [
      "H. Wang",
      "S. Karami",
      "O. Dia",
      "H. Ritter",
      "E. Emamjomeh-Zadeh",
      "J. Chen",
      "Z. Xiang",
      "D.J. Miller",
      "G. Kesidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.04610",
    "title": "PhaseAug: A Differentiable Augmentation for Speech Synthesis to Simulate  One-to-Many Mapping",
    "abstract": " Comments: Accepted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.04610",
    "authors": [
      "Junhyeok Lee",
      "Seungu Han",
      "Hyunjae Cho",
      "Wonbin Jung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.13292",
    "title": "Discovering Influencers in Opinion Formation over Social Graphs",
    "abstract": " Title: Discovering Influencers in Opinion Formation over Social Graphs ",
    "url": "https://arxiv.org/abs/2211.13292",
    "authors": [
      "Valentina Shumovskaia",
      "Mert Kayaalp",
      "Mert Cemri",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.16762",
    "title": "GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided  Distance Representation",
    "abstract": " Title: GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided  Distance Representation ",
    "url": "https://arxiv.org/abs/2211.16762",
    "authors": [
      "Siyu Ren",
      "Junhui Hou",
      "Xiaodong Chen",
      "Ying He",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00290",
    "title": "Component Segmentation of Engineering Drawings Using Graph Convolutional  Networks",
    "abstract": " Comments: Preprint accepted to Computers in Industry ",
    "url": "https://arxiv.org/abs/2212.00290",
    "authors": [
      "Wentai Zhang",
      "Joe Joseph",
      "Yue Yin",
      "Liuyue Xie",
      "Tomotake Furuhata",
      "Soji Yamakawa",
      "Kenji Shimada",
      "Levent Burak Kara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.02501",
    "title": "SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance  Fields",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2212.02501",
    "authors": [
      "Anh-Quan Cao",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.03022",
    "title": "Iterative Next Boundary Detection for Instance Segmentation of Tree  Rings in Microscopy Images of Shrub Cross Sections",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2212.03022",
    "authors": [
      "Alexander Gillert",
      "Giulia Resente",
      "Alba Anadon-Rosell",
      "Martin Wilmking",
      "Uwe Freiherr von Lukas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.12756",
    "title": "Computational Complexity of Minimal Trap Spaces in Boolean Networks",
    "abstract": " Title: Computational Complexity of Minimal Trap Spaces in Boolean Networks ",
    "url": "https://arxiv.org/abs/2212.12756",
    "authors": [
      "Kyungduk Moon",
      "Kangbok Lee",
      "Lo\u00efc Paulev\u00e9"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2212.12902",
    "title": "TexPose: Neural Texture Learning for Self-Supervised 6D Object Pose  Estimation",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2212.12902",
    "authors": [
      "Hanzhi Chen",
      "Fabian Manhardt",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00351",
    "title": "Skew Class-balanced Re-weighting for Unbiased Scene Graph Generation",
    "abstract": " Title: Skew Class-balanced Re-weighting for Unbiased Scene Graph Generation ",
    "url": "https://arxiv.org/abs/2301.00351",
    "authors": [
      "Haeyong Kang",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00503",
    "title": "A Concept Knowledge Graph for User Next Intent Prediction at Alipay",
    "abstract": " Comments: Accepted by WWW 2023 poster ",
    "url": "https://arxiv.org/abs/2301.00503",
    "authors": [
      "Yacheng He",
      "Qianghuai Jia",
      "Lin Yuan",
      "Ruopeng Li",
      "Yixin Ou",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00656",
    "title": "TriNet: stabilizing self-supervised learning from complete or slow  collapse on ASR",
    "abstract": " Comments: Accepted by ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2301.00656",
    "authors": [
      "Lixin Cao",
      "Jun Wang",
      "Ben Yang",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01970",
    "title": "CAT: LoCalization and IdentificAtion Cascade Detection Transformer for  Open-World Object Detection",
    "abstract": " Title: CAT: LoCalization and IdentificAtion Cascade Detection Transformer for  Open-World Object Detection ",
    "url": "https://arxiv.org/abs/2301.01970",
    "authors": [
      "Shuailei Ma",
      "Yuefeng Wang",
      "Jiaqi Fan",
      "Ying Wei",
      "Thomas H. Li",
      "Hongli Liu",
      "Fanbing Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.03944",
    "title": "CHRONOS: Time-Aware Zero-Shot Identification of Libraries from  Vulnerability Reports",
    "abstract": " Comments: Accepted to the Technical Track of ICSE 2023 ",
    "url": "https://arxiv.org/abs/2301.03944",
    "authors": [
      "Yunbo Lyu",
      "Thanh Le-Cong",
      "Hong Jin Kang",
      "Ratnadira Widyasari",
      "Zhipeng Zhao",
      "Xuan-Bach D. Le",
      "Ming Li",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.07074",
    "title": "SegViz: A federated-learning based framework for multi-organ  segmentation on heterogeneous data sets with partial annotations",
    "abstract": " Title: SegViz: A federated-learning based framework for multi-organ  segmentation on heterogeneous data sets with partial annotations ",
    "url": "https://arxiv.org/abs/2301.07074",
    "authors": [
      "Adway U. Kanhere",
      "Pranav Kulkarni",
      "Paul H. Yi",
      "Vishwa S. Parekh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.09667",
    "title": "Improving Performance of Object Detection using the Mechanisms of Visual  Recognition in Humans",
    "abstract": " Title: Improving Performance of Object Detection using the Mechanisms of Visual  Recognition in Humans ",
    "url": "https://arxiv.org/abs/2301.09667",
    "authors": [
      "Amir Ghasemi",
      "Nasrin Bayat",
      "Fatemeh Mottaghian",
      "Akram Bayat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12355",
    "title": "Semantics-enhanced Temporal Graph Networks for Content Popularity  Prediction",
    "abstract": " Title: Semantics-enhanced Temporal Graph Networks for Content Popularity  Prediction ",
    "url": "https://arxiv.org/abs/2301.12355",
    "authors": [
      "Jianhang Zhu",
      "Rongpeng Li",
      "Xianfu Chen",
      "Shiwen Mao",
      "Jianjun Wu",
      "Zhifeng Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.13060",
    "title": "Zero-One Laws of Graph Neural Networks",
    "abstract": " Comments: 8 pages + references + 9 pages appendices, 2 figures ",
    "url": "https://arxiv.org/abs/2301.13060",
    "authors": [
      "Sam Adam-Day",
      "Theodor Mihai Iliant",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01838",
    "title": "vMAP: Vectorised Object Mapping for Neural Field SLAM",
    "abstract": " Comments: CVPR2023 Project Page:this https URL ",
    "url": "https://arxiv.org/abs/2302.01838",
    "authors": [
      "Xin Kong",
      "Shikun Liu",
      "Marwan Taher",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02601",
    "title": "Learning Representations of Bi-level Knowledge Graphs for Reasoning  beyond Link Prediction",
    "abstract": " Comments: 14 pages, 3 figures, 15 tables. 37th AAAI Conference on Artificial Intelligence (AAAI 2023) ",
    "url": "https://arxiv.org/abs/2302.02601",
    "authors": [
      "Chanyoung Chung",
      "Joyce Jiyoung Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.03992",
    "title": "Convolutional Neural Networks Trained to Identify Words Provide a  Surprisingly Good Account of Visual Form Priming Effects",
    "abstract": " Title: Convolutional Neural Networks Trained to Identify Words Provide a  Surprisingly Good Account of Visual Form Priming Effects ",
    "url": "https://arxiv.org/abs/2302.03992",
    "authors": [
      "Dong Yin",
      "Valerio Biscione",
      "Jeffrey Bowers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.06751",
    "title": "OpenHLS: High-Level Synthesis for Low-Latency Deep Neural Networks for  Experimental Science",
    "abstract": " Title: OpenHLS: High-Level Synthesis for Low-Latency Deep Neural Networks for  Experimental Science ",
    "url": "https://arxiv.org/abs/2302.06751",
    "authors": [
      "Maksim Levental",
      "Arham Khan",
      "Ryan Chard",
      "Kazutomo Yoshii",
      "Kyle Chard",
      "Ian Foster"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.07577",
    "title": "Efficient Teacher: Semi-Supervised Object Detection for YOLOv5",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2302.07577",
    "authors": [
      "Bowen Xu",
      "Mingtao Chen",
      "Wenlong Guan",
      "Lulu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.08664",
    "title": "Socialz: Multi-Feature Social Fuzz Testing",
    "abstract": " Title: Socialz: Multi-Feature Social Fuzz Testing ",
    "url": "https://arxiv.org/abs/2302.08664",
    "authors": [
      "Francisco Zanartu",
      "Christoph Treude",
      "Markus Wagner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.10842",
    "title": "DSL-Assembly: A Robust and Safe Assembly Strategy",
    "abstract": " Comments: 4 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2302.10842",
    "authors": [
      "Yi Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.12529",
    "title": "Time-aware Multiway Adaptive Fusion Network for Temporal Knowledge Graph  Question Answering",
    "abstract": " Comments: ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2302.12529",
    "authors": [
      "Yonghao Liu",
      "Di Liang",
      "Fang Fang",
      "Sirui Wang",
      "Wei Wu",
      "Rui Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.14402",
    "title": "Neural Video Compression with Diverse Contexts",
    "abstract": " Comments: Accepted by CVPR 2023. Codes are at this https URL ",
    "url": "https://arxiv.org/abs/2302.14402",
    "authors": [
      "Jiahao Li",
      "Bin Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.00320",
    "title": "TimeMAE: Self-Supervised Representations of Time Series with Decoupled  Masked Autoencoders",
    "abstract": " Comments: Submitted to IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING(TKDE), under review ",
    "url": "https://arxiv.org/abs/2303.00320",
    "authors": [
      "Mingyue Cheng",
      "Qi Liu",
      "Zhiding Liu",
      "Hao Zhang",
      "Rujiao Zhang",
      "Enhong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.00515",
    "title": "Interpretable Water Level Forecaster with Spatiotemporal Causal  Attention Mechanisms",
    "abstract": " Title: Interpretable Water Level Forecaster with Spatiotemporal Causal  Attention Mechanisms ",
    "url": "https://arxiv.org/abs/2303.00515",
    "authors": [
      "Sunghcul Hong",
      "Yunjin Choi",
      "Jong-June Jeon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.01339",
    "title": "Sensitivity of matrix function based network communicability measures:  Computational methods and a priori bounds",
    "abstract": " Title: Sensitivity of matrix function based network communicability measures:  Computational methods and a priori bounds ",
    "url": "https://arxiv.org/abs/2303.01339",
    "authors": [
      "Marcel Schweitzer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.02489",
    "title": "CapDet: Unifying Dense Captioning and Open-World Detection Pretraining",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.02489",
    "authors": [
      "Yanxin Long",
      "Youpeng Wen",
      "Jianhua Han",
      "Hang Xu",
      "Pengzhen Ren",
      "Wei Zhang",
      "Shen Zhao",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03052",
    "title": "Masked Images Are Counterfactual Samples for Robust Fine-tuning",
    "abstract": " Comments: Accepted by CVPR 2023 (v2: improve the clarity) ",
    "url": "https://arxiv.org/abs/2303.03052",
    "authors": [
      "Yao Xiao",
      "Ziyi Tang",
      "Pengxu Wei",
      "Cong Liu",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03340",
    "title": "Symbolic Synthesis of Neural Networks",
    "abstract": " Comments: 8 pages, 1 figure. Minor formula correction and minor textual revision ",
    "url": "https://arxiv.org/abs/2303.03340",
    "authors": [
      "Eli Whitehouse"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03595",
    "title": "LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global  Cross-Modal Fusion",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.03595",
    "authors": [
      "Xin Li",
      "Tao Ma",
      "Yuenan Hou",
      "Botian Shi",
      "Yuchen Yang",
      "Youquan Liu",
      "Xingjiao Wu",
      "Qin Chen",
      "Yikang Li",
      "Yu Qiao",
      "Liang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04115",
    "title": "Predicted Embedding Power Regression for Large-Scale Out-of-Distribution  Detection",
    "abstract": " Title: Predicted Embedding Power Regression for Large-Scale Out-of-Distribution  Detection ",
    "url": "https://arxiv.org/abs/2303.04115",
    "authors": [
      "Hong Yang",
      "William Gebhardt",
      "Alexander G. Ororbia",
      "Travis Desell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04660",
    "title": "Neural Probabilistic Logic Programming in Discrete-Continuous Domains",
    "abstract": " Comments: 27 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2303.04660",
    "authors": [
      "Lennert De Smet",
      "Pedro Zuidberg Dos Martires",
      "Robin Manhaeve",
      "Giuseppe Marra",
      "Angelika Kimmig",
      "Luc De Raedt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2303.05183",
    "title": "Blind2Sound: Self-Supervised Image Denoising without Residual Noise",
    "abstract": " Title: Blind2Sound: Self-Supervised Image Denoising without Residual Noise ",
    "url": "https://arxiv.org/abs/2303.05183",
    "authors": [
      "Zejin Wang",
      "Jiazheng Liu",
      "Hao Zhai",
      "Hua Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05233",
    "title": "Dual-Attention Deep Reinforcement Learning for Multi-MAP 3D Trajectory  Optimization in Dynamic 5G Networks",
    "abstract": " Title: Dual-Attention Deep Reinforcement Learning for Multi-MAP 3D Trajectory  Optimization in Dynamic 5G Networks ",
    "url": "https://arxiv.org/abs/2303.05233",
    "authors": [
      "Esteban Catt\u00e9",
      "Mohamed Sana",
      "Mickael Maman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.05606",
    "title": "Variance-aware robust reinforcement learning with linear function  approximation under heavy-tailed rewards",
    "abstract": " Comments: 23 page main text, 42 page appendix ",
    "url": "https://arxiv.org/abs/2303.05606",
    "authors": [
      "Xiang Li",
      "Qiang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05660",
    "title": "Towards better traffic volume estimation: Tackling both underdetermined  and non-equilibrium problems via a correlation-adaptive graph convolution  network",
    "abstract": " Title: Towards better traffic volume estimation: Tackling both underdetermined  and non-equilibrium problems via a correlation-adaptive graph convolution  network ",
    "url": "https://arxiv.org/abs/2303.05660",
    "authors": [
      "Tong Nie",
      "Guoyang Qin",
      "Yunpeng Wang",
      "Jian Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05735",
    "title": "Hardware Acceleration of Neural Graphics",
    "abstract": " Title: Hardware Acceleration of Neural Graphics ",
    "url": "https://arxiv.org/abs/2303.05735",
    "authors": [
      "Muhammad Husnain Mubarik",
      "Ramakrishna Kanungo",
      "Tobias Zirr",
      "Rakesh Kumar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07122",
    "title": "Quantifying Causes of Arctic Amplification via Deep Learning based  Time-series Causal Inference",
    "abstract": " Title: Quantifying Causes of Arctic Amplification via Deep Learning based  Time-series Causal Inference ",
    "url": "https://arxiv.org/abs/2303.07122",
    "authors": [
      "Sahara Ali",
      "Omar Faruque",
      "Jianwu Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.07125",
    "title": "Don't PANIC: Prototypical Additive Neural Network for Interpretable  Classification of Alzheimer's Disease",
    "abstract": " Comments: To be published in proceedings of Information Processing In Medical Imaging 2023 ",
    "url": "https://arxiv.org/abs/2303.07125",
    "authors": [
      "Tom Nuno Wolf",
      "Sebastian P\u00f6lsterl",
      "Christian Wachinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07127",
    "title": "Improving physics-informed neural networks with meta-learned  optimization",
    "abstract": " Comments: 15 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2303.07127",
    "authors": [
      "Alex Bihlo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.07200",
    "title": "Supervised Feature Selection with Neuron Evolution in Sparse Neural  Networks",
    "abstract": " Title: Supervised Feature Selection with Neuron Evolution in Sparse Neural  Networks ",
    "url": "https://arxiv.org/abs/2303.07200",
    "authors": [
      "Zahra Atashgahi",
      "Xuhao Zhang",
      "Neil Kichler",
      "Shiwei Liu",
      "Lu Yin",
      "Mykola Pechenizkiy",
      "Raymond Veldhuis",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]