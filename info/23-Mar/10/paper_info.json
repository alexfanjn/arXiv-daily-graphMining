[
  {
    "id": "arXiv:2303.04811",
    "title": "Certifiable Robustness for Naive Bayes Classifiers",
    "abstract": "Data cleaning is crucial but often laborious in most machine learning (ML) applications. However, task-agnostic data cleaning is sometimes unnecessary if certain inconsistencies in the dirty data will not affect the prediction of ML models to the test points. A test point is certifiably robust for an ML classifier if the prediction remains the same regardless of which (among exponentially many) cleaned dataset it is trained on. In this paper, we study certifiable robustness for the Naive Bayes classifier (NBC) on dirty datasets with missing values. We present (i) a linear time algorithm in the number of entries in the dataset that decides whether a test point is certifiably robust for NBC, (ii) an algorithm that counts for each label, the number of cleaned datasets on which the NBC can be trained to predict that label, and (iii) an efficient optimal algorithm that poisons a clean dataset by inserting the minimum number of missing values such that a test point is not certifiably robust for NBC. We prove that (iv) poisoning a clean dataset such that multiple test points become certifiably non-robust is NP-hard for any dataset with at least three features. Our experiments demonstrate that our algorithms for the decision and data poisoning problems achieve up to $19.5\\times$ and $3.06\\times$ speed-up over the baseline algorithms across different real-world datasets. ",
    "url": "https://arxiv.org/abs/2303.04811",
    "authors": [
      "Song Bian",
      "Xiating Ouyang",
      "Zhiwei Fan",
      "Paraschos Koutris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2303.04835",
    "title": "The Bystander Affect Detection (BAD) Dataset for Failure Detection in  HRI",
    "abstract": "For a robot to repair its own error, it must first know it has made a mistake. One way that people detect errors is from the implicit reactions from bystanders -- their confusion, smirks, or giggles clue us in that something unexpected occurred. To enable robots to detect and act on bystander responses to task failures, we developed a novel method to elicit bystander responses to human and robot errors. Using 46 different stimulus videos featuring a variety of human and machine task failures, we collected a total of 2452 webcam videos of human reactions from 54 participants. To test the viability of the collected data, we used the bystander reaction dataset as input to a deep-learning model, BADNet, to predict failure occurrence. We tested different data labeling methods and learned how they affect model performance, achieving precisions above 90%. We discuss strategies to model bystander reactions and predict failure and how this approach can be used in real-world robotic deployments to detect errors and improve robot performance. As part of this work, we also contribute with the \"Bystander Affect Detection\" (BAD) dataset of bystander reactions, supporting the development of better prediction models. ",
    "url": "https://arxiv.org/abs/2303.04835",
    "authors": [
      "Alexandra Bremers",
      "Maria Teresa Parreira",
      "Xuanyu Fang",
      "Natalie Friedman",
      "Adolfo Ramirez-Aristizabal",
      "Alexandria Pabst",
      "Mirjana Spasojevic",
      "Michael Kuniavsky",
      "Wendy Ju"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.04869",
    "title": "CROSSFIRE: Camera Relocalization On Self-Supervised Features from an  Implicit Representation",
    "abstract": "Beyond novel view synthesis, Neural Radiance Fields are useful for applications that interact with the real world. In this paper, we use them as an implicit map of a given scene and propose a camera relocalization algorithm tailored for this representation. The proposed method enables to compute in real-time the precise position of a device using a single RGB camera, during its navigation. In contrast with previous work, we do not rely on pose regression or photometric alignment but rather use dense local features obtained through volumetric rendering which are specialized on the scene with a self-supervised objective. As a result, our algorithm is more accurate than competitors, able to operate in dynamic outdoor environments with changing lightning conditions and can be readily integrated in any volumetric neural renderer. ",
    "url": "https://arxiv.org/abs/2303.04869",
    "authors": [
      "Arthur Moreau",
      "Nathan Piasco",
      "Moussab Bennehar",
      "Dzmitry Tsishkou",
      "Bogdan Stanciulescu",
      "Arnaud de La Fortelle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04873",
    "title": "MOREA: a GPU-accelerated Evolutionary Algorithm for Multi-Objective  Deformable Registration of 3D Medical Images",
    "abstract": "Finding a realistic deformation that transforms one image into another, in case large deformations are required, is considered a key challenge in medical image analysis. Having a proper image registration approach to achieve this could unleash a number of applications requiring information to be transferred between images. Clinical adoption is currently hampered by many existing methods requiring extensive configuration effort before each use, or not being able to (realistically) capture large deformations. A recent multi-objective approach that uses the Multi-Objective Real-Valued Gene-pool Optimal Mixing Evolutionary Algorithm (MO-RV-GOMEA) and a dual-dynamic mesh transformation model has shown promise, exposing the trade-offs inherent to image registration problems and modeling large deformations in 2D. This work builds on this promise and introduces MOREA: the first evolutionary algorithm-based multi-objective approach to deformable registration of 3D images capable of tackling large deformations. MOREA includes a 3D biomechanical mesh model for physical plausibility and is fully GPU-accelerated. We compare MOREA to two state-of-the-art approaches on abdominal CT scans of 4 cervical cancer patients, with the latter two approaches configured for the best results per patient. Without requiring per-patient configuration, MOREA significantly outperforms these approaches on 3 of the 4 patients that represent the most difficult cases. ",
    "url": "https://arxiv.org/abs/2303.04873",
    "authors": [
      "Georgios Andreadis",
      "Peter A.N. Bosman",
      "Tanja Alderliesten"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.04878",
    "title": "DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep  Neural Networks",
    "abstract": "Deep neural networks (DNNs) are widely used in various application domains such as image processing, speech recognition, and natural language processing. However, testing DNN models may be challenging due to the complexity and size of their input domain. Particularly, testing DNN models often requires generating or exploring large unlabeled datasets. In practice, DNN test oracles, which identify the correct outputs for inputs, often require expensive manual effort to label test data, possibly involving multiple experts to ensure labeling correctness. In this paper, we propose DeepGD, a black-box multi-objective test selection approach for DNN models. It reduces the cost of labeling by prioritizing the selection of test inputs with high fault revealing power from large unlabeled datasets. DeepGD not only selects test inputs with high uncertainty scores to trigger as many mispredicted inputs as possible but also maximizes the probability of revealing distinct faults in the DNN model by selecting diverse mispredicted inputs. The experimental results conducted on four widely used datasets and five DNN models show that in terms of fault-revealing ability: (1) White-box, coverage-based approaches fare poorly, (2) DeepGD outperforms existing black-box test selection approaches in terms of fault detection, and (3) DeepGD also leads to better guidance for DNN model retraining when using selected inputs to augment the training set. ",
    "url": "https://arxiv.org/abs/2303.04878",
    "authors": [
      "Zohreh Aghababaeyan",
      "Manel Abdellatif",
      "Mahboubeh Dadkhah",
      "Lionel Briand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.04884",
    "title": "O2RNet: Occluder-Occludee Relational Network for Robust Apple Detection  in Clustered Orchard Environments",
    "abstract": "Automated apple harvesting has attracted significant research interest in recent years due to its potential to revolutionize the apple industry, addressing the issues of shortage and high costs in labor. One key technology to fully enable efficient automated harvesting is accurate and robust apple detection, which is challenging due to complex orchard environments that involve varying lighting conditions and foliage/branch occlusions. Furthermore, clustered apples are common in the orchard, which brings additional challenges as the clustered apples may be identified as one apple. This will cause issues in localization for subsequent robotic operations. In this paper, we present the development of a novel deep learning-based apple detection framework, Occluder-Occludee Relational Network (O2RNet), for robust detection of apples in such clustered environments. This network exploits the occuluder-occludee relationship modeling head by introducing a feature expansion structure to enable the combination of layered traditional detectors to split clustered apples and foliage occlusions. More specifically, we collect a comprehensive apple orchard image dataset under different lighting conditions (overcast, front lighting, and back lighting) with frequent apple occlusions. We then develop a novel occlusion-aware network for apple detection, in which a feature expansion structure is incorporated into the convolutional neural networks to extract additional features generated by the original network for occluded apples. Comprehensive evaluations are performed, which show that the developed O2RNet outperforms state-of-the-art models with a higher accuracy of 94\\% and a higher F1-score of 0.88 on apple detection. ",
    "url": "https://arxiv.org/abs/2303.04884",
    "authors": [
      "Pengyu Chu",
      "Zhaojian Li",
      "Kaixiang Zhang",
      "Dong Chen",
      "Kyle Lammers",
      "Renfu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04891",
    "title": "You Only Crash Once: Improved Object Detection for Real-Time,  Sim-to-Real Hazardous Terrain Detection and Classification for Autonomous  Planetary Landings",
    "abstract": "The detection of hazardous terrain during the planetary landing of spacecraft plays a critical role in assuring vehicle safety and mission success. A cheap and effective way of detecting hazardous terrain is through the use of visual cameras, which ensure operational ability from atmospheric entry through touchdown. Plagued by resource constraints and limited computational power, traditional techniques for visual hazardous terrain detection focus on template matching and registration to pre-built hazard maps. Although successful on previous missions, this approach is restricted to the specificity of the templates and limited by the fidelity of the underlying hazard map, which both require extensive pre-flight cost and effort to obtain and develop. Terrestrial systems that perform a similar task in applications such as autonomous driving utilize state-of-the-art deep learning techniques to successfully localize and classify navigation hazards. Advancements in spacecraft co-processors aimed at accelerating deep learning inference enable the application of these methods in space for the first time. In this work, we introduce You Only Crash Once (YOCO), a deep learning-based visual hazardous terrain detection and classification technique for autonomous spacecraft planetary landings. Through the use of unsupervised domain adaptation we tailor YOCO for training by simulation, removing the need for real-world annotated data and expensive mission surveying phases. We further improve the transfer of representative terrain knowledge between simulation and the real world through visual similarity clustering. We demonstrate the utility of YOCO through a series of terrestrial and extraterrestrial simulation-to-real experiments and show substantial improvements toward the ability to both detect and accurately classify instances of planetary terrain. ",
    "url": "https://arxiv.org/abs/2303.04891",
    "authors": [
      "Timothy Chase Jr",
      "Chris Gnam",
      "John Crassidis",
      "Karthik Dantu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.04909",
    "title": "Robotic Fabric Flattening with Wrinkle Direction Detection",
    "abstract": "Deformable Object Manipulation (DOM) is an important field of research as it contributes to practical tasks such as automatic cloth handling, cable routing, surgical operation, etc. Perception is considered one of the major challenges in DOM due to the complex dynamics and high degree of freedom of deformable objects. In this paper, we develop a novel image-processing algorithm based on Gabor filters to extract useful features from cloth, and based on this, devise a strategy for cloth flattening tasks. We evaluate the overall framework experimentally, and compare it with three human operators. The results show that our algorithm can determine the direction of wrinkles on the cloth accurately in the simulation as well as the real robot experiments. Besides, the robot executing the flattening tasks using the dewrinkling strategy given by our algorithm achieves satisfying performance compared to other baseline methods. The experiment video is available on https://sites.google.com/view/robotic-fabric-flattening/home ",
    "url": "https://arxiv.org/abs/2303.04909",
    "authors": [
      "Yulei Qiu",
      "Jihong Zhu",
      "Cosimo Della Santina",
      "Michael Gienger",
      "Jen Kober"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04939",
    "title": "UT-Net: Combining U-Net and Transformer for Joint Optic Disc and Cup  Segmentation and Glaucoma Detection",
    "abstract": "Glaucoma is a chronic visual disease that may cause permanent irreversible blindness. Measurement of the cup-to-disc ratio (CDR) plays a pivotal role in the detection of glaucoma in its early stage, preventing visual disparities. Therefore, accurate and automatic segmentation of optic disc (OD) and optic cup (OC) from retinal fundus images is a fundamental requirement. Existing CNN-based segmentation frameworks resort to building deep encoders with aggressive downsampling layers, which suffer from a general limitation on modeling explicit long-range dependency. To this end, in this paper, we propose a new segmentation pipeline, called UT-Net, availing the advantages of U-Net and transformer both in its encoding layer, followed by an attention-gated bilinear fusion scheme. In addition to this, we incorporate Multi-Head Contextual attention to enhance the regular self-attention used in traditional vision transformers. Thus low-level features along with global dependencies are captured in a shallow manner. Besides, we extract context information at multiple encoding layers for better exploration of receptive fields, and to aid the model to learn deep hierarchical representations. Finally, an enhanced mixing loss is proposed to tightly supervise the overall learning process. The proposed model has been implemented for joint OD and OC segmentation on three publicly available datasets: DRISHTI-GS, RIM-ONE R3, and REFUGE. Additionally, to validate our proposal, we have performed exhaustive experimentation on Glaucoma detection from all three datasets by measuring the Cup to Disc Ratio (CDR) value. Experimental results demonstrate the superiority of UT-Net as compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2303.04939",
    "authors": [
      "Rukhshanda Hussain",
      "Hritam Basak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.04942",
    "title": "A Study of Variable-Role-based Feature Enrichment in Neural Models of  Code",
    "abstract": "Although deep neural models substantially reduce the overhead of feature engineering, the features readily available in the inputs might significantly impact training cost and the performance of the models. In this paper, we explore the impact of an unsuperivsed feature enrichment approach based on variable roles on the performance of neural models of code. The notion of variable roles (as introduced in the works of Sajaniemi et al. [Refs. 1,2]) has been found to help students' abilities in programming. In this paper, we investigate if this notion would improve the performance of neural models of code. To the best of our knowledge, this is the first work to investigate how Sajaniemi et al.'s concept of variable roles can affect neural models of code. In particular, we enrich a source code dataset by adding the role of individual variables in the dataset programs, and thereby conduct a study on the impact of variable role enrichment in training the Code2Seq model. In addition, we shed light on some challenges and opportunities in feature enrichment for neural code intelligence models. ",
    "url": "https://arxiv.org/abs/2303.04942",
    "authors": [
      "Aftab Hussain",
      "Md Rafiqul Islam Rabin",
      "Bowen Xu",
      "David Lo",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.04946",
    "title": "ATM Fraud Detection using Streaming Data Analytics",
    "abstract": "Gaining the trust and confidence of customers is the essence of the growth and success of financial institutions and organizations. Of late, the financial industry is significantly impacted by numerous instances of fraudulent activities. Further, owing to the generation of large voluminous datasets, it is highly essential that underlying framework is scalable and meet real time needs. To address this issue, in the study, we proposed ATM fraud detection in static and streaming contexts respectively. In the static context, we investigated a parallel and scalable machine learning algorithms for ATM fraud detection that is built on Spark and trained with a variety of machine learning (ML) models including Naive Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF), Gradient Boosting Tree (GBT), and Multi-layer perceptron (MLP). We also employed several balancing techniques like Synthetic Minority Oversampling Technique (SMOTE) and its variants, Generative Adversarial Networks (GAN), to address the rarity in the dataset. In addition, we proposed a streaming based ATM fraud detection in the streaming context. Our sliding window based method collects ATM transactions that are performed within a specified time interval and then utilizes to train several ML models, including NB, RF, DT, and K-Nearest Neighbour (KNN). We selected these models based on their less model complexity and quicker response time. In both contexts, RF turned out to be the best model. RF obtained the best mean AUC of 0.975 in the static context and mean AUC of 0.910 in the streaming context. RF is also empirically proven to be statistically significant than the next-best performing models. ",
    "url": "https://arxiv.org/abs/2303.04946",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "Abhay Anand Mane",
      "Laveti Ramesh Naidu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.04958",
    "title": "NIFF: Alleviating Forgetting in Generalized Few-Shot Object Detection  via Neural Instance Feature Forging",
    "abstract": "Privacy and memory are two recurring themes in a broad conversation about the societal impact of AI. These concerns arise from the need for huge amounts of data to train deep neural networks. A promise of Generalized Few-shot Object Detection (G-FSOD), a learning paradigm in AI, is to alleviate the need for collecting abundant training samples of novel classes we wish to detect by leveraging prior knowledge from old classes (i.e., base classes). G-FSOD strives to learn these novel classes while alleviating catastrophic forgetting of the base classes. However, existing approaches assume that the base images are accessible, an assumption that does not hold when sharing and storing data is problematic. In this work, we propose the first data-free knowledge distillation (DFKD) approach for G-FSOD that leverages the statistics of the region of interest (RoI) features from the base model to forge instance-level features without accessing the base images. Our contribution is three-fold: (1) we design a standalone lightweight generator with (2) class-wise heads (3) to generate and replay diverse instance-level base features to the RoI head while finetuning on the novel data. This stands in contrast to standard DFKD approaches in image classification, which invert the entire network to generate base images. Moreover, we make careful design choices in the novel finetuning pipeline to regularize the model. We show that our approach can dramatically reduce the base memory requirements, all while setting a new standard for G-FSOD on the challenging MS-COCO and PASCAL-VOC benchmarks. ",
    "url": "https://arxiv.org/abs/2303.04958",
    "authors": [
      "Karim Guirguis",
      "Johannes Meier",
      "George Eskandar",
      "Matthias Kayser",
      "Bin Yang",
      "Juergen Beyerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.04971",
    "title": "Optimizing network robustness via Krylov subspaces",
    "abstract": "We consider the problem of attaining either the maximal increase or reduction of the robustness of a complex network by means of a bounded modification of a subset of the edge weights. We propose two novel strategies combining Krylov subspace approximations with a greedy scheme and with the limited-memory BFGS. The paper discuss the computational and modeling aspects of our methodology and illustrates the various optimization problems on networks that can be addressed within the proposed framework. Finally, in the numerical experiments we compare the performances of our algorithms with state-of-the-art techniques on synthetic and real-world networks. ",
    "url": "https://arxiv.org/abs/2303.04971",
    "authors": [
      "Stefano Massei",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.04980",
    "title": "Decision-BADGE: Decision-based Adversarial Batch Attack with Directional  Gradient Estimation",
    "abstract": "The vulnerability of deep neural networks to adversarial examples has led to the rise in the use of adversarial attacks. While various decision-based and universal attack methods have been proposed, none have attempted to create a decision-based universal adversarial attack. This research proposes Decision-BADGE, which uses random gradient-free optimization and batch attack to generate universal adversarial perturbations for decision-based attacks. Multiple adversarial examples are combined to optimize a single universal perturbation, and the accuracy metric is reformulated into a continuous Hamming distance form. The effectiveness of accuracy metric as a loss function is demonstrated and mathematically proven. The combination of Decision-BADGE and the accuracy loss function performs better than both score-based image-dependent attack and white-box universal attack methods in terms of attack time efficiency. The research also shows that Decision-BADGE can successfully deceive unseen victims and accurately target specific classes. ",
    "url": "https://arxiv.org/abs/2303.04980",
    "authors": [
      "Geunhyeok Yu",
      "Minwoo Jeon",
      "Hyoseok Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04989",
    "title": "ARS-DETR: Aspect Ratio Sensitive Oriented Object Detection with  Transformer",
    "abstract": "Existing oriented object detection methods commonly use metric AP$_{50}$ to measure the performance of the model. We argue that AP$_{50}$ is inherently unsuitable for oriented object detection due to its large tolerance in angle deviation. Therefore, we advocate using high-precision metric, e.g. AP$_{75}$, to measure the performance of models. In this paper, we propose an Aspect Ratio Sensitive Oriented Object Detector with Transformer, termed ARS-DETR, which exhibits a competitive performance in high-precision oriented object detection. Specifically, a new angle classification method, calling Aspect Ratio aware Circle Smooth Label (AR-CSL), is proposed to smooth the angle label in a more reasonable way and discard the hyperparameter that introduced by previous work (e.g. CSL). Then, a rotated deformable attention module is designed to rotate the sampling points with the corresponding angles and eliminate the misalignment between region features and sampling points. Moreover, a dynamic weight coefficient according to the aspect ratio is adopted to calculate the angle loss. Comprehensive experiments on several challenging datasets show that our method achieves competitive performance on the high-precision oriented object detection task. ",
    "url": "https://arxiv.org/abs/2303.04989",
    "authors": [
      "Ying Zeng",
      "Xue Yang",
      "Qingyun Li",
      "Yushi Chen",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.04991",
    "title": "Deformer: Dynamic Fusion Transformer for Robust Hand Pose Estimation",
    "abstract": "Accurately estimating 3D hand pose is crucial for understanding how humans interact with the world. Despite remarkable progress, existing methods often struggle to generate plausible hand poses when the hand is heavily occluded or blurred. In videos, the movements of the hand allow us to observe various parts of the hand that may be occluded or blurred in a single frame. To adaptively leverage the visual clue before and after the occlusion or blurring for robust hand pose estimation, we propose the Deformer: a framework that implicitly reasons about the relationship between hand parts within the same image (spatial dimension) and different timesteps (temporal dimension). We show that a naive application of the transformer self-attention mechanism is not sufficient because motion blur or occlusions in certain frames can lead to heavily distorted hand features and generate imprecise keys and queries. To address this challenge, we incorporate a Dynamic Fusion Module into Deformer, which predicts the deformation of the hand and warps the hand mesh predictions from nearby frames to explicitly support the current frame estimation. Furthermore, we have observed that errors are unevenly distributed across different hand parts, with vertices around fingertips having disproportionately higher errors than those around the palm. We mitigate this issue by introducing a new loss function called maxMSE that automatically adjusts the weight of every vertex to focus the model on critical hand parts. Extensive experiments show that our method significantly outperforms state-of-the-art methods by 10%, and is more robust to occlusions (over 14%). ",
    "url": "https://arxiv.org/abs/2303.04991",
    "authors": [
      "Qichen Fu",
      "Xingyu Liu",
      "Ran Xu",
      "Juan Carlos Niebles",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05000",
    "title": "Learning Representation for Anomaly Detection of Vehicle Trajectories",
    "abstract": "Predicting the future trajectories of surrounding vehicles based on their history trajectories is a critical task in autonomous driving. However, when small crafted perturbations are introduced to those history trajectories, the resulting anomalous (or adversarial) trajectories can significantly mislead the future trajectory prediction module of the ego vehicle, which may result in unsafe planning and even fatal accidents. Therefore, it is of great importance to detect such anomalous trajectories of the surrounding vehicles for system safety, but few works have addressed this issue. In this work, we propose two novel methods for learning effective and efficient representations for online anomaly detection of vehicle trajectories. Different from general time-series anomaly detection, anomalous vehicle trajectory detection deals with much richer contexts on the road and fewer observable patterns on the anomalous trajectories themselves. To address these challenges, our methods exploit contrastive learning techniques and trajectory semantics to capture the patterns underlying the driving scenarios for effective anomaly detection under supervised and unsupervised settings, respectively. We conduct extensive experiments to demonstrate that our supervised method based on contrastive learning and unsupervised method based on reconstruction with semantic latent space can significantly improve the performance of anomalous trajectory detection in their corresponding settings over various baseline methods. We also demonstrate our methods' generalization ability to detect unseen patterns of anomalies. ",
    "url": "https://arxiv.org/abs/2303.05000",
    "authors": [
      "Ruochen Jiao",
      "Juyang Bai",
      "Xiangguo Liu",
      "Takami Sato",
      "Xiaowei Yuan",
      "Qi Alfred Chen",
      "Qi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05005",
    "title": "Parallel Computing Based Solution for Reliability-Constrained  Distribution Network Planning",
    "abstract": "The main goal of distribution network (DN) expansion planning is essentially to achieve minimal investment constrained with specified reliability requirements. The reliability-constrained distribution network planning (RcDNP) problem can be cast an instance of mixed-integer linear programming (MILP) which involves ultra-heavy computation burden especially for large scale DNs. In this paper, we propose a parallel computing-based acceleration algorithm for solve RcDNP problem. The RcDNP is decomposed into a backbone grid and several lateral grid problems with coordination. Then a parallelizable augmented Lagrangian algorithm with acceleration strategy is developed to solve the coordination planning problems. In this method, the lateral grid problems are solved in parallel through coordinating with the backbone grid planning problem. To address the presence of nonconvexity, Gauss-Seidel iteration is adopted on the convex hull of the feasible region constructed by the decomposition method. Under mild conditions, the optimality and convergence of this algorithm is proven. The numerical tests show the proposed method can significantly reduce the computation time and make the RcDNP applicable for real-world problems. ",
    "url": "https://arxiv.org/abs/2303.05005",
    "authors": [
      "Yaqi Sun",
      "Wenchuan Wu",
      "Yi Lin",
      "Hai Huang",
      "Hao Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.05007",
    "title": "Towards Robust Image-in-Audio Deep Steganography",
    "abstract": "The field of steganography has experienced a surge of interest due to the recent advancements in AI-powered techniques, particularly in the context of multimodal setups that enable the concealment of signals within signals of a different nature. The primary objectives of all steganographic methods are to achieve perceptual transparency, robustness, and large embedding capacity - which often present conflicting goals that classical methods have struggled to reconcile. This paper extends and enhances an existing image-in-audio deep steganography method by focusing on improving its robustness. The proposed enhancements include modifications to the loss function, utilization of the Short-Time Fourier Transform (STFT), introduction of redundancy in the encoding process for error correction, and buffering of additional information in the pixel subconvolution operation. The results demonstrate that our approach outperforms the existing method in terms of robustness and perceptual transparency. ",
    "url": "https://arxiv.org/abs/2303.05007",
    "authors": [
      "Jaume Ros Alonso",
      "Margarita Geleta",
      "Jordi Pons",
      "Xavier Giro-i-Nieto"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.05009",
    "title": "Parallel Filtered Graphs for Hierarchical Clustering",
    "abstract": "Given all pairwise weights (distances) among a set of objects, filtered graphs provide a sparse representation by only keeping an important subset of weights. Such graphs can be passed to graph clustering algorithms to generate hierarchical clusters. In particular, the directed bubble hierarchical tree (DBHT) algorithm on filtered graphs has been shown to produce good hierarchical clusters for time series data. We propose a new parallel algorithm for constructing triangulated maximally filtered graphs (TMFG), which produces valid inputs for DBHT, and a scalable parallel algorithm for generating DBHTs that is optimized for TMFG inputs. In addition to parallelizing the original TMFG construction, which has limited parallelism, we also design a new algorithm that inserts multiple vertices on each round to enable more parallelism. We show that the graphs generated by our new algorithm have similar quality compared to the original TMFGs, while being much faster to generate. Our new parallel algorithms for TMFGs and DBHTs are 136--2483x faster than state-of-the-art implementations, while achieving up to 41.56x self-relative speedup on 48 cores with hyper-threading, and achieve better clustering results compared to the standard average-linkage and complete-linkage hierarchical clustering algorithms. We show that on a stock data set, our algorithms produce clusters that align well with human experts' classification. ",
    "url": "https://arxiv.org/abs/2303.05009",
    "authors": [
      "Shangdi Yu",
      "Julian Shun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.05015",
    "title": "Smooth and Stepwise Self-Distillation for Object Detection",
    "abstract": "Distilling the structured information captured in feature maps has contributed to improved results for object detection tasks, but requires careful selection of baseline architectures and substantial pre-training. Self-distillation addresses these limitations and has recently achieved state-of-the-art performance for object detection despite making several simplifying architectural assumptions. Building on this work, we propose Smooth and Stepwise Self-Distillation (SSSD) for object detection. Our SSSD architecture forms an implicit teacher from object labels and a feature pyramid network backbone to distill label-annotated feature maps using Jensen-Shannon distance, which is smoother than distillation losses used in prior work. We additionally add a distillation coefficient that is adaptively configured based on the learning rate. We extensively benchmark SSSD against a baseline and two state-of-the-art object detector architectures on the COCO dataset by varying the coefficients and backbone and detector networks. We demonstrate that SSSD achieves higher average precision in most experimental settings, is robust to a wide range of coefficients, and benefits from our stepwise distillation procedure. ",
    "url": "https://arxiv.org/abs/2303.05015",
    "authors": [
      "Jieren Deng",
      "Xin Zhou",
      "Hao Tian",
      "Zhihong Pan",
      "Derek Aguiar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05026",
    "title": "SSL^2: Self-Supervised Learning meets Semi-Supervised Learning: Multiple  Sclerosis Segmentation in 7T-MRI from large-scale 3T-MRI",
    "abstract": "Automated segmentation of multiple sclerosis (MS) lesions from MRI scans is important to quantify disease progression. In recent years, convolutional neural networks (CNNs) have shown top performance for this task when a large amount of labeled data is available. However, the accuracy of CNNs suffers when dealing with few and/or sparsely labeled datasets. A potential solution is to leverage the information available in large public datasets in conjunction with a target dataset which only has limited labeled data. In this paper, we propose a training framework, SSL2 (self-supervised-semi-supervised), for multi-modality MS lesion segmentation with limited supervision. We adopt self-supervised learning to leverage the knowledge from large public 3T datasets to tackle the limitations of a small 7T target dataset. To leverage the information from unlabeled 7T data, we also evaluate state-of-the-art semi-supervised methods for other limited annotation settings, such as small labeled training size and sparse annotations. We use the shifted-window (Swin) transformer1 as our backbone network. The effectiveness of self-supervised and semi-supervised training strategies is evaluated in our in-house 7T MRI dataset. The results indicate that each strategy improves lesion segmentation for both limited training data size and for sparse labeling scenarios. The combined overall framework further improves the performance substantially compared to either of its components alone. Our proposed framework thus provides a promising solution for future data/label-hungry 7T MS studies. ",
    "url": "https://arxiv.org/abs/2303.05026",
    "authors": [
      "Jiacheng Wang",
      "Hao Li",
      "Han Liu",
      "Dewei Hu",
      "Daiwei Lu",
      "Keejin Yoon",
      "Kelsey Barter",
      "Francesca Bagnato",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.05033",
    "title": "Out-of-distribution Detection with Implicit Outlier Transformation",
    "abstract": "Outlier exposure (OE) is powerful in out-of-distribution (OOD) detection, enhancing detection capability via model fine-tuning with surrogate OOD data. However, surrogate data typically deviate from test OOD data. Thus, the performance of OE, when facing unseen OOD data, can be weakened. To address this issue, we propose a novel OE-based approach that makes the model perform well for unseen OOD situations, even for unseen OOD cases. It leads to a min-max learning scheme -- searching to synthesize OOD data that leads to worst judgments and learning from such OOD data for uniform performance in OOD detection. In our realization, these worst OOD data are synthesized by transforming original surrogate ones. Specifically, the associated transform functions are learned implicitly based on our novel insight that model perturbation leads to data transformation. Our methodology offers an efficient way of synthesizing OOD data, which can further benefit the detection model, besides the surrogate OOD data. We conduct extensive experiments under various OOD detection setups, demonstrating the effectiveness of our method against its advanced counterparts. ",
    "url": "https://arxiv.org/abs/2303.05033",
    "authors": [
      "Qizhou Wang",
      "Junjie Ye",
      "Feng Liu",
      "Quanyu Dai",
      "Marcus Kalander",
      "Tongliang Liu",
      "Jianye Hao",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05036",
    "title": "Generative Model-Based Attack on Learnable Image Encryption for  Privacy-Preserving Deep Learning",
    "abstract": "In this paper, we propose a novel generative model-based attack on learnable image encryption methods proposed for privacy-preserving deep learning. Various learnable encryption methods have been studied to protect the sensitive visual information of plain images, and some of them have been investigated to be robust enough against all existing attacks. However, previous attacks on image encryption focus only on traditional cryptanalytic attacks or reverse translation models, so these attacks cannot recover any visual information if a block-scrambling encryption step, which effectively destroys global information, is applied. Accordingly, in this paper, generative models are explored to evaluate whether such models can restore sensitive visual information from encrypted images for the first time. We first point out that encrypted images have some similarity with plain images in the embedding space. By taking advantage of leaked information from encrypted images, we propose a guided generative model as an attack on learnable image encryption to recover personally identifiable visual information. We implement the proposed attack in two ways by utilizing two state-of-the-art generative models: a StyleGAN-based model and latent diffusion-based one. Experiments were carried out on the CelebA-HQ and ImageNet datasets. Results show that images reconstructed by the proposed method have perceptual similarities to plain images. ",
    "url": "https://arxiv.org/abs/2303.05036",
    "authors": [
      "AprilPyone MaungMaung",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.05047",
    "title": "Diversity-Measurable Anomaly Detection",
    "abstract": "Reconstruction-based anomaly detection models achieve their purpose by suppressing the generalization ability for anomaly. However, diverse normal patterns are consequently not well reconstructed as well. Although some efforts have been made to alleviate this problem by modeling sample diversity, they suffer from shortcut learning due to undesired transmission of abnormal information. In this paper, to better handle the tradeoff problem, we propose Diversity-Measurable Anomaly Detection (DMAD) framework to enhance reconstruction diversity while avoid the undesired generalization on anomalies. To this end, we design Pyramid Deformation Module (PDM), which models diverse normals and measures the severity of anomaly by estimating multi-scale deformation fields from reconstructed reference to original input. Integrated with an information compression module, PDM essentially decouples deformation from prototypical embedding and makes the final anomaly score more reliable. Experimental results on both surveillance videos and industrial images demonstrate the effectiveness of our method. In addition, DMAD works equally well in front of contaminated data and anomaly-like normal samples. ",
    "url": "https://arxiv.org/abs/2303.05047",
    "authors": [
      "Wenrui Liu",
      "Hong Chang",
      "Bingpeng Ma",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05048",
    "title": "Semi-Federated Learning for Collaborative Intelligence in Massive IoT  Networks",
    "abstract": "Implementing existing federated learning in massive Internet of Things (IoT) networks faces critical challenges such as imbalanced and statistically heterogeneous data and device diversity. To this end, we propose a semi-federated learning (SemiFL) framework to provide a potential solution for the realization of intelligent IoT. By seamlessly integrating the centralized and federated paradigms, our SemiFL framework shows high scalability in terms of the number of IoT devices even in the presence of computing-limited sensors. Furthermore, compared to traditional learning approaches, the proposed SemiFL can make better use of distributed data and computing resources, due to the collaborative model training between the edge server and local devices. Simulation results show the effectiveness of our SemiFL framework for massive IoT networks. The code can be found at https://github.com/niwanli/SemiFL_IoT. ",
    "url": "https://arxiv.org/abs/2303.05048",
    "authors": [
      "Wanli Ni",
      "Jingheng Zheng",
      "Hui Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.05061",
    "title": "A Syntax-Guided Multi-Task Learning Approach for Turducken-Style Code  Generation",
    "abstract": "Due to the development of pre-trained language models, automated code generation techniques have shown great promise in recent years. However, the generated code is difficult to meet the syntactic constraints of the target language, especially in the case of Turducken-style code, where declarative code snippets are embedded within imperative programs. In this study, we summarize the lack of syntactic constraints into three significant challenges: (1) the efficient representation of syntactic constraints, (2) the effective integration of syntactic information, and (3) the scalable syntax-first decoding algorithm. To address these challenges, we propose a syntax-guided multi-task learning approach TurduckenGen. Specifically, we first explicitly append the type information to the code tokens to capture the representation of syntactic constraints. Then we formalize code generation with syntactic constraint representation as an auxiliary task to enable the model to learn the syntactic constraints of the code. Finally, the syntactically correct code is selected accurately from the multiple candidates with the help of the compiler feedback. Extensive experiments and comprehensive analysis demonstrate the effectiveness and general applicability of our approach after being compared with six state-of-the-art baselines on two Turducken-style code datasets. Finally, we conducted a human study and found the code quality generated by our approach is better than baselines in terms of code readability and semantic similarity. ",
    "url": "https://arxiv.org/abs/2303.05061",
    "authors": [
      "Guang Yang",
      "Yu Zhou",
      "Xiang Chen",
      "Xiangyu Zhang",
      "Yiran Xu",
      "Tingting Han",
      "Taolue Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.05067",
    "title": "Robust optimization with belief functions",
    "abstract": "In this paper, an optimization problem with uncertain objective function coefficients is considered. The uncertainty is specified by providing a discrete scenario set, containing possible realizations of the objective function coefficients. The concept of belief function in the traditional and possibilistic setting is applied to define a set of admissible probability distributions over the scenario set. The generalized Hurwicz criterion is then used to compute a solution. In this paper, the complexity of the resulting problem is explored. Some exact and approximation methods of solving it are proposed. ",
    "url": "https://arxiv.org/abs/2303.05067",
    "authors": [
      "Marc Goerigk",
      "Romain Guillaume",
      "Adam Kasperski",
      "Pawe\u0142 Zieli\u0144ski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.05071",
    "title": "MBPTrack: Improving 3D Point Cloud Tracking with Memory Networks and Box  Priors",
    "abstract": "3D single object tracking has been a crucial problem for decades with numerous applications such as autonomous driving. Despite its wide-ranging use, this task remains challenging due to the significant appearance variation caused by occlusion and size differences among tracked targets. To address these issues, we present MBPTrack, which adopts a Memory mechanism to utilize past information and formulates localization in a coarse-to-fine scheme using Box Priors given in the first frame. Specifically, past frames with targetness masks serve as an external memory, and a transformer-based module propagates tracked target cues from the memory to the current frame. To precisely localize objects of all sizes, MBPTrack first predicts the target center via Hough voting. By leveraging box priors given in the first frame, we adaptively sample reference points around the target center that roughly cover the target of different sizes. Then, we obtain dense feature maps by aggregating point features into the reference points, where localization can be performed more effectively. Extensive experiments demonstrate that MBPTrack achieves state-of-the-art performance on KITTI, nuScenes and Waymo Open Dataset, while running at 50 FPS on a single RTX3090 GPU. ",
    "url": "https://arxiv.org/abs/2303.05071",
    "authors": [
      "Tian-Xing Xu",
      "Yuan-Chen Guo",
      "Yu-Kun Lai",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05076",
    "title": "GaitEditer: Attribute Editing for Gait Representation Learning",
    "abstract": "Gait pattern is a promising biometric for applications, as it can be captured from a distance without requiring individual cooperation. Nevertheless, existing gait datasets typically suffer from limited diversity, with indoor datasets requiring participants to walk along a fixed route in a restricted setting, and outdoor datasets containing only few walking sequences per subject. Prior generative methods have attempted to mitigate these limitations by building virtual gait datasets. They primarily focus on manipulating a single, specific gait attribute (e.g., viewpoint or carrying), and require the supervised data pairs for training, thus lacking the flexibility and diversity for practical usage. In contrast, our GaitEditer can act as an online module to edit a broad range of gait attributes, such as pants, viewpoint, and even age, in an unsupervised manner, which current gait generative methods struggle with. Additionally, GaitEidter also finely preserves both temporal continuity and identity characteristics in generated gait sequences. Experiments show that GaitEditer provides extensive knowledge for clothing-invariant and view-invariant gait representation learning under various challenging scenarios. The source code will be available. ",
    "url": "https://arxiv.org/abs/2303.05076",
    "authors": [
      "Dingqiang Ye",
      "Jingzhe Ma",
      "Chao Fan",
      "Shiqi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05078",
    "title": "Efficient Transformer-based 3D Object Detection with Dynamic Token  Halting",
    "abstract": "Balancing efficiency and accuracy is a long-standing problem for deploying deep learning models. The trade-off is even more important for real-time safety-critical systems like autonomous vehicles. In this paper, we propose an effective approach for accelerating transformer-based 3D object detectors by dynamically halting tokens at different layers depending on their contribution to the detection task. Although halting a token is a non-differentiable operation, our method allows for differentiable end-to-end learning by leveraging an equivalent differentiable forward-pass. Furthermore, our framework allows halted tokens to be reused to inform the model's predictions through a straightforward token recycling mechanism. Our method significantly improves the Pareto frontier of efficiency versus accuracy when compared with the existing approaches. By halting tokens and increasing model capacity, we are able to improve the baseline model's performance without increasing the model's latency on the Waymo Open Dataset. ",
    "url": "https://arxiv.org/abs/2303.05078",
    "authors": [
      "Mao Ye",
      "Gregory P. Meyer",
      "Yuning Chai",
      "Qiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05079",
    "title": "DDS3D: Dense Pseudo-Labels with Dynamic Threshold for Semi-Supervised 3D  Object Detection",
    "abstract": "In this paper, we present a simple yet effective semi-supervised 3D object detector named DDS3D. Our main contributions have two-fold. On the one hand, different from previous works using Non-Maximal Suppression (NMS) or its variants for obtaining the sparse pseudo labels, we propose a dense pseudo-label generation strategy to get dense pseudo-labels, which can retain more potential supervision information for the student network. On the other hand, instead of traditional fixed thresholds, we propose a dynamic threshold manner to generate pseudo-labels, which can guarantee the quality and quantity of pseudo-labels during the whole training process. Benefiting from these two components, our DDS3D outperforms the state-of-the-art semi-supervised 3d object detection with mAP of 3.1% on the pedestrian and 2.1% on the cyclist under the same configuration of 1% samples. Extensive ablation studies on the KITTI dataset demonstrate the effectiveness of our DDS3D. The code and models will be made publicly available at https://github.com/hust-jy/DDS3D ",
    "url": "https://arxiv.org/abs/2303.05079",
    "authors": [
      "Jingyu Li1",
      "Zhe Liu1",
      "Jinghua Hou1",
      "Dingkang Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05080",
    "title": "Revisiting the relevance of traditional genres: a network analysis of  fiction readers' preferences",
    "abstract": "We investigate how well traditional fiction genres like Fantasy, Thriller, and Literature represent readers' preferences. Using user data from Goodreads we construct a book network where two books are strongly linked if the same people tend to read or enjoy them both. We then partition this network into communities of similar books and assign each a list of subjects from The Open Library to serve as a proxy for traditional genres. Our analysis reveals that the network communities correspond to existing combinations of traditional genres, but that the exact communities differ depending on whether we consider books that people read or books that people enjoy. In addition, we apply principal component analysis to the data and find that the variance in the book communities is best explained by two factors: the maturity/childishness and realism/fantastical nature of the books. We propose using this maturity-realism plane as a coarse classification tool for stories. ",
    "url": "https://arxiv.org/abs/2303.05080",
    "authors": [
      "Taom Sakal",
      "Stephen Proulx"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.05109",
    "title": "Updated version: A Video Anomaly Detection Framework based on  Appearance-Motion Semantics Representation Consistency",
    "abstract": "Video anomaly detection is an essential but challenging task. The prevalent methods mainly investigate the reconstruction difference between normal and abnormal patterns but ignore the semantics consistency between appearance and motion information of behavior patterns, making the results highly dependent on the local context of frame sequences and lacking the understanding of behavior semantics. To address this issue, we propose a framework of Appearance-Motion Semantics Representation Consistency that uses the gap of appearance and motion semantic representation consistency between normal and abnormal data. The two-stream structure is designed to encode the appearance and motion information representation of normal samples, and a novel consistency loss is proposed to enhance the consistency of feature semantics so that anomalies with low consistency can be identified. Moreover, the lower consistency features of anomalies can be used to deteriorate the quality of the predicted frame, which makes anomalies easier to spot. Experimental results demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2303.05109",
    "authors": [
      "Xiangyu Huang",
      "Caidan Zhao",
      "Zhiqiang Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05116",
    "title": "Multi-level Memory-augmented Appearance-Motion Correspondence Framework  for Video Anomaly Detection",
    "abstract": "Frame prediction based on AutoEncoder plays a significant role in unsupervised video anomaly detection. Ideally, the models trained on the normal data could generate larger prediction errors of anomalies. However, the correlation between appearance and motion information is underutilized, which makes the models lack an understanding of normal patterns. Moreover, the models do not work well due to the uncontrollable generalizability of deep AutoEncoder. To tackle these problems, we propose a multi-level memory-augmented appearance-motion correspondence framework. The latent correspondence between appearance and motion is explored via appearance-motion semantics alignment and semantics replacement training. Besides, we also introduce a Memory-Guided Suppression Module, which utilizes the difference from normal prototype features to suppress the reconstruction capacity caused by skip-connection, achieving the tradeoff between the good reconstruction of normal data and the poor reconstruction of abnormal data. Experimental results show that our framework outperforms the state-of-the-art methods, achieving AUCs of 99.6\\%, 93.8\\%, and 76.3\\% on UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets. ",
    "url": "https://arxiv.org/abs/2303.05116",
    "authors": [
      "Xiangyu Huang",
      "Caidan Zhao",
      "Jinghui Yu",
      "Chenxing Gao",
      "Zhiqiang Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05134",
    "title": "hierarchical network with decoupled knowledge distillation for speech  emotion recognition",
    "abstract": "The goal of Speech Emotion Recognition (SER) is to enable computers to recognize the emotion category of a given utterance in the same way that humans do. The accuracy of SER is strongly dependent on the validity of the utterance-level representation obtained by the model. Nevertheless, the ``dark knowledge\" carried by non-target classes is always ignored by previous studies. In this paper, we propose a hierarchical network, called DKDFMH, which employs decoupled knowledge distillation in a deep convolutional neural network with a fused multi-head attention mechanism. Our approach applies logit distillation to obtain higher-level semantic features from different scales of attention sets and delve into the knowledge carried by non-target classes, thus guiding the model to focus more on the differences between sentiment features. To validate the effectiveness of our model, we conducted experiments on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset. We achieved competitive performance, with 79.1% weighted accuracy (WA) and 77.1% unweighted accuracy (UA). To the best of our knowledge, this is the first time since 2015 that logit distillation has been returned to state-of-the-art status. ",
    "url": "https://arxiv.org/abs/2303.05134",
    "authors": [
      "Ziping Zhao",
      "Huan Wang",
      "Haishuai Wang",
      "Bjorn Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.05148",
    "title": "Weakly Supervised Knowledge Transfer with Probabilistic Logical  Reasoning for Object Detection",
    "abstract": "Training object detection models usually requires instance-level annotations, such as the positions and labels of all objects present in each image. Such supervision is unfortunately not always available and, more often, only image-level information is provided, also known as weak supervision. Recent works have addressed this limitation by leveraging knowledge from a richly annotated domain. However, the scope of weak supervision supported by these approaches has been very restrictive, preventing them to use all available information. In this work, we propose ProbKT, a framework based on probabilistic logical reasoning that allows to train object detection models with arbitrary types of weak supervision. We empirically show on different datasets that using all available information is beneficial as our ProbKT leads to significant improvement on target domain and better generalization compared to existing baselines. We also showcase the ability of our approach to handle complex logic statements as supervision signal. ",
    "url": "https://arxiv.org/abs/2303.05148",
    "authors": [
      "Martijn Oldenhof",
      "Adam Arany",
      "Yves Moreau",
      "Edward De Brouwer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05151",
    "title": "Provable Data Subset Selection For Efficient Neural Network Training",
    "abstract": "Radial basis function neural networks (\\emph{RBFNN}) are {well-known} for their capability to approximate any continuous function on a closed bounded set with arbitrary precision given enough hidden neurons. In this paper, we introduce the first algorithm to construct coresets for \\emph{RBFNNs}, i.e., small weighted subsets that approximate the loss of the input data on any radial basis function network and thus approximate any function defined by an \\emph{RBFNN} on the larger input data. In particular, we construct coresets for radial basis and Laplacian loss functions. We then use our coresets to obtain a provable data subset selection algorithm for training deep neural networks. Since our coresets approximate every function, they also approximate the gradient of each weight in a neural network, which is a particular function on the input. We then perform empirical evaluations on function approximation and dataset subset selection on popular network architectures and data sets, demonstrating the efficacy and accuracy of our coreset construction. ",
    "url": "https://arxiv.org/abs/2303.05151",
    "authors": [
      "Murad Tukan",
      "Samson Zhou",
      "Alaa Maalouf",
      "Daniela Rus",
      "Vladimir Braverman",
      "Dan Feldman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05153",
    "title": "Can a Frozen Pretrained Language Model be used for Zero-shot Neural  Retrieval on Entity-centric Questions?",
    "abstract": "Neural document retrievers, including dense passage retrieval (DPR), have outperformed classical lexical-matching retrievers, such as BM25, when fine-tuned and tested on specific question-answering datasets. However, it has been shown that the existing dense retrievers do not generalize well not only out of domain but even in domain such as Wikipedia, especially when a named entity in a question is a dominant clue for retrieval. In this paper, we propose an approach toward in-domain generalization using the embeddings generated by the frozen language model trained with the entities in the domain. By not fine-tuning, we explore the possibility that the rich knowledge contained in a pretrained language model can be used for retrieval tasks. The proposed method outperforms conventional DPRs on entity-centric questions in Wikipedia domain and achieves almost comparable performance to BM25 and state-of-the-art SPAR model. We also show that the contextualized keys lead to strong improvements compared to BM25 when the entity names consist of common words. Our results demonstrate the feasibility of the zero-shot retrieval method for entity-centric questions of Wikipedia domain, where DPR has struggled to perform. ",
    "url": "https://arxiv.org/abs/2303.05153",
    "authors": [
      "Yasuto Hoshi",
      "Daisuke Miyashita",
      "Yasuhiro Morioka",
      "Youyang Ng",
      "Osamu Torii",
      "Jun Deguchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05162",
    "title": "EVOLIN Benchmark: Evaluation of Line Detection and Association",
    "abstract": "Lines are interesting geometrical features commonly seen in indoor and urban environments. There is missing a complete benchmark where one can evaluate lines from a sequential stream of images in all its stages: Line detection, Line Association and Pose error. To do so, we present a complete and exhaustive benchmark for visual lines in a SLAM front-end, both for RGB and RGBD, by providing a plethora of complementary metrics. We have also labelled data from well-known SLAM datasets in order to have all in one poses and accurately annotated lines. In particular, we have evaluated 17 line detection algorithms, 5 line associations methods and the resultant pose error for aligning a pair of frames with several combinations of detector-association. We have packaged all methods and evaluations metrics and made them publicly available on web-page https://prime-slam.github.io/evolin/. ",
    "url": "https://arxiv.org/abs/2303.05162",
    "authors": [
      "Kirill Ivanov",
      "Gonzalo Ferrer",
      "Anastasiia Kornilova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05166",
    "title": "TAEC: Unsupervised Action Segmentation with Temporal-Aware Embedding and  Clustering",
    "abstract": "Temporal action segmentation in untrimmed videos has gained increased attention recently. However, annotating action classes and frame-wise boundaries is extremely time consuming and cost intensive, especially on large-scale datasets. To address this issue, we propose an unsupervised approach for learning action classes from untrimmed video sequences. In particular, we propose a temporal embedding network that combines relative time prediction, feature reconstruction, and sequence-to-sequence learning, to preserve the spatial layout and sequential nature of the video features. A two-step clustering pipeline on these embedded feature representations then allows us to enforce temporal consistency within, as well as across videos. Based on the identified clusters, we decode the video into coherent temporal segments that correspond to semantically meaningful action classes. Our evaluation on three challenging datasets shows the impact of each component and, furthermore, demonstrates our state-of-the-art unsupervised action segmentation results. ",
    "url": "https://arxiv.org/abs/2303.05166",
    "authors": [
      "Wei Lin",
      "Anna Kukleva",
      "Horst Possegger",
      "Hilde Kuehne",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05183",
    "title": "Blind2Sound: Self-Supervised Image Denoising without Residual Noise",
    "abstract": "Self-supervised blind denoising for Poisson-Gaussian noise remains a challenging task. Pseudo-supervised pairs constructed from single noisy images re-corrupt the signal and degrade the performance. The visible blindspots solve the information loss in masked inputs. However, without explicitly noise sensing, mean square error as an objective function cannot adjust denoising intensities for dynamic noise levels, leading to noticeable residual noise. In this paper, we propose Blind2Sound, a simple yet effective approach to overcome residual noise in denoised images. The proposed adaptive re-visible loss senses noise levels and performs personalized denoising without noise residues while retaining the signal lossless. The theoretical analysis of intermediate medium gradients guarantees stable training, while the Cramer Gaussian loss acts as a regularization to facilitate the accurate perception of noise levels and improve the performance of the denoiser. Experiments on synthetic and real-world datasets show the superior performance of our method, especially for single-channel images. ",
    "url": "https://arxiv.org/abs/2303.05183",
    "authors": [
      "Zejin Wang",
      "Jiazheng Liu",
      "Jiazheng Liu",
      "Hua Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05194",
    "title": "Contrastive Model Adaptation for Cross-Condition Robustness in Semantic  Segmentation",
    "abstract": "Standard unsupervised domain adaptation methods adapt models from a source to a target domain using labeled source data and unlabeled target data jointly. In model adaptation, on the other hand, access to the labeled source data is prohibited, i.e., only the source-trained model and unlabeled target data are available. We investigate normal-to-adverse condition model adaptation for semantic segmentation, whereby image-level correspondences are available in the target domain. The target set consists of unlabeled pairs of adverse- and normal-condition street images taken at GPS-matched locations. Our method -- CMA -- leverages such image pairs to learn condition-invariant features via contrastive learning. In particular, CMA encourages features in the embedding space to be grouped according to their condition-invariant semantic content and not according to the condition under which respective inputs are captured. To obtain accurate cross-domain semantic correspondences, we warp the normal image to the viewpoint of the adverse image and leverage warp-confidence scores to create robust, aggregated features. With this approach, we achieve state-of-the-art semantic segmentation performance for model adaptation on several normal-to-adverse adaptation benchmarks, such as ACDC and Dark Zurich. We also evaluate CMA on a newly procured adverse-condition generalization benchmark and report favorable results compared to standard unsupervised domain adaptation methods, despite the comparative handicap of CMA due to source data inaccessibility. Code is available at https://github.com/brdav/cma. ",
    "url": "https://arxiv.org/abs/2303.05194",
    "authors": [
      "David Bruggemann",
      "Christos Sakaridis",
      "Tim Br\u00f6dermann",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05195",
    "title": "Revisiting Rotation Averaging: Uncertainties and Robust Losses",
    "abstract": "In this paper, we revisit the rotation averaging problem applied in global Structure-from-Motion pipelines. We argue that the main problem of current methods is the minimized cost function that is only weakly connected with the input data via the estimated epipolar geometries.We propose to better model the underlying noise distributions by directly propagating the uncertainty from the point correspondences into the rotation averaging. Such uncertainties are obtained for free by considering the Jacobians of two-view refinements. Moreover, we explore integrating a variant of the MAGSAC loss into the rotation averaging problem, instead of using classical robust losses employed in current frameworks. The proposed method leads to results superior to baselines, in terms of accuracy, on large-scale public benchmarks. The code is public. https://github.com/zhangganlin/GlobalSfMpy ",
    "url": "https://arxiv.org/abs/2303.05195",
    "authors": [
      "Ganlin Zhang",
      "Viktor Larsson",
      "Daniel Barath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05203",
    "title": "RMMDet: Road-Side Multitype and Multigroup Sensor Detection System for  Autonomous Driving",
    "abstract": "Autonomous driving has now made great strides thanks to artificial intelligence, and numerous advanced methods have been proposed for vehicle end target detection, including single sensor or multi sensor detection methods. However, the complexity and diversity of real traffic situations necessitate an examination of how to use these methods in real road conditions. In this paper, we propose RMMDet, a road-side multitype and multigroup sensor detection system for autonomous driving. We use a ROS-based virtual environment to simulate real-world conditions, in particular the physical and functional construction of the sensors. Then we implement muti-type sensor detection and multi-group sensors fusion in this environment, including camera-radar and camera-lidar detection based on result-level fusion. We produce local datasets and real sand table field, and conduct various experiments. Furthermore, we link a multi-agent collaborative scheduling system to the fusion detection system. Hence, the whole roadside detection system is formed by roadside perception, fusion detection, and scheduling planning. Through the experiments, it can be seen that RMMDet system we built plays an important role in vehicle-road collaboration and its optimization. The code and supplementary materials can be found at: https://github.com/OrangeSodahub/RMMDet ",
    "url": "https://arxiv.org/abs/2303.05203",
    "authors": [
      "Xiuyu Yang",
      "Zhuangyan Zhang",
      "Haikuo Du",
      "Sui Yang",
      "Fengping Sun",
      "Yanbo Liu",
      "Ling Pei",
      "Wenchao Xu",
      "Weiqi Sun",
      "Zhengyu Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.05231",
    "title": "Structure-Aware Group Discrimination with Adaptive-View Graph Encoder: A  Fast Graph Contrastive Learning Framework",
    "abstract": "Albeit having gained significant progress lately, large-scale graph representation learning remains expensive to train and deploy for two main reasons: (i) the repetitive computation of multi-hop message passing and non-linearity in graph neural networks (GNNs); (ii) the computational cost of complex pairwise contrastive learning loss. Two main contributions are made in this paper targeting this twofold challenge: we first propose an adaptive-view graph neural encoder (AVGE) with a limited number of message passing to accelerate the forward pass computation, and then we propose a structure-aware group discrimination (SAGD) loss in our framework which avoids inefficient pairwise loss computing in most common GCL and improves the performance of the simple group discrimination. By the framework proposed, we manage to bring down the training and inference cost on various large-scale datasets by a significant margin (250x faster inference time) without loss of the downstream-task performance. ",
    "url": "https://arxiv.org/abs/2303.05231",
    "authors": [
      "Zhenshuo Zhang",
      "Yun Zhu",
      "Haizhou Shi",
      "Siliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05233",
    "title": "Dual-Attention Deep Reinforcement Learning for Multi-MAP 3D Trajectory  Optimization in Dynamic 5G Networks",
    "abstract": "5G and beyond networks need to provide dynamic and efficient infrastructure management to better adapt to time-varying user behaviors (e.g., user mobility, interference, user traffic and evolution of the network topology). In this paper, we propose to manage the trajectory of Mobile Access Points (MAPs) under all these dynamic constraints with reduced complexity. We first formulate the placement problem to manage MAPs over time. Our solution addresses time-varying user traffic and user mobility through a Multi-Agent Deep Reinforcement Learning (MADRL). To achieve real-time behavior, the proposed solution learns to perform distributed assignment of MAP-user positions and schedules the MAP path among all users without centralized user's clustering feedback. Our solution exploits a dual-attention MADRL model via proximal policy optimization to dynamically move MAPs in 3D. The dual-attention takes into account information from both users and MAPs. The cooperation mechanism of our solution allows to manage different scenarios, without a priory information and without re-training, which significantly reduces complexity. ",
    "url": "https://arxiv.org/abs/2303.05233",
    "authors": [
      "Esteban Catt\u00e9",
      "Mohamed Sana",
      "Mickael Maman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.05238",
    "title": "An Unscented Kalman Filter-Informed Neural Network for Vehicle Sideslip  Angle Estimation",
    "abstract": "This paper proposes a novel vehicle sideslip angle estimator, which uses the physical knowledge from an Unscented Kalman Filter (UKF) based on a non-linear single-track vehicle model to enhance the estimation accuracy of a Convolutional Neural Network (CNN). The model-based and data-driven approaches interact mutually, and both use the standard inertial measurement unit and the tyre forces measured by load sensing technology. CNN benefits from the UKF the capacity to leverage the laws of physics. Concurrently, the UKF uses the CNN outputs as sideslip angle pseudo-measurement and adaptive process noise parameters. The back-propagation through time algorithm is applied end-to-end to the CNN and the UKF to employ the mutualistic property. Using a large-scale experimental dataset of 216 manoeuvres containing a great diversity of vehicle behaviours, we demonstrate a significant improvement in the accuracy of the proposed architecture over the current state-of-art hybrid approach combined with model-based and data-driven techniques. In the case that a limited dataset is provided for the training phase, the proposed hybrid approach still guarantees estimation robustness. ",
    "url": "https://arxiv.org/abs/2303.05238",
    "authors": [
      "Alberto Bertipaglia",
      "Mohsen Alirezaei",
      "Riender Happee",
      "Barys Shyrokau"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.05246",
    "title": "Efficient Certified Training and Robustness Verification of Neural ODEs",
    "abstract": "Neural Ordinary Differential Equations (NODEs) are a novel neural architecture, built around initial value problems with learned dynamics which are solved during inference. Thought to be inherently more robust against adversarial perturbations, they were recently shown to be vulnerable to strong adversarial attacks, highlighting the need for formal guarantees. However, despite significant progress in robustness verification for standard feed-forward architectures, the verification of high dimensional NODEs remains an open problem. In this work, we address this challenge and propose GAINS, an analysis framework for NODEs combining three key ideas: (i) a novel class of ODE solvers, based on variable but discrete time steps, (ii) an efficient graph representation of solver trajectories, and (iii) a novel abstraction algorithm operating on this graph representation. Together, these advances enable the efficient analysis and certified training of high-dimensional NODEs, by reducing the runtime from an intractable $O(\\exp(d)+\\exp(T))$ to ${O}(d+T^2 \\log^2T)$ in the dimensionality $d$ and integration time $T$. In an extensive evaluation on computer vision (MNIST and FMNIST) and time-series forecasting (PHYSIO-NET) problems, we demonstrate the effectiveness of both our certified training and verification methods. ",
    "url": "https://arxiv.org/abs/2303.05246",
    "authors": [
      "Mustafa Zeqiri",
      "Mark Niklas M\u00fcller",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05262",
    "title": "Fredholm integral equations for function approximation and the training  of neural networks",
    "abstract": "We present a novel and mathematically transparent approach to function approximation and the training of large, high-dimensional neural networks, based on the approximate least-squares solution of associated Fredholm integral equations of the first kind by Ritz-Galerkin discretization, Tikhonov regularization and tensor-train methods. Practical application to supervised learning problems of regression and classification type confirm that the resulting algorithms are competitive with state-of-the-art neural network-based methods. ",
    "url": "https://arxiv.org/abs/2303.05262",
    "authors": [
      "Patrick Gel\u00df",
      "Aizhan Issagali",
      "Ralf Kornhuber"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.05269",
    "title": "Effective Pseudo-Labeling based on Heatmap for Unsupervised Domain  Adaptation in Cell Detection",
    "abstract": "Cell detection is an important task in biomedical research. Recently, deep learning methods have made it possible to improve the performance of cell detection. However, a detection network trained with training data under a specific condition (source domain) may not work well on data under other conditions (target domains), which is called the domain shift problem. In particular, cells are cultured under different conditions depending on the purpose of the research. Characteristics, e.g., the shapes and density of the cells, change depending on the conditions, and such changes may cause domain shift problems. Here, we propose an unsupervised domain adaptation method for cell detection using a pseudo-cell-position heatmap, where the cell centroid is at the peak of a Gaussian distribution in the map and selective pseudo-labeling. In the prediction result for the target domain, even if the peak location is correct, the signal distribution around the peak often has a non-Gaussian shape. The pseudo-cell-position heatmap is thus re-generated using the peak positions in the predicted heatmap to have a clear Gaussian shape. Our method selects confident pseudo-cell-position heatmaps based on uncertainty and curriculum learning. We conducted numerous experiments showing that, compared with the existing methods, our method improved detection performance under different conditions. ",
    "url": "https://arxiv.org/abs/2303.05269",
    "authors": [
      "Hyeonwoo Cho",
      "Kazuya Nishimura",
      "Kazuhide Watanabe",
      "Ryoma Bise"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05279",
    "title": "Can large language models build causal graphs?",
    "abstract": "Building causal graphs can be a laborious process. To ensure all relevant causal pathways have been captured, researchers often have to discuss with clinicians and experts while also reviewing extensive relevant medical literature. By encoding common and medical knowledge, large language models (LLMs) represent an opportunity to ease this process by automatically scoring edges (i.e., connections between two variables) in potential graphs. LLMs however have been shown to be brittle to the choice of probing words, context, and prompts that the user employs. In this work, we evaluate if LLMs can be a useful tool in complementing causal graph development. ",
    "url": "https://arxiv.org/abs/2303.05279",
    "authors": [
      "Stephanie Long",
      "Tibor Schuster",
      "Alexandre Pich\u00e9",
      "Department of Family Medicine",
      "McGill University",
      "Mila",
      "Universit\u00e9 de Montreal",
      "ServiceNow Research"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05300",
    "title": "CoolPINNs: A Physics-informed Neural Network Modeling of Active Cooling  in Vascular Systems",
    "abstract": "Emerging technologies like hypersonic aircraft, space exploration vehicles, and batteries avail fluid circulation in embedded microvasculatures for efficient thermal regulation. Modeling is vital during these engineered systems' design and operational phases. However, many challenges exist in developing a modeling framework. What is lacking is an accurate framework that (i) captures sharp jumps in the thermal flux across complex vasculature layouts, (ii) deals with oblique derivatives (involving tangential and normal components), (iii) handles nonlinearity because of radiative heat transfer, (iv) provides a high-speed forecast for real-time monitoring, and (v) facilitates robust inverse modeling. This paper addresses these challenges by availing the power of physics-informed neural networks (PINNs). We develop a fast, reliable, and accurate Scientific Machine Learning (SciML) framework for vascular-based thermal regulation -- called CoolPINNs: a PINNs-based modeling framework for active cooling. The proposed mesh-less framework elegantly overcomes all the mentioned challenges. The significance of the reported research is multi-fold. First, the framework is valuable for real-time monitoring of thermal regulatory systems because of rapid forecasting. Second, researchers can address complex thermoregulation designs inasmuch as the approach is mesh-less. Finally, the framework facilitates systematic parameter identification and inverse modeling studies, perhaps the current framework's most significant utility. ",
    "url": "https://arxiv.org/abs/2303.05300",
    "authors": [
      "N. V. Jagtap",
      "M. K. Mudunuru",
      "K. B. Nakshatrala"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05321",
    "title": "WASD: A Wilder Active Speaker Detection Dataset",
    "abstract": "Current Active Speaker Detection (ASD) models achieve great results on AVA-ActiveSpeaker (AVA), using only sound and facial features. Although this approach is applicable in movie setups (AVA), it is not suited for less constrained conditions. To demonstrate this limitation, we propose a Wilder Active Speaker Detection (WASD) dataset, with increased difficulty by targeting the two key components of current ASD: audio and face. Grouped into 5 categories, ranging from optimal conditions to surveillance settings, WASD contains incremental challenges for ASD with tactical impairment of audio and face data. We select state-of-the-art models and assess their performance in two groups of WASD: Easy (cooperative settings) and Hard (audio and/or face are specifically degraded). The results show that: 1) AVA trained models maintain a state-of-the-art performance in WASD Easy group, while underperforming in the Hard one, showing the 2) similarity between AVA and Easy data; and 3) training in WASD does not improve models performance to AVA levels, particularly for audio impairment and surveillance settings. This shows that AVA does not prepare models for wild ASD and current approaches are subpar to deal with such conditions. The proposed dataset also contains body data annotations to provide a new source for ASD, and is available at https://github.com/Tiago-Roxo/WASD. ",
    "url": "https://arxiv.org/abs/2303.05321",
    "authors": [
      "Tiago Roxo",
      "Joana C. Costa",
      "Pedro R. M. In\u00e1cio",
      "Hugo Proen\u00e7a"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.05322",
    "title": "Improving Few-Shot Learning for Talking Face System with TTS Data  Augmentation",
    "abstract": "Audio-driven talking face has attracted broad interest from academia and industry recently. However, data acquisition and labeling in audio-driven talking face are labor-intensive and costly. The lack of data resource results in poor synthesis effect. To alleviate this issue, we propose to use TTS (Text-To-Speech) for data augmentation to improve few-shot ability of the talking face system. The misalignment problem brought by the TTS audio is solved with the introduction of soft-DTW, which is first adopted in the talking face task. Moreover, features extracted by HuBERT are explored to utilize underlying information of audio, and found to be superior over other features. The proposed method achieves 17%, 14%, 38% dominance on MSE score, DTW score and user study preference repectively over the baseline model, which shows the effectiveness of improving few-shot learning for talking face system with TTS augmentation. ",
    "url": "https://arxiv.org/abs/2303.05322",
    "authors": [
      "Qi Chen",
      "Ziyang Ma",
      "Tao Liu",
      "Xu Tan",
      "Qu Lu",
      "Xie Chen",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.05323",
    "title": "Controllable Video Generation by Learning the Underlying Dynamical  System with Neural ODE",
    "abstract": "Videos depict the change of complex dynamical systems over time in the form of discrete image sequences. Generating controllable videos by learning the dynamical system is an important yet underexplored topic in the computer vision community. This paper presents a novel framework, TiV-ODE, to generate highly controllable videos from a static image and a text caption. Specifically, our framework leverages the ability of Neural Ordinary Differential Equations~(Neural ODEs) to represent complex dynamical systems as a set of nonlinear ordinary differential equations. The resulting framework is capable of generating videos with both desired dynamics and content. Experiments demonstrate the ability of the proposed method in generating highly controllable and visually consistent videos, and its capability of modeling dynamical systems. Overall, this work is a significant step towards developing advanced controllable video generation models that can handle complex and dynamic scenes. ",
    "url": "https://arxiv.org/abs/2303.05323",
    "authors": [
      "Yucheng Xu",
      "Nanbo Li",
      "Arushi Goel",
      "Zijian Guo",
      "Zonghai Yao",
      "Hamidreza Kasaei",
      "Mohammadreze Kasaei",
      "Zhibin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05329",
    "title": "Tucker Bilinear Attention Network for Multi-scale Remote Sensing Object  Detection",
    "abstract": "Object detection on VHR remote sensing images plays a vital role in applications such as urban planning, land resource management, and rescue missions. The large-scale variation of the remote-sensing targets is one of the main challenges in VHR remote-sensing object detection. Existing methods improve the detection accuracy of high-resolution remote sensing objects by improving the structure of feature pyramids and adopting different attention modules. However, for small targets, there still be seriously missed detections due to the loss of key detail features. There is still room for improvement in the way of multiscale feature fusion and balance. To address this issue, this paper proposes two novel modules: Guided Attention and Tucker Bilinear Attention, which are applied to the stages of early fusion and late fusion respectively. The former can effectively retain clean key detail features, and the latter can better balance features through semantic-level correlation mining. Based on two modules, we build a new multi-scale remote sensing object detection framework. No bells and whistles. The proposed method largely improves the average precisions of small objects and achieves the highest mean average precisions compared with 9 state-of-the-art methods on DOTA, DIOR, and NWPU VHR-10.Code and models are available at https://github.com/Shinichict/GTNet. ",
    "url": "https://arxiv.org/abs/2303.05329",
    "authors": [
      "Tao Chen",
      "Ruirui Li",
      "Jiafeng Fu",
      "Daguang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05336",
    "title": "Elastic Founder Graphs Improved and Enhanced",
    "abstract": "Indexing labeled graphs for pattern matching is a central challenge of pangenomics. Equi et al. (Algorithmica, 2022) developed the Elastic Founder Graph ($\\mathsf{EFG}$) representing an alignment of $m$ sequences of length $n$, drawn from alphabet $\\Sigma$ plus the special gap character: the paths spell the original sequences or their recombination. By enforcing the semi-repeat-free property, the $\\mathsf{EFG}$ admits a polynomial-space index for linear-time pattern matching, breaking through the conditional lower bounds on indexing labeled graphs (Equi et al., SOFSEM 2021). In this work we improve the space of the $\\mathsf{EFG}$ index answering pattern matching queries in linear time, from linear in the length of all strings spelled by three consecutive node labels, to linear in the size of the edge labels. Then, we develop linear-time construction algorithms optimizing for different metrics: we improve the existing linearithmic construction algorithms to $O(mn)$, by solving the novel exclusive ancestor set problem on trees; we propose, for the simplified gapless setting, an $O(mn)$-time solution minimizing the maximum block height, that we generalize by substituting block height with prefix-aware height. Finally, to show the versatility of the framework, we develop a BWT-based $\\mathsf{EFG}$ index and study how to encode and perform document listing queries on a set of paths of the graphs, reporting which paths present a given pattern as a substring. We propose the $\\mathsf{EFG}$ framework as an improved and enhanced version of the framework for the gapless setting, along with construction methods that are valid in any setting concerned with the segmentation of aligned sequences. ",
    "url": "https://arxiv.org/abs/2303.05336",
    "authors": [
      "Nicola Rizzo",
      "Massimo Equi",
      "Tuukka Norri",
      "Veli M\u00e4kinen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2303.05342",
    "title": "Knowledge-augmented Few-shot Visual Relation Detection",
    "abstract": "Visual Relation Detection (VRD) aims to detect relationships between objects for image understanding. Most existing VRD methods rely on thousands of training samples of each relationship to achieve satisfactory performance. Some recent papers tackle this problem by few-shot learning with elaborately designed pipelines and pre-trained word vectors. However, the performance of existing few-shot VRD models is severely hampered by the poor generalization capability, as they struggle to handle the vast semantic diversity of visual relationships. Nonetheless, humans have the ability to learn new relationships with just few examples based on their knowledge. Inspired by this, we devise a knowledge-augmented, few-shot VRD framework leveraging both textual knowledge and visual relation knowledge to improve the generalization ability of few-shot VRD. The textual knowledge and visual relation knowledge are acquired from a pre-trained language model and an automatically constructed visual relation knowledge graph, respectively. We extensively validate the effectiveness of our framework. Experiments conducted on three benchmarks from the commonly used Visual Genome dataset show that our performance surpasses existing state-of-the-art models with a large improvement. ",
    "url": "https://arxiv.org/abs/2303.05342",
    "authors": [
      "Tianyu Yu",
      "Yangning Li",
      "Jiaoyan Chen",
      "Yinghui Li",
      "Hai-Tao Zheng",
      "Xi Chen",
      "Qingbin Liu",
      "Wenqiang Liu",
      "Dongxiao Huang",
      "Bei Wu",
      "Yexin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05367",
    "title": "Rethinking Range View Representation for LiDAR Segmentation",
    "abstract": "LiDAR segmentation is crucial for autonomous driving perception. Recent trends favor point- or voxel-based methods as they often yield better performance than the traditional range view representation. In this work, we unveil several key factors in building powerful range view models. We observe that the \"many-to-one\" mapping, semantic incoherence, and shape deformation are possible impediments against effective learning from range view projections. We present RangeFormer -- a full-cycle framework comprising novel designs across network architecture, data augmentation, and post-processing -- that better handles the learning and processing of LiDAR point clouds from the range view. We further introduce a Scalable Training from Range view (STR) strategy that trains on arbitrary low-resolution 2D range images, while still maintaining satisfactory 3D segmentation accuracy. We show that, for the first time, a range view method is able to surpass the point, voxel, and multi-view fusion counterparts in the competing LiDAR semantic and panoptic segmentation benchmarks, i.e., SemanticKITTI, nuScenes, and ScribbleKITTI. ",
    "url": "https://arxiv.org/abs/2303.05367",
    "authors": [
      "Lingdong Kong",
      "Youquan Liu",
      "Runnan Chen",
      "Yuexin Ma",
      "Xinge Zhu",
      "Yikang Li",
      "Yuenan Hou",
      "Yu Qiao",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05370",
    "title": "Rethinking Self-Supervised Visual Representation Learning in  Pre-training for 3D Human Pose and Shape Estimation",
    "abstract": "Recently, a few self-supervised representation learning (SSL) methods have outperformed the ImageNet classification pre-training for vision tasks such as object detection. However, its effects on 3D human body pose and shape estimation (3DHPSE) are open to question, whose target is fixed to a unique class, the human, and has an inherent task gap with SSL. We empirically study and analyze the effects of SSL and further compare it with other pre-training alternatives for 3DHPSE. The alternatives are 2D annotation-based pre-training and synthetic data pre-training, which share the motivation of SSL that aims to reduce the labeling cost. They have been widely utilized as a source of weak-supervision or fine-tuning, but have not been remarked as a pre-training source. SSL methods underperform the conventional ImageNet classification pre-training on multiple 3DHPSE benchmarks by 7.7% on average. In contrast, despite a much less amount of pre-training data, the 2D annotation-based pre-training improves accuracy on all benchmarks and shows faster convergence during fine-tuning. Our observations challenge the naive application of the current SSL pre-training to 3DHPSE and relight the value of other data types in the pre-training aspect. ",
    "url": "https://arxiv.org/abs/2303.05370",
    "authors": [
      "Hongsuk Choi",
      "Hyeongjin Nam",
      "Taeryung Lee",
      "Gyeongsik Moon",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05378",
    "title": "Greener yet Powerful: Taming Large Code Generation Models with  Quantization",
    "abstract": "ML-powered code generation aims to assist developers to write code in a more productive manner, by intelligently generating code blocks based on natural language prompts. Recently, large pretrained deep learning models have substantially pushed the boundary of code generation and achieved impressive performance. Despite their great power, the huge number of model parameters poses a significant threat to adapting them in a regular software development environment, where a developer might use a standard laptop or mid-size server to develop her code. Such large models incur significant resource usage (in terms of memory, latency, and dollars) as well as carbon footprint. Model compression is a promising approach to address these challenges. Several techniques are proposed to compress large pretrained models typically used for vision or textual data. Out of many available compression techniques, we identified that quantization is mostly applicable for code generation task as it does not require significant retraining cost. As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation. We extensively study the impact of quantized model on code generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation. We further found the recipe is readily applicable to code summarization task as well. ",
    "url": "https://arxiv.org/abs/2303.05378",
    "authors": [
      "Xiaokai Wei",
      "Sujan Gonugondla",
      "Wasi Ahmad",
      "Shiqi Wang",
      "Baishakhi Ray",
      "Haifeng Qian",
      "Xiaopeng Li",
      "Varun Kumar",
      "Zijian Wang",
      "Yuchen Tian",
      "Qing Sun",
      "Ben Athiwaratkun",
      "Mingyue Shang",
      "Murali Krishna Ramanathan",
      "Parminder Bhatia",
      "Bing Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.05385",
    "title": "PyGenStability: Multiscale community detection with generalized Markov  Stability",
    "abstract": "We present PyGenStability, a general-use Python software package that provides a suite of analysis and visualisation tools for unsupervised multiscale community detection in graphs. PyGenStability finds optimized partitions of a graph at different levels of resolution by maximizing the generalized Markov Stability quality function with the Louvain or Leiden algorithms. The package includes automatic detection of robust graph partitions and allows the flexibility to choose quality functions for weighted undirected, directed and signed graphs, and to include other user-defined quality functions. The code and documentation are hosted on GitHub under a GNU General Public License at https://github.com/barahona-research-group/PyGenStability. ",
    "url": "https://arxiv.org/abs/2303.05385",
    "authors": [
      "Alexis Arnaudon",
      "Dominik J. Schindler",
      "Robert L. Peach",
      "Adam Gosztolai",
      "Maxwell Hodges",
      "Michael T. Schaub",
      "Mauricio Barahona"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2303.05387",
    "title": "Automatic Detection of Industry Sectors in Legal Articles Using Machine  Learning Approaches",
    "abstract": "The ability to automatically identify industry sector coverage in articles on legal developments, or any kind of news articles for that matter, can bring plentiful of benefits both to the readers and the content creators themselves. By having articles tagged based on industry coverage, readers from all around the world would be able to get to legal news that are specific to their region and professional industry. Simultaneously, writers would benefit from understanding which industries potentially lack coverage or which industries readers are currently mostly interested in and thus, they would focus their writing efforts towards more inclusive and relevant legal news coverage. In this paper, a Machine Learning-powered industry analysis approach which combined Natural Language Processing (NLP) with Statistical and Machine Learning (ML) techniques was investigated. A dataset consisting of over 1,700 annotated legal articles was created for the identification of six industry sectors. Text and legal based features were extracted from the text. Both traditional ML methods (e.g. gradient boosting machine algorithms, and decision-tree based algorithms) and deep neural network (e.g. transformer models) were applied for performance comparison of predictive models. The system achieved promising results with area under the receiver operating characteristic curve scores above 0.90 and F-scores above 0.81 with respect to the six industry sectors. The experimental results show that the suggested automated industry analysis which employs ML techniques allows the processing of large collections of text data in an easy, efficient, and scalable way. Traditional ML methods perform better than deep neural networks when only a small and domain-specific training data is available for the study. ",
    "url": "https://arxiv.org/abs/2303.05387",
    "authors": [
      "Hui Yang",
      "Stella Hadjiantoni",
      "Yunfei Long",
      "Ruta Petraityte",
      "Berthold Lausen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05389",
    "title": "Depression Detection Using Digital Traces on Social Media: A  Knowledge-aware Deep Learning Approach",
    "abstract": "Depression is a common disease worldwide. It is difficult to diagnose and continues to be underdiagnosed. Because depressed patients constantly share their symptoms, major life events, and treatments on social media, researchers are turning to user-generated digital traces on social media for depression detection. Such methods have distinct advantages in combating depression because they can facilitate innovative approaches to fight depression and alleviate its social and economic burden. However, most existing studies lack effective means to incorporate established medical domain knowledge in depression detection or suffer from feature extraction difficulties that impede greater performance. Following the design science research paradigm, we propose a Deep Knowledge-aware Depression Detection (DKDD) framework to accurately detect social media users at risk of depression and explain the critical factors that contribute to such detection. Extensive empirical studies with real-world data demonstrate that, by incorporating domain knowledge, our method outperforms existing state-of-the-art methods. Our work has significant implications for IS research in knowledge-aware machine learning, digital traces utilization, and NLP research in IS. Practically, by providing early detection and explaining the critical factors, DKDD can supplement clinical depression screening and enable large-scale evaluations of a population's mental health status. ",
    "url": "https://arxiv.org/abs/2303.05389",
    "authors": [
      "Wenli Zhang",
      "Jiaheng Xie",
      "Xiang Liu",
      "Zhu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2303.05391",
    "title": "Disambiguation of Company names via Deep Recurrent Networks",
    "abstract": "Name Entity Disambiguation is the Natural Language Processing task of identifying textual records corresponding to the same Named Entity, i.e. real-world entities represented as a list of attributes (names, places, organisations, etc.). In this work, we face the task of disambiguating companies on the basis of their written names. We propose a Siamese LSTM Network approach to extract -- via supervised learning -- an embedding of company name strings in a (relatively) low dimensional vector space and use this representation to identify pairs of company names that actually represent the same company (i.e. the same Entity). Given that the manual labelling of string pairs is a rather onerous task, we analyse how an Active Learning approach to prioritise the samples to be labelled leads to a more efficient overall learning pipeline. With empirical investigations, we show that our proposed Siamese Network outperforms several benchmark approaches based on standard string matching algorithms when enough labelled data are available. Moreover, we show that Active Learning prioritisation is indeed helpful when labelling resources are limited, and let the learning models reach the out-of-sample performance saturation with less labelled data with respect to standard (random) data labelling approaches. ",
    "url": "https://arxiv.org/abs/2303.05391",
    "authors": [
      "Alessandro Basile",
      "Riccardo Crupi",
      "Michele Grasso",
      "Alessandro Mercanti",
      "Daniele Regoli",
      "Simone Scarsi",
      "Shuyi Yang",
      "Andrea Cosentini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05393",
    "title": "Deep Functional Predictive Control for Strawberry Cluster Manipulation  using Tactile Prediction",
    "abstract": "This paper introduces a novel approach to address the problem of Physical Robot Interaction (PRI) during robot pushing tasks. The approach uses a data-driven forward model based on tactile predictions to inform the controller about potential future movements of the object being pushed, such as a strawberry stem, using a robot tactile finger. The model is integrated into a Deep Functional Predictive Control (d-FPC) system to control the displacement of the stem on the tactile finger during pushes. Pushing an object with a robot finger along a desired trajectory in 3D is a highly nonlinear and complex physical robot interaction, especially when the object is not stably grasped. The proposed approach controls the stem movements on the tactile finger in a prediction horizon. The effectiveness of the proposed FPC is demonstrated in a series of tests involving a real robot pushing a strawberry in a cluster. The results indicate that the d-FPC controller can successfully control PRI in robotic manipulation tasks beyond the handling of strawberries. The proposed approach offers a promising direction for addressing the challenging PRI problem in robotic manipulation tasks. Future work will explore the generalisation of the approach to other objects and tasks. ",
    "url": "https://arxiv.org/abs/2303.05393",
    "authors": [
      "Kiyanoush Nazari",
      "Gabriele Gandolfi",
      "Zeynab Talebpour",
      "Vishnu Rajendran",
      "Paolo Rocco",
      "Amir Ghalamzan E."
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05400",
    "title": "Prompt-Based Learning for Thread Structure Prediction in Cybersecurity  Forums",
    "abstract": "With recent trends indicating cyber crimes increasing in both frequency and cost, it is imperative to develop new methods that leverage data-rich hacker forums to assist in combating ever evolving cyber threats. Defining interactions within these forums is critical as it facilitates identifying highly skilled users, which can improve prediction of novel threats and future cyber attacks. We propose a method called Next Paragraph Prediction with Instructional Prompting (NPP-IP) to predict thread structures while grounded on the context around posts. This is the first time to apply an instructional prompting approach to the cybersecurity domain. We evaluate our NPP-IP with the Reddit dataset and Hacker Forums dataset that has posts and thread structures of real hacker forums' threads, and compare our method's performance with existing methods. The experimental evaluation shows that our proposed method can predict the thread structure significantly better than existing methods allowing for better social network prediction based on forum interactions. ",
    "url": "https://arxiv.org/abs/2303.05400",
    "authors": [
      "Kazuaki Kashihara",
      "Kuntal Kumar Pal",
      "Chitta Baral",
      "Robert P Trevino"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.05401",
    "title": "Early Warning Signals of Social Instabilities in Twitter Data",
    "abstract": "The goal of this project is to create and study novel techniques to identify early warning signals for socially disruptive events, like riots, wars, or revolutions using only publicly available data on social media. Such techniques need to be robust enough to work on real-time data: to achieve this goal we propose a topological approach together with more standard BERT models. Indeed, topology-based algorithms, being provably stable against deformations and noise, seem to work well in low-data regimes. The general idea is to build a binary classifier that predicts if a given tweet is related to a disruptive event or not. The results indicate that the persistent-gradient approach is stable and even more performant than deep-learning-based anomaly detection algorithms. We also benchmark the generalisability of the methodology against out-of-samples tasks, with very promising results. ",
    "url": "https://arxiv.org/abs/2303.05401",
    "authors": [
      "Vahid Shamsaddini",
      "Henry Kirveslahti",
      "Raphael Reinauer",
      "Wallyson Lemes de Oliveira",
      "Matteo Caorsi",
      "Etienne Voutaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.05404",
    "title": "On Onboard LiDAR-based Flying Object Detection",
    "abstract": "A new robust and accurate approach for the detection and localization of flying objects with the purpose of highly dynamic aerial interception and agile multi-robot interaction is presented in this paper. The approach is proposed for use onboard an autonomous aerial vehicle equipped with a 3D LiDAR sensor providing input data for the algorithm. It relies on a novel 3D occupancy voxel mapping method for the target detection and a cluster-based multiple hypothesis tracker to compensate uncertainty of the sensory data. When compared to state-of-the-art methods of onboard detection of other flying objects, the presented approach provides superior localization accuracy and robustness to different environments and appearance changes of the target, as well as a greater detection range. Furthermore, in combination with the proposed multi-target tracker, sporadic false positives are suppressed, state estimation of the target is provided and the detection latency is negligible. This makes the detector suitable for tasks of agile multi-robot interaction, such as autonomous aerial interception or formation control where precise, robust, and fast relative localization of other robots is crucial. We demonstrate the practical usability and performance of the system in simulated and real-world experiments. ",
    "url": "https://arxiv.org/abs/2303.05404",
    "authors": [
      "Matou\u0161 Vrba",
      "Viktor Walter",
      "Martin Saska"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05408",
    "title": "Fast algorithms for Vizing's theorem on bounded degree graphs",
    "abstract": "Vizing's theorem states that every graph $G$ of maximum degree $\\Delta$ can be properly edge-colored using $\\Delta + 1$ colors. The fastest currently known $(\\Delta+1)$-edge-coloring algorithm for general graphs is due to Sinnamon and runs in time $O(m\\sqrt{n})$, where $n = |V(G)|$ and $m =|E(G)|$. Using the bound $m \\leq \\Delta n/2$, the running time of Sinnamon's algorithm can be expressed as $O(\\Delta n^{3/2})$. In the regime when $\\Delta$ is considerably smaller than $n$ (for instance, when $\\Delta$ is a constant), this can be improved, as Gabow, Nishizeki, Kariv, Leven, and Terada designed an algorithm with running time $O(\\Delta m \\log n) = O(\\Delta^2 n \\log n)$. Here we give an algorithm whose running time is only linear in $n$ (which is obviously best possible) and polynomial in $\\Delta$. We also develop new algorithms for $(\\Delta+1)$-edge-coloring in the $\\mathsf{LOCAL}$ model of distributed computation. Namely, we design a deterministic $\\mathsf{LOCAL}$ algorithm with running time $\\mathsf{poly}(\\Delta, \\log\\log n) \\log^5 n$ and a randomized $\\mathsf{LOCAL}$ algorithm with running time $\\mathsf{poly}(\\Delta) \\log^2 n$. The key new ingredient in our algorithms is a novel application of the entropy compression method. ",
    "url": "https://arxiv.org/abs/2303.05408",
    "authors": [
      "Anton Bernshteyn",
      "Abhishek Dhawan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2303.05416",
    "title": "FaceXHuBERT: Text-less Speech-driven E(X)pressive 3D Facial Animation  Synthesis Using Self-Supervised Speech Representation Learning",
    "abstract": "This paper presents FaceXHuBERT, a text-less speech-driven 3D facial animation generation method that allows to capture personalized and subtle cues in speech (e.g. identity, emotion and hesitation). It is also very robust to background noise and can handle audio recorded in a variety of situations (e.g. multiple people speaking). Recent approaches employ end-to-end deep learning taking into account both audio and text as input to generate facial animation for the whole face. However, scarcity of publicly available expressive audio-3D facial animation datasets poses a major bottleneck. The resulting animations still have issues regarding accurate lip-synching, expressivity, person-specific information and generalizability. We effectively employ self-supervised pretrained HuBERT model in the training process that allows us to incorporate both lexical and non-lexical information in the audio without using a large lexicon. Additionally, guiding the training with a binary emotion condition and speaker identity distinguishes the tiniest subtle facial motion. We carried out extensive objective and subjective evaluation in comparison to ground-truth and state-of-the-art work. A perceptual user study demonstrates that our approach produces superior results with respect to the realism of the animation 78% of the time in comparison to the state-of-the-art. In addition, our method is 4 times faster eliminating the use of complex sequential models such as transformers. We strongly recommend watching the supplementary video before reading the paper. We also provide the implementation and evaluation codes with a GitHub repository link. ",
    "url": "https://arxiv.org/abs/2303.05416",
    "authors": [
      "Kazi Injamamul Haque",
      "Zerrin Yumak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05445",
    "title": "Communication-Efficient Collaborative Heterogeneous Bandits in Networks",
    "abstract": "The multi-agent multi-armed bandit problem has been studied extensively due to its ubiquity in many real-life applications, such as online recommendation systems and wireless networking. We consider the setting where agents should minimize their group regret while collaborating over a given graph via some communication protocol and where each agent is given a different set of arms. Previous literature on this problem only considered one of the two desired features separately: agents with the same arm set communicate over a general graph, or agents with different arm sets communicate over a fully connected graph. In this work, we introduce a more general problem setting that encompasses all the desired features. For this novel setting, we first provide a rigorous regret analysis for the standard flooding protocol combined with the UCB policy. Then, to mitigate the issue of high communication costs incurred by flooding, we propose a new protocol called Flooding with Absorption (FWA). We provide a theoretical analysis of the regret bound and intuitions on the advantages of using FWA over flooding. Lastly, we verify empirically that using FWA leads to significantly lower communication costs despite minimal regret performance loss compared to flooding. ",
    "url": "https://arxiv.org/abs/2303.05445",
    "authors": [
      "Junghyun Lee",
      "Laura Schmid",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05459",
    "title": "Presentation Attack Detection with Advanced CNN Models for  Noncontact-based Fingerprint Systems",
    "abstract": "Touch-based fingerprint biometrics is one of the most popular biometric modalities with applications in several fields. Problems associated with touch-based techniques such as the presence of latent fingerprints and hygiene issues due to many people touching the same surface motivated the community to look for non-contact-based solutions. For the last few years, contactless fingerprint systems are on the rise and in demand because of the ability to turn any device with a camera into a fingerprint reader. Yet, before we can fully utilize the benefit of noncontact-based methods, the biometric community needs to resolve a few concerns such as the resiliency of the system against presentation attacks. One of the major obstacles is the limited publicly available data sets with inadequate spoof and live data. In this publication, we have developed a Presentation attack detection (PAD) dataset of more than 7500 four-finger images and more than 14,000 manually segmented single-fingertip images, and 10,000 synthetic fingertips (deepfakes). The PAD dataset was collected from six different Presentation Attack Instruments (PAI) of three different difficulty levels according to FIDO protocols, with five different types of PAI materials, and different smartphone cameras with manual focusing. We have utilized DenseNet-121 and NasNetMobile models and our proposed dataset to develop PAD algorithms and achieved PAD accuracy of Attack presentation classification error rate (APCER) 0.14\\% and Bonafide presentation classification error rate (BPCER) 0.18\\%. We have also reported the test results of the models against unseen spoof types to replicate uncertain real-world testing scenarios. ",
    "url": "https://arxiv.org/abs/2303.05459",
    "authors": [
      "Sandip Purnapatra",
      "Conor Miller-Lynch",
      "Stephen Miner",
      "Yu Liu",
      "Keivan Bahmani",
      "Soumyabrata Dey",
      "Stephanie Schuckers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05463",
    "title": "Understanding the Challenges and Opportunities of Pose-based Anomaly  Detection",
    "abstract": "Pose-based anomaly detection is a video-analysis technique for detecting anomalous events or behaviors by examining human pose extracted from the video frames. Utilizing pose data alleviates privacy and ethical issues. Also, computation-wise, the complexity of pose-based models is lower than pixel-based approaches. However, it introduces more challenges, such as noisy skeleton data, losing important pixel information, and not having enriched enough features. These problems are exacerbated by a lack of anomaly detection datasets that are good enough representatives of real-world scenarios. In this work, we analyze and quantify the characteristics of two well-known video anomaly datasets to better understand the difficulties of pose-based anomaly detection. We take a step forward, exploring the discriminating power of pose and trajectory for video anomaly detection and their effectiveness based on context. We believe these experiments are beneficial for a better comprehension of pose-based anomaly detection and the datasets currently available. This will aid researchers in tackling the task of anomaly detection with a more lucid perspective, accelerating the development of robust models with better performance. ",
    "url": "https://arxiv.org/abs/2303.05463",
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Vinit Katariya",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05480",
    "title": "Designing Ocean Vision AI: An Investigation of Community Needs for  Imaging-based Ocean Conservation",
    "abstract": "Ocean scientists studying diverse organisms and phenomena increasingly rely on imaging devices for their research. These scientists have many tools to collect their data, but few resources for automated analysis. In this paper, we report on discussions with diverse stakeholders to identify community needs and develop a set of functional requirements for the ongoing development of ocean science-specific analysis tools. We conducted 36 in-depth interviews with individuals working in the Blue Economy space, revealing four central issues inhibiting the development of effective imaging analysis monitoring tools for marine science. We also identified twelve user archetypes that will engage with these services. Additionally, we held a workshop with 246 participants from 35 countries centered around FathomNet, a web-based open-source annotated image database for marine research. Findings from these discussions are being used to define the feature set and interface design of Ocean Vision AI, a suite of tools and services to advance observational capabilities of life in the ocean. ",
    "url": "https://arxiv.org/abs/2303.05480",
    "authors": [
      "Alison Crosby",
      "Eric C. Orenstein",
      "Susan E. Poulton",
      "Katherine L.C. Bell",
      "Benjamin Woodward",
      "Henry Ruhl",
      "Kakani Katija",
      "Angus G. Forbes"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.05485",
    "title": "Efficient Testable Learning of Halfspaces with Adversarial Label Noise",
    "abstract": "We give the first polynomial-time algorithm for the testable learning of halfspaces in the presence of adversarial label noise under the Gaussian distribution. In the recently introduced testable learning model, one is required to produce a tester-learner such that if the data passes the tester, then one can trust the output of the robust learner on the data. Our tester-learner runs in time $\\poly(d/\\eps)$ and outputs a halfspace with misclassification error $O(\\opt)+\\eps$, where $\\opt$ is the 0-1 error of the best fitting halfspace. At a technical level, our algorithm employs an iterative soft localization technique enhanced with appropriate testers to ensure that the data distribution is sufficiently similar to a Gaussian. ",
    "url": "https://arxiv.org/abs/2303.05485",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Vasilis Kontonis",
      "Sihan Liu",
      "Nikos Zarifis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05490",
    "title": "On the Expressiveness and Generalization of Hypergraph Neural Networks",
    "abstract": "This extended abstract describes a framework for analyzing the expressiveness, learning, and (structural) generalization of hypergraph neural networks (HyperGNNs). Specifically, we focus on how HyperGNNs can learn from finite datasets and generalize structurally to graph reasoning problems of arbitrary input sizes. Our first contribution is a fine-grained analysis of the expressiveness of HyperGNNs, that is, the set of functions that they can realize. Our result is a hierarchy of problems they can solve, defined in terms of various hyperparameters such as depths and edge arities. Next, we analyze the learning properties of these neural networks, especially focusing on how they can be trained on a finite set of small graphs and generalize to larger graphs, which we term structural generalization. Our theoretical results are further supported by the empirical results. ",
    "url": "https://arxiv.org/abs/2303.05490",
    "authors": [
      "Zhezheng Luo",
      "Jiayuan Mao",
      "Joshua B. Tenenbaum",
      "Leslie Pack Kaelbling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05496",
    "title": "Sparse and Local Networks for Hypergraph Reasoning",
    "abstract": "Reasoning about the relationships between entities from input facts (e.g., whether Ari is a grandparent of Charlie) generally requires explicit consideration of other entities that are not mentioned in the query (e.g., the parents of Charlie). In this paper, we present an approach for learning to solve problems of this kind in large, real-world domains, using sparse and local hypergraph neural networks (SpaLoc). SpaLoc is motivated by two observations from traditional logic-based reasoning: relational inferences usually apply locally (i.e., involve only a small number of individuals), and relations are usually sparse (i.e., only hold for a small percentage of tuples in a domain). We exploit these properties to make learning and inference efficient in very large domains by (1) using a sparse tensor representation for hypergraph neural networks, (2) applying a sparsification loss during training to encourage sparse representations, and (3) subsampling based on a novel information sufficiency-based sampling process during training. SpaLoc achieves state-of-the-art performance on several real-world, large-scale knowledge graph reasoning benchmarks, and is the first framework for applying hypergraph neural networks on real-world knowledge graphs with more than 10k nodes. ",
    "url": "https://arxiv.org/abs/2303.05496",
    "authors": [
      "Guangxuan Xiao",
      "Leslie Pack Kaelbling",
      "Jiajun Wu",
      "Jiayuan Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05499",
    "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set  Object Detection",
    "abstract": "In this paper, we present an open-set object detector, called Grounding DINO, by marrying Transformer-based detector DINO with grounded pre-training, which can detect arbitrary objects with human inputs such as category names or referring expressions. The key solution of open-set object detection is introducing language to a closed-set detector for open-set concept generalization. To effectively fuse language and vision modalities, we conceptually divide a closed-set detector into three phases and propose a tight fusion solution, which includes a feature enhancer, a language-guided query selection, and a cross-modality decoder for cross-modality fusion. While previous works mainly evaluate open-set object detection on novel categories, we propose to also perform evaluations on referring expression comprehension for objects specified with attributes. Grounding DINO performs remarkably well on all three settings, including benchmarks on COCO, LVIS, ODinW, and RefCOCO/+/g. Grounding DINO achieves a $52.5$ AP on the COCO detection zero-shot transfer benchmark, i.e., without any training data from COCO. It sets a new record on the ODinW zero-shot benchmark with a mean $26.1$ AP. Code will be available at \\url{https://github.com/IDEA-Research/GroundingDINO}. ",
    "url": "https://arxiv.org/abs/2303.05499",
    "authors": [
      "Shilong Liu",
      "Zhaoyang Zeng",
      "Tianhe Ren",
      "Feng Li",
      "Hao Zhang",
      "Jie Yang",
      "Chunyuan Li",
      "Jianwei Yang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05506",
    "title": "TANGOS: Regularizing Tabular Neural Networks through Gradient  Orthogonalization and Specialization",
    "abstract": "Despite their success with unstructured data, deep neural networks are not yet a panacea for structured tabular data. In the tabular domain, their efficiency crucially relies on various forms of regularization to prevent overfitting and provide strong generalization performance. Existing regularization techniques include broad modelling decisions such as choice of architecture, loss functions, and optimization methods. In this work, we introduce Tabular Neural Gradient Orthogonalization and Specialization (TANGOS), a novel framework for regularization in the tabular setting built on latent unit attributions. The gradient attribution of an activation with respect to a given input feature suggests how the neuron attends to that feature, and is often employed to interpret the predictions of deep networks. In TANGOS, we take a different approach and incorporate neuron attributions directly into training to encourage orthogonalization and specialization of latent attributions in a fully-connected network. Our regularizer encourages neurons to focus on sparse, non-overlapping input features and results in a set of diverse and specialized latent units. In the tabular domain, we demonstrate that our approach can lead to improved out-of-sample generalization performance, outperforming other popular regularization methods. We provide insight into why our regularizer is effective and demonstrate that TANGOS can be applied jointly with existing methods to achieve even greater generalization performance. ",
    "url": "https://arxiv.org/abs/2303.05506",
    "authors": [
      "Alan Jeffares",
      "Tennison Liu",
      "Jonathan Crabb\u00e9",
      "Fergus Imrie",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05510",
    "title": "Planning with Large Language Models for Code Generation",
    "abstract": "Existing large language model-based code generation pipelines typically use beam search or sampling algorithms during the decoding process. Although the programs they generate achieve high token-matching-based scores, they often fail to compile or generate incorrect outputs. The main reason is that conventional Transformer decoding algorithms may not be the best choice for code generation. In this work, we propose a novel Transformer decoding algorithm, Planning-Guided Transformer Decoding (PG-TD), that uses a planning algorithm to do lookahead search and guide the Transformer to generate better programs. Specifically, instead of simply optimizing the likelihood of the generated sequences, the Transformer makes use of a planner to generate candidate programs and test them on public test cases. The Transformer can therefore make more informed decisions and generate tokens that will eventually lead to higher-quality programs. We also design a mechanism that shares information between the Transformer and the planner to make our algorithm computationally efficient. We empirically evaluate our framework with several large language models as backbones on public coding challenge benchmarks, showing that 1) it can generate programs that consistently achieve higher performance compared with competing baseline methods; 2) it enables controllable code generation, such as concise codes and highly-commented codes by optimizing modified objective. ",
    "url": "https://arxiv.org/abs/2303.05510",
    "authors": [
      "Shun Zhang",
      "Zhenfang Chen",
      "Yikang Shen",
      "Mingyu Ding",
      "Joshua B. Tenenbaum",
      "Chuang Gan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2303.05512",
    "title": "PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for  Geometry-Agnostic System Identification",
    "abstract": "Existing approaches to system identification (estimating the physical parameters of an object) from videos assume known object geometries. This precludes their applicability in a vast majority of scenes where object geometries are complex or unknown. In this work, we aim to identify parameters characterizing a physical system from a set of multi-view videos without any assumption on object geometry or topology. To this end, we propose \"Physics Augmented Continuum Neural Radiance Fields\" (PAC-NeRF), to estimate both the unknown geometry and physical parameters of highly dynamic objects from multi-view videos. We design PAC-NeRF to only ever produce physically plausible states by enforcing the neural radiance field to follow the conservation laws of continuum mechanics. For this, we design a hybrid Eulerian-Lagrangian representation of the neural radiance field, i.e., we use the Eulerian grid representation for NeRF density and color fields, while advecting the neural radiance fields via Lagrangian particles. This hybrid Eulerian-Lagrangian representation seamlessly blends efficient neural rendering with the material point method (MPM) for robust differentiable physics simulation. We validate the effectiveness of our proposed framework on geometry and physical parameter estimation over a vast range of materials, including elastic bodies, plasticine, sand, Newtonian and non-Newtonian fluids, and demonstrate significant performance gain on most tasks. ",
    "url": "https://arxiv.org/abs/2303.05512",
    "authors": [
      "Xuan Li",
      "Yi-Ling Qiao",
      "Peter Yichen Chen",
      "Krishna Murthy Jatavallabhula",
      "Ming Lin",
      "Chenfanfu Jiang",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.04833",
    "title": "Finding Regularized Competitive Equilibria of Heterogeneous Agent  Macroeconomic Models with Reinforcement Learning",
    "abstract": "We study a heterogeneous agent macroeconomic model with an infinite number of households and firms competing in a labor market. Each household earns income and engages in consumption at each time step while aiming to maximize a concave utility subject to the underlying market conditions. The households aim to find the optimal saving strategy that maximizes their discounted cumulative utility given the market condition, while the firms determine the market conditions through maximizing corporate profit based on the household population behavior. The model captures a wide range of applications in macroeconomic studies, and we propose a data-driven reinforcement learning framework that finds the regularized competitive equilibrium of the model. The proposed algorithm enjoys theoretical guarantees in converging to the equilibrium of the market at a sub-linear rate. ",
    "url": "https://arxiv.org/abs/2303.04833",
    "authors": [
      "Ruitu Xu",
      "Yifei Min",
      "Tianhao Wang",
      "Zhaoran Wang",
      "Michael I. Jordan",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04874",
    "title": "Bayesian Causal Forests for Multivariate Outcomes: Application to Irish  Data From an International Large Scale Education Assessment",
    "abstract": "Bayesian Causal Forests (BCF) is a causal inference machine learning model based on a highly flexible non-parametric regression and classification tool called Bayesian Additive Regression Trees (BART). Motivated by data from the Trends in International Mathematics and Science Study (TIMSS), which includes data on student achievement in both mathematics and science, we present a multivariate extension of the BCF algorithm. With the help of simulation studies we show that our approach can accurately estimate causal effects for multiple outcomes subject to the same treatment. We also apply our model to Irish data from TIMSS 2019. Our findings reveal the positive effects of having access to a study desk at home (Mathematics ATE 95% CI: [0.20, 11.67]) while also highlighting the negative consequences of students often feeling hungry at school (Mathematics ATE 95% CI: [-11.15, -2.78] , Science ATE 95% CI: [-10.82,-1.72]) or often being absent (Mathematics ATE 95% CI: [-12.47, -1.55]). ",
    "url": "https://arxiv.org/abs/2303.04874",
    "authors": [
      "Nathan McJames",
      "Andrew Parnell",
      "Yong Chen Goh",
      "Ann O'Shea"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2303.04982",
    "title": "The Robustness Verification of Linear Sound Quantum Classifiers",
    "abstract": "I present a quick and sound method for the robustness verification of a sort of quantum classifiers who are Linear Sound. Since quantum machine learning has been put into practice in relevant fields and Linear Sound Property, LSP is a pervasive property, the method could be universally applied. I implemented my method with a Quantum Convolutional Neural Network, QCNN using MindQuantum, Huawei and successfully verified its robustness when classifying MNIST dataset. ",
    "url": "https://arxiv.org/abs/2303.04982",
    "authors": [
      "Su Bonan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05023",
    "title": "X-SepFormer: End-to-end Speaker Extraction Network with Explicit  Optimization on Speaker Confusion",
    "abstract": "Target speech extraction (TSE) systems are designed to extract target speech from a multi-talker mixture. The popular training objective for most prior TSE networks is to enhance reconstruction performance of extracted speech waveform. However, it has been reported that a TSE system delivers high reconstruction performance may still suffer low-quality experience problems in practice. One such experience problem is wrong speaker extraction (called speaker confusion, SC), which leads to strong negative experience and hampers effective conversations. To mitigate the imperative SC issue, we reformulate the training objective and propose two novel loss schemes that explore the metric of reconstruction improvement performance defined at small chunk-level and leverage the metric associated distribution information. Both loss schemes aim to encourage a TSE network to pay attention to those SC chunks based on the said distribution information. On this basis, we present X-SepFormer, an end-to-end TSE model with proposed loss schemes and a backbone of SepFormer. Experimental results on the benchmark WSJ0-2mix dataset validate the effectiveness of our proposals, showing consistent improvements on SC errors (by 14.8% relative). Moreover, with SI-SDRi of 19.4 dB and PESQ of 3.81, our best system significantly outperforms the current SOTA systems and offers the top TSE results reported till date on the WSJ0-2mix. ",
    "url": "https://arxiv.org/abs/2303.05023",
    "authors": [
      "Kai Liu",
      "Ziqing Du",
      "Xucheng Wan",
      "Huan Zhou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2303.05024",
    "title": "Phase transition for detecting a small community in a large network",
    "abstract": "How to detect a small community in a large network is an interesting problem, including clique detection as a special case, where a naive degree-based $\\chi^2$-test was shown to be powerful in the presence of an Erd\\H{o}s-Renyi background. Using Sinkhorn's theorem, we show that the signal captured by the $\\chi^2$-test may be a modeling artifact, and it may disappear once we replace the Erd\\H{o}s-Renyi model by a broader network model. We show that the recent SgnQ test is more appropriate for such a setting. The test is optimal in detecting communities with sizes comparable to the whole network, but has never been studied for our setting, which is substantially different and more challenging. Using a degree-corrected block model (DCBM), we establish phase transitions of this testing problem concerning the size of the small community and the edge densities in small and large communities. When the size of the small community is larger than $\\sqrt{n}$, the SgnQ test is optimal for it attains the computational lower bound (CLB), the information lower bound for methods allowing polynomial computation time. When the size of the small community is smaller than $\\sqrt{n}$, we establish the parameter regime where the SgnQ test has full power and make some conjectures of the CLB. We also study the classical information lower bound (LB) and show that there is always a gap between the CLB and LB in our range of interest. ",
    "url": "https://arxiv.org/abs/2303.05024",
    "authors": [
      "Jiashun Jin",
      "Zheng Tracy Ke",
      "Paxton Turner",
      "Anru R. Zhang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.05126",
    "title": "Hybrid Dual Mean-Teacher Network With Double-Uncertainty Guidance for  Semi-Supervised Segmentation of MRI Scans",
    "abstract": "Semi-supervised learning has made significant progress in medical image segmentation. However, existing methods primarily utilize information acquired from a single dimensionality (2D/3D), resulting in sub-optimal performance on challenging data, such as magnetic resonance imaging (MRI) scans with multiple objects and highly anisotropic resolution. To address this issue, we present a Hybrid Dual Mean-Teacher (HD-Teacher) model with hybrid, semi-supervised, and multi-task learning to achieve highly effective semi-supervised segmentation. HD-Teacher employs a 2D and a 3D mean-teacher network to produce segmentation labels and signed distance fields from the hybrid information captured in both dimensionalities. This hybrid learning mechanism allows HD-Teacher to combine the `best of both worlds', utilizing features extracted from either 2D, 3D, or both dimensions to produce outputs as it sees fit. Outputs from 2D and 3D teacher models are also dynamically combined, based on their individual uncertainty scores, into a single hybrid prediction, where the hybrid uncertainty is estimated. We then propose a hybrid regularization module to encourage both student models to produce results close to the uncertainty-weighted hybrid prediction. The hybrid uncertainty suppresses unreliable knowledge in the hybrid prediction, leaving only useful information to improve network performance further. Extensive experiments of binary and multi-class segmentation conducted on three MRI datasets demonstrate the effectiveness of the proposed framework. Code is available at https://github.com/ThisGame42/Hybrid-Teacher. ",
    "url": "https://arxiv.org/abs/2303.05126",
    "authors": [
      "Jiayi Zhu",
      "Bart Bolsterlee",
      "Brian V. Y. Chow",
      "Yang Song",
      "Erik Meijering"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05138",
    "title": "The joint node degree distribution in the Erd\u0151s-R\u00e9nyi network",
    "abstract": "The Erd\\H{o}s-R\\'enyi random graph is the simplest model for node degree distribution, and it is one of the most widely studied. In this model, pairs of $n$ vertices are selected and connected uniformly at random with probability $p$, consequently, the degrees for a given vertex follow the binomial distribution. If the number of vertices is large, the binomial can be approximated by Normal using the Central Limit Theorem, which is often allowed when $\\min (np, n(1-p)) > 5$. This is true for every node independently. However, due to the fact that the degrees of nodes in a graph are not independent, we aim in this paper to test whether the degrees of per node collectively in the Erd\\H{o}s-R\\'enyi graph have a multivariate normal distribution MVN. A chi square goodness of fit test for the hypothesis that binomial is a distribution for the whole set of nodes is rejected because of the dependence between degrees. Before testing MVN we show that the covariance and correlation between the degrees of any pair of nodes in the graph are $p(1-p)$ and $1/(n-1)$, respectively. We test MVN considering two assumptions: independent and dependent degrees, and we obtain our results based on the percentages of rejected statistics of chi square, the $p$-values of Anderson Darling test, and a CDF comparison. We always achieve a good fit of multivariate normal distribution with large values of $n$ and $p$, and very poor fit when $n$ or $p$ are very small. The approximation seems valid when $np \\geq 10$. We also compare the maximum likelihood estimate of $p$ in MVN distribution where we assume independence and dependence. The estimators are assessed using bias, variance and mean square error. ",
    "url": "https://arxiv.org/abs/2303.05138",
    "authors": [
      "Boshra Alarfaj",
      "Charles Taylor",
      "Leonid Bogachev"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2303.05302",
    "title": "M3AE: Multimodal Representation Learning for Brain Tumor Segmentation  with Missing Modalities",
    "abstract": "Multimodal magnetic resonance imaging (MRI) provides complementary information for sub-region analysis of brain tumors. Plenty of methods have been proposed for automatic brain tumor segmentation using four common MRI modalities and achieved remarkable performance. In practice, however, it is common to have one or more modalities missing due to image corruption, artifacts, acquisition protocols, allergy to contrast agents, or simply cost. In this work, we propose a novel two-stage framework for brain tumor segmentation with missing modalities. In the first stage, a multimodal masked autoencoder (M3AE) is proposed, where both random modalities (i.e., modality dropout) and random patches of the remaining modalities are masked for a reconstruction task, for self-supervised learning of robust multimodal representations against missing modalities. To this end, we name our framework M3AE. Meanwhile, we employ model inversion to optimize a representative full-modal image at marginal extra cost, which will be used to substitute for the missing modalities and boost performance during inference. Then in the second stage, a memory-efficient self distillation is proposed to distill knowledge between heterogenous missing-modal situations while fine-tuning the model for supervised segmentation. Our M3AE belongs to the 'catch-all' genre where a single model can be applied to all possible subsets of modalities, thus is economic for both training and deployment. Extensive experiments on BraTS 2018 and 2020 datasets demonstrate its superior performance to existing state-of-the-art methods with missing modalities, as well as the efficacy of its components. Our code is available at: https://github.com/ccarliu/m3ae. ",
    "url": "https://arxiv.org/abs/2303.05302",
    "authors": [
      "Hong Liu",
      "Dong Wei",
      "Donghuan Lu",
      "Jinghan Sun",
      "Liansheng Wang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05420",
    "title": "Kernel Regression with Infinite-Width Neural Networks on Millions of  Examples",
    "abstract": "Neural kernels have drastically increased performance on diverse and nonstandard data modalities but require significantly more compute, which previously limited their application to smaller datasets. In this work, we address this by massively parallelizing their computation across many GPUs. We combine this with a distributed, preconditioned conjugate gradients algorithm to enable kernel regression at a large scale (i.e. up to five million examples). Using this approach, we study scaling laws of several neural kernels across many orders of magnitude for the CIFAR-5m dataset. Using data augmentation to expand the original CIFAR-10 training dataset by a factor of 20, we obtain a test accuracy of 91.2\\% (SotA for a pure kernel method). Moreover, we explore neural kernels on other data modalities, obtaining results on protein and small molecule prediction tasks that are competitive with SotA methods. ",
    "url": "https://arxiv.org/abs/2303.05420",
    "authors": [
      "Ben Adlam",
      "Jaehoon Lee",
      "Shreyas Padhy",
      "Zachary Nado",
      "Jasper Snoek"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.05432",
    "title": "Describing the effect of influential spreaders on the different sectors  of Indian market: a complex networks perspective",
    "abstract": "Market competition has a role which is directly or indirectly associated with influential effects of individual sectors on other sectors of the economy. The present work studies the relative position of a product in the market through the identification of influential spreaders and its corresponding effect on the other sectors of the market using complex network analysis during the pre-, in-, and post-crisis induced lockdown periods using daily data of NSE from December, 2019 to June, 2021. The existing approaches using different centrality measures failed to distinguish between the positive and negative influences of the different sectors in the market which act as spreaders. To obviate this problem, this paper presents an effective measure called LIEST (Local Influential Effects for Specific Target) that can examine the positive and negative influences separately with respect to any crisis period. LIEST considers the combined impact of all possible nodes which are at most three steps away from the specific targets for the networks. The essence of non-linearity in the network dynamics without considering single node effect becomes visible particularly in the proposed network. ",
    "url": "https://arxiv.org/abs/2303.05432",
    "authors": [
      "Anwesha Sengupta",
      "Shashankaditya Upadhyay",
      "Indranil Mukherjee",
      "Prasanta K. Panigrahi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2303.05489",
    "title": "Robust Optimization Approach to Information Design in  Linear-Quadratic-Gaussian Games",
    "abstract": "Information design in an incomplete information game includes a designer with the goal of influencing players' actions through signals generated from a designed probability distribution so that its objective function is optimized. If the players have quadratic payoffs that depend on the players' actions and an unknown payoff-relevant state, and signals on the state that follow a Gaussian distribution conditional on the state realization, then the information design problem under quadratic design objectives is a semidefinite program (SDP). We consider a setting in which the designer has partial knowledge on agents' utilities. We address the uncertainty about players' preferences by formulating a robust information design problem. Specifically, we consider ellipsoid perturbations over payoff matrices in linear-quadratic-Gaussian (LQG) games. We show that this leads to a tractable robust SDP formulation. Using the robust SDP formulation, we obtain analytical conditions for the optimality of no information and full information disclosure. The robust convex program is also extended to interval and general convex cone uncertainty sets on the payoff matrices. Numerical studies are carried out to identify the relation between the perturbation levels and the optimal information structures. ",
    "url": "https://arxiv.org/abs/2303.05489",
    "authors": [
      "Furkan Sezer",
      "Ceyhun Eksin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2006.11440",
    "title": "Local Convolutions Cause an Implicit Bias towards High Frequency  Adversarial Examples",
    "abstract": " Comments: 23 pages, 11 figures, 12 Tables ",
    "url": "https://arxiv.org/abs/2006.11440",
    "authors": [
      "Josue Ortega Caro",
      "Yilong Ju",
      "Ryan Pyle",
      "Sourav Dey",
      "Wieland Brendel",
      "Fabio Anselmi",
      "Ankit Patel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.08722",
    "title": "RAIST: Learning Risk Aware Traffic Interactions via Spatio-Temporal  Graph Convolutional Networks",
    "abstract": " Title: RAIST: Learning Risk Aware Traffic Interactions via Spatio-Temporal  Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2011.08722",
    "authors": [
      "Videsh Suman",
      "Phu Pham",
      "Aniket Bera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2101.00311",
    "title": "Disclosure Risk from Homogeneity Attack in Differentially Private  Frequency Distribution",
    "abstract": " Title: Disclosure Risk from Homogeneity Attack in Differentially Private  Frequency Distribution ",
    "url": "https://arxiv.org/abs/2101.00311",
    "authors": [
      "Fang Liu",
      "Xingyuan Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2108.03372",
    "title": "Neighborhood Consensus Contrastive Learning for Backward-Compatible  Representation",
    "abstract": " Comments: Accepted by AAAI 2022 ",
    "url": "https://arxiv.org/abs/2108.03372",
    "authors": [
      "Shengsen Wu",
      "Liang Chen",
      "Yihang Lou",
      "Yan Bai",
      "Tao Bai",
      "Minghua Deng",
      "Lingyu Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03073",
    "title": "Active Learning for Event Extraction with Memory-based Loss Prediction  Model",
    "abstract": " Title: Active Learning for Event Extraction with Memory-based Loss Prediction  Model ",
    "url": "https://arxiv.org/abs/2112.03073",
    "authors": [
      "Shirong Shen",
      "Zhen Li",
      "Guilin Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11191",
    "title": "Developing a Trusted Human-AI Network for Humanitarian Benefit",
    "abstract": " Comments: 30 pages, 7 figures, 2 boxes, submitted for peer review to the Journal of Digital War, My War Special Issue ",
    "url": "https://arxiv.org/abs/2112.11191",
    "authors": [
      "Susannah Kate Devitt",
      "Jason Scholz",
      "Timo Schless",
      "Larry Lewis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.04122",
    "title": "In Defense of the Unitary Scalarization for Deep Multi-Task Learning",
    "abstract": " Comments: NeurIPS 2022 camera-ready version, fixed training loss y axis scale ",
    "url": "https://arxiv.org/abs/2201.04122",
    "authors": [
      "Vitaly Kurin",
      "Alessandro De Palma",
      "Ilya Kostrikov",
      "Shimon Whiteson",
      "M. Pawan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.13094",
    "title": "Designing Universal Causal Deep Learning Models: The Geometric  (Hyper)Transformer",
    "abstract": " Comments: Main Body: 31 Pages, Proofs: 16 Pages, Figures: 13, Tables: 3 ",
    "url": "https://arxiv.org/abs/2201.13094",
    "authors": [
      "Beatrice Acciaio",
      "Anastasis Kratsios",
      "Gudmund Pammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)",
      "Probability (math.PR)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2202.03609",
    "title": "Backdoor Detection and Mitigation in Competitive Reinforcement Learning",
    "abstract": " Title: Backdoor Detection and Mitigation in Competitive Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2202.03609",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.11202",
    "title": "Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning",
    "abstract": " Comments: ICLR 2023 Spotlight (notable top 25%). The first two authors contributed equally to this paper ",
    "url": "https://arxiv.org/abs/2202.11202",
    "authors": [
      "Hao He",
      "Kaiwen Zha",
      "Dina Katabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.11556",
    "title": "Bounds on the Twin-Width of Product Graphs",
    "abstract": " Comments: 20 pages, 1 table, 1 figure ",
    "url": "https://arxiv.org/abs/2202.11556",
    "authors": [
      "William Pettersson",
      "John Sylvester"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.08147",
    "title": "Energy-Latency Attacks via Sponge Poisoning",
    "abstract": " Comments: Preprint;16 pages ",
    "url": "https://arxiv.org/abs/2203.08147",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Ambra Demontis",
      "Battista Biggio",
      "Fabio Roli",
      "Marcello Pelillo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11375",
    "title": "Robust Model Predictive Control with Polytopic Model Uncertainty through  System Level Synthesis",
    "abstract": " Comments: Added extensive simulation for comparison with robust MPC baselines. Submitted to Automatica ",
    "url": "https://arxiv.org/abs/2203.11375",
    "authors": [
      "Shaoru Chen",
      "Victor M. Preciado",
      "Manfred Morari",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.06601",
    "title": "Causal Confusion and Reward Misidentification in Preference-Based Reward  Learning",
    "abstract": " Comments: In the proceedings of the Eleventh International Conference on Learning Representations (ICLR 2023). $\\href{this https URL}{\\text{URL}}$ ",
    "url": "https://arxiv.org/abs/2204.06601",
    "authors": [
      "Jeremy Tien",
      "Jerry Zhi-Yang He",
      "Zackory Erickson",
      "Anca D. Dragan",
      "Daniel S. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.01992",
    "title": "Wild Patterns Reloaded: A Survey of Machine Learning Security against  Training Data Poisoning",
    "abstract": " Comments: 35 pages, Accepted at ACM Computing Surveys ",
    "url": "https://arxiv.org/abs/2205.01992",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Kathrin Grosse",
      "Ambra Demontis",
      "Sebastiano Vascon",
      "Werner Zellinger",
      "Bernhard A. Moser",
      "Alina Oprea",
      "Battista Biggio",
      "Marcello Pelillo",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.00531",
    "title": "Masked Autoencoder for Self-Supervised Pre-training on Lidar Point  Clouds",
    "abstract": " Title: Masked Autoencoder for Self-Supervised Pre-training on Lidar Point  Clouds ",
    "url": "https://arxiv.org/abs/2207.00531",
    "authors": [
      "Georg Hess",
      "Johan Jaxing",
      "Elias Svensson",
      "David Hagerman",
      "Christoffer Petersson",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10609",
    "title": "Global Concept-Based Interpretability for Graph Neural Networks via  Neuron Analysis",
    "abstract": " Comments: 9 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2208.10609",
    "authors": [
      "Han Xuanyuan",
      "Pietro Barbiero",
      "Dobrik Georgiev",
      "Lucie Charlotte Magister",
      "Pietro Li\u00f3"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.02890",
    "title": "Data-Driven Target Localization Using Adaptive Radar Processing and  Convolutional Neural Networks",
    "abstract": " Comments: 34 pages, 22 figures. Submitted to IEEE Transactions on Aerospace and Electronic Systems ",
    "url": "https://arxiv.org/abs/2209.02890",
    "authors": [
      "Shyam Venkatasubramanian",
      "Sandeep Gogineni",
      "Bosung Kang",
      "Ali Pezeshki",
      "Muralidhar Rangaswamy",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.04415",
    "title": "Non-convex Quadratic Programming Using Coherent Optical Networks",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2209.04415",
    "authors": [
      "Farhad Khosravi",
      "Ugur Yildiz",
      "Artur Scherer",
      "Pooya Ronagh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.08323",
    "title": "RGB-Event Fusion for Moving Object Detection in Autonomous Driving",
    "abstract": " Comments: ICRA'23 ",
    "url": "https://arxiv.org/abs/2209.08323",
    "authors": [
      "Zhuyun Zhou",
      "Zongwei Wu",
      "R\u00e9mi Boutteau",
      "Fan Yang",
      "C\u00e9dric Demonceaux",
      "Dominique Ginhac"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.09117",
    "title": "Part-Based Models Improve Adversarial Robustness",
    "abstract": " Comments: Published in ICLR 2023 (poster). Code can be found at this https URL ",
    "url": "https://arxiv.org/abs/2209.09117",
    "authors": [
      "Chawin Sitawarin",
      "Kornrapat Pongmala",
      "Yizheng Chen",
      "Nicholas Carlini",
      "David Wagner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00173",
    "title": "Predictive Inference with Feature Conformal Prediction",
    "abstract": " Comments: Published as a conference paper at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.00173",
    "authors": [
      "Jiaye Teng",
      "Chuan Wen",
      "Dinghuai Zhang",
      "Yoshua Bengio",
      "Yang Gao",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.02835",
    "title": "Sequentially Swapping Tokens: Further on Graph Classes",
    "abstract": " Comments: 24 pages, 15 figures, SOFSEM 2023 ",
    "url": "https://arxiv.org/abs/2210.02835",
    "authors": [
      "Hironori Kiya",
      "Yuto Okada",
      "Hirotaka Ono",
      "Yota Otachi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.07889",
    "title": "Semi-supervised Learning with Network Embedding on Ambient RF Signals  for Geofencing Services",
    "abstract": " Comments: A conference version of this paper will appear in IEEE ICDE 2023 ",
    "url": "https://arxiv.org/abs/2210.07889",
    "authors": [
      "Weipeng Zhuo",
      "Ka Ho Chiu",
      "Jierun Chen",
      "Jiajie Tan",
      "Edmund Sumpena",
      "S.-H. Gary Chan",
      "Sangtae Ha",
      "Chul-Ho Lee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.13631",
    "title": "On the Robustness of Dataset Inference",
    "abstract": " Comments: 17 pages, 5 tables, 4 figures ",
    "url": "https://arxiv.org/abs/2210.13631",
    "authors": [
      "Sebastian Szyller",
      "Rui Zhang",
      "Jian Liu",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.16060",
    "title": "Deep network series for large-scale high-dynamic range imaging",
    "abstract": " Comments: 5 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2210.16060",
    "authors": [
      "Amir Aghabiglou",
      "Matthieu Terris",
      "Adrian Jackson",
      "Yves Wiaux"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00109",
    "title": "ImagineNET: Target Speaker Extraction with Intermittent Visual Cue  through Embedding Inpainting",
    "abstract": " Comments: Accepted by ICASSP2023 ",
    "url": "https://arxiv.org/abs/2211.00109",
    "authors": [
      "Zexu Pan",
      "Wupeng Wang",
      "Marvin Borsdorf",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.02849",
    "title": "Coarse-to-fine Knowledge Graph Domain Adaptation based on  Distantly-supervised Iterative Training",
    "abstract": " Title: Coarse-to-fine Knowledge Graph Domain Adaptation based on  Distantly-supervised Iterative Training ",
    "url": "https://arxiv.org/abs/2211.02849",
    "authors": [
      "Hongmin Cai",
      "Wenxiong Liao",
      "Zhengliang Liu",
      "Yiyang Zhang",
      "Xiaoke Huang",
      "Siqi Ding",
      "Hui Ren",
      "Zihao Wu",
      "Haixing Dai",
      "Sheng Li",
      "Lingfei Wu",
      "Ninghao Liu",
      "Quanzheng Li",
      "Tianming Liu",
      "Xiang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.07533",
    "title": "Generalized Balancing Weights via Deep Neural Networks",
    "abstract": " Title: Generalized Balancing Weights via Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2211.07533",
    "authors": [
      "Yoshiaki Kitazawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08229",
    "title": "CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning",
    "abstract": " Title: CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning ",
    "url": "https://arxiv.org/abs/2211.08229",
    "authors": [
      "Jinghuai Zhang",
      "Hongbin Liu",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09041",
    "title": "Anomaly Detection via Multi-Scale Contrasted Memory",
    "abstract": " Title: Anomaly Detection via Multi-Scale Contrasted Memory ",
    "url": "https://arxiv.org/abs/2211.09041",
    "authors": [
      "Loic Jezequel",
      "Ngoc-Son Vu",
      "Jean Beaudet",
      "Aymeric Histace"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.09565",
    "title": "Towards Good Practices in Evaluating Transfer Adversarial Attacks",
    "abstract": " Comments: Our code and a list of categorized attacks are publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2211.09565",
    "authors": [
      "Zhengyu Zhao",
      "Hanwei Zhang",
      "Renjue Li",
      "Ronan Sicre",
      "Laurent Amsaleg",
      "Michael Backes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10791",
    "title": "AdaFNIO: Adaptive Fourier Neural Interpolation Operator for video frame  interpolation",
    "abstract": " Title: AdaFNIO: Adaptive Fourier Neural Interpolation Operator for video frame  interpolation ",
    "url": "https://arxiv.org/abs/2211.10791",
    "authors": [
      "Hrishikesh Viswanath",
      "Md Ashiqur Rahman",
      "Rashmi Bhaskara",
      "Aniket Bera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12046",
    "title": "DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors",
    "abstract": " Comments: Accepted at CVPR 2023, Code: this https URL, Project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.12046",
    "authors": [
      "Dogyoon Lee",
      "Minhyeok Lee",
      "Chajin Shin",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12914",
    "title": "Open-vocabulary Attribute Detection",
    "abstract": " Comments: Accepted at CVPR 2023. this https URL ",
    "url": "https://arxiv.org/abs/2211.12914",
    "authors": [
      "Mar\u00eda A. Bravo",
      "Sudhanshu Mittal",
      "Simon Ging",
      "Thomas Brox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14456",
    "title": "TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud  Classification",
    "abstract": " Title: TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud  Classification ",
    "url": "https://arxiv.org/abs/2211.14456",
    "authors": [
      "Pavlo Melnyk",
      "Andreas Robinson",
      "M\u00e5rten Wadenb\u00e4ck",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05946",
    "title": "Evaluation and Improvement of Interpretability for Self-Explainable  Part-Prototype Networks",
    "abstract": " Title: Evaluation and Improvement of Interpretability for Self-Explainable  Part-Prototype Networks ",
    "url": "https://arxiv.org/abs/2212.05946",
    "authors": [
      "Qihan Huang",
      "Mengqi Xue",
      "Wenqi Huang",
      "Haofei Zhang",
      "Jie Song",
      "Yongcheng Jing",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.13136",
    "title": "Fewer is More: Efficient Object Detection in Large Aerial Images",
    "abstract": " Comments: This manuscript is the accepted version for SCIENCE CHINA Information Sciences ",
    "url": "https://arxiv.org/abs/2212.13136",
    "authors": [
      "Xingxing Xie",
      "Gong Cheng",
      "Qingyang Li",
      "Shicheng Miao",
      "Ke Li",
      "Junwei Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00122",
    "title": "Hair and Scalp Disease Detection using Machine Learning and Image  Processing",
    "abstract": " Title: Hair and Scalp Disease Detection using Machine Learning and Image  Processing ",
    "url": "https://arxiv.org/abs/2301.00122",
    "authors": [
      "Mrinmoy Roy",
      "Anica Tasnim Protity"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01850",
    "title": "Bayesian Weapon System Reliability Modeling with Cox-Weibull Neural  Network",
    "abstract": " Comments: Pre-print with minor revisions, published at The 69th Annual Reliability and Maintainability Symposium, January 23-26, 2023, FL, USA ",
    "url": "https://arxiv.org/abs/2301.01850",
    "authors": [
      "Michael Potter",
      "Benny Cheng"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2301.06986",
    "title": "General Index Reduction by Embedding for Integro-differential-algebraic  Equations",
    "abstract": " Comments: 11 pages, 7 figures, conference. arXiv admin note: text overlap with arXiv:2210.16707 ",
    "url": "https://arxiv.org/abs/2301.06986",
    "authors": [
      "Wenqiang Yang",
      "Wenyuan Wu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12868",
    "title": "On Robustness of Prompt-based Semantic Parsing with Large Pre-trained  Language Model: An Empirical Study on Codex",
    "abstract": " Comments: Accepted at EACL2023 (main) ",
    "url": "https://arxiv.org/abs/2301.12868",
    "authors": [
      "Terry Yue Zhuo",
      "Zhuang Li",
      "Yujin Huang",
      "Fatemeh Shiri",
      "Weiqing Wang",
      "Gholamreza Haffari",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.02012",
    "title": "DeTorrent: An Adversarial Padding-only Traffic Analysis Defense",
    "abstract": " Title: DeTorrent: An Adversarial Padding-only Traffic Analysis Defense ",
    "url": "https://arxiv.org/abs/2302.02012",
    "authors": [
      "James K Holland",
      "Jason Carpenter",
      "Se Eun Oh",
      "Nicholas Hopper"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.02914",
    "title": "Energy-based Out-of-Distribution Detection for Graph Neural Networks",
    "abstract": " Comments: Published at ICLR 2023, the implementation code is available at this https URL ",
    "url": "https://arxiv.org/abs/2302.02914",
    "authors": [
      "Qitian Wu",
      "Yiting Chen",
      "Chenxiao Yang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.07868",
    "title": "Target Specific De Novo Design of Drug Candidate Molecules with Graph  Transformer-based Generative Adversarial Networks",
    "abstract": " Title: Target Specific De Novo Design of Drug Candidate Molecules with Graph  Transformer-based Generative Adversarial Networks ",
    "url": "https://arxiv.org/abs/2302.07868",
    "authors": [
      "Atabey \u00dcnl\u00fc",
      "Elif \u00c7evrim",
      "Ahmet Sar\u0131g\u00fcn",
      "Hayriye \u00c7elikbilek",
      "Heval Ata\u015f G\u00fcvenilir",
      "Altay Koya\u015f",
      "Deniz Cansen Kahraman",
      "Abdurrahman Ol\u011fa\u00e7",
      "Ahmet Rifaio\u011flu",
      "Tunca Do\u011fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.09051",
    "title": "Complex QA and language models hybrid architectures, Survey",
    "abstract": " Title: Complex QA and language models hybrid architectures, Survey ",
    "url": "https://arxiv.org/abs/2302.09051",
    "authors": [
      "Xavier Daull",
      "Patrice Bellot",
      "Emmanuel Bruno",
      "Vincent Martin",
      "Elisabeth Murisasco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10899",
    "title": "Feature Affinity Assisted Knowledge Distillation and Quantization of  Deep Neural Networks on Label-Free Data",
    "abstract": " Title: Feature Affinity Assisted Knowledge Distillation and Quantization of  Deep Neural Networks on Label-Free Data ",
    "url": "https://arxiv.org/abs/2302.10899",
    "authors": [
      "Zhijian Li",
      "Biao Yang",
      "Penghang Yin",
      "Yingyong Qi",
      "Jack Xin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.00286",
    "title": "Enhancing Knowledge Graph Embedding Models with Semantic-driven Loss  Functions",
    "abstract": " Title: Enhancing Knowledge Graph Embedding Models with Semantic-driven Loss  Functions ",
    "url": "https://arxiv.org/abs/2303.00286",
    "authors": [
      "Nicolas Hubert",
      "Pierre Monnin",
      "Armelle Brun",
      "Davy Monticolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.02370",
    "title": "Self-Supervised Learning for Place Representation Generalization across  Appearance Changes",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2303.02370",
    "authors": [
      "Mohamed Adel Musallam",
      "Vincent Gaudilli\u00e8re",
      "Djamila Aouada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.03398",
    "title": "Acceleration of a production Solar MHD code with Fortran standard  parallelism: From OpenACC to `do concurrent'",
    "abstract": " Comments: 10 pages, 2 tables, 4 figures, accepted to the AsHES workshop at IPDPS 2023 ",
    "url": "https://arxiv.org/abs/2303.03398",
    "authors": [
      "Ronald M. Caplan",
      "Miko M. Stulajter",
      "Jon A. Linker"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2303.03916",
    "title": "A survey on automated detection and classification of acute leukemia and  WBCs in microscopic blood cells",
    "abstract": " Title: A survey on automated detection and classification of acute leukemia and  WBCs in microscopic blood cells ",
    "url": "https://arxiv.org/abs/2303.03916",
    "authors": [
      "Mohammad Zolfaghari",
      "Hedieh Sajedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04001",
    "title": "ELODIN: Naming Concepts in Embedding Spaces",
    "abstract": " Comments: Added quantitative data, fixed formatting issues ",
    "url": "https://arxiv.org/abs/2303.04001",
    "authors": [
      "Rodrigo Mello",
      "Filipe Calegario",
      "Geber Ramalho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04238",
    "title": "Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on  Object Detectors",
    "abstract": " Title: Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on  Object Detectors ",
    "url": "https://arxiv.org/abs/2303.04238",
    "authors": [
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  }
]