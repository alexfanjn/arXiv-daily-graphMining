[
  {
    "id": "arXiv:2303.12081",
    "title": "Intelligent Throughput-based Sleep Control Algorithm for the 5G Dense  Heterogeneous Cellular Networks",
    "abstract": "In the recent past, many mobile/telecom operators have seen a continuously growing demand for ubiquitous high-speed wireless access and an unprecedented increase in connected wireless devices. As a result, we have seen explosive growth in traffic volumes and a wide range of QoS requirements. The Fifth generation (5G) heterogeneous cellular networks (HetNets) have been developed by different mobile operators to achieve the growing mass data capacity and to reconnoiter the energy efficiency guaranteed trade-off between throughput QoS requirements and latency performance. However, existing energy efficiency algorithms do not satisfy the throughput QoS requirements such as reduced latency and packet loss, longer battery lifetime, reliability, and high data rates with regards to the three components of energy consumption of the 5G radio access network (RANs) that dominate the overall mobile communication networks. In addition, real-time traffic types such as voice and video require a high computational load at the terminal side which has an undesirable impact on energy/battery lifetime which further affects the throughput QoS performance such as reduced packet loss, longer battery lifetime, reliability, and high data rates. As a result, this paper proposed an Intelligent Throughput-based Sleep Control (ITSC) algorithm for throughput QoS and energy efficiency enhancement in 5G dense HetNets. In the proposed ITSC algorithm, a deep neural network (DNN) was used to determine the cell capacity ratio for the small base stations (SBSs). ",
    "url": "https://arxiv.org/abs/2303.12081",
    "authors": [
      "Topside E. Mathonsi",
      "Tshimangadzo M. Tshilongamulenzhe"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2303.12096",
    "title": "Reply to: Inability of a graph neural network heuristic to outperform  greedy algorithms in solving combinatorial optimization problems",
    "abstract": "We provide a comprehensive reply to the comment written by Stefan Boettcher [arXiv:2210.00623] and argue that the comment singles out one particular non-representative example problem, entirely focusing on the maximum cut problem (MaxCut) on sparse graphs, for which greedy algorithms are expected to perform well. Conversely, we highlight the broader algorithmic development underlying our original work, and (within our original framework) provide additional numerical results showing sizable improvements over our original data, thereby refuting the comment's original performance statements. Furthermore, it has already been shown that physics-inspired graph neural networks (PI-GNNs) can outperform greedy algorithms, in particular on hard, dense instances. We also argue that the internal (parallel) anatomy of graph neural networks is very different from the (sequential) nature of greedy algorithms, and (based on their usage at the scale of real-world social networks) point out that graph neural networks have demonstrated their potential for superior scalability compared to existing heuristics such as extremal optimization. Finally, we conclude highlighting the conceptual novelty of our work and outline some potential extensions. ",
    "url": "https://arxiv.org/abs/2303.12096",
    "authors": [
      "Martin J. A. Schuetz",
      "J. Kyle Brubaker",
      "Helmut G. Katzgraber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2303.12097",
    "title": "CLSA: Contrastive Learning-based Survival Analysis for Popularity  Prediction in MEC Networks",
    "abstract": "Mobile Edge Caching (MEC) integrated with Deep Neural Networks (DNNs) is an innovative technology with significant potential for the future generation of wireless networks, resulting in a considerable reduction in users' latency. The MEC network's effectiveness, however, heavily relies on its capacity to predict and dynamically update the storage of caching nodes with the most popular contents. To be effective, a DNN-based popularity prediction model needs to have the ability to understand the historical request patterns of content, including their temporal and spatial correlations. Existing state-of-the-art time-series DNN models capture the latter by simultaneously inputting the sequential request patterns of multiple contents to the network, considerably increasing the size of the input sample. This motivates us to address this challenge by proposing a DNN-based popularity prediction framework based on the idea of contrasting input samples against each other, designed for the Unmanned Aerial Vehicle (UAV)-aided MEC networks. Referred to as the Contrastive Learning-based Survival Analysis (CLSA), the proposed architecture consists of a self-supervised Contrastive Learning (CL) model, where the temporal information of sequential requests is learned using a Long Short Term Memory (LSTM) network as the encoder of the CL architecture. Followed by a Survival Analysis (SA) network, the output of the proposed CLSA architecture is probabilities for each content's future popularity, which are then sorted in descending order to identify the Top-K popular contents. Based on the simulation results, the proposed CLSA architecture outperforms its counterparts across the classification accuracy and cache-hit ratio. ",
    "url": "https://arxiv.org/abs/2303.12097",
    "authors": [
      "Zohreh Hajiakhondi-Meybodi",
      "Arash Mohammadi",
      "Jamshid Abouei",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.12116",
    "title": "Physics Informed Neural Networks for Phase Locked Loop Transient  Stability Assessment",
    "abstract": "A significant increase in renewable energy production is necessary to achieve the UN's net-zero emission targets for 2050. Using power-electronic controllers, such as Phase Locked Loops (PLLs), to keep grid-tied renewable resources in synchronism with the grid can cause fast transient behavior during grid faults leading to instability. However, assessing all the probable scenarios is impractical, so determining the stability boundary or region of attraction (ROA) is necessary. However, using EMT simulations or Reduced-order models (ROMs) to accurately determine the ROA is computationally expensive. Alternatively, Machine Learning (ML) models have been proposed as an efficient method to predict stability. However, traditional ML algorithms require large amounts of labeled data for training, which is computationally expensive. This paper proposes a Physics-Informed Neural Network (PINN) architecture that accurately predicts the nonlinear transient dynamics of a PLL controller under fault with less labeled training data. The proposed PINN algorithm can be incorporated into conventional simulations, accelerating EMT simulations or ROMs by over 100 times. The PINN algorithm's performance is compared against a ROM and an EMT simulation in PSCAD for the CIGRE benchmark model C4.49, demonstrating its ability to accurately approximate trajectories and ROAs of a PLL controller under varying grid impedance. ",
    "url": "https://arxiv.org/abs/2303.12116",
    "authors": [
      "Rahul Nellikkath",
      "Andreas Venzke",
      "Mohammad Kazem Bakhshizadeh",
      "Ilgiz Murzakhanov",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12127",
    "title": "Robust Output-Lifted Learning Model Predictive Control",
    "abstract": "We propose an iterative approach for designing Robust Learning Model Predictive Control (LMPC) policies for a class of nonlinear systems with additive, unmodelled dynamics. The nominal dynamics are assumed to be difference flat, i.e., the state and input can be reconstructed using flat output sequences. For the considered class of systems, we synthesize Robust MPC policies and show how to use historical trajectory data collected during iterative tasks to 1) obtain bounds on the unmodelled dynamics and 2) construct a convex value function approximation along with a convex safe set in the space of output sequences for designing terminal components in the Robust MPC design. We show that the proposed strategy guarantees robust constraint satisfaction, asymptotic convergence to a desired subset of the state space, and non-decreasing closed-loop performance at each policy update. Finally, simulation results demonstrate the effectiveness of the proposed strategy on a minimum time control problem using a constrained nonlinear and uncertain vehicle model. ",
    "url": "https://arxiv.org/abs/2303.12127",
    "authors": [
      "Siddharth H. Nair",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.12130",
    "title": "MV-MR: multi-views and multi-representations for self-supervised  learning and knowledge distillation",
    "abstract": "We present a new method of self-supervised learning and knowledge distillation based on the multi-views and multi-representations (MV-MR). The MV-MR is based on the maximization of dependence between learnable embeddings from augmented and non-augmented views, jointly with the maximization of dependence between learnable embeddings from augmented view and multiple non-learnable representations from non-augmented view. We show that the proposed method can be used for efficient self-supervised classification and model-agnostic knowledge distillation. Unlike other self-supervised techniques, our approach does not use any contrastive learning, clustering, or stop gradients. MV-MR is a generic framework allowing the incorporation of constraints on the learnable embeddings via the usage of image multi-representations as regularizers. Along this line, knowledge distillation is considered a particular case of such a regularization. MV-MR provides the state-of-the-art performance on the STL10 and ImageNet-1K datasets among non-contrastive and clustering-free methods. We show that a lower complexity ResNet50 model pretrained using proposed knowledge distillation based on the CLIP ViT model achieves state-of-the-art performance on STL10 linear evaluation. The code is available at: https://github.com/vkinakh/mv-mr ",
    "url": "https://arxiv.org/abs/2303.12130",
    "authors": [
      "Vitaliy Kinakh",
      "Mariia Drozdova",
      "Slava Voloshynovskiy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12145",
    "title": "Efficient Feature Distillation for Zero-shot Detection",
    "abstract": "The large-scale vision-language models (e.g., CLIP) are leveraged by different methods to detect unseen objects. However, most of these works require additional captions or images for training, which is not feasible in the context of zero-shot detection. In contrast, the distillation-based method is an extra-data-free method, but it has its limitations. Specifically, existing work creates distillation regions that are biased to the base categories, which limits the distillation of novel category information and harms the distillation efficiency. Furthermore, directly using the raw feature from CLIP for distillation neglects the domain gap between the training data of CLIP and the detection datasets, which makes it difficult to learn the mapping from the image region to the vision-language feature space - an essential component for detecting unseen objects. As a result, existing distillation-based methods require an excessively long training schedule. To solve these problems, we propose Efficient feature distillation for Zero-Shot Detection (EZSD). Firstly, EZSD adapts the CLIP's feature space to the target detection domain by re-normalizing CLIP to bridge the domain gap; Secondly, EZSD uses CLIP to generate distillation proposals with potential novel instances, to avoid the distillation being overly biased to the base categories. Finally, EZSD takes advantage of semantic meaning for regression to further improve the model performance. As a result, EZSD achieves state-of-the-art performance in the COCO zero-shot benchmark with a much shorter training schedule and outperforms previous work by 4% in LVIS overall setting with 1/10 training time. ",
    "url": "https://arxiv.org/abs/2303.12145",
    "authors": [
      "Zhuoming Liu",
      "Xuefeng Hu",
      "Ram Nevatia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12147",
    "title": "Universal Approximation Property of Hamiltonian Deep Neural Networks",
    "abstract": "This paper investigates the universal approximation capabilities of Hamiltonian Deep Neural Networks (HDNNs) that arise from the discretization of Hamiltonian Neural Ordinary Differential Equations. Recently, it has been shown that HDNNs enjoy, by design, non-vanishing gradients, which provide numerical stability during training. However, although HDNNs have demonstrated state-of-the-art performance in several applications, a comprehensive study to quantify their expressivity is missing. In this regard, we provide a universal approximation theorem for HDNNs and prove that a portion of the flow of HDNNs can approximate arbitrary well any continuous function over a compact domain. This result provides a solid theoretical foundation for the practical use of HDNNs. ",
    "url": "https://arxiv.org/abs/2303.12147",
    "authors": [
      "Muhammad Zakwan",
      "Massimiliano d'Angelo",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.12149",
    "title": "Group Activity Recognition using Self-supervised Approach of  Spatiotemporal Transformers",
    "abstract": "In this paper, we propose a new, simple, and effective Self-supervised Spatio-temporal Transformers (SPARTAN) approach to Group Activity Recognition (GAR) using unlabeled video data. Given a video, we create local and global Spatio-temporal views with varying spatial patch sizes and frame rates. The proposed self-supervised objective aims to match the features of these contrasting views representing the same video to be consistent with the variations in spatiotemporal domains. To the best of our knowledge, the proposed mechanism is one of the first works to alleviate the weakly supervised setting of GAR using the encoders in video transformers. Furthermore, using the advantage of transformer models, our proposed approach supports long-term relationship modeling along spatio-temporal dimensions. The proposed SPARTAN approach performs well on two group activity recognition benchmarks, including NBA and Volleyball datasets, by surpassing the state-of-the-art results by a significant margin in terms of MCA and MPCA metrics. ",
    "url": "https://arxiv.org/abs/2303.12149",
    "authors": [
      "Naga VS Raviteja Chappa",
      "Pha Nguyen",
      "Alexander H Nelson",
      "Han-Seok Seo",
      "Xin Li",
      "Page Daniel Dobbs",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12175",
    "title": "Black-box Backdoor Defense via Zero-shot Image Purification",
    "abstract": "Backdoor attacks inject poisoned data into the training set, resulting in misclassification of the poisoned samples during model inference. Defending against such attacks is challenging, especially in real-world black-box settings where only model predictions are available. In this paper, we propose a novel backdoor defense framework that can effectively defend against various attacks through zero-shot image purification (ZIP). Our proposed framework can be applied to black-box models without requiring any internal information about the poisoned model or any prior knowledge of the clean/poisoned samples. Our defense framework involves a two-step process. First, we apply a linear transformation on the poisoned image to destroy the trigger pattern. Then, we use a pre-trained diffusion model to recover the missing semantic information removed by the transformation. In particular, we design a new reverse process using the transformed image to guide the generation of high-fidelity purified images, which can be applied in zero-shot settings. We evaluate our ZIP backdoor defense framework on multiple datasets with different kinds of attacks. Experimental results demonstrate the superiority of our ZIP framework compared to state-of-the-art backdoor defense baselines. We believe that our results will provide valuable insights for future defense methods for black-box models. ",
    "url": "https://arxiv.org/abs/2303.12175",
    "authors": [
      "Yucheng Shi",
      "Mengnan Du",
      "Xuansheng Wu",
      "Zihan Guan",
      "Ninghao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.12194",
    "title": "LiDARFormer: A Unified Transformer-based Multi-task Network for LiDAR  Perception",
    "abstract": "There is a recent trend in the LiDAR perception field towards unifying multiple tasks in a single strong network with improved performance, as opposed to using separate networks for each task. In this paper, we introduce a new LiDAR multi-task learning paradigm based on the transformer. The proposed LiDARFormer utilizes cross-space global contextual feature information and exploits cross-task synergy to boost the performance of LiDAR perception tasks across multiple large-scale datasets and benchmarks. Our novel transformer-based framework includes a cross-space transformer module that learns attentive features between the 2D dense Bird's Eye View (BEV) and 3D sparse voxel feature maps. Additionally, we propose a transformer decoder for the segmentation task to dynamically adjust the learned features by leveraging the categorical feature representations. Furthermore, we combine the segmentation and detection features in a shared transformer decoder with cross-task attention layers to enhance and integrate the object-level and class-level features. LiDARFormer is evaluated on the large-scale nuScenes and the Waymo Open datasets for both 3D detection and semantic segmentation tasks, and it outperforms all previously published methods on both tasks. Notably, LiDARFormer achieves the state-of-the-art performance of 76.4% L2 mAPH and 74.3% NDS on the challenging Waymo and nuScenes detection benchmarks for a single model LiDAR-only method. ",
    "url": "https://arxiv.org/abs/2303.12194",
    "authors": [
      "Zixiang Zhou",
      "Dongqiangzi Ye",
      "Weijia Chen",
      "Yufei Xie",
      "Yu Wang",
      "Panqu Wang",
      "Hassan Foroosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12212",
    "title": "Community detection in complex networks via node similarity, graph  representation learning, and hierarchical clustering",
    "abstract": "Community detection is a critical challenge in the analysis of real-world graphs and complex networks, including social, transportation, citation, cybersecurity networks, and food webs. Motivated by many similarities between community detection and clustering in Euclidean spaces, we propose three algorithm frameworks to apply hierarchical clustering methods for community detection in graphs. We show that using our methods, it is possible to apply various linkage-based (single-, complete-, average- linkage, Ward, Genie) clustering algorithms to find communities based on vertex similarity matrices, eigenvector matrices thereof, and Euclidean vector representations of nodes. We convey a comprehensive analysis of choices for each framework, including state-of-the-art graph representation learning algorithms, such as Deep Neural Graph Representation, and a vertex proximity matrix known to yield high-quality results in machine learning -- Positive Pointwise Mutual Information. Overall, we test over a hundred combinations of framework components and show that some -- including Wasserman-Faust and PPMI proximity, DNGR representation -- can compete with algorithms such as state-of-the-art Leiden and Louvain and easily outperform other known community detection algorithms. Notably, our algorithms remain hierarchical and allow the user to specify any number of clusters a priori. ",
    "url": "https://arxiv.org/abs/2303.12212",
    "authors": [
      "\u0141ukasz Brzozowski",
      "Grzegorz Siudem",
      "Marek Gagolewski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12234",
    "title": "Pre-NeRF 360: Enriching Unbounded Appearances for Neural Radiance Fields",
    "abstract": "Neural radiance fields (NeRF) appeared recently as a powerful tool to generate realistic views of objects and confined areas. Still, they face serious challenges with open scenes, where the camera has unrestricted movement and content can appear at any distance. In such scenarios, current NeRF-inspired models frequently yield hazy or pixelated outputs, suffer slow training times, and might display irregularities, because of the challenging task of reconstructing an extensive scene from a limited number of images. We propose a new framework to boost the performance of NeRF-based architectures yielding significantly superior outcomes compared to the prior work. Our solution overcomes several obstacles that plagued earlier versions of NeRF, including handling multiple video inputs, selecting keyframes, and extracting poses from real-world frames that are ambiguous and symmetrical. Furthermore, we applied our framework, dubbed as \"Pre-NeRF 360\", to enable the use of the Nutrition5k dataset in NeRF and introduce an updated version of this dataset, known as the N5k360 dataset. ",
    "url": "https://arxiv.org/abs/2303.12234",
    "authors": [
      "Ahmad AlMughrabi",
      "Umair Haroon",
      "Ricardo Marques",
      "Petia Radeva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12238",
    "title": "DG-Trans: Dual-level Graph Transformer for Spatiotemporal Incident  Impact Prediction on Traffic Networks",
    "abstract": "The prompt estimation of traffic incident impacts can guide commuters in their trip planning and improve the resilience of transportation agencies' decision-making on resilience. However, it is more challenging than node-level and graph-level forecasting tasks, as it requires extracting the anomaly subgraph or sub-time-series from dynamic graphs. In this paper, we propose DG-Trans, a novel traffic incident impact prediction framework, to foresee the impact of traffic incidents through dynamic graph learning. The proposed framework contains a dual-level spatial transformer and an importance-score-based temporal transformer, and the performance of this framework is justified by two newly constructed benchmark datasets. The dual-level spatial transformer removes unnecessary edges between nodes to isolate the affected subgraph from the other nodes. Meanwhile, the importance-score-based temporal transformer identifies abnormal changes in node features, causing the predictions to rely more on measurement changes after the incident occurs. Therefore, DG-Trans is equipped with dual abilities that extract spatiotemporal dependency and identify anomaly nodes affected by incidents while removing noise introduced by benign nodes. Extensive experiments on real-world datasets verify that DG-Trans outperforms the existing state-of-the-art methods, especially in extracting spatiotemporal dependency patterns and predicting traffic accident impacts. It offers promising potential for traffic incident management systems. ",
    "url": "https://arxiv.org/abs/2303.12238",
    "authors": [
      "Yanshen Sun",
      "Kaiqun Fu",
      "Chang-Tien Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.12245",
    "title": "Error Analysis of Physics-Informed Neural Networks for Approximating  Dynamic PDEs of Second Order in Time",
    "abstract": "We consider the approximation of a class of dynamic partial differential equations (PDE) of second order in time by the physics-informed neural network (PINN) approach, and provide an error analysis of PINN for the wave equation, the Sine-Gordon equation and the linear elastodynamic equation. Our analyses show that, with feed-forward neural networks having two hidden layers and the $\\tanh$ activation function, the PINN approximation errors for the solution field, its time derivative and its gradient field can be effectively bounded by the training loss and the number of training data points (quadrature points). Our analyses further suggest new forms for the training loss function, which contain certain residuals that are crucial to the error estimate but would be absent from the canonical PINN loss formulation. Adopting these new forms for the loss function leads to a variant PINN algorithm. We present ample numerical experiments with the new PINN algorithm for the wave equation, the Sine-Gordon equation and the linear elastodynamic equation, which show that the method can capture the solution well. ",
    "url": "https://arxiv.org/abs/2303.12245",
    "authors": [
      "Yanxia Qian",
      "Yongchao Zhang",
      "Yunqing Huang",
      "Suchuan Dong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2303.12246",
    "title": "Object Pose Estimation with Statistical Guarantees: Conformal Keypoint  Detection and Geometric Uncertainty Propagation",
    "abstract": "The two-stage object pose estimation paradigm first detects semantic keypoints on the image and then estimates the 6D pose by minimizing reprojection errors. Despite performing well on standard benchmarks, existing techniques offer no provable guarantees on the quality and uncertainty of the estimation. In this paper, we inject two fundamental changes, namely conformal keypoint detection and geometric uncertainty propagation, into the two-stage paradigm and propose the first pose estimator that endows an estimation with provable and computable worst-case error bounds. On one hand, conformal keypoint detection applies the statistical machinery of inductive conformal prediction to convert heuristic keypoint detections into circular or elliptical prediction sets that cover the groundtruth keypoints with a user-specified marginal probability (e.g., 90%). Geometric uncertainty propagation, on the other, propagates the geometric constraints on the keypoints to the 6D object pose, leading to a Pose UnceRtainty SEt (PURSE) that guarantees coverage of the groundtruth pose with the same probability. The PURSE, however, is a nonconvex set that does not directly lead to estimated poses and uncertainties. Therefore, we develop RANdom SAmple averaGing (RANSAG) to compute an average pose and apply semidefinite relaxation to upper bound the worst-case errors between the average pose and the groundtruth. On the LineMOD Occlusion dataset we demonstrate: (i) the PURSE covers the groundtruth with valid probabilities; (ii) the worst-case error bounds provide correct uncertainty quantification; and (iii) the average pose achieves better or similar accuracy as representative methods based on sparse keypoints. ",
    "url": "https://arxiv.org/abs/2303.12246",
    "authors": [
      "Heng Yang",
      "Marco Pavone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.12247",
    "title": "Exploring the Benefits of Visual Prompting in Differential Privacy",
    "abstract": "Visual Prompting (VP) is an emerging and powerful technique that allows sample-efficient adaptation to downstream tasks by engineering a well-trained frozen source model. In this work, we explore the benefits of VP in constructing compelling neural network classifiers with differential privacy (DP). We explore and integrate VP into canonical DP training methods and demonstrate its simplicity and efficiency. In particular, we discover that VP in tandem with PATE, a state-of-the-art DP training method that leverages the knowledge transfer from an ensemble of teachers, achieves the state-of-the-art privacy-utility trade-off with minimum expenditure of privacy budget. Moreover, we conduct additional experiments on cross-domain image classification with a sufficient domain gap to further unveil the advantage of VP in DP. Lastly, we also conduct extensive ablation studies to validate the effectiveness and contribution of VP under DP consideration. ",
    "url": "https://arxiv.org/abs/2303.12247",
    "authors": [
      "Yizhe Li",
      "Yu-Lin Tsai",
      "Xuebin Ren",
      "Chia-Mu Yu",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12249",
    "title": "State-of-the-art optical-based physical adversarial attacks for deep  learning computer vision systems",
    "abstract": "Adversarial attacks can mislead deep learning models to make false predictions by implanting small perturbations to the original input that are imperceptible to the human eye, which poses a huge security threat to the computer vision systems based on deep learning. Physical adversarial attacks, which is more realistic, as the perturbation is introduced to the input before it is being captured and converted to a binary image inside the vision system, when compared to digital adversarial attacks. In this paper, we focus on physical adversarial attacks and further classify them into invasive and non-invasive. Optical-based physical adversarial attack techniques (e.g. using light irradiation) belong to the non-invasive category. As the perturbations can be easily ignored by humans as the perturbations are very similar to the effects generated by a natural environment in the real world. They are highly invisibility and executable and can pose a significant or even lethal threats to real systems. This paper focuses on optical-based physical adversarial attack techniques for computer vision systems, with emphasis on the introduction and discussion of optical-based physical adversarial attack techniques. ",
    "url": "https://arxiv.org/abs/2303.12249",
    "authors": [
      "Junbin Fang",
      "You Jiang",
      "Canjian Jiang",
      "Zoe L. Jiang",
      "Siu-Ming Yiu",
      "Chuanyi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.12255",
    "title": "Encoding Binary Concepts in the Latent Space of Generative Models for  Enhancing Data Representation",
    "abstract": "Binary concepts are empirically used by humans to generalize efficiently. And they are based on Bernoulli distribution which is the building block of information. These concepts span both low-level and high-level features such as \"large vs small\" and \"a neuron is active or inactive\". Binary concepts are ubiquitous features and can be used to transfer knowledge to improve model generalization. We propose a novel binarized regularization to facilitate learning of binary concepts to improve the quality of data generation in autoencoders. We introduce a binarizing hyperparameter $r$ in data generation process to disentangle the latent space symmetrically. We demonstrate that this method can be applied easily to existing variational autoencoder (VAE) variants to encourage symmetric disentanglement, improve reconstruction quality, and prevent posterior collapse without computation overhead. We also demonstrate that this method can boost existing models to learn more transferable representations and generate more representative samples for the input distribution which can alleviate catastrophic forgetting using generative replay under continual learning settings. ",
    "url": "https://arxiv.org/abs/2303.12255",
    "authors": [
      "Zizhao Hu",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12267",
    "title": "AUTO: Adaptive Outlier Optimization for Online Test-Time OOD Detection",
    "abstract": "Out-of-distribution (OOD) detection is a crucial aspect of deploying machine learning models in open-world applications. Empirical evidence suggests that training with auxiliary outliers substantially improves OOD detection. However, such outliers typically exhibit a distribution gap compared to the test OOD data and do not cover all possible test OOD scenarios. Additionally, incorporating these outliers introduces additional training burdens. In this paper, we introduce a novel paradigm called test-time OOD detection, which utilizes unlabeled online data directly at test time to improve OOD detection performance. While this paradigm is efficient, it also presents challenges such as catastrophic forgetting. To address these challenges, we propose adaptive outlier optimization (AUTO), which consists of an in-out-aware filter, an ID memory bank, and a semantically-consistent objective. AUTO adaptively mines pseudo-ID and pseudo-OOD samples from test data, utilizing them to optimize networks in real time during inference. Extensive results on CIFAR-10, CIFAR-100, and ImageNet benchmarks demonstrate that AUTO significantly enhances OOD detection performance. ",
    "url": "https://arxiv.org/abs/2303.12267",
    "authors": [
      "Puning Yang",
      "Jian Liang",
      "Jie Cao",
      "Ran He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12269",
    "title": "A Cycle-Accurate Soft Error Vulnerability Analysis Framework for  FPGA-based Designs",
    "abstract": "Many aerospace and automotive applications use FPGAs in their designs due to their low power and reconfigurability requirements. Meanwhile, such applications also pose a high standard on system reliability, which makes the early-stage reliability analysis for FPGA-based designs very critical. In this paper, we present a framework that enables fast and accurate early-stage analysis of soft error vulnerability for small FPGA-based designs. Our framework first extracts the post-synthesis netlist from an FPGA design. Then it inserts the bit-flip configuration faults into the design netlist using our proposed interface software. After that, it seamlessly feeds the golden copy and fault copies of the netlist into the open source simulator Verilator for cycle-accurate simulation. Finally, it generates a histogram of vulnerability scores of the original design to guide the reliability analysis. Experimental results show that our framework runs up to 53x faster than the Xilinx Vivado fault simulation with cycle-level accuracy, when analyzing the injected bit-flip faults on the ITC'99 benchmarks. ",
    "url": "https://arxiv.org/abs/2303.12269",
    "authors": [
      "Eduardo Rhod",
      "Behnam Ghavami",
      "Zhenman Fang",
      "Lesley Shannon"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2303.12270",
    "title": "EBSR: Enhanced Binary Neural Network for Image Super-Resolution",
    "abstract": "While the performance of deep convolutional neural networks for image super-resolution (SR) has improved significantly, the rapid increase of memory and computation requirements hinders their deployment on resource-constrained devices. Quantized networks, especially binary neural networks (BNN) for SR have been proposed to significantly improve the model inference efficiency but suffer from large performance degradation. We observe the activation distribution of SR networks demonstrates very large pixel-to-pixel, channel-to-channel, and image-to-image variation, which is important for high performance SR but gets lost during binarization. To address the problem, we propose two effective methods, including the spatial re-scaling as well as channel-wise shifting and re-scaling, which augments binary convolutions by retaining more spatial and channel-wise information. Our proposed models, dubbed EBSR, demonstrate superior performance over prior art methods both quantitatively and qualitatively across different datasets and different model sizes. Specifically, for x4 SR on Set5 and Urban100, EBSRlight improves the PSNR by 0.31 dB and 0.28 dB compared to SRResNet-E2FIF, respectively, while EBSR outperforms EDSR-E2FIF by 0.29 dB and 0.32 dB PSNR, respectively. ",
    "url": "https://arxiv.org/abs/2303.12270",
    "authors": [
      "Renjie Wei",
      "Shuwen Zhang",
      "Zechun Liu",
      "Meng Li",
      "Yuchen Fan",
      "Runsheng Wang",
      "Ru Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.12274",
    "title": "A Hierarchical Hybrid Learning Framework for Multi-agent Trajectory  Prediction",
    "abstract": "Accurate and robust trajectory prediction of neighboring agents is critical for autonomous vehicles traversing in complex scenes. Most methods proposed in recent years are deep learning-based due to their strength in encoding complex interactions. However, unplausible predictions are often generated since they rely heavily on past observations and cannot effectively capture the transient and contingency interactions from sparse samples. In this paper, we propose a hierarchical hybrid framework of deep learning (DL) and reinforcement learning (RL) for multi-agent trajectory prediction, to cope with the challenge of predicting motions shaped by multi-scale interactions. In the DL stage, the traffic scene is divided into multiple intermediate-scale heterogenous graphs based on which Transformer-style GNNs are adopted to encode heterogenous interactions at intermediate and global levels. In the RL stage, we divide the traffic scene into local sub-scenes utilizing the key future points predicted in the DL stage. To emulate the motion planning procedure so as to produce trajectory predictions, a Transformer-based Proximal Policy Optimization (PPO) incorporated with a vehicle kinematics model is devised to plan motions under the dominant influence of microscopic interactions. A multi-objective reward is designed to balance between agent-centric accuracy and scene-wise compatibility. Experimental results show that our proposal matches the state-of-the-arts on the Argoverse forecasting benchmark. It's also revealed by the visualized results that the hierarchical learning framework captures the multi-scale interactions and improves the feasibility and compliance of the predicted trajectories. ",
    "url": "https://arxiv.org/abs/2303.12274",
    "authors": [
      "Yujun Jiao",
      "Mingze Miao",
      "Zhishuai Yin",
      "Chunyuan Lei",
      "Xu Zhu",
      "Linzhen Nie",
      "Bo Tao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12278",
    "title": "X-CANIDS: Signal-Aware Explainable Intrusion Detection System for  Controller Area Network-Based In-Vehicle Network",
    "abstract": "Controller Area Network (CAN) is an essential networking protocol that connects multiple electronic control units (ECUs) in a vehicle. However, CAN-based in-vehicle networks (IVNs) face security risks owing to the CAN mechanisms. An adversary can sabotage a vehicle by leveraging the security risks if they can access the CAN bus. Thus, recent actions and cybersecurity regulations (e.g., UNR 155) require carmakers to implement intrusion detection systems (IDSs) in their vehicles. An IDS should detect cyberattacks and provide a forensic capability to analyze attacks. Although many IDSs have been proposed, considerations regarding their feasibility and explainability remain lacking. This study proposes X-CANIDS, which is a novel IDS for CAN-based IVNs. X-CANIDS dissects the payloads in CAN messages into human-understandable signals using a CAN database. The signals improve the intrusion detection performance compared with the use of bit representations of raw payloads. These signals also enable an understanding of which signal or ECU is under attack. X-CANIDS can detect zero-day attacks because it does not require any labeled dataset in the training phase. We confirmed the feasibility of the proposed method through a benchmark test on an automotive-grade embedded device with a GPU. The results of this work will be valuable to carmakers and researchers considering the installation of in-vehicle IDSs for their vehicles. ",
    "url": "https://arxiv.org/abs/2303.12278",
    "authors": [
      "Seonghoon Jeong",
      "Sangho Lee",
      "Hwejae Lee",
      "Huy Kang Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.12280",
    "title": "NLOS-NeuS: Non-line-of-sight Neural Implicit Surface",
    "abstract": "Non-line-of-sight (NLOS) imaging is conducted to infer invisible scenes from indirect light on visible objects. The neural transient field (NeTF) was proposed for representing scenes as neural radiance fields in NLOS scenes. We propose NLOS neural implicit surface (NLOS-NeuS), which extends the NeTF to neural implicit surfaces with a signed distance function (SDF) for reconstructing three-dimensional surfaces in NLOS scenes. We introduce two constraints as loss functions for correctly learning an SDF to avoid non-zero level-set surfaces. We also introduce a lower bound constraint of an SDF based on the geometry of the first-returning photons. The experimental results indicate that these constraints are essential for learning a correct SDF in NLOS scenes. Compared with previous methods with discretized representation, NLOS-NeuS with the neural continuous representation enables us to reconstruct smooth surfaces while preserving fine details in NLOS scenes. To the best of our knowledge, this is the first study on neural implicit surfaces with volume rendering in NLOS scenes. ",
    "url": "https://arxiv.org/abs/2303.12280",
    "authors": [
      "Yuki Fujimura",
      "Takahiro Kushida",
      "Takuya Funatomi",
      "Yasuhiro Mukaigawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.12300",
    "title": "Exploring Turkish Speech Recognition via Hybrid CTC/Attention  Architecture and Multi-feature Fusion Network",
    "abstract": "In recent years, End-to-End speech recognition technology based on deep learning has developed rapidly. Due to the lack of Turkish speech data, the performance of Turkish speech recognition system is poor. Firstly, this paper studies a series of speech recognition tuning technologies. The results show that the performance of the model is the best when the data enhancement technology combining speed perturbation with noise addition is adopted and the beam search width is set to 16. Secondly, to maximize the use of effective feature information and improve the accuracy of feature extraction, this paper proposes a new feature extractor LSPC. LSPC and LiGRU network are combined to form a shared encoder structure, and model compression is realized. The results show that the performance of LSPC is better than MSPC and VGGnet when only using Fbank features, and the WER is improved by 1.01% and 2.53% respectively. Finally, based on the above two points, a new multi-feature fusion network is proposed as the main structure of the encoder. The results show that the WER of the proposed feature fusion network based on LSPC is improved by 0.82% and 1.94% again compared with the single feature (Fbank feature and Spectrogram feature) extraction using LSPC. Our model achieves performance comparable to that of advanced End-to-End models. ",
    "url": "https://arxiv.org/abs/2303.12300",
    "authors": [
      "Zeyu Ren",
      "Nurmement Yolwas",
      "Huiru Wang",
      "Wushour Slamu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.12302",
    "title": "Anomaly Detection in Aeronautics Data with Quantum-compatible Discrete  Deep Generative Model",
    "abstract": "Deep generative learning cannot only be used for generating new data with statistical characteristics derived from input data but also for anomaly detection, by separating nominal and anomalous instances based on their reconstruction quality. In this paper, we explore the performance of three unsupervised deep generative models -- variational autoencoders (VAEs) with Gaussian, Bernoulli, and Boltzmann priors -- in detecting anomalies in flight-operations data of commercial flights consisting of multivariate time series. We devised two VAE models with discrete latent variables (DVAEs), one with a factorized Bernoulli prior and one with a restricted Boltzmann machine (RBM) as prior, because of the demand for discrete-variable models in machine-learning applications and because the integration of quantum devices based on two-level quantum systems requires such models. The DVAE with RBM prior, using a relatively simple -- and classically or quantum-mechanically enhanceable -- sampling technique for the evolution of the RBM's negative phase, performed better than the Bernoulli DVAE and on par with the Gaussian model, which has a continuous latent space. Our studies demonstrate the competitiveness of a discrete deep generative model with its Gaussian counterpart on anomaly-detection tasks. Moreover, the DVAE model with RBM prior can be easily integrated with quantum sampling by outsourcing its generative process to measurements of quantum states obtained from a quantum annealer or gate-model device. ",
    "url": "https://arxiv.org/abs/2303.12302",
    "authors": [
      "Thomas Templin",
      "Milad Memarzadeh",
      "Walter Vinci",
      "P. Aaron Lott",
      "Ata Akbari Asanjan",
      "Anthony Alexiades Armenakas",
      "Eleanor Rieffel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12304",
    "title": "SiamTHN: Siamese Target Highlight Network for Visual Tracking",
    "abstract": "Siamese network based trackers develop rapidly in the field of visual object tracking in recent years. The majority of siamese network based trackers now in use treat each channel in the feature maps generated by the backbone network equally, making the similarity response map sensitive to background influence and hence challenging to focus on the target region. Additionally, there are no structural links between the classification and regression branches in these trackers, and the two branches are optimized separately during training. Therefore, there is a misalignment between the classification and regression branches, which results in less accurate tracking results. In this paper, a Target Highlight Module is proposed to help the generated similarity response maps to be more focused on the target region. To reduce the misalignment and produce more precise tracking results, we propose a corrective loss to train the model. The two branches of the model are jointly tuned with the use of corrective loss to produce more reliable prediction results. Experiments on 5 challenging benchmark datasets reveal that the method outperforms current models in terms of performance, and runs at 38 fps, proving its effectiveness and efficiency. ",
    "url": "https://arxiv.org/abs/2303.12304",
    "authors": [
      "Jiahao Bao",
      "Kaiqiang Chen",
      "Xian Sun",
      "Liangjin Zhao",
      "Wenhui Diao",
      "Menglong Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12306",
    "title": "Logical Expressiveness of Graph Neural Network for Knowledge Graph  Reasoning",
    "abstract": "Graph Neural Networks (GNNs) have been recently introduced to learn from knowledge graph (KG) and achieved state-of-the-art performance in KG reasoning. However, a theoretical certification for their good empirical performance is still absent. Besides, while logic in KG is important for inductive and interpretable inference, existing GNN-based methods are just designed to fit data distributions with limited knowledge of their logical expressiveness. We propose to fill the above gap in this paper. Specifically, we theoretically analyze GNN from logical expressiveness and find out what kind of logical rules can be captured from KG. Our results first show that GNN can capture logical rules from graded modal logic, providing a new theoretical tool for analyzing the expressiveness of GNN for KG reasoning; and a query labeling trick makes it easier for GNN to capture logical rules, explaining why SOTA methods are mainly based on labeling trick. Finally, insights from our theory motivate the development of an entity labeling method for capturing difficult logical rules. Experimental results are consistent with our theoretical results and verify the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2303.12306",
    "authors": [
      "Haiquan Qiu",
      "Yongqi Zhang",
      "Yong Li",
      "Quanming Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12313",
    "title": "Distribution Aligned Diffusion and Prototype-guided network for  Unsupervised Domain Adaptive Segmentation",
    "abstract": "The Diffusion Probabilistic Model (DPM) has emerged as a highly effective generative model in the field of computer vision. Its intermediate latent vectors offer rich semantic information, making it an attractive option for various downstream tasks such as segmentation and detection. In order to explore its potential further, we have taken a step forward and considered a more complex scenario in the medical image domain, specifically, under an unsupervised adaptation condition. To this end, we propose a Diffusion-based and Prototype-guided network (DP-Net) for unsupervised domain adaptive segmentation. Concretely, our DP-Net consists of two stages: 1) Distribution Aligned Diffusion (DADiff), which involves training a domain discriminator to minimize the difference between the intermediate features generated by the DPM, thereby aligning the inter-domain distribution; and 2) Prototype-guided Consistency Learning (PCL), which utilizes feature centroids as prototypes and applies a prototype-guided loss to ensure that the segmentor learns consistent content from both source and target domains. Our approach is evaluated on fundus datasets through a series of experiments, which demonstrate that the performance of the proposed method is reliable and outperforms state-of-the-art methods. Our work presents a promising direction for using DPM in complex medical image scenarios, opening up new possibilities for further research in medical imaging. ",
    "url": "https://arxiv.org/abs/2303.12313",
    "authors": [
      "Haipeng Zhou",
      "Lei Zhu",
      "Yuyin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12314",
    "title": "Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization  for Few-shot Generalization",
    "abstract": "Prompt tuning is a parameter-efficient method, which learns soft prompts and conditions frozen language models to perform specific downstream tasks. Though effective, prompt tuning under few-shot settings on the one hand heavily relies on a good initialization of soft prompts. On the other hand, it can easily result in overfitting. Existing works leverage pre-training or supervised meta-learning to initialize soft prompts but they cannot data-efficiently generalize to unseen downstream tasks. To address the above problems, this paper proposes a novel Self-sUpervised meta-Prompt learning framework with meta-gradient Regularization for few-shot generalization (SUPMER). We first design a set of self-supervised anchor meta-training tasks with different task formats and further enrich the task distribution with curriculum-based task augmentation. Then a novel meta-gradient regularization method is integrated into meta-prompt learning. It meta-learns to transform the raw gradients during few-shot learning into a domain-generalizable direction, thus alleviating the problem of overfitting. Extensive experiments show that SUPMER achieves better performance for different few-shot downstream tasks, and also exhibits a stronger domain generalization ability. ",
    "url": "https://arxiv.org/abs/2303.12314",
    "authors": [
      "Kaihang Pan",
      "Juncheng Li",
      "Hongye Song",
      "Jun Lin",
      "Xiaozhong Liu",
      "Siliang Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12316",
    "title": "TsSHAP: Robust model agnostic feature-based explainability for time  series forecasting",
    "abstract": "A trustworthy machine learning model should be accurate as well as explainable. Understanding why a model makes a certain decision defines the notion of explainability. While various flavors of explainability have been well-studied in supervised learning paradigms like classification and regression, literature on explainability for time series forecasting is relatively scarce. In this paper, we propose a feature-based explainability algorithm, TsSHAP, that can explain the forecast of any black-box forecasting model. The method is agnostic of the forecasting model and can provide explanations for a forecast in terms of interpretable features defined by the user a prior. The explanations are in terms of the SHAP values obtained by applying the TreeSHAP algorithm on a surrogate model that learns a mapping between the interpretable feature space and the forecast of the black-box model. Moreover, we formalize the notion of local, semi-local, and global explanations in the context of time series forecasting, which can be useful in several scenarios. We validate the efficacy and robustness of TsSHAP through extensive experiments on multiple datasets. ",
    "url": "https://arxiv.org/abs/2303.12316",
    "authors": [
      "Vikas C. Raykar",
      "Arindam Jati",
      "Sumanta Mukherjee",
      "Nupur Aggarwal",
      "Kanthi Sarpatwar",
      "Giridhar Ganapavarapu",
      "Roman Vaculin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12320",
    "title": "GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering",
    "abstract": "Commonsense question-answering (QA) methods combine the power of pre-trained Language Models (LM) with the reasoning provided by Knowledge Graphs (KG). A typical approach collects nodes relevant to the QA pair from a KG to form a Working Graph (WG) followed by reasoning using Graph Neural Networks(GNNs). This faces two major challenges: (i) it is difficult to capture all the information from the QA in the WG, and (ii) the WG contains some irrelevant nodes from the KG. To address these, we propose GrapeQA with two simple improvements on the WG: (i) Prominent Entities for Graph Augmentation identifies relevant text chunks from the QA pair and augments the WG with corresponding latent representations from the LM, and (ii) Context-Aware Node Pruning removes nodes that are less relevant to the QA pair. We evaluate our results on OpenBookQA, CommonsenseQA and MedQA-USMLE and see that GrapeQA shows consistent improvements over its LM + KG predecessor (QA-GNN in particular) and large improvements on OpenBookQA. ",
    "url": "https://arxiv.org/abs/2303.12320",
    "authors": [
      "Dhaval Taunk",
      "Lakshya Khanna",
      "Pavan Kandru",
      "Vasudeva Varma",
      "Charu Sharma",
      "Makarand Tapaswi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.12341",
    "title": "EasyDGL: Encode, Train and Interpret for Continuous-time Dynamic Graph  Learning",
    "abstract": "Dynamic graphs arise in various real-world applications, and it is often welcomed to model the dynamics directly in continuous time domain for its flexibility. This paper aims to design an easy-to-use pipeline (termed as EasyDGL which is also due to its implementation by DGL toolkit) composed of three key modules with both strong fitting ability and interpretability. Specifically the proposed pipeline which involves encoding, training and interpreting: i) a temporal point process (TPP) modulated attention architecture to endow the continuous-time resolution with the coupled spatiotemporal dynamics of the observed graph with edge-addition events; ii) a principled loss composed of task-agnostic TPP posterior maximization based on observed events on the graph, and a task-aware loss with a masking strategy over dynamic graph, where the covered tasks include dynamic link prediction, dynamic node classification and node traffic forecasting; iii) interpretation of the model outputs (e.g., representations and predictions) with scalable perturbation-based quantitative analysis in the graph Fourier domain, which could more comprehensively reflect the behavior of the learned model. Extensive experimental results on public benchmarks show the superior performance of our EasyDGL for time-conditioned predictive tasks, and in particular demonstrate that EasyDGL can effectively quantify the predictive power of frequency content that a model learn from the evolving graph data. ",
    "url": "https://arxiv.org/abs/2303.12341",
    "authors": [
      "Chao Chen",
      "Haoyu Geng",
      "Nianzu Yang",
      "Xiaokang Yang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12342",
    "title": "One-Step Detection Paradigm for Hyperspectral Anomaly Detection via  Spectral Deviation Relationship Learning",
    "abstract": "Hyperspectral anomaly detection (HAD) involves identifying the targets that deviate spectrally from their surroundings, without prior knowledge. Recently, deep learning based methods have become the mainstream HAD methods, due to their powerful spatial-spectral feature extraction ability. However, the current deep detection models are optimized to complete a proxy task (two-step paradigm), such as background reconstruction or generation, rather than achieving anomaly detection directly. This leads to suboptimal results and poor transferability, which means that the deep model is trained and tested on the same image. In this paper, an unsupervised transferred direct detection (TDD) model is proposed, which is optimized directly for the anomaly detection task (one-step paradigm) and has transferability. Specially, the TDD model is optimized to identify the spectral deviation relationship according to the anomaly definition. Compared to learning the specific background distribution as most models do, the spectral deviation relationship is universal for different images and guarantees the model transferability. To train the TDD model in an unsupervised manner, an anomaly sample simulation strategy is proposed to generate numerous pairs of anomaly samples. Furthermore, a global self-attention module and a local self-attention module are designed to help the model focus on the \"spectrally deviating\" relationship. The TDD model was validated on four public HAD datasets. The results show that the proposed TDD model can successfully overcome the limitation of traditional model training and testing on a single image, and the model has a powerful detection ability and excellent transferability. ",
    "url": "https://arxiv.org/abs/2303.12342",
    "authors": [
      "Jingtao Li",
      "Xinyu Wang",
      "Shaoyu Wang",
      "Hengwei Zhao",
      "Liangpei Zhang",
      "Yanfei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12357",
    "title": "Wasserstein Adversarial Examples on Univariant Time Series Data",
    "abstract": "Adversarial examples are crafted by adding indistinguishable perturbations to normal examples in order to fool a well-trained deep learning model to misclassify. In the context of computer vision, this notion of indistinguishability is typically bounded by $L_{\\infty}$ or other norms. However, these norms are not appropriate for measuring indistinguishiability for time series data. In this work, we propose adversarial examples in the Wasserstein space for time series data for the first time and utilize Wasserstein distance to bound the perturbation between normal examples and adversarial examples. We introduce Wasserstein projected gradient descent (WPGD), an adversarial attack method for perturbing univariant time series data. We leverage the closed-form solution of Wasserstein distance in the 1D space to calculate the projection step of WPGD efficiently with the gradient descent method. We further propose a two-step projection so that the search of adversarial examples in the Wasserstein space is guided and constrained by Euclidean norms to yield more effective and imperceptible perturbations. We empirically evaluate the proposed attack on several time series datasets in the healthcare domain. Extensive results demonstrate that the Wasserstein attack is powerful and can successfully attack most of the target classifiers with a high attack success rate. To better study the nature of Wasserstein adversarial example, we evaluate a strong defense mechanism named Wasserstein smoothing for potential certified robustness defense. Although the defense can achieve some accuracy gain, it still has limitations in many cases and leaves space for developing a stronger certified robustness method to Wasserstein adversarial examples on univariant time series data. ",
    "url": "https://arxiv.org/abs/2303.12357",
    "authors": [
      "Wenjie Wang",
      "Li Xiong",
      "Jian Lou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12363",
    "title": "Distribution-restrained Softmax Loss for the Model Robustness",
    "abstract": "Recently, the robustness of deep learning models has received widespread attention, and various methods for improving model robustness have been proposed, including adversarial training, model architecture modification, design of loss functions, certified defenses, and so on. However, the principle of the robustness to attacks is still not fully understood, also the related research is still not sufficient. Here, we have identified a significant factor that affects the robustness of models: the distribution characteristics of softmax values for non-real label samples. We found that the results after an attack are highly correlated with the distribution characteristics, and thus we proposed a loss function to suppress the distribution diversity of softmax. A large number of experiments have shown that our method can improve robustness without significant time consumption. ",
    "url": "https://arxiv.org/abs/2303.12363",
    "authors": [
      "Hao Wang",
      "Chen Li",
      "Jinzhe Jiang",
      "Xin Zhang",
      "Yaqian Zhao",
      "Weifeng Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.12369",
    "title": "Unbiased Multiple Instance Learning for Weakly Supervised Video Anomaly  Detection",
    "abstract": "Weakly Supervised Video Anomaly Detection (WSVAD) is challenging because the binary anomaly label is only given on the video level, but the output requires snippet-level predictions. So, Multiple Instance Learning (MIL) is prevailing in WSVAD. However, MIL is notoriously known to suffer from many false alarms because the snippet-level detector is easily biased towards the abnormal snippets with simple context, confused by the normality with the same bias, and missing the anomaly with a different pattern. To this end, we propose a new MIL framework: Unbiased MIL (UMIL), to learn unbiased anomaly features that improve WSVAD. At each MIL training iteration, we use the current detector to divide the samples into two groups with different context biases: the most confident abnormal/normal snippets and the rest ambiguous ones. Then, by seeking the invariant features across the two sample groups, we can remove the variant context biases. Extensive experiments on benchmarks UCF-Crime and TAD demonstrate the effectiveness of our UMIL. Our code is provided at https://github.com/ktr-hubrt/UMIL. ",
    "url": "https://arxiv.org/abs/2303.12369",
    "authors": [
      "Hui Lv",
      "Zhongqi Yue",
      "Qianru Sun",
      "Bin Luo",
      "Zhen Cui",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12370",
    "title": "Weakly Supervised Video Representation Learning with Unaligned Text for  Sequential Videos",
    "abstract": "Sequential video understanding, as an emerging video understanding task, has driven lots of researchers' attention because of its goal-oriented nature. This paper studies weakly supervised sequential video understanding where the accurate time-stamp level text-video alignment is not provided. We solve this task by borrowing ideas from CLIP. Specifically, we use a transformer to aggregate frame-level features for video representation and use a pre-trained text encoder to encode the texts corresponding to each action and the whole video, respectively. To model the correspondence between text and video, we propose a multiple granularity loss, where the video-paragraph contrastive loss enforces matching between the whole video and the complete script, and a fine-grained frame-sentence contrastive loss enforces the matching between each action and its description. As the frame-sentence correspondence is not available, we propose to use the fact that video actions happen sequentially in the temporal domain to generate pseudo frame-sentence correspondence and supervise the network training with the pseudo labels. Extensive experiments on video sequence verification and text-to-video matching show that our method outperforms baselines by a large margin, which validates the effectiveness of our proposed approach. Code is available at https://github.com/svip-lab/WeakSVR ",
    "url": "https://arxiv.org/abs/2303.12370",
    "authors": [
      "Sixun Dong",
      "Huazhang Hu",
      "Dongze Lian",
      "Weixin Luo",
      "Yicheng Qian",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12375",
    "title": "Disturbance Injection under Partial Automation: Robust Imitation  Learning for Long-horizon Tasks",
    "abstract": "Partial Automation (PA) with intelligent support systems has been introduced in industrial machinery and advanced automobiles to reduce the burden of long hours of human operation. Under PA, operators perform manual operations (providing actions) and operations that switch to automatic/manual mode (mode-switching). Since PA reduces the total duration of manual operation, these two action and mode-switching operations can be replicated by imitation learning with high sample efficiency. To this end, this paper proposes Disturbance Injection under Partial Automation (DIPA) as a novel imitation learning framework. In DIPA, mode and actions (in the manual mode) are assumed to be observables in each state and are used to learn both action and mode-switching policies. The above learning is robustified by injecting disturbances into the operator's actions to optimize the disturbance's level for minimizing the covariate shift under PA. We experimentally validated the effectiveness of our method for long-horizon tasks in two simulations and a real robot environment and confirmed that our method outperformed the previous methods and reduced the demonstration burden. ",
    "url": "https://arxiv.org/abs/2303.12375",
    "authors": [
      "Hirotaka Tahara",
      "Hikaru Sasaki",
      "Hanbit Oh",
      "Edgar Anarossi",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12376",
    "title": "Graph Data Models and Relational Database Technology",
    "abstract": "Recent work on database application development platforms has sought to include a declarative formulation of a conceptual data model in the application code, using annotations or attributes. Some recent work has used metadata to include the details of such formulations in the physical database, and this approach brings significant advantages in that the model can be enforced across a range of applications for a single database. In previous work, we have discussed the advantages for enterprise integration of typed graph data models (TGM), which can play a similar role in graphical databases, leveraging the existing support for the unified modelling language UML. Ideally, the integration of systems designed with different models, for example, graphical and relational database, should also be supported. In this work, we implement this approach, using metadata in a relational database management system (DBMS). ",
    "url": "https://arxiv.org/abs/2303.12376",
    "authors": [
      "Malcolm Crowe",
      "Fritz Laux"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2303.12384",
    "title": "RegFormer: An Efficient Projection-Aware Transformer Network for  Large-Scale Point Cloud Registration",
    "abstract": "Although point cloud registration has achieved remarkable advances in object-level and indoor scenes, large-scale registration methods are rarely explored. Challenges mainly arise from the huge point number, complex distribution, and outliers of outdoor LiDAR scans. In addition, most existing registration works generally adopt a two-stage paradigm: They first find correspondences by extracting discriminative local features, and then leverage estimators (eg. RANSAC) to filter outliers, which are highly dependent on well-designed descriptors and post-processing choices. To address these problems, we propose an end-to-end transformer network (RegFormer) for large-scale point cloud alignment without any further post-processing. Specifically, a projection-aware hierarchical transformer is proposed to capture long-range dependencies and filter outliers by extracting point features globally. Our transformer has linear complexity, which guarantees high efficiency even for large-scale scenes. Furthermore, to effectively reduce mismatches, a bijective association transformer is designed for regressing the initial transformation. Extensive experiments on KITTI and NuScenes datasets demonstrate that our RegFormer achieves state-of-the-art performance in terms of both accuracy and efficiency. ",
    "url": "https://arxiv.org/abs/2303.12384",
    "authors": [
      "Jiuming Liu",
      "Guangming Wang",
      "Zhe Liu",
      "Chaokang Jiang",
      "Marc Pollefeys",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12396",
    "title": "Rigidity-Aware Detection for 6D Object Pose Estimation",
    "abstract": "Most recent 6D object pose estimation methods first use object detection to obtain 2D bounding boxes before actually regressing the pose. However, the general object detection methods they use are ill-suited to handle cluttered scenes, thus producing poor initialization to the subsequent pose network. To address this, we propose a rigidity-aware detection method exploiting the fact that, in 6D pose estimation, the target objects are rigid. This lets us introduce an approach to sampling positive object regions from the entire visible object area during training, instead of naively drawing samples from the bounding box center where the object might be occluded. As such, every visible object part can contribute to the final bounding box prediction, yielding better detection robustness. Key to the success of our approach is a visibility map, which we propose to build using a minimum barrier distance between every pixel in the bounding box and the box boundary. Our results on seven challenging 6D pose estimation datasets evidence that our method outperforms general detection frameworks by a large margin. Furthermore, combined with a pose regression network, we obtain state-of-the-art pose estimation results on the challenging BOP benchmark. ",
    "url": "https://arxiv.org/abs/2303.12396",
    "authors": [
      "Yang Hai",
      "Rui Song",
      "Jiaojiao Li",
      "Mathieu Salzmann",
      "Yinlin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12398",
    "title": "Multiscale Attention via Wavelet Neural Operators for Vision  Transformers",
    "abstract": "Transformers have achieved widespread success in computer vision. At their heart, there is a Self-Attention (SA) mechanism, an inductive bias that associates each token in the input with every other token through a weighted basis. The standard SA mechanism has quadratic complexity with the sequence length, which impedes its utility to long sequences appearing in high resolution vision. Recently, inspired by operator learning for PDEs, Adaptive Fourier Neural Operators (AFNO) were introduced for high resolution attention based on global convolution that is efficiently implemented via FFT. However, the AFNO global filtering cannot well represent small and moderate scale structures that commonly appear in natural images. To leverage the coarse-to-fine scale structures we introduce a Multiscale Wavelet Attention (MWA) by leveraging wavelet neural operators which incurs linear complexity in the sequence size. We replace the attention in ViT with MWA and our experiments with CIFAR and ImageNet classification demonstrate significant improvement over alternative Fourier-based attentions such as AFNO and Global Filter Network (GFN). ",
    "url": "https://arxiv.org/abs/2303.12398",
    "authors": [
      "Anahita Nekoozadeh",
      "Mohammad Reza Ahmadzadeh",
      "Zahra Mardani",
      "Morteza Mardani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12423",
    "title": "Text with Knowledge Graph Augmented Transformer for Video Captioning",
    "abstract": "Video captioning aims to describe the content of videos using natural language. Although significant progress has been made, there is still much room to improve the performance for real-world applications, mainly due to the long-tail words challenge. In this paper, we propose a text with knowledge graph augmented transformer (TextKG) for video captioning. Notably, TextKG is a two-stream transformer, formed by the external stream and internal stream. The external stream is designed to absorb additional knowledge, which models the interactions between the additional knowledge, e.g., pre-built knowledge graph, and the built-in information of videos, e.g., the salient object regions, speech transcripts, and video captions, to mitigate the long-tail words challenge. Meanwhile, the internal stream is designed to exploit the multi-modality information in videos (e.g., the appearance of video frames, speech transcripts, and video captions) to ensure the quality of caption results. In addition, the cross attention mechanism is also used in between the two streams for sharing information. In this way, the two streams can help each other for more accurate results. Extensive experiments conducted on four challenging video captioning datasets, i.e., YouCookII, ActivityNet Captions, MSRVTT, and MSVD, demonstrate that the proposed method performs favorably against the state-of-the-art methods. Specifically, the proposed TextKG method outperforms the best published results by improving 18.7% absolute CIDEr scores on the YouCookII dataset. ",
    "url": "https://arxiv.org/abs/2303.12423",
    "authors": [
      "Xin Gu",
      "Guang Chen",
      "Yufei Wang",
      "Libo Zhang",
      "Tiejian Luo",
      "Longyin Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12424",
    "title": "Unsupervised Domain Adaptation for Training Event-Based Networks Using  Contrastive Learning and Uncorrelated Conditioning",
    "abstract": "Event-based cameras offer reliable measurements for preforming computer vision tasks in high-dynamic range environments and during fast motion maneuvers. However, adopting deep learning in event-based vision faces the challenge of annotated data scarcity due to recency of event cameras. Transferring the knowledge that can be obtained from conventional camera annotated data offers a practical solution to this challenge. We develop an unsupervised domain adaptation algorithm for training a deep network for event-based data image classification using contrastive learning and uncorrelated conditioning of data. Our solution outperforms the existing algorithms for this purpose. ",
    "url": "https://arxiv.org/abs/2303.12424",
    "authors": [
      "Dayuan Jian",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12445",
    "title": "MEDIMP: Medical Images and Prompts for renal transplant representation  learning",
    "abstract": "Renal transplantation emerges as the most effective solution for end-stage renal disease. Occurring from complex causes, a substantial risk of transplant chronic dysfunction persists and may lead to graft loss. Medical imaging plays a substantial role in renal transplant monitoring in clinical practice. However, graft supervision is multi-disciplinary, notably joining nephrology, urology, and radiology, while identifying robust biomarkers from such high-dimensional and complex data for prognosis is challenging. In this work, taking inspiration from the recent success of Large Language Models (LLMs), we propose MEDIMP -- Medical Images and Prompts -- a model to learn meaningful multi-modal representations of renal transplant Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE MRI) by incorporating structural clinicobiological data after translating them into text prompts. MEDIMP is based on contrastive learning from joint text-image paired embeddings to perform this challenging task. Moreover, we propose a framework that generates medical prompts using automatic textual data augmentations from LLMs. Our goal is to learn meaningful manifolds of renal transplant DCE MRI, interesting for the prognosis of the transplant or patient status (2, 3, and 4 years after the transplant), fully exploiting the available multi-modal data in the most efficient way. Extensive experiments and comparisons with other renal transplant representation learning methods with limited data prove the effectiveness of MEDIMP in a relevant clinical setting, giving new directions toward medical prompts. Our code is available at https://github.com/leomlck/MEDIMP. ",
    "url": "https://arxiv.org/abs/2303.12445",
    "authors": [
      "Leo Milecki",
      "Vicky Kalogeiton",
      "Sylvain Bodard",
      "Dany Anglicheau",
      "Jean-Michel Correas",
      "Marc-Olivier Timsit",
      "Maria Vakalopoulou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12460",
    "title": "Multi-Task Diffusion Incentive Design for Mobile Crowdsourcing in Social  Networks",
    "abstract": "Mobile Crowdsourcing (MCS) is a novel distributed computing paradigm that recruits skilled workers to perform location-dependent tasks. A number of mature incentive mechanisms have been proposed to address the worker recruitment problem in MCS systems. However, they all assume that there is a large enough worker pool and a sufficient number of users can be selected. This may be impossible in large-scale crowdsourcing environments. To address this challenge, we consider the MCS system defined on a location-aware social network provided by a social platform. In this system, we can recruit a small number of seed workers from the existing worker pool to spread the information of multiple tasks in the social network, thus attracting more users to perform tasks. In this paper, we propose a Multi-Task Diffusion Maximization (MT-DM) problem that aims to maximize the total utility of performing multiple crowdsourcing tasks under the budget. To accommodate multiple tasks diffusion over a social network, we create a multi-task diffusion model, and based on this model, we design an auction-based incentive mechanism, MT-DM-L. To deal with the high complexity of computing the multi-task diffusion, we adopt Multi-Task Reverse Reachable (MT-RR) sets to approximate the utility of information diffusion efficiently. Through both complete theoretical analysis and extensive simulations by using real-world datasets, we validate that our estimation for the spread of multi-task diffusion is accurate and the proposed mechanism achieves individual rationality, truthfulness, computational efficiency, and $(1-1/\\sqrt{e}-\\varepsilon)$ approximation with at least $1-\\delta$ probability. ",
    "url": "https://arxiv.org/abs/2303.12460",
    "authors": [
      "Jianxiong Guo",
      "Qiufen Ni",
      "Weili Wu",
      "Ding-Zhu Du"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2303.12512",
    "title": "Sibling-Attack: Rethinking Transferable Adversarial Attacks against Face  Recognition",
    "abstract": "A hard challenge in developing practical face recognition (FR) attacks is due to the black-box nature of the target FR model, i.e., inaccessible gradient and parameter information to attackers. While recent research took an important step towards attacking black-box FR models through leveraging transferability, their performance is still limited, especially against online commercial FR systems that can be pessimistic (e.g., a less than 50% ASR--attack success rate on average). Motivated by this, we present Sibling-Attack, a new FR attack technique for the first time explores a novel multi-task perspective (i.e., leveraging extra information from multi-correlated tasks to boost attacking transferability). Intuitively, Sibling-Attack selects a set of tasks correlated with FR and picks the Attribute Recognition (AR) task as the task used in Sibling-Attack based on theoretical and quantitative analysis. Sibling-Attack then develops an optimization framework that fuses adversarial gradient information through (1) constraining the cross-task features to be under the same space, (2) a joint-task meta optimization framework that enhances the gradient compatibility among tasks, and (3) a cross-task gradient stabilization method which mitigates the oscillation effect during attacking. Extensive experiments demonstrate that Sibling-Attack outperforms state-of-the-art FR attack techniques by a non-trivial margin, boosting ASR by 12.61% and 55.77% on average on state-of-the-art pre-trained FR models and two well-known, widely used commercial FR systems. ",
    "url": "https://arxiv.org/abs/2303.12512",
    "authors": [
      "Zexin Li",
      "Bangjie Yin",
      "Taiping Yao",
      "Juefeng Guo",
      "Shouhong Ding",
      "Simin Chen",
      "Cong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12525",
    "title": "A survey of hardware-based malware detection approach",
    "abstract": "Malware is the most significant threat to computer security. This paper aims to overview the malware detection field, focusing on the recent and promising hardware-based approach. This approach leverages the Hardware Performance Counters already available in modern processors and the power of Machine Learning, offering attractive advantages like resilience to disabling the protection, resilience to unknown malware, low complexity/overhead/cost, and run-time detection. The approach is deeply analyzed in light of a generic hardware-based detection framework. Some challenges related to the approach are presented: the necessary accuracy improvements, how to deal with the classification error, better correlating the hardware events behavior with the malware, and essential improvements on the hardware performance monitor. ",
    "url": "https://arxiv.org/abs/2303.12525",
    "authors": [
      "Cristiano Pegoraro Chenet",
      "Alessandro Savino",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.12529",
    "title": "DevelSet: Deep Neural Level Set for Instant Mask Optimization",
    "abstract": "With the feature size continuously shrinking in advanced technology nodes, mask optimization is increasingly crucial in the conventional design flow, accompanied by an explosive growth in prohibitive computational overhead in optical proximity correction (OPC) methods. Recently, inverse lithography technique (ILT) has drawn significant attention and is becoming prevalent in emerging OPC solutions. However, ILT methods are either time-consuming or in weak performance of mask printability and manufacturability. In this paper, we present DevelSet, a GPU and deep neural network (DNN) accelerated level set OPC framework for metal layer. We first improve the conventional level set-based ILT algorithm by introducing the curvature term to reduce mask complexity and applying GPU acceleration to overcome computational bottlenecks. To further enhance printability and fast iterative convergence, we propose a novel deep neural network delicately designed with level set intrinsic principles to facilitate the joint optimization of DNN and GPU accelerated level set optimizer. Experimental results show that DevelSet framework surpasses the state-of-the-art methods in printability and boost the runtime performance achieving instant level (around 1 second). ",
    "url": "https://arxiv.org/abs/2303.12529",
    "authors": [
      "Guojin Chen",
      "Ziyang Yu",
      "Hongduo Liu",
      "Yuzhe Ma",
      "Bei Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12569",
    "title": "GraphIT: Iterative reweighted $\\ell_1$ algorithm for sparse graph  inference in state-space models",
    "abstract": "State-space models (SSMs) are a common tool for modeling multi-variate discrete-time signals. The linear-Gaussian (LG) SSM is widely applied as it allows for a closed-form solution at inference, if the model parameters are known. However, they are rarely available in real-world problems and must be estimated. Promoting sparsity of these parameters favours both interpretability and tractable inference. In this work, we propose GraphIT, a majorization-minimization (MM) algorithm for estimating the linear operator in the state equation of an LG-SSM under sparse prior. A versatile family of non-convex regularization potentials is proposed. The MM method relies on tools inherited from the expectation-maximization methodology and the iterated reweighted-l1 approach. In particular, we derive a suitable convex upper bound for the objective function, that we then minimize using a proximal splitting algorithm. Numerical experiments illustrate the benefits of the proposed inference technique. ",
    "url": "https://arxiv.org/abs/2303.12569",
    "authors": [
      "Emilie Chouzenoux",
      "Victor Elvira"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2303.12570",
    "title": "RepoCoder: Repository-Level Code Completion Through Iterative Retrieval  and Generation",
    "abstract": "The task of repository-level code completion is to continue writing the unfinished code based on a broader context of the repository. While for automated code completion tools, it is difficult to utilize the useful information scattered in different files. We propose RepoCoder, a simple, generic, and effective framework to address the challenge. It streamlines the repository-level code completion process by incorporating a similarity-based retriever and a pre-trained code language model, which allows for the effective utilization of repository-level information for code completion and grants the ability to generate code at various levels of granularity. Furthermore, RepoCoder utilizes a novel iterative retrieval-generation paradigm that bridges the gap between retrieval context and the intended completion target. We also propose a new benchmark RepoEval, which consists of the latest and high-quality real-world repositories covering line, API invocation, and function body completion scenarios. We test the performance of RepoCoder by using various combinations of code retrievers and generators. Experimental results indicate that RepoCoder significantly improves the zero-shot code completion baseline by over 10% in all settings and consistently outperforms the vanilla retrieval-augmented code completion approach. Furthermore, we validate the effectiveness of RepoCoder through comprehensive analysis, providing valuable insights for future research. ",
    "url": "https://arxiv.org/abs/2303.12570",
    "authors": [
      "Fengji Zhang",
      "Bei Chen",
      "Yue Zhang",
      "Jin Liu",
      "Daoguang Zan",
      "Yi Mao",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.12588",
    "title": "Epidemic Model-based Network Influential Node Ranking Methods: A Ranking  Rationality Perspective",
    "abstract": "Most recent surveys and reviews on Influential Node Ranking Methods (INRMs) hightlight discussions on the methods' technical details, but there still lacks in-depth research on the fundamental issue of how to verify the considerable influence of these nodes in a network. Compared to conventional verification models such as cascade failure and linear threshold, the epidemic model is more widely used. Accordingly, we conducted a survey of INRM based on epidemic model on 81 primary studies and analyzed their Capability and Correctness which we defined in our work. Our study categorized 4 types of networks used by INRM, classified 7 categories of INRMs for analyzing the networks and defined 2 evaluation metrics set of Capability and Correctness for evaluating INRM from Ranking Rationality Perspective. We also discussed particular real-world networks that were used to evaluate INRM and the Capability and Correctness of different INRMs on ranking nodes in specific networks. This is, as far as we know, the first survey aimed at systematically summarizing the Capability and Correctness of INRM. Our findings can assist practitioners and researchers in choosing and comparing INRMs and identifying research gaps. ",
    "url": "https://arxiv.org/abs/2303.12588",
    "authors": [
      "Bing Zhang",
      "Xuyang Zhao",
      "Jiangtian Nie",
      "Jianhang Tang",
      "Yang Zhang",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.12612",
    "title": "LoadLord: Loading on the Fly to Defend Against Code-Reuse Attacks",
    "abstract": "Code-reuse attacks have become a kind of common attack method, in which attackers use the existing code in the program to hijack the control flow. Most existing defenses focus on control flow integrity (CFI), code randomization, and software debloating. However, most fine-grained schemes of those that ensure such high security suffer from significant performance overhead, and only reduce attack surfaces such as software debloating can not defend against code-reuse attacks completely. In this paper, from the perspective of shrinking the available code space at runtime, we propose LoadLord, which dynamically loads, and timely unloads functions during program running to defend against code-reuse attacks. LoadLord can reduce the number of gadgets in memory, especially high-risk gadgets. Moreover, LoadLord ensures the control flow integrity of the loading process and breaks the necessary conditions to build a gadget chain. We implemented LoadLord on Linux operating system and experimented that when limiting only 1/16 of the original function. As a result, LoadLord can defend against code-reuse attacks and has an average runtime overhead of 1.7% on the SPEC CPU 2006, reducing gadgets by 94.02%. ",
    "url": "https://arxiv.org/abs/2303.12612",
    "authors": [
      "Xiaoqi Song",
      "Wenjie Lv",
      "Haipeng Qu",
      "Lingyun Ying"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.12621",
    "title": "OcTr: Octree-based Transformer for 3D Object Detection",
    "abstract": "A key challenge for LiDAR-based 3D object detection is to capture sufficient features from large scale 3D scenes especially for distant or/and occluded objects. Albeit recent efforts made by Transformers with the long sequence modeling capability, they fail to properly balance the accuracy and efficiency, suffering from inadequate receptive fields or coarse-grained holistic correlations. In this paper, we propose an Octree-based Transformer, named OcTr, to address this issue. It first constructs a dynamic octree on the hierarchical feature pyramid through conducting self-attention on the top level and then recursively propagates to the level below restricted by the octants, which captures rich global context in a coarse-to-fine manner while maintaining the computational complexity under control. Furthermore, for enhanced foreground perception, we propose a hybrid positional embedding, composed of the semantic-aware positional embedding and attention mask, to fully exploit semantic and geometry clues. Extensive experiments are conducted on the Waymo Open Dataset and KITTI Dataset, and OcTr reaches newly state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2303.12621",
    "authors": [
      "Chao Zhou",
      "Yanan Zhang",
      "Jiaxin Chen",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12643",
    "title": "Traffic Volume Prediction using Memory-Based Recurrent Neural Networks:  A comparative analysis of LSTM and GRU",
    "abstract": "Predicting traffic volume in real-time can improve both traffic flow and road safety. A precise traffic volume forecast helps alert drivers to the flow of traffic along their preferred routes, preventing potential deadlock situations. Existing parametric models cannot reliably forecast traffic volume in dynamic and complex traffic conditions. Therefore, in order to evaluate and forecast the traffic volume for every given time step in a real-time manner, we develop non-linear memory-based deep neural network models. Our extensive experiments run on the Metro Interstate Traffic Volume dataset demonstrate the effectiveness of the proposed models in predicting traffic volume in highly dynamic and heterogeneous traffic environments. ",
    "url": "https://arxiv.org/abs/2303.12643",
    "authors": [
      "Lokesh Chandra Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12653",
    "title": "Robust Holographic mmWave Beamforming by Self-Supervised Hybrid Deep  Learning",
    "abstract": "Beamforming with large-scale antenna arrays has been widely used in recent years, which is acknowledged as an important part in 5G and incoming 6G. Thus, various techniques are leveraged to improve its performance, e.g., deep learning, advanced optimization algorithms, etc. Although its performance in many previous research scenarios with deep learning is quite attractive, usually it drops rapidly when the environment or dataset is changed. Therefore, designing effective beamforming network with strong robustness is an open issue for the intelligent wireless communications. In this paper, we propose a robust beamforming self-supervised network, and verify it in two kinds of different datasets with various scenarios. Simulation results show that the proposed self-supervised network with hybrid learning performs well in both classic DeepMIMO and new WAIR-D dataset with the strong robustness under the various environments. Also, we present the principle to explain the rationality of this kind of hybrid learning, which is instructive to apply with more kinds of datasets. ",
    "url": "https://arxiv.org/abs/2303.12653",
    "authors": [
      "Fenghao Zhu",
      "Bohao Wang",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Zhaoyang Zhang",
      "George C.Alexandropoulos",
      "Chau Yuen",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12658",
    "title": "Reliable and Efficient Evaluation of Adversarial Robustness for Deep  Hashing-Based Retrieval",
    "abstract": "Deep hashing has been extensively applied to massive image retrieval due to its efficiency and effectiveness. Recently, several adversarial attacks have been presented to reveal the vulnerability of deep hashing models against adversarial examples. However, existing attack methods suffer from degraded performance or inefficiency because they underutilize the semantic relations between original samples or spend a lot of time learning these relations with a deep neural network. In this paper, we propose a novel Pharos-guided Attack, dubbed PgA, to evaluate the adversarial robustness of deep hashing networks reliably and efficiently. Specifically, we design pharos code to represent the semantics of the benign image, which preserves the similarity to semantically relevant samples and dissimilarity to irrelevant ones. It is proven that we can quickly calculate the pharos code via a simple math formula. Accordingly, PgA can directly conduct a reliable and efficient attack on deep hashing-based retrieval by maximizing the similarity between the hash code of the adversarial example and the pharos code. Extensive experiments on the benchmark datasets verify that the proposed algorithm outperforms the prior state-of-the-arts in both attack strength and speed. ",
    "url": "https://arxiv.org/abs/2303.12658",
    "authors": [
      "Xunguang Wang",
      "Jiawang Bai",
      "Xinyue Xu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.12660",
    "title": "Production Networks Resilience: Cascading Failures, Power Laws and  Optimal Interventions",
    "abstract": "In this paper, we study the severity of cascading failures in supply chain networks defined by a node percolation process corresponding to product suppliers failing independently due to systemic shocks. We first show that the size of the cascades follows a power law in random directed acyclic graphs, whose topology encodes the natural ordering of products from simple raw materials to complex products. This motivates the need for a supply chain resilience metric, which we define as the maximum magnitude shock that the production network can withstand such that at least $(1 - \\varepsilon)$-fraction of the products are produced with high probability as the size of the production network grows to infinity. Next, we study the resilience of many network architectures and classify them as resilient, where large cascading failures can be avoided almost surely, and as fragile, where large cascades are inevitable. In the next step, we give bounds on the expected size of cascading failures in a given production network graph as the solution to a linear program and show that extending the node percolation process to a joint percolation process that affects the nodes and the links of the production network becomes a special instance of the well-studied financial contagion model of Eisenberg and Noe. We show that under certain assumptions, the Katz centrality of each node can be used as a measure of their vulnerability and give general lower bounds as well as optimal interventions for improving resilience as a function of Katz centralities. Finally, to validate our theoretical results, we empirically calculate the resilience metric and study interventions in a variety of real-world networks. ",
    "url": "https://arxiv.org/abs/2303.12660",
    "authors": [
      "Marios Papachristou",
      "M. Amin Rahimian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2303.12669",
    "title": "An Extended Study of Human-like Behavior under Adversarial Training",
    "abstract": "Neural networks have a number of shortcomings. Amongst the severest ones is the sensitivity to distribution shifts which allows models to be easily fooled into wrong predictions by small perturbations to inputs that are often imperceivable to humans and do not have to carry semantic meaning. Adversarial training poses a partial solution to address this issue by training models on worst-case perturbations. Yet, recent work has also pointed out that the reasoning in neural networks is different from humans. Humans identify objects by shape, while neural nets mainly employ texture cues. Exemplarily, a model trained on photographs will likely fail to generalize to datasets containing sketches. Interestingly, it was also shown that adversarial training seems to favorably increase the shift toward shape bias. In this work, we revisit this observation and provide an extensive analysis of this effect on various architectures, the common $\\ell_2$- and $\\ell_\\infty$-training, and Transformer-based models. Further, we provide a possible explanation for this phenomenon from a frequency perspective. ",
    "url": "https://arxiv.org/abs/2303.12669",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper",
      "Margret Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12670",
    "title": "Correlational Image Modeling for Self-Supervised Visual Pre-Training",
    "abstract": "We introduce Correlational Image Modeling (CIM), a novel and surprisingly effective approach to self-supervised visual pre-training. Our CIM performs a simple pretext task: we randomly crop image regions (exemplars) from an input image (context) and predict correlation maps between the exemplars and the context. Three key designs enable correlational image modeling as a nontrivial and meaningful self-supervisory task. First, to generate useful exemplar-context pairs, we consider cropping image regions with various scales, shapes, rotations, and transformations. Second, we employ a bootstrap learning framework that involves online and target encoders. During pre-training, the former takes exemplars as inputs while the latter converts the context. Third, we model the output correlation maps via a simple cross-attention block, within which the context serves as queries and the exemplars offer values and keys. We show that CIM performs on par or better than the current state of the art on self-supervised and transfer benchmarks. ",
    "url": "https://arxiv.org/abs/2303.12670",
    "authors": [
      "Wei Li",
      "Jiahao Xie",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12671",
    "title": "Integrating Image Features with Convolutional Sequence-to-sequence  Network for Multilingual Visual Question Answering",
    "abstract": "Visual Question Answering (VQA) is a task that requires computers to give correct answers for the input questions based on the images. This task can be solved by humans with ease but is a challenge for computers. The VLSP2022-EVJVQA shared task carries the Visual Question Answering task in the multilingual domain on a newly released dataset: UIT-EVJVQA, in which the questions and answers are written in three different languages: English, Vietnamese and Japanese. We approached the challenge as a sequence-to-sequence learning task, in which we integrated hints from pre-trained state-of-the-art VQA models and image features with Convolutional Sequence-to-Sequence network to generate the desired answers. Our results obtained up to 0.3442 by F1 score on the public test set, 0.4210 on the private test set, and placed 3rd in the competition. ",
    "url": "https://arxiv.org/abs/2303.12671",
    "authors": [
      "Triet Minh Thai",
      "Son T. Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.12693",
    "title": "Resilient Output Containment Control of Heterogeneous Multiagent Systems  Against Composite Attacks: A Digital Twin Approach",
    "abstract": "This paper studies the distributed resilient output containment control of heterogeneous multiagent systems against composite attacks, including denial-of-services (DoS) attacks, false-data injection (FDI) attacks, camouflage attacks, and actuation attacks. Inspired by digital twins, a twin layer (TL) with higher security and privacy is used to decouple the above problem into two tasks: defense protocols against DoS attacks on TL and defense protocols against actuation attacks on cyber-physical layer (CPL). First, considering modeling errors of leader dynamics, we introduce distributed observers to reconstruct the leader dynamics for each follower on TL under DoS attacks. Second, distributed estimators are used to estimate follower states according to the reconstructed leader dynamics on the TL. Third, according to the reconstructed leader dynamics, we design decentralized solvers that calculate the output regulator equations on CPL. Fourth, decentralized adaptive attack-resilient control schemes that resist unbounded actuation attacks are provided on CPL. Furthermore, we apply the above control protocols to prove that the followers can achieve uniformly ultimately bounded (UUB) convergence, and the upper bound of the UUB convergence is determined explicitly. Finally, two simulation examples are provided to show the effectiveness of the proposed control protocols. ",
    "url": "https://arxiv.org/abs/2303.12693",
    "authors": [
      "Yukang Cui",
      "Lingbo Cao",
      "Michael V. Basin",
      "Jun Shen",
      "Tingwen Huang",
      "Xin Gong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12696",
    "title": "Dense Network Expansion for Class Incremental Learning",
    "abstract": "The problem of class incremental learning (CIL) is considered. State-of-the-art approaches use a dynamic architecture based on network expansion (NE), in which a task expert is added per task. While effective from a computational standpoint, these methods lead to models that grow quickly with the number of tasks. A new NE method, dense network expansion (DNE), is proposed to achieve a better trade-off between accuracy and model complexity. This is accomplished by the introduction of dense connections between the intermediate layers of the task expert networks, that enable the transfer of knowledge from old to new tasks via feature sharing and reusing. This sharing is implemented with a cross-task attention mechanism, based on a new task attention block (TAB), that fuses information across tasks. Unlike traditional attention mechanisms, TAB operates at the level of the feature mixing and is decoupled with spatial attentions. This is shown more effective than a joint spatial-and-task attention for CIL. The proposed DNE approach can strictly maintain the feature space of old classes while growing the network and feature scale at a much slower rate than previous methods. In result, it outperforms the previous SOTA methods by a margin of 4\\% in terms of accuracy, with similar or even smaller model scale. ",
    "url": "https://arxiv.org/abs/2303.12696",
    "authors": [
      "Zhiyuan Hu",
      "Yunsheng Li",
      "Jiancheng Lyu",
      "Dashan Gao",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12703",
    "title": "Causal Reasoning in the Presence of Latent Confounders via Neural ADMG  Learning",
    "abstract": "Latent confounding has been a long-standing obstacle for causal reasoning from observational data. One popular approach is to model the data using acyclic directed mixed graphs (ADMGs), which describe ancestral relations between variables using directed and bidirected edges. However, existing methods using ADMGs are based on either linear functional assumptions or a discrete search that is complicated to use and lacks computational tractability for large datasets. In this work, we further extend the existing body of work and develop a novel gradient-based approach to learning an ADMG with non-linear functional relations from observational data. We first show that the presence of latent confounding is identifiable under the assumptions of bow-free ADMGs with non-linear additive noise models. With this insight, we propose a novel neural causal model based on autoregressive flows for ADMG learning. This not only enables us to determine complex causal structural relationships behind the data in the presence of latent confounding, but also estimate their functional relationships (hence treatment effects) simultaneously. We further validate our approach via experiments on both synthetic and real-world datasets, and demonstrate the competitive performance against relevant baselines. ",
    "url": "https://arxiv.org/abs/2303.12703",
    "authors": [
      "Matthew Ashman",
      "Chao Ma",
      "Agrin Hilmkil",
      "Joel Jennings",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2303.12707",
    "title": "Comparison of Probabilistic Deep Learning Methods for Autism Detection",
    "abstract": "Autism Spectrum Disorder (ASD) is one neuro developmental disorder that is now widespread in the world. ASD persists throughout the life of an individual, impacting the way they behave and communicate, resulting to notable deficits consisting of social life retardation, repeated behavioural traits and a restriction in their interests. Early detection of the disorder helps in the onset treatment and helps one to lead a normal life. There are clinical approaches used in detection of autism, relying on behavioural data and in worst cases, neuroimaging. Quantitative methods involving machine learning have been studied and developed to overcome issues with clinical approaches. These quantitative methods rely on machine learning, with some complex methods based on deep learning developed to accelerate detection and diagnosis of ASD. These literature is aimed at exploring most state-of-the-art probabilistic methods in use today, characterizing them with the type of dataset they're most applied on, their accuracy according to their novel research and how well they are suited in ASD classification. The findings will purposely serve as a benchmark in selection of the model to use when performing ASD detection. ",
    "url": "https://arxiv.org/abs/2303.12707",
    "authors": [
      "Godfrin Ismail",
      "Kenneth Chesoli",
      "Golda Moni",
      "Kinyua Gikunda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12725",
    "title": "Pedestrain detection for low-light vision proposal",
    "abstract": "The demand for pedestrian detection has created a challenging problem for various visual tasks such as image fusion. As infrared images can capture thermal radiation information, image fusion between infrared and visible images could significantly improve target detection under environmental limitations. In our project, we would approach by preprocessing our dataset with image fusion technique, then using Vision Transformer model to detect pedestrians from the fused images. During the evaluation procedure, a comparison would be made between YOLOv5 and the revised ViT model performance on our fused images ",
    "url": "https://arxiv.org/abs/2303.12725",
    "authors": [
      "Zhipeng Chang",
      "Ruiling Ma",
      "Wenliang Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12727",
    "title": "A XGBoost Algorithm-based Fatigue Recognition Model Using Face Detection",
    "abstract": "As fatigue is normally revealed in the eyes and mouth of a person's face, this paper tried to construct a XGBoost Algorithm-Based fatigue recognition model using the two indicators, EAR (Eye Aspect Ratio) and MAR(Mouth Aspect Ratio). With an accuracy rate of 87.37% and sensitivity rate of 89.14%, the model was proved to be efficient and valid for further applications. ",
    "url": "https://arxiv.org/abs/2303.12727",
    "authors": [
      "Xinrui Chen",
      "Bingquan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12730",
    "title": "Toward Data-Driven Glare Classification and Prediction for Marine  Megafauna Survey",
    "abstract": "Critically endangered species in Canadian North Atlantic waters are systematically surveyed to estimate species populations which influence governing policies. Due to its impact on policy, population accuracy is important. This paper lays the foundation towards a data-driven glare modelling system, which will allow surveyors to preemptively minimize glare. Surveyors use a detection function to estimate megafauna populations which are not explicitly seen. A goal of the research is to maximize useful imagery collected, to that end we will use our glare model to predict glare and optimize for glare-free data collection. To build this model, we leverage a small labelled dataset to perform semi-supervised learning. The large dataset is labelled with a Cascading Random Forest Model using a na\\\"ive pseudo-labelling approach. A reflectance model is used, which pinpoints features of interest, to populate our datasets which allows for context-aware machine learning models. The pseudo-labelled dataset is used on two models: a Multilayer Perceptron and a Recurrent Neural Network. With this paper, we lay the foundation for data-driven mission planning; a glare modelling system which allows surveyors to preemptively minimize glare and reduces survey reliance on the detection function as an estimator of whale populations during periods of poor subsurface visibility. ",
    "url": "https://arxiv.org/abs/2303.12730",
    "authors": [
      "Joshua Power",
      "Derek Jacoby",
      "Marc-Antoine Drouin",
      "Guillaume Durand",
      "Yvonne Coady",
      "Julian Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12731",
    "title": "Visualizing Semiotics in Generative Adversarial Networks",
    "abstract": "We perform a set of experiments to demonstrate that images generated using a Generative Adversarial Network can be modified using 'semiotics.' We show that just as physical attributes such as the hue and saturation of an image can be modified, so too can its non-physical, abstract properties using our method. For example, the design of a flight attendant's uniform may be modified to look more 'alert,' less 'austere,' or more 'practical.' The form of a house can be modified to appear more 'futuristic,' a car more 'friendly' a pair of sneakers, 'evil.' Our method uncovers latent visual iconography associated with the semiotic property of interest, enabling a process of visual form-finding using abstract concepts. Our approach is iterative and allows control over the degree of attribute presence and can be used to aid the design process to yield emergent visual concepts. ",
    "url": "https://arxiv.org/abs/2303.12731",
    "authors": [
      "Sabrina Osmany"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12737",
    "title": "Comparing Trajectory and Vision Modalities for Verb Representation",
    "abstract": "Three-dimensional trajectories, or the 3D position and rotation of objects over time, have been shown to encode key aspects of verb semantics (e.g., the meanings of roll vs. slide). However, most multimodal models in NLP use 2D images as representations of the world. Given the importance of 3D space in formal models of verb semantics, we expect that these 2D images would result in impoverished representations that fail to capture nuanced differences in meaning. This paper tests this hypothesis directly in controlled experiments. We train self-supervised image and trajectory encoders, and then evaluate them on the extent to which each learns to differentiate verb concepts. Contrary to our initial expectations, we find that 2D visual modalities perform similarly well to 3D trajectories. While further work should be conducted on this question, our initial findings challenge the conventional wisdom that richer environment representations necessarily translate into better representation learning for language. ",
    "url": "https://arxiv.org/abs/2303.12737",
    "authors": [
      "Dylan Ebert",
      "Chen Sun",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.12743",
    "title": "DR.CPO: Diversified and Realistic 3D Augmentation via Iterative  Construction, Random Placement, and HPR Occlusion",
    "abstract": "In autonomous driving, data augmentation is commonly used for improving 3D object detection. The most basic methods include insertion of copied objects and rotation and scaling of the entire training frame. Numerous variants have been developed as well. The existing methods, however, are considerably limited when compared to the variety of the real world possibilities. In this work, we develop a diversified and realistic augmentation method that can flexibly construct a whole-body object, freely locate and rotate the object, and apply self-occlusion and external-occlusion accordingly. To improve the diversity of the whole-body object construction, we develop an iterative method that stochastically combines multiple objects observed from the real world into a single object. Unlike the existing augmentation methods, the constructed objects can be randomly located and rotated in the training frame because proper occlusions can be reflected to the whole-body objects in the final step. Finally, proper self-occlusion at each local object level and external-occlusion at the global frame level are applied using the Hidden Point Removal (HPR) algorithm that is computationally efficient. HPR is also used for adaptively controlling the point density of each object according to the object's distance from the LiDAR. Experiment results show that the proposed DR.CPO algorithm is data-efficient and model-agnostic without incurring any computational overhead. Also, DR.CPO can improve mAP performance by 2.08% when compared to the best 3D detection result known for KITTI dataset. The code is available at https://github.com/SNU-DRL/DRCPO.git ",
    "url": "https://arxiv.org/abs/2303.12743",
    "authors": [
      "Jungwook Shin",
      "Jaeill Kim",
      "Kyungeun Lee",
      "Hyunghun Cho",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.12760",
    "title": "Uncertainty Aware Active Learning for Reconfiguration of Pre-trained  Deep Object-Detection Networks for New Target Domains",
    "abstract": "Object detection is one of the most important and fundamental aspects of computer vision tasks, which has been broadly utilized in pose estimation, object tracking and instance segmentation models. To obtain training data for object detection model efficiently, many datasets opt to obtain their unannotated data in video format and the annotator needs to draw a bounding box around each object in the images. Annotating every frame from a video is costly and inefficient since many frames contain very similar information for the model to learn from. How to select the most informative frames from a video to annotate has become a highly practical task to solve but attracted little attention in research. In this paper, we proposed a novel active learning algorithm for object detection models to tackle this problem. In the proposed active learning algorithm, both classification and localization informativeness of unlabelled data are measured and aggregated. Utilizing the temporal information from video frames, two novel localization informativeness measurements are proposed. Furthermore, a weight curve is proposed to avoid querying adjacent frames. Proposed active learning algorithm with multiple configurations was evaluated on the MuPoTS dataset and FootballPD dataset. ",
    "url": "https://arxiv.org/abs/2303.12760",
    "authors": [
      "Jiaming Na",
      "Varuna De-Silva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.12772",
    "title": "Interpretable Bangla Sarcasm Detection using BERT and Explainable AI",
    "abstract": "A positive phrase or a sentence with an underlying negative motive is usually defined as sarcasm that is widely used in today's social media platforms such as Facebook, Twitter, Reddit, etc. In recent times active users in social media platforms are increasing dramatically which raises the need for an automated NLP-based system that can be utilized in various tasks such as determining market demand, sentiment analysis, threat detection, etc. However, since sarcasm usually implies the opposite meaning and its detection is frequently a challenging issue, data meaning extraction through an NLP-based model becomes more complicated. As a result, there has been a lot of study on sarcasm detection in English over the past several years, and there's been a noticeable improvement and yet sarcasm detection in the Bangla language's state remains the same. In this article, we present a BERT-based system that can achieve 99.60\\% while the utilized traditional machine learning algorithms are only capable of achieving 89.93\\%. Additionally, we have employed Local Interpretable Model-Agnostic Explanations that introduce explainability to our system. Moreover, we have utilized a newly collected bangla sarcasm dataset, BanglaSarc that was constructed specifically for the evaluation of this study. This dataset consists of fresh records of sarcastic and non-sarcastic comments, the majority of which are acquired from Facebook and YouTube comment sections. ",
    "url": "https://arxiv.org/abs/2303.12772",
    "authors": [
      "Ramisa Anan",
      "Tasnim Sakib Apon",
      "Zeba Tahsin Hossain",
      "Elizabeth Antora Modhu",
      "Sudipta Mondal",
      "MD. Golam Rabiul Alam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12776",
    "title": "Dense Distinct Query for End-to-End Object Detection",
    "abstract": "One-to-one label assignment in object detection has successfully obviated the need for non-maximum suppression (NMS) as postprocessing and makes the pipeline end-to-end. However, it triggers a new dilemma as the widely used sparse queries cannot guarantee a high recall, while dense queries inevitably bring more similar queries and encounter optimization difficulties. As both sparse and dense queries are problematic, then what are the expected queries in end-to-end object detection? This paper shows that the solution should be Dense Distinct Queries (DDQ). Concretely, we first lay dense queries like traditional detectors and then select distinct ones for one-to-one assignments. DDQ blends the advantages of traditional and recent end-to-end detectors and significantly improves the performance of various detectors including FCN, R-CNN, and DETRs. Most impressively, DDQ-DETR achieves 52.1 AP on MS-COCO dataset within 12 epochs using a ResNet-50 backbone, outperforming all existing detectors in the same setting. DDQ also shares the benefit of end-to-end detectors in crowded scenes and achieves 93.8 AP on CrowdHuman. We hope DDQ can inspire researchers to consider the complementarity between traditional methods and end-to-end detectors. The source code can be found at \\url{https://github.com/jshilong/DDQ}. ",
    "url": "https://arxiv.org/abs/2303.12776",
    "authors": [
      "Shilong Zhang",
      "Wang xinjiang",
      "Jiaqi Wang",
      "Jiangmiao Pang",
      "Chengqi Lyu",
      "Wenwei Zhang",
      "Ping Luo",
      "Kai Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12783",
    "title": "Conformal Prediction for Time Series with Modern Hopfield Networks",
    "abstract": "To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains. ",
    "url": "https://arxiv.org/abs/2303.12783",
    "authors": [
      "Andreas Auer",
      "Martin Gauch",
      "Daniel Klotz",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.12095",
    "title": "Interpretable histopathology-based prediction of disease relevant  features in Inflammatory Bowel Disease biopsies using weakly-supervised deep  learning",
    "abstract": "Crohn's Disease (CD) and Ulcerative Colitis (UC) are the two main Inflammatory Bowel Disease (IBD) types. We developed deep learning models to identify histological disease features for both CD and UC using only endoscopic labels. We explored fine-tuning and end-to-end training of two state-of-the-art self-supervised models for predicting three different endoscopic categories (i) CD vs UC (AUC=0.87), (ii) normal vs lesional (AUC=0.81), (iii) low vs high disease severity score (AUC=0.80). We produced visual attention maps to interpret what the models learned and validated them with the support of a pathologist, where we observed a strong association between the models' predictions and histopathological inflammatory features of the disease. Additionally, we identified several cases where the model incorrectly predicted normal samples as lesional but were correct on the microscopic level when reviewed by the pathologist. This tendency of histological presentation to be more severe than endoscopic presentation was previously published in the literature. In parallel, we utilised a model trained on the Colon Nuclei Identification and Counting (CoNIC) dataset to predict and explore 6 cell populations. We observed correlation between areas enriched with the predicted immune cells in biopsies and the pathologist's feedback on the attention maps. Finally, we identified several cell level features indicative of disease severity in CD and UC. These models can enhance our understanding about the pathology behind IBD and can shape our strategies for patient stratification in clinical trials. ",
    "url": "https://arxiv.org/abs/2303.12095",
    "authors": [
      "Ricardo Mokhtari",
      "Azam Hamidinekoo",
      "Daniel Sutton",
      "Arthur Lewis",
      "Bastian Angermann",
      "Ulf Gehrmann",
      "Pal Lundin",
      "Hibret Adissu",
      "Junmei Cairns",
      "Jessica Neisen",
      "Emon Khan",
      "Daniel Marks",
      "Nia Khachapuridze",
      "Talha Qaiser",
      "Nikolay Burlutskiy"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12123",
    "title": "Oral-NeXF: 3D Oral Reconstruction with Neural X-ray Field from Panoramic  Imaging",
    "abstract": "3D reconstruction of medical images from 2D images has increasingly become a challenging research topic with the advanced development of deep learning methods. Previous work in 3D reconstruction from limited (generally one or two) X-ray images mainly relies on learning from paired 2D and 3D images. In 3D oral reconstruction from panoramic imaging, the model also relies on some prior individual information, such as the dental arch curve or voxel-wise annotations, to restore the curved shape of the mandible during reconstruction. These limitations have hindered the use of single X-ray tomography in clinical applications. To address these challenges, we propose a new model that relies solely on projection data, including imaging direction and projection image, during panoramic scans to reconstruct the 3D oral structure. Our model builds on the neural radiance field by introducing multi-head prediction, dynamic sampling, and adaptive rendering, which accommodates the projection process of panoramic X-ray in dental imaging. Compared to end-to-end learning methods, our method achieves state-of-the-art performance without requiring additional supervision or prior knowledge. ",
    "url": "https://arxiv.org/abs/2303.12123",
    "authors": [
      "Weinan Song",
      "Haoxin Zheng",
      "Jiawei Yang",
      "Chengwen Liang",
      "Lei He"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12148",
    "title": "Neural Pre-Processing: A Learning Framework for End-to-end Brain MRI  Pre-processing",
    "abstract": "Head MRI pre-processing involves converting raw images to an intensity-normalized, skull-stripped brain in a standard coordinate space. In this paper, we propose an end-to-end weakly supervised learning approach, called Neural Pre-processing (NPP), for solving all three sub-tasks simultaneously via a neural network, trained on a large dataset without individual sub-task supervision. Because the overall objective is highly under-constrained, we explicitly disentangle geometric-preserving intensity mapping (skull-stripping and intensity normalization) and spatial transformation (spatial normalization). Quantitative results show that our model outperforms state-of-the-art methods which tackle only a single sub-task. Our ablation experiments demonstrate the importance of the architecture design we chose for NPP. Furthermore, NPP affords the user the flexibility to control each of these tasks at inference time. The code and model are freely-available at \\url{https://github.com/Novestars/Neural-Pre-processing}. ",
    "url": "https://arxiv.org/abs/2303.12148",
    "authors": [
      "Xinzi He",
      "Alan Wang",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12164",
    "title": "Viscoelastic Constitutive Artificial Neural Networks (vCANNs) $-$ a  framework for data-driven anisotropic nonlinear finite viscoelasticity",
    "abstract": "The constitutive behavior of polymeric materials is often modeled by finite linear viscoelastic (FLV) or quasi-linear viscoelastic (QLV) models. These popular models are simplifications that typically cannot accurately capture the nonlinear viscoelastic behavior of materials. For example, the success of attempts to capture strain rate-dependent behavior has been limited so far. To overcome this problem, we introduce viscoelastic Constitutive Artificial Neural Networks (vCANNs), a novel physics-informed machine learning framework for anisotropic nonlinear viscoelasticity at finite strains. vCANNs rely on the concept of generalized Maxwell models enhanced with nonlinear strain (rate)-dependent properties represented by neural networks. The flexibility of vCANNs enables them to automatically identify accurate and sparse constitutive models of a broad range of materials. To test vCANNs, we trained them on stress-strain data from Polyvinyl Butyral, the electro-active polymers VHB 4910 and 4905, and a biological tissue, the rectus abdominis muscle. Different loading conditions were considered, including relaxation tests, cyclic tension-compression tests, and blast loads. We demonstrate that vCANNs can learn to capture the behavior of all these materials accurately and computationally efficiently without human guidance. ",
    "url": "https://arxiv.org/abs/2303.12164",
    "authors": [
      "Kian P. Abdolazizi",
      "Kevin Linka",
      "Christian J. Cyron"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12198",
    "title": "Autofluorescence Bronchoscopy Video Analysis for Lesion Frame Detection",
    "abstract": "Because of the significance of bronchial lesions as indicators of early lung cancer and squamous cell carcinoma, a critical need exists for early detection of bronchial lesions. Autofluorescence bronchoscopy (AFB) is a primary modality used for bronchial lesion detection, as it shows high sensitivity to suspicious lesions. The physician, however, must interactively browse a long video stream to locate lesions, making the search exceedingly tedious and error prone. Unfortunately, limited research has explored the use of automated AFB video analysis for efficient lesion detection. We propose a robust automatic AFB analysis approach that distinguishes informative and uninformative AFB video frames in a video. In addition, for the informative frames, we determine the frames containing potential lesions and delineate candidate lesion regions. Our approach draws upon a combination of computer-based image analysis, machine learning, and deep learning. Thus, the analysis of an AFB video stream becomes more tractable. Tests with patient AFB video indicate that $\\ge$97\\% of frames were correctly labeled as informative or uninformative. In addition, $\\ge$97\\% of lesion frames were correctly identified, with false positive and false negative rates $\\le$3\\%. ",
    "url": "https://arxiv.org/abs/2303.12198",
    "authors": [
      "Qi Chang",
      "Rebecca Bascom",
      "Jennifer Toth",
      "Danish Ahmad",
      "William E. Higgins"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12402",
    "title": "Benders decomposition algorithms for minimizing the spread of harmful  contagions in networks",
    "abstract": "The COVID-19 pandemic has been a recent example for the spread of a harmful contagion in large populations. Moreover, the spread of harmful contagions is not only restricted to an infectious disease, but is also relevant to computer viruses and malware in computer networks. Furthermore, the spread of fake news and propaganda in online social networks is also of major concern. In this study, we introduce the measure-based spread minimization problem (MBSMP), which can help policy makers in minimizing the spread of harmful contagions in large networks. We develop exact solution methods based on branch-and-Benders-cut algorithms that make use of the application of Benders decomposition method to two different mixed-integer programming formulations of the MBSMP: an arc-based formulation and a path-based formulation. We show that for both formulations the Benders optimality cuts can be generated using a combinatorial procedure rather than solving the dual subproblems using linear programming. Additional improvements such as using scenario-dependent extended seed sets, initial cuts, and a starting heuristic are also incorporated into our branch-and-Benders-cut algorithms. We investigate the contribution of various components of the solution algorithms to the performance on the basis of computational results obtained on a set of instances derived from existing ones in the literature. ",
    "url": "https://arxiv.org/abs/2303.12402",
    "authors": [
      "K\u00fcbra Tan\u0131nm\u0131\u015f",
      "Necati Aras",
      "Evren G\u00fcney",
      "Markus Sinnl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.12695",
    "title": "Adaptive Conformal Prediction by Reweighting Nonconformity Score",
    "abstract": "Despite attractive theoretical guarantees and practical successes, Predictive Interval (PI) given by Conformal Prediction (CP) may not reflect the uncertainty of a given model. This limitation arises from CP methods using a constant correction for all test points, disregarding their individual uncertainties, to ensure coverage properties. To address this issue, we propose using a Quantile Regression Forest (QRF) to learn the distribution of nonconformity scores and utilizing the QRF's weights to assign more importance to samples with residuals similar to the test point. This approach results in PI lengths that are more aligned with the model's uncertainty. In addition, the weights learnt by the QRF provide a partition of the features space, allowing for more efficient computations and improved adaptiveness of the PI through groupwise conformalization. Our approach enjoys an assumption-free finite sample marginal and training-conditional coverage, and under suitable assumptions, it also ensures conditional coverage. Our methods work for any nonconformity score and are available as a Python package. We conduct experiments on simulated and real-world data that demonstrate significant improvements compared to existing methods. ",
    "url": "https://arxiv.org/abs/2303.12695",
    "authors": [
      "Salim I. Amoukou",
      "Nicolas J.B Brunel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12711",
    "title": "Geometry-Aware Latent Representation Learning for Modeling Disease  Progression of Barrett's Esophagus",
    "abstract": "Barrett's Esophagus (BE) is the only precursor known to Esophageal Adenocarcinoma (EAC), a type of esophageal cancer with poor prognosis upon diagnosis. Therefore, diagnosing BE is crucial in preventing and treating esophageal cancer. While supervised machine learning supports BE diagnosis, high interobserver variability in histopathological training data limits these methods. Unsupervised representation learning via Variational Autoencoders (VAEs) shows promise, as they map input data to a lower-dimensional manifold with only useful features, characterizing BE progression for improved downstream tasks and insights. However, the VAE's Euclidean latent space distorts point relationships, hindering disease progression modeling. Geometric VAEs provide additional geometric structure to the latent space, with RHVAE assuming a Riemannian manifold and $\\mathcal{S}$-VAE a hyperspherical manifold. Our study shows that $\\mathcal{S}$-VAE outperforms vanilla VAE with better reconstruction losses, representation classification accuracies, and higher-quality generated images and interpolations in lower-dimensional settings. By disentangling rotation information from the latent space, we improve results further using a group-based architecture. Additionally, we take initial steps towards $\\mathcal{S}$-AE, a novel autoencoder model generating qualitative images without a variational framework, but retaining benefits of autoencoders such as stability and reconstruction quality. ",
    "url": "https://arxiv.org/abs/2303.12711",
    "authors": [
      "Vivien van Veldhuizen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12735",
    "title": "SMUG: Towards robust MRI reconstruction by smoothed unrolling",
    "abstract": "Although deep learning (DL) has gained much popularity for accelerated magnetic resonance imaging (MRI), recent studies have shown that DL-based MRI reconstruction models could be oversensitive to tiny input perturbations (that are called 'adversarial perturbations'), which cause unstable, low-quality reconstructed images. This raises the question of how to design robust DL methods for MRI reconstruction. To address this problem, we propose a novel image reconstruction framework, termed SMOOTHED UNROLLING (SMUG), which advances a deep unrolling-based MRI reconstruction model using a randomized smoothing (RS)-based robust learning operation. RS, which improves the tolerance of a model against input noises, has been widely used in the design of adversarial defense for image classification. Yet, we find that the conventional design that applies RS to the entire DL process is ineffective for MRI reconstruction. We show that SMUG addresses the above issue by customizing the RS operation based on the unrolling architecture of the DL-based MRI reconstruction model. Compared to the vanilla RS approach and several variants of SMUG, we show that SMUG improves the robustness of MRI reconstruction with respect to a diverse set of perturbation sources, including perturbations to the input measurements, different measurement sampling rates, and different unrolling steps. Code for SMUG will be available at https://github.com/LGM70/SMUG. ",
    "url": "https://arxiv.org/abs/2303.12735",
    "authors": [
      "Hui Li",
      "Jinghan Jia",
      "Shijun Liang",
      "Yuguang Yao",
      "Saiprasad Ravishankar",
      "Sijia Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2303.12761",
    "title": "LSTM-based Video Quality Prediction Accounting for Temporal Distortions  in Videoconferencing Calls",
    "abstract": "Current state-of-the-art video quality models, such as VMAF, give excellent prediction results by comparing the degraded video with its reference video. However, they do not consider temporal distortions (e.g., frame freezes or skips) that occur during videoconferencing calls. In this paper, we present a data-driven approach for modeling such distortions automatically by training an LSTM with subjective quality ratings labeled via crowdsourcing. The videos were collected from live videoconferencing calls in 83 different network conditions. We applied QR codes as markers on the source videos to create aligned references and compute temporal features based on the alignment vectors. Using these features together with VMAF core features, our proposed model achieves a PCC of 0.99 on the validation set. Furthermore, our model outputs per-frame quality that gives detailed insight into the cause of video quality impairments. The VCM model and dataset are open-sourced at https://github.com/microsoft/Video_Call_MOS. ",
    "url": "https://arxiv.org/abs/2303.12761",
    "authors": [
      "Gabriel Mittag",
      "Babak Naderi",
      "Vishak Gopal",
      "Ross Cutler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1808.05177",
    "title": "Forbidden cycles in metrically homogeneous graphs",
    "abstract": " Comments: 25 pages. Minor revisions, accepted to European Journal of Combinatorics ",
    "url": "https://arxiv.org/abs/1808.05177",
    "authors": [
      "Jan Hubi\u010dka",
      "Michael Kompatscher",
      "Mat\u011bj Kone\u010dn\u00fd"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2012.10016",
    "title": "The dual of an evaluation code",
    "abstract": " Comments: The previous version has a typo on the statement of Theorem 5.4. The published version can be found here: this https URL ",
    "url": "https://arxiv.org/abs/2012.10016",
    "authors": [
      "Hiram H. L\u00f3pez",
      "Ivan Soprunov",
      "Rafael H. Villarreal"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2102.05368",
    "title": "RoBIC: A benchmark suite for assessing classifiers robustness",
    "abstract": " Comments: 4 pages, accepted to ICIP 2021 ",
    "url": "https://arxiv.org/abs/2102.05368",
    "authors": [
      "Thibault Maho",
      "Beno\u00eet Bonnet",
      "Teddy Furon",
      "Erwan Le Merrer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.17084",
    "title": "DA-DETR: Domain Adaptive Detection Transformer with Information Fusion",
    "abstract": " Comments: Accepted to CVPR2023 ",
    "url": "https://arxiv.org/abs/2103.17084",
    "authors": [
      "Jingyi Zhang",
      "Jiaxing Huang",
      "Zhipeng Luo",
      "Gongjie Zhang",
      "Xiaoqin Zhang",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.05740",
    "title": "Adaptive Robust Data-driven Building Control via Bi-level Reformulation:  an Experimental Result",
    "abstract": " Title: Adaptive Robust Data-driven Building Control via Bi-level Reformulation:  an Experimental Result ",
    "url": "https://arxiv.org/abs/2106.05740",
    "authors": [
      "Yingzhao Lian",
      "Jicheng Shi",
      "Manuel Koch",
      "Colin Neil Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.10836",
    "title": "Active Learning for Deep Neural Networks on Edge Devices",
    "abstract": " Title: Active Learning for Deep Neural Networks on Edge Devices ",
    "url": "https://arxiv.org/abs/2106.10836",
    "authors": [
      "Yuya Senzaki",
      "Christian Hamelain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2108.02235",
    "title": "Dynamic Relevance Learning for Few-Shot Object Detection",
    "abstract": " Comments: 12 pages, 8 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2108.02235",
    "authors": [
      "Weijie Liu",
      "Chong Wang",
      "Haohe Li",
      "Shenghao Yu",
      "Jiafei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11097",
    "title": "Adaptive Instance Distillation for Object Detection in Autonomous  Driving",
    "abstract": " Comments: 6 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2201.11097",
    "authors": [
      "Qizhen Lan",
      "Qing Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.04235",
    "title": "Towards Compositional Adversarial Robustness: Generalizing Adversarial  Training to Composite Semantic Perturbations",
    "abstract": " Comments: CVPR 2023. The research demo is at this https URL ",
    "url": "https://arxiv.org/abs/2202.04235",
    "authors": [
      "Lei Hsiung",
      "Yun-Yun Tsai",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11437",
    "title": "Representation Uncertainty in Self-Supervised Learning as Variational  Inference",
    "abstract": " Comments: 15 pages, 12 figures, work in progress ",
    "url": "https://arxiv.org/abs/2203.11437",
    "authors": [
      "Hiroki Nakamura",
      "Masashi Okada",
      "Tadahiro Taniguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15752",
    "title": "Information Consumption and Boundary Spanning in Decentralized Online  Social Networks: the case of Mastodon Users",
    "abstract": " Comments: Published with Online Social Networks and Media, vol. 30:100220, June 2022. Elsevier ",
    "url": "https://arxiv.org/abs/2203.15752",
    "authors": [
      "Lucio La Cava",
      "Andrea Tagarelli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2204.10779",
    "title": "CgAT: Center-Guided Adversarial Training for Deep Hashing-Based  Retrieval",
    "abstract": " Title: CgAT: Center-Guided Adversarial Training for Deep Hashing-Based  Retrieval ",
    "url": "https://arxiv.org/abs/2204.10779",
    "authors": [
      "Xunguang Wang",
      "Yiqun Lin",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04192",
    "title": "ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion",
    "abstract": " Title: ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion ",
    "url": "https://arxiv.org/abs/2206.04192",
    "authors": [
      "Aleksandar Pavlovi\u0107",
      "Emanuel Sallinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.06807",
    "title": "The Causal Structure of Semantic Ambiguities",
    "abstract": " Title: The Causal Structure of Semantic Ambiguities ",
    "url": "https://arxiv.org/abs/2206.06807",
    "authors": [
      "Daphne Wang",
      "Mehrnoosh Sadrzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2207.11900",
    "title": "GA2MIF: Graph and Attention based Two-stage Multi-source Information  Fusion for Conversational Emotion Detection",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2207.11900",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.00277",
    "title": "MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient  Neural Field Rendering on Mobile Architectures",
    "abstract": " Comments: CVPR 2023. Project page: this https URL, code: this https URL ",
    "url": "https://arxiv.org/abs/2208.00277",
    "authors": [
      "Zhiqin Chen",
      "Thomas Funkhouser",
      "Peter Hedman",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00690",
    "title": "Generative Bias for Robust Visual Question Answering",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2208.00690",
    "authors": [
      "Jae Won Cho",
      "Dong-jin Kim",
      "Hyeonggon Ryu",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.04589",
    "title": "Long-term Causal Effects Estimation via Latent Surrogates Representation  Learning",
    "abstract": " Title: Long-term Causal Effects Estimation via Latent Surrogates Representation  Learning ",
    "url": "https://arxiv.org/abs/2208.04589",
    "authors": [
      "Ruichu Cai",
      "Weilin Chen",
      "Zeqin Yang",
      "Shu Wan",
      "Chen Zheng",
      "Xiaoqing Yang",
      "Jiecheng Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.01011",
    "title": "On the Complexity of Robust Multi-Stage Problems in the Polynomial  Hierarchy",
    "abstract": " Title: On the Complexity of Robust Multi-Stage Problems in the Polynomial  Hierarchy ",
    "url": "https://arxiv.org/abs/2209.01011",
    "authors": [
      "Marc Goerigk",
      "Stefan Lendl",
      "Lasse Wulf"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2209.03716",
    "title": "Enhancing the Self-Universality for Transferable Targeted Attacks",
    "abstract": " Title: Enhancing the Self-Universality for Transferable Targeted Attacks ",
    "url": "https://arxiv.org/abs/2209.03716",
    "authors": [
      "Zhipeng Wei",
      "Jingjing Chen",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.04187",
    "title": "Efficient Multi-view Clustering via Unified and Discrete Bipartite Graph  Learning",
    "abstract": " Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2209.04187",
    "authors": [
      "Si-Guo Fang",
      "Dong Huang",
      "Xiao-Sha Cai",
      "Chang-Dong Wang",
      "Chaobo He",
      "Yong Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.09385",
    "title": "LidarMultiNet: Towards a Unified Multi-Task Network for LiDAR Perception",
    "abstract": " Comments: Accepted to AAAI 2023 (Oral). Full-length paper extending our previous technical report of the 1st place solution of the 2022 Waymo Open Dataset 3D Semantic Segmentation challenge, including evaluations on 5 major benchmarks. arXiv admin note: text overlap with arXiv:2206.11428 ",
    "url": "https://arxiv.org/abs/2209.09385",
    "authors": [
      "Dongqiangzi Ye",
      "Zixiang Zhou",
      "Weijia Chen",
      "Yufei Xie",
      "Yu Wang",
      "Panqu Wang",
      "Hassan Foroosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11425",
    "title": "RIS-Aided MIMO Systems with Hardware Impairments: Robust Beamforming  Design and Analysis",
    "abstract": " Comments: 16 pages, 6 figures. Accepted by IEEE Transactions on Wireless Communications ",
    "url": "https://arxiv.org/abs/2209.11425",
    "authors": [
      "Jintao Wang",
      "Shiqi Gong",
      "Qingqing Wu",
      "Shaodan Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.01269",
    "title": "Course-Prerequisite Networks for Analyzing and Understanding Academic  Curricula",
    "abstract": " Comments: 25 pages, 20 figures, 10 Tables ",
    "url": "https://arxiv.org/abs/2210.01269",
    "authors": [
      "Pavlos Stavrinides",
      "Konstantin Zuev"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.11684",
    "title": "Change Point Detection Approach for Online Control of Unknown Time  Varying Dynamical Systems",
    "abstract": " Title: Change Point Detection Approach for Online Control of Unknown Time  Varying Dynamical Systems ",
    "url": "https://arxiv.org/abs/2210.11684",
    "authors": [
      "Deepan Muthirayan",
      "Ruijie Du",
      "Yanning Shen",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.12239",
    "title": "Auto-Encoder Neural Network Incorporating X-Ray Fluorescence Fundamental  Parameters with Machine Learning",
    "abstract": " Comments: X-Ray Spectrometry 2023 ",
    "url": "https://arxiv.org/abs/2210.12239",
    "authors": [
      "Matthew Dirks",
      "David Poole"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00288",
    "title": "Self-supervised Character-to-Character Distillation for Text Recognition",
    "abstract": " Title: Self-supervised Character-to-Character Distillation for Text Recognition ",
    "url": "https://arxiv.org/abs/2211.00288",
    "authors": [
      "Tongkun Guan",
      "Wei Shen",
      "Xue Yang",
      "Qi Feng",
      "Zekun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.03168",
    "title": "Approximate Graph Colouring and the Crystal with a Hollow Shadow",
    "abstract": " Comments: Full version of a STOC'23 paper and a SODA'23 paper (arXiv:2210.08293). Generalises and subsumes results from Section 6 in arXiv:2203.02478 ",
    "url": "https://arxiv.org/abs/2211.03168",
    "authors": [
      "Lorenzo Ciardo",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.04561",
    "title": "A physics-aware deep learning model for energy localization in  multiscale shock-to-detonation simulations of heterogeneous energetic  materials",
    "abstract": " Title: A physics-aware deep learning model for energy localization in  multiscale shock-to-detonation simulations of heterogeneous energetic  materials ",
    "url": "https://arxiv.org/abs/2211.04561",
    "authors": [
      "Phong C.H. Nguyen",
      "Yen-Thi Nguyen",
      "Pradeep K. Seshadri",
      "Joseph B. Choi",
      "H.S. Udaykumar",
      "Stephen Baek"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.06627",
    "title": "MARLIN: Masked Autoencoder for facial video Representation LearnINg",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2211.06627",
    "authors": [
      "Zhixi Cai",
      "Shreya Ghosh",
      "Kalin Stefanov",
      "Abhinav Dhall",
      "Jianfei Cai",
      "Hamid Rezatofighi",
      "Reza Haffari",
      "Munawar Hayat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11277",
    "title": "DrapeNet: Garment Generation and Self-Supervised Draping",
    "abstract": " Title: DrapeNet: Garment Generation and Self-Supervised Draping ",
    "url": "https://arxiv.org/abs/2211.11277",
    "authors": [
      "Luca De Luigi",
      "Ren Li",
      "Beno\u00eet Guillard",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12501",
    "title": "AeDet: Azimuth-invariant Multi-view 3D Object Detection",
    "abstract": " Comments: CVPR2023 ",
    "url": "https://arxiv.org/abs/2211.12501",
    "authors": [
      "Chengjian Feng",
      "Zequn Jie",
      "Yujie Zhong",
      "Xiangxiang Chu",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13436",
    "title": "Solving Bilevel Knapsack Problem using Graph Neural Networks",
    "abstract": " Comments: 27 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2211.13436",
    "authors": [
      "Sunhyeon Kwon",
      "Hwayong Choi",
      "Sungsoo Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.15387",
    "title": "AIREPAIR: A Repair Platform for Neural Networks",
    "abstract": " Title: AIREPAIR: A Repair Platform for Neural Networks ",
    "url": "https://arxiv.org/abs/2211.15387",
    "authors": [
      "Xidan Song",
      "Youcheng Sun",
      "Mustafa A. Mustafa",
      "Lucas Cordeiro"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.02809",
    "title": "An advanced YOLOv3 method for small object detection",
    "abstract": " Title: An advanced YOLOv3 method for small object detection ",
    "url": "https://arxiv.org/abs/2212.02809",
    "authors": [
      "Baokai Liu",
      "Fengjie He",
      "Shiqiang Du",
      "Jiacheng Li",
      "Wenjie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.07060",
    "title": "VINet: Lightweight, Scalable, and Heterogeneous Cooperative Perception  for 3D Object Detection",
    "abstract": " Title: VINet: Lightweight, Scalable, and Heterogeneous Cooperative Perception  for 3D Object Detection ",
    "url": "https://arxiv.org/abs/2212.07060",
    "authors": [
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Matthew J. Barth",
      "Yongkang Liu",
      "Emrah Akin Sisbot",
      "Kentaro Oguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.07090",
    "title": "Database Matching Under Adversarial Column Deletions",
    "abstract": " Title: Database Matching Under Adversarial Column Deletions ",
    "url": "https://arxiv.org/abs/2212.07090",
    "authors": [
      "Serhat Bakirtas",
      "Elza Erkip"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2212.07593",
    "title": "Enhanced Training of Query-Based Object Detection via Selective Query  Recollection",
    "abstract": " Comments: CVPR2023 ",
    "url": "https://arxiv.org/abs/2212.07593",
    "authors": [
      "Fangyi Chen",
      "Han Zhang",
      "Kai Hu",
      "Yu-kai Huang",
      "Chenchen Zhu",
      "Marios Savvides"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.08481",
    "title": "Machine Learning for Relaying Topology: Optimization of IoT Network with  Energy Harvesting",
    "abstract": " Comments: 12 pages, 11 figures;Re-submitted to IEEE Access on 22 March 2023 ",
    "url": "https://arxiv.org/abs/2301.08481",
    "authors": [
      "Kiseop Chung",
      "Jin-Taek Lim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.02005",
    "title": "DeepAstroUDA: Semi-Supervised Universal Domain Adaptation for  Cross-Survey Galaxy Morphology Classification and Anomaly Detection",
    "abstract": " Comments: Accepted in Machine Learning Science and Technology (MLST); 24 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2302.02005",
    "authors": [
      "A. \u0106iprijanovi\u0107",
      "A. Lewis",
      "K. Pedro",
      "S. Madireddy",
      "B. Nord",
      "G. N. Perdue",
      "S. M. Wild"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02590",
    "title": "Consensus dynamics and coherence in hierarchical small-world networks",
    "abstract": " Title: Consensus dynamics and coherence in hierarchical small-world networks ",
    "url": "https://arxiv.org/abs/2302.02590",
    "authors": [
      "Yunhua Liao",
      "Mohamed Maama",
      "M.A. Aziz-Alaoui"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2302.03262",
    "title": "Membership Inference Attacks against Diffusion Models",
    "abstract": " Title: Membership Inference Attacks against Diffusion Models ",
    "url": "https://arxiv.org/abs/2302.03262",
    "authors": [
      "Tomoya Matsumoto",
      "Takayuki Miura",
      "Naoto Yanai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.07260",
    "title": "Scalable Bayesian optimization with high-dimensional outputs using  randomized prior networks",
    "abstract": " Comments: 18 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2302.07260",
    "authors": [
      "Mohamed Aziz Bhouri",
      "Michael Joly",
      "Robert Yu",
      "Soumalya Sarkar",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.12242",
    "title": "Side Adapter Network for Open-Vocabulary Semantic Segmentation",
    "abstract": " Comments: CVPR2023 Highlight ",
    "url": "https://arxiv.org/abs/2302.12242",
    "authors": [
      "Mengde Xu",
      "Zheng Zhang",
      "Fangyun Wei",
      "Han Hu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.03711",
    "title": "SCRAMBLE-CFI: Mitigating Fault-Induced Control-Flow Attacks on OpenTitan",
    "abstract": " Comments: Accepted at GLSVLS'23 ",
    "url": "https://arxiv.org/abs/2303.03711",
    "authors": [
      "Pascal Nasahl",
      "Stefan Mangard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.06919",
    "title": "NeRFLiX: High-Quality Neural View Synthesis by Learning a  Degradation-Driven Inter-viewpoint MiXer",
    "abstract": " Comments: Accepted to CVPR 2023; Project Page: see this https URL ",
    "url": "https://arxiv.org/abs/2303.06919",
    "authors": [
      "Kun Zhou",
      "Wenbo Li",
      "Yi Wang",
      "Tao Hu",
      "Nianjuan Jiang",
      "Xiaoguang Han",
      "Jiangbo Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07543",
    "title": "WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant  Analysis",
    "abstract": " Title: WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminant  Analysis ",
    "url": "https://arxiv.org/abs/2303.07543",
    "authors": [
      "Yiye Chen",
      "Yunzhi Lin",
      "Ruinian Xu",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09998",
    "title": "TBP-Former: Learning Temporal Bird's-Eye-View Pyramid for Joint  Perception and Prediction in Vision-Centric Autonomous Driving",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.09998",
    "authors": [
      "Shaoheng Fang",
      "Zi Wang",
      "Yiqi Zhong",
      "Junhao Ge",
      "Siheng Chen",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10382",
    "title": "Interpretable Reinforcement Learning via Neural Additive Models for  Inventory Management",
    "abstract": " Title: Interpretable Reinforcement Learning via Neural Additive Models for  Inventory Management ",
    "url": "https://arxiv.org/abs/2303.10382",
    "authors": [
      "Julien Siems",
      "Maximilian Schambach",
      "Sebastian Schulze",
      "Johannes S. Otterbach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.10598",
    "title": "StyleRF: Zero-shot 3D Style Transfer of Neural Radiance Fields",
    "abstract": " Comments: Accepted to CVPR 2023. Project website: this https URL ",
    "url": "https://arxiv.org/abs/2303.10598",
    "authors": [
      "Kunhao Liu",
      "Fangneng Zhan",
      "Yiwen Chen",
      "Jiahui Zhang",
      "Yingchen Yu",
      "Abdulmotaleb El Saddik",
      "Shijian Lu",
      "Eric Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10752",
    "title": "Fully Self-Supervised Depth Estimation from Defocus Clue",
    "abstract": " Comments: CVPR 2023 camera-ready version. The code is released at this https URL ",
    "url": "https://arxiv.org/abs/2303.10752",
    "authors": [
      "Haozhe Si",
      "Bin Zhao",
      "Dong Wang",
      "Yupeng Gao",
      "Mulin Chen",
      "Zhigang Wang",
      "Xuelong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10992",
    "title": "Pressure and convection robust bounds for continuous interior penalty  divergence-free finite element methods for the incompressible Navier-Stokes  equations",
    "abstract": " Title: Pressure and convection robust bounds for continuous interior penalty  divergence-free finite element methods for the incompressible Navier-Stokes  equations ",
    "url": "https://arxiv.org/abs/2303.10992",
    "authors": [
      "Bosco Garc\u00eda-Archilla",
      "Julia Novo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.11331",
    "title": "EVA-02: A Visual Representation for Neon Genesis",
    "abstract": " Comments: v2: Fix some known issues & typos. v1: To Asuka. Code & Models: this https URL ",
    "url": "https://arxiv.org/abs/2303.11331",
    "authors": [
      "Yuxin Fang",
      "Quan Sun",
      "Xinggang Wang",
      "Tiejun Huang",
      "Xinlong Wang",
      "Yue Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.11575",
    "title": "\"I Want the Payment Process to be Cool'': Understanding How Interaction  Factors into Security and Privacy Perception of Authentication in Virtual  Reality",
    "abstract": " Title: \"I Want the Payment Process to be Cool'': Understanding How Interaction  Factors into Security and Privacy Perception of Authentication in Virtual  Reality ",
    "url": "https://arxiv.org/abs/2303.11575",
    "authors": [
      "Jingjie Li",
      "Sunpreet Singh Arora",
      "Kassem Fawaz",
      "Younghyun Kim",
      "Can Liu",
      "Sebastian Meiser",
      "Mohsen Minaei",
      "Maliheh Shirvanian",
      "Kim Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.11617",
    "title": "Adaptive quadratures for nonlinear approximation of low-dimensional PDEs  using smooth neural networks",
    "abstract": " Comments: Corrected the numbering of references ",
    "url": "https://arxiv.org/abs/2303.11617",
    "authors": [
      "Alexandre Magueresse",
      "Santiago Badia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.11728",
    "title": "ExtremeNeRF: Few-shot Neural Radiance Fields Under Unconstrained  Illumination",
    "abstract": " Comments: Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2303.11728",
    "authors": [
      "SeokYeong Lee",
      "JunYong Choi",
      "Seungryong Kim",
      "Ig-Jae Kim",
      "Junghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11899",
    "title": "Multi-agent Reinforcement Learning for Regional Signal control in  Large-scale Grid Traffic network",
    "abstract": " Title: Multi-agent Reinforcement Learning for Regional Signal control in  Large-scale Grid Traffic network ",
    "url": "https://arxiv.org/abs/2303.11899",
    "authors": [
      "Hankang Gu",
      "Shangbo Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11943",
    "title": "Data assimilation for sparsification of reaction diffusion systems in a  complex network",
    "abstract": " Comments: 28 pages, 23 figures ",
    "url": "https://arxiv.org/abs/2303.11943",
    "authors": [
      "Abhishek Ajayakumar",
      "Soumyendu Raha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Physics and Society (physics.soc-ph)"
    ]
  }
]