[
  {
    "id": "arXiv:2309.13046",
    "title": "Privacy Preserving Machine Learning for Behavioral Authentication  Systems",
    "abstract": "A behavioral authentication (BA) system uses the behavioral characteristics of users to verify their identity claims. A BA verification algorithm can be constructed by training a neural network (NN) classifier on users' profiles. The trained NN model classifies the presented verification data, and if the classification matches the claimed identity, the verification algorithm accepts the claim. This classification-based approach removes the need to maintain a profile database. However, similar to other NN architectures, the NN classifier of the BA system is vulnerable to privacy attacks. To protect the privacy of training and test data used in an NN different techniques are widely used. In this paper, our focus is on a non-crypto-based approach, and we used random projection (RP) to ensure data privacy in an NN model. RP is a distance-preserving transformation based on a random matrix. Before sharing the profiles with the verifier, users will transform their profiles by RP and keep their matrices secret. To reduce the computation load in RP, we use sparse random projection, which is very effective for low-compute devices. Along with correctness and security properties, our system can ensure the changeability property of the BA system. We also introduce an ML-based privacy attack, and our proposed system is robust against this and other privacy and security attacks. We implemented our approach on three existing behavioral BA systems and achieved a below 2.0% FRR and a below 1.0% FAR rate. Moreover, the machine learning-based privacy attacker can only recover below 3.0% to 12.0% of features from a portion of the projected profiles. However, these recovered features are not sufficient to know details about the users' behavioral pattern or to be used in a subsequent attack. Our approach is general and can be used in other NN-based BA systems as well as in traditional biometric systems. ",
    "url": "https://arxiv.org/abs/2309.13046",
    "authors": [
      "Md Morshedul Islam",
      "Md Abdur Rafiq"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13050",
    "title": "Decoding the Alphabet Soup of Degrees in the United States Postsecondary  Education System Through Hybrid Method: Database and Text Mining",
    "abstract": "This paper proposes a model to predict the levels (e.g., Bachelor, Master, etc.) of postsecondary degree awards that have been ambiguously expressed in the student tracking reports of the National Student Clearinghouse (NSC). The model will be the hybrid of two modules. The first module interprets the relevant abbreviatory elements embedded in NSC reports by referring to a comprehensive database that we have made of nearly 950 abbreviations for degree titles used by American postsecondary educators. The second module is a combination of feature classification and text mining modeled with CNN-BiLSTM, which is preceded by several steps of heavy pre-processing. The model proposed in this paper was trained with four multi-label datasets of different grades of resolution and returned 97.83\\% accuracy with the most sophisticated dataset. Such a thorough classification of degree levels will provide insights into the modeling patterns of student success and mobility. To date, such a classification strategy has not been attempted except using manual methods and simple text parsing logic. ",
    "url": "https://arxiv.org/abs/2309.13050",
    "authors": [
      "Sahar Voghoei",
      "James Byars",
      "John A Miller",
      "Khaled Rasheed",
      "Hamid A Arabnia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13058",
    "title": "Mathematical Modeling and Optimal Control of Untrue Information :  Dynamic SEIZ in Online Social Networks",
    "abstract": "We propose to model the phenomenon of the spread of a rumor in this paper. We manipulate a model that is based on SEIR model that specializes in spreading rumors. In the second part, we introduce a control strategy to fight against the diffusion of the rumor. Our main objective is to characterize the three optimal controls that minimize the number of spreaders, susceptibles who enter and spread the rumor, and skeptics. For that matter, using the maximum principle of Pontryagin, we prove the existence and give characterization of our controls. To illustrate the theoretical results obtained, numerical simulations are given to concretize our approach. ",
    "url": "https://arxiv.org/abs/2309.13058",
    "authors": [
      "Fulgence Mansal",
      "Ibrahima Faye"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.13061",
    "title": "Applying BioBERT to Extract Germline Gene-Disease Associations for  Building a Knowledge Graph from the Biomedical Literature",
    "abstract": "Published biomedical information has and continues to rapidly increase. The recent advancements in Natural Language Processing (NLP), have generated considerable interest in automating the extraction, normalization, and representation of biomedical knowledge about entities such as genes and diseases. Our study analyzes germline abstracts in the construction of knowledge graphs of the of the immense work that has been done in this area for genes and diseases. This paper presents SimpleGermKG, an automatic knowledge graph construction approach that connects germline genes and diseases. For the extraction of genes and diseases, we employ BioBERT, a pre-trained BERT model on biomedical corpora. We propose an ontology-based and rule-based algorithm to standardize and disambiguate medical terms. For semantic relationships between articles, genes, and diseases, we implemented a part-whole relation approach to connect each entity with its data source and visualize them in a graph-based knowledge representation. Lastly, we discuss the knowledge graph applications, limitations, and challenges to inspire the future research of germline corpora. Our knowledge graph contains 297 genes, 130 diseases, and 46,747 triples. Graph-based visualizations are used to show the results. ",
    "url": "https://arxiv.org/abs/2309.13061",
    "authors": [
      "Armando D. Diaz Gonzalez",
      "Songhui Yue",
      "Sean T. Hayes",
      "Kevin S. Hughes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.13065",
    "title": "Personality Profiling: How informative are social media profiles in  predicting personal information?",
    "abstract": "Personality profiling has been utilised by companies for targeted advertising, political campaigns and vaccine campaigns. However, the accuracy and versatility of such models still remains relatively unknown. Consequently, we aim to explore the extent to which peoples' online digital footprints can be used to profile their Myers-Briggs personality type. We analyse and compare the results of four models: logistic regression, naive Bayes, support vector machines (SVMs) and random forests. We discover that a SVM model achieves the best accuracy of 20.95% for predicting someones complete personality type. However, logistic regression models perform only marginally worse and are significantly faster to train and perform predictions. We discover that many labelled datasets present substantial class imbalances of personal characteristics on social media, including our own. As a result, we highlight the need for attentive consideration when reporting model performance on these datasets and compare a number of methods for fixing the class-imbalance problems. Moreover, we develop a statistical framework for assessing the importance of different sets of features in our models. We discover some features to be more informative than others in the Intuitive/Sensory (p = 0.032) and Thinking/Feeling (p = 0.019) models. While we apply these methods to Myers-Briggs personality profiling, they could be more generally used for any labelling of individuals on social media. ",
    "url": "https://arxiv.org/abs/2309.13065",
    "authors": [
      "Joshua Watt",
      "Jonathan Tuke",
      "Lewis Mitchell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.13066",
    "title": "Causal Discovery and Counterfactual Explanations for Personalized  Student Learning",
    "abstract": "The paper focuses on identifying the causes of student performance to provide personalized recommendations for improving pass rates. We introduce the need to move beyond predictive models and instead identify causal relationships. We propose using causal discovery techniques to achieve this. The study's main contributions include using causal discovery to identify causal predictors of student performance and applying counterfactual analysis to provide personalized recommendations. The paper describes the application of causal discovery methods, specifically the PC algorithm, to real-life student performance data. It addresses challenges such as sample size limitations and emphasizes the role of domain knowledge in causal discovery. The results reveal the identified causal relationships, such as the influence of earlier test grades and mathematical ability on final student performance. Limitations of this study include the reliance on domain expertise for accurate causal discovery, and the necessity of larger sample sizes for reliable results. The potential for incorrect causal structure estimations is acknowledged. A major challenge remains, which is the real-time implementation and validation of counterfactual recommendations. In conclusion, the paper demonstrates the value of causal discovery for understanding student performance and providing personalized recommendations. It highlights the challenges, benefits, and limitations of using causal inference in an educational context, setting the stage for future studies to further explore and refine these methods. ",
    "url": "https://arxiv.org/abs/2309.13066",
    "authors": [
      "Bevan I. Smith"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.13069",
    "title": "Machine Learning Technique Based Fake News Detection",
    "abstract": "False news has received attention from both the general public and the scholarly world. Such false information has the ability to affect public perception, giving nefarious groups the chance to influence the results of public events like elections. Anyone can share fake news or facts about anyone or anything for their personal gain or to cause someone trouble. Also, information varies depending on the part of the world it is shared on. Thus, in this paper, we have trained a model to classify fake and true news by utilizing the 1876 news data from our collected dataset. We have preprocessed the data to get clean and filtered texts by following the Natural Language Processing approaches. Our research conducts 3 popular Machine Learning (Stochastic gradient descent, Na\\\"ive Bayes, Logistic Regression,) and 2 Deep Learning (Long-Short Term Memory, ASGD Weight-Dropped LSTM, or AWD-LSTM) algorithms. After we have found our best Naive Bayes classifier with 56% accuracy and an F1-macro score of an average of 32%. ",
    "url": "https://arxiv.org/abs/2309.13069",
    "authors": [
      "Biplob Kumar Sutradhar",
      "Md. Zonaid",
      "Nushrat Jahan Ria",
      "Sheak Rashed Haider Noori"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13080",
    "title": "SPICED: News Similarity Detection Dataset with Multiple Topics and  Complexity Levels",
    "abstract": "Nowadays, the use of intelligent systems to detect redundant information in news articles has become especially prevalent with the proliferation of news media outlets in order to enhance user experience. However, the heterogeneous nature of news can lead to spurious findings in these systems: Simple heuristics such as whether a pair of news are both about politics can provide strong but deceptive downstream performance. Segmenting news similarity datasets into topics improves the training of these models by forcing them to learn how to distinguish salient characteristics under more narrow domains. However, this requires the existence of topic-specific datasets, which are currently lacking. In this article, we propose a new dataset of similar news, SPICED, which includes seven topics: Crime & Law, Culture & Entertainment, Disasters & Accidents, Economy & Business, Politics & Conflicts, Science & Technology, and Sports. Futhermore, we present four distinct approaches for generating news pairs, which are used in the creation of datasets specifically designed for news similarity detection task. We benchmarked the created datasets using MinHash, BERT, SBERT, and SimCSE models. ",
    "url": "https://arxiv.org/abs/2309.13080",
    "authors": [
      "Elena Shushkevich",
      "Long Mai",
      "Manuel V. Loureiro",
      "Steven Derby",
      "Tri Kurniawan Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13092",
    "title": "Prototype-Enhanced Hypergraph Learning for Heterogeneous Information  Networks",
    "abstract": "The variety and complexity of relations in multimedia data lead to Heterogeneous Information Networks (HINs). Capturing the semantics from such networks requires approaches capable of utilizing the full richness of the HINs. Existing methods for modeling HINs employ techniques originally designed for graph neural networks, and HINs decomposition analysis, like using manually predefined metapaths. In this paper, we introduce a novel prototype-enhanced hypergraph learning approach for node classification in HINs. Using hypergraphs instead of graphs, our method captures higher-order relationships among nodes and extracts semantic information without relying on metapaths. Our method leverages the power of prototypes to improve the robustness of the hypergraph learning process and creates the potential to provide human-interpretable insights into the underlying network structure. Extensive experiments on three real-world HINs demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2309.13092",
    "authors": [
      "Shuai Wang",
      "Jiayi Shen",
      "Athanasios Efthymiou",
      "Stevan Rudinac",
      "Monika Kackovic",
      "Nachoem Wijnberg",
      "Marcel Worring"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.13103",
    "title": "OpportunityFinder: A Framework for Automated Causal Inference",
    "abstract": "We introduce OpportunityFinder, a code-less framework for performing a variety of causal inference studies with panel data for non-expert users. In its current state, OpportunityFinder only requires users to provide raw observational data and a configuration file. A pipeline is then triggered that inspects/processes data, chooses the suitable algorithm(s) to execute the causal study. It returns the causal impact of the treatment on the configured outcome, together with sensitivity and robustness results. Causal inference is widely studied and used to estimate the downstream impact of individual's interactions with products and features. It is common that these causal studies are performed by scientists and/or economists periodically. Business stakeholders are often bottle-necked on scientist or economist bandwidth to conduct causal studies. We offer OpportunityFinder as a solution for commonly performed causal studies with four key features: (1) easy to use for both Business Analysts and Scientists, (2) abstraction of multiple algorithms under a single I/O interface, (3) support for causal impact analysis under binary treatment with panel data and (4) dynamic selection of algorithm based on scale of data. ",
    "url": "https://arxiv.org/abs/2309.13103",
    "authors": [
      "Huy Nguyen",
      "Prince Grover",
      "Devashish Khatwani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.13132",
    "title": "Understanding Calibration of Deep Neural Networks for Medical Image  Classification",
    "abstract": "In the field of medical image analysis, achieving high accuracy is not enough; ensuring well-calibrated predictions is also crucial. Confidence scores of a deep neural network play a pivotal role in explainability by providing insights into the model's certainty, identifying cases that require attention, and establishing trust in its predictions. Consequently, the significance of a well-calibrated model becomes paramount in the medical imaging domain, where accurate and reliable predictions are of utmost importance. While there has been a significant effort towards training modern deep neural networks to achieve high accuracy on medical imaging tasks, model calibration and factors that affect it remain under-explored. To address this, we conducted a comprehensive empirical study that explores model performance and calibration under different training regimes. We considered fully supervised training, which is the prevailing approach in the community, as well as rotation-based self-supervised method with and without transfer learning, across various datasets and architecture sizes. Multiple calibration metrics were employed to gain a holistic understanding of model calibration. Our study reveals that factors such as weight distributions and the similarity of learned representations correlate with the calibration trends observed in the models. Notably, models trained using rotation-based self-supervised pretrained regime exhibit significantly better calibration while achieving comparable or even superior performance compared to fully supervised models across different medical imaging datasets. These findings shed light on the importance of model calibration in medical image analysis and highlight the benefits of incorporating self-supervised learning approach to improve both performance and calibration. ",
    "url": "https://arxiv.org/abs/2309.13132",
    "authors": [
      "Abhishek Singh Sambyal",
      "Usma Niyaz",
      "Narayanan C. Krishnan",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13144",
    "title": "SoRTS: Learned Tree Search for Long Horizon Social Robot Navigation",
    "abstract": "The fast-growing demand for fully autonomous robots in shared spaces calls for the development of trustworthy agents that can safely and seamlessly navigate in crowded environments. Recent models for motion prediction show promise in characterizing social interactions in such environments. Still, adapting them for navigation is challenging as they often suffer from generalization failures. Prompted by this, we propose Social Robot Tree Search (SoRTS), an algorithm for safe robot navigation in social domains. SoRTS aims to augment existing socially aware motion prediction models for long-horizon navigation using Monte Carlo Tree Search. We use social navigation in general aviation as a case study to evaluate our approach and further the research in full-scale aerial autonomy. In doing so, we introduce XPlaneROS, a high-fidelity aerial simulator that enables human-robot interaction. We use XPlaneROS to conduct a first-of-its-kind user study where 26 FAA-certified pilots interact with a human pilot, our algorithm, and its ablation. Our results, supported by statistical evidence, show that SoRTS exhibits a comparable performance to competent human pilots, significantly outperforming its ablation. Finally, we complement these results with a broad set of self-play experiments to showcase our algorithm's performance in scenarios with increasing complexity. ",
    "url": "https://arxiv.org/abs/2309.13144",
    "authors": [
      "Ingrid Navarro",
      "Jay Patrikar",
      "Joao P. A. Dantas",
      "Rohan Baijal",
      "Ian Higgins",
      "Sebastian Scherer",
      "Jean Oh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.13147",
    "title": "Cardiovascular Disease Risk Prediction via Social Media",
    "abstract": "Researchers utilize Twitter and sentiment analysis to forecast the risk of Cardiovascular Disease (CVD). We have introduced a novel CVD-related keyword dictionary by scrutinizing the emotions conveyed in tweets. We gathered tweets from eighteen U.S. states, encompassing the Appalachian region. Employing the VADER model for sentiment analysis, we categorized users as potentially at risk for CVD. Machine Learning (ML) models were employed to assess individuals' CVD risk and were subsequently applied to a CDC dataset containing demographic information for comparison. We considered various performance evaluation metrics, including Test Accuracy, Precision, Recall, F1 score, Mathew's Correlation Coefficient (MCC), and Cohen's Kappa (CK) score. Our findings demonstrate that analyzing the emotional content of tweets outperforms the predictive capabilities of demographic data alone, enabling the identification of individuals at potential risk of developing CVD. This research underscores the potential of Natural Language Processing (NLP) and ML techniques in leveraging tweets to identify individuals with CVD risks, offering an alternative approach to traditional demographic information for public health monitoring. ",
    "url": "https://arxiv.org/abs/2309.13147",
    "authors": [
      "Al Zadid Sultan Bin Habib",
      "Md Asif Bin Syed",
      "Md Tanvirul Islam",
      "Donald A. Adjeroh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.13150",
    "title": "Pixel-wise Smoothing for Certified Robustness against Camera Motion  Perturbations",
    "abstract": "In recent years, computer vision has made remarkable advancements in autonomous driving and robotics. However, it has been observed that deep learning-based visual perception models lack robustness when faced with camera motion perturbations. The current certification process for assessing robustness is costly and time-consuming due to the extensive number of image projections required for Monte Carlo sampling in the 3D camera motion space. To address these challenges, we present a novel, efficient, and practical framework for certifying the robustness of 3D-2D projective transformations against camera motion perturbations. Our approach leverages a smoothing distribution over the 2D pixel space instead of in the 3D physical space, eliminating the need for costly camera motion sampling and significantly enhancing the efficiency of robustness certifications. With the pixel-wise smoothed classifier, we are able to fully upper bound the projection errors using a technique of uniform partitioning in camera motion space. Additionally, we extend our certification framework to a more general scenario where only a single-frame point cloud is required in the projection oracle. This is achieved by deriving Lipschitz-based approximated partition intervals. Through extensive experimentation, we validate the trade-off between effectiveness and efficiency enabled by our proposed method. Remarkably, our approach achieves approximately 80% certified accuracy while utilizing only 30% of the projected image frames. ",
    "url": "https://arxiv.org/abs/2309.13150",
    "authors": [
      "Hanjiang Hu",
      "Zuxin Liu",
      "Linyi Li",
      "Jiacheng Zhu",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.13167",
    "title": "Flow Factorized Representation Learning",
    "abstract": "A prominent goal of representation learning research is to achieve representations which are factorized in a useful manner with respect to the ground truth factors of variation. The fields of disentangled and equivariant representation learning have approached this ideal from a range of complimentary perspectives; however, to date, most approaches have proven to either be ill-specified or insufficiently flexible to effectively separate all realistic factors of interest in a learned latent space. In this work, we propose an alternative viewpoint on such structured representation learning which we call Flow Factorized Representation Learning, and demonstrate it to learn both more efficient and more usefully structured representations than existing frameworks. Specifically, we introduce a generative model which specifies a distinct set of latent probability paths that define different input transformations. Each latent flow is generated by the gradient field of a learned potential following dynamic optimal transport. Our novel setup brings new understandings to both \\textit{disentanglement} and \\textit{equivariance}. We show that our model achieves higher likelihoods on standard representation learning benchmarks while simultaneously being closer to approximately equivariant models. Furthermore, we demonstrate that the transformations learned by our model are flexibly composable and can also extrapolate to new data, implying a degree of robustness and generalizability approaching the ultimate goal of usefully factorized representation learning. ",
    "url": "https://arxiv.org/abs/2309.13167",
    "authors": [
      "Yue Song",
      "T. Anderson Keller",
      "Nicu Sebe",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13170",
    "title": "Investigating Efficient Deep Learning Architectures For Side-Channel  Attacks on AES",
    "abstract": "Over the past few years, deep learning has been getting progressively more popular for the exploitation of side-channel vulnerabilities in embedded cryptographic applications, as it offers advantages in terms of the amount of attack traces required for effective key recovery. A number of effective attacks using neural networks have already been published, but reducing their cost in terms of the amount of computing resources and data required is an ever-present goal, which we pursue in this work. We focus on the ANSSI Side-Channel Attack Database (ASCAD), and produce a JAX-based framework for deep-learning-based SCA, with which we reproduce a selection of previous results and build upon them in an attempt to improve their performance. We also investigate the effectiveness of various Transformer-based models. ",
    "url": "https://arxiv.org/abs/2309.13170",
    "authors": [
      "Yoha\u00ef-Eliel Berreby",
      "Laurent Sauvage"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13174",
    "title": "Robust self-propulsion in sand using simply controlled vibrating cubes",
    "abstract": "Much of the Earth and many surfaces of extraterrestrial bodies are composed of in-cohesive particle matter. Locomoting on granular terrain is challenging for common robotic devices, either wheeled or legged. In this work, we discover a robust alternative locomotion mechanism on granular media -- generating movement via self-vibration. To demonstrate the effectiveness of this locomotion mechanism, we develop a cube-shaped robot with an embedded vibratory motor and conduct systematic experiments on diverse granular terrains of various particle properties. We investigate how locomotion changes as a function of vibration frequency/intensity on granular terrains. Compared to hard surfaces, we find such a vibratory locomotion mechanism enables the robot to move faster, and more stable on granular surfaces, facilitated by the interaction between the body and surrounding granules. The simplicity in structural design and controls of this robotic system indicates that vibratory locomotion can be a valuable alternative way to produce robust locomotion on granular terrains. We further demonstrate that such cube-shape robots can be used as modular units for morphologically structured vibratory robots with capabilities of maneuverable forward and turning motions, showing potential practical scenarios for robotic systems. ",
    "url": "https://arxiv.org/abs/2309.13174",
    "authors": [
      "Bangyuan Liu",
      "Tianyu Wang",
      "Velin Kojouharov",
      "Frank L. Hammond III",
      "Daniel I. Goldman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.13190",
    "title": "Spatial-frequency channels, shape bias, and adversarial robustness",
    "abstract": "What spatial frequency information do humans and neural networks use to recognize objects? In neuroscience, critical band masking is an established tool that can reveal the frequency-selective filters used for object recognition. Critical band masking measures the sensitivity of recognition performance to noise added at each spatial frequency. Existing critical band masking studies show that humans recognize periodic patterns (gratings) and letters by means of a spatial-frequency filter (or \"channel'') that has a frequency bandwidth of one octave (doubling of frequency). Here, we introduce critical band masking as a task for network-human comparison and test 14 humans and 76 neural networks on 16-way ImageNet categorization in the presence of narrowband noise. We find that humans recognize objects in natural images using the same one-octave-wide channel that they use for letters and gratings, making it a canonical feature of human object recognition. On the other hand, the neural network channel, across various architectures and training strategies, is 2-4 times as wide as the human channel. In other words, networks are vulnerable to high and low frequency noise that does not affect human performance. Adversarial and augmented-image training are commonly used to increase network robustness and shape bias. Does this training align network and human object recognition channels? Three network channel properties (bandwidth, center frequency, peak noise sensitivity) correlate strongly with shape bias (53% variance explained) and with robustness of adversarially-trained networks (74% variance explained). Adversarial training increases robustness but expands the channel bandwidth even further away from the human bandwidth. Thus, critical band masking reveals that the network channel is more than twice as wide as the human channel, and that adversarial training only increases this difference. ",
    "url": "https://arxiv.org/abs/2309.13190",
    "authors": [
      "Ajay Subramanian",
      "Elena Sizikova",
      "Najib J. Majaj",
      "Denis G. Pelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.13194",
    "title": "Federated Short-Term Load Forecasting with Personalization Layers for  Heterogeneous Clients",
    "abstract": "The advent of smart meters has enabled pervasive collection of energy consumption data for training short-term load forecasting (STLF) models. In response to privacy concerns, federated learning (FL) has been proposed as a privacy-preserving approach for training, but the quality of trained models degrades as client data becomes heterogeneous. In this paper we alleviate this drawback using personalization layers, wherein certain layers of an STLF model in an FL framework are trained exclusively on the clients' own data. To that end, we propose a personalized FL algorithm (PL-FL) enabling FL to handle personalization layers. The PL-FL algorithm is implemented by using the Argonne Privacy-Preserving Federated Learning package. We test the forecast performance of models trained on the NREL ComStock dataset, which contains heterogeneous energy consumption data of multiple commercial buildings. Superior performance of models trained with PL-FL demonstrates that personalization layers enable classical FL algorithms to handle clients with heterogeneous data. ",
    "url": "https://arxiv.org/abs/2309.13194",
    "authors": [
      "Shourya Bose",
      "Kibaek Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13220",
    "title": "Poster: Self-Supervised Quantization-Aware Knowledge Distillation",
    "abstract": "Quantization-aware training (QAT) starts with a pre-trained full-precision model and performs quantization during retraining. However, existing QAT works require supervision from the labels and they suffer from accuracy loss due to reduced precision. To address these limitations, this paper proposes a novel Self-Supervised Quantization-Aware Knowledge Distillation framework (SQAKD). SQAKD first unifies the forward and backward dynamics of various quantization functions and then reframes QAT as a co-optimization problem that simultaneously minimizes the KL-Loss and the discretization error, in a self-supervised manner. The evaluation shows that SQAKD significantly improves the performance of various state-of-the-art QAT works. SQAKD establishes stronger baselines and does not require extensive labeled training data, potentially making state-of-the-art QAT research more accessible. ",
    "url": "https://arxiv.org/abs/2309.13220",
    "authors": [
      "Kaiqi Zhao",
      "Ming Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13222",
    "title": "Hindi to English: Transformer-Based Neural Machine Translation",
    "abstract": "Machine Translation (MT) is one of the most prominent tasks in Natural Language Processing (NLP) which involves the automatic conversion of texts from one natural language to another while preserving its meaning and fluency. Although the research in machine translation has been going on since multiple decades, the newer approach of integrating deep learning techniques in natural language processing has led to significant improvements in the translation quality. In this paper, we have developed a Neural Machine Translation (NMT) system by training the Transformer model to translate texts from Indian Language Hindi to English. Hindi being a low resource language has made it difficult for neural networks to understand the language thereby leading to a slow growth in the development of neural machine translators. Thus, to address this gap, we implemented back-translation to augment the training data and for creating the vocabulary, we experimented with both word and subword level tokenization using Byte Pair Encoding (BPE) thereby ending up training the Transformer in 10 different configurations. This led us to achieve a state-of-the-art BLEU score of 24.53 on the test set of IIT Bombay English-Hindi Corpus in one of the configurations. ",
    "url": "https://arxiv.org/abs/2309.13222",
    "authors": [
      "Kavit Gangar",
      "Hardik Ruparel",
      "Shreyas Lele"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13223",
    "title": "Causal Reasoning: Charting a Revolutionary Course for Next-Generation  AI-Native Wireless Networks",
    "abstract": "Despite the basic premise that next-generation wireless networks (e.g., 6G) will be artificial intelligence (AI)-native, to date, most existing efforts remain either qualitative or incremental extensions to existing ``AI for wireless'' paradigms. Indeed, creating AI-native wireless networks faces significant technical challenges due to the limitations of data-driven, training-intensive AI. These limitations include the black-box nature of the AI models, their curve-fitting nature, which can limit their ability to reason and adapt, their reliance on large amounts of training data, and the energy inefficiency of large neural networks. In response to these limitations, this article presents a comprehensive, forward-looking vision that addresses these shortcomings by introducing a novel framework for building AI-native wireless networks; grounded in the emerging field of causal reasoning. Causal reasoning, founded on causal discovery, causal representation learning, and causal inference, can help build explainable, reasoning-aware, and sustainable wireless networks. Towards fulfilling this vision, we first highlight several wireless networking challenges that can be addressed by causal discovery and representation, including ultra-reliable beamforming for terahertz (THz) systems, near-accurate physical twin modeling for digital twins, training data augmentation, and semantic communication. We showcase how incorporating causal discovery can assist in achieving dynamic adaptability, resilience, and cognition in addressing these challenges. Furthermore, we outline potential frameworks that leverage causal inference to achieve the overarching objectives of future-generation networks, including intent management, dynamic adaptability, human-level cognition, reasoning, and the critical element of time sensitivity. ",
    "url": "https://arxiv.org/abs/2309.13223",
    "authors": [
      "Christo Kurisummoottil Thomas",
      "Christina Chaccour",
      "Walid Saad",
      "Merouane Debbah",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13226",
    "title": "Real3D-AD: A Dataset of Point Cloud Anomaly Detection",
    "abstract": "High-precision point cloud anomaly detection is the gold standard for identifying the defects of advancing machining and precision manufacturing. Despite some methodological advances in this area, the scarcity of datasets and the lack of a systematic benchmark hinder its development. We introduce Real3D-AD, a challenging high-precision point cloud anomaly detection dataset, addressing the limitations in the field. With 1,254 high-resolution 3D items (\\xgy{from forty thousand to millions of points for each item}), Real3D-AD is the largest dataset for high-precision 3D industrial anomaly detection to date. Real3D-AD surpasses existing 3D anomaly detection datasets available regarding point cloud resolution (0.0010mm-0.0015mm), $360^{\\circ}$ degree coverage and perfect prototype. Additionally, we present a comprehensive benchmark for Real3D-AD, revealing the absence of baseline methods for high-precision point cloud anomaly detection. To address this, we propose Reg3D-AD, a registration-based 3D anomaly detection method incorporating a novel feature memory bank that preserves local and global representations. Extensive experiments on the Real3D-AD dataset highlight the effectiveness of Reg3D-AD. For reproducibility and accessibility, we provide the Real3D-AD dataset, benchmark source code, and Reg3D-AD on our website:https://github.com/M-3LAB/Real3D-AD. ",
    "url": "https://arxiv.org/abs/2309.13226",
    "authors": [
      "Jiaqi Liu",
      "Guoyang Xie",
      "Ruitao Chen",
      "Xinpeng Li",
      "Jinbao Wang",
      "Yong Liu",
      "Chengjie Wang",
      "Feng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13229",
    "title": "Heterogeneous Feature Representation for Digital Twin-Oriented Complex  Networked Systems",
    "abstract": "Building models of Complex Networked Systems (CNS) that can accurately represent reality forms an important research area. To be able to reflect real world systems, the modelling needs to consider not only the intensity of interactions between the entities but also features of all the elements of the system. This study aims to improve the expressive power of node features in Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with heterogeneous feature representation principles. This involves representing features with crisp feature values and fuzzy sets, each describing the objective and the subjective inductions of the nodes' features and feature differences. Our empirical analysis builds DT-CNSs to recreate realistic physical contact networks in different countries from real node feature distributions based on various representation principles and an optimised feature preference. We also investigate their respective disaster resilience to an epidemic outbreak starting from the most popular node. The results suggest that the increasing flexibility of feature representation with fuzzy sets improves the expressive power and enables more accurate modelling. In addition, the heterogeneous features influence the network structure and the speed of the epidemic outbreak, requiring various mitigation policies targeted at different people. ",
    "url": "https://arxiv.org/abs/2309.13229",
    "authors": [
      "Jiaqi Wen",
      "Bogdan Gabrys",
      "Katarzyna Musial"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13237",
    "title": "Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph  Generation",
    "abstract": "Video scene graph generation (VidSGG) aims to identify objects in visual scenes and infer their relationships for a given video. It requires not only a comprehensive understanding of each object scattered on the whole scene but also a deep dive into their temporal motions and interactions. Inherently, object pairs and their relationships enjoy spatial co-occurrence correlations within each image and temporal consistency/transition correlations across different images, which can serve as prior knowledge to facilitate VidSGG model learning and inference. In this work, we propose a spatial-temporal knowledge-embedded transformer (STKET) that incorporates the prior spatial-temporal knowledge into the multi-head cross-attention mechanism to learn more representative relationship representations. Specifically, we first learn spatial co-occurrence and temporal transition correlations in a statistical manner. Then, we design spatial and temporal knowledge-embedded layers that introduce the multi-head cross-attention mechanism to fully explore the interaction between visual representation and the knowledge to generate spatial- and temporal-embedded representations, respectively. Finally, we aggregate these representations for each subject-object pair to predict the final semantic labels and their relationships. Extensive experiments show that STKET outperforms current competing algorithms by a large margin, e.g., improving the mR@50 by 8.1%, 4.7%, and 2.1% on different settings over current algorithms. ",
    "url": "https://arxiv.org/abs/2309.13237",
    "authors": [
      "Tao Pu",
      "Tianshui Chen",
      "Hefeng Wu",
      "Yongyi Lu",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13242",
    "title": "UniHead: Unifying Multi-Perception for Detection Heads",
    "abstract": "The detection head constitutes a pivotal component within object detectors, tasked with executing both classification and localization functions. Regrettably, the commonly used parallel head often lacks omni perceptual capabilities, such as deformation perception, global perception and cross-task perception. Despite numerous methods attempt to enhance these abilities from a single aspect, achieving a comprehensive and unified solution remains a significant challenge. In response to this challenge, we have developed an innovative detection head, termed UniHead, to unify three perceptual abilities simultaneously. More precisely, our approach (1) introduces deformation perception, enabling the model to adaptively sample object features; (2) proposes a Dual-axial Aggregation Transformer (DAT) to adeptly model long-range dependencies, thereby achieving global perception; and (3) devises a Cross-task Interaction Transformer (CIT) that facilitates interaction between the classification and localization branches, thus aligning the two tasks. As a plug-and-play method, the proposed UniHead can be conveniently integrated with existing detectors. Extensive experiments on the COCO dataset demonstrate that our UniHead can bring significant improvements to many detectors. For instance, the UniHead can obtain +2.7 AP gains in RetinaNet, +2.9 AP gains in FreeAnchor, and +2.1 AP gains in GFL. The code will be publicly available. Code Url: https://github.com/zht8506/UniHead. ",
    "url": "https://arxiv.org/abs/2309.13242",
    "authors": [
      "Hantao Zhou",
      "Rui Yang",
      "Yachao Zhang",
      "Haoran Duan",
      "Yawen Huang",
      "Runze Hu",
      "Xiu Li",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13245",
    "title": "RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias",
    "abstract": "Recently, there has been a surge of interest and attention in Transformer-based structures, such as Vision Transformer (ViT) and Vision Multilayer Perceptron (VMLP). Compared with the previous convolution-based structures, the Transformer-based structure under investigation showcases a comparable or superior performance under its distinctive attention-based input token mixer strategy. Introducing adversarial examples as a robustness consideration has had a profound and detrimental impact on the performance of well-established convolution-based structures. This inherent vulnerability to adversarial attacks has also been demonstrated in Transformer-based structures. In this paper, our emphasis lies on investigating the intrinsic robustness of the structure rather than introducing novel defense measures against adversarial attacks. To address the susceptibility to robustness issues, we employ a rational structure design approach to mitigate such vulnerabilities. Specifically, we enhance the adversarial robustness of the structure by increasing the proportion of high-frequency structural robust biases. As a result, we introduce a novel structure called Robust Bias Transformer-based Structure (RBFormer) that shows robust superiority compared to several existing baseline structures. Through a series of extensive experiments, RBFormer outperforms the original structures by a significant margin, achieving an impressive improvement of +16.12% and +5.04% across different evaluation criteria on CIFAR-10 and ImageNet-1k, respectively. ",
    "url": "https://arxiv.org/abs/2309.13245",
    "authors": [
      "Hao Cheng",
      "Jinhao Duan",
      "Hui Li",
      "Lyutianyang Zhang",
      "Jiahang Cao",
      "Ping Wang",
      "Jize Zhang",
      "Kaidi Xu",
      "Renjing Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13248",
    "title": "Rethinking Amodal Video Segmentation from Learning Supervised Signals  with Object-centric Representation",
    "abstract": "Video amodal segmentation is a particularly challenging task in computer vision, which requires to deduce the full shape of an object from the visible parts of it. Recently, some studies have achieved promising performance by using motion flow to integrate information across frames under a self-supervised setting. However, motion flow has a clear limitation by the two factors of moving cameras and object deformation. This paper presents a rethinking to previous works. We particularly leverage the supervised signals with object-centric representation in \\textit{real-world scenarios}. The underlying idea is the supervision signal of the specific object and the features from different views can mutually benefit the deduction of the full mask in any specific frame. We thus propose an Efficient object-centric Representation amodal Segmentation (EoRaS). Specially, beyond solely relying on supervision signals, we design a translation module to project image features into the Bird's-Eye View (BEV), which introduces 3D information to improve current feature quality. Furthermore, we propose a multi-view fusion layer based temporal module which is equipped with a set of object slots and interacts with features from different views by attention mechanism to fulfill sufficient object representation completion. As a result, the full mask of the object can be decoded from image features updated by object slots. Extensive experiments on both real-world and synthetic benchmarks demonstrate the superiority of our proposed method, achieving state-of-the-art performance. Our code will be released at \\url{https://github.com/kfan21/EoRaS}. ",
    "url": "https://arxiv.org/abs/2309.13248",
    "authors": [
      "Ke Fan",
      "Jingshi Lei",
      "Xuelin Qian",
      "Miaopeng Yu",
      "Tianjun Xiao",
      "Tong He",
      "Zheng Zhang",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13256",
    "title": "Defending Pre-trained Language Models as Few-shot Learners against  Backdoor Attacks",
    "abstract": "Pre-trained language models (PLMs) have demonstrated remarkable performance as few-shot learners. However, their security risks under such settings are largely unexplored. In this work, we conduct a pilot study showing that PLMs as few-shot learners are highly vulnerable to backdoor attacks while existing defenses are inadequate due to the unique challenges of few-shot scenarios. To address such challenges, we advocate MDP, a novel lightweight, pluggable, and effective defense for PLMs as few-shot learners. Specifically, MDP leverages the gap between the masking-sensitivity of poisoned and clean samples: with reference to the limited few-shot data as distributional anchors, it compares the representations of given samples under varying masking and identifies poisoned samples as ones with significant variations. We show analytically that MDP creates an interesting dilemma for the attacker to choose between attack effectiveness and detection evasiveness. The empirical evaluation using benchmark datasets and representative attacks validates the efficacy of MDP. ",
    "url": "https://arxiv.org/abs/2309.13256",
    "authors": [
      "Zhaohan Xi",
      "Tianyu Du",
      "Changjiang Li",
      "Ren Pang",
      "Shouling Ji",
      "Jinghui Chen",
      "Fenglong Ma",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13264",
    "title": "Randomize to Generalize: Domain Randomization for Runway FOD Detection",
    "abstract": "Tiny Object Detection is challenging due to small size, low resolution, occlusion, background clutter, lighting conditions and small object-to-image ratio. Further, object detection methodologies often make underlying assumption that both training and testing data remain congruent. However, this presumption often leads to decline in performance when model is applied to out-of-domain(unseen) data. Techniques like synthetic image generation are employed to improve model performance by leveraging variations in input data. Such an approach typically presumes access to 3D-rendered datasets. In contrast, we propose a novel two-stage methodology Synthetic Randomized Image Augmentation (SRIA), carefully devised to enhance generalization capabilities of models encountering 2D datasets, particularly with lower resolution which is more practical in real-world scenarios. The first stage employs a weakly supervised technique to generate pixel-level segmentation masks. Subsequently, the second stage generates a batch-wise synthesis of artificial images, carefully designed with an array of diverse augmentations. The efficacy of proposed technique is illustrated on challenging foreign object debris (FOD) detection. We compare our results with several SOTA models including CenterNet, SSD, YOLOv3, YOLOv4, YOLOv5, and Outer Vit on a publicly available FOD-A dataset. We also construct an out-of-distribution test set encompassing 800 annotated images featuring a corpus of ten common categories. Notably, by harnessing merely 1.81% of objects from source training data and amalgamating with 29 runway background images, we generate 2227 synthetic images. Subsequent model retraining via transfer learning, utilizing enriched dataset generated by domain randomization, demonstrates significant improvement in detection accuracy. We report that detection accuracy improved from an initial 41% to 92% for OOD test set. ",
    "url": "https://arxiv.org/abs/2309.13264",
    "authors": [
      "Javaria Farooq",
      "Nayyer Aafaq",
      "M Khizer Ali Khan",
      "Ammar Saleem",
      "M Ibraheem Siddiqui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13266",
    "title": "Robust Navigation with Cross-Modal Fusion and Knowledge Transfer",
    "abstract": "Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying working conditions. ",
    "url": "https://arxiv.org/abs/2309.13266",
    "authors": [
      "Wenzhe Cai",
      "Guangran Cheng",
      "Lingyue Kong",
      "Lu Dong",
      "Changyin Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13289",
    "title": "USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion  Segmentation",
    "abstract": "Unsupervised skin lesion segmentation offers several benefits, including conserving expert human resources, reducing discrepancies due to subjective human labeling, and adapting to novel environments. However, segmenting dermoscopic images without manual labeling guidance presents significant challenges due to dermoscopic image artifacts such as hair noise, blister noise, and subtle edge differences. To address these challenges, we introduce an innovative Uncertainty Self-Learning Network (USL-Net) designed for skin lesion segmentation. The USL-Net can effectively segment a range of lesions, eliminating the need for manual labeling guidance. Initially, features are extracted using contrastive learning, followed by the generation of Class Activation Maps (CAMs) as saliency maps using these features. The different CAM locations correspond to the importance of the lesion region based on their saliency. High-saliency regions in the map serve as pseudo-labels for lesion regions while low-saliency regions represent the background. However, intermediate regions can be hard to classify, often due to their proximity to lesion edges or interference from hair or blisters. Rather than risk potential pseudo-labeling errors or learning confusion by forcefully classifying these regions, we consider them as uncertainty regions, exempting them from pseudo-labeling and allowing the network to self-learn. Further, we employ connectivity detection and centrality detection to refine foreground pseudo-labels and reduce noise-induced errors. The application of cycle refining enhances performance further. Our method underwent thorough experimental validation on the ISIC-2017, ISIC-2018, and PH2 datasets, demonstrating that its performance is on par with weakly supervised and supervised methods, and exceeds that of other existing unsupervised methods. ",
    "url": "https://arxiv.org/abs/2309.13289",
    "authors": [
      "Xiaofan Li",
      "Bo Peng",
      "Daipeng Yang",
      "Zhuyang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13292",
    "title": "Beyond Fairness: Age-Harmless Parkinson's Detection via Voice",
    "abstract": "Parkinson's disease (PD), a neurodegenerative disorder, often manifests as speech and voice dysfunction. While utilizing voice data for PD detection has great potential in clinical applications, the widely used deep learning models currently have fairness issues regarding different ages of onset. These deep models perform well for the elderly group (age $>$ 55) but are less accurate for the young group (age $\\leq$ 55). Through our investigation, the discrepancy between the elderly and the young arises due to 1) an imbalanced dataset and 2) the milder symptoms often seen in early-onset patients. However, traditional debiasing methods are impractical as they typically impair the prediction accuracy for the majority group while minimizing the discrepancy. To address this issue, we present a new debiasing method using GradCAM-based feature masking combined with ensemble models, ensuring that neither fairness nor accuracy is compromised. Specifically, the GradCAM-based feature masking selectively obscures age-related features in the input voice data while preserving essential information for PD detection. The ensemble models further improve the prediction accuracy for the minority (young group). Our approach effectively improves detection accuracy for early-onset patients without sacrificing performance for the elderly group. Additionally, we propose a two-step detection strategy for the young group, offering a practical risk assessment for potential early-onset PD patients. ",
    "url": "https://arxiv.org/abs/2309.13292",
    "authors": [
      "Yicheng Wang",
      "Xiaotian Han",
      "Leisheng Yu",
      "Na Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.13302",
    "title": "Gaining the Sparse Rewards by Exploring Binary Lottery Tickets in  Spiking Neural Network",
    "abstract": "Spiking Neural Network (SNN) as a brain-inspired strategy receives lots of attention because of the high-sparsity and low-power properties derived from its inherent spiking information state. To further improve the efficiency of SNN, some works declare that the Lottery Tickets (LTs) Hypothesis, which indicates that the Artificial Neural Network (ANN) contains a subnetwork without sacrificing the performance of the original network, also exists in SNN. However, the spiking information handled by SNN has a natural similarity and affinity with binarization in sparsification. Therefore, to further explore SNN efficiency, this paper focuses on (1) the presence or absence of LTs in the binary SNN, and (2) whether the spiking mechanism is a superior strategy in terms of handling binary information compared to simple model binarization. To certify these consumptions, a sparse training method is proposed to find Binary Weights Spiking Lottery Tickets (BinW-SLT) under different network structures. Through comprehensive evaluations, we show that BinW-SLT could attain up to +5.86% and +3.17% improvement on CIFAR-10 and CIFAR-100 compared with binary LTs, as well as achieve 1.86x and 8.92x energy saving compared with full-precision SNN and ANN. ",
    "url": "https://arxiv.org/abs/2309.13302",
    "authors": [
      "Hao Cheng",
      "Jiahang Cao",
      "Erjia Xiao",
      "Pu Zhao",
      "Mengshu Sun",
      "Jiaxu Wang",
      "Jize Zhang",
      "Xue Lin",
      "Bhavya Kailkhura",
      "Kaidi Xu",
      "Renjing Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13305",
    "title": "Multilevel User Credibility Assessment in Social Networks",
    "abstract": "Online social networks are one of the largest platforms for disseminating both real and fake news. Many users on these networks, intentionally or unintentionally, spread harmful content, fake news, and rumors in fields such as politics and business. As a result, numerous studies have been conducted in recent years to assess the credibility of users. A shortcoming of most of existing methods is that they assess users by placing them in one of two categories, real or fake. However, in real-world applications it is usually more desirable to consider several levels of user credibility. Another shortcoming is that existing approaches only use a portion of important features, which downgrades their performance. In this paper, due to the lack of an appropriate dataset for multilevel user credibility assessment, first we design a method to collect data suitable to assess credibility at multiple levels. Then, we develop the MultiCred model that places users at one of several levels of credibility, based on a rich and diverse set of features extracted from users' profile, tweets and comments. MultiCred exploits deep language models to analyze textual data and deep neural models to process non-textual features. Our extensive experiments reveal that MultiCred considerably outperforms existing approaches, in terms of several accuracy measures. ",
    "url": "https://arxiv.org/abs/2309.13305",
    "authors": [
      "Mohammad Moradi",
      "Mostafa Haghir Chehreghani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.13306",
    "title": "Tackling the Incomplete Annotation Issue in Universal Lesion Detection  Task By Exploratory Training",
    "abstract": "Universal lesion detection has great value for clinical practice as it aims to detect various types of lesions in multiple organs on medical images. Deep learning methods have shown promising results, but demanding large volumes of annotated data for training. However, annotating medical images is costly and requires specialized knowledge. The diverse forms and contrasts of objects in medical images make fully annotation even more challenging, resulting in incomplete annotations. Directly training ULD detectors on such datasets can yield suboptimal results. Pseudo-label-based methods examine the training data and mine unlabelled objects for retraining, which have shown to be effective to tackle this issue. Presently, top-performing methods rely on a dynamic label-mining mechanism, operating at the mini-batch level. However, the model's performance varies at different iterations, leading to inconsistencies in the quality of the mined labels and limits their performance enhancement. Inspired by the observation that deep models learn concepts with increasing complexity, we introduce an innovative exploratory training to assess the reliability of mined lesions over time. Specifically, we introduce a teacher-student detection model as basis, where the teacher's predictions are combined with incomplete annotations to train the student. Additionally, we design a prediction bank to record high-confidence predictions. Each sample is trained several times, allowing us to get a sequence of records for each sample. If a prediction consistently appears in the record sequence, it is likely to be a true object, otherwise it may just a noise. This serves as a crucial criterion for selecting reliable mined lesions for retraining. Our experimental results substantiate that the proposed framework surpasses state-of-the-art methods on two medical image datasets, demonstrating its superior performance. ",
    "url": "https://arxiv.org/abs/2309.13306",
    "authors": [
      "Xiaoyu Bai",
      "Benteng Ma",
      "Changyang Li",
      "Yong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13343",
    "title": "Two vs. Four-Channel Sound Event Localization and Detection",
    "abstract": "Sound event localization and detection (SELD) systems estimate both the direction-of-arrival (DOA) and class of sound sources over time. In the DCASE 2022 SELD Challenge (Task 3), models are designed to operate in a 4-channel setting. While beneficial to further the development of SELD systems using a multichannel recording setup such as first-order Ambisonics (FOA), most consumer electronics devices rarely are able to record using more than two channels. For this reason, in this work we investigate the performance of the DCASE 2022 SELD baseline model using three audio input representations: FOA, binaural, and stereo. We perform a novel comparative analysis illustrating the effect of these audio input representations on SELD performance. Crucially, we show that binaural and stereo (i.e. 2-channel) audio-based SELD models are still able to localize and detect sound sources laterally quite well, despite overall performance degrading as less audio information is provided. Further, we segment our analysis by scenes containing varying degrees of sound source polyphony to better understand the effect of audio input representation on localization and detection performance as scene conditions become increasingly complex. ",
    "url": "https://arxiv.org/abs/2309.13343",
    "authors": [
      "Julia Wilkins",
      "Magdalena Fuentes",
      "Luca Bondi",
      "Shabnam Ghaffarzadegan",
      "Ali Abavisani",
      "Juan Pablo Bello"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.13349",
    "title": "Speeding-up Evolutionary Algorithms to solve Black-Box Optimization  Problems",
    "abstract": "Population-based evolutionary algorithms are often considered when approaching computationally expensive black-box optimization problems. They employ a selection mechanism to choose the best solutions from a given population after comparing their objective values, which are then used to generate the next population. This iterative process explores the solution space efficiently, leading to improved solutions over time. However, these algorithms require a large number of evaluations to provide a quality solution, which might be computationally expensive when the evaluation cost is high. In some cases, it is possible to replace the original objective function with a less accurate approximation of lower cost. This introduces a trade-off between the evaluation cost and its accuracy. In this paper, we propose a technique capable of choosing an appropriate approximate function cost during the execution of the optimization algorithm. The proposal finds the minimum evaluation cost at which the solutions are still properly ranked, and consequently, more evaluations can be computed in the same amount of time with minimal accuracy loss. An experimental section on four very different problems reveals that the proposed approach can reach the same objective value in less than half of the time in certain cases. ",
    "url": "https://arxiv.org/abs/2309.13349",
    "authors": [
      "Judith Echevarrieta",
      "Etor Arza",
      "Aritz P\u00e9rez"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.13354",
    "title": "Lexical Squad@Multimodal Hate Speech Event Detection 2023: Multimodal  Hate Speech Detection using Fused Ensemble Approach",
    "abstract": "With a surge in the usage of social media postings to express opinions, emotions, and ideologies, there has been a significant shift towards the calibration of social media as a rapid medium of conveying viewpoints and outlooks over the globe. Concurrently, the emergence of a multitude of conflicts between two entities has given rise to a stream of social media content containing propaganda, hate speech, and inconsiderate views. Thus, the issue of monitoring social media postings is rising swiftly, attracting major attention from those willing to solve such problems. One such problem is Hate Speech detection. To mitigate this problem, we present our novel ensemble learning approach for detecting hate speech, by classifying text-embedded images into two labels, namely \"Hate Speech\" and \"No Hate Speech\". We have incorporated state-of-art models including InceptionV3, BERT, and XLNet. Our proposed ensemble model yielded promising results with 75.21 and 74.96 as accuracy and F-1 score (respectively). We also present an empirical evaluation of the text-embedded images to elaborate on how well the model was able to predict and classify. We release our codebase here (https://github.com/M0hammad-Kashif/MultiModalHateSpeech). ",
    "url": "https://arxiv.org/abs/2309.13354",
    "authors": [
      "Mohammad Kashif",
      "Mohammad Zohair",
      "Saquib Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13363",
    "title": "MLPST: MLP is All You Need for Spatio-Temporal Prediction",
    "abstract": "Traffic prediction is a typical spatio-temporal data mining task and has great significance to the public transportation system. Considering the demand for its grand application, we recognize key factors for an ideal spatio-temporal prediction method: efficient, lightweight, and effective. However, the current deep model-based spatio-temporal prediction solutions generally own intricate architectures with cumbersome optimization, which can hardly meet these expectations. To accomplish the above goals, we propose an intuitive and novel framework, MLPST, a pure multi-layer perceptron architecture for traffic prediction. Specifically, we first capture spatial relationships from both local and global receptive fields. Then, temporal dependencies in different intervals are comprehensively considered. Through compact and swift MLP processing, MLPST can well capture the spatial and temporal dependencies while requiring only linear computational complexity, as well as model parameters that are more than an order of magnitude lower than baselines. Extensive experiments validated the superior effectiveness and efficiency of MLPST against advanced baselines, and among models with optimal accuracy, MLPST achieves the best time and space efficiency. ",
    "url": "https://arxiv.org/abs/2309.13363",
    "authors": [
      "Zijian Zhang",
      "Ze Huang",
      "Zhiwei Hu",
      "Xiangyu Zhao",
      "Wanyu Wang",
      "Zitao Liu",
      "Junbo Zhang",
      "S. Joe Qin",
      "Hongwei Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13378",
    "title": "Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and  Treatment",
    "abstract": "Spatio-Temporal Graph (STG) forecasting is a fundamental task in many real-world applications. Spatio-Temporal Graph Neural Networks have emerged as the most popular method for STG forecasting, but they often struggle with temporal out-of-distribution (OoD) issues and dynamic spatial causation. In this paper, we propose a novel framework called CaST to tackle these two challenges via causal treatments. Concretely, leveraging a causal lens, we first build a structural causal model to decipher the data generation process of STGs. To handle the temporal OoD issue, we employ the back-door adjustment by a novel disentanglement block to separate invariant parts and temporal environments from input data. Moreover, we utilize the front-door adjustment and adopt the Hodge-Laplacian operator for edge-level convolution to model the ripple effect of causation. Experiments results on three real-world datasets demonstrate the effectiveness and practicality of CaST, which consistently outperforms existing methods with good interpretability. ",
    "url": "https://arxiv.org/abs/2309.13378",
    "authors": [
      "Yutong Xia",
      "Yuxuan Liang",
      "Haomin Wen",
      "Xu Liu",
      "Kun Wang",
      "Zhengyang Zhou",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13391",
    "title": "D-Separation for Causal Self-Explanation",
    "abstract": "Rationalization is a self-explaining framework for NLP models. Conventional work typically uses the maximum mutual information (MMI) criterion to find the rationale that is most indicative of the target label. However, this criterion can be influenced by spurious features that correlate with the causal rationale or the target label. Instead of attempting to rectify the issues of the MMI criterion, we propose a novel criterion to uncover the causal rationale, termed the Minimum Conditional Dependence (MCD) criterion, which is grounded on our finding that the non-causal features and the target label are \\emph{d-separated} by the causal rationale. By minimizing the dependence between the unselected parts of the input and the target label conditioned on the selected rationale candidate, all the causes of the label are compelled to be selected. In this study, we employ a simple and practical measure of dependence, specifically the KL-divergence, to validate our proposed MCD criterion. Empirically, we demonstrate that MCD improves the F1 score by up to $13.7\\%$ compared to previous state-of-the-art MMI-based methods. Our code is available at: \\url{https://github.com/jugechengzi/Rationalization-MCD}. ",
    "url": "https://arxiv.org/abs/2309.13391",
    "authors": [
      "Wei Liu",
      "Jun Wang",
      "Haozhao Wang",
      "Ruixuan Li",
      "Zhiying Deng",
      "YuanKai Zhang",
      "Yang Qiu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.13402",
    "title": "ML Algorithm Synthesizing Domain Knowledge for Fungal Spores  Concentration Prediction",
    "abstract": "The pulp and paper manufacturing industry requires precise quality control to ensure pure, contaminant-free end products suitable for various applications. Fungal spore concentration is a crucial metric that affects paper usability, and current testing methods are labor-intensive with delayed results, hindering real-time control strategies. To address this, a machine learning algorithm utilizing time-series data and domain knowledge was proposed. The optimal model employed Ridge Regression achieving an MSE of 2.90 on training and validation data. This approach could lead to significant improvements in efficiency and sustainability by providing real-time predictions for fungal spore concentrations. This paper showcases a promising method for real-time fungal spore concentration prediction, enabling stringent quality control measures in the pulp-and-paper industry. ",
    "url": "https://arxiv.org/abs/2309.13402",
    "authors": [
      "Md Asif Bin Syed",
      "Azmine Toushik Wasi",
      "Imtiaz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13410",
    "title": "Tropical neural networks and its applications to classifying  phylogenetic trees",
    "abstract": "Deep neural networks show great success when input vectors are in an Euclidean space. However, those classical neural networks show a poor performance when inputs are phylogenetic trees, which can be written as vectors in the tropical projective torus. Here we propose tropical embedding to transform a vector in the tropical projective torus to a vector in the Euclidean space via the tropical metric. We introduce a tropical neural network where the first layer is a tropical embedding layer and the following layers are the same as the classical ones. We prove that this neural network with the tropical metric is a universal approximator and we derive a backpropagation rule for deep neural networks. Then we provide TensorFlow 2 codes for implementing a tropical neural network in the same fashion as the classical one, where the weights initialization problem is considered according to the extreme value statistics. We apply our method to empirical data including sequences of hemagglutinin for influenza virus from New York. Finally we show that a tropical neural network can be interpreted as a generalization of a tropical logistic regression. ",
    "url": "https://arxiv.org/abs/2309.13410",
    "authors": [
      "Ruriko Yoshida",
      "Georgios Aliatimis",
      "Keiji Miura"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2309.13439",
    "title": "Finding Order in Chaos: A Novel Data Augmentation Method for Time Series  in Contrastive Learning",
    "abstract": "The success of contrastive learning is well known to be dependent on data augmentation. Although the degree of data augmentations has been well controlled by utilizing pre-defined techniques in some domains like vision, time-series data augmentation is less explored and remains a challenging problem due to the complexity of the data generation mechanism, such as the intricate mechanism involved in the cardiovascular system. Moreover, there is no widely recognized and general time-series augmentation method that can be applied across different tasks. In this paper, we propose a novel data augmentation method for quasi-periodic time-series tasks that aims to connect intra-class samples together, and thereby find order in the latent space. Our method builds upon the well-known mixup technique by incorporating a novel approach that accounts for the periodic nature of non-stationary time-series. Also, by controlling the degree of chaos created by data augmentation, our method leads to improved feature representations and performance on downstream tasks. We evaluate our proposed method on three time-series tasks, including heart rate estimation, human activity recognition, and cardiovascular disease detection. Extensive experiments against state-of-the-art methods show that the proposed approach outperforms prior works on optimal data generation and known data augmentation techniques in the three tasks, reflecting the effectiveness of the presented method. Source code: https://github.com/eth-siplab/Finding_Order_in_Chaos ",
    "url": "https://arxiv.org/abs/2309.13439",
    "authors": [
      "Berken Utku Demirel",
      "Christian Holz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.13443",
    "title": "Early Classification for Dynamic Inference of Neural Networks",
    "abstract": "Deep neural networks (DNNs) have been successfully applied in various fields. In DNNs, a large number of multiply-accumulate (MAC) operations is required to be performed, posing critical challenges in applying them in resource-constrained platforms, e.g., edge devices. Dynamic neural networks have been introduced to allow a structural adaption, e.g., early-exit, according to different inputs to reduce the computational cost of DNNs. Existing early-exit techniques deploy classifiers at intermediate layers of DNNs to push them to make a classification decision as early as possible. However, the learned features at early layers might not be sufficient to exclude all the irrelevant classes and decide the correct class, leading to suboptimal results. To address this challenge, in this paper, we propose a class-based early-exit for dynamic inference. Instead of pushing DNNs to make a dynamic decision at intermediate layers, we take advantages of the learned features in these layers to exclude as many irrelevant classes as possible, so that later layers only have to determine the target class among the remaining classes. Until at a layer only one class remains, this class is the corresponding classification result. To realize this class-based exclusion, we assign each class with a classifier at intermediate layers and train the networks together with these classifiers. Afterwards, an exclusion strategy is developed to exclude irrelevant classes at early layers. Experimental results demonstrate the computational cost of DNNs in inference can be reduced significantly. ",
    "url": "https://arxiv.org/abs/2309.13443",
    "authors": [
      "Jingcun Wang",
      "Bing Li",
      "Grace Li Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13444",
    "title": "Moving Target Defense based Secured Network Slicing System in the O-RAN  Architecture",
    "abstract": "The open radio access network (O-RAN) architecture's native virtualization and embedded intelligence facilitate RAN slicing and enable comprehensive end-to-end services in post-5G networks. However, any vulnerabilities could harm security. Therefore, artificial intelligence (AI) and machine learning (ML) security threats can even threaten O-RAN benefits. This paper proposes a novel approach to estimating the optimal number of predefined VNFs for each slice while addressing secure AI/ML methods for dynamic service admission control and power minimization in the O-RAN architecture. We solve this problem on two-time scales using mathematical methods for determining the predefined number of VNFs on a large time scale and the proximal policy optimization (PPO), a Deep Reinforcement Learning algorithm, for solving dynamic service admission control and power minimization for different slices on a small-time scale. To secure the ML system for O-RAN, we implement a moving target defense (MTD) strategy to prevent poisoning attacks by adding uncertainty to the system. Our experimental results show that the proposed PPO-based service admission control approach achieves an admission rate above 80\\% and that the MTD strategy effectively strengthens the robustness of the PPO method against adversarial attacks. ",
    "url": "https://arxiv.org/abs/2309.13444",
    "authors": [
      "Mojdeh Karbalaee Motalleb",
      "Chafika Benza\u00efd",
      "Tarik Taleb",
      "Vahid Shah-Mansouri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.13452",
    "title": "Monotonic Neural Ordinary Differential Equation: Time-series Forecasting  for Cumulative Data",
    "abstract": "Time-Series Forecasting based on Cumulative Data (TSFCD) is a crucial problem in decision-making across various industrial scenarios. However, existing time-series forecasting methods often overlook two important characteristics of cumulative data, namely monotonicity and irregularity, which limit their practical applicability. To address this limitation, we propose a principled approach called Monotonic neural Ordinary Differential Equation (MODE) within the framework of neural ordinary differential equations. By leveraging MODE, we are able to effectively capture and represent the monotonicity and irregularity in practical cumulative data. Through extensive experiments conducted in a bonus allocation scenario, we demonstrate that MODE outperforms state-of-the-art methods, showcasing its ability to handle both monotonicity and irregularity in cumulative data and delivering superior forecasting performance. ",
    "url": "https://arxiv.org/abs/2309.13452",
    "authors": [
      "Zhichao Chen",
      "Leilei Ding",
      "Zhixuan Chu",
      "Yucheng Qi",
      "Jianmin Huang",
      "Hao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13466",
    "title": "Targeted Learning: A Hybrid Approach to Social Robot Navigation",
    "abstract": "Empowering robots to navigate in a socially compliant manner is essential for the acceptance of robots moving in human-inhabited environments. Previously, roboticists have developed classical navigation systems with decades of empirical validation to achieve safety and efficiency. However, the many complex factors of social compliance make classical navigation systems hard to adapt to social situations, where no amount of tuning enables them to be both safe (people are too unpredictable) and efficient (the frozen robot problem). With recent advances in deep learning approaches, the common reaction has been to entirely discard classical navigation systems and start from scratch, building a completely new learning-based social navigation planner. In this work, we find that this reaction is unnecessarily extreme: using a large-scale real-world social navigation dataset, SCAND, we find that classical systems can be used safely and efficiently in a large number of social situations (up to 80%). We therefore ask if we can rethink this problem by leveraging the advantages of both classical and learning-based approaches. We propose a hybrid strategy in which we learn to switch between a classical geometric planner and a data-driven method. Our experiments on both SCAND and two physical robots show that the hybrid planner can achieve better social compliance in terms of a variety of metrics, compared to using either the classical or learning-based approach alone. ",
    "url": "https://arxiv.org/abs/2309.13466",
    "authors": [
      "Amir Hossain Raj",
      "Zichao Hu",
      "Haresh Karnan",
      "Rohan Chandra",
      "Amirreza Payandeh",
      "Luisa Mao",
      "Peter Stone",
      "Joydeep Biswas",
      "Xuesu Xiao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.13471",
    "title": "Cloud Watching: Understanding Attacks Against Cloud-Hosted Services",
    "abstract": "Cloud computing has dramatically changed service deployment patterns. In this work, we analyze how attackers identify and target cloud services in contrast to traditional enterprise networks and network telescopes. Using a diverse set of cloud honeypots in 5~providers and 23~countries as well as 2~educational networks and 1~network telescope, we analyze how IP address assignment, geography, network, and service-port selection, influence what services are targeted in the cloud. We find that scanners that target cloud compute are selective: they avoid scanning networks without legitimate services and they discriminate between geographic regions. Further, attackers mine Internet-service search engines to find exploitable services and, in some cases, they avoid targeting IANA-assigned protocols, causing researchers to misclassify at least 15\\% of traffic on select ports. Based on our results, we derive recommendations for researchers and operators. ",
    "url": "https://arxiv.org/abs/2309.13471",
    "authors": [
      "Liz Izhikevich",
      "Manda Tran",
      "Michalis Kallitsis",
      "Aurore Fass",
      "Zakir Durumeric"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.13476",
    "title": "Hierarchical attention interpretation: an interpretable speech-level  transformer for bi-modal depression detection",
    "abstract": "Depression is a common mental disorder. Automatic depression detection tools using speech, enabled by machine learning, help early screening of depression. This paper addresses two limitations that may hinder the clinical implementations of such tools: noise resulting from segment-level labelling and a lack of model interpretability. We propose a bi-modal speech-level transformer to avoid segment-level labelling and introduce a hierarchical interpretation approach to provide both speech-level and sentence-level interpretations, based on gradient-weighted attention maps derived from all attention layers to track interactions between input features. We show that the proposed model outperforms a model that learns at a segment level ($p$=0.854, $r$=0.947, $F1$=0.947 compared to $p$=0.732, $r$=0.808, $F1$=0.768). For model interpretation, using one true positive sample, we show which sentences within a given speech are most relevant to depression detection; and which text tokens and Mel-spectrogram regions within these sentences are most relevant to depression detection. These interpretations allow clinicians to verify the validity of predictions made by depression detection tools, promoting their clinical implementations. ",
    "url": "https://arxiv.org/abs/2309.13476",
    "authors": [
      "Qingkun Deng",
      "Saturnino Luz",
      "Sofia de la Fuente Garcia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.13485",
    "title": "Interpretable and Flexible Target-Conditioned Neural Planners For  Autonomous Vehicles",
    "abstract": "Learning-based approaches to autonomous vehicle planners have the potential to scale to many complicated real-world driving scenarios by leveraging huge amounts of driver demonstrations. However, prior work only learns to estimate a single planning trajectory, while there may be multiple acceptable plans in real-world scenarios. To solve the problem, we propose an interpretable neural planner to regress a heatmap, which effectively represents multiple potential goals in the bird's-eye view of an autonomous vehicle. The planner employs an adaptive Gaussian kernel and relaxed hourglass loss to better capture the uncertainty of planning problems. We also use a negative Gaussian kernel to add supervision to the heatmap regression, enabling the model to learn collision avoidance effectively. Our systematic evaluation on the Lyft Open Dataset across a diverse range of real-world driving scenarios shows that our model achieves a safer and more flexible driving performance than prior works. ",
    "url": "https://arxiv.org/abs/2309.13485",
    "authors": [
      "Haolan Liu",
      "Jishen Zhao",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13492",
    "title": "Portrait Stylization: Artistic Style Transfer with Auxiliary Networks  for Human Face Stylization",
    "abstract": "Today's image style transfer methods have difficulty retaining humans face individual features after the whole stylizing process. This occurs because the features like face geometry and people's expressions are not captured by the general-purpose image classifiers like the VGG-19 pre-trained models. This paper proposes the use of embeddings from an auxiliary pre-trained face recognition model to encourage the algorithm to propagate human face features from the content image to the final stylized result. ",
    "url": "https://arxiv.org/abs/2309.13492",
    "authors": [
      "Thiago Ambiel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13500",
    "title": "Enhancing Student Performance Prediction on Learnersourced Questions  with SGNN-LLM Synergy",
    "abstract": "As an emerging education strategy, learnersourcing offers the potential for personalized learning content creation, but also grapples with the challenge of predicting student performance due to inherent noise in student-generated data. While graph-based methods excel in capturing dense learner-question interactions, they falter in cold start scenarios, characterized by limited interactions, as seen when questions lack substantial learner responses. In response, we introduce an innovative strategy that synergizes the potential of integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology employs a signed bipartite graph to comprehensively model student answers, complemented by a contrastive learning framework that enhances noise resilience. Furthermore, LLM's contribution lies in generating foundational question embeddings, proving especially advantageous in addressing cold start scenarios characterized by limited graph data interactions. Validation across five real-world datasets sourced from the PeerWise platform underscores our approach's effectiveness. Our method outperforms baselines, showcasing enhanced predictive accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2309.13500",
    "authors": [
      "Lin Ni",
      "Sijie Wang",
      "Zeyu Zhang",
      "Xiaoxuan Li",
      "Xianda Zheng",
      "Paul Denny",
      "Jiamou Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13506",
    "title": "Evaluating the Usability of Differential Privacy Tools with Data  Practitioners",
    "abstract": "Differential privacy (DP) has become the gold standard in privacy-preserving data analytics, but implementing it in real-world datasets and systems remains challenging. Recently developed DP tools aim to ease data practitioners' burden in implementing DP solutions, but limited research has investigated these DP tools' usability. Through a usability study with 24 US data practitioners with varying prior DP knowledge, we comprehensively evaluate the usability of four Python-based open-source DP tools: DiffPrivLib, Tumult Analytics, PipelineDP, and OpenDP. Our results suggest that DP tools can help novices learn DP concepts; that Application Programming Interface (API) design and documentation are vital for learnability and error prevention; and that user satisfaction highly correlates with the effectiveness of the tool. We discuss the balance between ease of use and the learning curve needed to appropriately implement DP and also provide recommendations to improve DP tools' usability to broaden adoption. ",
    "url": "https://arxiv.org/abs/2309.13506",
    "authors": [
      "Ivoline C. Ngong",
      "Brad Stenger",
      "Joseph P. Near",
      "Yuanyuan Feng"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.13525",
    "title": "Semi-Supervised Domain Generalization for Object Detection via  Language-Guided Feature Alignment",
    "abstract": "Existing domain adaptation (DA) and generalization (DG) methods in object detection enforce feature alignment in the visual space but face challenges like object appearance variability and scene complexity, which make it difficult to distinguish between objects and achieve accurate detection. In this paper, we are the first to address the problem of semi-supervised domain generalization by exploring vision-language pre-training and enforcing feature alignment through the language space. We employ a novel Cross-Domain Descriptive Multi-Scale Learning (CDDMSL) aiming to maximize the agreement between descriptions of an image presented with different domain-specific characteristics in the embedding space. CDDMSL significantly outperforms existing methods, achieving 11.7% and 7.5% improvement in DG and DA settings, respectively. Comprehensive analysis and ablation studies confirm the effectiveness of our method, positioning CDDMSL as a promising approach for domain generalization in object detection tasks. ",
    "url": "https://arxiv.org/abs/2309.13525",
    "authors": [
      "Sina Malakouti",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13532",
    "title": "Anisotropic body compliance facilitates robotic sidewinding in complex  environments",
    "abstract": "Sidewinding, a locomotion strategy characterized by the coordination of lateral and vertical body undulations, is frequently observed in rattlesnakes and has been successfully reconstructed by limbless robotic systems for effective movement across diverse terrestrial terrains. However, the integration of compliant mechanisms into sidewinding limbless robots remains less explored, posing challenges for navigation in complex, rheologically diverse environments. Inspired by a notable control simplification via mechanical intelligence in lateral undulation, which offloads feedback control to passive body mechanics and interactions with the environment, we present an innovative design of a mechanically intelligent limbless robot for sidewinding. This robot features a decentralized bilateral cable actuation system that resembles organismal muscle actuation mechanisms. We develop a feedforward controller that incorporates programmable body compliance into the sidewinding gait template. Our experimental results highlight the emergence of mechanical intelligence when the robot is equipped with an appropriate level of body compliance. This allows the robot to 1) locomote more energetically efficiently, as evidenced by a reduced cost of transport, and 2) navigate through terrain heterogeneities, all achieved in an open-loop manner, without the need for environmental awareness. ",
    "url": "https://arxiv.org/abs/2309.13532",
    "authors": [
      "Velin Kojouharov",
      "Tianyu Wang",
      "Matthew Fernandez",
      "Jiyeon Maeng",
      "Daniel I. Goldman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.13546",
    "title": "DFRD: Data-Free Robustness Distillation for Heterogeneous Federated  Learning",
    "abstract": "Federated Learning (FL) is a privacy-constrained decentralized machine learning paradigm in which clients enable collaborative training without compromising private data. However, how to learn a robust global model in the data-heterogeneous and model-heterogeneous FL scenarios is challenging. To address it, we resort to data-free knowledge distillation to propose a new FL method (namely DFRD). DFRD equips a conditional generator on the server to approximate the training space of the local models uploaded by clients, and systematically investigates its training in terms of fidelity, transferability} and diversity. To overcome the catastrophic forgetting of the global model caused by the distribution shifts of the generator across communication rounds, we maintain an exponential moving average copy of the generator on the server. Additionally, we propose dynamic weighting and label sampling to accurately extract knowledge from local models. Finally, our extensive experiments on various image classification tasks illustrate that DFRD achieves significant performance gains compared to SOTA baselines. ",
    "url": "https://arxiv.org/abs/2309.13546",
    "authors": [
      "Kangyang Luo",
      "Shuai Wang",
      "Yexuan Fu",
      "Xiang Li",
      "Yunshi Lan",
      "Ming Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13549",
    "title": "Towards Robust Robot 3D Perception in Urban Environments: The UT Campus  Object Dataset",
    "abstract": "We introduce the UT Campus Object Dataset (CODa), a mobile robot egocentric perception dataset collected on the University of Texas Austin Campus. Our dataset contains 8.5 hours of multimodal sensor data: synchronized 3D point clouds and stereo RGB video from a 128-channel 3D LiDAR and two 1.25MP RGB cameras at 10 fps; RGB-D videos from an additional 0.5MP sensor at 7 fps, and a 9-DOF IMU sensor at 40 Hz. We provide 58 minutes of ground-truth annotations containing 1.3 million 3D bounding boxes with instance IDs for 53 semantic classes, 5000 frames of 3D semantic annotations for urban terrain, and pseudo-ground truth localization. We repeatedly traverse identical geographic locations for a wide range of indoor and outdoor areas, weather conditions, and times of the day. Using CODa, we empirically demonstrate that: 1) 3D object detection performance in urban settings is significantly higher when trained using CODa compared to existing datasets even when employing state-of-the-art domain adaptation approaches, 2) sensor-specific fine-tuning improves 3D object detection accuracy and 3) pretraining on CODa improves cross-dataset 3D object detection performance in urban settings compared to pretraining on AV datasets. Using our dataset and annotations, we release benchmarks for 3D object detection and 3D semantic segmentation using established metrics. In the future, the CODa benchmark will include additional tasks like unsupervised object discovery and re-identification. We publicly release CODa on the Texas Data Repository, pre-trained models, dataset development package, and interactive dataset viewer. We expect CODa to be a valuable dataset for research in egocentric 3D perception and planning for autonomous navigation in urban environments. ",
    "url": "https://arxiv.org/abs/2309.13549",
    "authors": [
      "Arthur Zhang",
      "Chaitanya Eranki",
      "Christina Zhang",
      "Ji-Hwan Park",
      "Raymond Hong",
      "Pranav Kalyani",
      "Lochana Kalyanaraman",
      "Arsh Gamare",
      "Arnav Bagad",
      "Maria Esteva",
      "Joydeep Biswas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13556",
    "title": "LOGICSEG: Parsing Visual Semantics with Neural Logic Learning and  Reasoning",
    "abstract": "Current high-performance semantic segmentation models are purely data-driven sub-symbolic approaches and blind to the structured nature of the visual world. This is in stark contrast to human cognition which abstracts visual perceptions at multiple levels and conducts symbolic reasoning with such structured abstraction. To fill these fundamental gaps, we devise LOGICSEG, a holistic visual semantic parser that integrates neural inductive learning and logic reasoning with both rich data and symbolic knowledge. In particular, the semantic concepts of interest are structured as a hierarchy, from which a set of constraints are derived for describing the symbolic relations and formalized as first-order logic rules. After fuzzy logic-based continuous relaxation, logical formulae are grounded onto data and neural computational graphs, hence enabling logic-induced network training. During inference, logical constraints are packaged into an iterative process and injected into the network in a form of several matrix multiplications, so as to achieve hierarchy-coherent prediction with logic reasoning. These designs together make LOGICSEG a general and compact neural-logic machine that is readily integrated into existing segmentation models. Extensive experiments over four datasets with various segmentation models and backbones verify the effectiveness and generality of LOGICSEG. We believe this study opens a new avenue for visual semantic parsing. ",
    "url": "https://arxiv.org/abs/2309.13556",
    "authors": [
      "Liulei Li",
      "Wenguan Wang",
      "Yang Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13563",
    "title": "Multivariate Prototype Representation for Domain-Generalized Incremental  Learning",
    "abstract": "Deep learning models suffer from catastrophic forgetting when being fine-tuned with samples of new classes. This issue becomes even more pronounced when faced with the domain shift between training and testing data. In this paper, we study the critical and less explored Domain-Generalized Class-Incremental Learning (DGCIL). We design a DGCIL approach that remembers old classes, adapts to new classes, and can classify reliably objects from unseen domains. Specifically, our loss formulation maintains classification boundaries and suppresses the domain-specific information of each class. With no old exemplars stored, we use knowledge distillation and estimate old class prototype drift as incremental training advances. Our prototype representations are based on multivariate Normal distributions whose means and covariances are constantly adapted to changing model features to represent old classes well by adapting to the feature space drift. For old classes, we sample pseudo-features from the adapted Normal distributions with the help of Cholesky decomposition. In contrast to previous pseudo-feature sampling strategies that rely solely on average mean prototypes, our method excels at capturing varying semantic information. Experiments on several benchmarks validate our claims. ",
    "url": "https://arxiv.org/abs/2309.13563",
    "authors": [
      "Can Peng",
      "Piotr Koniusz",
      "Kaiyu Guo",
      "Brian C. Lovell",
      "Peyman Moghadam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13567",
    "title": "MentalLLaMA: Interpretable Mental Health Analysis on Social Media with  Large Language Models",
    "abstract": "With the development of web technology, social media texts are becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear the problem of low interpretability, the recent large language models have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions. The results show that ChatGPT can generate approaching-human explanations for its correct classifications. However, LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner. Domain-specific finetuning is an effective solution, but faces 2 challenges: 1) lack of high-quality training data. 2) no open-source LLMs for interpretable mental health analysis were released to lower the finetuning cost. To alleviate these problems, we build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset on social media, with 105K data samples. The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We use expert-written few-shot prompts and collected labels to prompt ChatGPT and obtain explanations from its responses. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA, the first open-source LLM series for interpretable mental health analysis with instruction-following capability. We also evaluate the performance of MentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their correctness for making predictions and the quality of explanations are examined. The results show that MentalLLaMA approaches state-of-the-art discriminative methods in correctness and generates high-quality explanations. ",
    "url": "https://arxiv.org/abs/2309.13567",
    "authors": [
      "Kailai Yang",
      "Tianlin Zhang",
      "Ziyan Kuang",
      "Qianqian Xie",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.13575",
    "title": "Probabilistic Weight Fixing: Large-scale training of neural network  weight uncertainties for quantization",
    "abstract": "Weight-sharing quantization has emerged as a technique to reduce energy expenditure during inference in large neural networks by constraining their weights to a limited set of values. However, existing methods for weight-sharing quantization often make assumptions about the treatment of weights based on value alone that neglect the unique role weight position plays. This paper proposes a probabilistic framework based on Bayesian neural networks (BNNs) and a variational relaxation to identify which weights can be moved to which cluster centre and to what degree based on their individual position-specific learned uncertainty distributions. We introduce a new initialisation setting and a regularisation term which allow for the training of BNNs under complex dataset-model combinations. By leveraging the flexibility of weight values captured through a probability distribution, we enhance noise resilience and downstream compressibility. Our iterative clustering procedure demonstrates superior compressibility and higher accuracy compared to state-of-the-art methods on both ResNet models and the more complex transformer-based architectures. In particular, our method outperforms the state-of-the-art quantization method top-1 accuracy by 1.6% on ImageNet using DeiT-Tiny, with its 5 million+ weights now represented by only 296 unique values. ",
    "url": "https://arxiv.org/abs/2309.13575",
    "authors": [
      "Christopher Subia-Waud",
      "Srinandan Dasmahapatra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13579",
    "title": "Seeing Is Not Always Believing: Invisible Collision Attack and Defence  on Pre-Trained Models",
    "abstract": "Large-scale pre-trained models (PTMs) such as BERT and GPT have achieved great success in diverse fields. The typical paradigm is to pre-train a big deep learning model on large-scale data sets, and then fine-tune the model on small task-specific data sets for downstream tasks. Although PTMs have rapidly progressed with wide real-world applications, they also pose significant risks of potential attacks. Existing backdoor attacks or data poisoning methods often build up the assumption that the attacker invades the computers of victims or accesses the target data, which is challenging in real-world scenarios. In this paper, we propose a novel framework for an invisible attack on PTMs with enhanced MD5 collision. The key idea is to generate two equal-size models with the same MD5 checksum by leveraging the MD5 chosen-prefix collision. Afterwards, the two ``same\" models will be deployed on public websites to induce victims to download the poisoned model. Unlike conventional attacks on deep learning models, this new attack is flexible, covert, and model-independent. Additionally, we propose a simple defensive strategy for recognizing the MD5 chosen-prefix collision and provide a theoretical justification for its feasibility. We extensively validate the effectiveness and stealthiness of our proposed attack and defensive method on different models and data sets. ",
    "url": "https://arxiv.org/abs/2309.13579",
    "authors": [
      "Minghang Deng",
      "Zhong Zhang",
      "Junming Shao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13591",
    "title": "Robust Distributed Learning: Tight Error Bounds and Breakdown Point  under Data Heterogeneity",
    "abstract": "The theory underlying robust distributed learning algorithms, designed to resist adversarial machines, matches empirical observations when data is homogeneous. Under data heterogeneity however, which is the norm in practical scenarios, established lower bounds on the learning error are essentially vacuous and greatly mismatch empirical observations. This is because the heterogeneity model considered is too restrictive and does not cover basic learning tasks such as least-squares regression. We consider in this paper a more realistic heterogeneity model, namely (G,B)-gradient dissimilarity, and show that it covers a larger class of learning problems than existing theory. Notably, we show that the breakdown point under heterogeneity is lower than the classical fraction 1/2. We also prove a new lower bound on the learning error of any distributed learning algorithm. We derive a matching upper bound for a robust variant of distributed gradient descent, and empirically show that our analysis reduces the gap between theory and practice. ",
    "url": "https://arxiv.org/abs/2309.13591",
    "authors": [
      "Youssef Allouah",
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "Rafa\u00ebl Pinot",
      "Geovani Rizk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.13596",
    "title": "Advancements in 3D Lane Detection Using LiDAR Point Clouds: From Data  Collection to Model Development",
    "abstract": "Advanced Driver-Assistance Systems (ADAS) have successfully integrated learning-based techniques into vehicle perception and decision-making. However, their application in 3D lane detection for effective driving environment perception is hindered by the lack of comprehensive LiDAR datasets. The sparse nature of LiDAR point cloud data prevents an efficient manual annotation process. To solve this problem, we present LiSV-3DLane, a large-scale 3D lane dataset that comprises 20k frames of surround-view LiDAR point clouds with enriched semantic annotation. Unlike existing datasets confined to a frontal perspective, LiSV-3DLane provides a full 360-degree spatial panorama around the ego vehicle, capturing complex lane patterns in both urban and highway environments. We leverage the geometric traits of lane lines and the intrinsic spatial attributes of LiDAR data to design a simple yet effective automatic annotation pipeline for generating finer lane labels. To propel future research, we propose a novel LiDAR-based 3D lane detection model, LiLaDet, incorporating the spatial geometry learning of the LiDAR point cloud into Bird's Eye View (BEV) based lane identification. Experimental results indicate that LiLaDet outperforms existing camera- and LiDAR-based approaches in the 3D lane detection task on the K-Lane dataset and our LiSV-3DLane. ",
    "url": "https://arxiv.org/abs/2309.13596",
    "authors": [
      "Runkai Zhao",
      "Yuwen Heng",
      "Yuanda Gao",
      "Shilei Liu",
      "Heng Wang",
      "Changhao Yao",
      "Jiawen Chen",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13599",
    "title": "From Cluster Assumption to Graph Convolution: Graph-based  Semi-Supervised Learning Revisited",
    "abstract": "Graph-based semi-supervised learning (GSSL) has long been a hot research topic. Traditional methods are generally shallow learners, based on the cluster assumption. Recently, graph convolutional networks (GCNs) have become the predominant techniques for their promising performance. In this paper, we theoretically discuss the relationship between these two types of methods in a unified optimization framework. One of the most intriguing findings is that, unlike traditional ones, typical GCNs may not jointly consider the graph structure and label information at each layer. Motivated by this, we further propose three simple but powerful graph convolution methods. The first is a supervised method OGC which guides the graph convolution process with labels. The others are two unsupervised methods: GGC and its multi-scale version GGCM, both aiming to preserve the graph structure information during the convolution process. Finally, we conduct extensive experiments to show the effectiveness of our methods. ",
    "url": "https://arxiv.org/abs/2309.13599",
    "authors": [
      "Zheng Wang",
      "Hongming Ding",
      "Li Pan",
      "Jianhua Li",
      "Zhiguo Gong",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13607",
    "title": "MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance  Field",
    "abstract": "3D style transfer aims to render stylized novel views of 3D scenes with the specified style, which requires high-quality rendering and keeping multi-view consistency. Benefiting from the ability of 3D representation from Neural Radiance Field (NeRF), existing methods learn the stylized NeRF by giving a reference style from an image. However, they suffer the challenges of high-quality stylization with texture details for multi-style transfer and stylization with multimodal guidance. In this paper, we reveal that the same objects in 3D scenes show various states (color tone, details, etc.) from different views after stylization since previous methods optimized by single-view image-based style loss functions, leading NeRF to tend to smooth texture details, further resulting in low-quality rendering. To tackle these problems, we propose a novel Multimodal-guided 3D Multi-style transfer of NeRF, termed MM-NeRF, which achieves high-quality 3D multi-style rendering with texture details and can be driven by multimodal-style guidance. First, MM-NeRF adopts a unified framework to project multimodal guidance into CLIP space and extracts multimodal style features to guide the multi-style stylization. To relieve the problem of lacking details, we propose a novel Multi-Head Learning Scheme (MLS), in which each style head predicts the parameters of the color head of NeRF. MLS decomposes the learning difficulty caused by the inconsistency of multi-style transfer and improves the quality of stylization. In addition, the MLS can generalize pre-trained MM-NeRF to any new styles by adding heads with small training costs (a few minutes). Extensive experiments on three real-world 3D scene datasets show that MM-NeRF achieves high-quality 3D multi-style stylization with multimodal guidance, keeps multi-view consistency, and keeps semantic consistency of multimodal style guidance. Codes will be released later. ",
    "url": "https://arxiv.org/abs/2309.13607",
    "authors": [
      "Zijiang Yang",
      "Zhongwei Qiu",
      "Chang Xu",
      "Dongmei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13609",
    "title": "Vulnerabilities in Video Quality Assessment Models: The Challenge of  Adversarial Attacks",
    "abstract": "No-Reference Video Quality Assessment (NR-VQA) plays an essential role in improving the viewing experience of end-users. Driven by deep learning, recent NR-VQA models based on Convolutional Neural Networks (CNNs) and Transformers have achieved outstanding performance. To build a reliable and practical assessment system, it is of great necessity to evaluate their robustness. However, such issue has received little attention in the academic community. In this paper, we make the first attempt to evaluate the robustness of NR-VQA models against adversarial attacks under black-box setting, and propose a patch-based random search method for black-box attack. Specifically, considering both the attack effect on quality score and the visual quality of adversarial video, the attack problem is formulated as misleading the estimated quality score under the constraint of just-noticeable difference (JND). Built upon such formulation, a novel loss function called Score-Reversed Boundary Loss is designed to push the adversarial video's estimated quality score far away from its ground-truth score towards a specific boundary, and the JND constraint is modeled as a strict $L_2$ and $L_\\infty$ norm restriction. By this means, both white-box and black-box attacks can be launched in an effective and imperceptible manner. The source code is available at https://github.com/GZHU-DVL/AttackVQA. ",
    "url": "https://arxiv.org/abs/2309.13609",
    "authors": [
      "Ao-Xiang Zhang",
      "Yu Ran",
      "Weixuan Tang",
      "Yuan-Gen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.13610",
    "title": "VisionKG: Unleashing the Power of Visual Datasets via Knowledge Graph",
    "abstract": "The availability of vast amounts of visual data with heterogeneous features is a key factor for developing, testing, and benchmarking of new computer vision (CV) algorithms and architectures. Most visual datasets are created and curated for specific tasks or with limited image data distribution for very specific situations, and there is no unified approach to manage and access them across diverse sources, tasks, and taxonomies. This not only creates unnecessary overheads when building robust visual recognition systems, but also introduces biases into learning systems and limits the capabilities of data-centric AI. To address these problems, we propose the Vision Knowledge Graph (VisionKG), a novel resource that interlinks, organizes and manages visual datasets via knowledge graphs and Semantic Web technologies. It can serve as a unified framework facilitating simple access and querying of state-of-the-art visual datasets, regardless of their heterogeneous formats and taxonomies. One of the key differences between our approach and existing methods is that ours is knowledge-based rather than metadatabased. It enhances the enrichment of the semantics at both image and instance levels and offers various data retrieval and exploratory services via SPARQL. VisionKG currently contains 519 million RDF triples that describe approximately 40 million entities, and are accessible at https://vision.semkg.org and through APIs. With the integration of 30 datasets and four popular CV tasks, we demonstrate its usefulness across various scenarios when working with CV pipelines. ",
    "url": "https://arxiv.org/abs/2309.13610",
    "authors": [
      "Jicheng Yuan",
      "Anh Le-Tuan",
      "Manh Nguyen-Duc",
      "Trung-Kien Tran",
      "Manfred Hauswirth",
      "Danh Le-Phuoc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13619",
    "title": "Changes-Aware Transformer: Learning Generalized Changes Representation",
    "abstract": "Difference features obtained by comparing the images of two periods play an indispensable role in the change detection (CD) task. However, a pair of bi-temporal images can exhibit diverse changes, which may cause various difference features. Identifying changed pixels with differ difference features to be the same category is thus a challenge for CD. Most nowadays' methods acquire distinctive difference features in implicit ways like enhancing image representation or supervision information. Nevertheless, informative image features only guarantee object semantics are modeled and can not guarantee that changed pixels have similar semantics in the difference feature space and are distinct from those unchanged ones. In this work, the generalized representation of various changes is learned straightforwardly in the difference feature space, and a novel Changes-Aware Transformer (CAT) for refining difference features is proposed. This generalized representation can perceive which pixels are changed and which are unchanged and further guide the update of pixels' difference features. CAT effectively accomplishes this refinement process through the stacked cosine cross-attention layer and self-attention layer. After refinement, the changed pixels in the difference feature space are closer to each other, which facilitates change detection. In addition, CAT is compatible with various backbone networks and existing CD methods. Experiments on remote sensing CD data set and street scene CD data set show that our method achieves state-of-the-art performance and has excellent generalization. ",
    "url": "https://arxiv.org/abs/2309.13619",
    "authors": [
      "Dan Wang",
      "Licheng Jiao",
      "Jie Chen",
      "Shuyuan Yang",
      "Fang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13620",
    "title": "PRIS: Practical robust invertible network for image steganography",
    "abstract": "Image steganography is a technique of hiding secret information inside another image, so that the secret is not visible to human eyes and can be recovered when needed. Most of the existing image steganography methods have low hiding robustness when the container images affected by distortion. Such as Gaussian noise and lossy compression. This paper proposed PRIS to improve the robustness of image steganography, it based on invertible neural networks, and put two enhance modules before and after the extraction process with a 3-step training strategy. Moreover, rounding error is considered which is always ignored by existing methods, but actually it is unavoidable in practical. A gradient approximation function (GAF) is also proposed to overcome the undifferentiable issue of rounding distortion. Experimental results show that our PRIS outperforms the state-of-the-art robust image steganography method in both robustness and practicability. Codes are available at https://github.com/yanghangAI/PRIS, demonstration of our model in practical at this http URL ",
    "url": "https://arxiv.org/abs/2309.13620",
    "authors": [
      "Hang Yang",
      "Yitian Xu",
      "Xuhua Liu",
      "Xiaodong Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.13625",
    "title": "GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph",
    "abstract": "Adapter-style efficient transfer learning (ETL) has shown excellent performance in the tuning of vision-language models (VLMs) under the low-data regime, where only a few additional parameters are introduced to excavate the task-specific knowledge based on the general and powerful representation of VLMs. However, most adapter-style works face two limitations: (i) modeling task-specific knowledge with a single modality only; and (ii) overlooking the exploitation of the inter-class relationships in downstream tasks, thereby leading to sub-optimal solutions. To mitigate that, we propose an effective adapter-style tuning strategy, dubbed GraphAdapter, which performs the textual adapter by explicitly modeling the dual-modality structure knowledge (i.e., the correlation of different semantics/classes in textual and visual modalities) with a dual knowledge graph. In particular, the dual knowledge graph is established with two sub-graphs, i.e., a textual knowledge sub-graph, and a visual knowledge sub-graph, where the nodes and edges represent the semantics/classes and their correlations in two modalities, respectively. This enables the textual feature of each prompt to leverage the task-specific structure knowledge from both textual and visual modalities, yielding a more effective classifier for downstream tasks. Extensive experimental results on 11 benchmark datasets reveal that our GraphAdapter significantly outperforms previous adapter-based methods. The code will be released at https://github.com/lixinustc/GraphAdapter ",
    "url": "https://arxiv.org/abs/2309.13625",
    "authors": [
      "Xin Li",
      "Dongze Lian",
      "Zhihe Lu",
      "Jiawang Bai",
      "Zhibo Chen",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13634",
    "title": "Unique Least Common Ancestors and Clusters in Directed Acyclic Graphs",
    "abstract": "We investigate the connections between clusters and least common ancestors (LCAs) in directed acyclic graphs (DAGs). We focus on the class of DAGs having unique least common ancestors for certain subsets of their minimal elements since these are of interest, particularly as models of phylogenetic networks. Here, we use the close connection between the canonical k-ary transit function and the closure function on a set system to show that pre-k-ary clustering systems are exactly those that derive from a class of DAGs with unique LCAs. Moreover, we show that k-ary T-systems and k-weak hierarchies are associated with DAGs that satisfy stronger conditions on the existence of unique LCAs for sets of size at most k. ",
    "url": "https://arxiv.org/abs/2309.13634",
    "authors": [
      "Ameera Vaheeda Shanavas",
      "Manoj Changat",
      "Marc Hellmuth",
      "Peter F. Stadler"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2309.13635",
    "title": "PanopticNDT: Efficient and Robust Panoptic Mapping",
    "abstract": "As the application scenarios of mobile robots are getting more complex and challenging, scene understanding becomes increasingly crucial. A mobile robot that is supposed to operate autonomously in indoor environments must have precise knowledge about what objects are present, where they are, what their spatial extent is, and how they can be reached; i.e., information about free space is also crucial. Panoptic mapping is a powerful instrument providing such information. However, building 3D panoptic maps with high spatial resolution is challenging on mobile robots, given their limited computing capabilities. In this paper, we propose PanopticNDT - an efficient and robust panoptic mapping approach based on occupancy normal distribution transform (NDT) mapping. We evaluate our approach on the publicly available datasets Hypersim and ScanNetV2. The results reveal that our approach can represent panoptic information at a higher level of detail than other state-of-the-art approaches while enabling real-time panoptic mapping on mobile robots. Finally, we prove the real-world applicability of PanopticNDT with qualitative results in a domestic application. ",
    "url": "https://arxiv.org/abs/2309.13635",
    "authors": [
      "Daniel Seichter",
      "Benedict Stephan",
      "S\u00f6hnke Benedikt Fischedick",
      "Steffen M\u00fcller",
      "Leonard Rabes",
      "Horst-Michael Gross"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13636",
    "title": "Development of an intelligent system for the detection of corona virus  using artificial neural network",
    "abstract": "This paper presents the development of an intelligent system for the detection of coronavirus using artificial neural network. This was done after series of literature review which indicated that high fever accounts for 87.9% of the COVID-19 symptoms. 683 temperature data of COVID-19 patients at >= 38C^o were collected from Colliery hospital Enugu, Nigeria and used to train an artificial neural network detective model for the detection of COVID-19. The reference model generated was used converted into Verilog codes using Hardware Description Language (HDL) and then burn into a Field Programming Gate Array (FPGA) controller using FPGA tool in Matlab. The performance of the model when evaluated using confusion matrix, regression and means square error (MSE) showed that the regression value is 0.967; the accuracy is 97% and then MSE is 0.00100Mu. These results all implied that the new detection system for is reliable and very effective for the detection of COVID-19. ",
    "url": "https://arxiv.org/abs/2309.13636",
    "authors": [
      "Nwafor Emmanuel O",
      "Ngozi Maryrose Umeh",
      "Ikechukwu Ekene Onyenwe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13646",
    "title": "ILNet: Low-level Matters for Salient Infrared Small Target Detection",
    "abstract": "Infrared small target detection is a technique for finding small targets from infrared clutter background. Due to the dearth of high-level semantic information, small infrared target features are weakened in the deep layers of the CNN, which underachieves the CNN's representation ability. To address the above problem, in this paper, we propose an infrared low-level network (ILNet) that considers infrared small targets as salient areas with little semantic information. Unlike other SOTA methods, ILNet pays greater attention to low-level information instead of treating them equally. A new lightweight feature fusion module, named Interactive Polarized Orthogonal Fusion module (IPOF), is proposed, which integrates more important low-level features from the shallow layers into the deep layers. A Dynamic One-Dimensional Aggregation layers (DODA) are inserted into the IPOF, to dynamically adjust the aggregation of low dimensional information according to the number of input channels. In addition, the idea of ensemble learning is used to design a Representative Block (RB) to dynamically allocate weights for shallow and deep layers. Experimental results on the challenging NUAA-SIRST (78.22% nIoU and 1.33e-6 Fa) and IRSTD-1K (68.91% nIoU and 3.23e-6 Fa) dataset demonstrate that the proposed ILNet can get better performances than other SOTA methods. Moreover, ILNet can obtain a greater improvement with the increasement of data volume. Training code are available at https://github.com/Li-Haoqing/ILNet. ",
    "url": "https://arxiv.org/abs/2309.13646",
    "authors": [
      "Haoqing Li",
      "Jinfu Yang",
      "Runshi Wang",
      "Yifei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13662",
    "title": "Topology-Agnostic Detection of Temporal Money Laundering Flows in  Billion-Scale Transactions",
    "abstract": "Money launderers exploit the weaknesses in detection systems by purposefully placing their ill-gotten money into multiple accounts, at different banks. That money is then layered and moved around among mule accounts to obscure the origin and the flow of transactions. Consequently, the money is integrated into the financial system without raising suspicion. Path finding algorithms that aim at tracking suspicious flows of money usually struggle with scale and complexity. Existing community detection techniques also fail to properly capture the time-dependent relationships. This is particularly evident when performing analytics over massive transaction graphs. We propose a framework (called FaSTMAN), adapted for domain-specific constraints, to efficiently construct a temporal graph of sequential transactions. The framework includes a weighting method, using 2nd order graph representation, to quantify the significance of the edges. This method enables us to distribute complex queries on smaller and densely connected networks of flows. Finally, based on those queries, we can effectively identify networks of suspicious flows. We extensively evaluate the scalability and the effectiveness of our framework against two state-of-the-art solutions for detecting suspicious flows of transactions. For a dataset of over 1 Billion transactions from multiple large European banks, the results show a clear superiority of our framework both in efficiency and usefulness. ",
    "url": "https://arxiv.org/abs/2309.13662",
    "authors": [
      "Haseeb Tariq",
      "Marwan Hassani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2309.13679",
    "title": "Neural Network-PSO-based Velocity Control Algorithm for Landing UAVs on  a Boat",
    "abstract": "Precise landing of Unmanned Aerial Vehicles (UAVs) onto moving platforms like Autonomous Surface Vehicles (ASVs) is both important and challenging, especially in GPS-denied environments, for collaborative navigation of heterogeneous vehicles. UAVs need to land within a confined space onboard ASV to get energy replenishment, while ASV is subject to translational and rotational disturbances due to wind and water flow. Current solutions either rely on high-level waypoint navigation, which struggles to robustly land on varied-speed targets, or necessitate laborious manual tuning of controller parameters, and expensive sensors for target localization. Therefore, we propose an adaptive velocity control algorithm that leverages Particle Swarm Optimization (PSO) and Neural Network (NN) to optimize PID parameters across varying flight altitudes and distinct speeds of a moving boat. The cost function of PSO includes the status change rates of UAV and proximity to the target. The NN further interpolates the PSO-founded PID parameters. The proposed method implemented on a water strider hexacopter design, not only ensures accuracy but also increases robustness. Moreover, this NN-PSO can be readily adapted to suit various mission requirements. Its ability to achieve precise landings extends its applicability to scenarios, including but not limited to rescue missions, package deliveries, and workspace inspections. ",
    "url": "https://arxiv.org/abs/2309.13679",
    "authors": [
      "Li-Fan Wu",
      "Zihan Wang",
      "Mo Rastgaar",
      "Nina Mahmoudian"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.13682",
    "title": "Causal-DFQ: Causality Guided Data-free Network Quantization",
    "abstract": "Model quantization, which aims to compress deep neural networks and accelerate inference speed, has greatly facilitated the development of cumbersome models on mobile and edge devices. There is a common assumption in quantization methods from prior works that training data is available. In practice, however, this assumption cannot always be fulfilled due to reasons of privacy and security, rendering these methods inapplicable in real-life situations. Thus, data-free network quantization has recently received significant attention in neural network compression. Causal reasoning provides an intuitive way to model causal relationships to eliminate data-driven correlations, making causality an essential component of analyzing data-free problems. However, causal formulations of data-free quantization are inadequate in the literature. To bridge this gap, we construct a causal graph to model the data generation and discrepancy reduction between the pre-trained and quantized models. Inspired by the causal understanding, we propose the Causality-guided Data-free Network Quantization method, Causal-DFQ, to eliminate the reliance on data via approaching an equilibrium of causality-driven intervened distributions. Specifically, we design a content-style-decoupled generator, synthesizing images conditioned on the relevant and irrelevant factors; then we propose a discrepancy reduction loss to align the intervened distributions of the pre-trained and quantized models. It is worth noting that our work is the first attempt towards introducing causality to data-free quantization problem. Extensive experiments demonstrate the efficacy of Causal-DFQ. The code is available at https://github.com/42Shawn/Causal-DFQ. ",
    "url": "https://arxiv.org/abs/2309.13682",
    "authors": [
      "Yuzhang Shang",
      "Bingxin Xu",
      "Gaowen Liu",
      "Ramana Kompella",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13690",
    "title": "Scalable data concentrator with baseline interconnection network for  triggerless data acquisition systems",
    "abstract": "Triggerless Data Acquisition Systems (DAQs) require transmitting the data stream from multiple links to the processing node. The short input data words must be concentrated and packed into the longer bit vectors the output interface (e.g. PCI Express) uses. In that process, the unneeded data must be eliminated, and a dense stream of useful DAQ data must be created. Additionally, the time order of the data should be preserved. This paper presents a new solution using the Baseline Network with Reversed Outputs (BNRO)for high-speed data routing.A thorough analysis of the network operation enabled increased scalability compared to the previously published concentrator based on 8x8 network. The presented solution may be scaled by adding additional layers to the BNRO network while minimizing resource consumption. Simulations were done for 4 and 5 layers (16 and 32 inputs). The FPGA synthesis has been performed for 16inputs. The pipeline registers may be added in each network independently, shortening the critical path and increasing the maximum acceptable clock frequency. ",
    "url": "https://arxiv.org/abs/2309.13690",
    "authors": [
      "Wojciech M. Zabo\u0142otny"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2309.13700",
    "title": "Video Adverse-Weather-Component Suppression Network via Weather  Messenger and Adversarial Backpropagation",
    "abstract": "Although convolutional neural networks (CNNs) have been proposed to remove adverse weather conditions in single images using a single set of pre-trained weights, they fail to restore weather videos due to the absence of temporal information. Furthermore, existing methods for removing adverse weather conditions (e.g., rain, fog, and snow) from videos can only handle one type of adverse weather. In this work, we propose the first framework for restoring videos from all adverse weather conditions by developing a video adverse-weather-component suppression network (ViWS-Net). To achieve this, we first devise a weather-agnostic video transformer encoder with multiple transformer stages. Moreover, we design a long short-term temporal modeling mechanism for weather messenger to early fuse input adjacent video frames and learn weather-specific information. We further introduce a weather discriminator with gradient reversion, to maintain the weather-invariant common information and suppress the weather-specific information in pixel features, by adversarially predicting weather types. Finally, we develop a messenger-driven video transformer decoder to retrieve the residual weather-specific feature, which is spatiotemporally aggregated with hierarchical pixel features and refined to predict the clean target frame of input videos. Experimental results, on benchmark datasets and real-world weather videos, demonstrate that our ViWS-Net outperforms current state-of-the-art methods in terms of restoring videos degraded by any weather condition. ",
    "url": "https://arxiv.org/abs/2309.13700",
    "authors": [
      "Yijun Yang",
      "Angelica I. Aviles-Rivero",
      "Huazhu Fu",
      "Ye Liu",
      "Weiming Wang",
      "Lei Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13704",
    "title": "Sound-Print: Generalised Face Presentation Attack Detection using Deep  Representation of Sound Echoes",
    "abstract": "Facial biometrics are widely deployed in smartphone-based applications because of their usability and increased verification accuracy in unconstrained scenarios. The evolving applications of smartphone-based facial recognition have also increased Presentation Attacks (PAs), where an attacker can present a Presentation Attack Instrument (PAI) to maliciously gain access to the application. Because the materials used to generate PAI are not deterministic, the detection of unknown presentation attacks is challenging. In this paper, we present an acoustic echo-based face Presentation Attack Detection (PAD) on a smartphone in which the PAs are detected based on the reflection profiles of the transmitted signal. We propose a novel transmission signal based on the wide pulse that allows us to model the background noise before transmitting the signal and increase the Signal-to-Noise Ratio (SNR). The received signal reflections were processed to remove background noise and accurately represent reflection characteristics. The reflection profiles of the bona fide and PAs are different owing to the different reflection characteristics of the human skin and artefact materials. Extensive experiments are presented using the newly collected Acoustic Sound Echo Dataset (ASED) with 4807 samples captured from bona fide and four different types of PAIs, including print (two types), display, and silicone face-mask attacks. The obtained results indicate the robustness of the proposed method for detecting unknown face presentation attacks. ",
    "url": "https://arxiv.org/abs/2309.13704",
    "authors": [
      "Raghavendra Ramachandra",
      "Jag Mohan Singh",
      "Sushma Venkatesh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13705",
    "title": "A Neural-Guided Dynamic Symbolic Network for Exploring Mathematical  Expressions from Data",
    "abstract": "Symbolic regression (SR) is a powerful technique for discovering the underlying mathematical expressions from observed data. Inspired by the success of deep learning, recent efforts have focused on two categories for SR methods. One is using a neural network or genetic programming to search the expression tree directly. Although this has shown promising results, the large search space poses difficulties in learning constant factors and processing high-dimensional problems. Another approach is leveraging a transformer-based model training on synthetic data and offers advantages in inference speed. However, this method is limited to fixed small numbers of dimensions and may encounter inference problems when given data is out-of-distribution compared to the synthetic data. In this work, we propose DySymNet, a novel neural-guided Dynamic Symbolic Network for SR. Instead of searching for expressions within a large search space, we explore DySymNet with various structures and optimize them to identify expressions that better-fitting the data. With a topology structure like neural networks, DySymNet not only tackles the challenge of high-dimensional problems but also proves effective in optimizing constants. Based on extensive numerical experiments using low-dimensional public standard benchmarks and the well-known SRBench with more variables, our method achieves state-of-the-art performance in terms of fitting accuracy and robustness to noise. ",
    "url": "https://arxiv.org/abs/2309.13705",
    "authors": [
      "Wenqiang Li",
      "Weijun Li",
      "Lina Yu",
      "Min Wu",
      "Jingyi Liu",
      "Yanjie Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13722",
    "title": "Deep neural networks with ReLU, leaky ReLU, and softplus activation  provably overcome the curse of dimensionality for Kolmogorov partial  differential equations with Lipschitz nonlinearities in the $L^p$-sense",
    "abstract": "Recently, several deep learning (DL) methods for approximating high-dimensional partial differential equations (PDEs) have been proposed. The interest that these methods have generated in the literature is in large part due to simulations which appear to demonstrate that such DL methods have the capacity to overcome the curse of dimensionality (COD) for PDEs in the sense that the number of computational operations they require to achieve a certain approximation accuracy $\\varepsilon\\in(0,\\infty)$ grows at most polynomially in the PDE dimension $d\\in\\mathbb N$ and the reciprocal of $\\varepsilon$. While there is thus far no mathematical result that proves that one of such methods is indeed capable of overcoming the COD, there are now a number of rigorous results in the literature that show that deep neural networks (DNNs) have the expressive power to approximate PDE solutions without the COD in the sense that the number of parameters used to describe the approximating DNN grows at most polynomially in both the PDE dimension $d\\in\\mathbb N$ and the reciprocal of the approximation accuracy $\\varepsilon>0$. Roughly speaking, in the literature it is has been proved for every $T>0$ that solutions $u_d\\colon [0,T]\\times\\mathbb R^d\\to \\mathbb R$, $d\\in\\mathbb N$, of semilinear heat PDEs with Lipschitz continuous nonlinearities can be approximated by DNNs with ReLU activation at the terminal time in the $L^2$-sense without the COD provided that the initial value functions $\\mathbb R^d\\ni x\\mapsto u_d(0,x)\\in\\mathbb R$, $d\\in\\mathbb N$, can be approximated by ReLU DNNs without the COD. It is the key contribution of this work to generalize this result by establishing this statement in the $L^p$-sense with $p\\in(0,\\infty)$ and by allowing the activation function to be more general covering the ReLU, the leaky ReLU, and the softplus activation functions as special cases. ",
    "url": "https://arxiv.org/abs/2309.13722",
    "authors": [
      "Julia Ackermann",
      "Arnulf Jentzen",
      "Thomas Kruse",
      "Benno Kuckuck",
      "Joshua Lee Padgett"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2309.13736",
    "title": "Geometry of Linear Neural Networks: Equivariance and Invariance under  Permutation Groups",
    "abstract": "The set of functions parameterized by a linear fully-connected neural network is a determinantal variety. We investigate the subvariety of functions that are equivariant or invariant under the action of a permutation group. Examples of such group actions are translations or $90^\\circ$ rotations on images. For such equivariant or invariant subvarieties, we provide an explicit description of their dimension, their degree as well as their Euclidean distance degree, and their singularities. We fully characterize invariance for arbitrary permutation groups, and equivariance for cyclic groups. We draw conclusions for the parameterization and the design of equivariant and invariant linear networks, such as a weight sharing property, and we prove that all invariant linear functions can be learned by linear autoencoders. ",
    "url": "https://arxiv.org/abs/2309.13736",
    "authors": [
      "Kathl\u00e9n Kohn",
      "Anna-Laura Sattelberger",
      "Vahid Shahverdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)"
    ]
  },
  {
    "id": "arXiv:2309.13743",
    "title": "Robust Adaptive MPC Using Uncertainty Compensation",
    "abstract": "This paper presents an uncertainty compensation-based robust adaptive model predictive control (MPC) framework for linear systems with both matched and unmatched nonlinear uncertainties subject to both state and input constraints. In particular, the proposed control framework leverages an L1 adaptive controller (L1AC) to compensate for the matched uncertainties and to provide guaranteed uniform bounds on the error between the actual states and control inputs and those from a nominal i.e., uncertainty-free, system. The performance bounds provided by the L1AC are then used to tighten the state and control constraints of the actual system, and a model predictive controller is designed for the nominal system with the tightened constraints. The proposed control framework, which we denote as uncertainty compensation-based MPC (UC-MPC), guarantees constraint satisfaction and achieves improved performance compared with existing methods. Simulation results on a flight control example demonstrate the benefits of the proposed framework. ",
    "url": "https://arxiv.org/abs/2309.13743",
    "authors": [
      "Ran Tao",
      "Pan Zhao",
      "Ilya Kolmanovsky",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.13746",
    "title": "Deep Learning-Based Connector Detection for Robotized Assembly of  Automotive Wire Harnesses",
    "abstract": "The shift towards electrification and autonomous driving in the automotive industry results in more and more automotive wire harnesses being installed in modern automobiles, which stresses the great significance of guaranteeing the quality of automotive wire harness assembly. The mating of connectors is essential in the final assembly of automotive wire harnesses due to the importance of connectors on wire harness connection and signal transmission. However, the current manual operation of mating connectors leads to severe problems regarding assembly quality and ergonomics, where the robotized assembly has been considered, and different vision-based solutions have been proposed to facilitate a better perception of the robot control system on connectors. Nonetheless, there has been a lack of deep learning-based solutions for detecting automotive wire harness connectors in previous literature. This paper presents a deep learning-based connector detection for robotized automotive wire harness assembly. A dataset of twenty automotive wire harness connectors was created to train and evaluate a two-stage and a one-stage object detection model, respectively. The experiment results indicate the effectiveness of deep learning-based connector detection for automotive wire harness assembly but are limited by the design of the exteriors of connectors. ",
    "url": "https://arxiv.org/abs/2309.13746",
    "authors": [
      "Hao Wang",
      "Bj\u00f6rn Johansson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13752",
    "title": "Improving Robustness of Deep Convolutional Neural Networks via  Multiresolution Learning",
    "abstract": "The current learning process of deep learning, regardless of any deep neural network (DNN) architecture and/or learning algorithm used, is essentially a single resolution training. We explore multiresolution learning and show that multiresolution learning can significantly improve robustness of DNN models for both 1D signal and 2D signal (image) prediction problems. We demonstrate this improvement in terms of both noise and adversarial robustness as well as with small training dataset size. Our results also suggest that it may not be necessary to trade standard accuracy for robustness with multiresolution learning, which is, interestingly, contrary to the observation obtained from the traditional single resolution learning setting. ",
    "url": "https://arxiv.org/abs/2309.13752",
    "authors": [
      "Hongyan Zhou",
      "Yao Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13763",
    "title": "Combining Two Adversarial Attacks Against Person Re-Identification  Systems",
    "abstract": "The field of Person Re-Identification (Re-ID) has received much attention recently, driven by the progress of deep neural networks, especially for image classification. The problem of Re-ID consists in identifying individuals through images captured by surveillance cameras in different scenarios. Governments and companies are investing a lot of time and money in Re-ID systems for use in public safety and identifying missing persons. However, several challenges remain for successfully implementing Re-ID, such as occlusions and light reflections in people's images. In this work, we focus on adversarial attacks on Re-ID systems, which can be a critical threat to the performance of these systems. In particular, we explore the combination of adversarial attacks against Re-ID models, trying to strengthen the decrease in the classification results. We conduct our experiments on three datasets: DukeMTMC-ReID, Market-1501, and CUHK03. We combine the use of two types of adversarial attacks, P-FGSM and Deep Mis-Ranking, applied to two popular Re-ID models: IDE (ResNet-50) and AlignedReID. The best result demonstrates a decrease of 3.36% in the Rank-10 metric for AlignedReID applied to CUHK03. We also try to use Dropout during the inference as a defense method. ",
    "url": "https://arxiv.org/abs/2309.13763",
    "authors": [
      "Eduardo de O. Andrade",
      "Igor Garcia Ballhausen Sampaio",
      "Joris Gu\u00e9rin",
      "Jos\u00e9 Viterbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13770",
    "title": "Devil in the Number: Towards Robust Multi-modality Data Filter",
    "abstract": "In order to appropriately filter multi-modality data sets on a web-scale, it becomes crucial to employ suitable filtering methods to boost performance and reduce training costs. For instance, LAION papers employs the CLIP score filter to select data with CLIP scores surpassing a certain threshold. On the other hand, T-MARS achieves high-quality data filtering by detecting and masking text within images and then filtering by CLIP score. Through analyzing the dataset, we observe a significant proportion of redundant information, such as numbers, present in the textual content. Our experiments on a subset of the data unveil the profound impact of these redundant elements on the CLIP scores. A logical approach would involve reevaluating the CLIP scores after eliminating these influences. Experimentally, our text-based CLIP filter outperforms the top-ranked method on the ``small scale\" of DataComp (a data filtering benchmark) on ImageNet distribution shifts, achieving a 3.6% performance improvement. The results also demonstrate that our proposed text-masked filter outperforms the original CLIP score filter when selecting the top 40% of the data. The impact of numbers on CLIP and their handling provide valuable insights for improving the effectiveness of CLIP training, including language rewrite techniques. ",
    "url": "https://arxiv.org/abs/2309.13770",
    "authors": [
      "Yichen Xu",
      "Zihan Xu",
      "Wenhao Chai",
      "Zhonghan Zhao",
      "Enxin Song",
      "Gaoang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13773",
    "title": "GHN-QAT: Training Graph Hypernetworks to Predict Quantization-Robust  Parameters of Unseen Limited Precision Neural Networks",
    "abstract": "Graph Hypernetworks (GHN) can predict the parameters of varying unseen CNN architectures with surprisingly good accuracy at a fraction of the cost of iterative optimization. Following these successes, preliminary research has explored the use of GHNs to predict quantization-robust parameters for 8-bit and 4-bit quantized CNNs. However, this early work leveraged full-precision float32 training and only quantized for testing. We explore the impact of quantization-aware training and/or other quantization-based training strategies on quantized robustness and performance of GHN predicted parameters for low-precision CNNs. We show that quantization-aware training can significantly improve quantized accuracy for GHN predicted parameters of 4-bit quantized CNNs and even lead to greater-than-random accuracy for 2-bit quantized CNNs. These promising results open the door for future explorations such as investigating the use of GHN predicted parameters as initialization for further quantized training of individual CNNs, further exploration of \"extreme bitwidth\" quantization, and mixed precision quantization schemes. ",
    "url": "https://arxiv.org/abs/2309.13773",
    "authors": [
      "Stone Yun",
      "Alexander Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13781",
    "title": "Explainable Machine Learning for ICU Readmission Prediction",
    "abstract": "The intensive care unit (ICU) comprises a complex hospital environment, where decisions made by clinicians have a high level of risk for the patients' lives. A comprehensive care pathway must then be followed to reduce p complications. Uncertain, competing and unplanned aspects within this environment increase the difficulty in uniformly implementing the care pathway. Readmission contributes to this pathway's difficulty, occurring when patients are admitted again to the ICU in a short timeframe, resulting in high mortality rates and high resource utilisation. Several works have tried to predict readmission through patients' medical information. Although they have some level of success while predicting readmission, those works do not properly assess, characterise and understand readmission prediction. This work proposes a standardised and explainable machine learning pipeline to model patient readmission on a multicentric database (i.e., the eICU cohort with 166,355 patients, 200,859 admissions and 6,021 readmissions) while validating it on monocentric (i.e., the MIMIC IV cohort with 382,278 patients, 523,740 admissions and 5,984 readmissions) and multicentric settings. Our machine learning pipeline achieved predictive performance in terms of the area of the receiver operating characteristic curve (AUC) up to 0.7 with a Random Forest classification model, yielding an overall good calibration and consistency on validation sets. From explanations provided by the constructed models, we could also derive a set of insightful conclusions, primarily on variables related to vital signs and blood tests (e.g., albumin, blood urea nitrogen and hemoglobin levels), demographics (e.g., age, and admission height and weight), and ICU-associated variables (e.g., unit type). These insights provide an invaluable source of information during clinicians' decision-making while discharging ICU patients. ",
    "url": "https://arxiv.org/abs/2309.13781",
    "authors": [
      "Alex de S\u00e1",
      "Daniel Gould",
      "Anna Fedyukova",
      "Mitchell Nicholas",
      "Lucy Dockrell",
      "Calvin Fletcher",
      "David Pilcher",
      "Daniel Capurro",
      "David Ascher",
      "Khaled El-Khawas",
      "Douglas Pires"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13785",
    "title": "Study of Robust Adaptive Beamforming Algorithms Based on Power Method  Processing and Spatial Spectrum Matching",
    "abstract": "Robust adaptive beamforming (RAB) based on interference-plus-noise covariance (INC) matrix reconstruction can experience performance degradation when model mismatch errors exist, particularly when the input signal-to-noise ratio (SNR) is large. In this work, we devise an efficient RAB technique for dealing with covariance matrix reconstruction issues. The proposed method involves INC matrix reconstruction using an idea in which the power and the steering vector of the interferences are estimated based on the power method. Furthermore, spatial match processing is computed to reconstruct the desired signal-plus-noise covariance matrix. Then, the noise components are excluded to retain the desired signal (DS) covariance matrix. A key feature of the proposed technique is to avoid eigenvalue decomposition of the INC matrix to obtain the dominant power of the interference-plus-noise region. Moreover, the INC reconstruction is carried out according to the definition of the theoretical INC matrix. Simulation results are shown and discussed to verify the effectiveness of the proposed method against existing approaches. ",
    "url": "https://arxiv.org/abs/2309.13785",
    "authors": [
      "S. Mohammadzadeh",
      "V. H. Nascimento",
      "R. C. de Lamare",
      "O. Kukrer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.13794",
    "title": "Projected Randomized Smoothing for Certified Adversarial Robustness",
    "abstract": "Randomized smoothing is the current state-of-the-art method for producing provably robust classifiers. While randomized smoothing typically yields robust $\\ell_2$-ball certificates, recent research has generalized provable robustness to different norm balls as well as anisotropic regions. This work considers a classifier architecture that first projects onto a low-dimensional approximation of the data manifold and then applies a standard classifier. By performing randomized smoothing in the low-dimensional projected space, we characterize the certified region of our smoothed composite classifier back in the high-dimensional input space and prove a tractable lower bound on its volume. We show experimentally on CIFAR-10 and SVHN that classifiers without the initial projection are vulnerable to perturbations that are normal to the data manifold and yet are captured by the certified regions of our method. We compare the volume of our certified regions against various baselines and show that our method improves on the state-of-the-art by many orders of magnitude. ",
    "url": "https://arxiv.org/abs/2309.13794",
    "authors": [
      "Samuel Pfrommer",
      "Brendon G. Anderson",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13800",
    "title": "Enumerating All Maximal Clique-Partitions of an Undirected Graph",
    "abstract": "We address the problem of enumerating all maximal clique-partitions of an undirected graph and present an algorithm based on the observation that every maximal clique-partition can be produced from the maximal clique-cover of the graph by assigning the vertices shared among maximal cliques, to belong to only one clique. This simple algorithm has the following drawbacks: (1) the search space is very large; (2) it finds some clique-partitions which are not maximal; and (3) some clique-partitions are found more than once. We propose two criteria to avoid these drawbacks. The outcome is an algorithm that explores a much smaller search space and guarantees that every maximal clique-partition is computed only once. The algorithm can be used in problems such as anti-unification with proximity relations or in resource allocation tasks when one looks for several alternative ways to allocate resources. ",
    "url": "https://arxiv.org/abs/2309.13800",
    "authors": [
      "Mircea Marin",
      "Temur Kutsia",
      "Cleo Pau",
      "Mikheil Rukhaia"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2309.13803",
    "title": "Privacy-preserving Linear Computations in Spiking Neural P Systems",
    "abstract": "Spiking Neural P systems are a class of membrane computing models inspired directly by biological neurons. Besides the theoretical progress made in this new computational model, there are also numerous applications of P systems in fields like formal verification, artificial intelligence, or cryptography. Motivated by all the use cases of SN P systems, in this paper, we present a new privacy-preserving protocol that enables a client to compute a linear function using an SN P system hosted on a remote server. Our protocol allows the client to use the server to evaluate functions of the form t_1k + t_2 without revealing t_1, t_2 or k and without the server knowing the result. We also present an SN P system to implement any linear function over natural numbers and some security considerations of our protocol in the honest-but-curious security model. ",
    "url": "https://arxiv.org/abs/2309.13803",
    "authors": [
      "Mihail-Iulian Plesa",
      "Marian Gheorghe",
      "Florentin Ipate"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13814",
    "title": "DVI-SLAM: A Dual Visual Inertial SLAM Network",
    "abstract": "Recent deep learning based visual simultaneous localization and mapping (SLAM) methods have made significant progress. However, how to make full use of visual information as well as better integrate with inertial measurement unit (IMU) in visual SLAM has potential research value. This paper proposes a novel deep SLAM network with dual visual factors. The basic idea is to integrate both photometric factor and re-projection factor into the end-to-end differentiable structure through multi-factor data association module. We show that the proposed network dynamically learns and adjusts the confidence maps of both visual factors and it can be further extended to include the IMU factors as well. Extensive experiments validate that our proposed method significantly outperforms the state-of-the-art methods on several public datasets, including TartanAir, EuRoC and ETH3D-SLAM. Specifically, when dynamically fusing the three factors together, the absolute trajectory error for both monocular and stereo configurations on EuRoC dataset has reduced by 45.3% and 36.2% respectively. ",
    "url": "https://arxiv.org/abs/2309.13814",
    "authors": [
      "Xiongfeng Peng",
      "Zhihua Liu",
      "Weiming Li",
      "Ping Tan",
      "SoonYong Cho",
      "Qiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13833",
    "title": "Dual Feature Augmentation Network for Generalized Zero-shot Learning",
    "abstract": "Zero-shot learning (ZSL) aims to infer novel classes without training samples by transferring knowledge from seen classes. Existing embedding-based approaches for ZSL typically employ attention mechanisms to locate attributes on an image. However, these methods often ignore the complex entanglement among different attributes' visual features in the embedding space. Additionally, these methods employ a direct attribute prediction scheme for classification, which does not account for the diversity of attributes in images of the same category. To address these issues, we propose a novel Dual Feature Augmentation Network (DFAN), which comprises two feature augmentation modules, one for visual features and the other for semantic features. The visual feature augmentation module explicitly learns attribute features and employs cosine distance to separate them, thus enhancing attribute representation. In the semantic feature augmentation module, we propose a bias learner to capture the offset that bridges the gap between actual and predicted attribute values from a dataset's perspective. Furthermore, we introduce two predictors to reconcile the conflicts between local and global features. Experimental results on three benchmarks demonstrate the marked advancement of our method compared to state-of-the-art approaches. Our code is available at https://github.com/Sion1/DFAN. ",
    "url": "https://arxiv.org/abs/2309.13833",
    "authors": [
      "Lei Xiang",
      "Yuan Zhou",
      "Haoran Duan",
      "Yang Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13834",
    "title": "Prior Bilinear Based Models for Knowledge Graph Completion",
    "abstract": "Bilinear based models are powerful and widely used approaches for Knowledge Graphs Completion (KGC). Although bilinear based models have achieved significant advances, these studies mainly concentrate on posterior properties (based on evidence, e.g. symmetry pattern) while neglecting the prior properties. In this paper, we find a prior property named \"the law of identity\" that cannot be captured by bilinear based models, which hinders them from comprehensively modeling the characteristics of KGs. To address this issue, we introduce a solution called Unit Ball Bilinear Model (UniBi). This model not only achieves theoretical superiority but also offers enhanced interpretability and performance by minimizing ineffective learning through minimal constraints. Experiments demonstrate that UniBi models the prior property and verify its interpretability and performance. ",
    "url": "https://arxiv.org/abs/2309.13834",
    "authors": [
      "Jiayi Li",
      "Ruilin Luo",
      "Jiaqi Sun",
      "Jing Xiao",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13836",
    "title": "On the Energy Efficiency of THz-NOMA enhanced UAV Cooperative Network  with SWIPT",
    "abstract": "This paper considers the energy efficiency (EE) maximization of a simultaneous wireless information and power transfer (SWIPT)-assisted unmanned aerial vehicles (UAV) cooperative network operating at TeraHertz (THz) frequencies. The source performs SWIPT enabling the UAV to receive both power and information while also transmitting the information to a designated destination node. Subsequently, the UAV utilizes the harvested energy to relay the data to the intended destination node effectively. Specifically, we maximize EE by optimizing the non-orthogonal multiple access (NOMA) power allocation coefficients, SWIPT power splitting (PS) ratio, and UAV trajectory. The main problem is broken down into a two-stage optimization problem and solved using an alternating optimization approach. In the first stage, optimization of the PS ratio and trajectory is performed by employing successive convex approximation using a lower bound on the exponential factor in the THz channel model. In the second phase, the NOMA power coefficients are optimized using a quadratic transform approach. Numerical results demonstrate the effectiveness of our proposed resource allocation algorithm compared to the baselines where there is no trajectory optimization or no NOMA power or PS optimization. ",
    "url": "https://arxiv.org/abs/2309.13836",
    "authors": [
      "Jalal Jalali",
      "Ata Khalili",
      "Hina Tabassum",
      "Rafael Berkvens",
      "Jeroen Famaey",
      "Walid Saad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.13837",
    "title": "Backorder Prediction in Inventory Management: Classification Techniques  and Cost Considerations",
    "abstract": "This article introduces an advanced analytical approach for predicting backorders in inventory management. Backorder refers to an order that cannot be immediately fulfilled due to stock depletion. Multiple classification techniques, including Balanced Bagging Classifiers, Fuzzy Logic, Variational Autoencoder - Generative Adversarial Networks, and Multi-layer Perceptron classifiers, are assessed in this work using performance evaluation metrics such as ROC-AUC and PR-AUC. Moreover, this work incorporates a profit function and misclassification costs, considering the financial implications and costs associated with inventory management and backorder handling. The results demonstrate the effectiveness of the predictive model in enhancing inventory system service levels, which leads to customer satisfaction and overall organizational performance. Considering interpretability is a significant aspect of using AI in commercial applications, permutation importance is applied to the selected model to determine the importance of features. This research contributes to the advancement of predictive analytics and offers valuable insights for future investigations in backorder forecasting and inventory control optimization for decision-making. ",
    "url": "https://arxiv.org/abs/2309.13837",
    "authors": [
      "Sarit Maitra",
      "Sukanya Kundu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.13841",
    "title": "On the Effectiveness of Adversarial Samples against Ensemble  Learning-based Windows PE Malware Detectors",
    "abstract": "Recently, there has been a growing focus and interest in applying machine learning (ML) to the field of cybersecurity, particularly in malware detection and prevention. Several research works on malware analysis have been proposed, offering promising results for both academic and practical applications. In these works, the use of Generative Adversarial Networks (GANs) or Reinforcement Learning (RL) can aid malware creators in crafting metamorphic malware that evades antivirus software. In this study, we propose a mutation system to counteract ensemble learning-based detectors by combining GANs and an RL model, overcoming the limitations of the MalGAN model. Our proposed FeaGAN model is built based on MalGAN by incorporating an RL model called the Deep Q-network anti-malware Engines Attacking Framework (DQEAF). The RL model addresses three key challenges in performing adversarial attacks on Windows Portable Executable malware, including format preservation, executability preservation, and maliciousness preservation. In the FeaGAN model, ensemble learning is utilized to enhance the malware detector's evasion ability, with the generated adversarial patterns. The experimental results demonstrate that 100\\% of the selected mutant samples preserve the format of executable files, while certain successes in both executability preservation and maliciousness preservation are achieved, reaching a stable success rate. ",
    "url": "https://arxiv.org/abs/2309.13841",
    "authors": [
      "Trong-Nghia To",
      "Danh Le Kim",
      "Do Thi Thu Hien",
      "Nghi Hoang Khoa",
      "Hien Do Hoang",
      "Phan The Duy",
      "Van-Hau Pham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13842",
    "title": "Traj-LO: In Defense of LiDAR-Only Odometry Using an Effective  Continuous-Time Trajectory",
    "abstract": "LiDAR Odometry is an essential component in many robotic applications. Unlike the mainstreamed approaches that focus on improving the accuracy by the additional inertial sensors, this letter explores the capability of LiDAR-only odometry through a continuous-time perspective. Firstly, the measurements of LiDAR are regarded as streaming points continuously captured at high frequency. Secondly, the LiDAR movement is parameterized by a simple yet effective continuous-time trajectory. Therefore, our proposed Traj-LO approach tries to recover the spatial-temporal consistent movement of LiDAR by tightly coupling the geometric information from LiDAR points and kinematic constraints from trajectory smoothness. This framework is generalized for different kinds of LiDAR as well as multi-LiDAR systems. Extensive experiments on the public datasets demonstrate the robustness and effectiveness of our proposed LiDAR-only approach, even in scenarios where the kinematic state exceeds the IMU's measuring range. Our implementation is open-sourced on GitHub. ",
    "url": "https://arxiv.org/abs/2309.13842",
    "authors": [
      "Xin Zheng",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13857",
    "title": "Adversarial Attacks on Video Object Segmentation with Hard Region  Discovery",
    "abstract": "Video object segmentation has been applied to various computer vision tasks, such as video editing, autonomous driving, and human-robot interaction. However, the methods based on deep neural networks are vulnerable to adversarial examples, which are the inputs attacked by almost human-imperceptible perturbations, and the adversary (i.e., attacker) will fool the segmentation model to make incorrect pixel-level predictions. This will rise the security issues in highly-demanding tasks because small perturbations to the input video will result in potential attack risks. Though adversarial examples have been extensively used for classification, it is rarely studied in video object segmentation. Existing related methods in computer vision either require prior knowledge of categories or cannot be directly applied due to the special design for certain tasks, failing to consider the pixel-wise region attack. Hence, this work develops an object-agnostic adversary that has adversarial impacts on VOS by first-frame attacking via hard region discovery. Particularly, the gradients from the segmentation model are exploited to discover the easily confused region, in which it is difficult to identify the pixel-wise objects from the background in a frame. This provides a hardness map that helps to generate perturbations with a stronger adversarial power for attacking the first frame. Empirical studies on three benchmarks indicate that our attacker significantly degrades the performance of several state-of-the-art video object segmentation models. ",
    "url": "https://arxiv.org/abs/2309.13857",
    "authors": [
      "Ping Li",
      "Yu Zhang",
      "Li Yuan",
      "Jian Zhao",
      "Xianghua Xu",
      "Xiaoqin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13860",
    "title": "Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech  Representation Learning",
    "abstract": "Recent years have witnessed significant advancements in self-supervised learning (SSL) methods for speech-processing tasks. Various speech-based SSL models have been developed and present promising performance on a range of downstream tasks including speech recognition. However, existing speech-based SSL models face a common dilemma in terms of computational cost, which might hinder their potential application and in-depth academic research. To address this issue, we first analyze the computational cost of different modules during HuBERT pre-training and then introduce a stack of efficiency optimizations, which is named Fast-HuBERT in this paper. The proposed Fast-HuBERT can be trained in 1.1 days with 8 V100 GPUs on the Librispeech 960h benchmark, without performance degradation, resulting in a 5.2x speedup, compared to the original implementation. Moreover, we explore two well-studied techniques in the Fast-HuBERT and demonstrate consistent improvements as reported in previous work. ",
    "url": "https://arxiv.org/abs/2309.13860",
    "authors": [
      "Guanrou Yang",
      "Ziyang Ma",
      "Zhisheng Zheng",
      "Yakun Song",
      "Zhikang Niu",
      "Xie Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.13864",
    "title": "PA-iMFL: Communication-Efficient Privacy Amplification Method against  Data Reconstruction Attack in Improved Multi-Layer Federated Learning",
    "abstract": "Recently, big data has seen explosive growth in the Internet of Things (IoT). Multi-layer FL (MFL) based on cloud-edge-end architecture can promote model training efficiency and model accuracy while preserving IoT data privacy. This paper considers an improved MFL, where edge layer devices own private data and can join the training process. iMFL can improve edge resource utilization and also alleviate the strict requirement of end devices, but suffers from the issues of Data Reconstruction Attack (DRA) and unacceptable communication overhead. This paper aims to address these issues with iMFL. We propose a Privacy Amplification scheme on iMFL (PA-iMFL). Differing from standard MFL, we design privacy operations in end and edge devices after local training, including three sequential components, local differential privacy with Laplace mechanism, privacy amplification subsample, and gradient sign reset. Benefitting from privacy operations, PA-iMFL reduces communication overhead and achieves privacy-preserving. Extensive results demonstrate that against State-Of-The-Art (SOTA) DRAs, PA-iMFL can effectively mitigate private data leakage and reach the same level of protection capability as the SOTA defense model. Moreover, due to adopting privacy operations in edge devices, PA-iMFL promotes up to 2.8 times communication efficiency than the SOTA compression method without compromising model accuracy. ",
    "url": "https://arxiv.org/abs/2309.13864",
    "authors": [
      "Jianhua Wang",
      "Xiaolin Chang",
      "Jelena Mi\u0161i\u0107",
      "Vojislav B. Mi\u0161i\u0107",
      "Zhi Chen",
      "Junchao Fan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.13866",
    "title": "On Calibration of Modern Quantized Efficient Neural Networks",
    "abstract": "We explore calibration properties at various precisions for three architectures: ShuffleNetv2, GhostNet-VGG, and MobileOne; and two datasets: CIFAR-100 and PathMNIST. The quality of calibration is observed to track the quantization quality; it is well-documented that performance worsens with lower precision, and we observe a similar correlation with poorer calibration. This becomes especially egregious at 4-bit activation regime. GhostNet-VGG is shown to be the most robust to overall performance drop at lower precision. We find that temperature scaling can improve calibration error for quantized networks, with some caveats. We hope that these preliminary insights can lead to more opportunities for explainable and reliable EdgeML. ",
    "url": "https://arxiv.org/abs/2309.13866",
    "authors": [
      "Joey Kuang",
      "Alexander Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13881",
    "title": "Skip-Connected Neural Networks with Layout Graphs for Floor Plan  Auto-Generation",
    "abstract": "With the advent of AI and computer vision techniques, the quest for automated and efficient floor plan designs has gained momentum. This paper presents a novel approach using skip-connected neural networks integrated with layout graphs. The skip-connected layers capture multi-scale floor plan information, and the encoder-decoder networks with GNN facilitate pixel-level probability-based generation. Validated on the MSD dataset, our approach achieved a 56.6 mIoU score in the ICCV 1st CVAAD workshop challenge. Code and pre-trained models are publicly available at https://github.com/yuntaeJ/SkipNet-FloorPlanGe. ",
    "url": "https://arxiv.org/abs/2309.13881",
    "authors": [
      "Yuntae Jeon",
      "Dai Quoc Tran",
      "Seunghee Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13882",
    "title": "FC-Planner: A Skeleton-guided Planning Framework for Fast Aerial  Coverage of Complex 3D Scenes",
    "abstract": "3D coverage path planning for UAVs is a crucial problem in diverse practical applications. However, existing methods have shown unsatisfactory system simplicity, computation efficiency, and path quality in large and complex scenes. To address these challenges, we propose FC-Planner, a skeleton-guided planning framework that can achieve fast aerial coverage of complex 3D scenes without pre-processing. We decompose the scene into several simple subspaces by a skeleton-based space decomposition (SSD). Additionally, the skeleton guides us to effortlessly determine free space. We utilize the skeleton to efficiently generate a minimal set of specialized and informative viewpoints for complete coverage. Based on SSD, a hierarchical planner effectively divides the large planning problem into independent sub-problems, enabling parallel planning for each subspace. The carefully designed global and local planning strategies are then incorporated to guarantee both high quality and efficiency in path generation. We conduct extensive benchmark and real-world tests, where FC-Planner computes over 10 times faster compared to state-of-the-art methods with shorter path and more complete coverage. The source code will be open at https://github.com/HKUST-Aerial-Robotics/FC-Planner. ",
    "url": "https://arxiv.org/abs/2309.13882",
    "authors": [
      "Chen Feng",
      "Haojia Li",
      "Jinqi Jiang",
      "Xinyi Chen",
      "Shaojie Shen",
      "Boyu Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.13884",
    "title": "Estimating Treatment Effects Under Heterogeneous Interference",
    "abstract": "Treatment effect estimation can assist in effective decision-making in e-commerce, medicine, and education. One popular application of this estimation lies in the prediction of the impact of a treatment (e.g., a promotion) on an outcome (e.g., sales) of a particular unit (e.g., an item), known as the individual treatment effect (ITE). In many online applications, the outcome of a unit can be affected by the treatments of other units, as units are often associated, which is referred to as interference. For example, on an online shopping website, sales of an item will be influenced by an advertisement of its co-purchased item. Prior studies have attempted to model interference to estimate the ITE accurately, but they often assume a homogeneous interference, i.e., relationships between units only have a single view. However, in real-world applications, interference may be heterogeneous, with multi-view relationships. For instance, the sale of an item is usually affected by the treatment of its co-purchased and co-viewed items. We hypothesize that ITE estimation will be inaccurate if this heterogeneous interference is not properly modeled. Therefore, we propose a novel approach to model heterogeneous interference by developing a new architecture to aggregate information from diverse neighbors. Our proposed method contains graph neural networks that aggregate same-view information, a mechanism that aggregates information from different views, and attention mechanisms. In our experiments on multiple datasets with heterogeneous interference, the proposed method significantly outperforms existing methods for ITE estimation, confirming the importance of modeling heterogeneous interference. ",
    "url": "https://arxiv.org/abs/2309.13884",
    "authors": [
      "Xiaofeng Lin",
      "Guoxi Zhang",
      "Xiaotian Lu",
      "Han Bao",
      "Koh Takeuchi",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.13885",
    "title": "TouchUp-G: Improving Feature Representation through Graph-Centric  Finetuning",
    "abstract": "How can we enhance the node features acquired from Pretrained Models (PMs) to better suit downstream graph learning tasks? Graph Neural Networks (GNNs) have become the state-of-the-art approach for many high-impact, real-world graph applications. For feature-rich graphs, a prevalent practice involves utilizing a PM directly to generate features, without incorporating any domain adaptation techniques. Nevertheless, this practice is suboptimal because the node features extracted from PM are graph-agnostic and prevent GNNs from fully utilizing the potential correlations between the graph structure and node features, leading to a decline in GNNs performance. In this work, we seek to improve the node features obtained from a PM for downstream graph tasks and introduce TOUCHUP-G, which has several advantages. It is (a) General: applicable to any downstream graph task, including link prediction which is often employed in recommender systems; (b) Multi-modal: able to improve raw features of any modality (e.g. images, texts, audio); (c) Principled: it is closely related to a novel metric, feature homophily, which we propose to quantify the potential correlations between the graph structure and node features and we show that TOUCHUP-G can effectively shrink the discrepancy between the graph structure and node features; (d) Effective: achieving state-of-the-art results on four real-world datasets spanning different tasks and modalities. ",
    "url": "https://arxiv.org/abs/2309.13885",
    "authors": [
      "Jing Zhu",
      "Xiang Song",
      "Vassilis N. Ioannidis",
      "Danai Koutra",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.13888",
    "title": "Graph Representation Learning Towards Patents Network Analysis",
    "abstract": "Patent analysis has recently been recognized as a powerful technique for large companies worldwide to lend them insight into the age of competition among various industries. This technique is considered a shortcut for developing countries since it can significantly accelerate their technology development. Therefore, as an inevitable process, patent analysis can be utilized to monitor rival companies and diverse industries. This research employed a graph representation learning approach to create, analyze, and find similarities in the patent data registered in the Iranian Official Gazette. The patent records were scrapped and wrangled through the Iranian Official Gazette portal. Afterward, the key entities were extracted from the scrapped patents dataset to create the Iranian patents graph from scratch based on novel natural language processing and entity resolution techniques. Finally, thanks to the utilization of novel graph algorithms and text mining methods, we identified new areas of industry and research from Iranian patent data, which can be used extensively to prevent duplicate patents, familiarity with similar and connected inventions, Awareness of legal entities supporting patents and knowledge of researchers and linked stakeholders in a particular research field. ",
    "url": "https://arxiv.org/abs/2309.13888",
    "authors": [
      "Mohammad Heydari",
      "Babak Teimourpour"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13893",
    "title": "Scene Informer: Anchor-based Occlusion Inference and Trajectory  Prediction in Partially Observable Environments",
    "abstract": "Navigating complex and dynamic environments requires autonomous vehicles (AVs) to reason about both visible and occluded regions. This involves predicting the future motion of observed agents, inferring occluded ones, and modeling their interactions based on vectorized scene representations of the partially observable environment. However, prior work on occlusion inference and trajectory prediction have developed in isolation, with the former based on simplified rasterized methods and the latter assuming full environment observability. We introduce the Scene Informer, a unified approach for predicting both observed agent trajectories and inferring occlusions in a partially observable setting. It uses a transformer to aggregate various input modalities and facilitate selective queries on occlusions that might intersect with the AV's planned path. The framework estimates occupancy probabilities and likely trajectories for occlusions, as well as forecast motion for observed agents. We explore common observability assumptions in both domains and their performance impact. Our approach outperforms existing methods in both occupancy prediction and trajectory prediction in partially observable setting on the Waymo Open Motion Dataset. ",
    "url": "https://arxiv.org/abs/2309.13893",
    "authors": [
      "Bernard Lange",
      "Jiachen Li",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13907",
    "title": "HiGNN-TTS: Hierarchical Prosody Modeling with Graph Neural Networks for  Expressive Long-form TTS",
    "abstract": "Recent advances in text-to-speech, particularly those based on Graph Neural Networks (GNNs), have significantly improved the expressiveness of short-form synthetic speech. However, generating human-parity long-form speech with high dynamic prosodic variations is still challenging. To address this problem, we expand the capabilities of GNNs with a hierarchical prosody modeling approach, named HiGNN-TTS. Specifically, we add a virtual global node in the graph to strengthen the interconnection of word nodes and introduce a contextual attention mechanism to broaden the prosody modeling scope of GNNs from intra-sentence to inter-sentence. Additionally, we perform hierarchical supervision from acoustic prosody on each node of the graph to capture the prosodic variations with a high dynamic range. Ablation studies show the effectiveness of HiGNN-TTS in learning hierarchical prosody. Both objective and subjective evaluations demonstrate that HiGNN-TTS significantly improves the naturalness and expressiveness of long-form synthetic speech ",
    "url": "https://arxiv.org/abs/2309.13907",
    "authors": [
      "Dake Guo",
      "Xinfa Zhu",
      "Liumeng Xue",
      "Tao Li",
      "Yuanjun Lv",
      "Yuepeng Jiang",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.13915",
    "title": "Sample Complexity of Neural Policy Mirror Descent for Policy  Optimization on Low-Dimensional Manifolds",
    "abstract": "Policy-based algorithms equipped with deep neural networks have achieved great success in solving high-dimensional policy optimization problems in reinforcement learning. However, current analyses cannot explain why they are resistant to the curse of dimensionality. In this work, we study the sample complexity of the neural policy mirror descent (NPMD) algorithm with convolutional neural networks (CNN) as function approximators. Motivated by the empirical observation that many high-dimensional environments have state spaces possessing low-dimensional structures, such as those taking images as states, we consider the state space to be a $d$-dimensional manifold embedded in the $D$-dimensional Euclidean space with intrinsic dimension $d\\ll D$. We show that in each iteration of NPMD, both the value function and the policy can be well approximated by CNNs. The approximation errors are controlled by the size of the networks, and the smoothness of the previous networks can be inherited. As a result, by properly choosing the network size and hyperparameters, NPMD can find an $\\epsilon$-optimal policy with $\\widetilde{O}(\\epsilon^{-\\frac{d}{\\alpha}-2})$ samples in expectation, where $\\alpha\\in(0,1]$ indicates the smoothness of environment. Compared to previous work, our result exhibits that NPMD can leverage the low-dimensional structure of state space to escape from the curse of dimensionality, providing an explanation for the efficacy of deep policy-based algorithms. ",
    "url": "https://arxiv.org/abs/2309.13915",
    "authors": [
      "Zhenghao Xu",
      "Xiang Ji",
      "Minshuo Chen",
      "Mengdi Wang",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.13920",
    "title": "Real-Time Emergency Vehicle Detection using Mel Spectrograms and Regular  Expressions",
    "abstract": "In emergency situations, the movement of vehicles through city streets can be problematic due to vehicular traffic. This paper presents a method for detecting emergency vehicle sirens in real time. To derive a siren Hi-Lo audio fingerprint it was necessary to apply digital signal processing techniques and signal symbolization, contrasting against a deep neural network audio classifier feeding 280 environmental sounds and 38 Hi-Lo sirens. In both methods, their precision was evaluated based on a confusion matrix and various metrics. The precision of the developed DSP algorithm presented a greater ability to discriminate between signal and noise, compared to the CNN model. ",
    "url": "https://arxiv.org/abs/2309.13920",
    "authors": [
      "Alberto Pacheco-Gonzalez",
      "Raymundo Torres",
      "Raul Chacon",
      "Isidro Robledo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Symbolic Computation (cs.SC)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.13930",
    "title": "SAMN: A Sample Attention Memory Network Combining SVM and NN in One  Architecture",
    "abstract": "Support vector machine (SVM) and neural networks (NN) have strong complementarity. SVM focuses on the inner operation among samples while NN focuses on the operation among the features within samples. Thus, it is promising and attractive to combine SVM and NN, as it may provide a more powerful function than SVM or NN alone. However, current work on combining them lacks true integration. To address this, we propose a sample attention memory network (SAMN) that effectively combines SVM and NN by incorporating sample attention module, class prototypes, and memory block to NN. SVM can be viewed as a sample attention machine. It allows us to add a sample attention module to NN to implement the main function of SVM. Class prototypes are representatives of all classes, which can be viewed as alternatives to support vectors. The memory block is used for the storage and update of class prototypes. Class prototypes and memory block effectively reduce the computational cost of sample attention and make SAMN suitable for multi-classification tasks. Extensive experiments show that SAMN achieves better classification performance than single SVM or single NN with similar parameter sizes, as well as the previous best model for combining SVM and NN. The sample attention mechanism is a flexible module that can be easily deepened and incorporated into neural networks that require it. ",
    "url": "https://arxiv.org/abs/2309.13930",
    "authors": [
      "Qiaoling Yang",
      "Linkai Luo",
      "Haoyu Zhang",
      "Hong Peng",
      "Ziyang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13940",
    "title": "A Lightweight Recurrent Grouping Attention Network for Video  Super-Resolution",
    "abstract": "Effective aggregation of temporal information of consecutive frames is the core of achieving video super-resolution. Many scholars have utilized structures such as sliding windows and recurrent to gather spatio-temporal information of frames. However, although the performance of the constructed VSR models is improving, the size of the models is also increasing, exacerbating the demand on the equipment. Thus, to reduce the stress on the device, we propose a novel lightweight recurrent grouping attention network. The parameters of this model are only 0.878M, which is much lower than the current mainstream model for studying video super-resolution. We design forward feature extraction module and backward feature extraction module to collect temporal information between consecutive frames from two directions. Moreover, a new grouping mechanism is proposed to efficiently collect spatio-temporal information of the reference frame and its neighboring frames. The attention supplementation module is presented to further enhance the information gathering range of the model. The feature reconstruction module aims to aggregate information from different directions to reconstruct high-resolution features. Experiments demonstrate that our model achieves state-of-the-art performance on multiple datasets. ",
    "url": "https://arxiv.org/abs/2309.13940",
    "authors": [
      "Yonggui Zhu",
      "Guofang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13944",
    "title": "Provable Training for Graph Contrastive Learning",
    "abstract": "Graph Contrastive Learning (GCL) has emerged as a popular training approach for learning node embeddings from augmented graphs without labels. Despite the key principle that maximizing the similarity between positive node pairs while minimizing it between negative node pairs is well established, some fundamental problems are still unclear. Considering the complex graph structure, are some nodes consistently well-trained and following this principle even with different graph augmentations? Or are there some nodes more likely to be untrained across graph augmentations and violate the principle? How to distinguish these nodes and further guide the training of GCL? To answer these questions, we first present experimental evidence showing that the training of GCL is indeed imbalanced across all nodes. To address this problem, we propose the metric \"node compactness\", which is the lower bound of how a node follows the GCL principle related to the range of augmentations. We further derive the form of node compactness theoretically through bound propagation, which can be integrated into binary cross-entropy as a regularization. To this end, we propose the PrOvable Training (POT) for GCL, which regularizes the training of GCL to encode node embeddings that follows the GCL principle better. Through extensive experiments on various benchmarks, POT consistently improves the existing GCL approaches, serving as a friendly plugin. ",
    "url": "https://arxiv.org/abs/2309.13944",
    "authors": [
      "Yue Yu",
      "Xiao Wang",
      "Mengmei Zhang",
      "Nian Liu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13965",
    "title": "May I Ask a Follow-up Question? Understanding the Benefits of  Conversations in Neural Network Explainability",
    "abstract": "Research in explainable AI (XAI) aims to provide insights into the decision-making process of opaque AI models. To date, most XAI methods offer one-off and static explanations, which cannot cater to the diverse backgrounds and understanding levels of users. With this paper, we investigate if free-form conversations can enhance users' comprehension of static explanations, improve acceptance and trust in the explanation methods, and facilitate human-AI collaboration. Participants are presented with static explanations, followed by a conversation with a human expert regarding the explanations. We measure the effect of the conversation on participants' ability to choose, from three machine learning models, the most accurate one based on explanations and their self-reported comprehension, acceptance, and trust. Empirical results show that conversations significantly improve comprehension, acceptance, trust, and collaboration. Our findings highlight the importance of customized model explanations in the format of free-form conversations and provide insights for the future design of conversational explanations. ",
    "url": "https://arxiv.org/abs/2309.13965",
    "authors": [
      "Tong Zhang",
      "X. Jessie Yang",
      "Boyang Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13970",
    "title": "A Cyberpunk 2077 perspective on the prediction and understanding of  future technology",
    "abstract": "Science fiction and video games have long served as valuable tools for envisioning and inspiring future technological advancements. This position paper investigates the potential of Cyberpunk 2077, a popular science fiction video game, to shed light on the future of technology, particularly in the areas of artificial intelligence, edge computing, augmented humans, and biotechnology. By analyzing the game's portrayal of these technologies and their implications, we aim to understand the possibilities and challenges that lie ahead. We discuss key themes such as neurolink and brain-computer interfaces, multimodal recording systems, virtual and simulated reality, digital representation of the physical world, augmented and AI-based home appliances, smart clothing, and autonomous vehicles. The paper highlights the importance of designing technologies that can coexist with existing preferences and systems, considering the uneven adoption of new technologies. Through this exploration, we emphasize the potential of science fiction and video games like Cyberpunk 2077 as tools for guiding future technological advancements and shaping public perception of emerging innovations. ",
    "url": "https://arxiv.org/abs/2309.13970",
    "authors": [
      "Miguel Bordallo L\u00f3pez",
      "Constantino \u00c1lvarez Casado"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2309.14006",
    "title": "Multiple evolutionary pressures shape identical consonant avoidance in  the world's languages",
    "abstract": "Languages disfavor word forms containing sequences of similar or identical consonants, due to the biomechanical and cognitive difficulties posed by patterns of this sort. However, the specific evolutionary processes responsible for this phenomenon are not fully understood. Words containing sequences of identical consonants may be more likely to arise than those without; processes of word form mutation may be more likely to remove than create sequences of identical consonants in word forms; finally, words containing identical consonants may die out more frequently than those without. Phylogenetic analyses of the evolution of homologous word forms indicate that words with identical consonants arise less frequently than those without, and processes which mutate word forms are more likely to remove sequences of identical consonants than introduce them. However, words with identical consonants do not die out more frequently than those without. Further analyses reveal that forms with identical consonants are replaced in basic meaning functions more frequently than words without. Taken together, results suggest that the under representation of sequences of identical consonants is overwhelmingly a byproduct of constraints on word form coinage, though processes related to word usage also serve to ensure that such patterns are infrequent in more salient vocabulary items. These findings clarify previously unknown aspects of processes of lexical evolution and competition that take place during language change, optimizing communicative systems. ",
    "url": "https://arxiv.org/abs/2309.14006",
    "authors": [
      "Chundra A. Cathcart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.14016",
    "title": "Virtuoso: High Resource Utilization and \u03bcs-scale Performance  Isolation in a Shared Virtual Machine TCP Network Stack",
    "abstract": "Virtualization improves resource efficiency and ensures security and performance isolation for cloud applications. To that end, operators today use a layered architecture that runs a separate network stack instance in each VM and container connected to a separate virtual switch. Decoupling through layering reduces complexity, but induces performance and resource overheads that are at odds with increasing demands for network bandwidth, communication requirements for large distributed applications, and low latency. We present Virtuoso, a new software networking stack for VMs and containers. Virtuoso performs a fundamental re-organization of the networking stack to maximize CPU utilization, enforce isolation, and minimize networking stack overheads. We maximize utilization by running one elastically shared network stack instance on dedicated cores; we enforce isolation by performing central and fine-grained per-packet resource accounting and scheduling; we reduce overheads by building a single-layer data path with a one-shot fast-path incorporating all processing from the TCP transport layer through network virtualization and virtual switching. Virtuoso improves resource utilization by up to 50%, latencies by up to 42% compared to other virtualized network stacks without sacrificing isolation, and keeps processing overhead within 11.5% of unvirtualized network stacks. ",
    "url": "https://arxiv.org/abs/2309.14016",
    "authors": [
      "Matheus Stolet",
      "Liam Arzola",
      "Simon Peter",
      "Antoine Kaufmann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2309.14021",
    "title": "LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot  Compression",
    "abstract": "Low Rank Decomposition of matrix - splitting a large matrix into a product of two smaller matrix offers a means for compression that reduces the parameters of a model without sparsification, and hence delivering more speedup on modern hardware. Moreover, unlike quantization, the compressed linear layers remain fully differentiable and all the parameters trainable, while being able to leverage the existing highly efficient kernels over floating point matrices. We study the potential to compress Large Language Models (LLMs) for monolingual Code generation via Low Rank Decomposition (LoRD) and observe that ranks for the linear layers in these models can be reduced by upto 39.58% with less than 1% increase in perplexity. We then use Low Rank Decomposition (LoRD) to compress StarCoder 16B to 13.2B parameter with no drop and to 12.3B with minimal drop in HumanEval Pass@1 score, in less than 10 minutes on a single A100. The compressed models speeds up inference by up to 22.35% with just a single line of change in code over huggingface's implementation with pytorch backend. Low Rank Decomposition (LoRD) models remain compatible with state of the art near-lossless quantization method such as SpQR, which allows leveraging further compression gains of quantization. Lastly, QLoRA over Low Rank Decomposition (LoRD) model further reduces memory requirements by as much as 21.2% over vanilla QLoRA while offering similar gains from parameter efficient fine tuning. Our work shows Low Rank Decomposition (LoRD) as a promising new paradigm for LLM compression. ",
    "url": "https://arxiv.org/abs/2309.14021",
    "authors": [
      "Ayush Kaushal",
      "Tejas Vaidhya",
      "Irina Rish"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.14022",
    "title": "Hashing Neural Video Decomposition with Multiplicative Residuals in  Space-Time",
    "abstract": "We present a video decomposition method that facilitates layer-based editing of videos with spatiotemporally varying lighting and motion effects. Our neural model decomposes an input video into multiple layered representations, each comprising a 2D texture map, a mask for the original video, and a multiplicative residual characterizing the spatiotemporal variations in lighting conditions. A single edit on the texture maps can be propagated to the corresponding locations in the entire video frames while preserving other contents' consistencies. Our method efficiently learns the layer-based neural representations of a 1080p video in 25s per frame via coordinate hashing and allows real-time rendering of the edited result at 71 fps on a single GPU. Qualitatively, we run our method on various videos to show its effectiveness in generating high-quality editing effects. Quantitatively, we propose to adopt feature-tracking evaluation metrics for objectively assessing the consistency of video editing. Project page: https://lightbulb12294.github.io/hashing-nvd/ ",
    "url": "https://arxiv.org/abs/2309.14022",
    "authors": [
      "Cheng-Hung Chan",
      "Cheng-Yang Yuan",
      "Cheng Sun",
      "Hwann-Tzong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14037",
    "title": "An automatic selection of optimal recurrent neural network architecture  for processes dynamics modelling purposes",
    "abstract": "A problem related to the development of algorithms designed to find the structure of artificial neural network used for behavioural (black-box) modelling of selected dynamic processes has been addressed in this paper. The research has included four original proposals of algorithms dedicated to neural network architecture search. Algorithms have been based on well-known optimisation techniques such as evolutionary algorithms and gradient descent methods. In the presented research an artificial neural network of recurrent type has been used, whose architecture has been selected in an optimised way based on the above-mentioned algorithms. The optimality has been understood as achieving a trade-off between the size of the neural network and its accuracy in capturing the response of the mathematical model under which it has been learnt. During the optimisation, original specialised evolutionary operators have been proposed. The research involved an extended validation study based on data generated from a mathematical model of the fast processes occurring in a pressurised water nuclear reactor. ",
    "url": "https://arxiv.org/abs/2309.14037",
    "authors": [
      "Krzysztof Laddach",
      "Rafa\u0142 \u0141angowski",
      "Tomasz A. Rutkowski",
      "Bartosz Puchalski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.14049",
    "title": "How Novices Use LLM-Based Code Generators to Solve CS1 Coding Tasks in a  Self-Paced Learning Environment",
    "abstract": "As Large Language Models (LLMs) gain in popularity, it is important to understand how novice programmers use them. We present a thematic analysis of 33 learners, aged 10-17, independently learning Python through 45 code-authoring tasks using Codex, an LLM-based code generator. We explore several questions related to how learners used these code generators and provide an analysis of the properties of the written prompts and the generated code. Specifically, we explore (A) the context in which learners use Codex, (B) what learners are asking from Codex, (C) properties of their prompts in terms of relation to task description, language, and clarity, and prompt crafting patterns, (D) the correctness, complexity, and accuracy of the AI-generated code, and (E) how learners utilize AI-generated code in terms of placement, verification, and manual modifications. Furthermore, our analysis reveals four distinct coding approaches when writing code with an AI code generator: AI Single Prompt, where learners prompted Codex once to generate the entire solution to a task; AI Step-by-Step, where learners divided the problem into parts and used Codex to generate each part; Hybrid, where learners wrote some of the code themselves and used Codex to generate others; and Manual coding, where learners wrote the code themselves. The AI Single Prompt approach resulted in the highest correctness scores on code-authoring tasks, but the lowest correctness scores on subsequent code-modification tasks during training. Our results provide initial insight into how novice learners use AI code generators and the challenges and opportunities associated with integrating them into self-paced learning environments. We conclude with various signs of over-reliance and self-regulation, as well as opportunities for curriculum and tool development. ",
    "url": "https://arxiv.org/abs/2309.14049",
    "authors": [
      "Majeed Kazemitabaar",
      "Xinying Hou",
      "Austin Henley",
      "Barbara J. Ericson",
      "David Weintrop",
      "Tovi Grossman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.14050",
    "title": "NNgTL: Neural Network Guided Optimal Temporal Logic Task Planning for  Mobile Robots",
    "abstract": "In this work, we investigate task planning for mobile robots under linear temporal logic (LTL) specifications. This problem is particularly challenging when robots navigate in continuous workspaces due to the high computational complexity involved. Sampling-based methods have emerged as a promising avenue for addressing this challenge by incrementally constructing random trees, thereby sidestepping the need to explicitly explore the entire state-space. However, the performance of this sampling-based approach hinges crucially on the chosen sampling strategy, and a well-informed heuristic can notably enhance sample efficiency. In this work, we propose a novel neural-network guided (NN-guided) sampling strategy tailored for LTL planning. Specifically, we employ a multi-modal neural network capable of extracting features concurrently from both the workspace and the B\\\"{u}chi automaton. This neural network generates predictions that serve as guidance for random tree construction, directing the sampling process toward more optimal directions. Through numerical experiments, we compare our approach with existing methods and demonstrate its superior efficiency, requiring less than 15% of the time of the existing methods to find a feasible solution. ",
    "url": "https://arxiv.org/abs/2309.14050",
    "authors": [
      "Ruijia Liu",
      "Shaoyuan Li",
      "Xiang Yin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.14053",
    "title": "Revisiting LARS for Large Batch Training Generalization of Neural  Networks",
    "abstract": "LARS and LAMB have emerged as prominent techniques in Large Batch Learning (LBL), ensuring the stability of AI training. One of the primary challenges in LBL is convergence stability, where the AI agent usually gets trapped into the sharp minimizer. Addressing this challenge, a relatively recent technique, known as warm-up, has been employed. However, warm-up lacks a strong theoretical foundation, leaving the door open for further exploration of more efficacious algorithms. In light of this situation, we conduct empirical experiments to analyze the behaviors of the two most popular optimizers in the LARS family: LARS and LAMB, with and without a warm-up strategy. Our analyses give us a comprehension of the novel LARS, LAMB, and the necessity of a warm-up technique in LBL. Building upon these insights, we propose a novel algorithm called Time Varying LARS (TVLARS), which facilitates robust training in the initial phase without the need for warm-up. Experimental evaluation demonstrates that TVLARS achieves competitive results with LARS and LAMB when warm-up is utilized while surpassing their performance without the warm-up technique. ",
    "url": "https://arxiv.org/abs/2309.14053",
    "authors": [
      "Khoi Do",
      "Duong Nguyen",
      "Hoa Nguyen",
      "Long Tran-Thanh",
      "Quoc-Viet Pham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.14054",
    "title": "Adapt then Unlearn: Exploiting Parameter Space Semantics for Unlearning  in Generative Adversarial Networks",
    "abstract": "The increased attention to regulating the outputs of deep generative models, driven by growing concerns about privacy and regulatory compliance, has highlighted the need for effective control over these models. This necessity arises from instances where generative models produce outputs containing undesirable, offensive, or potentially harmful content. To tackle this challenge, the concept of machine unlearning has emerged, aiming to forget specific learned information or to erase the influence of undesired data subsets from a trained model. The objective of this work is to prevent the generation of outputs containing undesired features from a pre-trained GAN where the underlying training data set is inaccessible. Our approach is inspired by a crucial observation: the parameter space of GANs exhibits meaningful directions that can be leveraged to suppress specific undesired features. However, such directions usually result in the degradation of the quality of generated samples. Our proposed method, known as 'Adapt-then-Unlearn,' excels at unlearning such undesirable features while also maintaining the quality of generated samples. This method unfolds in two stages: in the initial stage, we adapt the pre-trained GAN using negative samples provided by the user, while in the subsequent stage, we focus on unlearning the undesired feature. During the latter phase, we train the pre-trained GAN using positive samples, incorporating a repulsion regularizer. This regularizer encourages the model's parameters to be away from the parameters associated with the adapted model from the first stage while also maintaining the quality of generated samples. To the best of our knowledge, our approach stands as first method addressing unlearning in GANs. We validate the effectiveness of our method through comprehensive experiments. ",
    "url": "https://arxiv.org/abs/2309.14054",
    "authors": [
      "Piyush Tiwary",
      "Atri Guha",
      "Subhodip Panda",
      "Prathosh A.P"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14057",
    "title": "Weakly Supervised Semantic Segmentation by Knowledge Graph Inference",
    "abstract": "Currently, existing efforts in Weakly Supervised Semantic Segmentation (WSSS) based on Convolutional Neural Networks (CNNs) have predominantly focused on enhancing the multi-label classification network stage, with limited attention given to the equally important downstream segmentation network. Furthermore, CNN-based local convolutions lack the ability to model the extensive inter-category dependencies. Therefore, this paper introduces a graph reasoning-based approach to enhance WSSS. The aim is to improve WSSS holistically by simultaneously enhancing both the multi-label classification and segmentation network stages. In the multi-label classification network segment, external knowledge is integrated, coupled with GCNs, to globally reason about inter-class dependencies. This encourages the network to uncover features in non-salient regions of images, thereby refining the completeness of generated pseudo-labels. In the segmentation network segment, the proposed Graph Reasoning Mapping (GRM) module is employed to leverage knowledge obtained from textual databases, facilitating contextual reasoning for class representation within image regions. This GRM module enhances feature representation in high-level semantics of the segmentation network's local convolutions, while dynamically learning semantic coherence for individual samples. Using solely image-level supervision, we have achieved state-of-the-art performance in WSSS on the PASCAL VOC 2012 and MS-COCO datasets. Extensive experimentation on both the multi-label classification and segmentation network stages underscores the effectiveness of the proposed graph reasoning approach for advancing WSSS. ",
    "url": "https://arxiv.org/abs/2309.14057",
    "authors": [
      "Jia Zhang",
      "Bo Peng",
      "Xi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14065",
    "title": "AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation",
    "abstract": "In the realm of robotic intelligence, achieving efficient and precise RGB-D semantic segmentation is a key cornerstone. State-of-the-art multimodal semantic segmentation methods, primarily rooted in symmetrical skeleton networks, find it challenging to harmonize computational efficiency and precision. In this work, we propose AsymFormer, a novel network for real-time RGB-D semantic segmentation, which targets the minimization of superfluous parameters by optimizing the distribution of computational resources and introduces an asymmetrical backbone to allow for the effective fusion of multimodal features. Furthermore, we explore techniques to bolster network accuracy by redefining feature selection and extracting multi-modal self-similarity features without a substantial increase in the parameter count, thereby ensuring real-time execution on robotic platforms. Additionally, a Local Attention-Guided Feature Selection (LAFS) module is used to selectively fuse features from different modalities by leveraging their dependencies. Subsequently, a Cross-Modal Attention-Guided Feature Correlation Embedding (CMA) module is introduced to further extract cross-modal representations. This method is evaluated on NYUv2 and SUNRGBD datasets, with AsymFormer demonstrating competitive results with 52.0\\% mIoU on NYUv2 and 49.1\\% mIoU on SUNRGBD. Notably, AsymFormer achieves an inference speed of 65 FPS and after implementing mixed precision quantization, it attains an impressive inference speed of 79 FPS on RTX3090. This significantly outperforms existing multi-modal methods, thereby demonstrating that AsymFormer can strike a balance between high accuracy and efficiency for RGB-D semantic segmentation. ",
    "url": "https://arxiv.org/abs/2309.14065",
    "authors": [
      "Siqi Du",
      "Weixi Wang",
      "Renzhong Guo",
      "Shengjun Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14072",
    "title": "BoIR: Box-Supervised Instance Representation for Multi-Person Pose  Estimation",
    "abstract": "Single-stage multi-person human pose estimation (MPPE) methods have shown great performance improvements, but existing methods fail to disentangle features by individual instances under crowded scenes. In this paper, we propose a bounding box-level instance representation learning called BoIR, which simultaneously solves instance detection, instance disentanglement, and instance-keypoint association problems. Our new instance embedding loss provides a learning signal on the entire area of the image with bounding box annotations, achieving globally consistent and disentangled instance representation. Our method exploits multi-task learning of bottom-up keypoint estimation, bounding box regression, and contrastive instance embedding learning, without additional computational cost during inference. BoIR is effective for crowded scenes, outperforming state-of-the-art on COCO val (0.8 AP), COCO test-dev (0.5 AP), CrowdPose (4.9 AP), and OCHuman (3.5 AP). Code will be available at https://github.com/uyoung-jeong/BoIR ",
    "url": "https://arxiv.org/abs/2309.14072",
    "authors": [
      "Uyoung Jeong",
      "Seungryul Baek",
      "Hyung Jin Chang",
      "Kwang In Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14090",
    "title": "Convolutional autoencoder-based multimodal one-class classification",
    "abstract": "One-class classification refers to approaches of learning using data from a single class only. In this paper, we propose a deep learning one-class classification method suitable for multimodal data, which relies on two convolutional autoencoders jointly trained to reconstruct the positive input data while obtaining the data representations in the latent space as compact as possible. During inference, the distance of the latent representation of an input to the origin can be used as an anomaly score. Experimental results using a multimodal macroinvertebrate image classification dataset show that the proposed multimodal method yields better results as compared to the unimodal approach. Furthermore, study the effect of different input image sizes, and we investigate how recently proposed feature diversity regularizers affect the performance of our approach. We show that such regularizers improve performance. ",
    "url": "https://arxiv.org/abs/2309.14090",
    "authors": [
      "Firas Laakom",
      "Fahad Sohrab",
      "Jenni Raitoharju",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14118",
    "title": "MultiModN- Multimodal, Multi-Task, Interpretable Modular Networks",
    "abstract": "Predicting multiple real-world tasks in a single model often requires a particularly diverse feature space. Multimodal (MM) models aim to extract the synergistic predictive potential of multiple data types to create a shared feature space with aligned semantic meaning across inputs of drastically varying sizes (i.e. images, text, sound). Most current MM architectures fuse these representations in parallel, which not only limits their interpretability but also creates a dependency on modality availability. We present MultiModN, a multimodal, modular network that fuses latent representations in a sequence of any number, combination, or type of modality while providing granular real-time predictive feedback on any number or combination of predictive tasks. MultiModN's composable pipeline is interpretable-by-design, as well as innately multi-task and robust to the fundamental issue of biased missingness. We perform four experiments on several benchmark MM datasets across 10 real-world tasks (predicting medical diagnoses, academic performance, and weather), and show that MultiModN's sequential MM fusion does not compromise performance compared with a baseline of parallel fusion. By simulating the challenging bias of missing not-at-random (MNAR), this work shows that, contrary to MultiModN, parallel fusion baselines erroneously learn MNAR and suffer catastrophic failure when faced with different patterns of MNAR at inference. To the best of our knowledge, this is the first inherently MNAR-resistant approach to MM modeling. In conclusion, MultiModN provides granular insights, robustness, and flexibility without compromising performance. ",
    "url": "https://arxiv.org/abs/2309.14118",
    "authors": [
      "Vinitra Swamy",
      "Malika Satayeva",
      "Jibril Frej",
      "Thierry Bossy",
      "Thijs Vogels",
      "Martin Jaggi",
      "Tanja K\u00e4ser",
      "Mary-Anne Hartley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14130",
    "title": "On the Relation between Internal Language Model and Sequence  Discriminative Training for Neural Transducers",
    "abstract": "Internal language model (ILM) subtraction has been widely applied to improve the performance of the RNN-Transducer with external language model (LM) fusion for speech recognition. In this work, we show that sequence discriminative training has a strong correlation with ILM subtraction from both theoretical and empirical points of view. Theoretically, we derive that the global optimum of maximum mutual information (MMI) training shares a similar formula as ILM subtraction. Empirically, we show that ILM subtraction and sequence discriminative training achieve similar performance across a wide range of experiments on Librispeech, including both MMI and minimum Bayes risk (MBR) criteria, as well as neural transducers and LMs of both full and limited context. The benefit of ILM subtraction also becomes much smaller after sequence discriminative training. We also provide an in-depth study to show that sequence discriminative training has a minimal effect on the commonly used zero-encoder ILM estimation, but a joint effect on both encoder and prediction + joint network for posterior probability reshaping including both ILM and blank suppression. ",
    "url": "https://arxiv.org/abs/2309.14130",
    "authors": [
      "Zijian Yang",
      "Wei Zhou",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.14134",
    "title": "One-Class Classification for Intrusion Detection on Vehicular Networks",
    "abstract": "Controller Area Network bus systems within vehicular networks are not equipped with the tools necessary to ward off and protect themselves from modern cyber-security threats. Work has been done on using machine learning methods to detect and report these attacks, but common methods are not robust towards unknown attacks. These methods usually rely on there being a sufficient representation of attack data, which may not be available due to there either not being enough data present to adequately represent its distribution or the distribution itself is too diverse in nature for there to be a sufficient representation of it. With the use of one-class classification methods, this issue can be mitigated as only normal data is required to train a model for the detection of anomalous instances. Research has been done on the efficacy of these methods, most notably One-Class Support Vector Machine and Support Vector Data Description, but many new extensions of these works have been proposed and have yet to be tested for injection attacks in vehicular networks. In this paper, we investigate the performance of various state-of-the-art one-class classification methods for detecting injection attacks on Controller Area Network bus traffic. We investigate the effectiveness of these techniques on attacks launched on Controller Area Network buses from two different vehicles during normal operation and while being attacked. We observe that the Subspace Support Vector Data Description method outperformed all other tested methods with a Gmean of about 85%. ",
    "url": "https://arxiv.org/abs/2309.14134",
    "authors": [
      "Jake Guidry",
      "Fahad Sohrab",
      "Raju Gottumukkala",
      "Satya Katragadda",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.14146",
    "title": "Examining Temporal Bias in Abusive Language Detection",
    "abstract": "The use of abusive language online has become an increasingly pervasive problem that damages both individuals and society, with effects ranging from psychological harm right through to escalation to real-life violence and even death. Machine learning models have been developed to automatically detect abusive language, but these models can suffer from temporal bias, the phenomenon in which topics, language use or social norms change over time. This study aims to investigate the nature and impact of temporal bias in abusive language detection across various languages and explore mitigation methods. We evaluate the performance of models on abusive data sets from different time periods. Our results demonstrate that temporal bias is a significant challenge for abusive language detection, with models trained on historical data showing a significant drop in performance over time. We also present an extensive linguistic analysis of these abusive data sets from a diachronic perspective, aiming to explore the reasons for language evolution and performance decline. This study sheds light on the pervasive issue of temporal bias in abusive language detection across languages, offering crucial insights into language evolution and temporal bias mitigation. ",
    "url": "https://arxiv.org/abs/2309.14146",
    "authors": [
      "Mali Jin",
      "Yida Mu",
      "Diana Maynard",
      "Kalina Bontcheva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.14149",
    "title": "Multi-Domain Adaptation by Self-Supervised Learning for Speaker  Verification",
    "abstract": "In real-world applications, speaker recognition models often face various domain-mismatch challenges, leading to a significant drop in performance. Although numerous domain adaptation techniques have been developed to address this issue, almost all present methods focus on a simple configuration where the model is trained in one domain and deployed in another. However, real-world environments are often complex and may contain multiple domains, making the methods designed for one-to-one adaptation suboptimal. In our paper, we propose a self-supervised learning method to tackle this multi-domain adaptation problem. Building upon the basic self-supervised adaptation algorithm, we designed three strategies to make it suitable for multi-domain adaptation: an in-domain negative sampling strategy, a MoCo-like memory bank scheme, and a CORAL-like distribution alignment. We conducted experiments using VoxCeleb2 as the source domain dataset and CN-Celeb1 as the target multi-domain dataset. Our results demonstrate that our method clearly outperforms the basic self-supervised adaptation method, which simply treats the data of CN-Celeb1 as a single domain. Importantly, the improvement is consistent in nearly all in-domain tests and cross-domain tests, demonstrating the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2309.14149",
    "authors": [
      "Wan Lin",
      "Lantian Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.14174",
    "title": "Only 5\\% Attention Is All You Need: Efficient Long-range Document-level  Neural Machine Translation",
    "abstract": "Document-level Neural Machine Translation (DocNMT) has been proven crucial for handling discourse phenomena by introducing document-level context information. One of the most important directions is to input the whole document directly to the standard Transformer model. In this case, efficiency becomes a critical concern due to the quadratic complexity of the attention module. Existing studies either focus on the encoder part, which cannot be deployed on sequence-to-sequence generation tasks, e.g., Machine Translation (MT), or suffer from a significant performance drop. In this work, we keep the translation performance while gaining 20\\% speed up by introducing extra selection layer based on lightweight attention that selects a small portion of tokens to be attended. It takes advantage of the original attention to ensure performance and dimension reduction to accelerate inference. Experimental results show that our method could achieve up to 95\\% sparsity (only 5\\% tokens attended) approximately, and save 93\\% computation cost on the attention module compared with the original Transformer, while maintaining the performance. ",
    "url": "https://arxiv.org/abs/2309.14174",
    "authors": [
      "Zihan Liu",
      "Zewei Sun",
      "Shanbo Cheng",
      "Shujian Huang",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.14198",
    "title": "(Predictable) Performance Bias in Unsupervised Anomaly Detection",
    "abstract": "Background: With the ever-increasing amount of medical imaging data, the demand for algorithms to assist clinicians has amplified. Unsupervised anomaly detection (UAD) models promise to aid in the crucial first step of disease detection. While previous studies have thoroughly explored fairness in supervised models in healthcare, for UAD, this has so far been unexplored. Methods: In this study, we evaluated how dataset composition regarding subgroups manifests in disparate performance of UAD models along multiple protected variables on three large-scale publicly available chest X-ray datasets. Our experiments were validated using two state-of-the-art UAD models for medical images. Finally, we introduced a novel subgroup-AUROC (sAUROC) metric, which aids in quantifying fairness in machine learning. Findings: Our experiments revealed empirical \"fairness laws\" (similar to \"scaling laws\" for Transformers) for training-dataset composition: Linear relationships between anomaly detection performance within a subpopulation and its representation in the training data. Our study further revealed performance disparities, even in the case of balanced training data, and compound effects that exacerbate the drop in performance for subjects associated with multiple adversely affected groups. Interpretation: Our study quantified the disparate performance of UAD models against certain demographic subgroups. Importantly, we showed that this unfairness cannot be mitigated by balanced representation alone. Instead, the representation of some subgroups seems harder to learn by UAD models than that of others. The empirical fairness laws discovered in our study make disparate performance in UAD models easier to estimate and aid in determining the most desirable dataset composition. ",
    "url": "https://arxiv.org/abs/2309.14198",
    "authors": [
      "Felix Meissen",
      "Svenja Breuer",
      "Moritz Knolle",
      "Alena Buyx",
      "Ruth M\u00fcller",
      "Georgios Kaissis",
      "Benedikt Wiestler",
      "Daniel R\u00fcckert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.14208",
    "title": "Framework based on complex networks to model and mine patient pathways",
    "abstract": "The automatic discovery of a model to represent the history of encounters of a group of patients with the healthcare system -- the so-called ``pathway of patients'' -- is a new field of research that supports clinical and organisational decisions to improve the quality and efficiency of the treatment provided. The pathways of patients with chronic conditions tend to vary significantly from one person to another, have repetitive tasks, and demand the analysis of multiple perspectives (interventions, diagnoses, medical specialities, among others) influencing the results. Therefore, modelling and mining those pathways is still a challenging task. In this work, we propose a framework comprising: (i) a pathway model based on a multi-aspect graph, (ii) a novel dissimilarity measurement to compare pathways taking the elapsed time into account, and (iii) a mining method based on traditional centrality measures to discover the most relevant steps of the pathways. We evaluated the framework using the study cases of pregnancy and diabetes, which revealed its usefulness in finding clusters of similar pathways, representing them in an easy-to-interpret way, and highlighting the most significant patterns according to multiple perspectives. ",
    "url": "https://arxiv.org/abs/2309.14208",
    "authors": [
      "Caroline de Oliveira Costa Souza Rosa",
      "M\u00e1rcia Ito",
      "Alex Borges Vieira",
      "Klaus Wehmuth",
      "Ant\u00f4nio Tadeu Azevedo Gomes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14211",
    "title": "QuadricsNet: Learning Concise Representation for Geometric Primitives in  Point Clouds",
    "abstract": "This paper presents a novel framework to learn a concise geometric primitive representation for 3D point clouds. Different from representing each type of primitive individually, we focus on the challenging problem of how to achieve a concise and uniform representation robustly. We employ quadrics to represent diverse primitives with only 10 parameters and propose the first end-to-end learning-based framework, namely QuadricsNet, to parse quadrics in point clouds. The relationships between quadrics mathematical formulation and geometric attributes, including the type, scale and pose, are insightfully integrated for effective supervision of QuaidricsNet. Besides, a novel pattern-comprehensive dataset with quadrics segments and objects is collected for training and evaluation. Experiments demonstrate the effectiveness of our concise representation and the robustness of QuadricsNet. Our code is available at \\url{https://github.com/MichaelWu99-lab/QuadricsNet} ",
    "url": "https://arxiv.org/abs/2309.14211",
    "authors": [
      "Ji Wu",
      "Huai Yu",
      "Wen Yang",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14225",
    "title": "HumanMimic: Learning Natural Locomotion and Transitions for Humanoid  Robot via Wasserstein Adversarial Imitation",
    "abstract": "Transferring human motion skills to humanoid robots remains a significant challenge. In this study, we introduce a Wasserstein adversarial imitation learning system, allowing humanoid robots to replicate natural whole-body locomotion patterns and execute seamless transitions by mimicking human motions. First, we present a unified primitive-skeleton motion retargeting to mitigate morphological differences between arbitrary human demonstrators and humanoid robots. An adversarial critic component is integrated with Reinforcement Learning (RL) to guide the control policy to produce behaviors aligned with the data distribution of mixed reference motions. Additionally, we employ a specific Integral Probabilistic Metric (IPM), namely the Wasserstein-1 distance with a novel soft boundary constraint to stabilize the training process and prevent model collapse. Our system is evaluated on a full-sized humanoid JAXON in the simulator. The resulting control policy demonstrates a wide range of locomotion patterns, including standing, push-recovery, squat walking, human-like straight-leg walking, and dynamic running. Notably, even in the absence of transition motions in the demonstration dataset, robots showcase an emerging ability to transit naturally between distinct locomotion patterns as desired speed changes. ",
    "url": "https://arxiv.org/abs/2309.14225",
    "authors": [
      "Annan Tang",
      "Takuma Hiraoka",
      "Naoki Hiraoka",
      "Fan Shi",
      "Kento Kawaharazuka",
      "Kunio Kojima",
      "Kei Okada",
      "Masayuki Inaba"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.14241",
    "title": "Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation",
    "abstract": "Contemporary domain adaptation offers a practical solution for achieving cross-domain transfer of semantic segmentation between labeled source data and unlabeled target data. These solutions have gained significant popularity; however, they require the model to be retrained when the test environment changes. This can result in unbearable costs in certain applications due to the time-consuming training process and concerns regarding data privacy. One-shot domain adaptation methods attempt to overcome these challenges by transferring the pre-trained source model to the target domain using only one target data. Despite this, the referring style transfer module still faces issues with computation cost and over-fitting problems. To address this problem, we propose a novel framework called Informative Data Mining (IDM) that enables efficient one-shot domain adaptation for semantic segmentation. Specifically, IDM provides an uncertainty-based selection criterion to identify the most informative samples, which facilitates quick adaptation and reduces redundant training. We then perform a model adaptation method using these selected samples, which includes patch-wise mixing and prototype-based information maximization to update the model. This approach effectively enhances adaptation and mitigates the overfitting problem. In general, we provide empirical evidence of the effectiveness and efficiency of IDM. Our approach outperforms existing methods and achieves a new state-of-the-art one-shot performance of 56.7\\%/55.4\\% on the GTA5/SYNTHIA to Cityscapes adaptation tasks, respectively. The code will be released at \\url{https://github.com/yxiwang/IDM}. ",
    "url": "https://arxiv.org/abs/2309.14241",
    "authors": [
      "Yuxi Wang",
      "Jian Liang",
      "Jun Xiao",
      "Shuqi Mei",
      "Yuran Yang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14263",
    "title": "Target Controllability and Target Observability of Structured Network  Systems",
    "abstract": "The duality between controllability and observability enables methods developed for full-state control to be applied to full-state estimation, and vice versa. In applications in which control or estimation of all state variables is unfeasible, the generalized notions of output controllability and functional observability establish the minimal conditions for the control and estimation of a target subset of state variables, respectively. Given the seemly unrelated nature of these properties, thus far methods for target control and target estimation have been developed independently in the literature. Here, we characterize the graph-theoretic conditions for target controllability and target observability (which are, respectively, special cases of output controllability and functional observability for structured systems). This allow us to rigorously establish a weak and strong duality between these generalized properties. When both properties are equivalent (strongly dual), we show that efficient algorithms developed for target controllability can be used for target observability, and vice versa, for the optimal placement of sensors and drivers. These results are applicable to large-scale networks, in which control and monitoring are often sought for small subsets of nodes. ",
    "url": "https://arxiv.org/abs/2309.14263",
    "authors": [
      "Arthur N. Montanari",
      "Chao Duan",
      "Adilson E. Motter"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2309.14293",
    "title": "NAS-NeRF: Generative Neural Architecture Search for Neural Radiance  Fields",
    "abstract": "Neural radiance fields (NeRFs) enable high-quality novel view synthesis, but their prohibitively high computational complexity limits deployability, especially on resource-constrained platforms. To enable practical usage of NeRFs, quality tuning is essential to reduce computational complexity, akin to adjustable graphics settings in video games. However while existing solutions strive for efficiency, they use one-size-fits-all architectures regardless of scene complexity, although the same architecture may be unnecessarily large for simple scenes but insufficient for complex ones. Thus as NeRFs become more widely used for 3D visualization, there is a need to dynamically optimize the neural network component of NeRFs to achieve a balance between computational complexity and specific targets for synthesis quality. Addressing this gap, we introduce NAS-NeRF: a generative neural architecture search strategy uniquely tailored to generate NeRF architectures on a per-scene basis by optimizing the trade-off between complexity and performance, while adhering to constraints on computational budget and minimum synthesis quality. Our experiments on the Blender synthetic dataset show the proposed NAS-NeRF can generate architectures up to 5.74$\\times$ smaller, with 4.19$\\times$ fewer FLOPs, and 1.93$\\times$ faster on a GPU than baseline NeRFs, without suffering a drop in SSIM. Furthermore, we illustrate that NAS-NeRF can also achieve architectures up to 23$\\times$ smaller, 22$\\times$ fewer FLOPs, and 4.7$\\times$ faster than baseline NeRFs with only a 5.3\\% average SSIM drop. The source code for our work is also made publicly available at https://saeejithnair.github.io/NAS-NeRF. ",
    "url": "https://arxiv.org/abs/2309.14293",
    "authors": [
      "Saeejith Nair",
      "Yuhao Chen",
      "Mohammad Javad Shafiee",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14317",
    "title": "Online and Offline Dynamic Influence Maximization Games Over Social  Networks",
    "abstract": "In this work, we consider dynamic influence maximization games over social networks with multiple players (influencers). The goal of each influencer is to maximize their own reward subject to their limited total budget rate constraints. Thus, influencers need to carefully design their investment policies considering individuals' opinion dynamics and other influencers' investment strategies, leading to a dynamic game problem. We first consider the case of a single influencer who wants to maximize its utility subject to a total budget rate constraint. We study both offline and online versions of the problem where the opinion dynamics are either known or not known a priori. In the singe-influencer case, we propose an online no-regret algorithm, meaning that as the number of campaign opportunities grows, the average utilities obtained by the offline and online solutions converge. Then, we consider the game formulation with multiple influencers in offline and online settings. For the offline setting, we show that the dynamic game admits a unique Nash equilibrium policy and provide a method to compute it. For the online setting and with two influencers, we show that if each influencer applies the same no-regret online algorithm proposed for the single-influencer maximization problem, they will converge to the set of $\\epsilon$-Nash equilibrium policies where $\\epsilon=O(\\frac{1}{\\sqrt{K}})$ scales in average inversely with the number of campaign times $K$ considering the average utilities of the influencers. Moreover, we extend this result to any finite number of influencers under more strict requirements on the information structure. Finally, we provide numerical analysis to validate our results under various settings. ",
    "url": "https://arxiv.org/abs/2309.14317",
    "authors": [
      "Melih Bastopcu",
      "S. Rasoul Etesami",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.14327",
    "title": "DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention",
    "abstract": "Most of the existing multi-modal models, hindered by their incapacity to adeptly manage interleaved image-and-text inputs in multi-image, multi-round dialogues, face substantial constraints in resource allocation for training and data accessibility, impacting their adaptability and scalability across varied interaction realms. To address this, we present the DeepSpeed-VisualChat framework, designed to optimize Large Language Models (LLMs) by incorporating multi-modal capabilities, with a focus on enhancing the proficiency of Large Vision and Language Models in handling interleaved inputs. Our framework is notable for (1) its open-source support for multi-round and multi-image dialogues, (2) introducing an innovative multi-modal causal attention mechanism, and (3) utilizing data blending techniques on existing datasets to assure seamless interactions in multi-round, multi-image conversations. Compared to existing frameworks, DeepSpeed-VisualChat shows superior scalability up to 70B parameter language model size, representing a significant advancement in multi-modal language models and setting a solid foundation for future explorations. ",
    "url": "https://arxiv.org/abs/2309.14327",
    "authors": [
      "Zhewei Yao",
      "Xiaoxia Wu",
      "Conglong Li",
      "Minjia Zhang",
      "Heyang Qi",
      "Olatunji Ruwase",
      "Ammar Ahmad Awan",
      "Samyam Rajbhandari",
      "Yuxiong He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.14331",
    "title": "LinGCN: Structural Linearized Graph Convolutional Network for  Homomorphically Encrypted Inference",
    "abstract": "The growth of Graph Convolution Network (GCN) model sizes has revolutionized numerous applications, surpassing human performance in areas such as personal healthcare and financial systems. The deployment of GCNs in the cloud raises privacy concerns due to potential adversarial attacks on client data. To address security concerns, Privacy-Preserving Machine Learning (PPML) using Homomorphic Encryption (HE) secures sensitive client data. However, it introduces substantial computational overhead in practical applications. To tackle those challenges, we present LinGCN, a framework designed to reduce multiplication depth and optimize the performance of HE based GCN inference. LinGCN is structured around three key elements: (1) A differentiable structural linearization algorithm, complemented by a parameterized discrete indicator function, co-trained with model weights to meet the optimization goal. This strategy promotes fine-grained node-level non-linear location selection, resulting in a model with minimized multiplication depth. (2) A compact node-wise polynomial replacement policy with a second-order trainable activation function, steered towards superior convergence by a two-level distillation approach from an all-ReLU based teacher model. (3) an enhanced HE solution that enables finer-grained operator fusion for node-wise activation functions, further reducing multiplication level consumption in HE-based inference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that LinGCN excels in latency, accuracy, and scalability for homomorphically encrypted inference, outperforming solutions such as CryptoGCN. Remarkably, LinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving an inference accuracy of 75% and notably reducing multiplication depth. ",
    "url": "https://arxiv.org/abs/2309.14331",
    "authors": [
      "Hongwu Peng",
      "Ran Ran",
      "Yukui Luo",
      "Jiahui Zhao",
      "Shaoyi Huang",
      "Kiran Thorat",
      "Tong Geng",
      "Chenghong Wang",
      "Xiaolin Xu",
      "Wujie Wen",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.13108",
    "title": "Data is often loadable in short depth: Quantum circuits from tensor  networks for finance, images, fluids, and proteins",
    "abstract": "Though there has been substantial progress in developing quantum algorithms to study classical datasets, the cost of simply loading classical data is an obstacle to quantum advantage. When the amplitude encoding is used, loading an arbitrary classical vector requires up to exponential circuit depths with respect to the number of qubits. Here, we address this ``input problem'' with two contributions. First, we introduce a circuit compilation method based on tensor network (TN) theory. Our method -- AMLET (Automatic Multi-layer Loader Exploiting TNs) -- proceeds via careful construction of a specific TN topology and can be tailored to arbitrary circuit depths. Second, we perform numerical experiments on real-world classical data from four distinct areas: finance, images, fluid mechanics, and proteins. To the best of our knowledge, this is the broadest numerical analysis to date of loading classical data into a quantum computer. Consistent with other recent work in this area, the required circuit depths are often several orders of magnitude lower than the exponentially-scaling general loading algorithm would require. Besides introducing a more efficient loading algorithm, this work demonstrates that many classical datasets are loadable in depths that are much shorter than previously expected, which has positive implications for speeding up classical workloads on quantum computers. ",
    "url": "https://arxiv.org/abs/2309.13108",
    "authors": [
      "Raghav Jumade",
      "Nicolas PD Sawaya"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2309.13186",
    "title": "Deep Learning with Photonic Neural Cellular Automata",
    "abstract": "Rapid advancements in deep learning over the past decade have fueled an insatiable demand for efficient and scalable hardware. Photonics offers a promising solution by leveraging the unique properties of light. However, conventional neural network architectures, which typically require dense programmable connections, pose several practical challenges for photonic realizations. To overcome these limitations, we propose and experimentally demonstrate Photonic Neural Cellular Automata (PNCA) for photonic deep learning with sparse connectivity. PNCA harnesses the speed and interconnectivity of photonics, as well as the self-organizing nature of cellular automata through local interactions to achieve robust, reliable, and efficient processing. We utilize linear light interference and parametric nonlinear optics for all-optical computations in a time-multiplexed photonic network to experimentally perform self-organized image classification. We demonstrate binary classification of images in the fashion-MNIST dataset using as few as 3 programmable photonic parameters, achieving an experimental accuracy of 98.0% with the ability to also recognize out-of-distribution data. The proposed PNCA approach can be adapted to a wide range of existing photonic hardware and provides a compelling alternative to conventional photonic neural networks by maximizing the advantages of light-based computing whilst mitigating their practical challenges. Our results showcase the potential of PNCA in advancing photonic deep learning and highlights a path for next-generation photonic computers. ",
    "url": "https://arxiv.org/abs/2309.13186",
    "authors": [
      "Gordon H.Y. Li",
      "Christian R. Leefmans",
      "James Williams",
      "Robert M. Gray",
      "Midya Parto",
      "Alireza Marandi"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2309.13253",
    "title": "Contrastive Speaker Embedding With Sequential Disentanglement",
    "abstract": "Contrastive speaker embedding assumes that the contrast between the positive and negative pairs of speech segments is attributed to speaker identity only. However, this assumption is incorrect because speech signals contain not only speaker identity but also linguistic content. In this paper, we propose a contrastive learning framework with sequential disentanglement to remove linguistic content by incorporating a disentangled sequential variational autoencoder (DSVAE) into the conventional SimCLR framework. The DSVAE aims to disentangle speaker factors from content factors in an embedding space so that only the speaker factors are used for constructing a contrastive loss objective. Because content factors have been removed from the contrastive learning, the resulting speaker embeddings will be content-invariant. Experimental results on VoxCeleb1-test show that the proposed method consistently outperforms SimCLR. This suggests that applying sequential disentanglement is beneficial to learning speaker-discriminative embeddings. ",
    "url": "https://arxiv.org/abs/2309.13253",
    "authors": [
      "Youzhi Tu",
      "Man-Wai Mak",
      "Jen-Tzung Chien"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.13348",
    "title": "Accelerating Particle and Fluid Simulations with Differentiable Graph  Networks for Solving Forward and Inverse Problems",
    "abstract": "We leverage physics-embedded differentiable graph network simulators (GNS) to accelerate particulate and fluid simulations to solve forward and inverse problems. GNS represents the domain as a graph with particles as nodes and learned interactions as edges. Compared to modeling global dynamics, GNS enables learning local interaction laws through edge messages, improving its generalization to new environments. GNS achieves over 165x speedup for granular flow prediction compared to parallel CPU numerical simulations. We propose a novel hybrid GNS/Material Point Method (MPM) to accelerate forward simulations by minimizing error on a pure surrogate model by interleaving MPM in GNS rollouts to satisfy conservation laws and minimize errors achieving 24x speedup compared to pure numerical simulations. The differentiable GNS enables solving inverse problems through automatic differentiation, identifying material parameters that result in target runout distances. We demonstrate the ability of GNS to solve inverse problems by iteratively updating the friction angle (a material property) by computing the gradient of a loss function based on the final and target runouts, thereby identifying the friction angle that best matches the observed runout. The physics-embedded and differentiable simulators open an exciting new paradigm for AI-accelerated design, control, and optimization. ",
    "url": "https://arxiv.org/abs/2309.13348",
    "authors": [
      "Krishna Kumar",
      "Yongjin Choi"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2309.13385",
    "title": "Cine cardiac MRI reconstruction using a convolutional recurrent network  with refinement",
    "abstract": "Cine Magnetic Resonance Imaging (MRI) allows for understanding of the heart's function and condition in a non-invasive manner. Undersampling of the $k$-space is employed to reduce the scan duration, thus increasing patient comfort and reducing the risk of motion artefacts, at the cost of reduced image quality. In this challenge paper, we investigate the use of a convolutional recurrent neural network (CRNN) architecture to exploit temporal correlations in supervised cine cardiac MRI reconstruction. This is combined with a single-image super-resolution refinement module to improve single coil reconstruction by 4.4\\% in structural similarity and 3.9\\% in normalised mean square error compared to a plain CRNN implementation. We deploy a high-pass filter to our $\\ell_1$ loss to allow greater emphasis on high-frequency details which are missing in the original data. The proposed model demonstrates considerable enhancements compared to the baseline case and holds promising potential for further improving cardiac MRI reconstruction. ",
    "url": "https://arxiv.org/abs/2309.13385",
    "authors": [
      "Yuyang Xue",
      "Yuning Du",
      "Gianluca Carloni",
      "Eva Pachetti",
      "Connor Jordan",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13404",
    "title": "WS-YOLO: Weakly Supervised Yolo Network for Surgical Tool Localization  in Endoscopic Videos",
    "abstract": "Being able to automatically detect and track surgical instruments in endoscopic video recordings would allow for many useful applications that could transform different aspects of surgery. In robot-assisted surgery, the potentially informative data like categories of surgical tool can be captured, which is sparse, full of noise and without spatial information. We proposed a Weakly Supervised Yolo Network (WS-YOLO) for Surgical Tool Localization in Endoscopic Videos, to generate fine-grained semantic information with location and category from coarse-grained semantic information outputted by the da Vinci surgical robot, which significantly diminished the necessary human annotation labor while striking an optimal balance between the quantity of manually annotated data and detection performance. The source code is available at https://github.com/Breezewrf/Weakly-Supervised-Yolov8. ",
    "url": "https://arxiv.org/abs/2309.13404",
    "authors": [
      "Rongfeng Wei",
      "Jinlin Wu",
      "You Pang",
      "Zhen Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13459",
    "title": "A Model-Agnostic Graph Neural Network for Integrating Local and Global  Information",
    "abstract": "Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, existing GNNs suffer from two significant limitations: a lack of interpretability in results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to sequentially integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and important node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and showcase its power to represent layer-wise neighborhood mixing. We conduct comprehensive numerical studies using simulated data to demonstrate the superior performance of MaGNet in comparison to several state-of-the-art alternatives. Furthermore, we apply MaGNet to a real-world case study aimed at extracting task-critical information from brain activity data, thereby highlighting its effectiveness in advancing scientific research. ",
    "url": "https://arxiv.org/abs/2309.13459",
    "authors": [
      "Wenzhuo Zhou",
      "Annie Qu",
      "Keiland W. Cooper",
      "Norbert Fortin",
      "Babak Shahbaba"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13483",
    "title": "Enhancing Prediction and Analysis of UK Road Traffic Accident Severity  Using AI: Integration of Machine Learning, Econometric Techniques, and Time  Series Forecasting in Public Health Research",
    "abstract": "This research investigates road traffic accident severity in the UK, using a combination of machine learning, econometric, and statistical methods on historical data. We employed various techniques, including correlation analysis, regression models, GMM for error term issues, and time-series forecasting with VAR and ARIMA models. Our approach outperforms naive forecasting with an MASE of 0.800 and ME of -73.80. We also built a random forest classifier with 73% precision, 78% recall, and a 73% F1-score. Optimizing with H2O AutoML led to an XGBoost model with an RMSE of 0.176 and MAE of 0.087. Factor Analysis identified key variables, and we used SHAP for Explainable AI, highlighting influential factors like Driver_Home_Area_Type and Road_Type. Our study enhances understanding of accident severity and offers insights for evidence-based road safety policies. ",
    "url": "https://arxiv.org/abs/2309.13483",
    "authors": [
      "Md Abu Sufian",
      "Jayasree Varadarajan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13548",
    "title": "Quantum All-Subkeys-Recovery Attacks on 6-round Feistel-2* Structure  Based on Multi-Equations Quantum Claw Finding",
    "abstract": "Exploiting quantum mechanisms, quantum attacks have the potential ability to break the cipher structure. Recently, Ito et al. proposed a quantum attack on Feistel-2* structure (Ito et al.'s attack) based onthe Q2 model. However, it is not realistic since the quantum oracle needs to be accessed by the adversary, and the data complexityis high. To solve this problem, a quantum all-subkeys-recovery (ASR) attack based on multi-equations quantum claw-finding is proposed, which takes a more realistic model, the Q1 model, as the scenario, and only requires 3 plain-ciphertext pairs to quickly crack the 6-round Feistel-2* structure. First, we proposed a multi-equations quantum claw-finding algorithm to solve the claw problem of finding multiple equations. In addition, Grover's algorithm is used to speedup the rest subkeys recovery. Compared with Ito et al.'s attack, the data complexity of our attack is reduced from O(2^n) to O(1), while the time complexity and memory complexity are also significantly reduced. ",
    "url": "https://arxiv.org/abs/2309.13548",
    "authors": [
      "Wenjie Liu",
      "Mengting Wang",
      "Zixian Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2309.13571",
    "title": "Matrix Completion-Informed Deep Unfolded Equilibrium Models for  Self-Supervised k-Space Interpolation in MRI",
    "abstract": "Recently, regularization model-driven deep learning (DL) has gained significant attention due to its ability to leverage the potent representational capabilities of DL while retaining the theoretical guarantees of regularization models. However, most of these methods are tailored for supervised learning scenarios that necessitate fully sampled labels, which can pose challenges in practical MRI applications. To tackle this challenge, we propose a self-supervised DL approach for accelerated MRI that is theoretically guaranteed and does not rely on fully sampled labels. Specifically, we achieve neural network structure regularization by exploiting the inherent structural low-rankness of the $k$-space data. Simultaneously, we constrain the network structure to resemble a nonexpansive mapping, ensuring the network's convergence to a fixed point. Thanks to this well-defined network structure, this fixed point can completely reconstruct the missing $k$-space data based on matrix completion theory, even in situations where full-sampled labels are unavailable. Experiments validate the effectiveness of our proposed method and demonstrate its superiority over existing self-supervised approaches and traditional regularization methods, achieving performance comparable to that of supervised learning methods in certain scenarios. ",
    "url": "https://arxiv.org/abs/2309.13571",
    "authors": [
      "Chen Luo",
      "Huayu Wang",
      "Taofeng Xie",
      "Qiyu Jin",
      "Guoqing Chen",
      "Zhuo-Xu Cui",
      "Dong Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13611",
    "title": "Sparsity-regularized coded ptychography for robust and efficient  lensless microscopy on a chip",
    "abstract": "In ptychographic imaging, the trade-off between the number of acquisitions and the resultant imaging quality presents a complex optimization problem. Increasing the number of acquisitions typically yields reconstructions with higher spatial resolution and finer details. Conversely, a reduction in measurement frequency often compromises the quality of the reconstructed images, manifesting as increased noise and coarser details. To address this challenge, we employ sparsity priors to reformulate the ptychographic reconstruction task as a total variation regularized optimization problem. We introduce a new computational framework, termed the ptychographic proximal total-variation (PPTV) solver, designed to integrate into existing ptychography settings without necessitating hardware modifications. Through comprehensive numerical simulations, we validate that PPTV-driven coded ptychography is capable of producing highly accurate reconstructions with a minimal set of eight intensity measurements. Convergence analysis further substantiates the robustness, stability, and computational feasibility of the proposed PPTV algorithm. Experimental results obtained from optical setups unequivocally demonstrate that the PPTV algorithm facilitates high-throughput, high-resolution imaging while significantly reducing the measurement burden. These findings indicate that the PPTV algorithm has the potential to substantially mitigate the resource-intensive requirements traditionally associated with high-quality ptychographic imaging, thereby offering a pathway toward the development of more compact and efficient ptychographic microscopy systems. ",
    "url": "https://arxiv.org/abs/2309.13611",
    "authors": [
      "Ninghe Liu",
      "Qianhao Zhao",
      "Guoan Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Retrieval (cs.IR)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2309.13626",
    "title": "Crack-Net: Prediction of Crack Propagation in Composites",
    "abstract": "Computational solid mechanics has become an indispensable approach in engineering, and numerical investigation of fracture in composites is essential as composites are widely used in structural applications. Crack evolution in composites is the bridge to elucidate the relationship between the microstructure and fracture performance, but crack-based finite element methods are computationally expensive and time-consuming, limiting their application in computation-intensive scenarios. Here we propose a deep learning framework called Crack-Net, which incorporates the relationship between crack evolution and stress response to predict the fracture process in composites. Trained on a high-precision fracture development dataset generated using the phase field method, Crack-Net demonstrates a remarkable capability to accurately forecast the long-term evolution of crack growth patterns and the stress-strain curve for a given composite design. The Crack-Net captures the essential principle of crack growth, which enables it to handle more complex microstructures such as binary co-continuous structures. Moreover, transfer learning is adopted to further improve the generalization ability of Crack-Net for composite materials with reinforcements of different strengths. The proposed Crack-Net holds great promise for practical applications in engineering and materials science, in which accurate and efficient fracture prediction is crucial for optimizing material performance and microstructural design. ",
    "url": "https://arxiv.org/abs/2309.13626",
    "authors": [
      "Hao Xu",
      "Wei Fan",
      "Ambrose C. Taylor",
      "Dongxiao Zhang",
      "Lecheng Ruan",
      "Rundong Shi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2309.13817",
    "title": "MMA-Net: Multiple Morphology-Aware Network for Automated Cobb Angle  Measurement",
    "abstract": "Scoliosis diagnosis and assessment depend largely on the measurement of the Cobb angle in spine X-ray images. With the emergence of deep learning techniques that employ landmark detection, tilt prediction, and spine segmentation, automated Cobb angle measurement has become increasingly popular. However, these methods encounter difficulties such as high noise sensitivity, intricate computational procedures, and exclusive reliance on a single type of morphological information. In this paper, we introduce the Multiple Morphology-Aware Network (MMA-Net), a novel framework that improves Cobb angle measurement accuracy by integrating multiple spine morphology as attention information. In the MMA-Net, we first feed spine X-ray images into the segmentation network to produce multiple morphological information (spine region, centerline, and boundary) and then concatenate the original X-ray image with the resulting segmentation maps as input for the regression module to perform precise Cobb angle measurement. Furthermore, we devise joint loss functions for our segmentation and regression network training, respectively. We evaluate our method on the AASCE challenge dataset and achieve superior performance with the SMAPE of 7.28% and the MAE of 3.18{\\deg}, indicating a strong competitiveness compared to other outstanding methods. Consequently, we can offer clinicians automated, efficient, and reliable Cobb angle measurement. ",
    "url": "https://arxiv.org/abs/2309.13817",
    "authors": [
      "Zhengxuan Qiu",
      "Jie Yang",
      "Jiankun Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13825",
    "title": "NSOTree: Neural Survival Oblique Tree",
    "abstract": "Survival analysis is a statistical method employed to scrutinize the duration until a specific event of interest transpires, known as time-to-event information characterized by censorship. Recently, deep learning-based methods have dominated this field due to their representational capacity and state-of-the-art performance. However, the black-box nature of the deep neural network hinders its interpretability, which is desired in real-world survival applications but has been largely neglected by previous works. In contrast, conventional tree-based methods are advantageous with respect to interpretability, while consistently grappling with an inability to approximate the global optima due to greedy expansion. In this paper, we leverage the strengths of both neural networks and tree-based methods, capitalizing on their ability to approximate intricate functions while maintaining interpretability. To this end, we propose a Neural Survival Oblique Tree (NSOTree) for survival analysis. Specifically, the NSOTree was derived from the ReLU network and can be easily incorporated into existing survival models in a plug-and-play fashion. Evaluations on both simulated and real survival datasets demonstrated the effectiveness of the proposed method in terms of performance and interpretability. ",
    "url": "https://arxiv.org/abs/2309.13825",
    "authors": [
      "Xiaotong Sun",
      "Peijie Qiu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.13874",
    "title": "Diffusion Conditional Expectation Model for Efficient and Robust Target  Speech Extraction",
    "abstract": "Target Speech Extraction (TSE) is a crucial task in speech processing that focuses on isolating the clean speech of a specific speaker from complex mixtures. While discriminative methods are commonly used for TSE, they can introduce distortion in terms of speech perception quality. On the other hand, generative approaches, particularly diffusion-based methods, can enhance speech quality perceptually but suffer from slower inference speed. We propose an efficient generative approach named Diffusion Conditional Expectation Model (DCEM) for TSE. It can handle multi- and single-speaker scenarios in both noisy and clean conditions. Additionally, we introduce Regenerate-DCEM (R-DCEM) that can regenerate and optimize speech quality based on pre-processed speech from a discriminative model. Our method outperforms conventional methods in terms of both intrusive and non-intrusive metrics and demonstrates notable strengths in inference efficiency and robustness to unseen tasks. Audio examples are available online (https://vivian556123.github.io/dcem). ",
    "url": "https://arxiv.org/abs/2309.13874",
    "authors": [
      "Leying Zhang",
      "Yao Qian",
      "Linfeng Yu",
      "Heming Wang",
      "Xinkai Wang",
      "Hemin Yang",
      "Long Zhou",
      "Shujie Liu",
      "Yanmin Qian",
      "Michael Zeng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.13994",
    "title": "Unsupervised Accent Adaptation Through Masked Language Model Correction  Of Discrete Self-Supervised Speech Units",
    "abstract": "Self-supervised pre-trained speech models have strongly improved speech recognition, yet they are still sensitive to domain shifts and accented or atypical speech. Many of these models rely on quantisation or clustering to learn discrete acoustic units. We propose to correct the discovered discrete units for accented speech back to a standard pronunciation in an unsupervised manner. A masked language model is trained on discrete units from a standard accent and iteratively corrects an accented token sequence by masking unexpected cluster sequences and predicting their common variant. Small accent adapter blocks are inserted in the pre-trained model and fine-tuned by predicting the corrected clusters, which leads to an increased robustness of the pre-trained model towards a target accent, and this without supervision. We are able to improve a state-of-the-art HuBERT Large model on a downstream accented speech recognition task by altering the training regime with the proposed method. ",
    "url": "https://arxiv.org/abs/2309.13994",
    "authors": [
      "Jakob Poncelet",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.14073",
    "title": "Maximum Likelihood Estimation of Latent Variable Structural Equation  Models: A Neural Network Approach",
    "abstract": "We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models. ",
    "url": "https://arxiv.org/abs/2309.14073",
    "authors": [
      "Mehrzad Saremi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2309.14080",
    "title": "Analysis and Detection of Pathological Voice using Glottal Source  Features",
    "abstract": "Automatic detection of voice pathology enables objective assessment and earlier intervention for the diagnosis. This study provides a systematic analysis of glottal source features and investigates their effectiveness in voice pathology detection. Glottal source features are extracted using glottal flows estimated with the quasi-closed phase (QCP) glottal inverse filtering method, using approximate glottal source signals computed with the zero frequency filtering (ZFF) method, and using acoustic voice signals directly. In addition, we propose to derive mel-frequency cepstral coefficients (MFCCs) from the glottal source waveforms computed by QCP and ZFF to effectively capture the variations in glottal source spectra of pathological voice. Experiments were carried out using two databases, the Hospital Universitario Principe de Asturias (HUPA) database and the Saarbrucken Voice Disorders (SVD) database. Analysis of features revealed that the glottal source contains information that discriminates normal and pathological voice. Pathology detection experiments were carried out using support vector machine (SVM). From the detection experiments it was observed that the performance achieved with the studied glottal source features is comparable or better than that of conventional MFCCs and perceptual linear prediction (PLP) features. The best detection performance was achieved when the glottal source features were combined with the conventional MFCCs and PLP features, which indicates the complementary nature of the features. ",
    "url": "https://arxiv.org/abs/2309.14080",
    "authors": [
      "Sudarsana Reddy Kadiri",
      "Paavo Alku"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.14103",
    "title": "Upper clique transversals in graphs",
    "abstract": "A clique transversal in a graph is a set of vertices intersecting all maximal cliques. The problem of determining the minimum size of a clique transversal has received considerable attention in the literature. In this paper, we initiate the study of the \"upper\" variant of this parameter, the upper clique transversal number, defined as the maximum size of a minimal clique transversal. We investigate this parameter from the algorithmic and complexity points of view, with a focus on various graph classes. We show that the corresponding decision problem is NP-complete in the classes of chordal graphs, chordal bipartite graphs, and line graphs of bipartite graphs, but solvable in linear time in the classes of split graphs and proper interval graphs. ",
    "url": "https://arxiv.org/abs/2309.14103",
    "authors": [
      "Martin Milani\u010d",
      "Yushi Uno"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.14107",
    "title": "Wav2vec-based Detection and Severity Level Classification of Dysarthria  from Speech",
    "abstract": "Automatic detection and severity level classification of dysarthria directly from acoustic speech signals can be used as a tool in medical diagnosis. In this work, the pre-trained wav2vec 2.0 model is studied as a feature extractor to build detection and severity level classification systems for dysarthric speech. The experiments were carried out with the popularly used UA-speech database. In the detection experiments, the results revealed that the best performance was obtained using the embeddings from the first layer of the wav2vec model that yielded an absolute improvement of 1.23% in accuracy compared to the best performing baseline feature (spectrogram). In the studied severity level classification task, the results revealed that the embeddings from the final layer gave an absolute improvement of 10.62% in accuracy compared to the best baseline features (mel-frequency cepstral coefficients). ",
    "url": "https://arxiv.org/abs/2309.14107",
    "authors": [
      "Farhad Javanmardi",
      "Saska Tirronen",
      "Manila Kodali",
      "Sudarsana Reddy Kadiri",
      "Paavo Alku"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.14113",
    "title": "HyperTrack: Neural Combinatorics for High Energy Physics",
    "abstract": "Combinatorial inverse problems in high energy physics span enormous algorithmic challenges. This work presents a new deep learning driven clustering algorithm that utilizes a space-time non-local trainable graph constructor, a graph neural network, and a set transformer. The model is trained with loss functions at the graph node, edge and object level, including contrastive learning and meta-supervision. The algorithm can be applied to problems such as charged particle tracking, calorimetry, pile-up discrimination, jet physics, and beyond. We showcase the effectiveness of this cutting-edge AI approach through particle tracking simulations. The code is available online. ",
    "url": "https://arxiv.org/abs/2309.14113",
    "authors": [
      "Mikael Mieskolainen"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2309.14129",
    "title": "Speaker anonymization using neural audio codec language models",
    "abstract": "The vast majority of approaches to speaker anonymization involve the extraction of fundamental frequency estimates, linguistic features and a speaker embedding which is perturbed to obfuscate the speaker identity before an anonymized speech waveform is resynthesized using a vocoder. Recent work has shown that x-vector transformations are difficult to control consistently: other sources of speaker information contained within fundamental frequency and linguistic features are re-entangled upon vocoding, meaning that anonymized speech signals still contain speaker information. We propose an approach based upon neural audio codecs (NACs), which are known to generate high-quality synthetic speech when combined with language models. NACs use quantized codes, which are known to effectively bottleneck speaker-related information: we demonstrate the potential of speaker anonymization systems based on NAC language modeling by applying the evaluation framework of the Voice Privacy Challenge 2022. ",
    "url": "https://arxiv.org/abs/2309.14129",
    "authors": [
      "Michele Panariello",
      "Francesco Nespoli",
      "Massimiliano Todisco",
      "Nicholas Evans"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.14250",
    "title": "Prediction Model For Wordle Game Results With High Robustness",
    "abstract": "In this study, we delve into the dynamics of Wordle using data analysis and machine learning. Our analysis initially focused on the correlation between the date and the number of submitted results. Due to initial popularity bias, we modeled stable data using an ARIMAX model with coefficient values of 9, 0, 2, and weekdays/weekends as the exogenous variable. We found no significant relationship between word attributes and hard mode results. To predict word difficulty, we employed a Backpropagation Neural Network, overcoming overfitting via feature engineering. We also used K-means clustering, optimized at five clusters, to categorize word difficulty numerically. Our findings indicate that on March 1st, 2023, around 12,884 results will be submitted and the word \"eerie\" averages 4.8 attempts, falling into the hardest difficulty cluster. We further examined the percentage of loyal players and their propensity to undertake daily challenges. Our models underwent rigorous sensitivity analyses, including ADF, ACF, PACF tests, and cross-validation, confirming their robustness. Overall, our study provides a predictive framework for Wordle gameplay based on date or a given five-letter word. Results have been summarized and submitted to the Puzzle Editor of the New York Times. ",
    "url": "https://arxiv.org/abs/2309.14250",
    "authors": [
      "Jiaqi Weng",
      "Chunlin Feng"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:1910.09455",
    "title": "Depth-wise Decomposition for Accelerating Separable Convolutions in  Efficient Convolutional Neural Networks",
    "abstract": " Title: Depth-wise Decomposition for Accelerating Separable Convolutions in  Efficient Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/1910.09455",
    "authors": [
      "Yihui He",
      "Jianing Qian",
      "Jianren Wang",
      "Cindy X. Le",
      "Congrui Hetang",
      "Qi Lyu",
      "Wenping Wang",
      "Tianwei Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2002.00306",
    "title": "Brainstorming Generative Adversarial Networks (BGANs): Towards  Multi-Agent Generative Models with Distributed Private Datasets",
    "abstract": " Comments: 13 pages, 16 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2002.00306",
    "authors": [
      "Aidin Ferdowsi",
      "Walid Saad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.09565",
    "title": "Mining Label Distribution Drift in Unsupervised Domain Adaptation",
    "abstract": " Comments: Accepted to AJCAI'23 ",
    "url": "https://arxiv.org/abs/2006.09565",
    "authors": [
      "Peizhao Li",
      "Zhengming Ding",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.01331",
    "title": "BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on  Twitter",
    "abstract": " Title: BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on  Twitter ",
    "url": "https://arxiv.org/abs/2105.01331",
    "authors": [
      "Hasan Kemik",
      "Nusret \u00d6zate\u015f",
      "Meysam Asgari-Chenaghlu",
      "Erik Cambria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.13015",
    "title": "A recursive representation for decoupling time-state dependent jumps  from jump-diffusion processes",
    "abstract": " Comments: 25 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2105.13015",
    "authors": [
      "Qinjing Qiu",
      "Reiichiro Kawai"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2201.11935",
    "title": "Sequential Decoding of Convolutional Codes for Synchronization Errors",
    "abstract": " Title: Sequential Decoding of Convolutional Codes for Synchronization Errors ",
    "url": "https://arxiv.org/abs/2201.11935",
    "authors": [
      "Anisha Banerjee",
      "Andreas Lenz",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.03906",
    "title": "Graph Reinforcement Learning for Radio Resource Allocation",
    "abstract": " Title: Graph Reinforcement Learning for Radio Resource Allocation ",
    "url": "https://arxiv.org/abs/2203.03906",
    "authors": [
      "Jianyu Zhao",
      "Chenyang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.00751",
    "title": "Robotic Process Automation Using Process Mining $\\unicode{x2013}$ A  Systematic Literature Review",
    "abstract": " Comments: 51 pages, 5 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2204.00751",
    "authors": [
      "Najah Mary El-Gharib",
      "Daniel Amyot"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2204.04431",
    "title": "A Spiking Neural Network Structure Implementing Reinforcement Learning",
    "abstract": " Title: A Spiking Neural Network Structure Implementing Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2204.04431",
    "authors": [
      "Mikhail Kiselev"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.12983",
    "title": "Explainable and High-Performance Hate and Offensive Speech Detection",
    "abstract": " Title: Explainable and High-Performance Hate and Offensive Speech Detection ",
    "url": "https://arxiv.org/abs/2206.12983",
    "authors": [
      "Marzieh Babaeianjelodar",
      "Gurram Poorna Prudhvi",
      "Stephen Lorenz",
      "Keyu Chen",
      "Sumona Mondal",
      "Soumyabrata Dey",
      "Navin Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.01819",
    "title": "Adversarial Camouflage for Node Injection Attack on Graphs",
    "abstract": " Comments: Published in Information Sciences. Code: this https URL ",
    "url": "https://arxiv.org/abs/2208.01819",
    "authors": [
      "Shuchang Tao",
      "Qi Cao",
      "Huawei Shen",
      "Yunfan Wu",
      "Liang Hou",
      "Fei Sun",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.01913",
    "title": "EgPDE-Net: Building Continuous Neural Networks for Time Series  Prediction with Exogenous Variables",
    "abstract": " Title: EgPDE-Net: Building Continuous Neural Networks for Time Series  Prediction with Exogenous Variables ",
    "url": "https://arxiv.org/abs/2208.01913",
    "authors": [
      "Penglei Gao",
      "Xi Yang",
      "Rui Zhang",
      "Ping Guo",
      "John Y. Goulermas",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06900",
    "title": "Convolutional Spiking Neural Networks for Detecting Anticipatory Brain  Potentials Using Electroencephalogram",
    "abstract": " Comments: 14 pages, 6 figures, Scientific Reports submission ",
    "url": "https://arxiv.org/abs/2208.06900",
    "authors": [
      "Nathan Lutes",
      "Venkata Sriram Siddhardh Nadendla",
      "K. Krishnamurthy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.12587",
    "title": "Mitosis Detection, Fast and Slow: Robust and Efficient Detection of  Mitotic Figures",
    "abstract": " Comments: Extended version of the work done for MIDOG challenge submission ",
    "url": "https://arxiv.org/abs/2208.12587",
    "authors": [
      "Mostafa Jahanifar",
      "Adam Shephard",
      "Neda Zamanitajeddin",
      "Simon Graham",
      "Shan E Ahmed Raza",
      "Fayyaz Minhas",
      "Nasir Rajpoot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.08983",
    "title": "Optimal phase shift design for fair allocation in RIS aided uplink  network using statistical CSI",
    "abstract": " Title: Optimal phase shift design for fair allocation in RIS aided uplink  network using statistical CSI ",
    "url": "https://arxiv.org/abs/2209.08983",
    "authors": [
      "Athira Subhash",
      "Abla Kammoun",
      "Ahmed Elzanaty",
      "Sheetal Kalyani",
      "Yazan H.Al-Badarneh",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2209.15505",
    "title": "Momentum Tracking: Momentum Acceleration for Decentralized Deep Learning  on Heterogeneous Data",
    "abstract": " Comments: Transactions on Machine Learning Research 2023 ",
    "url": "https://arxiv.org/abs/2209.15505",
    "authors": [
      "Yuki Takezawa",
      "Han Bao",
      "Kenta Niwa",
      "Ryoma Sato",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11174",
    "title": "Overlapping Community Detection using Dynamic Dilated Aggregation in  Deep Residual GCN",
    "abstract": " Comments: Will resubmit later ",
    "url": "https://arxiv.org/abs/2210.11174",
    "authors": [
      "Md Nurul Muttakin",
      "Md Iqbal Hossain",
      "Md Saidur Rahman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.03550",
    "title": "Underwater Image Super-Resolution using Generative Adversarial  Network-based Model",
    "abstract": " Title: Underwater Image Super-Resolution using Generative Adversarial  Network-based Model ",
    "url": "https://arxiv.org/abs/2211.03550",
    "authors": [
      "Alireza Aghelan",
      "Modjtaba Rouhani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.12711",
    "title": "SnCQA: A hardware-efficient equivariant quantum convolutional circuit  architecture",
    "abstract": " Comments: 10 pages, many figures. IEEE QCE 2023, 1st best paper award in quantum algorithms ",
    "url": "https://arxiv.org/abs/2211.12711",
    "authors": [
      "Han Zheng",
      "Christopher Kang",
      "Gokul Subramanian Ravi",
      "Hanrui Wang",
      "Kanav Setia",
      "Frederic T. Chong",
      "Junyu Liu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.13775",
    "title": "SAGA: Spectral Adversarial Geometric Attack on 3D Meshes",
    "abstract": " Comments: Presented at ICCV 2023. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.13775",
    "authors": [
      "Tomer Stolik",
      "Itai Lang",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00979",
    "title": "PASTA: Proportional Amplitude Spectrum Training Augmentation for  Syn-to-Real Domain Generalization",
    "abstract": " Comments: Accepted at ICCV 2023, Code: this https URL ",
    "url": "https://arxiv.org/abs/2212.00979",
    "authors": [
      "Prithvijit Chattopadhyay",
      "Kartik Sarangmath",
      "Vivek Vijaykumar",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.01518",
    "title": "Hedging Complexity in Generalization via a Parametric Distributionally  Robust Optimization Framework",
    "abstract": " Comments: Preliminary version appeared in AISTATS 2023 ",
    "url": "https://arxiv.org/abs/2212.01518",
    "authors": [
      "Garud Iyengar",
      "Henry Lam",
      "Tianyu Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.02771",
    "title": "Detection of large exact subgraph isomorphisms with a topology-only  graphlet index built using deterministic walks",
    "abstract": " Comments: 13 pages, 11 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2212.02771",
    "authors": [
      "Patrick Wang",
      "Henry Ye",
      "Wayne Hayes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.05250",
    "title": "Phases, Modalities, Temporal and Spatial Locality: Domain Specific ML  Prefetcher for Accelerating Graph Analytics",
    "abstract": " Title: Phases, Modalities, Temporal and Spatial Locality: Domain Specific ML  Prefetcher for Accelerating Graph Analytics ",
    "url": "https://arxiv.org/abs/2212.05250",
    "authors": [
      "Pengmiao Zhang",
      "Rajgopal Kannan",
      "Viktor K. Prasanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2212.07425",
    "title": "Robust and Explainable Identification of Logical Fallacies in Natural  Language Arguments",
    "abstract": " Title: Robust and Explainable Identification of Logical Fallacies in Natural  Language Arguments ",
    "url": "https://arxiv.org/abs/2212.07425",
    "authors": [
      "Zhivar Sourati",
      "Vishnu Priya Prasanna Venkatesh",
      "Darshan Deshpande",
      "Himanshu Rawlani",
      "Filip Ilievski",
      "H\u00f4ng-\u00c2n Sandlin",
      "Alain Mermoud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.10614",
    "title": "MolCPT: Molecule Continuous Prompt Tuning to Generalize Molecular  Representation Learning",
    "abstract": " Title: MolCPT: Molecule Continuous Prompt Tuning to Generalize Molecular  Representation Learning ",
    "url": "https://arxiv.org/abs/2212.10614",
    "authors": [
      "Cameron Diao",
      "Kaixiong Zhou",
      "Zirui Liu",
      "Xiao Huang",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2212.14142",
    "title": "Joint User Association and Bandwidth Allocation in Semantic  Communication Networks",
    "abstract": " Comments: This paper has been accepted for publication by IEEE Transactions on Vehicular Technology. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2212.14142",
    "authors": [
      "Le Xia",
      "Yao Sun",
      "Dusit Niyato",
      "Xiaoqian Li",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.01947",
    "title": "StitchNet: Composing Neural Networks from Pre-Trained Fragments",
    "abstract": " Title: StitchNet: Composing Neural Networks from Pre-Trained Fragments ",
    "url": "https://arxiv.org/abs/2301.01947",
    "authors": [
      "Surat Teerapittayanon",
      "Marcus Comiter",
      "Brad McDanel",
      "H.T. Kung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.03283",
    "title": "A Robust Multilabel Method Integrating Rule-based Transparent Model,  Soft Label Correlation Learning and Label Noise Resistance",
    "abstract": " Comments: This paper has been accepted by IEEE Transactions on Fuzzy Systems ",
    "url": "https://arxiv.org/abs/2301.03283",
    "authors": [
      "Qiongdan Lou",
      "Zhaohong Deng",
      "Kup-Sze Choi",
      "Shitong Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.08807",
    "title": "4-clique Network Minor Embedding for Quantum Annealers",
    "abstract": " Title: 4-clique Network Minor Embedding for Quantum Annealers ",
    "url": "https://arxiv.org/abs/2301.08807",
    "authors": [
      "Elijah Pelofske"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2301.10859",
    "title": "Salesforce CausalAI Library: A Fast and Scalable Framework for Causal  Analysis of Time Series and Tabular Data",
    "abstract": " Title: Salesforce CausalAI Library: A Fast and Scalable Framework for Causal  Analysis of Time Series and Tabular Data ",
    "url": "https://arxiv.org/abs/2301.10859",
    "authors": [
      "Devansh Arpit",
      "Matthew Fernandez",
      "Itai Feigenbaum",
      "Weiran Yao",
      "Chenghao Liu",
      "Wenzhuo Yang",
      "Paul Josel",
      "Shelby Heinecke",
      "Eric Hu",
      "Huan Wang",
      "Stephen Hoi",
      "Caiming Xiong",
      "Kun Zhang",
      "Juan Carlos Niebles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.00869",
    "title": "Disentanglement of Latent Representations via Causal Interventions",
    "abstract": " Comments: 16 pages, 10 pages for the main paper and 6 pages for the supplement, 14 figures, accepted to IJCAI 2023. V3: content matches the IJCAI version ",
    "url": "https://arxiv.org/abs/2302.00869",
    "authors": [
      "Ga\u00ebl Gendron",
      "Michael Witbrock",
      "Gillian Dobbie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Discrete Mathematics (cs.DM)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.02012",
    "title": "DeTorrent: An Adversarial Padding-only Traffic Analysis Defense",
    "abstract": " Comments: Accepted to the 24th Privacy Enhancing Technologies Symposium (PETS 2024) ",
    "url": "https://arxiv.org/abs/2302.02012",
    "authors": [
      "James K Holland",
      "Jason Carpenter",
      "Se Eun Oh",
      "Nicholas Hopper"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.08051",
    "title": "Graph Adversarial Immunization for Certifiable Robustness",
    "abstract": " Comments: Published in TKDE. Code: this https URL ",
    "url": "https://arxiv.org/abs/2302.08051",
    "authors": [
      "Shuchang Tao",
      "Huawei Shen",
      "Qi Cao",
      "Yunfan Wu",
      "Liang Hou",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.08924",
    "title": "Multi-unit Auction over a Social Network",
    "abstract": " Title: Multi-unit Auction over a Social Network ",
    "url": "https://arxiv.org/abs/2302.08924",
    "authors": [
      "Yuan Fang",
      "Mengxiao Zhang",
      "Jiamou Liu",
      "Bakh Khoussainov",
      "Mingyu Xiao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.14040",
    "title": "Permutation Equivariant Neural Functionals",
    "abstract": " Comments: To appear in Neural Information Processing Systems (NeurIPS), 2023 ",
    "url": "https://arxiv.org/abs/2302.14040",
    "authors": [
      "Allan Zhou",
      "Kaien Yang",
      "Kaylee Burns",
      "Adriano Cardace",
      "Yiding Jiang",
      "Samuel Sokota",
      "J. Zico Kolter",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.14479",
    "title": "A Survey of Automatic Generation of Attack Trees and Attack Graphs",
    "abstract": " Title: A Survey of Automatic Generation of Attack Trees and Attack Graphs ",
    "url": "https://arxiv.org/abs/2302.14479",
    "authors": [
      "Alyzia-Maria Konsta",
      "Beatrice Spiga",
      "Alberto Lluch Lafuente",
      "Nicola Dragoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.14762",
    "title": "Kartezio: Evolutionary Design of Explainable Pipelines for Biomedical  Image Analysis",
    "abstract": " Comments: 36 pages, 6 main Figures. The Extended Data Movie is available at the following link: this https URL The source code is available on Github: this https URL ",
    "url": "https://arxiv.org/abs/2302.14762",
    "authors": [
      "K\u00e9vin Cortacero",
      "Brienne McKenzie",
      "Sabina M\u00fcller",
      "Roxana Khazen",
      "Fanny Lafouresse",
      "Ga\u00eblle Corsaut",
      "Nathalie Van Acker",
      "Fran\u00e7ois-Xavier Frenois",
      "Laurence Lamant",
      "Nicolas Meyer",
      "B\u00e9atrice Vergier",
      "Dennis G. Wilson",
      "Herv\u00e9 Luga",
      "Oskar Staufer",
      "Michael L. Dustin",
      "Salvatore Valitutti",
      "Sylvain Cussat-Blanc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.06945",
    "title": "CoGANPPIS: A Coevolution-enhanced Global Attention Neural Network for  Protein-Protein Interaction Site Prediction",
    "abstract": " Title: CoGANPPIS: A Coevolution-enhanced Global Attention Neural Network for  Protein-Protein Interaction Site Prediction ",
    "url": "https://arxiv.org/abs/2303.06945",
    "authors": [
      "Jiaxing Guo",
      "Xuening Zhu",
      "Zixin Hu",
      "Xiaoxi Hu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12233",
    "title": "LOKI: Large-scale Data Reconstruction Attack against Federated Learning  through Model Manipulation",
    "abstract": " Comments: To appear in the IEEE Symposium on Security & Privacy (S&P) 2024 ",
    "url": "https://arxiv.org/abs/2303.12233",
    "authors": [
      "Joshua C. Zhao",
      "Atul Sharma",
      "Ahmed Roushdy Elkordy",
      "Yahya H. Ezzeldin",
      "Salman Avestimehr",
      "Saurabh Bagchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.13047",
    "title": "Towards Better Dynamic Graph Learning: New Architecture and Unified  Library",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.13047",
    "authors": [
      "Le Yu",
      "Leilei Sun",
      "Bowen Du",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.13696",
    "title": "Adaptive Multi-scale Online Likelihood Network for AI-assisted  Interactive Segmentation",
    "abstract": " Title: Adaptive Multi-scale Online Likelihood Network for AI-assisted  Interactive Segmentation ",
    "url": "https://arxiv.org/abs/2303.13696",
    "authors": [
      "Muhammad Asad",
      "Helena Williams",
      "Indrajeet Mandal",
      "Sarim Ather",
      "Jan Deprest",
      "Jan D'hooge",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16355",
    "title": "Assessing the impact of Byzantine attacks on coupled phase oscillators",
    "abstract": " Comments: 9 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2303.16355",
    "authors": [
      "Melvyn Tyloo"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2304.01899",
    "title": "Cross-Class Feature Augmentation for Class Incremental Learning",
    "abstract": " Title: Cross-Class Feature Augmentation for Class Incremental Learning ",
    "url": "https://arxiv.org/abs/2304.01899",
    "authors": [
      "Taehoon Kim",
      "Jaeyoo Park",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03535",
    "title": "CRISP: Curriculum inducing Primitive Informed Subgoal Prediction",
    "abstract": " Title: CRISP: Curriculum inducing Primitive Informed Subgoal Prediction ",
    "url": "https://arxiv.org/abs/2304.03535",
    "authors": [
      "Utsav Singh",
      "Vinay P Namboodiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04531",
    "title": "Alon-Tarsi Number of Some Regular Graphs",
    "abstract": " Comments: 4 pages ",
    "url": "https://arxiv.org/abs/2304.04531",
    "authors": [
      "Prajnanaswaroopa S"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2304.09720",
    "title": "Genetic Algorithm Based Combinatorial Optimization for the Optimal  Design of Water Distribution Network of Gurudeniya Service Zone, Sri Lanka",
    "abstract": " Comments: Submitted to the journal ENGINEER - IESL Sri Lanka. Revised on Sep 22, 2023. arXiv admin note: text overlap with arXiv:2209.11993 ",
    "url": "https://arxiv.org/abs/2304.09720",
    "authors": [
      "K. H. M. R. N. Senavirathna",
      "C. K. Walgampaya"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.10740",
    "title": "Multi-Modal Deep Learning for Credit Rating Prediction Using Text and  Numerical Data Streams",
    "abstract": " Title: Multi-Modal Deep Learning for Credit Rating Prediction Using Text and  Numerical Data Streams ",
    "url": "https://arxiv.org/abs/2304.10740",
    "authors": [
      "Mahsa Tavakoli",
      "Rohitash Chandra",
      "Fengrui Tian",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11263",
    "title": "Benchmarking Low-Shot Robustness to Natural Distribution Shifts",
    "abstract": " Comments: 22 Pages, 18 Tables, 12 Figures ",
    "url": "https://arxiv.org/abs/2304.11263",
    "authors": [
      "Aaditya Singh",
      "Kartik Sarangmath",
      "Prithvijit Chattopadhyay",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.14774",
    "title": "A feature selection method based on Shapley values robust to concept  shift in regression",
    "abstract": " Title: A feature selection method based on Shapley values robust to concept  shift in regression ",
    "url": "https://arxiv.org/abs/2304.14774",
    "authors": [
      "Carlos Sebasti\u00e1n",
      "Carlos E. Gonz\u00e1lez-Guill\u00e9n"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.03271",
    "title": "Is It a Trap? A Large-scale Empirical Study And Comprehensive Assessment  of Online Automated Privacy Policy Generators for Mobile Apps",
    "abstract": " Comments: USENIX Security 2024 ",
    "url": "https://arxiv.org/abs/2305.03271",
    "authors": [
      "Shidong Pan",
      "Dawen Zhang",
      "Mark Staples",
      "Zhenchang Xing",
      "Jieshan Chen",
      "Xiwei Xu",
      "James Hoang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.04107",
    "title": "DMF-TONN: Direct Mesh-free Topology Optimization using Neural Networks",
    "abstract": " Title: DMF-TONN: Direct Mesh-free Topology Optimization using Neural Networks ",
    "url": "https://arxiv.org/abs/2305.04107",
    "authors": [
      "Aditya Joglekar",
      "Hongrui Chen",
      "Levent Burak Kara"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10468",
    "title": "Connected Hidden Neurons (CHNNet): An Artificial Neural Network for  Rapid Convergence",
    "abstract": " Title: Connected Hidden Neurons (CHNNet): An Artificial Neural Network for  Rapid Convergence ",
    "url": "https://arxiv.org/abs/2305.10468",
    "authors": [
      "Rafiad Sadat Shahir",
      "Zayed Humayun",
      "Mashrufa Akter Tamim",
      "Shouri Saha",
      "Md. Golam Rabiul Alam"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11400",
    "title": "Mode-Aware Continual Learning for Conditional Generative Adversarial  Networks",
    "abstract": " Title: Mode-Aware Continual Learning for Conditional Generative Adversarial  Networks ",
    "url": "https://arxiv.org/abs/2305.11400",
    "authors": [
      "Cat P. Le",
      "Juncheng Dong",
      "Ahmed Aloui",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.12021",
    "title": "A Secure and Robust Approach for Distance-Based Mutual Positioning of  Unmanned Aerial Vehicles",
    "abstract": " Comments: Submitted to IEEE WCNC 2024 ",
    "url": "https://arxiv.org/abs/2305.12021",
    "authors": [
      "Bin Han",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.12823",
    "title": "READMem: Robust Embedding Association for a Diverse Memory in  Unconstrained Video Object Segmentation",
    "abstract": " Comments: Accepted to BMVC 2023. Code @ this https URL ",
    "url": "https://arxiv.org/abs/2305.12823",
    "authors": [
      "St\u00e9phane Vujasinovi\u0107",
      "Sebastian Bullinger",
      "Stefan Becker",
      "Norbert Scherer-Negenborn",
      "Michael Arens",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14097",
    "title": "QFA2SR: Query-Free Adversarial Transfer Attacks to Speaker Recognition  Systems",
    "abstract": " Comments: Accepted by the 32nd USENIX Security Symposium (2023 USENIX Security); Full Version ",
    "url": "https://arxiv.org/abs/2305.14097",
    "authors": [
      "Guangke Chen",
      "Yedi Zhang",
      "Zhe Zhao",
      "Fu Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.14375",
    "title": "MGL2Rank: Learning to Rank the Importance of Nodes in Road Networks  Based on Multi-Graph Fusion",
    "abstract": " Title: MGL2Rank: Learning to Rank the Importance of Nodes in Road Networks  Based on Multi-Graph Fusion ",
    "url": "https://arxiv.org/abs/2305.14375",
    "authors": [
      "Ming Xu",
      "Jing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.15121",
    "title": "Beyond Individual Input for Deep Anomaly Detection on Tabular Data",
    "abstract": " Title: Beyond Individual Input for Deep Anomaly Detection on Tabular Data ",
    "url": "https://arxiv.org/abs/2305.15121",
    "authors": [
      "Hugo Thimonier",
      "Fabrice Popineau",
      "Arpad Rimmel",
      "Bich-Li\u00ean Doan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15930",
    "title": "End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes",
    "abstract": " Title: End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes ",
    "url": "https://arxiv.org/abs/2305.15930",
    "authors": [
      "Alexandre Maraval",
      "Matthieu Zimmer",
      "Antoine Grosnit",
      "Haitham Bou Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16437",
    "title": "KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired  True-Range Multilateration",
    "abstract": " Comments: Accepted to ACM Multimedia 2023; 10 pages, 7 figures, 6 tables; the code is at this https URL ",
    "url": "https://arxiv.org/abs/2305.16437",
    "authors": [
      "Xu Bao",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Chenyang Li",
      "Wangmeng Xiang",
      "Jingdong Sun",
      "Hanbing Liu",
      "Wei Liu",
      "Bin Luo",
      "Yifeng Geng",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.18668",
    "title": "Fine-Grained is Too Coarse: A Novel Data-Centric Approach for Efficient  Scene Graph Generation",
    "abstract": " Title: Fine-Grained is Too Coarse: A Novel Data-Centric Approach for Efficient  Scene Graph Generation ",
    "url": "https://arxiv.org/abs/2305.18668",
    "authors": [
      "Neau Ma\u00eblic",
      "Paulo E. Santos",
      "Anne-Gwenn Bosser",
      "C\u00e9dric Buche"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18743",
    "title": "Decomposed Human Motion Prior for Video Pose Estimation via Adversarial  Training",
    "abstract": " Title: Decomposed Human Motion Prior for Video Pose Estimation via Adversarial  Training ",
    "url": "https://arxiv.org/abs/2305.18743",
    "authors": [
      "Wenshuo Chen",
      "Xiang Zhou",
      "Zhengdi Yu",
      "Weixi Gu",
      "Kai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01913",
    "title": "PDT: Pretrained Dual Transformers for Time-aware Bipartite Graphs",
    "abstract": " Title: PDT: Pretrained Dual Transformers for Time-aware Bipartite Graphs ",
    "url": "https://arxiv.org/abs/2306.01913",
    "authors": [
      "Xin Dai",
      "Yujie Fan",
      "Zhongfang Zhuang",
      "Shubham Jain",
      "Chin-Chia Michael Yeh",
      "Junpeng Wang",
      "Liang Wang",
      "Yan Zheng",
      "Prince Osei Aboagye",
      "Wei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02879",
    "title": "Neuron Activation Coverage: Rethinking Out-of-distribution Detection and  Generalization",
    "abstract": " Comments: 28 pages, 9 figures, 20 tables ",
    "url": "https://arxiv.org/abs/2306.02879",
    "authors": [
      "Yibing Liu",
      "Chris Xing Tian",
      "Haoliang Li",
      "Lei Ma",
      "Shiqi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.04959",
    "title": "FedMLSecurity: A Benchmark for Attacks and Defenses in Federated  Learning and LLMs",
    "abstract": " Title: FedMLSecurity: A Benchmark for Attacks and Defenses in Federated  Learning and LLMs ",
    "url": "https://arxiv.org/abs/2306.04959",
    "authors": [
      "Shanshan Han",
      "Baturalp Buyukates",
      "Zijian Hu",
      "Han Jin",
      "Weizhao Jin",
      "Lichao Sun",
      "Xiaoyang Wang",
      "Wenxuan Wu",
      "Chulin Xie",
      "Yuhang Yao",
      "Kai Zhang",
      "Qifan Zhang",
      "Yuhui Zhang",
      "Salman Avestimehr",
      "Chaoyang He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06123",
    "title": "Adversarial Attacks and Defenses in Explainable Artificial Intelligence:  A Survey",
    "abstract": " Comments: A shorter version of this paper was presented at the IJCAI 2023 Workshop on Explainable AI ",
    "url": "https://arxiv.org/abs/2306.06123",
    "authors": [
      "Hubert Baniecki",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06198",
    "title": "Spoofing Against Spoofing: Towards Caller ID Verification In  Heterogeneous Telecommunication Systems",
    "abstract": " Comments: 25 pages, 12 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2306.06198",
    "authors": [
      "Shen Wang",
      "Mahshid Delavar",
      "Muhammad Ajmal Azad",
      "Farshad Nabizadeh",
      "Steve Smith",
      "Feng Hao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.10158",
    "title": "Learning-Augmented Decentralized Online Convex Optimization in Networks",
    "abstract": " Title: Learning-Augmented Decentralized Online Convex Optimization in Networks ",
    "url": "https://arxiv.org/abs/2306.10158",
    "authors": [
      "Pengfei Li",
      "Jianyi Yang",
      "Adam Wierman",
      "Shaolei Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2306.10598",
    "title": "DropCompute: simple and more robust distributed synchronous training via  compute variance reduction",
    "abstract": " Comments: this https URL ",
    "url": "https://arxiv.org/abs/2306.10598",
    "authors": [
      "Niv Giladi",
      "Shahar Gottlieb",
      "Moran Shkolnik",
      "Asaf Karnieli",
      "Ron Banner",
      "Elad Hoffer",
      "Kfir Yehuda Levy",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.12045",
    "title": "Temporal Conditioning Spiking Latent Variable Models of the Neural  Response to Natural Visual Scenes",
    "abstract": " Comments: Accepted at NeurIPS 2023. 22 pages, 7 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2306.12045",
    "authors": [
      "Gehua Ma",
      "Runhao Jiang",
      "Rui Yan",
      "Huajin Tang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.12321",
    "title": "Dynamic Implicit Image Function for Efficient Arbitrary-Scale Image  Representation",
    "abstract": " Title: Dynamic Implicit Image Function for Efficient Arbitrary-Scale Image  Representation ",
    "url": "https://arxiv.org/abs/2306.12321",
    "authors": [
      "Zongyao He",
      "Zhi Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13216",
    "title": "Diverse Community Data for Benchmarking Data Privacy Algorithms",
    "abstract": " Title: Diverse Community Data for Benchmarking Data Privacy Algorithms ",
    "url": "https://arxiv.org/abs/2306.13216",
    "authors": [
      "Aniruddha Sen",
      "Christine Task",
      "Dhruv Kapur",
      "Gary Howarth",
      "Karan Bhagat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.15354",
    "title": "3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and  Multi-Dialect Corpus for Speech Representation Disentanglement",
    "abstract": " Title: 3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and  Multi-Dialect Corpus for Speech Representation Disentanglement ",
    "url": "https://arxiv.org/abs/2306.15354",
    "authors": [
      "Siqi Zheng",
      "Luyao Cheng",
      "Yafeng Chen",
      "Hui Wang",
      "Qian Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.15988",
    "title": "AFPN: Asymptotic Feature Pyramid Network for Object Detection",
    "abstract": " Title: AFPN: Asymptotic Feature Pyramid Network for Object Detection ",
    "url": "https://arxiv.org/abs/2306.15988",
    "authors": [
      "Guoyu Yang",
      "Jie Lei",
      "Zhikuan Zhu",
      "Siyu Cheng",
      "Zunlei Feng",
      "Ronghua Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.06422",
    "title": "Differentially Private Decoupled Graph Convolutions for Multigranular  Topology Protection",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.06422",
    "authors": [
      "Eli Chien",
      "Wei-Ning Chen",
      "Chao Pan",
      "Pan Li",
      "Ayfer \u00d6zg\u00fcr",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.10982",
    "title": "MASR: Multi-label Aware Speech Representation",
    "abstract": " Comments: Accepted at ASRU 2023 ",
    "url": "https://arxiv.org/abs/2307.10982",
    "authors": [
      "Anjali Raj",
      "Shikhar Bharadwaj",
      "Sriram Ganapathy",
      "Min Ma",
      "Shikhar Vashishth"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.11058",
    "title": "Anticipating Driving Behavior through Deep Learning-Based Policy  Prediction",
    "abstract": " Comments: 5 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2307.11058",
    "authors": [
      "Alexander Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14619",
    "title": "Imitating Complex Trajectories: Bridging Low-Level Stability and  High-Level Behavior",
    "abstract": " Comments: updated figures, minor notational change for readability ",
    "url": "https://arxiv.org/abs/2307.14619",
    "authors": [
      "Adam Block",
      "Daniel Pfrommer",
      "Max Simchowitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.14751",
    "title": "FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal  Adversarial Masks",
    "abstract": " Comments: Will appear in the proceedings of ACSAC 2023; 14 pages, 6 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2307.14751",
    "authors": [
      "Buse G. A. Tekgul",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.03929",
    "title": "Challenging the Machinery of Generative AI with Fact-Checking:  Ontology-Driven Biological Graphs for Verifying Human Disease-Gene Links",
    "abstract": " Comments: 12 Pages, 4 algorithms, 6 tables, and 9 figures ",
    "url": "https://arxiv.org/abs/2308.03929",
    "authors": [
      "Ahmed Abdeen Hamed",
      "Byung Suk Lee",
      "Alessandro Crimi",
      "Magdalena M. Misiak"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.04736",
    "title": "Case Study: Using AI-Assisted Code Generation In Mobile Teams",
    "abstract": " Comments: 8 pages, 10 figures, 1 table, ICCP conference ",
    "url": "https://arxiv.org/abs/2308.04736",
    "authors": [
      "Mircea-Serban Vasiliniuc",
      "Adrian Groza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05103",
    "title": "Improved Multi-Shot Diffusion-Weighted MRI with Zero-Shot  Self-Supervised Learning Reconstruction",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2308.05103",
    "authors": [
      "Jaejin Cho",
      "Yohan Jun",
      "Xiaoqing Wang",
      "Caique Kobayashi",
      "Berkin Bilgic"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05274",
    "title": "Local-Global Information Interaction Debiasing for Dynamic Scene Graph  Generation",
    "abstract": " Comments: The author has withdrawn this paper due to a critical definitional error in multi-task learning for dynamic SGG debiasing. This error aligned with the definition of dynamic SGG tasks, resulting in an unfair comparison with state-of-the-art (SOTA) methods, which in turn, hindered the ability to evaluate the paper's contributions ",
    "url": "https://arxiv.org/abs/2308.05274",
    "authors": [
      "Xinyu Lyu",
      "Jingwei Liu",
      "Yuyu Guo",
      "Lianli Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.08143",
    "title": "SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech  Separation",
    "abstract": " Comments: 14 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2308.08143",
    "authors": [
      "Kai Li",
      "Runxuan Yang",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.10087",
    "title": "GNNPipe: Scaling Deep GNN Training with Pipelined Model Parallelism",
    "abstract": " Title: GNNPipe: Scaling Deep GNN Training with Pipelined Model Parallelism ",
    "url": "https://arxiv.org/abs/2308.10087",
    "authors": [
      "Jingji Chen",
      "Zhuoming Chen",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.11034",
    "title": "Digital Twin-Oriented Complex Networked Systems based on Heterogeneous  Node Features and Interaction Rules",
    "abstract": " Title: Digital Twin-Oriented Complex Networked Systems based on Heterogeneous  Node Features and Interaction Rules ",
    "url": "https://arxiv.org/abs/2308.11034",
    "authors": [
      "Jiaqi Wen",
      "Bogdan Gabrys",
      "Katarzyna Musial"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.11119",
    "title": "Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection",
    "abstract": " Comments: Accepted to BMVC2023 ",
    "url": "https://arxiv.org/abs/2308.11119",
    "authors": [
      "Masato Tamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11444",
    "title": "Adaptive Graduated Non-Convexity for Pose Graph Optimization",
    "abstract": " Comments: 4 pages, 3 figures. Accepted for the workshop on Robotic Perception and Mapping(ROPEM): Frontier Vision & Learning Techniques, organized at the 2023 International Conference on Intelligent Robots and Systems (IROS) ",
    "url": "https://arxiv.org/abs/2308.11444",
    "authors": [
      "Seungwon Choi",
      "Wonseok Kang",
      "Jiseong Chung",
      "Jaehyun Kim",
      "Tae-wan Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.13546",
    "title": "Functional Graph Contrastive Learning of Hyperscanning EEG Reveals  Emotional Contagion Evoked by Stereotype-Based Stressors",
    "abstract": " Comments: 14 pages, 4 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2308.13546",
    "authors": [
      "Jingyun Huang",
      "Rachel C. Amey",
      "Mengting Liu",
      "Chad E. Forbes"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.15309",
    "title": "Understanding the Privacy Risks of Popular Search Engine Advertising  Systems",
    "abstract": " Title: Understanding the Privacy Risks of Popular Search Engine Advertising  Systems ",
    "url": "https://arxiv.org/abs/2308.15309",
    "authors": [
      "Salim Chouaki",
      "Oana Goga",
      "Hamed Haddadi",
      "Peter Snyder"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.02354",
    "title": "A Lightweight and Transferable Design for Robust LEGO Manipulation",
    "abstract": " Title: A Lightweight and Transferable Design for Robust LEGO Manipulation ",
    "url": "https://arxiv.org/abs/2309.02354",
    "authors": [
      "Ruixuan Liu",
      "Yifan Sun",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.03033",
    "title": "Deep Learning for Polycystic Kidney Disease: Utilizing Neural Networks  for Accurate and Early Detection through Gene Expression Analysis",
    "abstract": " Comments: 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2309.03033",
    "authors": [
      "Kapil Panda",
      "Anirudh Mazumder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.04737",
    "title": "Training of Spiking Neural Network joint Curriculum Learning Strategy",
    "abstract": " Title: Training of Spiking Neural Network joint Curriculum Learning Strategy ",
    "url": "https://arxiv.org/abs/2309.04737",
    "authors": [
      "Lingling Tang",
      "Jiangtao Hu",
      "Hua Yu",
      "Surui Liu",
      "Jielei Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.06118",
    "title": "CHITNet: A Complementary to Harmonious Information Transfer Network for  Infrared and Visible Image Fusion",
    "abstract": " Title: CHITNet: A Complementary to Harmonious Information Transfer Network for  Infrared and Visible Image Fusion ",
    "url": "https://arxiv.org/abs/2309.06118",
    "authors": [
      "Yafei Zhang",
      "Keying Du",
      "Huafeng Li",
      "Zhengtao Yu",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.06219",
    "title": "Human Action Co-occurrence in Lifestyle Vlogs using Graph Link  Prediction",
    "abstract": " Title: Human Action Co-occurrence in Lifestyle Vlogs using Graph Link  Prediction ",
    "url": "https://arxiv.org/abs/2309.06219",
    "authors": [
      "Oana Ignat",
      "Santiago Castro",
      "Weiji Li",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.06577",
    "title": "Efficient Finite Initialization for Tensorized Neural Networks",
    "abstract": " Comments: 6 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2309.06577",
    "authors": [
      "Alejandro Mata Ali",
      "I\u00f1igo Perez Delgado",
      "Marina Ristol Roura",
      "Aitor Moreno Fdez. de Leceta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2309.06902",
    "title": "CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign  Detection Under Extreme Conditions",
    "abstract": " Title: CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign  Detection Under Extreme Conditions ",
    "url": "https://arxiv.org/abs/2309.06902",
    "authors": [
      "Haoqin Hong",
      "Yue Zhou",
      "Xiangyu Shu",
      "Xiaofang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07545",
    "title": "DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph",
    "abstract": " Comments: Accepted at International Semantic Web Conference (ISWC) 2023 Posters & Demo Track ",
    "url": "https://arxiv.org/abs/2309.07545",
    "authors": [
      "Debayan Banerjee",
      "Arefa",
      "Ricardo Usbeck",
      "Chris Biemann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08416",
    "title": "Deformable Neural Radiance Fields using RGB and Event Cameras",
    "abstract": " Title: Deformable Neural Radiance Fields using RGB and Event Cameras ",
    "url": "https://arxiv.org/abs/2309.08416",
    "authors": [
      "Qi Ma",
      "Danda Pani Paudel",
      "Ajad Chhatkuli",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.10173",
    "title": "GCNIDS: Graph Convolutional Network-Based Intrusion Detection System for  CAN Bus",
    "abstract": " Title: GCNIDS: Graph Convolutional Network-Based Intrusion Detection System for  CAN Bus ",
    "url": "https://arxiv.org/abs/2309.10173",
    "authors": [
      "Maloy Kumar Devnath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.10219",
    "title": "Multi-level feature fusion network combining attention mechanisms for  polyp segmentation",
    "abstract": " Title: Multi-level feature fusion network combining attention mechanisms for  polyp segmentation ",
    "url": "https://arxiv.org/abs/2309.10219",
    "authors": [
      "Junzhuo Liu",
      "Qiaosong Chen",
      "Ye Zhang",
      "Zhixiang Wang",
      "Deng Xin",
      "Jin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.10475",
    "title": "LineMarkNet: Line Landmark Detection for Valet Parking",
    "abstract": " Comments: 29 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2309.10475",
    "authors": [
      "Zizhang Wu",
      "Yuanzhu Gan",
      "Tianhao Xu",
      "Rui Tang",
      "Jian Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.10509",
    "title": "Polynomial-time Solver of Tridiagonal QUBO and QUDO problems with Tensor  Networks",
    "abstract": " Comments: 6 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2309.10509",
    "authors": [
      "Alejandro Mata Ali",
      "I\u00f1igo Perez Delgado",
      "Marina Ristol Roura",
      "Aitor Moreno Fdez. de Leceta"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2309.10527",
    "title": "SPOT: Scalable 3D Pre-training via Occupancy Prediction for Autonomous  Driving",
    "abstract": " Comments: 15 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2309.10527",
    "authors": [
      "Xiangchao Yan",
      "Runjian Chen",
      "Bo Zhang",
      "Jiakang Yuan",
      "Xinyu Cai",
      "Botian Shi",
      "Wenqi Shao",
      "Junchi Yan",
      "Ping Luo",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.10563",
    "title": "A Hierarchical Neural Framework for Classification and its Explanation  in Large Unstructured Legal Documents",
    "abstract": " Title: A Hierarchical Neural Framework for Classification and its Explanation  in Large Unstructured Legal Documents ",
    "url": "https://arxiv.org/abs/2309.10563",
    "authors": [
      "Nishchal Prasad",
      "Mohand Boughanem",
      "Taoufik Dkaki"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10639",
    "title": "Geometric structure of Deep Learning networks and construction of global  ${\\mathcal L}^2$ minimizers",
    "abstract": " Comments: AMS Latex, 21 pages. Typos corrected, slightly extended ",
    "url": "https://arxiv.org/abs/2309.10639",
    "authors": [
      "Thomas Chen",
      "Patricia Mu\u00f1oz Ewald"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Mathematical Physics (math-ph)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.11012",
    "title": "A Survey on Acoustic Side Channel Attacks on Keyboards",
    "abstract": " Comments: 22 pages, conference ",
    "url": "https://arxiv.org/abs/2309.11012",
    "authors": [
      "Alireza Taheritajar",
      "Zahra Mahmoudpour Harris",
      "Reza Rahaeimehr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.11109",
    "title": "Self-supervised Domain-agnostic Domain Adaptation for Satellite Images",
    "abstract": " Title: Self-supervised Domain-agnostic Domain Adaptation for Satellite Images ",
    "url": "https://arxiv.org/abs/2309.11109",
    "authors": [
      "Fahong Zhang",
      "Yilei Shi",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.11281",
    "title": "Language-driven Object Fusion into Neural Radiance Fields with  Pose-Conditioned Dataset Updates",
    "abstract": " Title: Language-driven Object Fusion into Neural Radiance Fields with  Pose-Conditioned Dataset Updates ",
    "url": "https://arxiv.org/abs/2309.11281",
    "authors": [
      "Ka Chun Shum",
      "Jaeyeon Kim",
      "Binh-Son Hua",
      "Duc Thanh Nguyen",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11851",
    "title": "DEYOv3: DETR with YOLO for Real-time Object Detection",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2309.11851",
    "authors": [
      "Haodong Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11917",
    "title": "Robust Sensor Fusion for Indoor Wireless Localization",
    "abstract": " Title: Robust Sensor Fusion for Indoor Wireless Localization ",
    "url": "https://arxiv.org/abs/2309.11917",
    "authors": [
      "Gang Wang",
      "Zuxuan Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.12585",
    "title": "BGF-YOLO: Enhanced YOLOv8 with Multiscale Attentional Feature Fusion for  Brain Tumor Detection",
    "abstract": " Title: BGF-YOLO: Enhanced YOLOv8 with Multiscale Attentional Feature Fusion for  Brain Tumor Detection ",
    "url": "https://arxiv.org/abs/2309.12585",
    "authors": [
      "Ming Kang",
      "Chee-Ming Ting",
      "Fung Fung Ting",
      "Rapha\u00ebl C.-W. Phan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2309.13002",
    "title": "Expressive variational quantum circuits provide inherent privacy in  federated learning",
    "abstract": " Comments: 24 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2309.13002",
    "authors": [
      "Niraj Kumar",
      "Jamie Heredge",
      "Changhao Li",
      "Shaltiel Eloul",
      "Shree Hari Sureshbabu",
      "Marco Pistoia"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  }
]