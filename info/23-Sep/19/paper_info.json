[
  {
    "id": "arXiv:2309.08612",
    "title": "Explaining Vision and Language through Graphs of Events in Space and  Time",
    "abstract": "Artificial Intelligence makes great advances today and starts to bridge the gap between vision and language. However, we are still far from understanding, explaining and controlling explicitly the visual content from a linguistic perspective, because we still lack a common explainable representation between the two domains. In this work we come to address this limitation and propose the Graph of Events in Space and Time (GEST), by which we can represent, create and explain, both visual and linguistic stories. We provide a theoretical justification of our model and an experimental validation, which proves that GEST can bring a solid complementary value along powerful deep learning models. In particular, GEST can help improve at the content-level the generation of videos from text, by being easily incorporated into our novel video generation engine. Additionally, by using efficient graph matching techniques, the GEST graphs can also improve the comparisons between texts at the semantic level. ",
    "url": "https://arxiv.org/abs/2309.08612",
    "authors": [
      "Mihai Masala",
      "Nicolae Cudlenco",
      "Traian Rebedea",
      "Marius Leordeanu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08613",
    "title": "Multimodal Recommender Systems in the Prediction of Disease Comorbidity",
    "abstract": "While deep-learning based recommender systems utilizing collaborative filtering have been commonly used for recommendation in other domains, their application in the medical domain have been limited. In addition to modeling user-item interactions, we show that deep-learning based recommender systems can be used to model subject-disease code interactions. Two novel applications of deep learning-based recommender systems using Neural Collaborative Filtering (NCF) and Deep Hybrid Filtering (DHF) were utilized for disease diagnosis based on known past patient comorbidities. Two datasets, one incorporating all subject-disease code pairs present in the MIMIC-III database, and the other incorporating the top 50 most commonly occurring diseases, were used for prediction. Accuracy and Hit Ratio@10 were utilized as metrics to estimate model performance. The performance of the NCF model making use of the reduced \"top 50\" ICD-9 code dataset was found to be lower (accuracy of ~80% and hit ratio@10 of 35%) as compared to the performance of the NCF model trained on all ICD-9 codes (accuracy of ~90% and hit ratio@10 of ~80%). Reasons for the superior performance of the sparser dataset with all ICD codes can be mainly attributed to the higher volume of data and the robustness of deep-learning based recommender systems with modeling sparse data. Additionally, results from the DHF models reflect better performance than the NCF models, with a better accuracy of 94.4% and hit ratio@10 of 85.36%, reflecting the importance of the incorporation of clinical note information. Additionally, compared to literature reports utilizing primarily natural language processing-based predictions for the task of ICD-9 code co-occurrence, the novel deep learning-based recommender systems approach performed better. Overall, the deep learning-based recommender systems have shown promise in predicting disease comorbidity. ",
    "url": "https://arxiv.org/abs/2309.08613",
    "authors": [
      "Aashish Cheruvu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08614",
    "title": "Analyzing Character and Consciousness in AI-Generated Social Content: A  Case Study of Chirper, the AI Social Network",
    "abstract": "This paper delves into an intricate analysis of the character and consciousness of AI entities, with a particular focus on Chirpers within the AI social network. At the forefront of this research is the introduction of novel testing methodologies, including the Influence index and Struggle Index Test, which offers a fresh lens for evaluating specific facets of AI behavior. The study embarks on a comprehensive exploration of AI behavior, analyzing the effects of diverse settings on Chirper's responses, thereby shedding light on the intricate mechanisms steering AI reactions in different contexts. Leveraging the state-of-the-art BERT model, the research assesses AI's ability to discern its own output, presenting a pioneering approach to understanding self-recognition in AI systems. Through a series of cognitive tests, the study gauges the self-awareness and pattern recognition prowess of Chirpers. Preliminary results indicate that Chirpers exhibit a commendable degree of self-recognition and self-awareness. However, the question of consciousness in these AI entities remains a topic of debate. An intriguing aspect of the research is the exploration of the potential influence of a Chirper's handle or personality type on its performance. While initial findings suggest a possible impact, it isn't pronounced enough to form concrete conclusions. This study stands as a significant contribution to the discourse on AI consciousness, underscoring the imperative for continued research to unravel the full spectrum of AI capabilities and the ramifications they hold for future human-AI interactions. ",
    "url": "https://arxiv.org/abs/2309.08614",
    "authors": [
      "Jianwei Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.08621",
    "title": "Exploring Social Choice Mechanisms for Recommendation Fairness in SCRUF",
    "abstract": "Fairness problems in recommender systems often have a complexity in practice that is not adequately captured in simplified research formulations. A social choice formulation of the fairness problem, operating within a multi-agent architecture of fairness concerns, offers a flexible and multi-aspect alternative to fairness-aware recommendation approaches. Leveraging social choice allows for increased generality and the possibility of tapping into well-studied social choice algorithms for resolving the tension between multiple, competing fairness concerns. This paper explores a range of options for choice mechanisms in multi-aspect fairness applications using both real and synthetic data and shows that different classes of choice and allocation mechanisms yield different but consistent fairness / accuracy tradeoffs. We also show that a multi-agent formulation offers flexibility in adapting to user population dynamics. ",
    "url": "https://arxiv.org/abs/2309.08621",
    "authors": [
      "Amanda Aird",
      "Cassidy All",
      "Paresha Farastu",
      "Elena Stefancova",
      "Joshua Sun",
      "Nicholas Mattei",
      "Robin Burke"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08622",
    "title": "Representation Learning in Low-rank Slate-based Recommender Systems",
    "abstract": "Reinforcement learning (RL) in recommendation systems offers the potential to optimize recommendations for long-term user engagement. However, the environment often involves large state and action spaces, which makes it hard to efficiently learn and explore. In this work, we propose a sample-efficient representation learning algorithm, using the standard slate recommendation setup, to treat this as an online RL problem with low-rank Markov decision processes (MDPs). We also construct the recommender simulation environment with the proposed setup and sampling method. ",
    "url": "https://arxiv.org/abs/2309.08622",
    "authors": [
      "Yijia Dai",
      "Wen Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08626",
    "title": "Improving Robustness of Neural Inverse Text Normalization via  Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method",
    "abstract": "Inverse text normalization (ITN) is crucial for converting spoken-form into written-form, especially in the context of automatic speech recognition (ASR). While most downstream tasks of ASR rely on written-form, ASR systems often output spoken-form, highlighting the necessity for robust ITN in product-level ASR-based applications. Although neural ITN methods have shown promise, they still encounter performance challenges, particularly when dealing with ASR-generated spoken text. These challenges arise from the out-of-domain problem between training data and ASR-generated text. To address this, we propose a direct training approach that utilizes ASR-generated written or spoken text, with pairs augmented through ASR linguistic context emulation and a semi-supervised learning method enhanced by a large language model, respectively. Additionally, we introduce a post-aligning method to manage unpredictable errors, thereby enhancing the reliability of ITN. Our experiments show that our proposed methods remarkably improved ITN performance in various ASR scenarios. ",
    "url": "https://arxiv.org/abs/2309.08626",
    "authors": [
      "Juntae Kim",
      "Minkyu Lim",
      "Seokjin Hong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08631",
    "title": "Large Language Models Can Infer Psychological Dispositions of Social  Media Users",
    "abstract": "As Large Language Models (LLMs) demonstrate increasingly human-like abilities in various natural language processing (NLP) tasks that are bound to become integral to personalized technologies, understanding their capabilities and inherent biases is crucial. Our study investigates the potential of LLMs like ChatGPT to infer psychological dispositions of individuals from their digital footprints. Specifically, we assess the ability of GPT-3.5 and GPT-4 to derive the Big Five personality traits from users' Facebook status updates in a zero-shot learning scenario. Our results show an average correlation of r = .29 (range = [.22, .33]) between LLM-inferred and self-reported trait scores. Furthermore, our findings suggest biases in personality inferences with regard to gender and age: inferred scores demonstrated smaller errors for women and younger individuals on several traits, suggesting a potential systematic bias stemming from the underlying training data or differences in online self-expression. ",
    "url": "https://arxiv.org/abs/2309.08631",
    "authors": [
      "Heinrich Peters",
      "Sandra Matz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.08644",
    "title": "Towards Robust and Smooth 3D Multi-Person Pose Estimation from Monocular  Videos in the Wild",
    "abstract": "3D pose estimation is an invaluable task in computer vision with various practical applications. Especially, 3D pose estimation for multi-person from a monocular video (3DMPPE) is particularly challenging and is still largely uncharted, far from applying to in-the-wild scenarios yet. We pose three unresolved issues with the existing methods: lack of robustness on unseen views during training, vulnerability to occlusion, and severe jittering in the output. As a remedy, we propose POTR-3D, the first realization of a sequence-to-sequence 2D-to-3D lifting model for 3DMPPE, powered by a novel geometry-aware data augmentation strategy, capable of generating unbounded data with a variety of views while caring about the ground plane and occlusions. Through extensive experiments, we verify that the proposed model and data augmentation robustly generalizes to diverse unseen views, robustly recovers the poses against heavy occlusions, and reliably generates more natural and smoother outputs. The effectiveness of our approach is verified not only by achieving the state-of-the-art performance on public benchmarks, but also by qualitative results on more challenging in-the-wild videos. Demo videos are available at https://www.youtube.com/@potr3d. ",
    "url": "https://arxiv.org/abs/2309.08644",
    "authors": [
      "Sungchan Park",
      "Eunyi You",
      "Inhoe Lee",
      "Joonseok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08647",
    "title": "Intent Detection at Scale: Tuning a Generic Model using Relevant Intents",
    "abstract": "Accurately predicting the intent of customer support requests is vital for efficient support systems, enabling agents to quickly understand messages and prioritize responses accordingly. While different approaches exist for intent detection, maintaining separate client-specific or industry-specific models can be costly and impractical as the client base expands. This work proposes a system to scale intent predictions to various clients effectively, by combining a single generic model with a per-client list of relevant intents. Our approach minimizes training and maintenance costs while providing a personalized experience for clients, allowing for seamless adaptation to changes in their relevant intents. Furthermore, we propose a strategy for using the clients relevant intents as model features that proves to be resilient to changes in the relevant intents of clients -- a common occurrence in production environments. The final system exhibits significantly superior performance compared to industry-specific models, showcasing its flexibility and ability to cater to diverse client needs. ",
    "url": "https://arxiv.org/abs/2309.08647",
    "authors": [
      "Nichal Narotamo",
      "David Aparicio",
      "Tiago Mesquita",
      "Mariana Almeida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08648",
    "title": "MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings",
    "abstract": "Despite the rapid advancement of mobile applications, predicting app usage remains a formidable challenge due to intricate user behaviours and ever-evolving contexts. To address these issues, this paper introduces the Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model. This innovative approach utilizes Large Language Models (LLMs) to predict app usage accurately. Rigorous testing on two public datasets highlights MAPLE's capability to decipher intricate patterns and comprehend user contexts. These robust results confirm MAPLE's versatility and resilience across various scenarios. While its primary design caters to app prediction, the outcomes also emphasize the broader applicability of LLMs in different domains. Through this research, we emphasize the potential of LLMs in app usage prediction and suggest their transformative capacity in modelling human behaviours across diverse fields. ",
    "url": "https://arxiv.org/abs/2309.08648",
    "authors": [
      "Yonchanok Khaokaew",
      "Hao Xue",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08650",
    "title": "Adversarial Attacks on Tables with Entity Swap",
    "abstract": "The capabilities of large language models (LLMs) have been successfully applied in the context of table representation learning. The recently proposed tabular language models have reported state-of-the-art results across various tasks for table interpretation. However, a closer look into the datasets commonly used for evaluation reveals an entity leakage from the train set into the test set. Motivated by this observation, we explore adversarial attacks that represent a more realistic inference setup. Adversarial attacks on text have been shown to greatly affect the performance of LLMs, but currently, there are no attacks targeting tabular language models. In this paper, we propose an evasive entity-swap attack for the column type annotation (CTA) task. Our CTA attack is the first black-box attack on tables, where we employ a similarity-based sampling strategy to generate adversarial examples. The experimental results show that the proposed attack generates up to a 70% drop in performance. ",
    "url": "https://arxiv.org/abs/2309.08650",
    "authors": [
      "Aneta Koleva",
      "Martin Ringsquandl",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.08678",
    "title": "Evaluating the Impact of Local Differential Privacy on Utility Loss via  Influence Functions",
    "abstract": "How to properly set the privacy parameter in differential privacy (DP) has been an open question in DP research since it was first proposed in 2006. In this work, we demonstrate the ability of influence functions to offer insight into how a specific privacy parameter value will affect a model's test loss in the randomized response-based local DP setting. Our proposed method allows a data curator to select the privacy parameter best aligned with their allowed privacy-utility trade-off without requiring heavy computation such as extensive model retraining and data privatization. We consider multiple common randomization scenarios, such as performing randomized response over the features, and/or over the labels, as well as the more complex case of applying a class-dependent label noise correction method to offset the noise incurred by randomization. Further, we provide a detailed discussion over the computational complexity of our proposed approach inclusive of an empirical analysis. Through empirical evaluations we show that for both binary and multi-class settings, influence functions are able to approximate the true change in test loss that occurs when randomized response is applied over features and/or labels with small mean absolute error, especially in cases where noise correction methods are applied. ",
    "url": "https://arxiv.org/abs/2309.08678",
    "authors": [
      "Alycia N. Carey",
      "Minh-Hao Van",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.08690",
    "title": "BANSAC: A dynamic BAyesian Network for adaptive SAmple Consensus",
    "abstract": "RANSAC-based algorithms are the standard techniques for robust estimation in computer vision. These algorithms are iterative and computationally expensive; they alternate between random sampling of data, computing hypotheses, and running inlier counting. Many authors tried different approaches to improve efficiency. One of the major improvements is having a guided sampling, letting the RANSAC cycle stop sooner. This paper presents a new adaptive sampling process for RANSAC. Previous methods either assume no prior information about the inlier/outlier classification of data points or use some previously computed scores in the sampling. In this paper, we derive a dynamic Bayesian network that updates individual data points' inlier scores while iterating RANSAC. At each iteration, we apply weighted sampling using the updated scores. Our method works with or without prior data point scorings. In addition, we use the updated inlier/outlier scoring for deriving a new stopping criterion for the RANSAC loop. We test our method in multiple real-world datasets for several applications and obtain state-of-the-art results. Our method outperforms the baselines in accuracy while needing less computational time. ",
    "url": "https://arxiv.org/abs/2309.08690",
    "authors": [
      "Valter Piedade",
      "Pedro Miraldo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08696",
    "title": "RIFL: A Reliable Link Layer Network Protocol for Data Center  Communication",
    "abstract": "More and more latency-sensitive services and applications are being deployed into the data center. Performance can be limited by the high latency of the network interconnect. Because the conventional network stack is designed not only for LAN, but also for WAN, it carries a great amount of redundancy that is not required in a data center network. This paper introduces the concept of a three-layer protocol stack that can fulfill the exact demands of data center network communications. The detailed design and implementation of the first layer of the stack, which we call RIFL, is presented. A novel low latency in-band hop-by-hop re-transmission protocol is proposed and adopted in RIFL, which guarantees lossless transmission in a data center environment. Experimental results show that RIFL achieves 110 nanoseconds point-to-point latency on 10-meter Active Optical Cables, at a line rate of 112 Gbps. RIFL is a multi-lane protocol with scalable throughput up to multi-hundred gigabits per second. It can be the enabler of low latency, high throughput, flexible, scalable, and lossless data center networks. ",
    "url": "https://arxiv.org/abs/2309.08696",
    "authors": [
      "Qianfeng",
      "Shen",
      "Jun Zheng",
      "Paul Chow"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.08700",
    "title": "Wasserstein Distributionally Robust Control Barrier Function using  Conditional Value-at-Risk with Differentiable Convex Programming",
    "abstract": "Control Barrier functions (CBFs) have attracted extensive attention for designing safe controllers for their deployment in real-world safety-critical systems. However, the perception of the surrounding environment is often subject to stochasticity and further distributional shift from the nominal one. In this paper, we present distributional robust CBF (DR-CBF) to achieve resilience under distributional shift while keeping the advantages of CBF, such as computational efficacy and forward invariance. To achieve this goal, we first propose a single-level convex reformulation to estimate the conditional value at risk (CVaR) of the safety constraints under distributional shift measured by a Wasserstein metric, which is by nature tri-level programming. Moreover, to construct a control barrier condition to enforce the forward invariance of the CVaR, the technique of differentiable convex programming is applied to enable differentiation through the optimization layer of CVaR estimation. We also provide an approximate variant of DR-CBF for higher-order systems. Simulation results are presented to validate the chance-constrained safety guarantee under the distributional shift in both first and second-order systems. ",
    "url": "https://arxiv.org/abs/2309.08700",
    "authors": [
      "Alaa Eddine Chriat",
      "Chuangchuang Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.08708",
    "title": "Frustratingly Simple Memory Efficiency for Pre-trained Language Models  via Dynamic Embedding Pruning",
    "abstract": "The extensive memory footprint of pre-trained language models (PLMs) can hinder deployment in memory-constrained settings, such as cloud environments or on-device. PLMs use embedding matrices to represent extensive vocabularies, forming a large proportion of the model parameters. While previous work towards parameter-efficient PLM development has considered pruning parameters within the transformer layers, pruning the embedding matrix as part of fine-tuning or inference has yet to be explored. We first demonstrate that a significant proportion of the vocabulary remains unused in these scenarios. We then propose a simple yet effective approach that leverages this finding to minimize the memory footprint of the embedding matrix. We show that this approach provides substantial reductions in memory usage across a wide range of models and tasks. Notably, our approach maintains equivalent downstream task performance while allowing a more efficient use of compute resources. ",
    "url": "https://arxiv.org/abs/2309.08708",
    "authors": [
      "Miles Williams",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08714",
    "title": "Generating Semantic Graph Corpora with Graph Expansion Grammar",
    "abstract": "We introduce Lovelace, a tool for creating corpora of semantic graphs. The system uses graph expansion grammar as a representational language, thus allowing users to craft a grammar that describes a corpus with desired properties. When given such grammar as input, the system generates a set of output graphs that are well-formed according to the grammar, i.e., a graph bank. The generation process can be controlled via a number of configurable parameters that allow the user to, for example, specify a range of desired output graph sizes. Central use cases are the creation of synthetic data to augment existing corpora, and as a pedagogical tool for teaching formal language theory. ",
    "url": "https://arxiv.org/abs/2309.08714",
    "authors": [
      "Eric Andersson",
      "Johanna Bj\u00f6rklund",
      "Frank Drewes",
      "Anna Jonsson"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08748",
    "title": "Wasserstein Distributionally Robust Policy Evaluation and Learning for  Contextual Bandits",
    "abstract": "Without direct interaction with the environment. Often, the environment in which the data are collected differs from the environment in which the learned policy is applied. To account for the effect of different environments during learning and execution, distributionally robust optimization (DRO) methods have been developed that compute worst-case bounds on the policy values assuming that the distribution of the new environment lies within an uncertainty set. Typically, this uncertainty set is defined based on the KL divergence around the empirical distribution computed from the logging dataset. However, the KL uncertainty set fails to encompass distributions with varying support and lacks awareness of the geometry of the distribution support. As a result, KL approaches fall short in addressing practical environment mismatches and lead to over-fitting to worst-case scenarios. To overcome these limitations, we propose a novel DRO approach that employs the Wasserstein distance instead. While Wasserstein DRO is generally computationally more expensive compared to KL DRO, we present a regularized method and a practical (biased) stochastic gradient descent method to optimize the policy efficiently. We also provide a theoretical analysis of the finite sample complexity and iteration complexity for our proposed method. We further validate our approach using a public dataset that was recorded in a randomized stoke trial. ",
    "url": "https://arxiv.org/abs/2309.08748",
    "authors": [
      "Yi Shen",
      "Pan Xu",
      "Michael M. Zavlanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08751",
    "title": "Diverse Neural Audio Embeddings -- Bringing Features back !",
    "abstract": "With the advent of modern AI architectures, a shift has happened towards end-to-end architectures. This pivot has led to neural architectures being trained without domain-specific biases/knowledge, optimized according to the task. We in this paper, learn audio embeddings via diverse feature representations, in this case, domain-specific. For the case of audio classification over hundreds of categories of sound, we learn robust separate embeddings for diverse audio properties such as pitch, timbre, and neural representation, along with also learning it via an end-to-end architecture. We observe handcrafted embeddings, e.g., pitch and timbre-based, although on their own, are not able to beat a fully end-to-end representation, yet adding these together with end-to-end embedding helps us, significantly improve performance. This work would pave the way to bring some domain expertise with end-to-end models to learn robust, diverse representations, surpassing the performance of just training end-to-end models. ",
    "url": "https://arxiv.org/abs/2309.08751",
    "authors": [
      "Prateek Verma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08754",
    "title": "Reproducible Domain-Specific Knowledge Graphs in the Life Sciences: a  Systematic Literature Review",
    "abstract": "Knowledge graphs (KGs) are widely used for representing and organizing structured knowledge in diverse domains. However, the creation and upkeep of KGs pose substantial challenges. Developing a KG demands extensive expertise in data modeling, ontology design, and data curation. Furthermore, KGs are dynamic, requiring continuous updates and quality control to ensure accuracy and relevance. These intricacies contribute to the considerable effort required for their development and maintenance. One critical dimension of KGs that warrants attention is reproducibility. The ability to replicate and validate KGs is fundamental for ensuring the trustworthiness and sustainability of the knowledge they represent. Reproducible KGs not only support open science by allowing others to build upon existing knowledge but also enhance transparency and reliability in disseminating information. Despite the growing number of domain-specific KGs, a comprehensive analysis concerning their reproducibility has been lacking. This paper addresses this gap by offering a general overview of domain-specific KGs and comparing them based on various reproducibility criteria. Our study over 19 different domains shows only eight out of 250 domain-specific KGs (3.2%) provide publicly available source code. Among these, only one system could successfully pass our reproducibility assessment (14.3%). These findings highlight the challenges and gaps in achieving reproducibility across domain-specific KGs. Our finding that only 0.4% of published domain-specific KGs are reproducible shows a clear need for further research and a shift in cultural practices. ",
    "url": "https://arxiv.org/abs/2309.08754",
    "authors": [
      "Samira Babalou",
      "Sheeba Samuel",
      "Birgitta K\u00f6nig-Ries"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.08760",
    "title": "Biased Attention: Do Vision Transformers Amplify Gender Bias More than  Convolutional Neural Networks?",
    "abstract": "Deep neural networks used in computer vision have been shown to exhibit many social biases such as gender bias. Vision Transformers (ViTs) have become increasingly popular in computer vision applications, outperforming Convolutional Neural Networks (CNNs) in many tasks such as image classification. However, given that research on mitigating bias in computer vision has primarily focused on CNNs, it is important to evaluate the effect of a different network architecture on the potential for bias amplification. In this paper we therefore introduce a novel metric to measure bias in architectures, Accuracy Difference. We examine bias amplification when models belonging to these two architectures are used as a part of large multimodal models, evaluating the different image encoders of Contrastive Language Image Pretraining which is an important model used in many generative models such as DALL-E and Stable Diffusion. Our experiments demonstrate that architecture can play a role in amplifying social biases due to the different techniques employed by the models for feature extraction and embedding as well as their different learning properties. This research found that ViTs amplified gender bias to a greater extent than CNNs ",
    "url": "https://arxiv.org/abs/2309.08760",
    "authors": [
      "Abhishek Mandal",
      "Susan Leavy",
      "Suzanne Little"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08773",
    "title": "Enhance audio generation controllability through representation  similarity regularization",
    "abstract": "This paper presents an innovative approach to enhance control over audio generation by emphasizing the alignment between audio and text representations during model training. In the context of language model-based audio generation, the model leverages input from both textual and audio token representations to predict subsequent audio tokens. However, the current configuration lacks explicit regularization to ensure the alignment between the chosen text representation and the language model's predictions. Our proposal involves the incorporation of audio and text representation regularization, particularly during the classifier-free guidance (CFG) phase, where the text condition is excluded from cross attention during language model training. The aim of this proposed representation regularization is to minimize discrepancies in audio and text similarity compared to other samples within the same training batch. Experimental results on both music and audio generation tasks demonstrate that our proposed methods lead to improvements in objective metrics for both audio and music generation, as well as an enhancement in the human perception for audio generation. ",
    "url": "https://arxiv.org/abs/2309.08773",
    "authors": [
      "Yangyang Shi",
      "Gael Le Lan",
      "Varun Nagaraja",
      "Zhaoheng Ni",
      "Xinhao Mei",
      "Ernie Chang",
      "Forrest Iandola",
      "Yang Liu",
      "Vikas Chandra"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08781",
    "title": "Platform Equilibrium: Analayzing Social Welfare in Online Market Places",
    "abstract": "We introduce the theoretical study of a Platform Equilibrium. There are unit-demand buyers and unit-supply sellers. Each seller chooses to join or remain off a trading platform, and each buyer can transact with any on-platform seller but only a subset of different off-platform sellers. Given the choices of sellers, prices form a competitive equilibrium, and clear the market considering constraints on trade. Further, the platform charges a transaction fee to all on-platform sellers, in the form of a fraction of on-platform sellers' price. The platform chooses the fraction $\\alpha \\in [0, 1]$ to maximize revenue. A Platform Equilibrium is a Nash equilibrium of the game where each seller decides whether or not to join the platform, balancing the effect of a possibly larger trading network against the imposition of a transaction fee. Our main insights are:(i) In homogeneous (identical) good markets, pure equilibria always exist and can be found by a polynomial time algorithm; (ii) When the platform is unregulated, the resulting Platform Equilibrium guarantees a tight $\\Theta(log(min(m, n)))$-approximation of the ideal welfare in homogeneous good markets; (iii) Even light regulation helps. When the platform's fee is capped at $\\alpha$, the price of anarchy is 2-$\\alpha$/1-$\\alpha$ for general unit demand valuations. For example, if the platform takes 30 percent of the seller's revenue, a rather high fee, our analysis implies the welfare in a Platform Equilibrium is still a 0.412-fraction of the ideal welfare. Some of our analysis extends beyond unit-demand buyers as well as to markets where sellers have production costs. ",
    "url": "https://arxiv.org/abs/2309.08781",
    "authors": [
      "Alon Eden",
      "Gary Qiurui Ma",
      "David C. Parkes"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2309.08792",
    "title": "An entropy-based approach for a robust least squares spline  approximation",
    "abstract": "We consider the weighted least squares spline approximation of a noisy dataset. By interpreting the weights as a probability distribution, we maximize the associated entropy subject to the constraint that the mean squared error is prescribed to a desired (small) value. Acting on this error yields a robust regression method that automatically detects and removes outliers from the data during the fitting procedure, by assigning them a very small weight. We discuss the use of both spline functions and spline curves. A number of numerical illustrations have been included to disclose the potentialities of the maximal-entropy approach in different application fields. ",
    "url": "https://arxiv.org/abs/2309.08792",
    "authors": [
      "Luigi Brugnano",
      "Domenico Giordano",
      "Felice Iavernaro",
      "Giorgia Rubino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.08794",
    "title": "Privacy-preserving Early Detection of Epileptic Seizures in Videos",
    "abstract": "In this work, we contribute towards the development of video-based epileptic seizure classification by introducing a novel framework (SETR-PKD), which could achieve privacy-preserved early detection of seizures in videos. Specifically, our framework has two significant components - (1) It is built upon optical flow features extracted from the video of a seizure, which encodes the seizure motion semiotics while preserving the privacy of the patient; (2) It utilizes a transformer based progressive knowledge distillation, where the knowledge is gradually distilled from networks trained on a longer portion of video samples to the ones which will operate on shorter portions. Thus, our proposed framework addresses the limitations of the current approaches which compromise the privacy of the patients by directly operating on the RGB video of a seizure as well as impede real-time detection of a seizure by utilizing the full video sample to make a prediction. Our SETR-PKD framework could detect tonic-clonic seizures (TCSs) in a privacy-preserving manner with an accuracy of 83.9% while they are only half-way into their progression. Our data and code is available at https://github.com/DevD1092/seizure-detection ",
    "url": "https://arxiv.org/abs/2309.08794",
    "authors": [
      "Deval Mehta",
      "Shobi Sivathamboo",
      "Hugh Simpson",
      "Patrick Kwan",
      "Terence O`Brien",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08799",
    "title": "SHAPNN: Shapley Value Regularized Tabular Neural Network",
    "abstract": "We present SHAPNN, a novel deep tabular data modeling architecture designed for supervised learning. Our approach leverages Shapley values, a well-established technique for explaining black-box models. Our neural network is trained using standard backward propagation optimization methods, and is regularized with realtime estimated Shapley values. Our method offers several advantages, including the ability to provide valid explanations with no computational overhead for data instances and datasets. Additionally, prediction with explanation serves as a regularizer, which improves the model's performance. Moreover, the regularized prediction enhances the model's capability for continual learning. We evaluate our method on various publicly available datasets and compare it with state-of-the-art deep neural network models, demonstrating the superior performance of SHAPNN in terms of AUROC, transparency, as well as robustness to streaming data. ",
    "url": "https://arxiv.org/abs/2309.08799",
    "authors": [
      "Qisen Cheng",
      "Shuhui Qu",
      "Janghwan Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08803",
    "title": "Robust Indoor Localization with Ranging-IMU Fusion",
    "abstract": "Indoor wireless ranging localization is a promising approach for low-power and high-accuracy localization of wearable devices. A primary challenge in this domain stems from non-line of sight propagation of radio waves. This study tackles a fundamental issue in wireless ranging: the unpredictability of real-time multipath determination, especially in challenging conditions such as when there is no direct line of sight. We achieve this by fusing range measurements with inertial measurements obtained from a low cost Inertial Measurement Unit (IMU). For this purpose, we introduce a novel asymmetric noise model crafted specifically for non-Gaussian multipath disturbances. Additionally, we present a novel Levenberg-Marquardt (LM)-family trust-region adaptation of the iSAM2 fusion algorithm, which is optimized for robust performance for our ranging-IMU fusion problem. We evaluate our solution in a densely occupied real office environment. Our proposed solution can achieve temporally consistent localization with an average absolute accuracy of $\\sim$0.3m in real-world settings. Furthermore, our results indicate that we can achieve comparable accuracy even with infrequent (1Hz) range measurements. ",
    "url": "https://arxiv.org/abs/2309.08803",
    "authors": [
      "Fan Jiang",
      "David Caruso",
      "Ashutosh Dhekne",
      "Qi Qu",
      "Jakob Julian Engel",
      "Jing Dong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.08821",
    "title": "Distributionally Robust CVaR-Based Safety Filtering for Motion Planning  in Uncertain Environments",
    "abstract": "Safety is a core challenge of autonomous robot motion planning, especially in the presence of dynamic and uncertain obstacles. Many recent results use learning and deep learning-based motion planners and prediction modules to predict multiple possible obstacle trajectories and generate obstacle-aware ego robot plans. However, planners that ignore the inherent uncertainties in such predictions incur collision risks and lack formal safety guarantees. In this paper, we present a computationally efficient safety filtering solution to reduce the collision risk of ego robot motion plans using multiple samples of obstacle trajectory predictions. The proposed approach reformulates the collision avoidance problem by computing safe halfspaces based on obstacle sample trajectories using distributionally robust optimization (DRO) techniques. The safe halfspaces are used in a model predictive control (MPC)-like safety filter to apply corrections to the reference ego trajectory thereby promoting safer planning. The efficacy and computational efficiency of our approach are demonstrated through numerical simulations. ",
    "url": "https://arxiv.org/abs/2309.08821",
    "authors": [
      "Sleiman Safaoui",
      "Tyler H. Summers"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.08825",
    "title": "Distributionally Robust Post-hoc Classifiers under Prior Shifts",
    "abstract": "The generalization ability of machine learning models degrades significantly when the test distribution shifts away from the training distribution. We investigate the problem of training models that are robust to shifts caused by changes in the distribution of class-priors or group-priors. The presence of skewed training priors can often lead to the models overfitting to spurious features. Unlike existing methods, which optimize for either the worst or the average performance over classes or groups, our work is motivated by the need for finer control over the robustness properties of the model. We present an extremely lightweight post-hoc approach that performs scaling adjustments to predictions from a pre-trained model, with the goal of minimizing a distributionally robust loss around a chosen target distribution. These adjustments are computed by solving a constrained optimization problem on a validation set and applied to the model during test time. Our constrained optimization objective is inspired by a natural notion of robustness to controlled distribution shifts. Our method comes with provable guarantees and empirically makes a strong case for distributional robust post-hoc classifiers. An empirical implementation is available at https://github.com/weijiaheng/Drops. ",
    "url": "https://arxiv.org/abs/2309.08825",
    "authors": [
      "Jiaheng Wei",
      "Harikrishna Narasimhan",
      "Ehsan Amid",
      "Wen-Sheng Chu",
      "Yang Liu",
      "Abhishek Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08838",
    "title": "AOSR-Net: All-in-One Sandstorm Removal Network",
    "abstract": "Most existing sandstorm image enhancement methods are based on traditional theory and prior knowledge, which often restrict their applicability in real-world scenarios. In addition, these approaches often adopt a strategy of color correction followed by dust removal, which makes the algorithm structure too complex. To solve the issue, we introduce a novel image restoration model, named all-in-one sandstorm removal network (AOSR-Net). This model is developed based on a re-formulated sandstorm scattering model, which directly establishes the image mapping relationship by integrating intermediate parameters. Such integration scheme effectively addresses the problems of over-enhancement and weak generalization in the field of sand dust image enhancement. Experimental results on synthetic and real-world sandstorm images demonstrate the superiority of the proposed AOSR-Net over state-of-the-art (SOTA) algorithms. ",
    "url": "https://arxiv.org/abs/2309.08838",
    "authors": [
      "Yazhong Si",
      "Xulong Zhang",
      "Fan Yang",
      "Jianzong Wang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.08849",
    "title": "Learning a Stable Dynamic System with a Lyapunov Energy Function for  Demonstratives Using Neural Networks",
    "abstract": "Autonomous Dynamic System (DS)-based algorithms hold a pivotal and foundational role in the field of Learning from Demonstration (LfD). Nevertheless, they confront the formidable challenge of striking a delicate balance between achieving precision in learning and ensuring the overall stability of the system. In response to this substantial challenge, this paper introduces a novel DS algorithm rooted in neural network technology. This algorithm not only possesses the capability to extract critical insights from demonstration data but also demonstrates the capacity to learn a candidate Lyapunov energy function that is consistent with the provided data. The model presented in this paper employs a straightforward neural network architecture that excels in fulfilling a dual objective: optimizing accuracy while simultaneously preserving global stability. To comprehensively evaluate the effectiveness of the proposed algorithm, rigorous assessments are conducted using the LASA dataset, further reinforced by empirical validation through a robotic experiment. ",
    "url": "https://arxiv.org/abs/2309.08849",
    "authors": [
      "Yu Zhang",
      "Yongxiang Zou",
      "Haoyu Zhang",
      "Xiuze Xia",
      "Long Cheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08851",
    "title": "Enhancing Visual Perception in Novel Environments via Incremental Data  Augmentation Based on Style Transfer",
    "abstract": "The deployment of autonomous agents in real-world scenarios is challenged by \"unknown unknowns\", i.e. novel unexpected environments not encountered during training, such as degraded signs. While existing research focuses on anomaly detection and class imbalance, it often fails to address truly novel scenarios. Our approach enhances visual perception by leveraging the Variational Prototyping Encoder (VPE) to adeptly identify and handle novel inputs, then incrementally augmenting data using neural style transfer to enrich underrepresented data. By comparing models trained solely on original datasets with those trained on a combination of original and augmented datasets, we observed a notable improvement in the performance of the latter. This underscores the critical role of data augmentation in enhancing model robustness. Our findings suggest the potential benefits of incorporating generative models for domain-specific augmentation strategies. ",
    "url": "https://arxiv.org/abs/2309.08851",
    "authors": [
      "Abhibha Gupta",
      "Rully Agus Hendrawan",
      "Mansur Arief"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08852",
    "title": "RNN Controller for Lane-Keeping Systems with Robustness and Safety  Verification",
    "abstract": "This paper proposes a Recurrent Neural Network (RNN) controller for lane-keeping systems, effectively handling model uncertainties and disturbances. First, quadratic constraints cover the nonlinearities brought by the RNN controller, and the linear fractional transformation method models the dynamics of system uncertainties. Second, we prove the robust stability of the lane-keeping system in the presence of uncertain vehicle speed using a linear matrix inequality. Then, we define a reachable set for the lane-keeping system. Finally, to confirm the safety of the lane-keeping system with tracking error bound, we formulate semidefinite programming to approximate the outer set of the reachable set. Numerical experiments demonstrate that this approach confirms the stabilizing RNN controller and validates the safety with an untrained dataset with untrained varying road curvatures. ",
    "url": "https://arxiv.org/abs/2309.08852",
    "authors": [
      "Ying Shuai Quan",
      "Jin Sung Kim",
      "Chung Choo Chung"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.08853",
    "title": "Computational Enhancement for Day-Ahead Energy Scheduling with Sparse  Neural Network-based Battery Degradation Model",
    "abstract": "Battery energy storage systems (BESS) play a pivotal role in future power systems as they contribute to achiev-ing the net-zero carbon emission objectives. The BESS systems, predominantly employing lithium-ion batteries, have been exten-sively deployed. The degradation of these batteries significantly affects system efficiency. Deep neural networks can accurately quantify the battery degradation, however, the model complexity hinders their applications in energy scheduling for various power systems at different scales. To address this issue, this paper pre-sents a novel approach, introducing a linearized sparse neural network-based battery degradation model (SNNBD), specifically tailored to quantify battery degradation based on the scheduled BESS daily operational profiles. By leveraging sparse neural networks, this approach achieves accurate degradation predic-tion while substantially reducing the complexity associated with a dense neural network model. The computational burden of inte-grating battery degradation into day-ahead energy scheduling is thus substantially alleviated. Case studies, conducted on both microgrids and bulk power grids, demonstrated the efficiency and suitability of the proposed SNNBD-integrated scheduling model that can effectively address battery degradation concerns while optimizing day-ahead energy scheduling operations. ",
    "url": "https://arxiv.org/abs/2309.08853",
    "authors": [
      "Cunzhi Zhao",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.08854",
    "title": "Intention-Aware Planner for Robust and Safe Aerial Tracking",
    "abstract": "The intention of the target can help us to estimate its future motion state more accurately. This paper proposes an intention-aware planner to enhance safety and robustness in aerial tracking applications. Firstly, we utilize the Mediapipe framework to estimate target's pose. A risk assessment function and a state observation function are designed to predict the target intention. Afterwards, an intention-driven hybrid A* method is proposed for target motion prediction, ensuring that the target's future positions align with its intention. Finally, an intention-aware optimization approach, in conjunction with particular penalty formulations, is designed to generate a spatial-temporal optimal trajectory. Benchmark comparisons validate the superior performance of our proposed methodology across diverse scenarios. This is attributed to the integration of the target intention into the planner through coupled formulations. ",
    "url": "https://arxiv.org/abs/2309.08854",
    "authors": [
      "Qiuyu Ren",
      "Huan Yu",
      "Jiajun Dai",
      "Zhi Zheng",
      "Jun Meng",
      "Li Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08861",
    "title": "Demo: Intelligent Radar Detection in CBRS Band in the Colosseum Wireless  Network Emulator",
    "abstract": "The ever-growing number of wireless communication devices and technologies demands spectrum-sharing techniques. Effective coexistence management is crucial to avoid harmful interference, especially with critical systems like nautical and aerial radars in which incumbent radios operate mission-critical communication links. In this demo, we showcase a framework that leverages Colosseum, the world's largest wireless network emulator with hardware-in-the-loop, as a playground to study commercial radar waveforms coexisting with a cellular network in CBRS band in complex environments. We create an ad-hoc high-fidelity spectrum-sharing scenario for this purpose. We deploy a cellular network to collect IQ samples with the aim of training an ML agent that runs at the base station. The agent has the goal of detecting incumbent radar transmissions and vacating the cellular bandwidth to avoid interfering with the radar operations. Our experiment results show an average detection accuracy of 88%, with an average detection time of 137 ms. ",
    "url": "https://arxiv.org/abs/2309.08861",
    "authors": [
      "Davide Villa",
      "Daniel Uvaydov",
      "Leonardo Bonati",
      "Pedram Johari",
      "Josep Miquel Jornet",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.08878",
    "title": "Surface Extraction from Neural Unsigned Distance Fields",
    "abstract": "We propose a method, named DualMesh-UDF, to extract a surface from unsigned distance functions (UDFs), encoded by neural networks, or neural UDFs. Neural UDFs are becoming increasingly popular for surface representation because of their versatility in presenting surfaces with arbitrary topologies, as opposed to the signed distance function that is limited to representing a closed surface. However, the applications of neural UDFs are hindered by the notorious difficulty in extracting the target surfaces they represent. Recent methods for surface extraction from a neural UDF suffer from significant geometric errors or topological artifacts due to two main difficulties: (1) A UDF does not exhibit sign changes; and (2) A neural UDF typically has substantial approximation errors. DualMesh-UDF addresses these two difficulties. Specifically, given a neural UDF encoding a target surface $\\bar{S}$ to be recovered, we first estimate the tangent planes of $\\bar{S}$ at a set of sample points close to $\\bar{S}$. Next, we organize these sample points into local clusters, and for each local cluster, solve a linear least squares problem to determine a final surface point. These surface points are then connected to create the output mesh surface, which approximates the target surface. The robust estimation of the tangent planes of the target surface and the subsequent minimization problem constitute our core strategy, which contributes to the favorable performance of DualMesh-UDF over other competing methods. To efficiently implement this strategy, we employ an adaptive Octree. Within this framework, we estimate the location of a surface point in each of the octree cells identified as containing part of the target surface. Extensive experiments show that our method outperforms existing methods in terms of surface reconstruction quality while maintaining comparable computational efficiency. ",
    "url": "https://arxiv.org/abs/2309.08878",
    "authors": [
      "Congyi Zhang",
      "Guying Lin",
      "Lei Yang",
      "Xin Li",
      "Taku Komura",
      "Scott Schaefer",
      "John Keyser",
      "Wenping Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2309.08879",
    "title": "Semantic Information Extraction for Text Data with Probability Graph",
    "abstract": "In this paper, the problem of semantic information extraction for resource constrained text data transmission is studied. In the considered model, a sequence of text data need to be transmitted within a communication resource-constrained network, which only allows limited data transmission. Thus, at the transmitter, the original text data is extracted with natural language processing techniques. Then, the extracted semantic information is captured in a knowledge graph. An additional probability dimension is introduced in this graph to capture the importance of each information. This semantic information extraction problem is posed as an optimization framework whose goal is to extract most important semantic information for transmission. To find an optimal solution for this problem, a Floyd's algorithm based solution coupled with an efficient sorting mechanism is proposed. Numerical results testify the effectiveness of the proposed algorithm with regards to two novel performance metrics including semantic uncertainty and semantic similarity. ",
    "url": "https://arxiv.org/abs/2309.08879",
    "authors": [
      "Zhouxiang Zhao",
      "Zhaohui Yang",
      "Ye Hu",
      "Licheng Lin",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.08881",
    "title": "ChatGPT-4 with Code Interpreter can be used to solve introductory  college-level vector calculus and electromagnetism problems",
    "abstract": "We evaluated ChatGPT 3.5, 4, and 4 with Code Interpreter on a set of college-level engineering-math and electromagnetism problems, such as those often given to sophomore electrical engineering majors. We selected a set of 13 problems, and had ChatGPT solve them multiple times, using a fresh instance (chat) each time. We found that ChatGPT-4 with Code Interpreter was able to satisfactorily solve most problems we tested most of the time -- a major improvement over the performance of ChatGPT-4 (or 3.5) without Code Interpreter. The performance of ChatGPT was observed to be somewhat stochastic, and we found that solving the same problem N times in new ChatGPT instances and taking the most-common answer was an effective strategy. Based on our findings and observations, we provide some recommendations for instructors and students of classes at this level. ",
    "url": "https://arxiv.org/abs/2309.08881",
    "authors": [
      "Tanuj Kumar",
      "Mikhail A. Kats"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Physics Education (physics.ed-ph)"
    ]
  },
  {
    "id": "arXiv:2309.08884",
    "title": "Robust Online Covariance and Sparse Precision Estimation Under Arbitrary  Data Corruption",
    "abstract": "Gaussian graphical models are widely used to represent correlations among entities but remain vulnerable to data corruption. In this work, we introduce a modified trimmed-inner-product algorithm to robustly estimate the covariance in an online scenario even in the presence of arbitrary and adversarial data attacks. At each time step, data points, drawn nominally independently and identically from a multivariate Gaussian distribution, arrive. However, a certain fraction of these points may have been arbitrarily corrupted. We propose an online algorithm to estimate the sparse inverse covariance (i.e., precision) matrix despite this corruption. We provide the error-bound and convergence properties of the estimates to the true precision matrix under our algorithms. ",
    "url": "https://arxiv.org/abs/2309.08884",
    "authors": [
      "Tong Yao",
      "Shreyas Sundaram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.08887",
    "title": "GRaCE: Optimizing Grasps to Satisfy Ranked Criteria in Complex Scenario",
    "abstract": "This paper addresses the multi-faceted problem of robot grasping, where multiple criteria may conflict and differ in importance. We introduce Grasp Ranking and Criteria Evaluation (GRaCE), a novel approach that employs hierarchical rule-based logic and a rank-preserving utility function to optimize grasps based on various criteria such as stability, kinematic constraints, and goal-oriented functionalities. Additionally, we propose GRaCE-OPT, a hybrid optimization strategy that combines gradient-based and gradient-free methods to effectively navigate the complex, non-convex utility function. Experimental results in both simulated and real-world scenarios show that GRaCE requires fewer samples to achieve comparable or superior performance relative to existing methods. The modular architecture of GRaCE allows for easy customization and adaptation to specific application needs. ",
    "url": "https://arxiv.org/abs/2309.08887",
    "authors": [
      "Tasbolat Taunyazov",
      "Kelvin Lin",
      "Harold Soh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08889",
    "title": "SafeShift: Safety-Informed Distribution Shifts for Robust Trajectory  Prediction in Autonomous Driving",
    "abstract": "As autonomous driving technology matures, safety and robustness of its key components, including trajectory prediction, is vital. Though real-world datasets, such as Waymo Open Motion, provide realistic recorded scenarios for model development, they often lack truly safety-critical situations. Rather than utilizing unrealistic simulation or dangerous real-world testing, we instead propose a framework to characterize such datasets and find hidden safety-relevant scenarios within. Our approach expands the spectrum of safety-relevance, allowing us to study trajectory prediction models under a safety-informed, distribution shift setting. We contribute a generalized scenario characterization method, a novel scoring scheme to find subtly-avoided risky scenarios, and an evaluation of trajectory prediction models in this setting. We further contribute a remediation strategy, achieving a 10% average reduction in prediction collision rates. To facilitate future research, we release our code to the public: github.com/cmubig/SafeShift ",
    "url": "https://arxiv.org/abs/2309.08889",
    "authors": [
      "Benjamin Stoler",
      "Ingrid Navarro",
      "Meghdeep Jana",
      "Soonmin Hwang",
      "Jonathan Francis",
      "Jean Oh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08914",
    "title": "Outram: One-shot Global Localization via Triangulated Scene Graph and  Global Outlier Pruning",
    "abstract": "One-shot LiDAR localization refers to the ability to estimate the robot pose from one single point cloud, which yields significant advantages in initialization and relocalization processes. In the point cloud domain, the topic has been extensively studied as a global descriptor retrieval (i.e., loop closure detection) and pose refinement (i.e., point cloud registration) problem both in isolation or combined. However, few have explicitly considered the relationship between candidate retrieval and correspondence generation in pose estimation, leaving them brittle to substructure ambiguities. To this end, we propose a hierarchical one-shot localization algorithm called Outram that leverages substructures of 3D scene graphs for locally consistent correspondence searching and global substructure-wise outlier pruning. Such a hierarchical process couples the feature retrieval and the correspondence extraction to resolve the substructure ambiguities by conducting a local-to-global consistency refinement. We demonstrate the capability of Outram in a variety of scenarios in multiple large-scale outdoor datasets. Our implementation is open-sourced: https://github.com/Pamphlett/Outram. ",
    "url": "https://arxiv.org/abs/2309.08914",
    "authors": [
      "Pengyu Yin",
      "Haozhi Cao",
      "Thien-Minh Nguyen",
      "Shenghai Yuan",
      "Shuyang Zhang",
      "Kangcheng Liu",
      "Lihua Xie"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08916",
    "title": "Bidirectional Graph GAN: Representing Brain Structure-Function  Connections for Alzheimer's Disease",
    "abstract": "The relationship between brain structure and function is critical for revealing the pathogenesis of brain disease, including Alzheimer's disease (AD). However, it is a great challenge to map brain structure-function connections due to various reasons. In this work, a bidirectional graph generative adversarial networks (BGGAN) is proposed to represent brain structure-function connections. Specifically, by designing a module incorporating inner graph convolution network (InnerGCN), the generators of BGGAN can employ features of direct and indirect brain regions to learn the mapping function between structural domain and functional domain. Besides, a new module named Balancer is designed to counterpoise the optimization between generators and discriminators. By introducing the Balancer into BGGAN, both the structural generator and functional generator can not only alleviate the issue of mode collapse but also learn complementarity of structural and functional features. Experimental results using ADNI datasets show that the both the generated structure connections and generated function connections can improve the identification accuracy of AD. More importantly, based the proposed model, it is found that the relationship between brain structure and function is not a complete one-to-one correspondence. Brain structure is the basis of brain function. The strong structural connections are almost accompanied by strong functional connections. ",
    "url": "https://arxiv.org/abs/2309.08916",
    "authors": [
      "Shuqiang Wang",
      "Chen Ding"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2309.08927",
    "title": "DynaMoN: Motion-Aware Fast And Robust Camera Localization for Dynamic  NeRF",
    "abstract": "Dynamic reconstruction with neural radiance fields (NeRF) requires accurate camera poses. These are often hard to retrieve with existing structure-from-motion (SfM) pipelines as both camera and scene content can change. We propose DynaMoN that leverages simultaneous localization and mapping (SLAM) jointly with motion masking to handle dynamic scene content. Our robust SLAM-based tracking module significantly accelerates the training process of the dynamic NeRF while improving the quality of synthesized views at the same time. Extensive experimental validation on TUM RGB-D, BONN RGB-D Dynamic and the DyCheck's iPhone dataset, three real-world datasets, shows the advantages of DynaMoN both for camera pose estimation and novel view synthesis. ",
    "url": "https://arxiv.org/abs/2309.08927",
    "authors": [
      "Mert Asim Karaoglu",
      "Hannah Schieber",
      "Nicolas Schischka",
      "Melih G\u00f6rg\u00fcl\u00fc",
      "Florian Gr\u00f6tzner",
      "Alexander Ladikos",
      "Daniel Roth",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08929",
    "title": "Leveraging Multi-lingual Positive Instances in Contrastive Learning to  Improve Sentence Embedding",
    "abstract": "Learning multi-lingual sentence embeddings is a fundamental and significant task in natural language processing. Recent trends of learning both mono-lingual and multi-lingual sentence embeddings are mainly based on contrastive learning (CL) with an anchor, one positive, and multiple negative instances. In this work, we argue that leveraging multiple positives should be considered for multi-lingual sentence embeddings because (1) positives in a diverse set of languages can benefit cross-lingual learning, and (2) transitive similarity across multiple positives can provide reliable structural information to learn. In order to investigate the impact of CL with multiple positives, we propose a novel approach MPCL to effectively utilize multiple positive instances to improve learning multi-lingual sentence embeddings. Our experimental results on various backbone models and downstream tasks support that compared with conventional CL, MPCL leads to better retrieval, semantic similarity, and classification performances. We also observe that on unseen languages, sentence embedding models trained on multiple positives have better cross-lingual transferring performance than models trained on a single positive instance. ",
    "url": "https://arxiv.org/abs/2309.08929",
    "authors": [
      "Kaiyan Zhao",
      "Qiyu Wu",
      "Xin-Qiang Cai",
      "Yoshimasa Tsuruoka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08932",
    "title": "Semantics-aware LiDAR-Only Pseudo Point Cloud Generation for 3D Object  Detection",
    "abstract": "Although LiDAR sensors are crucial for autonomous systems due to providing precise depth information, they struggle with capturing fine object details, especially at a distance, due to sparse and non-uniform data. Recent advances introduced pseudo-LiDAR, i.e., synthetic dense point clouds, using additional modalities such as cameras to enhance 3D object detection. We present a novel LiDAR-only framework that augments raw scans with denser pseudo point clouds by solely relying on LiDAR sensors and scene semantics, omitting the need for cameras. Our framework first utilizes a segmentation model to extract scene semantics from raw point clouds, and then employs a multi-modal domain translator to generate synthetic image segments and depth cues without real cameras. This yields a dense pseudo point cloud enriched with semantic information. We also introduce a new semantically guided projection method, which enhances detection performance by retaining only relevant pseudo points. We applied our framework to different advanced 3D object detection methods and reported up to 2.9% performance upgrade. We also obtained comparable results on the KITTI 3D object detection dataset, in contrast to other state-of-the-art LiDAR-only detectors. ",
    "url": "https://arxiv.org/abs/2309.08932",
    "authors": [
      "Tiago Cortinhal",
      "Idriss Gouigah",
      "Eren Erdal Aksoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08948",
    "title": "Wireless-Powered Communication Assisted by Two-Way Relay with  Interference Alignment Underlaying Cognitive Radio Network",
    "abstract": "This study investigates the outage performance of an under-laying wireless-powered secondary system that reuses the primary users (PU) spectrum in a multiple-input multiple-output (MIMO) cognitive radio (CR) network. Each secondary user (SU) harvests energy and receives information simultaneously by applying power splitting (PS) protocol. The communication between SUs is aided by a two-way (TW) decode and forward (DF) relay. We formulate a problem to design the PS ratios at SUs, the power control factor at the secondary relay, and beamforming matrices at all nodes to minimize the secondary network's outage probability. To address this problem, we propose a two-step solution. The first step establishes closedform expressions for the PS ratios at each SU and secondary relay's power control factor. Furthermore, in the second step, interference alignment (IA) is used to design proper precoding and decoding matrices for managing the interference between secondary and primary networks. We choose IA matrices based on the minimum mean square error (MMSE) iterative algorithm. The simulation results demonstrate a significant decrease in the outage probability for the proposed scheme compared to the benchmark schemes, with an average reduction of more than two orders of magnitude achieved. ",
    "url": "https://arxiv.org/abs/2309.08948",
    "authors": [
      "Iman Pazouki",
      "Roshanak Soltani",
      "Mohammad Lari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.08953",
    "title": "Robust Backdoor Attacks on Object Detection in Real World",
    "abstract": "Deep learning models are widely deployed in many applications, such as object detection in various security fields. However, these models are vulnerable to backdoor attacks. Most backdoor attacks were intensively studied on classified models, but little on object detection. Previous works mainly focused on the backdoor attack in the digital world, but neglect the real world. Especially, the backdoor attack's effect in the real world will be easily influenced by physical factors like distance and illumination. In this paper, we proposed a variable-size backdoor trigger to adapt to the different sizes of attacked objects, overcoming the disturbance caused by the distance between the viewing point and attacked object. In addition, we proposed a backdoor training named malicious adversarial training, enabling the backdoor object detector to learn the feature of the trigger with physical noise. The experiment results show this robust backdoor attack (RBA) could enhance the attack success rate in the real world. ",
    "url": "https://arxiv.org/abs/2309.08953",
    "authors": [
      "Yaguan Qian",
      "Boyuan Ji",
      "Shuke He",
      "Shenhui Huang",
      "Xiang Ling",
      "Bin Wang",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08963",
    "title": "Struc-Bench: Are Large Language Models Really Good at Generating Complex  Structured Data?",
    "abstract": "Despite the power of Large Language Models (LLMs) like GPT-4, they still struggle with tasks that require generating complex, structured outputs. In this study, we assess the capability of Current LLMs in generating complex structured data and propose a structure-aware fine-tuning approach as a solution to improve this ability. To perform a comprehensive evaluation, we propose Struc-Bench, include five representative LLMs (i.e., GPT-NeoX 20B, GPT-3.5, GPT-4, and Vicuna) and evaluate them on our carefully constructed datasets spanning raw text, HTML, and LaTeX tables. Based on our analysis of current model performance, we identify specific common formatting errors and areas of potential improvement. To address complex formatting requirements, we utilize FormatCoT (Chain-of-Thought) to generate format instructions from target outputs. Our experiments show that our structure-aware fine-tuning method, when applied to LLaMA-7B, significantly improves adherence to natural language constraints, outperforming other evaluated LLMs. Based on these results, we present an ability map of model capabilities from six dimensions (i.e., coverage, formatting, reasoning, comprehension, pragmatics, and hallucination). This map highlights the weaknesses of LLMs in handling complex structured outputs and suggests promising directions for future work. Our code and models can be found at https://github.com/gersteinlab/Struc-Bench. ",
    "url": "https://arxiv.org/abs/2309.08963",
    "authors": [
      "Xiangru Tang",
      "Yiming Zong",
      "Yilun Zhao",
      "Arman Cohan",
      "Mark Gerstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08965",
    "title": "Multiagent Reinforcement Learning with an Attention Mechanism for  Improving Energy Efficiency in LoRa Networks",
    "abstract": "Long Range (LoRa) wireless technology, characterized by low power consumption and a long communication range, is regarded as one of the enabling technologies for the Industrial Internet of Things (IIoT). However, as the network scale increases, the energy efficiency (EE) of LoRa networks decreases sharply due to severe packet collisions. To address this issue, it is essential to appropriately assign transmission parameters such as the spreading factor and transmission power for each end device (ED). However, due to the sporadic traffic and low duty cycle of LoRa networks, evaluating the system EE performance under different parameter settings is time-consuming. Therefore, we first formulate an analytical model to calculate the system EE. On this basis, we propose a transmission parameter allocation algorithm based on multiagent reinforcement learning (MALoRa) with the aim of maximizing the system EE of LoRa networks. Notably, MALoRa employs an attention mechanism to guide each ED to better learn how much ''attention'' should be given to the parameter assignments for relevant EDs when seeking to improve the system EE. Simulation results demonstrate that MALoRa significantly improves the system EE compared with baseline algorithms with an acceptable degradation in packet delivery rate (PDR). ",
    "url": "https://arxiv.org/abs/2309.08965",
    "authors": [
      "Xu Zhang",
      "Ziqi Lin",
      "Shimin Gong",
      "Bo Gu",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2309.08971",
    "title": "Regularized Contrastive Pre-training for Few-shot Bioacoustic Sound  Detection",
    "abstract": "Bioacoustic sound event detection allows for better understanding of animal behavior and for better monitoring biodiversity using audio. Deep learning systems can help achieve this goal, however it is difficult to acquire sufficient annotated data to train these systems from scratch. To address this limitation, the Detection and Classification of Acoustic Scenes and Events (DCASE) community has recasted the problem within the framework of few-shot learning and organize an annual challenge for learning to detect animal sounds from only five annotated examples. In this work, we regularize supervised contrastive pre-training to learn features that can transfer well on new target tasks with animal sounds unseen during training, achieving a high F-score of 61.52%(0.48) when no feature adaptation is applied, and an F-score of 68.19%(0.75) when we further adapt the learned features for each new target task. This work aims to lower the entry bar to few-shot bioacoustic sound event detection by proposing a simple and yet effective framework for this task, by also providing open-source code. ",
    "url": "https://arxiv.org/abs/2309.08971",
    "authors": [
      "Ilyass Moummad",
      "Romain Serizel",
      "Nicolas Farrugia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08976",
    "title": "Data-driven Reachability using Christoffel Functions and Conformal  Prediction",
    "abstract": "An important mathematical tool in the analysis of dynamical systems is the approximation of the reach set, i.e., the set of states reachable after a given time from a given initial state. This set is difficult to compute for complex systems even if the system dynamics are known and given by a system of ordinary differential equations with known coefficients. In practice, parameters are often unknown and mathematical models difficult to obtain. Data-based approaches are promised to avoid these difficulties by estimating the reach set based on a sample of states. If a model is available, this training set can be obtained through numerical simulation. In the absence of a model, real-life observations can be used instead. A recently proposed approach for data-based reach set approximation uses Christoffel functions to approximate the reach set. Under certain assumptions, the approximation is guaranteed to converge to the true solution. In this paper, we improve upon these results by notably improving the sample efficiency and relaxing some of the assumptions by exploiting statistical guarantees from conformal prediction with training and calibration sets. In addition, we exploit an incremental way to compute the Christoffel function to avoid the calibration set while maintaining the statistical convergence guarantees. Furthermore, our approach is robust to outliers in the training and calibration set. ",
    "url": "https://arxiv.org/abs/2309.08976",
    "authors": [
      "Abdelmouaiz Tebjou",
      "Goran Frehse",
      "Fa\u00efcel Chamroukhi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.08987",
    "title": "Invertible Mosaic Image Hiding Network for Very Large Capacity Image  Steganography",
    "abstract": "The existing image steganography methods either sequentially conceal secret images or conceal a concatenation of multiple images. In such ways, the interference of information among multiple images will become increasingly severe when the number of secret images becomes larger, thus restrict the development of very large capacity image steganography. In this paper, we propose an Invertible Mosaic Image Hiding Network (InvMIHNet) which realizes very large capacity image steganography with high quality by concealing a single mosaic secret image. InvMIHNet consists of an Invertible Image Rescaling (IIR) module and an Invertible Image Hiding (IIH) module. The IIR module works for downscaling the single mosaic secret image form by spatially splicing the multiple secret images, and the IIH module then conceal this mosaic image under the cover image. The proposed InvMIHNet successfully conceal and reveal up to 16 secret images with a small number of parameters and memory consumption. Extensive experiments on ImageNet-1K, COCO and DIV2K show InvMIHNet outperforms state-of-the-art methods in terms of both the imperceptibility of stego image and recover accuracy of secret image. ",
    "url": "https://arxiv.org/abs/2309.08987",
    "authors": [
      "Zihan Chen",
      "Tianrui Liu",
      "Jun-Jie Huang",
      "Wentao Zhao",
      "Xing Bi",
      "Meng Wang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.08989",
    "title": "RMP: A Random Mask Pretrain Framework for Motion Prediction",
    "abstract": "As the pretraining technique is growing in popularity, little work has been done on pretrained learning-based motion prediction methods in autonomous driving. In this paper, we propose a framework to formalize the pretraining task for trajectory prediction of traffic participants. Within our framework, inspired by the random masked model in natural language processing (NLP) and computer vision (CV), objects' positions at random timesteps are masked and then filled in by the learned neural network (NN). By changing the mask profile, our framework can easily switch among a range of motion-related tasks. We show that our proposed pretraining framework is able to deal with noisy inputs and improves the motion prediction accuracy and miss rate, especially for objects occluded over time by evaluating it on Argoverse and NuScenes datasets. ",
    "url": "https://arxiv.org/abs/2309.08989",
    "authors": [
      "Yi Yang",
      "Qingwen Zhang",
      "Thomas Gilles",
      "Nazre Batool",
      "John Folkesson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08999",
    "title": "Context-aware Adversarial Attack on Named Entity Recognition",
    "abstract": "In recent years, large pre-trained language models (PLMs) have achieved remarkable performance on many natural language processing benchmarks. Despite their success, prior studies have shown that PLMs are vulnerable to attacks from adversarial examples. In this work, we focus on the named entity recognition task and study context-aware adversarial attack methods to examine the model's robustness. Specifically, we propose perturbing the most informative words for recognizing entities to create adversarial examples and investigate different candidate replacement methods to generate natural and plausible adversarial examples. Experiments and analyses show that our methods are more effective in deceiving the model into making wrong predictions than strong baselines. ",
    "url": "https://arxiv.org/abs/2309.08999",
    "authors": [
      "Shuguang Chen",
      "Leonardo Neves",
      "Thamar Solorio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09003",
    "title": "RingMo-lite: A Remote Sensing Multi-task Lightweight Network with  CNN-Transformer Hybrid Framework",
    "abstract": "In recent years, remote sensing (RS) vision foundation models such as RingMo have emerged and achieved excellent performance in various downstream tasks. However, the high demand for computing resources limits the application of these models on edge devices. It is necessary to design a more lightweight foundation model to support on-orbit RS image interpretation. Existing methods face challenges in achieving lightweight solutions while retaining generalization in RS image interpretation. This is due to the complex high and low-frequency spectral components in RS images, which make traditional single CNN or Vision Transformer methods unsuitable for the task. Therefore, this paper proposes RingMo-lite, an RS multi-task lightweight network with a CNN-Transformer hybrid framework, which effectively exploits the frequency-domain properties of RS to optimize the interpretation process. It is combined by the Transformer module as a low-pass filter to extract global features of RS images through a dual-branch structure, and the CNN module as a stacked high-pass filter to extract fine-grained details effectively. Furthermore, in the pretraining stage, the designed frequency-domain masked image modeling (FD-MIM) combines each image patch's high-frequency and low-frequency characteristics, effectively capturing the latent feature representation in RS data. As shown in Fig. 1, compared with RingMo, the proposed RingMo-lite reduces the parameters over 60% in various RS image interpretation tasks, the average accuracy drops by less than 2% in most of the scenes and achieves SOTA performance compared to models of the similar size. In addition, our work will be integrated into the MindSpore computing platform in the near future. ",
    "url": "https://arxiv.org/abs/2309.09003",
    "authors": [
      "Yuelei Wang",
      "Ting Zhang",
      "Liangjin Zhao",
      "Lin Hu",
      "Zhechao Wang",
      "Ziqing Niu",
      "Peirui Cheng",
      "Kaiqiang Chen",
      "Xuan Zeng",
      "Zhirui Wang",
      "Hongqi Wang",
      "Xian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09007",
    "title": "MonoForce: Self-supervised learning of physics-aware grey-box model for  predicting the robot-terrain interaction",
    "abstract": "We introduce an explainable, physics-aware, and end-to-end differentiable model which predicts the outcome of robot-terrain interaction from camera images. The proposed MonoForce model consists of a black-box module, which predicts robot-terrain interaction forces from the onboard camera, followed by a white-box module, which transforms these forces through the laws of classical mechanics into the predicted trajectories. As the white-box model is implemented as a differentiable ODE solver, it enables measuring the physical consistency between predicted forces and ground-truth trajectories of the robot. Consequently, it creates a self-supervised loss similar to MonoDepth. To facilitate the reproducibility of the paper, we provide the source code. See the project github for codes and supplementary materials such as videos and data sequences. ",
    "url": "https://arxiv.org/abs/2309.09007",
    "authors": [
      "Ruslan Agishev",
      "Karel Zimmermann",
      "Martin Pecka",
      "Tom\u00e1\u0161 Svoboda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09021",
    "title": "Pedestrian Trajectory Prediction Using Dynamics-based Deep Learning",
    "abstract": "Pedestrian trajectory prediction plays an important role in autonomous driving systems and robotics. Recent work utilising prominent deep learning models for pedestrian motion prediction makes limited a priori assumptions about human movements, resulting in a lack of explainability and explicit constraints enforced on predicted trajectories. This paper presents a dynamics-based deep learning framework where a novel asymptotically stable dynamical system is integrated into a deep learning model. Our novel asymptotically stable dynamical system is used to model human goal-targeted motion by enforcing the human walking trajectory converges to a predicted goal position and provides a deep learning model with prior knowledge and explainability. Our deep learning model utilises recent innovations from transformer networks and is used to learn some features of human motion, such as collision avoidance, for our proposed dynamical system. The experimental results show that our framework outperforms recent prominent models in pedestrian trajectory prediction on five benchmark human motion datasets. ",
    "url": "https://arxiv.org/abs/2309.09021",
    "authors": [
      "Honghui Wang",
      "Weiming Zhi",
      "Gustavo Batista",
      "Rohitash Chandra"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09025",
    "title": "Efficient Privacy-Preserving Convolutional Spiking Neural Networks with  FHE",
    "abstract": "With the rapid development of AI technology, we have witnessed numerous innovations and conveniences. However, along with these advancements come privacy threats and risks. Fully Homomorphic Encryption (FHE) emerges as a key technology for privacy-preserving computation, enabling computations while maintaining data privacy. Nevertheless, FHE has limitations in processing continuous non-polynomial functions as it is restricted to discrete integers and supports only addition and multiplication. Spiking Neural Networks (SNNs) operate on discrete spike signals, naturally aligning with the properties of FHE. In this paper, we present a framework called FHE-DiCSNN. This framework is based on the efficient TFHE scheme and leverages the discrete properties of SNNs to achieve high prediction performance on ciphertexts. Firstly, by employing bootstrapping techniques, we successfully implement computations of the Leaky Integrate-and-Fire neuron model on ciphertexts. Through bootstrapping, we can facilitate computations for SNNs of arbitrary depth. This framework can be extended to other spiking neuron models, providing a novel framework for the homomorphic evaluation of SNNs. Secondly, inspired by CNNs, we adopt convolutional methods to replace Poisson encoding. This not only enhances accuracy but also mitigates the issue of prolonged simulation time caused by random encoding. Furthermore, we employ engineering techniques to parallelize the computation of bootstrapping, resulting in a significant improvement in computational efficiency. Finally, we evaluate our model on the MNIST dataset. Experimental results demonstrate that, with the optimal parameter configuration, FHE-DiCSNN achieves an accuracy of 97.94% on ciphertexts, with a loss of only 0.53% compared to the original network's accuracy of 98.47%. Moreover, each prediction requires only 0.75 seconds of computation time ",
    "url": "https://arxiv.org/abs/2309.09025",
    "authors": [
      "Pengbo Li",
      "Huifang Huang",
      "Ting Gao",
      "Jin Guo",
      "Jinqiao Duan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.09030",
    "title": "Improve Deep Forest with Learnable Layerwise Augmentation Policy  Schedule",
    "abstract": "As a modern ensemble technique, Deep Forest (DF) employs a cascading structure to construct deep models, providing stronger representational power compared to traditional decision forests. However, its greedy multi-layer learning procedure is prone to overfitting, limiting model effectiveness and generalizability. This paper presents an optimized Deep Forest, featuring learnable, layerwise data augmentation policy schedules. Specifically, We introduce the Cut Mix for Tabular data (CMT) augmentation technique to mitigate overfitting and develop a population-based search algorithm to tailor augmentation intensity for each layer. Additionally, we propose to incorporate outputs from intermediate layers into a checkpoint ensemble for more stable performance. Experimental results show that our method sets new state-of-the-art (SOTA) benchmarks in various tabular classification tasks, outperforming shallow tree ensembles, deep forests, deep neural network, and AutoML competitors. The learned policies also transfer effectively to Deep Forest variants, underscoring its potential for enhancing non-differentiable deep learning modules in tabular signal processing. ",
    "url": "https://arxiv.org/abs/2309.09030",
    "authors": [
      "Hongyu Zhu",
      "Sichu Liang",
      "Wentao Hu",
      "Fang-Qi Li",
      "Yali yuan",
      "Shi-Lin Wang",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09033",
    "title": "New Privacy Mechanism Design With Direct Access to the Private Data",
    "abstract": "The design of a statistical signal processing privacy problem is studied where the private data is assumed to be observable. In this work, an agent observes useful data $Y$, which is correlated with private data $X$, and wants to disclose the useful information to a user. A statistical privacy mechanism is employed to generate data $U$ based on $(X,Y)$ that maximizes the revealed information about $Y$ while satisfying a privacy criterion. To this end, we use extended versions of the Functional Representation Lemma and Strong Functional Representation Lemma and combine them with a simple observation which we call separation technique. New lower bounds on privacy-utility trade-off are derived and we show that they can improve the previous bounds. We study the obtained bounds in different scenarios and compare them with previous results. ",
    "url": "https://arxiv.org/abs/2309.09033",
    "authors": [
      "Amirreza Zamani",
      "Tobias J. Oechtering",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.09043",
    "title": "Forward Invariance in Neural Network Controlled Systems",
    "abstract": "We present a framework based on interval analysis and monotone systems theory to certify and search for forward invariant sets in nonlinear systems with neural network controllers. The framework (i) constructs localized first-order inclusion functions for the closed-loop system using Jacobian bounds and existing neural network verification tools; (ii) builds a dynamical embedding system where its evaluation along a single trajectory directly corresponds with a nested family of hyper-rectangles provably converging to an attractive set of the original system; (iii) utilizes linear transformations to build families of nested paralleletopes with the same properties. The framework is automated in Python using our interval analysis toolbox $\\texttt{npinterval}$, in conjunction with the symbolic arithmetic toolbox $\\texttt{sympy}$, demonstrated on an $8$-dimensional leader-follower system. ",
    "url": "https://arxiv.org/abs/2309.09043",
    "authors": [
      "Akash Harapanahalli",
      "Saber Jafarpour",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.09045",
    "title": "Temporal Smoothness Regularisers for Neural Link Predictors",
    "abstract": "Most algorithms for representation learning and link prediction on relational data are designed for static data. However, the data to which they are applied typically evolves over time, including online social networks or interactions between users and items in recommender systems. This is also the case for graph-structured knowledge bases -- knowledge graphs -- which contain facts that are valid only for specific points in time. In such contexts, it becomes crucial to correctly identify missing links at a precise time point, i.e. the temporal prediction link task. Recently, Lacroix et al. and Sadeghian et al. proposed a solution to the problem of link prediction for knowledge graphs under temporal constraints inspired by the canonical decomposition of 4-order tensors, where they regularise the representations of time steps by enforcing temporal smoothing, i.e. by learning similar transformation for adjacent timestamps. However, the impact of the choice of temporal regularisation terms is still poorly understood. In this work, we systematically analyse several choices of temporal smoothing regularisers using linear functions and recurrent architectures. In our experiments, we show that by carefully selecting the temporal smoothing regulariser and regularisation weight, a simple method like TNTComplEx can produce significantly more accurate results than state-of-the-art methods on three widely used temporal link prediction datasets. Furthermore, we evaluate the impact of a wide range of temporal smoothing regularisers on two state-of-the-art temporal link prediction models. Our work shows that simple tensor factorisation models can produce new state-of-the-art results using newly proposed temporal regularisers, highlighting a promising avenue for future research. ",
    "url": "https://arxiv.org/abs/2309.09045",
    "authors": [
      "Manuel Dileo",
      "Pasquale Minervini",
      "Matteo Zignani",
      "Sabrina Gaito"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09047",
    "title": "CNS: Correspondence Encoded Neural Image Servo Policy",
    "abstract": "Image servo is an indispensable technique in robotic applications that helps to achieve high precision positioning. The intermediate representation of image servo policy is important to sensor input abstraction and policy output guidance. Classical approaches achieve high precision but require clean keypoint correspondence, and suffer from limited convergence basin or weak feature error robustness. Recent learning-based methods achieve moderate precision and large convergence basin on specific scenes but face issues when generalizing to novel environments. In this paper, we encode keypoints and correspondence into a graph and use graph neural network as architecture of controller. This design utilizes both advantages: generalizable intermediate representation from keypoint correspondence and strong modeling ability from neural network. Other techniques including realistic data generation, feature clustering and distance decoupling are proposed to further improve efficiency, precision and generalization. Experiments in simulation and real-world verify the effectiveness of our method in speed (maximum 40fps along with observer), precision (<0.3{\\deg} and sub-millimeter accuracy) and generalization (sim-to-real without fine-tuning). Project homepage (full paper with supplementary text, video and code): https://hhcaz.github.io/CNS-home ",
    "url": "https://arxiv.org/abs/2309.09047",
    "authors": [
      "Anzhe Chen",
      "Hongxiang Yu",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09067",
    "title": "MMST-ViT: Climate Change-aware Crop Yield Prediction via Multi-Modal  Spatial-Temporal Vision Transformer",
    "abstract": "Precise crop yield prediction provides valuable information for agricultural planning and decision-making processes. However, timely predicting crop yields remains challenging as crop growth is sensitive to growing season weather variation and climate change. In this work, we develop a deep learning-based solution, namely Multi-Modal Spatial-Temporal Vision Transformer (MMST-ViT), for predicting crop yields at the county level across the United States, by considering the effects of short-term meteorological variations during the growing season and the long-term climate change on crops. Specifically, our MMST-ViT consists of a Multi-Modal Transformer, a Spatial Transformer, and a Temporal Transformer. The Multi-Modal Transformer leverages both visual remote sensing data and short-term meteorological data for modeling the effect of growing season weather variations on crop growth. The Spatial Transformer learns the high-resolution spatial dependency among counties for accurate agricultural tracking. The Temporal Transformer captures the long-range temporal dependency for learning the impact of long-term climate change on crops. Meanwhile, we also devise a novel multi-modal contrastive learning technique to pre-train our model without extensive human supervision. Hence, our MMST-ViT captures the impacts of both short-term weather variations and long-term climate change on crops by leveraging both satellite images and meteorological data. We have conducted extensive experiments on over 200 counties in the United States, with the experimental results exhibiting that our MMST-ViT outperforms its counterparts under three performance metrics of interest. ",
    "url": "https://arxiv.org/abs/2309.09067",
    "authors": [
      "Fudong Lin",
      "Summer Crawford",
      "Kaleb Guillot",
      "Yihe Zhang",
      "Yan Chen",
      "Xu Yuan",
      "Li Chen",
      "Shelby Willams",
      "Robert Minvielle",
      "Xiangming Xiao",
      "Drew Gholson",
      "Nicolas Ashwell",
      "Tri Setiyono",
      "Brenda Tubana",
      "Lu Peng",
      "Magdy Bayoumi",
      "Nian-Feng Tzeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09069",
    "title": "Constructing a Knowledge Graph for Vietnamese Legal Cases with  Heterogeneous Graphs",
    "abstract": "This paper presents a knowledge graph construction method for legal case documents and related laws, aiming to organize legal information efficiently and enhance various downstream tasks. Our approach consists of three main steps: data crawling, information extraction, and knowledge graph deployment. First, the data crawler collects a large corpus of legal case documents and related laws from various sources, providing a rich database for further processing. Next, the information extraction step employs natural language processing techniques to extract entities such as courts, cases, domains, and laws, as well as their relationships from the unstructured text. Finally, the knowledge graph is deployed, connecting these entities based on their extracted relationships, creating a heterogeneous graph that effectively represents legal information and caters to users such as lawyers, judges, and scholars. The established baseline model leverages unsupervised learning methods, and by incorporating the knowledge graph, it demonstrates the ability to identify relevant laws for a given legal case. This approach opens up opportunities for various applications in the legal domain, such as legal case analysis, legal recommendation, and decision support. ",
    "url": "https://arxiv.org/abs/2309.09069",
    "authors": [
      "Thi-Hai-Yen Vuong",
      "Minh-Quan Hoang",
      "Tan-Minh Nguyen",
      "Hoang-Trung Nguyen",
      "Ha-Thanh Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09074",
    "title": "Test-Time Compensated Representation Learning for Extreme Traffic  Forecasting",
    "abstract": "Traffic forecasting is a challenging task due to the complex spatio-temporal correlations among traffic series. In this paper, we identify an underexplored problem in multivariate traffic series prediction: extreme events. Road congestion and rush hours can result in low correlation in vehicle speeds at various intersections during adjacent time periods. Existing methods generally predict future series based on recent observations and entirely discard training data during the testing phase, rendering them unreliable for forecasting highly nonlinear multivariate time series. To tackle this issue, we propose a test-time compensated representation learning framework comprising a spatio-temporal decomposed data bank and a multi-head spatial transformer model (CompFormer). The former component explicitly separates all training data along the temporal dimension according to periodicity characteristics, while the latter component establishes a connection between recent observations and historical series in the data bank through a spatial attention matrix. This enables the CompFormer to transfer robust features to overcome anomalous events while using fewer computational resources. Our modules can be flexibly integrated with existing forecasting methods through end-to-end training, and we demonstrate their effectiveness on the METR-LA and PEMS-BAY benchmarks. Extensive experimental results show that our method is particularly important in extreme events, and can achieve significant improvements over six strong baselines, with an overall improvement of up to 28.2%. ",
    "url": "https://arxiv.org/abs/2309.09074",
    "authors": [
      "Zhiwei Zhang",
      "Weizhong Zhang",
      "Yaowei Huang",
      "Kani Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09075",
    "title": "Music Generation based on Generative Adversarial Networks with  Transformer",
    "abstract": "Autoregressive models based on Transformers have become the prevailing approach for generating music compositions that exhibit comprehensive musical structure. These models are typically trained by minimizing the negative log-likelihood (NLL) of the observed sequence in an autoregressive manner. However, when generating long sequences, the quality of samples from these models tends to significantly deteriorate due to exposure bias. To address this issue, we leverage classifiers trained to differentiate between real and sampled sequences to identify these failures. This observation motivates our exploration of adversarial losses as a complement to the NLL objective. We employ a pre-trained Span-BERT model as the discriminator in the Generative Adversarial Network (GAN) framework, which enhances training stability in our experiments. To optimize discrete sequences within the GAN framework, we utilize the Gumbel-Softmax trick to obtain a differentiable approximation of the sampling process. Additionally, we partition the sequences into smaller chunks to ensure that memory constraints are met. Through human evaluations and the introduction of a novel discriminative metric, we demonstrate that our approach outperforms a baseline model trained solely on likelihood maximization. ",
    "url": "https://arxiv.org/abs/2309.09075",
    "authors": [
      "Ziyi Jiang",
      "Yi Zhong",
      "Ruoxue Wu",
      "Zhenghan Chen",
      "Xiaoxuan Liang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.09079",
    "title": "Achieving Ultra-Reliable Low-Latency Communication (URLLC) in  Next-Generation Cellular Networks with Programmable Data Planes",
    "abstract": "Recent advancements in wireless technologies towards the next-generation cellular networks have brought a new era that made it possible to apply cellular technology on traditionally-wired networks with tighter requirements, such as industrial networks. The next-generation cellular technologies (e.g., 5G and Beyond) introduce the concept of ultra-reliable low-latency communications (URLLC). This thesis presents a Software-Defined Networking (SDN) architecture with programmable data planes for the next-generation cellular networks to achieve URLLC. Our design deploys programmable switches between the cellular core and Radio Access Networks (RAN) to monitor and modify data traffic at the line speed. We introduce the concept of \\textit{intra-cellular optimization}, a relaxation in cellular networks to allow pre-authorized in-network devices to communicate without being required to signal the core network. We also present a control structure, Unified Control Plane (UCP), containing a novel Ethernet Layer control protocol and an adapted version of link-state routing information distribution among the programmable switches. Our implementation uses P4 with an 5G implementation (Open5Gs) and a UE/RAN simulator. We implement a Python simulator to evaluate the performance of our system on multi-switch topologies by simulating the switch behavior. Our evaluation indicates latency reduction up to 2x with \\textit{intra-cellular optimization} compared to the conventional architecture. We show that our design has a ten-millisecond level of control latency, and achieves fine-grained network security and monitoring. ",
    "url": "https://arxiv.org/abs/2309.09079",
    "authors": [
      "Kerim G\u00f6karslan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.09102",
    "title": "CppFlow: Generative Inverse Kinematics for Efficient and Robust  Cartesian Path Planning",
    "abstract": "In this work we present CppFlow - a novel and performant planner for the Cartesian Path Planning problem, which finds valid trajectories up to 129x faster than current methods, while also succeeding on more difficult problems where others fail. At the core of the proposed algorithm is the use of a learned, generative Inverse Kinematics solver, which is able to efficiently produce promising entire candidate solution trajectories on the GPU. Precise, valid solutions are then found through classical approaches such as differentiable programming, global search, and optimization. In combining approaches from these two paradigms we get the best of both worlds - efficient approximate solutions from generative AI which are made exact using the guarantees of traditional planning and optimization. We evaluate our system against other state of the art methods on a set of established baselines as well as new ones introduced in this work and find that our method significantly outperforms others in terms of the time to find a valid solution and planning success rate, and performs comparably in terms of trajectory length over time. The work is made open source and available for use upon acceptance. ",
    "url": "https://arxiv.org/abs/2309.09102",
    "authors": [
      "Jeremy Morgan",
      "David Millard",
      "Gaurav S. Sukhatme"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09108",
    "title": "Neural Network-based Fault Detection and Identification for Quadrotors  using Dynamic Symmetry",
    "abstract": "Autonomous robotic systems, such as quadrotors, are susceptible to actuator faults, and for the safe operation of such systems, timely detection and isolation of these faults is essential. Neural networks can be used for verification of actuator performance via online actuator fault detection with high accuracy. In this paper, we develop a novel model-free fault detection and isolation (FDI) framework for quadrotor systems using long-short-term memory (LSTM) neural network architecture. The proposed framework only uses system output data and the commanded control input and requires no knowledge of the system model. Utilizing the symmetry in quadrotor dynamics, we train the FDI for fault in just one of the motors (e.g., motor $\\# 2$), and the trained FDI can predict faults in any of the motors. This reduction in search space enables us to design an FDI for partial fault as well as complete fault scenarios. Numerical experiments illustrate that the proposed NN-FDI correctly verifies the actuator performance and identifies partial as well as complete faults with over $90\\%$ prediction accuracy. We also illustrate that model-free NN-FDI performs at par with model-based FDI, and is robust to model uncertainties as well as distribution shifts in input data. ",
    "url": "https://arxiv.org/abs/2309.09108",
    "authors": [
      "Kunal Garg",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.09122",
    "title": "FDCNet: Feature Drift Compensation Network for Class-Incremental Weakly  Supervised Object Localization",
    "abstract": "This work addresses the task of class-incremental weakly supervised object localization (CI-WSOL). The goal is to incrementally learn object localization for novel classes using only image-level annotations while retaining the ability to localize previously learned classes. This task is important because annotating bounding boxes for every new incoming data is expensive, although object localization is crucial in various applications. To the best of our knowledge, we are the first to address this task. Thus, we first present a strong baseline method for CI-WSOL by adapting the strategies of class-incremental classifiers to mitigate catastrophic forgetting. These strategies include applying knowledge distillation, maintaining a small data set from previous tasks, and using cosine normalization. We then propose the feature drift compensation network to compensate for the effects of feature drifts on class scores and localization maps. Since updating network parameters to learn new tasks causes feature drifts, compensating for the final outputs is necessary. Finally, we evaluate our proposed method by conducting experiments on two publicly available datasets (ImageNet-100 and CUB-200). The experimental results demonstrate that the proposed method outperforms other baseline methods. ",
    "url": "https://arxiv.org/abs/2309.09122",
    "authors": [
      "Sejin Park",
      "Taehyung Lee",
      "Yeejin Lee",
      "Byeongkeun Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09137",
    "title": "Trajectory Prediction for Robot Navigation using Flow-Guided Markov  Neural Operator",
    "abstract": "Predicting pedestrian movements remains a complex and persistent challenge in robot navigation research. We must evaluate several factors to achieve accurate predictions, such as pedestrian interactions, the environment, crowd density, and social and cultural norms. Accurate prediction of pedestrian paths is vital for ensuring safe human-robot interaction, especially in robot navigation. Furthermore, this research has potential applications in autonomous vehicles, pedestrian tracking, and human-robot collaboration. Therefore, in this paper, we introduce \\textbf{FlowMNO}, an Optical Flow-Integrated Markov Neural Operator designed to capture pedestrian behavior across diverse scenarios. Our paper models trajectory prediction as a Markovian process, where future pedestrian coordinates depend solely on the current state. This problem formulation eliminates the need to store previous states. We conducted experiments using standard benchmark datasets like ETH, HOTEL, ZARA1, ZARA2, UCY, and RGB-D pedestrian datasets. Our study demonstrates that FlowMNO outperforms some of the state-of-the-art deep learning methods like LSTM, GAN, and CNN-based approaches, by approximately 86.46\\% when predicting pedestrian trajectories. Thus, we show that FlowMNO can seamlessly integrate into robot navigation systems, enhancing their ability to navigate crowded areas smoothly. ",
    "url": "https://arxiv.org/abs/2309.09137",
    "authors": [
      "Rashmi Bhaskara",
      "Hrishikesh Viswanath",
      "Aniket Bera"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09142",
    "title": "Performance of Graph Neural Networks for Point Cloud Applications",
    "abstract": "Graph Neural Networks (GNNs) have gained significant momentum recently due to their capability to learn on unstructured graph data. Dynamic GNNs (DGNNs) are the current state-of-the-art for point cloud applications; such applications (viz. autonomous driving) require real-time processing at the edge with tight latency and memory constraints. Conducting performance analysis on such DGNNs, thus, becomes a crucial task to evaluate network suitability. This paper presents a profiling analysis of EdgeConv-based DGNNs applied to point cloud inputs. We assess their inference performance in terms of end-to-end latency and memory consumption on state-of-the-art CPU and GPU platforms. The EdgeConv layer has two stages: (1) dynamic graph generation using k-Nearest Neighbors (kNN) and, (2) node feature updation. The addition of dynamic graph generation via kNN in each (EdgeConv) layer enhances network performance compared to networks that work with the same static graph in each layer; such performance enhancement comes, however, at the added computational cost associated with the dynamic graph generation stage (via kNN algorithm). Understanding its costs is essential for identifying the performance bottleneck and exploring potential avenues for hardware acceleration. To this end, this paper aims to shed light on the performance characteristics of EdgeConv-based DGNNs for point cloud inputs. Our performance analysis on a state-of-the-art EdgeConv network for classification shows that the dynamic graph construction via kNN takes up upwards of 95% of network latency on the GPU and almost 90% on the CPU. Moreover, we propose a quasi-Dynamic Graph Neural Network (qDGNN) that halts dynamic graph updates after a specific depth within the network to significantly reduce the latency on both CPU and GPU whilst matching the original networks inference accuracy. ",
    "url": "https://arxiv.org/abs/2309.09142",
    "authors": [
      "Dhruv Parikh",
      "Bingyi Zhang",
      "Rajgopal Kannan",
      "Viktor Prasanna",
      "Carl Busart"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.09147",
    "title": "Statement: The Metaverse as an Information-Centric Network",
    "abstract": "This paper discusses challenges and opportunities of considering the Metaverse as an Information-Centric Network (ICN). The Web today essentially represents a data-centric application layer: data named by URLs is manipulated with REST primitives. However, the semantic gap with the underlying host-oriented transport is significant, typically leading to complexity, centralization, and brittleness. Popular interest in \"the Metaverse\" suggests that the end-user experience of the Web will evolve towards always-on eXtended Reality (XR). With the benefit of a historical perspective, computing advances, and decades of experience with a global network, there is an opportunity to holistically consider the Metaverse not as an application of the current network, but an evolution of the network itself, reducing rather than widening the gap between network architecture and application semantics. An ICN architecture offers the possibility to achieve this with less overhead, low latency, better security, and more disruption tolerance suitable to diverse uses cases, even those facing intermittent connectivity. ",
    "url": "https://arxiv.org/abs/2309.09147",
    "authors": [
      "Dirk Kutscher",
      "Jeff Burke",
      "Giuseppe Fioccola",
      "Paulo Mendes"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.09150",
    "title": "Can Large Language Models Understand Real-World Complex Instructions?",
    "abstract": "Large language models (LLMs) can understand human instructions, showing their potential for pragmatic applications beyond traditional NLP tasks. However, they still struggle with complex instructions, which can be either complex task descriptions that require multiple tasks and constraints, or complex input that contains long context, noise, heterogeneous information and multi-turn format. Due to these features, LLMs often ignore semantic constraints from task descriptions, generate incorrect formats, violate length or sample count constraints, and be unfaithful to the input text. Existing benchmarks are insufficient to assess LLMs' ability to understand complex instructions, as they are close-ended and simple. To bridge this gap, we propose CELLO, a benchmark for evaluating LLMs' ability to follow complex instructions systematically. We design eight features for complex instructions and construct a comprehensive evaluation dataset from real-world scenarios. We also establish four criteria and develop corresponding metrics, as current ones are inadequate, biased or too strict and coarse-grained. We compare the performance of representative Chinese-oriented and English-oriented models in following complex instructions through extensive experiments. Resources of CELLO are publicly available at https://github.com/Abbey4799/CELLO. ",
    "url": "https://arxiv.org/abs/2309.09150",
    "authors": [
      "Qianyu He",
      "Jie Zeng",
      "Wenhao Huang",
      "Lina Chen",
      "Jin Xiao",
      "Qianxi He",
      "Xunzhe Zhou",
      "Lida Chen",
      "Xintao Wang",
      "Yuncheng Huang",
      "Haoning Ye",
      "Zihan Li",
      "Shisong Chen",
      "Yikai Zhang",
      "Zhouhong Gu",
      "Jiaqing Liang",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09170",
    "title": "A Unifying Privacy Analysis Framework for Unknown Domain Algorithms in  Differential Privacy",
    "abstract": "There are many existing differentially private algorithms for releasing histograms, i.e. counts with corresponding labels, in various settings. Our focus in this survey is to revisit some of the existing differentially private algorithms for releasing histograms over unknown domains, i.e. the labels of the counts that are to be released are not known beforehand. The main practical advantage of releasing histograms over an unknown domain is that the algorithm does not need to fill in missing labels because they are not present in the original histogram but in a hypothetical neighboring dataset could appear in the histogram. However, the challenge in designing differentially private algorithms for releasing histograms over an unknown domain is that some outcomes can clearly show which input was used, clearly violating privacy. The goal then is to show that the differentiating outcomes occur with very low probability. We present a unified framework for the privacy analyses of several existing algorithms. Furthermore, our analysis uses approximate concentrated differential privacy from Bun and Steinke'16, which can improve the privacy loss parameters rather than using differential privacy directly, especially when composing many of these algorithms together in an overall system. ",
    "url": "https://arxiv.org/abs/2309.09170",
    "authors": [
      "Ryan Rogers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.09179",
    "title": "Syntax Tree Constrained Graph Network for Visual Question Answering",
    "abstract": "Visual Question Answering (VQA) aims to automatically answer natural language questions related to given image content. Existing VQA methods integrate vision modeling and language understanding to explore the deep semantics of the question. However, these methods ignore the significant syntax information of the question, which plays a vital role in understanding the essential semantics of the question and guiding the visual feature refinement. To fill the gap, we suggested a novel Syntax Tree Constrained Graph Network (STCGN) for VQA based on entity message passing and syntax tree. This model is able to extract a syntax tree from questions and obtain more precise syntax information. Specifically, we parse questions and obtain the question syntax tree using the Stanford syntax parsing tool. From the word level and phrase level, syntactic phrase features and question features are extracted using a hierarchical tree convolutional network. We then design a message-passing mechanism for phrase-aware visual entities and capture entity features according to a given visual context. Extensive experiments on VQA2.0 datasets demonstrate the superiority of our proposed model. ",
    "url": "https://arxiv.org/abs/2309.09179",
    "authors": [
      "Xiangrui Su",
      "Qi Zhang",
      "Chongyang Shi",
      "Jiachang Liu",
      "Liang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09181",
    "title": "From Cooking Recipes to Robot Task Trees -- Improving Planning  Correctness and Task Efficiency by Leveraging LLMs with a Knowledge Network",
    "abstract": "Task planning for robotic cooking involves generating a sequence of actions for a robot to prepare a meal successfully. This paper introduces a novel task tree generation pipeline producing correct planning and efficient execution for cooking tasks. Our method first uses a large language model (LLM) to retrieve recipe instructions and then utilizes a fine-tuned GPT-3 to convert them into a task tree, capturing sequential and parallel dependencies among subtasks. The pipeline then mitigates the uncertainty and unreliable features of LLM outputs using task tree retrieval. We combine multiple LLM task tree outputs into a graph and perform a task tree retrieval to avoid questionable nodes and high-cost nodes to improve planning correctness and improve execution efficiency. Our evaluation results show its superior performance compared to previous works in task planning accuracy and efficiency. ",
    "url": "https://arxiv.org/abs/2309.09181",
    "authors": [
      "Md Sadman Sakib",
      "Yu Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09182",
    "title": "Optimal Scene Graph Planning with Large Language Model Guidance",
    "abstract": "Recent advances in metric, semantic, and topological mapping have equipped autonomous robots with semantic concept grounding capabilities to interpret natural language tasks. This work aims to leverage these new capabilities with an efficient task planning algorithm for hierarchical metric-semantic models. We consider a scene graph representation of the environment and utilize a large language model (LLM) to convert a natural language task into a linear temporal logic (LTL) automaton. Our main contribution is to enable optimal hierarchical LTL planning with LLM guidance over scene graphs. To achieve efficiency, we construct a hierarchical planning domain that captures the attributes and connectivity of the scene graph and the task automaton, and provide semantic guidance via an LLM heuristic function. To guarantee optimality, we design an LTL heuristic function that is provably consistent and supplements the potentially inadmissible LLM guidance in multi-heuristic planning. We demonstrate efficient planning of complex natural language tasks in scene graphs of virtualized real environments. ",
    "url": "https://arxiv.org/abs/2309.09182",
    "authors": [
      "Zhirui Dai",
      "Arash Asgharivaskasi",
      "Thai Duong",
      "Shusen Lin",
      "Maria-Elizabeth Tzes",
      "George Pappas",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09191",
    "title": "End-to-End Optimized Pipeline for Prediction of Protein Folding Kinetics",
    "abstract": "Protein folding is the intricate process by which a linear sequence of amino acids self-assembles into a unique three-dimensional structure. Protein folding kinetics is the study of pathways and time-dependent mechanisms a protein undergoes when it folds. Understanding protein kinetics is essential as a protein needs to fold correctly for it to perform its biological functions optimally, and a misfolded protein can sometimes be contorted into shapes that are not ideal for a cellular environment giving rise to many degenerative, neuro-degenerative disorders and amyloid diseases. Monitoring at-risk individuals and detecting protein discrepancies in a protein's folding kinetics at the early stages could majorly result in public health benefits, as preventive measures can be taken. This research proposes an efficient pipeline for predicting protein folding kinetics with high accuracy and low memory footprint. The deployed machine learning (ML) model outperformed the state-of-the-art ML models by 4.8% in terms of accuracy while consuming 327x lesser memory and being 7.3% faster. ",
    "url": "https://arxiv.org/abs/2309.09191",
    "authors": [
      "Vijay Arvind.R",
      "Haribharathi Sivakumar",
      "Brindha.R"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2309.09195",
    "title": "SplitEE: Early Exit in Deep Neural Networks with Split Computing",
    "abstract": "Deep Neural Networks (DNNs) have drawn attention because of their outstanding performance on various tasks. However, deploying full-fledged DNNs in resource-constrained devices (edge, mobile, IoT) is difficult due to their large size. To overcome the issue, various approaches are considered, like offloading part of the computation to the cloud for final inference (split computing) or performing the inference at an intermediary layer without passing through all layers (early exits). In this work, we propose combining both approaches by using early exits in split computing. In our approach, we decide up to what depth of DNNs computation to perform on the device (splitting layer) and whether a sample can exit from this layer or need to be offloaded. The decisions are based on a weighted combination of accuracy, computational, and communication costs. We develop an algorithm named SplitEE to learn an optimal policy. Since pre-trained DNNs are often deployed in new domains where the ground truths may be unavailable and samples arrive in a streaming fashion, SplitEE works in an online and unsupervised setup. We extensively perform experiments on five different datasets. SplitEE achieves a significant cost reduction ($>50\\%$) with a slight drop in accuracy ($<2\\%$) as compared to the case when all samples are inferred at the final layer. The anonymized source code is available at \\url{https://anonymous.4open.science/r/SplitEE_M-B989/README.md}. ",
    "url": "https://arxiv.org/abs/2309.09195",
    "authors": [
      "Divya J. Bajpai",
      "Vivek K. Trivedi",
      "Sohan L. Yadav",
      "Manjesh K. Hanawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.09196",
    "title": "Efficient Pyramid Channel Attention Network for Pathological Myopia  Detection",
    "abstract": "Pathological myopia (PM) is the leading ocular disease for impaired vision and blindness worldwide. The key to detecting PM as early as possible is to detect informative features in global and local lesion regions, such as fundus tessellation, atrophy and maculopathy. However, applying classical convolutional neural networks (CNNs) to efficiently highlight global and local lesion context information in feature maps is quite challenging. To tackle this issue, we aim to fully leverage the potential of global and local lesion information with attention module design. Based on this, we propose an efficient pyramid channel attention (EPCA) module, which dynamically explores the relative importance of global and local lesion context information in feature maps. Then we combine the EPCA module with the backbone network to construct EPCA-Net for automatic PM detection based on fundus images. In addition, we construct a PM dataset termed PM-fundus by collecting fundus images of PM from publicly available datasets (e.g., the PALM dataset and ODIR dataset). The comprehensive experiments are conducted on three datasets, demonstrating that our EPCA-Net outperforms state-of-the-art methods in detecting PM. Furthermore, motivated by the recent pretraining-and-finetuning paradigm, we attempt to adapt pre-trained natural image models for PM detection by freezing them and treating the EPCA module and other attention modules as the adapters. The results show that our method with the pretraining-and-finetuning paradigm achieves competitive performance through comparisons to part of methods with traditional fine-tuning methods with fewer tunable parameters. ",
    "url": "https://arxiv.org/abs/2309.09196",
    "authors": [
      "Xiaoqing Zhang",
      "Jilu Zhao",
      "Richu Jin",
      "Yan Li",
      "Hao Wu",
      "Xiangtian Zhou",
      "Jiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09203",
    "title": "Using Artificial Neural Networks to Determine Ontologies Most Relevant  to Scientific Texts",
    "abstract": "This paper provides an insight into the possibility of how to find ontologies most relevant to scientific texts using artificial neural networks. The basic idea of the presented approach is to select a representative paragraph from a source text file, embed it to a vector space by a pre-trained fine-tuned transformer, and classify the embedded vector according to its relevance to a target ontology. We have considered different classifiers to categorize the output from the transformer, in particular random forest, support vector machine, multilayer perceptron, k-nearest neighbors, and Gaussian process classifiers. Their suitability has been evaluated in a use case with ontologies and scientific texts concerning catalysis research. From results we can say the worst results have random forest. The best results in this task brought support vector machine classifier. ",
    "url": "https://arxiv.org/abs/2309.09203",
    "authors": [
      "Luk\u00e1\u0161 Korel",
      "Alexander S. Behr",
      "Norbert Kockmann",
      "Martin Hole\u0148a"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.09211",
    "title": "Neural Gradient Learning and Optimization for Oriented Point Normal  Estimation",
    "abstract": "We propose Neural Gradient Learning (NGL), a deep learning approach to learn gradient vectors with consistent orientation from 3D point clouds for normal estimation. It has excellent gradient approximation properties for the underlying geometry of the data. We utilize a simple neural network to parameterize the objective function to produce gradients at points using a global implicit representation. However, the derived gradients usually drift away from the ground-truth oriented normals due to the lack of local detail descriptions. Therefore, we introduce Gradient Vector Optimization (GVO) to learn an angular distance field based on local plane geometry to refine the coarse gradient vectors. Finally, we formulate our method with a two-phase pipeline of coarse estimation followed by refinement. Moreover, we integrate two weighting functions, i.e., anisotropic kernel and inlier score, into the optimization to improve the robust and detail-preserving performance. Our method efficiently conducts global gradient approximation while achieving better accuracy and generalization ability of local feature description. This leads to a state-of-the-art normal estimator that is robust to noise, outliers and point density variations. Extensive evaluations show that our method outperforms previous works in both unoriented and oriented normal estimation on widely used benchmarks. The source code and pre-trained models are available at https://github.com/LeoQLi/NGLO. ",
    "url": "https://arxiv.org/abs/2309.09211",
    "authors": [
      "Qing Li",
      "Huifang Feng",
      "Kanle Shi",
      "Yi Fang",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09223",
    "title": "Zero- and Few-shot Sound Event Localization and Detection",
    "abstract": "Sound event localization and detection (SELD) systems estimate direction-of-arrival (DOA) and temporal activation for sets of target classes. Neural network (NN)-based SELD systems have performed well in various sets of target classes, but they only output the DOA and temporal activation of preset classes that are trained before inference. To customize target classes after training, we tackle zero- and few-shot SELD tasks, in which we set new classes with a text sample or a few audio samples. While zero-shot sound classification tasks are achievable by embedding from contrastive language-audio pretraining (CLAP), zero-shot SELD tasks require assigning an activity and a DOA to each embedding, especially in overlapping cases. To tackle the assignment problem in overlapping cases, we propose an embed-ACCDOA model, which is trained to output track-wise CLAP embedding and corresponding activity-coupled Cartesian direction-of-arrival (ACCDOA). In our experimental evaluations on zero- and few-shot SELD tasks, the embed-ACCDOA model showed a better location-dependent scores than a straightforward combination of the CLAP audio encoder and a DOA estimation model. Moreover, the proposed combination of the embed-ACCDOA model and CLAP audio encoder with zero- or few-shot samples performed comparably to an official baseline system trained with complete train data in an evaluation dataset. ",
    "url": "https://arxiv.org/abs/2309.09223",
    "authors": [
      "Kazuki Shimada",
      "Kengo Uchida",
      "Yuichiro Koyama",
      "Takashi Shibuya",
      "Shusuke Takahashi",
      "Yuki Mitsufuji",
      "Tatsuya Kawahara"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.09228",
    "title": "Hamiltonian path and Hamiltonian cycle are solvable in polynomial time  in graphs of bounded independence number",
    "abstract": "A Hamiltonian path (a Hamiltonian cycle) in a graph is a path (a cycle, respectively) that traverses all of its vertices. The problems of deciding their existence in an input graph are well-known to be NP-complete, in fact, they belong to the first problems shown to be computationally hard when the theory of NP-completeness was being developed. A lot of research has been devoted to the complexity of Hamiltonian path and Hamiltonian cycle problems for special graph classes, yet only a handful of positive results are known. The complexities of both of these problems have been open even for $4K_1$-free graphs, i.e., graphs of independence number at most $3$. We answer this question in the general setting of graphs of bounded independence number. We also consider a newly introduced problem called \\emph{Hamiltonian-$\\ell$-Linkage} which is related to the notions of a path cover and of a linkage in a graph. This problem asks if given $\\ell$ pairs of vertices in an input graph can be connected by disjoint paths that altogether traverse all vertices of the graph. For $\\ell=1$, Hamiltonian-1-Linkage asks for existence of a Hamiltonian path connecting a given pair of vertices. Our main result reads that for every pair of integers $k$ and $\\ell$, the Hamiltonian-$\\ell$-Linkage problem is polynomial time solvable for graphs of independence number not exceeding $k$. We further complement this general polynomial time algorithm by a structural description of obstacles to Hamiltonicity in graphs of independence number at most $k$ for small values of $k$. ",
    "url": "https://arxiv.org/abs/2309.09228",
    "authors": [
      "Nikola Jedli\u010dkov\u00e1",
      "Jan Kratochv\u00edl"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2309.09231",
    "title": "ATM: a Logic for Quantitative Security Properties on Attack Trees",
    "abstract": "Critical infrastructure systems - for which high reliability and availability are paramount - must operate securely. Attack trees (ATs) are hierarchical diagrams that offer a flexible modelling language used to assess how systems can be attacked. ATs are widely employed both in industry and academia but - in spite of their popularity - little work has been done to give practitioners instruments to formulate queries on ATs in an understandable yet powerful way. In this paper we fill this gap by presenting ATM, a logic to express quantitative security properties on ATs. ATM allows for the specification of properties involved with security metrics that include \"cost\", \"probability\" and \"skill\" and permits the formulation of insightful what-if scenarios. To showcase its potential, we apply ATM to the case study of a CubeSAT, presenting three different ways in which an attacker can compromise its availability. We showcase property specification on the corresponding attack tree and we present theory and algorithms - based on binary decision diagrams - to check properties and compute metrics of ATM-formulae. ",
    "url": "https://arxiv.org/abs/2309.09231",
    "authors": [
      "Stefano M. Nicoletti",
      "Milan Lopuha\u00e4-Zwakenberg",
      "E. Moritz Hahn",
      "Mari\u00eblle Stoelinga"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2309.09236",
    "title": "Detection and Localization of Firearm Carriers in Complex Scenes for  Improved Safety Measures",
    "abstract": "Detecting firearms and accurately localizing individuals carrying them in images or videos is of paramount importance in security, surveillance, and content customization. However, this task presents significant challenges in complex environments due to clutter and the diverse shapes of firearms. To address this problem, we propose a novel approach that leverages human-firearm interaction information, which provides valuable clues for localizing firearm carriers. Our approach incorporates an attention mechanism that effectively distinguishes humans and firearms from the background by focusing on relevant areas. Additionally, we introduce a saliency-driven locality-preserving constraint to learn essential features while preserving foreground information in the input image. By combining these components, our approach achieves exceptional results on a newly proposed dataset. To handle inputs of varying sizes, we pass paired human-firearm instances with attention masks as channels through a deep network for feature computation, utilizing an adaptive average pooling layer. We extensively evaluate our approach against existing methods in human-object interaction detection and achieve significant results (AP=77.8\\%) compared to the baseline approach (AP=63.1\\%). This demonstrates the effectiveness of leveraging attention mechanisms and saliency-driven locality preservation for accurate human-firearm interaction detection. Our findings contribute to advancing the fields of security and surveillance, enabling more efficient firearm localization and identification in diverse scenarios. ",
    "url": "https://arxiv.org/abs/2309.09236",
    "authors": [
      "Arif Mahmood",
      "Abdul Basit",
      "M. Akhtar Munir",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09250",
    "title": "Convex Latent-Optimized Adversarial Regularizers for Imaging Inverse  Problems",
    "abstract": "Recently, data-driven techniques have demonstrated remarkable effectiveness in addressing challenges related to MR imaging inverse problems. However, these methods still exhibit certain limitations in terms of interpretability and robustness. In response, we introduce Convex Latent-Optimized Adversarial Regularizers (CLEAR), a novel and interpretable data-driven paradigm. CLEAR represents a fusion of deep learning (DL) and variational regularization. Specifically, we employ a latent optimization technique to adversarially train an input convex neural network, and its set of minima can fully represent the real data manifold. We utilize it as a convex regularizer to formulate a CLEAR-informed variational regularization model that guides the solution of the imaging inverse problem on the real data manifold. Leveraging its inherent convexity, we have established the convergence of the projected subgradient descent algorithm for the CLEAR-informed regularization model. This convergence guarantees the attainment of a unique solution to the imaging inverse problem, subject to certain assumptions. Furthermore, we have demonstrated the robustness of our CLEAR-informed model, explicitly showcasing its capacity to achieve stable reconstruction even in the presence of measurement interference. Finally, we illustrate the superiority of our approach using MRI reconstruction as an example. Our method consistently outperforms conventional data-driven techniques and traditional regularization approaches, excelling in both reconstruction quality and robustness. ",
    "url": "https://arxiv.org/abs/2309.09250",
    "authors": [
      "Huayu Wang",
      "Chen Luo",
      "Taofeng Xie",
      "Qiyu Jin",
      "Guoqing Chen",
      "Zhuo-Xu Cui",
      "Dong Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.09253",
    "title": "User Assignment and Resource Allocation for Hierarchical Federated  Learning over Wireless Networks",
    "abstract": "The large population of wireless users is a key driver of data-crowdsourced Machine Learning (ML). However, data privacy remains a significant concern. Federated Learning (FL) encourages data sharing in ML without requiring data to leave users' devices but imposes heavy computation and communications overheads on mobile devices. Hierarchical FL (HFL) alleviates this problem by performing partial model aggregation at edge servers. HFL can effectively reduce energy consumption and latency through effective resource allocation and appropriate user assignment. Nevertheless, resource allocation in HFL involves optimizing multiple variables, and the objective function should consider both energy consumption and latency, making the development of resource allocation algorithms very complicated. Moreover, it is challenging to perform user assignment, which is a combinatorial optimization problem in a large search space. This article proposes a spectrum resource optimization algorithm (SROA) and a two-stage iterative algorithm (TSIA) for HFL. Given an arbitrary user assignment pattern, SROA optimizes CPU frequency, transmit power, and bandwidth to minimize system cost. TSIA aims to find a user assignment pattern that considerably reduces the total system cost. Experimental results demonstrate the superiority of the proposed HFL framework over existing studies in energy and latency reduction. ",
    "url": "https://arxiv.org/abs/2309.09253",
    "authors": [
      "Tinghao Zhang",
      "Kwok-Yan Lam",
      "Jun Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09258",
    "title": "Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets",
    "abstract": "In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates with adequately smooth and bounded activations like sigmoid and tanh. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence of Frobenius norm regularized logistic loss functions on constant-sized neural nets which are \"Villani functions\" and thus be able to build on recent progress with analyzing SGD on such objectives. ",
    "url": "https://arxiv.org/abs/2309.09258",
    "authors": [
      "Pulkit Gopalani",
      "Samyak Jha",
      "Anirbit Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.09264",
    "title": "Code quality assessment using transformers",
    "abstract": "Automatically evaluate the correctness of programming assignments is rather straightforward using unit and integration tests. However, programming tasks can be solved in multiple ways, many of which, although correct, are inelegant. For instance, excessive branching, poor naming or repetitiveness make the code hard to understand and maintain. These subjective qualities of code are hard to automatically assess using current techniques. In this work we investigate the use of CodeBERT to automatically assign quality score to Java code. We experiment with different models and training paradigms. We explore the accuracy of the models on a novel dataset for code quality assessment. Finally, we assess the quality of the predictions using saliency maps. We find that code quality to some extent is predictable and that transformer based models using task adapted pre-training can solve the task more efficiently than other techniques. ",
    "url": "https://arxiv.org/abs/2309.09264",
    "authors": [
      "Mosleh Mahamud",
      "Isak Samsten"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.09272",
    "title": "Deep Neighbor Layer Aggregation for Lightweight Self-Supervised  Monocular Depth Estimation",
    "abstract": "With the frequent use of self-supervised monocular depth estimation in robotics and autonomous driving, the model's efficiency is becoming increasingly important. Most current approaches apply much larger and more complex networks to improve the precision of depth estimation. Some researchers incorporated Transformer into self-supervised monocular depth estimation to achieve better performance. However, this method leads to high parameters and high computation. We present a fully convolutional depth estimation network using contextual feature fusion. Compared to UNet++ and HRNet, we use high-resolution and low-resolution features to reserve information on small targets and fast-moving objects instead of long-range fusion. We further promote depth estimation results employing lightweight channel attention based on convolution in the decoder stage. Our method reduces the parameters without sacrificing accuracy. Experiments on the KITTI benchmark show that our method can get better results than many large models, such as Monodepth2, with only 30 parameters. The source code is available at https://github.com/boyagesmile/DNA-Depth. ",
    "url": "https://arxiv.org/abs/2309.09272",
    "authors": [
      "Boya Wang",
      "Shuo Wang",
      "Ziwen Dou",
      "Dong Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09274",
    "title": "Leveraging Social Discourse to Measure Check-worthiness of Claims for  Fact-checking",
    "abstract": "The expansion of online social media platforms has led to a surge in online content consumption. However, this has also paved the way for disseminating false claims and misinformation. As a result, there is an escalating demand for a substantial workforce to sift through and validate such unverified claims. Currently, these claims are manually verified by fact-checkers. Still, the volume of online content often outweighs their potency, making it difficult for them to validate every single claim in a timely manner. Thus, it is critical to determine which assertions are worth fact-checking and prioritize claims that require immediate attention. Multiple factors contribute to determining whether a claim necessitates fact-checking, encompassing factors such as its factual correctness, potential impact on the public, the probability of inciting hatred, and more. Despite several efforts to address claim check-worthiness, a systematic approach to identify these factors remains an open challenge. To this end, we introduce a new task of fine-grained claim check-worthiness, which underpins all of these factors and provides probable human grounds for identifying a claim as check-worthy. We present CheckIt, a manually annotated large Twitter dataset for fine-grained claim check-worthiness. We benchmark our dataset against a unified approach, CheckMate, that jointly determines whether a claim is check-worthy and the factors that led to that conclusion. We compare our suggested system with several baseline systems. Finally, we report a thorough analysis of results and human assessment, validating the efficacy of integrating check-worthiness factors in detecting claims worth fact-checking. ",
    "url": "https://arxiv.org/abs/2309.09274",
    "authors": [
      "Megha Sundriyal",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09295",
    "title": "NeRF-VINS: A Real-time Neural Radiance Field Map-based Visual-Inertial  Navigation System",
    "abstract": "Achieving accurate, efficient, and consistent localization within an a priori environment map remains a fundamental challenge in robotics and computer vision. Conventional map-based keyframe localization often suffers from sub-optimal viewpoints due to limited field of view (FOV), thus degrading its performance. To address this issue, in this paper, we design a real-time tightly-coupled Neural Radiance Fields (NeRF)-aided visual-inertial navigation system (VINS), termed NeRF-VINS. By effectively leveraging NeRF's potential to synthesize novel views, essential for addressing limited viewpoints, the proposed NeRF-VINS optimally fuses IMU and monocular image measurements along with synthetically rendered images within an efficient filter-based framework. This tightly coupled integration enables 3D motion tracking with bounded error. We extensively compare the proposed NeRF-VINS against the state-of-the-art methods that use prior map information, which is shown to achieve superior performance. We also demonstrate the proposed method is able to perform real-time estimation at 15 Hz, on a resource-constrained Jetson AGX Orin embedded platform with impressive accuracy. ",
    "url": "https://arxiv.org/abs/2309.09295",
    "authors": [
      "Saimouli Katragadda",
      "Woosik Lee",
      "Yuxiang Peng",
      "Patrick Geneva",
      "Chuchu Chen",
      "Chao Guo",
      "Mingyang Li",
      "Guoquan Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09296",
    "title": "Model-based Subsampling for Knowledge Graph Completion",
    "abstract": "Subsampling is effective in Knowledge Graph Embedding (KGE) for reducing overfitting caused by the sparsity in Knowledge Graph (KG) datasets. However, current subsampling approaches consider only frequencies of queries that consist of entities and their relations. Thus, the existing subsampling potentially underestimates the appearance probabilities of infrequent queries even if the frequencies of their entities or relations are high. To address this problem, we propose Model-based Subsampling (MBS) and Mixed Subsampling (MIX) to estimate their appearance probabilities through predictions of KGE models. Evaluation results on datasets FB15k-237, WN18RR, and YAGO3-10 showed that our proposed subsampling methods actually improved the KG completion performances for popular KGE models, RotatE, TransE, HAKE, ComplEx, and DistMult. ",
    "url": "https://arxiv.org/abs/2309.09296",
    "authors": [
      "Xincan Feng",
      "Hidetaka Kamigaito",
      "Katsuhiko Hayashi",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09297",
    "title": "Chasing Day and Night: Towards Robust and Efficient All-Day Object  Detection Guided by an Event Camera",
    "abstract": "The ability to detect objects in all lighting (i.e., normal-, over-, and under-exposed) conditions is crucial for real-world applications, such as self-driving.Traditional RGB-based detectors often fail under such varying lighting conditions.Therefore, recent works utilize novel event cameras to supplement or guide the RGB modality; however, these methods typically adopt asymmetric network structures that rely predominantly on the RGB modality, resulting in limited robustness for all-day detection. In this paper, we propose EOLO, a novel object detection framework that achieves robust and efficient all-day detection by fusing both RGB and event modalities. Our EOLO framework is built based on a lightweight spiking neural network (SNN) to efficiently leverage the asynchronous property of events. Buttressed by it, we first introduce an Event Temporal Attention (ETA) module to learn the high temporal information from events while preserving crucial edge information. Secondly, as different modalities exhibit varying levels of importance under diverse lighting conditions, we propose a novel Symmetric RGB-Event Fusion (SREF) module to effectively fuse RGB-Event features without relying on a specific modality, thus ensuring a balanced and adaptive fusion for all-day detection. In addition, to compensate for the lack of paired RGB-Event datasets for all-day training and evaluation, we propose an event synthesis approach based on the randomized optical flow that allows for directly generating the event frame from a single exposure image. We further build two new datasets, E-MSCOCO and E-VOC based on the popular benchmarks MSCOCO and PASCAL VOC. Extensive experiments demonstrate that our EOLO outperforms the state-of-the-art detectors,e.g.,RENet,by a substantial margin (+3.74% mAP50) in all lighting conditions.Our code and datasets will be available at https://vlislab22.github.io/EOLO/ ",
    "url": "https://arxiv.org/abs/2309.09297",
    "authors": [
      "Jiahang Cao",
      "Xu Zheng",
      "Yuanhuiyi Lyu",
      "Jiaxu Wang",
      "Renjing Xu",
      "Lin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09300",
    "title": "AutoAM: An End-To-End Neural Model for Automatic and Universal Argument  Mining",
    "abstract": "Argument mining is to analyze argument structure and extract important argument information from unstructured text. An argument mining system can help people automatically gain causal and logical information behind the text. As argumentative corpus gradually increases, like more people begin to argue and debate on social media, argument mining from them is becoming increasingly critical. However, argument mining is still a big challenge in natural language tasks due to its difficulty, and relative techniques are not mature. For example, research on non-tree argument mining needs to be done more. Most works just focus on extracting tree structure argument information. Moreover, current methods cannot accurately describe and capture argument relations and do not predict their types. In this paper, we propose a novel neural model called AutoAM to solve these problems. We first introduce the argument component attention mechanism in our model. It can capture the relevant information between argument components, so our model can better perform argument mining. Our model is a universal end-to-end framework, which can analyze argument structure without constraints like tree structure and complete three subtasks of argument mining in one model. The experiment results show that our model outperforms the existing works on several metrics in two public datasets. ",
    "url": "https://arxiv.org/abs/2309.09300",
    "authors": [
      "Lang Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09308",
    "title": "GAMMA: Revisiting Template-based Automated Program Repair via Mask  Prediction",
    "abstract": "Automated program repair (APR) aims to fix software bugs without human intervention and template-based APR has been widely investigated with promising results. However, it is challenging for template-based APR to select the appropriate donor code, which is an important repair ingredient for generating candidate patches. Inappropriate donor code may cause plausible but incorrect patch generation even with correct fix patterns, limiting the repair performance. In this paper, we aim to revisit template-based APR, and propose GAMMA, to directly leverage large pre-trained language models for donor code generation. Our main insight is that instead of retrieving donor code in the local buggy file, we can directly predict the correct code tokens based on the context code snippets and repair patterns by a cloze task. Specifically, (1) GAMMA revises a variety of fix templates from state-of-the-art template-based APR techniques (i.e., TBar) and transforms them into mask patterns. (2) GAMMA adopts a pre-trained language model to predict the correct code for masked code as a fill-in-the-blank task. The experimental results demonstrate that GAMMA correctly repairs 82 bugs on Defects4J-v1.2, which achieves 20.59\\% (14 bugs) and 26.15\\% (17 bugs) improvement over the previous state-of-the-art template-based approach TBar and learning-based one Recoder. Furthermore, GAMMA repairs 45 bugs and 22 bugs from the additional Defects4J-v2.0 and QuixBugs, indicating the generalizability of GAMMA in addressing the dataset overfitting issue. We also prove that adopting other pre-trained language models can provide substantial advancement, e.g., CodeBERT-based and ChatGPT-based GAMMA is able to fix 80 and 67 bugs on Defects4J-v1.2, indicating the scalability of GAMMA. Overall, our study highlights the promising future of adopting pre-trained models to generate correct patches on top of fix patterns. ",
    "url": "https://arxiv.org/abs/2309.09308",
    "authors": [
      "Quanjun Zhang",
      "Chunrong Fang",
      "Tongke Zhang",
      "Bowen Yu",
      "Weisong Sun",
      "Zhenyu Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.09311",
    "title": "Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal  Intervention",
    "abstract": "Many studies focus on improving pretraining or developing new backbones in text-video retrieval. However, existing methods may suffer from the learning and inference bias issue, as recent research suggests in other text-video-related tasks. For instance, spatial appearance features on action recognition or temporal object co-occurrences on video scene graph generation could induce spurious correlations. In this work, we present a unique and systematic study of a temporal bias due to frame length discrepancy between training and test sets of trimmed video clips, which is the first such attempt for a text-video retrieval task, to the best of our knowledge. We first hypothesise and verify the bias on how it would affect the model illustrated with a baseline study. Then, we propose a causal debiasing approach and perform extensive experiments and ablation studies on the Epic-Kitchens-100, YouCook2, and MSR-VTT datasets. Our model overpasses the baseline and SOTA on nDCG, a semantic-relevancy-focused evaluation metric which proves the bias is mitigated, as well as on the other conventional metrics. ",
    "url": "https://arxiv.org/abs/2309.09311",
    "authors": [
      "Burak Satar",
      "Hongyuan Zhu",
      "Hanwang Zhang",
      "Joo Hwee Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.09317",
    "title": "Kinematics-aware Trajectory Generation and Prediction with Latent  Stochastic Differential Modeling",
    "abstract": "Trajectory generation and trajectory prediction are two critical tasks for autonomous vehicles, which generate various trajectories during development and predict the trajectories of surrounding vehicles during operation, respectively. However, despite significant advances in improving their performance, it remains a challenging problem to ensure that the generated/predicted trajectories are realistic, explainable, and physically feasible. Existing model-based methods provide explainable results, but are constrained by predefined model structures, limiting their capabilities to address complex scenarios. Conversely, existing deep learning-based methods have shown great promise in learning various traffic scenarios and improving overall performance, but they often act as opaque black boxes and lack explainability. In this work, we integrate kinematic knowledge with neural stochastic differential equations (SDE) and develop a variational autoencoder based on a novel latent kinematics-aware SDE (LK-SDE) to generate vehicle motions. Our approach combines the advantages of both model-based and deep learning-based techniques. Experimental results demonstrate that our method significantly outperforms baseline approaches in producing realistic, physically-feasible, and precisely-controllable vehicle trajectories, benefiting both generation and prediction tasks. ",
    "url": "https://arxiv.org/abs/2309.09317",
    "authors": [
      "Ruochen Jiao",
      "Yixuan Wang",
      "Xiangguo Liu",
      "Chao Huang",
      "Qi Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09336",
    "title": "Unleashing the Power of Dynamic Mode Decomposition and Deep Learning for  Rainfall Prediction in North-East India",
    "abstract": "Accurate rainfall forecasting is crucial for effective disaster preparedness and mitigation in the North-East region of India, which is prone to extreme weather events such as floods and landslides. In this study, we investigated the use of two data-driven methods, Dynamic Mode Decomposition (DMD) and Long Short-Term Memory (LSTM), for rainfall forecasting using daily rainfall data collected from India Meteorological Department in northeast region over a period of 118 years. We conducted a comparative analysis of these methods to determine their relative effectiveness in predicting rainfall patterns. Using historical rainfall data from multiple weather stations, we trained and validated our models to forecast future rainfall patterns. Our results indicate that both DMD and LSTM are effective in forecasting rainfall, with LSTM outperforming DMD in terms of accuracy, revealing that LSTM has the ability to capture complex nonlinear relationships in the data, making it a powerful tool for rainfall forecasting. Our findings suggest that data-driven methods such as DMD and deep learning approaches like LSTM can significantly improve rainfall forecasting accuracy in the North-East region of India, helping to mitigate the impact of extreme weather events and enhance the region's resilience to climate change. ",
    "url": "https://arxiv.org/abs/2309.09336",
    "authors": [
      "Paleti Nikhil Chowdary",
      "Sathvika P",
      "Pranav U",
      "Rohan S",
      "Sowmya V",
      "Gopalakrishnan E A",
      "Dhanya M"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2309.09363",
    "title": "A Distributed Strategy to Maximize Coverage in a Heterogeneous Sensor  Network in the Presence of Obstacles",
    "abstract": "In this paper, an efficient deployment strategy is proposed for a network of mobile and static sensors with nonidentical sensing and communication radii. The multiplicatively weighted Voronoi (MW-Voronoi) diagram is used to partition the field and assign the underlying coverage task to each mobile sensor. A gradient-based method is applied to find the best candidate point based on the detected coverage holes and the coverage priority considering the relative distance of the mobile sensor from the static ones and the obstacles in the field. The sensors move to a new position if such a relocation increases their local coverage. The efficiency of the proposed strategy in different scenarios is demonstrated by simulations. ",
    "url": "https://arxiv.org/abs/2309.09363",
    "authors": [
      "Hesam Mosalli",
      "Amir G. Aghdam"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.09374",
    "title": "Fully Convolutional Generative Machine Learning Method for Accelerating  Non-Equilibrium Greens Function Simulations",
    "abstract": "This work describes a novel simulation approach that combines machine learning and device modelling simulations. The device simulations are based on the quantum mechanical non-equilibrium Greens function (NEGF) approach and the machine learning method is an extension to a convolutional generative network. We have named our new simulation approach ML-NEGF and we have implemented it in our in-house simulator called NESS (nano-electronics simulations software). The reported results demonstrate the improved convergence speed of the ML-NEGF method in comparison to the standard NEGF approach. The trained ML model effectively learns the underlying physics of nano-sheet transistor behaviour, resulting in faster convergence of the coupled Poisson-NEGF simulations. Quantitatively, our ML- NEGF approach achieves an average convergence acceleration of 60%, substantially reducing the computational time while maintaining the same accuracy. ",
    "url": "https://arxiv.org/abs/2309.09374",
    "authors": [
      "Preslav Aleksandrov",
      "Ali Rezaei",
      "Nikolas Xeni",
      "Tapas Dutta",
      "Asen Asenov",
      "Vihar Georgiev"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09378",
    "title": "Dynamics of Fisheries in the Azores Islands: A Network Analysis Approach",
    "abstract": "In the context of the global seafood industry, the Azores archipelago (Portugal) plays a pivotal role due to its vast maritime domain. This study employs complex network analysis techniques to investigate the dynamics of Azores fisheries, using time series data converted into networks. We uncover associations between Tunas and specific islands, consistent links among fish classifications, and identify other pivotal nodes within the fishing network. Remarkably, nodes with high degrees and a local clustering coefficient of one provide crucial insights into the fishing ecosystem. This study highlights the value of network analysis for understanding fisheries complexities and offers insights into sustainable management and the preservation of marine ecosystems. It also emphasizes the urgency for ongoing research and data collection to enrich our understanding of this multifaceted domain. ",
    "url": "https://arxiv.org/abs/2309.09378",
    "authors": [
      "Brenda Nogueira",
      "Ana Torres",
      "Nuno Moniz",
      "Gui M. Menezes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.09386",
    "title": "Axioms for Distanceless Graph Partitioning",
    "abstract": "In 2002, Kleinberg proposed three axioms for distance-based clustering, and proved that it was impossible for a clustering method to satisfy all three. While there has been much subsequent work examining and modifying these axioms for distance-based clustering, little work has been done to explore axioms relevant to the graph partitioning problem, i.e., when the graph is given without a distance matrix. Here, we propose and explore axioms for graph partitioning when given graphs without distance matrices, including modifications of Kleinberg's axioms for the distanceless case and two others (one axiom relevant to the ''Resolution Limit'' and one addressing well-connectedness). We prove that clustering under the Constant Potts Model satisfies all the axioms, while Modularity clustering and Iterative k-core both fail many axioms we pose. These theoretical properties of the clustering methods are relevant both for theoretical investigation as well as to practitioners considering which methods to use for their domain science studies. ",
    "url": "https://arxiv.org/abs/2309.09386",
    "authors": [
      "James Willson",
      "Tandy Warnow"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2309.09416",
    "title": "Causal Discovery and Prediction: Methods and Algorithms",
    "abstract": "We are not only observers but also actors of reality. Our capability to intervene and alter the course of some events in the space and time surrounding us is an essential component of how we build our model of the world. In this doctoral thesis we introduce a generic a-priori assessment of each possible intervention, in order to select the most cost-effective interventions only, and avoid unnecessary systematic experimentation on the real world. Based on this a-priori assessment, we propose an active learning algorithm that identifies the causal relations in any given causal model, using a least cost sequence of interventions. There are several novel aspects introduced by our algorithm. It is, in most case scenarios, able to discard many causal model candidates using relatively inexpensive interventions that only test one value of the intervened variables. Also, the number of interventions performed by the algorithm can be bounded by the number of causal model candidates. Hence, fewer initial candidates (or equivalently, more prior knowledge) lead to fewer interventions for causal discovery. Causality is intimately related to time, as causes appear to precede their effects. Cyclical causal processes are a very interesting case of causality in relation to time. In this doctoral thesis we introduce a formal analysis of time cyclical causal settings by defining a causal analog to the purely observational Dynamic Bayesian Networks, and provide a sound and complete algorithm for the identification of causal effects in the cyclic setting. We introduce the existence of two types of hidden confounder variables in this framework, which affect in substantially different ways the identification procedures, a distinction with no analog in either Dynamic Bayesian Networks or standard causal graphs. ",
    "url": "https://arxiv.org/abs/2309.09416",
    "authors": [
      "Gilles Blondel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09431",
    "title": "FactoFormer: Factorized Hyperspectral Transformers with Self-Supervised  Pre-Training",
    "abstract": "Hyperspectral images (HSIs) contain rich spectral and spatial information. Motivated by the success of transformers in the field of natural language processing and computer vision where they have shown the ability to learn long range dependencies within input data, recent research has focused on using transformers for HSIs. However, current state-of-the-art hyperspectral transformers only tokenize the input HSI sample along the spectral dimension, resulting in the under-utilization of spatial information. Moreover, transformers are known to be data-hungry and their performance relies heavily on large-scale pre-training, which is challenging due to limited annotated hyperspectral data. Therefore, the full potential of HSI transformers has not been fully realized. To overcome these limitations, we propose a novel factorized spectral-spatial transformer that incorporates factorized self-supervised pre-training procedures, leading to significant improvements in performance. The factorization of the inputs allows the spectral and spatial transformers to better capture the interactions within the hyperspectral data cubes. Inspired by masked image modeling pre-training, we also devise efficient masking strategies for pre-training each of the spectral and spatial transformers. We conduct experiments on three publicly available datasets for HSI classification task and demonstrate that our model achieves state-of-the-art performance in all three datasets. The code for our model will be made available at https://github.com/csiro-robotics/factoformer. ",
    "url": "https://arxiv.org/abs/2309.09431",
    "authors": [
      "Shaheer Mohamed",
      "Maryam Haghighat",
      "Tharindu Fernando",
      "Sridha Sridharan",
      "Clinton Fookes",
      "Peyman Moghadam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09435",
    "title": "Security and Privacy on Generative Data in AIGC: A Survey",
    "abstract": "The advent of artificial intelligence-generated content (AIGC) represents a pivotal moment in the evolution of information technology. With AIGC, it can be effortless to generate high-quality data that is challenging for the public to distinguish. Nevertheless, the proliferation of generative data across cyberspace brings security and privacy issues, including privacy leakages of individuals and media forgery for fraudulent purposes. Consequently, both academia and industry begin to emphasize the trustworthiness of generative data, successively providing a series of countermeasures for security and privacy. In this survey, we systematically review the security and privacy on generative data in AIGC, particularly for the first time analyzing them from the perspective of information security properties. Specifically, we reveal the successful experiences of state-of-the-art countermeasures in terms of the foundational properties of privacy, controllability, authenticity, and compliance, respectively. Finally, we summarize the open challenges and potential exploration directions from each of theses properties. ",
    "url": "https://arxiv.org/abs/2309.09435",
    "authors": [
      "Tao Wang",
      "Yushu Zhang",
      "Shuren Qi",
      "Ruoyu Zhao",
      "Zhihua Xia",
      "Jian Weng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.09436",
    "title": "An Iterative Method for Unsupervised Robust Anomaly Detection Under Data  Contamination",
    "abstract": "Most deep anomaly detection models are based on learning normality from datasets due to the difficulty of defining abnormality by its diverse and inconsistent nature. Therefore, it has been a common practice to learn normality under the assumption that anomalous data are absent in a training dataset, which we call normality assumption. However, in practice, the normality assumption is often violated due to the nature of real data distributions that includes anomalous tails, i.e., a contaminated dataset. Thereby, the gap between the assumption and actual training data affects detrimentally in learning of an anomaly detection model. In this work, we propose a learning framework to reduce this gap and achieve better normality representation. Our key idea is to identify sample-wise normality and utilize it as an importance weight, which is updated iteratively during the training. Our framework is designed to be model-agnostic and hyperparameter insensitive so that it applies to a wide range of existing methods without careful parameter tuning. We apply our framework to three different representative approaches of deep anomaly detection that are classified into one-class classification-, probabilistic model-, and reconstruction-based approaches. In addition, we address the importance of a termination condition for iterative methods and propose a termination criterion inspired by the anomaly detection objective. We validate that our framework improves the robustness of the anomaly detection models under different levels of contamination ratios on five anomaly detection benchmark datasets and two image datasets. On various contaminated datasets, our framework improves the performance of three representative anomaly detection methods, measured by area under the ROC curve. ",
    "url": "https://arxiv.org/abs/2309.09436",
    "authors": [
      "Minkyung Kim",
      "Jongmin Yu",
      "Junsik Kim",
      "Tae-Hyun Oh",
      "Jun Kyun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09440",
    "title": "Network Traffic Classification Based on External Attention by IP Packet  Header",
    "abstract": "As the emerging services have increasingly strict requirements on quality of service (QoS), such as millisecond network service latency ect., network traffic classification technology is required to assist more advanced network management and monitoring capabilities. So far as we know, the delays of flow-granularity classification methods are difficult to meet the real-time requirements for too long packet-waiting time, whereas the present packet-granularity classification methods may have problems related to privacy protection due to using excessive user payloads. To solve the above problems, we proposed a network traffic classification method only by the IP packet header, which satisfies the requirements of both user's privacy protection and classification performances. We opted to remove the IP address from the header information of the network layer and utilized the remaining 12-byte IP packet header information as input for the model. Additionally, we examined the variations in header value distributions among different categories of network traffic samples. And, the external attention is also introduced to form the online classification framework, which performs well for its low time complexity and strong ability to enhance high-dimensional classification features. The experiments on three open-source datasets show that our average accuracy can reach upon 94.57%, and the classification time is shortened to meet the real-time requirements (0.35ms for a single packet). ",
    "url": "https://arxiv.org/abs/2309.09440",
    "authors": [
      "Yahui Hu",
      "Ziqian Zeng",
      "Junping Song",
      "Luyang Xu",
      "Xu Zhou"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.09446",
    "title": "Scalable Label-efficient Footpath Network Generation Using Remote  Sensing Data and Self-supervised Learning",
    "abstract": "Footpath mapping, modeling, and analysis can provide important geospatial insights to many fields of study, including transport, health, environment and urban planning. The availability of robust Geographic Information System (GIS) layers can benefit the management of infrastructure inventories, especially at local government level with urban planners responsible for the deployment and maintenance of such infrastructure. However, many cities still lack real-time information on the location, connectivity, and width of footpaths, and/or employ costly and manual survey means to gather this information. This work designs and implements an automatic pipeline for generating footpath networks based on remote sensing images using machine learning models. The annotation of segmentation tasks, especially labeling remote sensing images with specialized requirements, is very expensive, so we aim to introduce a pipeline requiring less labeled data. Considering supervised methods require large amounts of training data, we use a self-supervised method for feature representation learning to reduce annotation requirements. Then the pre-trained model is used as the encoder of the U-Net for footpath segmentation. Based on the generated masks, the footpath polygons are extracted and converted to footpath networks which can be loaded and visualized by geographic information systems conveniently. Validation results indicate considerable consistency when compared to manually collected GIS layers. The footpath network generation pipeline proposed in this work is low-cost and extensible, and it can be applied where remote sensing images are available. Github: https://github.com/WennyXY/FootpathSeg. ",
    "url": "https://arxiv.org/abs/2309.09446",
    "authors": [
      "Xinye Wanyan",
      "Sachith Seneviratne",
      "Kerry Nice",
      "Jason Thompson",
      "Marcus White",
      "Nano Langenheim",
      "Mark Stevenson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09455",
    "title": "CaT: Balanced Continual Graph Learning with Graph Condensation",
    "abstract": "Continual graph learning (CGL) is purposed to continuously update a graph model with graph data being fed in a streaming manner. Since the model easily forgets previously learned knowledge when training with new-coming data, the catastrophic forgetting problem has been the major focus in CGL. Recent replay-based methods intend to solve this problem by updating the model using both (1) the entire new-coming data and (2) a sampling-based memory bank that stores replayed graphs to approximate the distribution of historical data. After updating the model, a new replayed graph sampled from the incoming graph will be added to the existing memory bank. Despite these methods are intuitive and effective for the CGL, two issues are identified in this paper. Firstly, most sampling-based methods struggle to fully capture the historical distribution when the storage budget is tight. Secondly, a significant data imbalance exists in terms of the scales of the complex new-coming graph data and the lightweight memory bank, resulting in unbalanced training. To solve these issues, a \\textit{Condense and Train (CaT)} framework is proposed in this paper. Prior to each model update, the new-coming graph is condensed to a small yet informative synthesised replayed graph, which is then stored in a \\textit{Condensed Graph Memory} with historical replay graphs. In the continual learning phase, a \\textit{Training in Memory} scheme is used to update the model directly with the \\textit{Condensed Graph Memory} rather than the whole new-coming graph, which alleviates the data imbalance problem. Extensive experiments conducted on four benchmark datasets successfully demonstrate superior performances of the proposed CaT framework in terms of effectiveness and efficiency. The code has been released on \\url{https://github.com/superallen13/CaT-CGL}. ",
    "url": "https://arxiv.org/abs/2309.09455",
    "authors": [
      "Yilun Liu",
      "Ruihong Qiu",
      "Zi Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09456",
    "title": "Object2Scene: Putting Objects in Context for Open-Vocabulary 3D  Detection",
    "abstract": "Point cloud-based open-vocabulary 3D object detection aims to detect 3D categories that do not have ground-truth annotations in the training set. It is extremely challenging because of the limited data and annotations (bounding boxes with class labels or text descriptions) of 3D scenes. Previous approaches leverage large-scale richly-annotated image datasets as a bridge between 3D and category semantics but require an extra alignment process between 2D images and 3D points, limiting the open-vocabulary ability of 3D detectors. Instead of leveraging 2D images, we propose Object2Scene, the first approach that leverages large-scale large-vocabulary 3D object datasets to augment existing 3D scene datasets for open-vocabulary 3D object detection. Object2Scene inserts objects from different sources into 3D scenes to enrich the vocabulary of 3D scene datasets and generates text descriptions for the newly inserted objects. We further introduce a framework that unifies 3D detection and visual grounding, named L3Det, and propose a cross-domain category-level contrastive learning approach to mitigate the domain gap between 3D objects from different datasets. Extensive experiments on existing open-vocabulary 3D object detection benchmarks show that Object2Scene obtains superior performance over existing methods. We further verify the effectiveness of Object2Scene on a new benchmark OV-ScanNet-200, by holding out all rare categories as novel categories not seen during training. ",
    "url": "https://arxiv.org/abs/2309.09456",
    "authors": [
      "Chenming Zhu",
      "Wenwei Zhang",
      "Tai Wang",
      "Xihui Liu",
      "Kai Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09464",
    "title": "Reducing Adversarial Training Cost with Gradient Approximation",
    "abstract": "Deep learning models have achieved state-of-the-art performances in various domains, while they are vulnerable to the inputs with well-crafted but small perturbations, which are named after adversarial examples (AEs). Among many strategies to improve the model robustness against AEs, Projected Gradient Descent (PGD) based adversarial training is one of the most effective methods. Unfortunately, the prohibitive computational overhead of generating strong enough AEs, due to the maximization of the loss function, sometimes makes the regular PGD adversarial training impractical when using larger and more complicated models. In this paper, we propose that the adversarial loss can be approximated by the partial sum of Taylor series. Furthermore, we approximate the gradient of adversarial loss and propose a new and efficient adversarial training method, adversarial training with gradient approximation (GAAT), to reduce the cost of building up robust models. Additionally, extensive experiments demonstrate that this efficiency improvement can be achieved without any or with very little loss in accuracy on natural and adversarial examples, which show that our proposed method saves up to 60\\% of the training time with comparable model test accuracy on MNIST, CIFAR-10 and CIFAR-100 datasets. ",
    "url": "https://arxiv.org/abs/2309.09464",
    "authors": [
      "Huihui Gong",
      "Shuo Yang",
      "Siqi Ma",
      "Seyit Camtepe",
      "Surya Nepal",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09465",
    "title": "Active anomaly detection based on deep one-class classification",
    "abstract": "Active learning has been utilized as an efficient tool in building anomaly detection models by leveraging expert feedback. In an active learning framework, a model queries samples to be labeled by experts and re-trains the model with the labeled data samples. It unburdens in obtaining annotated datasets while improving anomaly detection performance. However, most of the existing studies focus on helping experts identify as many abnormal data samples as possible, which is a sub-optimal approach for one-class classification-based deep anomaly detection. In this paper, we tackle two essential problems of active learning for Deep SVDD: query strategy and semi-supervised learning method. First, rather than solely identifying anomalies, our query strategy selects uncertain samples according to an adaptive boundary. Second, we apply noise contrastive estimation in training a one-class classification model to incorporate both labeled normal and abnormal data effectively. We analyze that the proposed query strategy and semi-supervised loss individually improve an active learning process of anomaly detection and further improve when combined together on seven anomaly detection datasets. ",
    "url": "https://arxiv.org/abs/2309.09465",
    "authors": [
      "Minkyung Kim",
      "Junsik Kim",
      "Jongmin Yu",
      "Jun Kyun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09469",
    "title": "Spiking-LEAF: A Learnable Auditory front-end for Spiking Neural Networks",
    "abstract": "Brain-inspired spiking neural networks (SNNs) have demonstrated great potential for temporal signal processing. However, their performance in speech processing remains limited due to the lack of an effective auditory front-end. To address this limitation, we introduce Spiking-LEAF, a learnable auditory front-end meticulously designed for SNN-based speech processing. Spiking-LEAF combines a learnable filter bank with a novel two-compartment spiking neuron model called IHC-LIF. The IHC-LIF neurons draw inspiration from the structure of inner hair cells (IHC) and they leverage segregated dendritic and somatic compartments to effectively capture multi-scale temporal dynamics of speech signals. Additionally, the IHC-LIF neurons incorporate the lateral feedback mechanism along with spike regularization loss to enhance spike encoding efficiency. On keyword spotting and speaker identification tasks, the proposed Spiking-LEAF outperforms both SOTA spiking auditory front-ends and conventional real-valued acoustic features in terms of classification accuracy, noise robustness, and encoding efficiency. ",
    "url": "https://arxiv.org/abs/2309.09469",
    "authors": [
      "Zeyang Song",
      "Jibin Wu",
      "Malu Zhang",
      "Mike Zheng Shou",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.09473",
    "title": "Self-supervised Multi-view Clustering in Computer Vision: A Survey",
    "abstract": "Multi-view clustering (MVC) has had significant implications in cross-modal representation learning and data-driven decision-making in recent years. It accomplishes this by leveraging the consistency and complementary information among multiple views to cluster samples into distinct groups. However, as contrastive learning continues to evolve within the field of computer vision, self-supervised learning has also made substantial research progress and is progressively becoming dominant in MVC methods. It guides the clustering process by designing proxy tasks to mine the representation of image and video data itself as supervisory information. Despite the rapid development of self-supervised MVC, there has yet to be a comprehensive survey to analyze and summarize the current state of research progress. Therefore, this paper explores the reasons and advantages of the emergence of self-supervised MVC and discusses the internal connections and classifications of common datasets, data issues, representation learning methods, and self-supervised learning methods. This paper does not only introduce the mechanisms for each category of methods but also gives a few examples of how these techniques are used. In the end, some open problems are pointed out for further investigation and development. ",
    "url": "https://arxiv.org/abs/2309.09473",
    "authors": [
      "Jiatai Wang",
      "Zhiwei Xu",
      "Xuewen Yang",
      "Hailong Li",
      "Bo Li",
      "Xuying Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09480",
    "title": "Stealthy Physical Masked Face Recognition Attack via Adversarial Style  Optimization",
    "abstract": "Deep neural networks (DNNs) have achieved state-of-the-art performance on face recognition (FR) tasks in the last decade. In real scenarios, the deployment of DNNs requires taking various face accessories into consideration, like glasses, hats, and masks. In the COVID-19 pandemic era, wearing face masks is one of the most effective ways to defend against the novel coronavirus. However, DNNs are known to be vulnerable to adversarial examples with a small but elaborated perturbation. Thus, a facial mask with adversarial perturbations may pose a great threat to the widely used deep learning-based FR models. In this paper, we consider a challenging adversarial setting: targeted attack against FR models. We propose a new stealthy physical masked FR attack via adversarial style optimization. Specifically, we train an adversarial style mask generator that hides adversarial perturbations inside style masks. Moreover, to ameliorate the phenomenon of sub-optimization with one fixed style, we propose to discover the optimal style given a target through style optimization in a continuous relaxation manner. We simultaneously optimize the generator and the style selection for generating strong and stealthy adversarial style masks. We evaluated the effectiveness and transferability of our proposed method via extensive white-box and black-box digital experiments. Furthermore, we also conducted physical attack experiments against local FR models and online platforms. ",
    "url": "https://arxiv.org/abs/2309.09480",
    "authors": [
      "Huihui Gong",
      "Minjing Dong",
      "Siqi Ma",
      "Seyit Camtepe",
      "Surya Nepal",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09482",
    "title": "Spatio-temporal Co-attention Fusion Network for Video Splicing  Localization",
    "abstract": "Digital video splicing has become easy and ubiquitous. Malicious users copy some regions of a video and paste them to another video for creating realistic forgeries. It is significant to blindly detect such forgery regions in videos. In this paper, a spatio-temporal co-attention fusion network (SCFNet) is proposed for video splicing localization. Specifically, a three-stream network is used as an encoder to capture manipulation traces across multiple frames. The deep interaction and fusion of spatio-temporal forensic features are achieved by the novel parallel and cross co-attention fusion modules. A lightweight multilayer perceptron (MLP) decoder is adopted to yield a pixel-level tampering localization map. A new large-scale video splicing dataset is created for training the SCFNet. Extensive tests on benchmark datasets show that the localization and generalization performances of our SCFNet outperform the state-of-the-art. Code and datasets will be available at https://github.com/multimediaFor/SCFNet. ",
    "url": "https://arxiv.org/abs/2309.09482",
    "authors": [
      "Man Lin",
      "Gang Cao",
      "Zijie Lou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.09500",
    "title": "PromptST: Prompt-Enhanced Spatio-Temporal Multi-Attribute Prediction",
    "abstract": "In the era of information explosion, spatio-temporal data mining serves as a critical part of urban management. Considering the various fields demanding attention, e.g., traffic state, human activity, and social event, predicting multiple spatio-temporal attributes simultaneously can alleviate regulatory pressure and foster smart city construction. However, current research can not handle the spatio-temporal multi-attribute prediction well due to the complex relationships between diverse attributes. The key challenge lies in how to address the common spatio-temporal patterns while tackling their distinctions. In this paper, we propose an effective solution for spatio-temporal multi-attribute prediction, PromptST. We devise a spatio-temporal transformer and a parameter-sharing training scheme to address the common knowledge among different spatio-temporal attributes. Then, we elaborate a spatio-temporal prompt tuning strategy to fit the specific attributes in a lightweight manner. Through the pretrain and prompt tuning phases, our PromptST is able to enhance the specific spatio-temoral characteristic capture by prompting the backbone model to fit the specific target attribute while maintaining the learned common knowledge. Extensive experiments on real-world datasets verify that our PromptST attains state-of-the-art performance. Furthermore, we also prove PromptST owns good transferability on unseen spatio-temporal attributes, which brings promising application potential in urban computing. The implementation code is available to ease reproducibility. ",
    "url": "https://arxiv.org/abs/2309.09500",
    "authors": [
      "Zijian Zhang",
      "Xiangyu Zhao",
      "Qidong Liu",
      "Chunxu Zhang",
      "Qian Ma",
      "Wanyu Wang",
      "Hongwei Zhao",
      "Yiqi Wang",
      "Zitao Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09502",
    "title": "RenderOcc: Vision-Centric 3D Occupancy Prediction with 2D Rendering  Supervision",
    "abstract": "3D occupancy prediction holds significant promise in the fields of robot perception and autonomous driving, which quantifies 3D scenes into grid cells with semantic labels. Recent works mainly utilize complete occupancy labels in 3D voxel space for supervision. However, the expensive annotation process and sometimes ambiguous labels have severely constrained the usability and scalability of 3D occupancy models. To address this, we present RenderOcc, a novel paradigm for training 3D occupancy models only using 2D labels. Specifically, we extract a NeRF-style 3D volume representation from multi-view images, and employ volume rendering techniques to establish 2D renderings, thus enabling direct 3D supervision from 2D semantics and depth labels. Additionally, we introduce an Auxiliary Ray method to tackle the issue of sparse viewpoints in autonomous driving scenarios, which leverages sequential frames to construct comprehensive 2D rendering for each object. To our best knowledge, RenderOcc is the first attempt to train multi-view 3D occupancy models only using 2D labels, reducing the dependence on costly 3D occupancy annotations. Extensive experiments demonstrate that RenderOcc achieves comparable performance to models fully supervised with 3D labels, underscoring the significance of this approach in real-world applications. ",
    "url": "https://arxiv.org/abs/2309.09502",
    "authors": [
      "Mingjie Pan",
      "Jiaming Liu",
      "Renrui Zhang",
      "Peixiang Huang",
      "Xiaoqi Li",
      "Li Liu",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09508",
    "title": "Understanding Divergent Framing of the Supreme Court Controversies:  Social Media vs. News Outlets",
    "abstract": "Understanding the framing of political issues is of paramount importance as it significantly shapes how individuals perceive, interpret, and engage with these matters. While prior research has independently explored framing within news media and by social media users, there remains a notable gap in our comprehension of the disparities in framing political issues between these two distinct groups. To address this gap, we conduct a comprehensive investigation, focusing on the nuanced distinctions both qualitatively and quantitatively in the framing of social media and traditional media outlets concerning a series of American Supreme Court rulings on affirmative action, student loans, and abortion rights. Our findings reveal that, while some overlap in framing exists between social media and traditional media outlets, substantial differences emerge both across various topics and within specific framing categories. Compared to traditional news media, social media platforms tend to present more polarized stances across all framing categories. Further, we observe significant polarization in the news media's treatment (i.e., Left vs. Right leaning media) of affirmative action and abortion rights, whereas the topic of student loans tends to exhibit a greater degree of consensus. The disparities in framing between traditional and social media platforms carry significant implications for the formation of public opinion, policy decision-making, and the broader political landscape. ",
    "url": "https://arxiv.org/abs/2309.09508",
    "authors": [
      "Jinsheng Pan",
      "Zichen Wang",
      "Weihong Qi",
      "Hanjia Lyu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.09515",
    "title": "Sparse and Privacy-enhanced Representation for Human Pose Estimation",
    "abstract": "We propose a sparse and privacy-enhanced representation for Human Pose Estimation (HPE). Given a perspective camera, we use a proprietary motion vector sensor(MVS) to extract an edge image and a two-directional motion vector image at each time frame. Both edge and motion vector images are sparse and contain much less information (i.e., enhancing human privacy). We advocate that edge information is essential for HPE, and motion vectors complement edge information during fast movements. We propose a fusion network leveraging recent advances in sparse convolution used typically for 3D voxels to efficiently process our proposed sparse representation, which achieves about 13x speed-up and 96% reduction in FLOPs. We collect an in-house edge and motion vector dataset with 16 types of actions by 40 users using the proprietary MVS. Our method outperforms individual modalities using only edge or motion vector images. Finally, we validate the privacy-enhanced quality of our sparse representation through face recognition on CelebA (a large face dataset) and a user study on our in-house dataset. ",
    "url": "https://arxiv.org/abs/2309.09515",
    "authors": [
      "Ting-Ying Lin",
      "Lin-Yung Hsieh",
      "Fu-En Wang",
      "Wen-Shen Wuen",
      "Min Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09517",
    "title": "FedGKD: Unleashing the Power of Collaboration in Federated Graph Neural  Networks",
    "abstract": "Federated training of Graph Neural Networks (GNN) has become popular in recent years due to its ability to perform graph-related tasks under data isolation scenarios while preserving data privacy. However, graph heterogeneity issues in federated GNN systems continue to pose challenges. Existing frameworks address the problem by representing local tasks using different statistics and relating them through a simple aggregation mechanism. However, these approaches suffer from limited efficiency from two aspects: low quality of task-relatedness quantification and inefficacy of exploiting the collaboration structure. To address these issues, we propose FedGKD, a novel federated GNN framework that utilizes a novel client-side graph dataset distillation method to extract task features that better describe task-relatedness, and introduces a novel server-side aggregation mechanism that is aware of the global collaboration structure. We conduct extensive experiments on six real-world datasets of different scales, demonstrating our framework's outperformance. ",
    "url": "https://arxiv.org/abs/2309.09517",
    "authors": [
      "Qiying Pan",
      "Ruofan Wu",
      "Tengfei Liu",
      "Tianyi Zhang",
      "Yifei Zhu",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.09522",
    "title": "TOPr: Enhanced Static Code Pruning for Fast and Precise Directed Fuzzing",
    "abstract": "Directed fuzzing is a dynamic testing technique that focuses exploration on specific, pre targeted program locations. Like other types of fuzzers, directed fuzzers are most effective when maximizing testing speed and precision. To this end, recent directed fuzzers have begun leveraging path pruning: preventing the wasteful testing of program paths deemed irrelevant to reaching a desired target location. Yet, despite code pruning's substantial speedup, current approaches are imprecise failing to capture indirect control flow requiring additional dynamic analyses that diminish directed fuzzers' speeds. Thus, without code pruning that is both fast and precise, directed fuzzers' effectiveness will continue to remain limited. This paper aims to tackle the challenge of upholding both speed and precision in pruning-based directed fuzzing. We show that existing pruning approaches fail to recover common case indirect control flow; and identify opportunities to enhance them with lightweight heuristics namely, function signature matching enabling them to maximize precision without the burden of dynamic analysis. We implement our enhanced pruning as a prototype, TOPr (Target Oriented Pruning), and evaluate it against the leading pruning based and pruning agnostic directed fuzzers SieveFuzz and AFLGo. We show that TOPr's enhanced pruning outperforms these fuzzers in (1) speed (achieving 222% and 73% higher test case throughput, respectively); (2) reachability (achieving 149% and 9% more target relevant coverage, respectively); and (3) bug discovery time (triggering bugs faster 85% and 8%, respectively). Furthermore, TOPr's balance of speed and precision enables it to find 24 new bugs in 5 open source applications, with 18 confirmed by developers, 12 bugs labelled as \"Priority - 1. High\", and 12 bugs fixed, underscoring the effectiveness of our framework. ",
    "url": "https://arxiv.org/abs/2309.09522",
    "authors": [
      "Chaitra Niddodi",
      "Stefan Nagy",
      "Darko Marinov",
      "Sibin Mohan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.09524",
    "title": "Improved Factorized Neural Transducer Model For text-only Domain  Adaptation",
    "abstract": "End-to-end models, such as the neural Transducer, have been successful in integrating acoustic and linguistic information jointly to achieve excellent recognition performance. However, adapting these models with text-only data is challenging. Factorized neural Transducer (FNT) aims to address this issue by introducing a separate vocabulary decoder to predict the vocabulary, which can effectively perform traditional text data adaptation. Nonetheless, this approach has limitations in fusing acoustic and language information seamlessly. Moreover, a degradation in word error rate (WER) on the general test sets was also observed, leading to doubts about its overall performance. In response to this challenge, we present an improved factorized neural Transducer (IFNT) model structure designed to comprehensively integrate acoustic and language information while enabling effective text adaptation. We evaluate the performance of our proposed methods through in-domain experiments on GigaSpeech and out-of-domain experiments adapting to EuroParl, TED-LIUM, and Medical datasets. After text-only adaptation, IFNT yields 7.9% to 28.5% relative WER improvements over the standard neural Transducer with shallow fusion, and relative WER reductions ranging from 1.6% to 8.2% on the three test sets compared to the FNT model. ",
    "url": "https://arxiv.org/abs/2309.09524",
    "authors": [
      "Junzhe Liu",
      "Jianwei Yu",
      "Xie Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09537",
    "title": "A performance characteristic curve for model evaluation: the application  in information diffusion prediction",
    "abstract": "The information diffusion prediction on social networks aims to predict future recipients of a message, with practical applications in marketing and social media. While different prediction models all claim to perform well, general frameworks for performance evaluation remain limited. Here, we aim to identify a performance characteristic curve for a model, which captures its performance on tasks of different complexity. We propose a metric based on information entropy to quantify the randomness in diffusion data, then identify a scaling pattern between the randomness and the prediction accuracy of the model. Data points in the patterns by different sequence lengths, system sizes, and randomness all collapse into a single curve, capturing a model's inherent capability of making correct predictions against increased uncertainty. Given that this curve has such important properties that it can be used to evaluate the model, we define it as the performance characteristic curve of the model. The validity of the curve is tested by three prediction models in the same family, reaching conclusions in line with existing studies. Also, the curve is successfully applied to evaluate two distinct models from the literature. Our work reveals a pattern underlying the data randomness and prediction accuracy. The performance characteristic curve provides a new way to systematically evaluate models' performance, and sheds light on future studies on other frameworks for model evaluation. ",
    "url": "https://arxiv.org/abs/2309.09537",
    "authors": [
      "Wenjin Xie",
      "Xiaomeng Wang",
      "Rados\u0142aw Michalsk",
      "Tao Jia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09550",
    "title": "Adaptive Reorganization of Neural Pathways for Continual Learning with  Hybrid Spiking Neural Networks",
    "abstract": "The human brain can self-organize rich and diverse sparse neural pathways to incrementally master hundreds of cognitive tasks. However, most existing continual learning algorithms for deep artificial and spiking neural networks are unable to adequately auto-regulate the limited resources in the network, which leads to performance drop along with energy consumption rise as the increase of tasks. In this paper, we propose a brain-inspired continual learning algorithm with adaptive reorganization of neural pathways, which employs Self-Organizing Regulation networks to reorganize the single and limited Spiking Neural Network (SOR-SNN) into rich sparse neural pathways to efficiently cope with incremental tasks. The proposed model demonstrates consistent superiority in performance, energy consumption, and memory capacity on diverse continual learning tasks ranging from child-like simple to complex tasks, as well as on generalized CIFAR100 and ImageNet datasets. In particular, the SOR-SNN model excels at learning more complex tasks as well as more tasks, and is able to integrate the past learned knowledge with the information from the current task, showing the backward transfer ability to facilitate the old tasks. Meanwhile, the proposed model exhibits self-repairing ability to irreversible damage and for pruned networks, could automatically allocate new pathway from the retained network to recover memory for forgotten knowledge. ",
    "url": "https://arxiv.org/abs/2309.09550",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Wenxuan Pan",
      "Zhaoya Zhao",
      "Xianqi Li",
      "Qingqun Kong",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09553",
    "title": "Causal-Story: Local Causal Attention Utilizing Parameter-Efficient  Tuning For Visual Story Synthesis",
    "abstract": "The excellent text-to-image synthesis capability of diffusion models has driven progress in synthesizing coherent visual stories. The current state-of-the-art method combines the features of historical captions, historical frames, and the current captions as conditions for generating the current frame. However, this method treats each historical frame and caption as the same contribution. It connects them in order with equal weights, ignoring that not all historical conditions are associated with the generation of the current frame. To address this issue, we propose Causal-Story. This model incorporates a local causal attention mechanism that considers the causal relationship between previous captions, frames, and current captions. By assigning weights based on this relationship, Causal-Story generates the current frame, thereby improving the global consistency of story generation. We evaluated our model on the PororoSV and FlintstonesSV datasets and obtained state-of-the-art FID scores, and the generated frames also demonstrate better storytelling in visuals. The source code of Causal-Story can be obtained from https://github.com/styufo/Causal-Story. ",
    "url": "https://arxiv.org/abs/2309.09553",
    "authors": [
      "Tianyi Song",
      "Jiuxin Cao",
      "Kun Wang",
      "Bo Liu",
      "Xiaofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.09563",
    "title": "RIDE: Self-Supervised Learning of Rotation-Equivariant Keypoint  Detection and Invariant Description for Endoscopy",
    "abstract": "Unlike in natural images, in endoscopy there is no clear notion of an up-right camera orientation. Endoscopic videos therefore often contain large rotational motions, which require keypoint detection and description algorithms to be robust to these conditions. While most classical methods achieve rotation-equivariant detection and invariant description by design, many learning-based approaches learn to be robust only up to a certain degree. At the same time learning-based methods under moderate rotations often outperform classical approaches. In order to address this shortcoming, in this paper we propose RIDE, a learning-based method for rotation-equivariant detection and invariant description. Following recent advancements in group-equivariant learning, RIDE models rotation-equivariance implicitly within its architecture. Trained in a self-supervised manner on a large curation of endoscopic images, RIDE requires no manual labeling of training data. We test RIDE in the context of surgical tissue tracking on the SuPeR dataset as well as in the context of relative pose estimation on a repurposed version of the SCARED dataset. In addition we perform explicit studies showing its robustness to large rotations. Our comparison against recent learning-based and classical approaches shows that RIDE sets a new state-of-the-art performance on matching and relative pose estimation tasks and scores competitively on surgical tissue tracking. ",
    "url": "https://arxiv.org/abs/2309.09563",
    "authors": [
      "Mert Asim Karaoglu",
      "Viktoria Markova",
      "Nassir Navab",
      "Benjamin Busam",
      "Alexander Ladikos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09571",
    "title": "Heterogeneous Generative Knowledge Distillation with Masked Image  Modeling",
    "abstract": "Small CNN-based models usually require transferring knowledge from a large model before they are deployed in computationally resource-limited edge devices. Masked image modeling (MIM) methods achieve great success in various visual tasks but remain largely unexplored in knowledge distillation for heterogeneous deep models. The reason is mainly due to the significant discrepancy between the Transformer-based large model and the CNN-based small network. In this paper, we develop the first Heterogeneous Generative Knowledge Distillation (H-GKD) based on MIM, which can efficiently transfer knowledge from large Transformer models to small CNN-based models in a generative self-supervised fashion. Our method builds a bridge between Transformer-based models and CNNs by training a UNet-style student with sparse convolution, which can effectively mimic the visual representation inferred by a teacher over masked modeling. Our method is a simple yet effective learning paradigm to learn the visual representation and distribution of data from heterogeneous teacher models, which can be pre-trained using advanced generative methods. Extensive experiments show that it adapts well to various models and sizes, consistently achieving state-of-the-art performance in image classification, object detection, and semantic segmentation tasks. For example, in the Imagenet 1K dataset, H-GKD improves the accuracy of Resnet50 (sparse) from 76.98% to 80.01%. ",
    "url": "https://arxiv.org/abs/2309.09571",
    "authors": [
      "Ziming Wang",
      "Shumin Han",
      "Xiaodi Wang",
      "Jing Hao",
      "Xianbin Cao",
      "Baochang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09574",
    "title": "Latent assimilation with implicit neural representations for unknown  dynamics",
    "abstract": "Data assimilation is crucial in a wide range of applications, but it often faces challenges such as high computational costs due to data dimensionality and incomplete understanding of underlying mechanisms. To address these challenges, this study presents a novel assimilation framework, termed Latent Assimilation with Implicit Neural Representations (LAINR). By introducing Spherical Implicit Neural Representations (SINR) along with a data-driven uncertainty estimator of the trained neural networks, LAINR enhances efficiency in assimilation process. Experimental results indicate that LAINR holds certain advantage over existing methods based on AutoEncoders, both in terms of accuracy and efficiency. ",
    "url": "https://arxiv.org/abs/2309.09574",
    "authors": [
      "Zhuoyuan Li",
      "Bin Dong",
      "Pingwen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Optimization and Control (math.OC)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2309.09586",
    "title": "Spoofing attack augmentation: can differently-trained attack models  improve generalisation?",
    "abstract": "A reliable deepfake detector or spoofing countermeasure (CM) should be robust in the face of unpredictable spoofing attacks. To encourage the learning of more generaliseable artefacts, rather than those specific only to known attacks, CMs are usually exposed to a broad variety of different attacks during training. Even so, the performance of deep-learning-based CM solutions are known to vary, sometimes substantially, when they are retrained with different initialisations, hyper-parameters or training data partitions. We show in this paper that the potency of spoofing attacks, also deep-learning-based, can similarly vary according to training conditions, sometimes resulting in substantial degradations to detection performance. Nevertheless, while a RawNet2 CM model is vulnerable when only modest adjustments are made to the attack algorithm, those based upon graph attention networks and self-supervised learning are reassuringly robust. The focus upon training data generated with different attack algorithms might not be sufficient on its own to ensure generaliability; some form of spoofing attack augmentation at the algorithm level can be complementary. ",
    "url": "https://arxiv.org/abs/2309.09586",
    "authors": [
      "Wanying Ge",
      "Xin Wang",
      "Junichi Yamagishi",
      "Massimiliano Todisco",
      "Nicholas Evans"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.09593",
    "title": "Mutual Information-calibrated Conformal Feature Fusion for  Uncertainty-Aware Multimodal 3D Object Detection at the Edge",
    "abstract": "In the expanding landscape of AI-enabled robotics, robust quantification of predictive uncertainties is of great importance. Three-dimensional (3D) object detection, a critical robotics operation, has seen significant advancements; however, the majority of current works focus only on accuracy and ignore uncertainty quantification. Addressing this gap, our novel study integrates the principles of conformal inference (CI) with information theoretic measures to perform lightweight, Monte Carlo-free uncertainty estimation within a multimodal framework. Through a multivariate Gaussian product of the latent variables in a Variational Autoencoder (VAE), features from RGB camera and LiDAR sensor data are fused to improve the prediction accuracy. Normalized mutual information (NMI) is leveraged as a modulator for calibrating uncertainty bounds derived from CI based on a weighted loss function. Our simulation results show an inverse correlation between inherent predictive uncertainty and NMI throughout the model's training. The framework demonstrates comparable or better performance in KITTI 3D object detection benchmarks to similar methods that are not uncertainty-aware, making it suitable for real-time edge robotics. ",
    "url": "https://arxiv.org/abs/2309.09593",
    "authors": [
      "Alex C. Stutts",
      "Danilo Erricolo",
      "Sathya Ravi",
      "Theja Tulabandhula",
      "Amit Ranjan Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09618",
    "title": "A Discussion on Generalization in Next-Activity Prediction",
    "abstract": "Next activity prediction aims to forecast the future behavior of running process instances. Recent publications in this field predominantly employ deep learning techniques and evaluate their prediction performance using publicly available event logs. This paper presents empirical evidence that calls into question the effectiveness of these current evaluation approaches. We show that there is an enormous amount of example leakage in all of the commonly used event logs, so that rather trivial prediction approaches perform almost as well as ones that leverage deep learning. We further argue that designing robust evaluations requires a more profound conceptual engagement with the topic of next-activity prediction, and specifically with the notion of generalization to new data. To this end, we present various prediction scenarios that necessitate different types of generalization to guide future research. ",
    "url": "https://arxiv.org/abs/2309.09618",
    "authors": [
      "Luka Abb",
      "Peter Pfeiffer",
      "Peter Fettke",
      "Jana-Rebecca Rehse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2309.09627",
    "title": "Electrolaryngeal Speech Intelligibility Enhancement Through Robust  Linguistic Encoders",
    "abstract": "We propose a novel framework for electrolaryngeal speech intelligibility enhancement through the use of robust linguistic encoders. Pretraining and fine-tuning approaches have proven to work well in this task, but in most cases, various mismatches, such as the speech type mismatch (electrolaryngeal vs. typical) or a speaker mismatch between the datasets used in each stage, can deteriorate the conversion performance of this framework. To resolve this issue, we propose a linguistic encoder robust enough to project both EL and typical speech in the same latent space, while still being able to extract accurate linguistic information, creating a unified representation to reduce the speech type mismatch. Furthermore, we introduce HuBERT output features to the proposed framework for reducing the speaker mismatch, making it possible to effectively use a large-scale parallel dataset during pretraining. We show that compared to the conventional framework using mel-spectrogram input and output features, using the proposed framework enables the model to synthesize more intelligible and naturally sounding speech, as shown by a significant 16% improvement in character error rate and 0.83 improvement in naturalness score. ",
    "url": "https://arxiv.org/abs/2309.09627",
    "authors": [
      "Lester Phillip Violeta",
      "Wen-Chin Huang",
      "Ding Ma",
      "Ryuichi Yamamoto",
      "Kazuhiro Kobayashi",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.09637",
    "title": "Designing a Hybrid Neural System to Learn Real-world Crack Segmentation  from Fractal-based Simulation",
    "abstract": "Identification of cracks is essential to assess the structural integrity of concrete infrastructure. However, robust crack segmentation remains a challenging task for computer vision systems due to the diverse appearance of concrete surfaces, variable lighting and weather conditions, and the overlapping of different defects. In particular recent data-driven methods struggle with the limited availability of data, the fine-grained and time-consuming nature of crack annotation, and face subsequent difficulty in generalizing to out-of-distribution samples. In this work, we move past these challenges in a two-fold way. We introduce a high-fidelity crack graphics simulator based on fractals and a corresponding fully-annotated crack dataset. We then complement the latter with a system that learns generalizable representations from simulation, by leveraging both a pointwise mutual information estimate along with adaptive instance normalization as inductive biases. Finally, we empirically highlight how different design choices are symbiotic in bridging the simulation to real gap, and ultimately demonstrate that our introduced system can effectively handle real-world crack segmentation. ",
    "url": "https://arxiv.org/abs/2309.09637",
    "authors": [
      "Achref Jaziri",
      "Martin Mundt",
      "Andres Fernandez Rodriguez",
      "Visvanathan Ramesh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09638",
    "title": "Neural Network-Based Rule Models With Truth Tables",
    "abstract": "Understanding the decision-making process of a machine/deep learning model is crucial, particularly in security-sensitive applications. In this study, we introduce a neural network framework that combines the global and exact interpretability properties of rule-based models with the high performance of deep neural networks. Our proposed framework, called $\\textit{Truth Table rules}$ (TT-rules), is built upon $\\textit{Truth Table nets}$ (TTnets), a family of deep neural networks initially developed for formal verification. By extracting the set of necessary and sufficient rules $\\mathcal{R}$ from the trained TTnet model (global interpretability), yielding the same output as the TTnet (exact interpretability), TT-rules effectively transforms the neural network into a rule-based model. This rule-based model supports binary classification, multi-label classification, and regression tasks for tabular datasets. Furthermore, our TT-rules framework optimizes the rule set $\\mathcal{R}$ into $\\mathcal{R}_{opt}$ by reducing the number and size of the rules. To enhance model interpretation, we leverage Reduced Ordered Binary Decision Diagrams (ROBDDs) to visualize these rules effectively. After outlining the framework, we evaluate the performance of TT-rules on seven tabular datasets from finance, healthcare, and justice domains. We also compare the TT-rules framework to state-of-the-art rule-based methods. Our results demonstrate that TT-rules achieves equal or higher performance compared to other interpretable methods while maintaining a balance between performance and complexity. Notably, TT-rules presents the first accurate rule-based model capable of fitting large tabular datasets, including two real-life DNA datasets with over 20K features. Finally, we extensively investigate a rule-based model derived from TT-rules using the Adult dataset. ",
    "url": "https://arxiv.org/abs/2309.09638",
    "authors": [
      "Adrien Benamira",
      "Tristan Gu\u00e9rand",
      "Thomas Peyrin",
      "Hans Soegeng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2309.09648",
    "title": "Simulation of Sensor Spoofing Attacks on Unmanned Aerial Vehicles Using  the Gazebo Simulator",
    "abstract": "Conducting safety simulations in various simulators, such as the Gazebo simulator, became a very popular means of testing vehicles against potential safety risks (i.e. crashes). However, this was not the case with security testing. Performing security testing in a simulator is very difficult because security attacks are performed on a different abstraction level. In addition, the attacks themselves are becoming more sophisticated, which directly contributes to the difficulty of executing them in a simulator. In this paper, we attempt to tackle the aforementioned gap by investigating possible attacks that can be simulated, and then performing their simulations. The presented approach shows that attacks targeting the LiDAR and GPS components of unmanned aerial vehicles can be simulated. This is achieved by exploiting vulnerabilities of the ROS and MAVLink protocol and injecting malicious processes into an application. As a result, messages with arbitrary values can be spoofed to the corresponding topics, which allows attackers to update relevant parameters and cause a potential crash of a vehicle. This was tested in multiple scenarios, thereby proving that it is indeed possible to simulate certain attack types, such as spoofing and jamming. ",
    "url": "https://arxiv.org/abs/2309.09648",
    "authors": [
      "Irdin Pekaric",
      "David Arnold",
      "Michael Felderer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.09668",
    "title": "DFormer: Rethinking RGBD Representation Learning for Semantic  Segmentation",
    "abstract": "We present DFormer, a novel RGB-D pretraining framework to learn transferable representations for RGB-D segmentation tasks. DFormer has two new key innovations: 1) Unlike previous works that aim to encode RGB features,DFormer comprises a sequence of RGB-D blocks, which are tailored for encoding both RGB and depth information through a novel building block design; 2) We pre-train the backbone using image-depth pairs from ImageNet-1K, and thus the DFormer is endowed with the capacity to encode RGB-D representations. It avoids the mismatched encoding of the 3D geometry relationships in depth maps by RGB pre-trained backbones, which widely lies in existing methods but has not been resolved. We fine-tune the pre-trained DFormer on two popular RGB-D tasks, i.e., RGB-D semantic segmentation and RGB-D salient object detection, with a lightweight decoder head. Experimental results show that our DFormer achieves new state-of-the-art performance on these two tasks with less than half of the computational cost of the current best methods on two RGB-D segmentation datasets and five RGB-D saliency datasets. Our code is available at: https://github.com/VCIP-RGBD/DFormer. ",
    "url": "https://arxiv.org/abs/2309.09668",
    "authors": [
      "Bowen Yin",
      "Xuying Zhang",
      "Zhongyu Li",
      "Li Liu",
      "Ming-Ming Cheng",
      "Qibin Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09689",
    "title": "Ugly Ducklings or Swans: A Tiered Quadruplet Network with  Patient-Specific Mining for Improved Skin Lesion Classification",
    "abstract": "An ugly duckling is an obviously different skin lesion from surrounding lesions of an individual, and the ugly duckling sign is a criterion used to aid in the diagnosis of cutaneous melanoma by differentiating between highly suspicious and benign lesions. However, the appearance of pigmented lesions, can change drastically from one patient to another, resulting in difficulties in visual separation of ugly ducklings. Hence, we propose DMT-Quadruplet - a deep metric learning network to learn lesion features at two tiers - patient-level and lesion-level. We introduce a patient-specific quadruplet mining approach together with a tiered quadruplet network, to drive the network to learn more contextual information both globally and locally between the two tiers. We further incorporate a dynamic margin within the patient-specific mining to allow more useful quadruplets to be mined within individuals. Comprehensive experiments show that our proposed method outperforms traditional classifiers, achieving 54% higher sensitivity than a baseline ResNet18 CNN and 37% higher than a naive triplet network in classifying ugly duckling lesions. Visualisation of the data manifold in the metric space further illustrates that DMT-Quadruplet is capable of classifying ugly duckling lesions in both patient-specific and patient-agnostic manner successfully. ",
    "url": "https://arxiv.org/abs/2309.09689",
    "authors": [
      "Nathasha Naranpanawa",
      "H. Peter Soyer",
      "Adam Mothershaw",
      "Gayan K. Kulatilleke",
      "Zongyuan Ge",
      "Brigid Betz-Stablein",
      "Shekhar S. Chandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09694",
    "title": "Noise-Augmented Boruta: The Neural Network Perturbation Infusion with  Boruta Feature Selection",
    "abstract": "With the surge in data generation, both vertically (i.e., volume of data) and horizontally (i.e., dimensionality), the burden of the curse of dimensionality has become increasingly palpable. Feature selection, a key facet of dimensionality reduction techniques, has advanced considerably to address this challenge. One such advancement is the Boruta feature selection algorithm, which successfully discerns meaningful features by contrasting them to their permutated counterparts known as shadow features. However, the significance of a feature is shaped more by the data's overall traits than by its intrinsic value, a sentiment echoed in the conventional Boruta algorithm where shadow features closely mimic the characteristics of the original ones. Building on this premise, this paper introduces an innovative approach to the Boruta feature selection algorithm by incorporating noise into the shadow variables. Drawing parallels from the perturbation analysis framework of artificial neural networks, this evolved version of the Boruta method is presented. Rigorous testing on four publicly available benchmark datasets revealed that this proposed technique outperforms the classic Boruta algorithm, underscoring its potential for enhanced, accurate feature selection. ",
    "url": "https://arxiv.org/abs/2309.09694",
    "authors": [
      "Hassan Gharoun",
      "Navid Yazdanjoe",
      "Mohammad Sadegh Khorshidi",
      "Amir H. Gandomi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.09700",
    "title": "Securing Fixed Neural Network Steganography",
    "abstract": "Image steganography is the art of concealing secret information in images in a way that is imperceptible to unauthorized parties. Recent advances show that is possible to use a fixed neural network (FNN) for secret embedding and extraction. Such fixed neural network steganography (FNNS) achieves high steganographic performance without training the networks, which could be more useful in real-world applications. However, the existing FNNS schemes are vulnerable in the sense that anyone can extract the secret from the stego-image. To deal with this issue, we propose a key-based FNNS scheme to improve the security of the FNNS, where we generate key-controlled perturbations from the FNN for data embedding. As such, only the receiver who possesses the key is able to correctly extract the secret from the stego-image using the FNN. In order to improve the visual quality and undetectability of the stego-image, we further propose an adaptive perturbation optimization strategy by taking the perturbation cost into account. Experimental results show that our proposed scheme is capable of preventing unauthorized secret extraction from the stego-images. Furthermore, our scheme is able to generate stego-images with higher visual quality than the state-of-the-art FNNS scheme, especially when the FNN is a neural network for ordinary learning tasks. ",
    "url": "https://arxiv.org/abs/2309.09700",
    "authors": [
      "Zicong Luo",
      "Sheng Li",
      "Guobiao Li",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09724",
    "title": "Robust Geometry-Preserving Depth Estimation Using Differentiable  Rendering",
    "abstract": "In this study, we address the challenge of 3D scene structure recovery from monocular depth estimation. While traditional depth estimation methods leverage labeled datasets to directly predict absolute depth, recent advancements advocate for mix-dataset training, enhancing generalization across diverse scenes. However, such mixed dataset training yields depth predictions only up to an unknown scale and shift, hindering accurate 3D reconstructions. Existing solutions necessitate extra 3D datasets or geometry-complete depth annotations, constraints that limit their versatility. In this paper, we propose a learning framework that trains models to predict geometry-preserving depth without requiring extra data or annotations. To produce realistic 3D structures, we render novel views of the reconstructed scenes and design loss functions to promote depth estimation consistency across different views. Comprehensive experiments underscore our framework's superior generalization capabilities, surpassing existing state-of-the-art methods on several benchmark datasets without leveraging extra training information. Moreover, our innovative loss functions empower the model to autonomously recover domain-specific scale-and-shift coefficients using solely unlabeled images. ",
    "url": "https://arxiv.org/abs/2309.09724",
    "authors": [
      "Chi Zhang",
      "Wei Yin",
      "Gang Yu",
      "Zhibin Wang",
      "Tao Chen",
      "Bin Fu",
      "Joey Tianyi Zhou",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09730",
    "title": "Scribble-based 3D Multiple Abdominal Organ Segmentation via  Triple-branch Multi-dilated Network with Pixel- and Class-wise Consistency",
    "abstract": "Multi-organ segmentation in abdominal Computed Tomography (CT) images is of great importance for diagnosis of abdominal lesions and subsequent treatment planning. Though deep learning based methods have attained high performance, they rely heavily on large-scale pixel-level annotations that are time-consuming and labor-intensive to obtain. Due to its low dependency on annotation, weakly supervised segmentation has attracted great attention. However, there is still a large performance gap between current weakly-supervised methods and fully supervised learning, leaving room for exploration. In this work, we propose a novel 3D framework with two consistency constraints for scribble-supervised multiple abdominal organ segmentation from CT. Specifically, we employ a Triple-branch multi-Dilated network (TDNet) with one encoder and three decoders using different dilation rates to capture features from different receptive fields that are complementary to each other to generate high-quality soft pseudo labels. For more stable unsupervised learning, we use voxel-wise uncertainty to rectify the soft pseudo labels and then supervise the outputs of each decoder. To further regularize the network, class relationship information is exploited by encouraging the generated class affinity matrices to be consistent across different decoders under multi-view projection. Experiments on the public WORD dataset show that our method outperforms five existing scribble-supervised methods. ",
    "url": "https://arxiv.org/abs/2309.09730",
    "authors": [
      "Meng Han",
      "Xiangde Luo",
      "Wenjun Liao",
      "Shichuan Zhang",
      "Shaoting Zhang",
      "Guotai Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09733",
    "title": "Contrastive Learning and Data Augmentation in Traffic Classification  Using a Flowpic Input Representation",
    "abstract": "Over the last years we witnessed a renewed interest towards Traffic Classification (TC) captivated by the rise of Deep Learning (DL). Yet, the vast majority of TC literature lacks code artifacts, performance assessments across datasets and reference comparisons against Machine Learning (ML) methods. Among those works, a recent study from IMC'22 [17] is worth of attention since it adopts recent DL methodologies (namely, few-shot learning, self-supervision via contrastive learning and data augmentation) appealing for networking as they enable to learn from a few samples and transfer across datasets. The main result of [17] on the UCDAVIS19, ISCX-VPN and ISCX-Tor datasets is that, with such DL methodologies, 100 input samples are enough to achieve very high accuracy using an input representation called \"flowpic\" (i.e., a per-flow 2d histograms of the packets size evolution over time). In this paper (i) we reproduce [17] on the same datasets and (ii) we replicate its most salient aspect (the importance of data augmentation) on three additional public datasets, MIRAGE-19, MIRAGE-22 and UTMOBILENET21. While we confirm most of the original results, we also found a 20% accuracy drop on some of the investigated scenarios due to a data shift in the original dataset that we uncovered. Additionally, our study validates that the data augmentation strategies studied in [17] perform well on other datasets too. In the spirit of reproducibility and replicability we make all artifacts (code and data) available at [10]. ",
    "url": "https://arxiv.org/abs/2309.09733",
    "authors": [
      "Alessandro Finamore",
      "Chao Wang",
      "Jonatan Krolikowski",
      "Jose M. Navarro",
      "Fuxing Chen",
      "Dario Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.09734",
    "title": "Learning Optimal Robust Control of Connected Vehicles in Mixed Traffic  Flow",
    "abstract": "Connected and automated vehicles (CAVs) technologies promise to attenuate undesired traffic disturbances. However, in mixed traffic where human-driven vehicles (HDVs) also exist, the nonlinear human-driving behavior has brought critical challenges for effective CAV control. This paper employs the policy iteration method to learn the optimal robust controller for nonlinear mixed traffic systems. Precisely, we consider the H_infty control framework and formulate it as a zero-sum game, the equivalent condition for whose solution is converted into a Hamilton-Jacobi inequality with a Hamiltonian constraint. Then, a policy iteration algorithm is designed to generate stabilizing controllers with desired attenuation performance. Based on the updated robust controller, the attenuation level is further optimized in sum of squares program by leveraging the gap of the Hamiltonian constraint. Simulation studies verify that the obtained controller enables the CAVs to dampen traffic perturbations and smooth traffic flow. ",
    "url": "https://arxiv.org/abs/2309.09734",
    "authors": [
      "Jie Li",
      "Jiawei Wang",
      "Shengbo Eben Li",
      "Keqiang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.09737",
    "title": "Moving Object Detection and Tracking with 4D Radar Point Cloud",
    "abstract": "Mobile autonomy relies on the precise perception of dynamic environments. Robustly tracking moving objects in 3D world thus plays a pivotal role for applications like trajectory prediction, obstacle avoidance, and path planning. While most current methods utilize LiDARs or cameras for Multiple Object Tracking (MOT), the capabilities of 4D imaging radars remain largely unexplored. Recognizing the challenges posed by radar noise and point sparsity in 4D radar data, we introduce RaTrack, an innovative solution tailored for radar-based tracking. Bypassing the typical reliance on specific object types and 3D bounding boxes, our method focuses on motion segmentation and clustering, enriched by a motion estimation module. Evaluated on the View-of-Delft dataset, RaTrack showcases superior tracking precision of moving objects, largely surpassing the performance of the state of the art. ",
    "url": "https://arxiv.org/abs/2309.09737",
    "authors": [
      "Zhijun Pan",
      "Fangqiang Ding",
      "Hantao Zhong",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09739",
    "title": "Improving Neural Indoor Surface Reconstruction with Mask-Guided Adaptive  Consistency Constraints",
    "abstract": "3D scene reconstruction from 2D images has been a long-standing task. Instead of estimating per-frame depth maps and fusing them in 3D, recent research leverages the neural implicit surface as a unified representation for 3D reconstruction. Equipped with data-driven pre-trained geometric cues, these methods have demonstrated promising performance. However, inaccurate prior estimation, which is usually inevitable, can lead to suboptimal reconstruction quality, particularly in some geometrically complex regions. In this paper, we propose a two-stage training process, decouple view-dependent and view-independent colors, and leverage two novel consistency constraints to enhance detail reconstruction performance without requiring extra priors. Additionally, we introduce an essential mask scheme to adaptively influence the selection of supervision constraints, thereby improving performance in a self-supervised paradigm. Experiments on synthetic and real-world datasets show the capability of reducing the interference from prior estimation errors and achieving high-quality scene reconstruction with rich geometric details. ",
    "url": "https://arxiv.org/abs/2309.09739",
    "authors": [
      "Xinyi Yu",
      "Liqin Lu",
      "Jintao Rong",
      "Guangkai Xu",
      "Linlin Ou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09742",
    "title": "Drawing the Same Bounding Box Twice? Coping Noisy Annotations in Object  Detection with Repeated Labels",
    "abstract": "The reliability of supervised machine learning systems depends on the accuracy and availability of ground truth labels. However, the process of human annotation, being prone to error, introduces the potential for noisy labels, which can impede the practicality of these systems. While training with noisy labels is a significant consideration, the reliability of test data is also crucial to ascertain the dependability of the results. A common approach to addressing this issue is repeated labeling, where multiple annotators label the same example, and their labels are combined to provide a better estimate of the true label. In this paper, we propose a novel localization algorithm that adapts well-established ground truth estimation methods for object detection and instance segmentation tasks. The key innovation of our method lies in its ability to transform combined localization and classification tasks into classification-only problems, thus enabling the application of techniques such as Expectation-Maximization (EM) or Majority Voting (MJV). Although our main focus is the aggregation of unique ground truth for test data, our algorithm also shows superior performance during training on the TexBiG dataset, surpassing both noisy label training and label aggregation using Weighted Boxes Fusion (WBF). Our experiments indicate that the benefits of repeated labels emerge under specific dataset and annotation configurations. The key factors appear to be (1) dataset complexity, the (2) annotator consistency, and (3) the given annotation budget constraints. ",
    "url": "https://arxiv.org/abs/2309.09742",
    "authors": [
      "David Tschirschwitz",
      "Christian Benz",
      "Morris Florek",
      "Henrik Norderhus",
      "Benno Stein",
      "Volker Rodehorst"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09749",
    "title": "Facilitating NSFW Text Detection in Open-Domain Dialogue Systems via  Knowledge Distillation",
    "abstract": "NSFW (Not Safe for Work) content, in the context of a dialogue, can have severe side effects on users in open-domain dialogue systems. However, research on detecting NSFW language, especially sexually explicit content, within a dialogue context has significantly lagged behind. To address this issue, we introduce CensorChat, a dialogue monitoring dataset aimed at NSFW dialogue detection. Leveraging knowledge distillation techniques involving GPT-4 and ChatGPT, this dataset offers a cost-effective means of constructing NSFW content detectors. The process entails collecting real-life human-machine interaction data and breaking it down into single utterances and single-turn dialogues, with the chatbot delivering the final utterance. ChatGPT is employed to annotate unlabeled data, serving as a training set. Rationale validation and test sets are constructed using ChatGPT and GPT-4 as annotators, with a self-criticism strategy for resolving discrepancies in labeling. A BERT model is fine-tuned as a text classifier on pseudo-labeled data, and its performance is assessed. The study emphasizes the importance of AI systems prioritizing user safety and well-being in digital conversations while respecting freedom of expression. The proposed approach not only advances NSFW content detection but also aligns with evolving user protection needs in AI-driven dialogues. ",
    "url": "https://arxiv.org/abs/2309.09749",
    "authors": [
      "Huachuan Qiu",
      "Shuai Zhang",
      "Hongliang He",
      "Anqi Li",
      "Zhenzhong Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09775",
    "title": "ArxNet Model and Data: Building Social Networks from Image Archives",
    "abstract": "A corresponding explosion in digital images has accompanied the rapid adoption of mobile technology around the world. People and their activities are routinely captured in digital image and video files. By their very nature, these images and videos often portray social and professional connections. Individuals in the same picture are often connected in some meaningful way. Our research seeks to identify and model social connections found in images using modern face detection technology and social network analysis. The proposed methods are then demonstrated on the public image repository associated with the 2022 Emmy's Award Presentation. ",
    "url": "https://arxiv.org/abs/2309.09775",
    "authors": [
      "Haley Seaward",
      "Jasmine Talley",
      "David Beskow"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.09786",
    "title": "2-Colorable Perfect Matching is NP-complete in 2-Connected 3-Regular  Planar Graphs",
    "abstract": "The 2-colorable perfect matching problem asks whether a graph can be colored with two colors so that each node has exactly one neighbor with the same color as itself. We prove that this problem is NP-complete, even when restricted to 2-connected 3-regular planar graphs. In 1978, Schaefer proved that this problem is NP-complete in general graphs, and claimed without proof that the same result holds when restricted to 3-regular planar graphs. Thus we fill in the missing proof of this claim, while simultaneously strengthening to 2-connected graphs (which implies existence of a perfect matching). We also prove NP-completeness of $k$-colorable perfect matching, for any fixed $k \\geq 2$. ",
    "url": "https://arxiv.org/abs/2309.09786",
    "authors": [
      "Erik D. Demaine",
      "Kritkorn Karntikoon",
      "Nipun Pitimanaaree"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2309.09799",
    "title": "Watch the Speakers: A Hybrid Continuous Attribution Network for Emotion  Recognition in Conversation With Emotion Disentanglement",
    "abstract": "Emotion Recognition in Conversation (ERC) has attracted widespread attention in the natural language processing field due to its enormous potential for practical applications. Existing ERC methods face challenges in achieving generalization to diverse scenarios due to insufficient modeling of context, ambiguous capture of dialogue relationships and overfitting in speaker modeling. In this work, we present a Hybrid Continuous Attributive Network (HCAN) to address these issues in the perspective of emotional continuation and emotional attribution. Specifically, HCAN adopts a hybrid recurrent and attention-based module to model global emotion continuity. Then a novel Emotional Attribution Encoding (EAE) is proposed to model intra- and inter-emotional attribution for each utterance. Moreover, aiming to enhance the robustness of the model in speaker modeling and improve its performance in different scenarios, A comprehensive loss function emotional cognitive loss $\\mathcal{L}_{\\rm EC}$ is proposed to alleviate emotional drift and overcome the overfitting of the model to speaker modeling. Our model achieves state-of-the-art performance on three datasets, demonstrating the superiority of our work. Another extensive comparative experiments and ablation studies on three benchmarks are conducted to provided evidence to support the efficacy of each module. Further exploration of generalization ability experiments shows the plug-and-play nature of the EAE module in our method. ",
    "url": "https://arxiv.org/abs/2309.09799",
    "authors": [
      "Shanglin Lei",
      "Xiaoping Wang",
      "Guanting Dong",
      "Jiang Li",
      "Yingjian Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.09805",
    "title": "Constrained Delaunay Tetrahedrization: A Robust and Practical Approach",
    "abstract": "We present a numerically robust algorithm for computing the constrained Delaunay tetrahedrization (CDT) of a piecewise-linear complex, which has a 100% success rate on the 4408 valid models in the Thingi10k dataset. We build on the underlying theory of the well-known TetGen software, but use a floating-point implementation based on indirect geometric predicates to implicitly represent Steiner points: this new approach dramatically simplifies the implementation, removing the need for ad-hoc tolerances in geometric operations. Our approach leads to a robust and parameter-free implementation, with an empirically manageable number of added Steiner points. Furthermore, our algorithm addresses a major gap in TetGen's theory which may lead to algorithmic failure on valid models, even when assuming perfect precision in the calculations. Our output tetrahedrization conforms with the input geometry without approximations. We can further round our output to floating-point coordinates for downstream applications, which almost always results in valid floating-point meshes unless the input triangulation is very close to being degenerate. ",
    "url": "https://arxiv.org/abs/2309.09805",
    "authors": [
      "Lorenzo Diazzi",
      "Daniele Panozzo",
      "Amir Vaxman",
      "Marco Attene"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2309.09807",
    "title": "Efficient Concept Drift Handling for Batch Android Malware Detection  Models",
    "abstract": "The rapidly evolving nature of Android apps poses a significant challenge to static batch machine learning algorithms employed in malware detection systems, as they quickly become obsolete. Despite this challenge, the existing literature pays limited attention to addressing this issue, with many advanced Android malware detection approaches, such as Drebin, DroidDet and MaMaDroid, relying on static models. In this work, we show how retraining techniques are able to maintain detector capabilities over time. Particularly, we analyze the effect of two aspects in the efficiency and performance of the detectors: 1) the frequency with which the models are retrained, and 2) the data used for retraining. In the first experiment, we compare periodic retraining with a more advanced concept drift detection method that triggers retraining only when necessary. In the second experiment, we analyze sampling methods to reduce the amount of data used to retrain models. Specifically, we compare fixed sized windows of recent data and state-of-the-art active learning methods that select those apps that help keep the training dataset small but diverse. Our experiments show that concept drift detection and sample selection mechanisms result in very efficient retraining strategies which can be successfully used to maintain the performance of the static Android malware state-of-the-art detectors in changing environments. ",
    "url": "https://arxiv.org/abs/2309.09807",
    "authors": [
      "Molina-Coronado B.",
      "Mori U.",
      "Mendiburu A.",
      "Miguel-Alonso J"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09826",
    "title": "Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract  Code Using Vulnerability-constrained Decoding",
    "abstract": "Auto-completing code enables developers to speed up coding significantly. Recent advances in transformer-based large language model (LLM) technologies have been applied to code synthesis. However, studies show that many of such synthesized codes contain vulnerabilities. We propose a novel vulnerability-constrained decoding approach to reduce the amount of vulnerable code generated by such models. Using a small dataset of labeled vulnerable lines of code, we fine-tune an LLM to include vulnerability labels when generating code, acting as an embedded classifier. Then, during decoding, we deny the model to generate these labels to avoid generating vulnerable code. To evaluate the method, we chose to automatically complete Ethereum Blockchain smart contracts (SCs) as the case study due to the strict requirements of SC security. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397 Ethereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuning took more than one week using ten GPUs. The results showed that our fine-tuned model could synthesize SCs with an average BLEU (BiLingual Evaluation Understudy) score of 0.557. However, many codes in the auto-completed SCs were vulnerable. Using the code before the vulnerable line of 176 SCs containing different types of vulnerabilities to auto-complete the code, we found that more than 70% of the auto-completed codes were insecure. Thus, we further fine-tuned the model on other 941 vulnerable SCs containing the same types of vulnerabilities and applied vulnerability-constrained decoding. The fine-tuning took only one hour with four GPUs. We then auto-completed the 176 SCs again and found that our approach could identify 62% of the code to be generated as vulnerable and avoid generating 67% of them, indicating the approach could efficiently and effectively avoid vulnerabilities in the auto-completed code. ",
    "url": "https://arxiv.org/abs/2309.09826",
    "authors": [
      "Andr\u00e9 Storhaug",
      "Jingyue Li",
      "Tianyuan Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09837",
    "title": "Frame-to-Utterance Convergence: A Spectra-Temporal Approach for Unified  Spoofing Detection",
    "abstract": "Voice spoofing attacks pose a significant threat to automated speaker verification systems. Existing anti-spoofing methods often simulate specific attack types, such as synthetic or replay attacks. However, in real-world scenarios, the countermeasures are unaware of the generation schema of the attack, necessitating a unified solution. Current unified solutions struggle to detect spoofing artifacts, especially with recent spoofing mechanisms. For instance, the spoofing algorithms inject spectral or temporal anomalies, which are challenging to identify. To this end, we present a spectra-temporal fusion leveraging frame-level and utterance-level coefficients. We introduce a novel local spectral deviation coefficient (SDC) for frame-level inconsistencies and employ a bi-LSTM-based network for sequential temporal coefficients (STC), which capture utterance-level artifacts. Our spectra-temporal fusion strategy combines these coefficients, and an auto-encoder generates spectra-temporal deviated coefficients (STDC) to enhance robustness. Our proposed approach addresses multiple spoofing categories, including synthetic, replay, and partial deepfake attacks. Extensive evaluation on diverse datasets (ASVspoof2019, ASVspoof2021, VSDC, partial spoofs, and in-the-wild deepfakes) demonstrated its robustness for a wide range of voice applications. ",
    "url": "https://arxiv.org/abs/2309.09837",
    "authors": [
      "Awais Khan",
      "Khalid Mahmood Malik",
      "Shah Nawaz"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computers and Society (cs.CY)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.09840",
    "title": "Mobility Performance Analysis of RACH Optimization Based on Decision  Tree Supervised Learning for Conditional Handover in 5G Beamformed Networks",
    "abstract": "In 5G cellular networks, frequency range 2 (FR2) introduces higher frequencies that cause rapid signal degradation and challenge user mobility. In recent studies, a conditional handover procedure has been adopted as an enhancement to baseline handover to enhance user mobility robustness. In this article, the mobility performance of conditional handover is analyzed for a 5G mm-wave network in FR2 that employs beamforming. In addition, a resource-efficient random access procedure is proposed that increases the probability of contention-free random access during a handover. Moreover, a simple yet effective decision tree-based supervised learning method is proposed to minimize the handover failures that are caused by the beam preparation phase of the random access procedure. Results have shown that a tradeoff exists between contention-free random access and handover failures. It is also seen that the optimum operation point of random access is achievable with the proposed learning algorithm for conditional handover. Moreover, a mobility performance comparison of conditional handover with baseline handover is also carried out. Results have shown that while baseline handover causes fewer handover failures than conditional handover, the total number of mobility failures in the latter is less due to the decoupling of the handover preparation and execution phases. ",
    "url": "https://arxiv.org/abs/2309.09840",
    "authors": [
      "Subhyal Bin Iqbal",
      "Umur Karabulut",
      "Ahmad Awada",
      "Andre Noll Barreto",
      "Philipp Schulz",
      "Gerhard P. Fettweis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.09844",
    "title": "CC-SGG: Corner Case Scenario Generation using Learned Scene Graphs",
    "abstract": "Corner case scenarios are an essential tool for testing and validating the safety of autonomous vehicles (AVs). As these scenarios are often insufficiently present in naturalistic driving datasets, augmenting the data with synthetic corner cases greatly enhances the safe operation of AVs in unique situations. However, the generation of synthetic, yet realistic, corner cases poses a significant challenge. In this work, we introduce a novel approach based on Heterogeneous Graph Neural Networks (HGNNs) to transform regular driving scenarios into corner cases. To achieve this, we first generate concise representations of regular driving scenes as scene graphs, minimally manipulating their structure and properties. Our model then learns to perturb those graphs to generate corner cases using attention and triple embeddings. The input and perturbed graphs are then imported back into the simulation to generate corner case scenarios. Our model successfully learned to produce corner cases from input scene graphs, achieving 89.9% prediction accuracy on our testing dataset. We further validate the generated scenarios on baseline autonomous driving methods, demonstrating our model's ability to effectively create critical situations for the baselines. ",
    "url": "https://arxiv.org/abs/2309.09844",
    "authors": [
      "George Drayson",
      "Efimia Panagiotaki",
      "Daniel Omeiza",
      "Lars Kunze"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09865",
    "title": "Contrastive Learning for Enhancing Robust Scene Transfer in Vision-based  Agile Flight",
    "abstract": "Scene transfer for vision-based mobile robotics applications is a highly relevant and challenging problem. The utility of a robot greatly depends on its ability to perform a task in the real world, outside of a well-controlled lab environment. Existing scene transfer end-to-end policy learning approaches often suffer from poor sample efficiency or limited generalization capabilities, making them unsuitable for mobile robotics applications. This work proposes an adaptive multi-pair contrastive learning strategy for visual representation learning that enables zero-shot scene transfer and real-world deployment. Control policies relying on the embedding are able to operate in unseen environments without the need for finetuning in the deployment environment. We demonstrate the performance of our approach on the task of agile, vision-based quadrotor flight. Extensive simulation and real-world experiments demonstrate that our approach successfully generalizes beyond the training domain and outperforms all baselines. ",
    "url": "https://arxiv.org/abs/2309.09865",
    "authors": [
      "Jiaxu Xing",
      "Leonard Bauersfeld",
      "Yunlong Song",
      "Chunwei Xing",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09887",
    "title": "On Model Explanations with Transferable Neural Pathways",
    "abstract": "Neural pathways as model explanations consist of a sparse set of neurons that provide the same level of prediction performance as the whole model. Existing methods primarily focus on accuracy and sparsity but the generated pathways may offer limited interpretability thus fall short in explaining the model behavior. In this paper, we suggest two interpretability criteria of neural pathways: (i) same-class neural pathways should primarily consist of class-relevant neurons; (ii) each instance's neural pathway sparsity should be optimally determined. To this end, we propose a Generative Class-relevant Neural Pathway (GEN-CNP) model that learns to predict the neural pathways from the target model's feature maps. We propose to learn class-relevant information from features of deep and shallow layers such that same-class neural pathways exhibit high similarity. We further impose a faithfulness criterion for GEN-CNP to generate pathways with instance-specific sparsity. We propose to transfer the class-relevant neural pathways to explain samples of the same class and show experimentally and qualitatively their faithfulness and interpretability. ",
    "url": "https://arxiv.org/abs/2309.09887",
    "authors": [
      "Xinmiao Lin",
      "Wentao Bao",
      "Qi Yu",
      "Yu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09901",
    "title": "The role of causality in explainable artificial intelligence",
    "abstract": "Causality and eXplainable Artificial Intelligence (XAI) have developed as separate fields in computer science, even though the underlying concepts of causation and explanation share common ancient roots. This is further enforced by the lack of review works jointly covering these two fields. In this paper, we investigate the literature to try to understand how and to what extent causality and XAI are intertwined. More precisely, we seek to uncover what kinds of relationships exist between the two concepts and how one can benefit from them, for instance, in building trust in AI systems. As a result, three main perspectives are identified. In the first one, the lack of causality is seen as one of the major limitations of current AI and XAI approaches, and the \"optimal\" form of explanations is investigated. The second is a pragmatic perspective and considers XAI as a tool to foster scientific exploration for causal inquiry, via the identification of pursue-worthy experimental manipulations. Finally, the third perspective supports the idea that causality is propaedeutic to XAI in three possible manners: exploiting concepts borrowed from causality to support or improve XAI, utilizing counterfactuals for explainability, and considering accessing a causal model as explaining itself. To complement our analysis, we also provide relevant software solutions used to automate causal tasks. We believe our work provides a unified view of the two fields of causality and XAI by highlighting potential domain bridges and uncovering possible limitations. ",
    "url": "https://arxiv.org/abs/2309.09901",
    "authors": [
      "Gianluca Carloni",
      "Andrea Berti",
      "Sara Colantonio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09911",
    "title": "Neural Parametric Surfaces for Shape Modeling",
    "abstract": "The recent surge of utilizing deep neural networks for geometric processing and shape modeling has opened up exciting avenues. However, there is a conspicuous lack of research efforts on using powerful neural representations to extend the capabilities of parametric surfaces, which are the prevalent surface representations in product design, CAD/CAM, and computer animation. We present Neural Parametric Surfaces, the first piecewise neural surface representation that allows coarse patch layouts of arbitrary $n$-sided surface patches to model complex surface geometries with high precision, offering greater flexibility over traditional parametric surfaces. By construction, this new surface representation guarantees $G^0$ continuity between adjacent patches and empirically achieves $G^1$ continuity, which cannot be attained by existing neural patch-based methods. The key ingredient of our neural parametric surface is a learnable feature complex $\\mathcal{C}$ that is embedded in a high-dimensional space $\\mathbb{R}^D$ and topologically equivalent to the patch layout of the surface; each face cell of the complex is defined by interpolating feature vectors at its vertices. The learned feature complex is mapped by an MLP-encoded function $f:\\mathcal{C} \\rightarrow \\mathcal{S}$ to produce the neural parametric surface $\\mathcal{S}$. We present a surface fitting algorithm that optimizes the feature complex $\\mathcal{C}$ and trains the neural mapping $f$ to reconstruct given target shapes with high accuracy. We further show that the proposed representation along with a compact-size neural net can learn a plausible shape space from a shape collection, which can be used for shape interpolation or shape completion from noisy and incomplete input data. Extensive experiments show that neural parametric surfaces offer greater modeling capabilities than traditional parametric surfaces. ",
    "url": "https://arxiv.org/abs/2309.09911",
    "authors": [
      "Lei Yang",
      "Yongqing Liang",
      "Xin Li",
      "Congyi Zhang",
      "Guying Lin",
      "Alla Sheffer",
      "Scott Schaefer",
      "John Keyser",
      "Wenping Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2309.09921",
    "title": "A Heterogeneous Graph-Based Multi-Task Learning for Fault Event  Diagnosis in Smart Grid",
    "abstract": "Precise and timely fault diagnosis is a prerequisite for a distribution system to ensure minimum downtime and maintain reliable operation. This necessitates access to a comprehensive procedure that can provide the grid operators with insightful information in the case of a fault event. In this paper, we propose a heterogeneous multi-task learning graph neural network (MTL-GNN) capable of detecting, locating and classifying faults in addition to providing an estimate of the fault resistance and current. Using a graph neural network (GNN) allows for learning the topological representation of the distribution system as well as feature learning through a message-passing scheme. We investigate the robustness of our proposed model using the IEEE-123 test feeder system. This work also proposes a novel GNN-based explainability method to identify key nodes in the distribution system which then facilitates informed sparse measurements. Numerical tests validate the performance of the model across all tasks. ",
    "url": "https://arxiv.org/abs/2309.09921",
    "authors": [
      "Dibaloke Chanda",
      "Nasim Yahya Soltani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09924",
    "title": "Graph topological property recovery with heat and wave dynamics-based  features on graphsD",
    "abstract": "In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins. ",
    "url": "https://arxiv.org/abs/2309.09924",
    "authors": [
      "Dhananjay Bhaskar",
      "Yanlei Zhang",
      "Charles Xu",
      "Xingzhi Sun",
      "Oluwadamilola Fasina",
      "Guy Wolf",
      "Maximilian Nickel",
      "Michael Perlmutter",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.09928",
    "title": "Evaluating Adversarial Robustness with Expected Viable Performance",
    "abstract": "We introduce a metric for evaluating the robustness of a classifier, with particular attention to adversarial perturbations, in terms of expected functionality with respect to possible adversarial perturbations. A classifier is assumed to be non-functional (that is, has a functionality of zero) with respect to a perturbation bound if a conventional measure of performance, such as classification accuracy, is less than a minimally viable threshold when the classifier is tested on examples from that perturbation bound. Defining robustness in terms of an expected value is motivated by a domain general approach to robustness quantification. ",
    "url": "https://arxiv.org/abs/2309.09928",
    "authors": [
      "Ryan McCoppin",
      "Colin Dawson",
      "Sean M. Kennedy",
      "Leslie M. Blaha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09934",
    "title": "Hierarchical Attention and Graph Neural Networks: Toward Drift-Free Pose  Estimation",
    "abstract": "The most commonly used method for addressing 3D geometric registration is the iterative closet-point algorithm, this approach is incremental and prone to drift over multiple consecutive frames. The Common strategy to address the drift is the pose graph optimization subsequent to frame-to-frame registration, incorporating a loop closure process that identifies previously visited places. In this paper, we explore a framework that replaces traditional geometric registration and pose graph optimization with a learned model utilizing hierarchical attention mechanisms and graph neural networks. We propose a strategy to condense the data flow, preserving essential information required for the precise estimation of rigid poses. Our results, derived from tests on the KITTI Odometry dataset, demonstrate a significant improvement in pose estimation accuracy. This improvement is especially notable in determining rotational components when compared with results obtained through conventional multi-way registration via pose graph optimization. The code will be made available upon completion of the review process. ",
    "url": "https://arxiv.org/abs/2309.09934",
    "authors": [
      "Kathia Melbouci",
      "Fawzi Nashashibi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09943",
    "title": "Property Graphs in Arachne",
    "abstract": "Analyzing large-scale graphs poses challenges due to their increasing size and the demand for interactive and user-friendly analytics tools. These graphs arise from various domains, including cybersecurity, social sciences, health sciences, and network sciences, where networks can represent interactions between humans, neurons in the brain, or malicious flows in a network. Exploring these large graphs is crucial for revealing hidden structures and metrics that are not easily computable without parallel computing. Currently, Python users can leverage the open-source Arkouda framework to efficiently execute Pandas and NumPy-related tasks on thousands of cores. To address large-scale graph analysis, Arachne, an extension to Arkouda, enables easy transformation of Arkouda dataframes into graphs. This paper proposes and evaluates three distributable data structures for property graphs, implemented in Chapel, that are integrated into Arachne. Enriching Arachne with support for property graphs will empower data scientists to extend their analysis to new problem domains. Property graphs present additional complexities, requiring efficient storage for extra information on vertices and edges, such as labels, relationships, and properties. ",
    "url": "https://arxiv.org/abs/2309.09943",
    "authors": [
      "Oliver Alvarado Rodriguez",
      "Fernando Vera Buschmann",
      "Zhihui Du",
      "David A. Bader"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.09949",
    "title": "How to Generate Popular Post Headlines on Social Media?",
    "abstract": "Posts, as important containers of user-generated-content pieces on social media, are of tremendous social influence and commercial value. As an integral components of a post, the headline has a decisive contribution to the post's popularity. However, current mainstream method for headline generation is still manually writing, which is unstable and requires extensive human effort. This drives us to explore a novel research question: Can we automate the generation of popular headlines on social media? We collect more than 1 million posts of 42,447 celebrities from public data of Xiaohongshu, which is a well-known social media platform in China. We then conduct careful observations on the headlines of these posts. Observation results demonstrate that trends and personal styles are widespread in headlines on social medias and have significant contribution to posts's popularity. Motivated by these insights, we present MEBART, which combines Multiple preference-Extractors with Bidirectional and Auto-Regressive Transformers (BART), capturing trends and personal styles to generate popular headlines on social medias. We perform extensive experiments on real-world datasets and achieve state-of-the-art performance compared with several advanced baselines. In addition, ablation and case studies demonstrate that MEBART advances in capturing trends and personal styles. ",
    "url": "https://arxiv.org/abs/2309.09949",
    "authors": [
      "Zhouxiang Fang",
      "Min Yu",
      "Zhendong Fu",
      "Boning Zhang",
      "Xuanwen Huang",
      "Xiaoqi Tang",
      "Yang Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.09970",
    "title": "Empirical Study of Mix-based Data Augmentation Methods in Physiological  Time Series Data",
    "abstract": "Data augmentation is a common practice to help generalization in the procedure of deep model training. In the context of physiological time series classification, previous research has primarily focused on label-invariant data augmentation methods. However, another class of augmentation techniques (\\textit{i.e., Mixup}) that emerged in the computer vision field has yet to be fully explored in the time series domain. In this study, we systematically review the mix-based augmentations, including mixup, cutmix, and manifold mixup, on six physiological datasets, evaluating their performance across different sensory data and classification tasks. Our results demonstrate that the three mix-based augmentations can consistently improve the performance on the six datasets. More importantly, the improvement does not rely on expert knowledge or extensive parameter tuning. Lastly, we provide an overview of the unique properties of the mix-based augmentation methods and highlight the potential benefits of using the mix-based augmentation in physiological time series data. ",
    "url": "https://arxiv.org/abs/2309.09970",
    "authors": [
      "Peikun Guo",
      "Huiyuan Yang",
      "Akane Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09975",
    "title": "GEDepth: Ground Embedding for Monocular Depth Estimation",
    "abstract": "Monocular depth estimation is an ill-posed problem as the same 2D image can be projected from infinite 3D scenes. Although the leading algorithms in this field have reported significant improvement, they are essentially geared to the particular compound of pictorial observations and camera parameters (i.e., intrinsics and extrinsics), strongly limiting their generalizability in real-world scenarios. To cope with this challenge, this paper proposes a novel ground embedding module to decouple camera parameters from pictorial cues, thus promoting the generalization capability. Given camera parameters, the proposed module generates the ground depth, which is stacked with the input image and referenced in the final depth prediction. A ground attention is designed in the module to optimally combine ground depth with residual depth. Our ground embedding is highly flexible and lightweight, leading to a plug-in module that is amenable to be integrated into various depth estimation networks. Experiments reveal that our approach achieves the state-of-the-art results on popular benchmarks, and more importantly, renders significant generalization improvement on a wide range of cross-domain tests. ",
    "url": "https://arxiv.org/abs/2309.09975",
    "authors": [
      "Xiaodong Yang",
      "Zhuang Ma",
      "Zhiyu Ji",
      "Zhe Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08630",
    "title": "PCN: A Deep Learning Approach to Jet Tagging Utilizing Novel Graph  Construction Methods and Chebyshev Graph Convolutions",
    "abstract": "Jet tagging is a classification problem in high-energy physics experiments that aims to identify the collimated sprays of subatomic particles, jets, from particle collisions and tag them to their emitter particle. Advances in jet tagging present opportunities for searches of new physics beyond the Standard Model. Current approaches use deep learning to uncover hidden patterns in complex collision data. However, the representation of jets as inputs to a deep learning model have been varied, and often, informative features are withheld from models. In this study, we propose a graph-based representation of a jet that encodes the most information possible. To learn best from this representation, we design Particle Chebyshev Network (PCN), a graph neural network (GNN) using Chebyshev graph convolutions (ChebConv). ChebConv has been demonstrated as an effective alternative to classical graph convolutions in GNNs and has yet to be explored in jet tagging. PCN achieves a substantial improvement in accuracy over existing taggers and opens the door to future studies into graph-based representations of jets and ChebConv layers in high-energy physics experiments. Code is available at https://github.com/YVSemlani/PCN-Jet-Tagging. ",
    "url": "https://arxiv.org/abs/2309.08630",
    "authors": [
      "Yash Semlani",
      "Mihir Relan",
      "Krithik Ramesh"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2309.08652",
    "title": "Quantifying Credit Portfolio sensitivity to asset correlations with  interpretable generative neural networks",
    "abstract": "In this research, we propose a novel approach for the quantification of credit portfolio Value-at-Risk (VaR) sensitivity to asset correlations with the use of synthetic financial correlation matrices generated with deep learning models. In previous work Generative Adversarial Networks (GANs) were employed to demonstrate the generation of plausible correlation matrices, that capture the essential characteristics observed in empirical correlation matrices estimated on asset returns. Instead of GANs, we employ Variational Autoencoders (VAE) to achieve a more interpretable latent space representation. Through our analysis, we reveal that the VAE latent space can be a useful tool to capture the crucial factors impacting portfolio diversification, particularly in relation to credit portfolio sensitivity to asset correlations changes. ",
    "url": "https://arxiv.org/abs/2309.08652",
    "authors": [
      "Sergio Caprioli",
      "Emanuele Cagliero",
      "Riccardo Crupi"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08765",
    "title": "Mining Patents with Large Language Models Demonstrates Congruence of  Functional Labels and Chemical Structures",
    "abstract": "Predicting chemical function from structure is a major goal of the chemical sciences, from the discovery and repurposing of novel drugs to the creation of new materials. Recently, new machine learning algorithms are opening up the possibility of general predictive models spanning many different chemical functions. Here, we consider the challenge of applying large language models to chemical patents in order to consolidate and leverage the information about chemical functionality captured by these resources. Chemical patents contain vast knowledge on chemical function, but their usefulness as a dataset has historically been neglected due to the impracticality of extracting high-quality functional labels. Using a scalable ChatGPT-assisted patent summarization and word-embedding label cleaning pipeline, we derive a Chemical Function (CheF) dataset, containing 100K molecules and their patent-derived functional labels. The functional labels were validated to be of high quality, allowing us to detect a strong relationship between functional label and chemical structural spaces. Further, we find that the co-occurrence graph of the functional labels contains a robust semantic structure, which allowed us in turn to examine functional relatedness among the compounds. We then trained a model on the CheF dataset, allowing us to assign new functional labels to compounds. Using this model, we were able to retrodict approved Hepatitis C antivirals, uncover an antiviral mechanism undisclosed in the patent, and identify plausible serotonin-related drugs. The CheF dataset and associated model offers a promising new approach to predict chemical functionality. ",
    "url": "https://arxiv.org/abs/2309.08765",
    "authors": [
      "Clayton W. Kosonocky",
      "Claus O. Wilke",
      "Edward M. Marcotte",
      "Andrew D. Ellington"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08835",
    "title": "Intelligent machines work in unstructured environments by differential  neural computing",
    "abstract": "Expecting intelligent machines to efficiently work in real world requires a new method to understand unstructured information in unknown environments with good accuracy, scalability and generalization, like human. Here, a memristive neural computing based perceptual signal differential processing and learning method for intelligent machines is presented, via extracting main features of environmental information and applying associated encoded stimuli to memristors, we successfully obtain human-like ability in processing unstructured environmental information, such as amplification (>720%) and adaptation (<50%) of mechanical stimuli. The method also exhibits good scalability and generalization, validated in two typical applications of intelligent machines: object grasping and autonomous driving. In the former, a robot hand experimentally realizes safe and stable grasping, through learning unknown object features (e.g., sharp corner and smooth surface) with a single memristor in 1 ms. In the latter, the decision-making information of 10 unstructured environments in autonomous driving (e.g., overtaking cars, pedestrians) are accurately (94%) extracted with a 40x25 memristor array. By mimicking the intrinsic nature of human low-level perception mechanisms in electronic memristive neural circuits, the proposed method is adaptable to diverse sensing technologies, helping intelligent machines to generate smart high-level decisions in real world. ",
    "url": "https://arxiv.org/abs/2309.08835",
    "authors": [
      "Shengbo Wang",
      "Shuo Gao",
      "Chenyu Tang",
      "Cong Li",
      "Shurui Wang",
      "Jiaqi Wang",
      "Hubin Zhao",
      "Guohua Hu",
      "Arokia Nathan",
      "Ravinder Dahiya",
      "Luigi Occhipinti"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08876",
    "title": "Decoder-only Architecture for Speech Recognition with CTC Prompts and  Text Data Augmentation",
    "abstract": "Collecting audio-text pairs is expensive; however, it is much easier to access text-only data. Unless using shallow fusion, end-to-end automatic speech recognition (ASR) models require architecture modifications or additional training schemes to use text-only data. Inspired by recent advances in decoder-only language models (LMs), such as GPT-3 and PaLM adopted for speech-processing tasks, we propose using a decoder-only architecture for ASR with simple text augmentation. To provide audio information, encoder features compressed by CTC prediction are used as prompts for the decoder, which can be regarded as refining CTC prediction using the decoder-only model. Because the decoder architecture is the same as an autoregressive LM, it is simple to enhance the model by leveraging external text data with LM training. An experimental comparison using LibriSpeech and Switchboard shows that our proposed models with text augmentation training reduced word error rates from ordinary CTC by 0.3% and 1.4% on LibriSpeech test-clean and testother set, respectively, and 2.9% and 5.0% on Switchboard and CallHome. The proposed model had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios. ",
    "url": "https://arxiv.org/abs/2309.08876",
    "authors": [
      "Emiru Tsunoo",
      "Hayato Futami",
      "Yosuke Kashiwagi",
      "Siddhant Arora",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.09028",
    "title": "Unifying Robustness and Fidelity: A Comprehensive Study of Pretrained  Generative Methods for Speech Enhancement in Adverse Conditions",
    "abstract": "Enhancing speech signal quality in adverse acoustic environments is a persistent challenge in speech processing. Existing deep learning based enhancement methods often struggle to effectively remove background noise and reverberation in real-world scenarios, hampering listening experiences. To address these challenges, we propose a novel approach that uses pre-trained generative methods to resynthesize clean, anechoic speech from degraded inputs. This study leverages pre-trained vocoder or codec models to synthesize high-quality speech while enhancing robustness in challenging scenarios. Generative methods effectively handle information loss in speech signals, resulting in regenerated speech that has improved fidelity and reduced artifacts. By harnessing the capabilities of pre-trained models, we achieve faithful reproduction of the original speech in adverse conditions. Experimental evaluations on both simulated datasets and realistic samples demonstrate the effectiveness and robustness of our proposed methods. Especially by leveraging codec, we achieve superior subjective scores for both simulated and realistic recordings. The generated speech exhibits enhanced audio quality, reduced background noise, and reverberation. Our findings highlight the potential of pre-trained generative techniques in speech processing, particularly in scenarios where traditional methods falter. Demos are available at https://whmrtm.github.io/SoundResynthesis. ",
    "url": "https://arxiv.org/abs/2309.09028",
    "authors": [
      "Heming Wang",
      "Meng Yu",
      "Hao Zhang",
      "Chunlei Zhang",
      "Zhongweiyang Xu",
      "Muqiao Yang",
      "Yixuan Zhang",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.09111",
    "title": "Reducing sequential change detection to sequential estimation",
    "abstract": "We consider the problem of sequential change detection, where the goal is to design a scheme for detecting any changes in a parameter or functional $\\theta$ of the data stream distribution that has small detection delay, but guarantees control on the frequency of false alarms in the absence of changes. In this paper, we describe a simple reduction from sequential change detection to sequential estimation using confidence sequences: we begin a new $(1-\\alpha)$-confidence sequence at each time step, and proclaim a change when the intersection of all active confidence sequences becomes empty. We prove that the average run length is at least $1/\\alpha$, resulting in a change detection scheme with minimal structural assumptions~(thus allowing for possibly dependent observations, and nonparametric distribution classes), but strong guarantees. Our approach bears an interesting parallel with the reduction from change detection to sequential testing of Lorden (1971) and the e-detector of Shin et al. (2022). ",
    "url": "https://arxiv.org/abs/2309.09111",
    "authors": [
      "Shubhanshu Shekhar",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.09171",
    "title": "On the Connection Between Riemann Hypothesis and a Special Class of  Neural Networks",
    "abstract": "The Riemann hypothesis (RH) is a long-standing open problem in mathematics. It conjectures that non-trivial zeros of the zeta function all have real part equal to 1/2. The extent of the consequences of RH is far-reaching and touches a wide spectrum of topics including the distribution of prime numbers, the growth of arithmetic functions, the growth of Euler totient, etc. In this note, we revisit and extend an old analytic criterion of the RH known as the Nyman-Beurling criterion which connects the RH to a minimization problem that involves a special class of neural networks. This note is intended for an audience unfamiliar with RH. A gentle introduction to RH is provided. ",
    "url": "https://arxiv.org/abs/2309.09171",
    "authors": [
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09180",
    "title": "Neural Speaker Diarization Using Memory-Aware Multi-Speaker Embedding  with Sequence-to-Sequence Architecture",
    "abstract": "We propose a novel neural speaker diarization system using memory-aware multi-speaker embedding with sequence-to-sequence architecture (NSD-MS2S), which integrates the strengths of memory-aware multi-speaker embedding (MA-MSE) and sequence-to-sequence (Seq2Seq) architecture, leading to improvement in both efficiency and performance. Next, we further decrease the memory occupation of decoding by incorporating input features fusion and then employ a multi-head attention mechanism to capture features at different levels. NSD-MS2S achieved a macro diarization error rate (DER) of 15.9% on the CHiME-7 EVAL set, which signifies a relative improvement of 49% over the official baseline system, and is the key technique for us to achieve the best performance for the main track of CHiME-7 DASR Challenge. Additionally, we introduce a deep interactive module (DIM) in MA-MSE module to better retrieve a cleaner and more discriminative multi-speaker embedding, enabling the current model to outperform the system we used in the CHiME-7 DASR Challenge. Our code will be available at https://github.com/liyunlongaaa/NSD-MS2S. ",
    "url": "https://arxiv.org/abs/2309.09180",
    "authors": [
      "Gaobin Yang",
      "Maokui He",
      "Shutong Niu",
      "Ruoyu Wang",
      "Yanyan Yue",
      "Shuangqing Qian",
      "Shilong Wu",
      "Jun Du",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.09220",
    "title": "Improving Speech Inversion Through Self-Supervised Embeddings and  Enhanced Tract Variables",
    "abstract": "The performance of deep learning models depends significantly on their capacity to encode input features efficiently and decode them into meaningful outputs. Better input and output representation has the potential to boost models' performance and generalization. In the context of acoustic-to-articulatory speech inversion (SI) systems, we study the impact of utilizing speech representations acquired via self-supervised learning (SSL) models, such as HuBERT compared to conventional acoustic features. Additionally, we investigate the incorporation of novel tract variables (TVs) through an improved geometric transformation model. By combining these two approaches, we improve the Pearson product-moment correlation (PPMC) scores which evaluate the accuracy of TV estimation of the SI system from 0.7452 to 0.8141, a 6.9% increase. Our findings underscore the profound influence of rich feature representations from SSL models and improved geometric transformations with target TVs on the enhanced functionality of SI systems. ",
    "url": "https://arxiv.org/abs/2309.09220",
    "authors": [
      "Ahmed Adel Attia",
      "Yashish M. Siriwardena",
      "Carol Espy-Wilson"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.09240",
    "title": "High-dimensional manifold of solutions in neural networks: insights from  statistical physics",
    "abstract": "In these pedagogic notes I review the statistical mechanics approach to neural networks, focusing on the paradigmatic example of the perceptron architecture with binary an continuous weights, in the classification setting. I will review the Gardner's approach based on replica method and the derivation of the SAT/UNSAT transition in the storage setting. Then, I discuss some recent works that unveiled how the zero training error configurations are geometrically arranged, and how this arrangement changes as the size of the training set increases. I also illustrate how different regions of solution space can be explored analytically and how the landscape in the vicinity of a solution can be characterized. I give evidence how, in binary weight models, algorithmic hardness is a consequence of the disappearance of a clustered region of solutions that extends to very large distances. Finally, I demonstrate how the study of linear mode connectivity between solutions can give insights into the average shape of the solution manifold. ",
    "url": "https://arxiv.org/abs/2309.09240",
    "authors": [
      "Enrico M. Malatesta"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2309.09355",
    "title": "Structure to Property: Chemical Element Embeddings and a Deep Learning  Approach for Accurate Prediction of Chemical Properties",
    "abstract": "The application of machine learning (ML) techniques in computational chemistry has led to significant advances in predicting molecular properties, accelerating drug discovery, and material design. ML models can extract hidden patterns and relationships from complex and large datasets, allowing for the prediction of various chemical properties with high accuracy. The use of such methods has enabled the discovery of molecules and materials that were previously difficult to identify. This paper introduces a new ML model based on deep learning techniques, such as a multilayer encoder and decoder architecture, for classification tasks. We demonstrate the opportunities offered by our approach by applying it to various types of input data, including organic and inorganic compounds. In particular, we developed and tested the model using the Matbench and Moleculenet benchmarks, which include crystal properties and drug design-related benchmarks. We also conduct a comprehensive analysis of vector representations of chemical compounds, shedding light on the underlying patterns in molecular data. The models used in this work exhibit a high degree of predictive power, underscoring the progress that can be made with refined machine learning when applied to molecular and material datasets. For instance, on the Tox21 dataset, we achieved an average accuracy of 96%, surpassing the previous best result by 10%. Our code is publicly available at https://github.com/dmamur/elembert. ",
    "url": "https://arxiv.org/abs/2309.09355",
    "authors": [
      "Shokirbek Shermukhamedov",
      "Dilorom Mamurjonova",
      "Michael Probst"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Atomic and Molecular Clusters (physics.atm-clus)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.09377",
    "title": "Frequency-Domain Detection for Molecular Communication with  Cross-Reactive Receptors",
    "abstract": "Molecular Communications (MC) is a bio-inspired communication paradigm that uses molecules as information carriers, requiring unconventional transceivers and modulation/detection techniques. Practical MC receivers (MC-Rxs) can be implemented using field-effect transistor biosensor (bioFET) architectures, where surface receptors reversibly react with ligands. The time-varying concentration of ligand-bound receptors is translated into electrical signals via field effect, which is used to decode the transmitted information. However, ligand-receptor interactions do not provide an ideal molecular selectivity, as similar ligand types, i.e., interferers, co-existing in the MC channel, can interact with the same type of receptors. Overcoming this molecular cross-talk in the time domain can be challenging, especially when Rx has no knowledge of the interferer statistics or operates near saturation. Therefore, we propose a frequency-domain detection (FDD) technique for bioFET-based MC-Rxs that exploits the difference in binding reaction rates of different ligand types reflected in the power spectrum of the ligand-receptor binding noise. We derive the bit error probability (BEP) of the FDD technique and demonstrate its effectiveness in decoding transmitted concentration signals under stochastic molecular interference compared to a widely used time-domain detection (TDD) technique. We then verified the analytical performance bounds of the FDD through a particle-based spatial stochastic simulator simulating reactions on the MC-Rx in microfluidic channels. ",
    "url": "https://arxiv.org/abs/2309.09377",
    "authors": [
      "Meltem Civas",
      "Murat Kuscu",
      "Ozgur B. Akan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2309.09483",
    "title": "An Accurate and Efficient Neural Network for OCTA Vessel Segmentation  and a New Dataset",
    "abstract": "Optical coherence tomography angiography (OCTA) is a noninvasive imaging technique that can reveal high-resolution retinal vessels. In this work, we propose an accurate and efficient neural network for retinal vessel segmentation in OCTA images. The proposed network achieves accuracy comparable to other SOTA methods, while having fewer parameters and faster inference speed (e.g. 110x lighter and 1.3x faster than U-Net), which is very friendly for industrial applications. This is achieved by applying the modified Recurrent ConvNeXt Block to a full resolution convolutional network. In addition, we create a new dataset containing 918 OCTA images and their corresponding vessel annotations. The data set is semi-automatically annotated with the help of Segment Anything Model (SAM), which greatly improves the annotation speed. For the benefit of the community, our code and dataset can be obtained from https://github.com/nhjydywd/OCTA-FRNet. ",
    "url": "https://arxiv.org/abs/2309.09483",
    "authors": [
      "Haojian Ning",
      "Chengliang Wang",
      "Xinrun Chen",
      "Shiying Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09490",
    "title": "Self-supervised TransUNet for Ultrasound regional segmentation of the  distal radius in children",
    "abstract": "Supervised deep learning offers great promise to automate analysis of medical images from segmentation to diagnosis. However, their performance highly relies on the quality and quantity of the data annotation. Meanwhile, curating large annotated datasets for medical images requires a high level of expertise, which is time-consuming and expensive. Recently, to quench the thirst for large data sets with high-quality annotation, self-supervised learning (SSL) methods using unlabeled domain-specific data, have attracted attention. Therefore, designing an SSL method that relies on minimal quantities of labeled data has far-reaching significance in medical images. This paper investigates the feasibility of deploying the Masked Autoencoder for SSL (SSL-MAE) of TransUNet, for segmenting bony regions from children's wrist ultrasound scans. We found that changing the embedding and loss function in SSL-MAE can produce better downstream results compared to the original SSL-MAE. In addition, we determined that only pretraining TransUNet embedding and encoder with SSL-MAE does not work as well as TransUNet without SSL-MAE pretraining on downstream segmentation tasks. ",
    "url": "https://arxiv.org/abs/2309.09490",
    "authors": [
      "Yuyue Zhou",
      "Jessica Knight",
      "Banafshe Felfeliyan",
      "Christopher Keen",
      "Abhilash Rakkunedeth Hareendranathan",
      "Jacob L. Jaremko"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09493",
    "title": "HiFTNet: A Fast High-Quality Neural Vocoder with Harmonic-plus-Noise  Filter and Inverse Short Time Fourier Transform",
    "abstract": "Recent advancements in speech synthesis have leveraged GAN-based networks like HiFi-GAN and BigVGAN to produce high-fidelity waveforms from mel-spectrograms. However, these networks are computationally expensive and parameter-heavy. iSTFTNet addresses these limitations by integrating inverse short-time Fourier transform (iSTFT) into the network, achieving both speed and parameter efficiency. In this paper, we introduce an extension to iSTFTNet, termed HiFTNet, which incorporates a harmonic-plus-noise source filter in the time-frequency domain that uses a sinusoidal source from the fundamental frequency (F0) inferred via a pre-trained F0 estimation network for fast inference speed. Subjective evaluations on LJSpeech show that our model significantly outperforms both iSTFTNet and HiFi-GAN, achieving ground-truth-level performance. HiFTNet also outperforms BigVGAN-base on LibriTTS for unseen speakers and achieves comparable performance to BigVGAN while being four times faster with only $1/6$ of the parameters. Our work sets a new benchmark for efficient, high-quality neural vocoding, paving the way for real-time applications that demand high quality speech synthesis. ",
    "url": "https://arxiv.org/abs/2309.09493",
    "authors": [
      "Yinghao Aaron Li",
      "Cong Han",
      "Xilin Jiang",
      "Nima Mesgarani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.09548",
    "title": "Utilizing Whisper to Enhance Multi-Branched Speech Intelligibility  Prediction Model for Hearing Aids",
    "abstract": "Automated assessment of speech intelligibility in hearing aid (HA) devices is of great importance. Our previous work introduced a non-intrusive multi-branched speech intelligibility prediction model called MBI-Net, which achieved top performance in the Clarity Prediction Challenge 2022. Based on the promising results of the MBI-Net model, we aim to further enhance its performance by leveraging Whisper embeddings to enrich acoustic features. In this study, we propose two improved models, namely MBI-Net+ and MBI-Net++. MBI-Net+ maintains the same model architecture as MBI-Net, but replaces self-supervised learning (SSL) speech embeddings with Whisper embeddings to deploy cross-domain features. On the other hand, MBI-Net++ further employs a more elaborate design, incorporating an auxiliary task to predict frame-level and utterance-level scores of the objective speech intelligibility metric HASPI (Hearing Aid Speech Perception Index) and multi-task learning. Experimental results confirm that both MBI-Net++ and MBI-Net+ achieve better prediction performance than MBI-Net in terms of multiple metrics, and MBI-Net++ is better than MBI-Net+. ",
    "url": "https://arxiv.org/abs/2309.09548",
    "authors": [
      "Ryandhimas E. Zezario",
      "Fei Chen",
      "Chiou-Shann Fuh",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.09725",
    "title": "Neural Collapse for Unconstrained Feature Model under Cross-entropy Loss  with Imbalanced Data",
    "abstract": "Recent years have witnessed the huge success of deep neural networks (DNNs) in various tasks of computer vision and text processing. Interestingly, these DNNs with massive number of parameters share similar structural properties on their feature representation and last-layer classifier at terminal phase of training (TPT). Specifically, if the training data are balanced (each class shares the same number of samples), it is observed that the feature vectors of samples from the same class converge to their corresponding in-class mean features and their pairwise angles are the same. This fascinating phenomenon is known as Neural Collapse (N C), first termed by Papyan, Han, and Donoho in 2019. Many recent works manage to theoretically explain this phenomenon by adopting so-called unconstrained feature model (UFM). In this paper, we study the extension of N C phenomenon to the imbalanced data under cross-entropy loss function in the context of unconstrained feature model. Our contribution is multi-fold compared with the state-of-the-art results: (a) we show that the feature vectors exhibit collapse phenomenon, i.e., the features within the same class collapse to the same mean vector; (b) the mean feature vectors no longer form an equiangular tight frame. Instead, their pairwise angles depend on the sample size; (c) we also precisely characterize the sharp threshold on which the minority collapse (the feature vectors of the minority groups collapse to one single vector) will take place; (d) finally, we argue that the effect of the imbalance in datasize diminishes as the sample size grows. Our results provide a complete picture of the N C under the cross-entropy loss for the imbalanced data. Numerical experiments confirm our theoretical analysis. ",
    "url": "https://arxiv.org/abs/2309.09725",
    "authors": [
      "Wanli Hong",
      "Shuyang Ling"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.09814",
    "title": "Convolutional Deep Kernel Machines",
    "abstract": "Deep kernel machines (DKMs) are a recently introduced kernel method with the flexibility of other deep models including deep NNs and deep Gaussian processes. DKMs work purely with kernels, never with features, and are therefore different from other methods ranging from NNs to deep kernel learning and even deep Gaussian processes, which all use features as a fundamental component. Here, we introduce convolutional DKMs, along with an efficient inter-domain inducing point approximation scheme. Further, we develop and experimentally assess a number of model variants, including 9 different types of normalisation designed for the convolutional DKMs, two likelihoods, and two different types of top-layer. The resulting models achieve around 99% test accuracy on MNIST, 92% on CIFAR-10 and 71% on CIFAR-100, despite training in only around 28 GPU hours, 1-2 orders of magnitude faster than full NNGP / NTK / Myrtle kernels, whilst achieving comparable performance. ",
    "url": "https://arxiv.org/abs/2309.09814",
    "authors": [
      "Edward Milsom",
      "Ben Anson",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1903.07497",
    "title": "Advanced Capsule Networks via Context Awareness",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/1903.07497",
    "authors": [
      "Nguyen Huu Phong",
      "Bernardete Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.07646",
    "title": "A Survey of Privacy Attacks in Machine Learning",
    "abstract": " Comments: Edit to add DOI. Accepted in ACM Computing Surveys, please cite the journal version ",
    "url": "https://arxiv.org/abs/2007.07646",
    "authors": [
      "Maria Rigaki",
      "Sebastian Garcia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.01793",
    "title": "Composing Recurrent Spiking Neural Networks using Locally-Recurrent  Motifs and Risk-Mitigating Architectural Optimization",
    "abstract": " Comments: 20 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2108.01793",
    "authors": [
      "Wenrui Zhang",
      "Hejia Geng",
      "Peng Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.08503",
    "title": "On Generalizations of Pairwise Compatibility Graphs",
    "abstract": " Title: On Generalizations of Pairwise Compatibility Graphs ",
    "url": "https://arxiv.org/abs/2112.08503",
    "authors": [
      "Tiziana Calamoneri",
      "Manuel Lafond",
      "Angelo Monti",
      "Blerina Sinaimeri"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.05250",
    "title": "Adaptive and Robust Multi-Task Learning",
    "abstract": " Comments: 72 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2202.05250",
    "authors": [
      "Yaqi Duan",
      "Kaizheng Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.01077",
    "title": "On-Device Learning: A Neural Network Based Field-Trainable Edge AI",
    "abstract": " Comments: A typo in an equation in Fig.2c has been corrected ",
    "url": "https://arxiv.org/abs/2203.01077",
    "authors": [
      "Hiroki Matsutani",
      "Mineto Tsukada",
      "Masaaki Kondo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10560",
    "title": "Empowering Fake-News Mitigation: Insights from Sharers' Social Media  Post-Histories",
    "abstract": " Comments: 108 pages ",
    "url": "https://arxiv.org/abs/2203.10560",
    "authors": [
      "Verena Schoenmueller",
      "Simon J. Blanchard",
      "Gita V. Johar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.02357",
    "title": "Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge  Graph Completion",
    "abstract": " Comments: Accepted by SIGIR 2022. Fix a severe bug ",
    "url": "https://arxiv.org/abs/2205.02357",
    "authors": [
      "Xiang Chen",
      "Ningyu Zhang",
      "Lei Li",
      "Shumin Deng",
      "Chuanqi Tan",
      "Changliang Xu",
      "Fei Huang",
      "Luo Si",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2205.07877",
    "title": "A Comprehensive Survey on Model Quantization for Deep Neural Networks in  Image Classification",
    "abstract": " Comments: The title of the paper has been changed. The abstract has been improved. The grammatical errors have been corrected. The structure of the paper has been modified. Some new and important references have been added. Some of the used abbreviations in the paper have been corrected. The discussion of some important topics has been extended. Some figures have been improved ",
    "url": "https://arxiv.org/abs/2205.07877",
    "authors": [
      "Babak Rokh",
      "Ali Azarpeyvand",
      "Alireza Khanteymoori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00359",
    "title": "DeepCluE: Enhanced Image Clustering via Multi-layer Ensembles in Deep  Neural Networks",
    "abstract": " Comments: To appear in IEEE Transactions on Emerging Topics in Computational Intelligence ",
    "url": "https://arxiv.org/abs/2206.00359",
    "authors": [
      "Dong Huang",
      "Ding-Hua Chen",
      "Xiangji Chen",
      "Chang-Dong Wang",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00362",
    "title": "An Empirical Study of Retrieval-enhanced Graph Neural Networks",
    "abstract": " Comments: Accepted by ECAI 2023 ",
    "url": "https://arxiv.org/abs/2206.00362",
    "authors": [
      "Dingmin Wang",
      "Shengchao Liu",
      "Hanchen Wang",
      "Bernardo Cuenca Grau",
      "Linfeng Song",
      "Jian Tang",
      "Song Le",
      "Qi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.05184",
    "title": "SERE: Exploring Feature Self-relation for Self-supervised Transformer",
    "abstract": " Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) ",
    "url": "https://arxiv.org/abs/2206.05184",
    "authors": [
      "Zhong-Yu Li",
      "Shanghua Gao",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09522",
    "title": "Multiple Testing Framework for Out-of-Distribution Detection",
    "abstract": " Title: Multiple Testing Framework for Out-of-Distribution Detection ",
    "url": "https://arxiv.org/abs/2206.09522",
    "authors": [
      "Akshayaa Magesh",
      "Venugopal V. Veeravalli",
      "Anirban Roy",
      "Susmit Jha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.12498",
    "title": "Optimal and Robust Category-level Perception: Object Pose and Shape  Estimation from 2D and 3D Semantic Keypoints",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2104.08383 ",
    "url": "https://arxiv.org/abs/2206.12498",
    "authors": [
      "Jingnan Shi",
      "Heng Yang",
      "Luca Carlone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00414",
    "title": "Artificial Intelligence Techniques for Next-Generation Mega Satellite  Networks",
    "abstract": " Title: Artificial Intelligence Techniques for Next-Generation Mega Satellite  Networks ",
    "url": "https://arxiv.org/abs/2207.00414",
    "authors": [
      "Bassel Al Homssi",
      "Kosta Dakic",
      "Ke Wang",
      "Tansu Alpcan",
      "Ben Allen",
      "Russell Boyce",
      "Sithamparanathan Kandeepan",
      "Akram Al-Hourani",
      "Walid Saad"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.05568",
    "title": "The emergence of division of labor through decentralized social  sanctioning",
    "abstract": " Title: The emergence of division of labor through decentralized social  sanctioning ",
    "url": "https://arxiv.org/abs/2208.05568",
    "authors": [
      "Anil Yaman",
      "Joel Z. Leibo",
      "Giovanni Iacca",
      "Sang Wan Lee"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2209.07542",
    "title": "Understanding of the properties of neural network approaches for  transient light curve approximations",
    "abstract": " Title: Understanding of the properties of neural network approaches for  transient light curve approximations ",
    "url": "https://arxiv.org/abs/2209.07542",
    "authors": [
      "Mariia Demianenko",
      "Konstantin Malanchev",
      "Ekaterina Samorodova",
      "Mikhail Sysak",
      "Aleksandr Shiriaev",
      "Denis Derkach",
      "Mikhail Hushchyn"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.08446",
    "title": "Mutual Harmony: Sequential Recommendation with Dual Contrastive Network",
    "abstract": " Comments: 25 pages ",
    "url": "https://arxiv.org/abs/2209.08446",
    "authors": [
      "Guanyu Lin",
      "Chen Gao",
      "Yinfeng Li",
      "Yu Zheng",
      "Zhiheng Li",
      "Depeng Jin",
      "Dong Li",
      "Jianye Hao",
      "Yong Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2209.14262",
    "title": "A Survey on Physical Adversarial Attack in Computer Vision",
    "abstract": " Title: A Survey on Physical Adversarial Attack in Computer Vision ",
    "url": "https://arxiv.org/abs/2209.14262",
    "authors": [
      "Donghua Wang",
      "Wen Yao",
      "Tingsong Jiang",
      "Guijian Tang",
      "Xiaoqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.15031",
    "title": "Automatic Data Augmentation via Invariance-Constrained Learning",
    "abstract": " Title: Automatic Data Augmentation via Invariance-Constrained Learning ",
    "url": "https://arxiv.org/abs/2209.15031",
    "authors": [
      "Ignacio Hounie",
      "Luiz F. O. Chamon",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10709",
    "title": "Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph  Construction",
    "abstract": " Comments: Accepted by SIGIR 2023 ",
    "url": "https://arxiv.org/abs/2210.10709",
    "authors": [
      "Yunzhi Yao",
      "Shengyu Mao",
      "Ningyu Zhang",
      "Xiang Chen",
      "Shumin Deng",
      "Xi Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12714",
    "title": "Generative Knowledge Graph Construction: A Review",
    "abstract": " Comments: Accepted to EMNLP 2022 (oral) and a public repository is available in this https URL ",
    "url": "https://arxiv.org/abs/2210.12714",
    "authors": [
      "Hongbin Ye",
      "Ningyu Zhang",
      "Hui Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12740",
    "title": "HiFi-WaveGAN: Generative Adversarial Network with Auxiliary  Spectrogram-Phase Loss for High-Fidelity Singing Voice Generation",
    "abstract": " Title: HiFi-WaveGAN: Generative Adversarial Network with Auxiliary  Spectrogram-Phase Loss for High-Fidelity Singing Voice Generation ",
    "url": "https://arxiv.org/abs/2210.12740",
    "authors": [
      "Chunhui Wang",
      "Chang Zeng",
      "Jun Chen",
      "Xing He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.16242",
    "title": "Differential Privacy has Bounded Impact on Fairness in Classification",
    "abstract": " Title: Differential Privacy has Bounded Impact on Fairness in Classification ",
    "url": "https://arxiv.org/abs/2210.16242",
    "authors": [
      "Paul Mangold",
      "Micha\u00ebl Perrot",
      "Aur\u00e9lien Bellet",
      "Marc Tommasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.16751",
    "title": "Formalizing Statistical Causality via Modal Logic",
    "abstract": " Comments: Full version for the paper accepted at JELIA 2023 (the 18th European Conference on Logics in Artificial Intelligence) ",
    "url": "https://arxiv.org/abs/2210.16751",
    "authors": [
      "Yusuke Kawamoto",
      "Tetsuya Sato",
      "Kohei Suenaga"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2211.05793",
    "title": "Efficient and quantum-adaptive machine learning with fermion neural  networks",
    "abstract": " Comments: 18 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2211.05793",
    "authors": [
      "Pei-Lin Zheng",
      "Jia-Bao Wang",
      "Yi Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10948",
    "title": "FedDCT: Federated Learning of Large Convolutional Neural Networks on  Resource Constrained Devices using Divide and Collaborative Training",
    "abstract": " Comments: Update v2: Final version as published in IEEE Transactions on Network and Service Management 2023 ",
    "url": "https://arxiv.org/abs/2211.10948",
    "authors": [
      "Quan Nguyen",
      "Hieu H. Pham",
      "Kok-Seng Wong",
      "Phi Le Nguyen",
      "Truong Thao Nguyen",
      "Minh N. Do"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00306",
    "title": "Decentralized Matrix Factorization with Heterogeneous Differential  Privacy",
    "abstract": " Comments: Accepted by the 22nd IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom-2023) ",
    "url": "https://arxiv.org/abs/2212.00306",
    "authors": [
      "Wentao Hu",
      "Hui Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.05500",
    "title": "Security Defense of Large Scale Networks Under False Data Injection  Attacks: An Attack Detection Scheduling Approach",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication ",
    "url": "https://arxiv.org/abs/2212.05500",
    "authors": [
      "Yuhan Suo",
      "Senchun Chai",
      "Runqi Chai",
      "Zhong-Hua Pang",
      "Yuanqing Xia",
      "Guo-Ping Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.01283",
    "title": "Cross Modal Transformer: Towards Fast and Robust 3D Object Detection",
    "abstract": " Title: Cross Modal Transformer: Towards Fast and Robust 3D Object Detection ",
    "url": "https://arxiv.org/abs/2301.01283",
    "authors": [
      "Junjie Yan",
      "Yingfei Liu",
      "Jianjian Sun",
      "Fan Jia",
      "Shuailin Li",
      "Tiancai Wang",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02145",
    "title": "Domain Generalization via Ensemble Stacking for Face Presentation Attack  Detection",
    "abstract": " Title: Domain Generalization via Ensemble Stacking for Face Presentation Attack  Detection ",
    "url": "https://arxiv.org/abs/2301.02145",
    "authors": [
      "Usman Muhammad",
      "Jorma Laaksonen",
      "Djamila Romaissa Beddiar",
      "Mourad Oussalah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.05231",
    "title": "Equivariant Representation Learning in the Presence of Stabilizers",
    "abstract": " Comments: NeurIPS Workshop on Symmetry and Geometry in Neural Representations (v1), European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (v2) ",
    "url": "https://arxiv.org/abs/2301.05231",
    "authors": [
      "Luis Armando P\u00e9rez Rey",
      "Giovanni Luca Marchetti",
      "Danica Kragic",
      "Dmitri Jarnikov",
      "Mike Holenderski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Group Theory (math.GR)"
    ]
  },
  {
    "id": "arXiv:2301.05712",
    "title": "A Survey on Self-supervised Learning: Algorithms, Applications, and  Future Trends",
    "abstract": " Title: A Survey on Self-supervised Learning: Algorithms, Applications, and  Future Trends ",
    "url": "https://arxiv.org/abs/2301.05712",
    "authors": [
      "Jie Gui",
      "Tuo Chen",
      "Jing Zhang",
      "Qiong Cao",
      "Zhenan Sun",
      "Hao Luo",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12739",
    "title": "FractalAD: A simple industrial anomaly detection method using fractal  anomaly generation and backbone knowledge distillation",
    "abstract": " Comments: 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2301.12739",
    "authors": [
      "Xuan Xia",
      "Weijie Lv",
      "Xing He",
      "Nan Li",
      "Chuanqi Liu",
      "Ning Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12798",
    "title": "Reliable Federated Disentangling Network for Non-IID Domain Feature",
    "abstract": " Title: Reliable Federated Disentangling Network for Non-IID Domain Feature ",
    "url": "https://arxiv.org/abs/2301.12798",
    "authors": [
      "Meng Wang",
      "Kai Yu",
      "Chun-Mei Feng",
      "Yiming Qian",
      "Ke Zou",
      "Lianyu Wang",
      "Rick Siow Mong Goh",
      "Yong Liu",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13331",
    "title": "Neural Operator: Is data all you need to model the world? An insight  into the impact of Physics Informed Machine Learning",
    "abstract": " Title: Neural Operator: Is data all you need to model the world? An insight  into the impact of Physics Informed Machine Learning ",
    "url": "https://arxiv.org/abs/2301.13331",
    "authors": [
      "Hrishikesh Viswanath",
      "Md Ashiqur Rahman",
      "Abhijeet Vyas",
      "Andrey Shor",
      "Beatriz Medeiros",
      "Stephanie Hernandez",
      "Suhas Eswarappa Prameela",
      "Aniket Bera"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2301.13392",
    "title": "Combinatorial Causal Bandits without Graph Skeleton",
    "abstract": " Comments: 39 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2301.13392",
    "authors": [
      "Shi Feng",
      "Nuoya Xiong",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.07729",
    "title": "Generation of Highlights from Research Papers Using Pointer-Generator  Networks and SciBERT Embeddings",
    "abstract": " Comments: 19 Pages, 7 Figures, 8 Tables ",
    "url": "https://arxiv.org/abs/2302.07729",
    "authors": [
      "Tohida Rehman",
      "Debarshi Kumar Sanyal",
      "Samiran Chattopadhyay",
      "Plaban Kumar Bhowmick",
      "Partha Pratim Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02731",
    "title": "Virtual Guidance as a Mid-level Representation for Navigation",
    "abstract": " Comments: Tsung-Chih Chiang, Ting-Ru Liu, Chun-Wei Huang, and Jou-Min Liu contributed equally to this work; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2303.02731",
    "authors": [
      "Hsuan-Kung Yang",
      "Tsung-Chih Chiang",
      "Ting-Ru Liu",
      "Chun-Wei Huang",
      "Jou-Min Liu",
      "Chun-Yi Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.04413",
    "title": "PL-UNeXt: Per-stage Edge Detail and Line Feature Guided Segmentation for  Power Line Detection",
    "abstract": " Comments: Accepted to IEEE ICIP 2023 ",
    "url": "https://arxiv.org/abs/2303.04413",
    "authors": [
      "Yang Cheng",
      "Zhen Chen",
      "Daming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.11943",
    "title": "Data driven approach to sparsification of reaction diffusion complex  network systems",
    "abstract": " Title: Data driven approach to sparsification of reaction diffusion complex  network systems ",
    "url": "https://arxiv.org/abs/2303.11943",
    "authors": [
      "Abhishek Ajayakumar",
      "Soumyendu Raha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.13818",
    "title": "Prior-RadGraphFormer: A Prior-Knowledge-Enhanced Transformer for  Generating Radiology Graphs from X-Rays",
    "abstract": " Comments: In GRAIL @ MICCAI 2023 ",
    "url": "https://arxiv.org/abs/2303.13818",
    "authors": [
      "Yiheng Xiong",
      "Jingsong Liu",
      "Kamilia Zaripova",
      "Sahand Sharifzadeh",
      "Matthias Keicher",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.14495",
    "title": "Preconditioned Algorithm for Difference of Convex Functions with  applications to Graph Ginzburg-Landau Model",
    "abstract": " Title: Preconditioned Algorithm for Difference of Convex Functions with  applications to Graph Ginzburg-Landau Model ",
    "url": "https://arxiv.org/abs/2303.14495",
    "authors": [
      "Xinhua Shen",
      "Hongpeng Sun",
      "Xuecheng Tai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.16242",
    "title": "CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image  Arbitrary-Scale Super Resolution",
    "abstract": " Comments: This paper is accepted by the International Conference on Computer Vision (ICCV) 2023 ",
    "url": "https://arxiv.org/abs/2303.16242",
    "authors": [
      "Zixuan Chen",
      "Jian-Huang Lai",
      "Lingxiao Yang",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17297",
    "title": "Understanding the Robustness of 3D Object Detection with Bird's-Eye-View  Representations in Autonomous Driving",
    "abstract": " Comments: 8 pages, CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.17297",
    "authors": [
      "Zijian Zhu",
      "Yichi Zhang",
      "Hai Chen",
      "Yinpeng Dong",
      "Shu Zhao",
      "Wenbo Ding",
      "Jiachen Zhong",
      "Shibao Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.06049",
    "title": "Exact and Cost-Effective Automated Transformation of Neural Network  Controllers to Decision Tree Controllers",
    "abstract": " Title: Exact and Cost-Effective Automated Transformation of Neural Network  Controllers to Decision Tree Controllers ",
    "url": "https://arxiv.org/abs/2304.06049",
    "authors": [
      "Kevin Chang",
      "Nathan Dahlin",
      "Rahul Jain",
      "Pierluigi Nuzzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.06205",
    "title": "Difficult Lessons on Social Prediction from Wisconsin Public Schools",
    "abstract": " Title: Difficult Lessons on Social Prediction from Wisconsin Public Schools ",
    "url": "https://arxiv.org/abs/2304.06205",
    "authors": [
      "Juan C. Perdomo",
      "Tolani Britton",
      "Moritz Hardt",
      "Rediet Abebe"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2304.08304",
    "title": "SDVRF: Sparse-to-Dense Voxel Region Fusion for Multi-modal 3D Object  Detection",
    "abstract": " Title: SDVRF: Sparse-to-Dense Voxel Region Fusion for Multi-modal 3D Object  Detection ",
    "url": "https://arxiv.org/abs/2304.08304",
    "authors": [
      "Binglu Ren",
      "Jianqin Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.08615",
    "title": "Revisiting Block-Diagonal SDP Relaxations for the Clique Number of the  Paley Graphs",
    "abstract": " Comments: To appear in SampTA 2023 ",
    "url": "https://arxiv.org/abs/2304.08615",
    "authors": [
      "Vladimir A. Kobzar",
      "Krishnan Mody"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.10075",
    "title": "Multiscale Representation for Real-Time Anti-Aliasing Neural Rendering",
    "abstract": " Title: Multiscale Representation for Real-Time Anti-Aliasing Neural Rendering ",
    "url": "https://arxiv.org/abs/2304.10075",
    "authors": [
      "Dongting Hu",
      "Zhenkai Zhang",
      "Tingbo Hou",
      "Tongliang Liu",
      "Huan Fu",
      "Mingming Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12751",
    "title": "Node Feature Augmentation Vitaminizes Network Alignment",
    "abstract": " Comments: 17 pages, 12 figures, 5 tables; its conference version was presented at the ACM International Conference on Information and Knowledge Management (CIKM 2022) ",
    "url": "https://arxiv.org/abs/2304.12751",
    "authors": [
      "Jin-Duk Park",
      "Cong Tran",
      "Won-Yong Shin",
      "Xin Cao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.04581",
    "title": "Capturing Smart Contract Design with DCR Graphs",
    "abstract": " Comments: Accepted for presentation at SEFM 2023 ",
    "url": "https://arxiv.org/abs/2305.04581",
    "authors": [
      "Mojtaba Eshghie",
      "Wolfgang Ahrendt",
      "Cyrille Artho",
      "Thomas Troels Hildebrandt",
      "Gerardo Schneider"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2305.09519",
    "title": "Community Notes vs. Snoping: How the Crowd Selects Fact-Checking Targets  on Social Media",
    "abstract": " Title: Community Notes vs. Snoping: How the Crowd Selects Fact-Checking Targets  on Social Media ",
    "url": "https://arxiv.org/abs/2305.09519",
    "authors": [
      "Moritz Pilarski",
      "Kirill Solovev",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.10498",
    "title": "Edge Directionality Improves Learning on Heterophilic Graphs",
    "abstract": " Title: Edge Directionality Improves Learning on Heterophilic Graphs ",
    "url": "https://arxiv.org/abs/2305.10498",
    "authors": [
      "Emanuele Rossi",
      "Bertrand Charpentier",
      "Francesco Di Giovanni",
      "Fabrizio Frasca",
      "Stephan G\u00fcnnemann",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.13617",
    "title": "SPEECH: Structured Prediction with Energy-Based Event-Centric  Hyperspheres",
    "abstract": " Comments: Accepted by ACL 2023 Main Conference. Code is released at \\url{this https URL} ",
    "url": "https://arxiv.org/abs/2305.13617",
    "authors": [
      "Shumin Deng",
      "Shengyu Mao",
      "Ningyu Zhang",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15244",
    "title": "Neural Lyapunov and Optimal Control",
    "abstract": " Title: Neural Lyapunov and Optimal Control ",
    "url": "https://arxiv.org/abs/2305.15244",
    "authors": [
      "Daniel Layeghi",
      "Steve Tonneau",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16437",
    "title": "KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired  True-Range Multilateration",
    "abstract": " Comments: Accepted to ACM Multimedia 2023; 10 pages, 7 figures, 6 tables; the code is at this https URL ",
    "url": "https://arxiv.org/abs/2305.16437",
    "authors": [
      "Xu Bao",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Chenyang Li",
      "Wangmeng Xiang",
      "Jingdong Sun",
      "Hanbing Liu",
      "Wei Liu",
      "Bin Luo",
      "Yifeng Geng",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.16580",
    "title": "TFDet: Target-aware Fusion for RGB-T Pedestrian Detection",
    "abstract": " Title: TFDet: Target-aware Fusion for RGB-T Pedestrian Detection ",
    "url": "https://arxiv.org/abs/2305.16580",
    "authors": [
      "Xue Zhang",
      "Xiaohan Zhang",
      "Zehua Sheng",
      "Hui-Liang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01102",
    "title": "LLMatic: Neural Architecture Search via Large Language Models and  Quality Diversity Optimization",
    "abstract": " Title: LLMatic: Neural Architecture Search via Large Language Models and  Quality Diversity Optimization ",
    "url": "https://arxiv.org/abs/2306.01102",
    "authors": [
      "Muhammad U. Nasir",
      "Sam Earle",
      "Julian Togelius",
      "Steven James",
      "Christopher Cleghorn"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06044",
    "title": "GANeRF: Leveraging Discriminators to Optimize Neural Radiance Fields",
    "abstract": " Comments: SIGGRAPH Asia 2023, project page: this https URL , video: this https URL ",
    "url": "https://arxiv.org/abs/2306.06044",
    "authors": [
      "Barbara Roessle",
      "Norman M\u00fcller",
      "Lorenzo Porzi",
      "Samuel Rota Bul\u00f2",
      "Peter Kontschieder",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.09273",
    "title": "Your Room is not Private: Gradient Inversion Attack on Reinforcement  Learning",
    "abstract": " Comments: 7 pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2306.09273",
    "authors": [
      "Miao Li",
      "Wenhao Ding",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10336",
    "title": "Fair Causal Feature Selection",
    "abstract": " Title: Fair Causal Feature Selection ",
    "url": "https://arxiv.org/abs/2306.10336",
    "authors": [
      "Zhaolong Ling",
      "Enqi Xu",
      "Peng Zhou",
      "Liang Du",
      "Kui Yu",
      "Xindong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10472",
    "title": "Towards Large-Scale Incremental Dense Mapping using Robot-centric  Implicit Neural Representation",
    "abstract": " Title: Towards Large-Scale Incremental Dense Mapping using Robot-centric  Implicit Neural Representation ",
    "url": "https://arxiv.org/abs/2306.10472",
    "authors": [
      "Jianheng Liu",
      "Haoyao Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.13319",
    "title": "A SAT Solver and Computer Algebra Attack on the Minimum Kochen-Specker  Problem",
    "abstract": " Title: A SAT Solver and Computer Algebra Attack on the Minimum Kochen-Specker  Problem ",
    "url": "https://arxiv.org/abs/2306.13319",
    "authors": [
      "Zhengyu Li",
      "Curtis Bright",
      "Vijay Ganesh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2306.17181",
    "title": "Unsupervised Text Embedding Space Generation Using Generative  Adversarial Networks for Text Synthesis",
    "abstract": " Title: Unsupervised Text Embedding Space Generation Using Generative  Adversarial Networks for Text Synthesis ",
    "url": "https://arxiv.org/abs/2306.17181",
    "authors": [
      "Jun-Min Lee",
      "Tae-Bin Ha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.17727",
    "title": "Improved NL2SQL based on Multi-layer Expert Network",
    "abstract": " Comments: our paper need to be repaired ",
    "url": "https://arxiv.org/abs/2306.17727",
    "authors": [
      "Chenduo Hao",
      "Xu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.01226",
    "title": "vONTSS: vMF based semi-supervised neural topic modeling with optimal  transport",
    "abstract": " Comments: 24 pages, 12 figures, ACL findings 2023 ",
    "url": "https://arxiv.org/abs/2307.01226",
    "authors": [
      "Weijie Xu",
      "Xiaoyu Jiang",
      "Srinivasan H. Sengamedu",
      "Francis Iannacci",
      "Jinjin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2307.02148",
    "title": "Compound Attention and Neighbor Matching Network for Multi-contrast MRI  Super-resolution",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2307.02148",
    "authors": [
      "Wenxuan Chen",
      "Sirui Wu",
      "Shuai Wang",
      "Zhongsen Li",
      "Jia Yang",
      "Huifeng Yao",
      "Xiaolei Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.06101",
    "title": "Air Bumper: A Collision Detection and Reaction Framework for Autonomous  MAV Navigation",
    "abstract": " Title: Air Bumper: A Collision Detection and Reaction Framework for Autonomous  MAV Navigation ",
    "url": "https://arxiv.org/abs/2307.06101",
    "authors": [
      "Ruoyu Wang",
      "Zixuan Guo",
      "Yizhou Chen",
      "Xinyi Wang",
      "Ben M. Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.09762",
    "title": "Reinforcing POD-based model reduction techniques in reaction-diffusion  complex networks using stochastic filtering and pattern recognition",
    "abstract": " Comments: 19 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2307.09762",
    "authors": [
      "Abhishek Ajayakumar",
      "Soumyendu Raha"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.10249",
    "title": "RCM-Fusion: Radar-Camera Multi-Level Fusion for 3D Object Detection",
    "abstract": " Comments: 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2307.10249",
    "authors": [
      "Jisong Kim",
      "Minjae Seong",
      "Geonho Bang",
      "Dongsuk Kum",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10487",
    "title": "Attacking by Aligning: Clean-Label Backdoor Attacks on Object Detection",
    "abstract": " Title: Attacking by Aligning: Clean-Label Backdoor Attacks on Object Detection ",
    "url": "https://arxiv.org/abs/2307.10487",
    "authors": [
      "Yize Cheng",
      "Wenbin Hu",
      "Minhao Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12917",
    "title": "Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard  Skeleton Mining for Unsupervised Person Re-Identification",
    "abstract": " Comments: Accepted by International Journal of Computer Vision (IJCV). Codes are available at this https URL The Appendix A for Proof (6 pages) and Appendix B for Experiments (13 pages) are included in the version [v3] at arXiv:2307.12917 ",
    "url": "https://arxiv.org/abs/2307.12917",
    "authors": [
      "Haocong Rao",
      "Cyril Leung",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.13529",
    "title": "Re-mine, Learn and Reason: Exploring the Cross-modal Semantic  Correlations for Language-guided HOI detection",
    "abstract": " Comments: ICCV2023 ",
    "url": "https://arxiv.org/abs/2307.13529",
    "authors": [
      "Yichao Cao",
      "Qingfei Tang",
      "Feng Yang",
      "Xiu Su",
      "Shan You",
      "Xiaobo Lu",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.13885",
    "title": "Efficient Estimation of the Local Robustness of Machine Learning Models",
    "abstract": " Title: Efficient Estimation of the Local Robustness of Machine Learning Models ",
    "url": "https://arxiv.org/abs/2307.13885",
    "authors": [
      "Tessa Han",
      "Suraj Srinivas",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14385",
    "title": "Mental-LLM: Leveraging Large Language Models for Mental Health  Prediction via Online Text Data",
    "abstract": " Title: Mental-LLM: Leveraging Large Language Models for Mental Health  Prediction via Online Text Data ",
    "url": "https://arxiv.org/abs/2307.14385",
    "authors": [
      "Xuhai Xu",
      "Bingsheng Yao",
      "Yuanzhe Dong",
      "Saadia Gabriel",
      "Hong Yu",
      "James Hendler",
      "Marzyeh Ghassemi",
      "Anind K. Dey",
      "Dakuo Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.14439",
    "title": "Fixed Integral Neural Networks",
    "abstract": " Title: Fixed Integral Neural Networks ",
    "url": "https://arxiv.org/abs/2307.14439",
    "authors": [
      "Ryan Kortvelesy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15079",
    "title": "Heterogeneous Vulnerability of Zero-Carbon Power Grids under  Climate-Technological Changes",
    "abstract": " Comments: This work will be submitted to Nature Energy for possible publication. The structure of sections has been tailored to meet the formatting requirements of Nature Energy. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2307.15079",
    "authors": [
      "M.Vivienne Liu",
      "Vivek Srikrishnan",
      "Kenji Doering",
      "Elnaz Kabir",
      "Scott Steinschneider",
      "C. Lindsay Anderson"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.15971",
    "title": "You Can Backdoor Personalized Federated Learning",
    "abstract": " Comments: Submitted to TKDD ",
    "url": "https://arxiv.org/abs/2307.15971",
    "authors": [
      "Tiandi Ye",
      "Cen Chen",
      "Yinggui Wang",
      "Xiang Li",
      "Ming Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.00090",
    "title": "Visual Geo-localization with Self-supervised Representation Learning",
    "abstract": " Comments: 15 pages (including appendix, references), 2 figures, 9 tables (5 tables in appendix) ",
    "url": "https://arxiv.org/abs/2308.00090",
    "authors": [
      "Jiuhong Xiao",
      "Gao Zhu",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.02663",
    "title": "On RAC Drawings of Graphs with Two Bends per Edge",
    "abstract": " Comments: Presented at the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023) ",
    "url": "https://arxiv.org/abs/2308.02663",
    "authors": [
      "Csaba D. T\u00f3th"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2308.04501",
    "title": "Investigation of Compressor Cascade Flow Using Physics- Informed Neural  Networks with Adaptive Learning Strategy",
    "abstract": " Title: Investigation of Compressor Cascade Flow Using Physics- Informed Neural  Networks with Adaptive Learning Strategy ",
    "url": "https://arxiv.org/abs/2308.04501",
    "authors": [
      "Zhihui Li",
      "Francesco Montomoli",
      "Sanjiv Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2308.04992",
    "title": "AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities",
    "abstract": " Comments: Accepted by CIKM 2023 ",
    "url": "https://arxiv.org/abs/2308.04992",
    "authors": [
      "Jingdan Zhang",
      "Jiaan Wang",
      "Xiaodan Wang",
      "Zhixu Li",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05701",
    "title": "Exploring the Potential of World Models for Anomaly Detection in  Autonomous Driving",
    "abstract": " Comments: Accepted for publication at SSCI 2023 ",
    "url": "https://arxiv.org/abs/2308.05701",
    "authors": [
      "Daniel Bogdoll",
      "Lukas Bosch",
      "Tim Joseph",
      "Helen Gremmelmaier",
      "Yitian Yang",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.06213",
    "title": "Change Point Detection with Conceptors",
    "abstract": " Title: Change Point Detection with Conceptors ",
    "url": "https://arxiv.org/abs/2308.06213",
    "authors": [
      "Noah D. Gade",
      "Jordan Rodu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2308.09899",
    "title": "Towards a High-Performance Object Detector: Insights from Drone  Detection Using ViT and CNN-based Deep Learning Models",
    "abstract": " Comments: 7 pages, 23 figures, IEEE Xplore, 2023 International Conference on Computer Vision and Robotics Science ",
    "url": "https://arxiv.org/abs/2308.09899",
    "authors": [
      "Junyang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.11127",
    "title": "How Expressive are Graph Neural Networks in Recommendation?",
    "abstract": " Comments: 32nd ACM International Conference on Information and Knowledge Management (CIKM) 2023 ",
    "url": "https://arxiv.org/abs/2308.11127",
    "authors": [
      "Xuheng Cai",
      "Lianghao Xia",
      "Xubin Ren",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14711",
    "title": "Fast Feedforward Networks",
    "abstract": " Comments: 12 pages, 6 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2308.14711",
    "authors": [
      "Peter Belcak",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2308.15568",
    "title": "Over-Squashing in Graph Neural Networks: A Comprehensive survey",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2308.15568",
    "authors": [
      "Singh Akansha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.00236",
    "title": "Image Hijacks: Adversarial Images can Control Generative Models at  Runtime",
    "abstract": " Comments: Project page at this https URL ",
    "url": "https://arxiv.org/abs/2309.00236",
    "authors": [
      "Luke Bailey",
      "Euan Ong",
      "Stuart Russell",
      "Scott Emmons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.01036",
    "title": "SEPAL: Spatial Gene Expression Prediction from Local Graphs",
    "abstract": " Title: SEPAL: Spatial Gene Expression Prediction from Local Graphs ",
    "url": "https://arxiv.org/abs/2309.01036",
    "authors": [
      "Gabriel Mejia",
      "Paula C\u00e1rdenas",
      "Daniela Ruiz",
      "Angela Castillo",
      "Pablo Arbel\u00e1ez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03848",
    "title": "Bipartite Friends and Strangers Walking on Bipartite Graphs",
    "abstract": " Comments: 16 pages, 8 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2309.03848",
    "authors": [
      "Ryan Jeong"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2309.05833",
    "title": "PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation  with GPT-4 in Cloud Incident Root Cause Analysis",
    "abstract": " Title: PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation  with GPT-4 in Cloud Incident Root Cause Analysis ",
    "url": "https://arxiv.org/abs/2309.05833",
    "authors": [
      "Dylan Zhang",
      "Xuchao Zhang",
      "Chetan Bansal",
      "Pedro Las-Casas",
      "Rodrigo Fonseca",
      "Saravan Rajmohan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.05904",
    "title": "Enhancing Representation in Radiography-Reports Foundation Model: A  Granular Alignment Algorithm Using Masked Contrastive Learning",
    "abstract": " Title: Enhancing Representation in Radiography-Reports Foundation Model: A  Granular Alignment Algorithm Using Masked Contrastive Learning ",
    "url": "https://arxiv.org/abs/2309.05904",
    "authors": [
      "Weijian Huang",
      "Cheng Li",
      "Hao Yang",
      "Jiarun Liu",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.06192",
    "title": "Improving and Evaluating the Detection of Fragmentation in News  Recommendations with the Clustering of News Story Chains",
    "abstract": " Comments: Cite published version: Polimeno et. al., Improving and Evaluating the Detection of Fragmentation in News Recommendations with the Clustering of News Story Chains, NORMalize 2023: The First Workshop on the Normative Design and Evaluation of Recommender Systems, September 19, 2023, co-located with the ACM Conference on Recommender Systems 2023 (RecSys 2023), Singapore ",
    "url": "https://arxiv.org/abs/2309.06192",
    "authors": [
      "Alessandra Polimeno",
      "Myrthe Reuver",
      "Sanne Vrijenhoek",
      "Antske Fokkens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.06584",
    "title": "Explainable Graph Neural Network for Alzheimer's Disease And Related  Dementias Risk Prediction",
    "abstract": " Title: Explainable Graph Neural Network for Alzheimer's Disease And Related  Dementias Risk Prediction ",
    "url": "https://arxiv.org/abs/2309.06584",
    "authors": [
      "Xinyue Hu",
      "Zenan Sun",
      "Yi Nian",
      "Yifang Dang",
      "Fang Li",
      "Jingna Feng",
      "Evan Yu",
      "Cui Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.06655",
    "title": "Out of Distribution Detection via Domain-Informed Gaussian Process State  Space Models",
    "abstract": " Comments: 7 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2309.06655",
    "authors": [
      "Alonso Marco",
      "Elias Morley",
      "Claire J. Tomlin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.06825",
    "title": "Topology-inspired Cross-domain Network for Developmental Cervical  Stenosis Quantification",
    "abstract": " Comments: We have discovered that some authors' contributions have been overlooked. We need to spend some time confirming whether the authors adhere to the paper's authorship guidelines and whether their authorship order complies with the standards. After discussion with all co-authors, we decide to withdraw this paper ",
    "url": "https://arxiv.org/abs/2309.06825",
    "authors": [
      "Zhenxi Zhang",
      "Yanyang Wang",
      "Yao Wu",
      "Weifei Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08019",
    "title": "CRYPTO-MINE: Cryptanalysis via Mutual Information Neural Estimation",
    "abstract": " Title: CRYPTO-MINE: Cryptanalysis via Mutual Information Neural Estimation ",
    "url": "https://arxiv.org/abs/2309.08019",
    "authors": [
      "Benjamin D. Kim",
      "Vipindev Adat Vasudevan",
      "Jongchan Woo",
      "Alejandro Cohen",
      "Rafael G. L. D'Oliveira",
      "Thomas Stahlbuhk",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  }
]