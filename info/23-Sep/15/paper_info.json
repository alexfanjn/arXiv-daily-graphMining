[
  {
    "id": "arXiv:2309.07139",
    "title": "VertiSync: A Traffic Management Policy with Maximum Throughput for  On-Demand Urban Air Mobility Networks",
    "abstract": "Urban Air Mobility (UAM) offers a solution to current traffic congestion by providing on-demand air mobility in urban areas. Effective traffic management is crucial for efficient operation of UAM systems, especially for high-demand scenarios. In this paper, we present VertiSync, a centralized traffic management policy for on-demand UAM networks. VertiSync schedules the aircraft for either servicing trip requests or rebalancing in the network subject to aircraft safety margins and separation requirements during takeoff and landing. We characterize the system-level throughput of VertiSync, which determines the demand threshold at which travel times transition from being stabilized to being increasing over time. We show that the proposed policy is able to maximize the throughput for sufficiently large fleet sizes. We demonstrate the performance of VertiSync through a case study for the city of Los Angeles. We show that VertiSync significantly reduces travel times compared to a first-come first-serve scheduling policy. ",
    "url": "https://arxiv.org/abs/2309.07139",
    "authors": [
      "Milad Pooladsanj",
      "Ketan Savla"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2309.07153",
    "title": "Finding Influencers in Complex Networks: An Effective Deep Reinforcement  Learning Approach",
    "abstract": "Maximizing influences in complex networks is a practically important but computationally challenging task for social network analysis, due to its NP- hard nature. Most current approximation or heuristic methods either require tremendous human design efforts or achieve unsatisfying balances between effectiveness and efficiency. Recent machine learning attempts only focus on speed but lack performance enhancement. In this paper, different from previous attempts, we propose an effective deep reinforcement learning model that achieves superior performances over traditional best influence maximization algorithms. Specifically, we design an end-to-end learning framework that combines graph neural network as the encoder and reinforcement learning as the decoder, named DREIM. Trough extensive training on small synthetic graphs, DREIM outperforms the state-of-the-art baseline methods on very large synthetic and real-world networks on solution quality, and we also empirically show its linear scalability with regard to the network size, which demonstrates its superiority in solving this problem. ",
    "url": "https://arxiv.org/abs/2309.07153",
    "authors": [
      "Changan Liu",
      "Changjun Fan",
      "Zhongzhi Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07166",
    "title": "Proceedings of the 31st International Symposium on Graph Drawing and  Network Visualization (GD 2023)",
    "abstract": "This is the arXiv index for the electronic proceedings of GD 2023, which contains the peer-reviewed and revised accepted papers with an optional appendix. Proceedings (without appendices) are also to be published by Springer in the Lecture Notes in Computer Science series. ",
    "url": "https://arxiv.org/abs/2309.07166",
    "authors": [
      "Michael A. Bekos",
      "Markus Chimani"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.07187",
    "title": "Multi-step prediction of chlorophyll concentration based on Adaptive  Graph-Temporal Convolutional Network with Series Decomposition",
    "abstract": "Chlorophyll concentration can well reflect the nutritional status and algal blooms of water bodies, and is an important indicator for evaluating water quality. The prediction of chlorophyll concentration change trend is of great significance to environmental protection and aquaculture. However, there is a complex and indistinguishable nonlinear relationship between many factors affecting chlorophyll concentration. In order to effectively mine the nonlinear features contained in the data. This paper proposes a time-series decomposition adaptive graph-time convolutional network ( AGTCNSD ) prediction model. Firstly, the original sequence is decomposed into trend component and periodic component by moving average method. Secondly, based on the graph convolutional neural network, the water quality parameter data is modeled, and a parameter embedding matrix is defined. The idea of matrix decomposition is used to assign weight parameters to each node. The adaptive graph convolution learns the relationship between different water quality parameters, updates the state information of each parameter, and improves the learning ability of the update relationship between nodes. Finally, time dependence is captured by time convolution to achieve multi-step prediction of chlorophyll concentration. The validity of the model is verified by the water quality data of the coastal city Beihai. The results show that the prediction effect of this method is better than other methods. It can be used as a scientific resource for environmental management decision-making. ",
    "url": "https://arxiv.org/abs/2309.07187",
    "authors": [
      "Ying Chen",
      "Xiao Li",
      "Hongbo Zhang",
      "Wenyang Song",
      "Chongxuan Xv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07196",
    "title": "Attention-based Dynamic Graph Convolutional Recurrent Neural Network for  Traffic Flow Prediction in Highway Transportation",
    "abstract": "As one of the important tools for spatial feature extraction, graph convolution has been applied in a wide range of fields such as traffic flow prediction. However, current popular works of graph convolution cannot guarantee spatio-temporal consistency in a long period. The ignorance of correlational dynamics, convolutional locality and temporal comprehensiveness would limit predictive accuracy. In this paper, a novel Attention-based Dynamic Graph Convolutional Recurrent Neural Network (ADGCRNN) is proposed to improve traffic flow prediction in highway transportation. Three temporal resolutions of data sequence are effectively integrated by self-attention to extract characteristics; multi-dynamic graphs and their weights are dynamically created to compliantly combine the varying characteristics; a dedicated gated kernel emphasizing highly relative nodes is introduced on these complete graphs to reduce overfitting for graph convolution operations. Experiments on two public datasets show our work better than state-of-the-art baselines, and case studies of a real Web system prove practical benefit in highway transportation. ",
    "url": "https://arxiv.org/abs/2309.07196",
    "authors": [
      "Tianpu Zhang",
      "Weilong Ding",
      "Mengda Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2309.07197",
    "title": "Mitigating Adversarial Attacks in Federated Learning with Trusted  Execution Environments",
    "abstract": "The main premise of federated learning (FL) is that machine learning model updates are computed locally to preserve user data privacy. This approach avoids by design user data to ever leave the perimeter of their device. Once the updates aggregated, the model is broadcast to all nodes in the federation. However, without proper defenses, compromised nodes can probe the model inside their local memory in search for adversarial examples, which can lead to dangerous real-world scenarios. For instance, in image-based applications, adversarial examples consist of images slightly perturbed to the human eye getting misclassified by the local model. These adversarial images are then later presented to a victim node's counterpart model to replay the attack. Typical examples harness dissemination strategies such as altered traffic signs (patch attacks) no longer recognized by autonomous vehicles or seemingly unaltered samples that poison the local dataset of the FL scheme to undermine its robustness. Pelta is a novel shielding mechanism leveraging Trusted Execution Environments (TEEs) that reduce the ability of attackers to craft adversarial samples. Pelta masks inside the TEE the first part of the back-propagation chain rule, typically exploited by attackers to craft the malicious samples. We evaluate Pelta on state-of-the-art accurate models using three well-established datasets: CIFAR-10, CIFAR-100 and ImageNet. We show the effectiveness of Pelta in mitigating six white-box state-of-the-art adversarial attacks, such as Projected Gradient Descent, Momentum Iterative Method, Auto Projected Gradient Descent, the Carlini & Wagner attack. In particular, Pelta constitutes the first attempt at defending an ensemble model against the Self-Attention Gradient attack to the best of our knowledge. Our code is available to the research community at https://github.com/queyrusi/Pelta. ",
    "url": "https://arxiv.org/abs/2309.07197",
    "authors": [
      "Simon Queyrut",
      "Valerio Schiavoni",
      "Pascal Felber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.07200",
    "title": "Latent Representation and Simulation of Markov Processes via Time-Lagged  Information Bottleneck",
    "abstract": "Markov processes are widely used mathematical models for describing dynamic systems in various fields. However, accurately simulating large-scale systems at long time scales is computationally expensive due to the short time steps required for accurate integration. In this paper, we introduce an inference process that maps complex systems into a simplified representational space and models large jumps in time. To achieve this, we propose Time-lagged Information Bottleneck (T-IB), a principled objective rooted in information theory, which aims to capture relevant temporal features while discarding high-frequency information to simplify the simulation task and minimize the inference error. Our experiments demonstrate that T-IB learns information-optimal representations for accurately modeling the statistical properties and dynamics of the original process at a selected time lag, outperforming existing time-lagged dimensionality reduction methods. ",
    "url": "https://arxiv.org/abs/2309.07200",
    "authors": [
      "Marco Federici",
      "Patrick Forr\u00e9",
      "Ryota Tomioka",
      "Bastiaan S. Veeling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.07289",
    "title": "User Training with Error Augmentation for Electromyogram-based Gesture  Classification",
    "abstract": "We designed and tested a system for real-time control of a user interface by extracting surface electromyographic (sEMG) activity from eight electrodes in a wrist-band configuration. sEMG data were streamed into a machine-learning algorithm that classified hand gestures in real-time. After an initial model calibration, participants were presented with one of three types of feedback during a human-learning stage: veridical feedback, in which predicted probabilities from the gesture classification algorithm were displayed without alteration, modified feedback, in which we applied a hidden augmentation of error to these probabilities, and no feedback. User performance was then evaluated in a series of minigames, in which subjects were required to use eight gestures to manipulate their game avatar to complete a task. Experimental results indicated that, relative to baseline, the modified feedback condition led to significantly improved accuracy and improved gesture class separation. These findings suggest that real-time feedback in a gamified user interface with manipulation of feedback may enable intuitive, rapid, and accurate task acquisition for sEMG-based gesture recognition applications. ",
    "url": "https://arxiv.org/abs/2309.07289",
    "authors": [
      "Yunus Bicer",
      "Niklas Smedemark-Margulies",
      "Basak Celik",
      "Elifnur Sunger",
      "Ryan Orendorff",
      "Stephanie Naufel",
      "Tales Imbiriba",
      "Deniz Erdo{\u011f}mu{\u015f}",
      "Eugene Tunik",
      "Mathew Yarossi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.07297",
    "title": "Multi-Modal Hybrid Learning and Sequential Training for RGB-T Saliency  Detection",
    "abstract": "RGB-T saliency detection has emerged as an important computer vision task, identifying conspicuous objects in challenging scenes such as dark environments. However, existing methods neglect the characteristics of cross-modal features and rely solely on network structures to fuse RGB and thermal features. To address this, we first propose a Multi-Modal Hybrid loss (MMHL) that comprises supervised and self-supervised loss functions. The supervised loss component of MMHL distinctly utilizes semantic features from different modalities, while the self-supervised loss component reduces the distance between RGB and thermal features. We further consider both spatial and channel information during feature fusion and propose the Hybrid Fusion Module to effectively fuse RGB and thermal features. Lastly, instead of jointly training the network with cross-modal features, we implement a sequential training strategy which performs training only on RGB images in the first stage and then learns cross-modal features in the second stage. This training strategy improves saliency detection performance without computational overhead. Results from performance evaluation and ablation studies demonstrate the superior performance achieved by the proposed method compared with the existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2309.07297",
    "authors": [
      "Guangyu Ren",
      "Jitesh Joshi",
      "Youngjun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07322",
    "title": "$\\texttt{NePhi}$: Neural Deformation Fields for Approximately  Diffeomorphic Medical Image Registration",
    "abstract": "This work proposes $\\texttt{NePhi}$, a neural deformation model which results in approximately diffeomorphic transformations. In contrast to the predominant voxel-based approaches, $\\texttt{NePhi}$ represents deformations functionally which allows for memory-efficient training and inference. This is of particular importance for large volumetric registrations. Further, while medical image registration approaches representing transformation maps via multi-layer perceptrons have been proposed, $\\texttt{NePhi}$ facilitates both pairwise optimization-based registration $\\textit{as well as}$ learning-based registration via predicted or optimized global and local latent codes. Lastly, as deformation regularity is a highly desirable property for most medical image registration tasks, $\\texttt{NePhi}$ makes use of gradient inverse consistency regularization which empirically results in approximately diffeomorphic transformations. We show the performance of $\\texttt{NePhi}$ on two 2D synthetic datasets as well as on real 3D lung registration. Our results show that $\\texttt{NePhi}$ can achieve similar accuracies as voxel-based representations in a single-resolution registration setting while using less memory and allowing for faster instance-optimization. ",
    "url": "https://arxiv.org/abs/2309.07322",
    "authors": [
      "Lin Tian",
      "Soumyadip Sengupta",
      "Hastings Greer",
      "Ra\u00fal San Jos\u00e9 Est\u00e9par",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07324",
    "title": "A Simple Non-Deterministic Approach Can Adapt to Complex Unpredictable  5G Cellular Networks",
    "abstract": "5G cellular networks are envisioned to support a wide range of emerging delay-oriented services with different delay requirements (e.g., 20ms for VR/AR, 40ms for cloud gaming, and 100ms for immersive video streaming). However, due to the highly variable and unpredictable nature of 5G access links, existing end-to-end (e2e) congestion control (CC) schemes perform poorly for them. In this paper, we demonstrate that properly blending non-deterministic exploration techniques with straightforward proactive and reactive measures is sufficient to design a simple yet effective e2e CC scheme for 5G networks that can: (1) achieve high controllable performance, and (2) possess provable properties. To that end, we designed Reminis and through extensive experiments on emulated and real-world 5G networks, show the performance benefits of it compared with different CC schemes. For instance, averaged over 60 different 5G cellular links on the Standalone (SA) scenarios, compared with a recent design by Google (BBR2), Reminis can achieve 2.2x lower 95th percentile delay while having the same link utilization. ",
    "url": "https://arxiv.org/abs/2309.07324",
    "authors": [
      "Parsa Pazhooheshy",
      "Soheil Abbasloo",
      "Yashar Ganjali"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.07332",
    "title": "Reliability-based cleaning of noisy training labels with inductive  conformal prediction in multi-modal biomedical data mining",
    "abstract": "Accurately labeling biomedical data presents a challenge. Traditional semi-supervised learning methods often under-utilize available unlabeled data. To address this, we propose a novel reliability-based training data cleaning method employing inductive conformal prediction (ICP). This method capitalizes on a small set of accurately labeled training data and leverages ICP-calculated reliability metrics to rectify mislabeled data and outliers within vast quantities of noisy training data. The efficacy of the method is validated across three classification tasks within distinct modalities: filtering drug-induced-liver-injury (DILI) literature with title and abstract, predicting ICU admission of COVID-19 patients through CT radiomics and electronic health records, and subtyping breast cancer using RNA-sequencing data. Varying levels of noise to the training labels were introduced through label permutation. Results show significant enhancements in classification performance: accuracy enhancement in 86 out of 96 DILI experiments (up to 11.4%), AUROC and AUPRC enhancements in all 48 COVID-19 experiments (up to 23.8% and 69.8%), and accuracy and macro-average F1 score improvements in 47 out of 48 RNA-sequencing experiments (up to 74.6% and 89.0%). Our method offers the potential to substantially boost classification performance in multi-modal biomedical machine learning tasks. Importantly, it accomplishes this without necessitating an excessive volume of meticulously curated training data. ",
    "url": "https://arxiv.org/abs/2309.07332",
    "authors": [
      "Xianghao Zhan",
      "Qinmei Xu",
      "Yuanning Zheng",
      "Guangming Lu",
      "Olivier Gevaert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.07360",
    "title": "Haptic search with the Smart Suction Cup on adversarial objects",
    "abstract": "Suction cups are an important gripper type in industrial robot applications, and prior literature focuses on using vision-based planners to improve grasping success in these tasks. Vision-based planners can fail due to adversarial objects or lose generalizability for unseen scenarios, without retraining learned algorithms. We propose haptic exploration to improve suction cup grasping when visual grasp planners fail. We present the Smart Suction Cup, an end-effector that utilizes internal flow measurements for tactile sensing. We show that model-based haptic search methods, guided by these flow measurements, improve grasping success by up to 2.5x as compared with using only a vision planner during a bin-picking task. In characterizing the Smart Suction Cup on both geometric edges and curves, we find that flow rate can accurately predict the ideal motion direction even with large postural errors. The Smart Suction Cup includes no electronics on the cup itself, such that the design is easy to fabricate and haptic exploration does not damage the sensor. This work motivates the use of suction cups with autonomous haptic search capabilities in especially adversarial scenarios. ",
    "url": "https://arxiv.org/abs/2309.07360",
    "authors": [
      "Jungpyo Lee",
      "Sebastian D. Lee",
      "Tae Myung Huh",
      "Hannah S. Stuart"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.07374",
    "title": "Beta quantile regression for robust estimation of uncertainty in the  presence of outliers",
    "abstract": "Quantile Regression (QR) can be used to estimate aleatoric uncertainty in deep neural networks and can generate prediction intervals. Quantifying uncertainty is particularly important in critical applications such as clinical diagnosis, where a realistic assessment of uncertainty is essential in determining disease status and planning the appropriate treatment. The most common application of quantile regression models is in cases where the parametric likelihood cannot be specified. Although quantile regression is quite robust to outlier response observations, it can be sensitive to outlier covariate observations (features). Outlier features can compromise the performance of deep learning regression problems such as style translation, image reconstruction, and deep anomaly detection, potentially leading to misleading conclusions. To address this problem, we propose a robust solution for quantile regression that incorporates concepts from robust divergence. We compare the performance of our proposed method with (i) least trimmed quantile regression and (ii) robust regression based on the regularization of case-specific parameters in a simple real dataset in the presence of outlier. These methods have not been applied in a deep learning framework. We also demonstrate the applicability of the proposed method by applying it to a medical imaging translation task using diffusion models. ",
    "url": "https://arxiv.org/abs/2309.07374",
    "authors": [
      "Haleh Akrami",
      "Omar Zamzam",
      "Anand Joshi",
      "Sergul Aydore",
      "Richard Leahy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07380",
    "title": "Domain-adaptive Graph Attention-supervised Network for Cross-network  Edge Classification",
    "abstract": "Graph neural networks (GNNs) have shown great ability in modeling graphs, however, their performance would significantly degrade when there are noisy edges connecting nodes from different classes. To alleviate negative effect of noisy edges on neighborhood aggregation, some recent GNNs propose to predict the label agreement between node pairs within a single network. However, predicting the label agreement of edges across different networks has not been investigated yet. Our work makes the pioneering attempt to study a novel problem of cross-network homophilous and heterophilous edge classification (CNHHEC), and proposes a novel domain-adaptive graph attention-supervised network (DGASN) to effectively tackle the CNHHEC problem. Firstly, DGASN adopts multi-head GAT as the GNN encoder, which jointly trains node embeddings and edge embeddings via the node classification and edge classification losses. As a result, label-discriminative embeddings can be obtained to distinguish homophilous edges from heterophilous edges. In addition, DGASN applies direct supervision on graph attention learning based on the observed edge labels from the source network, thus lowering the negative effects of heterophilous edges while enlarging the positive effects of homophilous edges during neighborhood aggregation. To facilitate knowledge transfer across networks, DGASN employs adversarial domain adaptation to mitigate domain divergence. Extensive experiments on real-world benchmark datasets demonstrate that the proposed DGASN achieves the state-of-the-art performance in CNHHEC. ",
    "url": "https://arxiv.org/abs/2309.07380",
    "authors": [
      "Xiao Shen",
      "Mengqiu Shao",
      "Shirui Pan",
      "Laurence T. Yang",
      "Xi Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.07381",
    "title": "International Competition on Graph Counting Algorithms 2023",
    "abstract": "This paper reports on the details of the International Competition on Graph Counting Algorithms (ICGCA) held in 2023. The graph counting problem is to count the subgraphs satisfying specified constraints on a given graph. The problem belongs to #P-complete, a computationally tough class. Since many essential systems in modern society, e.g., infrastructure networks, are often represented as graphs, graph counting algorithms are a key technology to efficiently scan all the subgraphs representing the feasible states of the system. In the ICGCA, contestants were asked to count the paths on a graph under a length constraint. The benchmark set included 150 challenging instances, emphasizing graphs resembling infrastructure networks. Eleven solvers were submitted and ranked by the number of benchmarks correctly solved within a time limit. The winning solver, TLDC, was designed based on three fundamental approaches: backtracking search, dynamic programming, and model counting or #SAT (a counting version of Boolean satisfiability). Detailed analyses show that each approach has its own strengths, and one approach is unlikely to dominate the others. The codes and papers of the participating solvers are available: https://afsa.jp/icgca/. ",
    "url": "https://arxiv.org/abs/2309.07381",
    "authors": [
      "Takeru Inoue",
      "Norihito Yasuda",
      "Hidetomo Nabeshima",
      "Masaaki Nishino",
      "Shuhei Denzumi",
      "Shin-ichi Minato"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.07388",
    "title": "On Autonomous Agents in a Cyber Defence Environment",
    "abstract": "Autonomous Cyber Defence is required to respond to high-tempo cyber-attacks. To facilitate the research in this challenging area, we explore the utility of the autonomous cyber operation environments presented as part of the Cyber Autonomy Gym for Experimentation (CAGE) Challenges, with a specific focus on CAGE Challenge 2. CAGE Challenge 2 required a defensive Blue agent to defend a network from an attacking Red agent. We provide a detailed description of the this challenge and describe the approaches taken by challenge participants. From the submitted agents, we identify four classes of algorithms, namely, Single- Agent Deep Reinforcement Learning (DRL), Hierarchical DRL, Ensembles, and Non-DRL approaches. Of these classes, we found that the hierarchical DRL approach was the most capable of learning an effective cyber defensive strategy. Our analysis of the agent policies identified that different algorithms within the same class produced diverse strategies and that the strategy used by the defensive Blue agent varied depending on the strategy used by the offensive Red agent. We conclude that DRL algorithms are a suitable candidate for autonomous cyber defence applications. ",
    "url": "https://arxiv.org/abs/2309.07388",
    "authors": [
      "Mitchell Kiely",
      "David Bowman",
      "Maxwell Standen",
      "Christopher Moir"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.07390",
    "title": "Unleashing the Power of Depth and Pose Estimation Neural Networks by  Designing Compatible Endoscopic Images",
    "abstract": "Deep learning models have witnessed depth and pose estimation framework on unannotated datasets as a effective pathway to succeed in endoscopic navigation. Most current techniques are dedicated to developing more advanced neural networks to improve the accuracy. However, existing methods ignore the special properties of endoscopic images, resulting in an inability to fully unleash the power of neural networks. In this study, we conduct a detail analysis of the properties of endoscopic images and improve the compatibility of images and neural networks, to unleash the power of current neural networks. First, we introcude the Mask Image Modelling (MIM) module, which inputs partial image information instead of complete image information, allowing the network to recover global information from partial pixel information. This enhances the network' s ability to perceive global information and alleviates the phenomenon of local overfitting in convolutional neural networks due to local artifacts. Second, we propose a lightweight neural network to enhance the endoscopic images, to explicitly improve the compatibility between images and neural networks. Extensive experiments are conducted on the three public datasets and one inhouse dataset, and the proposed modules improve baselines by a large margin. Furthermore, the enhanced images we proposed, which have higher network compatibility, can serve as an effective data augmentation method and they are able to extract more stable feature points in traditional feature point matching tasks and achieve outstanding performance. ",
    "url": "https://arxiv.org/abs/2309.07390",
    "authors": [
      "Junyang Wu",
      "Yun Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07391",
    "title": "EnCodecMAE: Leveraging neural codecs for universal audio representation  learning",
    "abstract": "The goal of universal audio representation learning is to obtain foundational models that can be used for a variety of downstream tasks involving speech, music or environmental sounds. To approach this problem, methods inspired by self-supervised models from NLP, like BERT, are often used and adapted to audio. These models rely on the discrete nature of text, hence adopting this type of approach for audio processing requires either a change in the learning objective or mapping the audio signal to a set of discrete classes. In this work, we explore the use of EnCodec, a neural audio codec, to generate discrete targets for learning an universal audio model based on a masked autoencoder (MAE). We evaluate this approach, which we call EncodecMAE, on a wide range of audio tasks spanning speech, music and environmental sounds, achieving performances comparable or better than leading audio representation models. ",
    "url": "https://arxiv.org/abs/2309.07391",
    "authors": [
      "Leonardo Pepino",
      "Pablo Riera",
      "Luciana Ferrer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07394",
    "title": "Nucleus-aware Self-supervised Pretraining Using Unpaired Image-to-image  Translation for Histopathology Images",
    "abstract": "Self-supervised pretraining attempts to enhance model performance by obtaining effective features from unlabeled data, and has demonstrated its effectiveness in the field of histopathology images. Despite its success, few works concentrate on the extraction of nucleus-level information, which is essential for pathologic analysis. In this work, we propose a novel nucleus-aware self-supervised pretraining framework for histopathology images. The framework aims to capture the nuclear morphology and distribution information through unpaired image-to-image translation between histopathology images and pseudo mask images. The generation process is modulated by both conditional and stochastic style representations, ensuring the reality and diversity of the generated histopathology images for pretraining. Further, an instance segmentation guided strategy is employed to capture instance-level information. The experiments on 7 datasets show that the proposed pretraining method outperforms supervised ones on Kather classification, multiple instance learning, and 5 dense-prediction tasks with the transfer learning protocol, and yields superior results than other self-supervised approaches on 8 semi-supervised tasks. Our project is publicly available at https://github.com/zhiyuns/UNITPathSSL. ",
    "url": "https://arxiv.org/abs/2309.07394",
    "authors": [
      "Zhiyun Song",
      "Penghui Du",
      "Junpeng Yan",
      "Kailu Li",
      "Jianzhong Shou",
      "Maode Lai",
      "Yubo Fan",
      "Yan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07396",
    "title": "DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning  in the Debiasing Perspective",
    "abstract": "Several prior studies have suggested that word frequency biases can cause the Bert model to learn indistinguishable sentence embeddings. Contrastive learning schemes such as SimCSE and ConSERT have already been adopted successfully in unsupervised sentence embedding to improve the quality of embeddings by reducing this bias. However, these methods still introduce new biases such as sentence length bias and false negative sample bias, that hinders model's ability to learn more fine-grained semantics. In this paper, we reexamine the challenges of contrastive sentence embedding learning from a debiasing perspective and argue that effectively eliminating the influence of various biases is crucial for learning high-quality sentence embeddings. We think all those biases are introduced by simple rules for constructing training data in contrastive learning and the key for contrastive learning sentence embedding is to mimic the distribution of training data in supervised machine learning in unsupervised way. We propose a novel contrastive framework for sentence embedding, termed DebCSE, which can eliminate the impact of these biases by an inverse propensity weighted sampling method to select high-quality positive and negative pairs according to both the surface and semantic similarity between sentences. Extensive experiments on semantic textual similarity (STS) benchmarks reveal that DebCSE significantly outperforms the latest state-of-the-art models with an average Spearman's correlation coefficient of 80.33% on BERTbase. ",
    "url": "https://arxiv.org/abs/2309.07396",
    "authors": [
      "Pu Miao",
      "Zeyao Du",
      "Junlin Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07398",
    "title": "Semantic Adversarial Attacks via Diffusion Models",
    "abstract": "Traditional adversarial attacks concentrate on manipulating clean examples in the pixel space by adding adversarial perturbations. By contrast, semantic adversarial attacks focus on changing semantic attributes of clean examples, such as color, context, and features, which are more feasible in the real world. In this paper, we propose a framework to quickly generate a semantic adversarial attack by leveraging recent diffusion models since semantic information is included in the latent space of well-trained diffusion models. Then there are two variants of this framework: 1) the Semantic Transformation (ST) approach fine-tunes the latent space of the generated image and/or the diffusion model itself; 2) the Latent Masking (LM) approach masks the latent space with another target image and local backpropagation-based interpretation methods. Additionally, the ST approach can be applied in either white-box or black-box settings. Extensive experiments are conducted on CelebA-HQ and AFHQ datasets, and our framework demonstrates great fidelity, generalizability, and transferability compared to other baselines. Our approaches achieve approximately 100% attack success rate in multiple settings with the best FID as 36.61. Code is available at https://github.com/steven202/semantic_adv_via_dm. ",
    "url": "https://arxiv.org/abs/2309.07398",
    "authors": [
      "Chenan Wang",
      "Jinhao Duan",
      "Chaowei Xiao",
      "Edward Kim",
      "Matthew Stamm",
      "Kaidi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07402",
    "title": "Semi-supervised Domain Adaptation on Graphs with Contrastive Learning  and Minimax Entropy",
    "abstract": "Label scarcity in a graph is frequently encountered in real-world applications due to the high cost of data labeling. To this end, semi-supervised domain adaptation (SSDA) on graphs aims to leverage the knowledge of a labeled source graph to aid in node classification on a target graph with limited labels. SSDA tasks need to overcome the domain gap between the source and target graphs. However, to date, this challenging research problem has yet to be formally considered by the existing approaches designed for cross-graph node classification. To tackle the SSDA problem on graphs, a novel method called SemiGCL is proposed, which benefits from graph contrastive learning and minimax entropy training. SemiGCL generates informative node representations by contrasting the representations learned from a graph's local and global views. Additionally, SemiGCL is adversarially optimized with the entropy loss of unlabeled target nodes to reduce domain divergence. Experimental results on benchmark datasets demonstrate that SemiGCL outperforms the state-of-the-art baselines on the SSDA tasks. ",
    "url": "https://arxiv.org/abs/2309.07402",
    "authors": [
      "Jiaren Xiao",
      "Quanyu Dai",
      "Xiao Shen",
      "Xiaochen Xie",
      "Jing Dai",
      "James Lam",
      "Ka-Wai Kwok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07405",
    "title": "FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit  for Neural Speech Codec",
    "abstract": "This paper presents FunCodec, a fundamental neural speech codec toolkit, which is an extension of the open-source speech processing toolkit FunASR. FunCodec provides reproducible training recipes and inference scripts for the latest neural speech codec models, such as SoundStream and Encodec. Thanks to the unified design with FunASR, FunCodec can be easily integrated into downstream tasks, such as speech recognition. Along with FunCodec, pre-trained models are also provided, which can be used for academic or generalized purposes. Based on the toolkit, we further propose the frequency-domain codec models, FreqCodec, which can achieve comparable speech quality with much lower computation and parameter complexity. Experimental results show that, under the same compression ratio, FunCodec can achieve better reconstruction quality compared with other toolkits and released models. We also demonstrate that the pre-trained models are suitable for downstream tasks, including automatic speech recognition and personalized text-to-speech synthesis. This toolkit is publicly available at https://github.com/alibaba-damo-academy/FunCodec. ",
    "url": "https://arxiv.org/abs/2309.07405",
    "authors": [
      "Zhihao Du",
      "Shiliang Zhang",
      "Kai Hu",
      "Siqi Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07412",
    "title": "Advancing Regular Language Reasoning in Linear Recurrent Neural Networks",
    "abstract": "In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic. ",
    "url": "https://arxiv.org/abs/2309.07412",
    "authors": [
      "Ting-Han Fan",
      "Ta-Chung Chi",
      "Alexander I. Rudnicky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07415",
    "title": "Client-side Gradient Inversion Against Federated Learning from Poisoning",
    "abstract": "Federated Learning (FL) enables distributed participants (e.g., mobile devices) to train a global model without sharing data directly to a central server. Recent studies have revealed that FL is vulnerable to gradient inversion attack (GIA), which aims to reconstruct the original training samples and poses high risk against the privacy of clients in FL. However, most existing GIAs necessitate control over the server and rely on strong prior knowledge including batch normalization and data distribution information. In this work, we propose Client-side poisoning Gradient Inversion (CGI), which is a novel attack method that can be launched from clients. For the first time, we show the feasibility of a client-side adversary with limited knowledge being able to recover the training samples from the aggregated global model. We take a distinct approach in which the adversary utilizes a malicious model that amplifies the loss of a specific targeted class of interest. When honest clients employ the poisoned global model, the gradients of samples belonging to the targeted class are magnified, making them the dominant factor in the aggregated update. This enables the adversary to effectively reconstruct the private input belonging to other clients using the aggregated update. In addition, our CGI also features its ability to remain stealthy against Byzantine-robust aggregation rules (AGRs). By optimizing malicious updates and blending benign updates with a malicious replacement vector, our method remains undetected by these defense mechanisms. To evaluate the performance of CGI, we conduct experiments on various benchmark datasets, considering representative Byzantine-robust AGRs, and exploring diverse FL settings with different levels of adversary knowledge about the data. Our results demonstrate that CGI consistently and successfully extracts training input in all tested scenarios. ",
    "url": "https://arxiv.org/abs/2309.07415",
    "authors": [
      "Jiaheng Wei",
      "Yanjun Zhang",
      "Leo Yu Zhang",
      "Chao Chen",
      "Shirui Pan",
      "Kok-Leong Ong",
      "Jun Zhang",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07428",
    "title": "Physical Invisible Backdoor Based on Camera Imaging",
    "abstract": "Backdoor attack aims to compromise a model, which returns an adversary-wanted output when a specific trigger pattern appears yet behaves normally for clean inputs. Current backdoor attacks require changing pixels of clean images, which results in poor stealthiness of attacks and increases the difficulty of the physical implementation. This paper proposes a novel physical invisible backdoor based on camera imaging without changing nature image pixels. Specifically, a compromised model returns a target label for images taken by a particular camera, while it returns correct results for other images. To implement and evaluate the proposed backdoor, we take shots of different objects from multi-angles using multiple smartphones to build a new dataset of 21,500 images. Conventional backdoor attacks work ineffectively with some classical models, such as ResNet18, over the above-mentioned dataset. Therefore, we propose a three-step training strategy to mount the backdoor attack. First, we design and train a camera identification model with the phone IDs to extract the camera fingerprint feature. Subsequently, we elaborate a special network architecture, which is easily compromised by our backdoor attack, by leveraging the attributes of the CFA interpolation algorithm and combining it with the feature extraction block in the camera identification model. Finally, we transfer the backdoor from the elaborated special network architecture to the classical architecture model via teacher-student distillation learning. Since the trigger of our method is related to the specific phone, our attack works effectively in the physical world. Experiment results demonstrate the feasibility of our proposed approach and robustness against various backdoor defenses. ",
    "url": "https://arxiv.org/abs/2309.07428",
    "authors": [
      "Yusheng Guo",
      "Nan Zhong",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.07431",
    "title": "Asynchronous Spatial Allocation Protocol for Trajectory Planning of  Heterogeneous Multi-Agent Systems",
    "abstract": "To plan the trajectories of a large and heterogeneous swarm, sequential or synchronous distributed methods usually become intractable, due to the lack of global connectivity and clock synchronization, Moreover, the existing asynchronously distributed schemes usually require recheck-like mechanisms instead of inherently considering the other' moving tendency. To this end, we propose a novel asynchronous protocol to allocate the agents' derivable space in a distributed way, by which each agent can replan trajectory depending on its own timetable. Properties such as collision avoidance and recursive feasibility are theoretically shown and a lower bound of protocol updating is provided. Comprehensive simulations and comparisons with five state-of-the-art methods validate the effectiveness of our method and illustrate the improvement in both the completion time and the moving distance. Finally, hardware experiments are carried out, where 8 heterogeneous unmanned ground vehicles with onboard computation navigate in cluttered scenarios at a high agility. ",
    "url": "https://arxiv.org/abs/2309.07431",
    "authors": [
      "Yuda Chen",
      "Haoze Dong",
      "Zhongkui Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.07432",
    "title": "SpatialCodec: Neural Spatial Speech Coding",
    "abstract": "In this work, we address the challenge of encoding speech captured by a microphone array using deep learning techniques with the aim of preserving and accurately reconstructing crucial spatial cues embedded in multi-channel recordings. We propose a neural spatial audio coding framework that achieves a high compression ratio, leveraging single-channel neural sub-band codec and SpatialCodec. Our approach encompasses two phases: (i) a neural sub-band codec is designed to encode the reference channel with low bit rates, and (ii), a SpatialCodec captures relative spatial information for accurate multi-channel reconstruction at the decoder end. In addition, we also propose novel evaluation metrics to assess the spatial cue preservation: (i) spatial similarity, which calculates cosine similarity on a spatially intuitive beamspace, and (ii), beamformed audio quality. Our system shows superior spatial performance compared with high bitrate baselines and black-box neural architecture. Demos are available at https://xzwy.github.io/SpatialCodecDemo. Codes and models are available at https://github.com/XZWY/SpatialCodec. ",
    "url": "https://arxiv.org/abs/2309.07432",
    "authors": [
      "Zhongweiyang Xu",
      "Yong Xu",
      "Vinay Kothapally",
      "Heming Wang",
      "Muqiao Yang",
      "Dong Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07443",
    "title": "Learning Tube-Certified Control Using Robust Contraction Metrics",
    "abstract": "Control design for general nonlinear robotic systems with guaranteed stability and/or safety in the presence of model uncertainties is a challenging problem. Recent efforts attempt to learn a controller and a certificate (e.g., a Lyapunov function or a contraction metric) jointly using neural networks (NNs), in which model uncertainties are generally ignored during the learning process. In this paper, for nonlinear systems subject to bounded disturbances, we present a framework for jointly learning a robust nonlinear controller and a contraction metric using a novel disturbance rejection objective that certifies a universal $\\mathcal L_\\infty$ gain bound using NNs for user-specified variables. The learned controller aims to minimize the effect of disturbances on the actual trajectories of state and/or input variables from their nominal counterparts while providing certificate tubes around nominal trajectories that are guaranteed to contain actual trajectories in the presence of disturbances. Experimental results demonstrate that our framework can generate tighter tubes and a controller that is computationally efficient to implement. ",
    "url": "https://arxiv.org/abs/2309.07443",
    "authors": [
      "Vivek Sharma",
      "Pan Zhao",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.07450",
    "title": "TensorFlow Chaotic Prediction and Blow Up",
    "abstract": "Predicting the dynamics of chaotic systems is one of the most challenging tasks for neural networks, and machine learning in general. Here we aim to predict the spatiotemporal chaotic dynamics of a high-dimensional non-linear system. In our attempt we use the TensorFlow library, representing the state of the art for deep neural networks training and prediction. While our results are encouraging, and show that the dynamics of the considered system can be predicted for short time, we also indirectly discovered an unexpected and undesirable behavior of the TensorFlow library. More specifically, the longer term prediction of the system's chaotic behavior quickly deteriorates and blows up due to the nondeterministic behavior of the TensorFlow library. Here we provide numerical evidence of the short time prediction ability, and of the longer term predictability blow up. ",
    "url": "https://arxiv.org/abs/2309.07450",
    "authors": [
      "M. Andrecut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07452",
    "title": "Is Solving Graph Neural Tangent Kernel Equivalent to Training Graph  Neural Network?",
    "abstract": "A rising trend in theoretical deep learning is to understand why deep learning works through Neural Tangent Kernel (NTK) [jgh18], a kernel method that is equivalent to using gradient descent to train a multi-layer infinitely-wide neural network. NTK is a major step forward in the theoretical deep learning because it allows researchers to use traditional mathematical tools to analyze properties of deep neural networks and to explain various neural network techniques from a theoretical view. A natural extension of NTK on graph learning is \\textit{Graph Neural Tangent Kernel (GNTK)}, and researchers have already provide GNTK formulation for graph-level regression and show empirically that this kernel method can achieve similar accuracy as GNNs on various bioinformatics datasets [dhs+19]. The remaining question now is whether solving GNTK regression is equivalent to training an infinite-wide multi-layer GNN using gradient descent. In this paper, we provide three new theoretical results. First, we formally prove this equivalence for graph-level regression. Second, we present the first GNTK formulation for node-level regression. Finally, we prove the equivalence for node-level regression. ",
    "url": "https://arxiv.org/abs/2309.07452",
    "authors": [
      "Lianke Qin",
      "Zhao Song",
      "Baocheng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07461",
    "title": "Detecting Unknown Attacks in IoT Environments: An Open Set Classifier  for Enhanced Network Intrusion Detection",
    "abstract": "The widespread integration of Internet of Things (IoT) devices across all facets of life has ushered in an era of interconnectedness, creating new avenues for cybersecurity challenges and underscoring the need for robust intrusion detection systems. However, traditional security systems are designed with a closed-world perspective and often face challenges in dealing with the ever-evolving threat landscape, where new and unfamiliar attacks are constantly emerging. In this paper, we introduce a framework aimed at mitigating the open set recognition (OSR) problem in the realm of Network Intrusion Detection Systems (NIDS) tailored for IoT environments. Our framework capitalizes on image-based representations of packet-level data, extracting spatial and temporal patterns from network traffic. Additionally, we integrate stacking and sub-clustering techniques, enabling the identification of unknown attacks by effectively modeling the complex and diverse nature of benign behavior. The empirical results prominently underscore the framework's efficacy, boasting an impressive 88\\% detection rate for previously unseen attacks when compared against existing approaches and recent advancements. Future work will perform extensive experimentation across various openness levels and attack scenarios, further strengthening the adaptability and performance of our proposed solution in safeguarding IoT environments. ",
    "url": "https://arxiv.org/abs/2309.07461",
    "authors": [
      "Yasir Ali Farrukh",
      "Syed Wali",
      "Irfan Khan",
      "Nathaniel D. Bastian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07467",
    "title": "Locating Community Smells in Software Development Processes Using  Higher-Order Network Centralities",
    "abstract": "Community smells are negative patterns in software development teams' interactions that impede their ability to successfully create software. Examples are team members working in isolation, lack of communication and collaboration across departments or sub-teams, or areas of the codebase where only a few team members can work on. Current approaches aim to detect community smells by analysing static network representations of software teams' interaction structures. In doing so, they are insufficient to locate community smells within development processes. Extending beyond the capabilities of traditional social network analysis, we show that higher-order network models provide a robust means of revealing such hidden patterns and complex relationships. To this end, we develop a set of centrality measures based on the MOGen higher-order network model and show their effectiveness in predicting influential nodes using five empirical datasets. We then employ these measures for a comprehensive analysis of a product team at the German IT security company genua GmbH, showcasing our method's success in identifying and locating community smells. Specifically, we uncover critical community smells in two areas of the team's development process. Semi-structured interviews with five team members validate our findings: while the team was aware of one community smell and employed measures to address it, it was not aware of the second. This highlights the potential of our approach as a robust tool for identifying and addressing community smells in software development teams. More generally, our work contributes to the social network analysis field with a powerful set of higher-order network centralities that effectively capture community dynamics and indirect relationships. ",
    "url": "https://arxiv.org/abs/2309.07467",
    "authors": [
      "Christoph Gote",
      "Vincenzo Perri",
      "Christian Zingg",
      "Giona Casiraghi",
      "Carsten Arzig",
      "Alexander von Gernler",
      "Frank Schweitzer",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2309.07477",
    "title": "Self-Supervised Prediction of the Intention to Interact with a Service  Robot",
    "abstract": "A service robot can provide a smoother interaction experience if it has the ability to proactively detect whether a nearby user intends to interact, in order to adapt its behavior e.g. by explicitly showing that it is available to provide a service. In this work, we propose a learning-based approach to predict the probability that a human user will interact with a robot before the interaction actually begins; the approach is self-supervised because after each encounter with a human, the robot can automatically label it depending on whether it resulted in an interaction or not. We explore different classification approaches, using different sets of features considering the pose and the motion of the user. We validate and deploy the approach in three scenarios. The first collects $3442$ natural sequences (both interacting and non-interacting) representing employees in an office break area: a real-world, challenging setting, where we consider a coffee machine in place of a service robot. The other two scenarios represent researchers interacting with service robots ($200$ and $72$ sequences, respectively). Results show that, even in challenging real-world settings, our approach can learn without external supervision, and can achieve accurate classification (i.e. AUROC greater than $0.9$) of the user's intention to interact with an advance of more than $3$s before the interaction actually occurs. ",
    "url": "https://arxiv.org/abs/2309.07477",
    "authors": [
      "Gabriele Abbate",
      "Alessandro Giusti",
      "Viktor Schmuck",
      "Oya Celiktutan",
      "Antonio Paolillo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.07481",
    "title": "Improved Auto-Encoding using Deterministic Projected Belief Networks",
    "abstract": "In this paper, we exploit the unique properties of a deterministic projected belief network (D-PBN) to take full advantage of trainable compound activation functions (TCAs). A D-PBN is a type of auto-encoder that operates by \"backing up\" through a feed-forward neural network. TCAs are activation functions with complex monotonic-increasing shapes that change the distribution of the data so that the linear transformation that follows is more effective. Because a D-PBN operates by \"backing up\", the TCAs are inverted in the reconstruction process, restoring the original distribution of the data, thus taking advantage of a given TCA in both analysis and reconstruction. In this paper, we show that a D-PBN auto-encoder with TCAs can significantly out-perform standard auto-encoders including variational auto-encoders. ",
    "url": "https://arxiv.org/abs/2309.07481",
    "authors": [
      "Paul M Baggenstoss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07482",
    "title": "MuLaN: a MultiLayer Networks Alignment Algorithm",
    "abstract": "A Multilayer Network (MN) is a system consisting of several topological levels (i.e., layers) representing the interactions between the system's objects and the related interdependency. Therefore, it may be represented as a set of layers that can be assimilated to a set of networks of its own objects, by means inter-layer edges (or inter-edges) linking the nodes of different layers; for instance, a biological MN may allow modeling of inter and intra interactions among diseases, genes, and drugs, only using its own structure. The analysis of MNs may reveal hidden knowledge, as demonstrated by several algorithms for the analysis. Recently, there is a growing interest in comparing two MNs by revealing local regions of similarity, as a counterpart of Network Alignment algorithms (NA) for simple networks. However, classical algorithms for NA such as Local NA (LNA) cannot be applied on multilayer networks, since they are not able to deal with inter-layer edges. Therefore, there is the need for the introduction of novel algorithms. In this paper, we present MuLaN, an algorithm for the local alignment of multilayer networks. We first show as proof of concept the performances of MuLaN on a set of synthetic multilayer networks. Then, we used as a case study a real multilayer network in the biomedical domain. Our results show that MuLaN is able to build high-quality alignments and can extract knowledge about the aligned multilayer networks. MuLaN is available at https://github.com/pietrocinaglia/mulan. ",
    "url": "https://arxiv.org/abs/2309.07482",
    "authors": [
      "Marianna Milano",
      "Pietro Cinaglia",
      "Pietro Hiram Guzzi",
      "Mario Cannataro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.07492",
    "title": "A Robust Finite-Difference Model Reduction for the Boundary Feedback  Stabilization of Fully-dynamic Piezoelectric Beams",
    "abstract": "Piezoelectric materials exhibit electric responses to mechanical stress, and mechanical responses to electric stress. The PDE model, describing the longitudinal oscillations on the beam, with two boundary feedback controllers is known to have exponentially stable solutions. However, the reduced model by the semi-discretized Finite Elements is shown to lack of exponential stability uniformly as the discretization parameter tends to zero. This is due to the loss of uniform gap among the high-frequency eigenvalues. In this paper, an alternate Finite-Difference based model reduction is investigated by cleverly reducing the order of the model together with the consideration of equidistant grid points and averaging operators. This new model reduction successfully retains the exponential stability uniformly as the discretization parameter tends to zero. Moreover, it does not need a further numerical Fourier filtering. Our results are based on a careful construction of a Lyapunov function. The numerical simulations are provided to compare reduced models and to show the strength of introduced results. ",
    "url": "https://arxiv.org/abs/2309.07492",
    "authors": [
      "Ahmet Ozkan Ozer",
      "Ahmet Kaan Aydin",
      "Jacob Walterman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.07495",
    "title": "HDTR-Net: A Real-Time High-Definition Teeth Restoration Network for  Arbitrary Talking Face Generation Methods",
    "abstract": "Talking Face Generation (TFG) aims to reconstruct facial movements to achieve high natural lip movements from audio and facial features that are under potential connections. Existing TFG methods have made significant advancements to produce natural and realistic images. However, most work rarely takes visual quality into consideration. It is challenging to ensure lip synchronization while avoiding visual quality degradation in cross-modal generation methods. To address this issue, we propose a universal High-Definition Teeth Restoration Network, dubbed HDTR-Net, for arbitrary TFG methods. HDTR-Net can enhance teeth regions at an extremely fast speed while maintaining synchronization, and temporal consistency. In particular, we propose a Fine-Grained Feature Fusion (FGFF) module to effectively capture fine texture feature information around teeth and surrounding regions, and use these features to fine-grain the feature map to enhance the clarity of teeth. Extensive experiments show that our method can be adapted to arbitrary TFG methods without suffering from lip synchronization and frame coherence. Another advantage of HDTR-Net is its real-time generation ability. Also under the condition of high-definition restoration of talking face video synthesis, its inference speed is $300\\%$ faster than the current state-of-the-art face restoration based on super-resolution. ",
    "url": "https://arxiv.org/abs/2309.07495",
    "authors": [
      "Yongyuan Li",
      "Xiuyuan Qin",
      "Chao Liang",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07500",
    "title": "Outlier-aware Inlier Modeling and Multi-scale Scoring for Anomalous  Sound Detection via Multitask Learning",
    "abstract": "This paper proposes an approach for anomalous sound detection that incorporates outlier exposure and inlier modeling within a unified framework by multitask learning. While outlier exposure-based methods can extract features efficiently, it is not robust. Inlier modeling is good at generating robust features, but the features are not very effective. Recently, serial approaches are proposed to combine these two methods, but it still requires a separate training step for normal data modeling. To overcome these limitations, we use multitask learning to train a conformer-based encoder for outlier-aware inlier modeling. Moreover, our approach provides multi-scale scores for detecting anomalies. Experimental results on the MIMII and DCASE 2020 task 2 datasets show that our approach outperforms state-of-the-art single-model systems and achieves comparable results with top-ranked multi-system ensembles. ",
    "url": "https://arxiv.org/abs/2309.07500",
    "authors": [
      "Yucong Zhang",
      "Hongbin Suo",
      "Yulong Wan",
      "Ming Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07504",
    "title": "Connected Autonomous Vehicle Motion Planning with Video Predictions from  Smart, Self-Supervised Infrastructure",
    "abstract": "Connected autonomous vehicles (CAVs) promise to enhance safety, efficiency, and sustainability in urban transportation. However, this is contingent upon a CAV correctly predicting the motion of surrounding agents and planning its own motion safely. Doing so is challenging in complex urban environments due to frequent occlusions and interactions among many agents. One solution is to leverage smart infrastructure to augment a CAV's situational awareness; the present work leverages a recently proposed \"Self-Supervised Traffic Advisor\" (SSTA) framework of smart sensors that teach themselves to generate and broadcast useful video predictions of road users. In this work, SSTA predictions are modified to predict future occupancy instead of raw video, which reduces the data footprint of broadcast predictions. The resulting predictions are used within a planning framework, demonstrating that this design can effectively aid CAV motion planning. A variety of numerical experiments study the key factors that make SSTA outputs useful for practical CAV planning in crowded urban environments. ",
    "url": "https://arxiv.org/abs/2309.07504",
    "authors": [
      "Jiankai Sun",
      "Shreyas Kousik",
      "David Fridovich-Keil",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07524",
    "title": "A Multi-scale Generalized Shrinkage Threshold Network for Image Blind  Deblurring in Remote Sensing",
    "abstract": "Remote sensing images are essential for many earth science applications, but their quality can be degraded due to limitations in sensor technology and complex imaging environments. To address this, various remote sensing image deblurring methods have been developed to restore sharp, high-quality images from degraded observational data. However, most traditional model-based deblurring methods usually require predefined hand-craft prior assumptions, which are difficult to handle in complex applications, and most deep learning-based deblurring methods are designed as a black box, lacking transparency and interpretability. In this work, we propose a novel blind deblurring learning framework based on alternating iterations of shrinkage thresholds, alternately updating blurring kernels and images, with the theoretical foundation of network design. Additionally, we propose a learnable blur kernel proximal mapping module to improve the blur kernel evaluation in the kernel domain. Then, we proposed a deep proximal mapping module in the image domain, which combines a generalized shrinkage threshold operator and a multi-scale prior feature extraction block. This module also introduces an attention mechanism to adaptively adjust the prior importance, thus avoiding the drawbacks of hand-crafted image prior terms. Thus, a novel multi-scale generalized shrinkage threshold network (MGSTNet) is designed to specifically focus on learning deep geometric prior features to enhance image restoration. Experiments demonstrate the superiority of our MGSTNet framework on remote sensing image datasets compared to existing deblurring methods. ",
    "url": "https://arxiv.org/abs/2309.07524",
    "authors": [
      "Yujie Feng",
      "Yin Yang",
      "Xiaohong Fan",
      "Zhengpeng Zhang",
      "Jianping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.07525",
    "title": "SingFake: Singing Voice Deepfake Detection",
    "abstract": "The rise of singing voice synthesis presents critical challenges to artists and industry stakeholders over unauthorized voice usage. Unlike synthesized speech, synthesized singing voices are typically released in songs containing strong background music that may hide synthesis artifacts. Additionally, singing voices present different acoustic and linguistic characteristics from speech utterances. These unique properties make singing voice deepfake detection a relevant but significantly different problem from synthetic speech detection. In this work, we propose the singing voice deepfake detection task. We first present SingFake, the first curated in-the-wild dataset consisting of 28.93 hours of bonafide and 29.40 hours of deepfake song clips in five languages from 40 singers. We provide a train/val/test split where the test sets include various scenarios. We then use SingFake to evaluate four state-of-the-art speech countermeasure systems trained on speech utterances. We find these systems lag significantly behind their performance on speech test data. When trained on SingFake, either using separated vocal tracks or song mixtures, these systems show substantial improvement. However, our evaluations also identify challenges associated with unseen singers, communication codecs, languages, and musical contexts, calling for dedicated research into singing voice deepfake detection. The SingFake dataset and related resources are available online. ",
    "url": "https://arxiv.org/abs/2309.07525",
    "authors": [
      "Yongyi Zang",
      "You Zhang",
      "Mojtaba Heydari",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07526",
    "title": "Learning Beyond Similarities: Incorporating Dissimilarities between  Positive Pairs in Self-Supervised Time Series Learning",
    "abstract": "By identifying similarities between successive inputs, Self-Supervised Learning (SSL) methods for time series analysis have demonstrated their effectiveness in encoding the inherent static characteristics of temporal data. However, an exclusive emphasis on similarities might result in representations that overlook the dynamic attributes critical for modeling cardiovascular diseases within a confined subject cohort. Introducing Distilled Encoding Beyond Similarities (DEBS), this paper pioneers an SSL approach that transcends mere similarities by integrating dissimilarities among positive pairs. The framework is applied to electrocardiogram (ECG) signals, leading to a notable enhancement of +10\\% in the detection accuracy of Atrial Fibrillation (AFib) across diverse subjects. DEBS underscores the potential of attaining a more refined representation by encoding the dynamic characteristics of time series data, tapping into dissimilarities during the optimization process. Broadly, the strategy delineated in this study holds the promise of unearthing novel avenues for advancing SSL methodologies tailored to temporal data. ",
    "url": "https://arxiv.org/abs/2309.07526",
    "authors": [
      "Adrian Atienza",
      "Jakob Bardram",
      "Sadasivan Puthusserypady"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07544",
    "title": "VerilogEval: Evaluating Large Language Models for Verilog Code  Generation",
    "abstract": "The increasing popularity of large language models (LLMs) has paved the way for their application in diverse domains. This paper proposes a benchmarking framework tailored specifically for evaluating LLM performance in the context of Verilog code generation for hardware design and verification. We present a comprehensive evaluation dataset consisting of 156 problems from the Verilog instructional website HDLBits. The evaluation set consists of a diverse set of Verilog code generation tasks, ranging from simple combinational circuits to complex finite state machines. The Verilog code completions can be automatically tested for functional correctness by comparing the transient simulation outputs of the generated design with a golden solution. We also demonstrate that the Verilog code generation capability of pretrained language models could be improved with supervised fine-tuning by bootstrapping with LLM generated synthetic problem-code pairs. ",
    "url": "https://arxiv.org/abs/2309.07544",
    "authors": [
      "Mingjie Liu",
      "Nathaniel Pinckney",
      "Brucek Khailany",
      "Haoxing Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.07545",
    "title": "DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph",
    "abstract": "In this work, we present a web application named DBLPLink, which performs entity linking over the DBLP scholarly knowledge graph. DBLPLink uses text-to-text pre-trained language models, such as T5, to produce entity label spans from an input text question. Entity candidates are fetched from a database based on the labels, and an entity re-ranker sorts them based on entity embeddings, such as TransE, DistMult and ComplEx. The results are displayed so that users may compare and contrast the results between T5-small, T5-base and the different KG embeddings used. The demo can be accessed at https://ltdemos.informatik.uni-hamburg.de/dblplink/. ",
    "url": "https://arxiv.org/abs/2309.07545",
    "authors": [
      "Debayan Banerjee",
      "Arefa",
      "Ricardo Usbeck",
      "Chris Biemann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.07550",
    "title": "Naturalistic Robot Arm Trajectory Generation via Representation Learning",
    "abstract": "The integration of manipulator robots in household environments suggests a need for more predictable and human-like robot motion. This holds especially true for wheelchair-mounted assistive robots that can support the independence of people with paralysis. One method of generating naturalistic motion trajectories is via the imitation of human demonstrators. This paper explores a self-supervised imitation learning method using an autoregressive spatio-temporal graph neural network for an assistive drinking task. We address learning from diverse human motion trajectory data that were captured via wearable IMU sensors on a human arm as the action-free task demonstrations. Observed arm motion data from several participants is used to generate natural and functional drinking motion trajectories for a UR5e robot arm. ",
    "url": "https://arxiv.org/abs/2309.07550",
    "authors": [
      "Jayjun Lee",
      "Adam J. Spiers"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07578",
    "title": "Equivariant Data Augmentation for Generalization in Offline  Reinforcement Learning",
    "abstract": "We present a novel approach to address the challenge of generalization in offline reinforcement learning (RL), where the agent learns from a fixed dataset without any additional interaction with the environment. Specifically, we aim to improve the agent's ability to generalize to out-of-distribution goals. To achieve this, we propose to learn a dynamics model and check if it is equivariant with respect to a fixed type of transformation, namely translations in the state space. We then use an entropy regularizer to increase the equivariant set and augment the dataset with the resulting transformed samples. Finally, we learn a new policy offline based on the augmented dataset, with an off-the-shelf offline RL algorithm. Our experimental results demonstrate that our approach can greatly improve the test performance of the policy on the considered environments. ",
    "url": "https://arxiv.org/abs/2309.07578",
    "authors": [
      "Cristina Pinneri",
      "Sarah Bechtle",
      "Markus Wulfmeier",
      "Arunkumar Byravan",
      "Jingwei Zhang",
      "William F. Whitney",
      "Martin Riedmiller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.07581",
    "title": "A Survey of Graph Pre-processing Methods: From Algorithmic to Hardware  Perspectives",
    "abstract": "Graph-related applications have experienced significant growth in academia and industry, driven by the powerful representation capabilities of graph. However, efficiently executing these applications faces various challenges, such as load imbalance, random memory access, etc. To address these challenges, researchers have proposed various acceleration systems, including software frameworks and hardware accelerators, all of which incorporate graph pre-processing (GPP). GPP serves as a preparatory step before the formal execution of applications, involving techniques such as sampling, reorder, etc. However, GPP execution often remains overlooked, as the primary focus is directed towards enhancing graph applications themselves. This oversight is concerning, especially considering the explosive growth of real-world graph data, where GPP becomes essential and even dominates system running overhead. Furthermore, GPP methods exhibit significant variations across devices and applications due to high customization. Unfortunately, no comprehensive work systematically summarizes GPP. To address this gap and foster a better understanding of GPP, we present a comprehensive survey dedicated to this area. We propose a double-level taxonomy of GPP, considering both algorithmic and hardware perspectives. Through listing relavent works, we illustrate our taxonomy and conduct a thorough analysis and summary of diverse GPP techniques. Lastly, we discuss challenges in GPP and potential future directions. ",
    "url": "https://arxiv.org/abs/2309.07581",
    "authors": [
      "Zhengyang Lv",
      "Mingyu Yan",
      "Xin Liu",
      "Mengyao Dong",
      "Xiaochun Ye",
      "Dongrui Fan",
      "Ninghui Sun"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2309.07597",
    "title": "C-Pack: Packaged Resources To Advance General Chinese Embedding",
    "abstract": "We introduce C-Pack, a package of resources that significantly advance the field of general Chinese embeddings. C-Pack includes three critical resources. 1) C-MTEB is a comprehensive benchmark for Chinese text embeddings covering 6 tasks and 35 datasets. 2) C-MTP is a massive text embedding dataset curated from labeled and unlabeled Chinese corpora for training embedding models. 3) C-TEM is a family of embedding models covering multiple sizes. Our models outperform all prior Chinese text embeddings on C-MTEB by up to +10% upon the time of the release. We also integrate and optimize the entire suite of training methods for C-TEM. Along with our resources on general Chinese embedding, we release our data and models for English text embeddings. The English models achieve state-of-the-art performance on MTEB benchmark; meanwhile, our released English data is 2 times larger than the Chinese data. All these resources are made publicly available at https://github.com/FlagOpen/FlagEmbedding. ",
    "url": "https://arxiv.org/abs/2309.07597",
    "authors": [
      "Shitao Xiao",
      "Zheng Liu",
      "Peitian Zhang",
      "Niklas Muennighof"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.07608",
    "title": "Identifying and analysing toxic actors and communities on Facebook by  employing network analysis",
    "abstract": "There has been an increasingly widespread agreement among both academic circles and the general public that the Social Media Platforms (SMPs) play a central role in the dissemination of harmful and negative sentiment content in a coordinated manner. A substantial body of recent scholarly research has demonstrated the ways in which hateful content, political propaganda, and targeted messaging on SMPs have contributed to serious real-world consequences. Adopting inspirations from graph theory, in this paper we apply novel network and community finding algorithms over a representative Facebook dataset (n=608,417) which we have scrapped through 630 pages. By applying Girvan-Newman algorithm over the historical dataset our analysis finds five communities of coordinated networks of actors, within the contexts of Indian far-right Hindutva discourse. This work further paves the path for future potentials of applying such novel network analysis algorithms to SMPs, in order to automatically identify toxic coordinated communities and sub-communities, and to possibly resist real-world threats emerging from information dissemination in the SMPs. ",
    "url": "https://arxiv.org/abs/2309.07608",
    "authors": [
      "Ritumbra Manuvie",
      "Saikat Chatterjee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.07610",
    "title": "Feature Engineering in Learning-to-Rank for Community Question Answering  Task",
    "abstract": "Community question answering (CQA) forums are Internet-based platforms where users ask questions about a topic and other expert users try to provide solutions. Many CQA forums such as Quora, Stackoverflow, Yahoo!Answer, StackExchange exist with a lot of user-generated data. These data are leveraged in automated CQA ranking systems where similar questions (and answers) are presented in response to the query of the user. In this work, we empirically investigate a few aspects of this domain. Firstly, in addition to traditional features like TF-IDF, BM25 etc., we introduce a BERT-based feature that captures the semantic similarity between the question and answer. Secondly, most of the existing research works have focused on features extracted only from the question part; features extracted from answers have not been explored extensively. We combine both types of features in a linear fashion. Thirdly, using our proposed concepts, we conduct an empirical investigation with different rank-learning algorithms, some of which have not been used so far in CQA domain. On three standard CQA datasets, our proposed framework achieves state-of-the-art performance. We also analyze importance of the features we use in our investigation. This work is expected to guide the practitioners to select a better set of features for the CQA retrieval task. ",
    "url": "https://arxiv.org/abs/2309.07610",
    "authors": [
      "Nafis Sajid",
      "Md Rashidul Hasan",
      "Muhammad Ibrahim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.07616",
    "title": "Road Disease Detection based on Latent Domain Background Feature  Separation and Suppression",
    "abstract": "Road disease detection is challenging due to the the small proportion of road damage in target region and the diverse background,which introduce lots of domain information.Besides, disease categories have high similarity,makes the detection more difficult. In this paper, we propose a new LDBFSS(Latent Domain Background Feature Separation and Suppression) network which could perform background information separation and suppression without domain supervision and contrastive enhancement of object features.We combine our LDBFSS network with YOLOv5 model to enhance disease features for better road disease detection. As the components of LDBFSS network, we first design a latent domain discovery module and a domain adversarial learning module to obtain pseudo domain labels through unsupervised method, guiding domain discriminator and model to train adversarially to suppress background information. In addition, we introduce a contrastive learning module and design k-instance contrastive loss, optimize the disease feature representation by increasing the inter-class distance and reducing the intra-class distance for object features. We conducted experiments on two road disease detection datasets, GRDDC and CNRDD, and compared with other models,which show an increase of nearly 4% on GRDDC dataset compared with optimal model, and an increase of 4.6% on CNRDD dataset. Experimental results prove the effectiveness and superiority of our model. ",
    "url": "https://arxiv.org/abs/2309.07616",
    "authors": [
      "Juwu Zheng",
      "Jiangtao Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07617",
    "title": "Influence Robustness of Nodes in Multiplex Networks against Attacks",
    "abstract": "Recent advances have focused mainly on the resilience of the monoplex network in attacks targeting random nodes or links, as well as the robustness of the network against cascading attacks. However, very little research has been done to investigate the robustness of nodes in multiplex networks against targeted attacks. In this paper, we first propose a new measure, MultiCoreRank, to calculate the global influence of nodes in a multiplex network. The measure models the influence propagation on the core lattice of a multiplex network after the core decomposition. Then, to study how the structural features can affect the influence robustness of nodes, we compare the dynamics of node influence on three types of multiplex networks: assortative, neutral, and disassortative, where the assortativity is measured by the correlation coefficient of the degrees of nodes across different layers. We found that assortative networks have higher resilience against attack than neutral and disassortative networks. The structure of disassortative networks tends to break down quicker under attack. ",
    "url": "https://arxiv.org/abs/2309.07617",
    "authors": [
      "Boqian Ma",
      "Hao Ren",
      "Jiaojiao Jiang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Networking and Internet Architecture (cs.NI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2309.07620",
    "title": "Neural Field Representations of Articulated Objects for Robotic  Manipulation Planning",
    "abstract": "Traditional approaches for manipulation planning rely on an explicit geometric model of the environment to formulate a given task as an optimization problem. However, inferring an accurate model from raw sensor input is a hard problem in itself, in particular for articulated objects (e.g., closets, drawers). In this paper, we propose a Neural Field Representation (NFR) of articulated objects that enables manipulation planning directly from images. Specifically, after taking a few pictures of a new articulated object, we can forward simulate its possible movements, and, therefore, use this neural model directly for planning with trajectory optimization. Additionally, this representation can be used for shape reconstruction, semantic segmentation and image rendering, which provides a strong supervision signal during training and generalization. We show that our model, which was trained only on synthetic images, is able to extract a meaningful representation for unseen objects of the same class, both in simulation and with real images. Furthermore, we demonstrate that the representation enables robotic manipulation of an articulated object in the real world directly from images. ",
    "url": "https://arxiv.org/abs/2309.07620",
    "authors": [
      "Phillip Grote",
      "Joaquim Ortiz-Haro",
      "Marc Toussaint",
      "Ozgur S. Oguz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.07621",
    "title": "Exact solution of the full RMSA problem in elastic optical networks",
    "abstract": "Exact solutions of the Routing, Modulation, and Spectrum Allocation (RMSA) problem in Elastic Optical Networks (EONs), so that the number of admitted demands is maximized while those of regenerators and frequency slots used are minimized, require a complex ILP formulation taking into account frequency-slot continuity and contiguity. We introduce the first such formulation, ending a hiatus of some years since the last ILP formulation for a much simpler RMSA variation was introduced. By exploiting a number of problem and solver specificities, we use the NSFNET topology to illustrate the practicality and importance of obtaining exact solutions. ",
    "url": "https://arxiv.org/abs/2309.07621",
    "authors": [
      "Fabio David",
      "Jos\u00e9 F. de Rezende",
      "Valmir C. Barbosa"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.07639",
    "title": "Do Not Give Away My Secrets: Uncovering the Privacy Issue of Neural Code  Completion Tools",
    "abstract": "Neural Code Completion Tools (NCCTs) have reshaped the field of software development, which accurately suggest contextually-relevant code snippets benefiting from language modeling techniques. However, language models may emit the training data verbatim during inference with appropriate prompts. This memorization property raises privacy concerns of commercial NCCTs about the hard-coded credential leakage, leading to unauthorized access to systems. Therefore, to answer whether NCCTs will inadvertently emit the hard-coded credential, we propose an evaluation tool called Hard-coded Credential Revealer (HCR). HCR effectively constructs test prompts from GitHub code files with credentials to trigger memorization phenomenon of commercial NCCTs. Then, HCR extracts credentials with pre-defined format from the responses by four designed filters. We apply HCR to evaluate two representative commercial NCCTs: GitHub Copilot and Amazon CodeWhisperer and successfully extracted 2,702 hard-coded credentials from Copilot and 129 secrets from CodeWhisper under the black-box setting, among which at least 3.6% and 5.4% secrets are real strings from GitHub repositories. Moreover, two operational credentials were identified. The experimental results raise the severe privacy concern of the potential leakage of hard-coded credentials in the training data of commercial NCCTs. ",
    "url": "https://arxiv.org/abs/2309.07639",
    "authors": [
      "Yizhan Huang",
      "Yichen Li",
      "Weibin Wu",
      "Jianping Zhang",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.07640",
    "title": "Indoor Scene Reconstruction with Fine-Grained Details Using Hybrid  Representation and Normal Prior Enhancement",
    "abstract": "The reconstruction of indoor scenes from multi-view RGB images is challenging due to the coexistence of flat and texture-less regions alongside delicate and fine-grained regions. Recent methods leverage neural radiance fields aided by predicted surface normal priors to recover the scene geometry. These methods excel in producing complete and smooth results for floor and wall areas. However, they struggle to capture complex surfaces with high-frequency structures due to the inadequate neural representation and the inaccurately predicted normal priors. To improve the capacity of the implicit representation, we propose a hybrid architecture to represent low-frequency and high-frequency regions separately. To enhance the normal priors, we introduce a simple yet effective image sharpening and denoising technique, coupled with a network that estimates the pixel-wise uncertainty of the predicted surface normal vectors. Identifying such uncertainty can prevent our model from being misled by unreliable surface normal supervisions that hinder the accurate reconstruction of intricate geometries. Experiments on the benchmark datasets show that our method significantly outperforms existing methods in terms of reconstruction quality. ",
    "url": "https://arxiv.org/abs/2309.07640",
    "authors": [
      "Sheng Ye",
      "Yubin Hu",
      "Matthieu Lin",
      "Yu-Hui Wen",
      "Wang Zhao",
      "Wenping Wang",
      "Yong-Jin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07654",
    "title": "Towards Robust and Unconstrained Full Range of Rotation Head Pose  Estimation",
    "abstract": "Estimating the head pose of a person is a crucial problem for numerous applications that is yet mainly addressed as a subtask of frontal pose prediction. We present a novel method for unconstrained end-to-end head pose estimation to tackle the challenging task of full range of orientation head pose prediction. We address the issue of ambiguous rotation labels by introducing the rotation matrix formalism for our ground truth data and propose a continuous 6D rotation matrix representation for efficient and robust direct regression. This allows to efficiently learn full rotation appearance and to overcome the limitations of the current state-of-the-art. Together with new accumulated training data that provides full head pose rotation data and a geodesic loss approach for stable learning, we design an advanced model that is able to predict an extended range of head orientations. An extensive evaluation on public datasets demonstrates that our method significantly outperforms other state-of-the-art methods in an efficient and robust manner, while its advanced prediction range allows the expansion of the application area. We open-source our training and testing code along with our trained models: https://github.com/thohemp/6DRepNet360. ",
    "url": "https://arxiv.org/abs/2309.07654",
    "authors": [
      "Thorsten Hempel",
      "Ahmed A. Abdelrahman",
      "Ayoub Al-Hamadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07658",
    "title": "DDSP-based Neural Waveform Synthesis of Polyphonic Guitar Performance  from String-wise MIDI Input",
    "abstract": "We explore the use of neural synthesis for acoustic guitar from string-wise MIDI input. We propose four different systems and compare them with both objective metrics and subjective evaluation against natural audio and a sample-based baseline. We iteratively develop these four systems by making various considerations on the architecture and intermediate tasks, such as predicting pitch and loudness control features. We find that formulating the control feature prediction task as a classification task rather than a regression task yields better results. Furthermore, we find that our simplest proposed system, which directly predicts synthesis parameters from MIDI input performs the best out of the four proposed systems. Audio examples are available at https://erl-j.github.io/neural-guitar-web-supplement. ",
    "url": "https://arxiv.org/abs/2309.07658",
    "authors": [
      "Nicolas Jonason",
      "Xin Wang",
      "Erica Cooper",
      "Lauri Juvela",
      "Bob L. T. Sturm",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07672",
    "title": "Physics-constrained robust learning of open-form PDEs from limited and  noisy data",
    "abstract": "Unveiling the underlying governing equations of nonlinear dynamic systems remains a significant challenge, especially when encountering noisy observations and no prior knowledge available. This study proposes R-DISCOVER, a framework designed to robustly uncover open-form partial differential equations (PDEs) from limited and noisy data. The framework operates through two alternating update processes: discovering and embedding. The discovering phase employs symbolic representation and a reinforcement learning (RL)-guided hybrid PDE generator to efficiently produce diverse open-form PDEs with tree structures. A neural network-based predictive model fits the system response and serves as the reward evaluator for the generated PDEs. PDEs with superior fits are utilized to iteratively optimize the generator via the RL method and the best-performing PDE is selected by a parameter-free stability metric. The embedding phase integrates the initially identified PDE from the discovering process as a physical constraint into the predictive model for robust training. The traversal of PDE trees automates the construction of the computational graph and the embedding process without human intervention. Numerical experiments demonstrate our framework's capability to uncover governing equations from nonlinear dynamic systems with limited and highly noisy data and outperform other physics-informed neural network-based discovery methods. This work opens new potential for exploring real-world systems with limited understanding. ",
    "url": "https://arxiv.org/abs/2309.07672",
    "authors": [
      "Mengge Du",
      "Longfeng Nie",
      "Siyu Lou",
      "Yuntian Chenc",
      "Dongxiao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2309.07684",
    "title": "deepFDEnet: A Novel Neural Network Architecture for Solving Fractional  Differential Equations",
    "abstract": "The primary goal of this research is to propose a novel architecture for a deep neural network that can solve fractional differential equations accurately. A Gaussian integration rule and a $L_1$ discretization technique are used in the proposed design. In each equation, a deep neural network is used to approximate the unknown function. Three forms of fractional differential equations have been examined to highlight the method's versatility: a fractional ordinary differential equation, a fractional order integrodifferential equation, and a fractional order partial differential equation. The results show that the proposed architecture solves different forms of fractional differential equations with excellent precision. ",
    "url": "https://arxiv.org/abs/2309.07684",
    "authors": [
      "Ali Nosrati Firoozsalari",
      "Hassan Dana Mazraeh",
      "Alireza Afzal Aghaei",
      "Kourosh Parand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.07703",
    "title": "Causal Entropy and Information Gain for Measuring Causal Control",
    "abstract": "Artificial intelligence models and methods commonly lack causal interpretability. Despite the advancements in interpretable machine learning (IML) methods, they frequently assign importance to features which lack causal influence on the outcome variable. Selecting causally relevant features among those identified as relevant by these methods, or even before model training, would offer a solution. Feature selection methods utilizing information theoretical quantities have been successful in identifying statistically relevant features. However, the information theoretical quantities they are based on do not incorporate causality, rendering them unsuitable for such scenarios. To address this challenge, this article proposes information theoretical quantities that incorporate the causal structure of the system, which can be used to evaluate causal importance of features for some given outcome variable. Specifically, we introduce causal versions of entropy and mutual information, termed causal entropy and causal information gain, which are designed to assess how much control a feature provides over the outcome variable. These newly defined quantities capture changes in the entropy of a variable resulting from interventions on other variables. Fundamental results connecting these quantities to the existence of causal effects are derived. The use of causal information gain in feature selection is demonstrated, highlighting its superiority over standard mutual information in revealing which features provide control over a chosen outcome variable. Our investigation paves the way for the development of methods with improved interpretability in domains involving causation. ",
    "url": "https://arxiv.org/abs/2309.07703",
    "authors": [
      "Francisco Nunes Ferreira Quialheiro Simoes",
      "Mehdi Dastani",
      "Thijs van Ommen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.07716",
    "title": "Understanding Vector-Valued Neural Networks and Their Relationship with  Real and Hypercomplex-Valued Neural Networks",
    "abstract": "Despite the many successful applications of deep learning models for multidimensional signal and image processing, most traditional neural networks process data represented by (multidimensional) arrays of real numbers. The intercorrelation between feature channels is usually expected to be learned from the training data, requiring numerous parameters and careful training. In contrast, vector-valued neural networks are conceived to process arrays of vectors and naturally consider the intercorrelation between feature channels. Consequently, they usually have fewer parameters and often undergo more robust training than traditional neural networks. This paper aims to present a broad framework for vector-valued neural networks, referred to as V-nets. In this context, hypercomplex-valued neural networks are regarded as vector-valued models with additional algebraic properties. Furthermore, this paper explains the relationship between vector-valued and traditional neural networks. Precisely, a vector-valued neural network can be obtained by placing restrictions on a real-valued model to consider the intercorrelation between feature channels. Finally, we show how V-nets, including hypercomplex-valued neural networks, can be implemented in current deep-learning libraries as real-valued networks. ",
    "url": "https://arxiv.org/abs/2309.07716",
    "authors": [
      "Marcos Eduardo Valle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.07719",
    "title": "L1-aware Multilingual Mispronunciation Detection Framework",
    "abstract": "The phonological discrepancies between a speaker's native (L1) and the non-native language (L2) serves as a major factor for mispronunciation. This paper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched with L1-aware speech representation. An end-to-end speech encoder is trained on the input signal and its corresponding reference phoneme sequence. First, an attention mechanism is deployed to align the input audio with the reference phoneme sequence. Afterwards, the L1-L2-speech embedding are extracted from an auxiliary model, pretrained in a multi-task setup identifying L1 and L2 language, and are infused with the primary network. Finally, the L1-MultiMDD is then optimized for a unified multilingual phoneme recognition task using connectionist temporal classification (CTC) loss for the target languages: English, Arabic, and Mandarin. Our experiments demonstrate the effectiveness of the proposed L1-MultiMDD framework on both seen -- L2-ARTIC, LATIC, and AraVoiceL2v2; and unseen -- EpaDB and Speechocean762 datasets. The consistent gains in PER, and false rejection rate (FRR) across all target languages confirm our approach's robustness, efficacy, and generalizability. ",
    "url": "https://arxiv.org/abs/2309.07719",
    "authors": [
      "Yassine El Kheir",
      "Shammur Absar Chwodhury",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07730",
    "title": "AIDPS:Adaptive Intrusion Detection and Prevention System for Underwater  Acoustic Sensor Networks",
    "abstract": "Underwater Acoustic Sensor Networks (UW-ASNs) are predominantly used for underwater environments and find applications in many areas. However, a lack of security considerations, the unstable and challenging nature of the underwater environment, and the resource-constrained nature of the sensor nodes used for UW-ASNs (which makes them incapable of adopting security primitives) make the UW-ASN prone to vulnerabilities. This paper proposes an Adaptive decentralised Intrusion Detection and Prevention System called AIDPS for UW-ASNs. The proposed AIDPS can improve the security of the UW-ASNs so that they can efficiently detect underwater-related attacks (e.g., blackhole, grayhole and flooding attacks). To determine the most effective configuration of the proposed construction, we conduct a number of experiments using several state-of-the-art machine learning algorithms (e.g., Adaptive Random Forest (ARF), light gradient-boosting machine, and K-nearest neighbours) and concept drift detection algorithms (e.g., ADWIN, kdqTree, and Page-Hinkley). Our experimental results show that incremental ARF using ADWIN provides optimal performance when implemented with One-class support vector machine (SVM) anomaly-based detectors. Furthermore, our extensive evaluation results also show that the proposed scheme outperforms state-of-the-art bench-marking methods while providing a wider range of desirable features such as scalability and complexity. ",
    "url": "https://arxiv.org/abs/2309.07730",
    "authors": [
      "Soumadeep Das",
      "Aryan Mohammadi Pasikhani",
      "Prosanta Gope",
      "John A. Clark",
      "Chintan Patel",
      "Biplab Sikdar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07739",
    "title": "The complementary roles of non-verbal cues for Robust Pronunciation  Assessment",
    "abstract": "Research on pronunciation assessment systems focuses on utilizing phonetic and phonological aspects of non-native (L2) speech, often neglecting the rich layer of information hidden within the non-verbal cues. In this study, we proposed a novel pronunciation assessment framework, IntraVerbalPA. % The framework innovatively incorporates both fine-grained frame- and abstract utterance-level non-verbal cues, alongside the conventional speech and phoneme representations. Additionally, we introduce ''Goodness of phonemic-duration'' metric to effectively model duration distribution within the framework. Our results validate the effectiveness of the proposed IntraVerbalPA framework and its individual components, yielding performance that either matches or outperforms existing research works. ",
    "url": "https://arxiv.org/abs/2309.07739",
    "authors": [
      "Yassine El Kheir",
      "Shammur Absar Chowdhury",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07742",
    "title": "Interpretability is in the Mind of the Beholder: A Causal Framework for  Human-interpretable Representation Learning",
    "abstract": "Focus in Explainable AI is shifting from explanations defined in terms of low-level elements, such as input features, to explanations encoded in terms of interpretable concepts learned from data. How to reliably acquire such concepts is, however, still fundamentally unclear. An agreed-upon notion of concept interpretability is missing, with the result that concepts used by both post-hoc explainers and concept-based neural networks are acquired through a variety of mutually incompatible strategies. Critically, most of these neglect the human side of the problem: a representation is understandable only insofar as it can be understood by the human at the receiving end. The key challenge in Human-interpretable Representation Learning (HRL) is how to model and operationalize this human element. In this work, we propose a mathematical framework for acquiring interpretable representations suitable for both post-hoc explainers and concept-based neural networks. Our formalization of HRL builds on recent advances in causal representation learning and explicitly models a human stakeholder as an external observer. This allows us to derive a principled notion of alignment between the machine representation and the vocabulary of concepts understood by the human. In doing so, we link alignment and interpretability through a simple and intuitive name transfer game, and clarify the relationship between alignment and a well-known property of representations, namely disentanglment. We also show that alignment is linked to the issue of undesirable correlations among concepts, also known as concept leakage, and to content-style separation, all through a general information-theoretic reformulation of these properties. Our conceptualization aims to bridge the gap between the human and algorithmic sides of interpretability and establish a stepping stone for new research on human-interpretable representations. ",
    "url": "https://arxiv.org/abs/2309.07742",
    "authors": [
      "Emanuele Marconato",
      "Andrea Passerini",
      "Stefano Teso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.07749",
    "title": "OmnimatteRF: Robust Omnimatte with 3D Background Modeling",
    "abstract": "Video matting has broad applications, from adding interesting effects to casually captured movies to assisting video production professionals. Matting with associated effects such as shadows and reflections has also attracted increasing research activity, and methods like Omnimatte have been proposed to separate dynamic foreground objects of interest into their own layers. However, prior works represent video backgrounds as 2D image layers, limiting their capacity to express more complicated scenes, thus hindering application to real-world videos. In this paper, we propose a novel video matting method, OmnimatteRF, that combines dynamic 2D foreground layers and a 3D background model. The 2D layers preserve the details of the subjects, while the 3D background robustly reconstructs scenes in real-world videos. Extensive experiments demonstrate that our method reconstructs scenes with better quality on various videos. ",
    "url": "https://arxiv.org/abs/2309.07749",
    "authors": [
      "Geng Lin",
      "Chen Gao",
      "Jia-Bin Huang",
      "Changil Kim",
      "Yipeng Wang",
      "Matthias Zwicker",
      "Ayush Saraf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07752",
    "title": "DT-NeRF: Decomposed Triplane-Hash Neural Radiance Fields for  High-Fidelity Talking Portrait Synthesis",
    "abstract": "In this paper, we present the decomposed triplane-hash neural radiance fields (DT-NeRF), a framework that significantly improves the photorealistic rendering of talking faces and achieves state-of-the-art results on key evaluation datasets. Our architecture decomposes the facial region into two specialized triplanes: one specialized for representing the mouth, and the other for the broader facial features. We introduce audio features as residual terms and integrate them as query vectors into our model through an audio-mouth-face transformer. Additionally, our method leverages the capabilities of Neural Radiance Fields (NeRF) to enrich the volumetric representation of the entire face through additive volumetric rendering techniques. Comprehensive experimental evaluations corroborate the effectiveness and superiority of our proposed approach. ",
    "url": "https://arxiv.org/abs/2309.07752",
    "authors": [
      "Yaoyu Su",
      "Shaohui Wang",
      "Haoqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07753",
    "title": "Co-Salient Object Detection with Semantic-Level Consensus Extraction and  Dispersion",
    "abstract": "Given a group of images, co-salient object detection (CoSOD) aims to highlight the common salient object in each image. There are two factors closely related to the success of this task, namely consensus extraction, and the dispersion of consensus to each image. Most previous works represent the group consensus using local features, while we instead utilize a hierarchical Transformer module for extracting semantic-level consensus. Therefore, it can obtain a more comprehensive representation of the common object category, and exclude interference from other objects that share local similarities with the target object. In addition, we propose a Transformer-based dispersion module that takes into account the variation of the co-salient object in different scenes. It distributes the consensus to the image feature maps in an image-specific way while making full use of interactions within the group. These two modules are integrated with a ViT encoder and an FPN-like decoder to form an end-to-end trainable network, without additional branch and auxiliary loss. The proposed method is evaluated on three commonly used CoSOD datasets and achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2309.07753",
    "authors": [
      "Peiran Xu",
      "Yadong Mu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07794",
    "title": "Improving Multimodal Classification of Social Media Posts by Leveraging  Image-Text Auxiliary tasks",
    "abstract": "Effectively leveraging multimodal information from social media posts is essential to various downstream tasks such as sentiment analysis, sarcasm detection and hate speech classification. However, combining text and image information is challenging because of the idiosyncratic cross-modal semantics with hidden or complementary information present in matching image-text pairs. In this work, we aim to directly model this by proposing the use of two auxiliary losses jointly with the main task when fine-tuning any pre-trained multimodal model. Image-Text Contrastive (ITC) brings image-text representations of a post closer together and separates them from different posts, capturing underlying dependencies. Image-Text Matching (ITM) facilitates the understanding of semantic correspondence between images and text by penalizing unrelated pairs. We combine these objectives with five multimodal models, demonstrating consistent improvements across four popular social media datasets. Furthermore, through detailed analysis, we shed light on the specific scenarios and cases where each auxiliary task proves to be most effective. ",
    "url": "https://arxiv.org/abs/2309.07794",
    "authors": [
      "Danae S\u00e1nchez Villegas",
      "Daniel Preo\u0163iuc-Pietro",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.07804",
    "title": "Pop Quiz! Do Pre-trained Code Models Possess Knowledge of Correct API  Names?",
    "abstract": "Recent breakthroughs in pre-trained code models, such as CodeBERT and Codex, have shown their superior performance in various downstream tasks. The correctness and unambiguity of API usage among these code models are crucial for achieving desirable program functionalities, requiring them to learn various API fully qualified names structurally and semantically. Recent studies reveal that even state-of-the-art pre-trained code models struggle with suggesting the correct APIs during code generation. However, the reasons for such poor API usage performance are barely investigated. To address this challenge, we propose using knowledge probing as a means of interpreting code models, which uses cloze-style tests to measure the knowledge stored in models. Our comprehensive study examines a code model's capability of understanding API fully qualified names from two different perspectives: API call and API import. Specifically, we reveal that current code models struggle with understanding API names, with pre-training strategies significantly affecting the quality of API name learning. We demonstrate that natural language context can assist code models in locating Python API names and generalize Python API name knowledge to unseen data. Our findings provide insights into the limitations and capabilities of current pre-trained code models, and suggest that incorporating API structure into the pre-training process can improve automated API usage and code representations. This work provides significance for advancing code intelligence practices and direction for future studies. All experiment results, data and source code used in this work are available at \\url{https://doi.org/10.5281/zenodo.7902072}. ",
    "url": "https://arxiv.org/abs/2309.07804",
    "authors": [
      "Terry Yue Zhuo",
      "Xiaoning Du",
      "Zhenchang Xing",
      "Jiamou Sun",
      "Haowei Quan",
      "Li Li",
      "Liming Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.07815",
    "title": "Nonlinear model order reduction for problems with microstructure using  mesh informed neural networks",
    "abstract": "Many applications in computational physics involve approximating problems with microstructure, characterized by multiple spatial scales in their data. However, these numerical solutions are often computationally expensive due to the need to capture fine details at small scales. As a result, simulating such phenomena becomes unaffordable for many-query applications, such as parametrized systems with multiple scale-dependent features. Traditional projection-based reduced order models (ROMs) fail to resolve these issues, even for second-order elliptic PDEs commonly found in engineering applications. To address this, we propose an alternative nonintrusive strategy to build a ROM, that combines classical proper orthogonal decomposition (POD) with a suitable neural network (NN) model to account for the small scales. Specifically, we employ sparse mesh-informed neural networks (MINNs), which handle both spatial dependencies in the solutions and model parameters simultaneously. We evaluate the performance of this strategy on benchmark problems and then apply it to approximate a real-life problem involving the impact of microcirculation in transport phenomena through the tissue microenvironment. ",
    "url": "https://arxiv.org/abs/2309.07815",
    "authors": [
      "Piermario Vitullo",
      "Alessio Colombo",
      "Nicola Rares Franco",
      "Andrea Manzoni",
      "Paolo Zunino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.07846",
    "title": "MC-NeRF: Muti-Camera Neural Radiance Fields for Muti-Camera Image  Acquisition Systems",
    "abstract": "Neural Radiance Fields (NeRF) employ multi-view images for 3D scene representation and have shown remarkable performance. As one of the primary sources of multi-view images, multi-camera systems encounter challenges such as varying intrinsic parameters and frequent pose changes. Most previous NeRF-based methods often assume a global unique camera and seldom consider scenarios with multiple cameras. Besides, some pose-robust methods still remain susceptible to suboptimal solutions when poses are poor initialized. In this paper, we propose MC-NeRF, a method can jointly optimize both intrinsic and extrinsic parameters for bundle-adjusting Neural Radiance Fields. Firstly, we conduct a theoretical analysis to tackle the degenerate case and coupling issue that arise from the joint optimization between intrinsic and extrinsic parameters. Secondly, based on the proposed solutions, we introduce an efficient calibration image acquisition scheme for multi-camera systems, including the design of calibration object. Lastly, we present a global end-to-end network with training sequence that enables the regression of intrinsic and extrinsic parameters, along with the rendering network. Moreover, most existing datasets are designed for unique camera, we create a new dataset that includes four different styles of multi-camera acquisition systems, allowing readers to generate custom datasets. Experiments confirm the effectiveness of our method when each image corresponds to different camera parameters. Specifically, we adopt up to 110 images with 110 different intrinsic and extrinsic parameters, to achieve 3D scene representation without providing initial poses. The Code and supplementary materials are available at https://in2-viaun.github.io/MC-NeRF. ",
    "url": "https://arxiv.org/abs/2309.07846",
    "authors": [
      "Yu Gao",
      "Lutong Su",
      "Hao Liang",
      "Yufeng Yue",
      "Yi Yang",
      "Mengyin Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07871",
    "title": "Gradient Dynamics in Linear Quadratic Network Games with Time-Varying  Connectivity and Population Fluctuation",
    "abstract": "In this paper, we consider a learning problem among non-cooperative agents interacting in a time-varying system. Specifically, we focus on repeated linear quadratic network games, in which the network of interactions changes with time and agents may not be present at each iteration. To get tractability, we assume that at each iteration, the network of interactions is sampled from an underlying random network model and agents participate at random with a given probability. Under these assumptions, we consider a gradient-based learning algorithm and establish almost sure convergence of the agents' strategies to the Nash equilibrium of the game played over the expected network. Additionally, we prove, in the large population regime, that the learned strategy is an $\\epsilon$-Nash equilibrium for each stage game with high probability. We validate our results over an online market application. ",
    "url": "https://arxiv.org/abs/2309.07871",
    "authors": [
      "Feras Al Taha",
      "Kiran Rokade",
      "Francesca Parise"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2309.07878",
    "title": "Using network metrics to explore the community structure that underlies  movement patterns",
    "abstract": "This work aims to explore the community structure of Santiago de Chile by analyzing the movement patterns of its residents. We use a dataset containing the approximate locations of home and work places for a subset of anonymized residents to construct a network that represents the movement patterns within the city. Through the analysis of this network, we aim to identify the communities or sub-cities that exist within Santiago de Chile and gain insights into the factors that drive the spatial organization of the city. We employ modularity optimization algorithms and clustering techniques to identify the communities within the network. Our results present that the novelty of combining community detection algorithms with segregation tools provides new insights to further the understanding of the complex geography of segregation during working hours. ",
    "url": "https://arxiv.org/abs/2309.07878",
    "authors": [
      "Anh Pham Thi Minh",
      "Abhishek Kumar Singh",
      "Soumya Snigdha Kundu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07880",
    "title": "mEBAL2 Database and Benchmark: Image-based Multispectral Eyeblink  Detection",
    "abstract": "This work introduces a new multispectral database and novel approaches for eyeblink detection in RGB and Near-Infrared (NIR) individual images. Our contributed dataset (mEBAL2, multimodal Eye Blink and Attention Level estimation, Version 2) is the largest existing eyeblink database, representing a great opportunity to improve data-driven multispectral approaches for blink detection and related applications (e.g., attention level estimation and presentation attack detection in face biometrics). mEBAL2 includes 21,100 image sequences from 180 different students (more than 2 million labeled images in total) while conducting a number of e-learning tasks of varying difficulty or taking a real course on HTML initiation through the edX MOOC platform. mEBAL2 uses multiple sensors, including two Near-Infrared (NIR) and one RGB camera to capture facial gestures during the execution of the tasks, as well as an Electroencephalogram (EEG) band to get the cognitive activity of the user and blinking events. Furthermore, this work proposes a Convolutional Neural Network architecture as benchmark for blink detection on mEBAL2 with performances up to 97%. Different training methodologies are implemented using the RGB spectrum, NIR spectrum, and the combination of both to enhance the performance on existing eyeblink detectors. We demonstrate that combining NIR and RGB images during training improves the performance of RGB eyeblink detectors (i.e., detection based only on a RGB image). Finally, the generalization capacity of the proposed eyeblink detectors is validated in wilder and more challenging environments like the HUST-LEBW dataset to show the usefulness of mEBAL2 to train a new generation of data-driven approaches for eyeblink detection. ",
    "url": "https://arxiv.org/abs/2309.07880",
    "authors": [
      "Roberto Daza",
      "Aythami Morales",
      "Julian Fierrez",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.07909",
    "title": "Boosting Unsupervised Contrastive Learning Using Diffusion-Based Data  Augmentation From Scratch",
    "abstract": "Unsupervised contrastive learning methods have recently seen significant improvements, particularly through data augmentation strategies that aim to produce robust and generalizable representations. However, prevailing data augmentation methods, whether hand designed or based on foundation models, tend to rely heavily on prior knowledge or external data. This dependence often compromises their effectiveness and efficiency. Furthermore, the applicability of most existing data augmentation strategies is limited when transitioning to other research domains, especially science-related data. This limitation stems from the paucity of prior knowledge and labeled data available in these domains. To address these challenges, we introduce DiffAug-a novel and efficient Diffusion-based data Augmentation technique. DiffAug aims to ensure that the augmented and original data share a smoothed latent space, which is achieved through diffusion steps. Uniquely, unlike traditional methods, DiffAug first mines sufficient prior semantic knowledge about the neighborhood. This provides a constraint to guide the diffusion steps, eliminating the need for labels, external data/models, or prior knowledge. Designed as an architecture-agnostic framework, DiffAug provides consistent improvements. Specifically, it improves image classification and clustering accuracy by 1.6%~4.5%. When applied to biological data, DiffAug improves performance by up to 10.1%, with an average improvement of 5.8%. DiffAug shows good performance in both vision and biological domains. ",
    "url": "https://arxiv.org/abs/2309.07909",
    "authors": [
      "Zelin Zang",
      "Hao Luo",
      "Kai Wang",
      "Panpan Zhang",
      "Fan Wang",
      "Stan.Z Li",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07914",
    "title": "ALWOD: Active Learning for Weakly-Supervised Object Detection",
    "abstract": "Object detection (OD), a crucial vision task, remains challenged by the lack of large training datasets with precise object localization labels. In this work, we propose ALWOD, a new framework that addresses this problem by fusing active learning (AL) with weakly and semi-supervised object detection paradigms. Because the performance of AL critically depends on the model initialization, we propose a new auxiliary image generator strategy that utilizes an extremely small labeled set, coupled with a large weakly tagged set of images, as a warm-start for AL. We then propose a new AL acquisition function, another critical factor in AL success, that leverages the student-teacher OD pair disagreement and uncertainty to effectively propose the most informative images to annotate. Finally, to complete the AL loop, we introduce a new labeling task delegated to human annotators, based on selection and correction of model-proposed detections, which is both rapid and effective in labeling the informative images. We demonstrate, across several challenging benchmarks, that ALWOD significantly narrows the gap between the ODs trained on few partially labeled but strategically selected image instances and those that rely on the fully-labeled data. Our code is publicly available on https://github.com/seqam-lab/ALWOD. ",
    "url": "https://arxiv.org/abs/2309.07914",
    "authors": [
      "Yuting Wang",
      "Velibor Ilic",
      "Jiatong Li",
      "Branislav Kisacanin",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07135",
    "title": "EpiDeNet: An Energy-Efficient Approach to Seizure Detection for Embedded  Systems",
    "abstract": "Epilepsy is a prevalent neurological disorder that affects millions of individuals globally, and continuous monitoring coupled with automated seizure detection appears as a necessity for effective patient treatment. To enable long-term care in daily-life conditions, comfortable and smart wearable devices with long battery life are required, which in turn set the demand for resource-constrained and energy-efficient computing solutions. In this context, the development of machine learning algorithms for seizure detection faces the challenge of heavily imbalanced datasets. This paper introduces EpiDeNet, a new lightweight seizure detection network, and Sensitivity-Specificity Weighted Cross-Entropy (SSWCE), a new loss function that incorporates sensitivity and specificity, to address the challenge of heavily unbalanced datasets. The proposed EpiDeNet-SSWCE approach demonstrates the successful detection of 91.16% and 92.00% seizure events on two different datasets (CHB-MIT and PEDESITE, respectively), with only four EEG channels. A three-window majority voting-based smoothing scheme combined with the SSWCE loss achieves 3x reduction of false positives to 1.18 FP/h. EpiDeNet is well suited for implementation on low-power embedded platforms, and we evaluate its performance on two ARM Cortex-based platforms (M4F/M7) and two parallel ultra-low power (PULP) systems (GAP8, GAP9). The most efficient implementation (GAP9) achieves an energy efficiency of 40 GMAC/s/W, with an energy consumption per inference of only 0.051 mJ at high performance (726.46 MMAC/s), outperforming the best ARM Cortex-based solutions by approximately 160x in energy efficiency. The EpiDeNet-SSWCE method demonstrates effective and accurate seizure detection performance on heavily imbalanced datasets, while being suited for implementation on energy-constrained platforms. ",
    "url": "https://arxiv.org/abs/2309.07135",
    "authors": [
      "Thorir Mar Ingolfsson",
      "Upasana Chakraborty",
      "Xiaying Wang",
      "Sandor Beniczky",
      "Pauline Ducouret",
      "Simone Benatti",
      "Philippe Ryvlin",
      "Andrea Cossettini",
      "Luca Benini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07138",
    "title": "Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders",
    "abstract": "The task of blind source separation (BSS) involves separating sources from a mixture without prior knowledge of the sources or the mixing system. This is a challenging problem that often requires making restrictive assumptions about both the mixing system and the sources. In this paper, we propose a novel method for addressing BSS of non-linear mixtures by leveraging the natural feature subspace specialization ability of multi-encoder autoencoders with fully self-supervised learning without strong priors. During the training phase, our method unmixes the input into the separate encoding spaces of the multi-encoder network and then remixes these representations within the decoder for a reconstruction of the input. Then to perform source inference, we introduce a novel encoding masking technique whereby masking out all but one of the encodings enables the decoder to estimate a source signal. To this end, we also introduce a so-called pathway separation loss that encourages sparsity between the unmixed encoding spaces throughout the decoder's layers and a so-called zero reconstruction loss on the decoder for coherent source estimations. In order to carefully evaluate our method, we conduct experiments on a toy dataset and with real-world biosignal recordings from a polysomnography sleep study for extracting respiration. ",
    "url": "https://arxiv.org/abs/2309.07138",
    "authors": [
      "Matthew B. Webster",
      "Joonnyong Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07147",
    "title": "DGSD: Dynamical Graph Self-Distillation for EEG-Based Auditory Spatial  Attention Detection",
    "abstract": "Auditory Attention Detection (AAD) aims to detect target speaker from brain signals in a multi-speaker environment. Although EEG-based AAD methods have shown promising results in recent years, current approaches primarily rely on traditional convolutional neural network designed for processing Euclidean data like images. This makes it challenging to handle EEG signals, which possess non-Euclidean characteristics. In order to address this problem, this paper proposes a dynamical graph self-distillation (DGSD) approach for AAD, which does not require speech stimuli as input. Specifically, to effectively represent the non-Euclidean properties of EEG signals, dynamical graph convolutional networks are applied to represent the graph structure of EEG signals, which can also extract crucial features related to auditory spatial attention in EEG signals. In addition, to further improve AAD detection performance, self-distillation, consisting of feature distillation and hierarchical distillation strategies at each layer, is integrated. These strategies leverage features and classification results from the deepest network layers to guide the learning of shallow layers. Our experiments are conducted on two publicly available datasets, KUL and DTU. Under a 1-second time window, we achieve results of 90.0\\% and 79.6\\% accuracy on KUL and DTU, respectively. We compare our DGSD method with competitive baselines, and the experimental results indicate that the detection performance of our proposed DGSD method is not only superior to the best reproducible baseline but also significantly reduces the number of trainable parameters by approximately 100 times. ",
    "url": "https://arxiv.org/abs/2309.07147",
    "authors": [
      "Cunhang Fan",
      "Hongyu Zhang",
      "Wei Huang",
      "Jun Xue",
      "Jianhua Tao",
      "Jiangyan Yi",
      "Zhao Lv",
      "Xiaopei Wu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07154",
    "title": "Recall-driven Precision Refinement: Unveiling Accurate Fall Detection  using LSTM",
    "abstract": "This paper presents an innovative approach to address the pressing concern of fall incidents among the elderly by developing an accurate fall detection system. Our proposed system combines state-of-the-art technologies, including accelerometer and gyroscope sensors, with deep learning models, specifically Long Short-Term Memory (LSTM) networks. Real-time execution capabilities are achieved through the integration of Raspberry Pi hardware. We introduce pruning techniques that strategically fine-tune the LSTM model's architecture and parameters to optimize the system's performance. We prioritize recall over precision, aiming to accurately identify falls and minimize false negatives for timely intervention. Extensive experimentation and meticulous evaluation demonstrate remarkable performance metrics, emphasizing a high recall rate while maintaining a specificity of 96\\%. Our research culminates in a state-of-the-art fall detection system that promptly sends notifications, ensuring vulnerable individuals receive timely assistance and improve their overall well-being. Applying LSTM models and incorporating pruning techniques represent a significant advancement in fall detection technology, offering an effective and reliable fall prevention and intervention solution. ",
    "url": "https://arxiv.org/abs/2309.07154",
    "authors": [
      "Rishabh Mondal",
      "Prasun Ghosal"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07163",
    "title": "Systematic Review of Experimental Paradigms and Deep Neural Networks for  Electroencephalography-Based Cognitive Workload Detection",
    "abstract": "This article summarizes a systematic review of the electroencephalography (EEG)-based cognitive workload (CWL) estimation. The focus of the article is twofold: identify the disparate experimental paradigms used for reliably eliciting discreet and quantifiable levels of cognitive load and the specific nature and representational structure of the commonly used input formulations in deep neural networks (DNNs) used for signal classification. The analysis revealed a number of studies using EEG signals in its native representation of a two-dimensional matrix for offline classification of CWL. However, only a few studies adopted an online or pseudo-online classification strategy for real-time CWL estimation. Further, only a couple of interpretable DNNs and a single generative model were employed for cognitive load detection till date during this review. More often than not, researchers were using DNNs as black-box type models. In conclusion, DNNs prove to be valuable tools for classifying EEG signals, primarily due to the substantial modeling power provided by the depth of their network architecture. It is further suggested that interpretable and explainable DNN models must be employed for cognitive workload estimation since existing methods are limited in the face of the non-stationary nature of the signal. ",
    "url": "https://arxiv.org/abs/2309.07163",
    "authors": [
      "Vishnu KN",
      "Cota Navin Gupta"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07192",
    "title": "The effect of data augmentation and 3D-CNN depth on Alzheimer's Disease  detection",
    "abstract": "Machine Learning (ML) has emerged as a promising approach in healthcare, outperforming traditional statistical techniques. However, to establish ML as a reliable tool in clinical practice, adherence to best practices regarding data handling, experimental design, and model evaluation is crucial. This work summarizes and strictly observes such practices to ensure reproducible and reliable ML. Specifically, we focus on Alzheimer's Disease (AD) detection, which serves as a paradigmatic example of challenging problem in healthcare. We investigate the impact of different data augmentation techniques and model complexity on the overall performance. We consider MRI data from ADNI dataset to address a classification problem employing 3D Convolutional Neural Network (CNN). The experiments are designed to compensate for data scarcity and initial random parameters by utilizing cross-validation and multiple training trials. Within this framework, we train 15 predictive models, considering three different data augmentation strategies and five distinct 3D CNN architectures, each varying in the number of convolutional layers. Specifically, the augmentation strategies are based on affine transformations, such as zoom, shift, and rotation, applied concurrently or separately. The combined effect of data augmentation and model complexity leads to a variation in prediction performance up to 10% of accuracy. When affine transformation are applied separately, the model is more accurate, independently from the adopted architecture. For all strategies, the model accuracy followed a concave behavior at increasing number of convolutional layers, peaking at an intermediate value of layers. The best model (8 CL, (B)) is the most stable across cross-validation folds and training trials, reaching excellent performance both on the testing set and on an external test set. ",
    "url": "https://arxiv.org/abs/2309.07192",
    "authors": [
      "Rosanna Turrisi",
      "Alessandro Verri",
      "Annalisa Barla"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07193",
    "title": "A Robust SINDy Approach by Combining Neural Networks and an Integral  Form",
    "abstract": "The discovery of governing equations from data has been an active field of research for decades. One widely used methodology for this purpose is sparse regression for nonlinear dynamics, known as SINDy. Despite several attempts, noisy and scarce data still pose a severe challenge to the success of the SINDy approach. In this work, we discuss a robust method to discover nonlinear governing equations from noisy and scarce data. To do this, we make use of neural networks to learn an implicit representation based on measurement data so that not only it produces the output in the vicinity of the measurements but also the time-evolution of output can be described by a dynamical system. Additionally, we learn such a dynamic system in the spirit of the SINDy framework. Leveraging the implicit representation using neural networks, we obtain the derivative information -- required for SINDy -- using an automatic differentiation tool. To enhance the robustness of our methodology, we further incorporate an integral condition on the output of the implicit networks. Furthermore, we extend our methodology to handle data collected from multiple initial conditions. We demonstrate the efficiency of the proposed methodology to discover governing equations under noisy and scarce data regimes by means of several examples and compare its performance with existing methods. ",
    "url": "https://arxiv.org/abs/2309.07193",
    "authors": [
      "Ali Forootani",
      "Pawan Goyal",
      "Peter Benner"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07250",
    "title": "All you need is spin: SU(2) equivariant variational quantum circuits  based on spin networks",
    "abstract": "Variational algorithms require architectures that naturally constrain the optimisation space to run efficiently. In geometric quantum machine learning, one achieves this by encoding group structure into parameterised quantum circuits to include the symmetries of a problem as an inductive bias. However, constructing such circuits is challenging as a concrete guiding principle has yet to emerge. In this paper, we propose the use of spin networks, a form of directed tensor network invariant under a group transformation, to devise SU(2) equivariant quantum circuit ans\\\"atze -- circuits possessing spin rotation symmetry. By changing to the basis that block diagonalises SU(2) group action, these networks provide a natural building block for constructing parameterised equivariant quantum circuits. We prove that our construction is mathematically equivalent to other known constructions, such as those based on twirling and generalised permutations, but more direct to implement on quantum hardware. The efficacy of our constructed circuits is tested by solving the ground state problem of SU(2) symmetric Heisenberg models on the one-dimensional triangular lattice and on the Kagome lattice. Our results highlight that our equivariant circuits boost the performance of quantum variational algorithms, indicating broader applicability to other real-world problems. ",
    "url": "https://arxiv.org/abs/2309.07250",
    "authors": [
      "Richard D. P. East",
      "Guillermo Alonso-Linaje",
      "Chae-Yeun Park"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.07305",
    "title": "SHIELD: Secure Haplotype Imputation Employing Local Differential Privacy",
    "abstract": "We introduce Secure Haplotype Imputation Employing Local Differential privacy (SHIELD), a program for accurately estimating the genotype of target samples at markers that are not directly assayed by array-based genotyping platforms while preserving the privacy of donors to public reference panels. At the core of SHIELD is the Li-Stephens model of genetic recombination, according to which genomic information is comprised of mosaics of ancestral haplotype fragments that coalesce via a Markov random field. We use the standard forward-backward algorithm for inferring the ancestral haplotypes of target genomes, and hence the most likely genotype at unobserved sites, using a reference panel of template haplotypes whose privacy is guaranteed by the randomized response technique from differential privacy. ",
    "url": "https://arxiv.org/abs/2309.07305",
    "authors": [
      "Marc Harary"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.07367",
    "title": "The kernel-balanced equation for deep neural networks",
    "abstract": "Deep neural networks have shown many fruitful applications in this decade. A network can get the generalized function through training with a finite dataset. The degree of generalization is a realization of the proximity scale in the data space. Specifically, the scale is not clear if the dataset is complicated. Here we consider a network for the distribution estimation of the dataset. We show the estimation is unstable and the instability depends on the data density and training duration. We derive the kernel-balanced equation, which gives a short phenomenological description of the solution. The equation tells us the reason for the instability and the mechanism of the scale. The network outputs a local average of the dataset as a prediction and the scale of averaging is determined along the equation. The scale gradually decreases along training and finally results in instability in our case. ",
    "url": "https://arxiv.org/abs/2309.07367",
    "authors": [
      "Kenichi Nakazato"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07449",
    "title": "Rate-Induced Transitions in Networked Complex Adaptive Systems:  Exploring Dynamics and Management Implications Across Ecological, Social, and  Socioecological Systems",
    "abstract": "Complex adaptive systems (CASs), from ecosystems to economies, are open systems and inherently dependent on external conditions. While a system can transition from one state to another based on the magnitude of change in external conditions, the rate of change -- irrespective of magnitude -- may also lead to system state changes due to a phenomenon known as a rate-induced transition (RIT). This study presents a novel framework that captures RITs in CASs through a local model and a network extension where each node contributes to the structural adaptability of others. Our findings reveal how RITs occur at a critical environmental change rate, with lower-degree nodes tipping first due to fewer connections and reduced adaptive capacity. High-degree nodes tip later as their adaptability sources (lower-degree nodes) collapse. This pattern persists across various network structures. Our study calls for an extended perspective when managing CASs, emphasizing the need to focus not only on thresholds of external conditions but also the rate at which those conditions change, particularly in the context of the collapse of surrounding systems that contribute to the focal system's resilience. Our analytical method opens a path to designing management policies that mitigate RIT impacts and enhance resilience in ecological, social, and socioecological systems. These policies could include controlling environmental change rates, fostering system adaptability, implementing adaptive management strategies, and building capacity and knowledge exchange. Our study contributes to the understanding of RIT dynamics and informs effective management strategies for complex adaptive systems in the face of rapid environmental change. ",
    "url": "https://arxiv.org/abs/2309.07449",
    "authors": [
      "V\u00edtor V. Vasconcelos",
      "Fl\u00e1via M.D. Marquitti",
      "Theresa Ong",
      "Lisa C. McManus",
      "Marcus Aguiar",
      "Amanda B. Campos",
      "Partha S. Dutta",
      "Kristen Jovanelly",
      "Victoria Junquera",
      "Jude Kong",
      "Elisabeth H. Krueger",
      "Simon A. Levin",
      "Wenying Liao",
      "Mingzhen Lu",
      "Dhruv Mittal",
      "Mercedes Pascual",
      "Fl\u00e1vio L. Pinheiro",
      "Juan Rocha",
      "Fernando P. Santos",
      "Peter Sloot",
      "Chenyang",
      "Benton Taylor",
      "Eden Tekwa",
      "Sjoerd Terpstra",
      "Andrew R. Tilman",
      "James R. Watson",
      "Luojun Yang",
      "Senay Yitbarek",
      "Qi Zhan"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2309.07453",
    "title": "SC-MAD: Mixtures of Higher-order Networks for Data Augmentation",
    "abstract": "The myriad complex systems with multiway interactions motivate the extension of graph-based pairwise connections to higher-order relations. In particular, the simplicial complex has inspired generalizations of graph neural networks (GNNs) to simplicial complex-based models. Learning on such systems requires large amounts of data, which can be expensive or impossible to obtain. We propose data augmentation of simplicial complexes through both linear and nonlinear mixup mechanisms that return mixtures of existing labeled samples. In addition to traditional pairwise mixup, we present a convex clustering mixup approach for a data-driven relationship among several simplicial complexes. We theoretically demonstrate that the resultant synthetic simplicial complexes interpolate among existing data with respect to homomorphism densities. Our method is demonstrated on both synthetic and real-world datasets for simplicial complex classification. ",
    "url": "https://arxiv.org/abs/2309.07453",
    "authors": [
      "Madeline Navarro",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07466",
    "title": "Codec Data Augmentation for Time-domain Heart Sound Classification",
    "abstract": "Heart auscultations are a low-cost and effective way of detecting valvular heart diseases early, which can save lives. Nevertheless, it has been difficult to scale this screening method since the effectiveness of auscultations is dependent on the skill of doctors. As such, there has been increasing research interest in the automatic classification of heart sounds using deep learning algorithms. However, it is currently difficult to develop good heart sound classification models due to the limited data available for training. In this work, we propose a simple time domain approach, to the heart sound classification problem with a base classification error rate of 0.8 and show that augmentation of the data through codec simulation can improve the classification error rate to 0.2. With data augmentation, our approach outperforms the existing time-domain CNN-BiLSTM baseline model. Critically, our experiments show that codec data augmentation is effective in getting around the data limitation. ",
    "url": "https://arxiv.org/abs/2309.07466",
    "authors": [
      "Ansh Mishra",
      "Jia Qi Yip",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.07498",
    "title": "Hierarchical Metadata Information Constrained Self-Supervised Learning  for Anomalous Sound Detection Under Domain Shift",
    "abstract": "Self-supervised learning methods have achieved promising performance for anomalous sound detection (ASD) under domain shift, where the type of domain shift is considered in feature learning by incorporating section IDs. However, the attributes accompanying audio files under each section, such as machine operating conditions and noise types, have not been considered, although they are also crucial for characterizing domain shifts. In this paper, we present a hierarchical metadata information constrained self-supervised (HMIC) ASD method, where the hierarchical relation between section IDs and attributes is constructed, and used as constraints to obtain finer feature representation. In addition, we propose an attribute-group-center (AGC)-based method for calculating the anomaly score under the domain shift condition. Experiments are performed to demonstrate its improved performance over the state-of-the-art self-supervised methods in DCASE 2022 challenge Task 2. ",
    "url": "https://arxiv.org/abs/2309.07498",
    "authors": [
      "Haiyan Lan",
      "Qiaoxi Zhu",
      "Jian Guan",
      "Yuming Wei",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.07548",
    "title": "Proximal Bellman mappings for reinforcement learning and their  application to robust adaptive filtering",
    "abstract": "This paper aims at the algorithmic/theoretical core of reinforcement learning (RL) by introducing the novel class of proximal Bellman mappings. These mappings are defined in reproducing kernel Hilbert spaces (RKHSs), to benefit from the rich approximation properties and inner product of RKHSs, they are shown to belong to the powerful Hilbertian family of (firmly) nonexpansive mappings, regardless of the values of their discount factors, and possess ample degrees of design freedom to even reproduce attributes of the classical Bellman mappings and to pave the way for novel RL designs. An approximate policy-iteration scheme is built on the proposed class of mappings to solve the problem of selecting online, at every time instance, the \"optimal\" exponent $p$ in a $p$-norm loss to combat outliers in linear adaptive filtering, without training data and any knowledge on the statistical properties of the outliers. Numerical tests on synthetic data showcase the superior performance of the proposed framework over several non-RL and kernel-based RL schemes. ",
    "url": "https://arxiv.org/abs/2309.07548",
    "authors": [
      "Yuki Akiyama",
      "Konstantinos Slavakis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07648",
    "title": "Incorporating Class-based Language Model for Named Entity Recognition in  Factorized Neural Transducer",
    "abstract": "In spite of the excellent strides made by end-to-end (E2E) models in speech recognition in recent years, named entity recognition is still challenging but critical for semantic understanding. In order to enhance the ability to recognize named entities in E2E models, previous studies mainly focus on various rule-based or attention-based contextual biasing algorithms. However, their performance might be sensitive to the biasing weight or degraded by excessive attention to the named entity list, along with a risk of false triggering. Inspired by the success of the class-based language model (LM) in named entity recognition in conventional hybrid systems and the effective decoupling of acoustic and linguistic information in the factorized neural Transducer (FNT), we propose a novel E2E model to incorporate class-based LMs into FNT, which is referred as C-FNT. In C-FNT, the language model score of named entities can be associated with the name class instead of its surface form. The experimental results show that our proposed C-FNT presents significant error reduction in named entities without hurting performance in general word recognition. ",
    "url": "https://arxiv.org/abs/2309.07648",
    "authors": [
      "Peng Wang",
      "Yifan Yang",
      "Zheng Liang",
      "Tian Tan",
      "Shiliang Zhang",
      "Xie Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2007.08284",
    "title": "Area- Efficient VLSI Implementation of Serial-In Parallel-Out Multiplier  Using Polynomial Representation in Finite Field GF(2m)",
    "abstract": " Comments: The simulation results needs to be to verified ",
    "url": "https://arxiv.org/abs/2007.08284",
    "authors": [
      "Saeideh Nabipour",
      "Gholamreza Zare Fatin",
      "Javad Javidan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2105.00495",
    "title": "BAARD: Blocking Adversarial Examples by Testing for Applicability,  Reliability and Decidability",
    "abstract": " Title: BAARD: Blocking Adversarial Examples by Testing for Applicability,  Reliability and Decidability ",
    "url": "https://arxiv.org/abs/2105.00495",
    "authors": [
      "Xinglong Chang",
      "Katharina Dost",
      "Kaiqi Zhao",
      "Ambra Demontis",
      "Fabio Roli",
      "Gill Dobbie",
      "J\u00f6rg Wicker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2105.06031",
    "title": "Joint Community Detection and Rotational Synchronization via  Semidefinite Programming",
    "abstract": " Title: Joint Community Detection and Rotational Synchronization via  Semidefinite Programming ",
    "url": "https://arxiv.org/abs/2105.06031",
    "authors": [
      "Yifeng Fan",
      "Yuehaw Khoo",
      "Zhizhen Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2110.12539",
    "title": "Discrete Acoustic Space for an Efficient Sampling in Neural  Text-To-Speech",
    "abstract": " Comments: 5 pages, 5 figures, accepted at IberSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2110.12539",
    "authors": [
      "Marek Strong",
      "Jonas Rohnke",
      "Antonio Bonafonte",
      "Mateusz \u0141ajszczak",
      "Trevor Wood"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.01996",
    "title": "Pareto Adversarial Robustness: Balancing Spatial Robustness and  Sensitivity-based Robustness",
    "abstract": " Comments: Published in SCIENCE CHINA Information Sciences (SCIS) 2023. Please also refer to the published version in the Journal reference this https URL ",
    "url": "https://arxiv.org/abs/2111.01996",
    "authors": [
      "Ke Sun",
      "Mingjie Li",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07611",
    "title": "Speeding up Learning Quantum States through Group Equivariant  Convolutional Quantum Ans\u00e4tze",
    "abstract": " Comments: 15 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2112.07611",
    "authors": [
      "Han Zheng",
      "Zimu Li",
      "Junyu Liu",
      "Sergii Strelchuk",
      "Risi Kondor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03609",
    "title": "PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement  Learning",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2202.03609",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.05928",
    "title": "Benign Overfitting without Linearity: Neural Network Classifiers Trained  by Gradient Descent for Noisy Linear Data",
    "abstract": " Comments: 39 pages; minor corrections ",
    "url": "https://arxiv.org/abs/2202.05928",
    "authors": [
      "Spencer Frei",
      "Niladri S. Chatterji",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07626",
    "title": "Random Feature Amplification: Feature Learning and Generalization in  Neural Networks",
    "abstract": " Comments: 46 pages; JMLR camera ready revision ",
    "url": "https://arxiv.org/abs/2202.07626",
    "authors": [
      "Spencer Frei",
      "Niladri S. Chatterji",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.02347",
    "title": "Rooted America: Immobility and Segregation of the Inter-county Migration  Networks",
    "abstract": " Title: Rooted America: Immobility and Segregation of the Inter-county Migration  Networks ",
    "url": "https://arxiv.org/abs/2205.02347",
    "authors": [
      "Peng Huang",
      "Carter T. Butts"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2205.08126",
    "title": "The Hamilton compression of highly symmetric graphs",
    "abstract": " Title: The Hamilton compression of highly symmetric graphs ",
    "url": "https://arxiv.org/abs/2205.08126",
    "authors": [
      "Petr Gregor",
      "Arturo Merino",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2206.03420",
    "title": "An Adaptive Federated Relevance Framework for Spatial Temporal Graph  Learning",
    "abstract": " Title: An Adaptive Federated Relevance Framework for Spatial Temporal Graph  Learning ",
    "url": "https://arxiv.org/abs/2206.03420",
    "authors": [
      "Tiehua Zhang",
      "Yuze Liu",
      "Zhishu Shen",
      "Rui Xu",
      "Xin Chen",
      "Xiaowei Huang",
      "Xi Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07745",
    "title": "GLIN: A (G)eneric (L)earned (In)dexing Mechanism for Complex Geometries",
    "abstract": " Title: GLIN: A (G)eneric (L)earned (In)dexing Mechanism for Complex Geometries ",
    "url": "https://arxiv.org/abs/2207.07745",
    "authors": [
      "Congying Wang",
      "Jia Yu",
      "Zhuoyue Zhao"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.08369",
    "title": "PerfCE: Performance Debugging on Databases with Chaos  Engineering-Enhanced Causality Analysis",
    "abstract": " Title: PerfCE: Performance Debugging on Databases with Chaos  Engineering-Enhanced Causality Analysis ",
    "url": "https://arxiv.org/abs/2207.08369",
    "authors": [
      "Zhenlan Ji",
      "Pingchuan Ma",
      "Shuai Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2208.06028",
    "title": "Gaussian Process Surrogate Models for Neural Networks",
    "abstract": " Comments: Proceedings of UAI 2023 ",
    "url": "https://arxiv.org/abs/2208.06028",
    "authors": [
      "Michael Y. Li",
      "Erin Grant",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00305",
    "title": "LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph  Embeddings",
    "abstract": " Comments: AACL 2023 System Demonstrations, the project website is this https URL ",
    "url": "https://arxiv.org/abs/2210.00305",
    "authors": [
      "Xin Xie",
      "Zhoubo Li",
      "Xiaohan Wang",
      "Zekun Xi",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04688",
    "title": "BAFFLE: Backdoor Attack in Offline Reinforcement Learning",
    "abstract": " Comments: 18 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2210.04688",
    "authors": [
      "Chen Gong",
      "Zhou Yang",
      "Yunpeng Bai",
      "Junda He",
      "Jieke Shi",
      "Kecen Li",
      "Arunesh Sinha",
      "Bowen Xu",
      "Xinwen Hou",
      "David Lo",
      "Tianhao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.09815",
    "title": "Improving robustness of spontaneous speech synthesis with linguistic  speech regularization and pseudo-filled-pause insertion",
    "abstract": " Comments: Accepted to SSW12 ",
    "url": "https://arxiv.org/abs/2210.09815",
    "authors": [
      "Yuta Matsunaga",
      "Takaaki Saeki",
      "Shinnosuke Takamichi",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.04674",
    "title": "Lipschitz Continuous Algorithms for Graph Problems",
    "abstract": " Comments: FOCS'23 ",
    "url": "https://arxiv.org/abs/2211.04674",
    "authors": [
      "Soh Kumabe",
      "Yuichi Yoshida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.05363",
    "title": "EmoFake: An Initial Dataset for Emotion Fake Audio Detection",
    "abstract": " Title: EmoFake: An Initial Dataset for Emotion Fake Audio Detection ",
    "url": "https://arxiv.org/abs/2211.05363",
    "authors": [
      "Yan Zhao",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Chenglong Wang",
      "Xiaohui Zhang",
      "Yongfeng Dong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.06660",
    "title": "Far Away in the Deep Space: Dense Nearest-Neighbor-Based  Out-of-Distribution Detection",
    "abstract": " Comments: Workshop on Uncertainty Quantification for Computer Vision, ICCV 2023. Code at: this https URL ",
    "url": "https://arxiv.org/abs/2211.06660",
    "authors": [
      "Silvio Galesso",
      "Max Argus",
      "Thomas Brox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.07260",
    "title": "Scalable Bayesian optimization with high-dimensional outputs using  randomized prior networks",
    "abstract": " Comments: 23 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2302.07260",
    "authors": [
      "Mohamed Aziz Bhouri",
      "Michael Joly",
      "Robert Yu",
      "Soumalya Sarkar",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.13348",
    "title": "Kernel Conditional Moment Constraints for Confounding Robust Inference",
    "abstract": " Title: Kernel Conditional Moment Constraints for Confounding Robust Inference ",
    "url": "https://arxiv.org/abs/2302.13348",
    "authors": [
      "Kei Ishikawa",
      "Niao He"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.00958",
    "title": "A Deep Reinforcement Learning-Based Resource Scheduler for Massive MIMO  Networks",
    "abstract": " Comments: IEEE Transactions on Machine Learning in Communications and Networking (TMLCN) 2023 ",
    "url": "https://arxiv.org/abs/2303.00958",
    "authors": [
      "Qing An",
      "Santiago Segarra",
      "Chris Dick",
      "Ashutosh Sabharwal",
      "Rahman Doost-Mohammady"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.09858",
    "title": "Preventing Unauthorized AI Over-Analysis by Medical Image Adversarial  Watermarking",
    "abstract": " Title: Preventing Unauthorized AI Over-Analysis by Medical Image Adversarial  Watermarking ",
    "url": "https://arxiv.org/abs/2303.09858",
    "authors": [
      "Xingxing Wei",
      "Bangzheng Pu",
      "Shiji Zhao",
      "Chen Chi",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2304.03778",
    "title": "Conformal Regression in Calorie Prediction for Team Jumbo-Visma",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2304.03778",
    "authors": [
      "Kristian van Kuijk",
      "Mark Dirksen",
      "Christof Seiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2304.07097",
    "title": "Interpretable Weighted Siamese Network to Predict the Time to Onset of  Alzheimer's Disease from MRI Images",
    "abstract": " Comments: Accepted at the Specialist Group on Artificial Intelligence, SGAI 2023, conference ",
    "url": "https://arxiv.org/abs/2304.07097",
    "authors": [
      "Misgina Tsighe Hagos",
      "Niamh Belton",
      "Ronan P. Killeen",
      "Kathleen M. Curran",
      "Brian Mac Namee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.12876",
    "title": "Evaluation of Parameter-based Attacks against Embedded Neural Networks  with Laser Injection",
    "abstract": " Comments: Accepted at 42nd International Conference on Computer Safety, Reliability and Security, SafeComp 2023 ",
    "url": "https://arxiv.org/abs/2304.12876",
    "authors": [
      "Mathieu Dumont",
      "Kevin Hector",
      "Pierre-Alain Moellic",
      "Jean-Max Dutertre",
      "Simon Ponti\u00e9"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07180",
    "title": "Robust Saliency-Aware Distillation for Few-shot Fine-grained Visual  Recognition",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2305.07180",
    "authors": [
      "Haiqi Liu",
      "C. L. Philip Chen",
      "Xinrong Gong",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11322",
    "title": "SpikeCP: Delay-Adaptive Reliable Spiking Neural Networks via Conformal  Prediction",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2305.11322",
    "authors": [
      "Jiechen Chen",
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14171",
    "title": "Probing in Context: Toward Building Robust Classifiers via Probing Large  Language Models",
    "abstract": " Title: Probing in Context: Toward Building Robust Classifiers via Probing Large  Language Models ",
    "url": "https://arxiv.org/abs/2305.14171",
    "authors": [
      "Afra Amini",
      "Massimiliano Ciaramita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15376",
    "title": "DeepCollide: Scalable Data-Driven High DoF Configuration Space Modeling  using Implicit Neural Representations",
    "abstract": " Title: DeepCollide: Scalable Data-Driven High DoF Configuration Space Modeling  using Implicit Neural Representations ",
    "url": "https://arxiv.org/abs/2305.15376",
    "authors": [
      "Gabriel Guo",
      "Judah Goldfeder",
      "Aniv Ray",
      "Tony Dear",
      "Hod Lipson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16941",
    "title": "Engagement, User Satisfaction, and the Amplification of Divisive Content  on Social Media",
    "abstract": " Title: Engagement, User Satisfaction, and the Amplification of Divisive Content  on Social Media ",
    "url": "https://arxiv.org/abs/2305.16941",
    "authors": [
      "Smitha Milli",
      "Micah Carroll",
      "Yike Wang",
      "Sashrika Pandey",
      "Sebastian Zhao",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.19862",
    "title": "Self-supervised Learning to Bring Dual Reversed Rolling Shutter Images  Alive",
    "abstract": " Comments: Accepted by ICCV 2023, available at this https URL ",
    "url": "https://arxiv.org/abs/2305.19862",
    "authors": [
      "Wei Shang",
      "Dongwei Ren",
      "Chaoyu Feng",
      "Xiaotao Wang",
      "Lei Lei",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.01522",
    "title": "Auditory Representation Effective for Estimating Vocal Tract Information",
    "abstract": " Comments: This manuscript is a revised version after acceptance for publication in Proc. APSIPA ASC 2023 on August 25, 2023 ",
    "url": "https://arxiv.org/abs/2306.01522",
    "authors": [
      "Toshio Irino",
      "Shintaro Doan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2306.05659",
    "title": "COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in  Language Models",
    "abstract": " Title: COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in  Language Models ",
    "url": "https://arxiv.org/abs/2306.05659",
    "authors": [
      "Zihao Tan",
      "Qingliang Chen",
      "Wenbin Zhu",
      "Yongjian Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.07937",
    "title": "Gibbs-Duhem-Informed Neural Networks for Binary Activity Coefficient  Prediction",
    "abstract": " Title: Gibbs-Duhem-Informed Neural Networks for Binary Activity Coefficient  Prediction ",
    "url": "https://arxiv.org/abs/2306.07937",
    "authors": [
      "Jan G. Rittig",
      "Kobi C. Felton",
      "Alexei A. Lapkin",
      "Alexander Mitsos"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.12794",
    "title": "Overview of Robust and Multilingual Automatic Evaluation Metrics for  Open-Domain Dialogue Systems at DSTC 11 Track 4",
    "abstract": " Title: Overview of Robust and Multilingual Automatic Evaluation Metrics for  Open-Domain Dialogue Systems at DSTC 11 Track 4 ",
    "url": "https://arxiv.org/abs/2306.12794",
    "authors": [
      "Mario Rodr\u00edguez-Cantelar",
      "Chen Zhang",
      "Chengguang Tang",
      "Ke Shi",
      "Sarik Ghazarian",
      "Jo\u00e3o Sedoc",
      "Luis Fernando D'Haro",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.14565",
    "title": "Mitigating Hallucination in Large Multi-Modal Models via Robust  Instruction Tuning",
    "abstract": " Comments: 35 pages, 27 figures. Under Review ",
    "url": "https://arxiv.org/abs/2306.14565",
    "authors": [
      "Fuxiao Liu",
      "Kevin Lin",
      "Linjie Li",
      "Jianfeng Wang",
      "Yaser Yacoob",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.16834",
    "title": "Benchmarking Jetson Edge Devices with an End-to-end Video-based Anomaly  Detection System",
    "abstract": " Comments: Accepted in Future of Information and Communication Conference (FICC) 2024 ",
    "url": "https://arxiv.org/abs/2307.16834",
    "authors": [
      "Hoang Viet Pham",
      "Thinh Gia Tran",
      "Chuong Dinh Le",
      "An Dinh Le",
      "Hien Bich Vo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.01921",
    "title": "Transferable Graph Neural Fingerprint Models for Quick Response to  Future Bio-Threats",
    "abstract": " Comments: 8 pages, 5 figures, 2 tables, accepted by ICLMA2023 ",
    "url": "https://arxiv.org/abs/2308.01921",
    "authors": [
      "Wei Chen",
      "Yihui Ren",
      "Ai Kagawa",
      "Matthew R. Carbone",
      "Samuel Yen-Chi Chen",
      "Xiaohui Qu",
      "Shinjae Yoo",
      "Austin Clyde",
      "Arvind Ramanathan",
      "Rick L. Stevens",
      "Hubertus J. J. van Dam",
      "Deyu Liu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07200",
    "title": "Neural Categorical Priors for Physics-Based Character Control",
    "abstract": " Comments: Accepted to Transactions on Graphics (Proc. ACM SIGGRAPH ASIA 2023) ",
    "url": "https://arxiv.org/abs/2308.07200",
    "authors": [
      "Qingxu Zhu",
      "He Zhang",
      "Mengting Lan",
      "Lei Han"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.08518",
    "title": "Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on  Bidirectional Prediction",
    "abstract": " Title: Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on  Bidirectional Prediction ",
    "url": "https://arxiv.org/abs/2308.08518",
    "authors": [
      "Yuhao Yang",
      "Jun Wu",
      "Yue Wang",
      "Guangjian Zhang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13436",
    "title": "An Intermediate Representation for Composable Typed Streaming Dataflow  Designs",
    "abstract": " Title: An Intermediate Representation for Composable Typed Streaming Dataflow  Designs ",
    "url": "https://arxiv.org/abs/2308.13436",
    "authors": [
      "Matthijs A. Reukers",
      "Yongding Tian",
      "Zaid Al-Ars",
      "Peter Hofstee",
      "Matthijs Brobbel",
      "Johan Peltenburg",
      "Jeroen van Straten"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2308.13469",
    "title": "RestNet: Boosting Cross-Domain Few-Shot Segmentation with Residual  Transformation Network",
    "abstract": " Comments: BMVC 2023 ",
    "url": "https://arxiv.org/abs/2308.13469",
    "authors": [
      "Xinyang Huang",
      "Chuang Zhu",
      "Wenkai Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.15309",
    "title": "Understanding the Privacy Risks of Popular Search Engine Advertising  Systems",
    "abstract": " Title: Understanding the Privacy Risks of Popular Search Engine Advertising  Systems ",
    "url": "https://arxiv.org/abs/2308.15309",
    "authors": [
      "Salim Chouaki",
      "Oana Goga",
      "Hamed Haddadi",
      "Peter Snyder"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.00655",
    "title": "RigNet++: Efficient Repetitive Image Guided Network for Depth Completion",
    "abstract": " Comments: 15 pages. arXiv admin note: text overlap with arXiv:2107.13802 ",
    "url": "https://arxiv.org/abs/2309.00655",
    "authors": [
      "Zhiqiang Yan",
      "Xiang Li",
      "Zhenyu Zhang",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.00855",
    "title": "DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource  Real Estate Appraisal",
    "abstract": " Comments: Accepted by CIKM 2023 ",
    "url": "https://arxiv.org/abs/2309.00855",
    "authors": [
      "Wei-Wei Du",
      "Wei-Yao Wang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.00917",
    "title": "Knowledge Graph Embeddings for Multi-Lingual Structured Representations  of Radiology Reports",
    "abstract": " Title: Knowledge Graph Embeddings for Multi-Lingual Structured Representations  of Radiology Reports ",
    "url": "https://arxiv.org/abs/2309.00917",
    "authors": [
      "Tom van Sonsbeek",
      "Xiantong Zhen",
      "Marcel Worring"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03955",
    "title": "SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with  Simpler Solutions",
    "abstract": " Comments: SIGGRAPH Asia 2023 ",
    "url": "https://arxiv.org/abs/2309.03955",
    "authors": [
      "Nagabhushan Somraj",
      "Adithyan Karanayil",
      "Rajiv Soundararajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2309.04100",
    "title": "Preserved Edge Convolutional Neural Network for Sensitivity Enhancement  of Deuterium Metabolic Imaging (DMI)",
    "abstract": " Title: Preserved Edge Convolutional Neural Network for Sensitivity Enhancement  of Deuterium Metabolic Imaging (DMI) ",
    "url": "https://arxiv.org/abs/2309.04100",
    "authors": [
      "Siyuan Dong",
      "Henk M. De Feyter",
      "Monique A. Thomas",
      "Robin A. de Graaf",
      "James S. Duncan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2309.04612",
    "title": "Self-optimizing Feature Generation via Categorical Hashing  Representation and Hierarchical Reinforcement Crossing",
    "abstract": " Title: Self-optimizing Feature Generation via Categorical Hashing  Representation and Hierarchical Reinforcement Crossing ",
    "url": "https://arxiv.org/abs/2309.04612",
    "authors": [
      "Wangyang Ying",
      "Dongjie Wang",
      "Kunpeng Liu",
      "Leilei Sun",
      "Yanjie Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.05406",
    "title": "Treatment-aware Diffusion Probabilistic Model for Longitudinal MRI  Generation and Diffuse Glioma Growth Prediction",
    "abstract": " Comments: 13 pages, 10 figures, 2 tables, 2 agls, preprints in the IEEE trans. format for submission to IEEE-TMI ",
    "url": "https://arxiv.org/abs/2309.05406",
    "authors": [
      "Qinghui Liu",
      "Elies Fuster-Garcia",
      "Ivar Thokle Hovden",
      "Donatas Sederevicius",
      "Karoline Skogen",
      "Bradley J MacIntosh",
      "Edvard Gr\u00f8dem",
      "Till Schellhorn",
      "Petter Brandal",
      "Atle Bj\u00f8rnerud",
      "Kyrre Eeg Emblem"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.05475",
    "title": "Zero-shot Learning with Minimum Instruction to Extract Social  Determinants and Family History from Clinical Notes using GPT Model",
    "abstract": " Comments: 5 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2309.05475",
    "authors": [
      "Neel Bhate",
      "Ansh Mittal",
      "Zhe He",
      "Xiao Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.05520",
    "title": "When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are  We?",
    "abstract": " Title: When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are  We? ",
    "url": "https://arxiv.org/abs/2309.05520",
    "authors": [
      "Chong Chen",
      "Jianzhong Su",
      "Jiachi Chen",
      "Yanlin Wang",
      "Tingting Bi",
      "Yanli Wang",
      "Xingwei Lin",
      "Ting Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.06573",
    "title": "Data-proximal null-space networks for inverse problems",
    "abstract": " Title: Data-proximal null-space networks for inverse problems ",
    "url": "https://arxiv.org/abs/2309.06573",
    "authors": [
      "Simon G\u00f6ppel",
      "J\u00fcrgen Frikel",
      "Markus Haltmeier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.06724",
    "title": "Deep Nonparametric Convexified Filtering for Computational Photography,  Image Synthesis and Adversarial Defense",
    "abstract": " Title: Deep Nonparametric Convexified Filtering for Computational Photography,  Image Synthesis and Adversarial Defense ",
    "url": "https://arxiv.org/abs/2309.06724",
    "authors": [
      "Jianqiao Wangni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.06800",
    "title": "Uncertainty-aware Traffic Prediction under Missing Data",
    "abstract": " Comments: 11 pages, 3 figures, Accepted as a short paper of IEEE International Conference on Data Mining (ICDM) 2023 ",
    "url": "https://arxiv.org/abs/2309.06800",
    "authors": [
      "Hao Mei",
      "Junxian Li",
      "Zhiming Liang",
      "Guanjie Zheng",
      "Bin Shi",
      "Hua Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.06902",
    "title": "CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign  Detection Under Extreme Conditions",
    "abstract": " Title: CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign  Detection Under Extreme Conditions ",
    "url": "https://arxiv.org/abs/2309.06902",
    "authors": [
      "Haoqin Hong",
      "Yue Zhou",
      "Xiangyu Shu",
      "Xiangfang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.06987",
    "title": "Instance Adaptive Prototypical Contrastive Embedding for Generalized  Zero Shot Learning",
    "abstract": " Comments: 7 pages, 4 figures. Accepted in IJCAI 2023 Workshop on Generalizing from Limited Resources in the Open World ",
    "url": "https://arxiv.org/abs/2309.06987",
    "authors": [
      "Riti Paul",
      "Sahil Vora",
      "Baoxin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07030",
    "title": "Optimal transport distances for directed, weighted graphs: a case study  with cell-cell communication networks",
    "abstract": " Comments: 5 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2309.07030",
    "authors": [
      "James S. Nagai",
      "Ivan G. Costa",
      "Michael T. Schaub"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Genomics (q-bio.GN)",
      "Molecular Networks (q-bio.MN)"
    ]
  }
]