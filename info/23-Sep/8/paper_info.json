[
  {
    "id": "arXiv:2309.03215",
    "title": "Explainable and Trustworthy Traffic Sign Detection for Safe Autonomous  Driving: An Inductive Logic Programming Approach",
    "abstract": "Traffic sign detection is a critical task in the operation of Autonomous Vehicles (AV), as it ensures the safety of all road users. Current DNN-based sign classification systems rely on pixel-level features to detect traffic signs and can be susceptible to adversarial attacks. These attacks involve small, imperceptible changes to a sign that can cause traditional classifiers to misidentify the sign. We propose an Inductive Logic Programming (ILP) based approach for stop sign detection in AVs to address this issue. This method utilises high-level features of a sign, such as its shape, colour, and text, to detect categories of traffic signs. This approach is more robust against adversarial attacks, as it mimics human-like perception and is less susceptible to the limitations of current DNN classifiers. We consider two adversarial attacking methods to evaluate our approach: Robust Physical Perturbation (PR2) and Adversarial Camouflage (AdvCam). These attacks are able to deceive DNN classifiers, causing them to misidentify stop signs as other signs with high confidence. The results show that the proposed ILP-based technique is able to correctly identify all targeted stop signs, even in the presence of PR2 and ADvCam attacks. The proposed learning method is also efficient as it requires minimal training data. Moreover, it is fully explainable, making it possible to debug AVs. ",
    "url": "https://arxiv.org/abs/2309.03215",
    "authors": [
      "Zahra Chaghazardi",
      "Saber Fallah",
      "Alireza Tamaddoni-Nezhad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2309.03219",
    "title": "Companion Animal Disease Diagnostics based on Literal-aware Medical  Knowledge Graph Representation Learning",
    "abstract": "Knowledge graph (KG) embedding has been used to benefit the diagnosis of animal diseases by analyzing electronic medical records (EMRs), such as notes and veterinary records. However, learning representations to capture entities and relations with literal information in KGs is challenging as the KGs show heterogeneous properties and various types of literal information. Meanwhile, the existing methods mostly aim to preserve graph structures surrounding target nodes without considering different types of literals, which could also carry significant information. In this paper, we propose a knowledge graph embedding model for the efficient diagnosis of animal diseases, which could learn various types of literal information and graph structure and fuse them into unified representations, namely LiteralKG. Specifically, we construct a knowledge graph that is built from EMRs along with literal information collected from various animal hospitals. We then fuse different types of entities and node feature information into unified vector representations through gate networks. Finally, we propose a self-supervised learning task to learn graph structure in pretext tasks and then towards various downstream tasks. Experimental results on link prediction tasks demonstrate that our model outperforms the baselines that consist of state-of-the-art models. The source code is available at https://github.com/NSLab-CUK/LiteralKG. ",
    "url": "https://arxiv.org/abs/2309.03219",
    "authors": [
      "Van Thuy Hoang",
      "Sang Thanh Nguyen",
      "Sangmyeong Lee",
      "Jooho Lee",
      "Luong Vuong Nguyen",
      "O-Joun Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03222",
    "title": "Sherlock Holmes Doesn't Play Dice: The significance of Evidence Theory  for the Social and Life Sciences",
    "abstract": "While Evidence Theory (Demster-Shafer Theory, Belief Functions Theory) is being increasingly used in data fusion, its potentialities in the Social and Life Sciences are often obscured by lack of awareness of its distinctive features. With this paper we stress that Evidence Theory can express the uncertainty deriving from the fear that events may materialize, that one has not been able to figure out. By contrast, Probability Theory must limit itself to the possibilities that a decision-maker is currently envisaging. Subsequently, we illustrate how Dempster-Shafer's combination rule relates to Bayes' Theorem for various versions of Probability Theory and discuss which applications of Information Theory can be enhanced by Evidence Theory. Finally, we illustrate our claims with an example where Evidence Theory is used to make sense of the partially overlapping, partially contradictory solutions that appear in an auditing exercise. ",
    "url": "https://arxiv.org/abs/2309.03222",
    "authors": [
      "V. L. Raju Chinthalapati",
      "Guido Fioretti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.03227",
    "title": "Learning a Patent-Informed Biomedical Knowledge Graph Reveals  Technological Potential of Drug Repositioning Candidates",
    "abstract": "Drug repositioning-a promising strategy for discovering new therapeutic uses for existing drugs-has been increasingly explored in the computational science literature using biomedical databases. However, the technological potential of drug repositioning candidates has often been overlooked. This study presents a novel protocol to comprehensively analyse various sources such as pharmaceutical patents and biomedical databases, and identify drug repositioning candidates with both technological potential and scientific evidence. To this end, first, we constructed a scientific biomedical knowledge graph (s-BKG) comprising relationships between drugs, diseases, and genes derived from biomedical databases. Our protocol involves identifying drugs that exhibit limited association with the target disease but are closely located in the s-BKG, as potential drug candidates. We constructed a patent-informed biomedical knowledge graph (p-BKG) by adding pharmaceutical patent information. Finally, we developed a graph embedding protocol to ascertain the structure of the p-BKG, thereby calculating the relevance scores of those candidates with target disease-related patents to evaluate their technological potential. Our case study on Alzheimer's disease demonstrates its efficacy and feasibility, while the quantitative outcomes and systematic methods are expected to bridge the gap between computational discoveries and successful market applications in drug repositioning research. ",
    "url": "https://arxiv.org/abs/2309.03227",
    "authors": [
      "Yongseung Jegal",
      "Jaewoong Choi",
      "Jiho Lee",
      "Ki-Su Park",
      "Seyoung Lee",
      "Janghyeok Yoon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.03239",
    "title": "Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd  Flow Inference",
    "abstract": "Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal for effective traffic management, public service, and urban planning. Despite this importance, due to the limitations of urban sensing techniques, the data quality from most sources is inadequate for monitoring crowd flow at each POI. This renders the inference of accurate crowd flow from low-quality data a critical and challenging task. The complexity is heightened by three key factors: 1) \\emph{The scarcity and rarity of labeled data}, 2) \\emph{The intricate spatio-temporal dependencies among POIs}, and 3) \\emph{The myriad correlations between precise crowd flow and GPS reports}. To address these challenges, we recast the crowd flow inference problem as a self-supervised attributed graph representation learning task and introduce a novel \\underline{C}ontrastive \\underline{S}elf-learning framework for \\underline{S}patio-\\underline{T}emporal data (\\model). Our approach initiates with the construction of a spatial adjacency graph founded on the POIs and their respective distances. We then employ a contrastive learning technique to exploit large volumes of unlabeled spatio-temporal data. We adopt a swapped prediction approach to anticipate the representation of the target subgraph from similar instances. Following the pre-training phase, the model is fine-tuned with accurate crowd flow data. Our experiments, conducted on two real-world datasets, demonstrate that the \\model pre-trained on extensive noisy data consistently outperforms models trained from scratch. ",
    "url": "https://arxiv.org/abs/2309.03239",
    "authors": [
      "Songyu Ke",
      "Ting Li",
      "Li Song",
      "Yanping Sun",
      "Qintian Sun",
      "Junbo Zhang",
      "Yu Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03240",
    "title": "RepSGG: Novel Representations of Entities and Relationships for Scene  Graph Generation",
    "abstract": "Scene Graph Generation (SGG) has achieved significant progress recently. However, most previous works rely heavily on fixed-size entity representations based on bounding box proposals, anchors, or learnable queries. As each representation's cardinality has different trade-offs between performance and computation overhead, extracting highly representative features efficiently and dynamically is both challenging and crucial for SGG. In this work, a novel architecture called RepSGG is proposed to address the aforementioned challenges, formulating a subject as queries, an object as keys, and their relationship as the maximum attention weight between pairwise queries and keys. With more fine-grained and flexible representation power for entities and relationships, RepSGG learns to sample semantically discriminative and representative points for relationship inference. Moreover, the long-tailed distribution also poses a significant challenge for generalization of SGG. A run-time performance-guided logit adjustment (PGLA) strategy is proposed such that the relationship logits are modified via affine transformations based on run-time performance during training. This strategy encourages a more balanced performance between dominant and rare classes. Experimental results show that RepSGG achieves the state-of-the-art or comparable performance on the Visual Genome and Open Images V6 datasets with fast inference speed, demonstrating the efficacy and efficiency of the proposed methods. ",
    "url": "https://arxiv.org/abs/2309.03240",
    "authors": [
      "Hengyue Liu",
      "Bir Bhanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03247",
    "title": "Robust Visual Tracking by Motion Analyzing",
    "abstract": "In recent years, Video Object Segmentation (VOS) has emerged as a complementary method to Video Object Tracking (VOT). VOS focuses on classifying all the pixels around the target, allowing for precise shape labeling, while VOT primarily focuses on the approximate region where the target might be. However, traditional segmentation modules usually classify pixels frame by frame, disregarding information between adjacent frames. In this paper, we propose a new algorithm that addresses this limitation by analyzing the motion pattern using the inherent tensor structure. The tensor structure, obtained through Tucker2 tensor decomposition, proves to be effective in describing the target's motion. By incorporating this information, we achieved competitive results on Four benchmarks LaSOT\\cite{fan2019lasot}, AVisT\\cite{noman2022avist}, OTB100\\cite{7001050}, and GOT-10k\\cite{huang2019got} LaSOT\\cite{fan2019lasot} with SOTA. Furthermore, the proposed tracker is capable of real-time operation, adding value to its practical application. ",
    "url": "https://arxiv.org/abs/2309.03247",
    "authors": [
      "Mohammed Leo",
      "Kurban Ubul",
      "ShengJie Cheng",
      "Michael Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03249",
    "title": "Graph Theory Applications in Advanced Geospatial Research",
    "abstract": "Geospatial sciences include a wide range of applications, from environmental monitoring transportation to infrastructure planning, as well as location-based analysis and services. Graph theory algorithms in mathematics have emerged as indispensable tools in these domains due to their capability to model and analyse spatial relationships efficiently. This technical report explores the applications of graph theory algorithms in geospatial sciences, highlighting their role in network analysis, spatial connectivity, geographic information systems, and various other spatial problem-solving scenarios. It provides a comprehensive idea about the key concepts and algorithms of graph theory that assist the modelling processes. The report provides insights into the practical significance of graph theory in addressing real-world geospatial challenges and opportunities. It lists the extensive research, innovative technologies and methodologies implemented in this field. ",
    "url": "https://arxiv.org/abs/2309.03249",
    "authors": [
      "Surajit Ghosh",
      "Archita Mallick",
      "Anuva Chowdhury",
      "Kounik De Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computers and Society (cs.CY)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2309.03251",
    "title": "Temporal Inductive Path Neural Network for Temporal Knowledge Graph  Reasoning",
    "abstract": "Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph (KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial task that aims to predict future facts based on historical occurrences. The key challenge lies in uncovering structural dependencies within historical subgraphs and temporal patterns. Most existing approaches model TKGs relying on entity modeling, as nodes in the graph play a crucial role in knowledge representation. However, the real-world scenario often involves an extensive number of entities, with new entities emerging over time. This makes it challenging for entity-dependent methods to cope with extensive volumes of entities, and effectively handling newly emerging entities also becomes a significant challenge. Therefore, we propose Temporal Inductive Path Neural Network (TiPNN), which models historical information in an entity-independent perspective. Specifically, TiPNN adopts a unified graph, namely history temporal graph, to comprehensively capture and encapsulate information from history. Subsequently, we utilize the defined query-aware temporal paths to model historical path information related to queries on history temporal graph for the reasoning. Extensive experiments illustrate that the proposed model not only attains significant performance enhancements but also handles inductive settings, while additionally facilitating the provision of reasoning evidence through history temporal graphs. ",
    "url": "https://arxiv.org/abs/2309.03251",
    "authors": [
      "Hao Dong",
      "Pengyang Wang",
      "Meng Xiao",
      "Zhiyuan Ning",
      "Pengfei Wang",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03294",
    "title": "MALITE: Lightweight Malware Detection and Classification for Constrained  Devices",
    "abstract": "Today, malware is one of the primary cyberthreats to organizations. Malware has pervaded almost every type of computing device including the ones having limited memory, battery and computation power such as mobile phones, tablets and embedded devices like Internet-of-Things (IoT) devices. Consequently, the privacy and security of the malware infected systems and devices have been heavily jeopardized. In recent years, researchers have leveraged machine learning based strategies for malware detection and classification. Malware analysis approaches can only be employed in resource constrained environments if the methods are lightweight in nature. In this paper, we present MALITE, a lightweight malware analysis system, that can classify various malware families and distinguish between benign and malicious binaries. MALITE converts a binary into a gray scale or an RGB image and employs low memory and battery power consuming as well as computationally inexpensive malware analysis strategies. We have designed MALITE-MN, a lightweight neural network based architecture and MALITE-HRF, an ultra lightweight random forest based method that uses histogram features extracted by a sliding window. We evaluate the performance of both on six publicly available datasets (Malimg, Microsoft BIG, Dumpware10, MOTIF, Drebin and CICAndMal2017), and compare them to four state-of-the-art malware classification techniques. The results show that MALITE-MN and MALITE-HRF not only accurately identify and classify malware but also respectively consume several orders of magnitude lower resources (in terms of both memory as well as computation capabilities), making them much more suitable for resource constrained environments. ",
    "url": "https://arxiv.org/abs/2309.03294",
    "authors": [
      "Sidharth Anand",
      "Barsha Mitra",
      "Soumyadeep Dey",
      "Abhinav Rao",
      "Rupsa Dhar",
      "Jaideep Vaidya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.03329",
    "title": "MEGANet: Multi-Scale Edge-Guided Attention Network for Weak Boundary  Polyp Segmentation",
    "abstract": "Efficient polyp segmentation in healthcare plays a critical role in enabling early diagnosis of colorectal cancer. However, the segmentation of polyps presents numerous challenges, including the intricate distribution of backgrounds, variations in polyp sizes and shapes, and indistinct boundaries. Defining the boundary between the foreground (i.e. polyp itself) and the background (surrounding tissue) is difficult. To mitigate these challenges, we propose Multi-Scale Edge-Guided Attention Network (MEGANet) tailored specifically for polyp segmentation within colonoscopy images. This network draws inspiration from the fusion of a classical edge detection technique with an attention mechanism. By combining these techniques, MEGANet effectively preserves high-frequency information, notably edges and boundaries, which tend to erode as neural networks deepen. MEGANet is designed as an end-to-end framework, encompassing three key modules: an encoder, which is responsible for capturing and abstracting the features from the input image, a decoder, which focuses on salient features, and the Edge-Guided Attention module (EGA) that employs the Laplacian Operator to accentuate polyp boundaries. Extensive experiments, both qualitative and quantitative, on five benchmark datasets, demonstrate that our EGANet outperforms other existing SOTA methods under six evaluation metrics. Our code is available at \\url{https://github.com/DinhHieuHoang/MEGANet} ",
    "url": "https://arxiv.org/abs/2309.03329",
    "authors": [
      "Nhat-Tan Bui",
      "Dinh-Hieu Hoang",
      "Quang-Thuc Nguyen",
      "Minh-Triet Tran",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03331",
    "title": "Expert Uncertainty and Severity Aware Chest X-Ray Classification by  Multi-Relationship Graph Learning",
    "abstract": "Patients undergoing chest X-rays (CXR) often endure multiple lung diseases. When evaluating a patient's condition, due to the complex pathologies, subtle texture changes of different lung lesions in images, and patient condition differences, radiologists may make uncertain even when they have experienced long-term clinical training and professional guidance, which makes much noise in extracting disease labels based on CXR reports. In this paper, we re-extract disease labels from CXR reports to make them more realistic by considering disease severity and uncertainty in classification. Our contributions are as follows: 1. We re-extracted the disease labels with severity and uncertainty by a rule-based approach with keywords discussed with clinical experts. 2. To further improve the explainability of chest X-ray diagnosis, we designed a multi-relationship graph learning method with an expert uncertainty-aware loss function. 3. Our multi-relationship graph learning method can also interpret the disease classification results. Our experimental results show that models considering disease severity and uncertainty outperform previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2309.03331",
    "authors": [
      "Mengliang Zhang",
      "Xinyue Hu",
      "Lin Gu",
      "Liangchen Liu",
      "Kazuma Kobayashi",
      "Tatsuya Harada",
      "Ronald M. Summers",
      "Yingying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.03340",
    "title": "Parameter Efficient Audio Captioning With Faithful Guidance Using  Audio-text Shared Latent Representation",
    "abstract": "There has been significant research on developing pretrained transformer architectures for multimodal-to-text generation tasks. Albeit performance improvements, such models are frequently overparameterized, hence suffer from hallucination and large memory footprint making them challenging to deploy on edge devices. In this paper, we address both these issues for the application of automated audio captioning. First, we propose a data augmentation technique for generating hallucinated audio captions and show that similarity based on an audio-text shared latent space is suitable for detecting hallucination. Then, we propose a parameter efficient inference time faithful decoding algorithm that enables smaller audio captioning models with performance equivalent to larger models trained with more data. During the beam decoding step, the smaller model utilizes an audio-text shared latent representation to semantically align the generated text with corresponding input audio. Faithful guidance is introduced into the beam probability by incorporating the cosine similarity between latent representation projections of greedy rolled out intermediate beams and audio clip. We show the efficacy of our algorithm on benchmark datasets and evaluate the proposed scheme against baselines using conventional audio captioning and semantic similarity metrics while illustrating tradeoffs between performance and complexity. ",
    "url": "https://arxiv.org/abs/2309.03340",
    "authors": [
      "Arvind Krishna Sridhar",
      "Yinyi Guo",
      "Erik Visser",
      "Rehana Mahfuz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.03347",
    "title": "Tensor Networks for Solving Realistic Time-independent Boltzmann Neutron  Transport Equation",
    "abstract": "Tensor network techniques, known for their low-rank approximation ability that breaks the curse of dimensionality, are emerging as a foundation of new mathematical methods for ultra-fast numerical solutions of high-dimensional Partial Differential Equations (PDEs). Here, we present a mixed Tensor Train (TT)/Quantized Tensor Train (QTT) approach for the numerical solution of time-independent Boltzmann Neutron Transport equations (BNTEs) in Cartesian geometry. Discretizing a realistic three-dimensional (3D) BNTE by (i) diamond differencing, (ii) multigroup-in-energy, and (iii) discrete ordinate collocation leads to huge generalized eigenvalue problems that generally require a matrix-free approach and large computer clusters. Starting from this discretization, we construct a TT representation of the PDE fields and discrete operators, followed by a QTT representation of the TT cores and solving the tensorized generalized eigenvalue problem in a fixed-point scheme with tensor network optimization techniques. We validate our approach by applying it to two realistic examples of 3D neutron transport problems, currently solved by the PARallel TIme-dependent SN (PARTISN) solver. We demonstrate that our TT/QTT method, executed on a standard desktop computer, leads to a yottabyte compression of the memory storage, and more than 7500 times speedup with a discrepancy of less than 1e-5 when compared to the PARTISN solution. ",
    "url": "https://arxiv.org/abs/2309.03347",
    "authors": [
      "Duc P. Truong",
      "Mario I. Ortega",
      "Ismael Boureima",
      "Gianmarco Manzini",
      "Kim \u00d8. Rasmussen",
      "Boian S. Alexandrov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.03351",
    "title": "Using Neural Networks for Fast SAR Roughness Estimation of High  Resolution Images",
    "abstract": "The analysis of Synthetic Aperture Radar (SAR) imagery is an important step in remote sensing applications, and it is a challenging problem due to its inherent speckle noise. One typical solution is to model the data using the $G_I^0$ distribution and extract its roughness information, which in turn can be used in posterior imaging tasks, such as segmentation, classification and interpretation. This leads to the need of quick and reliable estimation of the roughness parameter from SAR data, especially with high resolution images. Unfortunately, traditional parameter estimation procedures are slow and prone to estimation failures. In this work, we proposed a neural network-based estimation framework that first learns how to predict underlying parameters of $G_I^0$ samples and then can be used to estimate the roughness of unseen data. We show that this approach leads to an estimator that is quicker, yields less estimation error and is less prone to failures than the traditional estimation procedures for this problem, even when we use a simple network. More importantly, we show that this same methodology can be generalized to handle image inputs and, even if trained on purely synthetic data for a few seconds, is able to perform real time pixel-wise roughness estimation for high resolution real SAR imagery. ",
    "url": "https://arxiv.org/abs/2309.03351",
    "authors": [
      "Li Fan",
      "Jeova Farias Sales Rocha Neto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2309.03353",
    "title": "Source Camera Identification and Detection in Digital Videos through  Blind Forensics",
    "abstract": "Source camera identification in digital videos is the problem of associating an unknown digital video with its source device, within a closed set of possible devices. The existing techniques in source detection of digital videos try to find a fingerprint of the actual source in the video in form of PRNU (Photo Response Non--Uniformity), and match it against the SPN (Sensor Pattern Noise) of each possible device. The highest correlation indicates the correct source. We investigate the problem of identifying a video source through a feature based approach using machine learning. In this paper, we present a blind forensic technique of video source authentication and identification, based on feature extraction, feature selection and subsequent source classification. The main aim is to determine whether a claimed source for a video is actually its original source. If not, we identify its original source. Our experimental results prove the efficiency of the proposed method compared to traditional fingerprint based technique. ",
    "url": "https://arxiv.org/abs/2309.03353",
    "authors": [
      "Venkata Udaya Sameer",
      "Shilpa Mukhopadhyay",
      "Ruchira Naskar",
      "Ishaan Dali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.03360",
    "title": "ViewMix: Augmentation for Robust Representation in Self-Supervised  Learning",
    "abstract": "Joint Embedding Architecture-based self-supervised learning methods have attributed the composition of data augmentations as a crucial factor for their strong representation learning capabilities. While regional dropout strategies have proven to guide models to focus on lesser indicative parts of the objects in supervised methods, it hasn't been adopted by self-supervised methods for generating positive pairs. This is because the regional dropout methods are not suitable for the input sampling process of the self-supervised methodology. Whereas dropping informative pixels from the positive pairs can result in inefficient training, replacing patches of a specific object with a different one can steer the model from maximizing the agreement between different positive pairs. Moreover, joint embedding representation learning methods have not made robustness their primary training outcome. To this end, we propose the ViewMix augmentation policy, specially designed for self-supervised learning, upon generating different views of the same image, patches are cut and pasted from one view to another. By leveraging the different views created by this augmentation strategy, multiple joint embedding-based self-supervised methodologies obtained better localization capability and consistently outperformed their corresponding baseline methods. It is also demonstrated that incorporating ViewMix augmentation policy promotes robustness of the representations in the state-of-the-art methods. Furthermore, our experimentation and analysis of compute times suggest that ViewMix augmentation doesn't introduce any additional overhead compared to other counterparts. ",
    "url": "https://arxiv.org/abs/2309.03360",
    "authors": [
      "Arjon Das",
      "Xin Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03362",
    "title": "Unity is Strength: Cross-Task Knowledge Distillation to Improve Code  Review Generation",
    "abstract": "Code review is a fundamental process in software development that plays a critical role in ensuring code quality and reducing the likelihood of errors and bugs. However, code review might be complex, subjective, and time-consuming. Comment generation and code refinement are two key tasks of this process and their automation has traditionally been addressed separately in the literature using different approaches. In this paper, we propose a novel deep-learning architecture, DISCOREV, based on cross-task knowledge distillation that addresses these two tasks simultaneously. In our approach, the fine-tuning of the comment generation model is guided by the code refinement model. We implemented this guidance using two strategies, feedback-based learning objective and embedding alignment objective. We evaluated our approach based on cross-task knowledge distillation by comparing it to the state-of-the-art methods that are based on independent training and fine-tuning. Our results show that our approach generates better review comments as measured by the BLEU score. ",
    "url": "https://arxiv.org/abs/2309.03362",
    "authors": [
      "Oussama Ben Sghaier",
      "Lucas Maes",
      "Houari Sahraoui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.03367",
    "title": "Self-Supervised Masked Digital Elevation Models Encoding for  Low-Resource Downstream Tasks",
    "abstract": "The lack of quality labeled data is one of the main bottlenecks for training Deep Learning models. As the task increases in complexity, there is a higher penalty for overfitting and unstable learning. The typical paradigm employed today is Self-Supervised learning, where the model attempts to learn from a large corpus of unstructured and unlabeled data and then transfer that knowledge to the required task. Some notable examples of self-supervision in other modalities are BERT for Large Language Models, Wav2Vec for Speech Recognition, and the Masked AutoEncoder for Vision, which all utilize Transformers to solve a masked prediction task. GeoAI is uniquely poised to take advantage of the self-supervised methodology due to the decades of data collected, little of which is precisely and dependably annotated. Our goal is to extract building and road segmentations from Digital Elevation Models (DEM) that provide a detailed topography of the earths surface. The proposed architecture is the Masked Autoencoder pre-trained on ImageNet (with the limitation that there is a large domain discrepancy between ImageNet and DEM) with an UperNet Head for decoding segmentations. We tested this model with 450 and 50 training images only, utilizing roughly 5% and 0.5% of the original data respectively. On the building segmentation task, this model obtains an 82.1% Intersection over Union (IoU) with 450 Images and 69.1% IoU with only 50 images. On the more challenging road detection task the model obtains an 82.7% IoU with 450 images and 73.2% IoU with only 50 images. Any hand-labeled dataset made today about the earths surface will be immediately obsolete due to the constantly changing nature of the landscape. This motivates the clear necessity for data-efficient learners that can be used for a wide variety of downstream tasks. ",
    "url": "https://arxiv.org/abs/2309.03367",
    "authors": [
      "Priyam Mazumdar",
      "Aiman Soliman",
      "Volodymyr Kindratenko",
      "Luigi Marini",
      "Kenton McHenry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03380",
    "title": "Cyber Recovery from Dynamic Load Altering Attacks: Linking Electricity,  Transportation, and Cyber Networks",
    "abstract": "To address the increasing vulnerability of power grids, significant attention has been focused on the attack detection and impact mitigation. However, it is still unclear how to effectively and quickly recover the cyber and physical networks from a cyberattack. In this context, this paper presents the first investigation of the Cyber Recovery from Dynamic load altering Attack (CRDA). Considering the interconnection among electricity, transportation, and cyber networks, two essential sub-tasks are formulated for the CRDA: i) Optimal design of repair crew routes to remove installed malware and ii) Adaptive adjustment of system operation to eliminate the mitigation costs while guaranteeing stability. To achieve this, linear stability constraints are obtained by estimating the related eigenvalues under the variation of multiple IBR droop gains based on the sensitivity information of strategically selected sampling points. Moreover, to obtain the robust recovery strategy, the potential counter-measures from the adversary during the recovery process are modeled as maximizing the attack impact of remaining compromised resources in each step. A Mixed-Integer Linear Programming (MILP) problem can be finally formulated for the CRDA with the primary objective to reset involved droop gains and secondarily to repair all compromised loads. Case studies are performed in the modified IEEE 39-bus power system to illustrate the effectiveness of the proposed CRDA compared to the benchmark case. ",
    "url": "https://arxiv.org/abs/2309.03380",
    "authors": [
      "Mengxiang Liu",
      "Zhongda Chu",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.03381",
    "title": "Active shooter detection and robust tracking utilizing supplemental  synthetic data",
    "abstract": "The increasing concern surrounding gun violence in the United States has led to a focus on developing systems to improve public safety. One approach to developing such a system is to detect and track shooters, which would help prevent or mitigate the impact of violent incidents. In this paper, we proposed detecting shooters as a whole, rather than just guns, which would allow for improved tracking robustness, as obscuring the gun would no longer cause the system to lose sight of the threat. However, publicly available data on shooters is much more limited and challenging to create than a gun dataset alone. Therefore, we explore the use of domain randomization and transfer learning to improve the effectiveness of training with synthetic data obtained from Unreal Engine environments. This enables the model to be trained on a wider range of data, increasing its ability to generalize to different situations. Using these techniques with YOLOv8 and Deep OC-SORT, we implemented an initial version of a shooter tracking system capable of running on edge hardware, including both a Raspberry Pi and a Jetson Nano. ",
    "url": "https://arxiv.org/abs/2309.03381",
    "authors": [
      "Joshua R. Waite",
      "Jiale Feng",
      "Riley Tavassoli",
      "Laura Harris",
      "Sin Yong Tan",
      "Subhadeep Chakraborty",
      "Soumik Sarkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03386",
    "title": "Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for  Chronic Disease Prediction",
    "abstract": "Positive-Unlabeled (PU) Learning is a challenge presented by binary classification problems where there is an abundance of unlabeled data along with a small number of positive data instances, which can be used to address chronic disease screening problem. State-of-the-art PU learning methods have resulted in the development of various risk estimators, yet they neglect the differences among distinct populations. To address this issue, we present a novel Positive-Unlabeled Learning Tree (PUtree) algorithm. PUtree is designed to take into account communities such as different age or income brackets, in tasks of chronic disease prediction. We propose a novel approach for binary decision-making, which hierarchically builds community-based PU models and then aggregates their deliverables. Our method can explicate each PU model on the tree for the optimized non-leaf PU node splitting. Furthermore, a mask-recovery data augmentation strategy enables sufficient training of the model in individual communities. Additionally, the proposed approach includes an adversarial PU risk estimator to capture hierarchical PU-relationships, and a model fusion network that integrates data from each tree path, resulting in robust binary classification results. We demonstrate the superior performance of PUtree as well as its variants on two benchmarks and a new diabetes-prediction dataset. ",
    "url": "https://arxiv.org/abs/2309.03386",
    "authors": [
      "Yang Wu",
      "Xurui Li",
      "Xuhong Zhang",
      "Yangyang Kang",
      "Changlong Sun",
      "Xiaozhong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03387",
    "title": "Efficient Baselines for Motion Prediction in Autonomous Driving",
    "abstract": "Motion Prediction (MP) of multiple surroundings agents is a crucial task in arbitrarily complex environments, from simple robots to Autonomous Driving Stacks (ADS). Current techniques tackle this problem using end-to-end pipelines, where the input data is usually a rendered top-view of the physical information and the past trajectories of the most relevant agents; leveraging this information is a must to obtain optimal performance. In that sense, a reliable ADS must produce reasonable predictions on time. However, despite many approaches use simple ConvNets and LSTMs to obtain the social latent features, State-Of-The-Art (SOTA) models might be too complex for real-time applications when using both sources of information (map and past trajectories) as well as little interpretable, specially considering the physical information. Moreover, the performance of such models highly depends on the number of available inputs for each particular traffic scenario, which are expensive to obtain, particularly, annotated High-Definition (HD) maps. In this work, we propose several efficient baselines for the well-known Argoverse 1 Motion Forecasting Benchmark. We aim to develop compact models using SOTA techniques for MP, including attention mechanisms and GNNs. Our lightweight models use standard social information and interpretable map information such as points from the driveable area and plausible centerlines by means of a novel preprocessing step based on kinematic constraints, in opposition to black-box CNN-based or too-complex graphs methods for map encoding, to generate plausible multimodal trajectories achieving up-to-pair accuracy with less operations and parameters than other SOTA methods. Our code is publicly available at https://github.com/Cram3r95/mapfe4mp . ",
    "url": "https://arxiv.org/abs/2309.03387",
    "authors": [
      "Carlos G\u00f3mez-Hu\u00e9lamo",
      "Marcos V. Conde",
      "Rafael Barea",
      "Manuel Oca\u00f1a",
      "Luis M. Bergasa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2309.03390",
    "title": "A novel method for iris recognition using BP neural network and parallel  computing by the aid of GPUs (Graphics Processing Units)",
    "abstract": "In this paper, we seek a new method in designing an iris recognition system. In this method, first the Haar wavelet features are extracted from iris images. The advantage of using these features is the high-speed extraction, as well as being unique to each iris. Then the back propagation neural network (BPNN) is used as a classifier. In this system, the BPNN parallel algorithms and their implementation on GPUs have been used by the aid of CUDA in order to speed up the learning process. Finally, the system performance and the speeding outcomes in a way that this algorithm is done in series are presented. ",
    "url": "https://arxiv.org/abs/2309.03390",
    "authors": [
      "Farahnaz Hosseini",
      "Hossein Ebrahimpour",
      "Samaneh Askari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03401",
    "title": "Reasonable Anomaly Detection in Long Sequences",
    "abstract": "Video anomaly detection is a challenging task due to the lack in approaches for representing samples. The visual representations of most existing approaches are limited by short-term sequences of observations which cannot provide enough clues for achieving reasonable detections. In this paper, we propose to completely represent the motion patterns of objects by learning from long-term sequences. Firstly, a Stacked State Machine (SSM) model is proposed to represent the temporal dependencies which are consistent across long-range observations. Then SSM model functions in predicting future states based on past ones, the divergence between the predictions with inherent normal patterns and observed ones determines anomalies which violate normal motion patterns. Extensive experiments are carried out to evaluate the proposed approach on the dataset and existing ones. Improvements over state-of-the-art methods can be observed. Our code is available at https://github.com/AllenYLJiang/Anomaly-Detection-in-Sequences. ",
    "url": "https://arxiv.org/abs/2309.03401",
    "authors": [
      "Yalong Jiang",
      "Changkang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03411",
    "title": "Identifying Defect-Inducing Changes in Visual Code",
    "abstract": "Defects, or bugs, often form during software development. Identifying the root cause of defects is essential to improve code quality, evaluate testing methods, and support defect prediction. Examples of defect-inducing changes can be found using the SZZ algorithm to trace the textual history of defect-fixing changes back to the defect-inducing changes that they fix in line-based code. The line-based approach of the SZZ method is ineffective for visual code that represents source code graphically rather than textually. In this paper we adapt SZZ for visual code and present the \"SZZ Visual Code\" (SZZ-VC) algorithm, that finds changes in visual code based on the differences of graphical elements rather than differences of lines to detect defect-inducing changes. We validated the algorithm for an industry-made AAA video game and 20 music visual programming defects across 12 open source projects. Our results show that SZZ-VC is feasible for detecting defects in visual code for 3 different visual programming languages. ",
    "url": "https://arxiv.org/abs/2309.03411",
    "authors": [
      "Kalvin Eng",
      "Abram Hindle",
      "Alexander Senchenko"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.03414",
    "title": "Predicting Defective Visual Code Changes in a Multi-Language AAA Video  Game Project",
    "abstract": "Video game development increasingly relies on using visual programming languages as the primary way to build video game features. The aim of using visual programming is to move game logic into the hands of game designers, who may not be as well versed in textual coding. In this paper, we empirically observe that there are more defect-inducing commits containing visual code than textual code in a AAA video game project codebase. This indicates that the existing textual code Just-in-Time (JIT) defect prediction models under evaluation by Electronic Arts (EA) may be ineffective as they do not account for changes in visual code. Thus, we focus our research on constructing visual code defect prediction models that encompass visual code metrics and evaluate the models against defect prediction models that use language agnostic features, and textual code metrics. We test our models using features extracted from the historical codebase of a AAA video game project, as well as the historical codebases of 70 open source projects that use textual and visual code. We find that defect prediction models have better performance overall in terms of the area under the ROC curve (AUC), and Mathews Correlation Coefficient (MCC) when incorporating visual code features for projects that contain more commits with visual code than textual code. ",
    "url": "https://arxiv.org/abs/2309.03414",
    "authors": [
      "Kalvin Eng",
      "Abram Hindle",
      "Alexander Senchenko"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.03437",
    "title": "Byzantine-Robust Federated Learning with Variance Reduction and  Differential Privacy",
    "abstract": "Federated learning (FL) is designed to preserve data privacy during model training, where the data remains on the client side (i.e., IoT devices), and only model updates of clients are shared iteratively for collaborative learning. However, this process is vulnerable to privacy attacks and Byzantine attacks: the local model updates shared throughout the FL network will leak private information about the local training data, and they can also be maliciously crafted by Byzantine attackers to disturb the learning. In this paper, we propose a new FL scheme that guarantees rigorous privacy and simultaneously enhances system robustness against Byzantine attacks. Our approach introduces sparsification- and momentum-driven variance reduction into the client-level differential privacy (DP) mechanism, to defend against Byzantine attackers. The security design does not violate the privacy guarantee of the client-level DP mechanism; hence, our approach achieves the same client-level DP guarantee as the state-of-the-art. We conduct extensive experiments on both IID and non-IID datasets and different tasks and evaluate the performance of our approach against different Byzantine attacks by comparing it with state-of-the-art defense methods. The results of our experiments show the efficacy of our framework and demonstrate its ability to improve system robustness against Byzantine attacks while achieving a strong privacy guarantee. ",
    "url": "https://arxiv.org/abs/2309.03437",
    "authors": [
      "Zikai Zhang",
      "Rui Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.03452",
    "title": "Multi-Modality Guidance Network For Missing Modality Inference",
    "abstract": "Multimodal models have gained significant success in recent years. Standard multimodal approaches often assume unchanged modalities from training stage to inference stage. In practice, however, many scenarios fail to satisfy such assumptions with missing modalities during inference, leading to limitations on where multimodal models can be applied. While existing methods mitigate the problem through reconstructing the missing modalities, it increases unnecessary computational cost, which could be just as critical, especially for large, deployed systems. To solve the problem from both sides, we propose a novel guidance network that promotes knowledge sharing during training, taking advantage of the multimodal representations to train better single-modality models for inference. Real-life experiment in violence detection shows that our proposed framework trains single-modality models that significantly outperform its traditionally trained counterparts while maintaining the same inference cost. ",
    "url": "https://arxiv.org/abs/2309.03452",
    "authors": [
      "Zhuokai Zhao",
      "Harish Palani",
      "Tianyi Liu",
      "Lena Evans",
      "Ruth Toner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03466",
    "title": "MIRA: Cracking Black-box Watermarking on Deep Neural Networks via Model  Inversion-based Removal Attacks",
    "abstract": "To protect the intellectual property of well-trained deep neural networks (DNNs), black-box DNN watermarks, which are embedded into the prediction behavior of DNN models on a set of specially-crafted samples, have gained increasing popularity in both academy and industry. Watermark robustness is usually implemented against attackers who steal the protected model and obfuscate its parameters for watermark removal. Recent studies empirically prove the robustness of most black-box watermarking schemes against known removal attempts. In this paper, we propose a novel Model Inversion-based Removal Attack (\\textsc{Mira}), which is watermark-agnostic and effective against most of mainstream black-box DNN watermarking schemes. In general, our attack pipeline exploits the internals of the protected model to recover and unlearn the watermark message. We further design target class detection and recovered sample splitting algorithms to reduce the utility loss caused by \\textsc{Mira} and achieve data-free watermark removal on half of the watermarking schemes. We conduct comprehensive evaluation of \\textsc{Mira} against ten mainstream black-box watermarks on three benchmark datasets and DNN architectures. Compared with six baseline removal attacks, \\textsc{Mira} achieves strong watermark removal effects on the covered watermarks, preserving at least $90\\%$ of the stolen model utility, under more relaxed or even no assumptions on the dataset availability. ",
    "url": "https://arxiv.org/abs/2309.03466",
    "authors": [
      "Yifan Lu",
      "Wenxuan Li",
      "Mi Zhang",
      "Xudong Pan",
      "Min Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03471",
    "title": "Resource Management for IRS-assisted WP-MEC Networks with Practical  Phase Shift Model",
    "abstract": "Wireless powered mobile edge computing (WP-MEC) has been recognized as a promising solution to enhance the computational capability and sustainable energy supply for low-power wireless devices (WDs). However, when the communication links between the hybrid access point (HAP) and WDs are hostile, the energy transfer efficiency and task offloading rate are compromised. To tackle this problem, we propose to employ multiple intelligent reflecting surfaces (IRSs) to WP-MEC networks. Based on the practical IRS phase shift model, we formulate a total computation rate maximization problem by jointly optimizing downlink/uplink IRSs passive beamforming, downlink energy beamforming and uplink multi-user detection (MUD) vector at HAPs, task offloading power and local computing frequency of WDs, and the time slot allocation. Specifically, we first derive the optimal time allocation for downlink wireless energy transmission (WET) to IRSs and the corresponding energy beamforming. Next, with fixed time allocation for the downlink WET to WDs, the original optimization problem can be divided into two independent subproblems. For the WD charging subproblem, the optimal IRSs passive beamforming is derived by utilizing the successive convex approximation (SCA) method and the penalty-based optimization technique, and for the offloading computing subproblem, we propose a joint optimization framework based on the fractional programming (FP) method. Finally, simulation results validate that our proposed optimization method based on the practical phase shift model can achieve a higher total computation rate compared to the baseline schemes. ",
    "url": "https://arxiv.org/abs/2309.03471",
    "authors": [
      "Nana Li",
      "Wanming Hao",
      "Fuhui Zhou",
      "Zheng Chu",
      "Shouyi Yang",
      "Pei Xiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.03472",
    "title": "Perceptual Quality Assessment of 360\u00b0 Images Based on Generative  Scanpath Representation",
    "abstract": "Despite substantial efforts dedicated to the design of heuristic models for omnidirectional (i.e., 360{\\deg}) image quality assessment (OIQA), a conspicuous gap remains due to the lack of consideration for the diversity of viewing behaviors that leads to the varying perceptual quality of 360{\\deg} images. Two critical aspects underline this oversight: the neglect of viewing conditions that significantly sway user gaze patterns and the overreliance on a single viewport sequence from the 360{\\deg} image for quality inference. To address these issues, we introduce a unique generative scanpath representation (GSR) for effective quality inference of 360{\\deg} images, which aggregates varied perceptual experiences of multi-hypothesis users under a predefined viewing condition. More specifically, given a viewing condition characterized by the starting point of viewing and exploration time, a set of scanpaths consisting of dynamic visual fixations can be produced using an apt scanpath generator. Following this vein, we use the scanpaths to convert the 360{\\deg} image into the unique GSR, which provides a global overview of gazed-focused contents derived from scanpaths. As such, the quality inference of the 360{\\deg} image is swiftly transformed to that of GSR. We then propose an efficient OIQA computational framework by learning the quality maps of GSR. Comprehensive experimental results validate that the predictions of the proposed framework are highly consistent with human perception in the spatiotemporal domain, especially in the challenging context of locally distorted 360{\\deg} images under varied viewing conditions. The code will be released at https://github.com/xiangjieSui/GSR. ",
    "url": "https://arxiv.org/abs/2309.03472",
    "authors": [
      "Xiangjie Sui",
      "Hanwei Zhu",
      "Xuelin Liu",
      "Yuming Fang",
      "Shiqi Wang",
      "Zhou Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.03475",
    "title": "InteractionNet: Joint Planning and Prediction for Autonomous Driving  with Transformers",
    "abstract": "Planning and prediction are two important modules of autonomous driving and have experienced tremendous advancement recently. Nevertheless, most existing methods regard planning and prediction as independent and ignore the correlation between them, leading to the lack of consideration for interaction and dynamic changes of traffic scenarios. To address this challenge, we propose InteractionNet, which leverages transformer to share global contextual reasoning among all traffic participants to capture interaction and interconnect planning and prediction to achieve joint. Besides, InteractionNet deploys another transformer to help the model pay extra attention to the perceived region containing critical or unseen vehicles. InteractionNet outperforms other baselines in several benchmarks, especially in terms of safety, which benefits from the joint consideration of planning and forecasting. The code will be available at https://github.com/fujiawei0724/InteractionNet. ",
    "url": "https://arxiv.org/abs/2309.03475",
    "authors": [
      "Jiawei Fu",
      "Yanqing Shen",
      "Zhiqiang Jian",
      "Shitao Chen",
      "Jingmin Xin",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03483",
    "title": "DetermiNet: A Large-Scale Diagnostic Dataset for Complex  Visually-Grounded Referencing using Determiners",
    "abstract": "State-of-the-art visual grounding models can achieve high detection accuracy, but they are not designed to distinguish between all objects versus only certain objects of interest. In natural language, in order to specify a particular object or set of objects of interest, humans use determiners such as \"my\", \"either\" and \"those\". Determiners, as an important word class, are a type of schema in natural language about the reference or quantity of the noun. Existing grounded referencing datasets place much less emphasis on determiners, compared to other word classes such as nouns, verbs and adjectives. This makes it difficult to develop models that understand the full variety and complexity of object referencing. Thus, we have developed and released the DetermiNet dataset , which comprises 250,000 synthetically generated images and captions based on 25 determiners. The task is to predict bounding boxes to identify objects of interest, constrained by the semantics of the given determiner. We find that current state-of-the-art visual grounding models do not perform well on the dataset, highlighting the limitations of existing models on reference and quantification tasks. ",
    "url": "https://arxiv.org/abs/2309.03483",
    "authors": [
      "Clarence Lee",
      "M Ganesh Kumar",
      "Cheston Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03504",
    "title": "Stroke-based Neural Painting and Stylization with Dynamically Predicted  Painting Region",
    "abstract": "Stroke-based rendering aims to recreate an image with a set of strokes. Most existing methods render complex images using an uniform-block-dividing strategy, which leads to boundary inconsistency artifacts. To solve the problem, we propose Compositional Neural Painter, a novel stroke-based rendering framework which dynamically predicts the next painting region based on the current canvas, instead of dividing the image plane uniformly into painting regions. We start from an empty canvas and divide the painting process into several steps. At each step, a compositor network trained with a phasic RL strategy first predicts the next painting region, then a painter network trained with a WGAN discriminator predicts stroke parameters, and a stroke renderer paints the strokes onto the painting region of the current canvas. Moreover, we extend our method to stroke-based style transfer with a novel differentiable distance transform loss, which helps preserve the structure of the input image during stroke-based stylization. Extensive experiments show our model outperforms the existing models in both stroke-based neural painting and stroke-based stylization. Code is available at https://github.com/sjtuplayer/Compositional_Neural_Painter ",
    "url": "https://arxiv.org/abs/2309.03504",
    "authors": [
      "Teng Hu",
      "Ran Yi",
      "Haokun Zhu",
      "Liang Liu",
      "Jinlong Peng",
      "Yabiao Wang",
      "Chengjie Wang",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03506",
    "title": "Towards Robust Natural-Looking Mammography Lesion Synthesis on  Ipsilateral Dual-Views Breast Cancer Analysis",
    "abstract": "In recent years, many mammographic image analysis methods have been introduced for improving cancer classification tasks. Two major issues of mammogram classification tasks are leveraging multi-view mammographic information and class-imbalance handling. In the first problem, many multi-view methods have been released for concatenating features of two or more views for the training and inference stage. Having said that, most multi-view existing methods are not explainable in the meaning of feature fusion, and treat many views equally for diagnosing. Our work aims to propose a simple but novel method for enhancing examined view (main view) by leveraging low-level feature information from the auxiliary view (ipsilateral view) before learning the high-level feature that contains the cancerous features. For the second issue, we also propose a simple but novel malignant mammogram synthesis framework for upsampling minor class samples. Our easy-to-implement and no-training framework has eliminated the current limitation of the CutMix algorithm which is unreliable synthesized images with random pasted patches, hard-contour problems, and domain shift problems. Our results on VinDr-Mammo and CMMD datasets show the effectiveness of our two new frameworks for both multi-view training and synthesizing mammographic images, outperforming the previous conventional methods in our experimental settings. ",
    "url": "https://arxiv.org/abs/2309.03506",
    "authors": [
      "Thanh-Huy Nguyen",
      "Quang Hien Kha",
      "Thai Ngoc Toan Truong",
      "Ba Thinh Lam",
      "Ba Hung Ngo",
      "Quang Vinh Dinh",
      "Nguyen Quoc Khanh Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03512",
    "title": "Behind Recommender Systems: the Geography of the ACM RecSys Community",
    "abstract": "The amount and dissemination rate of media content accessible online is nowadays overwhelming. Recommender Systems filter this information into manageable streams or feeds, adapted to our personal needs or preferences. It is of utter importance that algorithms employed to filter information do not distort or cut out important elements from our perspectives of the world. Under this principle, it is essential to involve diverse views and teams from the earliest stages of their design and development. This has been highlighted, for instance, in recent European Union regulations such as the Digital Services Act, via the requirement of risk monitoring, including the risk of discrimination, and the AI Act, through the requirement to involve people with diverse backgrounds in the development of AI systems. We look into the geographic diversity of the recommender systems research community, specifically by analyzing the affiliation countries of the authors who contributed to the ACM Conference on Recommender Systems (RecSys) during the last 15 years. This study has been carried out in the framework of the Diversity in AI - DivinAI project, whose main objective is the long-term monitoring of diversity in AI forums through a set of indexes. ",
    "url": "https://arxiv.org/abs/2309.03512",
    "authors": [
      "Lorenzo Porcaro",
      "Jo\u00e3o Vinagre",
      "Pedro Frau",
      "Isabelle Hupont",
      "Emilia G\u00f3mez"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.03520",
    "title": "Deep Reinforcement Learning Enabled Joint Deployment and Beamforming in  STAR-RIS Assisted Networks",
    "abstract": "In the new generation of wireless communication systems, reconfigurable intelligent surfaces (RIS) and simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) have become competitive network components to achieve intelligent and reconfigurable network environments. However, existing work has not fully studied the deployment freedom of STAR-RIS, which limits further improvements in network communication performance. Therefore, this paper proposes a solution based on a deep reinforcement learning algorithm to dynamically deploy STAR-RIS and hybrid beamforming to improve the total communication rate of users in mobile wireless networks. The paper constructs a STAR-RIS assisted multi-user multiple-input single-output (MU-MISO) mobile wireless network and jointly optimizes the dynamic deployment strategy of STAR-RIS and the hybrid beamforming strategy to maximize the long-term total communication rate of users. To solve this problem, the paper uses the Proximal Policy Optimization (PPO) algorithm to optimize the deployment of STAR-RIS and the joint beamforming strategy of STAR-RIS and the base station. The trained policy can maximize the downlink transmission rate of the system and meet the real-time decision-making needs of the system. Numerical simulation results show that compared with the traditional scheme without using STAR-RIS and fixed STAR-RIS deployment, the PPO method proposed in this paper can effectively improve the total communication rate of wireless network users in the service area. ",
    "url": "https://arxiv.org/abs/2309.03520",
    "authors": [
      "Zhuoyuan Ma",
      "Qi Zhao",
      "Bai Yan",
      "Jin Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.03522",
    "title": "AR.S.Space: An AR Casual Game for Social Engagement in Work Environments",
    "abstract": "In social situations, individuals often encounter communication challenges, particularly when adapting to new environments. While some studies have acknowledged the potential of AR social games to aid in effective socialization to some extent, little attention has been given to AR HMD-based games specifically designed to facilitate social interactions. In response, we propose AR.S.Space, an AR HMD-based social game that employs augmented reality features to engage users with virtual social agents through asynchronous communication. The game aims to mitigate the unease associated with initial social interactions and foster long-term connections. To assess its efficacy, a user study was conducted within a specific scenario (an office space), gathering quantitative data and qualitative feedback through questionnaires and interviews. The findings highlight the game's potential to enhance socialization in small-scale environments. Moreover, the study offers valuable design guidelines for future research and the application of AR social games in similar settings. ",
    "url": "https://arxiv.org/abs/2309.03522",
    "authors": [
      "Boyuan Chen",
      "Junkun Long",
      "Wenxuan Zheng",
      "Yuzheng Wu",
      "Ziming Li",
      "Yue Li",
      "Hai-Ning Liang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.03523",
    "title": "DGC: Training Dynamic Graphs with Spatio-Temporal Non-Uniformity using  Graph Partitioning by Chunks",
    "abstract": "Dynamic Graph Neural Network (DGNN) has shown a strong capability of learning dynamic graphs by exploiting both spatial and temporal features. Although DGNN has recently received considerable attention by AI community and various DGNN models have been proposed, building a distributed system for efficient DGNN training is still challenging. It has been well recognized that how to partition the dynamic graph and assign workloads to multiple GPUs plays a critical role in training acceleration. Existing works partition a dynamic graph into snapshots or temporal sequences, which only work well when the graph has uniform spatio-temporal structures. However, dynamic graphs in practice are not uniformly structured, with some snapshots being very dense while others are sparse. To address this issue, we propose DGC, a distributed DGNN training system that achieves a 1.25x - 7.52x speedup over the state-of-the-art in our testbed. DGC's success stems from a new graph partitioning method that partitions dynamic graphs into chunks, which are essentially subgraphs with modest training workloads and few inter connections. This partitioning algorithm is based on graph coarsening, which can run very fast on large graphs. In addition, DGC has a highly efficient run-time, powered by the proposed chunk fusion and adaptive stale aggregation techniques. Extensive experimental results on 3 typical DGNN models and 4 popular dynamic graph datasets are presented to show the effectiveness of DGC. ",
    "url": "https://arxiv.org/abs/2309.03523",
    "authors": [
      "Fahao Chen",
      "Peng Li",
      "Celimuge Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03528",
    "title": "Common Ground In Crisis: Causal Narrative Networks of Public Official  Communications During the COVID-19 Pandemic",
    "abstract": "This study investigates the use of causal narratives in public social media communications by U.S. public agencies over the first fifteen months of the COVID-19 pandemic. We extract causal narratives in the form of cause/effect pairs from official communications, analyzing the resulting semantic network to understand the structure and dependencies among concepts within agency discourse and the evolution of that discourse over time. We show that although the semantic network of causally-linked claims is complex and dynamic, there is considerable consistency across agencies in their causal assertions. We also show that the position of concepts within the structure of causal discourse has a significant impact on message retransmission net of controls, an important engagement outcome. ",
    "url": "https://arxiv.org/abs/2309.03528",
    "authors": [
      "Sabrina Mai",
      "Scott Leo Renshaw",
      "Jeannette Sutton",
      "Carter T. Butts"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.03530",
    "title": "Efficient Single Object Detection on Image Patches with Early Exit  Enhanced High-Precision CNNs",
    "abstract": "This paper proposes a novel approach for detecting objects using mobile robots in the context of the RoboCup Standard Platform League, with a primary focus on detecting the ball. The challenge lies in detecting a dynamic object in varying lighting conditions and blurred images caused by fast movements. To address this challenge, the paper presents a convolutional neural network architecture designed specifically for computationally constrained robotic platforms. The proposed CNN is trained to achieve high precision classification of single objects in image patches and to determine their precise spatial positions. The paper further integrates Early Exits into the existing high-precision CNN architecture to reduce the computational cost of easily rejectable cases in the background class. The training process involves a composite loss function based on confidence and positional losses with dynamic weighting and data augmentation. The proposed approach achieves a precision of 100% on the validation dataset and a recall of almost 87%, while maintaining an execution time of around 170 $\\mu$s per hypotheses. By combining the proposed approach with an Early Exit, a runtime optimization of more than 28%, on average, can be achieved compared to the original CNN. Overall, this paper provides an efficient solution for an enhanced detection of objects, especially the ball, in computationally constrained robotic platforms. ",
    "url": "https://arxiv.org/abs/2309.03530",
    "authors": [
      "Arne Moos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.03531",
    "title": "A Robust Negative Learning Approach to Partial Domain Adaptation Using  Source Prototypes",
    "abstract": "This work proposes a robust Partial Domain Adaptation (PDA) framework that mitigates the negative transfer problem by incorporating a robust target-supervision strategy. It leverages ensemble learning and includes diverse, complementary label feedback, alleviating the effect of incorrect feedback and promoting pseudo-label refinement. Rather than relying exclusively on first-order moments for distribution alignment, our approach offers explicit objectives to optimize intra-class compactness and inter-class separation with the inferred source prototypes and highly-confident target samples in a domain-invariant fashion. Notably, we ensure source data privacy by eliminating the need to access the source data during the adaptation phase through a priori inference of source prototypes. We conducted a series of comprehensive experiments, including an ablation analysis, covering a range of partial domain adaptation tasks. Comprehensive evaluations on benchmark datasets corroborate our framework's enhanced robustness and generalization, demonstrating its superiority over existing state-of-the-art PDA approaches. ",
    "url": "https://arxiv.org/abs/2309.03531",
    "authors": [
      "Sandipan Choudhuri",
      "Suli Adeniye",
      "Arunabha Sen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03539",
    "title": "YOLO series target detection algorithms for underwater environments",
    "abstract": "You Only Look Once (YOLO) algorithm is a representative target detection algorithm emerging in 2016, which is known for its balance of computing speed and accuracy, and now plays an important role in various fields of human production and life. However, there are still many limitations in the application of YOLO algorithm in underwater environments due to problems such as dim light and turbid water. With limited land area resources, the ocean must have great potential for future human development. In this paper, starting from the actual needs of marine engineering applications, taking underwater structural health monitoring (SHM) and underwater biological detection as examples, we propose improved methods for the application of underwater YOLO algorithms, and point out the problems that still exist. ",
    "url": "https://arxiv.org/abs/2309.03539",
    "authors": [
      "Chenjie Zhang",
      "Pengcheng Jiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03542",
    "title": "Zero-Shot Scene Graph Generation via Triplet Calibration and Reduction",
    "abstract": "Scene Graph Generation (SGG) plays a pivotal role in downstream vision-language tasks. Existing SGG methods typically suffer from poor compositional generalizations on unseen triplets. They are generally trained on incompletely annotated scene graphs that contain dominant triplets and tend to bias toward these seen triplets during inference. To address this issue, we propose a Triplet Calibration and Reduction (T-CAR) framework in this paper. In our framework, a triplet calibration loss is first presented to regularize the representations of diverse triplets and to simultaneously excavate the unseen triplets in incompletely annotated training scene graphs. Moreover, the unseen space of scene graphs is usually several times larger than the seen space since it contains a huge number of unrealistic compositions. Thus, we propose an unseen space reduction loss to shift the attention of excavation to reasonable unseen compositions to facilitate the model training. Finally, we propose a contextual encoder to improve the compositional generalizations of unseen triplets by explicitly modeling the relative spatial relations between subjects and objects. Extensive experiments show that our approach achieves consistent improvements for zero-shot SGG over state-of-the-art methods. The code is available at https://github.com/jkli1998/T-CAR. ",
    "url": "https://arxiv.org/abs/2309.03542",
    "authors": [
      "Jiankai Li",
      "Yunhong Wang",
      "Weixin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.03548",
    "title": "Trash to Treasure: Low-Light Object Detection via  Decomposition-and-Aggregation",
    "abstract": "Object detection in low-light scenarios has attracted much attention in the past few years. A mainstream and representative scheme introduces enhancers as the pre-processing for regular detectors. However, because of the disparity in task objectives between the enhancer and detector, this paradigm cannot shine at its best ability. In this work, we try to arouse the potential of enhancer + detector. Different from existing works, we extend the illumination-based enhancers (our newly designed or existing) as a scene decomposition module, whose removed illumination is exploited as the auxiliary in the detector for extracting detection-friendly features. A semantic aggregation module is further established for integrating multi-scale scene-related semantic information in the context space. Actually, our built scheme successfully transforms the \"trash\" (i.e., the ignored illumination in the detector) into the \"treasure\" for the detector. Plenty of experiments are conducted to reveal our superiority against other state-of-the-art methods. The code will be public if it is accepted. ",
    "url": "https://arxiv.org/abs/2309.03548",
    "authors": [
      "Xiaohan Cui",
      "Long Ma",
      "Tengyu Ma",
      "Jinyuan Liu",
      "Xin Fan",
      "Risheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03550",
    "title": "Text2Control3D: Controllable 3D Avatar Generation in Neural Radiance  Fields using Geometry-Guided Text-to-Image Diffusion Model",
    "abstract": "Recent advances in diffusion models such as ControlNet have enabled geometrically controllable, high-fidelity text-to-image generation. However, none of them addresses the question of adding such controllability to text-to-3D generation. In response, we propose Text2Control3D, a controllable text-to-3D avatar generation method whose facial expression is controllable given a monocular video casually captured with hand-held camera. Our main strategy is to construct the 3D avatar in Neural Radiance Fields (NeRF) optimized with a set of controlled viewpoint-aware images that we generate from ControlNet, whose condition input is the depth map extracted from the input video. When generating the viewpoint-aware images, we utilize cross-reference attention to inject well-controlled, referential facial expression and appearance via cross attention. We also conduct low-pass filtering of Gaussian latent of the diffusion model in order to ameliorate the viewpoint-agnostic texture problem we observed from our empirical analysis, where the viewpoint-aware images contain identical textures on identical pixel positions that are incomprehensible in 3D. Finally, to train NeRF with the images that are viewpoint-aware yet are not strictly consistent in geometry, our approach considers per-image geometric variation as a view of deformation from a shared 3D canonical space. Consequently, we construct the 3D avatar in a canonical space of deformable NeRF by learning a set of per-image deformation via deformation field table. We demonstrate the empirical results and discuss the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2309.03550",
    "authors": [
      "Sungwon Hwang",
      "Junha Hyung",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03558",
    "title": "Region Generation and Assessment Network for Occluded Person  Re-Identification",
    "abstract": "Person Re-identification (ReID) plays a more and more crucial role in recent years with a wide range of applications. Existing ReID methods are suffering from the challenges of misalignment and occlusions, which degrade the performance dramatically. Most methods tackle such challenges by utilizing external tools to locate body parts or exploiting matching strategies. Nevertheless, the inevitable domain gap between the datasets utilized for external tools and the ReID datasets and the complicated matching process make these methods unreliable and sensitive to noises. In this paper, we propose a Region Generation and Assessment Network (RGANet) to effectively and efficiently detect the human body regions and highlight the important regions. In the proposed RGANet, we first devise a Region Generation Module (RGM) which utilizes the pre-trained CLIP to locate the human body regions using semantic prototypes extracted from text descriptions. Learnable prompt is designed to eliminate domain gap between CLIP datasets and ReID datasets. Then, to measure the importance of each generated region, we introduce a Region Assessment Module (RAM) that assigns confidence scores to different regions and reduces the negative impact of the occlusion regions by lower scores. The RAM consists of a discrimination-aware indicator and an invariance-aware indicator, where the former indicates the capability to distinguish from different identities and the latter represents consistency among the images of the same class of human body regions. Extensive experimental results for six widely-used benchmarks including three tasks (occluded, partial, and holistic) demonstrate the superiority of RGANet against state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2309.03558",
    "authors": [
      "Shuting He",
      "Weihua Chen",
      "Kai Wang",
      "Hao Luo",
      "Fan Wang",
      "Wei Jiang",
      "Henghui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03563",
    "title": "All Labels Together: Low-shot Intent Detection with an Efficient Label  Semantic Encoding Paradigm",
    "abstract": "In intent detection tasks, leveraging meaningful semantic information from intent labels can be particularly beneficial for few-shot scenarios. However, existing few-shot intent detection methods either ignore the intent labels, (e.g. treating intents as indices) or do not fully utilize this information (e.g. only using part of the intent labels). In this work, we present an end-to-end One-to-All system that enables the comparison of an input utterance with all label candidates. The system can then fully utilize label semantics in this way. Experiments on three few-shot intent detection tasks demonstrate that One-to-All is especially effective when the training resource is extremely scarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings. Moreover, we present a novel pretraining strategy for our model that utilizes indirect supervision from paraphrasing, enabling zero-shot cross-domain generalization on intent detection tasks. Our code is at https://github.com/jiangshdd/AllLablesTogethe. ",
    "url": "https://arxiv.org/abs/2309.03563",
    "authors": [
      "Jiangshu Du",
      "Congying Xia",
      "Wenpeng Yin",
      "Tingting Liang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.03564",
    "title": "Evaluating the Efficacy of Supervised Learning vs Large Language Models  for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social  Media",
    "abstract": "Large language models, particularly those akin to the rapidly progressing GPT series, are gaining traction for their expansive influence. While there is keen interest in their applicability within medical domains such as psychology, tangible explorations on real-world data remain scant. Concurrently, users on social media platforms are increasingly vocalizing personal sentiments; under specific thematic umbrellas, these sentiments often manifest as negative emotions, sometimes escalating to suicidal inclinations. Timely discernment of such cognitive distortions and suicidal risks is crucial to effectively intervene and potentially avert dire circumstances. Our study ventured into this realm by experimenting on two pivotal tasks: suicidal risk and cognitive distortion identification on Chinese social media platforms. Using supervised learning as a baseline, we examined and contrasted the efficacy of large language models via three distinct strategies: zero-shot, few-shot, and fine-tuning. Our findings revealed a discernible performance gap between the large language models and traditional supervised learning approaches, primarily attributed to the models' inability to fully grasp subtle categories. Notably, while GPT-4 outperforms its counterparts in multiple scenarios, GPT-3.5 shows significant enhancement in suicide risk classification after fine-tuning. To our knowledge, this investigation stands as the maiden attempt at gauging large language models on Chinese social media tasks. This study underscores the forward-looking and transformative implications of using large language models in the field of psychology. It lays the groundwork for future applications in psychological research and practice. ",
    "url": "https://arxiv.org/abs/2309.03564",
    "authors": [
      "Hongzhi Qi",
      "Qing Zhao",
      "Changwei Song",
      "Wei Zhai",
      "Dan Luo",
      "Shuo Liu",
      "Yi Jing Yu",
      "Fan Wang",
      "Huijing Zou",
      "Bing Xiang Yang",
      "Jianqiang Li",
      "Guanghui Fu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03567",
    "title": "The Devil is in the Tails: How Long-Tailed Code Distributions Impact  Large Language Models",
    "abstract": "Learning-based techniques, especially advanced Large Language Models (LLMs) for code, have gained considerable popularity in various software engineering (SE) tasks. However, most existing works focus on designing better learning-based models and pay less attention to the properties of datasets. Learning-based models, including popular LLMs for code, heavily rely on data, and the data's properties (e.g., data distribution) could significantly affect their behavior. We conducted an exploratory study on the distribution of SE data and found that such data usually follows a skewed distribution (i.e., long-tailed distribution) where a small number of classes have an extensive collection of samples, while a large number of classes have very few samples. We investigate three distinct SE tasks and analyze the impacts of long-tailed distribution on the performance of LLMs for code. Our experimental results reveal that the long-tailed distribution has a substantial impact on the effectiveness of LLMs for code. Specifically, LLMs for code perform between 30.0\\% and 254.0\\% worse on data samples associated with infrequent labels compared to data samples of frequent labels. Our study provides a better understanding of the effects of long-tailed distributions on popular LLMs for code and insights for the future development of SE automation. ",
    "url": "https://arxiv.org/abs/2309.03567",
    "authors": [
      "Xin Zhou",
      "Kisub Kim",
      "Bowen Xu",
      "Jiakun Liu",
      "DongGyun Han",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.03569",
    "title": "Sparse Federated Training of Object Detection in the Internet of  Vehicles",
    "abstract": "As an essential component part of the Intelligent Transportation System (ITS), the Internet of Vehicles (IoV) plays a vital role in alleviating traffic issues. Object detection is one of the key technologies in the IoV, which has been widely used to provide traffic management services by analyzing timely and sensitive vehicle-related information. However, the current object detection methods are mostly based on centralized deep training, that is, the sensitive data obtained by edge devices need to be uploaded to the server, which raises privacy concerns. To mitigate such privacy leakage, we first propose a federated learning-based framework, where well-trained local models are shared in the central server. However, since edge devices usually have limited computing power, plus a strict requirement of low latency in IoVs, we further propose a sparse training process on edge devices, which can effectively lighten the model, and ensure its training efficiency on edge devices, thereby reducing communication overheads. In addition, due to the diverse computing capabilities and dynamic environment, different sparsity rates are applied to edge devices. To further guarantee the performance, we propose, FedWeg, an improved aggregation scheme based on FedAvg, which is designed by the inverse ratio of sparsity rates. Experiments on the real-life dataset using YOLO show that the proposed scheme can achieve the required object detection rate while saving considerable communication costs. ",
    "url": "https://arxiv.org/abs/2309.03569",
    "authors": [
      "Luping Rao",
      "Chuan Ma",
      "Ming Ding",
      "Yuwen Qian",
      "Lu Zhou",
      "Zhe Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03575",
    "title": "Toward High Quality Facial Representation Learning",
    "abstract": "Face analysis tasks have a wide range of applications, but the universal facial representation has only been explored in a few works. In this paper, we explore high-performance pre-training methods to boost the face analysis tasks such as face alignment and face parsing. We propose a self-supervised pre-training framework, called \\textbf{\\it Mask Contrastive Face (MCF)}, with mask image modeling and a contrastive strategy specially adjusted for face domain tasks. To improve the facial representation quality, we use feature map of a pre-trained visual backbone as a supervision item and use a partially pre-trained decoder for mask image modeling. To handle the face identity during the pre-training stage, we further use random masks to build contrastive learning pairs. We conduct the pre-training on the LAION-FACE-cropped dataset, a variants of LAION-FACE 20M, which contains more than 20 million face images from Internet websites. For efficiency pre-training, we explore our framework pre-training performance on a small part of LAION-FACE-cropped and verify the superiority with different pre-training settings. Our model pre-trained with the full pre-training dataset outperforms the state-of-the-art methods on multiple downstream tasks. Our model achieves 0.932 NME$_{diag}$ for AFLW-19 face alignment and 93.96 F1 score for LaPa face parsing. Code is available at https://github.com/nomewang/MCF. ",
    "url": "https://arxiv.org/abs/2309.03575",
    "authors": [
      "Yue Wang",
      "Jinlong Peng",
      "Jiangning Zhang",
      "Ran Yi",
      "Liang Liu",
      "Yabiao Wang",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03598",
    "title": "Enhancing Sample Utilization through Sample Adaptive Augmentation in  Semi-Supervised Learning",
    "abstract": "In semi-supervised learning, unlabeled samples can be utilized through augmentation and consistency regularization. However, we observed certain samples, even undergoing strong augmentation, are still correctly classified with high confidence, resulting in a loss close to zero. It indicates that these samples have been already learned well and do not provide any additional optimization benefits to the model. We refer to these samples as ``naive samples\". Unfortunately, existing SSL models overlook the characteristics of naive samples, and they just apply the same learning strategy to all samples. To further optimize the SSL model, we emphasize the importance of giving attention to naive samples and augmenting them in a more diverse manner. Sample adaptive augmentation (SAA) is proposed for this stated purpose and consists of two modules: 1) sample selection module; 2) sample augmentation module. Specifically, the sample selection module picks out {naive samples} based on historical training information at each epoch, then the naive samples will be augmented in a more diverse manner in the sample augmentation module. Thanks to the extreme ease of implementation of the above modules, SAA is advantageous for being simple and lightweight. We add SAA on top of FixMatch and FlexMatch respectively, and experiments demonstrate SAA can significantly improve the models. For example, SAA helped improve the accuracy of FixMatch from 92.50% to 94.76% and that of FlexMatch from 95.01% to 95.31% on CIFAR-10 with 40 labels. ",
    "url": "https://arxiv.org/abs/2309.03598",
    "authors": [
      "Guan Gui",
      "Zhen Zhao",
      "Lei Qi",
      "Luping Zhou",
      "Lei Wang",
      "Yinghuan Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03603",
    "title": "Enhancing 5G Radio Planning with Graph Representations and Deep Learning",
    "abstract": "The roll out of new mobile network generations poses hard challenges due to various factors such as cost-benefit tradeoffs, existing infrastructure, and new technology aspects. In particular, one of the main challenges for the 5G deployment lies in optimal 5G radio coverage while accounting for diverse service performance metrics. This paper introduces a Deep Learning-based approach to assist in 5G radio planning by utilizing data from previous-generation cells. Our solution relies on a custom graph representation to leverage the information available from existing cells, and employs a Graph Neural Network (GNN) model to process such data efficiently. In our evaluation, we test its potential to model the transition from 4G to 5G NSA using real-world data from a UK mobile network operator. The experimental results show that our solution achieves high accuracy in predicting key performance indicators in new 5G cells, with a Mean Absolute Percentage Error (MAPE)~<17\\% when evaluated on samples from the same area where it was trained. Moreover, we test its generalization capability over various geographical areas not included in the training, achieving a MAPE~<19\\%. This suggests beneficial properties for achieving robust solutions applicable to 5G planning in new areas without the need of retraining. ",
    "url": "https://arxiv.org/abs/2309.03603",
    "authors": [
      "Paul Almasan",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Andra Lutu",
      "Albert Cabellos-Aparicio",
      "Pere Barlet-Ros"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.03616",
    "title": "Filtration Surfaces for Dynamic Graph Classification",
    "abstract": "Existing approaches for classifying dynamic graphs either lift graph kernels to the temporal domain, or use graph neural networks (GNNs). However, current baselines have scalability issues, cannot handle a changing node set, or do not take edge weight information into account. We propose filtration surfaces, a novel method that is scalable and flexible, to alleviate said restrictions. We experimentally validate the efficacy of our model and show that filtration surfaces outperform previous state-of-the-art baselines on datasets that rely on edge weight information. Our method does so while being either completely parameter-free or having at most one parameter, and yielding the lowest overall standard deviation. ",
    "url": "https://arxiv.org/abs/2309.03616",
    "authors": [
      "Franz Srambical",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03617",
    "title": "NeuroCodeBench: a plain C neural network benchmark for software  verification",
    "abstract": "Safety-critical systems with neural network components require strong guarantees. While existing neural network verification techniques have shown great progress towards this goal, they cannot prove the absence of software faults in the network implementation. This paper presents NeuroCodeBench - a verification benchmark for neural network code written in plain C. It contains 32 neural networks with 607 safety properties divided into 6 categories: maths library, activation functions, error-correcting networks, transfer function approximation, probability density estimation and reinforcement learning. Our preliminary evaluation shows that state-of-the-art software verifiers struggle to provide correct verdicts, due to their incomplete support of the standard C mathematical library and the complexity of larger neural networks. ",
    "url": "https://arxiv.org/abs/2309.03617",
    "authors": [
      "Edoardo Manino",
      "Rafael S\u00e1 Menezes",
      "Fedor Shmarov",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.03619",
    "title": "Understanding Self-Supervised Learning of Speech Representation via  Invariance and Redundancy Reduction",
    "abstract": "The choice of the objective function is crucial in emerging high-quality representations from self-supervised learning. This paper investigates how different formulations of the Barlow Twins (BT) objective impact downstream task performance for speech data. We propose Modified Barlow Twins (MBT) with normalized latents to enforce scale-invariance and evaluate on speaker identification, gender recognition and keyword spotting tasks. Our results show MBT improves representation generalization over original BT, especially when fine-tuning with limited target data. This highlights the importance of designing objectives that encourage invariant and transferable representations. Our analysis provides insights into how the BT learning objective can be tailored to produce speech representations that excel when adapted to new downstream tasks. This study is an important step towards developing reusable self-supervised speech representations. ",
    "url": "https://arxiv.org/abs/2309.03619",
    "authors": [
      "Yusuf Brima",
      "Ulf Krumnack",
      "Simone Pika",
      "Gunther Heidemann"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.03631",
    "title": "Insights Into the Inner Workings of Transformer Models for Protein  Function Prediction",
    "abstract": "Motivation: We explored how explainable AI (XAI) can help to shed light into the inner workings of neural networks for protein function prediction, by extending the widely used XAI method of integrated gradients such that latent representations inside of transformer models, which were finetuned to Gene Ontology term and Enzyme Commission number prediction, can be inspected too. Results: The approach enabled us to identify amino acids in the sequences that the transformers pay particular attention to, and to show that these relevant sequence parts reflect expectations from biology and chemistry, both in the embedding layer and inside of the model, where we identified transformer heads with a statistically significant correspondence of attribution maps with ground truth sequence annotations (e.g., transmembrane regions, active sites) across many proteins. Availability and Implementation: Source code can be accessed at https://github.com/markuswenzel/xai-proteins . ",
    "url": "https://arxiv.org/abs/2309.03631",
    "authors": [
      "Markus Wenzel",
      "Erik Gr\u00fcner",
      "Nils Strodthoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2309.03643",
    "title": "High-Speed (7,2) Compressor Using A Fast Carry-Generation Logic based on  Sorting Network",
    "abstract": "Fast binary compressors are the main components of many basic digital calculation units. In this paper, a high-speed (7,2) compressor with a fast carry-generation logic is proposed. The carry-generation logic is based on the sorting network, and it can generate a carry bit within 2 logical stages other than 3 stages as in previous school book full adders. Collaborating with the adjusted full adder logic, the proposed (7,2) compressor achieves using only 11 basic logical stages. Testing this new design in a binary arry with 7 rows and 8 columns, and the result shows that this design have higher proformance than previous designs. This method is suitable for high proformance cases in multiplication design or other cryptography hardware blocks. ",
    "url": "https://arxiv.org/abs/2309.03643",
    "authors": [
      "Wenbo Guo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2309.03647",
    "title": "ProvG-Searcher: A Graph Representation Learning Approach for Efficient  Provenance Graph Search",
    "abstract": "We present ProvG-Searcher, a novel approach for detecting known APT behaviors within system security logs. Our approach leverages provenance graphs, a comprehensive graph representation of event logs, to capture and depict data provenance relations by mapping system entities as nodes and their interactions as edges. We formulate the task of searching provenance graphs as a subgraph matching problem and employ a graph representation learning method. The central component of our search methodology involves embedding of subgraphs in a vector space where subgraph relationships can be directly evaluated. We achieve this through the use of order embeddings that simplify subgraph matching to straightforward comparisons between a query and precomputed subgraph representations. To address challenges posed by the size and complexity of provenance graphs, we propose a graph partitioning scheme and a behavior-preserving graph reduction method. Overall, our technique offers significant computational efficiency, allowing most of the search computation to be performed offline while incorporating a lightweight comparison step during query execution. Experimental results on standard datasets demonstrate that ProvG-Searcher achieves superior performance, with an accuracy exceeding 99% in detecting query behaviors and a false positive rate of approximately 0.02%, outperforming other approaches. ",
    "url": "https://arxiv.org/abs/2309.03647",
    "authors": [
      "Enes Altinisik",
      "Fatih Deniz",
      "Husrev Taha Sencar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.03648",
    "title": "Characterizing Lipschitz Stability of GNN for Fairness",
    "abstract": "The Lipschitz bound, a technique from robust statistics, can limit the maximum changes in the output concerning the input, taking into account associated irrelevant biased factors. It is an efficient and provable method for examining the output stability of machine learning models without incurring additional computation costs. Recently, Graph Neural Networks (GNNs), which operate on non-Euclidean data, have gained significant attention. However, no previous research has investigated the GNN Lipschitz bounds to shed light on stabilizing model outputs, especially when working on non-Euclidean data with inherent biases. Given the inherent biases in common graph data used for GNN training, it poses a serious challenge to constraining the GNN output perturbations induced by input biases, thereby safeguarding fairness during training. Recently, despite the Lipschitz constant's use in controlling the stability of Euclideanneural networks, the calculation of the precise Lipschitz constant remains elusive for non-Euclidean neural networks like GNNs, especially within fairness contexts. To narrow this gap, we begin with the general GNNs operating on an attributed graph, and formulate a Lipschitz bound to limit the changes in the output regarding biases associated with the input. Additionally, we theoretically analyze how the Lipschitz constant of a GNN model could constrain the output perturbations induced by biases learned from data for fairness training. We experimentally validate the Lipschitz bound's effectiveness in limiting biases of the model output. Finally, from a training dynamics perspective, we demonstrate why the theoretical Lipschitz bound can effectively guide the GNN training to better trade-off between accuracy and fairness. ",
    "url": "https://arxiv.org/abs/2309.03648",
    "authors": [
      "Yaning Jia",
      "Chunhui Zhang",
      "Jundong Li",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.03658",
    "title": "BNS-Net: A Dual-channel Sarcasm Detection Method Considering  Behavior-level and Sentence-level Conflicts",
    "abstract": "Sarcasm detection is a binary classification task that aims to determine whether a given utterance is sarcastic. Over the past decade, sarcasm detection has evolved from classical pattern recognition to deep learning approaches, where features such as user profile, punctuation and sentiment words have been commonly employed for sarcasm detection. In real-life sarcastic expressions, behaviors without explicit sentimental cues often serve as carriers of implicit sentimental meanings. Motivated by this observation, we proposed a dual-channel sarcasm detection model named BNS-Net. The model considers behavior and sentence conflicts in two channels. Channel 1: Behavior-level Conflict Channel reconstructs the text based on core verbs while leveraging the modified attention mechanism to highlight conflict information. Channel 2: Sentence-level Conflict Channel introduces external sentiment knowledge to segment the text into explicit and implicit sentences, capturing conflicts between them. To validate the effectiveness of BNS-Net, several comparative and ablation experiments are conducted on three public sarcasm datasets. The analysis and evaluation of experimental results demonstrate that the BNS-Net effectively identifies sarcasm in text and achieves the state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2309.03658",
    "authors": [
      "Liming Zhou",
      "Xiaowei Xu",
      "Xiaodong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.03660",
    "title": "Learning from Limited Heterogeneous Training Data: Meta-Learning for  Unsupervised Zero-Day Web Attack Detection across Web Domains",
    "abstract": "Recently unsupervised machine learning based systems have been developed to detect zero-day Web attacks, which can effectively enhance existing Web Application Firewalls (WAFs). However, prior arts only consider detecting attacks on specific domains by training particular detection models for the domains. These systems require a large amount of training data, which causes a long period of time for model training and deployment. In this paper, we propose RETSINA, a novel meta-learning based framework that enables zero-day Web attack detection across different domains in an organization with limited training data. Specifically, it utilizes meta-learning to share knowledge across these domains, e.g., the relationship between HTTP requests in heterogeneous domains, to efficiently train detection models. Moreover, we develop an adaptive preprocessing module to facilitate semantic analysis of Web requests across different domains and design a multi-domain representation method to capture semantic correlations between different domains for cross-domain model training. We conduct experiments using four real-world datasets on different domains with a total of 293M Web requests. The experimental results demonstrate that RETSINA outperforms the existing unsupervised Web attack detection methods with limited training data, e.g., RETSINA needs only 5-minute training data to achieve comparable detection performance to the existing methods that train separate models for different domains using 1-day training data. We also conduct real-world deployment in an Internet company. RETSINA captures on average 126 and 218 zero-day attack requests per day in two domains, respectively, in one month. ",
    "url": "https://arxiv.org/abs/2309.03660",
    "authors": [
      "Peiyang Li",
      "Ye Wang",
      "Qi Li",
      "Zhuotao Liu",
      "Ke Xu",
      "Ju Ren",
      "Zhiying Liu",
      "Ruilin Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.03664",
    "title": "Alzheimer Disease Detection from Raman Spectroscopy of the Cerebrospinal  Fluid via Topological Machine Learning",
    "abstract": "The cerebrospinal fluid (CSF) of 19 subjects who received a clinical diagnosis of Alzheimer's disease (AD) as well as of 5 pathological controls have been collected and analysed by Raman spectroscopy (RS). We investigated whether the raw and preprocessed Raman spectra could be used to distinguish AD from controls. First, we applied standard Machine Learning (ML) methods obtaining unsatisfactory results. Then, we applied ML to a set of topological descriptors extracted from raw spectra, achieving a very good classification accuracy (>87%). Although our results are preliminary, they indicate that RS and topological analysis together may provide an effective combination to confirm or disprove a clinical diagnosis of AD. The next steps will include enlarging the dataset of CSF samples to validate the proposed method better and, possibly, to understand if topological data analysis could support the characterization of AD subtypes. ",
    "url": "https://arxiv.org/abs/2309.03664",
    "authors": [
      "Francesco Conti",
      "Martina Banchelli",
      "Valentina Bessi",
      "Cristina Cecchi",
      "Fabrizio Chiti",
      "Sara Colantonio",
      "Cristiano D'Andrea",
      "Marella de Angelis",
      "Davide Moroni",
      "Benedetta Nacmias",
      "Maria Antonietta Pascali",
      "Sandro Sorbi",
      "Paolo Matteini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03665",
    "title": "How adversarial attacks can disrupt seemingly stable accurate  classifiers",
    "abstract": "Adversarial attacks dramatically change the output of an otherwise accurate learning system using a seemingly inconsequential modification to a piece of input data. Paradoxically, empirical evidence indicates that even systems which are robust to large random perturbations of the input data remain susceptible to small, easily constructed, adversarial perturbations of their inputs. Here, we show that this may be seen as a fundamental feature of classifiers working with high dimensional input data. We introduce a simple generic and generalisable framework for which key behaviours observed in practical systems arise with high probability -- notably the simultaneous susceptibility of the (otherwise accurate) model to easily constructed adversarial attacks, and robustness to random perturbations of the input data. We confirm that the same phenomena are directly observed in practical neural networks trained on standard image classification problems, where even large additive random noise fails to trigger the adversarial instability of the network. A surprising takeaway is that even small margins separating a classifier's decision surface from training and testing data can hide adversarial susceptibility from being detected using randomly sampled perturbations. Counterintuitively, using additive noise during training or testing is therefore inefficient for eradicating or detecting adversarial examples, and more demanding adversarial training is required. ",
    "url": "https://arxiv.org/abs/2309.03665",
    "authors": [
      "Oliver J. Sutton",
      "Qinghua Zhou",
      "Ivan Y. Tyukin",
      "Alexander N. Gorban",
      "Alexander Bastounis",
      "Desmond J. Higham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03670",
    "title": "Social Media Influence Operations",
    "abstract": "Social media platforms enable largely unrestricted many-to-many communication. In times of crisis, they offer a space for collective sense-making and gave rise to new social phenomena (e.g. open-source investigations). However, they also serve as a tool for threat actors to conduct cyber-enabled social influence operations (CeSIOs) in order to shape public opinion and interfere in decision-making processes. CeSIOs rely on the employment of sock puppet accounts to engage authentic users in online communication, exert influence, and subvert online discourse. Large Language Models (LLMs) may further enhance the deceptive properties of sock puppet accounts. Recent LLMs are able to generate targeted and persuasive text which is for the most part indistinguishable from human-written content -- ideal features for covert influence. This article reviews recent developments at the intersection of LLMs and influence operations, summarizes LLMs' salience, and explores the potential impact of LLM-instrumented sock puppet accounts for CeSIOs. Finally, mitigation measures for the near future are highlighted. ",
    "url": "https://arxiv.org/abs/2309.03670",
    "authors": [
      "Raphael Meier"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.03681",
    "title": "Manipulation of Neuronal Network Firing Patterns using Temporal Deep  Unfolding-based MPC",
    "abstract": "Because neuronal networks are intricate systems composed of interconnected neurons, their control poses challenges owing to their nonlinearity and complexity. In this paper, we propose a method to design control input to a neuronal network to manipulate the firing patterns of modules within the network. We propose a methodology for designing a control input based on temporal deep unfolding-based model predictive control (TDU-MPC), a control methodology based on the deep unfolding technique actively investigated in the context of wireless signal processing. During the method development, we address the unique characteristics of neuron dynamics, such as zero gradients in firing times, by approximating input currents using a sigmoid function. The effectiveness of the proposed method is confirmed via numerical simulations. In networks with 15 and 30 neurons, the control was achieved to switch the firing frequencies of two modules without directly applying control inputs. This study includes a tailored methodology for networked neurons, the extension of TDU-MPC to nonlinear systems with reset dynamics, and the achievement of desired firing patterns in neuronal networks. ",
    "url": "https://arxiv.org/abs/2309.03681",
    "authors": [
      "Jumpei Aizawa",
      "Masaki Ogura",
      "Masanori Shimono",
      "Naoki Wakamiya"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.03685",
    "title": "PyGraft: Configurable Generation of Schemas and Knowledge Graphs at Your  Fingertips",
    "abstract": "Knowledge graphs (KGs) have emerged as a prominent data representation and management paradigm. Being usually underpinned by a schema (e.g. an ontology), KGs capture not only factual information but also contextual knowledge. In some tasks, a few KGs established themselves as standard benchmarks. However, recent works outline that relying on a limited collection of datasets is not sufficient to assess the generalization capability of an approach. In some data-sensitive fields such as education or medicine, access to public datasets is even more limited. To remedy the aforementioned issues, we release PyGraft, a Python-based tool that generates highly customized, domain-agnostic schemas and knowledge graphs. The synthesized schemas encompass various RDFS and OWL constructs, while the synthesized KGs emulate the characteristics and scale of real-world KGs. Logical consistency of the generated resources is ultimately ensured by running a description logic (DL) reasoner. By providing a way of generating both a schema and KG in a single pipeline, PyGraft's aim is to empower the generation of a more diverse array of KGs for benchmarking novel approaches in areas such as graph-based machine learning (ML), or more generally KG processing. In graph-based ML in particular, this should foster a more holistic evaluation of model performance and generalization capability, thereby going beyond the limited collection of available benchmarks. PyGraft is available at: https://github.com/nicolas-hbt/pygraft. ",
    "url": "https://arxiv.org/abs/2309.03685",
    "authors": [
      "Nicolas Hubert",
      "Pierre Monnin",
      "Mathieu d'Aquin",
      "Armelle Brun",
      "Davy Monticolo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.03694",
    "title": "Short-Term Load Forecasting Using A Particle-Swarm Optimized Multi-Head  Attention-Augmented CNN-LSTM Network",
    "abstract": "Short-term load forecasting is of paramount importance in the efficient operation and planning of power systems, given its inherent non-linear and dynamic nature. Recent strides in deep learning have shown promise in addressing this challenge. However, these methods often grapple with hyperparameter sensitivity, opaqueness in interpretability, and high computational overhead for real-time deployment. In this paper, I propose a novel solution that surmounts these obstacles. Our approach harnesses the power of the Particle-Swarm Optimization algorithm to autonomously explore and optimize hyperparameters, a Multi-Head Attention mechanism to discern the salient features crucial for accurate forecasting, and a streamlined framework for computational efficiency. Our method undergoes rigorous evaluation using a genuine electricity demand dataset. The results underscore its superiority in terms of accuracy, robustness, and computational efficiency. Notably, our Mean Absolute Percentage Error of 1.9376 marks a significant advancement over existing state-of-the-art approaches, heralding a new era in short-term load forecasting. ",
    "url": "https://arxiv.org/abs/2309.03694",
    "authors": [
      "Paapa Kwesi Quansah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.03696",
    "title": "Efficient Adaptive Human-Object Interaction Detection with  Concept-guided Memory",
    "abstract": "Human Object Interaction (HOI) detection aims to localize and infer the relationships between a human and an object. Arguably, training supervised models for this task from scratch presents challenges due to the performance drop over rare classes and the high computational cost and time required to handle long-tailed distributions of HOIs in complex HOI scenes in realistic settings. This observation motivates us to design an HOI detector that can be trained even with long-tailed labeled data and can leverage existing knowledge from pre-trained models. Inspired by the powerful generalization ability of the large Vision-Language Models (VLM) on classification and retrieval tasks, we propose an efficient Adaptive HOI Detector with Concept-guided Memory (ADA-CM). ADA-CM has two operating modes. The first mode makes it tunable without learning new parameters in a training-free paradigm. Its second mode incorporates an instance-aware adapter mechanism that can further efficiently boost performance if updating a lightweight set of parameters can be afforded. Our proposed method achieves competitive results with state-of-the-art on the HICO-DET and V-COCO datasets with much less training time. Code can be found at https://github.com/ltttpku/ADA-CM. ",
    "url": "https://arxiv.org/abs/2309.03696",
    "authors": [
      "Ting Lei",
      "Fabian Caba",
      "Qingchao Chen",
      "Hailin Jin",
      "Yuxin Peng",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03701",
    "title": "User's Reaction Patterns in Online Social Network Communities",
    "abstract": "Several one-fits-all intervention policies were introduced by the Online Social Networks (OSNs) platforms to mitigate potential harms. Nevertheless, some studies showed the limited effectiveness of these approaches. An alternative to this would be a user-centered design of intervention policies. In this context, we study the susceptibility of users to undesired behavior in communities on OSNs. In particular, we explore their reaction to specific events. Our study shows that communities develop different undesired behavior patterns in reaction to specific events. These events can significantly alter the behavior of the community and invert the dynamics of behavior within the whole network. Our findings stress out the importance of understanding the reasons behind the changes in users' reactions and highlights the need of fine-tuning the research to the individual's level. It paves the way towards building better OSNs' intervention strategies centered on the user. ",
    "url": "https://arxiv.org/abs/2309.03701",
    "authors": [
      "Azza Bouleimen",
      "Nicol\u00f2 Pagan",
      "Stefano Cresci",
      "Aleksandra Urman",
      "Gianluca Nogara",
      "Silvia Giordano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.03702",
    "title": "DiffDefense: Defending against Adversarial Attacks via Diffusion Models",
    "abstract": "This paper presents a novel reconstruction method that leverages Diffusion Models to protect machine learning classifiers against adversarial attacks, all without requiring any modifications to the classifiers themselves. The susceptibility of machine learning models to minor input perturbations renders them vulnerable to adversarial attacks. While diffusion-based methods are typically disregarded for adversarial defense due to their slow reverse process, this paper demonstrates that our proposed method offers robustness against adversarial threats while preserving clean accuracy, speed, and plug-and-play compatibility. Code at: https://github.com/HondamunigePrasannaSilva/DiffDefence. ",
    "url": "https://arxiv.org/abs/2309.03702",
    "authors": [
      "Hondamunige Prasanna Silva",
      "Lorenzo Seidenari",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03710",
    "title": "A State Representation for Diminishing Rewards",
    "abstract": "A common setting in multitask reinforcement learning (RL) demands that an agent rapidly adapt to various stationary reward functions randomly sampled from a fixed distribution. In such situations, the successor representation (SR) is a popular framework which supports rapid policy evaluation by decoupling a policy's expected discounted, cumulative state occupancies from a specific reward function. However, in the natural world, sequential tasks are rarely independent, and instead reflect shifting priorities based on the availability and subjective perception of rewarding stimuli. Reflecting this disjunction, in this paper we study the phenomenon of diminishing marginal utility and introduce a novel state representation, the $\\lambda$ representation ($\\lambda$R) which, surprisingly, is required for policy evaluation in this setting and which generalizes the SR as well as several other state representations from the literature. We establish the $\\lambda$R's formal properties and examine its normative advantages in the context of machine learning, as well as its usefulness for studying natural behaviors, particularly foraging. ",
    "url": "https://arxiv.org/abs/2309.03710",
    "authors": [
      "Ted Moskovitz",
      "Samo Hromadka",
      "Ahmed Touati",
      "Diana Borsa",
      "Maneesh Sahani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03720",
    "title": "A Natural Gas Consumption Forecasting System for Continual Learning  Scenarios based on Hoeffding Trees with Change Point Detection Mechanism",
    "abstract": "Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities. However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security. This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing. The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model collection for successive time frames. Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points. These models were compared with change point agnostic baseline approaches. Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed. Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks. ",
    "url": "https://arxiv.org/abs/2309.03720",
    "authors": [
      "Radek Svoboda",
      "Sebastian Basterrech",
      "J\u0119drzej Kozal",
      "Jan Plato\u0161",
      "Micha\u0142 Wo\u017aniak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03722",
    "title": "A boundary-aware point clustering approach in Euclidean and embedding  spaces for roof plane segmentation",
    "abstract": "Roof plane segmentation from airborne LiDAR point clouds is an important technology for 3D building model reconstruction. One of the key issues of plane segmentation is how to design powerful features that can exactly distinguish adjacent planar patches. The quality of point feature directly determines the accuracy of roof plane segmentation. Most of existing approaches use handcrafted features to extract roof planes. However, the abilities of these features are relatively low, especially in boundary area. To solve this problem, we propose a boundary-aware point clustering approach in Euclidean and embedding spaces constructed by a multi-task deep network for roof plane segmentation. We design a three-branch network to predict semantic labels, point offsets and extract deep embedding features. In the first branch, we classify the input data as non-roof, boundary and plane points. In the second branch, we predict point offsets for shifting each point toward its respective instance center. In the third branch, we constrain that points of the same plane instance should have the similar embeddings. We aim to ensure that points of the same plane instance are close as much as possible in both Euclidean and embedding spaces. However, although deep network has strong feature representative ability, it is still hard to accurately distinguish points near plane instance boundary. Therefore, we first group plane points into many clusters in the two spaces, and then we assign the rest boundary points to their closest clusters to generate final complete roof planes. In this way, we can effectively reduce the influence of unreliable boundary points. In addition, we construct a synthetic dataset and a real dataset to train and evaluate our approach. The experiments results show that the proposed approach significantly outperforms the existing state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2309.03722",
    "authors": [
      "Li Li",
      "Qingqing Li",
      "Guozheng Xu",
      "Pengwei Zhou",
      "Jingmin Tu",
      "Jie Li",
      "Jian Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03724",
    "title": "HSTF-Model: an HTTP-based Trojan Detection Model via the Hierarchical  Spatio-Temporal Features of Traffics",
    "abstract": "HTTP-based Trojan is extremely threatening, and it is difficult to be effectively detected because of its concealment and confusion. Previous detection methods usually are with poor generalization ability due to outdated datasets and reliance on manual feature extraction, which makes these methods always perform well under their private dataset, but poorly or even fail to work in real network environment. In this paper, we propose an HTTP-based Trojan detection model via the Hierarchical Spatio-Temporal Features of traffics (HSTF-Model) based on the formalized description of traffic spatio-temporal behavior from both packet level and flow level. In this model, we employ Convolutional Neural Network (CNN) to extract spatial information and Long Short-Term Memory (LSTM) to extract temporal information. In addition, we present a dataset consisting of Benign and Trojan HTTP Traffic (BTHT-2018). Experimental results show that our model can guarantee high accuracy (the F1 of 98.62%-99.81% and the FPR of 0.34%-0.02% in BTHT-2018). More importantly, our model has a huge advantage over other related methods in generalization ability. HSTF-Model trained with BTHT-2018 can reach the F1 of 93.51% on the public dataset ISCX-2012, which is 20+% better than the best of related machine learning methods. ",
    "url": "https://arxiv.org/abs/2309.03724",
    "authors": [
      "Jiang Xie",
      "Shuhao Lia",
      "Xiaochun Yun",
      "Yongzheng Zhang",
      "Peng Chang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.03728",
    "title": "Adjacency Sketches in Adversarial Environments",
    "abstract": "An adjacency sketching or implicit labeling scheme for a family $\\cal F$ of graphs is a method that defines for any $n$ vertex $G \\in \\cal F$ an assignment of labels to each vertex in $G$, so that the labels of two vertices tell you whether or not they are adjacent. The goal is to come up with labeling schemes that use as few bits as possible to represent the labels. By using randomness when assigning labels, it is sometimes possible to produce adjacency sketches with much smaller label sizes, but this comes at the cost of introducing some probability of error. Both deterministic and randomized labeling schemes have been extensively studied, as they have applications for distributed data structures and deeper connections to universal graphs and communication complexity. The main question of interest is which graph families have schemes using short labels, usually $O(\\log n)$ in the deterministic case or constant for randomized sketches. In this work we consider the resilience of probabilistic adjacency sketches against an adversary making adaptive queries to the labels. This differs from the previously analyzed probabilistic setting which is ``one shot\". We show that in the adaptive adversarial case the size of the labels is tightly related to the maximal degree of the graphs in $\\cal F$. This results in a stronger characterization compared to what is known in the non-adversarial setting. In more detail, we construct sketches that fail with probability $\\varepsilon$ for graphs with maximal degree $d$ using $2d\\log (1/\\varepsilon)$ bit labels and show that this is roughly the best that can be done for any specific graph of maximal degree $d$, e.g.\\ a $d$-ary tree. ",
    "url": "https://arxiv.org/abs/2309.03728",
    "authors": [
      "Moni Naor",
      "Eugene Pekel"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.03730",
    "title": "A Causal Perspective on Loan Pricing: Investigating the Impacts of  Selection Bias on Identifying Bid-Response Functions",
    "abstract": "In lending, where prices are specific to both customers and products, having a well-functioning personalized pricing policy in place is essential to effective business making. Typically, such a policy must be derived from observational data, which introduces several challenges. While the problem of ``endogeneity'' is prominently studied in the established pricing literature, the problem of selection bias (or, more precisely, bid selection bias) is not. We take a step towards understanding the effects of selection bias by posing pricing as a problem of causal inference. Specifically, we consider the reaction of a customer to price a treatment effect. In our experiments, we simulate varying levels of selection bias on a semi-synthetic dataset on mortgage loan applications in Belgium. We investigate the potential of parametric and nonparametric methods for the identification of individual bid-response functions. Our results illustrate how conventional methods such as logistic regression and neural networks suffer adversely from selection bias. In contrast, we implement state-of-the-art methods from causal machine learning and show their capability to overcome selection bias in pricing data. ",
    "url": "https://arxiv.org/abs/2309.03730",
    "authors": [
      "Christopher Bockel-Rickermann",
      "Sam Verboven",
      "Tim Verdonck",
      "Wouter Verbeke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2309.03731",
    "title": "Learning continuous-valued treatment effects through representation  balancing",
    "abstract": "Estimating the effects of treatments with an associated dose on an instance's outcome, the \"dose response\", is relevant in a variety of domains, from healthcare to business, economics, and beyond. Such effects, also known as continuous-valued treatment effects, are typically estimated from observational data, which may be subject to dose selection bias. This means that the allocation of doses depends on pre-treatment covariates. Previous studies have shown that conventional machine learning approaches fail to learn accurate individual estimates of dose responses under the presence of dose selection bias. In this work, we propose CBRNet, a causal machine learning approach to estimate an individual dose response from observational data. CBRNet adopts the Neyman-Rubin potential outcome framework and extends the concept of balanced representation learning for overcoming selection bias to continuous-valued treatments. Our work is the first to apply representation balancing in a continuous-valued treatment setting. We evaluate our method on a newly proposed benchmark. Our experiments demonstrate CBRNet's ability to accurately learn treatment effects under selection bias and competitive performance with respect to other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2309.03731",
    "authors": [
      "Christopher Bockel-Rickermann",
      "Toon Vanderschueren",
      "Jeroen Berrevoets",
      "Tim Verdonck",
      "Wouter Verbeke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.03734",
    "title": "ClusterFusion: Leveraging Radar Spatial Features for Radar-Camera 3D  Object Detection in Autonomous Vehicles",
    "abstract": "Thanks to the complementary nature of millimeter wave radar and camera, deep learning-based radar-camera 3D object detection methods may reliably produce accurate detections even in low-visibility conditions. This makes them preferable to use in autonomous vehicles' perception systems, especially as the combined cost of both sensors is cheaper than the cost of a lidar. Recent radar-camera methods commonly perform feature-level fusion which often involves projecting the radar points onto the same plane as the image features and fusing the extracted features from both modalities. While performing fusion on the image plane is generally simpler and faster, projecting radar points onto the image plane flattens the depth dimension of the point cloud which might lead to information loss and makes extracting the spatial features of the point cloud harder. We proposed ClusterFusion, an architecture that leverages the local spatial features of the radar point cloud by clustering the point cloud and performing feature extraction directly on the point cloud clusters before projecting the features onto the image plane. ClusterFusion achieved the state-of-the-art performance among all radar-monocular camera methods on the test slice of the nuScenes dataset with 48.7% nuScenes detection score (NDS). We also investigated the performance of different radar feature extraction strategies on point cloud clusters: a handcrafted strategy, a learning-based strategy, and a combination of both, and found that the handcrafted strategy yielded the best performance. The main goal of this work is to explore the use of radar's local spatial and point-wise features by extracting them directly from radar point cloud clusters for a radar-monocular camera 3D object detection method that performs cross-modal feature fusion on the image plane. ",
    "url": "https://arxiv.org/abs/2309.03734",
    "authors": [
      "Irfan Tito Kurniawan",
      "Bambang Riyanto Trilaksono"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03739",
    "title": "Detecting unknown HTTP-based malicious communication behavior via  generated adversarial flows and hierarchical traffic features",
    "abstract": "Malicious communication behavior is the network communication behavior generated by malware (bot-net, spyware, etc.) after victim devices are infected. Experienced adversaries often hide malicious information in HTTP traffic to evade detection. However, related detection methods have inadequate generalization ability because they are usually based on artificial feature engineering and outmoded datasets. In this paper, we propose an HTTP-based Malicious Communication traffic Detection Model (HMCD-Model) based on generated adversarial flows and hierarchical traffic features. HMCD-Model consists of two parts. The first is a generation algorithm based on WGAN-GP to generate HTTP-based malicious communication traffic for data enhancement. The second is a hybrid neural network based on CNN and LSTM to extract hierarchical spatial-temporal features of traffic. In addition, we collect and publish a dataset, HMCT-2020, which consists of large-scale malicious and benign traffic during three years (2018-2020). Taking the data in HMCT-2020(18) as the training set and the data in other datasets as the test set, the experimental results show that the HMCD-Model can effectively detect unknown HTTP-based malicious communication traffic. It can reach F1 = 98.66% in the dataset HMCT-2020(19-20), F1 = 90.69% in the public dataset CIC-IDS-2017, and F1 = 83.66% in the real traffic, which is 20+% higher than other representative methods on average. This validates that HMCD-Model has the ability to discover unknown HTTP-based malicious communication behavior. ",
    "url": "https://arxiv.org/abs/2309.03739",
    "authors": [
      "Xiaochun Yun",
      "Jiang Xie",
      "Shuhao Li",
      "Yongzheng Zhang",
      "Peishuai Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.03750",
    "title": "PBP: Path-based Trajectory Prediction for Autonomous Driving",
    "abstract": "Trajectory prediction plays a crucial role in the autonomous driving stack by enabling autonomous vehicles to anticipate the motion of surrounding agents. Goal-based prediction models have gained traction in recent years for addressing the multimodal nature of future trajectories. Goal-based prediction models simplify multimodal prediction by first predicting 2D goal locations of agents and then predicting trajectories conditioned on each goal. However, a single 2D goal location serves as a weak inductive bias for predicting the whole trajectory, often leading to poor map compliance, i.e., part of the trajectory going off-road or breaking traffic rules. In this paper, we improve upon goal-based prediction by proposing the Path-based prediction (PBP) approach. PBP predicts a discrete probability distribution over reference paths in the HD map using the path features and predicts trajectories in the path-relative Frenet frame. We applied the PBP trajectory decoder on top of the HiVT scene encoder and report results on the Argoverse dataset. Our experiments show that PBP achieves competitive performance on the standard trajectory prediction metrics, while significantly outperforming state-of-the-art baselines in terms of map compliance. ",
    "url": "https://arxiv.org/abs/2309.03750",
    "authors": [
      "Sepideh Afshar",
      "Nachiket Deo",
      "Akshay Bhagat",
      "Titas Chakraborty",
      "Yunming Shao",
      "Balarama Raju Buddharaju",
      "Adwait Deshpande",
      "Henggang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03758",
    "title": "Hybrid of representation learning and reinforcement learning for dynamic  and complex robotic motion planning",
    "abstract": "Motion planning is the soul of robot decision making. Classical planning algorithms like graph search and reaction-based algorithms face challenges in cases of dense and dynamic obstacles. Deep learning algorithms generate suboptimal one-step predictions that cause many collisions. Reinforcement learning algorithms generate optimal or near-optimal time-sequential predictions. However, they suffer from slow convergence, suboptimal converged results, and overfittings. This paper introduces a hybrid algorithm for robotic motion planning: long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC). First, graph network (relational graph) and attention network (attention weight) interpret the environmental state for the learning of the discrete soft actor critic algorithm. The expressive power of attention network outperforms that of graph in our task by difference analysis of these two representation methods. However, attention based DSAC faces the overfitting problem in training. Second, the skip connection method is integrated to attention based DSAC to mitigate overfitting and improve convergence speed. Third, LSTM pooling is taken to replace the sum operator of attention weigh and eliminate overfitting by slightly sacrificing convergence speed at early-stage training. Experiments show that LSA-DSAC outperforms the state-of-the-art in training and most evaluations. The physical robot is also implemented and tested in the real world. ",
    "url": "https://arxiv.org/abs/2309.03758",
    "authors": [
      "Chengmin Zhou",
      "Xin Lu",
      "Jiapeng Dai",
      "Bingding Huang",
      "Xiaoxu Liu",
      "Pasi Fr\u00e4nti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03764",
    "title": "$L_{2,1}$-Norm Regularized Quaternion Matrix Completion Using Sparse  Representation and Quaternion QR Decomposition",
    "abstract": "Color image completion is a challenging problem in computer vision, but recent research has shown that quaternion representations of color images perform well in many areas. These representations consider the entire color image and effectively utilize coupling information between the three color channels. Consequently, low-rank quaternion matrix completion (LRQMC) algorithms have gained significant attention. We propose a method based on quaternion Qatar Riyal decomposition (QQR) and quaternion $L_{2,1}$-norm called QLNM-QQR. This new approach reduces computational complexity by avoiding the need to calculate the QSVD of large quaternion matrices. We also present two improvements to the QLNM-QQR method: an enhanced version called IRQLNM-QQR that uses iteratively reweighted quaternion $L_{2,1}$-norm minimization and a method called QLNM-QQR-SR that integrates sparse regularization. Our experiments on natural color images and color medical images show that IRQLNM-QQR outperforms QLNM-QQR and that the proposed QLNM-QQR-SR method is superior to several state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2309.03764",
    "authors": [
      "Juan Han",
      "Kit Ian Kou",
      "Jifei Miao",
      "Lizhi Liu",
      "Haojiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.03773",
    "title": "Extending Transductive Knowledge Graph Embedding Models for Inductive  Logical Relational Inference",
    "abstract": "Many downstream inference tasks for knowledge graphs, such as relation prediction, have been handled successfully by knowledge graph embedding techniques in the transductive setting. To address the inductive setting wherein new entities are introduced into the knowledge graph at inference time, more recent work opts for models which learn implicit representations of the knowledge graph through a complex function of a network's subgraph structure, often parametrized by graph neural network architectures. These come at the cost of increased parametrization, reduced interpretability and limited generalization to other downstream inference tasks. In this work, we bridge the gap between traditional transductive knowledge graph embedding approaches and more recent inductive relation prediction models by introducing a generalized form of harmonic extension which leverages representations learned through transductive embedding methods to infer representations of new entities introduced at inference time as in the inductive setting. This harmonic extension technique provides the best such approximation, can be implemented via an efficient iterative scheme, and can be employed to answer a family of conjunctive logical queries over the knowledge graph, further expanding the capabilities of transductive embedding methods. In experiments on a number of large-scale knowledge graph embedding benchmarks, we find that this approach for extending the functionality of transductive knowledge graph embedding models to perform knowledge graph completion and answer logical queries in the inductive setting is competitive with--and in some scenarios outperforms--several state-of-the-art models derived explicitly for such inductive tasks. ",
    "url": "https://arxiv.org/abs/2309.03773",
    "authors": [
      "Thomas Gebhart",
      "John Cobb"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.03791",
    "title": "Adversarially Robust Deep Learning with Optimal-Transport-Regularized  Divergences",
    "abstract": "We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\\%$ against $FGSM$ and $98.18\\%$ against $PGD^{40}$ on the MNIST dataset, reducing the error rate by more than $19.7\\%$ and $37.2\\%$ respectively compared to prior methods. Similarly, in malware detection, a discrete (binary) data domain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack compared to the previous best-performing adversarial training methods by $37.0\\%$ while lowering false negative and false positive rates by $51.1\\%$ and $57.53\\%$, respectively. ",
    "url": "https://arxiv.org/abs/2309.03791",
    "authors": [
      "Jeremiah Birrell",
      "Mohammadreza Ebrahimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.03798",
    "title": "Managing the Uncertainty in System Dynamics Through Distributionally  Robust Stability-Constrained Optimization",
    "abstract": "With the increasing penetration of Inverter-Based Resources (IBRs) and their impact on power system stability and operation, the concept of stability-constrained optimization has drawn significant attentions from researchers. In order to manage the parametric uncertainty due to inaccurate modeling that influences the system dynamics, this work proposes a distributionally robust stability constraint formulation, where the propagation mechanism from uncertainty of the system dynamic parameters to the stability constraint coefficients is established and managed. Since these coefficients are connected to the uncertain parameters through highly nonlinear and implicit functions, an approximation approach utilizing Taylor expansion and the Delta method is developed to estimate the statistical moments of the stability constraint coefficients based on the first and second-order derivatives, with which an ambiguity set for the distributionally robust optimization can be formulated. The accuracy of the uncertainty propagation as well as the effectiveness of the distributionally robust stability constraints are demonstrated through detailed case studies in the modified IEEE 39-bus system. ",
    "url": "https://arxiv.org/abs/2309.03798",
    "authors": [
      "Zhongda Chu",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.03800",
    "title": "Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and  Luck",
    "abstract": "This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding \"lottery ticket\" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning. We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests. ",
    "url": "https://arxiv.org/abs/2309.03800",
    "authors": [
      "Benjamin L. Edelman",
      "Surbhi Goel",
      "Sham Kakade",
      "Eran Malach",
      "Cyril Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.03809",
    "title": "SimNP: Learning Self-Similarity Priors Between Neural Points",
    "abstract": "Existing neural field representations for 3D object reconstruction either (1) utilize object-level representations, but suffer from low-quality details due to conditioning on a global latent code, or (2) are able to perfectly reconstruct the observations, but fail to utilize object-level prior knowledge to infer unobserved regions. We present SimNP, a method to learn category-level self-similarities, which combines the advantages of both worlds by connecting neural point radiance fields with a category-level self-similarity representation. Our contribution is two-fold. (1) We design the first neural point representation on a category level by utilizing the concept of coherent point clouds. The resulting neural point radiance fields store a high level of detail for locally supported object regions. (2) We learn how information is shared between neural points in an unconstrained and unsupervised fashion, which allows to derive unobserved regions of an object during the reconstruction process from given observations. We show that SimNP is able to outperform previous methods in reconstructing symmetric unseen object regions, surpassing methods that build upon category-level or pixel-aligned radiance fields, while providing semantic correspondences between instances ",
    "url": "https://arxiv.org/abs/2309.03809",
    "authors": [
      "Christopher Wewer",
      "Eddy Ilg",
      "Bernt Schiele",
      "Jan Eric Lenssen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03810",
    "title": "Three Hardness Results for Graph Similarity Problems",
    "abstract": "Notions of graph similarity provide alternative perspective on the graph isomorphism problem and vice-versa. In this paper, we consider measures of similarity arising from mismatch norms as studied in Gervens and Grohe: the edit distance $\\delta_{\\mathcal{E}}$, and the metrics arising from $\\ell_p$-operator norms, which we denote by $\\delta_p$ and $\\delta_{|p|}$. We address the following question: can these measures of similarity be used to design polynomial-time approximation algorithms for graph isomorphism? We show that computing an optimal value of $\\delta_{\\mathcal{E}}$ is \\NP-hard on pairs of graphs with the same number of edges. In addition, we show that computing optimal values of $\\delta_p$ and $\\delta_{|p|}$ is \\NP-hard even on pairs of $1$-planar graphs with the same degree sequence and bounded degree. These two results improve on previous known ones, which did not examine the restricted case where the pairs of graphs are required to have the same number of edges. Finally, we study similarity problems on strongly regular graphs and prove some near optimal inequalities with interesting consequences on the computational complexity of graph and group isomorphism. ",
    "url": "https://arxiv.org/abs/2309.03810",
    "authors": [
      "He Sun",
      "Danny Vagnozzi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2309.03824",
    "title": "Training Acceleration of Low-Rank Decomposed Networks using Sequential  Freezing and Rank Quantization",
    "abstract": "Low Rank Decomposition (LRD) is a model compression technique applied to the weight tensors of deep learning models in order to reduce the number of trainable parameters and computational complexity. However, due to high number of new layers added to the architecture after applying LRD, it may not lead to a high training/inference acceleration if the decomposition ranks are not small enough. The issue is that using small ranks increases the risk of significant accuracy drop after decomposition. In this paper, we propose two techniques for accelerating low rank decomposed models without requiring to use small ranks for decomposition. These methods include rank optimization and sequential freezing of decomposed layers. We perform experiments on both convolutional and transformer-based models. Experiments show that these techniques can improve the model throughput up to 60% during training and 37% during inference when combined together while preserving the accuracy close to that of the original models ",
    "url": "https://arxiv.org/abs/2309.03824",
    "authors": [
      "Habib Hajimolahoseini",
      "Walid Ahmed",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03844",
    "title": "Experimental Study of Adversarial Attacks on ML-based xApps in O-RAN",
    "abstract": "Open Radio Access Network (O-RAN) is considered as a major step in the evolution of next-generation cellular networks given its support for open interfaces and utilization of artificial intelligence (AI) into the deployment, operation, and maintenance of RAN. However, due to the openness of the O-RAN architecture, such AI models are inherently vulnerable to various adversarial machine learning (ML) attacks, i.e., adversarial attacks which correspond to slight manipulation of the input to the ML model. In this work, we showcase the vulnerability of an example ML model used in O-RAN, and experimentally deploy it in the near-real time (near-RT) RAN intelligent controller (RIC). Our ML-based interference classifier xApp (extensible application in near-RT RIC) tries to classify the type of interference to mitigate the interference effect on the O-RAN system. We demonstrate the first-ever scenario of how such an xApp can be impacted through an adversarial attack by manipulating the data stored in a shared database inside the near-RT RIC. Through a rigorous performance analysis deployed on a laboratory O-RAN testbed, we evaluate the performance in terms of capacity and the prediction accuracy of the interference classifier xApp using both clean and perturbed data. We show that even small adversarial attacks can significantly decrease the accuracy of ML application in near-RT RIC, which can directly impact the performance of the entire O-RAN deployment. ",
    "url": "https://arxiv.org/abs/2309.03844",
    "authors": [
      "Naveen Naik Sapavath",
      "Brian Kim",
      "Kaushik Chowdhury",
      "Vijay K Shah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.03846",
    "title": "Scalable Forward Reachability Analysis of Multi-Agent Systems with  Neural Network Controllers",
    "abstract": "Neural networks (NNs) have been shown to learn complex control laws successfully, often with performance advantages or decreased computational cost compared to alternative methods. Neural network controllers (NNCs) are, however, highly sensitive to disturbances and uncertainty, meaning that it can be challenging to make satisfactory robustness guarantees for systems with these controllers. This problem is exacerbated when considering multi-agent NN-controlled systems, as existing reachability methods often scale poorly for large systems. This paper addresses the problem of finding overapproximations of forward reachable sets for discrete-time uncertain multi-agent systems with distributed NNC architectures. We first reformulate the dynamics, making the system more amenable to reachablility analysis. Next, we take advantage of the distributed architecture to split the overall reachability problem into smaller problems, significantly reducing computation time. We use quadratic constraints, along with a convex representation of uncertainty in each agent's model, to form semidefinite programs, the solutions of which give overapproximations of forward reachable sets for each agent. Finally, the methodology is tested on two realistic examples: a platoon of vehicles and a power network system. ",
    "url": "https://arxiv.org/abs/2309.03846",
    "authors": [
      "Oliver Gates",
      "Matthew Newton",
      "Konstantinos Gatsis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.03875",
    "title": "Network Sampling Methods for Estimating Social Networks, Population  Percentages and Totals of People Experiencing Homelessness",
    "abstract": "In this article, we propose using network-based sampling strategies to estimate the number of unsheltered people experiencing homelessness within a given administrative service unit, known as a Continuum of Care. Further, we specifically advocate for the network sampling method known as Respondent Driven Sampling (RDS), which has been shown to provide unbiased or low-biased estimates of totals and proportions for hard-to-reach populations in contexts where a sampling frame (e.g., housing addresses) not available. To make the RDS estimator work for estimating the total number of unsheltered people, we introduce a new method that leverages administrative data from the HUD-mandated Homeless Management Information System (HMIS). The HMIS provides high-quality counts and demographics for people experiencing homelessness who sleep in emergency shelters. We then demonstrate this method using network data collected in Nashville, TN, combined with simulation methods to illustrate the efficacy of this approach. Finally, we end with discussing how this could be used in practice. ",
    "url": "https://arxiv.org/abs/2309.03875",
    "authors": [
      "Zack W. Almquist",
      "Ashley Hazel",
      "Mary-Catherine Anderson",
      "Larisa Ozeryansky",
      "Amy Hagopian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.03893",
    "title": "DiffusionEngine: Diffusion Model is Scalable Data Engine for Object  Detection",
    "abstract": "Data is the cornerstone of deep learning. This paper reveals that the recently developed Diffusion Model is a scalable data engine for object detection. Existing methods for scaling up detection-oriented data often require manual collection or generative models to obtain target images, followed by data augmentation and labeling to produce training pairs, which are costly, complex, or lacking diversity. To address these issues, we presentDiffusionEngine (DE), a data scaling-up engine that provides high-quality detection-oriented training pairs in a single stage. DE consists of a pre-trained diffusion model and an effective Detection-Adapter, contributing to generating scalable, diverse and generalizable detection data in a plug-and-play manner. Detection-Adapter is learned to align the implicit semantic and location knowledge in off-the-shelf diffusion models with detection-aware signals to make better bounding-box predictions. Additionally, we contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing detection benchmarks for facilitating follow-up research. Extensive experiments demonstrate that data scaling-up via DE can achieve significant improvements in diverse scenarios, such as various detection algorithms, self-supervised pre-training, data-sparse, label-scarce, cross-domain, and semi-supervised learning. For example, when using DE with a DINO-based adapter to scale up data, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart. ",
    "url": "https://arxiv.org/abs/2309.03893",
    "authors": [
      "Manlin Zhang",
      "Jie Wu",
      "Yuxi Ren",
      "Ming Li",
      "Jie Qin",
      "Xuefeng Xiao",
      "Wei Liu",
      "Rui Wang",
      "Min Zheng",
      "Andy J. Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03898",
    "title": "Multivariate, Multi-step, and Spatiotemporal Traffic Prediction for  NextG Network Slicing under SLA Constraints",
    "abstract": "This study presents a spatiotemporal traffic prediction approach for NextG mobile networks, ensuring the service-level agreements (SLAs) of each network slice. Our approach is multivariate, multi-step, and spatiotemporal. Leveraging 20 radio access network (RAN) features, peak traffic hour data, and mobility-based clustering, we propose a parametric SLA-based loss function to guarantee an SLA violation rate. We focus on single-cell, multi-cell, and slice-based prediction approaches and present a detailed comparative analysis of their performances, strengths, and limitations. First, we address the application of single-cell and multi-cell training architectures. While single-cell training offers individual cell-level prediction, multi-cell training involves training a model using traffic from multiple cells from the same or different base stations. We show that the single-cell approach outperforms the multi-cell approach and results in test loss improvements of 11.4% and 38.1% compared to baseline SLA-based and MAE-based models, respectively. Next, we explore slice-based traffic prediction. We present single-slice and multi-slice methods for slice-based downlink traffic volume prediction, arguing that multi-slice prediction offers a more accurate forecast. The slice-based model we introduce offers substantial test loss improvements of 28.2%, 36.4%, and 55.6% compared to our cell-based model, the baseline SLA-based model, and the baseline MAE-based model, respectively. ",
    "url": "https://arxiv.org/abs/2309.03898",
    "authors": [
      "Evren Tuna",
      "Alkan Soysal"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.03231",
    "title": "Quantum-AI empowered Intelligent Surveillance: Advancing Public Safety  Through Innovative Contraband Detection",
    "abstract": "Surveillance systems have emerged as crucial elements in upholding peace and security in the modern world. Their ubiquity aids in monitoring suspicious activities effectively. However, in densely populated environments, continuous active monitoring becomes impractical, necessitating the development of intelligent surveillance systems. AI integration in the surveillance domain was a big revolution, however, speed issues have prevented its widespread implementation in the field. It has been observed that quantum artificial intelligence has led to a great breakthrough. Quantum artificial intelligence-based surveillance systems have shown to be more accurate as well as capable of performing well in real-time scenarios, which had never been seen before. In this research, a RentinaNet model is integrated with Quantum CNN and termed as Quantum-RetinaNet. By harnessing the Quantum capabilities of QCNN, Quantum-RetinaNet strikes a balance between accuracy and speed. This innovative integration positions it as a game-changer, addressing the challenges of active monitoring in densely populated scenarios. As demand for efficient surveillance solutions continues to grow, Quantum-RetinaNet offers a compelling alternative to existing CNN models, upholding accuracy standards without sacrificing real-time performance. The unique attributes of Quantum-RetinaNet have far-reaching implications for the future of intelligent surveillance. With its enhanced processing speed, it is poised to revolutionize the field, catering to the pressing need for rapid yet precise monitoring. As Quantum-RetinaNet becomes the new standard, it ensures public safety and security while pushing the boundaries of AI in surveillance. ",
    "url": "https://arxiv.org/abs/2309.03231",
    "authors": [
      "Syed Atif Ali Shah",
      "Nasir Algeelani",
      "Najeeb Al-Sammarraie"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03279",
    "title": "Let Quantum Neural Networks Choose Their Own Frequencies",
    "abstract": "Parameterized quantum circuits as machine learning models are typically well described by their representation as a partial Fourier series of the input features, with frequencies uniquely determined by the feature map's generator Hamiltonians. Ordinarily, these data-encoding generators are chosen in advance, fixing the space of functions that can be represented. In this work we consider a generalization of quantum models to include a set of trainable parameters in the generator, leading to a trainable frequency (TF) quantum model. We numerically demonstrate how TF models can learn generators with desirable properties for solving the task at hand, including non-regularly spaced frequencies in their spectra and flexible spectral richness. Finally, we showcase the real-world effectiveness of our approach, demonstrating an improved accuracy in solving the Navier-Stokes equations using a TF model with only a single parameter added to each encoding operation. Since TF models encompass conventional fixed frequency models, they may offer a sensible default choice for variational quantum machine learning. ",
    "url": "https://arxiv.org/abs/2309.03279",
    "authors": [
      "Ben Jaderberg",
      "Antonio A. Gentile",
      "Youssef Achari Berrada",
      "Elvira Shishenina",
      "Vincent E. Elfving"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03320",
    "title": "CoNeS: Conditional neural fields with shift modulation for  multi-sequence MRI translation",
    "abstract": "Multi-sequence magnetic resonance imaging (MRI) has found wide applications in both modern clinical studies and deep learning research. However, in clinical practice, it frequently occurs that one or more of the MRI sequences are missing due to different image acquisition protocols or contrast agent contraindications of patients, limiting the utilization of deep learning models trained on multi-sequence data. One promising approach is to leverage generative models to synthesize the missing sequences, which can serve as a surrogate acquisition. State-of-the-art methods tackling this problem are based on convolutional neural networks (CNN) which usually suffer from spectral biases, resulting in poor reconstruction of high-frequency fine details. In this paper, we propose Conditional Neural fields with Shift modulation (CoNeS), a model that takes voxel coordinates as input and learns a representation of the target images for multi-sequence MRI translation. The proposed model uses a multi-layer perceptron (MLP) instead of a CNN as the decoder for pixel-to-pixel mapping. Hence, each target image is represented as a neural field that is conditioned on the source image via shift modulation with a learned latent code. Experiments on BraTS 2018 and an in-house clinical dataset of vestibular schwannoma patients showed that the proposed method outperformed state-of-the-art methods for multi-sequence MRI translation both visually and quantitatively. Moreover, we conducted spectral analysis, showing that CoNeS was able to overcome the spectral bias issue common in conventional CNN models. To further evaluate the usage of synthesized images in clinical downstream tasks, we tested a segmentation network using the synthesized images at inference. ",
    "url": "https://arxiv.org/abs/2309.03320",
    "authors": [
      "Yunjie Chen",
      "Marius Staring",
      "Olaf M. Neve",
      "Stephan R. Romeijn",
      "Erik F. Hensen",
      "Berit M. Verbist",
      "Jelmer M. Wolterink",
      "Qian Tao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03337",
    "title": "Leveraging Geometrical Acoustic Simulations of Spatial Room Impulse  Responses for Improved Sound Event Detection and Localization",
    "abstract": "As deeper and more complex models are developed for the task of sound event localization and detection (SELD), the demand for annotated spatial audio data continues to increase. Annotating field recordings with 360$^{\\circ}$ video takes many hours from trained annotators, while recording events within motion-tracked laboratories are bounded by cost and expertise. Because of this, localization models rely on a relatively limited amount of spatial audio data in the form of spatial room impulse response (SRIR) datasets, which limits the progress of increasingly deep neural network based approaches. In this work, we demonstrate that simulated geometrical acoustics can provide an appealing solution to this problem. We use simulated geometrical acoustics to generate a novel SRIR dataset that can train a SELD model to provide similar performance to that of a real SRIR dataset. Furthermore, we demonstrate using simulated data to augment existing datasets, improving on benchmarks set by state of the art SELD models. We explore the potential and limitations of geometric acoustic simulation for localization and event detection. We also propose further studies to verify the limitations of this method, as well as further methods to generate synthetic data for SELD tasks without the need to record more data. ",
    "url": "https://arxiv.org/abs/2309.03337",
    "authors": [
      "Christopher Ick",
      "Brian McFee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.03447",
    "title": "Broadband Ground Motion Synthesis via Generative Adversarial Neural  Operators: Development and Validation",
    "abstract": "We present a data-driven model for ground-motion synthesis using a Generative Adversarial Neural Operator (GANO) that combines recent advancements in machine learning and open access strong motion data sets to generate three-component acceleration time histories conditioned on moment magnitude ($M$), rupture distance ($R_{rup}$), time-average shear-wave velocity at the top $30m$ ($V_{S30}$), and tectonic environment or style of faulting. We use Neural Operators, a resolution invariant architecture that guarantees that the model training is independent of the data sampling frequency. We first present the conditional ground-motion synthesis algorithm (referred to heretofore as cGM-GANO) and discuss its advantages compared to previous work. Next, we verify the cGM-GANO framework using simulated ground motions generated with the Southern California Earthquake Center (SCEC) Broadband Platform (BBP). We lastly train cGM-GANO on a KiK-net dataset from Japan, showing that the framework can recover the magnitude, distance, and $V_{S30}$ scaling of Fourier amplitude and pseudo-spectral accelerations. We evaluate cGM-GANO through residual analysis with the empirical dataset as well as by comparison with conventional Ground Motion Models (GMMs) for selected ground motion scenarios. Results show that cGM-GANO produces consistent median scaling with the GMMs for the corresponding tectonic environments. The largest misfit is observed at short distances due to the scarcity of training data. With the exception of short distances, the aleatory variability of the response spectral ordinates is also well captured, especially for subduction events due to the adequacy of training data. Applications of the presented framework include generation of risk-targeted ground motions for site-specific engineering applications. ",
    "url": "https://arxiv.org/abs/2309.03447",
    "authors": [
      "Yaozhong Shi",
      "Grigorios Lavrentiadis",
      "Domniki Asimaki",
      "Zachary E. Ross",
      "Kamyar Azizzadenesheli"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03477",
    "title": "TSI-Net: A Timing Sequence Image Segmentation Network for Intracranial  Artery Segmentation in Digital Subtraction Angiography",
    "abstract": "Cerebrovascular disease is one of the major diseases facing the world today. Automatic segmentation of intracranial artery (IA) in digital subtraction angiography (DSA) sequences is an important step in the diagnosis of vascular related diseases and in guiding neurointerventional procedures. While, a single image can only show part of the IA within the contrast medium according to the imaging principle of DSA technology. Therefore, 2D DSA segmentation methods are unable to capture the complete IA information and treatment of cerebrovascular diseases. We propose A timing sequence image segmentation network with U-shape, called TSI-Net, which incorporates a bi-directional ConvGRU module (BCM) in the encoder. The network incorporates a bi-directional ConvGRU module (BCM) in the encoder, which can input variable-length DSA sequences, retain past and future information, segment them into 2D images. In addition, we introduce a sensitive detail branch (SDB) at the end for supervising fine vessels. Experimented on the DSA sequence dataset DIAS, the method performs significantly better than state-of-the-art networks in recent years. In particular, it achieves a Sen evaluation metric of 0.797, which is a 3% improvement compared to other methods. ",
    "url": "https://arxiv.org/abs/2309.03477",
    "authors": [
      "Lemeng Wang",
      "Wentao Liu",
      "Weijin Xu",
      "Haoyuan Li",
      "Huihua Yang",
      "Feng Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03519",
    "title": "A cutting-surface consensus approach for distributed robust optimization  of multi-agent systems",
    "abstract": "A novel and fully distributed optimization method is proposed for the distributed robust convex program (DRCP) over a time-varying unbalanced directed network without imposing any differentiability assumptions. Firstly, a tractable approximated DRCP (ADRCP) is introduced by discretizing the semi-infinite constraints into a finite number of inequality constraints and restricting the right-hand side of the constraints with a proper positive parameter, which will be iteratively solved by a random-fixed projection algorithm. Secondly, a cutting-surface consensus approach is proposed for locating an approximately optimal consensus solution of the DRCP with guaranteed feasibility. This approach is based on iteratively approximating the DRCP by successively reducing the restriction parameter of the right-hand constraints and populating the cutting-surfaces into the existing finite set of constraints. Thirdly, to ensure finite-time convergence of the distributed optimization, a distributed termination algorithm is developed based on uniformly local consensus and zeroth-order optimality under uniformly strongly connected graphs. Fourthly, it is proved that the cutting-surface consensus approach converges within a finite number of iterations. Finally, the effectiveness of the approach is illustrated through a numerical example. ",
    "url": "https://arxiv.org/abs/2309.03519",
    "authors": [
      "Jun Fu",
      "Xunhao Wu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.03535",
    "title": "Feature Enhancer Segmentation Network (FES-Net) for Vessel Segmentation",
    "abstract": "Diseases such as diabetic retinopathy and age-related macular degeneration pose a significant risk to vision, highlighting the importance of precise segmentation of retinal vessels for the tracking and diagnosis of progression. However, existing vessel segmentation methods that heavily rely on encoder-decoder structures struggle to capture contextual information about retinal vessel configurations, leading to challenges in reconciling semantic disparities between encoder and decoder features. To address this, we propose a novel feature enhancement segmentation network (FES-Net) that achieves accurate pixel-wise segmentation without requiring additional image enhancement steps. FES-Net directly processes the input image and utilizes four prompt convolutional blocks (PCBs) during downsampling, complemented by a shallow upsampling approach to generate a binary mask for each class. We evaluate the performance of FES-Net on four publicly available state-of-the-art datasets: DRIVE, STARE, CHASE, and HRF. The evaluation results clearly demonstrate the superior performance of FES-Net compared to other competitive approaches documented in the existing literature. ",
    "url": "https://arxiv.org/abs/2309.03535",
    "authors": [
      "Tariq M. Khan",
      "Muhammad Arsalan",
      "Shahzaib Iqbal",
      "Imran Razzak",
      "Erik Meijering"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03537",
    "title": "Subgraph-based Tight Frames on Graphs with Compact Supports and  Vanishing Moments",
    "abstract": "In this work, we proposed a novel and general method to construct tight frames on graphs with compact supports based on a series of hierarchical partitions. Starting from our abstract construction that generalizes previous methods based on partition trees, we are able to flexibly incorporate subgraph Laplacians into our design of graph frames. Consequently, our general methods permit adjusting the (subgraph) vanishing moments of the framelets and extra properties, such as directionality, for efficiently representing graph signals with path-like supports. Several variants are explicitly defined and tested. Experimental results show our proposed graph frames perform superiorly in non-linear approximation tasks. ",
    "url": "https://arxiv.org/abs/2309.03537",
    "authors": [
      "Ruigang Zheng",
      "Xiaosheng Zhuang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03652",
    "title": "Anatomy-informed Data Augmentation for Enhanced Prostate Cancer  Detection",
    "abstract": "Data augmentation (DA) is a key factor in medical image analysis, such as in prostate cancer (PCa) detection on magnetic resonance images. State-of-the-art computer-aided diagnosis systems still rely on simplistic spatial transformations to preserve the pathological label post transformation. However, such augmentations do not substantially increase the organ as well as tumor shape variability in the training set, limiting the model's ability to generalize to unseen cases with more diverse localized soft-tissue deformations. We propose a new anatomy-informed transformation that leverages information from adjacent organs to simulate typical physiological deformations of the prostate and generates unique lesion shapes without altering their label. Due to its lightweight computational requirements, it can be easily integrated into common DA frameworks. We demonstrate the effectiveness of our augmentation on a dataset of 774 biopsy-confirmed examinations, by evaluating a state-of-the-art method for PCa detection with different augmentation settings. ",
    "url": "https://arxiv.org/abs/2309.03652",
    "authors": [
      "Balint Kovacs",
      "Nils Netzer",
      "Michael Baumgartner",
      "Carolin Eith",
      "Dimitrios Bounias",
      "Clara Meinzer",
      "Paul F. Jaeger",
      "Kevin S. Zhang",
      "Ralf Floca",
      "Adrian Schrader",
      "Fabian Isensee",
      "Regula Gnirs",
      "Magdalena Goertz",
      "Viktoria Schuetz",
      "Albrecht Stenzinger",
      "Markus Hohenfellner",
      "Heinz-Peter Schlemmer",
      "Ivo Wolf",
      "David Bonekamp",
      "Klaus H. Maier-Hein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03684",
    "title": "Causal Signal-Based DCCRN with Overlapped-Frame Prediction for Online  Speech Enhancement",
    "abstract": "The aim of speech enhancement is to improve speech signal quality and intelligibility from a noisy microphone signal. In many applications, it is crucial to enable processing with small computational complexity and minimal requirements regarding access to future signal samples (look-ahead). This paper presents signal-based causal DCCRN that improves online single-channel speech enhancement by reducing the required look-ahead and the number of network parameters. The proposed modifications include complex filtering of the signal, application of overlapped-frame prediction, causal convolutions and deconvolutions, and modification of the loss function. Results of performed experiments indicate that the proposed model with overlapped signal prediction and additional adjustments, achieves similar or better performance than the original DCCRN in terms of various speech enhancement metrics, while it reduces the latency and network parameter number by around 30%. ",
    "url": "https://arxiv.org/abs/2309.03684",
    "authors": [
      "Julitta Bartolewska",
      "Stanis\u0142aw Kacprzak",
      "Konrad Kowalczyk"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.03744",
    "title": "Label-efficient Contrastive Learning-based model for nuclei detection  and classification in 3D Cardiovascular Immunofluorescent Images",
    "abstract": "Recently, deep learning-based methods achieved promising performance in nuclei detection and classification applications. However, training deep learning-based methods requires a large amount of pixel-wise annotated data, which is time-consuming and labor-intensive, especially in 3D images. An alternative approach is to adapt weak-annotation methods, such as labeling each nucleus with a point, but this method does not extend from 2D histopathology images (for which it was originally developed) to 3D immunofluorescent images. The reason is that 3D images contain multiple channels (z-axis) for nuclei and different markers separately, which makes training using point annotations difficult. To address this challenge, we propose the Label-efficient Contrastive learning-based (LECL) model to detect and classify various types of nuclei in 3D immunofluorescent images. Previous methods use Maximum Intensity Projection (MIP) to convert immunofluorescent images with multiple slices to 2D images, which can cause signals from different z-stacks to falsely appear associated with each other. To overcome this, we devised an Extended Maximum Intensity Projection (EMIP) approach that addresses issues using MIP. Furthermore, we performed a Supervised Contrastive Learning (SCL) approach for weakly supervised settings. We conducted experiments on cardiovascular datasets and found that our proposed framework is effective and efficient in detecting and classifying various types of nuclei in 3D immunofluorescent images. ",
    "url": "https://arxiv.org/abs/2309.03744",
    "authors": [
      "Nazanin Moradinasab",
      "Rebecca A. Deaton",
      "Laura S. Shankman",
      "Gary K. Owens",
      "Donald E. Brown"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03759",
    "title": "M(otion)-mode Based Prediction of Ejection Fraction using  Echocardiograms",
    "abstract": "Early detection of cardiac dysfunction through routine screening is vital for diagnosing cardiovascular diseases. An important metric of cardiac function is the left ventricular ejection fraction (EF), where lower EF is associated with cardiomyopathy. Echocardiography is a popular diagnostic tool in cardiology, with ultrasound being a low-cost, real-time, and non-ionizing technology. However, human assessment of echocardiograms for calculating EF is time-consuming and expertise-demanding, raising the need for an automated approach. In this work, we propose using the M(otion)-mode of echocardiograms for estimating the EF and classifying cardiomyopathy. We generate multiple artificial M-mode images from a single echocardiogram and combine them using off-the-shelf model architectures. Additionally, we extend contrastive learning (CL) to cardiac imaging to learn meaningful representations from exploiting structures in unlabeled data allowing the model to achieve high accuracy, even with limited annotations. Our experiments show that the supervised setting converges with only ten modes and is comparable to the baseline method while bypassing its cumbersome training process and being computationally much more efficient. Furthermore, CL using M-mode images is helpful for limited data scenarios, such as having labels for only 200 patients, which is common in medical applications. ",
    "url": "https://arxiv.org/abs/2309.03759",
    "authors": [
      "Ece Ozkan",
      "Thomas M. Sutter",
      "Yurong Hu",
      "Sebastian Balzer",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03770",
    "title": "Neural lasso: a unifying approach of lasso and neural networks",
    "abstract": "In recent years, there is a growing interest in combining techniques attributed to the areas of Statistics and Machine Learning in order to obtain the benefits of both approaches. In this article, the statistical technique lasso for variable selection is represented through a neural network. It is observed that, although both the statistical approach and its neural version have the same objective function, they differ due to their optimization. In particular, the neural version is usually optimized in one-step using a single validation set, while the statistical counterpart uses a two-step optimization based on cross-validation. The more elaborated optimization of the statistical method results in more accurate parameter estimation, especially when the training set is small. For this reason, a modification of the standard approach for training neural networks, that mimics the statistical framework, is proposed. During the development of the above modification, a new optimization algorithm for identifying the significant variables emerged. Experimental results, using synthetic and real data sets, show that this new optimization algorithm achieves better performance than any of the three previous optimization approaches. ",
    "url": "https://arxiv.org/abs/2309.03770",
    "authors": [
      "David Delgado",
      "Ernesto Curbelo",
      "Danae Carreras"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03783",
    "title": "Not your private t\u00eate-\u00e0-t\u00eate: leveraging the power of higher-order  networks to study animal communication",
    "abstract": "Animal communication is frequently studied with conventional network representations that link pairs of individuals who interact, for example, through vocalisation. However, acoustic signals often have multiple simultaneous receivers, or receivers integrate information from multiple signallers, meaning these interactions are not dyadic. Additionally, non-dyadic social structures often shape an individual's behavioural response to vocal communication. Recently, major advances have been made in the study of these non-dyadic, higher-order networks (e.g., hypergraphs and simplicial complexes). Here, we show how these approaches can provide new insights into vocal communication through three case studies that illustrate how higher-order network models can: a) alter predictions made about the outcome of vocally-coordinated group departures; b) generate different patterns of song synchronisation than models that only include dyadic interactions; and c) inform models of cultural evolution of vocal communication. Together, our examples highlight the potential power of higher-order networks to study animal vocal communication. We then build on our case studies to identify key challenges in applying higher-order network approaches in this context and outline important research questions these techniques could help answer. ",
    "url": "https://arxiv.org/abs/2309.03783",
    "authors": [
      "Iacopo Iacopini",
      "Jennifer R Foote",
      "Nina H Fefferman",
      "Elizabeth P Derryberry",
      "Matthew J Silk"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.03848",
    "title": "Bipartite Friends and Strangers Walking on Bipartite Graphs",
    "abstract": "Given $n$-vertex simple graphs $X$ and $Y$, the friends-and-strangers graph $\\mathsf{FS}(X, Y)$ has as its vertices all $n!$ bijections from $V(X)$ to $V(Y)$, with bijections $\\sigma, \\tau$ adjacent if and only if they differ on two adjacent elements of $V(X)$ whose mappings are adjacent in $Y$. We consider the setting where $X$ and $Y$ are both edge-subgraphs of $K_{r,r}$: due to a parity obstruction, $\\mathsf{FS}(X,Y)$ is always disconnected in this setting. Sharpening a result of Bangachev, we show that if $X$ and $Y$ respectively have minimum degrees $\\delta(X)$ and $\\delta(Y)$ and they satisfy $\\delta(X) + \\delta(Y) \\geq \\lfloor 3r/2 \\rfloor + 1$, then $\\mathsf{FS}(X,Y)$ has exactly two connected components. This proves that the cutoff for $\\mathsf{FS}(X,Y)$ to avoid isolated vertices is equal to the cutoff for $\\mathsf{FS}(X,Y)$ to have exactly two connected components. We also consider a probabilistic setup in which we fix $Y$ to be $K_{r,r}$, but randomly generate $X$ by including each edge in $K_{r,r}$ independently with probability $p$. Invoking a result of Zhu, we exhibit a phase transition phenomenon with threshold function $(\\log r)/r$: below the threshold, $\\mathsf{FS}(X,Y)$ has more than two connected components with high probability, while above the threshold, $\\mathsf{FS}(X,Y)$ has exactly two connected components with high probability. Altogether, our results settle a conjecture and completely answer two problems of Alon, Defant, and Kravitz. ",
    "url": "https://arxiv.org/abs/2309.03848",
    "authors": [
      "Ryan Jeong"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1909.05487",
    "title": "Learning Graphs from Linear Measurements: Fundamental Trade-offs and  Applications",
    "abstract": " Title: Learning Graphs from Linear Measurements: Fundamental Trade-offs and  Applications ",
    "url": "https://arxiv.org/abs/1909.05487",
    "authors": [
      "Tongxin Li",
      "Lucien Werner",
      "Steven H. Low"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2010.10274",
    "title": "Graph Fairing Convolutional Networks for Anomaly Detection",
    "abstract": " Title: Graph Fairing Convolutional Networks for Anomaly Detection ",
    "url": "https://arxiv.org/abs/2010.10274",
    "authors": [
      "Mahsa Mesgaran",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.07001",
    "title": "Burling graphs revisited, part I: New characterizations",
    "abstract": " Comments: 32 pages, 20 figures. Some typos fixed in this new version ",
    "url": "https://arxiv.org/abs/2104.07001",
    "authors": [
      "Pegah Pournajafi",
      "Nicolas Trotignon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2106.02613",
    "title": "Bridging the Gap Between Target Networks and Functional Regularization",
    "abstract": " Comments: The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2106.02613",
    "authors": [
      "Alexandre Pich\u00e9",
      "Valentin Thomas",
      "Rafael Pardinas",
      "Joseph Marino",
      "Gian Maria Marconi",
      "Christopher Pal",
      "Mohammad Emtiyaz Khan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11970",
    "title": "Burling graphs revisited, part III: Applications to $\u03c7$-boundedness",
    "abstract": " Comments: 24 pages, 15 figures Some typos fixed in this new version ",
    "url": "https://arxiv.org/abs/2112.11970",
    "authors": [
      "Pegah Pournajafi",
      "Nicolas Trotignon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.09671",
    "title": "Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial  Auto-Encoders",
    "abstract": " Comments: ICLR 2023 camera-ready version ",
    "url": "https://arxiv.org/abs/2202.09671",
    "authors": [
      "Huangjie Zheng",
      "Pengcheng He",
      "Weizhu Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03624",
    "title": "FCNet: A Convolutional Neural Network for Arbitrary-Length Exposure  Estimation",
    "abstract": " Title: FCNet: A Convolutional Neural Network for Arbitrary-Length Exposure  Estimation ",
    "url": "https://arxiv.org/abs/2203.03624",
    "authors": [
      "Jin Liang",
      "Yuchen Yang",
      "Anran Zhang",
      "Jun Xu",
      "Hui Li",
      "Xiantong Zhen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09096",
    "title": "DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications",
    "abstract": " Title: DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications ",
    "url": "https://arxiv.org/abs/2203.09096",
    "authors": [
      "Somaye Hashemifar",
      "Claudia Iriondo",
      "Evan Casey",
      "Mohsen Hejrati",
      "for Alzheimer's Disease Neuroimaging Initiative"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2205.12250",
    "title": "Efficient anti-symmetrization of a neural network layer by taming the  sign problem",
    "abstract": " Comments: To appear in JML, ISSN: 2790-2048(e), 2790-203X(p) ",
    "url": "https://arxiv.org/abs/2205.12250",
    "authors": [
      "Nilin Abrahamsen",
      "Lin Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2207.03367",
    "title": "Joint Super-Resolution and Inverse Tone-Mapping: A Feature Decomposition  Aggregation Network and A New Benchmark",
    "abstract": " Comments: update the authors info and the article template ",
    "url": "https://arxiv.org/abs/2207.03367",
    "authors": [
      "Gang Xu",
      "Yu-chen Yang",
      "Liang Wang",
      "Xian-Tong Zhen",
      "Jun Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.04521",
    "title": "The Space of Adversarial Strategies",
    "abstract": " Comments: Accepted to the 32nd USENIX Security Symposium ",
    "url": "https://arxiv.org/abs/2209.04521",
    "authors": [
      "Ryan Sheatsley",
      "Blaine Hoak",
      "Eric Pauley",
      "Patrick McDaniel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16193",
    "title": "M3FGM:a node masking and multi-granularity message passing-based  federated graph model for spatial-temporal data prediction",
    "abstract": " Comments: Accepted by ICONIP2023 ",
    "url": "https://arxiv.org/abs/2210.16193",
    "authors": [
      "Yuxing Tian",
      "Zheng Liu",
      "Yanwen Qu",
      "Song Li",
      "Jiachi Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.17040",
    "title": "CodeEditor: Learning to Edit Source Code with Pre-trained Models",
    "abstract": " Comments: Accepted by the ACM Transactions on Software Engineering and Methodology (TOSEM) ",
    "url": "https://arxiv.org/abs/2210.17040",
    "authors": [
      "Jia Li",
      "Ge Li",
      "Zhuo Li",
      "Zhi Jin",
      "Xing Hu",
      "Kechi Zhang",
      "Zhiyi Fu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.03698",
    "title": "Privacy-Preserving Anomaly Detection in Stochastic Dynamical Systems:  Synthesis of Optimal Gaussian Mechanisms",
    "abstract": " Title: Privacy-Preserving Anomaly Detection in Stochastic Dynamical Systems:  Synthesis of Optimal Gaussian Mechanisms ",
    "url": "https://arxiv.org/abs/2211.03698",
    "authors": [
      "Haleh Hayati",
      "Carlos Murguia",
      "Nathan van de Wouw"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.04031",
    "title": "On Root Cause Localization and Anomaly Mitigation through Causal  Inference",
    "abstract": " Title: On Root Cause Localization and Anomaly Mitigation through Causal  Inference ",
    "url": "https://arxiv.org/abs/2212.04031",
    "authors": [
      "Xiao Han",
      "Lu Zhang",
      "Yongkai Wu",
      "Shuhan Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05798",
    "title": "BigText-QA: Question Answering over a Large-Scale Hybrid Knowledge Graph",
    "abstract": " Title: BigText-QA: Question Answering over a Large-Scale Hybrid Knowledge Graph ",
    "url": "https://arxiv.org/abs/2212.05798",
    "authors": [
      "Jingjing Xu",
      "Maria Biryukov",
      "Martin Theobald",
      "Vinu Ellampallil Venugopal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.04838",
    "title": "LB-SimTSC: An Efficient Similarity-Aware Graph Neural Network for  Semi-Supervised Time Series Classification",
    "abstract": " Comments: Accpeted by DLG-AAAI'23 ",
    "url": "https://arxiv.org/abs/2301.04838",
    "authors": [
      "Wenjie Xi",
      "Arnav Jain",
      "Li Zhang",
      "Jessica Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.03744",
    "title": "3D Neural Embedding Likelihood: Probabilistic Inverse Graphics for  Robust 6D Pose Estimation",
    "abstract": " Comments: ICCV 2023 camera ready ",
    "url": "https://arxiv.org/abs/2302.03744",
    "authors": [
      "Guangyao Zhou",
      "Nishad Gothoskar",
      "Lirui Wang",
      "Joshua B. Tenenbaum",
      "Dan Gutfreund",
      "Miguel L\u00e1zaro-Gredilla",
      "Dileep George",
      "Vikash K. Mansinghka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.06144",
    "title": "SkCoder: A Sketch-based Approach for Automatic Code Generation",
    "abstract": " Comments: Accepted by the 45th IEEE/ACM International Conference on Software Engineering (ICSE 2023) ",
    "url": "https://arxiv.org/abs/2302.06144",
    "authors": [
      "Jia Li",
      "Yongmin Li",
      "Ge Li",
      "Zhi Jin",
      "Yiyang Hao",
      "Xing Hu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.14051",
    "title": "Internet Explorer: Targeted Representation Learning on the Open Web",
    "abstract": " Comments: In ICML 2023. Website at this https URL ",
    "url": "https://arxiv.org/abs/2302.14051",
    "authors": [
      "Alexander C. Li",
      "Ellis Brown",
      "Alexei A. Efros",
      "Deepak Pathak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.00601",
    "title": "Multimodal Industrial Anomaly Detection via Hybrid Fusion",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.00601",
    "authors": [
      "Yue Wang",
      "Jinlong Peng",
      "Jiangning Zhang",
      "Ran Yi",
      "Yabiao Wang",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.04436",
    "title": "A comparison of rational and neural network based approximations",
    "abstract": " Comments: 39 pages ",
    "url": "https://arxiv.org/abs/2303.04436",
    "authors": [
      "Vinesha Peiris",
      "Reinier Diaz Millan",
      "Nadezda Sukhorukova",
      "Julien Ugon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11899",
    "title": "Large-Scale Traffic Signal Control Using Constrained Network Partition  and Adaptive Deep Reinforcement Learning",
    "abstract": " Title: Large-Scale Traffic Signal Control Using Constrained Network Partition  and Adaptive Deep Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2303.11899",
    "authors": [
      "Hankang Gu",
      "Shangbo Wang",
      "Xiaoguang Ma",
      "Dongyao Jia",
      "Guoqiang Mao",
      "Eng Gee Lim",
      "Cheuk Pong Ryan Wong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.13606",
    "title": "Adaptive Similarity Bootstrapping for Self-Distillation based  Representation Learning",
    "abstract": " Comments: ICCV 2023. * denotes equal contribution ",
    "url": "https://arxiv.org/abs/2303.13606",
    "authors": [
      "Tim Lebailly",
      "Thomas Stegm\u00fcller",
      "Behzad Bozorgtabar",
      "Jean-Philippe Thiran",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17780",
    "title": "AceCoder: Utilizing Existing Code to Enhance Code Generation",
    "abstract": " Title: AceCoder: Utilizing Existing Code to Enhance Code Generation ",
    "url": "https://arxiv.org/abs/2303.17780",
    "authors": [
      "Jia Li",
      "Yunfei Zhao",
      "Yongmin Li",
      "Ge Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.01311",
    "title": "Knowledge Graphs in Practice: Characterizing their Users, Challenges,  and Visualization Opportunities",
    "abstract": " Title: Knowledge Graphs in Practice: Characterizing their Users, Challenges,  and Visualization Opportunities ",
    "url": "https://arxiv.org/abs/2304.01311",
    "authors": [
      "Harry Li",
      "Gabriel Appleby",
      "Camelia Daniela Brumar",
      "Remco Chang",
      "Ashley Suh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06599",
    "title": "Structured Chain-of-Thought Prompting for Code Generation",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2303.17780 ",
    "url": "https://arxiv.org/abs/2305.06599",
    "authors": [
      "Jia Li",
      "Ge Li",
      "Yongmin Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06551",
    "title": "An Efficient and Accurate Memristive Memory for Array-based Spiking  Neural Networks",
    "abstract": " Title: An Efficient and Accurate Memristive Memory for Array-based Spiking  Neural Networks ",
    "url": "https://arxiv.org/abs/2306.06551",
    "authors": [
      "Hritom Das",
      "Rocco D. Febbo",
      "SNB Tushar",
      "Nishith N. Chakraborty",
      "Maximilian Liehr",
      "Nathaniel Cady",
      "Garrett S. Rose"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2306.07019",
    "title": "Dynamic Causal Graph Convolutional Network for Traffic Prediction",
    "abstract": " Comments: Accepted to IEEE CASE 2023; Peter Luh Best Memorial Award for Young Researcher (Finalist) ",
    "url": "https://arxiv.org/abs/2306.07019",
    "authors": [
      "Junpeng Lin",
      "Ziyue Li",
      "Zhishuai Li",
      "Lei Bai",
      "Rui Zhao",
      "Chen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.07050",
    "title": "Revisiting Token Pruning for Object Detection and Instance Segmentation",
    "abstract": " Title: Revisiting Token Pruning for Object Detection and Instance Segmentation ",
    "url": "https://arxiv.org/abs/2306.07050",
    "authors": [
      "Yifei Liu",
      "Mathias Gehrig",
      "Nico Messikommer",
      "Marco Cannici",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.10890",
    "title": "QoS-Aware Downlink Beamforming for Joint Transmission in Multi-Cell  Networks",
    "abstract": " Title: QoS-Aware Downlink Beamforming for Joint Transmission in Multi-Cell  Networks ",
    "url": "https://arxiv.org/abs/2306.10890",
    "authors": [
      "Chen-Yen Lin",
      "Kuang-Hao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2306.12760",
    "title": "Blended-NeRF: Zero-Shot Object Generation and Blending in Existing  Neural Radiance Fields",
    "abstract": " Comments: 16 pages, 14 figures. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2306.12760",
    "authors": [
      "Ori Gordon",
      "Omri Avrahami",
      "Dani Lischinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13166",
    "title": "A Sparse Graph Formulation for Efficient Spectral Image Segmentation",
    "abstract": " Title: A Sparse Graph Formulation for Efficient Spectral Image Segmentation ",
    "url": "https://arxiv.org/abs/2306.13166",
    "authors": [
      "Rahul Palnitkar",
      "Jeova Farias Sales Rocha Neto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.13186",
    "title": "A Decade of Scholarly Research on Open Knowledge Graphs",
    "abstract": " Title: A Decade of Scholarly Research on Open Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2306.13186",
    "authors": [
      "Houcemeddine Turki",
      "Abraham Toluwase Owodunni",
      "Mohamed Ali Hadj Taieb",
      "Ren\u00e9 Fabrice Bile",
      "Mohamed Ben Aouicha"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.13455",
    "title": "DreamEditor: Text-Driven 3D Scene Editing with Neural Fields",
    "abstract": " Comments: Accepted by SIGGRAPH Asia 2023 ",
    "url": "https://arxiv.org/abs/2306.13455",
    "authors": [
      "Jingyu Zhuang",
      "Chen Wang",
      "Lingjie Liu",
      "Liang Lin",
      "Guanbin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.15955",
    "title": "Understanding Prompt Tuning for V-L Models Through the Lens of Neural  Collapse",
    "abstract": " Title: Understanding Prompt Tuning for V-L Models Through the Lens of Neural  Collapse ",
    "url": "https://arxiv.org/abs/2306.15955",
    "authors": [
      "Didi Zhu",
      "Zexi Li",
      "Min Zhang",
      "Junkun Yuan",
      "Yunfeng Shao",
      "Jiashuo Liu",
      "Kun Kuang",
      "Yinchuan Li",
      "Chao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.06555",
    "title": "Deep Network Approximation: Beyond ReLU to Diverse Activation Functions",
    "abstract": " Title: Deep Network Approximation: Beyond ReLU to Diverse Activation Functions ",
    "url": "https://arxiv.org/abs/2307.06555",
    "authors": [
      "Shijun Zhang",
      "Jianfeng Lu",
      "Hongkai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.09882",
    "title": "Adversarial Likelihood Estimation With One-Way Flows",
    "abstract": " Title: Adversarial Likelihood Estimation With One-Way Flows ",
    "url": "https://arxiv.org/abs/2307.09882",
    "authors": [
      "Omri Ben-Dov",
      "Pravir Singh Gupta",
      "Victoria Abrevaya",
      "Michael J. Black",
      "Partha Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12900",
    "title": "Automotive Object Detection via Learning Sparse Events by Spiking  Neurons",
    "abstract": " Title: Automotive Object Detection via Learning Sparse Events by Spiking  Neurons ",
    "url": "https://arxiv.org/abs/2307.12900",
    "authors": [
      "Hu Zhang",
      "Yanchen Li",
      "Luziwei Leng",
      "Kaiwei Che",
      "Qian Liu",
      "Qinghai Guo",
      "Jianxing Liao",
      "Ran Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.00452",
    "title": "A Majority Invariant Approach to Patch Robustness Certification for Deep  Learning Models",
    "abstract": " Comments: 5 pages, 2 figures, accepted for inclusion in the ASE 2023 NIER track ",
    "url": "https://arxiv.org/abs/2308.00452",
    "authors": [
      "Qilin Zhou",
      "Zhengyuan Wei",
      "Haipeng Wang",
      "W.K. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.02335",
    "title": "RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph  Classification",
    "abstract": " Comments: Accepted by the ACM International Conference on Multimedia (MM) 2023 ",
    "url": "https://arxiv.org/abs/2308.02335",
    "authors": [
      "Zhengyang Mao",
      "Wei Ju",
      "Yifang Qin",
      "Xiao Luo",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.03944",
    "title": "GraPhSyM: Graph Physical Synthesis Model",
    "abstract": " Comments: Accepted at Proceedings of the 42nd International Conference on Computer-Aided Design (ICCAD), 2023 ",
    "url": "https://arxiv.org/abs/2308.03944",
    "authors": [
      "Ahmed Agiza",
      "Rajarshi Roy",
      "Teodor Dumitru Ene",
      "Saad Godil",
      "Sherief Reda",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2308.08643",
    "title": "Towards Personalized Federated Learning via Heterogeneous Model  Reassembly",
    "abstract": " Title: Towards Personalized Federated Learning via Heterogeneous Model  Reassembly ",
    "url": "https://arxiv.org/abs/2308.08643",
    "authors": [
      "Jiaqi Wang",
      "Xingyi Yang",
      "Suhan Cui",
      "Liwei Che",
      "Lingjuan Lyu",
      "Dongkuan Xu",
      "Fenglong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.09183",
    "title": "RatGPT: Turning online LLMs into Proxies for Malware Attacks",
    "abstract": " Title: RatGPT: Turning online LLMs into Proxies for Malware Attacks ",
    "url": "https://arxiv.org/abs/2308.09183",
    "authors": [
      "Mika Beckerich",
      "Laura Plein",
      "Sergio Coronado"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13280",
    "title": "AtmoRep: A stochastic model of atmosphere dynamics using large scale  representation learning",
    "abstract": " Title: AtmoRep: A stochastic model of atmosphere dynamics using large scale  representation learning ",
    "url": "https://arxiv.org/abs/2308.13280",
    "authors": [
      "Christian Lessig",
      "Ilaria Luise",
      "Bing Gong",
      "Michael Langguth",
      "Scarlet Stadler",
      "Martin Schultz"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2308.13754",
    "title": "ZC3: Zero-Shot Cross-Language Code Clone Detection",
    "abstract": " Comments: Accepted by the 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023) ",
    "url": "https://arxiv.org/abs/2308.13754",
    "authors": [
      "Jia Li",
      "Chongyang Tao",
      "Zhi Jin",
      "Fang Liu",
      "Jia Li",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.13775",
    "title": "EditSum: A Retrieve-and-Edit Framework for Source Code Summarization",
    "abstract": " Comments: Accepted by the 36th IEEE/ACM International Conference on Automated Software Engineering (ASE 2021) ",
    "url": "https://arxiv.org/abs/2308.13775",
    "authors": [
      "Jia Li",
      "Yongmin Li",
      "Ge Li",
      "Xing Hu",
      "Xin Xia",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.15536",
    "title": "DebSDF: Delving into the Details and Bias of Neural Indoor Scene  Reconstruction",
    "abstract": " Title: DebSDF: Delving into the Details and Bias of Neural Indoor Scene  Reconstruction ",
    "url": "https://arxiv.org/abs/2308.15536",
    "authors": [
      "Yuting Xiao",
      "Jingwei Xu",
      "Zehao Yu",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.15990",
    "title": "Dual-path Transformer Based Neural Beamformer for Target Speech  Extraction",
    "abstract": " Title: Dual-path Transformer Based Neural Beamformer for Target Speech  Extraction ",
    "url": "https://arxiv.org/abs/2308.15990",
    "authors": [
      "Aoqi Guo",
      "Sichong Qian",
      "Baoxiang Li",
      "Dazhi Gao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.16763",
    "title": "Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection",
    "abstract": " Comments: 5 pages, 2 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2308.16763",
    "authors": [
      "Kairui Hu",
      "Ming Yan",
      "Joey Tianyi Zhou",
      "Ivor W. Tsang",
      "Wen Haw Chong",
      "Yong Keong Yap"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.00938",
    "title": "Exploring the Robustness of Human Parsers Towards Common Corruptions",
    "abstract": " Comments: Accepted by IEEE Transactions on Image Processing (TIP) ",
    "url": "https://arxiv.org/abs/2309.00938",
    "authors": [
      "Sanyi Zhang",
      "Xiaochun Cao",
      "Rui Wang",
      "Guo-Jun Qi",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01001",
    "title": "Cops and Robbers on 1-Planar Graphs",
    "abstract": " Comments: Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023) ",
    "url": "https://arxiv.org/abs/2309.01001",
    "authors": [
      "Stephane Durocher",
      "Shahin Kamali",
      "Myroslav Kryven",
      "Fengyi Liu",
      "Amirhossein Mashghdoust",
      "Avery Miller",
      "Pouria Zamani Nezhad",
      "Ikaro Penha Costa",
      "Timothy Zapp"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2309.01108",
    "title": "Acoustic-to-articulatory inversion for dysarthric speech: Are  pre-trained self-supervised representations favorable?",
    "abstract": " Comments: Submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.01108",
    "authors": [
      "Sarthak Kumar Maharana",
      "Krishna Kamal Adidam",
      "Shoumik Nandi",
      "Ajitesh Srivastava"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.01409",
    "title": "Implicit Neural Image Stitching With Enhanced and Blended Feature  Reconstruction",
    "abstract": " Title: Implicit Neural Image Stitching With Enhanced and Blended Feature  Reconstruction ",
    "url": "https://arxiv.org/abs/2309.01409",
    "authors": [
      "Minsu Kim",
      "Jaewon Lee",
      "Byeonghun Lee",
      "Sunghoon Im",
      "Kyong Hwan Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01582",
    "title": "Improving Visual Quality and Transferability of Adversarial Attacks on  Face Recognition Simultaneously with Adversarial Restoration",
    "abstract": " Title: Improving Visual Quality and Transferability of Adversarial Attacks on  Face Recognition Simultaneously with Adversarial Restoration ",
    "url": "https://arxiv.org/abs/2309.01582",
    "authors": [
      "Fengfan Zhou",
      "Hefei Ling",
      "Yuxuan Shi",
      "Jiazhong Chen",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01627",
    "title": "Cross-Consistent Deep Unfolding Network for Adaptive All-In-One Video  Restoration",
    "abstract": " Comments: 16 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2309.01627",
    "authors": [
      "Yuanshuo Cheng",
      "Mingwen Shao",
      "Yecong Wan",
      "Lixu Zhang",
      "Wangmeng Zuo",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01671",
    "title": "A Simple Pipeline for Orthogonal Graph Drawing",
    "abstract": " Comments: Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023) ",
    "url": "https://arxiv.org/abs/2309.01671",
    "authors": [
      "Tim Hegemann",
      "Alexander Wolff"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2309.02539",
    "title": "A Generalized Bandsplit Neural Network for Cinematic Audio Source  Separation",
    "abstract": " Comments: Submitted to ICASSP-OJSP 2024 ",
    "url": "https://arxiv.org/abs/2309.02539",
    "authors": [
      "Karn N. Watcharasupat",
      "Chih-Wei Wu",
      "Yiwei Ding",
      "Iroro Orife",
      "Aaron J. Hipple",
      "Phillip A. Williams",
      "Scott Kramer",
      "Alexander Lerch",
      "William Wolcott"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.02589",
    "title": "Approximating High-Dimensional Minimal Surfaces with Physics-Informed  Neural Networks",
    "abstract": " Comments: 22 pages, 27 figures ",
    "url": "https://arxiv.org/abs/2309.02589",
    "authors": [
      "Steven Zhou",
      "Xiaojing Ye"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.02719",
    "title": "DMKD: Improving Feature-based Knowledge Distillation for Object  Detection Via Dual Masking Augmentation",
    "abstract": " Title: DMKD: Improving Feature-based Knowledge Distillation for Object  Detection Via Dual Masking Augmentation ",
    "url": "https://arxiv.org/abs/2309.02719",
    "authors": [
      "Guang Yang",
      "Yin Tang",
      "Zhijian Wu",
      "Jun Li",
      "Jianhua Xu",
      "Xili Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.02855",
    "title": "Bandwidth-efficient Inference for Neural Image Compression",
    "abstract": " Comments: 9 pages, 6 figures, submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.02855",
    "authors": [
      "Shanzhi Yin",
      "Tongda Xu",
      "Yongsheng Liang",
      "Yuanyuan Wang",
      "Yanghao Li",
      "Yan Wang",
      "Jingjing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.02976",
    "title": "Natural and Robust Walking using Reinforcement Learning without  Demonstrations in High-Dimensional Musculoskeletal Models",
    "abstract": " Title: Natural and Robust Walking using Reinforcement Learning without  Demonstrations in High-Dimensional Musculoskeletal Models ",
    "url": "https://arxiv.org/abs/2309.02976",
    "authors": [
      "Pierre Schumacher",
      "Thomas Geijtenbeek",
      "Vittorio Caggiano",
      "Vikash Kumar",
      "Syn Schmitt",
      "Georg Martius",
      "Daniel F. B. Haeufle"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03169",
    "title": "Impression-Informed Multi-Behavior Recommender System: A Hierarchical  Graph Attention Approach",
    "abstract": " Title: Impression-Informed Multi-Behavior Recommender System: A Hierarchical  Graph Attention Approach ",
    "url": "https://arxiv.org/abs/2309.03169",
    "authors": [
      "Dong Li",
      "Divya Bhargavi",
      "Vidya Sagar Ravipati"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.03190",
    "title": "Blink: Link Local Differential Privacy in Graph Neural Networks via  Bayesian Estimation",
    "abstract": " Comments: 17 pages, accepted by ACM CCS 2023 as a conference paper ",
    "url": "https://arxiv.org/abs/2309.03190",
    "authors": [
      "Xiaochen Zhu",
      "Vincent Y. F. Tan",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  }
]