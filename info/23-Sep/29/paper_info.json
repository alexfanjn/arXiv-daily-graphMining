[
  {
    "id": "arXiv:2309.15855",
    "title": "Temporally-Evolving Generalised Networks and their Reproducing Kernels",
    "abstract": "This paper considers generalised network, intended as networks where (a) the edges connecting the nodes are nonlinear, and (b) stochastic processes are continuously indexed over both vertices and edges. Such topological structures are normally represented through special classes of graphs, termed graphs with Euclidean edges. We build generalised networks in which topology changes over time instants. That is, vertices and edges can disappear at subsequent time instants and edges may change in shape and length. We consider both cases of linear or circular time. For the second case, the generalised network exhibits a periodic structure. Our findings allow to illustrate pros and cons of each setting. Generalised networks become semi-metric spaces whenever equipped with a proper semi-metric. Our approach allows to build proper semi-metrics for the temporally-evolving topological structures of the networks. Our final effort is then devoted to guiding the reader through appropriate choice of classes of functions that allow to build proper reproducing kernels when composed with the temporally-evolving semi-metrics topological structures. ",
    "url": "https://arxiv.org/abs/2309.15855",
    "authors": [
      "Tobia Filosi",
      "Claudio Agostinelli",
      "Emilio Porcu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.15875",
    "title": "STAG: Enabling Low Latency and Low Staleness of GNN-based Services with  Dynamic Graphs",
    "abstract": "Many emerging user-facing services adopt Graph Neural Networks (GNNs) to improve serving accuracy. When the graph used by a GNN model changes, representations (embedding) of nodes in the graph should be updated accordingly. However, the node representation update is too slow, resulting in either long response latency of user queries (the inference is performed after the update completes) or high staleness problem (the inference is performed based on stale data). Our in-depth analysis shows that the slow update is mainly due to neighbor explosion problem in graphs and duplicated computation. Based on such findings, we propose STAG, a GNN serving framework that enables low latency and low staleness of GNN-based services. It comprises a collaborative serving mechanism and an additivity-based incremental propagation strategy. With the collaborative serving mechanism, only part of node representations are updated during the update phase, and the final representations are calculated in the inference phase. It alleviates the neighbor explosion problem. The additivity-based incremental propagation strategy reuses intermediate data during the update phase, eliminating duplicated computation problem. Experimental results show that STAG accelerates the update phase by 1.3x~90.1x, and greatly reduces staleness time with a slight increase in response latency. ",
    "url": "https://arxiv.org/abs/2309.15875",
    "authors": [
      "Jiawen Wang",
      "Quan Chen",
      "Deze Zeng",
      "Zhuo Song",
      "Chen Chen",
      "Minyi Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.15881",
    "title": "Enhancing Cross-Category Learning in Recommendation Systems with  Multi-Layer Embedding Training",
    "abstract": "Modern DNN-based recommendation systems rely on training-derived embeddings of sparse features. Input sparsity makes obtaining high-quality embeddings for rarely-occurring categories harder as their representations are updated infrequently. We demonstrate a training-time technique to produce superior embeddings via effective cross-category learning and theoretically explain its surprising effectiveness. The scheme, termed the multi-layer embeddings training (MLET), trains embeddings using factorization of the embedding layer, with an inner dimension higher than the target embedding dimension. For inference efficiency, MLET converts the trained two-layer embedding into a single-layer one thus keeping inference-time model size unchanged. Empirical superiority of MLET is puzzling as its search space is not larger than that of the single-layer embedding. The strong dependence of MLET on the inner dimension is even more surprising. We develop a theory that explains both of these behaviors by showing that MLET creates an adaptive update mechanism modulated by the singular vectors of embeddings. When tested on multiple state-of-the-art recommendation models for click-through rate (CTR) prediction tasks, MLET consistently produces better models, especially for rare items. At constant model quality, MLET allows embedding dimension, and model size, reduction by up to 16x, and 5.8x on average, across the models. ",
    "url": "https://arxiv.org/abs/2309.15881",
    "authors": [
      "Zihao Deng",
      "Benjamin Ghaemmaghami",
      "Ashish Kumar Singh",
      "Benjamin Cho",
      "Leo Orshansky",
      "Mattan Erez",
      "Michael Orshansky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.15883",
    "title": "Highly Efficient SNNs for High-speed Object Detection",
    "abstract": "The high biological properties and low energy consumption of Spiking Neural Networks (SNNs) have brought much attention in recent years. However, the converted SNNs generally need large time steps to achieve satisfactory performance, which will result in high inference latency and computational resources increase. In this work, we propose a highly efficient and fast SNN for object detection. First, we build an initial compact ANN by using quantization training method of convolution layer fold batch normalization layer and neural network modification. Second, we theoretically analyze how to obtain the low complexity SNN correctly. Then, we propose a scale-aware pseudoquantization scheme to guarantee the correctness of the compact ANN to SNN. Third, we propose a continuous inference scheme by using a Feed-Forward Integrate-and-Fire (FewdIF) neuron to realize high-speed object detection. Experimental results show that our efficient SNN can achieve 118X speedup on GPU with only 1.5MB parameters for object detection tasks. We further verify our SNN on FPGA platform and the proposed model can achieve 800+FPS object detection with extremely low latency. ",
    "url": "https://arxiv.org/abs/2309.15883",
    "authors": [
      "Nemin Qiu",
      "Zhiguo Li",
      "Yuan Li",
      "Chuang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15940",
    "title": "Context-Aware Entity Grounding with Open-Vocabulary 3D Scene Graphs",
    "abstract": "We present an Open-Vocabulary 3D Scene Graph (OVSG), a formal framework for grounding a variety of entities, such as object instances, agents, and regions, with free-form text-based queries. Unlike conventional semantic-based object localization approaches, our system facilitates context-aware entity localization, allowing for queries such as ``pick up a cup on a kitchen table\" or ``navigate to a sofa on which someone is sitting\". In contrast to existing research on 3D scene graphs, OVSG supports free-form text input and open-vocabulary querying. Through a series of comparative experiments using the ScanNet dataset and a self-collected dataset, we demonstrate that our proposed approach significantly surpasses the performance of previous semantic-based localization techniques. Moreover, we highlight the practical application of OVSG in real-world robot navigation and manipulation experiments. ",
    "url": "https://arxiv.org/abs/2309.15940",
    "authors": [
      "Haonan Chang",
      "Kowndinya Boyalakuntla",
      "Shiyang Lu",
      "Siwei Cai",
      "Eric Jing",
      "Shreesh Keskar",
      "Shijie Geng",
      "Adeeb Abbas",
      "Lifeng Zhou",
      "Kostas Bekris",
      "Abdeslam Boularias"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15963",
    "title": "An Uncertainty-Aware Pseudo-Label Selection Framework using Regularized  Conformal Prediction",
    "abstract": "Consistency regularization-based methods are prevalent in semi-supervised learning (SSL) algorithms due to their exceptional performance. However, they mainly depend on domain-specific data augmentations, which are not usable in domains where data augmentations are less practicable. On the other hand, Pseudo-labeling (PL) is a general and domain-agnostic SSL approach that, unlike consistency regularization-based methods, does not rely on the domain. PL underperforms due to the erroneous high-confidence predictions from poorly calibrated models. This paper proposes an uncertainty-aware pseudo-label selection framework that employs uncertainty sets yielded by the conformal regularization algorithm to fix the poor calibration neural networks, reducing noisy training data. The codes of this work are available at: https://github.com/matinmoezzi/ups conformal classification ",
    "url": "https://arxiv.org/abs/2309.15963",
    "authors": [
      "Matin Moezzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.15968",
    "title": "Dynamics of Ideological Biases of Social Media Users",
    "abstract": "Humanity for centuries has perfected skills of interpersonal interactions and evolved patterns that enable people to detect lies and deceiving behavior of others in face-to-face settings. Unprecedented growth of people's access to mobile phones and social media raises an important question: How does this new technology influence people's interactions and support the use of traditional patterns? In this paper, we answer this question for homophily driven patterns in social media. In our previous studies, we found that, on a university campus, changes in student opinions were driven by the desire to hold popular opinions. Here, we demonstrate that the evolution of online platform-wide opinion groups is driven by the same desire. We focus on two social media: Twitter and Parler, on which we tracked the political biases of their users. On Parler, an initially stable group of right-biased users evolved into a permanent right-leaning echo chamber dominating weaker, transient groups of members with opposing political biases. In contrast, on Twitter, the initial presence of two large opposing bias groups led to the evolution of a bimodal bias distribution, with a high degree of polarization. We capture the movement of users from the initial to final bias groups during the tracking period. We also show that user choices are influenced by side-effects of homophily. The users entering the platform attempt to find a sufficiently large group whose members hold political bias within the range sufficiently close to the new user's bias. If successful, they stabilize their bias and become a permanent member of the group. Otherwise, they leave the platform. We believe that the dynamics of users uncovered in this paper create a foundation for technical solutions supporting social groups on social media and socially aware networks. ",
    "url": "https://arxiv.org/abs/2309.15968",
    "authors": [
      "Mohammed Shahid Modi",
      "James Flamino",
      "Boleslaw K. Szymanski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.15971",
    "title": "OPPO: An Ontology for Describing Fine-Grained Data Practices in Privacy  Policies of Online Social Networks",
    "abstract": "Privacy policies outline the data practices of Online Social Networks (OSN) to comply with privacy regulations such as the EU-GDPR and CCPA. Several ontologies for modeling privacy regulations, policies, and compliance have emerged in recent years. However, they are limited in various ways: (1) they specifically model what is required of privacy policies according to one specific privacy regulation such as GDPR; (2) they provide taxonomies of concepts but are not sufficiently axiomatized to afford automated reasoning with them; and (3) they do not model data practices of privacy policies in sufficient detail to allow assessing the transparency of policies. This paper presents an OWL Ontology for Privacy Policies of OSNs, OPPO, that aims to fill these gaps by formalizing detailed data practices from OSNS' privacy policies. OPPO is grounded in BFO, IAO, OMRSE, and OBI, and its design is guided by the use case of representing and reasoning over the content of OSNs' privacy policies and evaluating policies' transparency in greater detail. ",
    "url": "https://arxiv.org/abs/2309.15971",
    "authors": [
      "Sanonda Datta Gupta",
      "Torsten Hahmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.15975",
    "title": "Enabling Large-scale Heterogeneous Collaboration with Opportunistic  Communications",
    "abstract": "Multi-robot collaboration in large-scale environments with limited-sized teams and without external infrastructure is challenging, since the software framework required to support complex tasks must be robust to unreliable and intermittent communication links. In this work, we present MOCHA (Multi-robot Opportunistic Communication for Heterogeneous Collaboration), a framework for resilient multi-robot collaboration that enables large-scale exploration in the absence of continuous communications. MOCHA is based on a gossip communication protocol that allows robots to interact opportunistically whenever communication links are available, propagating information on a peer-to-peer basis. We demonstrate the performance of MOCHA through real-world experiments with commercial-off-the-shelf (COTS) communication hardware. We further explore the system's scalability in simulation, evaluating the performance of our approach as the number of robots increases and communication ranges vary. Finally, we demonstrate how MOCHA can be tightly integrated with the planning stack of autonomous robots. We show a communication-aware planning algorithm for a high-altitude aerial robot executing a collaborative task while maximizing the amount of information shared with ground robots. The source code for MOCHA and the high-altitude UAV planning system is available open source: this http URL, this http URL ",
    "url": "https://arxiv.org/abs/2309.15975",
    "authors": [
      "Fernando Cladera",
      "Zachary Ravichandran",
      "Ian D. Miller",
      "M. Ani Hsieh",
      "C. J. Taylor",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.15977",
    "title": "Neural Acoustic Context Field: Rendering Realistic Room Impulse Response  With Neural Fields",
    "abstract": "Room impulse response (RIR), which measures the sound propagation within an environment, is critical for synthesizing high-fidelity audio for a given environment. Some prior work has proposed representing RIR as a neural field function of the sound emitter and receiver positions. However, these methods do not sufficiently consider the acoustic properties of an audio scene, leading to unsatisfactory performance. This letter proposes a novel Neural Acoustic Context Field approach, called NACF, to parameterize an audio scene by leveraging multiple acoustic contexts, such as geometry, material property, and spatial information. Driven by the unique properties of RIR, i.e., temporal un-smoothness and monotonic energy attenuation, we design a temporal correlation module and multi-scale energy decay criterion. Experimental results show that NACF outperforms existing field-based methods by a notable margin. Please visit our project page for more qualitative results. ",
    "url": "https://arxiv.org/abs/2309.15977",
    "authors": [
      "Susan Liang",
      "Chao Huang",
      "Yapeng Tian",
      "Anurag Kumar",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.15979",
    "title": "Clinical Trial Recommendations Using Semantics-Based Inductive Inference  and Knowledge Graph Embeddings",
    "abstract": "Designing a new clinical trial entails many decisions, such as defining a cohort and setting the study objectives to name a few, and therefore can benefit from recommendations based on exhaustive mining of past clinical trial records. Here, we propose a novel recommendation methodology, based on neural embeddings trained on a first-of-a-kind knowledge graph of clinical trials. We addressed several important research questions in this context, including designing a knowledge graph (KG) for clinical trial data, effectiveness of various KG embedding (KGE) methods for it, a novel inductive inference using KGE, and its use in generating recommendations for clinical trial design. We used publicly available data from clinicaltrials.gov for the study. Results show that our recommendations approach achieves relevance scores of 70%-83%, measured as the text similarity to actual clinical trial elements, and the most relevant recommendation can be found near the top of list. Our study also suggests potential improvement in training KGE using node semantics. ",
    "url": "https://arxiv.org/abs/2309.15979",
    "authors": [
      "Murthy V. Devarakonda",
      "Smita Mohanty",
      "Raja Rao Sunkishala",
      "Nag Mallampalli",
      "Xiong Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.15991",
    "title": "Targeted Image Data Augmentation Increases Basic Skills Captioning  Robustness",
    "abstract": "Artificial neural networks typically struggle in generalizing to out-of-context examples. One reason for this limitation is caused by having datasets that incorporate only partial information regarding the potential correlational structure of the world. In this work, we propose TIDA (Targeted Image-editing Data Augmentation), a targeted data augmentation method focused on improving models' human-like abilities (e.g., gender recognition) by filling the correlational structure gap using a text-to-image generative model. More specifically, TIDA identifies specific skills in captions describing images (e.g., the presence of a specific gender in the image), changes the caption (e.g., \"woman\" to \"man\"), and then uses a text-to-image model to edit the image in order to match the novel caption (e.g., uniquely changing a woman to a man while maintaining the context identical). Based on the Flickr30K benchmark, we show that, compared with the original data set, a TIDA-enhanced dataset related to gender, color, and counting abilities induces better performance in several image captioning metrics. Furthermore, on top of relying on the classical BLEU metric, we conduct a fine-grained analysis of the improvements of our models against the baseline in different ways. We compared text-to-image generative models and found different behaviors of the image captioning models in terms of encoding visual encoding and textual decoding. ",
    "url": "https://arxiv.org/abs/2309.15991",
    "authors": [
      "Valentin Barriere",
      "Felipe del Rio",
      "Andres Carvallo De Ferari",
      "Carlos Aspillaga",
      "Eugenio Herrera-Berg",
      "Cristian Buc Calderon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.15995",
    "title": "Digital Twin-based Anomaly Detection with Curriculum Learning in  Cyber-physical Systems",
    "abstract": "Anomaly detection is critical to ensure the security of cyber-physical systems (CPS). However, due to the increasing complexity of attacks and CPS themselves, anomaly detection in CPS is becoming more and more challenging. In our previous work, we proposed a digital twin-based anomaly detection method, called ATTAIN, which takes advantage of both historical and real-time data of CPS. However, such data vary significantly in terms of difficulty. Therefore, similar to human learning processes, deep learning models (e.g., ATTAIN) can benefit from an easy-to-difficult curriculum. To this end, in this paper, we present a novel approach, named digitaL twin-based Anomaly deTecTion wIth Curriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum learning to optimize its learning paradigm. LATTICE attributes each sample with a difficulty score, before being fed into a training scheduler. The training scheduler samples batches of training data based on these difficulty scores such that learning from easy to difficult data can be performed. To evaluate LATTICE, we use five publicly available datasets collected from five real-world CPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art anomaly detectors. Evaluation results show that LATTICE outperforms the three baselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also, on average, reduces the training time of ATTAIN by 4.2% on the five datasets and is on par with the baselines in terms of detection delay time. ",
    "url": "https://arxiv.org/abs/2309.15995",
    "authors": [
      "Qinghua Xu",
      "Shaukat Ali",
      "Tao Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.16002",
    "title": "Robust Blockwise Random Pivoting: Fast and Accurate Adaptive  Interpolative Decomposition",
    "abstract": "The interpolative decomposition (ID) aims to construct a low-rank approximation formed by a basis consisting of row/column skeletons in the original matrix and a corresponding interpolation matrix. This work explores fast and accurate ID algorithms from five essential perspectives for empirical performance: (a) skeleton complexity that measures the minimum possible ID rank for a given low-rank approximation error, (b) asymptotic complexity in FLOPs, (c) parallelizability of the computational bottleneck as matrix-matrix multiplications, (d) error-revealing property that enables automatic rank detection for given error tolerances without prior knowledge of target ranks, (e) ID-revealing property that ensures efficient construction of the optimal interpolation matrix after selecting the skeletons. While a broad spectrum of algorithms have been developed to optimize parts of the aforementioned perspectives, practical ID algorithms proficient in all perspectives remain absent. To fill in the gap, we introduce robust blockwise random pivoting (RBRP) that is parallelizable, error-revealing, and exact-ID-revealing, with comparable skeleton and asymptotic complexities to the best existing ID algorithms in practice. Through extensive numerical experiments on various synthetic and natural datasets, we empirically demonstrate the appealing performance of RBRP from the five perspectives above, as well as the robustness of RBRP to adversarial inputs. ",
    "url": "https://arxiv.org/abs/2309.16002",
    "authors": [
      "Yijun Dong",
      "Chao Chen",
      "Per-Gunnar Martinsson",
      "Katherine Pearce"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.16014",
    "title": "Graph-level Representation Learning with Joint-Embedding Predictive  Architectures",
    "abstract": "Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a novel and powerful technique for self-supervised representation learning. They aim to learn an energy-based model by predicting the latent representation of a target signal $y$ from a context signal $x$. JEPAs bypass the need for data augmentation and negative samples, which are typically required by contrastive learning, while avoiding the overfitting issues associated with generative-based pretraining. In this paper, we show that graph-level representations can be effectively modeled using this paradigm and propose Graph-JEPA, the first JEPA for the graph domain. In particular, we employ masked modeling to learn embeddings for different subgraphs of the input graph. To endow the representations with the implicit hierarchy that is often present in graph-level concepts, we devise an alternative training objective that consists of predicting the coordinates of the encoded subgraphs on the unit hyperbola in the 2D plane. Extensive validation shows that Graph-JEPA can learn representations that are expressive and competitive in both graph classification and regression problems. ",
    "url": "https://arxiv.org/abs/2309.16014",
    "authors": [
      "Geri Skenderi",
      "Hang Li",
      "Jiliang Tang",
      "Marco Cristani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16019",
    "title": "GasMono: Geometry-Aided Self-Supervised Monocular Depth Estimation for  Indoor Scenes",
    "abstract": "This paper tackles the challenges of self-supervised monocular depth estimation in indoor scenes caused by large rotation between frames and low texture. We ease the learning process by obtaining coarse camera poses from monocular sequences through multi-view geometry to deal with the former. However, we found that limited by the scale ambiguity across different scenes in the training dataset, a na\\\"ive introduction of geometric coarse poses cannot play a positive role in performance improvement, which is counter-intuitive. To address this problem, we propose to refine those poses during training through rotation and translation/scale optimization. To soften the effect of the low texture, we combine the global reasoning of vision transformers with an overfitting-aware, iterative self-distillation mechanism, providing more accurate depth guidance coming from the network itself. Experiments on NYUv2, ScanNet, 7scenes, and KITTI datasets support the effectiveness of each component in our framework, which sets a new state-of-the-art for indoor self-supervised monocular depth estimation, as well as outstanding generalization ability. Code and models are available at https://github.com/zxcqlf/GasMono ",
    "url": "https://arxiv.org/abs/2309.16019",
    "authors": [
      "Chaoqiang Zhao",
      "Matteo Poggi",
      "Fabio Tosi",
      "Lei Zhou",
      "Qiyu Sun",
      "Yang Tang",
      "Stefano Mattoccia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16021",
    "title": "HuntGPT: Integrating Machine Learning-Based Anomaly Detection and  Explainable AI with Large Language Models (LLMs)",
    "abstract": "Machine learning (ML) is crucial in network anomaly detection for proactive threat hunting, reducing detection and response times significantly. However, challenges in model training, maintenance, and frequent false positives impact its acceptance and reliability. Explainable AI (XAI) attempts to mitigate these issues, allowing cybersecurity teams to assess AI-generated alerts with confidence, but has seen limited acceptance from incident responders. Large Language Models (LLMs) present a solution through discerning patterns in extensive information and adapting to different functional requirements. We present HuntGPT, a specialized intrusion detection dashboard applying a Random Forest classifier using the KDD99 dataset, integrating XAI frameworks like SHAP and Lime for user-friendly and intuitive model interaction, and combined with a GPT-3.5 Turbo, it delivers threats in an understandable format. The paper delves into the system's architecture, components, and technical accuracy, assessed through Certified Information Security Manager (CISM) Practice Exams, evaluating response quality across six metrics. The results demonstrate that conversational agents, supported by LLM and integrated with XAI, provide robust, explainable, and actionable AI solutions in intrusion detection, enhancing user understanding and interactive experience. ",
    "url": "https://arxiv.org/abs/2309.16021",
    "authors": [
      "Tarek Ali",
      "Panos Kostakos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.16022",
    "title": "GNNHLS: Evaluating Graph Neural Network Inference via High-Level  Synthesis",
    "abstract": "With the ever-growing popularity of Graph Neural Networks (GNNs), efficient GNN inference is gaining tremendous attention. Field-Programming Gate Arrays (FPGAs) are a promising execution platform due to their fine-grained parallelism, low-power consumption, reconfigurability, and concurrent execution. Even better, High-Level Synthesis (HLS) tools bridge the gap between the non-trivial FPGA development efforts and rapid emergence of new GNN models. In this paper, we propose GNNHLS, an open-source framework to comprehensively evaluate GNN inference acceleration on FPGAs via HLS, containing a software stack for data generation and baseline deployment, and FPGA implementations of 6 well-tuned GNN HLS kernels. We evaluate GNNHLS on 4 graph datasets with distinct topologies and scales. The results show that GNNHLS achieves up to 50.8x speedup and 423x energy reduction relative to the CPU baselines. Compared with the GPU baselines, GNNHLS achieves up to 5.16x speedup and 74.5x energy reduction. ",
    "url": "https://arxiv.org/abs/2309.16022",
    "authors": [
      "Chenfeng Zhao",
      "Zehao Dong",
      "Yixin Chen",
      "Xuan Zhang",
      "Roger D. Chamberlain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2309.16032",
    "title": "Learning Dissipative Neural Dynamical Systems",
    "abstract": "Consider an unknown nonlinear dynamical system that is known to be dissipative. The objective of this paper is to learn a neural dynamical model that approximates this system, while preserving the dissipativity property in the model. In general, imposing dissipativity constraints during neural network training is a hard problem for which no known techniques exist. In this work, we address the problem of learning a dissipative neural dynamical system model in two stages. First, we learn an unconstrained neural dynamical model that closely approximates the system dynamics. Next, we derive sufficient conditions to perturb the weights of the neural dynamical model to ensure dissipativity, followed by perturbation of the biases to retain the fit of the model to the trajectories of the nonlinear system. We show that these two perturbation problems can be solved independently to obtain a neural dynamical model that is guaranteed to be dissipative while closely approximating the nonlinear system. ",
    "url": "https://arxiv.org/abs/2309.16032",
    "authors": [
      "Yuezhu Xu",
      "S. Sivaranjani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.16045",
    "title": "Minimum Monotone Tree Decomposition of Density Functions Defined on  Graphs",
    "abstract": "Monotone trees - trees with a function defined on their vertices that decreases the further away from a root node one travels, are a natural model for a process that weakens the further one gets from its source. Given an aggregation of monotone trees, one may wish to reconstruct the individual monotone components. A natural representation of such an aggregation would be a graph. While many methods have been developed for extracting hidden graph structure from datasets, which makes obtaining such an aggregation possible, decomposing such graphs into the original monotone trees is algorithmically challenging. Recently, a polynomial time algorithm has been developed to extract a minimum cardinality collection of monotone trees (M-Tree Set) from a given density tree - but no such algorithm exists for density graphs that may contain cycles. In this work, we prove that extracting such minimum M-Tree Sets of density graphs is NP-Complete. We additionally prove three additional variations of the problem - such as the minimum M-Tree Set such that the intersection between any two monotone trees is either empty or contractible (SM-Tree Set) - are also NP-Complete. We conclude by providing some approximation algorithms, highlighted by a 3-approximation algorithm for computing the minimum SM-Tree Set for density cactus graphs. ",
    "url": "https://arxiv.org/abs/2309.16045",
    "authors": [
      "Lucas Magee",
      "Yusu Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2309.16066",
    "title": "Label Augmentation Method for Medical Landmark Detection in Hip  Radiograph Images",
    "abstract": "This work reports the empirical performance of an automated medical landmark detection method for predict clinical markers in hip radiograph images. Notably, the detection method was trained using a label-only augmentation scheme; our results indicate that this form of augmentation outperforms traditional data augmentation and produces highly sample efficient estimators. We train a generic U-Net-based architecture under a curriculum consisting of two phases: initially relaxing the landmarking task by enlarging the label points to regions, then gradually eroding these label regions back to the base task. We measure the benefits of this approach on six datasets of radiographs with gold-standard expert annotations. ",
    "url": "https://arxiv.org/abs/2309.16066",
    "authors": [
      "Yehyun Suh",
      "Peter Chan",
      "J.Ryan Martin",
      "Daniel Moyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16071",
    "title": "Influence Pathway Discovery on Social Media",
    "abstract": "This paper addresses influence pathway discovery, a key emerging problem in today's online media. We propose a discovery algorithm that leverages recently published work on unsupervised interpretable ideological embedding, a mapping of ideological beliefs (done in a self-supervised fashion) into interpretable low-dimensional spaces. Computing the ideological embedding at scale allows one to analyze correlations between the ideological positions of leaders, influencers, news portals, or population segments, deriving potential influence pathways. The work is motivated by the importance of social media as the preeminent means for global interactions and collaborations on today's Internet, as well as their frequent (mis-)use to wield influence that targets social beliefs and attitudes of selected populations. Tools that enable the understanding and mapping of influence propagation through population segments on social media are therefore increasingly important. In this paper, influence is measured by the perceived ideological shift over time that is correlated with influencers' activity. Correlated shifts in ideological embeddings indicate changes, such as swings/switching (among competing ideologies), polarization (depletion of neutral ideological positions), escalation/radicalization (shifts to more extreme versions of the ideology), or unification/cooldown (shifts towards more neutral stances). Case-studies are presented to explore selected influence pathways (i) in a recent French election, (ii) during political discussions in the Philippines, and (iii) for some Russian messaging during the Russia/Ukraine conflict. ",
    "url": "https://arxiv.org/abs/2309.16071",
    "authors": [
      "Xinyi Liu",
      "Ruijie Wang",
      "Dachun Sun",
      "Jinning Li",
      "Christina Youn",
      "You Lyu",
      "Jianyuan Zhan",
      "Dayou Wu",
      "Xinhe Xu",
      "Mingjun Liu",
      "Xinshuo Lei",
      "Zhihao Xu",
      "Yutong Zhang",
      "Zehao Li",
      "Qikai Yang",
      "Tarek Abdelzaher"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.16085",
    "title": "Differentiable Robot Neural Distance Function for Adaptive Grasp  Synthesis on a Unified Robotic Arm-Hand System",
    "abstract": "Grasping is a fundamental skill for robots to interact with their environment. While grasp execution requires coordinated movement of the hand and arm to achieve a collision-free and secure grip, many grasp synthesis studies address arm and hand motion planning independently, leading to potentially unreachable grasps in practical settings. The challenge of determining integrated arm-hand configurations arises from its computational complexity and high-dimensional nature. We address this challenge by presenting a novel differentiable robot neural distance function. Our approach excels in capturing intricate geometry across various joint configurations while preserving differentiability. This innovative representation proves instrumental in efficiently addressing downstream tasks with stringent contact constraints. Leveraging this, we introduce an adaptive grasp synthesis framework that exploits the full potential of the unified arm-hand system for diverse grasping tasks. Our neural joint space distance function achieves an 84.7% error reduction compared to baseline methods. We validated our approaches on a unified robotic arm-hand system that consists of a 7-DoF robot arm and a 16-DoF multi-fingered robotic hand. Results demonstrate that our approach empowers this high-DoF system to generate and execute various arm-hand grasp configurations that adapt to the size of the target objects while ensuring whole-body movements to be collision-free. ",
    "url": "https://arxiv.org/abs/2309.16085",
    "authors": [
      "Yiting Chen",
      "Xiao Gao",
      "Kunpeng Yao",
      "Lo\u00efc Niederhauser",
      "Yasemin Bekiroglu",
      "Aude Billard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.16096",
    "title": "Adversarial Examples Might be Avoidable: The Role of Data Concentration  in Adversarial Robustness",
    "abstract": "The susceptibility of modern machine learning classifiers to adversarial examples has motivated theoretical results suggesting that these might be unavoidable. However, these results can be too general to be applicable to natural data distributions. Indeed, humans are quite robust for tasks involving vision. This apparent conflict motivates a deeper dive into the question: Are adversarial examples truly unavoidable? In this work, we theoretically demonstrate that a key property of the data distribution -- concentration on small-volume subsets of the input space -- determines whether a robust classifier exists. We further demonstrate that, for a data distribution concentrated on a union of low-dimensional linear subspaces, exploiting data structure naturally leads to classifiers that enjoy good robustness guarantees, improving upon methods for provable certification in certain regimes. ",
    "url": "https://arxiv.org/abs/2309.16096",
    "authors": [
      "Ambar Pal",
      "Jeremias Sulam",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16110",
    "title": "Learning Effective NeRFs and SDFs Representations with 3D Generative  Adversarial Networks for 3D Object Generation: Technical Report for ICCV 2023  OmniObject3D Challenge",
    "abstract": "In this technical report, we present a solution for 3D object generation of ICCV 2023 OmniObject3D Challenge. In recent years, 3D object generation has made great process and achieved promising results, but it remains a challenging task due to the difficulty of generating complex, textured and high-fidelity results. To resolve this problem, we study learning effective NeRFs and SDFs representations with 3D Generative Adversarial Networks (GANs) for 3D object generation. Specifically, inspired by recent works, we use the efficient geometry-aware 3D GANs as the backbone incorporating with label embedding and color mapping, which enables to train the model on different taxonomies simultaneously. Then, through a decoder, we aggregate the resulting features to generate Neural Radiance Fields (NeRFs) based representations for rendering high-fidelity synthetic images. Meanwhile, we optimize Signed Distance Functions (SDFs) to effectively represent objects with 3D meshes. Besides, we observe that this model can be effectively trained with only a few images of each object from a variety of classes, instead of using a great number of images per object or training one model per class. With this pipeline, we can optimize an effective model for 3D object generation. This solution is one of the final top-3-place solutions in the ICCV 2023 OmniObject3D Challenge. ",
    "url": "https://arxiv.org/abs/2309.16110",
    "authors": [
      "Zheyuan Yang",
      "Yibo Liu",
      "Guile Wu",
      "Tongtong Cao",
      "Yuan Ren",
      "Yang Liu",
      "Bingbing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16114",
    "title": "Comparing Active Learning Performance Driven by Gaussian Processes or  Bayesian Neural Networks for Constrained Trajectory Exploration",
    "abstract": "Robots with increasing autonomy progress our space exploration capabilities, particularly for in-situ exploration and sampling to stand in for human explorers. Currently, humans drive robots to meet scientific objectives, but depending on the robot's location, the exchange of information and driving commands between the human operator and robot may cause undue delays in mission fulfillment. An autonomous robot encoded with a scientific objective and an exploration strategy incurs no communication delays and can fulfill missions more quickly. Active learning algorithms offer this capability of intelligent exploration, but the underlying model structure varies the performance of the active learning algorithm in accurately forming an understanding of the environment. In this paper, we investigate the performance differences between active learning algorithms driven by Gaussian processes or Bayesian neural networks for exploration strategies encoded on agents that are constrained in their trajectories, like planetary surface rovers. These two active learning strategies were tested in a simulation environment against science-blind strategies to predict the spatial distribution of a variable of interest along multiple datasets. The performance metrics of interest are model accuracy in root mean squared (RMS) error, training time, model convergence, total distance traveled until convergence, and total samples until convergence. Active learning strategies encoded with Gaussian processes require less computation to train, converge to an accurate model more quickly, and propose trajectories of shorter distance, except in a few complex environments in which Bayesian neural networks achieve a more accurate model in the large data regime due to their more expressive functional bases. The paper concludes with advice on when and how to implement either exploration strategy for future space missions. ",
    "url": "https://arxiv.org/abs/2309.16114",
    "authors": [
      "Sapphira Akins",
      "Frances Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16117",
    "title": "E2Net: Resource-Efficient Continual Learning with Elastic Expansion  Network",
    "abstract": "Continual Learning methods are designed to learn new tasks without erasing previous knowledge. However, Continual Learning often requires massive computational power and storage capacity for satisfactory performance. In this paper, we propose a resource-efficient continual learning method called the Elastic Expansion Network (E2Net). Leveraging core subnet distillation and precise replay sample selection, E2Net achieves superior average accuracy and diminished forgetting within the same computational and storage constraints, all while minimizing processing time. In E2Net, we propose Representative Network Distillation to identify the representative core subnet by assessing parameter quantity and output similarity with the working network, distilling analogous subnets within the working network to mitigate reliance on rehearsal buffers and facilitating knowledge transfer across previous tasks. To enhance storage resource utilization, we then propose Subnet Constraint Experience Replay to optimize rehearsal efficiency through a sample storage strategy based on the structures of representative networks. Extensive experiments conducted predominantly on cloud environments with diverse datasets and also spanning the edge environment demonstrate that E2Net consistently outperforms state-of-the-art methods. In addition, our method outperforms competitors in terms of both storage and computational requirements. ",
    "url": "https://arxiv.org/abs/2309.16117",
    "authors": [
      "RuiQi Liu",
      "Boyu Diao",
      "Libo Huang",
      "Zhulin An",
      "Yongjun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16120",
    "title": "Test-Case-Driven Programming Understanding in Large Language Models for  Better Code Generation",
    "abstract": "Code generation is to automatically generate source code conforming to a given programming specification, which has received extensive attention especially with the development of large language models (LLMs). Due to the inherent difficulty of code generation, the code generated by LLMs may be also not aligned with the specification. To improve the perfor mance of LLMs in code generation, some Chain of Thought (CoT) techniques have been proposed to guide LLMs for programming understanding before code generation. However, they are still hard to figure out complicated programming logic according to the (concise) specification, leadingto unsatisfactory code generation performance. In this work, we propose the first test-case-driven CoT technique, called TCoT, to further enhance the ability of LLMs in code generation. It understands the programming specification from the novel perspective of test cases, which is aligned with human practice by using examples to understand complicated problems. Due to the existence of the expected output specified in a test case, TCoT can instantly check the correctness of the programming understanding and then refine it to be as correct as possible before code generation. In this way, it is more likely to generate correct code. Our evaluation on 6 datasets and 14 baselines demonstrates the effectiveness of TCoT. For example, TCoT improves ChatGPT by 13.93%~69.44% in terms of Pass@1 (measuring the ratio of programming problems for which the generated code passes all test cases), and outperforms the existing CoT technique with the improvement of 12.14%~53.72% in terms of Pass@1. ",
    "url": "https://arxiv.org/abs/2309.16120",
    "authors": [
      "Zhao Tian",
      "Junjie Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.16131",
    "title": "A Spectral Approach for Learning Spatiotemporal Neural Differential  Equations",
    "abstract": "Rapidly developing machine learning methods has stimulated research interest in computationally reconstructing differential equations (DEs) from observational data which may provide additional insight into underlying causative mechanisms. In this paper, we propose a novel neural-ODE based method that uses spectral expansions in space to learn spatiotemporal DEs. The major advantage of our spectral neural DE learning approach is that it does not rely on spatial discretization, thus allowing the target spatiotemporal equations to contain long range, nonlocal spatial interactions that act on unbounded spatial domains. Our spectral approach is shown to be as accurate as some of the latest machine learning approaches for learning PDEs operating on bounded domains. By developing a spectral framework for learning both PDEs and integro-differential equations, we extend machine learning methods to apply to unbounded DEs and a larger class of problems. ",
    "url": "https://arxiv.org/abs/2309.16131",
    "authors": [
      "Mingtao Xia",
      "Xiangting Li",
      "Qijing Shen",
      "Tom Chou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2309.16134",
    "title": "Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph  through AI Chain",
    "abstract": "API recommendation methods have evolved from literal and semantic keyword matching to query expansion and query clarification. The latest query clarification method is knowledge graph (KG)-based, but limitations include out-of-vocabulary (OOV) failures and rigid question templates. To address these limitations, we propose a novel knowledge-guided query clarification approach for API recommendation that leverages a large language model (LLM) guided by KG. We utilize the LLM as a neural knowledge base to overcome OOV failures, generating fluent and appropriate clarification questions and options. We also leverage the structured API knowledge and entity relationships stored in the KG to filter out noise, and transfer the optimal clarification path from KG to the LLM, increasing the efficiency of the clarification process. Our approach is designed as an AI chain that consists of five steps, each handled by a separate LLM call, to improve accuracy, efficiency, and fluency for query clarification in API recommendation. We verify the usefulness of each unit in our AI chain, which all received high scores close to a perfect 5. When compared to the baselines, our approach shows a significant improvement in MRR, with a maximum increase of 63.9% higher when the query statement is covered in KG and 37.2% when it is not. Ablation experiments reveal that the guidance of knowledge in the KG and the knowledge-guided pathfinding strategy are crucial for our approach's performance, resulting in a 19.0% and 22.2% increase in MAP, respectively. Our approach demonstrates a way to bridge the gap between KG and LLM, effectively compensating for the strengths and weaknesses of both. ",
    "url": "https://arxiv.org/abs/2309.16134",
    "authors": [
      "Qing Huang",
      "Zhenyu Wan",
      "Zhenchang Xing",
      "Changjing Wang",
      "Jieshan Chen",
      "Xiwei Xu",
      "Qinghua Lu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.16158",
    "title": "FireFly v2: Advancing Hardware Support for High-Performance Spiking  Neural Network with a Spatiotemporal FPGA Accelerator",
    "abstract": "Spiking Neural Networks (SNNs) are expected to be a promising alternative to Artificial Neural Networks (ANNs) due to their strong biological interpretability and high energy efficiency. Specialized SNN hardware offers clear advantages over general-purpose devices in terms of power and performance. However, there's still room to advance hardware support for state-of-the-art (SOTA) SNN algorithms and improve computation and memory efficiency. As a further step in supporting high-performance SNNs on specialized hardware, we introduce FireFly v2, an FPGA SNN accelerator that can address the issue of non-spike operation in current SOTA SNN algorithms, which presents an obstacle in the end-to-end deployment onto existing SNN hardware. To more effectively align with the SNN characteristics, we design a spatiotemporal dataflow that allows four dimensions of parallelism and eliminates the need for membrane potential storage, enabling on-the-fly spike processing and spike generation. To further improve hardware acceleration performance, we develop a high-performance spike computing engine as a backend based on a systolic array operating at 500-600MHz. To the best of our knowledge, FireFly v2 achieves the highest clock frequency among all FPGA-based implementations. Furthermore, it stands as the first SNN accelerator capable of supporting non-spike operations, which are commonly used in advanced SNN algorithms. FireFly v2 has doubled the throughput and DSP efficiency when compared to our previous version of FireFly and it exhibits 1.33 times the DSP efficiency and 1.42 times the power efficiency compared to the current most advanced FPGA accelerators. ",
    "url": "https://arxiv.org/abs/2309.16158",
    "authors": [
      "Jindong Li",
      "Guobin Shen",
      "Dongcheng Zhao",
      "Qian Zhang",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2309.16172",
    "title": "Random and Safe Cache Architecture to Defeat Cache Timing Attacks",
    "abstract": "Caches have been exploited to leak secret information due to the different times they take to handle memory accesses. Cache timing attacks include non-speculative cache side and covert channel attacks and cache-based speculative execution attacks. We first present a systematic view of the attack and defense space and show that no existing defense has addressed both speculative and non-speculative cache timing attack families, which we do in this paper. We propose Random and Safe (RaS) cache architectures to decorrelate the cache state changes from memory requests. RaS fills the cache with ``safe'' cache lines that are likely to be used in the future, rather than with demand-fetched, security-sensitive lines. RaS captures a group of safe addresses during runtime and fetches addresses randomly displaced from these addresses. Our proposed RaS architecture is flexible to allow security-performance trade-offs. We show different designs of RaS architectures that can defeat cache side-channel attacks and cache-based speculative execution attacks. The RaS variant against cache-based speculative execution attacks has 4.2% average performance overhead and other RaS variants against both attack families have 7.9% to 45.2% average overhead. For some benchmarks, RaS defenses improve the performance while providing security. ",
    "url": "https://arxiv.org/abs/2309.16172",
    "authors": [
      "Guangyuan Hu",
      "Ruby B. Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2309.16173",
    "title": "Distill to Delete: Unlearning in Graph Networks with Knowledge  Distillation",
    "abstract": "Graph unlearning has emerged as a pivotal method to delete information from a pre-trained graph neural network (GNN). One may delete nodes, a class of nodes, edges, or a class of edges. An unlearning method enables the GNN model to comply with data protection regulations (i.e., the right to be forgotten), adapt to evolving data distributions, and reduce the GPU-hours carbon footprint by avoiding repetitive retraining. Existing partitioning and aggregation-based methods have limitations due to their poor handling of local graph dependencies and additional overhead costs. More recently, GNNDelete offered a model-agnostic approach that alleviates some of these issues. Our work takes a novel approach to address these challenges in graph unlearning through knowledge distillation, as it distills to delete in GNN (D2DGN). It is a model-agnostic distillation framework where the complete graph knowledge is divided and marked for retention and deletion. It performs distillation with response-based soft targets and feature-based node embedding while minimizing KL divergence. The unlearned model effectively removes the influence of deleted graph elements while preserving knowledge about the retained graph elements. D2DGN surpasses the performance of existing methods when evaluated on various real-world graph datasets by up to $43.1\\%$ (AUC) in edge and node unlearning tasks. Other notable advantages include better efficiency, better performance in removing target elements, preservation of performance for the retained elements, and zero overhead costs. Notably, our D2DGN surpasses the state-of-the-art GNNDelete in AUC by $2.4\\%$, improves membership inference ratio by $+1.3$, requires $10.2\\times10^6$ fewer FLOPs per forward pass and up to $\\mathbf{3.2}\\times$ faster. ",
    "url": "https://arxiv.org/abs/2309.16173",
    "authors": [
      "Yash Sinha",
      "Murari Mandal",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16175",
    "title": "Using Weak Supervision and Data Augmentation in Question Answering",
    "abstract": "The onset of the COVID-19 pandemic accentuated the need for access to biomedical literature to answer timely and disease-specific questions. During the early days of the pandemic, one of the biggest challenges we faced was the lack of peer-reviewed biomedical articles on COVID-19 that could be used to train machine learning models for question answering (QA). In this paper, we explore the roles weak supervision and data augmentation play in training deep neural network QA models. First, we investigate whether labels generated automatically from the structured abstracts of scholarly papers using an information retrieval algorithm, BM25, provide a weak supervision signal to train an extractive QA model. We also curate new QA pairs using information retrieval techniques, guided by the clinicaltrials.gov schema and the structured abstracts of articles, in the absence of annotated data from biomedical domain experts. Furthermore, we explore augmenting the training data of a deep neural network model with linguistic features from external sources such as lexical databases to account for variations in word morphology and meaning. To better utilize our training data, we apply curriculum learning to domain adaptation, fine-tuning our QA model in stages based on characteristics of the QA pairs. We evaluate our methods in the context of QA models at the core of a system to answer questions about COVID-19. ",
    "url": "https://arxiv.org/abs/2309.16175",
    "authors": [
      "Chumki Basu",
      "Himanshu Garg",
      "Allen McIntosh",
      "Sezai Sablak",
      "John R. Wullert II"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16179",
    "title": "BEVHeight++: Toward Robust Visual Centric 3D Object Detection",
    "abstract": "While most recent autonomous driving system focuses on developing perception methods on ego-vehicle sensors, people tend to overlook an alternative approach to leverage intelligent roadside cameras to extend the perception ability beyond the visual range. We discover that the state-of-the-art vision-centric bird's eye view detection methods have inferior performances on roadside cameras. This is because these methods mainly focus on recovering the depth regarding the camera center, where the depth difference between the car and the ground quickly shrinks while the distance increases. In this paper, we propose a simple yet effective approach, dubbed BEVHeight++, to address this issue. In essence, we regress the height to the ground to achieve a distance-agnostic formulation to ease the optimization process of camera-only perception methods. By incorporating both height and depth encoding techniques, we achieve a more accurate and robust projection from 2D to BEV spaces. On popular 3D detection benchmarks of roadside cameras, our method surpasses all previous vision-centric methods by a significant margin. In terms of the ego-vehicle scenario, our BEVHeight++ possesses superior over depth-only methods. Specifically, it yields a notable improvement of +1.9% NDS and +1.1% mAP over BEVDepth when evaluated on the nuScenes validation set. Moreover, on the nuScenes test set, our method achieves substantial advancements, with an increase of +2.8% NDS and +1.7% mAP, respectively. ",
    "url": "https://arxiv.org/abs/2309.16179",
    "authors": [
      "Lei Yang",
      "Tao Tang",
      "Jun Li",
      "Peng Chen",
      "Kun Yuan",
      "Li Wang",
      "Yi Huang",
      "Xinyu Zhang",
      "Kaicheng Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16205",
    "title": "DiffGAN-F2S: Symmetric and Efficient Denoising Diffusion GANs for  Structural Connectivity Prediction from Brain fMRI",
    "abstract": "Mapping from functional connectivity (FC) to structural connectivity (SC) can facilitate multimodal brain network fusion and discover potential biomarkers for clinical implications. However, it is challenging to directly bridge the reliable non-linear mapping relations between SC and functional magnetic resonance imaging (fMRI). In this paper, a novel diffusision generative adversarial network-based fMRI-to-SC (DiffGAN-F2S) model is proposed to predict SC from brain fMRI in an end-to-end manner. To be specific, the proposed DiffGAN-F2S leverages denoising diffusion probabilistic models (DDPMs) and adversarial learning to efficiently generate high-fidelity SC through a few steps from fMRI. By designing the dual-channel multi-head spatial attention (DMSA) and graph convolutional modules, the symmetric graph generator first captures global relations among direct and indirect connected brain regions, then models the local brain region interactions. It can uncover the complex mapping relations between fMRI and structural connectivity. Furthermore, the spatially connected consistency loss is devised to constrain the generator to preserve global-local topological information for accurate intrinsic SC prediction. Testing on the public Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, the proposed model can effectively generate empirical SC-preserved connectivity from four-dimensional imaging data and shows superior performance in SC prediction compared with other related models. Furthermore, the proposed model can identify the vast majority of important brain regions and connections derived from the empirical method, providing an alternative way to fuse multimodal brain networks and analyze clinical disease. ",
    "url": "https://arxiv.org/abs/2309.16205",
    "authors": [
      "Qiankun Zuo",
      "Ruiheng Li",
      "Yi Di",
      "Hao Tian",
      "Changhong Jing",
      "Xuhang Chen",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.16207",
    "title": "Parameter-Saving Adversarial Training: Reinforcing Multi-Perturbation  Robustness via Hypernetworks",
    "abstract": "Adversarial training serves as one of the most popular and effective methods to defend against adversarial perturbations. However, most defense mechanisms only consider a single type of perturbation while various attack methods might be adopted to perform stronger adversarial attacks against the deployed model in real-world scenarios, e.g., $\\ell_2$ or $\\ell_\\infty$. Defending against various attacks can be a challenging problem since multi-perturbation adversarial training and its variants only achieve suboptimal robustness trade-offs, due to the theoretical limit to multi-perturbation robustness for a single model. Besides, it is impractical to deploy large models in some storage-efficient scenarios. To settle down these drawbacks, in this paper we propose a novel multi-perturbation adversarial training framework, parameter-saving adversarial training (PSAT), to reinforce multi-perturbation robustness with an advantageous side effect of saving parameters, which leverages hypernetworks to train specialized models against a single perturbation and aggregate these specialized models to defend against multiple perturbations. Eventually, we extensively evaluate and compare our proposed method with state-of-the-art single/multi-perturbation robust methods against various latest attack methods on different datasets, showing the robustness superiority and parameter efficiency of our proposed method, e.g., for the CIFAR-10 dataset with ResNet-50 as the backbone, PSAT saves approximately 80\\% of parameters with achieving the state-of-the-art robustness trade-off accuracy. ",
    "url": "https://arxiv.org/abs/2309.16207",
    "authors": [
      "Huihui Gong",
      "Minjing Dong",
      "Siqi Ma",
      "Seyit Camtepe",
      "Surya Nepal",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16220",
    "title": "Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection  in Medical Tabular Data",
    "abstract": "Despite their success, Machine Learning (ML) models do not generalize effectively to data not originating from the training distribution. To reliably employ ML models in real-world healthcare systems and avoid inaccurate predictions on out-of-distribution (OOD) data, it is crucial to detect OOD samples. Numerous OOD detection approaches have been suggested in other fields - especially in computer vision - but it remains unclear whether the challenge is resolved when dealing with medical tabular data. To answer this pressing need, we propose an extensive reproducible benchmark to compare different methods across a suite of tests including both near and far OODs. Our benchmark leverages the latest versions of eICU and MIMIC-IV, two public datasets encompassing tens of thousands of ICU patients in several hospitals. We consider a wide array of density-based methods and SOTA post-hoc detectors across diverse predictive architectures, including MLP, ResNet, and Transformer. Our findings show that i) the problem appears to be solved for far-OODs, but remains open for near-OODs; ii) post-hoc methods alone perform poorly, but improve substantially when coupled with distance-based mechanisms; iii) the transformer architecture is far less overconfident compared to MLP and ResNet. ",
    "url": "https://arxiv.org/abs/2309.16220",
    "authors": [
      "Mohammad Azizmalayeri",
      "Ameen Abu-Hanna",
      "Giovanni Cin\u00e1"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16223",
    "title": "GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network  Explanations",
    "abstract": "Diverse explainability methods of graph neural networks (GNN) have recently been developed to highlight the edges and nodes in the graph that contribute the most to the model predictions. However, it is not clear yet how to evaluate the correctness of those explanations, whether it is from a human or a model perspective. One unaddressed bottleneck in the current evaluation procedure is the problem of out-of-distribution explanations, whose distribution differs from those of the training data. This important issue affects existing evaluation metrics such as the popular faithfulness or fidelity score. In this paper, we show the limitations of faithfulness metrics. We propose GInX-Eval (Graph In-distribution eXplanation Evaluation), an evaluation procedure of graph explanations that overcomes the pitfalls of faithfulness and offers new insights on explainability methods. Using a retraining strategy, the GInX score measures how informative removed edges are for the model and the EdgeRank score evaluates if explanatory edges are correctly ordered by their importance. GInX-Eval verifies if ground-truth explanations are instructive to the GNN model. In addition, it shows that many popular methods, including gradient-based methods, produce explanations that are not better than a random designation of edges as important subgraphs, challenging the findings of current works in the area. Results with GInX-Eval are consistent across multiple datasets and align with human evaluation. ",
    "url": "https://arxiv.org/abs/2309.16223",
    "authors": [
      "Kenza Amara",
      "Mennatallah El-Assady",
      "Rex Ying"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16228",
    "title": "Brand Network Booster: A New System for Improving Brand Connectivity",
    "abstract": "This paper presents a new decision support system offered for an in-depth analysis of semantic networks, which can provide insights for a better exploration of a brand's image and the improvement of its connectivity. In terms of network analysis, we show that this goal is achieved by solving an extended version of the Maximum Betweenness Improvement problem, which includes the possibility of considering adversarial nodes, constrained budgets, and weighted networks - where connectivity improvement can be obtained by adding links or increasing the weight of existing connections. We present this new system together with two case studies, also discussing its performance. Our tool and approach are useful both for network scholars and for supporting the strategic decision-making processes of marketing and communication managers. ",
    "url": "https://arxiv.org/abs/2309.16228",
    "authors": [
      "J. Cancellieri",
      "W. Didimo",
      "A. Fronzetti Colladon",
      "F. Montecchiani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2309.16248",
    "title": "Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph  Question Answering Systems",
    "abstract": "With the recent spike in the number and availability of Large Language Models (LLMs), it has become increasingly important to provide large and realistic benchmarks for evaluating Knowledge Graph Question Answering (KBQA) systems. So far the majority of benchmarks rely on pattern-based SPARQL query generation approaches. The subsequent natural language (NL) question generation is conducted through crowdsourcing or other automated methods, such as rule-based paraphrasing or NL question templates. Although some of these datasets are of considerable size, their pitfall lies in their pattern-based generation approaches, which do not always generalize well to the vague and linguistically diverse questions asked by humans in real-world contexts. In this paper, we introduce Spider4SPARQL - a new SPARQL benchmark dataset featuring 9,693 previously existing manually generated NL questions and 4,721 unique, novel, and complex SPARQL queries of varying complexity. In addition to the NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs and ontologies, which cover 138 different domains. Our complex benchmark enables novel ways of evaluating the strengths and weaknesses of modern KGQA systems. We evaluate the system with state-of-the-art KGQA systems as well as LLMs, which achieve only up to 45\\% execution accuracy, demonstrating that Spider4SPARQL is a challenging benchmark for future research. ",
    "url": "https://arxiv.org/abs/2309.16248",
    "authors": [
      "Catherine Kosten",
      "Philippe Cudr\u00e9-Mauroux",
      "Kurt Stockinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.16249",
    "title": "FORB: A Flat Object Retrieval Benchmark for Universal Image Embedding",
    "abstract": "Image retrieval is a fundamental task in computer vision. Despite recent advances in this field, many techniques have been evaluated on a limited number of domains, with a small number of instance categories. Notably, most existing works only consider domains like 3D landmarks, making it difficult to generalize the conclusions made by these works to other domains, e.g., logo and other 2D flat objects. To bridge this gap, we introduce a new dataset for benchmarking visual search methods on flat images with diverse patterns. Our flat object retrieval benchmark (FORB) supplements the commonly adopted 3D object domain, and more importantly, it serves as a testbed for assessing the image embedding quality on out-of-distribution domains. In this benchmark we investigate the retrieval accuracy of representative methods in terms of candidate ranks, as well as matching score margin, a viewpoint which is largely ignored by many works. Our experiments not only highlight the challenges and rich heterogeneity of FORB, but also reveal the hidden properties of different retrieval strategies. The proposed benchmark is a growing project and we expect to expand in both quantity and variety of objects. The dataset and supporting codes are available at https://github.com/pxiangwu/FORB/. ",
    "url": "https://arxiv.org/abs/2309.16249",
    "authors": [
      "Pengxiang Wu",
      "Siman Wang",
      "Kevin Dela Rosa",
      "Derek Hao Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16254",
    "title": "On the Challenges of Fully Incremental Neural Dependency Parsing",
    "abstract": "Since the popularization of BiLSTMs and Transformer-based bidirectional encoders, state-of-the-art syntactic parsers have lacked incrementality, requiring access to the whole sentence and deviating from human language processing. This paper explores whether fully incremental dependency parsing with modern architectures can be competitive. We build parsers combining strictly left-to-right neural encoders with fully incremental sequence-labeling and transition-based decoders. The results show that fully incremental parsing with modern architectures considerably lags behind bidirectional parsing, noting the challenges of psycholinguistically plausible parsing. ",
    "url": "https://arxiv.org/abs/2309.16254",
    "authors": [
      "Ana Ezquerro",
      "Carlos G\u00f3mez-Rodr\u00edguez",
      "David Vilares"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.16257",
    "title": "Nondestructive chicken egg fertility detection using CNN-transfer  learning algorithms",
    "abstract": "This study explored the application of CNN-Transfer Learning for nondestructive chicken egg fertility detection for precision poultry hatchery practices. Four models, VGG16, ResNet50, InceptionNet, and MobileNet, were trained and evaluated on a dataset (200 single egg images) using augmented images (rotation, flip, scale, translation, and reflection). Although the training results demonstrated that all models achieved high accuracy, indicating their ability to accurately learn and classify chicken eggs' fertility state, when evaluated on the testing set, variations in accuracy and performance were observed. InceptionNet exhibited the best overall performance, accurately classifying fertile and non-fertile eggs. It demonstrated excellent performance in both training and testing sets in all parameters of the evaluation metrics. In testing set, it achieved an accuracy of 0.98, a sensitivity of 1 for detecting fertile eggs, and a specificity of 0.96 for identifying non-fertile eggs. The higher performance is attributed to its unique architecture efficiently capturing features at different scales leading to improved accuracy and robustness. Further optimization and fine-tuning of the models might necessary to address the limitations in accurately detecting fertile and non-fertile eggs in case of other models. This study highlighted the potential of CNN-Transfer Learning for nondestructive fertility detection and emphasizes the need for further research to enhance the models' capabilities and ensure accurate classification. ",
    "url": "https://arxiv.org/abs/2309.16257",
    "authors": [
      "Shoffan Saifullah",
      "Rafal Drezewski",
      "Anton Yudhana",
      "Andri Pranolo",
      "Wilis Kaswijanti",
      "Andiko Putro Suryotomo",
      "Seno Aji Putra",
      "Alin Khaliduzzaman",
      "Anton Satria Prabuwono",
      "Nathalie Japkowicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.16269",
    "title": "Hierarchical Network Data Analytics Framework for B5G Network  Automation: Design and Implementation",
    "abstract": "5G introduced modularized network functions (NFs) to support emerging services in a more flexible and elastic manner. To mitigate the complexity in such modularized NF management, automated network operation and management are indispensable, and thus the 3rd generation partnership project (3GPP) has introduced a network data analytics function (NWDAF). However, a conventional NWDAF needs to conduct both inference and training tasks, and thus it is difficult to provide the analytics results to NFs in a timely manner for an increased number of analytics requests. In this article, we propose a hierarchical network data analytics framework (H-NDAF) where inference tasks are distributed to multiple leaf NWDAFs and training tasks are conducted at the root NWDAF. Extensive simulation results using open-source software (i.e., free5GC) demonstrate that H-NDAF can provide sufficiently accurate analytics and faster analytics provision time compared to the conventional NWDAF. ",
    "url": "https://arxiv.org/abs/2309.16269",
    "authors": [
      "Youbin Jeon",
      "Sangheon Pack"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2309.16270",
    "title": "Social Media Fashion Knowledge Extraction as Captioning",
    "abstract": "Social media plays a significant role in boosting the fashion industry, where a massive amount of fashion-related posts are generated every day. In order to obtain the rich fashion information from the posts, we study the task of social media fashion knowledge extraction. Fashion knowledge, which typically consists of the occasion, person attributes, and fashion item information, can be effectively represented as a set of tuples. Most previous studies on fashion knowledge extraction are based on the fashion product images without considering the rich text information in social media posts. Existing work on fashion knowledge extraction in social media is classification-based and requires to manually determine a set of fashion knowledge categories in advance. In our work, we propose to cast the task as a captioning problem to capture the interplay of the multimodal post information. Specifically, we transform the fashion knowledge tuples into a natural language caption with a sentence transformation method. Our framework then aims to generate the sentence-based fashion knowledge directly from the social media post. Inspired by the big success of pre-trained models, we build our model based on a multimodal pre-trained generative model and design several auxiliary tasks for enhancing the knowledge extraction. Since there is no existing dataset which can be directly borrowed to our task, we introduce a dataset consisting of social media posts with manual fashion knowledge annotation. Extensive experiments are conducted to demonstrate the effectiveness of our model. ",
    "url": "https://arxiv.org/abs/2309.16270",
    "authors": [
      "Yifei Yuan",
      "Wenxuan Zhang",
      "Yang Deng",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.16283",
    "title": "Self-supervised Cross-view Representation Reconstruction for Change  Captioning",
    "abstract": "Change captioning aims to describe the difference between a pair of similar images. Its key challenge is how to learn a stable difference representation under pseudo changes caused by viewpoint change. In this paper, we address this by proposing a self-supervised cross-view representation reconstruction (SCORER) network. Concretely, we first design a multi-head token-wise matching to model relationships between cross-view features from similar/dissimilar images. Then, by maximizing cross-view contrastive alignment of two similar images, SCORER learns two view-invariant image representations in a self-supervised way. Based on these, we reconstruct the representations of unchanged objects by cross-attention, thus learning a stable difference representation for caption generation. Further, we devise a cross-modal backward reasoning to improve the quality of caption. This module reversely models a ``hallucination'' representation with the caption and ``before'' representation. By pushing it closer to the ``after'' representation, we enforce the caption to be informative about the difference in a self-supervised manner. Extensive experiments show our method achieves the state-of-the-art results on four datasets. The code is available at https://github.com/tuyunbin/SCORER. ",
    "url": "https://arxiv.org/abs/2309.16283",
    "authors": [
      "Yunbin Tu",
      "Liang Li",
      "Li Su",
      "Zheng-Jun Zha",
      "Chenggang Yan",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.16285",
    "title": "A Framework to Assess Knowledge Graphs Accountability",
    "abstract": "Knowledge Graphs (KGs), and Linked Open Data in particular, enable the generation and exchange of more and more information on the Web. In order to use and reuse these data properly, the presence of accountability information is essential. Accountability requires specific and accurate information about people's responsibilities and actions. In this article, we define KGAcc, a framework dedicated to the assessment of RDF graphs accountability. It consists of accountability requirements and a measure of accountability for KGs. Then, we evaluate KGs from the LOD cloud and describe the results obtained. Finally, we compare our approach with data quality and FAIR assessment frameworks to highlight the differences. ",
    "url": "https://arxiv.org/abs/2309.16285",
    "authors": [
      "Jennie Andersen",
      "Sylvie Cazalens",
      "Philippe Lamarre",
      "Pierre Maillot"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2309.16286",
    "title": "Generalizable Heterogeneous Federated Cross-Correlation and Instance  Similarity Learning",
    "abstract": "Federated learning is an important privacy-preserving multi-party learning paradigm, involving collaborative learning with others and local updating on private data. Model heterogeneity and catastrophic forgetting are two crucial challenges, which greatly limit the applicability and generalizability. This paper presents a novel FCCL+, federated correlation and similarity learning with non-target distillation, facilitating the both intra-domain discriminability and inter-domain generalization. For heterogeneity issue, we leverage irrelevant unlabeled public data for communication between the heterogeneous participants. We construct cross-correlation matrix and align instance similarity distribution on both logits and feature levels, which effectively overcomes the communication barrier and improves the generalizable ability. For catastrophic forgetting in local updating stage, FCCL+ introduces Federated Non Target Distillation, which retains inter-domain knowledge while avoiding the optimization conflict issue, fulling distilling privileged inter-domain information through depicting posterior classes relation. Considering that there is no standard benchmark for evaluating existing heterogeneous federated learning under the same setting, we present a comprehensive benchmark with extensive representative methods under four domain shift scenarios, supporting both heterogeneous and homogeneous federated settings. Empirical results demonstrate the superiority of our method and the efficiency of modules on various scenarios. ",
    "url": "https://arxiv.org/abs/2309.16286",
    "authors": [
      "Wenke Huang",
      "Mang Ye",
      "Zekun Shi",
      "Bo Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16301",
    "title": "Multi-scale Recurrent LSTM and Transformer Network for Depth Completion",
    "abstract": "Lidar depth completion is a new and hot topic of depth estimation. In this task, it is the key and difficult point to fuse the features of color space and depth space. In this paper, we migrate the classic LSTM and Transformer modules from NLP to depth completion and redesign them appropriately. Specifically, we use Forget gate, Update gate, Output gate, and Skip gate to achieve the efficient fusion of color and depth features and perform loop optimization at multiple scales. Finally, we further fuse the deep features through the Transformer multi-head attention mechanism. Experimental results show that without repetitive network structure and post-processing steps, our method can achieve state-of-the-art performance by adding our modules to a simple encoder-decoder network structure. Our method ranks first on the current mainstream autonomous driving KITTI benchmark dataset. It can also be regarded as a backbone network for other methods, which likewise achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2309.16301",
    "authors": [
      "Xiaogang Jia",
      "Yusong Tan",
      "Songlei Jian",
      "Yonggang Che"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16305",
    "title": "Does Explanation Matter? An Exploratory Study on the Effects of Covid 19  Misinformation Warning Flags on Social Media",
    "abstract": "We investigate whether adding specific explanations from fact checking websites enhances trust in these flags. We experimented with 348 American participants, exposing them to a randomised order of true and false news headlines related to COVID 19, with and without warning flags and explanation text. Our findings suggest that warning flags, whether alone or accompanied by explanatory text, effectively reduce the perceived accuracy of fake news and the intent to share such headlines. Interestingly, our study also suggests that incorporating explanatory text in misinformation warning systems could significantly enhance their trustworthiness, emphasising the importance of transparency and user comprehension in combating fake news on social media. ",
    "url": "https://arxiv.org/abs/2309.16305",
    "authors": [
      "Dipto Barman",
      "Owen Conlan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2309.16309",
    "title": "Weakly-Supervised Video Anomaly Detection with Snippet Anomalous  Attention",
    "abstract": "With a focus on abnormal events contained within untrimmed videos, there is increasing interest among researchers in video anomaly detection. Among different video anomaly detection scenarios, weakly-supervised video anomaly detection poses a significant challenge as it lacks frame-wise labels during the training stage, only relying on video-level labels as coarse supervision. Previous methods have made attempts to either learn discriminative features in an end-to-end manner or employ a twostage self-training strategy to generate snippet-level pseudo labels. However, both approaches have certain limitations. The former tends to overlook informative features at the snippet level, while the latter can be susceptible to noises. In this paper, we propose an Anomalous Attention mechanism for weakly-supervised anomaly detection to tackle the aforementioned problems. Our approach takes into account snippet-level encoded features without the supervision of pseudo labels. Specifically, our approach first generates snippet-level anomalous attention and then feeds it together with original anomaly scores into a Multi-branch Supervision Module. The module learns different areas of the video, including areas that are challenging to detect, and also assists the attention optimization. Experiments on benchmark datasets XDViolence and UCF-Crime verify the effectiveness of our method. Besides, thanks to the proposed snippet-level attention, we obtain a more precise anomaly localization. ",
    "url": "https://arxiv.org/abs/2309.16309",
    "authors": [
      "Yidan Fan",
      "Yongxin Yu",
      "Wenhuan Lu",
      "Yahong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16318",
    "title": "DeepPCR: Parallelizing Sequential Operations in Neural Networks",
    "abstract": "Parallelization techniques have become ubiquitous for accelerating inference and training of deep neural networks. Despite this, several operations are still performed in a sequential manner. For instance, the forward and backward passes are executed layer-by-layer, and the output of diffusion models is produced by applying a sequence of denoising steps. This sequential approach results in a computational cost proportional to the number of steps involved, presenting a potential bottleneck as the number of steps increases. In this work, we introduce DeepPCR, a novel algorithm which parallelizes typically sequential operations used in inference and training of neural networks. DeepPCR is based on interpreting a sequence of $L$ steps as the solution of a specific system of equations, which we recover using the Parallel Cyclic Reduction algorithm. This reduces the complexity of computing the sequential operations from $\\mathcal{O}(L)$ to $\\mathcal{O}(\\log_2L)$, thus yielding a speedup for large $L$. To verify the theoretical lower complexity of the algorithm, and to identify regimes for speedup, we test the effectiveness of DeepPCR in parallelizing the forward and backward pass in multi-layer perceptrons, and reach speedups of up to $30\\times$ for forward and $200\\times$ for backward pass. We additionally showcase the flexibility of DeepPCR by parallelizing training of ResNets with as many as 1024 layers, and generation in diffusion models, enabling up to $7\\times$ faster training and $11\\times$ faster generation, respectively, when compared to the sequential approach. ",
    "url": "https://arxiv.org/abs/2309.16318",
    "authors": [
      "Federico Danieli",
      "Miguel Sarabia",
      "Xavier Suau",
      "Pau Rodr\u00edguez",
      "Luca Zappella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16333",
    "title": "CloudProphet: A Machine Learning-Based Performance Prediction for Public  Clouds",
    "abstract": "Computing servers have played a key role in developing and processing emerging compute-intensive applications in recent years. Consolidating multiple virtual machines (VMs) inside one server to run various applications introduces severe competence for limited resources among VMs. Many techniques such as VM scheduling and resource provisioning are proposed to maximize the cost-efficiency of the computing servers while alleviating the performance inference between VMs. However, these management techniques require accurate performance prediction of the application running inside the VM, which is challenging to get in the public cloud due to the black-box nature of the VMs. From this perspective, this paper proposes a novel machine learning-based performance prediction approach for applications running in the cloud. To achieve high accuracy predictions for black-box VMs, the proposed method first identifies the running application inside the virtual machine. It then selects highly-correlated runtime metrics as the input of the machine learning approach to accurately predict the performance level of the cloud application. Experimental results with state-of-the-art cloud benchmarks demonstrate that our proposed method outperforms the existing prediction methods by more than 2x in terms of worst prediction error. In addition, we successfully tackle the challenge in performance prediction for applications with variable workloads by introducing the performance degradation index, which other comparison methods fail to consider. The workflow versatility of the proposed approach has been verified with different modern servers and VM configurations. ",
    "url": "https://arxiv.org/abs/2309.16333",
    "authors": [
      "Darong Huang",
      "Luis Costero",
      "Ali Pahlevan",
      "Marina Zapater",
      "David Atienza"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.16335",
    "title": "End-to-end Risk Prediction of Atrial Fibrillation from the 12-Lead ECG  by Deep Neural Networks",
    "abstract": "Background: Atrial fibrillation (AF) is one of the most common cardiac arrhythmias that affects millions of people each year worldwide and it is closely linked to increased risk of cardiovascular diseases such as stroke and heart failure. Machine learning methods have shown promising results in evaluating the risk of developing atrial fibrillation from the electrocardiogram. We aim to develop and evaluate one such algorithm on a large CODE dataset collected in Brazil. Results: The deep neural network model identified patients without indication of AF in the presented ECG but who will develop AF in the future with an AUC score of 0.845. From our survival model, we obtain that patients in the high-risk group (i.e. with the probability of a future AF case being greater than 0.7) are 50% more likely to develop AF within 40 weeks, while patients belonging to the minimal-risk group (i.e. with the probability of a future AF case being less than or equal to 0.1) have more than 85% chance of remaining AF free up until after seven years. Conclusion: We developed and validated a model for AF risk prediction. If applied in clinical practice, the model possesses the potential of providing valuable and useful information in decision-making and patient management processes. ",
    "url": "https://arxiv.org/abs/2309.16335",
    "authors": [
      "Theogene Habineza",
      "Ant\u00f4nio H. Ribeiro",
      "Daniel Gedon",
      "Joachim A. Behar",
      "Antonio Luiz P. Ribeiro",
      "Thomas B. Sch\u00f6n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2309.16343",
    "title": "Online Estimation of Articulated Objects with Factor Graphs using Vision  and Proprioceptive Sensing",
    "abstract": "From dishwashers to cabinets, humans interact with articulated objects every day, and for a robot to assist in common manipulation tasks, it must learn a representation of articulation. Recent deep learning learning methods can provide powerful vision-based priors on the affordance of articulated objects from previous, possibly simulated, experiences. In contrast, many works estimate articulation by observing the object in motion, requiring the robot to already be interacting with the object. In this work, we propose to use the best of both worlds by introducing an online estimation method that merges vision-based affordance predictions from a neural network with interactive kinematic sensing in an analytical model. Our work has the benefit of using vision to predict an articulation model before touching the object, while also being able to update the model quickly from kinematic sensing during the interaction. In this paper, we implement a full system using shared autonomy for robotic opening of articulated objects, in particular objects in which the articulation is not apparent from vision alone. We implemented our system on a real robot and performed several autonomous closed-loop experiments in which the robot had to open a door with unknown joint while estimating the articulation online. Our system achieved an 80% success rate for autonomous opening of unknown articulated objects. ",
    "url": "https://arxiv.org/abs/2309.16343",
    "authors": [
      "Russell Buchanan",
      "Adrian R\u00f6fer",
      "Jo\u00e3o Moura",
      "Abhinav Valada",
      "Sethu Vijayakumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.16347",
    "title": "Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic  Manipulation Tasks",
    "abstract": "Current reinforcement learning algorithms struggle in sparse and complex environments, most notably in long-horizon manipulation tasks entailing a plethora of different sequences. In this work, we propose the Intrinsically Guided Exploration from Large Language Models (IGE-LLMs) framework. By leveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the exploratory process in reinforcement learning to address intricate long-horizon with sparse rewards robotic manipulation tasks. We evaluate our framework and related intrinsic learning methods in an environment challenged with exploration, and a complex robotic manipulation task challenged by both exploration and long-horizons. Results show IGE-LLMs (i) exhibit notably higher performance over related intrinsic methods and the direct use of LLMs in decision-making, (ii) can be combined and complement existing learning methods highlighting its modularity, (iii) are fairly insensitive to different intrinsic scaling parameters, and (iv) maintain robustness against increased levels of uncertainty and horizons. ",
    "url": "https://arxiv.org/abs/2309.16347",
    "authors": [
      "Eleftherios Triantafyllidis",
      "Filippos Christianos",
      "Zhibin Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16357",
    "title": "Leveraging Pre-trained Language Models for Time Interval Prediction in  Text-Enhanced Temporal Knowledge Graphs",
    "abstract": "Most knowledge graph completion (KGC) methods learn latent representations of entities and relations of a given graph by mapping them into a vector space. Although the majority of these methods focus on static knowledge graphs, a large number of publicly available KGs contain temporal information stating the time instant/period over which a certain fact has been true. Such graphs are often known as temporal knowledge graphs. Furthermore, knowledge graphs may also contain textual descriptions of entities and relations. Both temporal information and textual descriptions are not taken into account during representation learning by static KGC methods, and only structural information of the graph is leveraged. Recently, some studies have used temporal information to improve link prediction, yet they do not exploit textual descriptions and do not support inductive inference (prediction on entities that have not been seen in training). We propose a novel framework called TEMT that exploits the power of pre-trained language models (PLMs) for text-enhanced temporal knowledge graph completion. The knowledge stored in the parameters of a PLM allows TEMT to produce rich semantic representations of facts and to generalize on previously unseen entities. TEMT leverages textual and temporal information available in a KG, treats them separately, and fuses them to get plausibility scores of facts. Unlike previous approaches, TEMT effectively captures dependencies across different time points and enables predictions on unseen entities. To assess the performance of TEMT, we carried out several experiments including time interval prediction, both in transductive and inductive settings, and triple classification. The experimental results show that TEMT is competitive with the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2309.16357",
    "authors": [
      "Duygu Sezen Islakoglu",
      "Mel Chekol",
      "Yannis Velegrakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16364",
    "title": "FG-NeRF: Flow-GAN based Probabilistic Neural Radiance Field for  Independence-Assumption-Free Uncertainty Estimation",
    "abstract": "Neural radiance fields with stochasticity have garnered significant interest by enabling the sampling of plausible radiance fields and quantifying uncertainty for downstream tasks. Existing works rely on the independence assumption of points in the radiance field or the pixels in input views to obtain tractable forms of the probability density function. However, this assumption inadvertently impacts performance when dealing with intricate geometry and texture. In this work, we propose an independence-assumption-free probabilistic neural radiance field based on Flow-GAN. By combining the generative capability of adversarial learning and the powerful expressivity of normalizing flow, our method explicitly models the density-radiance distribution of the whole scene. We represent our probabilistic NeRF as a mean-shifted probabilistic residual neural model. Our model is trained without an explicit likelihood function, thereby avoiding the independence assumption. Specifically, We downsample the training images with different strides and centers to form fixed-size patches which are used to train the generator with patch-based adversarial learning. Through extensive experiments, our method demonstrates state-of-the-art performance by predicting lower rendering errors and more reliable uncertainty on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2309.16364",
    "authors": [
      "Songlin Wei",
      "Jiazhao Zhang",
      "Yang Wang",
      "Fanbo Xiang",
      "Hao Su",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16374",
    "title": "MHG-GNN: Combination of Molecular Hypergraph Grammar with Graph Neural  Network",
    "abstract": "Property prediction plays an important role in material discovery. As an initial step to eventually develop a foundation model for material science, we introduce a new autoencoder called the MHG-GNN, which combines graph neural network (GNN) with Molecular Hypergraph Grammar (MHG). Results on a variety of property prediction tasks with diverse materials show that MHG-GNN is promising. ",
    "url": "https://arxiv.org/abs/2309.16374",
    "authors": [
      "Akihiro Kishimoto",
      "Hiroshi Kajino",
      "Masataka Hirose",
      "Junta Fuchiwaki",
      "Indra Priyadarsini",
      "Lisa Hamada",
      "Hajime Shinohara",
      "Daiju Nakano",
      "Seiji Takeda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16375",
    "title": "A Comprehensive Review on Tree Detection Methods Using Point Cloud and  Aerial Imagery from Unmanned Aerial Vehicles",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are considered cutting-edge technology with highly cost-effective and flexible usage scenarios. Although many papers have reviewed the application of UAVs in agriculture, the review of the application for tree detection is still insufficient. This paper focuses on tree detection methods applied to UAV data collected by UAVs. There are two kinds of data, the point cloud and the images, which are acquired by the Light Detection and Ranging (LiDAR) sensor and camera, respectively. Among the detection methods using point-cloud data, this paper mainly classifies these methods according to LiDAR and Digital Aerial Photography (DAP). For the detection methods using images directly, this paper reviews these methods by whether or not to use the Deep Learning (DL) method. Our review concludes and analyses the comparison and combination between the application of LiDAR-based and DAP-based point cloud data. The performance, relative merits, and application fields of the methods are also introduced. Meanwhile, this review counts the number of tree detection studies using different methods in recent years. From our statics, the detection task using DL methods on the image has become a mainstream trend as the number of DL-based detection researches increases to 45% of the total number of tree detection studies up to 2022. As a result, this review could help and guide researchers who want to carry out tree detection on specific forests and for farmers to use UAVs in managing agriculture production. ",
    "url": "https://arxiv.org/abs/2309.16375",
    "authors": [
      "Weijie Kuang",
      "Hann Woei Ho",
      "Ye Zhou",
      "Shahrel Azmin Suandi",
      "Farzad Ismail"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.16388",
    "title": "Biomedical Image Splicing Detection using Uncertainty-Guided Refinement",
    "abstract": "Recently, a surge in biomedical academic publications suspected of image manipulation has led to numerous retractions, turning biomedical image forensics into a research hotspot. While manipulation detectors are concerning, the specific detection of splicing traces in biomedical images remains underexplored. The disruptive factors within biomedical images, such as artifacts, abnormal patterns, and noises, show misleading features like the splicing traces, greatly increasing the challenge for this task. Moreover, the scarcity of high-quality spliced biomedical images also limits potential advancements in this field. In this work, we propose an Uncertainty-guided Refinement Network (URN) to mitigate the effects of these disruptive factors. Our URN can explicitly suppress the propagation of unreliable information flow caused by disruptive factors among regions, thereby obtaining robust features. Moreover, URN enables a concentration on the refinement of uncertainly predicted regions during the decoding phase. Besides, we construct a dataset for Biomedical image Splicing (BioSp) detection, which consists of 1,290 spliced images. Compared with existing datasets, BioSp comprises the largest number of spliced images and the most diverse sources. Comprehensive experiments on three benchmark datasets demonstrate the superiority of the proposed method. Meanwhile, we verify the generalizability of URN when against cross-dataset domain shifts and its robustness to resist post-processing approaches. Our BioSp dataset will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2309.16388",
    "authors": [
      "Xun Lin",
      "Wenzhong Tang",
      "Shuai Wang",
      "Zitong Yu",
      "Yizhong Liu",
      "Haoran Wang",
      "Ying Fu",
      "Alex Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16391",
    "title": "Differential 2D Copula Approximating Transforms via Sobolev Training:  2-Cats Networks",
    "abstract": "Copulas are a powerful statistical tool that captures dependencies across data dimensions. When applying Copulas, we can estimate multivariate distribution functions by initially estimating independent marginals, an easy task, and then a single copulating function, $C$, to connect the marginals, a hard task. For two-dimensional data, a copula is a two-increasing function of the form $C: (u,v)\\in \\mathbf{I}^2 \\rightarrow \\mathbf{I}$, where $\\mathbf{I} = [0, 1]$. In this paper, we show how Neural Networks (NNs) can approximate any two-dimensional copula non-parametrically. Our approach, denoted as 2-Cats, is inspired by the Physics-Informed Neural Networks and Sobolev Training literature. Not only do we show that we can estimate the output of a 2d Copula better than the state-of-the-art, our approach is non-parametric and respects the mathematical properties of a Copula $C$. ",
    "url": "https://arxiv.org/abs/2309.16391",
    "authors": [
      "Flavio Figueiredo",
      "Jos\u00e9 Geraldo Fernandes",
      "Jackson Silva",
      "Renato M. Assun\u00e7\u00e3o"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16393",
    "title": "HIC-YOLOv5: Improved YOLOv5 For Small Object Detection",
    "abstract": "Small object detection has been a challenging problem in the field of object detection. There has been some works that proposes improvements for this task, such as adding several attention blocks or changing the whole structure of feature fusion networks. However, the computation cost of these models is large, which makes deploying a real-time object detection system unfeasible, while leaving room for improvement. To this end, an improved YOLOv5 model: HIC-YOLOv5 is proposed to address the aforementioned problems. Firstly, an additional prediction head specific to small objects is added to provide a higher-resolution feature map for better prediction. Secondly, an involution block is adopted between the backbone and neck to increase channel information of the feature map. Moreover, an attention mechanism named CBAM is applied at the end of the backbone, thus not only decreasing the computation cost compared with previous works but also emphasizing the important information in both channel and spatial domain. Our result shows that HIC-YOLOv5 has improved mAP@[.5:.95] by 6.42% and mAP@0.5 by 9.38% on VisDrone-2019-DET dataset. ",
    "url": "https://arxiv.org/abs/2309.16393",
    "authors": [
      "Shiyi Tang",
      "Yini Fang",
      "Shu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16398",
    "title": "Recent Advances of Differential Privacy in Centralized Deep Learning: A  Systematic Survey",
    "abstract": "Differential Privacy has become a widely popular method for data protection in machine learning, especially since it allows formulating strict mathematical privacy guarantees. This survey provides an overview of the state-of-the-art of differentially private centralized deep learning, thorough analyses of recent advances and open problems, as well as a discussion of potential future developments in the field. Based on a systematic literature review, the following topics are addressed: auditing and evaluation methods for private models, improvements of privacy-utility trade-offs, protection against a broad range of threats and attacks, differentially private generative models, and emerging application domains. ",
    "url": "https://arxiv.org/abs/2309.16398",
    "authors": [
      "Lea Demelius",
      "Roman Kern",
      "Andreas Tr\u00fcgler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16405",
    "title": "gSPICE: Model-Based Event Shedding in Complex Event Processing",
    "abstract": "Overload situations, in the presence of resource limitations, in complex event processing (CEP) systems are typically handled using load shedding to maintain a given latency bound. However, load shedding might negatively impact the quality of results (QoR). To minimize the shedding impact on QoR, CEP researchers propose shedding approaches that drop events/internal state with the lowest importances/utilities. In both black-box and white-box shedding approaches, different features are used to predict these utilities. In this work, we propose a novel black-box shedding approach that uses a new set of features to drop events from the input event stream to maintain a given latency bound. Our approach uses a probabilistic model to predict these event utilities. Moreover, our approach uses Zobrist hashing and well-known machine learning models, e.g., decision trees and random forests, to handle the predicted event utilities. Through extensive evaluations on several synthetic and two real-world datasets and a representative set of CEP queries, we show that, in the majority of cases, our load shedding approach outperforms state-of-the-art black-box load shedding approaches, w.r.t. QoR. ",
    "url": "https://arxiv.org/abs/2309.16405",
    "authors": [
      "Ahmad Slo",
      "Sukanya Bhowmik",
      "Kurt Rothermel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.16418",
    "title": "Efficient Supervised Training of Audio Transformers for Music  Representation Learning",
    "abstract": "In this work, we address music representation learning using convolution-free transformers. We build on top of existing spectrogram-based audio transformers such as AST and train our models on a supervised task using patchout training similar to PaSST. In contrast to previous works, we study how specific design decisions affect downstream music tagging tasks instead of focusing on the training task. We assess the impact of initializing the models with different pre-trained weights, using various input audio segment lengths, using learned representations from different blocks and tokens of the transformer for downstream tasks, and applying patchout at inference to speed up feature extraction. We find that 1) initializing the model from ImageNet or AudioSet weights and using longer input segments are beneficial both for the training and downstream tasks, 2) the best representations for the considered downstream tasks are located in the middle blocks of the transformer, and 3) using patchout at inference allows faster processing than our convolutional baselines while maintaining superior performance. The resulting models, MAEST, are publicly available and obtain the best performance among open models in music tagging tasks. ",
    "url": "https://arxiv.org/abs/2309.16418",
    "authors": [
      "Pablo Alonso-Jim\u00e9nez",
      "Xavier Serra",
      "Dmitry Bogdanov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.16424",
    "title": "Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News  Detection",
    "abstract": "Despite considerable advances in automated fake news detection, due to the timely nature of news, it remains a critical open question how to effectively predict the veracity of news articles based on limited fact-checks. Existing approaches typically follow a \"Train-from-Scratch\" paradigm, which is fundamentally bounded by the availability of large-scale annotated data. While expressive pre-trained language models (PLMs) have been adapted in a \"Pre-Train-and-Fine-Tune\" manner, the inconsistency between pre-training and downstream objectives also requires costly task-specific supervision. In this paper, we propose \"Prompt-and-Align\" (P&A), a novel prompt-based paradigm for few-shot fake news detection that jointly leverages the pre-trained knowledge in PLMs and the social context topology. Our approach mitigates label scarcity by wrapping the news article in a task-related textual prompt, which is then processed by the PLM to directly elicit task-specific knowledge. To supplement the PLM with social context without inducing additional training overheads, motivated by empirical observation on user veracity consistency (i.e., social users tend to consume news of the same veracity type), we further construct a news proximity graph among news articles to capture the veracity-consistent signals in shared readerships, and align the prompting predictions along the graph edges in a confidence-informed manner. Extensive experiments on three real-world benchmarks demonstrate that P&A sets new states-of-the-art for few-shot fake news detection performance by significant margins. ",
    "url": "https://arxiv.org/abs/2309.16424",
    "authors": [
      "Jiaying Wu",
      "Shen Li",
      "Ailin Deng",
      "Miao Xiong",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.16428",
    "title": "Nonlinear MPC design for incrementally ISS systems with application to  GRU networks",
    "abstract": "This brief addresses the design of a Nonlinear Model Predictive Control (NMPC) strategy for exponentially incremental Input-to-State Stable (ISS) systems. In particular, a novel formulation is devised, which does not necessitate the onerous computation of terminal ingredients, but rather relies on the explicit definition of a minimum prediction horizon ensuring closed-loop stability. The designed methodology is particularly suited for the control of systems learned by Recurrent Neural Networks (RNNs), which are known for their enhanced modeling capabilities and for which the incremental ISS properties can be studied thanks to simple algebraic conditions. The approach is applied to Gated Recurrent Unit (GRU) networks, providing also a method for the design of a tailored state observer with convergence guarantees. The resulting control architecture is tested on a benchmark system, demonstrating its good control performances and efficient applicability. ",
    "url": "https://arxiv.org/abs/2309.16428",
    "authors": [
      "Fabio Bonassi",
      "Alessio La Bella",
      "Marcello Farina",
      "Riccardo Scattolini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16439",
    "title": "Uncertainty quantification and complex analyticity of the nonlinear  Poisson-Boltzmann equation for the interface problem with random domains",
    "abstract": "The nonlinear Poisson-Boltzmann equation (NPBE) is an elliptic partial differential equation used in applications such as protein interactions and biophysical chemistry (among many others). It describes the nonlinear electrostatic potential of charged bodies submerged in an ionic solution. The kinetic presence of the solvent molecules introduces randomness to the shape of a protein, and thus a more accurate model that incorporates these random perturbations of the domain is analyzed to compute the statistics of quantities of interest of the solution. When the parameterization of the random perturbations is high-dimensional, this calculation is intractable as it is subject to the curse of dimensionality. However, if the solution of the NPBE varies analytically with respect to the random parameters, the problem becomes amenable to techniques such as sparse grids and deep neural networks. In this paper, we show analyticity of the solution of the NPBE with respect to analytic perturbations of the domain by using the analytic implicit function theorem and the domain mapping method. Previous works have shown analyticity of solutions to linear elliptic equations but not for nonlinear problems. We further show how to derive \\emph{a priori} bounds on the size of the region of analyticity. This method is applied to the trypsin molecule to demonstrate that the convergence rates of the quantity of interest are consistent with the analyticity result. Furthermore, the approach developed here is sufficiently general enough to be applied to other nonlinear problems in uncertainty quantification. ",
    "url": "https://arxiv.org/abs/2309.16439",
    "authors": [
      "Trevor Norton",
      "Jie Xu",
      "Brian Choi",
      "Mark Kon",
      "Julio Enrique Castrill\u00f3n-Cand\u00e1s"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.16452",
    "title": "On the Trade-offs between Adversarial Robustness and Actionable  Explanations",
    "abstract": "As machine learning models are increasingly being employed in various high-stakes settings, it becomes important to ensure that predictions of these models are not only adversarially robust, but also readily explainable to relevant stakeholders. However, it is unclear if these two notions can be simultaneously achieved or if there exist trade-offs between them. In this work, we make one of the first attempts at studying the impact of adversarially robust models on actionable explanations which provide end users with a means for recourse. We theoretically and empirically analyze the cost (ease of implementation) and validity (probability of obtaining a positive model prediction) of recourses output by state-of-the-art algorithms when the underlying models are adversarially robust vs. non-robust. More specifically, we derive theoretical bounds on the differences between the cost and the validity of the recourses generated by state-of-the-art algorithms for adversarially robust vs. non-robust linear and non-linear models. Our empirical results with multiple real-world datasets validate our theoretical results and show the impact of varying degrees of model robustness on the cost and validity of the resulting recourses. Our analyses demonstrate that adversarially robust models significantly increase the cost and reduce the validity of the resulting recourses, thus shedding light on the inherent trade-offs between adversarial robustness and actionable explanations ",
    "url": "https://arxiv.org/abs/2309.16452",
    "authors": [
      "Satyapriya Krishna",
      "Chirag Agarwal",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16456",
    "title": "Resisting Backdoor Attacks in Federated Learning via Bidirectional  Elections and Individual Perspective",
    "abstract": "Existing approaches defend against backdoor attacks in federated learning (FL) mainly through a) mitigating the impact of infected models, or b) excluding infected models. The former negatively impacts model accuracy, while the latter usually relies on globally clear boundaries between benign and infected model updates. However, model updates are easy to be mixed and scattered throughout in reality due to the diverse distributions of local data. This work focuses on excluding infected models in FL. Unlike previous perspectives from a global view, we propose Snowball, a novel anti-backdoor FL framework through bidirectional elections from an individual perspective inspired by one principle deduced by us and two principles in FL and deep learning. It is characterized by a) bottom-up election, where each candidate model update votes to several peer ones such that a few model updates are elected as selectees for aggregation; and b) top-down election, where selectees progressively enlarge themselves through picking up from the candidates. We compare Snowball with state-of-the-art defenses to backdoor attacks in FL on five real-world datasets, demonstrating its superior resistance to backdoor attacks and slight impact on the accuracy of the global model. ",
    "url": "https://arxiv.org/abs/2309.16456",
    "authors": [
      "Zhen Qin",
      "Feiyi Chen",
      "Chen Zhi",
      "Xueqiang Yan",
      "Shuiguang Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16457",
    "title": "Universal Sleep Decoder: Aligning awake and sleep neural representation  across subjects",
    "abstract": "Decoding memory content from brain activity during sleep has long been a goal in neuroscience. While spontaneous reactivation of memories during sleep in rodents is known to support memory consolidation and offline learning, capturing memory replay in humans is challenging due to the absence of well-annotated sleep datasets and the substantial differences in neural patterns between wakefulness and sleep. To address these challenges, we designed a novel cognitive neuroscience experiment and collected a comprehensive, well-annotated electroencephalography (EEG) dataset from 52 subjects during both wakefulness and sleep. Leveraging this benchmark dataset, we developed the Universal Sleep Decoder (USD) to align neural representations between wakefulness and sleep across subjects. Our model achieves up to 16.6% top-1 zero-shot accuracy on unseen subjects, comparable to decoding performances using individual sleep data. Furthermore, fine-tuning USD on test subjects enhances decoding accuracy to 25.9% top-1 accuracy, a substantial improvement over the baseline chance of 6.7%. Model comparison and ablation analyses reveal that our design choices, including the use of (i) an additional contrastive objective to integrate awake and sleep neural signals and (ii) the pretrain-finetune paradigm to incorporate different subjects, significantly contribute to these performances. Collectively, our findings and methodologies represent a significant advancement in the field of sleep decoding. ",
    "url": "https://arxiv.org/abs/2309.16457",
    "authors": [
      "Hui Zheng",
      "Zhongtao Chen",
      "Haiteng Wang",
      "Jianyang Zhou",
      "Lin Zheng",
      "Yunzhe Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2309.16487",
    "title": "Towards Poisoning Fair Representations",
    "abstract": "Fair machine learning seeks to mitigate model prediction bias against certain demographic subgroups such as elder and female. Recently, fair representation learning (FRL) trained by deep neural networks has demonstrated superior performance, whereby representations containing no demographic information are inferred from the data and then used as the input to classification or other downstream tasks. Despite the development of FRL methods, their vulnerability under data poisoning attack, a popular protocol to benchmark model robustness under adversarial scenarios, is under-explored. Data poisoning attacks have been developed for classical fair machine learning methods which incorporate fairness constraints into shallow-model classifiers. Nonetheless, these attacks fall short in FRL due to notably different fairness goals and model architectures. This work proposes the first data poisoning framework attacking FRL. We induce the model to output unfair representations that contain as much demographic information as possible by injecting carefully crafted poisoning samples into the training data. This attack entails a prohibitive bilevel optimization, wherefore an effective approximated solution is proposed. A theoretical analysis on the needed number of poisoning samples is derived and sheds light on defending against the attack. Experiments on benchmark fairness datasets and state-of-the-art fair representation learning models demonstrate the superiority of our attack. ",
    "url": "https://arxiv.org/abs/2309.16487",
    "authors": [
      "Tianci Liu",
      "Haoyu Wang",
      "Feijie Wu",
      "Hengtong Zhang",
      "Pan Li",
      "Lu Su",
      "Jing Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16494",
    "title": "Accurate and lightweight dehazing via multi-receptive-field non-local  network and novel contrastive regularization",
    "abstract": "Recently, deep learning-based methods have dominated image dehazing domain. Although very competitive dehazing performance has been achieved with sophisticated models, effective solutions for extracting useful features are still under-explored. In addition, non-local network, which has made a breakthrough in many vision tasks, has not been appropriately applied to image dehazing. Thus, a multi-receptive-field non-local network (MRFNLN) consisting of the multi-stream feature attention block (MSFAB) and cross non-local block (CNLB) is presented in this paper. We start with extracting richer features for dehazing. Specifically, we design a multi-stream feature extraction (MSFE) sub-block, which contains three parallel convolutions with different receptive fields (i.e., $1\\times 1$, $3\\times 3$, $5\\times 5$) for extracting multi-scale features. Following MSFE, we employ an attention sub-block to make the model adaptively focus on important channels/regions. The MSFE and attention sub-blocks constitute our MSFAB. Then, we design a cross non-local block (CNLB), which can capture long-range dependencies beyond the query. Instead of the same input source of query branch, the key and value branches are enhanced by fusing more preceding features. CNLB is computation-friendly by leveraging a spatial pyramid down-sampling (SPDS) strategy to reduce the computation and memory consumption without sacrificing the performance. Last but not least, a novel detail-focused contrastive regularization (DFCR) is presented by emphasizing the low-level details and ignoring the high-level semantic information in the representation space. Comprehensive experimental results demonstrate that the proposed MRFNLN model outperforms recent state-of-the-art dehazing methods with less than 1.5 Million parameters. ",
    "url": "https://arxiv.org/abs/2309.16494",
    "authors": [
      "Zewei He",
      "Zixuan Chen",
      "Ziqian Lu",
      "Xuecheng Sun",
      "Zhe-Ming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16499",
    "title": "Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for  Cross-City Semantic Segmentation using High-Resolution Domain Adaptation  Networks",
    "abstract": "Artificial intelligence (AI) approaches nowadays have gained remarkable success in single-modality-dominated remote sensing (RS) applications, especially with an emphasis on individual urban environments (e.g., single cities or regions). Yet these AI models tend to meet the performance bottleneck in the case studies across cities or regions, due to the lack of diverse RS information and cutting-edge solutions with high generalization ability. To this end, we build a new set of multimodal remote sensing benchmark datasets (including hyperspectral, multispectral, SAR) for the study purpose of the cross-city semantic segmentation task (called C2Seg dataset), which consists of two cross-city scenes, i.e., Berlin-Augsburg (in Germany) and Beijing-Wuhan (in China). Beyond the single city, we propose a high-resolution domain adaptation network, HighDAN for short, to promote the AI model's generalization ability from the multi-city environments. HighDAN is capable of retaining the spatially topological structure of the studied urban scene well in a parallel high-to-low resolution fusion fashion but also closing the gap derived from enormous differences of RS image representations between different cities by means of adversarial learning. In addition, the Dice loss is considered in HighDAN to alleviate the class imbalance issue caused by factors across cities. Extensive experiments conducted on the C2Seg dataset show the superiority of our HighDAN in terms of segmentation performance and generalization ability, compared to state-of-the-art competitors. The C2Seg dataset and the semantic segmentation toolbox (involving the proposed HighDAN) will be available publicly at https://github.com/danfenghong. ",
    "url": "https://arxiv.org/abs/2309.16499",
    "authors": [
      "Danfeng Hong",
      "Bing Zhang",
      "Hao Li",
      "Yuxuan Li",
      "Jing Yao",
      "Chenyu Li",
      "Martin Werner",
      "Jocelyn Chanussote",
      "Alexander Zipf",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.16512",
    "title": "From Complexity to Clarity: Analytical Expressions of Deep Neural  Network Weights via Clifford's Geometric Algebra and Convexity",
    "abstract": "In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers. ",
    "url": "https://arxiv.org/abs/2309.16512",
    "authors": [
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.16515",
    "title": "Latent Noise Segmentation: How Neural Noise Leads to the Emergence of  Segmentation and Grouping",
    "abstract": "Deep Neural Networks (DNNs) that achieve human-level performance in general tasks like object segmentation typically require supervised labels. In contrast, humans are able to perform these tasks effortlessly without supervision. To accomplish this, the human visual system makes use of perceptual grouping. Understanding how perceptual grouping arises in an unsupervised manner is critical for improving both models of the visual system, and computer vision models. In this work, we propose a counterintuitive approach to unsupervised perceptual grouping and segmentation: that they arise because of neural noise, rather than in spite of it. We (1) mathematically demonstrate that under realistic assumptions, neural noise can be used to separate objects from each other, and (2) show that adding noise in a DNN enables the network to segment images even though it was never trained on any segmentation labels. Interestingly, we find that (3) segmenting objects using noise results in segmentation performance that aligns with the perceptual grouping phenomena observed in humans. We introduce the Good Gestalt (GG) datasets -- six datasets designed to specifically test perceptual grouping, and show that our DNN models reproduce many important phenomena in human perception, such as illusory contours, closure, continuity, proximity, and occlusion. Finally, we (4) demonstrate the ecological plausibility of the method by analyzing the sensitivity of the DNN to different magnitudes of noise. We find that some model variants consistently succeed with remarkably low levels of neural noise ($\\sigma<0.001$), and surprisingly, that segmenting this way requires as few as a handful of samples. Together, our results suggest a novel unsupervised segmentation method requiring few assumptions, a new explanation for the formation of perceptual grouping, and a potential benefit of neural noise in the visual system. ",
    "url": "https://arxiv.org/abs/2309.16515",
    "authors": [
      "Ben Lonnqvist",
      "Zhengqing Wu",
      "Michael H. Herzog"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16519",
    "title": "AtomSurf : Surface Representation for Learning on Protein Structures",
    "abstract": "Recent advancements in Cryo-EM and protein structure prediction algorithms have made large-scale protein structures accessible, paving the way for machine learning-based functional annotations.The field of geometric deep learning focuses on creating methods working on geometric data. An essential aspect of learning from protein structures is representing these structures as a geometric object (be it a grid, graph, or surface) and applying a learning method tailored to this representation. The performance of a given approach will then depend on both the representation and its corresponding learning method. In this paper, we investigate representing proteins as $\\textit{3D mesh surfaces}$ and incorporate them into an established representation benchmark. Our first finding is that despite promising preliminary results, the surface representation alone does not seem competitive with 3D grids. Building on this, we introduce a synergistic approach, combining surface representations with graph-based methods, resulting in a general framework that incorporates both representations in learning. We show that using this combination, we are able to obtain state-of-the-art results across $\\textit{all tested tasks}$. Our code and data can be found online: https://github.com/Vincentx15/atom2D . ",
    "url": "https://arxiv.org/abs/2309.16519",
    "authors": [
      "Vincent Mallet",
      "Souhaib Attaiki",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2309.16552",
    "title": "Semantic Scene Difference Detection in Daily Life Patroling by Mobile  Robots using Pre-Trained Large-Scale Vision-Language Model",
    "abstract": "It is important for daily life support robots to detect changes in their environment and perform tasks. In the field of anomaly detection in computer vision, probabilistic and deep learning methods have been used to calculate the image distance. These methods calculate distances by focusing on image pixels. In contrast, this study aims to detect semantic changes in the daily life environment using the current development of large-scale vision-language models. Using its Visual Question Answering (VQA) model, we propose a method to detect semantic changes by applying multiple questions to a reference image and a current image and obtaining answers in the form of sentences. Unlike deep learning-based methods in anomaly detection, this method does not require any training or fine-tuning, is not affected by noise, and is sensitive to semantic state changes in the real world. In our experiments, we demonstrated the effectiveness of this method by applying it to a patrol task in a real-life environment using a mobile robot, Fetch Mobile Manipulator. In the future, it may be possible to add explanatory power to changes in the daily life environment through spoken language. ",
    "url": "https://arxiv.org/abs/2309.16552",
    "authors": [
      "Yoshiki Obinata",
      "Kento Kawaharazuka",
      "Naoaki Kanazawa",
      "Naoya Yamaguchi",
      "Naoto Tsukamoto",
      "Iori Yanokura",
      "Shingo Kitagawa",
      "Koki Shinjo",
      "Kei Okada",
      "Masayuki Inaba"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.16553",
    "title": "MatrixCity: A Large-scale City Dataset for City-scale Neural Rendering  and Beyond",
    "abstract": "Neural radiance fields (NeRF) and its subsequent variants have led to remarkable progress in neural rendering. While most of recent neural rendering works focus on objects and small-scale scenes, developing neural rendering methods for city-scale scenes is of great potential in many real-world applications. However, this line of research is impeded by the absence of a comprehensive and high-quality dataset, yet collecting such a dataset over real city-scale scenes is costly, sensitive, and technically difficult. To this end, we build a large-scale, comprehensive, and high-quality synthetic dataset for city-scale neural rendering researches. Leveraging the Unreal Engine 5 City Sample project, we develop a pipeline to easily collect aerial and street city views, accompanied by ground-truth camera poses and a range of additional data modalities. Flexible controls over environmental factors like light, weather, human and car crowd are also available in our pipeline, supporting the need of various tasks covering city-scale neural rendering and beyond. The resulting pilot dataset, MatrixCity, contains 67k aerial images and 452k street images from two city maps of total size $28km^2$. On top of MatrixCity, a thorough benchmark is also conducted, which not only reveals unique challenges of the task of city-scale neural rendering, but also highlights potential improvements for future works. The dataset and code will be publicly available at our project page: https://city-super.github.io/matrixcity/. ",
    "url": "https://arxiv.org/abs/2309.16553",
    "authors": [
      "Yixuan Li",
      "Lihan Jiang",
      "Linning Xu",
      "Yuanbo Xiangli",
      "Zhenzhi Wang",
      "Dahua Lin",
      "Bo Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16561",
    "title": "Voting Network for Contour Levee Farmland Segmentation and  Classification",
    "abstract": "High-resolution aerial imagery allows fine details in the segmentation of farmlands. However, small objects and features introduce distortions to the delineation of object boundaries, and larger contextual views are needed to mitigate class confusion. In this work, we present an end-to-end trainable network for segmenting farmlands with contour levees from high-resolution aerial imagery. A fusion block is devised that includes multiple voting blocks to achieve image segmentation and classification. We integrate the fusion block with a backbone and produce both semantic predictions and segmentation slices. The segmentation slices are used to perform majority voting on the predictions. The network is trained to assign the most likely class label of a segment to its pixels, learning the concept of farmlands rather than analyzing constitutive pixels separately. We evaluate our method using images from the National Agriculture Imagery Program. Our method achieved an average accuracy of 94.34\\%. Compared to the state-of-the-art methods, the proposed method obtains an improvement of 6.96% and 2.63% in the F1 score on average. ",
    "url": "https://arxiv.org/abs/2309.16561",
    "authors": [
      "Abolfazl Meyarian",
      "Xiaohui Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16564",
    "title": "Augment to Interpret: Unsupervised and Inherently Interpretable Graph  Embeddings",
    "abstract": "Unsupervised learning allows us to leverage unlabelled data, which has become abundantly available, and to create embeddings that are usable on a variety of downstream tasks. However, the typical lack of interpretability of unsupervised representation learning has become a limiting factor with regard to recent transparent-AI regulations. In this paper, we study graph representation learning and we show that data augmentation that preserves semantics can be learned and used to produce interpretations. Our framework, which we named INGENIOUS, creates inherently interpretable embeddings and eliminates the need for costly additional post-hoc analysis. We also introduce additional metrics addressing the lack of formalism and metrics in the understudied area of unsupervised-representation learning interpretability. Our results are supported by an experimental study applied to both graph-level and node-level tasks and show that interpretable embeddings provide state-of-the-art performance on subsequent downstream tasks. ",
    "url": "https://arxiv.org/abs/2309.16564",
    "authors": [
      "Gregory Scafarto",
      "Madalina Ciortan",
      "Simon Tihon",
      "Quentin Ferre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16577",
    "title": "Compilation as a Defense: Enhancing DL Model Attack Robustness via  Tensor Optimization",
    "abstract": "Adversarial Machine Learning (AML) is a rapidly growing field of security research, with an often overlooked area being model attacks through side-channels. Previous works show such attacks to be serious threats, though little progress has been made on efficient remediation strategies that avoid costly model re-engineering. This work demonstrates a new defense against AML side-channel attacks using model compilation techniques, namely tensor optimization. We show relative model attack effectiveness decreases of up to 43% using tensor optimization, discuss the implications, and direction of future work. ",
    "url": "https://arxiv.org/abs/2309.16577",
    "authors": [
      "Stefan Trawicki",
      "William Hackett",
      "Lewis Birch",
      "Neeraj Suri",
      "Peter Garraghan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.16583",
    "title": "GPT-Fathom: Benchmarking Large Language Models to Decipher the  Evolutionary Path towards GPT-4 and Beyond",
    "abstract": "With the rapid advancement of large language models (LLMs), there is a pressing need for a comprehensive evaluation suite to assess their capabilities and limitations. Existing LLM leaderboards often reference scores reported in other papers without consistent settings and prompts, which may inadvertently encourage cherry-picking favored settings and prompts for better results. In this work, we introduce GPT-Fathom, an open-source and reproducible LLM evaluation suite built on top of OpenAI Evals. We systematically evaluate 10+ leading LLMs as well as OpenAI's legacy models on 20+ curated benchmarks across 7 capability categories, all under aligned settings. Our retrospective study on OpenAI's earlier models offers valuable insights into the evolutionary path from GPT-3 to GPT-4. Currently, the community is eager to know how GPT-3 progressively improves to GPT-4, including technical details like whether adding code data improves LLM's reasoning capability, which aspects of LLM capability can be improved by SFT and RLHF, how much is the alignment tax, etc. Our analysis sheds light on many of these questions, aiming to improve the transparency of advanced LLMs. ",
    "url": "https://arxiv.org/abs/2309.16583",
    "authors": [
      "Shen Zheng",
      "Yuyu Zhang",
      "Yijie Zhu",
      "Chenguang Xi",
      "Pengyang Gao",
      "Xun Zhou",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.16592",
    "title": "Tensor Factorization for Leveraging Cross-Modal Knowledge in  Data-Constrained Infrared Object Detection",
    "abstract": "The primary bottleneck towards obtaining good recognition performance in IR images is the lack of sufficient labeled training data, owing to the cost of acquiring such data. Realizing that object detection methods for the RGB modality are quite robust (at least for some commonplace classes, like person, car, etc.), thanks to the giant training sets that exist, in this work we seek to leverage cues from the RGB modality to scale object detectors to the IR modality, while preserving model performance in the RGB modality. At the core of our method, is a novel tensor decomposition method called TensorFact which splits the convolution kernels of a layer of a Convolutional Neural Network (CNN) into low-rank factor matrices, with fewer parameters than the original CNN. We first pretrain these factor matrices on the RGB modality, for which plenty of training data are assumed to exist and then augment only a few trainable parameters for training on the IR modality to avoid over-fitting, while encouraging them to capture complementary cues from those trained only on the RGB modality. We validate our approach empirically by first assessing how well our TensorFact decomposed network performs at the task of detecting objects in RGB images vis-a-vis the original network and then look at how well it adapts to IR images of the FLIR ADAS v1 dataset. For the latter, we train models under scenarios that pose challenges stemming from data paucity. From the experiments, we observe that: (i) TensorFact shows performance gains on RGB images; (ii) further, this pre-trained model, when fine-tuned, outperforms a standard state-of-the-art object detector on the FLIR ADAS v1 dataset by about 4% in terms of mAP 50 score. ",
    "url": "https://arxiv.org/abs/2309.16592",
    "authors": [
      "Manish Sharma",
      "Moitreya Chatterjee",
      "Kuan-Chuan Peng",
      "Suhas Lohit",
      "Michael Jones"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16593",
    "title": "Navigating Healthcare Insights: A Birds Eye View of Explainability with  Knowledge Graphs",
    "abstract": "Knowledge graphs (KGs) are gaining prominence in Healthcare AI, especially in drug discovery and pharmaceutical research as they provide a structured way to integrate diverse information sources, enhancing AI system interpretability. This interpretability is crucial in healthcare, where trust and transparency matter, and eXplainable AI (XAI) supports decision making for healthcare professionals. This overview summarizes recent literature on the impact of KGs in healthcare and their role in developing explainable AI models. We cover KG workflow, including construction, relationship extraction, reasoning, and their applications in areas like Drug-Drug Interactions (DDI), Drug Target Interactions (DTI), Drug Development (DD), Adverse Drug Reactions (ADR), and bioinformatics. We emphasize the importance of making KGs more interpretable through knowledge-infused learning in healthcare. Finally, we highlight research challenges and provide insights for future directions. ",
    "url": "https://arxiv.org/abs/2309.16593",
    "authors": [
      "Satvik Garg",
      "Shivam Parikh",
      "Somya Garg"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16595",
    "title": "Can LLMs Effectively Leverage Structural Information for Graph Learning:  When and Why",
    "abstract": "This paper studies Large Language Models (LLMs) for structured data--particularly graphs--a crucial data modality that remains underexplored in the LLM literature. We aim to understand when and why the incorporation of structural information inherent in graph data can improve the prediction performance of LLMs on node classification tasks. To address the ``when'' question, we examine a variety of prompting methods for encoding structural information, in settings where textual node features are either rich or scarce. For the ``why'' questions, we probe into two potential contributing factors to the LLM performance: data leakage and homophily. Our exploration of these questions reveals that (i) LLMs can benefit from structural information, especially when textual node features are scarce; (ii) there is no substantial evidence indicating that the performance of LLMs is significantly attributed to data leakage; and (iii) the performance of LLMs on a target node is strongly positively related to the local homophily ratio of the node. ",
    "url": "https://arxiv.org/abs/2309.16595",
    "authors": [
      "Jin Huang",
      "Xingjian Zhang",
      "Qiaozhu Mei",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16597",
    "title": "Transfer Learning for Bayesian Optimization on Heterogeneous Search  Spaces",
    "abstract": "Bayesian optimization (BO) is a popular black-box function optimization method, which makes sequential decisions based on a Bayesian model, typically a Gaussian process (GP), of the function. To ensure the quality of the model, transfer learning approaches have been developed to automatically design GP priors by learning from observations on \"training\" functions. These training functions are typically required to have the same domain as the \"test\" function (black-box function to be optimized). In this paper, we introduce MPHD, a model pre-training method on heterogeneous domains, which uses a neural net mapping from domain-specific contexts to specifications of hierarchical GPs. MPHD can be seamlessly integrated with BO to transfer knowledge across heterogeneous search spaces. Our theoretical and empirical results demonstrate the validity of MPHD and its superior performance on challenging black-box function optimization tasks. ",
    "url": "https://arxiv.org/abs/2309.16597",
    "authors": [
      "Zhou Fan",
      "Xinran Han",
      "Zi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.16606",
    "title": "\"AI enhances our performance, I have no doubt this one will do the  same\": The Placebo effect is robust to negative descriptions of AI",
    "abstract": "Heightened AI expectations facilitate performance in human-AI interactions through placebo effects. While lowering expectations to control for placebo effects is advisable, overly negative expectations could induce nocebo effects. In a letter discrimination task, we informed participants that an AI would either increase or decrease their performance by adapting the interface, but in reality, no AI was present in any condition. A Bayesian analysis showed that participants had high expectations and performed descriptively better irrespective of the AI description when a sham-AI was present. Using cognitive modeling, we could trace this advantage back to participants gathering more information. A replication study verified that negative AI descriptions do not alter expectations, suggesting that performance expectations with AI are biased and robust to negative verbal descriptions. We discuss the impact of user expectations on AI interactions and evaluation and provide a behavioral placebo marker for human-AI interaction ",
    "url": "https://arxiv.org/abs/2309.16606",
    "authors": [
      "Agnes M. Kloft",
      "Robin Welsch",
      "Thomas Kosch",
      "Steeven Villa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16618",
    "title": "Revisiting Neural Program Smoothing for Fuzzing",
    "abstract": "Testing with randomly generated inputs (fuzzing) has gained significant traction due to its capacity to expose program vulnerabilities automatically. Fuzz testing campaigns generate large amounts of data, making them ideal for the application of machine learning (ML). Neural program smoothing (NPS), a specific family of ML-guided fuzzers, aims to use a neural network as a smooth approximation of the program target for new test case generation. In this paper, we conduct the most extensive evaluation of NPS fuzzers against standard gray-box fuzzers (>11 CPU years and >5.5 GPU years), and make the following contributions: (1) We find that the original performance claims for NPS fuzzers do not hold; a gap we relate to fundamental, implementation, and experimental limitations of prior works. (2) We contribute the first in-depth analysis of the contribution of machine learning and gradient-based mutations in NPS. (3) We implement Neuzz++, which shows that addressing the practical limitations of NPS fuzzers improves performance, but that standard gray-box fuzzers almost always surpass NPS-based fuzzers. (4) As a consequence, we propose new guidelines targeted at benchmarking fuzzing based on machine learning, and present MLFuzz, a platform with GPU access for easy and reproducible evaluation of ML-based fuzzers. Neuzz++, MLFuzz, and all our data are public. ",
    "url": "https://arxiv.org/abs/2309.16618",
    "authors": [
      "Maria-Irina Nicolae",
      "Max Eisele",
      "Andreas Zeller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.16628",
    "title": "On the Role of 5G and Beyond Sidelink Communication in Multi-Hop  Tactical Networks",
    "abstract": "This work investigates the potential of 5G and beyond sidelink (SL) communication to support multi-hop tactical networks. We first provide a technical and historical overview of 3GPP SL standardization activities, and then consider applications to current problems of interest in tactical networking. We consider a number of multi-hop routing techniques which are expected to be of interest for SL-enabled multi-hop tactical networking and examine open-source tools useful for network emulation. Finally, we discuss relevant research directions which may be of interest for 5G SL-enabled tactical communications, namely the integration of RF sensing and positioning, as well as emerging machine learning tools such as federated and decentralized learning, which may be of great interest for resource allocation and routing problems that arise in tactical applications. We conclude by summarizing recent developments in the 5G SL literature and provide guidelines for future research. ",
    "url": "https://arxiv.org/abs/2309.16628",
    "authors": [
      "Charles E. Thornton",
      "Evan Allen",
      "Evar Jones",
      "Daniel Jakubisin",
      "Fred Templin",
      "Lingjia Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.16631",
    "title": "Robust Offline Reinforcement Learning -- Certify the Confidence Interval",
    "abstract": "Currently, reinforcement learning (RL), especially deep RL, has received more and more attention in the research area. However, the security of RL has been an obvious problem due to the attack manners becoming mature. In order to defend against such adversarial attacks, several practical approaches are developed, such as adversarial training, data filtering, etc. However, these methods are mostly based on empirical algorithms and experiments, without rigorous theoretical analysis of the robustness of the algorithms. In this paper, we develop an algorithm to certify the robustness of a given policy offline with random smoothing, which could be proven and conducted as efficiently as ones without random smoothing. Experiments on different environments confirm the correctness of our algorithm. ",
    "url": "https://arxiv.org/abs/2309.16631",
    "authors": [
      "Jiarui Yao",
      "Simon Shaolei Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16645",
    "title": "Reusability report: Prostate cancer stratification with diverse  biologically-informed neural architectures",
    "abstract": "In, Elmarakeby et al., \"Biologically informed deep neural network for prostate cancer discovery\", a feedforward neural network with biologically informed, sparse connections (P-NET) was presented to model the state of prostate cancer. We verified the reproducibility of the study conducted by Elmarakeby et al., using both their original codebase, and our own re-implementation using more up-to-date libraries. We quantified the contribution of network sparsification by Reactome biological pathways, and confirmed its importance to P-NET's superior performance. Furthermore, we explored alternative neural architectures and approaches to incorporating biological information into the networks. We experimented with three types of graph neural networks on the same training data, and investigated the clinical prediction agreement between different models. Our analyses demonstrated that deep neural networks with distinct architectures make incorrect predictions for individual patient that are persistent across different initializations of a specific neural architecture. This suggests that different neural architectures are sensitive to different aspects of the data, an important yet under-explored challenge for clinical prediction tasks. ",
    "url": "https://arxiv.org/abs/2309.16645",
    "authors": [
      "Christian Pedersen",
      "Tiberiu Tesileanu",
      "Tinghui Wu",
      "Siavash Golkar",
      "Miles Cranmer",
      "Zijun Zhang",
      "Shirley Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16650",
    "title": "ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and  Planning",
    "abstract": "For robots to perform a wide variety of tasks, they require a 3D representation of the world that is semantically rich, yet compact and efficient for task-driven perception and planning. Recent approaches have attempted to leverage features from large vision-language models to encode semantics in 3D representations. However, these approaches tend to produce maps with per-point feature vectors, which do not scale well in larger environments, nor do they contain semantic spatial relationships between entities in the environment, which are useful for downstream planning. In this work, we propose ConceptGraphs, an open-vocabulary graph-structured representation for 3D scenes. ConceptGraphs is built by leveraging 2D foundation models and fusing their output to 3D by multi-view association. The resulting representations generalize to novel semantic classes, without the need to collect large 3D datasets or finetune models. We demonstrate the utility of this representation through a number of downstream planning tasks that are specified through abstract (language) prompts and require complex reasoning over spatial and semantic concepts. (Project page: https://concept-graphs.github.io/ Explainer video: https://youtu.be/mRhNkQwRYnc ) ",
    "url": "https://arxiv.org/abs/2309.16650",
    "authors": [
      "Qiao Gu",
      "Alihusein Kuwajerwala",
      "Sacha Morin",
      "Krishna Murthy Jatavallabhula",
      "Bipasha Sen",
      "Aditya Agarwal",
      "Corban Rivera",
      "William Paul",
      "Kirsty Ellis",
      "Rama Chellappa",
      "Chuang Gan",
      "Celso Miguel de Melo",
      "Joshua B. Tenenbaum",
      "Antonio Torralba",
      "Florian Shkurti",
      "Liam Paull"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16654",
    "title": "Novel Deep Learning Pipeline for Automatic Weapon Detection",
    "abstract": "Weapon and gun violence have recently become a pressing issue today. The degree of these crimes and activities has risen to the point of being termed as an epidemic. This prevalent misuse of weapons calls for an automatic system that detects weapons in real-time. Real-time surveillance video is captured and recorded in almost all public forums and places. These videos contain abundant raw data which can be extracted and processed into meaningful information. This paper proposes a novel pipeline consisting of an ensemble of convolutional neural networks with distinct architectures. Each neural network is trained with a unique mini-batch with little to no overlap in the training samples. This paper will present several promising results using multiple datasets associated with comparing the proposed architecture and state-of-the-art (SoA) models. The proposed pipeline produced an average increase of 5% in accuracy, specificity, and recall compared to the SoA systems. ",
    "url": "https://arxiv.org/abs/2309.16654",
    "authors": [
      "Haribharathi Sivakumar",
      "Vijay Arvind.R",
      "Pawan Ragavendhar V",
      "G.Balamurugan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16661",
    "title": "SA2-Net: Scale-aware Attention Network for Microscopic Image  Segmentation",
    "abstract": "Microscopic image segmentation is a challenging task, wherein the objective is to assign semantic labels to each pixel in a given microscopic image. While convolutional neural networks (CNNs) form the foundation of many existing frameworks, they often struggle to explicitly capture long-range dependencies. Although transformers were initially devised to address this issue using self-attention, it has been proven that both local and global features are crucial for addressing diverse challenges in microscopic images, including variations in shape, size, appearance, and target region density. In this paper, we introduce SA2-Net, an attention-guided method that leverages multi-scale feature learning to effectively handle diverse structures within microscopic images. Specifically, we propose scale-aware attention (SA2) module designed to capture inherent variations in scales and shapes of microscopic regions, such as cells, for accurate segmentation. This module incorporates local attention at each level of multi-stage features, as well as global attention across multiple resolutions. Furthermore, we address the issue of blurred region boundaries (e.g., cell boundaries) by introducing a novel upsampling strategy called the Adaptive Up-Attention (AuA) module. This module enhances the discriminative ability for improved localization of microscopic regions using an explicit attention mechanism. Extensive experiments on five challenging datasets demonstrate the benefits of our SA2-Net model. Our source code is publicly available at \\url{https://github.com/mustansarfiaz/SA2-Net}. ",
    "url": "https://arxiv.org/abs/2309.16661",
    "authors": [
      "Mustansar Fiaz",
      "Moein Heidari",
      "Rao Muhammad Anwer",
      "Hisham Cholakkal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.15938",
    "title": "Exploring Self-Supervised Contrastive Learning of Spatial Sound Event  Representation",
    "abstract": "In this study, we present a simple multi-channel framework for contrastive learning (MC-SimCLR) to encode 'what' and 'where' of spatial audios. MC-SimCLR learns joint spectral and spatial representations from unlabeled spatial audios, thereby enhancing both event classification and sound localization in downstream tasks. At its core, we propose a multi-level data augmentation pipeline that augments different levels of audio features, including waveforms, Mel spectrograms, and generalized cross-correlation (GCC) features. In addition, we introduce simple yet effective channel-wise augmentation methods to randomly swap the order of the microphones and mask Mel and GCC channels. By using these augmentations, we find that linear layers on top of the learned representation significantly outperform supervised models in terms of both event classification accuracy and localization error. We also perform a comprehensive analysis of the effect of each augmentation method and a comparison of the fine-tuning performance using different amounts of labeled data. ",
    "url": "https://arxiv.org/abs/2309.15938",
    "authors": [
      "Xilin Jiang",
      "Cong Han",
      "Yinghao Aaron Li",
      "Nima Mesgarani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.16036",
    "title": "Multichannel Voice Trigger Detection Based on  Transform-average-concatenate",
    "abstract": "Voice triggering (VT) enables users to activate their devices by just speaking a trigger phrase. A front-end system is typically used to perform speech enhancement and/or separation, and produces multiple enhanced and/or separated signals. Since conventional VT systems take only single-channel audio as input, channel selection is performed. A drawback of this approach is that unselected channels are discarded, even if the discarded channels could contain useful information for VT. In this work, we propose multichannel acoustic models for VT, where the multichannel output from the frond-end is fed directly into a VT model. We adopt a transform-average-concatenate (TAC) block and modify the TAC block by incorporating the channel from the conventional channel selection so that the model can attend to a target speaker when multiple speakers are present. The proposed approach achieves up to 30% reduction in the false rejection rate compared to the baseline channel selection approach. ",
    "url": "https://arxiv.org/abs/2309.16036",
    "authors": [
      "Takuya Higuchi",
      "Avamarie Brueggeman",
      "Masood Delfarah",
      "Stephen Shum"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.16046",
    "title": "Precision estimation and second-order prediction errors in cortical  circuits",
    "abstract": "Minimization of cortical prediction errors is believed to be a key canonical computation of the cerebral cortex underlying perception, action and learning. However, it is still unclear how the cortex should form and use knowledge about uncertainty in this process of prediction error minimization. Here we derive neural dynamics minimizing prediction errors under the assumption that cortical areas must not only predict the activity in other areas and sensory streams, but also jointly estimate the precision of their predictions. This leads to a dynamic modulatory balancing of cortical streams based on context-dependent precision estimates. Moreover, the theory predicts the existence of second-order prediction errors, i.e. errors on precision estimates, computed and propagated through the cortical hierarchy alongside classical prediction errors. These second-order errors are used to learn weights of synapses responsible for precision estimation through an error-correcting synaptic learning rule. Finally, we propose a mapping of the theory to cortical circuitry. ",
    "url": "https://arxiv.org/abs/2309.16046",
    "authors": [
      "Arno Granier",
      "Mihai A. Petrovici",
      "Walter Senn",
      "Katharina A. Wilmes"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.16048",
    "title": "Advancing Acoustic Howling Suppression through Recursive Training of  Neural Networks",
    "abstract": "In this paper, we introduce a novel training framework designed to comprehensively address the acoustic howling issue by examining its fundamental formation process. This framework integrates a neural network (NN) module into the closed-loop system during training with signals generated recursively on the fly to closely mimic the streaming process of acoustic howling suppression (AHS). The proposed recursive training strategy bridges the gap between training and real-world inference scenarios, marking a departure from previous NN-based methods that typically approach AHS as either noise suppression or acoustic echo cancellation. Within this framework, we explore two methodologies: one exclusively relying on NN and the other combining NN with the traditional Kalman filter. Additionally, we propose strategies, including howling detection and initialization using pre-trained offline models, to bolster trainability and expedite the training process. Experimental results validate that this framework offers a substantial improvement over previous methodologies for acoustic howling suppression. ",
    "url": "https://arxiv.org/abs/2309.16048",
    "authors": [
      "Hao Zhang",
      "Yixuan Zhang",
      "Meng Yu",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.16049",
    "title": "Neural Network Augmented Kalman Filter for Robust Acoustic Howling  Suppression",
    "abstract": "Acoustic howling suppression (AHS) is a critical challenge in audio communication systems. In this paper, we propose a novel approach that leverages the power of neural networks (NN) to enhance the performance of traditional Kalman filter algorithms for AHS. Specifically, our method involves the integration of NN modules into the Kalman filter, enabling refining reference signal, a key factor in effective adaptive filtering, and estimating covariance metrics for the filter which are crucial for adaptability in dynamic conditions, thereby obtaining improved AHS performance. As a result, the proposed method achieves improved AHS performance compared to both standalone NN and Kalman filter methods. Experimental evaluations validate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2309.16049",
    "authors": [
      "Yixuan Zhang",
      "Hao Zhang",
      "Meng Yu",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.16053",
    "title": "Diagnosis of Helicobacter pylori using AutoEncoders for the Detection of  Anomalous Staining Patterns in Immunohistochemistry Images",
    "abstract": "This work addresses the detection of Helicobacter pylori a bacterium classified since 1994 as class 1 carcinogen to humans. By its highest specificity and sensitivity, the preferred diagnosis technique is the analysis of histological images with immunohistochemical staining, a process in which certain stained antibodies bind to antigens of the biological element of interest. This analysis is a time demanding task, which is currently done by an expert pathologist that visually inspects the digitized samples. We propose to use autoencoders to learn latent patterns of healthy tissue and detect H. pylori as an anomaly in image staining. Unlike existing classification approaches, an autoencoder is able to learn patterns in an unsupervised manner (without the need of image annotations) with high performance. In particular, our model has an overall 91% of accuracy with 86\\% sensitivity, 96% specificity and 0.97 AUC in the detection of H. pylori. ",
    "url": "https://arxiv.org/abs/2309.16053",
    "authors": [
      "Pau Cano",
      "\u00c1lvaro Caravaca",
      "Debora Gil",
      "Eva Musulen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16192",
    "title": "Phase-Amplitude Reduction and Optimal Phase Locking of Collectively  Oscillating Networks",
    "abstract": "We present a phase-amplitude reduction framework for analyzing collective oscillations in networked dynamical systems. The framework, which builds on the phase reduction method, takes into account not only the collective dynamics on the limit cycle but also deviations from it by introducing amplitude variables and using them with the phase variable. The framework allows us to study how networks react to applied inputs or coupling, including their synchronization and phase-locking, while capturing the deviations of the network states from the unperturbed dynamics. Numerical simulations are used to demonstrate the effectiveness of the framework for networks composed of FitzHugh-Nagumo elements. The resulting phase-amplitude equation can be used in deriving optimal periodic waveforms or introducing feedback control for achieving fast phase locking while stabilizing the collective oscillations. ",
    "url": "https://arxiv.org/abs/2309.16192",
    "authors": [
      "Petar Mircheski",
      "Jinjie Zhu",
      "Hiroya Nakao"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.16206",
    "title": "Cross-Modal Transformer GAN: Brain Structural-Functional Deep Fusing  Network for Alzheimer's Disease Analysis",
    "abstract": "Fusing structural-functional images of the brain has shown great potential to analyze the deterioration of Alzheimer's disease (AD). However, it is a big challenge to effectively fuse the correlated and complementary information from multimodal neuroimages. In this paper, a novel model termed cross-modal transformer generative adversarial network (CT-GAN) is proposed to effectively fuse the functional and structural information contained in functional magnetic resonance imaging (fMRI) and diffusion tensor imaging (DTI). The CT-GAN can learn topological features and generate multimodal connectivity from multimodal imaging data in an efficient end-to-end manner. Moreover, the swapping bi-attention mechanism is designed to gradually align common features and effectively enhance the complementary features between modalities. By analyzing the generated connectivity features, the proposed model can identify AD-related brain connections. Evaluations on the public ADNI dataset show that the proposed CT-GAN can dramatically improve prediction performance and detect AD-related brain regions effectively. The proposed model also provides new insights for detecting AD-related abnormal neural circuits. ",
    "url": "https://arxiv.org/abs/2309.16206",
    "authors": [
      "Qiankun Zuo",
      "Junren Pan",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16314",
    "title": "A Primer on Bayesian Neural Networks: Review and Debates",
    "abstract": "Neural networks have achieved remarkable performance across various problem domains, but their widespread applicability is hindered by inherent limitations such as overconfidence in predictions, lack of interpretability, and vulnerability to adversarial attacks. To address these challenges, Bayesian neural networks (BNNs) have emerged as a compelling extension of conventional neural networks, integrating uncertainty estimation into their predictive capabilities. This comprehensive primer presents a systematic introduction to the fundamental concepts of neural networks and Bayesian inference, elucidating their synergistic integration for the development of BNNs. The target audience comprises statisticians with a potential background in Bayesian methods but lacking deep learning expertise, as well as machine learners proficient in deep neural networks but with limited exposure to Bayesian statistics. We provide an overview of commonly employed priors, examining their impact on model behavior and performance. Additionally, we delve into the practical considerations associated with training and inference in BNNs. Furthermore, we explore advanced topics within the realm of BNN research, acknowledging the existence of ongoing debates and controversies. By offering insights into cutting-edge developments, this primer not only equips researchers and practitioners with a solid foundation in BNNs, but also illuminates the potential applications of this dynamic field. As a valuable resource, it fosters an understanding of BNNs and their promising prospects, facilitating further advancements in the pursuit of knowledge and innovation. ",
    "url": "https://arxiv.org/abs/2309.16314",
    "authors": [
      "Julyan Arbel",
      "Konstantinos Pitas",
      "Mariia Vladimirova",
      "Vincent Fortuin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2309.16475",
    "title": "Circuit-to-Hamiltonian from tensor networks and fault tolerance",
    "abstract": "We define a map from an arbitrary quantum circuit to a local Hamiltonian whose ground state encodes the quantum computation. All previous maps relied on the Feynman-Kitaev construction, which introduces an ancillary `clock register' to track the computational steps. Our construction, on the other hand, relies on injective tensor networks with associated parent Hamiltonians, avoiding the introduction of a clock register. This comes at the cost of the ground state containing only a noisy version of the quantum computation, with independent stochastic noise. We can remedy this - making our construction robust - by using quantum fault tolerance. In addition to the stochastic noise, we show that any state with energy density exponentially small in the circuit depth encodes a noisy version of the quantum computation with adversarial noise. We also show that any `combinatorial state' with energy density polynomially small in depth encodes the quantum computation with adversarial noise. This serves as evidence that any state with energy density polynomially small in depth has a similar property. As an application, we show that contracting injective tensor networks to additive error is BQP-hard. We also discuss the implication of our construction to the quantum PCP conjecture, combining with an observation that QMA verification can be done in logarithmic depth. ",
    "url": "https://arxiv.org/abs/2309.16475",
    "authors": [
      "Anurag Anshu",
      "Nikolas P. Breuckmann",
      "Quynh T. Nguyen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2309.16476",
    "title": "High-dimensional robust regression under heavy-tailed data: Asymptotics  and Universality",
    "abstract": "We investigate the high-dimensional properties of robust regression estimators in the presence of heavy-tailed contamination of both the covariates and response functions. In particular, we provide a sharp asymptotic characterisation of M-estimators trained on a family of elliptical covariate and noise data distributions including cases where second and higher moments do not exist. We show that, despite being consistent, the Huber loss with optimally tuned location parameter $\\delta$ is suboptimal in the high-dimensional regime in the presence of heavy-tailed noise, highlighting the necessity of further regularisation to achieve optimal performance. This result also uncovers the existence of a curious transition in $\\delta$ as a function of the sample complexity and contamination. Moreover, we derive the decay rates for the excess risk of ridge regression. We show that, while it is both optimal and universal for noise distributions with finite second moment, its decay rate can be considerably faster when the covariates' second moment does not exist. Finally, we show that our formulas readily generalise to a richer family of models and data distributions, such as generalised linear estimation with arbitrary convex regularisation trained on mixture models. ",
    "url": "https://arxiv.org/abs/2309.16476",
    "authors": [
      "Urte Adomaityte",
      "Leonardo Defilippis",
      "Bruno Loureiro",
      "Gabriele Sicuro"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.16604",
    "title": "Exploiting Edge Features in Graphs with Fused Network Gromov-Wasserstein  Distance",
    "abstract": "Pairwise comparison of graphs is key to many applications in Machine learning ranging from clustering, kernel-based classification/regression and more recently supervised graph prediction. Distances between graphs usually rely on informative representations of these structured objects such as bag of substructures or other graph embeddings. A recently popular solution consists in representing graphs as metric measure spaces, allowing to successfully leverage Optimal Transport, which provides meaningful distances allowing to compare them: the Gromov-Wasserstein distances. However, this family of distances overlooks edge attributes, which are essential for many structured objects. In this work, we introduce an extension of Gromov-Wasserstein distance for comparing graphs whose both nodes and edges have features. We propose novel algorithms for distance and barycenter computation. We empirically show the effectiveness of the novel distance in learning tasks where graphs occur in either input space or output space, such as classification and graph prediction. ",
    "url": "https://arxiv.org/abs/2309.16604",
    "authors": [
      "Junjie Yang",
      "Matthieu Labeau",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.02324",
    "title": "Estimating the Expected Influence Capacities of Nodes in Complex  Networks under the Susceptible-Infectious-Recovered (SIR) Model",
    "abstract": " Comments: There was a minor inaccuracy in coefficient calculation for a competitor centrality measure named as Convex Combinations of Centrality Measures. So, we excluded this centrality measure. Also, there were some minor computational errors in monotonicity calculations, which we think are caused by the computational precision of the programming tools we use or the computer. We fixed it ",
    "url": "https://arxiv.org/abs/2103.02324",
    "authors": [
      "Aybike \u015eim\u015fek"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.00723",
    "title": "Infinite Neural Network Quantum States: Entanglement and Training  Dynamics",
    "abstract": " Title: Infinite Neural Network Quantum States: Entanglement and Training  Dynamics ",
    "url": "https://arxiv.org/abs/2112.00723",
    "authors": [
      "Di Luo",
      "James Halverson"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)"
    ]
  },
  {
    "id": "arXiv:2202.09134",
    "title": "Data Augmentation in the Underparameterized and Overparameterized  Regimes",
    "abstract": " Comments: Changed title and added an analysis on the effect of augmentations on the double-descent risk curve of a high-dimensional ridgeless estimator ",
    "url": "https://arxiv.org/abs/2202.09134",
    "authors": [
      "Kevin Han Huang",
      "Peter Orbanz",
      "Morgane Austern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.03959",
    "title": "Enhancing Door-Status Detection for Autonomous Mobile Robots during  Environment-Specific Operational Use",
    "abstract": " Title: Enhancing Door-Status Detection for Autonomous Mobile Robots during  Environment-Specific Operational Use ",
    "url": "https://arxiv.org/abs/2203.03959",
    "authors": [
      "Michele Antonazzi",
      "Matteo Luperto",
      "Nicola Basilico",
      "N. Alberto Borghese"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.05625",
    "title": "Quantum Self-Attention Neural Networks for Text Classification",
    "abstract": " Comments: v2 is close to the published version ",
    "url": "https://arxiv.org/abs/2205.05625",
    "authors": [
      "Guangxi Li",
      "Xuanqiang Zhao",
      "Xin Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.08310",
    "title": "Decomposition and factorisation of transients in Functional Graphs",
    "abstract": " Title: Decomposition and factorisation of transients in Functional Graphs ",
    "url": "https://arxiv.org/abs/2208.08310",
    "authors": [
      "Fran\u00e7ois Dor\u00e9",
      "Enrico Formenti",
      "Antonio E. Porreca",
      "Sara Riva"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2208.10074",
    "title": "Product structure of graph classes with strongly sublinear separators",
    "abstract": " Comments: v2: added bad news subsection; v3: removed section \"Polynomial Expansion Classes\" which had an error, added section \"Lower Bounds\", and added a new author; v4: minor revisions and corrections; ",
    "url": "https://arxiv.org/abs/2208.10074",
    "authors": [
      "Zden\u011bk Dvo\u0159\u00e1k",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2208.14708",
    "title": "Classical-to-quantum convolutional neural network transfer learning",
    "abstract": " Comments: 16 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2208.14708",
    "authors": [
      "Juhyeon Kim",
      "Joonsuk Huh",
      "Daniel K. Park"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06061",
    "title": "Non-Smooth, H\u00f6lder-Smooth, and Robust Submodular Maximization",
    "abstract": " Title: Non-Smooth, H\u00f6lder-Smooth, and Robust Submodular Maximization ",
    "url": "https://arxiv.org/abs/2210.06061",
    "authors": [
      "Duksang Lee",
      "Nam Ho-Nguyen",
      "Dabeen Lee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.08217",
    "title": "A Low-Shot Object Counting Network With Iterative Prototype Adaptation",
    "abstract": " Comments: Accepted to ICCV2023, code: this https URL ",
    "url": "https://arxiv.org/abs/2211.08217",
    "authors": [
      "Nikola Djukic",
      "Alan Lukezic",
      "Vitjan Zavrtanik",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.09916",
    "title": "Online Distribution Shift Detection via Recency Prediction",
    "abstract": " Title: Online Distribution Shift Detection via Recency Prediction ",
    "url": "https://arxiv.org/abs/2211.09916",
    "authors": [
      "Rachel Luo",
      "Rohan Sinha",
      "Yixiao Sun",
      "Ali Hindy",
      "Shengjia Zhao",
      "Silvio Savarese",
      "Edward Schmerling",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16808",
    "title": "Efficient Adversarial Input Generation via Neural Net Patching",
    "abstract": " Title: Efficient Adversarial Input Generation via Neural Net Patching ",
    "url": "https://arxiv.org/abs/2211.16808",
    "authors": [
      "Tooba Khan",
      "Kumar Madhukar",
      "Subodh Vishnu Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.03559",
    "title": "Attribute Graph Clustering via Learnable Augmentation",
    "abstract": " Title: Attribute Graph Clustering via Learnable Augmentation ",
    "url": "https://arxiv.org/abs/2212.03559",
    "authors": [
      "Xihong Yang",
      "Yue Liu",
      "Ke Liang",
      "Sihang Zhou",
      "Xinwang Liu",
      "En Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11562",
    "title": "Is My Prediction Arbitrary? Confounding Effects of Variance in Fair  Classification",
    "abstract": " Title: Is My Prediction Arbitrary? Confounding Effects of Variance in Fair  Classification ",
    "url": "https://arxiv.org/abs/2301.11562",
    "authors": [
      "A. Feder Cooper",
      "Katherine Lee",
      "Madiha Choksi",
      "Solon Barocas",
      "Christopher De Sa",
      "James Grimmelmann",
      "Jon Kleinberg",
      "Siddhartha Sen",
      "Baobao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03037",
    "title": "EvCenterNet: Uncertainty Estimation for Object Detection using  Evidential Learning",
    "abstract": " Title: EvCenterNet: Uncertainty Estimation for Object Detection using  Evidential Learning ",
    "url": "https://arxiv.org/abs/2303.03037",
    "authors": [
      "Monish R. Nallapareddy",
      "Kshitij Sirohi",
      "Paulo L. J. Drews-Jr",
      "Wolfram Burgard",
      "Chih-Hong Cheng",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.04116",
    "title": "TrafficBots: Towards World Models for Autonomous Driving Simulation and  Motion Prediction",
    "abstract": " Comments: Published at ICRA 2023. The repository is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.04116",
    "authors": [
      "Zhejun Zhang",
      "Alexander Liniger",
      "Dengxin Dai",
      "Fisher Yu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.07556",
    "title": "Unique Nash equilibrium of a nonlinear model of opinion dynamics on  networks with friction-inspired stubbornness",
    "abstract": " Title: Unique Nash equilibrium of a nonlinear model of opinion dynamics on  networks with friction-inspired stubbornness ",
    "url": "https://arxiv.org/abs/2304.07556",
    "authors": [
      "David N. Reynolds",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2304.10749",
    "title": "Emergence of Brain-inspired Small-world Spiking Neural Network through  Neuroevolution",
    "abstract": " Title: Emergence of Brain-inspired Small-world Spiking Neural Network through  Neuroevolution ",
    "url": "https://arxiv.org/abs/2304.10749",
    "authors": [
      "Wenxuan Pan",
      "Feifei Zhao",
      "Bing Han",
      "Yiting Dong",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.04866",
    "title": "Causal Policy Gradient for Whole-Body Mobile Manipulation",
    "abstract": " Title: Causal Policy Gradient for Whole-Body Mobile Manipulation ",
    "url": "https://arxiv.org/abs/2305.04866",
    "authors": [
      "Jiaheng Hu",
      "Peter Stone",
      "Roberto Mart\u00edn-Mart\u00edn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06141",
    "title": "Active Semantic Localization with Graph Neural Embedding",
    "abstract": " Comments: 7 pages, 6 figures, 1 table ",
    "url": "https://arxiv.org/abs/2305.06141",
    "authors": [
      "Mitsuki Yoshida",
      "Kanji Tanaka",
      "Ryogo Yamamoto",
      "Daiki Iwata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16912",
    "title": "Disambiguated Attention Embedding for Multi-Instance Partial-Label  Learning",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2305.16912",
    "authors": [
      "Wei Tang",
      "Weijia Zhang",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.08836",
    "title": "Probabilistic-based Feature Embedding of 4-D Light Fields for  Compressive Imaging and Denoising",
    "abstract": " Title: Probabilistic-based Feature Embedding of 4-D Light Fields for  Compressive Imaging and Denoising ",
    "url": "https://arxiv.org/abs/2306.08836",
    "authors": [
      "Xianqiang Lyu",
      "Junhui Hou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.15891",
    "title": "Capturing the Diffusive Behavior of the Multiscale Linear Transport  Equations by Asymptotic-Preserving Convolutional DeepONets",
    "abstract": " Title: Capturing the Diffusive Behavior of the Multiscale Linear Transport  Equations by Asymptotic-Preserving Convolutional DeepONets ",
    "url": "https://arxiv.org/abs/2306.15891",
    "authors": [
      "Keke Wu",
      "Xiong-bin Yan",
      "Shi Jin",
      "Zheng Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.01026",
    "title": "Temporal Graph Benchmark for Machine Learning on Temporal Graphs",
    "abstract": " Comments: 20 pages, 7 figures, 7 tables, accepted at NeurIPS 2023 Datasets and Benchmarks Track ",
    "url": "https://arxiv.org/abs/2307.01026",
    "authors": [
      "Shenyang Huang",
      "Farimah Poursafaei",
      "Jacob Danovitch",
      "Matthias Fey",
      "Weihua Hu",
      "Emanuele Rossi",
      "Jure Leskovec",
      "Michael Bronstein",
      "Guillaume Rabusseau",
      "Reihaneh Rabbany"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.06135",
    "title": "SayPlan: Grounding Large Language Models using 3D Scene Graphs for  Scalable Robot Task Planning",
    "abstract": " Comments: Accepted for oral presentation at the Conference on Robot Learning (CoRL), 2023. Project page can be found here: this https URL ",
    "url": "https://arxiv.org/abs/2307.06135",
    "authors": [
      "Krishan Rana",
      "Jesse Haviland",
      "Sourav Garg",
      "Jad Abou-Chakra",
      "Ian Reid",
      "Niko Suenderhauf"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.06738",
    "title": "Closeness Centralities of Lollipop Graphs",
    "abstract": " Title: Closeness Centralities of Lollipop Graphs ",
    "url": "https://arxiv.org/abs/2307.06738",
    "authors": [
      "Chavdar Dangalchev"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2307.12499",
    "title": "AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion  Models",
    "abstract": " Title: AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion  Models ",
    "url": "https://arxiv.org/abs/2307.12499",
    "authors": [
      "Xuelong Dai",
      "Kaisheng Liang",
      "Bin Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15506",
    "title": "Improving Image Quality of Sparse-view Lung Cancer CT Images with a  Convolutional Neural Network",
    "abstract": " Title: Improving Image Quality of Sparse-view Lung Cancer CT Images with a  Convolutional Neural Network ",
    "url": "https://arxiv.org/abs/2307.15506",
    "authors": [
      "Annika Ries",
      "Tina Dorosti",
      "Johannes Thalhammer",
      "Daniel Sasse",
      "Andreas Sauter",
      "Felix Meurer",
      "Ashley Benne",
      "Tobias Lasser",
      "Franz Pfeiffer",
      "Florian Schaff",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2307.15567",
    "title": "Panoptic Scene Graph Generation with Semantics-prototype Learning",
    "abstract": " Title: Panoptic Scene Graph Generation with Semantics-prototype Learning ",
    "url": "https://arxiv.org/abs/2307.15567",
    "authors": [
      "Li Li",
      "Wei Ji",
      "Yiming Wu",
      "Mengze Li",
      "You Qin",
      "Lina Wei",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01213",
    "title": "Embedding Capabilities of Neural ODEs",
    "abstract": " Title: Embedding Capabilities of Neural ODEs ",
    "url": "https://arxiv.org/abs/2308.01213",
    "authors": [
      "Christian Kuehn",
      "Sara-Viola Kuntz"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.03666",
    "title": "Bridging Trustworthiness and Open-World Learning: An Exploratory Neural  Approach for Enhancing Interpretability, Generalization, and Robustness",
    "abstract": " Title: Bridging Trustworthiness and Open-World Learning: An Exploratory Neural  Approach for Enhancing Interpretability, Generalization, and Robustness ",
    "url": "https://arxiv.org/abs/2308.03666",
    "authors": [
      "Shide Du",
      "Zihan Fang",
      "Shiyang Lan",
      "Yanchao Tan",
      "Manuel G\u00fcnther",
      "Shiping Wang",
      "Wenzhong Guo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05034",
    "title": "Kairos: Practical Intrusion Detection and Investigation using  Whole-system Provenance",
    "abstract": " Comments: 24 pages, 16 figures, to appear in the 45th IEEE Symposium on Security and Privacy (S&P'24) ",
    "url": "https://arxiv.org/abs/2308.05034",
    "authors": [
      "Zijun Cheng",
      "Qiujian Lv",
      "Jinyuan Liang",
      "Yan Wang",
      "Degang Sun",
      "Thomas Pasquier",
      "Xueyuan Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09830",
    "title": "Synergistic Integration of Large Language Models and Cognitive  Architectures for Robust AI: An Exploratory Analysis",
    "abstract": " Comments: AAAI 2023 Fall Symposium ",
    "url": "https://arxiv.org/abs/2308.09830",
    "authors": [
      "Oscar J. Romero",
      "John Zimmerman",
      "Aaron Steinfeld",
      "Anthony Tomasic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10425",
    "title": "STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer  SOTA for Traffic Forecasting",
    "abstract": " Comments: Accepted as CIKM2023 Short Paper ",
    "url": "https://arxiv.org/abs/2308.10425",
    "authors": [
      "Hangchen Liu",
      "Zheng Dong",
      "Renhe Jiang",
      "Jiewen Deng",
      "Jinliang Deng",
      "Quanjun Chen",
      "Xuan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13436",
    "title": "An Intermediate Representation for Composable Typed Streaming Dataflow  Designs",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2212.12003 ",
    "url": "https://arxiv.org/abs/2308.13436",
    "authors": [
      "Matthijs A. Reukers",
      "Yongding Tian",
      "Zaid Al-Ars",
      "Peter Hofstee",
      "Matthijs Brobbel",
      "Johan Peltenburg",
      "Jeroen van Straten"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2308.13978",
    "title": "A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss  Function for Combinatorial Optimization using Reinforcement Learning",
    "abstract": " Title: A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss  Function for Combinatorial Optimization using Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2308.13978",
    "authors": [
      "Redwan Ahmed Rizvee",
      "Md. Mosaddek Khan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.14359",
    "title": "Effect of Attention and Self-Supervised Speech Embeddings on  Non-Semantic Speech Tasks",
    "abstract": " Comments: Accepted to appear at ACM Multimedia 2023 Multimedia Grand Challenges Track ",
    "url": "https://arxiv.org/abs/2308.14359",
    "authors": [
      "Payal Mohapatra",
      "Akash Pandey",
      "Yueyuan Sui",
      "Qi Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.02672",
    "title": "Geometry of Sensitivity: Twice Sampling and Hybrid Clipping in  Differential Privacy with Optimal Gaussian Noise and Application to Deep  Learning",
    "abstract": " Title: Geometry of Sensitivity: Twice Sampling and Hybrid Clipping in  Differential Privacy with Optimal Gaussian Noise and Application to Deep  Learning ",
    "url": "https://arxiv.org/abs/2309.02672",
    "authors": [
      "Hanshen Xiao",
      "Jun Wan",
      "Srinivas Devadas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.06612",
    "title": "Harmonic-NAS: Hardware-Aware Multimodal Neural Architecture Search on  Resource-constrained Devices",
    "abstract": " Comments: Accepted to the 15th Asian Conference on Machine Learning (ACML 2023) ",
    "url": "https://arxiv.org/abs/2309.06612",
    "authors": [
      "Mohamed Imed Eddine Ghebriout",
      "Halima Bouzidi",
      "Smail Niar",
      "Hamza Ouarnoughi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.07461",
    "title": "Detecting Unknown Attacks in IoT Environments: An Open Set Classifier  for Enhanced Network Intrusion Detection",
    "abstract": " Comments: 6 Pages, 5 figures ",
    "url": "https://arxiv.org/abs/2309.07461",
    "authors": [
      "Yasir Ali Farrukh",
      "Syed Wali",
      "Irfan Khan",
      "Nathaniel D. Bastian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10331",
    "title": "Hardness results for decoding the surface code with Pauli noise",
    "abstract": " Comments: 37 pages, 18 figures. 26 pages, 12 figures in main text ",
    "url": "https://arxiv.org/abs/2309.10331",
    "authors": [
      "Alex Fischer",
      "Akimasa Miyake"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2309.10941",
    "title": "Data-driven design of complex network structures to promote  synchronization",
    "abstract": " Title: Data-driven design of complex network structures to promote  synchronization ",
    "url": "https://arxiv.org/abs/2309.10941",
    "authors": [
      "Marco Coraggio",
      "Mario di Bernardo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.11500",
    "title": "A Large-scale Dataset for Audio-Language Representation Learning",
    "abstract": " Title: A Large-scale Dataset for Audio-Language Representation Learning ",
    "url": "https://arxiv.org/abs/2309.11500",
    "authors": [
      "Luoyi Sun",
      "Xuenan Xu",
      "Mengyue Wu",
      "Weidi Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.13302",
    "title": "Gaining the Sparse Rewards by Exploring Binary Lottery Tickets in  Spiking Neural Network",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2309.13302",
    "authors": [
      "Hao Cheng",
      "Jiahang Cao",
      "Erjia Xiao",
      "Pu Zhao",
      "Mengshu Sun",
      "Jiaxu Wang",
      "Jize Zhang",
      "Xue Lin",
      "Bhavya Kailkhura",
      "Kaidi Xu",
      "Renjing Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13556",
    "title": "LOGICSEG: Parsing Visual Semantics with Neural Logic Learning and  Reasoning",
    "abstract": " Comments: ICCV 2023 (Oral). Code: this https URL ",
    "url": "https://arxiv.org/abs/2309.13556",
    "authors": [
      "Liulei Li",
      "Wenguan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13752",
    "title": "Improving Robustness of Deep Convolutional Neural Networks via  Multiresolution Learning",
    "abstract": " Title: Improving Robustness of Deep Convolutional Neural Networks via  Multiresolution Learning ",
    "url": "https://arxiv.org/abs/2309.13752",
    "authors": [
      "Hongyan Zhou",
      "Yao Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14129",
    "title": "Speaker anonymization using neural audio codec language models",
    "abstract": " Comments: Submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.14129",
    "authors": [
      "Michele Panariello",
      "Francesco Nespoli",
      "Massimiliano Todisco",
      "Nicholas Evans"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.14225",
    "title": "HumanMimic: Learning Natural Locomotion and Transitions for Humanoid  Robot via Wasserstein Adversarial Imitation",
    "abstract": " Title: HumanMimic: Learning Natural Locomotion and Transitions for Humanoid  Robot via Wasserstein Adversarial Imitation ",
    "url": "https://arxiv.org/abs/2309.14225",
    "authors": [
      "Annan Tang",
      "Takuma Hiraoka",
      "Naoki Hiraoka",
      "Fan Shi",
      "Kento Kawaharazuka",
      "Kunio Kojima",
      "Kei Okada",
      "Masayuki Inaba"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.14704",
    "title": "Tile Classification Based Viewport Prediction with Multi-modal Fusion  Transformer",
    "abstract": " Comments: This paper is accepted by ACM-MM 2023 ",
    "url": "https://arxiv.org/abs/2309.14704",
    "authors": [
      "Zhihao Zhang",
      "Yiwei Chen",
      "Weizhan Zhang",
      "Caixia Yan",
      "Qinghua Zheng",
      "Qi Wang",
      "Wangdu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.15123",
    "title": "Uncovering Neural Scaling Laws in Molecular Representation Learning",
    "abstract": " Comments: 23 pages; accepted to NeurIPS 2023 Datasets and Benchmarks ",
    "url": "https://arxiv.org/abs/2309.15123",
    "authors": [
      "Dingshuo Chen",
      "Yanqiao Zhu",
      "Jieyu Zhang",
      "Yuanqi Du",
      "Zhixun Li",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.15317",
    "title": "Joint Prediction and Denoising for Large-scale Multilingual  Self-supervised Learning",
    "abstract": " Comments: Accepted to ASRU 2023 ",
    "url": "https://arxiv.org/abs/2309.15317",
    "authors": [
      "William Chen",
      "Jiatong Shi",
      "Brian Yan",
      "Dan Berrebbi",
      "Wangyou Zhang",
      "Yifan Peng",
      "Xuankai Chang",
      "Soumi Maiti",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.15757",
    "title": "Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data",
    "abstract": " Title: Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data ",
    "url": "https://arxiv.org/abs/2309.15757",
    "authors": [
      "Boshko Koloski",
      "Bla\u017e \u0160krlj",
      "Senja Pollak",
      "Nada Lavra\u010d"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]