[
  {
    "id": "arXiv:2309.10822",
    "title": "A Real-Time Approach for Smart Building Operations Prediction Using  Rule-Based Complex Event Processing and SPARQL Query",
    "abstract": "Due to intelligent, adaptive nature towards various operations and their ability to provide maximum comfort to the occupants residing in them, smart buildings are becoming a pioneering area of research. Since these architectures leverage the Internet of Things (IoT), there is a need for monitoring different operations (Occupancy, Humidity, Temperature, CO2, etc.) to provide sustainable comfort to the occupants. This paper proposes a novel approach for intelligent building operations monitoring using rule-based complex event processing and query-based approaches for dynamically monitoring the different operations. Siddhi is a complex event processing engine designed for handling multiple sources of event data in real time and processing it according to predefined rules using a decision tree. Since streaming data is dynamic in nature, to keep track of different operations, we have converted the IoT data into an RDF dataset. The RDF dataset is ingested to Apache Kafka for streaming purposes and for stored data we have used the GraphDB tool that extracts information with the help of SPARQL query. Consequently, the proposed approach is also evaluated by deploying the large number of events through the Siddhi CEP engine and how efficiently they are processed in terms of time. Apart from that, a risk estimation scenario is also designed to generate alerts for end users in case any of the smart building operations need immediate attention. The output is visualized and monitored for the end user through a tableau dashboard. ",
    "url": "https://arxiv.org/abs/2309.10822",
    "authors": [
      "Shashi Shekhar Kumar",
      "Ritesh Chandra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2309.10834",
    "title": "Sparser Random Networks Exist: Enforcing Communication-Efficient  Federated Learning via Regularization",
    "abstract": "This work presents a new method for enhancing communication efficiency in stochastic Federated Learning that trains over-parameterized random networks. In this setting, a binary mask is optimized instead of the model weights, which are kept fixed. The mask characterizes a sparse sub-network that is able to generalize as good as a smaller target network. Importantly, sparse binary masks are exchanged rather than the floating point weights in traditional federated learning, reducing communication cost to at most 1 bit per parameter. We show that previous state of the art stochastic methods fail to find the sparse networks that can reduce the communication and storage overhead using consistent loss objectives. To address this, we propose adding a regularization term to local objectives that encourages sparser solutions by eliminating redundant features across sub-networks. Extensive experiments demonstrate significant improvements in communication and memory efficiency of up to five magnitudes compared to the literature, with minimal performance degradation in validation accuracy in some instances. ",
    "url": "https://arxiv.org/abs/2309.10834",
    "authors": [
      "Mohamad Mestoukirdi",
      "Omid Esrafilian",
      "David Gesbert",
      "Qianrui Li",
      "Nicolas Gresset"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.10890",
    "title": "Crypto'Graph: Leveraging Privacy-Preserving Distributed Link Prediction  for Robust Graph Learning",
    "abstract": "Graphs are a widely used data structure for collecting and analyzing relational data. However, when the graph structure is distributed across several parties, its analysis is particularly challenging. In particular, due to the sensitivity of the data each party might want to keep their partial knowledge of the graph private, while still willing to collaborate with the other parties for tasks of mutual benefit, such as data curation or the removal of poisoned data. To address this challenge, we propose Crypto'Graph, an efficient protocol for privacy-preserving link prediction on distributed graphs. More precisely, it allows parties partially sharing a graph with distributed links to infer the likelihood of formation of new links in the future. Through the use of cryptographic primitives, Crypto'Graph is able to compute the likelihood of these new links on the joint network without revealing the structure of the private individual graph of each party, even though they know the number of nodes they have, since they share the same graph but not the same links. Crypto'Graph improves on previous works by enabling the computation of a certain number of similarity metrics without any additional cost. The use of Crypto'Graph is illustrated for defense against graph poisoning attacks, in which it is possible to identify potential adversarial links without compromising the privacy of the graphs of individual parties. The effectiveness of Crypto'Graph in mitigating graph poisoning attacks and achieving high prediction accuracy on a graph neural network node classification task is demonstrated through extensive experimentation on a real-world dataset. ",
    "url": "https://arxiv.org/abs/2309.10890",
    "authors": [
      "Sofiane Azogagh",
      "Zelma Aubin Birba",
      "S\u00e9bastien Gambs",
      "Marc-Olivier Killijian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.10910",
    "title": "Amplifying Pathological Detection in EEG Signaling Pathways through  Cross-Dataset Transfer Learning",
    "abstract": "Pathology diagnosis based on EEG signals and decoding brain activity holds immense importance in understanding neurological disorders. With the advancement of artificial intelligence methods and machine learning techniques, the potential for accurate data-driven diagnoses and effective treatments has grown significantly. However, applying machine learning algorithms to real-world datasets presents diverse challenges at multiple levels. The scarcity of labelled data, especially in low regime scenarios with limited availability of real patient cohorts due to high costs of recruitment, underscores the vital deployment of scaling and transfer learning techniques. In this study, we explore a real-world pathology classification task to highlight the effectiveness of data and model scaling and cross-dataset knowledge transfer. As such, we observe varying performance improvements through data scaling, indicating the need for careful evaluation and labelling. Additionally, we identify the challenges of possible negative transfer and emphasize the significance of some key components to overcome distribution shifts and potential spurious correlations and achieve positive transfer. We see improvement in the performance of the target model on the target (NMT) datasets by using the knowledge from the source dataset (TUAB) when a low amount of labelled data was available. Our findings indicate a small and generic model (e.g. ShallowNet) performs well on a single dataset, however, a larger model (e.g. TCN) performs better on transfer and learning from a larger and diverse dataset. ",
    "url": "https://arxiv.org/abs/2309.10910",
    "authors": [
      "Mohammad-Javad Darvishi-Bayazi",
      "Mohammad Sajjad Ghaemi",
      "Timothee Lesort",
      "Md Rifat Arefin",
      "Jocelyn Faubert",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.10911",
    "title": "Language-Conditioned Affordance-Pose Detection in 3D Point Clouds",
    "abstract": "Affordance detection and pose estimation are of great importance in many robotic applications. Their combination helps the robot gain an enhanced manipulation capability, in which the generated pose can facilitate the corresponding affordance task. Previous methods for affodance-pose joint learning are limited to a predefined set of affordances, thus limiting the adaptability of robots in real-world environments. In this paper, we propose a new method for language-conditioned affordance-pose joint learning in 3D point clouds. Given a 3D point cloud object, our method detects the affordance region and generates appropriate 6-DoF poses for any unconstrained affordance label. Our method consists of an open-vocabulary affordance detection branch and a language-guided diffusion model that generates 6-DoF poses based on the affordance text. We also introduce a new high-quality dataset for the task of language-driven affordance-pose joint learning. Intensive experimental results demonstrate that our proposed method works effectively on a wide range of open-vocabulary affordances and outperforms other baselines by a large margin. In addition, we illustrate the usefulness of our method in real-world robotic applications. Our code and dataset are publicly available at https://3DAPNet.github.io ",
    "url": "https://arxiv.org/abs/2309.10911",
    "authors": [
      "Toan Nguyen",
      "Minh Nhat Vu",
      "Baoru Huang",
      "Tuan Van Vo",
      "Vy Truong",
      "Ngan Le",
      "Thieu Vo",
      "Bac Le",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.10916",
    "title": "What Learned Representations and Influence Functions Can Tell Us About  Adversarial Examples",
    "abstract": "Adversarial examples, deliberately crafted using small perturbations to fool deep neural networks, were first studied in image processing and more recently in NLP. While approaches to detecting adversarial examples in NLP have largely relied on search over input perturbations, image processing has seen a range of techniques that aim to characterise adversarial subspaces over the learned representations. In this paper, we adapt two such approaches to NLP, one based on nearest neighbors and influence functions and one on Mahalanobis distances. The former in particular produces a state-of-the-art detector when compared against several strong baselines; moreover, the novel use of influence functions provides insight into how the nature of adversarial example subspaces in NLP relate to those in image processing, and also how they differ depending on the kind of NLP task. ",
    "url": "https://arxiv.org/abs/2309.10916",
    "authors": [
      "Shakila Mahjabin Tonni",
      "Mark Dras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.10924",
    "title": "Change of Scenery: Unsupervised LiDAR Change Detection for Mobile Robots",
    "abstract": "This paper presents a fully unsupervised deep change detection approach for mobile robots with 3D LiDAR. In unstructured environments, it is infeasible to define a closed set of semantic classes. Instead, semantic segmentation is reformulated as binary change detection. We develop a neural network, RangeNetCD, that uses an existing point-cloud map and a live LiDAR scan to detect scene changes with respect to the map. Using a novel loss function, existing point-cloud semantic segmentation networks can be trained to perform change detection without any labels or assumptions about local semantics. We demonstrate the performance of this approach on data from challenging terrains; mean intersection over union (mIoU) scores range between 67.4% and 82.2% depending on the amount of environmental structure. This outperforms the geometric baseline used in all experiments. The neural network runs faster than 10Hz and is integrated into a robot's autonomy stack to allow safe navigation around obstacles that intersect the planned path. In addition, a novel method for the rapid automated acquisition of per-point ground-truth labels is described. Covering changed parts of the scene with retroreflective materials and applying a threshold filter to the intensity channel of the LiDAR allows for quantitative evaluation of the change detector. ",
    "url": "https://arxiv.org/abs/2309.10924",
    "authors": [
      "Alexander Krawciw",
      "Jordy Sehn",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.10929",
    "title": "Specializing Small Language Models towards Complex Style Transfer via  Latent Attribute Pre-Training",
    "abstract": "In this work, we introduce the concept of complex text style transfer tasks, and constructed complex text datasets based on two widely applicable scenarios. Our dataset is the first large-scale data set of its kind, with 700 rephrased sentences and 1,000 sentences from the game Genshin Impact. While large language models (LLM) have shown promise in complex text style transfer, they have drawbacks such as data privacy concerns, network instability, and high deployment costs. To address these issues, we explore the effectiveness of small models (less than T5-3B) with implicit style pre-training through contrastive learning. We also propose a method for automated evaluation of text generation quality based on alignment with human evaluations using ChatGPT. Finally, we compare our approach with existing methods and show that our model achieves state-of-art performances of few-shot text style transfer models. ",
    "url": "https://arxiv.org/abs/2309.10929",
    "authors": [
      "Ruiqi Xu",
      "Yongfeng Huang",
      "Xin Chen",
      "Lin Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.10932",
    "title": "Open-Vocabulary Affordance Detection using Knowledge Distillation and  Text-Point Correlation",
    "abstract": "Affordance detection presents intricate challenges and has a wide range of robotic applications. Previous works have faced limitations such as the complexities of 3D object shapes, the wide range of potential affordances on real-world objects, and the lack of open-vocabulary support for affordance understanding. In this paper, we introduce a new open-vocabulary affordance detection method in 3D point clouds, leveraging knowledge distillation and text-point correlation. Our approach employs pre-trained 3D models through knowledge distillation to enhance feature extraction and semantic understanding in 3D point clouds. We further introduce a new text-point correlation method to learn the semantic links between point cloud features and open-vocabulary labels. The intensive experiments show that our approach outperforms previous works and adapts to new affordance labels and unseen objects. Notably, our method achieves the improvement of 7.96% mIOU score compared to the baselines. Furthermore, it offers real-time inference which is well-suitable for robotic manipulation applications. ",
    "url": "https://arxiv.org/abs/2309.10932",
    "authors": [
      "Tuan Van Vo",
      "Minh Nhat Vu",
      "Baoru Huang",
      "Toan Nguyen",
      "Ngan Le",
      "Thieu Vo",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.10941",
    "title": "Data-driven design of complex network structures to promote  synchronization",
    "abstract": "We consider the problem of optimizing the interconnection graphs of complex networks to promote synchronization. When traditional optimization methods are inapplicable, due to uncertain or unknown node dynamics, we propose a data-driven approach leveraging datasets of relevant examples. We analyze two case studies, with linear and nonlinear node dynamics. First, we show how including node dynamics in the objective function makes the optimal graphs heterogeneous. Then, we compare various design strategies, finding that the best either utilize data samples close to a specific Pareto front or a combination of a neural network and a genetic algorithm, with statistically better performance than the best examples in the datasets. ",
    "url": "https://arxiv.org/abs/2309.10941",
    "authors": [
      "Marco Coraggio",
      "Mario di Bernardo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.10948",
    "title": "A Novel Deep Neural Network for Trajectory Prediction in Automated  Vehicles Using Velocity Vector Field",
    "abstract": "Anticipating the motion of other road users is crucial for automated driving systems (ADS), as it enables safe and informed downstream decision-making and motion planning. Unfortunately, contemporary learning-based approaches for motion prediction exhibit significant performance degradation as the prediction horizon increases or the observation window decreases. This paper proposes a novel technique for trajectory prediction that combines a data-driven learning-based method with a velocity vector field (VVF) generated from a nature-inspired concept, i.e., fluid flow dynamics. In this work, the vector field is incorporated as an additional input to a convolutional-recurrent deep neural network to help predict the most likely future trajectories given a sequence of bird's eye view scene representations. The performance of the proposed model is compared with state-of-the-art methods on the HighD dataset demonstrating that the VVF inclusion improves the prediction accuracy for both short and long-term (5~sec) time horizons. It is also shown that the accuracy remains consistent with decreasing observation windows which alleviates the requirement of a long history of past observations for accurate trajectory prediction. Source codes are available at: https://github.com/Amir-Samadi/VVF-TP. ",
    "url": "https://arxiv.org/abs/2309.10948",
    "authors": [
      "MReza Alipour Sormoli",
      "Amir Samadi",
      "Sajjad Mozaffari",
      "Konstantinos Koufos",
      "Mehrdad Dianati",
      "Roger Woodman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.10972",
    "title": "SEMPART: Self-supervised Multi-resolution Partitioning of Image  Semantics",
    "abstract": "Accurately determining salient regions of an image is challenging when labeled data is scarce. DINO-based self-supervised approaches have recently leveraged meaningful image semantics captured by patch-wise features for locating foreground objects. Recent methods have also incorporated intuitive priors and demonstrated value in unsupervised methods for object partitioning. In this paper, we propose SEMPART, which jointly infers coarse and fine bi-partitions over an image's DINO-based semantic graph. Furthermore, SEMPART preserves fine boundary details using graph-driven regularization and successfully distills the coarse mask semantics into the fine mask. Our salient object detection and single object localization findings suggest that SEMPART produces high-quality masks rapidly without additional post-processing and benefits from co-optimizing the coarse and fine branches. ",
    "url": "https://arxiv.org/abs/2309.10972",
    "authors": [
      "Sriram Ravindran",
      "Debraj Basu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10973",
    "title": "Reachability Analysis for Lexicase Selection via Community Assembly  Graphs",
    "abstract": "Fitness landscapes have historically been a powerful tool for analyzing the search space explored by evolutionary algorithms. In particular, they facilitate understanding how easily reachable an optimal solution is from a given starting point. However, simple fitness landscapes are inappropriate for analyzing the search space seen by selection schemes like lexicase selection in which the outcome of selection depends heavily on the current contents of the population (i.e. selection schemes with complex ecological dynamics). Here, we propose borrowing a tool from ecology to solve this problem: community assembly graphs. We demonstrate a simple proof-of-concept for this approach on an NK Landscape where we have perfect information. We then demonstrate that this approach can be successfully applied to a complex genetic programming problem. While further research is necessary to understand how to best use this tool, we believe it will be a valuable addition to our toolkit and facilitate analyses that were previously impossible. ",
    "url": "https://arxiv.org/abs/2309.10973",
    "authors": [
      "Emily Dolson",
      "Alexander Lalejini"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.10975",
    "title": "SPFQ: A Stochastic Algorithm and Its Error Analysis for Neural Network  Quantization",
    "abstract": "Quantization is a widely used compression method that effectively reduces redundancies in over-parameterized neural networks. However, existing quantization techniques for deep neural networks often lack a comprehensive error analysis due to the presence of non-convex loss functions and nonlinear activations. In this paper, we propose a fast stochastic algorithm for quantizing the weights of fully trained neural networks. Our approach leverages a greedy path-following mechanism in combination with a stochastic quantizer. Its computational complexity scales only linearly with the number of weights in the network, thereby enabling the efficient quantization of large networks. Importantly, we establish, for the first time, full-network error bounds, under an infinite alphabet condition and minimal assumptions on the weights and input data. As an application of this result, we prove that when quantizing a multi-layer network having Gaussian weights, the relative square quantization error exhibits a linear decay as the degree of over-parametrization increases. Furthermore, we demonstrate that it is possible to achieve error bounds equivalent to those obtained in the infinite alphabet case, using on the order of a mere $\\log\\log N$ bits per weight, where $N$ represents the largest number of neurons in a layer. ",
    "url": "https://arxiv.org/abs/2309.10975",
    "authors": [
      "Jinjie Zhang",
      "Rayan Saab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.10976",
    "title": "Accurate and Scalable Estimation of Epistemic Uncertainty for Graph  Neural Networks",
    "abstract": "Safe deployment of graph neural networks (GNNs) under distribution shift requires models to provide accurate confidence indicators (CI). However, while it is well-known in computer vision that CI quality diminishes under distribution shift, this behavior remains understudied for GNNs. Hence, we begin with a case study on CI calibration under controlled structural and feature distribution shifts and demonstrate that increased expressivity or model size do not always lead to improved CI performance. Consequently, we instead advocate for the use of epistemic uncertainty quantification (UQ) methods to modulate CIs. To this end, we propose G-$\\Delta$UQ, a new single model UQ method that extends the recently proposed stochastic centering framework to support structured data and partial stochasticity. Evaluated across covariate, concept, and graph size shifts, G-$\\Delta$UQ not only outperforms several popular UQ methods in obtaining calibrated CIs, but also outperforms alternatives when CIs are used for generalization gap prediction or OOD detection. Overall, our work not only introduces a new, flexible GNN UQ method, but also provides novel insights into GNN CIs on safety-critical tasks. ",
    "url": "https://arxiv.org/abs/2309.10976",
    "authors": [
      "Puja Trivedi",
      "Mark Heimann",
      "Rushil Anirudh",
      "Danai Koutra",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10979",
    "title": "Towards Data-centric Graph Machine Learning: Review and Outlook",
    "abstract": "Data-centric AI, with its primary focus on the collection, management, and utilization of data to drive AI models and applications, has attracted increasing attention in recent years. In this article, we conduct an in-depth and comprehensive review, offering a forward-looking outlook on the current efforts in data-centric AI pertaining to graph data-the fundamental data structure for representing and capturing intricate dependencies among massive and diverse real-life entities. We introduce a systematic framework, Data-centric Graph Machine Learning (DC-GML), that encompasses all stages of the graph data lifecycle, including graph data collection, exploration, improvement, exploitation, and maintenance. A thorough taxonomy of each stage is presented to answer three critical graph-centric questions: (1) how to enhance graph data availability and quality; (2) how to learn from graph data with limited-availability and low-quality; (3) how to build graph MLOps systems from the graph data-centric view. Lastly, we pinpoint the future prospects of the DC-GML domain, providing insights to navigate its advancements and applications. ",
    "url": "https://arxiv.org/abs/2309.10979",
    "authors": [
      "Xin Zheng",
      "Yixin Liu",
      "Zhifeng Bao",
      "Meng Fang",
      "Xia Hu",
      "Alan Wee-Chung Liew",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10987",
    "title": "Spiking NeRF: Making Bio-inspired Neural Networks See through the Real  World",
    "abstract": "Spiking neuron networks (SNNs) have been thriving on numerous tasks to leverage their promising energy efficiency and exploit their potentialities as biologically plausible intelligence. Meanwhile, the Neural Radiance Fields (NeRF) render high-quality 3D scenes with massive energy consumption, and few works delve into the energy-saving solution with a bio-inspired approach. In this paper, we propose spiking NeRF (SpikingNeRF), which aligns the radiance ray with the temporal dimension of SNN, to naturally accommodate the SNN to the reconstruction of Radiance Fields. Thus, the computation turns into a spike-based, multiplication-free manner, reducing the energy consumption. In SpikingNeRF, each sampled point on the ray is matched onto a particular time step, and represented in a hybrid manner where the voxel grids are maintained as well. Based on the voxel grids, sampled points are determined whether to be masked for better training and inference. However, this operation also incurs irregular temporal length. We propose the temporal condensing-and-padding (TCP) strategy to tackle the masked samples to maintain regular temporal length, i.e., regular tensors, for hardware-friendly computation. Extensive experiments on a variety of datasets demonstrate that our method reduces the $76.74\\%$ energy consumption on average and obtains comparable synthesis quality with the ANN baseline. ",
    "url": "https://arxiv.org/abs/2309.10987",
    "authors": [
      "Xingting Yao",
      "Qinghao Hu",
      "Tielong Liu",
      "Zitao Mo",
      "Zeyu Zhu",
      "Zhengyang Zhuge",
      "Jian Cheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.10993",
    "title": "Directional Source Separation for Robust Speech Recognition on Smart  Glasses",
    "abstract": "Modern smart glasses leverage advanced audio sensing and machine learning technologies to offer real-time transcribing and captioning services, considerably enriching human experiences in daily communications. However, such systems frequently encounter challenges related to environmental noises, resulting in degradation to speech recognition and speaker change detection. To improve voice quality, this work investigates directional source separation using the multi-microphone array. We first explore multiple beamformers to assist source separation modeling by strengthening the directional properties of speech signals. In addition to relying on predetermined beamformers, we investigate neural beamforming in multi-channel source separation, demonstrating that automatic learning directional characteristics effectively improves separation quality. We further compare the ASR performance leveraging separated outputs to noisy inputs. Our results show that directional source separation benefits ASR for the wearer but not for the conversation partner. Lastly, we perform the joint training of the directional source separation and ASR model, achieving the best overall ASR performance. ",
    "url": "https://arxiv.org/abs/2309.10993",
    "authors": [
      "Tiantian Feng",
      "Ju Lin",
      "Yiteng Huang",
      "Weipeng He",
      "Kaustubh Kalgaonkar",
      "Niko Moritz",
      "Li Wan",
      "Xin Lei",
      "Ming Sun",
      "Frank Seide"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.11005",
    "title": "It's Simplex! Disaggregating Measures to Improve Certified Robustness",
    "abstract": "Certified robustness circumvents the fragility of defences against adversarial attacks, by endowing model predictions with guarantees of class invariance for attacks up to a calculated size. While there is value in these certifications, the techniques through which we assess their performance do not present a proper accounting of their strengths and weaknesses, as their analysis has eschewed consideration of performance over individual samples in favour of aggregated measures. By considering the potential output space of certified models, this work presents two distinct approaches to improve the analysis of certification mechanisms, that allow for both dataset-independent and dataset-dependent measures of certification performance. Embracing such a perspective uncovers new certification approaches, which have the potential to more than double the achievable radius of certification, relative to current state-of-the-art. Empirical evaluation verifies that our new approach can certify $9\\%$ more samples at noise scale $\\sigma = 1$, with greater relative improvements observed as the difficulty of the predictive task increases. ",
    "url": "https://arxiv.org/abs/2309.11005",
    "authors": [
      "Andrew C. Cullen",
      "Paul Montague",
      "Shijie Liu",
      "Sarah M. Erfani",
      "Benjamin I.P. Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.11006",
    "title": "STARNet: Sensor Trustworthiness and Anomaly Recognition via Approximated  Likelihood Regret for Robust Edge Autonomy",
    "abstract": "Complex sensors such as LiDAR, RADAR, and event cameras have proliferated in autonomous robotics to enhance perception and understanding of the environment. Meanwhile, these sensors are also vulnerable to diverse failure mechanisms that can intricately interact with their operation environment. In parallel, the limited availability of training data on complex sensors also affects the reliability of their deep learning-based prediction flow, where their prediction models can fail to generalize to environments not adequately captured in the training set. To address these reliability concerns, this paper introduces STARNet, a Sensor Trustworthiness and Anomaly Recognition Network designed to detect untrustworthy sensor streams that may arise from sensor malfunctions and/or challenging environments. We specifically benchmark STARNet on LiDAR and camera data. STARNet employs the concept of approximated likelihood regret, a gradient-free framework tailored for low-complexity hardware, especially those with only fixed-point precision capabilities. Through extensive simulations, we demonstrate the efficacy of STARNet in detecting untrustworthy sensor streams in unimodal and multimodal settings. In particular, the network shows superior performance in addressing internal sensor failures, such as cross-sensor interference and crosstalk. In diverse test scenarios involving adverse weather and sensor malfunctions, we show that STARNet enhances prediction accuracy by approximately 10% by filtering out untrustworthy sensor streams. STARNet is publicly available at \\url{https://github.com/sinatayebati/STARNet}. ",
    "url": "https://arxiv.org/abs/2309.11006",
    "authors": [
      "Nastaran Darabi",
      "Sina Tayebati",
      "Sureshkumar S.",
      "Sathya Ravi",
      "Theja Tulabandhula",
      "Amit R. Trivedi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11009",
    "title": "Controllable Dynamic Appearance for Neural 3D Portraits",
    "abstract": "Recent advances in Neural Radiance Fields (NeRFs) have made it possible to reconstruct and reanimate dynamic portrait scenes with control over head-pose, facial expressions and viewing direction. However, training such models assumes photometric consistency over the deformed region e.g. the face must be evenly lit as it deforms with changing head-pose and facial expression. Such photometric consistency across frames of a video is hard to maintain, even in studio environments, thus making the created reanimatable neural portraits prone to artifacts during reanimation. In this work, we propose CoDyNeRF, a system that enables the creation of fully controllable 3D portraits in real-world capture conditions. CoDyNeRF learns to approximate illumination dependent effects via a dynamic appearance model in the canonical space that is conditioned on predicted surface normals and the facial expressions and head-pose deformations. The surface normals prediction is guided using 3DMM normals that act as a coarse prior for the normals of the human head, where direct prediction of normals is hard due to rigid and non-rigid deformations induced by head-pose and facial expression changes. Using only a smartphone-captured short video of a subject for training, we demonstrate the effectiveness of our method on free view synthesis of a portrait scene with explicit head pose and expression controls, and realistic lighting effects. The project page can be found here: this http URL ",
    "url": "https://arxiv.org/abs/2309.11009",
    "authors": [
      "ShahRukh Athar",
      "Zhixin Shu",
      "Zexiang Xu",
      "Fujun Luan",
      "Sai Bi",
      "Kalyan Sunkavalli",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11012",
    "title": "A Survey on Acoustic Side Channel Attacks on Keyboards",
    "abstract": "In today's digital world, protecting personal and sensitive information is crucial. A new threat has emerged called acoustic side-channel attacks on keyboards, which exploit unintentional acoustic signals generated while typing to decipher keystrokes. This survey paper provides a thorough analysis of this danger, including attack strategies, methods, and their consequences. We explore key recognition techniques, the different acoustic features used, and performance metrics for evaluation. This survey is an essential resource for researchers, practitioners, and security experts to protect against acoustic side-channel attacks on keyboards. ",
    "url": "https://arxiv.org/abs/2309.11012",
    "authors": [
      "Alireza Taheritajar",
      "Zahra Mahmoudpour Harris",
      "Reza Rahaeimehr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.11021",
    "title": "An Empirical Study of Malicious Code In PyPI Ecosystem",
    "abstract": "PyPI provides a convenient and accessible package management platform to developers, enabling them to quickly implement specific functions and improve work efficiency. However, the rapid development of the PyPI ecosystem has led to a severe problem of malicious package propagation. Malicious developers disguise malicious packages as normal, posing a significant security risk to end-users. To this end, we conducted an empirical study to understand the characteristics and current state of the malicious code lifecycle in the PyPI ecosystem. We first built an automated data collection framework and collated a multi-source malicious code dataset containing 4,669 malicious package files. We preliminarily classified these malicious code into five categories based on malicious behaviour characteristics. Our research found that over 50% of malicious code exhibits multiple malicious behaviours, with information stealing and command execution being particularly prevalent. In addition, we observed several novel attack vectors and anti-detection techniques. Our analysis revealed that 74.81% of all malicious packages successfully entered end-user projects through source code installation, thereby increasing security risks. A real-world investigation showed that many reported malicious packages persist in PyPI mirror servers globally, with over 72% remaining for an extended period after being discovered. Finally, we sketched a portrait of the malicious code lifecycle in the PyPI ecosystem, effectively reflecting the characteristics of malicious code at different stages. We also present some suggested mitigations to improve the security of the Python open-source ecosystem. ",
    "url": "https://arxiv.org/abs/2309.11021",
    "authors": [
      "Wenbo Guo",
      "Zhengzi Xu",
      "Chengwei Liu",
      "Cheng Huang",
      "Yong Fang",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.11046",
    "title": "Heterogeneous Entity Matching with Complex Attribute Associations using  BERT and Neural Networks",
    "abstract": "Across various domains, data from different sources such as Baidu Baike and Wikipedia often manifest in distinct forms. Current entity matching methodologies predominantly focus on homogeneous data, characterized by attributes that share the same structure and concise attribute values. However, this orientation poses challenges in handling data with diverse formats. Moreover, prevailing approaches aggregate the similarity of attribute values between corresponding attributes to ascertain entity similarity. Yet, they often overlook the intricate interrelationships between attributes, where one attribute may have multiple associations. The simplistic approach of pairwise attribute comparison fails to harness the wealth of information encapsulated within entities.To address these challenges, we introduce a novel entity matching model, dubbed Entity Matching Model for Capturing Complex Attribute Relationships(EMM-CCAR),built upon pre-trained models. Specifically, this model transforms the matching task into a sequence matching problem to mitigate the impact of varying data formats. Moreover, by introducing attention mechanisms, it identifies complex relationships between attributes, emphasizing the degree of matching among multiple attributes rather than one-to-one correspondences. Through the integration of the EMM-CCAR model, we adeptly surmount the challenges posed by data heterogeneity and intricate attribute interdependencies. In comparison with the prevalent DER-SSM and Ditto approaches, our model achieves improvements of approximately 4% and 1% in F1 scores, respectively. This furnishes a robust solution for addressing the intricacies of attribute complexity in entity matching. ",
    "url": "https://arxiv.org/abs/2309.11046",
    "authors": [
      "Shitao Wang",
      "Jiamin Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11048",
    "title": "Containing Analog Data Deluge at Edge through Frequency-Domain  Compression in Collaborative Compute-in-Memory Networks",
    "abstract": "Edge computing is a promising solution for handling high-dimensional, multispectral analog data from sensors and IoT devices for applications such as autonomous drones. However, edge devices' limited storage and computing resources make it challenging to perform complex predictive modeling at the edge. Compute-in-memory (CiM) has emerged as a principal paradigm to minimize energy for deep learning-based inference at the edge. Nevertheless, integrating storage and processing complicates memory cells and/or memory peripherals, essentially trading off area efficiency for energy efficiency. This paper proposes a novel solution to improve area efficiency in deep learning inference tasks. The proposed method employs two key strategies. Firstly, a Frequency domain learning approach uses binarized Walsh-Hadamard Transforms, reducing the necessary parameters for DNN (by 87% in MobileNetV2) and enabling compute-in-SRAM, which better utilizes parallelism during inference. Secondly, a memory-immersed collaborative digitization method is described among CiM arrays to reduce the area overheads of conventional ADCs. This facilitates more CiM arrays in limited footprint designs, leading to better parallelism and reduced external memory accesses. Different networking configurations are explored, where Flash, SA, and their hybrid digitization steps can be implemented using the memory-immersed scheme. The results are demonstrated using a 65 nm CMOS test chip, exhibiting significant area and energy savings compared to a 40 nm-node 5-bit SAR ADC and 5-bit Flash ADC. By processing analog data more efficiently, it is possible to selectively retain valuable data from sensors and alleviate the challenges posed by the analog data deluge. ",
    "url": "https://arxiv.org/abs/2309.11048",
    "authors": [
      "Nastaran Darabi",
      "Amit R. Trivedi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11052",
    "title": "fakenewsbr: A Fake News Detection Platform for Brazilian Portuguese",
    "abstract": "The proliferation of fake news has become a significant concern in recent times due to its potential to spread misinformation and manipulate public opinion. This paper presents a comprehensive study on detecting fake news in Brazilian Portuguese, focusing on journalistic-type news. We propose a machine learning-based approach that leverages natural language processing techniques, including TF-IDF and Word2Vec, to extract features from textual data. We evaluate the performance of various classification algorithms, such as logistic regression, support vector machine, random forest, AdaBoost, and LightGBM, on a dataset containing both true and fake news articles. The proposed approach achieves high accuracy and F1-Score, demonstrating its effectiveness in identifying fake news. Additionally, we developed a user-friendly web platform, fakenewsbr.com, to facilitate the verification of news articles' veracity. Our platform provides real-time analysis, allowing users to assess the likelihood of fake news articles. Through empirical analysis and comparative studies, we demonstrate the potential of our approach to contribute to the fight against the spread of fake news and promote more informed media consumption. ",
    "url": "https://arxiv.org/abs/2309.11052",
    "authors": [
      "Luiz Giordani",
      "Gilsiley Dar\u00fa",
      "Rhenan Queiroz",
      "Vitor Buzinaro",
      "Davi Keglevich Neiva",
      "Daniel Camilo Fuentes Guzm\u00e1n",
      "Marcos Jardel Henriques",
      "Oilson Alberto Gonzatto Junior",
      "Francisco Louzada"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.11053",
    "title": "Fed-LSAE: Thwarting Poisoning Attacks against Federated Cyber Threat  Detection System via Autoencoder-based Latent Space Inspection",
    "abstract": "The significant rise of security concerns in conventional centralized learning has promoted federated learning (FL) adoption in building intelligent applications without privacy breaches. In cybersecurity, the sensitive data along with the contextual information and high-quality labeling in each enterprise organization play an essential role in constructing high-performance machine learning (ML) models for detecting cyber threats. Nonetheless, the risks coming from poisoning internal adversaries against FL systems have raised discussions about designing robust anti-poisoning frameworks. Whereas defensive mechanisms in the past were based on outlier detection, recent approaches tend to be more concerned with latent space representation. In this paper, we investigate a novel robust aggregation method for FL, namely Fed-LSAE, which takes advantage of latent space representation via the penultimate layer and Autoencoder to exclude malicious clients from the training process. The experimental results on the CIC-ToN-IoT and N-BaIoT datasets confirm the feasibility of our defensive mechanism against cutting-edge poisoning attacks for developing a robust FL-based threat detector in the context of IoT. More specifically, the FL evaluation witnesses an upward trend of approximately 98% across all metrics when integrating with our Fed-LSAE defense. ",
    "url": "https://arxiv.org/abs/2309.11053",
    "authors": [
      "Tran Duc Luong",
      "Vuong Minh Tien",
      "Nguyen Huu Quyen",
      "Do Thi Thu Hien",
      "Phan The Duy",
      "Van-Hau Pham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.11057",
    "title": "Safe and Robust Multi-Agent Reinforcement Learning for Connected  Autonomous Vehicles under State Perturbations",
    "abstract": "Sensing and communication technologies have enhanced learning-based decision making methodologies for multi-agent systems such as connected autonomous vehicles (CAV). However, most existing safe reinforcement learning based methods assume accurate state information. It remains challenging to achieve safety requirement under state uncertainties for CAVs, considering the noisy sensor measurements and the vulnerability of communication channels. In this work, we propose a Robust Multi-Agent Proximal Policy Optimization with robust Safety Shield (SR-MAPPO) for CAVs in various driving scenarios. Both robust MARL algorithm and control barrier function (CBF)-based safety shield are used in our approach to cope with the perturbed or uncertain state inputs. The robust policy is trained with a worst-case Q function regularization module that pursues higher lower-bounded reward in the former, whereas the latter, i.e., the robust CBF safety shield accounts for CAVs' collision-free constraints in complicated driving scenarios with even perturbed vehicle state information. We validate the advantages of SR-MAPPO in robustness and safety and compare it with baselines under different driving and state perturbation scenarios in CARLA simulator. The SR-MAPPO policy is verified to maintain higher safety rates and efficiency (reward) when threatened by both state perturbations and unconnected vehicles' dangerous behaviors. ",
    "url": "https://arxiv.org/abs/2309.11057",
    "authors": [
      "Zhili Zhang",
      "Yanchao Sun",
      "Furong Huang",
      "Fei Miao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2309.11062",
    "title": "The social stratification of internal migration and daily mobility  during the COVID-19 pandemic",
    "abstract": "This study leverages mobile phone data for 5.4 million users to unveil the complex dynamics of internal migration and daily mobility in Santiago de Chile during the global COVID-19 pandemic, with a focus on socioeconomic differentials. Major findings include an increase in daily mobility among lower-income brackets compared to higher ones in 2020. In contrast, long-term relocation patterns rose primarily among higher-income groups. These shifts indicate a nuanced response to the pandemic across socioeconomic strata. Unlike in 2017, economic factors in 2020 influenced a change not only in the decision to emigrate but also in the selection of destinations, suggesting a profound transformation in mobility behaviors. Contrary to expectations, there was no evidence supporting a preference for rural over urban destinations despite the surge in emigration from Santiago during the pandemic. The study enhances our understanding of how varying socioeconomic conditions intersect with mobility decisions during crises and provides valuable insights for policymakers aiming to enact fair, informed measures in rapidly changing circumstances. ",
    "url": "https://arxiv.org/abs/2309.11062",
    "authors": [
      "Erick Elejalde",
      "Leo Ferres",
      "V\u00edctor Navarro",
      "Loreto Bravo",
      "Emilio Zagheni"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.11069",
    "title": "Dynamic Tiling: A Model-Agnostic, Adaptive, Scalable, and  Inference-Data-Centric Approach for Efficient and Accurate Small Object  Detection",
    "abstract": "We introduce Dynamic Tiling, a model-agnostic, adaptive, and scalable approach for small object detection, anchored in our inference-data-centric philosophy. Dynamic Tiling starts with non-overlapping tiles for initial detections and utilizes dynamic overlapping rates along with a tile minimizer. This dual approach effectively resolves fragmented objects, improves detection accuracy, and minimizes computational overhead by reducing the number of forward passes through the object detection model. Adaptable to a variety of operational environments, our method negates the need for laborious recalibration. Additionally, our large-small filtering mechanism boosts the detection quality across a range of object sizes. Overall, Dynamic Tiling outperforms existing model-agnostic uniform cropping methods, setting new benchmarks for efficiency and accuracy. ",
    "url": "https://arxiv.org/abs/2309.11069",
    "authors": [
      "Son The Nguyen",
      "Theja Tulabandhula",
      "Duy Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11071",
    "title": "InkStream: Real-time GNN Inference on Streaming Graphs via Incremental  Update",
    "abstract": "Classic Graph Neural Network (GNN) inference approaches, designed for static graphs, are ill-suited for streaming graphs that evolve with time. The dynamism intrinsic to streaming graphs necessitates constant updates, posing unique challenges to acceleration on GPU. We address these challenges based on two key insights: (1) Inside the $k$-hop neighborhood, a significant fraction of the nodes is not impacted by the modified edges when the model uses min or max as aggregation function; (2) When the model weights remain static while the graph structure changes, node embeddings can incrementally evolve over time by computing only the impacted part of the neighborhood. With these insights, we propose a novel method, InkStream, designed for real-time inference with minimal memory access and computation, while ensuring an identical output to conventional methods. InkStream operates on the principle of propagating and fetching data only when necessary. It uses an event-based system to control inter-layer effect propagation and intra-layer incremental updates of node embedding. InkStream is highly extensible and easily configurable by allowing users to create and process customized events. We showcase that less than 10 lines of additional user code are needed to support popular GNN models such as GCN, GraphSAGE, and GIN. Our experiments with three GNN models on four large graphs demonstrate that InkStream accelerates by 2.5-427$\\times$ on a CPU cluster and 2.4-343$\\times$ on two different GPU clusters while producing identical outputs as GNN model inference on the latest graph snapshot. ",
    "url": "https://arxiv.org/abs/2309.11071",
    "authors": [
      "Dan Wu",
      "Zhaoying Li",
      "Tulika Mitra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.11077",
    "title": "Weak Supervision for Label Efficient Visual Bug Detection",
    "abstract": "As video games evolve into expansive, detailed worlds, visual quality becomes essential, yet increasingly challenging. Traditional testing methods, limited by resources, face difficulties in addressing the plethora of potential bugs. Machine learning offers scalable solutions; however, heavy reliance on large labeled datasets remains a constraint. Addressing this challenge, we propose a novel method, utilizing unlabeled gameplay and domain-specific augmentations to generate datasets & self-supervised objectives used during pre-training or multi-task settings for downstream visual bug detection. Our methodology uses weak-supervision to scale datasets for the crafted objectives and facilitates both autonomous and interactive weak-supervision, incorporating unsupervised clustering and/or an interactive approach based on text and geometric prompts. We demonstrate on first-person player clipping/collision bugs (FPPC) within the expansive Giantmap game world, that our approach is very effective, improving over a strong supervised baseline in a practical, very low-prevalence, low data regime (0.336 $\\rightarrow$ 0.550 F1 score). With just 5 labeled \"good\" exemplars (i.e., 0 bugs), our self-supervised objective alone captures enough signal to outperform the low-labeled supervised settings. Building on large-pretrained vision models, our approach is adaptable across various visual bugs. Our results suggest applicability in curating datasets for broader image and video tasks within video games beyond visual bugs. ",
    "url": "https://arxiv.org/abs/2309.11077",
    "authors": [
      "Farrukh Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11081",
    "title": "Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal  Distillation",
    "abstract": "Sound can convey significant information for spatial reasoning in our daily lives. To endow deep networks with such ability, we address the challenge of dense indoor prediction with sound in both 2D and 3D via cross-modal knowledge distillation. In this work, we propose a Spatial Alignment via Matching (SAM) distillation framework that elicits local correspondence between the two modalities in vision-to-audio knowledge transfer. SAM integrates audio features with visually coherent learnable spatial embeddings to resolve inconsistencies in multiple layers of a student model. Our approach does not rely on a specific input representation, allowing for flexibility in the input shapes or dimensions without performance degradation. With a newly curated benchmark named Dense Auditory Prediction of Surroundings (DAPS), we are the first to tackle dense indoor prediction of omnidirectional surroundings in both 2D and 3D with audio observations. Specifically, for audio-based depth estimation, semantic segmentation, and challenging 3D scene reconstruction, the proposed distillation framework consistently achieves state-of-the-art performance across various metrics and backbone architectures. ",
    "url": "https://arxiv.org/abs/2309.11081",
    "authors": [
      "Heeseung Yun",
      "Joonil Na",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11092",
    "title": "Forgery-aware Adaptive Vision Transformer for Face Forgery Detection",
    "abstract": "With the advancement in face manipulation technologies, the importance of face forgery detection in protecting authentication integrity becomes increasingly evident. Previous Vision Transformer (ViT)-based detectors have demonstrated subpar performance in cross-database evaluations, primarily because fully fine-tuning with limited Deepfake data often leads to forgetting pre-trained knowledge and over-fitting to data-specific ones. To circumvent these issues, we propose a novel Forgery-aware Adaptive Vision Transformer (FA-ViT). In FA-ViT, the vanilla ViT's parameters are frozen to preserve its pre-trained knowledge, while two specially designed components, the Local-aware Forgery Injector (LFI) and the Global-aware Forgery Adaptor (GFA), are employed to adapt forgery-related knowledge. our proposed FA-ViT effectively combines these two different types of knowledge to form the general forgery features for detecting Deepfakes. Specifically, LFI captures local discriminative information and incorporates these information into ViT via Neighborhood-Preserving Cross Attention (NPCA). Simultaneously, GFA learns adaptive knowledge in the self-attention layer, bridging the gap between the two different domain. Furthermore, we design a novel Single Domain Pairwise Learning (SDPL) to facilitate fine-grained information learning in FA-ViT. The extensive experiments demonstrate that our FA-ViT achieves state-of-the-art performance in cross-dataset evaluation and cross-manipulation scenarios, and improves the robustness against unseen perturbations. ",
    "url": "https://arxiv.org/abs/2309.11092",
    "authors": [
      "Anwei Luo",
      "Rizhao Cai",
      "Chenqi Kong",
      "Xiangui Kang",
      "Jiwu Huang",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.11101",
    "title": "A New Interpretable Neural Network-Based Rule Model for Healthcare  Decision Making",
    "abstract": "In healthcare applications, understanding how machine/deep learning models make decisions is crucial. In this study, we introduce a neural network framework, $\\textit{Truth Table rules}$ (TT-rules), that combines the global and exact interpretability properties of rule-based models with the high performance of deep neural networks. TT-rules is built upon $\\textit{Truth Table nets}$ (TTnet), a family of deep neural networks initially developed for formal verification. By extracting the necessary and sufficient rules $\\mathcal{R}$ from the trained TTnet model (global interpretability) to yield the same output as the TTnet (exact interpretability), TT-rules effectively transforms the neural network into a rule-based model. This rule-based model supports binary classification, multi-label classification, and regression tasks for small to large tabular datasets. After outlining the framework, we evaluate TT-rules' performance on healthcare applications and compare it to state-of-the-art rule-based methods. Our results demonstrate that TT-rules achieves equal or higher performance compared to other interpretable methods. Notably, TT-rules presents the first accurate rule-based model capable of fitting large tabular datasets, including two real-life DNA datasets with over 20K features. ",
    "url": "https://arxiv.org/abs/2309.11101",
    "authors": [
      "Adrien Benamira",
      "Tristan Guerand",
      "Thomas Peyrin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11104",
    "title": "AttentionMix: Data augmentation method that relies on BERT attention  mechanism",
    "abstract": "The Mixup method has proven to be a powerful data augmentation technique in Computer Vision, with many successors that perform image mixing in a guided manner. One of the interesting research directions is transferring the underlying Mixup idea to other domains, e.g. Natural Language Processing (NLP). Even though there already exist several methods that apply Mixup to textual data, there is still room for new, improved approaches. In this work, we introduce AttentionMix, a novel mixing method that relies on attention-based information. While the paper focuses on the BERT attention mechanism, the proposed approach can be applied to generally any attention-based model. AttentionMix is evaluated on 3 standard sentiment classification datasets and in all three cases outperforms two benchmark approaches that utilize Mixup mechanism, as well as the vanilla BERT method. The results confirm that the attention-based information can be effectively used for data augmentation in the NLP domain. ",
    "url": "https://arxiv.org/abs/2309.11104",
    "authors": [
      "Dominik Lewy",
      "Jacek Ma\u0144dziuk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11109",
    "title": "Self-supervised Domain-agnostic Domain Adaptation for Satellite Images",
    "abstract": "Domain shift caused by, e.g., different geographical regions or acquisition conditions is a common issue in machine learning for global scale satellite image processing. A promising method to address this problem is domain adaptation, where the training and the testing datasets are split into two or multiple domains according to their distributions, and an adaptation method is applied to improve the generalizability of the model on the testing dataset. However, defining the domain to which each satellite image belongs is not trivial, especially under large-scale multi-temporal and multi-sensory scenarios, where a single image mosaic could be generated from multiple data sources. In this paper, we propose an self-supervised domain-agnostic domain adaptation (SS(DA)2) method to perform domain adaptation without such a domain definition. To achieve this, we first design a contrastive generative adversarial loss to train a generative network to perform image-to-image translation between any two satellite image patches. Then, we improve the generalizability of the downstream models by augmenting the training data with different testing spectral characteristics. The experimental results on public benchmarks verify the effectiveness of SS(DA)2. ",
    "url": "https://arxiv.org/abs/2309.11109",
    "authors": [
      "Fahong Zhang",
      "Yilei Shi",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.11111",
    "title": "PRAT: PRofiling Adversarial aTtacks",
    "abstract": "Intrinsic susceptibility of deep learning to adversarial examples has led to a plethora of attack techniques with a broad common objective of fooling deep models. However, we find slight compositional differences between the algorithms achieving this objective. These differences leave traces that provide important clues for attacker profiling in real-life scenarios. Inspired by this, we introduce a novel problem of PRofiling Adversarial aTtacks (PRAT). Given an adversarial example, the objective of PRAT is to identify the attack used to generate it. Under this perspective, we can systematically group existing attacks into different families, leading to the sub-problem of attack family identification, which we also study. To enable PRAT analysis, we introduce a large Adversarial Identification Dataset (AID), comprising over 180k adversarial samples generated with 13 popular attacks for image specific/agnostic white/black box setups. We use AID to devise a novel framework for the PRAT objective. Our framework utilizes a Transformer based Global-LOcal Feature (GLOF) module to extract an approximate signature of the adversarial attack, which in turn is used for the identification of the attack. Using AID and our framework, we provide multiple interesting benchmark results for the PRAT problem. ",
    "url": "https://arxiv.org/abs/2309.11111",
    "authors": [
      "Rahul Ambati",
      "Naveed Akhtar",
      "Ajmal Mian",
      "Yogesh Singh Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11131",
    "title": "Locate and Verify: A Two-Stream Network for Improved Deepfake Detection",
    "abstract": "Deepfake has taken the world by storm, triggering a trust crisis. Current deepfake detection methods are typically inadequate in generalizability, with a tendency to overfit to image contents such as the background, which are frequently occurring but relatively unimportant in the training dataset. Furthermore, current methods heavily rely on a few dominant forgery regions and may ignore other equally important regions, leading to inadequate uncovering of forgery cues. In this paper, we strive to address these shortcomings from three aspects: (1) We propose an innovative two-stream network that effectively enlarges the potential regions from which the model extracts forgery evidence. (2) We devise three functional modules to handle the multi-stream and multi-scale features in a collaborative learning scheme. (3) Confronted with the challenge of obtaining forgery annotations, we propose a Semi-supervised Patch Similarity Learning strategy to estimate patch-level forged location annotations. Empirically, our method demonstrates significantly improved robustness and generalizability, outperforming previous methods on six benchmarks, and improving the frame-level AUC on Deepfake Detection Challenge preview dataset from 0.797 to 0.835 and video-level AUC on CelebDF$\\_$v1 dataset from 0.811 to 0.847. Our implementation is available at https://github.com/sccsok/Locate-and-Verify. ",
    "url": "https://arxiv.org/abs/2309.11131",
    "authors": [
      "Chao Shuai",
      "Jieming Zhong",
      "Shuang Wu",
      "Feng Lin",
      "Zhibo Wang",
      "Zhongjie Ba",
      "Zhenguang Liu",
      "Lorenzo Cavallaro",
      "Kui Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11134",
    "title": "GNSS/Multi-Sensor Fusion Using Continuous-Time Factor Graph Optimization  for Robust Localization",
    "abstract": "Accurate and robust vehicle localization in highly urbanized areas is challenging. Sensors are often corrupted in those complicated and large-scale environments. This paper introduces GNSS-FGO, an online and global trajectory estimator that fuses GNSS observations alongside multiple sensor measurements for robust vehicle localization. In GNSS-FGO, we fuse asynchronous sensor measurements into the graph with a continuous-time trajectory representation using Gaussian process regression. This enables querying states at arbitrary timestamps so that sensor observations are fused without requiring strict state and measurement synchronization. Thus, the proposed method presents a generalized factor graph for multi-sensor fusion. To evaluate and study different GNSS fusion strategies, we fuse GNSS measurements in loose and tight coupling with a speed sensor, IMU, and lidar-odometry. We employed datasets from measurement campaigns in Aachen, Duesseldorf, and Cologne in experimental studies and presented comprehensive discussions on sensor observations, smoother types, and hyperparameter tuning. Our results show that the proposed approach enables robust trajectory estimation in dense urban areas, where the classic multi-sensor fusion method fails due to sensor degradation. In a test sequence containing a 17km route through Aachen, the proposed method results in a mean 2D positioning error of 0.19m for loosely coupled GNSS fusion and 0.48m while fusing raw GNSS observations with lidar odometry in tight coupling. ",
    "url": "https://arxiv.org/abs/2309.11134",
    "authors": [
      "Haoming Zhang",
      "Chih-Chun Chen",
      "Heike Vallery",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.11143",
    "title": "CoT-BERT: Enhancing Unsupervised Sentence Representation through  Chain-of-Thought",
    "abstract": "Unsupervised sentence representation learning aims to transform input sentences into fixed-length vectors enriched with intricate semantic information while obviating the reliance on labeled data. Recent progress within this field, propelled by contrastive learning and prompt engineering, has significantly bridged the gap between unsupervised and supervised strategies. Nonetheless, the potential utilization of Chain-of-Thought, remains largely untapped within this trajectory. To unlock latent capabilities within pre-trained models, such as BERT, we propose a two-stage approach for sentence representation: comprehension and summarization. Subsequently, the output of the latter phase is harnessed as the vectorized representation of the input sentence. For further performance enhancement, we meticulously refine both the contrastive learning loss function and the template denoising technique for prompt engineering. Rigorous experimentation substantiates our method, CoT-BERT, transcending a suite of robust baselines without necessitating other text representation models or external databases. ",
    "url": "https://arxiv.org/abs/2309.11143",
    "authors": [
      "Bowen Zhang",
      "Kehua Chang",
      "Chunping Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11144",
    "title": "GL-Fusion: Global-Local Fusion Network for Multi-view Echocardiogram  Video Segmentation",
    "abstract": "Cardiac structure segmentation from echocardiogram videos plays a crucial role in diagnosing heart disease. The combination of multi-view echocardiogram data is essential to enhance the accuracy and robustness of automated methods. However, due to the visual disparity of the data, deriving cross-view context information remains a challenging task, and unsophisticated fusion strategies can even lower performance. In this study, we propose a novel Gobal-Local fusion (GL-Fusion) network to jointly utilize multi-view information globally and locally that improve the accuracy of echocardiogram analysis. Specifically, a Multi-view Global-based Fusion Module (MGFM) is proposed to extract global context information and to explore the cyclic relationship of different heartbeat cycles in an echocardiogram video. Additionally, a Multi-view Local-based Fusion Module (MLFM) is designed to extract correlations of cardiac structures from different views. Furthermore, we collect a multi-view echocardiogram video dataset (MvEVD) to evaluate our method. Our method achieves an 82.29% average dice score, which demonstrates a 7.83% improvement over the baseline method, and outperforms other existing state-of-the-art methods. To our knowledge, this is the first exploration of a multi-view method for echocardiogram video segmentation. Code available at: https://github.com/xmed-lab/GL-Fusion ",
    "url": "https://arxiv.org/abs/2309.11144",
    "authors": [
      "Ziyang Zheng",
      "Jiewen Yang",
      "Xinpeng Ding",
      "Xiaowei Xu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11157",
    "title": "Learning Deformable 3D Graph Similarity to Track Plant Cells in  Unregistered Time Lapse Images",
    "abstract": "Tracking of plant cells in images obtained by microscope is a challenging problem due to biological phenomena such as large number of cells, non-uniform growth of different layers of the tightly packed plant cells and cell division. Moreover, images in deeper layers of the tissue being noisy and unavoidable systemic errors inherent in the imaging process further complicates the problem. In this paper, we propose a novel learning-based method that exploits the tightly packed three-dimensional cell structure of plant cells to create a three-dimensional graph in order to perform accurate cell tracking. We further propose novel algorithms for cell division detection and effective three-dimensional registration, which improve upon the state-of-the-art algorithms. We demonstrate the efficacy of our algorithm in terms of tracking accuracy and inference-time on a benchmark dataset. ",
    "url": "https://arxiv.org/abs/2309.11157",
    "authors": [
      "Md Shazid Islam",
      "Arindam Dutta",
      "Calvin-Khang Ta",
      "Kevin Rodriguez",
      "Christian Michael",
      "Mark Alber",
      "G. Venugopala Reddy",
      "Amit K. Roy-Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11166",
    "title": "Are Large Language Models Really Robust to Word-Level Perturbations?",
    "abstract": "The swift advancement in the scale and capabilities of Large Language Models (LLMs) positions them as promising tools for a variety of downstream tasks. In addition to the pursuit of better performance and the avoidance of violent feedback on a certain prompt, to ensure the responsibility of the LLM, much attention is drawn to the robustness of LLMs. However, existing evaluation methods mostly rely on traditional question answering datasets with predefined supervised labels, which do not align with the superior generation capabilities of contemporary LLMs. To address this issue, we propose a novel rational evaluation approach that leverages pre-trained reward models as diagnostic tools to evaluate the robustness of LLMs, which we refer to as the Reward Model for Reasonable Robustness Evaluation (TREvaL). Our extensive empirical experiments have demonstrated that TREval provides an accurate method for evaluating the robustness of an LLM, especially when faced with more challenging open questions. Furthermore, our results demonstrate that LLMs frequently exhibit vulnerability to word-level perturbations, which are commonplace in daily language usage. Notably, we were surprised to discover that robustness tends to decrease as fine-tuning (SFT and RLHF) is conducted. The code of TREval is available in https://github.com/Harry-mic/TREval. ",
    "url": "https://arxiv.org/abs/2309.11166",
    "authors": [
      "Haoyu Wang",
      "Guozheng Ma",
      "Cong Yu",
      "Ning Gui",
      "Linrui Zhang",
      "Zhiqi Huang",
      "Suwei Ma",
      "Yongzhe Chang",
      "Sen Zhang",
      "Li Shen",
      "Xueqian Wang",
      "Peilin Zhao",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11177",
    "title": "Long-tail Augmented Graph Contrastive Learning for Recommendation",
    "abstract": "Graph Convolutional Networks (GCNs) has demonstrated promising results for recommender systems, as they can effectively leverage high-order relationship. However, these methods usually encounter data sparsity issue in real-world scenarios. To address this issue, GCN-based recommendation methods employ contrastive learning to introduce self-supervised signals. Despite their effectiveness, these methods lack consideration of the significant degree disparity between head and tail nodes. This can lead to non-uniform representation distribution, which is a crucial factor for the performance of contrastive learning methods. To tackle the above issue, we propose a novel Long-tail Augmented Graph Contrastive Learning (LAGCL) method for recommendation. Specifically, we introduce a learnable long-tail augmentation approach to enhance tail nodes by supplementing predicted neighbor information, and generate contrastive views based on the resulting augmented graph. To make the data augmentation schema learnable, we design an auto drop module to generate pseudo-tail nodes from head nodes and a knowledge transfer module to reconstruct the head nodes from pseudo-tail nodes. Additionally, we employ generative adversarial networks to ensure that the distribution of the generated tail/head nodes matches that of the original tail/head nodes. Extensive experiments conducted on three benchmark datasets demonstrate the significant improvement in performance of our model over the state-of-the-arts. Further analyses demonstrate the uniformity of learned representations and the superiority of LAGCL on long-tail performance. Code is publicly available at https://github.com/im0qianqian/LAGCL ",
    "url": "https://arxiv.org/abs/2309.11177",
    "authors": [
      "Qian Zhao",
      "Zhengwei Wu",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.11193",
    "title": "RHALE: Robust and Heterogeneity-aware Accumulated Local Effects",
    "abstract": "Accumulated Local Effects (ALE) is a widely-used explainability method for isolating the average effect of a feature on the output, because it handles cases with correlated features well. However, it has two limitations. First, it does not quantify the deviation of instance-level (local) effects from the average (global) effect, known as heterogeneity. Second, for estimating the average effect, it partitions the feature domain into user-defined, fixed-sized bins, where different bin sizes may lead to inconsistent ALE estimations. To address these limitations, we propose Robust and Heterogeneity-aware ALE (RHALE). RHALE quantifies the heterogeneity by considering the standard deviation of the local effects and automatically determines an optimal variable-size bin-splitting. In this paper, we prove that to achieve an unbiased approximation of the standard deviation of local effects within each bin, bin splitting must follow a set of sufficient conditions. Based on these conditions, we propose an algorithm that automatically determines the optimal partitioning, balancing the estimation bias and variance. Through evaluations on synthetic and real datasets, we demonstrate the superiority of RHALE compared to other methods, including the advantages of automatic bin splitting, especially in cases with correlated features. ",
    "url": "https://arxiv.org/abs/2309.11193",
    "authors": [
      "Vasilis Gkolemis",
      "Theodore Dalamagas",
      "Eirini Ntoutsi",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11196",
    "title": "When to Trust AI: Advances and Challenges for Certification of Neural  Networks",
    "abstract": "Artificial intelligence (AI) has been advancing at a fast pace and it is now poised for deployment in a wide range of applications, such as autonomous systems, medical diagnosis and natural language processing. Early adoption of AI technology for real-world applications has not been without problems, particularly for neural networks, which may be unstable and susceptible to adversarial examples. In the longer term, appropriate safety assurance techniques need to be developed to reduce potential harm due to avoidable system failures and ensure trustworthiness. Focusing on certification and explainability, this paper provides an overview of techniques that have been developed to ensure safety of AI decisions and discusses future challenges. ",
    "url": "https://arxiv.org/abs/2309.11196",
    "authors": [
      "Marta Kwiatkowska",
      "Xiyue Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2309.11206",
    "title": "Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for  Knowledge Graph Question Answering",
    "abstract": "Despite their competitive performance on knowledge-intensive tasks, large language models (LLMs) still have limitations in memorizing all world knowledge especially long tail knowledge. In this paper, we study the KG-augmented language model approach for solving the knowledge graph question answering (KGQA) task that requires rich world knowledge. Existing work has shown that retrieving KG knowledge to enhance LLMs prompting can significantly improve LLMs performance in KGQA. However, their approaches lack a well-formed verbalization of KG knowledge, i.e., they ignore the gap between KG representations and textual representations. To this end, we propose an answer-sensitive KG-to-Text approach that can transform KG knowledge into well-textualized statements most informative for KGQA. Based on this approach, we propose a KG-to-Text enhanced LLMs framework for solving the KGQA task. Experiments on several KGQA benchmarks show that the proposed KG-to-Text augmented LLMs approach outperforms previous KG-augmented LLMs approaches regarding answer accuracy and usefulness of knowledge statements. ",
    "url": "https://arxiv.org/abs/2309.11206",
    "authors": [
      "Yike Wu",
      "Nan Hu",
      "Sheng Bi",
      "Guilin Qi",
      "Jie Ren",
      "Anhuan Xie",
      "Wei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11218",
    "title": "Automatic Bat Call Classification using Transformer Networks",
    "abstract": "Automatically identifying bat species from their echolocation calls is a difficult but important task for monitoring bats and the ecosystem they live in. Major challenges in automatic bat call identification are high call variability, similarities between species, interfering calls and lack of annotated data. Many currently available models suffer from relatively poor performance on real-life data due to being trained on single call datasets and, moreover, are often too slow for real-time classification. Here, we propose a Transformer architecture for multi-label classification with potential applications in real-time classification scenarios. We train our model on synthetically generated multi-species recordings by merging multiple bats calls into a single recording with multiple simultaneous calls. Our approach achieves a single species accuracy of 88.92% (F1-score of 84.23%) and a multi species macro F1-score of 74.40% on our test set. In comparison to three other tools on the independent and publicly available dataset ChiroVox, our model achieves at least 25.82% better accuracy for single species classification and at least 6.9% better macro F1-score for multi species classification. ",
    "url": "https://arxiv.org/abs/2309.11218",
    "authors": [
      "Frank Fundel",
      "Daniel A. Braun",
      "Sebastian Gottwald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.11226",
    "title": "Towards a Prediction of Machine Learning Training Time to Support  Continuous Learning Systems Development",
    "abstract": "The problem of predicting the training time of machine learning (ML) models has become extremely relevant in the scientific community. Being able to predict a priori the training time of an ML model would enable the automatic selection of the best model both in terms of energy efficiency and in terms of performance in the context of, for instance, MLOps architectures. In this paper, we present the work we are conducting towards this direction. In particular, we present an extensive empirical study of the Full Parameter Time Complexity (FPTC) approach by Zheng et al., which is, to the best of our knowledge, the only approach formalizing the training time of ML models as a function of both dataset's and model's parameters. We study the formulations proposed for the Logistic Regression and Random Forest classifiers, and we highlight the main strengths and weaknesses of the approach. Finally, we observe how, from the conducted study, the prediction of training time is strictly related to the context (i.e., the involved dataset) and how the FPTC approach is not generalizable. ",
    "url": "https://arxiv.org/abs/2309.11226",
    "authors": [
      "Francesca Marzi",
      "Giordano d'Aloisio",
      "Antinisca Di Marco",
      "Giovanni Stilo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2309.11228",
    "title": "Towards Robust Few-shot Point Cloud Semantic Segmentation",
    "abstract": "Few-shot point cloud semantic segmentation aims to train a model to quickly adapt to new unseen classes with only a handful of support set samples. However, the noise-free assumption in the support set can be easily violated in many practical real-world settings. In this paper, we focus on improving the robustness of few-shot point cloud segmentation under the detrimental influence of noisy support sets during testing time. To this end, we first propose a Component-level Clean Noise Separation (CCNS) representation learning to learn discriminative feature representations that separates the clean samples of the target classes from the noisy samples. Leveraging the well separated clean and noisy support samples from our CCNS, we further propose a Multi-scale Degree-based Noise Suppression (MDNS) scheme to remove the noisy shots from the support set. We conduct extensive experiments on various noise settings on two benchmark datasets. Our results show that the combination of CCNS and MDNS significantly improves the performance. Our code is available at https://github.com/Pixie8888/R3DFSSeg. ",
    "url": "https://arxiv.org/abs/2309.11228",
    "authors": [
      "Yating Xu",
      "Na Zhao",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11248",
    "title": "Box2Poly: Memory-Efficient Polygon Prediction of Arbitrarily Shaped and  Rotated Text",
    "abstract": "Recently, Transformer-based text detection techniques have sought to predict polygons by encoding the coordinates of individual boundary vertices using distinct query features. However, this approach incurs a significant memory overhead and struggles to effectively capture the intricate relationships between vertices belonging to the same instance. Consequently, irregular text layouts often lead to the prediction of outlined vertices, diminishing the quality of results. To address these challenges, we present an innovative approach rooted in Sparse R-CNN: a cascade decoding pipeline for polygon prediction. Our method ensures precision by iteratively refining polygon predictions, considering both the scale and location of preceding results. Leveraging this stabilized regression pipeline, even employing just a single feature vector to guide polygon instance regression yields promising detection results. Simultaneously, the leverage of instance-level feature proposal substantially enhances memory efficiency (>50% less vs. the state-of-the-art method DPText-DETR) and reduces inference speed (>40% less vs. DPText-DETR) with minor performance drop on benchmarks. ",
    "url": "https://arxiv.org/abs/2309.11248",
    "authors": [
      "Xuyang Chen",
      "Dong Wang",
      "Konrad Schindler",
      "Mingwei Sun",
      "Yongliang Wang",
      "Nicolo Savioli",
      "Liqiu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11250",
    "title": "A Game-theoretic Approach for Provably-Uniform Random Number Generation  in Decentralized Networks",
    "abstract": "Many protocols in distributed computing rely on a source of randomness, usually called a random beacon, both for their applicability and security. This is especially true for proof-of-stake blockchain protocols in which the next miner or set of miners have to be chosen randomly and each party's likelihood to be selected is in proportion to their stake in the cryptocurrency. Current random beacons used in proof-of-stake protocols, such as Ouroboros and Algorand, have two fundamental limitations: Either (i)~they rely on pseudorandomness, e.g.~assuming that the output of a hash function is uniform, which is a widely-used but unproven assumption, or (ii)~they generate their randomness using a distributed protocol in which several participants are required to submit random numbers which are then used in the generation of a final random result. However, in this case, there is no guarantee that the numbers provided by the parties are uniformly random and there is no incentive for the parties to honestly generate uniform randomness. Most random beacons have both limitations. In this thesis, we provide a protocol for distributed generation of randomness. Our protocol does not rely on pseudorandomness at all. Similar to some of the previous approaches, it uses random inputs by different participants to generate a final random result. However, the crucial difference is that we provide a game-theoretic guarantee showing that it is in everyone's best interest to submit uniform random numbers. Hence, our approach is the first to incentivize honest behavior instead of just assuming it. Moreover, the approach is trustless and generates unbiased random numbers. It is also tamper-proof and no party can change the output or affect its distribution. Finally, it is designed with modularity in mind and can be easily plugged into existing distributed protocols such as proof-of-stake blockchains. ",
    "url": "https://arxiv.org/abs/2309.11250",
    "authors": [
      "Zhuo Cai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.11267",
    "title": "From Classification to Segmentation with Explainable AI: A Study on  Crack Detection and Growth Monitoring",
    "abstract": "Monitoring surface cracks in infrastructure is crucial for structural health monitoring. Automatic visual inspection offers an effective solution, especially in hard-to-reach areas. Machine learning approaches have proven their effectiveness but typically require large annotated datasets for supervised training. Once a crack is detected, monitoring its severity often demands precise segmentation of the damage. However, pixel-level annotation of images for segmentation is labor-intensive. To mitigate this cost, one can leverage explainable artificial intelligence (XAI) to derive segmentations from the explanations of a classifier, requiring only weak image-level supervision. This paper proposes applying this methodology to segment and monitor surface cracks. We evaluate the performance of various XAI methods and examine how this approach facilitates severity quantification and growth monitoring. Results reveal that while the resulting segmentation masks may exhibit lower quality than those produced by supervised methods, they remain meaningful and enable severity monitoring, thus reducing substantial labeling costs. ",
    "url": "https://arxiv.org/abs/2309.11267",
    "authors": [
      "Florent Forest",
      "Hugo Porta",
      "Devis Tuia",
      "Olga Fink"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.11271",
    "title": "Grounded Complex Task Segmentation for Conversational Assistants",
    "abstract": "Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step's characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructional text. Specifically, 86% of the evaluated tasks were improved from a conversational suitability point of view. ",
    "url": "https://arxiv.org/abs/2309.11271",
    "authors": [
      "Rafael Ferreira",
      "David Semedo",
      "Jo\u00e3o Magalh\u00e3es"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11276",
    "title": "Towards Real-Time Neural Video Codec for Cross-Platform Application  Using Calibration Information",
    "abstract": "The state-of-the-art neural video codecs have outperformed the most sophisticated traditional codecs in terms of RD performance in certain cases. However, utilizing them for practical applications is still challenging for two major reasons. 1) Cross-platform computational errors resulting from floating point operations can lead to inaccurate decoding of the bitstream. 2) The high computational complexity of the encoding and decoding process poses a challenge in achieving real-time performance. In this paper, we propose a real-time cross-platform neural video codec, which is capable of efficiently decoding of 720P video bitstream from other encoding platforms on a consumer-grade GPU. First, to solve the problem of inconsistency of codec caused by the uncertainty of floating point calculations across platforms, we design a calibration transmitting system to guarantee the consistent quantization of entropy parameters between the encoding and decoding stages. The parameters that may have transboundary quantization between encoding and decoding are identified in the encoding stage, and their coordinates will be delivered by auxiliary transmitted bitstream. By doing so, these inconsistent parameters can be processed properly in the decoding stage. Furthermore, to reduce the bitrate of the auxiliary bitstream, we rectify the distribution of entropy parameters using a piecewise Gaussian constraint. Second, to match the computational limitations on the decoding side for real-time video codec, we design a lightweight model. A series of efficiency techniques enable our model to achieve 25 FPS decoding speed on NVIDIA RTX 2080 GPU. Experimental results demonstrate that our model can achieve real-time decoding of 720P videos while encoding on another platform. Furthermore, the real-time model brings up to a maximum of 24.2\\% BD-rate improvement from the perspective of PSNR with the anchor H.265. ",
    "url": "https://arxiv.org/abs/2309.11276",
    "authors": [
      "Kuan Tian",
      "Yonghang Guan",
      "Jinxi Xiang",
      "Jun Zhang",
      "Xiao Han",
      "Wei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.11281",
    "title": "Language-driven Object Fusion into Neural Radiance Fields with  Pose-Conditioned Dataset Updates",
    "abstract": "Neural radiance field is an emerging rendering method that generates high-quality multi-view consistent images from a neural scene representation and volume rendering. Although neural radiance field-based techniques are robust for scene reconstruction, their ability to add or remove objects remains limited. This paper proposes a new language-driven approach for object manipulation with neural radiance fields through dataset updates. Specifically, to insert a new foreground object represented by a set of multi-view images into a background radiance field, we use a text-to-image diffusion model to learn and generate combined images that fuse the object of interest into the given background across views. These combined images are then used for refining the background radiance field so that we can render view-consistent images containing both the object and the background. To ensure view consistency, we propose a dataset updates strategy that prioritizes radiance field training with camera views close to the already-trained views prior to propagating the training to remaining views. We show that under the same dataset updates strategy, we can easily adapt our method for object insertion using data from text-to-3D models as well as object removal. Experimental results show that our method generates photorealistic images of the edited scenes, and outperforms state-of-the-art methods in 3D reconstruction and neural radiance field blending. ",
    "url": "https://arxiv.org/abs/2309.11281",
    "authors": [
      "Ka Chun Shum",
      "Jaeyeon Kim",
      "Binh-Son Hua",
      "Duc Thanh Nguyen",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11285",
    "title": "Overview of AuTexTification at IberLEF 2023: Detection and Attribution  of Machine-Generated Text in Multiple Domains",
    "abstract": "This paper presents the overview of the AuTexTification shared task as part of the IberLEF 2023 Workshop in Iberian Languages Evaluation Forum, within the framework of the SEPLN 2023 conference. AuTexTification consists of two subtasks: for Subtask 1, participants had to determine whether a text is human-authored or has been generated by a large language model. For Subtask 2, participants had to attribute a machine-generated text to one of six different text generation models. Our AuTexTification 2023 dataset contains more than 160.000 texts across two languages (English and Spanish) and five domains (tweets, reviews, news, legal, and how-to articles). A total of 114 teams signed up to participate, of which 36 sent 175 runs, and 20 of them sent their working notes. In this overview, we present the AuTexTification dataset and task, the submitted participating systems, and the results. ",
    "url": "https://arxiv.org/abs/2309.11285",
    "authors": [
      "Areg Mikael Sarvazyan",
      "Jos\u00e9 \u00c1ngel Gonz\u00e1lez",
      "Marc Franco-Salvador",
      "Francisco Rangel",
      "Berta Chulvi",
      "Paolo Rosso"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11294",
    "title": "Beyond Accuracy: Measuring Representation Capacity of Embeddings to  Preserve Structural and Contextual Information",
    "abstract": "Effective representation of data is crucial in various machine learning tasks, as it captures the underlying structure and context of the data. Embeddings have emerged as a powerful technique for data representation, but evaluating their quality and capacity to preserve structural and contextual information remains a challenge. In this paper, we address this need by proposing a method to measure the \\textit{representation capacity} of embeddings. The motivation behind this work stems from the importance of understanding the strengths and limitations of embeddings, enabling researchers and practitioners to make informed decisions in selecting appropriate embedding models for their specific applications. By combining extrinsic evaluation methods, such as classification and clustering, with t-SNE-based neighborhood analysis, such as neighborhood agreement and trustworthiness, we provide a comprehensive assessment of the representation capacity. Additionally, the use of optimization techniques (bayesian optimization) for weight optimization (for classification, clustering, neighborhood agreement, and trustworthiness) ensures an objective and data-driven approach in selecting the optimal combination of metrics. The proposed method not only contributes to advancing the field of embedding evaluation but also empowers researchers and practitioners with a quantitative measure to assess the effectiveness of embeddings in capturing structural and contextual information. For the evaluation, we use $3$ real-world biological sequence (proteins and nucleotide) datasets and performed representation capacity analysis of $4$ embedding methods from the literature, namely Spike2Vec, Spaced $k$-mers, PWM2Vec, and AutoEncoder. ",
    "url": "https://arxiv.org/abs/2309.11294",
    "authors": [
      "Sarwan Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11295",
    "title": "CPLLM: Clinical Prediction with Large Language Models",
    "abstract": "We present Clinical Prediction with Large Language Models (CPLLM), a method that involves fine-tuning a pre-trained Large Language Model (LLM) for clinical disease prediction. We utilized quantization and fine-tuned the LLM using prompts, with the task of predicting whether patients will be diagnosed with a target disease during their next visit or in the subsequent diagnosis, leveraging their historical diagnosis records. We compared our results versus various baselines, including Logistic Regression, RETAIN, and Med-BERT, which is the current state-of-the-art model for disease prediction using structured EHR data. Our experiments have shown that CPLLM surpasses all the tested models in terms of both PR-AUC and ROC-AUC metrics, displaying noteworthy enhancements compared to the baseline models. ",
    "url": "https://arxiv.org/abs/2309.11295",
    "authors": [
      "Ofir Ben Shoham",
      "Nadav Rappoport"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11307",
    "title": "Rating Prediction in Conversational Task Assistants with Behavioral and  Conversational-Flow Features",
    "abstract": "Predicting the success of Conversational Task Assistants (CTA) can be critical to understand user behavior and act accordingly. In this paper, we propose TB-Rater, a Transformer model which combines conversational-flow features with user behavior features for predicting user ratings in a CTA scenario. In particular, we use real human-agent conversations and ratings collected in the Alexa TaskBot challenge, a novel multimodal and multi-turn conversational context. Our results show the advantages of modeling both the conversational-flow and behavioral aspects of the conversation in a single model for offline rating prediction. Additionally, an analysis of the CTA-specific behavioral features brings insights into this setting and can be used to bootstrap future systems. ",
    "url": "https://arxiv.org/abs/2309.11307",
    "authors": [
      "Rafael Ferreira",
      "David Semedo",
      "Jo\u00e3o Magalh\u00e3es"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11310",
    "title": "Social interactions for a sustainable lifestyle: The design of an  experimental case study",
    "abstract": "Every day we face numerous lifestyle decisions, some dictated by habits and some more conscious, which may or may not promote sustainable living. Aided by digital technology, sustainable behaviors can diffuse within social groups and inclusive communities. This paper outlines a longitudinal experimental study of social influence in behavioral changes toward sustainability, in the context of smart residential homes. Participants are residing in the housing on campus referred to as KTH Live-In Lab, whose behaviors are observed w.r.t. key lifestyle choices, such as food, resources, mobility, consumption, and environmental citizenship. The focus is on the preparatory phase of the case study and the challenges and limitations encountered during its setup. In particular, this work proposes a definition of sustainability indicators for environmentally significant behaviors, and hypothesizes that, through digitalization of a household into a social network of interacting tenants, sustainable living can be promoted. Preliminary results confirm the feasibility of the proposed experimental methodology. ",
    "url": "https://arxiv.org/abs/2309.11310",
    "authors": [
      "Angela Fontan",
      "Mahsa Farjadnia",
      "Joe Llewellyn",
      "Cecilia Katzeff",
      "Marco Molinari",
      "Vladimir Cvetkovic",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.11341",
    "title": "Improving Article Classification with Edge-Heterogeneous Graph Neural  Networks",
    "abstract": "Classifying research output into context-specific label taxonomies is a challenging and relevant downstream task, given the volume of existing and newly published articles. We propose a method to enhance the performance of article classification by enriching simple Graph Neural Networks (GNN) pipelines with edge-heterogeneous graph representations. SciBERT is used for node feature generation to capture higher-order semantics within the articles' textual metadata. Fully supervised transductive node classification experiments are conducted on the Open Graph Benchmark (OGB) ogbn-arxiv dataset and the PubMed diabetes dataset, augmented with additional metadata from Microsoft Academic Graph (MAG) and PubMed Central, respectively. The results demonstrate that edge-heterogeneous graphs consistently improve the performance of all GNN models compared to the edge-homogeneous graphs. The transformed data enable simple and shallow GNN pipelines to achieve results on par with more complex architectures. On ogbn-arxiv, we achieve a top-15 result in the OGB competition with a 2-layer GCN (accuracy 74.61%), being the highest-scoring solution with sub-1 million parameters. On PubMed, we closely trail SOTA GNN architectures using a 2-layer GraphSAGE by including additional co-authorship edges in the graph (accuracy 89.88%). The implementation is available at: $\\href{https://github.com/lyvykhang/edgehetero-nodeproppred}{\\text{https://github.com/lyvykhang/edgehetero-nodeproppred}}$. ",
    "url": "https://arxiv.org/abs/2309.11341",
    "authors": [
      "Khang Ly",
      "Yury Kashnitsky",
      "Savvas Chamezopoulos",
      "Valeria Krzhizhanovskaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11346",
    "title": "GECTurk: Grammatical Error Correction and Detection Dataset for Turkish",
    "abstract": "Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners. Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages. Synthetic data generation is a common practice to overcome the scarcity of such data. However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information. In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions. Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles. Additionally, we create a more realistic test set by manually annotating a set of movie reviews. We implement three baselines formulating the task as i) neural machine translation, ii) sequence tagging, and iii) prefix tuning with a pretrained decoder-only model, achieving strong results. Furthermore, we perform exhaustive experiments on out-of-domain datasets to gain insights on the transferability and robustness of the proposed approaches. Our results suggest that our corpus, GECTurk, is high-quality and allows knowledge transfer for the out-of-domain setting. To encourage further research on Turkish GEC, we release our datasets, baseline models, and the synthetic data generation pipeline at https://github.com/GGLAB-KU/gecturk. ",
    "url": "https://arxiv.org/abs/2309.11346",
    "authors": [
      "Atakan Kara",
      "Farrin Marouf Sofian",
      "Andrew Bond",
      "G\u00f6zde G\u00fcl \u015eahin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11351",
    "title": "C$\\cdot$ASE: Learning Conditional Adversarial Skill Embeddings for  Physics-based Characters",
    "abstract": "We present C$\\cdot$ASE, an efficient and effective framework that learns conditional Adversarial Skill Embeddings for physics-based characters. Our physically simulated character can learn a diverse repertoire of skills while providing controllability in the form of direct manipulation of the skills to be performed. C$\\cdot$ASE divides the heterogeneous skill motions into distinct subsets containing homogeneous samples for training a low-level conditional model to learn conditional behavior distribution. The skill-conditioned imitation learning naturally offers explicit control over the character's skills after training. The training course incorporates the focal skill sampling, skeletal residual forces, and element-wise feature masking to balance diverse skills of varying complexities, mitigate dynamics mismatch to master agile motions and capture more general behavior characteristics, respectively. Once trained, the conditional model can produce highly diverse and realistic skills, outperforming state-of-the-art models, and can be repurposed in various downstream tasks. In particular, the explicit skill control handle allows a high-level policy or user to direct the character with desired skill specifications, which we demonstrate is advantageous for interactive character animation. ",
    "url": "https://arxiv.org/abs/2309.11351",
    "authors": [
      "Zhiyang Dou",
      "Xuelin Chen",
      "Qingnan Fan",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11354",
    "title": "Self-supervised learning unveils change in urban housing from  street-level images",
    "abstract": "Cities around the world face a critical shortage of affordable and decent housing. Despite its critical importance for policy, our ability to effectively monitor and track progress in urban housing is limited. Deep learning-based computer vision methods applied to street-level images have been successful in the measurement of socioeconomic and environmental inequalities but did not fully utilize temporal images to track urban change as time-varying labels are often unavailable. We used self-supervised methods to measure change in London using 15 million street images taken between 2008 and 2021. Our novel adaptation of Barlow Twins, Street2Vec, embeds urban structure while being invariant to seasonal and daily changes without manual annotations. It outperformed generic embeddings, successfully identified point-level change in London's housing supply from street-level images, and distinguished between major and minor change. This capability can provide timely information for urban planning and policy decisions toward more liveable, equitable, and sustainable cities. ",
    "url": "https://arxiv.org/abs/2309.11354",
    "authors": [
      "Steven Stalder",
      "Michele Volpi",
      "Nicolas B\u00fcttner",
      "Stephen Law",
      "Kenneth Harttgen",
      "Esra Suel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11356",
    "title": "A Comprehensive Survey on Rare Event Prediction",
    "abstract": "Rare event prediction involves identifying and forecasting events with a low probability using machine learning and data analysis. Due to the imbalanced data distributions, where the frequency of common events vastly outweighs that of rare events, it requires using specialized methods within each step of the machine learning pipeline, i.e., from data processing to algorithms to evaluation protocols. Predicting the occurrences of rare events is important for real-world applications, such as Industry 4.0, and is an active research area in statistical and machine learning. This paper comprehensively reviews the current approaches for rare event prediction along four dimensions: rare event data, data processing, algorithmic approaches, and evaluation approaches. Specifically, we consider 73 datasets from different modalities (i.e., numerical, image, text, and audio), four major categories of data processing, five major algorithmic groupings, and two broader evaluation approaches. This paper aims to identify gaps in the current literature and highlight the challenges of predicting rare events. It also suggests potential research directions, which can help guide practitioners and researchers. ",
    "url": "https://arxiv.org/abs/2309.11356",
    "authors": [
      "Chathurangi Shyalika",
      "Ruwan Wickramarachchi",
      "Amit Sheth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11361",
    "title": "Knowledge Graph Question Answering for Materials Science (KGQA4MAT):  Developing Natural Language Interface for Metal-Organic Frameworks Knowledge  Graph (MOF-KG)",
    "abstract": "We present a comprehensive benchmark dataset for Knowledge Graph Question Answering in Materials Science (KGQA4MAT), with a focus on metal-organic frameworks (MOFs). A knowledge graph for metal-organic frameworks (MOF-KG) has been constructed by integrating structured databases and knowledge extracted from the literature. To enhance MOF-KG accessibility for domain experts, we aim to develop a natural language interface for querying the knowledge graph. We have developed a benchmark comprised of 161 complex questions involving comparison, aggregation, and complicated graph structures. Each question is rephrased in three additional variations, resulting in 644 questions and 161 KG queries. To evaluate the benchmark, we have developed a systematic approach for utilizing ChatGPT to translate natural language questions into formal KG queries. We also apply the approach to the well-known QALD-9 dataset, demonstrating ChatGPT's potential in addressing KGQA issues for different platforms and query languages. The benchmark and the proposed approach aim to stimulate further research and development of user-friendly and efficient interfaces for querying domain-specific materials science knowledge graphs, thereby accelerating the discovery of novel materials. ",
    "url": "https://arxiv.org/abs/2309.11361",
    "authors": [
      "Yuan An",
      "Jane Greenberg",
      "Alex Kalinowski",
      "Xintong Zhao",
      "Xiaohua Hu",
      "Fernando J. Uribe-Romo",
      "Kyle Langlois",
      "Jacob Furst",
      "Diego A. G\u00f3mez-Gualdr\u00f3n"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11363",
    "title": "Robert's theorem and graphs on complete lattices",
    "abstract": "Automata networks, and in particular Boolean networks, are used to model diverse networks of interacting entities. The interaction graph of an automata network is its most important parameter, as it represents the overall architecture of the network. A continuous amount of work has been devoted to infer dynamical properties of the automata network based on its interaction graph only. Robert's theorem is the seminal result in this area; it states that automata networks with an acyclic interaction graph converge to a unique fixed point. The feedback bound can be viewed as an extension of Robert's theorem; it gives an upper bound on the number of fixed points of an automata network based on the size of a minimum feedback vertex set of its interaction graph. Boolean networks can be viewed as self-mappings on the power set lattice of the set of entities. In this paper, we consider self-mappings on a general complete lattice. We make two conceptual contributions. Firstly, we can view a digraph as a residuated mapping on the power set lattice; as such, we define a graph on a complete lattice as a residuated mapping on that lattice. We extend and generalise some results on digraphs to our setting. Secondly, we introduce a generalised notion of dependency whereby any mapping $\\phi$ can depend on any other mapping $\\alpha$. In fact, we are able to give four kinds of dependency in this case. We can then vastly expand Robert's theorem to self-mappings on general complete lattices; we similarly generalise the feedback bound. We then obtain stronger results in the case where the lattice is a complete Boolean algebra. We finally show how our results can be applied to prove the convergence of automata networks. ",
    "url": "https://arxiv.org/abs/2309.11363",
    "authors": [
      "Maximilien Gadouleau"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2309.11366",
    "title": "Single-Exponential FPT Algorithms for Enumerating Secluded  $\\mathcal{F}$-Free Subgraphs and Deleting to Scattered Graph Classes",
    "abstract": "The celebrated notion of important separators bounds the number of small $(S,T)$-separators in a graph which are 'farthest from $S$' in a technical sense. In this paper, we introduce a generalization of this powerful algorithmic primitive that is phrased in terms of $k$-secluded vertex sets: sets with an open neighborhood of size at most $k$. In this terminology, the bound on important separators says that there are at most $4^k$ maximal $k$-secluded connected vertex sets $C$ containing $S$ but disjoint from $T$. We generalize this statement significantly: even when we demand that $G[C]$ avoids a finite set $\\mathcal{F}$ of forbidden induced subgraphs, the number of such maximal subgraphs is $2^{O(k)}$ and they can be enumerated efficiently. This allows us to make significant improvements for two problems from the literature. Our first application concerns the 'Connected $k$-Secluded $\\mathcal{F}$-free subgraph' problem, where $\\mathcal{F}$ is a finite set of forbidden induced subgraphs. Given a graph in which each vertex has a positive integer weight, the problem asks to find a maximum-weight connected $k$-secluded vertex set $C \\subseteq V(G)$ such that $G[C]$ does not contain an induced subgraph isomorphic to any $F \\in \\mathcal{F}$. The parameterization by $k$ is known to be solvable in triple-exponential time via the technique of recursive understanding, which we improve to single-exponential. Our second application concerns the deletion problem to scattered graph classes. Here, the task is to find a vertex set of size at most $k$ whose removal yields a graph whose each connected component belongs to one of the prescribed graph classes $\\Pi_1, \\ldots, \\Pi_d$. We obtain a single-exponential algorithm whenever each class $\\Pi_i$ is characterized by a finite number of forbidden induced subgraphs. This generalizes and improves upon earlier results in the literature. ",
    "url": "https://arxiv.org/abs/2309.11366",
    "authors": [
      "Bart M. P. Jansen",
      "Jari J. H. de Kroon",
      "Micha\u0142 W\u0142odarczyk"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.11373",
    "title": "Learning Patient Static Information from Time-series EHR and an Approach  for Safeguarding Privacy and Fairness",
    "abstract": "Recent work in machine learning for healthcare has raised concerns about patient privacy and algorithmic fairness. For example, previous work has shown that patient self-reported race can be predicted from medical data that does not explicitly contain racial information. However, the extent of data identification is unknown, and we lack ways to develop models whose outcomes are minimally affected by such information. Here we systematically investigated the ability of time-series electronic health record data to predict patient static information. We found that not only the raw time-series data, but also learned representations from machine learning models, can be trained to predict a variety of static information with area under the receiver operating characteristic curve as high as 0.851 for biological sex, 0.869 for binarized age and 0.810 for self-reported race. Such high predictive performance can be extended to a wide range of comorbidity factors and exists even when the model was trained for different tasks, using different cohorts, using different model architectures and databases. Given the privacy and fairness concerns these findings pose, we develop a variational autoencoder-based approach that learns a structured latent space to disentangle patient-sensitive attributes from time-series data. Our work thoroughly investigates the ability of machine learning models to encode patient static information from time-series electronic health records and introduces a general approach to protect patient-sensitive attribute information for downstream tasks. ",
    "url": "https://arxiv.org/abs/2309.11373",
    "authors": [
      "Wei Liao",
      "Joel Voldman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.11385",
    "title": "Safurai 001: New Qualitative Approach for Code LLM Evaluation",
    "abstract": "This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance. Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al., 2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more conversational interaction. By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments. Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance. Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% in the Code Readability parameter and more. ",
    "url": "https://arxiv.org/abs/2309.11385",
    "authors": [
      "Davide Cifarelli",
      "Leonardo Boiardi",
      "Alessandro Puppo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11411",
    "title": "Distributed Finite-Time Cooperative Localization for Three-Dimensional  Sensor Networks",
    "abstract": "This paper addresses the distributed localization problem for a network of sensors placed in a three-dimensional space, in which sensors are able to perform range measurements, i.e., measure the relative distance between them, and exchange information on a network structure. First, we derive a necessary and sufficient condition for node localizability using barycentric coordinates. Then, building on this theoretical result, we design a distributed localizability verification algorithm, in which we propose and employ a novel distributed finite-time algorithm for sum consensus. Finally, we develop a distributed localization algorithm based on conjugate gradient method, and we derive a theoretical guarantee on its performance, which ensures finite-time convergence to the exact position for all localizable nodes. The efficiency of our algorithm compared to the existing ones from the state-of-the-art literature is further demonstrated through numerical simulations. ",
    "url": "https://arxiv.org/abs/2309.11411",
    "authors": [
      "Jinze Wu",
      "Lorenzo Zino",
      "Zhiyun Lin",
      "Alessandro Rizzo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.11413",
    "title": "Enhancing motion trajectory segmentation of rigid bodies using a novel  screw-based trajectory-shape representation",
    "abstract": "Trajectory segmentation refers to dividing a trajectory into meaningful consecutive sub-trajectories. This paper focuses on trajectory segmentation for 3D rigid-body motions. Most segmentation approaches in the literature represent the body's trajectory as a point trajectory, considering only its translation and neglecting its rotation. We propose a novel trajectory representation for rigid-body motions that incorporates both translation and rotation, and additionally exhibits several invariant properties. This representation consists of a geometric progress rate and a third-order trajectory-shape descriptor. Concepts from screw theory were used to make this representation time-invariant and also invariant to the choice of body reference point. This new representation is validated for a self-supervised segmentation approach, both in simulation and using real recordings of human-demonstrated pouring motions. The results show a more robust detection of consecutive submotions with distinct features and a more consistent segmentation compared to conventional representations. We believe that other existing segmentation methods may benefit from using this trajectory representation to improve their invariance. ",
    "url": "https://arxiv.org/abs/2309.11413",
    "authors": [
      "Arno Verduyn",
      "Maxim Vochten",
      "Joris De Schutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11420",
    "title": "Deep Networks as Denoising Algorithms: Sample-Efficient Learning of  Diffusion Models in High-Dimensional Graphical Models",
    "abstract": "We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling. While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data. This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished. To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms. Furthermore, these algorithms are amenable to efficient neural network representation. We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models. Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample complexity bound for diffusion-based generative modeling when the score function is learned by deep neural networks. ",
    "url": "https://arxiv.org/abs/2309.11420",
    "authors": [
      "Song Mei",
      "Yuchen Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.11427",
    "title": "Generative Pre-Training of Time-Series Data for Unsupervised Fault  Detection in Semiconductor Manufacturing",
    "abstract": "This paper introduces TRACE-GPT, which stands for Time-seRies Anomaly-detection with Convolutional Embedding and Generative Pre-trained Transformers. TRACE-GPT is designed to pre-train univariate time-series sensor data and detect faults on unlabeled datasets in semiconductor manufacturing. In semiconductor industry, classifying abnormal time-series sensor data from normal data is important because it is directly related to wafer defect. However, small, unlabeled, and even mixed training data without enough anomalies make classification tasks difficult. In this research, we capture features of time-series data with temporal convolutional embedding and Generative Pre-trained Transformer (GPT) to classify abnormal sequences from normal sequences using cross entropy loss. We prove that our model shows better performance than previous unsupervised models with both an open dataset, the University of California Riverside (UCR) time-series classification archive, and the process log of our Chemical Vapor Deposition (CVD) equipment. Our model has the highest F1 score at Equal Error Rate (EER) across all datasets and is only 0.026 below the supervised state-of-the-art baseline on the open dataset. ",
    "url": "https://arxiv.org/abs/2309.11427",
    "authors": [
      "Sewoong Lee",
      "JinKyou Choi",
      "Min Su Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11453",
    "title": "Multi-Step Model Predictive Safety Filters: Reducing Chattering by  Increasing the Prediction Horizon",
    "abstract": "Learning-based controllers have demonstrated superior performance compared to classical controllers in various tasks. However, providing safety guarantees is not trivial. Safety, the satisfaction of state and input constraints, can be guaranteed by augmenting the learned control policy with a safety filter. Model predictive safety filters (MPSFs) are a common safety filtering approach based on model predictive control (MPC). MPSFs seek to guarantee safety while minimizing the difference between the proposed and applied inputs in the immediate next time step. This limited foresight can lead to jerky motions and undesired oscillations close to constraint boundaries, known as chattering. In this paper, we reduce chattering by considering input corrections over a longer horizon. Under the assumption of bounded model uncertainties, we prove recursive feasibility using techniques from robust MPC. We verified the proposed approach in both extensive simulation and quadrotor experiments. In experiments with a Crazyflie 2.0 drone, we show that, in addition to preserving the desired safety guarantees, the proposed MPSF reduces chattering by more than a factor of 4 compared to previous MPSF formulations. ",
    "url": "https://arxiv.org/abs/2309.11453",
    "authors": [
      "Federico Pizarro Bejarano",
      "Lukas Brunke",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.11454",
    "title": "NeighViz: Towards Better Understanding of Neighborhood Effects on Social  Groups with Spatial Data",
    "abstract": "Understanding how local environments influence individual behaviors, such as voting patterns or suicidal tendencies, is crucial in social science to reveal and reduce spatial disparities and promote social well-being. With the increasing availability of large-scale individual-level census data, new analytical opportunities arise for social scientists to explore human behaviors (e.g., political engagement) among social groups at a fine-grained level. However, traditional statistical methods mostly focus on global, aggregated spatial correlations, which are limited to understanding and comparing the impact of local environments (e.g., neighborhoods) on human behaviors among social groups. In this study, we introduce a new analytical framework for analyzing multi-variate neighborhood effects between social groups. We then propose NeighVi, an interactive visual analytics system that helps social scientists explore, understand, and verify the influence of neighborhood effects on human behaviors. Finally, we use a case study to illustrate the effectiveness and usability of our system. ",
    "url": "https://arxiv.org/abs/2309.11454",
    "authors": [
      "Yue Yu",
      "Yifang Wang",
      "Qisen Yang",
      "Di Weng",
      "Yongjun Zhang",
      "Xiaogang Wu",
      "Yingcai Wu",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.11456",
    "title": "Generative Agent-Based Modeling: Unveiling Social System Dynamics  through Coupling Mechanistic Models with Generative Artificial Intelligence",
    "abstract": "We discuss the emerging new opportunity for building feedback-rich computational models of social systems using generative artificial intelligence. Referred to as Generative Agent-Based Models (GABMs), such individual-level models utilize large language models such as ChatGPT to represent human decision-making in social settings. We provide a GABM case in which human behavior can be incorporated in simulation models by coupling a mechanistic model of human interactions with a pre-trained large language model. This is achieved by introducing a simple GABM of social norm diffusion in an organization. For educational purposes, the model is intentionally kept simple. We examine a wide range of scenarios and the sensitivity of the results to several changes in the prompt. We hope the article and the model serve as a guide for building useful diffusion models that include realistic human reasoning and decision-making. ",
    "url": "https://arxiv.org/abs/2309.11456",
    "authors": [
      "Navid Ghaffarzadegan",
      "Aritra Majumdar",
      "Ross Williams",
      "Niyousha Hosseinichimeh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2309.11462",
    "title": "AudioFool: Fast, Universal and synchronization-free Cross-Domain Attack  on Speech Recognition",
    "abstract": "Automatic Speech Recognition systems have been shown to be vulnerable to adversarial attacks that manipulate the command executed on the device. Recent research has focused on exploring methods to create such attacks, however, some issues relating to Over-The-Air (OTA) attacks have not been properly addressed. In our work, we examine the needed properties of robust attacks compatible with the OTA model, and we design a method of generating attacks with arbitrary such desired properties, namely the invariance to synchronization, and the robustness to filtering: this allows a Denial-of-Service (DoS) attack against ASR systems. We achieve these characteristics by constructing attacks in a modified frequency domain through an inverse Fourier transform. We evaluate our method on standard keyword classification tasks and analyze it in OTA, and we analyze the properties of the cross-domain attacks to explain the efficiency of the approach. ",
    "url": "https://arxiv.org/abs/2309.11462",
    "authors": [
      "Mohamad Fakih",
      "Rouwaida Kanj",
      "Fadi Kurdahi",
      "Mohammed E. Fouda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.11470",
    "title": "Model-free tracking control of complex dynamical trajectories with  machine learning",
    "abstract": "Nonlinear tracking control enabling a dynamical system to track a desired trajectory is fundamental to robotics, serving a wide range of civil and defense applications. In control engineering, designing tracking control requires complete knowledge of the system model and equations. We develop a model-free, machine-learning framework to control a two-arm robotic manipulator using only partially observed states, where the controller is realized by reservoir computing. Stochastic input is exploited for training, which consists of the observed partial state vector as the first and its immediate future as the second component so that the neural machine regards the latter as the future state of the former. In the testing (deployment) phase, the immediate-future component is replaced by the desired observational vector from the reference trajectory. We demonstrate the effectiveness of the control framework using a variety of periodic and chaotic signals, and establish its robustness against measurement noise, disturbances, and uncertainties. ",
    "url": "https://arxiv.org/abs/2309.11470",
    "authors": [
      "Zheng-Meng Zhai",
      "Mohammadamin Moradi",
      "Ling-Wei Kong",
      "Bryan Glaz",
      "Mulugeta Haile",
      "Ying-Cheng Lai"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2309.11473",
    "title": "Multi-view Fuzzy Representation Learning with Rules based Model",
    "abstract": "Unsupervised multi-view representation learning has been extensively studied for mining multi-view data. However, some critical challenges remain. On the one hand, the existing methods cannot explore multi-view data comprehensively since they usually learn a common representation between views, given that multi-view data contains both the common information between views and the specific information within each view. On the other hand, to mine the nonlinear relationship between data, kernel or neural network methods are commonly used for multi-view representation learning. However, these methods are lacking in interpretability. To this end, this paper proposes a new multi-view fuzzy representation learning method based on the interpretable Takagi-Sugeno-Kang (TSK) fuzzy system (MVRL_FS). The method realizes multi-view representation learning from two aspects. First, multi-view data are transformed into a high-dimensional fuzzy feature space, while the common information between views and specific information of each view are explored simultaneously. Second, a new regularization method based on L_(2,1)-norm regression is proposed to mine the consistency information between views, while the geometric structure of the data is preserved through the Laplacian graph. Finally, extensive experiments on many benchmark multi-view datasets are conducted to validate the superiority of the proposed method. ",
    "url": "https://arxiv.org/abs/2309.11473",
    "authors": [
      "Wei Zhang",
      "Zhaohong Deng",
      "Te Zhang",
      "Kup-Sze Choi",
      "Shitong Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11477",
    "title": "Multi-Agent Robust Control Synthesis from Global Temporal Logic Tasks",
    "abstract": "This paper focuses on the heterogeneous multi-agent control problem under global temporal logic tasks. We define a specification language, called extended capacity temporal logic (ECaTL), to describe the required global tasks, including the number of times that a local or coupled signal temporal logic (STL) task needs to be satisfied and the synchronous requirements on task satisfaction. The robustness measure for ECaTL is formally designed. In particular, the robustness for synchronous tasks is evaluated from both the temporal and spatial perspectives. Mixed-integer linear constraints are designed to encode ECaTL specifications, and a two-step optimization framework is further proposed to realize task-satisfied motion planning with high spatial robustness and synchronicity. Simulations are conducted to demonstrate the expressivity of ECaTL and the efficiency of the proposed control synthesis approach. ",
    "url": "https://arxiv.org/abs/2309.11477",
    "authors": [
      "Tiange Yang",
      "Yuanyuan Zou",
      "Jinfeng Liu",
      "Tianyu Jia",
      "Shaoyuan Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.11478",
    "title": "Fictional Worlds, Real Connections: Developing Community Storytelling  Social Chatbots through LLMs",
    "abstract": "We address the integration of storytelling and Large Language Models (LLMs) to develop engaging and believable Social Chatbots (SCs) in community settings. Motivated by the potential of fictional characters to enhance social interactions, we introduce Storytelling Social Chatbots (SSCs) and the concept of story engineering to transform fictional game characters into \"live\" social entities within player communities. Our story engineering process includes three steps: (1) Character and story creation, defining the SC's personality and worldview, (2) Presenting Live Stories to the Community, allowing the SC to recount challenges and seek suggestions, and (3) Communication with community members, enabling interaction between the SC and users. We employed the LLM GPT-3 to drive our SSC prototypes, \"David\" and \"Catherine,\" and evaluated their performance in an online gaming community, \"DE (Alias),\" on Discord. Our mixed-method analysis, based on questionnaires (N=15) and interviews (N=8) with community members, reveals that storytelling significantly enhances the engagement and believability of SCs in community settings. ",
    "url": "https://arxiv.org/abs/2309.11478",
    "authors": [
      "Yuqian Sun",
      "Hanyi Wang",
      "Pok Man Chan",
      "Morteza Tabibi",
      "Yan Zhang",
      "Huan Lu",
      "Yuheng Chen",
      "Chang Hee Lee",
      "Ali Asadipour"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11484",
    "title": "Bravo MaRDI: A Wikibase Powered Knowledge Graph on Mathematics",
    "abstract": "Mathematical world knowledge is a fundamental component of Wikidata. However, to date, no expertly curated knowledge graph has focused specifically on contemporary mathematics. Addressing this gap, the Mathematical Research Data Initiative (MaRDI) has developed a comprehensive knowledge graph that links multimodal research data in mathematics. This encompasses traditional research data items like datasets, software, and publications and includes semantically advanced objects such as mathematical formulas and hypotheses. This paper details the abilities of the MaRDI knowledge graph, which is based on Wikibase, leading up to its inaugural public release, codenamed Bravo, available on https://portal.mardi4nfdi.de. ",
    "url": "https://arxiv.org/abs/2309.11484",
    "authors": [
      "Moritz Schubotz",
      "Eloi Ferrer",
      "Johannes Stegm\u00fcller",
      "Daniel Mietchen",
      "Olaf Teschke",
      "Larissa Pusch",
      "Tim OF Conrad"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.11500",
    "title": "A Large-scale Dataset for Audio-Language Representation Learning",
    "abstract": "The AI community has made significant strides in developing powerful foundation models, driven by large-scale multimodal datasets. However, in the audio representation learning community, the present audio-language datasets suffer from limitations such as insufficient volume, simplistic content, and arduous collection procedures. To tackle these challenges, we present an innovative and automatic audio caption generation pipeline based on a series of public tools or APIs, and construct a large-scale, high-quality, audio-language dataset, named as Auto-ACD, comprising over 1.9M audio-text pairs. To demonstrate the effectiveness of the proposed dataset, we train popular models on our dataset and show performance improvement on various downstream tasks, namely, audio-language retrieval, audio captioning, environment classification. In addition, we establish a novel test set and provide a benchmark for audio-text tasks. The proposed dataset will be released at https://auto-acd.github.io/. ",
    "url": "https://arxiv.org/abs/2309.11500",
    "authors": [
      "Luoyi Sun",
      "Xuenan Xu",
      "Mengyue Wu",
      "Weidi Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08835",
    "title": "Intelligent machines work in unstructured environments by differential  neural computing",
    "abstract": "Expecting intelligent machines to efficiently work in real world requires a new method to understand unstructured information in unknown environments with good accuracy, scalability and generalization, like human. Here, a memristive neural computing based perceptual signal differential processing and learning method for intelligent machines is presented, via extracting main features of environmental information and applying associated encoded stimuli to memristors, we successfully obtain human-like ability in processing unstructured environmental information, such as amplification (>720%) and adaptation (<50%) of mechanical stimuli. The method also exhibits good scalability and generalization, validated in two typical applications of intelligent machines: object grasping and autonomous driving. In the former, a robot hand experimentally realizes safe and stable grasping, through learning unknown object features (e.g., sharp corner and smooth surface) with a single memristor in 1 ms. In the latter, the decision-making information of 10 unstructured environments in autonomous driving (e.g., overtaking cars, pedestrians) are accurately (94%) extracted with a 40x25 memristor array. By mimicking the intrinsic nature of human low-level perception mechanisms in electronic memristive neural circuits, the proposed method is adaptable to diverse sensing technologies, helping intelligent machines to generate smart high-level decisions in real world. ",
    "url": "https://arxiv.org/abs/2309.08835",
    "authors": [
      "Shengbo Wang",
      "Shuo Gao",
      "Chenyu Tang",
      "Cong Li",
      "Shurui Wang",
      "Jiaqi Wang",
      "Hubin Zhao",
      "Guohua Hu",
      "Arokia Nathan",
      "Ravinder Dahiya",
      "Luigi Occhipinti"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.10835",
    "title": "Analysing race and sex bias in brain age prediction",
    "abstract": "Brain age prediction from MRI has become a popular imaging biomarker associated with a wide range of neuropathologies. The datasets used for training, however, are often skewed and imbalanced regarding demographics, potentially making brain age prediction models susceptible to bias. We analyse the commonly used ResNet-34 model by conducting a comprehensive subgroup performance analysis and feature inspection. The model is trained on 1,215 T1-weighted MRI scans from Cam-CAN and IXI, and tested on UK Biobank (n=42,786), split into six racial and biological sex subgroups. With the objective of comparing the performance between subgroups, measured by the absolute prediction error, we use a Kruskal-Wallis test followed by two post-hoc Conover-Iman tests to inspect bias across race and biological sex. To examine biases in the generated features, we use PCA for dimensionality reduction and employ two-sample Kolmogorov-Smirnov tests to identify distribution shifts among subgroups. Our results reveal statistically significant differences in predictive performance between Black and White, Black and Asian, and male and female subjects. Seven out of twelve pairwise comparisons show statistically significant differences in the feature distributions. Our findings call for further analysis of brain age prediction models. ",
    "url": "https://arxiv.org/abs/2309.10835",
    "authors": [
      "Carolina Pi\u00e7arra",
      "Ben Glocker"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10867",
    "title": "Dynamical Tests of a Deep-Learning Weather Prediction Model",
    "abstract": "Global deep-learning weather prediction models have recently been shown to produce forecasts that rival those from physics-based models run at operational centers. It is unclear whether these models have encoded atmospheric dynamics, or simply pattern matching that produces the smallest forecast error. Answering this question is crucial to establishing the utility of these models as tools for basic science. Here we subject one such model, Pangu-weather, to a set of four classical dynamical experiments that do not resemble the model training data. Localized perturbations to the model output and the initial conditions are added to steady time-averaged conditions, to assess the propagation speed and structural evolution of signals away from the local source. Perturbing the model physics by adding a steady tropical heat source results in a classical Matsuno--Gill response near the heating, and planetary waves that radiate into the extratropics. A localized disturbance on the winter-averaged North Pacific jet stream produces realistic extratropical cyclones and fronts, including the spontaneous emergence of polar lows. Perturbing the 500hPa height field alone yields adjustment from a state of rest to one of wind--pressure balance over ~6 hours. Localized subtropical low pressure systems produce Atlantic hurricanes, provided the initial amplitude exceeds about 5 hPa, and setting the initial humidity to zero eliminates hurricane development. We conclude that the model encodes realistic physics in all experiments, and suggest it can be used as a tool for rapidly testing ideas before using expensive physics-based models. ",
    "url": "https://arxiv.org/abs/2309.10867",
    "authors": [
      "Gregory J. Hakim",
      "Sanjit Masanam"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10922",
    "title": "Discrete Audio Representation as an Alternative to Mel-Spectrograms for  Speaker and Speech Recognition",
    "abstract": "Discrete audio representation, aka audio tokenization, has seen renewed interest driven by its potential to facilitate the application of text language modeling approaches in audio domain. To this end, various compression and representation-learning based tokenization schemes have been proposed. However, there is limited investigation into the performance of compression-based audio tokens compared to well-established mel-spectrogram features across various speaker and speech related tasks. In this paper, we evaluate compression based audio tokens on three tasks: Speaker Verification, Diarization and (Multi-lingual) Speech Recognition. Our findings indicate that (i) the models trained on audio tokens perform competitively, on average within $1\\%$ of mel-spectrogram features for all the tasks considered, and do not surpass them yet. (ii) these models exhibit robustness for out-of-domain narrowband data, particularly in speaker tasks. (iii) audio tokens allow for compression to 20x compared to mel-spectrogram features with minimal loss of performance in speech and speaker related tasks, which is crucial for low bit-rate applications, and (iv) the examined Residual Vector Quantization (RVQ) based audio tokenizer exhibits a low-pass frequency response characteristic, offering a plausible explanation for the observed results, and providing insight for future tokenizer designs. ",
    "url": "https://arxiv.org/abs/2309.10922",
    "authors": [
      "Krishna C. Puvvada",
      "Nithin Rao Koluguri",
      "Kunal Dhawan",
      "Jagadeesh Balam",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.11015",
    "title": "3D-U-SAM Network For Few-shot Tooth Segmentation in CBCT Images",
    "abstract": "Accurate representation of tooth position is extremely important in treatment. 3D dental image segmentation is a widely used method, however labelled 3D dental datasets are a scarce resource, leading to the problem of small samples that this task faces in many cases. To this end, we address this problem with a pretrained SAM and propose a novel 3D-U-SAM network for 3D dental image segmentation. Specifically, in order to solve the problem of using 2D pre-trained weights on 3D datasets, we adopted a convolution approximation method; in order to retain more details, we designed skip connections to fuse features at all levels with reference to U-Net. The effectiveness of the proposed method is demonstrated in ablation experiments, comparison experiments, and sample size experiments. ",
    "url": "https://arxiv.org/abs/2309.11015",
    "authors": [
      "Yifu Zhang",
      "Zuozhu Liu",
      "Yang Feng",
      "Renjing Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11028",
    "title": "The Topology and Geometry of Neural Representations",
    "abstract": "A central question for neuroscience is how to characterize brain representations of perceptual and cognitive content. An ideal characterization should distinguish different functional regions with robustness to noise and idiosyncrasies of individual brains that do not correspond to computational differences. Previous studies have characterized brain representations by their representational geometry, which is defined by the representational dissimilarity matrix (RDM), a summary statistic that abstracts from the roles of individual neurons (or responses channels) and characterizes the discriminability of stimuli. Here we explore a further step of abstraction: from the geometry to the topology of brain representations. We propose topological representational similarity analysis (tRSA), an extension of representational similarity analysis (RSA) that uses a family of geo-topological summary statistics that generalizes the RDM to characterize the topology while de-emphasizing the geometry. We evaluate this new family of statistics in terms of the sensitivity and specificity for model selection using both simulations and functional MRI (fMRI) data. In the simulations, the ground truth is a data-generating layer representation in a neural network model and the models are the same and other layers in different model instances (trained from different random seeds). In fMRI, the ground truth is a visual area and the models are the same and other areas measured in different subjects. Results show that topology-sensitive characterizations of population codes are robust to noise and interindividual variability and maintain excellent sensitivity to the unique representational signatures of different neural network layers and brain regions. ",
    "url": "https://arxiv.org/abs/2309.11028",
    "authors": [
      "Baihan Lin",
      "Nikolaus Kriegeskorte"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.11059",
    "title": "Deep Complex U-Net with Conformer for Audio-Visual Speech Enhancement",
    "abstract": "Recent studies have increasingly acknowledged the advantages of incorporating visual data into speech enhancement (SE) systems. In this paper, we introduce a novel audio-visual SE approach, termed DCUC-Net (deep complex U-Net with conformer network). The proposed DCUC-Net leverages complex domain features and a stack of conformer blocks. The encoder and decoder of DCUC-Net are designed using a complex U-Net-based framework. The audio and visual signals are processed using a complex encoder and a ResNet-18 model, respectively. These processed signals are then fused using the conformer blocks and transformed into enhanced speech waveforms via a complex decoder. The conformer blocks consist of a combination of self-attention mechanisms and convolutional operations, enabling DCUC-Net to effectively capture both global and local audio-visual dependencies. Our experimental results demonstrate the effectiveness of DCUC-Net, as it outperforms the baseline model from the COG-MHEAR AVSE Challenge 2023 by a notable margin of 0.14 in terms of PESQ. Additionally, the proposed DCUC-Net performs comparably to a state-of-the-art model and outperforms all other compared models on the Taiwan Mandarin speech with video (TMSV) dataset. ",
    "url": "https://arxiv.org/abs/2309.11059",
    "authors": [
      "Shafique Ahmed",
      "Chia-Wei Chen",
      "Wenze Ren",
      "Chin-Jou Li",
      "Ernie Chu",
      "Jun-Cheng Chen",
      "Amir Hussain",
      "Hsin-Min Wang",
      "Yu Tsao",
      "Jen-Cheng Hou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.11120",
    "title": "Ano-SuPs: Multi-size anomaly detection for manufactured products by  identifying suspected patches",
    "abstract": "Image-based systems have gained popularity owing to their capacity to provide rich manufacturing status information, low implementation costs and high acquisition rates. However, the complexity of the image background and various anomaly patterns pose new challenges to existing matrix decomposition methods, which are inadequate for modeling requirements. Moreover, the uncertainty of the anomaly can cause anomaly contamination problems, making the designed model and method highly susceptible to external disturbances. To address these challenges, we propose a two-stage strategy anomaly detection method that detects anomalies by identifying suspected patches (Ano-SuPs). Specifically, we propose to detect the patches with anomalies by reconstructing the input image twice: the first step is to obtain a set of normal patches by removing those suspected patches, and the second step is to use those normal patches to refine the identification of the patches with anomalies. To demonstrate its effectiveness, we evaluate the proposed method systematically through simulation experiments and case studies. We further identified the key parameters and designed steps that impact the model's performance and efficiency. ",
    "url": "https://arxiv.org/abs/2309.11120",
    "authors": [
      "Hao Xu",
      "Juan Du",
      "Andi Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11126",
    "title": "Towards fractal origins of the community structure in complex networks:  a model-based approach",
    "abstract": "In this paper, we pose a hypothesis that the structure of communities in complex networks may result from their latent fractal properties. This hypothesis is based not only on the general observation that many real networks have multilevel organization, which is reminiscent of the geometric self-similarity of classical fractals. Quantitative arguments supporting this hypothesis are: first, many non-fractal real complex networks that have a well-defined community structure reveal fractal properties when suitably diluted; second, the scale-free community size distributions observed in many real networks directly relate to scale-invariant box mass distributions, which have recently been described as a fundamental feature of fractal complex networks. We test this hypothesis in a general model of evolving network with community structure that exhibits dual scale invariance: at the level of node degrees and community sizes, respectively. We show that, at least in this model, the proposed hypothesis cannot be rejected. The argument for this is that a kind of fractal core can be identified in the networks studied, which appears as a macroscopic connected component when the edges between modules identified by the community detection algorithm are removed in a supervised manner. ",
    "url": "https://arxiv.org/abs/2309.11126",
    "authors": [
      "Mateusz Samsel",
      "Kordian Makulski",
      "Micha\u0142 \u0141epek",
      "Agata Fronczak",
      "Piotr Fronczak"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.11139",
    "title": "More complex encoder is not all you need",
    "abstract": "U-Net and its variants have been widely used in medical image segmentation. However, most current U-Net variants confine their improvement strategies to building more complex encoder, while leaving the decoder unchanged or adopting a simple symmetric structure. These approaches overlook the true functionality of the decoder: receiving low-resolution feature maps from the encoder and restoring feature map resolution and lost information through upsampling. As a result, the decoder, especially its upsampling component, plays a crucial role in enhancing segmentation outcomes. However, in 3D medical image segmentation, the commonly used transposed convolution can result in visual artifacts. This issue stems from the absence of direct relationship between adjacent pixels in the output feature map. Furthermore, plain encoder has already possessed sufficient feature extraction capability because downsampling operation leads to the gradual expansion of the receptive field, but the loss of information during downsampling process is unignorable. To address the gap in relevant research, we extend our focus beyond the encoder and introduce neU-Net (i.e., not complex encoder U-Net), which incorporates a novel Sub-pixel Convolution for upsampling to construct a powerful decoder. Additionally, we introduce multi-scale wavelet inputs module on the encoder side to provide additional information. Our model design achieves excellent results, surpassing other state-of-the-art methods on both the Synapse and ACDC datasets. ",
    "url": "https://arxiv.org/abs/2309.11139",
    "authors": [
      "Weibin Yang",
      "Longwei Xu",
      "Pengwei Wang",
      "Dehua Geng",
      "Yusong Li",
      "Mingyuan Xu",
      "Zhiqi Dong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2002.06914",
    "title": "On the Ambiguity of Rank-Based Evaluation of Entity Alignment or Link  Prediction Methods",
    "abstract": " Comments: fixed a typo on page 6, eq.8 ",
    "url": "https://arxiv.org/abs/2002.06914",
    "authors": [
      "Max Berrendorf",
      "Evgeniy Faerman",
      "Laurent Vermue",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.07803",
    "title": "Attacking Open-domain Question Answering by Injecting Misinformation",
    "abstract": " Comments: AACL-IJCNLP 2023 (main conference, long paper) ",
    "url": "https://arxiv.org/abs/2110.07803",
    "authors": [
      "Liangming Pan",
      "Wenhu Chen",
      "Min-Yen Kan",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.10854",
    "title": "XnODR and XnIDR: Two Accurate and Fast Fully Connected Layers For  Convolutional Neural Networks",
    "abstract": " Comments: 19 pages, 5 figures, 9 tables, 2 algorithms ",
    "url": "https://arxiv.org/abs/2111.10854",
    "authors": [
      "Jian Sun",
      "Ali Pourramezan Fard",
      "Mohammad H. Mahoor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.01165",
    "title": "Inductive Subgraph Embedding for Link Prediction",
    "abstract": " Comments: 5 pages, 2 figures, 1 table ",
    "url": "https://arxiv.org/abs/2112.01165",
    "authors": [
      "Chunyu Miao",
      "Chenxuan Xie",
      "Jiajun Zhou",
      "Shanqing Yu",
      "Lina Chen",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.00968",
    "title": "Detection Recovery in Online Multi-Object Tracking with Sparse Graph  Tracker",
    "abstract": " Comments: Accepted to WACV 2023; fix figures ",
    "url": "https://arxiv.org/abs/2205.00968",
    "authors": [
      "Jeongseok Hyun",
      "Myunggu Kang",
      "Dongyoon Wee",
      "Dit-Yan Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.04952",
    "title": "Read the Room: Adapting a Robot's Voice to Ambient and Social Contexts",
    "abstract": " Comments: 8 pages, 10 figures, Accepted to International Conference on Intelligent Robots and Systems, project webpage: this https URL ",
    "url": "https://arxiv.org/abs/2205.04952",
    "authors": [
      "Paige Tuttosi",
      "Emma Hughson",
      "Akihiro Matsufuji",
      "Angelica Lim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03292",
    "title": "Learning-Based Motion Planning with Mixture Density Networks",
    "abstract": " Title: Learning-Based Motion Planning with Mixture Density Networks ",
    "url": "https://arxiv.org/abs/2206.03292",
    "authors": [
      "Yinghan Wang",
      "Xiaoming Duan",
      "Jianping He"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.06369",
    "title": "Toward Dynamic Stability Assessment of Power Grid Topologies using Graph  Neural Networks",
    "abstract": " Comments: 9 pages + appendix and references, 7 figures ",
    "url": "https://arxiv.org/abs/2206.06369",
    "authors": [
      "Christian Nauck",
      "Michael Lindner",
      "Konstantin Sch\u00fcrholt",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2208.03680",
    "title": "On Fast Simulation of Dynamical System with Neural Vector Enhanced  Numerical Solver",
    "abstract": " Comments: Accepted by Scientific Report ",
    "url": "https://arxiv.org/abs/2208.03680",
    "authors": [
      "Zhongzhan Huang",
      "Senwei Liang",
      "Hong Zhang",
      "Haizhao Yang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2208.05845",
    "title": "A Comprehensive Analysis of AI Biases in DeepFake Detection With  Massively Annotated Databases",
    "abstract": " Title: A Comprehensive Analysis of AI Biases in DeepFake Detection With  Massively Annotated Databases ",
    "url": "https://arxiv.org/abs/2208.05845",
    "authors": [
      "Ying Xu",
      "Philipp Terh\u00f6rst",
      "Kiran Raja",
      "Marius Pedersen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14295",
    "title": "Conformal Prediction is Robust to Dispersive Label Noise",
    "abstract": " Title: Conformal Prediction is Robust to Dispersive Label Noise ",
    "url": "https://arxiv.org/abs/2209.14295",
    "authors": [
      "Shai Feldman",
      "Bat-Sheva Einbinder",
      "Stephen Bates",
      "Anastasios N. Angelopoulos",
      "Asaf Gendler",
      "Yaniv Romano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01346",
    "title": "ImmFusion: Robust mmWave-RGB Fusion for 3D Human Body Reconstruction in  All Weather Conditions",
    "abstract": " Comments: Accepted to ICRA2023, Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2210.01346",
    "authors": [
      "Anjun Chen",
      "Xiangyu Wang",
      "Kun Shi",
      "Shaohao Zhu",
      "Bin Fang",
      "Yingfeng Chen",
      "Jiming Chen",
      "Yuchi Huo",
      "Qi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16730",
    "title": "Graph Fuzzy System: Concepts, Models and Algorithms",
    "abstract": " Comments: This paper has been submitted to a journal ",
    "url": "https://arxiv.org/abs/2210.16730",
    "authors": [
      "Fuping Hu",
      "Zhaohong Deng",
      "Zhenping Xie",
      "Kup-Sze Choi",
      "Shitong Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16906",
    "title": "DyG2Vec: Representation Learning for Dynamic Graphs with  Self-Supervision",
    "abstract": " Comments: Proceedings of the 19th International Workshop on Mining and Learning with Graphs (MLG) ",
    "url": "https://arxiv.org/abs/2210.16906",
    "authors": [
      "Mohammad Ali Alomrani",
      "Mahdi Biparva",
      "Yingxue Zhang",
      "Mark Coates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.09771",
    "title": "Boosting Object Representation Learning via Motion and Object Continuity",
    "abstract": " Comments: 8 pages main text, 32 tables, 21 Figures ",
    "url": "https://arxiv.org/abs/2211.09771",
    "authors": [
      "Quentin Delfosse",
      "Wolfgang Stammer",
      "Thomas Rothenbacher",
      "Dwarak Vittal",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04679",
    "title": "Motion and Context-Aware Audio-Visual Conditioned Video Prediction",
    "abstract": " Comments: BMVC 2023 ",
    "url": "https://arxiv.org/abs/2212.04679",
    "authors": [
      "Yating Xu",
      "Conghui Hu",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.12070",
    "title": "RouteNet-Fermi: Network Modeling with Graph Neural Networks",
    "abstract": " Comments: This paper has been accepted for publication at IEEE/ACM Transactions on Networking 2023 (DOI: 10.1109/TNET.2023.3269983). \\copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses ",
    "url": "https://arxiv.org/abs/2212.12070",
    "authors": [
      "Miquel Ferriol-Galm\u00e9s",
      "Jordi Paillisse",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Krzysztof Rusek",
      "Shihan Xiao",
      "Xiang Shi",
      "Xiangle Cheng",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.12395",
    "title": "Detecting Objects with Graph Priors and Graph Refinement",
    "abstract": " Comments: 13 pages, 8 figures. In Proceedings of International Conference on Computer Vision 2023 ",
    "url": "https://arxiv.org/abs/2212.12395",
    "authors": [
      "Aritra Bhowmik",
      "Martin R. Oswald",
      "Yu Wang",
      "Nora Baka",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.03283",
    "title": "A Robust Multilabel Method Integrating Rule-based Transparent Model,  Soft Label Correlation Learning and Label Noise Resistance",
    "abstract": " Comments: This paper has been accepted by IEEE Transactions on Fuzzy Systems ",
    "url": "https://arxiv.org/abs/2301.03283",
    "authors": [
      "Qiongdan Lou",
      "Zhaohong Deng",
      "Kup-Sze Choi",
      "Shitong Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.04571",
    "title": "Analyzing And Improving Neural Speaker Embeddings for ASR",
    "abstract": " Comments: Accepted at ITG Speech Communications 2023 ",
    "url": "https://arxiv.org/abs/2301.04571",
    "authors": [
      "Christoph L\u00fcscher",
      "Jingjing Xu",
      "Mohammad Zeineldeen",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13541",
    "title": "Singular Value Approximation and Sparsifying Random Walks on Directed  Graphs",
    "abstract": " Comments: FOCS 2023 ",
    "url": "https://arxiv.org/abs/2301.13541",
    "authors": [
      "AmirMahdi Ahmadinejad",
      "John Peebles",
      "Edward Pyne",
      "Aaron Sidford",
      "Salil Vadhan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2303.04971",
    "title": "Optimizing network robustness via Krylov subspaces",
    "abstract": " Title: Optimizing network robustness via Krylov subspaces ",
    "url": "https://arxiv.org/abs/2303.04971",
    "authors": [
      "Stefano Massei",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.18104",
    "title": "Status Updating under Partial Battery Knowledge in Energy Harvesting IoT  Networks",
    "abstract": " Comments: 36 Pages. arXiv admin note: text overlap with arXiv:2203.10400, arXiv:2212.05979 ",
    "url": "https://arxiv.org/abs/2303.18104",
    "authors": [
      "Mohammad Hatami",
      "Markus Leinonen",
      "Marian Codreanu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.03535",
    "title": "CRISP: Curriculum inducing Primitive Informed Subgoal Prediction",
    "abstract": " Title: CRISP: Curriculum inducing Primitive Informed Subgoal Prediction ",
    "url": "https://arxiv.org/abs/2304.03535",
    "authors": [
      "Utsav Singh",
      "Vinay P Namboodiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04688",
    "title": "Interaction-Aware Prompting for Zero-Shot Spatio-Temporal Action  Detection",
    "abstract": " Comments: Accepted by ICCV Workshop 2023 (What is Next in Multimodal Foundation Models?) ",
    "url": "https://arxiv.org/abs/2304.04688",
    "authors": [
      "Wei-Jhe Huang",
      "Jheng-Hsien Yeh",
      "Min-Hung Chen",
      "Gueter Josmy Faure",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.13032",
    "title": "A Unified Active Learning Framework for Annotating Graph Data with  Application to Software Source Code Performance Prediction",
    "abstract": " Title: A Unified Active Learning Framework for Annotating Graph Data with  Application to Software Source Code Performance Prediction ",
    "url": "https://arxiv.org/abs/2304.13032",
    "authors": [
      "Peter Samoaa",
      "Linus Aronsson",
      "Antonio Longa",
      "Philipp Leitner",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.01698",
    "title": "DeepAqua: Self-Supervised Semantic Segmentation of Wetland Surface Water  Extent with SAR Images using Knowledge Distillation",
    "abstract": " Comments: 29 pages, 8 figures, 1 table ",
    "url": "https://arxiv.org/abs/2305.01698",
    "authors": [
      "Francisco J. Pe\u00f1a",
      "Clara H\u00fcbinger",
      "Amir H. Payberah",
      "Fernando Jaramillo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.02199",
    "title": "Multi-Head Graph Convolutional Network for Structural Connectome  Classification",
    "abstract": " Title: Multi-Head Graph Convolutional Network for Structural Connectome  Classification ",
    "url": "https://arxiv.org/abs/2305.02199",
    "authors": [
      "Anees Kazi",
      "Jocelyn Mora",
      "Bruce Fischl",
      "Adrian V. Dalca",
      "Iman Aganj"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.03462",
    "title": "General Neural Gauge Fields",
    "abstract": " Comments: ICLR 2023 ",
    "url": "https://arxiv.org/abs/2305.03462",
    "authors": [
      "Fangneng Zhan",
      "Lingjie Liu",
      "Adam Kortylewski",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.06395",
    "title": "ACTC: Active Threshold Calibration for Cold-Start Knowledge Graph  Completion",
    "abstract": " Comments: ACL'23 ",
    "url": "https://arxiv.org/abs/2305.06395",
    "authors": [
      "Anastasiia Sedova",
      "Benjamin Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08415",
    "title": "Marsellus: A Heterogeneous RISC-V AI-IoT End-Node SoC with 2-to-8b DNN  Acceleration and 30%-Boost Adaptive Body Biasing",
    "abstract": " Comments: Post-print accepted by IEEE Journal of Solid-State Circuits ",
    "url": "https://arxiv.org/abs/2305.08415",
    "authors": [
      "Francesco Conti",
      "Gianna Paulin",
      "Davide Rossi",
      "Alfio Di Mauro",
      "Georg Rutishauser",
      "Gianmarco Ottavi",
      "Manuel Eggimann",
      "Hayate Okuhara",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14949",
    "title": "Cross-lingual Data Augmentation for Document-grounded Dialog Systems in  Low Resource Languages",
    "abstract": " Comments: The Third DialDoc Workshop at ACL 2023, this https URL ",
    "url": "https://arxiv.org/abs/2305.14949",
    "authors": [
      "Qi Gou",
      "Zehua Xia",
      "Wenzhe Du"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.03207",
    "title": "H2-Mapping: Real-time Dense Mapping Using Hierarchical Hybrid  Representation",
    "abstract": " Comments: Accepted by IEEE Robotics and Automation Letters ",
    "url": "https://arxiv.org/abs/2306.03207",
    "authors": [
      "Chenxing Jiang",
      "Hanwen Zhang",
      "Peize Liu",
      "Zehuan Yu",
      "Hui Cheng",
      "Boyu Zhou",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.16740",
    "title": "Principles and Guidelines for Evaluating Social Robot Navigation  Algorithms",
    "abstract": " Comments: 42 pages, 11 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2306.16740",
    "authors": [
      "Anthony Francis",
      "Claudia P\u00e9rez-D'Arpino",
      "Chengshu Li",
      "Fei Xia",
      "Alexandre Alahi",
      "Rachid Alami",
      "Aniket Bera",
      "Abhijat Biswas",
      "Joydeep Biswas",
      "Rohan Chandra",
      "Hao-Tien Lewis Chiang",
      "Michael Everett",
      "Sehoon Ha",
      "Justin Hart",
      "Jonathan P. How",
      "Haresh Karnan",
      "Tsang-Wei Edward Lee",
      "Luis J. Manso",
      "Reuth Mirksy",
      "S\u00f6ren Pirk",
      "Phani Teja Singamaneni",
      "Peter Stone",
      "Ada V. Taylor",
      "Peter Trautman",
      "Nathan Tsoi",
      "Marynel V\u00e1zquez",
      "Xuesu Xiao",
      "Peng Xu",
      "Naoki Yokoyama",
      "Alexander Toshev",
      "Roberto Mart\u00edn-Mart\u00edn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.05318",
    "title": "Predicting small molecules solubilities on endpoint devices using deep  ensemble neural networks",
    "abstract": " Title: Predicting small molecules solubilities on endpoint devices using deep  ensemble neural networks ",
    "url": "https://arxiv.org/abs/2307.05318",
    "authors": [
      "Mayk Caldas Ramos",
      "Andrew D. White"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.01621",
    "title": "A Novel Convolutional Neural Network Architecture with a Continuous  Symmetry",
    "abstract": " Comments: Accepted by the 3rd CAAI International Conference on Artificial Intelligence (CICAI), 2023; with Addendum + minor edits ",
    "url": "https://arxiv.org/abs/2308.01621",
    "authors": [
      "Yao Liu",
      "Hang Shao",
      "Bing Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.06534",
    "title": "Dealing with Small Datasets for Deep Learning in Medical Imaging: An  Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive  and Masked Autoencoder Methods for Convolutional Models",
    "abstract": " Comments: This paper is under review. The code will be released if accepted ",
    "url": "https://arxiv.org/abs/2308.06534",
    "authors": [
      "Daniel Wolf",
      "Tristan Payer",
      "Catharina Silvia Lisson",
      "Christoph Gerhard Lisson",
      "Meinrad Beer",
      "Michael G\u00f6tz",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06629",
    "title": "Optimal FIFO grouping in public transit networks",
    "abstract": " Comments: 1 page, 0 figures ",
    "url": "https://arxiv.org/abs/2308.06629",
    "authors": [
      "Patrick Steil"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2308.09313",
    "title": "Domain Adaptive Code Completion via Language Models and Decoupled Domain  Databases",
    "abstract": " Comments: Accepted by ASE2023 ",
    "url": "https://arxiv.org/abs/2308.09313",
    "authors": [
      "Ze Tang",
      "Jidong Ge",
      "Shangqing Liu",
      "Tingwei Zhu",
      "Tongtong Xu",
      "Liguo Huang",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.13049",
    "title": "Bayesian Exploration Networks",
    "abstract": " Comments: Changed email contact for joint first author 2. Fixed minor typos ",
    "url": "https://arxiv.org/abs/2308.13049",
    "authors": [
      "Mattie Fellows",
      "Brandon Kaplowitz",
      "Christian Schroeder de Witt",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.04810",
    "title": "Neural Latent Geometry Search: Product Manifold Inference via  Gromov-Hausdorff-Informed Bayesian Optimization",
    "abstract": " Title: Neural Latent Geometry Search: Product Manifold Inference via  Gromov-Hausdorff-Informed Bayesian Optimization ",
    "url": "https://arxiv.org/abs/2309.04810",
    "authors": [
      "Haitz Saez de Ocariz Borde",
      "Alvaro Arroyo",
      "Ismael Morales",
      "Ingmar Posner",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.06635",
    "title": "Collaborative Dynamic 3D Scene Graphs for Automated Driving",
    "abstract": " Comments: Refined manuscript and extended supplementary ",
    "url": "https://arxiv.org/abs/2309.06635",
    "authors": [
      "Elias Greve",
      "Martin B\u00fcchner",
      "Niclas V\u00f6disch",
      "Wolfram Burgard",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09553",
    "title": "Causal-Story: Local Causal Attention Utilizing Parameter-Efficient  Tuning For Visual Story Synthesis",
    "abstract": " Comments: Submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.09553",
    "authors": [
      "Tianyi Song",
      "Jiuxin Cao",
      "Kun Wang",
      "Bo Liu",
      "Xiaofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.10121",
    "title": "Pre-training on Synthetic Driving Data for Trajectory Prediction",
    "abstract": " Title: Pre-training on Synthetic Driving Data for Trajectory Prediction ",
    "url": "https://arxiv.org/abs/2309.10121",
    "authors": [
      "Yiheng Li",
      "Seth Z. Zhao",
      "Chenfeng Xu",
      "Chen Tang",
      "Chenran Li",
      "Mingyu Ding",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.10230",
    "title": "Learning Point-wise Abstaining Penalty for Point Cloud Anomaly Detection",
    "abstract": " Comments: codes is available at this https URL ",
    "url": "https://arxiv.org/abs/2309.10230",
    "authors": [
      "Shaocong Xu",
      "Pengfei Li",
      "Xinyu Liu",
      "Qianpu Sun",
      "Yang Li",
      "Shihui Guo",
      "Zhen Wang",
      "Bo Jiang",
      "Rui Wang",
      "Kehua Sheng",
      "Bo Zhang",
      "Hao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]