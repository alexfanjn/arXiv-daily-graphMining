[
  {
    "id": "arXiv:2309.11509",
    "title": "Using causal inference to avoid fallouts in data-driven parametric  analysis: a case study in the architecture, engineering, and construction  industry",
    "abstract": "The decision-making process in real-world implementations has been affected by a growing reliance on data-driven models. We investigated the synergetic pattern between the data-driven methods, empirical domain knowledge, and first-principles simulations. We showed the potential risk of biased results when using data-driven models without causal analysis. Using a case study assessing the implication of several design solutions on the energy consumption of a building, we proved the necessity of causal analysis during the data-driven modeling process. We concluded that: (a) Data-driven models' accuracy assessment or domain knowledge screening may not rule out biased and spurious results; (b) Data-driven models' feature selection should involve careful consideration of causal relationships, especially colliders; (c) Causal analysis results can be used as an aid to first-principles simulation design and parameter checking to avoid cognitive biases. We proved the benefits of causal analysis when applied to data-driven models in building engineering. ",
    "url": "https://arxiv.org/abs/2309.11509",
    "authors": [
      "Xia Chen",
      "Ruiji Sun",
      "Ueli Saluz",
      "Stefano Schiavon",
      "Philipp Geyer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.11515",
    "title": "Towards Differential Privacy in Sequential Recommendation: A Noisy Graph  Neural Network Approach",
    "abstract": "With increasing frequency of high-profile privacy breaches in various online platforms, users are becoming more concerned about their privacy. And recommender system is the core component of online platforms for providing personalized service, consequently, its privacy preservation has attracted great attention. As the gold standard of privacy protection, differential privacy has been widely adopted to preserve privacy in recommender systems. However, existing differentially private recommender systems only consider static and independent interactions, so they cannot apply to sequential recommendation where behaviors are dynamic and dependent. Meanwhile, little attention has been paid on the privacy risk of sensitive user features, most of them only protect user feedbacks. In this work, we propose a novel DIfferentially Private Sequential recommendation framework with a noisy Graph Neural Network approach (denoted as DIPSGNN) to address these limitations. To the best of our knowledge, we are the first to achieve differential privacy in sequential recommendation with dependent interactions. Specifically, in DIPSGNN, we first leverage piecewise mechanism to protect sensitive user features. Then, we innovatively add calibrated noise into aggregation step of graph neural network based on aggregation perturbation mechanism. And this noisy graph neural network can protect sequentially dependent interactions and capture user preferences simultaneously. Extensive experiments demonstrate the superiority of our method over state-of-the-art differentially private recommender systems in terms of better balance between privacy and accuracy. ",
    "url": "https://arxiv.org/abs/2309.11515",
    "authors": [
      "Wentao Hu",
      "Hui Fang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11523",
    "title": "RMT: Retentive Networks Meet Vision Transformers",
    "abstract": "Transformer first appears in the field of natural language processing and is later migrated to the computer vision domain, where it demonstrates excellent performance in vision tasks. However, recently, Retentive Network (RetNet) has emerged as an architecture with the potential to replace Transformer, attracting widespread attention in the NLP community. Therefore, we raise the question of whether transferring RetNet's idea to vision can also bring outstanding performance to vision tasks. To address this, we combine RetNet and Transformer to propose RMT. Inspired by RetNet, RMT introduces explicit decay into the vision backbone, bringing prior knowledge related to spatial distances to the vision model. This distance-related spatial prior allows for explicit control of the range of tokens that each token can attend to. Additionally, to reduce the computational cost of global modeling, we decompose this modeling process along the two coordinate axes of the image. Abundant experiments have demonstrated that our RMT exhibits exceptional performance across various computer vision tasks. For example, RMT achieves 84.1% Top1-acc on ImageNet-1k using merely 4.5G FLOPs. To the best of our knowledge, among all models, RMT achieves the highest Top1-acc when models are of similar size and trained with the same strategy. Moreover, RMT significantly outperforms existing vision backbones in downstream tasks such as object detection, instance segmentation, and semantic segmentation. Our work is still in progress. ",
    "url": "https://arxiv.org/abs/2309.11523",
    "authors": [
      "Qihang Fan",
      "Huaibo Huang",
      "Mingrui Chen",
      "Hongmin Liu",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11528",
    "title": "Learning Complete Topology-Aware Correlations Between Relations for  Inductive Link Prediction",
    "abstract": "Inductive link prediction -- where entities during training and inference stages can be different -- has shown great potential for completing evolving knowledge graphs in an entity-independent manner. Many popular methods mainly focus on modeling graph-level features, while the edge-level interactions -- especially the semantic correlations between relations -- have been less explored. However, we notice a desirable property of semantic correlations between relations is that they are inherently edge-level and entity-independent. This implies the great potential of the semantic correlations for the entity-independent inductive link prediction task. Inspired by this observation, we propose a novel subgraph-based method, namely TACO, to model Topology-Aware COrrelations between relations that are highly correlated to their topological structures within subgraphs. Specifically, we prove that semantic correlations between any two relations can be categorized into seven topological patterns, and then proposes Relational Correlation Network (RCN) to learn the importance of each pattern. To further exploit the potential of RCN, we propose Complete Common Neighbor induced subgraph that can effectively preserve complete topological patterns within the subgraph. Extensive experiments demonstrate that TACO effectively unifies the graph-level information and edge-level interactions to jointly perform reasoning, leading to a superior performance over existing state-of-the-art methods for the inductive link prediction task. ",
    "url": "https://arxiv.org/abs/2309.11528",
    "authors": [
      "Jie Wang",
      "Hanzhu Chen",
      "Qitan Lv",
      "Zhihao Shi",
      "Jiajun Chen",
      "Huarui He",
      "Hongtao Xie",
      "Yongdong Zhang",
      "Feng Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11572",
    "title": "Architecture Knowledge Representation and Communication Industry Survey",
    "abstract": "Background: The literature offers various methods for capturing software architectural knowledge (AK), including views, viewpoints, and architecture decision records (ADRs). In parallel, sustainability has gained prominence in software engineering, especially concerning software architecture. Nevertheless, practical industry reviews on these subjects seem to be lacking. Aim: In this research we aim to understand the current practice in architecture knowledge, and to explore where sustainability can be applied to address sustainability in software architecture in the future. Method: We used a survey, which utilized a questionnaire containing 34 questions and collected responses from 45 architects working at a prominent bank in the Netherlands, aimed to evaluate the practical representation and communication of architectural knowledge and sustainability. Result: Our analysis yielded two primary discoveries and several intriguing detailed results regarding how AK is captured and conveyed to diverse stakeholders. Firstly, it seems crucial to develop a new architectural element that connects various architectural features and perspectives tailored for different stakeholders. Secondly, providing clear guidance, references, and goals is essential to motivate architects to adopt Sustainable Software Engineering practices. Conclusion: After analysing the data collected through this survey, we have concluded that: a) There are no established domain-specific AK methods/tools in the financial domain. Most practitioners use domain-generic tools. b) A new architectural element that links the various architectural features and viewpoints created for various stakeholders appears to be necessary. c) There is sufficient sustainability awareness and motivation among software architects. However, what they lack are clear guidance, references, and goals to practice sustainable software engineering. ",
    "url": "https://arxiv.org/abs/2309.11572",
    "authors": [
      "Haben Birhane Gebreweld"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.11575",
    "title": "Distilling Adversarial Prompts from Safety Benchmarks: Report for the  Adversarial Nibbler Challenge",
    "abstract": "Text-conditioned image generation models have recently achieved astonishing image quality and alignment results. Consequently, they are employed in a fast-growing number of applications. Since they are highly data-driven, relying on billion-sized datasets randomly scraped from the web, they also produce unsafe content. As a contribution to the Adversarial Nibbler challenge, we distill a large set of over 1,000 potential adversarial inputs from existing safety benchmarks. Our analysis of the gathered prompts and corresponding images demonstrates the fragility of input filters and provides further insights into systematic safety issues in current generative image models. ",
    "url": "https://arxiv.org/abs/2309.11575",
    "authors": [
      "Manuel Brack",
      "Patrick Schramowski",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11576",
    "title": "Examining the Limitations of Computational Rumor Detection Models  Trained on Static Datasets",
    "abstract": "A crucial aspect of a rumor detection model is its ability to generalize, particularly its ability to detect emerging, previously unknown rumors. Past research has indicated that content-based (i.e., using solely source posts as input) rumor detection models tend to perform less effectively on unseen rumors. At the same time, the potential of context-based models remains largely untapped. The main contribution of this paper is in the in-depth evaluation of the performance gap between content and context-based models specifically on detecting new, unseen rumors. Our empirical findings demonstrate that context-based models are still overly dependent on the information derived from the rumors' source post and tend to overlook the significant role that contextual information can play. We also study the effect of data split strategies on classifier performance. Based on our experimental results, the paper also offers practical suggestions on how to minimize the effects of temporal concept drift in static datasets during the training of rumor detection methods. ",
    "url": "https://arxiv.org/abs/2309.11576",
    "authors": [
      "Yida Mu",
      "Xingyi Song",
      "Kalina Bontcheva",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11587",
    "title": "CATS: Conditional Adversarial Trajectory Synthesis for  Privacy-Preserving Trajectory Data Publication Using Deep Learning Approaches",
    "abstract": "The prevalence of ubiquitous location-aware devices and mobile Internet enables us to collect massive individual-level trajectory dataset from users. Such trajectory big data bring new opportunities to human mobility research but also raise public concerns with regard to location privacy. In this work, we present the Conditional Adversarial Trajectory Synthesis (CATS), a deep-learning-based GeoAI methodological framework for privacy-preserving trajectory data generation and publication. CATS applies K-anonymity to the underlying spatiotemporal distributions of human movements, which provides a distributional-level strong privacy guarantee. By leveraging conditional adversarial training on K-anonymized human mobility matrices, trajectory global context learning using the attention-based mechanism, and recurrent bipartite graph matching of adjacent trajectory points, CATS is able to reconstruct trajectory topology from conditionally sampled locations and generate high-quality individual-level synthetic trajectory data, which can serve as supplements or alternatives to raw data for privacy-preserving trajectory data publication. The experiment results on over 90k GPS trajectories show that our method has a better performance in privacy preservation, spatiotemporal characteristic preservation, and downstream utility compared with baseline methods, which brings new insights into privacy-preserving human mobility research using generative AI techniques and explores data ethics issues in GIScience. ",
    "url": "https://arxiv.org/abs/2309.11587",
    "authors": [
      "Jinmeng Rao",
      "Song Gao",
      "Sijia Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.11591",
    "title": "Continuous Levels of Detail for Light Field Networks",
    "abstract": "Recently, several approaches have emerged for generating neural representations with multiple levels of detail (LODs). LODs can improve the rendering by using lower resolutions and smaller model sizes when appropriate. However, existing methods generally focus on a few discrete LODs which suffer from aliasing and flicker artifacts as details are changed and limit their granularity for adapting to resource limitations. In this paper, we propose a method to encode light field networks with continuous LODs, allowing for finely tuned adaptations to rendering conditions. Our training procedure uses summed-area table filtering allowing efficient and continuous filtering at various LODs. Furthermore, we use saliency-based importance sampling which enables our light field networks to distribute their capacity, particularly limited at lower LODs, towards representing the details viewers are most likely to focus on. Incorporating continuous LODs into neural representations enables progressive streaming of neural representations, decreasing the latency and resource utilization for rendering. ",
    "url": "https://arxiv.org/abs/2309.11591",
    "authors": [
      "David Li",
      "Brandon Y. Feng",
      "Amitabh Varshney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2309.11611",
    "title": "Hate speech detection in algerian dialect using deep learning",
    "abstract": "With the proliferation of hate speech on social networks under different formats, such as abusive language, cyberbullying, and violence, etc., people have experienced a significant increase in violence, putting them in uncomfortable situations and threats. Plenty of efforts have been dedicated in the last few years to overcome this phenomenon to detect hate speech in different structured languages like English, French, Arabic, and others. However, a reduced number of works deal with Arabic dialects like Tunisian, Egyptian, and Gulf, mainly the Algerian ones. To fill in the gap, we propose in this work a complete approach for detecting hate speech on online Algerian messages. Many deep learning architectures have been evaluated on the corpus we created from some Algerian social networks (Facebook, YouTube, and Twitter). This corpus contains more than 13.5K documents in Algerian dialect written in Arabic, labeled as hateful or non-hateful. Promising results are obtained, which show the efficiency of our approach. ",
    "url": "https://arxiv.org/abs/2309.11611",
    "authors": [
      "Dihia Lanasri",
      "Juan Olano",
      "Sifal Klioui",
      "Sin Liang Lee",
      "Lamia Sekkai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11639",
    "title": "The latent cognitive structures of social networks",
    "abstract": "Cognitive Social Structures (CSS) are multilayer social networks where each layer corresponds to an individual's perception of the network. Traditional analyses of CSSs have focused on identifying individuals' accurate (or inaccurate) perceptions of a network or examining how these perceptions correlate with behavior. Largely overlooked, however, has been the rich information that CSSs contain about the possible correspondence between the social and cognitive structure shared by the individuals within a network. How does a person's social position, capturing how they are related to other individuals, relate to their cognitive position, capturing how they view the network? In this work, we study CSSs as three-dimensional tensors, applying tensor decomposition methods to simultaneously capture the joint latent social structure of how individuals are perceived as connected as well as the latent cognitive structure of how different individuals view the connections. In addition to modeling cognitively independent, dependent, and redundant networks, we propose a specific model instance and related statistical test for testing when there is social-cognitive agreement in a network: when the social and cognitive spaces are equivalent. We employ low-rank nonnegative Tucker decompositions (NNTuck) to approximate the CSS, a procedure closely related to estimating a multilayer stochastic block model (SBM) from such data. We place a particular emphasis on the NNTuck's latent cognitive space, proposing it as an operationalization of sociological theories of social cognition and relational schema. We use our approach to analyze four different CSSs and give insights into the latent cognitive structures of those networks. ",
    "url": "https://arxiv.org/abs/2309.11639",
    "authors": [
      "Izabel Aguiar",
      "Johan Ugander"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.11651",
    "title": "Drift Control of High-Dimensional RBM: A Computational Method Based on  Neural Networks",
    "abstract": "Motivated by applications in queueing theory, we consider a stochastic control problem whose state space is the $d$-dimensional positive orthant. The controlled process $Z$ evolves as a reflected Brownian motion whose covariance matrix is exogenously specified, as are its directions of reflection from the orthant's boundary surfaces. A system manager chooses a drift vector $\\theta(t)$ at each time $t$ based on the history of $Z$, and the cost rate at time $t$ depends on both $Z(t)$ and $\\theta(t)$. In our initial problem formulation, the objective is to minimize expected discounted cost over an infinite planning horizon, after which we treat the corresponding ergodic control problem. Extending earlier work by Han et al. (Proceedings of the National Academy of Sciences, 2018, 8505-8510), we develop and illustrate a simulation-based computational method that relies heavily on deep neural network technology. For test problems studied thus far, our method is accurate to within a fraction of one percent, and is computationally feasible in dimensions up to at least $d=30$. ",
    "url": "https://arxiv.org/abs/2309.11651",
    "authors": [
      "Baris Ata",
      "J. Michael Harrison",
      "Nian Si"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.11661",
    "title": "Neural Image Compression Using Masked Sparse Visual Representation",
    "abstract": "We study neural image compression based on the Sparse Visual Representation (SVR), where images are embedded into a discrete latent space spanned by learned visual codebooks. By sharing codebooks with the decoder, the encoder transfers integer codeword indices that are efficient and cross-platform robust, and the decoder retrieves the embedded latent feature using the indices for reconstruction. Previous SVR-based compression lacks effective mechanism for rate-distortion tradeoffs, where one can only pursue either high reconstruction quality or low transmission bitrate. We propose a Masked Adaptive Codebook learning (M-AdaCode) method that applies masks to the latent feature subspace to balance bitrate and reconstruction quality. A set of semantic-class-dependent basis codebooks are learned, which are weighted combined to generate a rich latent feature for high-quality reconstruction. The combining weights are adaptively derived from each input image, providing fidelity information with additional transmission costs. By masking out unimportant weights in the encoder and recovering them in the decoder, we can trade off reconstruction quality for transmission bits, and the masking rate controls the balance between bitrate and distortion. Experiments over the standard JPEG-AI dataset demonstrate the effectiveness of our M-AdaCode approach. ",
    "url": "https://arxiv.org/abs/2309.11661",
    "authors": [
      "Wei Jiang",
      "Wei Wang",
      "Yue Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.11676",
    "title": "Cardinality and Representation of Stone Relation Algebras",
    "abstract": "Previous work has axiomatised the cardinality operation in relation algebras, which counts the number of edges of an unweighted graph. We generalise the cardinality axioms to Stone relation algebras, which model weighted graphs, and study the relationships between various axioms for cardinality. This results in simpler cardinality axioms also for relation algebras. We give sufficient conditions for the representation of Stone relation algebras and for Stone relation algebras to be relation algebras. ",
    "url": "https://arxiv.org/abs/2309.11676",
    "authors": [
      "Hitoshi Furusawa",
      "Walter Guttmann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2309.11680",
    "title": "Federated Learning with Neural Graphical Models",
    "abstract": "Federated Learning (FL) addresses the need to create models based on proprietary data in such a way that multiple clients retain exclusive control over their data, while all benefit from improved model accuracy due to pooled resources. Recently proposed Neural Graphical Models (NGMs) are Probabilistic Graphical models that utilize the expressive power of neural networks to learn complex non-linear dependencies between the input features. They learn to capture the underlying data distribution and have efficient algorithms for inference and sampling. We develop a FL framework which maintains a global NGM model that learns the averaged information from the local NGM models while keeping the training data within the client's environment. Our design, FedNGMs, avoids the pitfalls and shortcomings of neuron matching frameworks like Federated Matched Averaging that suffers from model parameter explosion. Our global model size remains constant throughout the process. In the cases where clients have local variables that are not part of the combined global distribution, we propose a `Stitching' algorithm, which personalizes the global NGM models by merging the additional variables using the client's data. FedNGM is robust to data heterogeneity, large number of participants, and limited communication bandwidth. ",
    "url": "https://arxiv.org/abs/2309.11680",
    "authors": [
      "Urszula Chajewska",
      "Harsh Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11682",
    "title": "Dr. FERMI: A Stochastic Distributionally Robust Fair Empirical Risk  Minimization Framework",
    "abstract": "While training fair machine learning models has been studied extensively in recent years, most developed methods rely on the assumption that the training and test data have similar distributions. In the presence of distribution shifts, fair models may behave unfairly on test data. There have been some developments for fair learning robust to distribution shifts to address this shortcoming. However, most proposed solutions are based on the assumption of having access to the causal graph describing the interaction of different features. Moreover, existing algorithms require full access to data and cannot be used when small batches are used (stochastic/batch implementation). This paper proposes the first stochastic distributionally robust fairness framework with convergence guarantees that do not require knowledge of the causal graph. More specifically, we formulate the fair inference in the presence of the distribution shift as a distributionally robust optimization problem under $L_p$ norm uncertainty sets with respect to the Exponential Renyi Mutual Information (ERMI) as the measure of fairness violation. We then discuss how the proposed method can be implemented in a stochastic fashion. We have evaluated the presented framework's performance and efficiency through extensive experiments on real datasets consisting of distribution shifts. ",
    "url": "https://arxiv.org/abs/2309.11682",
    "authors": [
      "Sina Baharlouei",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.11689",
    "title": "Task-Oriented Grasping with Point Cloud Representation of Objects",
    "abstract": "In this paper, we study the problem of task-oriented grasp synthesis from partial point cloud data using an eye-in-hand camera configuration. In task-oriented grasp synthesis, a grasp has to be selected so that the object is not lost during manipulation, and it is also ensured that adequate force/moment can be applied to perform the task. We formalize the notion of a gross manipulation task as a constant screw motion (or a sequence of constant screw motions) to be applied to the object after grasping. Using this notion of task, and a corresponding grasp quality metric developed in our prior work, we use a neural network to approximate a function for predicting the grasp quality metric on a cuboid shape. We show that by using a bounding box obtained from the partial point cloud of an object, and the grasp quality metric mentioned above, we can generate a good grasping region on the bounding box that can be used to compute an antipodal grasp on the actual object. Our algorithm does not use any manually labeled data or grasping simulator, thus making it very efficient to implement and integrate with screw linear interpolation-based motion planners. We present simulation as well as experimental results that show the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2309.11689",
    "authors": [
      "Aditya Patankar",
      "Khiem Phi",
      "Dasharadhan Mahalingam",
      "Nilanjan Chakraborty",
      "IV Ramakrishnan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.11695",
    "title": "Active perception network for non-myopic online exploration and visual  surface coverage",
    "abstract": "This work addresses the problem of online exploration and visual sensor coverage of unknown environments. We introduce a novel perception roadmap we refer to as the Active Perception Network (APN) that serves as a hierarchical topological graph describing how to traverse and perceive an incrementally built spatial map of the environment. The APN state is incrementally updated to expand a connected configuration space that extends throughout as much of the known space as possible, using efficient difference-awareness techniques that track the discrete changes of the spatial map to inform the updates. A frontier-guided approach is presented for efficient evaluation of information gain and covisible information, which guides view sampling and refinement to ensure maximum coverage of the unmapped space is maintained within the APN. The updated roadmap is hierarchically decomposed into subgraph regions which we use to facilitate a non-myopic global view sequence planner. A comparative analysis to several state-of-the-art approaches was conducted, showing significant performance improvements in terms of total exploration time and surface coverage, and demonstrating high computational efficiency that is scalable to large and complex environments. ",
    "url": "https://arxiv.org/abs/2309.11695",
    "authors": [
      "David Vutetakis",
      "Jing Xiao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.11698",
    "title": "Rendering stable features improves sampling-based localisation with  Neural radiance fields",
    "abstract": "Neural radiance fields (NeRFs) are a powerful tool for implicit scene representations, allowing for differentiable rendering and the ability to make predictions about previously unseen viewpoints. From a robotics perspective, there has been growing interest in object and scene-based localisation using NeRFs, with a number of recent works relying on sampling-based or Monte-Carlo localisation schemes. Unfortunately, these can be extremely computationally expensive, requiring multiple network forward passes to infer camera or object pose. To alleviate this, a variety of sampling strategies have been applied, many relying on keypoint recognition techniques from classical computer vision. This work conducts a systematic empirical comparison of these approaches and shows that in contrast to conventional feature matching approaches for geometry-based localisation, sampling-based localisation using NeRFs benefits significantly from stable features. Results show that rendering stable features can result in a tenfold reduction in the number of forward passes required, a significant speed improvement. ",
    "url": "https://arxiv.org/abs/2309.11698",
    "authors": [
      "Boxuan Zhang",
      "Lindsay Kleeman",
      "Michael Burke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.11705",
    "title": "Meta OOD Learning for Continuously Adaptive OOD Detection",
    "abstract": "Out-of-distribution (OOD) detection is crucial to modern deep learning applications by identifying and alerting about the OOD samples that should not be tested or used for making predictions. Current OOD detection methods have made significant progress when in-distribution (ID) and OOD samples are drawn from static distributions. However, this can be unrealistic when applied to real-world systems which often undergo continuous variations and shifts in ID and OOD distributions over time. Therefore, for an effective application in real-world systems, the development of OOD detection methods that can adapt to these dynamic and evolving distributions is essential. In this paper, we propose a novel and more realistic setting called continuously adaptive out-of-distribution (CAOOD) detection which targets on developing an OOD detection model that enables dynamic and quick adaptation to a new arriving distribution, with insufficient ID samples during deployment time. To address CAOOD, we develop meta OOD learning (MOL) by designing a learning-to-adapt diagram such that a good initialized OOD detection model is learned during the training process. In the testing process, MOL ensures OOD detection performance over shifting distributions by quickly adapting to new distributions with a few adaptations. Extensive experiments on several OOD benchmarks endorse the effectiveness of our method in preserving both ID classification accuracy and OOD detection performance on continuously shifting distributions. ",
    "url": "https://arxiv.org/abs/2309.11705",
    "authors": [
      "Xinheng Wu",
      "Jie Lu",
      "Zhen Fang",
      "Guangquan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11707",
    "title": "Efficient Long-Short Temporal Attention Network for Unsupervised Video  Object Segmentation",
    "abstract": "Unsupervised Video Object Segmentation (VOS) aims at identifying the contours of primary foreground objects in videos without any prior knowledge. However, previous methods do not fully use spatial-temporal context and fail to tackle this challenging task in real-time. This motivates us to develop an efficient Long-Short Temporal Attention network (termed LSTA) for unsupervised VOS task from a holistic view. Specifically, LSTA consists of two dominant modules, i.e., Long Temporal Memory and Short Temporal Attention. The former captures the long-term global pixel relations of the past frames and the current frame, which models constantly present objects by encoding appearance pattern. Meanwhile, the latter reveals the short-term local pixel relations of one nearby frame and the current frame, which models moving objects by encoding motion pattern. To speedup the inference, the efficient projection and the locality-based sliding window are adopted to achieve nearly linear time complexity for the two light modules, respectively. Extensive empirical studies on several benchmarks have demonstrated promising performances of the proposed method with high efficiency. ",
    "url": "https://arxiv.org/abs/2309.11707",
    "authors": [
      "Ping Li",
      "Yu Zhang",
      "Li Yuan",
      "Huaxin Xiao",
      "Binbin Lin",
      "Xianghua Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11726",
    "title": "Turaco: Complexity-Guided Data Sampling for Training Neural Surrogates  of Programs",
    "abstract": "Programmers and researchers are increasingly developing surrogates of programs, models of a subset of the observable behavior of a given program, to solve a variety of software development challenges. Programmers train surrogates from measurements of the behavior of a program on a dataset of input examples. A key challenge of surrogate construction is determining what training data to use to train a surrogate of a given program. We present a methodology for sampling datasets to train neural-network-based surrogates of programs. We first characterize the proportion of data to sample from each region of a program's input space (corresponding to different execution paths of the program) based on the complexity of learning a surrogate of the corresponding execution path. We next provide a program analysis to determine the complexity of different paths in a program. We evaluate these results on a range of real-world programs, demonstrating that complexity-guided sampling results in empirical improvements in accuracy. ",
    "url": "https://arxiv.org/abs/2309.11726",
    "authors": [
      "Alex Renda",
      "Yi Ding",
      "Michael Carbin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.11741",
    "title": "Unveiling Optimal SDG Pathways: An Innovative Approach Leveraging Graph  Pruning and Intent Graph for Effective Recommendations",
    "abstract": "The recommendation of appropriate development pathways, also known as ecological civilization patterns for achieving Sustainable Development Goals (namely, sustainable development patterns), are of utmost importance for promoting ecological, economic, social, and resource sustainability in a specific region. To achieve this, the recommendation process must carefully consider the region's natural, environmental, resource, and economic characteristics. However, current recommendation algorithms in the field of computer science fall short in adequately addressing the spatial heterogeneity related to environment and sparsity of regional historical interaction data, which limits their effectiveness in recommending sustainable development patterns. To overcome these challenges, this paper proposes a method called User Graph after Pruning and Intent Graph (UGPIG). Firstly, we utilize the high-density linking capability of the pruned User Graph to address the issue of spatial heterogeneity neglect in recommendation algorithms. Secondly, we construct an Intent Graph by incorporating the intent network, which captures the preferences for attributes including environmental elements of target regions. This approach effectively alleviates the problem of sparse historical interaction data in the region. Through extensive experiments, we demonstrate that UGPIG outperforms state-of-the-art recommendation algorithms like KGCN, KGAT, and KGIN in sustainable development pattern recommendations, with a maximum improvement of 9.61% in Top-3 recommendation performance. ",
    "url": "https://arxiv.org/abs/2309.11741",
    "authors": [
      "Zhihang Yu",
      "Shu Wang",
      "Yunqiang Zhu",
      "Wen Yuan",
      "Xiaoliang Dai",
      "Zhiqiang Zou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11747",
    "title": "MarkNerf:Watermarking for Neural Radiance Field",
    "abstract": "A watermarking algorithm is proposed in this paper to address the copyright protection issue of implicit 3D models. The algorithm involves embedding watermarks into the images in the training set through an embedding network, and subsequently utilizing the NeRF model for 3D modeling. A copyright verifier is employed to generate a backdoor image by providing a secret perspective as input to the neural radiation field. Subsequently, a watermark extractor is devised using the hyperparameterization method of the neural network to extract the embedded watermark image from that perspective. In a black box scenario, if there is a suspicion that the 3D model has been used without authorization, the verifier can extract watermarks from a secret perspective to verify network copyright. Experimental results demonstrate that the proposed algorithm effectively safeguards the copyright of 3D models. Furthermore, the extracted watermarks exhibit favorable visual effects and demonstrate robust resistance against various types of noise attacks. ",
    "url": "https://arxiv.org/abs/2309.11747",
    "authors": [
      "Lifeng Chen",
      "Jia Liu",
      "Yan Ke",
      "Wenquan Sun",
      "Weina Dong",
      "Xiaozhong Pan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.11751",
    "title": "How Robust is Google's Bard to Adversarial Image Attacks?",
    "abstract": "Multimodal Large Language Models (MLLMs) that integrate text and other modalities (especially vision) have achieved unprecedented performance in various multimodal tasks. However, due to the unsolved adversarial robustness problem of vision models, MLLMs can have more severe safety and security risks by introducing the vision inputs. In this work, we study the adversarial robustness of Google's Bard, a competitive chatbot to ChatGPT that released its multimodal capability recently, to better understand the vulnerabilities of commercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs, the generated adversarial examples can mislead Bard to output wrong image descriptions with a 22% success rate based solely on the transferability. We show that the adversarial examples can also attack other MLLMs, e.g., a 26% attack success rate against Bing Chat and a 86% attack success rate against ERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face detection and toxicity detection of images. We design corresponding attacks to evade these defenses, demonstrating that the current defenses of Bard are also vulnerable. We hope this work can deepen our understanding on the robustness of MLLMs and facilitate future research on defenses. Our code is available at https://github.com/thu-ml/Attack-Bard. ",
    "url": "https://arxiv.org/abs/2309.11751",
    "authors": [
      "Yinpeng Dong",
      "Huanran Chen",
      "Jiawei Chen",
      "Zhengwei Fang",
      "Xiao Yang",
      "Yichi Zhang",
      "Yu Tian",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11755",
    "title": "2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic  Segmentation on Point Cloud",
    "abstract": "Recently, multi-modality models have been introduced because of the complementary information from different sensors such as LiDAR and cameras. It requires paired data along with precise calibrations for all modalities, the complicated calibration among modalities hugely increases the cost of collecting such high-quality datasets, and hinder it from being applied to practical scenarios. Inherit from the previous works, we not only fuse the information from multi-modality without above issues, and also exhaust the information in the RGB modality. We introduced the 2D Detection Annotations Transmittable Aggregation(\\textbf{2DDATA}), designing a data-specific branch, called \\textbf{Local Object Branch}, which aims to deal with points in a certain bounding box, because of its easiness of acquiring 2D bounding box annotations. We demonstrate that our simple design can transmit bounding box prior information to the 3D encoder model, proving the feasibility of large multi-modality models fused with modality-specific data. ",
    "url": "https://arxiv.org/abs/2309.11755",
    "authors": [
      "Guan-Cheng Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11759",
    "title": "Symbol Detection for Coarsely Quantized OTFS",
    "abstract": "This paper explicitly models a coarse and noisy quantization in a communication system empowered by orthogonal time frequency space (OTFS) for cost and power efficiency. We first point out, with coarse quantization, the effective channel is imbalanced and thus no longer able to circularly shift the transmitted symbols along the delay-Doppler domain. Meanwhile, the effective channel is non-isotropic, which imposes a significant loss to symbol detection algorithms like the original approximate message passing (AMP). Although the algorithm of generalized expectation consistent for signal recovery (GEC-SR) can mitigate this loss, the complexity in computation is prohibitively high, mainly due to an dramatic increase in the matrix size of OTFS. In this context, we propose a low-complexity algorithm that incorporates into the GEC-SR a quick inversion of quasi-banded matrices, reducing the complexity from a cubic order to a linear order while keeping the performance at the same level. ",
    "url": "https://arxiv.org/abs/2309.11759",
    "authors": [
      "Junwei He",
      "Haochuan Zhang",
      "Chao Dong",
      "Huimin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.11766",
    "title": "Dictionary Attack on IMU-based Gait Authentication",
    "abstract": "We present a novel adversarial model for authentication systems that use gait patterns recorded by the inertial measurement unit (IMU) built into smartphones. The attack idea is inspired by and named after the concept of a dictionary attack on knowledge (PIN or password) based authentication systems. In particular, this work investigates whether it is possible to build a dictionary of IMUGait patterns and use it to launch an attack or find an imitator who can actively reproduce IMUGait patterns that match the target's IMUGait pattern. Nine physically and demographically diverse individuals walked at various levels of four predefined controllable and adaptable gait factors (speed, step length, step width, and thigh-lift), producing 178 unique IMUGait patterns. Each pattern attacked a wide variety of user authentication models. The deeper analysis of error rates (before and after the attack) challenges the belief that authentication systems based on IMUGait patterns are the most difficult to spoof; further research is needed on adversarial models and associated countermeasures. ",
    "url": "https://arxiv.org/abs/2309.11766",
    "authors": [
      "Rajesh Kumar",
      "Can Isik",
      "Chilukuri K. Mohan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.11773",
    "title": "A Real-Time Multi-Task Learning System for Joint Detection of Face,  Facial Landmark and Head Pose",
    "abstract": "Extreme head postures pose a common challenge across a spectrum of facial analysis tasks, including face detection, facial landmark detection (FLD), and head pose estimation (HPE). These tasks are interdependent, where accurate FLD relies on robust face detection, and HPE is intricately associated with these key points. This paper focuses on the integration of these tasks, particularly when addressing the complexities posed by large-angle face poses. The primary contribution of this study is the proposal of a real-time multi-task detection system capable of simultaneously performing joint detection of faces, facial landmarks, and head poses. This system builds upon the widely adopted YOLOv8 detection framework. It extends the original object detection head by incorporating additional landmark regression head, enabling efficient localization of crucial facial landmarks. Furthermore, we conduct optimizations and enhancements on various modules within the original YOLOv8 framework. To validate the effectiveness and real-time performance of our proposed model, we conduct extensive experiments on 300W-LP and AFLW2000-3D datasets. The results obtained verify the capability of our model to tackle large-angle face pose challenges while delivering real-time performance across these interconnected tasks. ",
    "url": "https://arxiv.org/abs/2309.11773",
    "authors": [
      "Qingtian Wu",
      "Liming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11782",
    "title": "DimCL: Dimensional Contrastive Learning For Improving Self-Supervised  Learning",
    "abstract": "Self-supervised learning (SSL) has gained remarkable success, for which contrastive learning (CL) plays a key role. However, the recent development of new non-CL frameworks has achieved comparable or better performance with high improvement potential, prompting researchers to enhance these frameworks further. Assimilating CL into non-CL frameworks has been thought to be beneficial, but empirical evidence indicates no visible improvements. In view of that, this paper proposes a strategy of performing CL along the dimensional direction instead of along the batch direction as done in conventional contrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL aims to enhance the feature diversity, and it can serve as a regularizer to prior SSL frameworks. DimCL has been found to be effective, and the hardness-aware property is identified as a critical reason for its success. Extensive experimental results reveal that assimilating DimCL into SSL frameworks leads to performance improvement by a non-trivial margin on various datasets and backbone architectures. ",
    "url": "https://arxiv.org/abs/2309.11782",
    "authors": [
      "Thanh Nguyen",
      "Trung Pham",
      "Chaoning Zhang",
      "Tung Luu",
      "Thang Vu",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11783",
    "title": "Frame Pairwise Distance Loss for Weakly-supervised Sound Event Detection",
    "abstract": "Weakly-supervised learning has emerged as a promising approach to leverage limited labeled data in various domains by bridging the gap between fully supervised methods and unsupervised techniques. Acquisition of strong annotations for detecting sound events is prohibitively expensive, making weakly supervised learning a more cost-effective and broadly applicable alternative. In order to enhance the recognition rate of the learning of detection of weakly-supervised sound events, we introduce a Frame Pairwise Distance (FPD) loss branch, complemented with a minimal amount of synthesized data. The corresponding sampling and label processing strategies are also proposed. Two distinct distance metrics are employed to evaluate the proposed approach. Finally, the method is validated on the standard DCASE dataset. The obtained experimental results corroborated the efficacy of this approach. ",
    "url": "https://arxiv.org/abs/2309.11783",
    "authors": [
      "Rui Tao",
      "Yuxing Huang",
      "Xiangdong Wang",
      "Long Yan",
      "Lufeng Zhai",
      "Kazushige Ouchi",
      "Taihao Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.11798",
    "title": "A Comprehensive Review of Community Detection in Graphs",
    "abstract": "The study of complex networks has significantly advanced our understanding of community structures which serves as a crucial feature of real-world graphs. Detecting communities in graphs is a challenging problem with applications in sociology, biology, and computer science. Despite the efforts of an interdisciplinary community of scientists, a satisfactory solution to this problem has not yet been achieved. This review article delves into the topic of community detection in graphs, which serves as a crucial role in understanding the organization and functioning of complex systems. We begin by introducing the concept of community structure, which refers to the arrangement of vertices into clusters, with strong internal connections and weaker connections between clusters. Then, we provide a thorough exposition of various community detection methods, including a new method designed by us. Additionally, we explore real-world applications of community detection in diverse networks. In conclusion, this comprehensive review provides a deep understanding of community detection in graphs. It serves as a valuable resource for researchers and practitioners in multiple disciplines, offering insights into the challenges, methodologies, and applications of community detection in complex networks. ",
    "url": "https://arxiv.org/abs/2309.11798",
    "authors": [
      "Songlai Ning",
      "Jiakang Li",
      "Yonggang Lu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11804",
    "title": "FGFusion: Fine-Grained Lidar-Camera Fusion for 3D Object Detection",
    "abstract": "Lidars and cameras are critical sensors that provide complementary information for 3D detection in autonomous driving. While most prevalent methods progressively downscale the 3D point clouds and camera images and then fuse the high-level features, the downscaled features inevitably lose low-level detailed information. In this paper, we propose Fine-Grained Lidar-Camera Fusion (FGFusion) that make full use of multi-scale features of image and point cloud and fuse them in a fine-grained way. First, we design a dual pathway hierarchy structure to extract both high-level semantic and low-level detailed features of the image. Second, an auxiliary network is introduced to guide point cloud features to better learn the fine-grained spatial information. Finally, we propose multi-scale fusion (MSF) to fuse the last N feature maps of image and point cloud. Extensive experiments on two popular autonomous driving benchmarks, i.e. KITTI and Waymo, demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2309.11804",
    "authors": [
      "Zixuan Yin",
      "Han Sun",
      "Ningzhong Liu",
      "Huiyu Zhou",
      "Jiaquan Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11814",
    "title": "Physics-Informed Neural Network-Based Parametric Deep Material Network  for Multiphysics Behavior Prediction of Heterogeneous Materials with a  Varying Morphology",
    "abstract": "Deep Material Network (DMN) has recently emerged as a data-driven surrogate model for heterogeneous materials. Given a particular microstructural morphology, the effective linear and nonlinear behaviors can be successfully approximated by such physics-based neural-network like architecture. In this work, a novel parametric DMN architecture is proposed for multiscale materials with a varying microstructure characterized by several parameters. A Physics-Informed Neural Network (PINN) is used to account for the dependence of DMN fitting parameters on the microstructural ones. Micromechanical constraints are prescribed both on the network architecture and on the output of this PINN. The proposed PINN-DMN architecture is also recast in a multiphysics setting, where physical properties other than the mechanical ones can also be predicted. In the numerical simulations conducted on three parametric microstructures, PINN-DMN demonstrates satisfying interpolative and extrapolative generalization capabilities when morphology varies. The effective multiphysics behaviors of such parametric multiscale materials can thus be predicted and encoded by PINN-DMN with high accuracy and efficiency. ",
    "url": "https://arxiv.org/abs/2309.11814",
    "authors": [
      "Tianyi Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2309.11824",
    "title": "Word Embedding with Neural Probabilistic Prior",
    "abstract": "To improve word representation learning, we propose a probabilistic prior which can be seamlessly integrated with word embedding models. Different from previous methods, word embedding is taken as a probabilistic generative model, and it enables us to impose a prior regularizing word representation learning. The proposed prior not only enhances the representation of embedding vectors but also improves the model's robustness and stability. The structure of the proposed prior is simple and effective, and it can be easily implemented and flexibly plugged in most existing word embedding models. Extensive experiments show the proposed method improves word representation on various tasks. ",
    "url": "https://arxiv.org/abs/2309.11824",
    "authors": [
      "Shaogang Ren",
      "Dingcheng Li",
      "Ping Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11830",
    "title": "A Chinese Prompt Attack Dataset for LLMs with Evil Content",
    "abstract": "Large Language Models (LLMs) present significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with harmful contents. Researchers are interested in Prompt Attack and Defense with LLMs, while there is no publicly available dataset to evaluate the abilities of defending prompt attack. In this paper, we introduce a Chinese Prompt Attack Dataset for LLMs, called CPAD. Our prompts aim to induce LLMs to generate unexpected outputs with several carefully designed prompt attack approaches and widely concerned attacking contents. Different from previous datasets involving safety estimation, We construct the prompts considering three dimensions: contents, attacking methods and goals, thus the responses can be easily evaluated and analysed. We run several well-known Chinese LLMs on our dataset, and the results show that our prompts are significantly harmful to LLMs, with around 70% attack success rate. We will release CPAD to encourage further studies on prompt attack and defense. ",
    "url": "https://arxiv.org/abs/2309.11830",
    "authors": [
      "Chengyuan Liu",
      "Fubang Zhao",
      "Lizhi Qing",
      "Yangyang Kang",
      "Changlong Sun",
      "Kun Kuang",
      "Fei Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11843",
    "title": "Temporal Network Core Decomposition and Community Search",
    "abstract": "We introduce a new generalization of the $k$-core decomposition for temporal networks that respects temporal dynamics. In contrast to the standard definition and previous core-like decompositions for temporal graphs, our $(k,\\Delta)$-core decomposition is an edge-based decomposition founded on the new notion of $\\Delta$-degree. The $\\Delta$-degree of an edge is defined as the minimum number of edges incident to one of its endpoints that have a temporal distance of at most~$\\Delta$. Moreover, we define a new notion of temporal connectedness leading to an efficiently computable equivalence relation between so-called $\\Delta$-connected components of the temporal network. We provide efficient algorithms for the $(k,\\Delta)$-core decomposition and $\\Delta$-connectedness, and apply them to solve community search problems, where we are given a query node and want to find a densely connected community containing the query node. Such a community is an edge-induced temporal subgraph representing densely connected groups of nodes with frequent interactions, which also captures changes over time. We provide an efficient algorithm for community search for the case without restricting the number of nodes. If the number of nodes is restricted, we show that the decision version is NP-complete. In our evaluation, we show how in a real-world social network, the inner $(k,\\Delta)$-cores contain only the spreading of misinformation and that the $\\Delta$-connected components of the cores are highly edge-homophilic, i.e., the majorities of the edges in the $\\Delta$-connected components represent either misinformation or fact-checking. Moreover, we demonstrate how our algorithms for $\\Delta$-community search successfully and efficiently identify informative structures in collaboration networks. ",
    "url": "https://arxiv.org/abs/2309.11843",
    "authors": [
      "Lutz Oettershagen",
      "Athanasios L. Konstantinidis",
      "Giuseppe F. Italiano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.11845",
    "title": "TMac: Temporal Multi-Modal Graph Learning for Acoustic Event  Classification",
    "abstract": "Audiovisual data is everywhere in this digital age, which raises higher requirements for the deep learning models developed on them. To well handle the information of the multi-modal data is the key to a better audiovisual modal. We observe that these audiovisual data naturally have temporal attributes, such as the time information for each frame in the video. More concretely, such data is inherently multi-modal according to both audio and visual cues, which proceed in a strict chronological order. It indicates that temporal information is important in multi-modal acoustic event modeling for both intra- and inter-modal. However, existing methods deal with each modal feature independently and simply fuse them together, which neglects the mining of temporal relation and thus leads to sub-optimal performance. With this motivation, we propose a Temporal Multi-modal graph learning method for Acoustic event Classification, called TMac, by modeling such temporal information via graph learning techniques. In particular, we construct a temporal graph for each acoustic event, dividing its audio data and video data into multiple segments. Each segment can be considered as a node, and the temporal relationships between nodes can be considered as timestamps on their edges. In this case, we can smoothly capture the dynamic information in intra-modal and inter-modal. Several experiments are conducted to demonstrate TMac outperforms other SOTA models in performance. Our code is available at https://github.com/MGitHubL/TMac. ",
    "url": "https://arxiv.org/abs/2309.11845",
    "authors": [
      "Meng Liu",
      "Ke Liang",
      "Dayu Hu",
      "Hao Yu",
      "Yue Liu",
      "Lingyuan Meng",
      "Wenxuan Tu",
      "Sihang Zhou",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.11851",
    "title": "DEYOv3: DETR with YOLO for Real-time Object Detection",
    "abstract": "Recently, end-to-end object detectors have gained significant attention from the research community due to their outstanding performance. However, DETR typically relies on supervised pretraining of the backbone on ImageNet, which limits the practical application of DETR and the design of the backbone, affecting the model's potential generalization ability. In this paper, we propose a new training method called step-by-step training. Specifically, in the first stage, the one-to-many pre-trained YOLO detector is used to initialize the end-to-end detector. In the second stage, the backbone and encoder are consistent with the DETR-like model, but only the detector needs to be trained from scratch. Due to this training method, the object detector does not need the additional dataset (ImageNet) to train the backbone, which makes the design of the backbone more flexible and dramatically reduces the training cost of the detector, which is helpful for the practical application of the object detector. At the same time, compared with the DETR-like model, the step-by-step training method can achieve higher accuracy than the traditional training method of the DETR-like model. With the aid of this novel training method, we propose a brand-new end-to-end real-time object detection model called DEYOv3. DEYOv3-N achieves 41.1% on COCO val2017 and 270 FPS on T4 GPU, while DEYOv3-L achieves 51.3% AP and 102 FPS. Without the use of additional training data, DEYOv3 surpasses all existing real-time object detectors in terms of both speed and accuracy. It is worth noting that for models of N, S, and M scales, the training on the COCO dataset can be completed using a single 24GB RTX3090 GPU. ",
    "url": "https://arxiv.org/abs/2309.11851",
    "authors": [
      "Haodong Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11869",
    "title": "Syntactic Variation Across the Grammar: Modelling a Complex Adaptive  System",
    "abstract": "While language is a complex adaptive system, most work on syntactic variation observes a few individual constructions in isolation from the rest of the grammar. This means that the grammar, a network which connects thousands of structures at different levels of abstraction, is reduced to a few disconnected variables. This paper quantifies the impact of such reductions by systematically modelling dialectal variation across 49 local populations of English speakers in 16 countries. We perform dialect classification with both an entire grammar as well as with isolated nodes within the grammar in order to characterize the syntactic differences between these dialects. The results show, first, that many individual nodes within the grammar are subject to variation but, in isolation, none perform as well as the grammar as a whole. This indicates that an important part of syntactic variation consists of interactions between different parts of the grammar. Second, the results show that the similarity between dialects depends heavily on the sub-set of the grammar being observed: for example, New Zealand English could be more similar to Australian English in phrasal verbs but at the same time more similar to UK English in dative phrases. ",
    "url": "https://arxiv.org/abs/2309.11869",
    "authors": [
      "Jonathan Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11892",
    "title": "Latency-Aware Radio Resource Optimization in Learning-Based Cloud-Aided  Small Cell Wireless Networks",
    "abstract": "Low latency communication is one of the fundamental requirements for 5G wireless networks and beyond. In this paper, a novel approach for joint caching, user scheduling and resource allocation is proposed for minimizing the queuing latency in serving user's requests in cloud-aided wireless networks. Due to the slow temporal variations in user requests, a time-scale separation technique is used to decouple the joint caching problem from user scheduling and radio resource allocation problems. To serve the spatio-temporal user requests under storage limitations, a Reinforcement Learning (RL) approach is used to optimize the caching strategy at the small cell base stations by minimizing the content fetching cost. A spectral clustering algorithm is proposed to speed-up the convergence of the RL algorithm for a large content caching problem by clustering contents based on user requests. Meanwhile, a dynamic mechanism is proposed to locally group coupled base stations based on user requests to collaboratively optimize the caching strategies. To further improve the latency in fetching and serving user requests, a dynamic matching algorithm is proposed to schedule users and to allocate users to radio resources based on user requests and queue lengths under probabilistic latency constraints. Simulation results show the proposed approach significantly reduces the average delay from 21% to 90% compared to random caching strategy, random resource allocation and random scheduling baselines. ",
    "url": "https://arxiv.org/abs/2309.11892",
    "authors": [
      "Tamoor-ul-Hassan Syed",
      "Samarakoon Sumudu",
      "Bennis Mehdi",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.11896",
    "title": "Focal Inferential Infusion Coupled with Tractable Density Discrimination  for Implicit Hate Speech Detection",
    "abstract": "Although pre-trained large language models (PLMs) have achieved state-of-the-art on many NLP tasks, they lack understanding of subtle expressions of implicit hate speech. Such nuanced and implicit hate is often misclassified as non-hate. Various attempts have been made to enhance the detection of (implicit) hate content by augmenting external context or enforcing label separation via distance-based metrics. We combine these two approaches and introduce FiADD, a novel Focused Inferential Adaptive Density Discrimination framework. FiADD enhances the PLM finetuning pipeline by bringing the surface form of an implicit hate speech closer to its implied form while increasing the inter-cluster distance among various class labels. We test FiADD on three implicit hate datasets and observe significant improvement in the two-way and three-way hate classification tasks. We further experiment on the generalizability of FiADD on three other tasks, namely detecting sarcasm, irony, and stance, in which surface and implied forms differ, and observe similar performance improvement. We analyze the generated latent space to understand its evolution under FiADD, which corroborates the advantage of employing FiADD for implicit hate speech detection. ",
    "url": "https://arxiv.org/abs/2309.11896",
    "authors": [
      "Sarah Masud",
      "Ashutosh Bajpai",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.11898",
    "title": "REM-U-net: Deep Learning Based Agile REM Prediction with  Energy-Efficient Cell-Free Use Case",
    "abstract": "Radio environment maps (REMs) hold a central role in optimizing wireless network deployment, enhancing network performance, and ensuring effective spectrum management. Conventional REM prediction methods are either excessively time-consuming, e.g., ray tracing, or inaccurate, e.g., statistical models, limiting their adoption in modern inherently dynamic wireless networks. Deep-learning-based REM prediction has recently attracted considerable attention as an appealing, accurate, and time-efficient alternative. However, existing works on REM prediction using deep learning are either confined to 2D maps or use a limited dataset. In this paper, we introduce a runtime-efficient REM prediction framework based on u-nets, trained on a large-scale 3D maps dataset. In addition, data preprocessing steps are investigated to further refine the REM prediction accuracy. The proposed u-net framework, along with preprocessing steps, are evaluated in the context of the 2023 IEEE ICASSP Signal Processing Grand Challenge, namely, the First Pathloss Radio Map Prediction Challenge. The evaluation results demonstrate that the proposed method achieves an average normalized root-mean-square error (RMSE) of 0.045 with an average of 14 milliseconds (ms) runtime. Finally, we position our achieved REM prediction accuracy in the context of a relevant cell-free massive multiple-input multiple-output (CF-mMIMO) use case. We demonstrate that one can obviate consuming energy on large-scale fading measurements and rely on predicted REM instead to decide on which sleep access points (APs) to switch on in a CF-mMIMO network that adopts a minimum propagation loss AP switch ON/OFF strategy. ",
    "url": "https://arxiv.org/abs/2309.11898",
    "authors": [
      "Hazem Sallouha",
      "Shamik Sarkar",
      "Enes Krijestorac",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.11899",
    "title": "Unlocking the Heart Using Adaptive Locked Agnostic Networks",
    "abstract": "Supervised training of deep learning models for medical imaging applications requires a significant amount of labeled data. This is posing a challenge as the images are required to be annotated by medical professionals. To address this limitation, we introduce the Adaptive Locked Agnostic Network (ALAN), a concept involving self-supervised visual feature extraction using a large backbone model to produce anatomically robust semantic self-segmentation. In the ALAN methodology, this self-supervised training occurs only once on a large and diverse dataset. Due to the intuitive interpretability of the segmentation, downstream models tailored for specific tasks can be easily designed using white-box models with few parameters. This, in turn, opens up the possibility of communicating the inner workings of a model with domain experts and introducing prior knowledge into it. It also means that the downstream models become less data-hungry compared to fully supervised approaches. These characteristics make ALAN particularly well-suited for resource-scarce scenarios, such as costly clinical trials and rare diseases. In this paper, we apply the ALAN approach to three publicly available echocardiography datasets: EchoNet-Dynamic, CAMUS, and TMED-2. Our findings demonstrate that the self-supervised backbone model robustly identifies anatomical subregions of the heart in an apical four-chamber view. Building upon this, we design two downstream models, one for segmenting a target anatomical region, and a second for echocardiogram view classification. ",
    "url": "https://arxiv.org/abs/2309.11899",
    "authors": [
      "Sylwia Majchrowska",
      "Anders Hildeman",
      "Philip Teare",
      "Tom Diethe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11917",
    "title": "Robust Sensor Fusion for Indoor Wireless Localization",
    "abstract": "Location knowledge in indoor environment using Indoor Positioning Systems (IPS) has become very useful and popular in recent years. Indoor wireless localization suffers from severe multi-path fading and non-line-of-sight conditions. This paper presents a novel indoor localization framework based on sensor fusion of Zigbee Wireless Sensor Networks (WSN) using Received Signal Strength (RSS). The unknown position is equipped with two or more mobile nodes. The range between two mobile nodes is fixed as priori. The attitude (roll, pitch, and yaw) of the mobile node are measured by inertial sensors (ISs). Then the angle and the range between any two nodes can be obtained, and thus the path between the two nodes can be modeled as a curve. Through an efficient cooperation between two or more mobile nodes, this framework effectively exploits the RSS techniques. This constraint help improve the positioning accuracy. Theoretical analysis on localization distortion and Monte Carlo simulations shows that the proposed cooperative strategy of multiple nodes with extended Kalman filter (EKF) achieves significantly higher positioning accuracy than the existing systems, especially in heavily obstructed scenarios. ",
    "url": "https://arxiv.org/abs/2309.11917",
    "authors": [
      "Gang Wang",
      "Zuxuan Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.11923",
    "title": "TextCLIP: Text-Guided Face Image Generation And Manipulation Without  Adversarial Training",
    "abstract": "Text-guided image generation aimed to generate desired images conditioned on given texts, while text-guided image manipulation refers to semantically edit parts of a given image based on specified texts. For these two similar tasks, the key point is to ensure image fidelity as well as semantic consistency. Many previous approaches require complex multi-stage generation and adversarial training, while struggling to provide a unified framework for both tasks. In this work, we propose TextCLIP, a unified framework for text-guided image generation and manipulation without adversarial training. The proposed method accepts input from images or random noise corresponding to these two different tasks, and under the condition of the specific texts, a carefully designed mapping network that exploits the powerful generative capabilities of StyleGAN and the text image representation capabilities of Contrastive Language-Image Pre-training (CLIP) generates images of up to $1024\\times1024$ resolution that can currently be generated. Extensive experiments on the Multi-modal CelebA-HQ dataset have demonstrated that our proposed method outperforms existing state-of-the-art methods, both on text-guided generation tasks and manipulation tasks. ",
    "url": "https://arxiv.org/abs/2309.11923",
    "authors": [
      "Xiaozhou You",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11924",
    "title": "Generic Selfish Mining MDP for DAG Protocols",
    "abstract": "Selfish Mining is strategic rule-breaking to maximize rewards in proof-of-work protocols [3] and Markov Decision Processes (MDPs) are the preferred tool for finding optimal strategies in Bitcoin [4, 10] and similar linear chain protocols [12]. Protocols increasingly adopt non-sequential chain structures [11], for which MDP analysis is more involved [2]. To date, researchers have tailored specific attack spaces for each protocol [2, 4, 5, 7, 10, 12]. Assumptions differ, and validating and comparing results is difficult. To overcome this, we propose a generic attack space that supports the wide class of DAG protocols that provide a total ordering of blocks [11], e. g., Ethereum, Fruitchains, and Parallel Proof-of-Work. Our approach is modular: we specify each protocol as one program, and then derive the Selfish Mining MDPs automatically. ",
    "url": "https://arxiv.org/abs/2309.11924",
    "authors": [
      "Patrik Keller",
      "George Bissias"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.11928",
    "title": "Video Scene Location Recognition with Neural Networks",
    "abstract": "This paper provides an insight into the possibility of scene recognition from a video sequence with a small set of repeated shooting locations (such as in television series) using artificial neural networks. The basic idea of the presented approach is to select a set of frames from each scene, transform them by a pre-trained singleimage pre-processing convolutional network, and classify the scene location with subsequent layers of the neural network. The considered networks have been tested and compared on a dataset obtained from The Big Bang Theory television series. We have investigated different neural network layers to combine individual frames, particularly AveragePooling, MaxPooling, Product, Flatten, LSTM, and Bidirectional LSTM layers. We have observed that only some of the approaches are suitable for the task at hand. ",
    "url": "https://arxiv.org/abs/2309.11928",
    "authors": [
      "Luk\u00e1\u0161 Korel",
      "Petr Pulc",
      "Ji\u0159\u00ed Tumpach",
      "Martin Hole\u0148a"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.11941",
    "title": "A Digital Marketplace Combining WS-Agreement, Service Negotiation  Protocols and Heterogeneous Services",
    "abstract": "With the ever increasing importance of web services and the Cloud as a reliable commodity to provide business value as well as consolidate IT infrastructure, electronic contracts have become very important. WS-Agreement has itself established as a well accepted container format for describing such contracts. However, the semantic interpretation of the terms contained in these contracts, as well as the process of agreeing to contracts when multiple options have to be considered (negotiation), are still pretty much dealt with on a case by case basis. In this paper we address the issues of diverging contracts and varying contract negotiation protocols by introducing the concept of a contract aware marketplace, which abstracts from the heterogeneous offers of different services providers. This allows for the automated consumption of services solely based on preferences, instead of additional restrictions such as understanding of contract terms and/or negotiation protocols. We also contribute an evaluation of several existing negotiation concepts/protocols. We think that reducing the complexity for automated contract negotiation and thus service consumption is a key for the success of future service and Cloud infrastructures. ",
    "url": "https://arxiv.org/abs/2309.11941",
    "authors": [
      "Ralph Vigne",
      "Juergen Mangler",
      "Erich Schikuta"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2309.11955",
    "title": "A Study of Forward-Forward Algorithm for Self-Supervised Learning",
    "abstract": "Self-supervised representation learning has seen remarkable progress in the last few years, with some of the recent methods being able to learn useful image representations without labels. These methods are trained using backpropagation, the de facto standard. Recently, Geoffrey Hinton proposed the forward-forward algorithm as an alternative training method. It utilizes two forward passes and a separate loss function for each layer to train the network without backpropagation. In this study, for the first time, we study the performance of forward-forward vs. backpropagation for self-supervised representation learning and provide insights into the learned representation spaces. Our benchmark employs four standard datasets, namely MNIST, F-MNIST, SVHN and CIFAR-10, and three commonly used self-supervised representation learning techniques, namely rotation, flip and jigsaw. Our main finding is that while the forward-forward algorithm performs comparably to backpropagation during (self-)supervised training, the transfer performance is significantly lagging behind in all the studied settings. This may be caused by a combination of factors, including having a loss function for each layer and the way the supervised training is realized in the forward-forward paradigm. In comparison to backpropagation, the forward-forward algorithm focuses more on the boundaries and drops part of the information unnecessary for making decisions which harms the representation learning goal. Further investigation and research are necessary to stabilize the forward-forward strategy for self-supervised learning, to work beyond the datasets and configurations demonstrated by Geoffrey Hinton. ",
    "url": "https://arxiv.org/abs/2309.11955",
    "authors": [
      "Jonas Brenig",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.11965",
    "title": "Coordination Control of Discrete Event Systems under Cyber Attacks",
    "abstract": "This paper investigates the coordination control of discrete event systems in the presence of combined sensor and actuator attacks. Discrete event systems are modeled as automata, and sensor attacks are defined using specific attack languages. The approach involves employing multiple local supervisors to control the system. The primary objective is to devise these local supervisors to ensure the system's safety, even when facing sensor and actuator attacks. The paper establishes the necessary and sufficient conditions for the existence of such supervisors in terms of conditional decomposability, CA-controllability, and CA-observability. Furthermore, a methodology is developed to compute local state estimates when sensor attacks occur. Based on the local state estimates, local supervisors are designed to ensure the safety of a system even under cyber attacks. ",
    "url": "https://arxiv.org/abs/2309.11965",
    "authors": [
      "Fei Wang",
      "Jan Komenda",
      "Feng Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.11966",
    "title": "NeuralLabeling: A versatile toolset for labeling vision datasets using  Neural Radiance Fields",
    "abstract": "We present NeuralLabeling, a labeling approach and toolset for annotating a scene using either bounding boxes or meshes and generating segmentation masks, affordance maps, 2D bounding boxes, 3D bounding boxes, 6DOF object poses, depth maps and object meshes. NeuralLabeling uses Neural Radiance Fields (NeRF) as renderer, allowing labeling to be performed using 3D spatial tools while incorporating geometric clues such as occlusions, relying only on images captured from multiple viewpoints as input. To demonstrate the applicability of NeuralLabeling to a practical problem in robotics, we added ground truth depth maps to 30000 frames of transparent object RGB and noisy depth maps of glasses placed in a dishwasher captured using an RGBD sensor, yielding the Dishwasher30k dataset. We show that training a simple deep neural network with supervision using the annotated depth maps yields a higher reconstruction performance than training with the previously applied weakly supervised approach. ",
    "url": "https://arxiv.org/abs/2309.11966",
    "authors": [
      "Floris Erich",
      "Naoya Chiba",
      "Yusuke Yoshiyasu",
      "Noriaki Ando",
      "Ryo Hanai",
      "Yukiyasu Domae"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.11969",
    "title": "A survey of trends and motivations regarding Communication Service  Providers' metro area network implementations",
    "abstract": "Relevance of research on telecommunications networks is predicated upon the implementations which it explicitly claims or implicitly subsumes. This paper supports researchers through a survey of Communications Service Providers current implementations within the metro area, and trends that are expected to shape the next-generation metro area network. The survey is composed of a quantitative component, complemented by a qualitative component carried out among field experts. Among the several findings, it has been found that service providers with large subscriber base sizes, are less agile in their response to technological change than those with smaller subscriber base sizes: thus, copper media are still an important component in the set of access network technologies. On the other hand, service providers with large subscriber base sizes are strongly committed to deploying distributed access architectures, notably using remote access nodes like remote OLT and remote MAC-PHY. This study also shows that the extent of remote node deployment for multi-access edge computing is about the same as remote node deployment for distributed access architectures, indicating that these two aspects of metro area networks are likely to be co-deployed. ",
    "url": "https://arxiv.org/abs/2309.11969",
    "authors": [
      "Etienne-Victor Depasquale",
      "Mark Tinka",
      "Saviour Zammit",
      "Franco Davoli"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.11984",
    "title": "Representation Abstractions as Incentives for Reinforcement Learning  Agents: A Robotic Grasping Case Study",
    "abstract": "Choosing an appropriate representation of the environment for the underlying decision-making process of the \\gls{RL} agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and compact enough to increase sample efficiency for policy training. Given this outlook, this work examines the effect of various state representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representation abstractions is defined, starting from a model-based approach with complete system knowledge, through hand-crafted numerical, to image-based representations with decreasing level of induced task-specific knowledge. We examine the effects of each representation in the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot. The results show that RL agents using numerical states can perform on par with non-learning baselines. Furthermore, we find that agents using image-based representations from pre-trained environment embedding vectors perform better than end-to-end trained agents, and hypothesize that task-specific knowledge is necessary for achieving convergence and high success rates in robot control. Supplementary material can be found at the project webpage: https://github.com/PetropoulakisPanagiotis/igae. ",
    "url": "https://arxiv.org/abs/2309.11984",
    "authors": [
      "Panagiotis Petropoulakis",
      "Ludwig Gr\u00e4f",
      "Josip Josifovski",
      "Mohammadhossein Malmir",
      "Alois Knoll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11993",
    "title": "Neural Stochastic Screened Poisson Reconstruction",
    "abstract": "Reconstructing a surface from a point cloud is an underdetermined problem. We use a neural network to study and quantify this reconstruction uncertainty under a Poisson smoothness prior. Our algorithm addresses the main limitations of existing work and can be fully integrated into the 3D scanning pipeline, from obtaining an initial reconstruction to deciding on the next best sensor position and updating the reconstruction upon capturing more data. ",
    "url": "https://arxiv.org/abs/2309.11993",
    "authors": [
      "Silvia Sell\u00e1n",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12025",
    "title": "Robust Approximation Algorithms for Non-monotone $k$-Submodular  Maximization under a Knapsack Constraint",
    "abstract": "The problem of non-monotone $k$-submodular maximization under a knapsack constraint ($\\kSMK$) over the ground set size $n$ has been raised in many applications in machine learning, such as data summarization, information propagation, etc. However, existing algorithms for the problem are facing questioning of how to overcome the non-monotone case and how to fast return a good solution in case of the big size of data. This paper introduces two deterministic approximation algorithms for the problem that competitively improve the query complexity of existing algorithms. Our first algorithm, $\\LAA$, returns an approximation ratio of $1/19$ within $O(nk)$ query complexity. The second one, $\\RLA$, improves the approximation ratio to $1/5-\\epsilon$ in $O(nk)$ queries, where $\\epsilon$ is an input parameter. Our algorithms are the first ones that provide constant approximation ratios within only $O(nk)$ query complexity for the non-monotone objective. They, therefore, need fewer the number of queries than state-of-the-the-art ones by a factor of $\\Omega(\\log n)$. Besides the theoretical analysis, we have evaluated our proposed ones with several experiments in some instances: Influence Maximization and Sensor Placement for the problem. The results confirm that our algorithms ensure theoretical quality as the cutting-edge techniques and significantly reduce the number of queries. ",
    "url": "https://arxiv.org/abs/2309.12025",
    "authors": [
      "Dung T.K. Ha",
      "Canh V. Pham",
      "Tan D. Tran",
      "Huan X. Hoang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2309.12029",
    "title": "Unveiling the Hidden Realm: Self-supervised Skeleton-based Action  Recognition in Occluded Environments",
    "abstract": "To integrate action recognition methods into autonomous robotic systems, it is crucial to consider adverse situations involving target occlusions. Such a scenario, despite its practical relevance, is rarely addressed in existing self-supervised skeleton-based action recognition methods. To empower robots with the capacity to address occlusion, we propose a simple and effective method. We first pre-train using occluded skeleton sequences, then use k-means clustering (KMeans) on sequence embeddings to group semantically similar samples. Next, we employ K-nearest-neighbor (KNN) to fill in missing skeleton data based on the closest sample neighbors. Imputing incomplete skeleton sequences to create relatively complete sequences as input provides significant benefits to existing skeleton-based self-supervised models. Meanwhile, building on the state-of-the-art Partial Spatio-Temporal Learning (PSTL), we introduce an Occluded Partial Spatio-Temporal Learning (OPSTL) framework. This enhancement utilizes Adaptive Spatial Masking (ASM) for better use of high-quality, intact skeletons. The effectiveness of our imputation methods is verified on the challenging occluded versions of the NTURGB+D 60 and NTURGB+D 120. The source code will be made publicly available at https://github.com/cyfml/OPSTL. ",
    "url": "https://arxiv.org/abs/2309.12029",
    "authors": [
      "Yifei Chen",
      "Kunyu Peng",
      "Alina Roitberg",
      "David Schneider",
      "Jiaming Zhang",
      "Junwei Zheng",
      "Ruiping Liu",
      "Yufan Chen",
      "Kailun Yang",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.12032",
    "title": "Human-in-the-Loop Causal Discovery under Latent Confounding using  Ancestral GFlowNets",
    "abstract": "Structure learning is the crux of causal inference. Notably, causal discovery (CD) algorithms are brittle when data is scarce, possibly inferring imprecise causal relations that contradict expert knowledge -- especially when considering latent confounders. To aggravate the issue, most CD methods do not provide uncertainty estimates, making it hard for users to interpret results and improve the inference process. Surprisingly, while CD is a human-centered affair, no works have focused on building methods that both 1) output uncertainty estimates that can be verified by experts and 2) interact with those experts to iteratively refine CD. To solve these issues, we start by proposing to sample (causal) ancestral graphs proportionally to a belief distribution based on a score function, such as the Bayesian information criterion (BIC), using generative flow networks. Then, we leverage the diversity in candidate graphs and introduce an optimal experimental design to iteratively probe the expert about the relations among variables, effectively reducing the uncertainty of our belief over ancestral graphs. Finally, we update our samples to incorporate human feedback via importance sampling. Importantly, our method does not require causal sufficiency (i.e., unobserved confounders may exist). Experiments with synthetic observational data show that our method can accurately sample from distributions over ancestral graphs and that we can greatly improve inference quality with human aid. ",
    "url": "https://arxiv.org/abs/2309.12032",
    "authors": [
      "Tiago da Silva",
      "Eliezer Silva",
      "Ad\u00e8le Ribeiro",
      "Ant\u00f3nio G\u00f3is",
      "Dominik Heider",
      "Samuel Kaski",
      "Diego Mesquita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.12058",
    "title": "An Efficient Consolidation of Word Embedding and Deep Learning  Techniques for Classifying Anticancer Peptides: FastText+BiLSTM",
    "abstract": "Anticancer peptides (ACPs) are a group of peptides that exhibite antineoplastic properties. The utilization of ACPs in cancer prevention can present a viable substitute for conventional cancer therapeutics, as they possess a higher degree of selectivity and safety. Recent scientific advancements generate an interest in peptide-based therapies which offer the advantage of efficiently treating intended cells without negatively impacting normal cells. However, as the number of peptide sequences continues to increase rapidly, developing a reliable and precise prediction model becomes a challenging task. In this work, our motivation is to advance an efficient model for categorizing anticancer peptides employing the consolidation of word embedding and deep learning models. First, Word2Vec and FastText are evaluated as word embedding techniques for the purpose of extracting peptide sequences. Then, the output of word embedding models are fed into deep learning approaches CNN, LSTM, BiLSTM. To demonstrate the contribution of proposed framework, extensive experiments are carried on widely-used datasets in the literature, ACPs250 and Independent. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed combination, FastText+BiLSTM, exhibits 92.50% of accuracy for ACPs250 dataset, and 96.15% of accuracy for Independent dataset, thence determining new state-of-the-art. ",
    "url": "https://arxiv.org/abs/2309.12058",
    "authors": [
      "Onur Karakaya",
      "Zeynep Hilal Kilimci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2309.12118",
    "title": "Vulnerability of 3D Face Recognition Systems to Morphing Attacks",
    "abstract": "In recent years face recognition systems have been brought to the mainstream due to development in hardware and software. Consistent efforts are being made to make them better and more secure. This has also brought developments in 3D face recognition systems at a rapid pace. These 3DFR systems are expected to overcome certain vulnerabilities of 2DFR systems. One such problem that the domain of 2DFR systems face is face image morphing. A substantial amount of research is being done for generation of high quality face morphs along with detection of attacks from these morphs. Comparatively the understanding of vulnerability of 3DFR systems against 3D face morphs is less. But at the same time an expectation is set from 3DFR systems to be more robust against such attacks. This paper attempts to research and gain more information on this matter. The paper describes a couple of methods that can be used to generate 3D face morphs. The face morphs that are generated using this method are then compared to the contributing faces to obtain similarity scores. The highest MMPMR is obtained around 40% with RMMR of 41.76% when 3DFRS are attacked with look-a-like morphs. ",
    "url": "https://arxiv.org/abs/2309.12118",
    "authors": [
      "Sanjeet Vardam",
      "Luuk Spreeuwers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12120",
    "title": "Sustainability indicators in an open online community",
    "abstract": "Software is often abandoned or shut down, for one reason or another, and whilst research on academic open source software is sparse, there seems little reason to assume it is any different. While some reasons may be straightforward, e.g. a sole maintainer has moved on, or grant funding has ceased - some projects are able to withstand these barriers and may remain active and maintained despite adversity. This study monitored open source projects over the period of a year, measuring common performance indicators, using both subjective and qualitative measures (participant surveys), as well as using scripts to analyse indicators associated with these projects' online source control codebases. We find that these health indicators can not be used as cross project benchmarks, due to the significant variation in context for each project. They can, however, often be useful in signifying changes in a single project's health, providing they are not used to compare between different unrelated projects. ",
    "url": "https://arxiv.org/abs/2309.12120",
    "authors": [
      "Yo Yehudi",
      "Carole Goble",
      "Caroline Jay"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.12128",
    "title": "Convergence and Recovery Guarantees of Unsupervised Neural Networks for  Inverse Problems",
    "abstract": "Neural networks have become a prominent approach to solve inverse problems in recent years. While a plethora of such methods was developed to solve inverse problems empirically, we are still lacking clear theoretical guarantees for these methods. On the other hand, many works proved convergence to optimal solutions of neural networks in a more general setting using overparametrization as a way to control the Neural Tangent Kernel. In this work we investigate how to bridge these two worlds and we provide deterministic convergence and recovery guarantees for the class of unsupervised feedforward multilayer neural networks trained to solve inverse problems. We also derive overparametrization bounds under which a two-layers Deep Inverse Prior network with smooth activation function will benefit from our guarantees. ",
    "url": "https://arxiv.org/abs/2309.12128",
    "authors": [
      "Nathan Buskulic",
      "Jalal Fadili",
      "Yvain Qu\u00e9au"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.12132",
    "title": "A knowledge representation approach for construction contract knowledge  modeling",
    "abstract": "The emergence of large language models (LLMs) presents an unprecedented opportunity to automate construction contract management, reducing human errors and saving significant time and costs. However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise. To address this issue, expert-driven contract knowledge can be represented in a structured manner to constrain the automatic contract management process. This paper introduces the Nested Contract Knowledge Graph (NCKG), a knowledge representation approach that captures the complexity of contract knowledge using a nested structure. It includes a nested knowledge representation framework, a NCKG ontology built on the framework, and an implementation method. Furthermore, we present the LLM-assisted contract review pipeline enhanced with external knowledge in NCKG. Our pipeline achieves a promising performance in contract risk reviewing, shedding light on the combination of LLM and KG towards more reliable and interpretable contract management. ",
    "url": "https://arxiv.org/abs/2309.12132",
    "authors": [
      "Chunmo Zheng",
      "Saika Wong",
      "Xing Su",
      "Yinqiu Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.12134",
    "title": "Self-Supervised Contrastive Learning for Robust Audio-Sheet Music  Retrieval Systems",
    "abstract": "Linking sheet music images to audio recordings remains a key problem for the development of efficient cross-modal music retrieval systems. One of the fundamental approaches toward this task is to learn a cross-modal embedding space via deep neural networks that is able to connect short snippets of audio and sheet music. However, the scarcity of annotated data from real musical content affects the capability of such methods to generalize to real retrieval scenarios. In this work, we investigate whether we can mitigate this limitation with self-supervised contrastive learning, by exposing a network to a large amount of real music data as a pre-training step, by contrasting randomly augmented views of snippets of both modalities, namely audio and sheet images. Through a number of experiments on synthetic and real piano data, we show that pre-trained models are able to retrieve snippets with better precision in all scenarios and pre-training configurations. Encouraged by these results, we employ the snippet embeddings in the higher-level task of cross-modal piece identification and conduct more experiments on several retrieval configurations. In this task, we observe that the retrieval quality improves from 30% up to 100% when real music data is present. We then conclude by arguing for the potential of self-supervised contrastive learning for alleviating the annotated data scarcity in multi-modal music retrieval models. ",
    "url": "https://arxiv.org/abs/2309.12134",
    "authors": [
      "Luis Carvalho",
      "Tobias Wash\u00fcttl",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.12137",
    "title": "OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal  Conversations on Online Social Media",
    "abstract": "While resources for English language are fairly sufficient to understand content on social media, similar resources in Arabic are still immature. The main reason that the resources in Arabic are insufficient is that Arabic has many dialects in addition to the standard version (MSA). Arabs do not use MSA in their daily communications; rather, they use dialectal versions. Unfortunately, social users transfer this phenomenon into their use of social media platforms, which in turn has raised an urgent need for building suitable AI models for language-dependent applications. Existing machine translation (MT) systems designed for MSA fail to work well with Arabic dialects. In light of this, it is necessary to adapt to the informal nature of communication on social networks by developing MT systems that can effectively handle the various dialects of Arabic. Unlike for MSA that shows advanced progress in MT systems, little effort has been exerted to utilize Arabic dialects for MT systems. While few attempts have been made to build translation datasets for dialectal Arabic, they are domain dependent and are not OSN cultural-language friendly. In this work, we attempt to alleviate these limitations by proposing an online social network-based multidialect Arabic dataset that is crafted by contextually translating English tweets into four Arabic dialects: Gulf, Yemeni, Iraqi, and Levantine. To perform the translation, we followed our proposed guideline framework for content translation, which could be universally applicable for translation between foreign languages and local dialects. We validated the authenticity of our proposed dataset by developing neural MT models for four Arabic dialects. Our results have shown a superior performance of our NMT models trained using our dataset. We believe that our dataset can reliably serve as an Arabic multidialectal translation dataset for informal MT tasks. ",
    "url": "https://arxiv.org/abs/2309.12137",
    "authors": [
      "Fatimah Alzamzami",
      "Abdulmotaleb El Saddik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.12148",
    "title": "Neural Modelling of Dynamic Systems with Time Delays Based on an  Adjusted NEAT Algorithm",
    "abstract": "A problem related to the development of an algorithm designed to find an architecture of artificial neural network used for black-box modelling of dynamic systems with time delays has been addressed in this paper. The proposed algorithm is based on a well-known NeuroEvolution of Augmenting Topologies (NEAT) algorithm. The NEAT algorithm has been adjusted by allowing additional connections within an artificial neural network and developing original specialised evolutionary operators. This resulted in a compromise between the size of neural network and its accuracy in capturing the response of the mathematical model under which it has been learnt. The research involved an extended validation study based on data generated from a mathematical model of an exemplary system as well as the fast processes occurring in a pressurised water nuclear reactor. The obtaining simulation results demonstrate the high effectiveness of the devised neural (black-box) models of dynamic systems with time delays. ",
    "url": "https://arxiv.org/abs/2309.12148",
    "authors": [
      "Krzysztof Laddach",
      "Rafa\u0142 \u0141angowskii"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.12158",
    "title": "Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval",
    "abstract": "A range of applications of multi-modal music information retrieval is centred around the problem of connecting large collections of sheet music (images) to corresponding audio recordings, that is, identifying pairs of audio and score excerpts that refer to the same musical content. One of the typical and most recent approaches to this task employs cross-modal deep learning architectures to learn joint embedding spaces that link the two distinct modalities - audio and sheet music images. While there has been steady improvement on this front over the past years, a number of open problems still prevent large-scale employment of this methodology. In this article we attempt to provide an insightful examination of the current developments on audio-sheet music retrieval via deep learning methods. We first identify a set of main challenges on the road towards robust and large-scale cross-modal music retrieval in real scenarios. We then highlight the steps we have taken so far to address some of these challenges, documenting step-by-step improvement along several dimensions. We conclude by analysing the remaining challenges and present ideas for solving these, in order to pave the way to a unified and robust methodology for cross-modal music retrieval. ",
    "url": "https://arxiv.org/abs/2309.12158",
    "authors": [
      "Luis Carvalho",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.12161",
    "title": "Code Soliloquies for Accurate Calculations in Large Language Models",
    "abstract": "High-quality conversational datasets are integral to the successful development of Intelligent Tutoring Systems (ITS) that employ a Large Language Model (LLM) backend. These datasets, when used to fine-tune the LLM backend, significantly enhance the quality of interactions between students and ITS. A common strategy for developing these datasets involves generating synthetic student-teacher dialogues using advanced GPT-4 models. However, challenges arise when these dialogues demand complex calculations, common in subjects like physics. Despite its advanced capabilities, GPT-4's performance falls short in reliably handling even simple multiplication tasks, marking a significant limitation in its utility for these subjects. To address these challenges, this paper introduces an innovative stateful prompt design. Our approach generates a mock conversation between a student and a tutorbot, both roles simulated by GPT-4. Each student response triggers a soliloquy (an inner monologue) in the GPT-tutorbot, which assesses whether its response would necessitate calculations. If so, it proceeds to script the required code in Python and then uses the resulting output to construct its response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. Our findings show that our Higgs model -- a LLaMA finetuned with datasets generated through our novel stateful prompt design -- proficiently utilizes Python for computations. Consequently, finetuning with our datasets enriched with code soliloquies enhances not just the accuracy but also the computational reliability of Higgs' responses. ",
    "url": "https://arxiv.org/abs/2309.12161",
    "authors": [
      "Shashank Sonkar",
      "MyCo Le",
      "Xinghe Chen",
      "Naiming Liu",
      "Debshila Basu Mallick",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.12188",
    "title": "SG-Bot: Object Rearrangement via Coarse-to-Fine Robotic Imagination on  Scene Graphs",
    "abstract": "Object rearrangement is pivotal in robotic-environment interactions, representing a significant capability in embodied AI. In this paper, we present SG-Bot, a novel rearrangement framework that utilizes a coarse-to-fine scheme with a scene graph as the scene representation. Unlike previous methods that rely on either known goal priors or zero-shot large models, SG-Bot exemplifies lightweight, real-time, and user-controllable characteristics, seamlessly blending the consideration of commonsense knowledge with automatic generation capabilities. SG-Bot employs a three-fold procedure--observation, imagination, and execution--to adeptly address the task. Initially, objects are discerned and extracted from a cluttered scene during the observation. These objects are first coarsely organized and depicted within a scene graph, guided by either commonsense or user-defined criteria. Then, this scene graph subsequently informs a generative model, which forms a fine-grained goal scene considering the shape information from the initial scene and object semantics. Finally, for execution, the initial and envisioned goal scenes are matched to formulate robotic action policies. Experimental results demonstrate that SG-Bot outperforms competitors by a large margin. ",
    "url": "https://arxiv.org/abs/2309.12188",
    "authors": [
      "Guangyao Zhai",
      "Xiaoni Cai",
      "Dianye Huang",
      "Yan Di",
      "Fabian Manhardt",
      "Federico Tombari",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12204",
    "title": "PrNet: A Neural Network for Correcting Pseudoranges to Improve  Positioning with Android Raw GNSS Measurements",
    "abstract": "We present a neural network for mitigating pseudorange bias to improve localization performance with data collected from Android smartphones. We represent pseudorange bias using a pragmatic satellite-wise Multiple Layer Perceptron (MLP), the inputs of which are six satellite-receiver-context-related features derived from Android raw Global Navigation Satellite System (GNSS) measurements. To supervise the training process, we carefully calculate the target values of pseudorange bias using location ground truth and smoothing techniques and optimize a loss function containing the estimation residuals of smartphone clock bias. During the inference process, we employ model-based localization engines to compute locations with pseudoranges corrected by the neural network. Consequently, this hybrid pipeline can attend to both pseudorange bias and noise. We evaluate the framework on an open dataset and consider four application scenarios for investigating fingerprinting and cross-trace localization in rural and urban areas. Extensive experiments demonstrate that the proposed framework outperforms model-based and state-of-the-art data-driven approaches. ",
    "url": "https://arxiv.org/abs/2309.12204",
    "authors": [
      "Xu Weng",
      "Keck Voon Ling",
      "Haochen Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.12211",
    "title": "Physics-informed State-space Neural Networks for Transport Phenomena",
    "abstract": "This work introduces Physics-informed State-space neural network Models (PSMs), a novel solution to achieving real-time optimization, flexibility, and fault tolerance in autonomous systems, particularly in transport-dominated systems such as chemical, biomedical, and power plants. Traditional data-driven methods fall short due to a lack of physical constraints like mass conservation; PSMs address this issue by training deep neural networks with sensor data and physics-informing using components' Partial Differential Equations (PDEs), resulting in a physics-constrained, end-to-end differentiable forward dynamics model. Through two in silico experiments - a heated channel and a cooling system loop - we demonstrate that PSMs offer a more accurate approach than purely data-driven models. Beyond accuracy, there are several compelling use cases for PSMs. In this work, we showcase two: the creation of a nonlinear supervisory controller through a sequentially updated state-space representation and the proposal of a diagnostic algorithm using residuals from each of the PDEs. The former demonstrates the ability of PSMs to handle both constant and time-dependent constraints, while the latter illustrates their value in system diagnostics and fault detection. We further posit that PSMs could serve as a foundation for Digital Twins, constantly updated digital representations of physical systems. ",
    "url": "https://arxiv.org/abs/2309.12211",
    "authors": [
      "Akshay J Dave",
      "Richard B. Vilim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2309.12212",
    "title": "SupeRBNN: Randomized Binary Neural Network Using Adiabatic  Superconductor Josephson Devices",
    "abstract": "Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with extremely high energy efficiency. By employing the distinct polarity of current to denote logic `0' and `1', AQFP devices serve as excellent carriers for binary neural network (BNN) computations. Although recent research has made initial strides toward developing an AQFP-based BNN accelerator, several critical challenges remain, preventing the design from being a comprehensive solution. In this paper, we propose SupeRBNN, an AQFP-based randomized BNN acceleration framework that leverages software-hardware co-optimization to eventually make the AQFP devices a feasible solution for BNN acceleration. Specifically, we investigate the randomized behavior of the AQFP devices and analyze the impact of crossbar size on current attenuation, subsequently formulating the current amplitude into the values suitable for use in BNN computation. To tackle the accumulation problem and improve overall hardware performance, we propose a stochastic computing-based accumulation module and a clocking scheme adjustment-based circuit optimization method. We validate our SupeRBNN framework across various datasets and network architectures, comparing it with implementations based on different technologies, including CMOS, ReRAM, and superconducting RSFQ/ERSFQ. Experimental results demonstrate that our design achieves an energy efficiency of approximately 7.8x10^4 times higher than that of the ReRAM-based BNN framework while maintaining a similar level of model accuracy. Furthermore, when compared with superconductor-based counterparts, our framework demonstrates at least two orders of magnitude higher energy efficiency. ",
    "url": "https://arxiv.org/abs/2309.12212",
    "authors": [
      "Zhengang Li",
      "Geng Yuan",
      "Tomoharu Yamauchi",
      "Zabihi Masoud",
      "Yanyue Xie",
      "Peiyan Dong",
      "Xulong Tang",
      "Nobuyuki Yoshikawa",
      "Devesh Tiwari",
      "Yanzhi Wang",
      "Olivia Chen"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.12214",
    "title": "Can We Reliably Improve the Robustness to Image Acquisition of Remote  Sensing of PV Systems?",
    "abstract": "Photovoltaic (PV) energy is crucial for the decarbonization of energy systems. Due to the lack of centralized data, remote sensing of rooftop PV installations is the best option to monitor the evolution of the rooftop PV installed fleet at a regional scale. However, current techniques lack reliability and are notably sensitive to shifts in the acquisition conditions. To overcome this, we leverage the wavelet scale attribution method (WCAM), which decomposes a model's prediction in the space-scale domain. The WCAM enables us to assess on which scales the representation of a PV model rests and provides insights to derive methods that improve the robustness to acquisition conditions, thus increasing trust in deep learning systems to encourage their use for the safe integration of clean energy in electric systems. ",
    "url": "https://arxiv.org/abs/2309.12214",
    "authors": [
      "Gabriel Kasmi",
      "Laurent Dubus",
      "Yves-Marie Saint-Drenan",
      "Philippe Blanc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12247",
    "title": "Bad Actor, Good Advisor: Exploring the Role of Large Language Models in  Fake News Detection",
    "abstract": "Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good advisor for SLMs by providing multi-perspective instructive rationales. To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection (ARG), in which SLMs selectively acquire insights on news analysis from the LLMs' rationales. We further derive a rationale-free version of ARG by distillation, namely ARG-D, which services cost-sensitive scenarios without inquiring LLMs. Experiments on two real-world datasets demonstrate that ARG and ARG-D outperform three types of baseline methods, including SLM-based, LLM-based, and combinations of small and large language models. ",
    "url": "https://arxiv.org/abs/2309.12247",
    "authors": [
      "Beizhe Hu",
      "Qiang Sheng",
      "Juan Cao",
      "Yuhui Shi",
      "Yang Li",
      "Danding Wang",
      "Peng Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.12259",
    "title": "Soft Merging: A Flexible and Robust Soft Model Merging Approach for  Enhanced Neural Network Performance",
    "abstract": "Stochastic Gradient Descent (SGD), a widely used optimization algorithm in deep learning, is often limited to converging to local optima due to the non-convex nature of the problem. Leveraging these local optima to improve model performance remains a challenging task. Given the inherent complexity of neural networks, the simple arithmetic averaging of the obtained local optima models in undesirable results. This paper proposes a {\\em soft merging} method that facilitates rapid merging of multiple models, simplifies the merging of specific parts of neural networks, and enhances robustness against malicious models with extreme values. This is achieved by learning gate parameters through a surrogate of the $l_0$ norm using hard concrete distribution without modifying the model weights of the given local optima models. This merging process not only enhances the model performance by converging to a better local optimum, but also minimizes computational costs, offering an efficient and explicit learning process integrated with stochastic gradient descent. Thorough experiments underscore the effectiveness and superior performance of the merged neural networks. ",
    "url": "https://arxiv.org/abs/2309.12259",
    "authors": [
      "Hao Chen",
      "Yusen Wu",
      "Phuong Nguyen",
      "Chao Liu",
      "Yelena Yesha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.12263",
    "title": "On the Relationship between Skill Neurons and Robustness in Prompt  Tuning",
    "abstract": "Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs). Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task. In this paper, we study the robustness of Prompt Tuning in relation to these \"skill neurons\", using RoBERTa and T5. We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa. At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5. Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa. We conclude that higher adversarial robustness may be related to a model's ability to activate the relevant skill neurons on adversarial data. ",
    "url": "https://arxiv.org/abs/2309.12263",
    "authors": [
      "Leon Ackermann",
      "Xenia Ohmer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.12275",
    "title": "AIM: Accelerating Arbitrary-precision Integer Multiplication on  Heterogeneous Reconfigurable Computing Platform Versal ACAP",
    "abstract": "Arbitrary-precision integer multiplication is the core kernel of many applications in simulation, cryptography, etc. Existing acceleration of arbitrary-precision integer multiplication includes CPUs, GPUs, FPGAs, and ASICs. Among these accelerators, FPGAs are promised to provide both good energy efficiency and flexibility. Surprisingly, in our implementations, FPGA has the lowest energy efficiency, i.e., 0.29x of the CPU and 0.17x of the GPU with the same generation fabrication. Therefore, key questions arise: Where do the energy efficiency gains of CPUs and GPUs come from? Can reconfigurable computing do better? If can, how to achieve that? We identify that the biggest energy efficiency gains of the CPUs and GPUs come from the dedicated vector units. FPGA uses DSPs and lookup tables to compose the needed computation, which incurs overhead when compared to using vector units directly. New reconfigurable computing, e.g., 'FPGA+vector units' is a novel and feasible solution to improve energy efficiency. In this paper, we propose to map arbitrary-precision integer multiplication onto such a heterogeneous platform, i.e., AMD/Xilinx Versal ACAP architecture. Designing on Versal ACAP incurs several challenges and we propose AIM: Arbitrary-precision Integer Multiplication on Versal ACAP to automate and optimize the design. AIM framework includes design space exploration and AIM automatic code generation to facilitate the system design and verification. We deploy the AIM framework on three different applications, including large integer multiplication (LIM), RSA, and Mandelbrot, on the AMD/Xilinx Versal ACAP VCK190 evaluation board. Our experimental results show that AIM achieves up to 12.6x, and 2.1x energy efficiency gains over the Intel Xeon Ice Lake 6346 CPU, and NVidia A5000 GPU respectively, which brings reconfigurable computing the most energy-efficient platform among CPUs and GPUs. ",
    "url": "https://arxiv.org/abs/2309.12275",
    "authors": [
      "Zhuoping Yang",
      "Jinming Zhuang",
      "Jiaqi Yin",
      "Cunxi Yu",
      "Alex K. Jones",
      "Peipei Zhou"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2309.12279",
    "title": "The Broad Impact of Feature Imitation: Neural Enhancements Across  Financial, Speech, and Physiological Domains",
    "abstract": "Initialization of neural network weights plays a pivotal role in determining their performance. Feature Imitating Networks (FINs) offer a novel strategy by initializing weights to approximate specific closed-form statistical features, setting a promising foundation for deep learning architectures. While the applicability of FINs has been chiefly tested in biomedical domains, this study extends its exploration into other time series datasets. Three different experiments are conducted in this study to test the applicability of imitating Tsallis entropy for performance enhancement: Bitcoin price prediction, speech emotion recognition, and chronic neck pain detection. For the Bitcoin price prediction, models embedded with FINs reduced the root mean square error by around 1000 compared to the baseline. In the speech emotion recognition task, the FIN-augmented model increased classification accuracy by over 3 percent. Lastly, in the CNP detection experiment, an improvement of about 7 percent was observed compared to established classifiers. These findings validate the broad utility and potency of FINs in diverse applications. ",
    "url": "https://arxiv.org/abs/2309.12279",
    "authors": [
      "Reza Khanmohammadi",
      "Tuka Alhanai",
      "Mohammad M. Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.12301",
    "title": "Environment-biased Feature Ranking for Novelty Detection Robustness",
    "abstract": "We tackle the problem of robust novelty detection, where we aim to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors. Specifically, we operate in a setup with multiple environments, where we determine the set of features that are associated more with the environments, rather than to the content relevant for the task. Thus, we propose a method that starts with a pretrained embedding and a multi-env setup and manages to rank the features based on their environment-focus. First, we compute a per-feature score based on the feature distribution variance between envs. Next, we show that by dropping the highly scored ones, we manage to remove spurious correlations and improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark, that we introduce for this task. ",
    "url": "https://arxiv.org/abs/2309.12301",
    "authors": [
      "Stefan Smeu",
      "Elena Burceanu",
      "Emanuela Haller",
      "Andrei Liviu Nicolicioiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12304",
    "title": "SlowFast Network for Continuous Sign Language Recognition",
    "abstract": "The objective of this work is the effective extraction of spatial and dynamic features for Continuous Sign Language Recognition (CSLR). To accomplish this, we utilise a two-pathway SlowFast network, where each pathway operates at distinct temporal resolutions to separately capture spatial (hand shapes, facial expressions) and dynamic (movements) information. In addition, we introduce two distinct feature fusion methods, carefully designed for the characteristics of CSLR: (1) Bi-directional Feature Fusion (BFF), which facilitates the transfer of dynamic semantics into spatial semantics and vice versa; and (2) Pathway Feature Enhancement (PFE), which enriches dynamic and spatial representations through auxiliary subnetworks, while avoiding the need for extra inference time. As a result, our model further strengthens spatial and dynamic representations in parallel. We demonstrate that the proposed framework outperforms the current state-of-the-art performance on popular CSLR datasets, including PHOENIX14, PHOENIX14-T, and CSL-Daily. ",
    "url": "https://arxiv.org/abs/2309.12304",
    "authors": [
      "Junseok Ahn",
      "Youngjoon Jang",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12306",
    "title": "TalkNCE: Improving Active Speaker Detection with Talk-Aware Contrastive  Learning",
    "abstract": "The goal of this work is Active Speaker Detection (ASD), a task to determine whether a person is speaking or not in a series of video frames. Previous works have dealt with the task by exploring network architectures while learning effective representations has been less explored. In this work, we propose TalkNCE, a novel talk-aware contrastive loss. The loss is only applied to part of the full segments where a person on the screen is actually speaking. This encourages the model to learn effective representations through the natural correspondence of speech and facial movements. Our loss can be jointly optimized with the existing objectives for training ASD models without the need for additional supervision or training data. The experiments demonstrate that our loss can be easily integrated into the existing ASD frameworks, improving their performance. Our method achieves state-of-the-art performances on AVA-ActiveSpeaker and ASW datasets. ",
    "url": "https://arxiv.org/abs/2309.12306",
    "authors": [
      "Chaeyoung Jung",
      "Suyeon Lee",
      "Kihyun Nam",
      "Kyeongha Rho",
      "You Jin Kim",
      "Youngjoon Jang",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.11530",
    "title": "Robust fake-post detection against real-coloring adversaries",
    "abstract": "The viral propagation of fake posts on online social networks (OSNs) has become an alarming concern. The paper aims to design control mechanisms for fake post detection while negligibly affecting the propagation of real posts. Towards this, a warning mechanism based on crowd-signals was recently proposed, where all users actively declare the post as real or fake. In this paper, we consider a more realistic framework where users exhibit different adversarial or non-cooperative behaviour: (i) they can independently decide whether to provide their response, (ii) they can choose not to consider the warning signal while providing the response, and (iii) they can be real-coloring adversaries who deliberately declare any post as real. To analyze the post-propagation process in this complex system, we propose and study a new branching process, namely total-current population-dependent branching process with multiple death types. At first, we compare and show that the existing warning mechanism significantly under-performs in the presence of adversaries. Then, we design new mechanisms which remarkably perform better than the existing mechanism by cleverly eliminating the influence of the responses of the adversaries. Finally, we propose another enhanced mechanism which assumes minimal knowledge about the user-specific parameters. The theoretical results are validated using Monte-Carlo simulations. ",
    "url": "https://arxiv.org/abs/2309.11530",
    "authors": [
      "Khushboo Agarwal",
      "Veeraruna Kavitha"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.11606",
    "title": "Decycling cubic graphs",
    "abstract": "A set of vertices of a graph $G$ is said to be decycling if its removal leaves an acyclic subgraph. The size of a smallest decycling set is the decycling number of $G$. Generally, at least $\\lceil(n+2)/4\\rceil$ vertices have to be removed in order to decycle a cubic graph on $n$ vertices. In 1979, Payan and Sakarovitch proved that the decycling number of a cyclically $4$-edge-connected cubic graph of order $n$ equals $\\lceil (n+2)/4\\rceil$. In addition, they characterised the structure of minimum decycling sets and their complements. If $n\\equiv 2\\pmod4$, then $G$ has a decycling set which is independent and its complement induces a tree. If $n\\equiv 0\\pmod4$, then one of two possibilities occurs: either $G$ has an independent decycling set whose complement induces a forest of two trees, or the decycling set is near-independent (which means that it induces a single edge) and its complement induces a tree. In this paper we strengthen the result of Payan and Sakarovitch by proving that the latter possibility (a near-independent set and a tree) can always be guaranteed. Moreover, we relax the assumption of cyclic $4$-edge-connectivity to a significantly weaker condition expressed through the canonical decomposition of 3-connected cubic graphs into cyclically $4$-edge-connected ones. Our methods substantially use a surprising and seemingly distant relationship between the decycling number and the maximum genus of a cubic graph. ",
    "url": "https://arxiv.org/abs/2309.11606",
    "authors": [
      "Roman Nedela",
      "Michaela Seifrtov\u00e1",
      "Martin \u0160koviera"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2309.11714",
    "title": "A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor  Imagery Classification",
    "abstract": "There is a correlation between adjacent channels of electroencephalogram (EEG), and how to represent this correlation is an issue that is currently being explored. In addition, due to inter-individual differences in EEG signals, this discrepancy results in new subjects need spend a amount of calibration time for EEG-based motor imagery brain-computer interface. In order to solve the above problems, we propose a Dynamic Domain Adaptation Based Deep Learning Network (DADL-Net). First, the EEG data is mapped to the three-dimensional geometric space and its temporal-spatial features are learned through the 3D convolution module, and then the spatial-channel attention mechanism is used to strengthen the features, and the final convolution module can further learn the spatial-temporal information of the features. Finally, to account for inter-subject and cross-sessions differences, we employ a dynamic domain-adaptive strategy, the distance between features is reduced by introducing a Maximum Mean Discrepancy loss function, and the classification layer is fine-tuned by using part of the target domain data. We verify the performance of the proposed method on BCI competition IV 2a and OpenBMI datasets. Under the intra-subject experiment, the accuracy rates of 70.42% and 73.91% were achieved on the OpenBMI and BCIC IV 2a datasets. ",
    "url": "https://arxiv.org/abs/2309.11714",
    "authors": [
      "Jie Jiao",
      "Meiyan Xu",
      "Qingqing Chen",
      "Hefan Zhou",
      "Wangliang Zhou"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11730",
    "title": "Leveraging In-the-Wild Data for Effective Self-Supervised Pretraining in  Speaker Recognition",
    "abstract": "Current speaker recognition systems primarily rely on supervised approaches, constrained by the scale of labeled datasets. To boost the system performance, researchers leverage large pretrained models such as WavLM to transfer learned high-level features to the downstream speaker recognition task. However, this approach introduces extra parameters as the pretrained model remains in the inference stage. Another group of researchers directly apply self-supervised methods such as DINO to speaker embedding learning, yet they have not explored its potential on large-scale in-the-wild datasets. In this paper, we present the effectiveness of DINO training on the large-scale WenetSpeech dataset and its transferability in enhancing the supervised system performance on the CNCeleb dataset. Additionally, we introduce a confidence-based data filtering algorithm to remove unreliable data from the pretraining dataset, leading to better performance with less training data. The associated pretrained models, confidence files, pretraining and finetuning scripts will be made available in the Wespeaker toolkit. ",
    "url": "https://arxiv.org/abs/2309.11730",
    "authors": [
      "Shuai Wang",
      "Qibing Bai",
      "Qi Liu",
      "Jianwei Yu",
      "Zhengyang Chen",
      "Bing Han",
      "Yanmin Qian",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.11811",
    "title": "Multimodal Transformers for Wireless Communications: A Case Study in  Beam Prediction",
    "abstract": "Wireless communications at high-frequency bands with large antenna arrays face challenges in beam management, which can potentially be improved by multimodality sensing information from cameras, LiDAR, radar, and GPS. In this paper, we present a multimodal transformer deep learning framework for sensing-assisted beam prediction. We employ a convolutional neural network to extract the features from a sequence of images, point clouds, and radar raw data sampled over time. At each convolutional layer, we use transformer encoders to learn the hidden relations between feature tokens from different modalities and time instances over abstraction space and produce encoded vectors for the next-level feature extraction. We train the model on a combination of different modalities with supervised learning. We try to enhance the model over imbalanced data by utilizing focal loss and exponential moving average. We also evaluate data processing and augmentation techniques such as image enhancement, segmentation, background filtering, multimodal data flipping, radar signal transformation, and GPS angle calibration. Experimental results show that our solution trained on image and GPS data produces the best distance-based accuracy of predicted beams at 78.44%, with effective generalization to unseen day scenarios near 73% and night scenarios over 84%. This outperforms using other modalities and arbitrary data processing techniques, which demonstrates the effectiveness of transformers with feature fusion in performing radio beam prediction from images and GPS. Furthermore, our solution could be pretrained from large sequences of multimodality wireless data, on fine-tuning for multiple downstream radio network tasks. ",
    "url": "https://arxiv.org/abs/2309.11811",
    "authors": [
      "Yu Tian",
      "Qiyang Zhao",
      "Zine el abidine Kherroubi",
      "Fouzi Boukhalfa",
      "Kebin Wu",
      "Faouzi Bader"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11840",
    "title": "Four universal growth regimes in degree-dependent first passage  percolation on spatial random graphs I",
    "abstract": "We consider three spatial scale-free random graph models: finite and infinite Geometric Inhomogeneous Random Graphs, and Scale-Free Percolation. In these spatial models, the connection probability between two nodes depends on their spatial distance and on their expected degrees. Motivated by awareness or time-limitations of nodes to pass information or an infection along, we study a version of first-passage percolation on these graphs where the transmission time between two connected nodes is non-iid, but instead increases by a penalty factor polynomial in their expected degrees. Beyond the Markov case, we also allow a wide range of transmission time distributions $L$ across edges, where the growth behaviour we see depends on the cumulative distribution function of $L$ at $0$. We show that the transmission time between two far away vertices can be either linear, polynomial, or polylogarithmic in their geometric distance, based on a few parameters of the model such as the tail of the degree distribution, the long-range parameter, and the penalty function. In this paper we present the proofs of the upper bounds. This complements results from a companion paper in which we show matching lower bounds in the polynomial and linear regimes. Together with the companion paper and previous work, our results imply that the transmission time undergoes three phase transitions as the penalty exponent increases, yielding phases in which transmission times are linear in the Euclidean distance, or polynomial but sublinear, or at most polylogarithmic but unbounded, or bounded (called explosive regime). ",
    "url": "https://arxiv.org/abs/2309.11840",
    "authors": [
      "J\u00falia Komj\u00e1thy",
      "John Lapinskas",
      "Johannes Lengler",
      "Ulysse Schaller"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2309.11856",
    "title": "Activation Compression of Graph Neural Networks using Block-wise  Quantization with Improved Variance Minimization",
    "abstract": "Efficient training of large-scale graph neural networks (GNNs) has been studied with a specific focus on reducing their memory consumption. Work by Liu et al. (2022) proposed extreme activation compression (EXACT) which demonstrated drastic reduction in memory consumption by performing quantization of the intermediate activation maps down to using INT2 precision. They showed little to no reduction in performance while achieving large reductions in GPU memory consumption. In this work, we present an improvement to the EXACT strategy by using block-wise quantization of the intermediate activation maps. We experimentally analyze different block sizes and show further reduction in memory consumption (>15%), and runtime speedup per epoch (about 5%) even when performing extreme extents of quantization with similar performance trade-offs as with the original EXACT. Further, we present a correction to the assumptions on the distribution of intermediate activation maps in EXACT (assumed to be uniform) and show improved variance estimations of the quantization and dequantization steps. ",
    "url": "https://arxiv.org/abs/2309.11856",
    "authors": [
      "Sebastian Eliassen",
      "Raghavendra Selvan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11880",
    "title": "Four universal growth regimes in degree-dependent first passage  percolation on spatial random graphs II",
    "abstract": "In this paper we study a version of (non-Markovian) first passage percolation on graphs, where the transmission time between two connected vertices is non-iid, but increases by a penalty factor polynomial in their expected degrees. Based on the exponent of the penalty-polynomial, this makes it increasingly harder to transmit to and from high-degree vertices. This choice is motivated by awareness or time-limitations. For the underlying graph models we choose spatial random graphs that have power-law degree distributions, so that the effect of the penalisation becomes visible: (finite and infinite) Geometric Inhomogeneous Random Graphs, and Scale-Free Percolation. In these spatial models, the connection probability between two vertices depends on their spatial distance and on their expected degrees. We identify the parameter-regimes where the transmission time between two far away vertices $x,y$ are respectively polynomial ($\\Theta(|x-y|^{\\eta_0})$ for some $\\eta_0<1$), and linear ($\\Theta(|x-y|)$) in their Euclidean distance. In this paper we present proofs of lower bounds and the upper bound for the linear regime. These complement the matching upper bounds for the polynomial regime in our companion paper. Together with the companion paper and other work, our results imply that the transmission time between $x,y$ undergoes three phase transitions as the penalty exponent increases. The four phases are: bounded (explosive), at most polylogarithmic, polynomial but sublinear, and linear transmission times. We conjecture universality of this phenomenon across models. ",
    "url": "https://arxiv.org/abs/2309.11880",
    "authors": [
      "J\u00falia Komj\u00e1thy",
      "John Lapinskas",
      "Johannes Lengler",
      "Ulysse Schaller"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2309.11891",
    "title": "Heart Rate Detection Using an Event Camera",
    "abstract": "Event cameras, also known as neuromorphic cameras, are an emerging technology that offer advantages over traditional shutter and frame-based cameras, including high temporal resolution, low power consumption, and selective data acquisition. In this study, we propose to harnesses the capabilities of event-based cameras to capture subtle changes in the surface of the skin caused by the pulsatile flow of blood in the wrist region. We investigate whether an event camera could be used for continuous noninvasive monitoring of heart rate (HR). Event camera video data from 25 participants, comprising varying age groups and skin colours, was collected and analysed. Ground-truth HR measurements obtained using conventional methods were used to evaluate of the accuracy of automatic detection of HR from event camera data. Our experimental results and comparison to the performance of other non-contact HR measurement methods demonstrate the feasibility of using event cameras for pulse detection. We also acknowledge the challenges and limitations of our method, such as light-induced flickering and the sub-conscious but naturally-occurring tremors of an individual during data capture. ",
    "url": "https://arxiv.org/abs/2309.11891",
    "authors": [
      "Aniket Jagtap",
      "RamaKrishna Venkatesh Saripalli",
      "Joe Lemley",
      "Waseem Shariff",
      "Alan F. Smeaton"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12010",
    "title": "Convolution and Attention Mixer for Synthetic Aperture Radar Image  Change Detection",
    "abstract": "Synthetic aperture radar (SAR) image change detection is a critical task and has received increasing attentions in the remote sensing community. However, existing SAR change detection methods are mainly based on convolutional neural networks (CNNs), with limited consideration of global attention mechanism. In this letter, we explore Transformer-like architecture for SAR change detection to incorporate global attention. To this end, we propose a convolution and attention mixer (CAMixer). First, to compensate the inductive bias for Transformer, we combine self-attention with shift convolution in a parallel way. The parallel design effectively captures the global semantic information via the self-attention and performs local feature extraction through shift convolution simultaneously. Second, we adopt a gating mechanism in the feed-forward network to enhance the non-linear feature transformation. The gating mechanism is formulated as the element-wise multiplication of two parallel linear layers. Important features can be highlighted, leading to high-quality representations against speckle noise. Extensive experiments conducted on three SAR datasets verify the superior performance of the proposed CAMixer. The source codes will be publicly available at https://github.com/summitgao/CAMixer . ",
    "url": "https://arxiv.org/abs/2309.12010",
    "authors": [
      "Haopeng Zhang",
      "Zijing Lin",
      "Feng Gao",
      "Junyu Dong",
      "Qian Du",
      "Heng-Chao Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12094",
    "title": "RadYOLOLet: Radar Detection and Parameter Estimation Using YOLO and  WaveLet",
    "abstract": "Detection of radar signals without assistance from the radar transmitter is a crucial requirement for emerging and future shared-spectrum wireless networks like Citizens Broadband Radio Service (CBRS). In this paper, we propose a supervised deep learning-based spectrum sensing approach called RadYOLOLet that can detect low-power radar signals in the presence of interference and estimate the radar signal parameters. The core of RadYOLOLet is two different convolutional neural networks (CNN), RadYOLO and Wavelet-CNN, that are trained independently. RadYOLO operates on spectrograms and provides most of the capabilities of RadYOLOLet. However, it suffers from low radar detection accuracy in the low signal-to-noise ratio (SNR) regime. We develop Wavelet-CNN specifically to deal with this limitation of RadYOLO. Wavelet-CNN operates on continuous Wavelet transform of the captured signals, and we use it only when RadYOLO fails to detect any radar signal. We thoroughly evaluate RadYOLOLet using different experiments corresponding to different types of interference signals. Based on our evaluations, we find that RadYOLOLet can achieve 100% radar detection accuracy for our considered radar types up to 16 dB SNR, which cannot be guaranteed by other comparable methods. RadYOLOLet can also function accurately under interference up to 16 dB SINR. ",
    "url": "https://arxiv.org/abs/2309.12094",
    "authors": [
      "Shamik Sarkar",
      "Dongning Guo",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.12095",
    "title": "Bayesian sparsification for deep neural networks with Bayesian model  reduction",
    "abstract": "Deep learning's immense capabilities are often constrained by the complexity of its models, leading to an increasing demand for effective sparsification techniques. Bayesian sparsification for deep learning emerges as a crucial approach, facilitating the design of models that are both computationally efficient and competitive in terms of performance across various deep learning applications. The state-of-the-art -- in Bayesian sparsification of deep neural networks -- combines structural shrinkage priors on model weights with an approximate inference scheme based on black-box stochastic variational inference. However, model inversion of the full generative model is exceptionally computationally demanding, especially when compared to standard deep learning of point estimates. In this context, we advocate for the use of Bayesian model reduction (BMR) as a more efficient alternative for pruning of model weights. As a generalization of the Savage-Dickey ratio, BMR allows a post-hoc elimination of redundant model weights based on the posterior estimates under a straightforward (non-hierarchical) generative model. Our comparative study highlights the computational efficiency and the pruning rate of the BMR method relative to the established stochastic variational inference (SVI) scheme, when applied to the full hierarchical generative model. We illustrate the potential of BMR to prune model parameters across various deep learning architectures, from classical networks like LeNet to modern frameworks such as Vision Transformers and MLP-Mixers. ",
    "url": "https://arxiv.org/abs/2309.12095",
    "authors": [
      "Dimitrije Markovi\u0107",
      "Karl J. Friston",
      "Stefan J. Kiebel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.12121",
    "title": "A Multiscale Autoencoder (MSAE) Framework for End-to-End Neural Network  Speech Enhancement",
    "abstract": "Neural network approaches to single-channel speech enhancement have received much recent attention. In particular, mask-based architectures have achieved significant performance improvements over conventional methods. This paper proposes a multiscale autoencoder (MSAE) for mask-based end-to-end neural network speech enhancement. The MSAE performs spectral decomposition of an input waveform within separate band-limited branches, each operating with a different rate and scale, to extract a sequence of multiscale embeddings. The proposed framework features intuitive parameterization of the autoencoder, including a flexible spectral band design based on the Constant-Q transform. Additionally, the MSAE is constructed entirely of differentiable operators, allowing it to be implemented within an end-to-end neural network, and be discriminatively trained. The MSAE draws motivation both from recent multiscale network topologies and from traditional multiresolution transforms in speech processing. Experimental results show the MSAE to provide clear performance benefits relative to conventional single-branch autoencoders. Additionally, the proposed framework is shown to outperform a variety of state-of-the-art enhancement systems, both in terms of objective speech quality metrics and automatic speech recognition accuracy. ",
    "url": "https://arxiv.org/abs/2309.12121",
    "authors": [
      "Bengt J. Borgstrom",
      "Michael S. Brandstein"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.12141",
    "title": "Guided rewiring of social networks reduces polarization and accelerates  collective action",
    "abstract": "Global challenges like climate change may be considered as collective action problems that require sufficient cooperation with pro-mitigation norms, soon enough to be effective. Socio-political polarization is a barrier to collective action. Prior agent-based models of behavioural change on structured networks in a shared socio-political environment have shown that polarization emerges naturally in such systems and that the speed of consensus formation is limited by the rate at which polarized clusters can be dissolved. Here we study how guided social link rewiring affects the speed of network depolarization. We investigate rewiring algorithms representing random meetings, introduction by mutual acquaintances, and bridging between socially distant communities. We find that building lasting links between polarized individuals and communities can accelerate consensus formation when the sociopolitical environment is favourable. This strengthens the evidence that promoting connection between polarized communities could accelerate collective action on urgent global challenges. ",
    "url": "https://arxiv.org/abs/2309.12141",
    "authors": [
      "Lilli Frei",
      "Jordan Everall",
      "Andrew K. Ringsmuth"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2309.12165",
    "title": "Analysis of the Error-Correcting Radius of a Renormalisation Decoder for  Kitaev's Toric Code",
    "abstract": "Kitaev's toric code is arguably the most studied quantum code and is expected to be implemented in future generations of quantum computers. The renormalisation decoders introduced by Duclos-Cianci and Poulin exhibit one of the best trade-offs between efficiency and speed, but one question that was left open is how they handle worst-case or adversarial errors, i.e. what is the order of magnitude of the smallest weight of an error pattern that will be wrongly decoded. We initiate such a study involving a simple hard-decision and deterministic version of a renormalisation decoder. We exhibit an uncorrectable error pattern whose weight scales like $d^{1/2}$ and prove that the decoder corrects all error patterns of weight less than $\\frac{5}{6} d^{\\log_{2}(6/5)}$, where $d$ is the minimum distance of the toric code. ",
    "url": "https://arxiv.org/abs/2309.12165",
    "authors": [
      "Wouter Rozendaal",
      "Gilles Z\u00e9mor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.12193",
    "title": "Brain Tumor Detection Using Deep Learning Approaches",
    "abstract": "Brain tumors are collections of abnormal cells that can develop into masses or clusters. Because they have the potential to infiltrate other tissues, they pose a risk to the patient. The main imaging technique used, MRI, may be able to identify a brain tumor with accuracy. The fast development of Deep Learning methods for use in computer vision applications has been facilitated by a vast amount of training data and improvements in model construction that offer better approximations in a supervised setting. The need for these approaches has been the main driver of this expansion. Deep learning methods have shown promise in improving the precision of brain tumor detection and classification using magnetic resonance imaging (MRI). The study on the use of deep learning techniques, especially ResNet50, for brain tumor identification is presented in this abstract. As a result, this study investigates the possibility of automating the detection procedure using deep learning techniques. In this study, I utilized five transfer learning models which are VGG16, VGG19, DenseNet121, ResNet50 and YOLO V4 where ResNet50 provide the best or highest accuracy 99.54%. The goal of the study is to guide researchers and medical professionals toward powerful brain tumor detecting systems by employing deep learning approaches by way of this evaluation and analysis. ",
    "url": "https://arxiv.org/abs/2309.12193",
    "authors": [
      "Razia Sultana Misu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.12200",
    "title": "A Variational Auto-Encoder Enabled Multi-Band Channel Prediction Scheme  for Indoor Localization",
    "abstract": "Indoor localization is getting increasing demands for various cutting-edged technologies, like Virtual/Augmented reality and smart home. Traditional model-based localization suffers from significant computational overhead, so fingerprint localization is getting increasing attention, which needs lower computation cost after the fingerprint database is built. However, the accuracy of indoor localization is limited by the complicated indoor environment which brings the multipath signal refraction. In this paper, we provided a scheme to improve the accuracy of indoor fingerprint localization from the frequency domain by predicting the channel state information (CSI) values from another transmitting channel and spliced the multi-band information together to get more precise localization results. We tested our proposed scheme on COST 2100 simulation data and real time orthogonal frequency division multiplexing (OFDM) WiFi data collected from an office scenario. ",
    "url": "https://arxiv.org/abs/2309.12200",
    "authors": [
      "Ruihao Yuan",
      "Kaixuan Huang",
      "Pan Yang",
      "Shunqing Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2103.07666",
    "title": "GraphIQA: Learning Distortion Graph Representations for Blind Image  Quality Assessment",
    "abstract": " Comments: 12 pages, 7 figures, published on IEEE Transactions on Multimedia ",
    "url": "https://arxiv.org/abs/2103.07666",
    "authors": [
      "Simeng Sun",
      "Tao Yu",
      "Jiahua Xu",
      "Wei Zhou",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2109.05152",
    "title": "Making Online Communities 'Better': A Taxonomy of Community Values on  Reddit",
    "abstract": " Comments: to appear at ICWSM 2024 ",
    "url": "https://arxiv.org/abs/2109.05152",
    "authors": [
      "Galen Weld",
      "Amy X. Zhang",
      "Tim Althoff"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.14985",
    "title": "THE Benchmark: Transferable Representation Learning for Monocular Height  Estimation",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2112.14985",
    "authors": [
      "Zhitong Xiong",
      "Wei Huang",
      "Jingtao Hu",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.02998",
    "title": "Optimal Propagation for Graph Neural Networks",
    "abstract": " Comments: 7 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2205.02998",
    "authors": [
      "Beidi Zhao",
      "Boxin Du",
      "Zhe Xu",
      "Liangyue Li",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.04952",
    "title": "Read the Room: Adapting a Robot's Voice to Ambient and Social Contexts",
    "abstract": " Comments: 8 pages, 10 figures, Accepted to International Conference on Intelligent Robots and Systems, project webpage: this https URL ",
    "url": "https://arxiv.org/abs/2205.04952",
    "authors": [
      "Paige Tuttosi",
      "Emma Hughson",
      "Akihiro Matsufuji",
      "Angelica Lim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00164",
    "title": "Distilled Low Rank Neural Radiance Field with Quantization for Light  Field Compression",
    "abstract": " Title: Distilled Low Rank Neural Radiance Field with Quantization for Light  Field Compression ",
    "url": "https://arxiv.org/abs/2208.00164",
    "authors": [
      "Jinglei Shi",
      "Christine Guillemot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2209.10682",
    "title": "Effects of Online Self-Disclosure on Social Feedback During the COVID-19  Pandemic",
    "abstract": " Comments: Accepted to ACM Transactions on Social Computing ",
    "url": "https://arxiv.org/abs/2209.10682",
    "authors": [
      "Jooyoung Lee",
      "Sarah Rajtmajer",
      "Eesha Srivatsavaya",
      "Shomir Wilson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.10136",
    "title": "Discipline Reputation Evaluation Based on PhD Exchange Network",
    "abstract": " Comments: 18 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2210.10136",
    "authors": [
      "Shudong Yang",
      "Hua Jiang",
      "Shuang Li",
      "Shengbo Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.11278",
    "title": "Decision-making and control with diffractive optical networks",
    "abstract": " Title: Decision-making and control with diffractive optical networks ",
    "url": "https://arxiv.org/abs/2212.11278",
    "authors": [
      "Jumin Qiu",
      "Shuyuan Xiao",
      "Lujun Huang",
      "Andrey Miroshnichenko",
      "Dejian Zhang",
      "Tingting Liu",
      "Tianbao Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2212.14142",
    "title": "Joint User Association and Bandwidth Allocation in Semantic  Communication Networks",
    "abstract": " Comments: This paper has been accepted for publication by IEEE Transactions on Vehicular Technology. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2212.14142",
    "authors": [
      "Le Xia",
      "Yao Sun",
      "Dusit Niyato",
      "Xiaoqian Li",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.06681",
    "title": "Cross-domain Self-supervised Framework for Photoacoustic Computed  Tomography Image Reconstruction",
    "abstract": " Title: Cross-domain Self-supervised Framework for Photoacoustic Computed  Tomography Image Reconstruction ",
    "url": "https://arxiv.org/abs/2301.06681",
    "authors": [
      "Hengrong Lan",
      "Lijie Huang",
      "Zhiqiang Li",
      "Jing Lv",
      "Jianwen Luo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.01682",
    "title": "Neural-BO: A Black-box Optimization Algorithm using Deep Neural Networks",
    "abstract": " Title: Neural-BO: A Black-box Optimization Algorithm using Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2303.01682",
    "authors": [
      "Dat Phan-Trong",
      "Hung Tran-The",
      "Sunil Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07820",
    "title": "Adaptive Rotated Convolution for Rotated Object Detection",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2303.07820",
    "authors": [
      "Yifan Pu",
      "Yiru Wang",
      "Zhuofan Xia",
      "Yizeng Han",
      "Yulin Wang",
      "Weihao Gan",
      "Zidong Wang",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.13773",
    "title": "Graph Neural Networks for the Offline Nanosatellite Task Scheduling  Problem",
    "abstract": " Title: Graph Neural Networks for the Offline Nanosatellite Task Scheduling  Problem ",
    "url": "https://arxiv.org/abs/2303.13773",
    "authors": [
      "Bruno Machado Pacheco",
      "Laio Oriel Seman",
      "Cezar Antonio Rigo",
      "Eduardo Camponogara",
      "Eduardo Augusto Bezerra",
      "Leandro dos Santos Coelho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.14772",
    "title": "$\u0394$-Patching: A Framework for Rapid Adaptation of Pre-trained  Convolutional Networks without Base Performance Loss",
    "abstract": " Title: $\u0394$-Patching: A Framework for Rapid Adaptation of Pre-trained  Convolutional Networks without Base Performance Loss ",
    "url": "https://arxiv.org/abs/2303.14772",
    "authors": [
      "Chaitanya Devaguptapu",
      "Samarth Sinha",
      "K J Joseph",
      "Vineeth N Balasubramanian",
      "Animesh Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03398",
    "title": "Quantum Conformal Prediction for Reliable Uncertainty Quantification in  Quantum Machine Learning",
    "abstract": " Comments: added subsection on application to quantum data ",
    "url": "https://arxiv.org/abs/2304.03398",
    "authors": [
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.13147",
    "title": "Self-Supervised Multi-Object Tracking For Autonomous Driving From  Consistency Across Timescales",
    "abstract": " Comments: 8 pages, 3 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2304.13147",
    "authors": [
      "Christopher Lang",
      "Alexander Braun",
      "Lars Schillingmann",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.14923",
    "title": "Deep sound-field denoiser: optically-measured sound-field denoising  using deep neural network",
    "abstract": " Comments: 16 pages, 10 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2304.14923",
    "authors": [
      "Kenji Ishikawa",
      "Daiki Takeuchi",
      "Noboru Harada",
      "Takehiro Moriya"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2305.14129",
    "title": "GrACE: Generation using Associated Code Edits",
    "abstract": " Title: GrACE: Generation using Associated Code Edits ",
    "url": "https://arxiv.org/abs/2305.14129",
    "authors": [
      "Priyanshu Gupta",
      "Avishree Khare",
      "Yasharth Bajpai",
      "Saikat Chakraborty",
      "Sumit Gulwani",
      "Aditya Kanade",
      "Arjun Radhakrishna",
      "Gustavo Soares",
      "Ashish Tiwari"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14310",
    "title": "Navigating Prompt Complexity for Zero-Shot Classification: A Study of  Large Language Models in Computational Social Science",
    "abstract": " Title: Navigating Prompt Complexity for Zero-Shot Classification: A Study of  Large Language Models in Computational Social Science ",
    "url": "https://arxiv.org/abs/2305.14310",
    "authors": [
      "Yida Mu",
      "Ben P. Wu",
      "William Thorne",
      "Ambrose Robinson",
      "Nikolaos Aletras",
      "Carolina Scarton",
      "Kalina Bontcheva",
      "Xingyi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.18568",
    "title": "Performance of affine-splitting pseudo-spectral methods for fractional  complex Ginzburg-Landau equations",
    "abstract": " Comments: 37 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2305.18568",
    "authors": [
      "Lisandro A. Raviola",
      "Mariano F. De Leo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2306.14437",
    "title": "A Self-supervised Contrastive Learning Method for Grasp Outcomes  Prediction",
    "abstract": " Comments: Manuscript accepted to RCAR 2023 ",
    "url": "https://arxiv.org/abs/2306.14437",
    "authors": [
      "Chengliang Liu",
      "Binhua Huang",
      "Yiwen Liu",
      "Yuanzhe Su",
      "Ke Mai",
      "Yupo Zhang",
      "Zhengkun Yi",
      "Xinyu Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16524",
    "title": "Hyena Neural Operator for Partial Differential Equations",
    "abstract": " Title: Hyena Neural Operator for Partial Differential Equations ",
    "url": "https://arxiv.org/abs/2306.16524",
    "authors": [
      "Saurabh Patil",
      "Zijie Li",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.00215",
    "title": "A Constructive Approach to Function Realization by Neural Stochastic  Differential Equations",
    "abstract": " Comments: 6 pages, 1 pdf figure; final version accepted to IEEE Conference on Decision and Control ",
    "url": "https://arxiv.org/abs/2307.00215",
    "authors": [
      "Tanya Veeravalli",
      "Maxim Raginsky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.01701",
    "title": "Synthetic is all you need: removing the auxiliary data assumption for  membership inference attacks against synthetic data",
    "abstract": " Title: Synthetic is all you need: removing the auxiliary data assumption for  membership inference attacks against synthetic data ",
    "url": "https://arxiv.org/abs/2307.01701",
    "authors": [
      "Florent Gu\u00e9pin",
      "Matthieu Meeus",
      "Ana-Maria Cretu",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15299",
    "title": "Differential Evolution Algorithm based Hyper-Parameters Selection of  Transformer Neural Network Model for Load Forecasting",
    "abstract": " Comments: 6 Pages, 6 Figures, 2 Tables, Accepted by the 14th IEEE International Symposium Series on Computational Intelligence (SSCI 2023), December 5-8, 2023, Mexico City, Mexico ",
    "url": "https://arxiv.org/abs/2307.15299",
    "authors": [
      "Anuvab Sen",
      "Arul Rhik Mazumder",
      "Udayon Sen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15506",
    "title": "Improving Image Quality of Sparse-view Lung Cancer CT Images with a  Convolutional Neural Network",
    "abstract": " Title: Improving Image Quality of Sparse-view Lung Cancer CT Images with a  Convolutional Neural Network ",
    "url": "https://arxiv.org/abs/2307.15506",
    "authors": [
      "Annika Ries",
      "Tina Dorosti",
      "Johannes Thalhammer",
      "Daniel Sasse",
      "Andreas Sauter",
      "Felix Meurer",
      "Ashley Benne",
      "Tobias Lasser",
      "Franz Pfeiffer",
      "Florian Schaff",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2308.05721",
    "title": "Deformable Mixer Transformer with Gating for Multi-Task Learning of  Dense Prediction",
    "abstract": " Comments: submitted to IJCV; an extension to our previous AAAI 2023 paper arXiv:2301.03461 ",
    "url": "https://arxiv.org/abs/2308.05721",
    "authors": [
      "Yangyang Xu",
      "Yibo Yang",
      "Bernard Ghanem",
      "Lefei Zhang",
      "Du Bo",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07037",
    "title": "Bayesian Flow Networks",
    "abstract": " Title: Bayesian Flow Networks ",
    "url": "https://arxiv.org/abs/2308.07037",
    "authors": [
      "Alex Graves",
      "Rupesh Kumar Srivastava",
      "Timothy Atkinson",
      "Faustino Gomez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09440",
    "title": "Scope is all you need: Transforming LLMs for HPC Code",
    "abstract": " Title: Scope is all you need: Transforming LLMs for HPC Code ",
    "url": "https://arxiv.org/abs/2308.09440",
    "authors": [
      "Tal Kadosh",
      "Niranjan Hasabnis",
      "Vy A. Vo",
      "Nadav Schneider",
      "Neva Krien",
      "Abdul Wasay",
      "Nesreen Ahmed",
      "Ted Willke",
      "Guy Tamir",
      "Yuval Pinter",
      "Timothy Mattson",
      "Gal Oren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2308.10658",
    "title": "Learning Clothing and Pose Invariant 3D Shape Representation for  Long-Term Person Re-Identification",
    "abstract": " Comments: 10 pages, 7 figures, accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2308.10658",
    "authors": [
      "Feng Liu",
      "Minchul Kim",
      "ZiAng Gu",
      "Anil Jain",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03992",
    "title": "ConDA: Contrastive Domain Adaptation for AI-generated Text Detection",
    "abstract": " Comments: Camera-ready for IJCNLP-AACL 2023 main track ",
    "url": "https://arxiv.org/abs/2309.03992",
    "authors": [
      "Amrita Bhattacharjee",
      "Tharindu Kumarage",
      "Raha Moraffah",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07719",
    "title": "L1-aware Multilingual Mispronunciation Detection Framework",
    "abstract": " Comments: 5 papers, submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.07719",
    "authors": [
      "Yassine El Kheir",
      "Shammur Absar Chowdhury",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.09517",
    "title": "FedGKD: Unleashing the Power of Collaboration in Federated Graph Neural  Networks",
    "abstract": " Title: FedGKD: Unleashing the Power of Collaboration in Federated Graph Neural  Networks ",
    "url": "https://arxiv.org/abs/2309.09517",
    "authors": [
      "Qiying Pan",
      "Ruofan Wu",
      "Tengfei Liu",
      "Tianyi Zhang",
      "Yifei Zhu",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.09553",
    "title": "Causal-Story: Local Causal Attention Utilizing Parameter-Efficient  Tuning For Visual Story Synthesis",
    "abstract": " Comments: Submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.09553",
    "authors": [
      "Tianyi Song",
      "Jiuxin Cao",
      "Kun Wang",
      "Bo Liu",
      "Xiaofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2309.10532",
    "title": "A Cognitively-Inspired Neural Architecture for Visual Abstract Reasoning  Using Contrastive Perceptual and Conceptual Processing",
    "abstract": " Title: A Cognitively-Inspired Neural Architecture for Visual Abstract Reasoning  Using Contrastive Perceptual and Conceptual Processing ",
    "url": "https://arxiv.org/abs/2309.10532",
    "authors": [
      "Yuan Yang",
      "Deepayan Sanyal",
      "James Ainooson",
      "Joel Michelson",
      "Effat Farhana",
      "Maithilee Kunda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.10916",
    "title": "What Learned Representations and Influence Functions Can Tell Us About  Adversarial Examples",
    "abstract": " Comments: 20 pages, Accepted long-paper IJCNLP_AACL 2023 ",
    "url": "https://arxiv.org/abs/2309.10916",
    "authors": [
      "Shakila Mahjabin Tonni",
      "Mark Dras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.11009",
    "title": "Controllable Dynamic Appearance for Neural 3D Portraits",
    "abstract": " Title: Controllable Dynamic Appearance for Neural 3D Portraits ",
    "url": "https://arxiv.org/abs/2309.11009",
    "authors": [
      "ShahRukh Athar",
      "Zhixin Shu",
      "Zexiang Xu",
      "Fujun Luan",
      "Sai Bi",
      "Kalyan Sunkavalli",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11052",
    "title": "fakenewsbr: A Fake News Detection Platform for Brazilian Portuguese",
    "abstract": " Title: fakenewsbr: A Fake News Detection Platform for Brazilian Portuguese ",
    "url": "https://arxiv.org/abs/2309.11052",
    "authors": [
      "Luiz Giordani",
      "Gilsiley Dar\u00fa",
      "Rhenan Queiroz",
      "Vitor Buzinaro",
      "Davi Keglevich Neiva",
      "Daniel Camilo Fuentes Guzm\u00e1n",
      "Marcos Jardel Henriques",
      "Oilson Alberto Gonzatto Junior",
      "Francisco Louzada"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.11062",
    "title": "The social stratification of internal migration and daily mobility  during the COVID-19 pandemic",
    "abstract": " Title: The social stratification of internal migration and daily mobility  during the COVID-19 pandemic ",
    "url": "https://arxiv.org/abs/2309.11062",
    "authors": [
      "Erick Elejalde",
      "Leo Ferres",
      "V\u00edctor Navarro",
      "Loreto Bravo",
      "Emilio Zagheni"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.11139",
    "title": "More complex encoder is not all you need",
    "abstract": " Title: More complex encoder is not all you need ",
    "url": "https://arxiv.org/abs/2309.11139",
    "authors": [
      "Weibin Yang",
      "Longwei Xu",
      "Pengwei Wang",
      "Dehua Geng",
      "Yusong Li",
      "Mingyuan Xu",
      "Zhiqi Dong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11157",
    "title": "Learning Deformable 3D Graph Similarity to Track Plant Cells in  Unregistered Time Lapse Images",
    "abstract": " Title: Learning Deformable 3D Graph Similarity to Track Plant Cells in  Unregistered Time Lapse Images ",
    "url": "https://arxiv.org/abs/2309.11157",
    "authors": [
      "Md Shazid Islam",
      "Arindam Dutta",
      "Calvin-Khang Ta",
      "Kevin Rodriguez",
      "Christian Michael",
      "Mark Alber",
      "G. Venugopala Reddy",
      "Amit K. Roy-Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11206",
    "title": "Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for  Knowledge Graph Question Answering",
    "abstract": " Title: Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for  Knowledge Graph Question Answering ",
    "url": "https://arxiv.org/abs/2309.11206",
    "authors": [
      "Yike Wu",
      "Nan Hu",
      "Sheng Bi",
      "Guilin Qi",
      "Jie Ren",
      "Anhuan Xie",
      "Wei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.11354",
    "title": "Self-supervised learning unveils change in urban housing from  street-level images",
    "abstract": " Comments: 16 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2309.11354",
    "authors": [
      "Steven Stalder",
      "Michele Volpi",
      "Nicolas B\u00fcttner",
      "Stephen Law",
      "Kenneth Harttgen",
      "Esra Suel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]