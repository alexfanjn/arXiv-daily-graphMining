[
  {
    "id": "arXiv:2309.07941",
    "title": "MDP Abstractions from Data: Large-Scale Stochastic Networks",
    "abstract": "This work proposes a compositional data-driven technique for the construction of finite Markov decision processes (MDPs) for large-scale stochastic networks with unknown mathematical models. Our proposed framework leverages dissipativity properties of subsystems and their finite MDPs using a notion of stochastic storage functions (SStF). In our data-driven scheme, we first build an SStF between each unknown subsystem and its data-driven finite MDP with a certified probabilistic confidence. We then derive dissipativity-type compositional conditions to construct a stochastic bisimulation function (SBF) between an interconnected network and its finite MDP using data-driven SStF of subsystems. Accordingly, we formally quantify the probabilistic distance between trajectories of an unknown large-scale stochastic network and those of its finite MDP with a guaranteed confidence. We illustrate the efficacy of our data-driven results over a room temperature network composing 100 rooms with unknown models. ",
    "url": "https://arxiv.org/abs/2309.07941",
    "authors": [
      "Abolfazl Lavaei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.07947",
    "title": "TiBGL: Template-induced Brain Graph Learning for Functional Neuroimaging  Analysis",
    "abstract": "In recent years, functional magnetic resonance imaging has emerged as a powerful tool for investigating the human brain's functional connectivity networks. Related studies demonstrate that functional connectivity networks in the human brain can help to improve the efficiency of diagnosing neurological disorders. However, there still exist two challenges that limit the progress of functional neuroimaging. Firstly, there exists an abundance of noise and redundant information in functional connectivity data, resulting in poor performance. Secondly, existing brain network models have tended to prioritize either classification performance or the interpretation of neuroscience findings behind the learned models. To deal with these challenges, this paper proposes a novel brain graph learning framework called Template-induced Brain Graph Learning (TiBGL), which has both discriminative and interpretable abilities. Motivated by the related medical findings on functional connectivites, TiBGL proposes template-induced brain graph learning to extract template brain graphs for all groups. The template graph can be regarded as an augmentation process on brain networks that removes noise information and highlights important connectivity patterns. To simultaneously support the tasks of discrimination and interpretation, TiBGL further develops template-induced convolutional neural network and template-induced brain interpretation analysis. Especially, the former fuses rich information from brain graphs and template brain graphs for brain disorder tasks, and the latter can provide insightful connectivity patterns related to brain disorders based on template brain graphs. Experimental results on three real-world datasets show that the proposed TiBGL can achieve superior performance compared with nine state-of-the-art methods and keep coherent with neuroscience findings in recent literatures. ",
    "url": "https://arxiv.org/abs/2309.07947",
    "authors": [
      "Xiangzhu Meng",
      "Wei Wei",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07983",
    "title": "SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker  Recognition Systems",
    "abstract": "Membership inference attacks allow adversaries to determine whether a particular example was contained in the model's training dataset. While previous works have confirmed the feasibility of such attacks in various applications, none has focused on speaker recognition (SR), a promising voice-based biometric recognition technique. In this work, we propose SLMIA-SR, the first membership inference attack tailored to SR. In contrast to conventional example-level attack, our attack features speaker-level membership inference, i.e., determining if any voices of a given speaker, either the same as or different from the given inference voices, have been involved in the training of a model. It is particularly useful and practical since the training and inference voices are usually distinct, and it is also meaningful considering the open-set nature of SR, namely, the recognition speakers were often not present in the training data. We utilize intra-closeness and inter-farness, two training objectives of SR, to characterize the differences between training and non-training speakers and quantify them with two groups of features driven by carefully-established feature engineering to mount the attack. To improve the generalizability of our attack, we propose a novel mixing ratio training strategy to train attack models. To enhance the attack performance, we introduce voice chunk splitting to cope with the limited number of inference voices and propose to train attack models dependent on the number of inference voices. Our attack is versatile and can work in both white-box and black-box scenarios. Additionally, we propose two novel techniques to reduce the number of black-box queries while maintaining the attack performance. Extensive experiments demonstrate the effectiveness of SLMIA-SR. ",
    "url": "https://arxiv.org/abs/2309.07983",
    "authors": [
      "Guangke Chen",
      "Yedi Zhang",
      "Fu Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07990",
    "title": "Leveraging Contextual Information for Effective Entity Salience  Detection",
    "abstract": "In text documents such as news articles, the content and key events usually revolve around a subset of all the entities mentioned in a document. These entities, often deemed as salient entities, provide useful cues of the aboutness of a document to a reader. Identifying the salience of entities was found helpful in several downstream applications such as search, ranking, and entity-centric summarization, among others. Prior work on salient entity detection mainly focused on machine learning models that require heavy feature engineering. We show that fine-tuning medium-sized language models with a cross-encoder style architecture yields substantial performance gains over feature engineering approaches. To this end, we conduct a comprehensive benchmarking of four publicly available datasets using models representative of the medium-sized pre-trained language model family. Additionally, we show that zero-shot prompting of instruction-tuned language models yields inferior results, indicating the task's uniqueness and complexity. ",
    "url": "https://arxiv.org/abs/2309.07990",
    "authors": [
      "Rajarshi Bhowmik",
      "Marco Ponza",
      "Atharva Tendle",
      "Anant Gupta",
      "Rebecca Jiang",
      "Xingyu Lu",
      "Qian Zhao",
      "Daniel Preotiuc-Pietro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08006",
    "title": "Kinship Verification from rPPG using 1DCNN Attention networks",
    "abstract": "Facial kinship verification aims at automatically determining whether two subjects have a kinship relation. It has been widely studied from different modalities, such as faces, voices, gait, and smiling expressions. However, the potential of bio-signals, such as remote Photoplethysmography (rPPG) extracted from facial videos, remains largely unexplored in the kinship verification problem. In this paper, we investigate for the first time the usage of the rPPG signal for kinship verification. Specifically, we proposed a one-dimensional Convolutional Neural Network (1DCNN) with a 1DCNN-Attention module and contrastive loss to learn the kinship similarity from rPPGs. The network takes multiple rPPG signals extracted from various facial Regions of Interest (ROIs) as inputs. Additionally, the 1DCNN attention module is designed to learn and capture the discriminative kin features from feature embeddings. Finally, the proposed method is evaluated on the UvANEMO Smile Database from different kin relations, showing the usefulness of rPPG signals in verifying kinship. ",
    "url": "https://arxiv.org/abs/2309.08006",
    "authors": [
      "Xiaoting Wu",
      "Xiaoyi Feng",
      "Lili Liu",
      "Constantino \u00c1lvarez Casado",
      "Miguel Bordallo L\u00f3pez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08010",
    "title": "Malicious Cyber Activity Detection Using Zigzag Persistence",
    "abstract": "In this study we synthesize zigzag persistence from topological data analysis with autoencoder-based approaches to detect malicious cyber activity and derive analytic insights. Cybersecurity aims to safeguard computers, networks, and servers from various forms of malicious attacks, including network damage, data theft, and activity monitoring. Here we focus on the detection of malicious activity using log data. To do this we consider the dynamics of the data by exploring the changing topology of a hypergraph representation gaining insights into the underlying activity. Hypergraphs provide a natural representation of cyber log data by capturing complex interactions between processes. To study the changing topology we use zigzag persistence which captures how topological features persist at multiple dimensions over time. We observe that the resulting barcodes represent malicious activity differently than benign activity. To automate this detection we implement an autoencoder trained on a vectorization of the resulting zigzag persistence barcodes. Our experimental results demonstrate the effectiveness of the autoencoder in detecting malicious activity in comparison to standard summary statistics. Overall, this study highlights the potential of zigzag persistence and its combination with temporal hypergraphs for analyzing cybersecurity log data and detecting malicious behavior. ",
    "url": "https://arxiv.org/abs/2309.08010",
    "authors": [
      "Audun Myers",
      "Alyson Bittner",
      "Sinan Aksoy",
      "Daniel M. Best",
      "Gregory Henselman-Petrusek",
      "Helen Jenne",
      "Cliff Joslyn",
      "Bill Kay",
      "Garret Seppala",
      "Stephen J. Young",
      "Emilie Purvine"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2309.08019",
    "title": "CRYPTO-MINE: Cryptanalysis via Mutual Information Neural Estimation",
    "abstract": "The use of Mutual Information (MI) as a measure to evaluate the efficiency of cryptosystems has an extensive history. However, estimating MI between unknown random variables in a high-dimensional space is challenging. Recent advances in machine learning have enabled progress in estimating MI using neural networks. This work presents a novel application of MI estimation in the field of cryptography. We propose applying this methodology directly to estimate the MI between plaintext and ciphertext in a chosen plaintext attack. The leaked information, if any, from the encryption could potentially be exploited by adversaries to compromise the computational security of the cryptosystem. We evaluate the efficiency of our approach by empirically analyzing multiple encryption schemes and baseline approaches. Furthermore, we extend the analysis to novel network coding-based cryptosystems that provide individual secrecy and study the relationship between information leakage and input distribution. ",
    "url": "https://arxiv.org/abs/2309.08019",
    "authors": [
      "Benjamin D. Kim",
      "Vipindev Adat Vasudevan",
      "Jongchan Woo",
      "Alejandro Cohen",
      "Rafael G. L. D'Oliveira",
      "Thomas Stahlbuhk",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08027",
    "title": "Comparative Assessment of Markov Models and Recurrent Neural Networks  for Jazz Music Generation",
    "abstract": "As generative models have risen in popularity, a domain that has risen alongside is generative models for music. Our study aims to compare the performance of a simple Markov chain model and a recurrent neural network (RNN) model, two popular models for sequence generating tasks, in jazz music improvisation. While music, especially jazz, remains subjective in telling whether a composition is \"good\" or \"bad\", we aim to quantify our results using metrics of groove pattern similarity and pitch class histogram entropy. We trained both models using transcriptions of jazz blues choruses from professional jazz players, and also fed musical jazz seeds to help give our model some context in beginning the generation. Our results show that the RNN outperforms the Markov model on both of our metrics, indicating better rhythmic consistency and tonal stability in the generated music. Through the use of music21 library, we tokenized our jazz dataset into pitches and durations that our model could interpret and train on. Our findings contribute to the growing field of AI-generated music, highlighting the important use of metrics to assess generation quality. Future work includes expanding the dataset of MIDI files to a larger scale, conducting human surveys for subjective evaluations, and incorporating additional metrics to address the challenge of subjectivity in music evaluation. Our study provides valuable insight into the use of recurrent neural networks for sequential based tasks like generating music. ",
    "url": "https://arxiv.org/abs/2309.08027",
    "authors": [
      "Conrad Hsu",
      "Ross Greer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08036",
    "title": "BEA: Revisiting anchor-based object detection DNN using Budding Ensemble  Architecture",
    "abstract": "This paper introduces the Budding Ensemble Architecture (BEA), a novel reduced ensemble architecture for anchor-based object detection models. Object detection models are crucial in vision-based tasks, particularly in autonomous systems. They should provide precise bounding box detections while also calibrating their predicted confidence scores, leading to higher-quality uncertainty estimates. However, current models may make erroneous decisions due to false positives receiving high scores or true positives being discarded due to low scores. BEA aims to address these issues. The proposed loss functions in BEA improve the confidence score calibration and lower the uncertainty error, which results in a better distinction of true and false positives and, eventually, higher accuracy of the object detection models. Both Base-YOLOv3 and SSD models were enhanced using the BEA method and its proposed loss functions. The BEA on Base-YOLOv3 trained on the KITTI dataset results in a 6% and 3.7% increase in mAP and AP50, respectively. Utilizing a well-balanced uncertainty estimation threshold to discard samples in real-time even leads to a 9.6% higher AP50 than its base model. This is attributed to a 40% increase in the area under the AP50-based retention curve used to measure the quality of calibration of confidence scores. Furthermore, BEA-YOLOV3 trained on KITTI provides superior out-of-distribution detection on Citypersons, BDD100K, and COCO datasets compared to the ensembles and vanilla models of YOLOv3 and Gaussian-YOLOv3. ",
    "url": "https://arxiv.org/abs/2309.08036",
    "authors": [
      "Syed Sha Qutub",
      "Neslihan Kose",
      "Rafael Rosales",
      "Michael Paulitsch",
      "Korbinian Hagn",
      "Florian Geissler",
      "Yang Peng",
      "Gereon Hinz",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08043",
    "title": "On Prediction Feature Assignment in the Heckman Selection Model",
    "abstract": "Under missing-not-at-random (MNAR) sample selection bias, the performance of a prediction model is often degraded. This paper focuses on one classic instance of MNAR sample selection bias where a subset of samples have non-randomly missing outcomes. The Heckman selection model and its variants have commonly been used to handle this type of sample selection bias. The Heckman model uses two separate equations to model the prediction and selection of samples, where the selection features include all prediction features. When using the Heckman model, the prediction features must be properly chosen from the set of selection features. However, choosing the proper prediction features is a challenging task for the Heckman model. This is especially the case when the number of selection features is large. Existing approaches that use the Heckman model often provide a manually chosen set of prediction features. In this paper, we propose Heckman-FA as a novel data-driven framework for obtaining prediction features for the Heckman model. Heckman-FA first trains an assignment function that determines whether or not a selection feature is assigned as a prediction feature. Using the parameters of the trained function, the framework extracts a suitable set of prediction features based on the goodness-of-fit of the prediction model given the chosen prediction features and the correlation between noise terms of the prediction and selection equations. Experimental results on real-world datasets show that Heckman-FA produces a robust regression model under MNAR sample selection bias. ",
    "url": "https://arxiv.org/abs/2309.08043",
    "authors": [
      "Huy Mai",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.08049",
    "title": "VoicePAT: An Efficient Open-source Evaluation Toolkit for Voice Privacy  Research",
    "abstract": "Speaker anonymization is the task of modifying a speech recording such that the original speaker cannot be identified anymore. Since the first Voice Privacy Challenge in 2020, along with the release of a framework, the popularity of this research topic is continually increasing. However, the comparison and combination of different anonymization approaches remains challenging due to the complexity of evaluation and the absence of user-friendly research frameworks. We therefore propose an efficient speaker anonymization and evaluation framework based on a modular and easily extendable structure, almost fully in Python. The framework facilitates the orchestration of several anonymization approaches in parallel and allows for interfacing between different techniques. Furthermore, we propose modifications to common evaluation methods which make the evaluation more powerful and reduces their computation time by 65 to 95\\%, depending on the metric. Our code is fully open source. ",
    "url": "https://arxiv.org/abs/2309.08049",
    "authors": [
      "Sarina Meyer",
      "Xiaoxiao Miao",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08050",
    "title": "Robust Control Barrier Functions for Sampled-Data Systems",
    "abstract": "This paper studies the problem of safe control of sampled-data systems under bounded disturbance and measurement errors with piecewise-constant controllers. To achieve this, we first propose the High-Order Doubly Robust Control Barrier Function (HO-DRCBF) for continuous-time systems where the safety enforcing constraint is of relative degree 1 or higher. We then extend this formulation to sampled-data systems with piecewise-constant controllers by bounding the evolution of the system state over the sampling period given a state estimate at the beginning of the sampling period. We demonstrate the proposed approach on a kinematic obstacle avoidance problem for wheeled robots using a unicycle model. We verify that with the proposed approach, the system does not violate the safety constraints in the presence of bounded disturbance and measurement errors. ",
    "url": "https://arxiv.org/abs/2309.08050",
    "authors": [
      "Pradeep Sharma Oruganti",
      "Parinaz Naghizadeh",
      "Qadeer Ahmed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.08058",
    "title": "Unleashing the Adversarial Facet of Software Debloating",
    "abstract": "Software debloating techniques are applied to craft a specialized version of the program based on the user's requirements and remove irrelevant code accordingly. The debloated programs presumably maintain better performance and reduce the attack surface in contrast to the original programs. This work unleashes the effectiveness of applying software debloating techniques on the robustness of machine learning systems in the malware classification domain. We empirically study how an adversarial can leverage software debloating techniques to mislead machine learning malware classification models. We apply software debloating techniques to generate adversarial examples and demonstrate these adversarial examples can reduce the detection rate of VirusTotal. Our study opens new directions for research into adversarial machine learning not only in malware detection/classification but also in other software domains. ",
    "url": "https://arxiv.org/abs/2309.08058",
    "authors": [
      "Do-Men Su",
      "Mohannad Alhanahnah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.08072",
    "title": "SSL-Net: A Synergistic Spectral and Learning-based Network for Efficient  Bird Sound Classification",
    "abstract": "Efficient and accurate bird sound classification is of important for ecology, habitat protection and scientific research, as it plays a central role in monitoring the distribution and abundance of species. However, prevailing methods typically demand extensively labeled audio datasets and have highly customized frameworks, imposing substantial computational and annotation loads. In this study, we present an efficient and general framework called SSL-Net, which combines spectral and learned features to identify different bird sounds. Encouraging empirical results gleaned from a standard field-collected bird audio dataset validate the efficacy of our method in extracting features efficiently and achieving heightened performance in bird sound classification, even when working with limited sample sizes. Furthermore, we present three feature fusion strategies, aiding engineers and researchers in their selection through quantitative analysis. ",
    "url": "https://arxiv.org/abs/2309.08072",
    "authors": [
      "Yiyuan Yang",
      "Kaichen Zhou",
      "Niki Trigoni",
      "Andrew Markham"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08075",
    "title": "Social media polarization reflects shifting political alliances in  Pakistan",
    "abstract": "The rise of ideological divides in public discourse has received considerable attention in recent years. However, much of this research has been concentrated on Western democratic nations, leaving other regions largely unexplored. Here, we delve into the political landscape of Pakistan, a nation marked by intricate political dynamics and persistent turbulence. Spanning from 2018 to 2022, our analysis of Twitter data allows us to capture pivotal shifts and developments in Pakistan's political arena. By examining interactions and content generated by politicians affiliated with major political parties, we reveal a consistent and active presence of politicians on Twitter, with opposition parties exhibiting particularly robust engagement. We explore the alignment of party audiences, highlighting a notable convergence among opposition factions over time. Our analysis also uncovers significant shifts in political affiliations, including the transition of politicians to the opposition alliance. Quantitatively, we assess evolving interaction patterns, showcasing the prevalence of homophilic connections while identifying a growing interconnection among audiences of opposition parties. Our study, by accurately reflecting shifts in the political landscape, underscores the reliability of our methodology and social media data as a valuable tool for monitoring political polarization and providing a nuanced understanding of macro-level trends and individual-level transformations. ",
    "url": "https://arxiv.org/abs/2309.08075",
    "authors": [
      "Anees Baqir",
      "Alessandro Galeazzi",
      "Andrea Drocco",
      "Fabiana Zollo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.08077",
    "title": "Supervised Stochastic Neighbor Embedding Using Contrastive Learning",
    "abstract": "Stochastic neighbor embedding (SNE) methods $t$-SNE, UMAP are two most popular dimensionality reduction methods for data visualization. Contrastive learning, especially self-supervised contrastive learning (SSCL), has showed great success in embedding features from unlabeled data. The conceptual connection between SNE and SSCL has been exploited. In this work, within the scope of preserving neighboring information of a dataset, we extend the self-supervised contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of samples belonging to the same class are pulled together in low-dimensional embedding space, while simultaneously pushing apart clusters of samples from different classes. ",
    "url": "https://arxiv.org/abs/2309.08077",
    "authors": [
      "Yi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08097",
    "title": "Detail Reinforcement Diffusion Model: Augmentation Fine-Grained Visual  Categorization in Few-Shot Conditions",
    "abstract": "The challenge in fine-grained visual categorization lies in how to explore the subtle differences between different subclasses and achieve accurate discrimination. Previous research has relied on large-scale annotated data and pre-trained deep models to achieve the objective. However, when only a limited amount of samples is available, similar methods may become less effective. Diffusion models have been widely adopted in data augmentation due to their outstanding diversity in data generation. However, the high level of detail required for fine-grained images makes it challenging for existing methods to be directly employed. To address this issue, we propose a novel approach termed the detail reinforcement diffusion model~(DRDM), which leverages the rich knowledge of large models for fine-grained data augmentation and comprises two key components including discriminative semantic recombination (DSR) and spatial knowledge reference~(SKR). Specifically, DSR is designed to extract implicit similarity relationships from the labels and reconstruct the semantic mapping between labels and instances, which enables better discrimination of subtle differences between different subclasses. Furthermore, we introduce the SKR module, which incorporates the distributions of different datasets as references in the feature space. This allows the SKR to aggregate the high-dimensional distribution of subclass features in few-shot FGVC tasks, thus expanding the decision boundary. Through these two critical components, we effectively utilize the knowledge from large models to address the issue of data scarcity, resulting in improved performance for fine-grained visual recognition tasks. Extensive experiments demonstrate the consistent performance gain offered by our DRDM. ",
    "url": "https://arxiv.org/abs/2309.08097",
    "authors": [
      "Tianxu Wu",
      "Shuo Ye",
      "Shuhuang Chen",
      "Qinmu Peng",
      "Xinge You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08099",
    "title": "Characterizing the temporal dynamics of universal speech representations  for generalizable deepfake detection",
    "abstract": "Existing deepfake speech detection systems lack generalizability to unseen attacks (i.e., samples generated by generative algorithms not seen during training). Recent studies have explored the use of universal speech representations to tackle this issue and have obtained inspiring results. These works, however, have focused on innovating downstream classifiers while leaving the representation itself untouched. In this study, we argue that characterizing the long-term temporal dynamics of these representations is crucial for generalizability and propose a new method to assess representation dynamics. Indeed, we show that different generative models generate similar representation dynamics patterns with our proposed method. Experiments on the ASVspoof 2019 and 2021 datasets validate the benefits of the proposed method to detect deepfakes from methods unseen during training, significantly improving on several benchmark methods. ",
    "url": "https://arxiv.org/abs/2309.08099",
    "authors": [
      "Yi Zhu",
      "Saurabh Powar",
      "Tiago H. Falk"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08100",
    "title": "Research on Joint Representation Learning Methods for Entity  Neighborhood Information and Description Information",
    "abstract": "To address the issue of poor embedding performance in the knowledge graph of a programming design course, a joint represen-tation learning model that combines entity neighborhood infor-mation and description information is proposed. Firstly, a graph at-tention network is employed to obtain the features of entity neigh-boring nodes, incorporating relationship features to enrich the structural information. Next, the BERT-WWM model is utilized in conjunction with attention mechanisms to obtain the representation of entity description information. Finally, the final entity vector representation is obtained by combining the vector representations of entity neighborhood information and description information. Experimental results demonstrate that the proposed model achieves favorable performance on the knowledge graph dataset of the pro-gramming design course, outperforming other baseline models. ",
    "url": "https://arxiv.org/abs/2309.08100",
    "authors": [
      "Le Xiao",
      "Xin Shan",
      "Yuhua Wang",
      "Miaolei Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08106",
    "title": "Data-Driven Goal Recognition in Transhumeral Prostheses Using Process  Mining Techniques",
    "abstract": "A transhumeral prosthesis restores missing anatomical segments below the shoulder, including the hand. Active prostheses utilize real-valued, continuous sensor data to recognize patient target poses, or goals, and proactively move the artificial limb. Previous studies have examined how well the data collected in stationary poses, without considering the time steps, can help discriminate the goals. In this case study paper, we focus on using time series data from surface electromyography electrodes and kinematic sensors to sequentially recognize patients' goals. Our approach involves transforming the data into discrete events and training an existing process mining-based goal recognition system. Results from data collected in a virtual reality setting with ten subjects demonstrate the effectiveness of our proposed goal recognition approach, which achieves significantly better precision and recall than the state-of-the-art machine learning techniques and is less confident when wrong, which is beneficial when approximating smoother movements of prostheses. ",
    "url": "https://arxiv.org/abs/2309.08106",
    "authors": [
      "Zihang Su",
      "Tianshi Yu",
      "Nir Lipovetzky",
      "Alireza Mohammadi",
      "Denny Oetomo",
      "Artem Polyvyanyy",
      "Sebastian Sardina",
      "Ying Tan",
      "Nick van Beest"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08118",
    "title": "Graph IRs for Impure Higher-Order Languages (Technical Report)",
    "abstract": "This is a companion report for the OOPSLA 2023 paper of the same title, presenting a detailed end-to-end account of the $\\lambda^*_{\\mathsf{G}}$ graph IR, at a level of detail beyond a regular conference paper. Our first concern is adequacy and soundness of $\\lambda^*_{\\mathsf{G}}$, which we derive from a direct-style imperative functional language (a variant of Bao et al.'s $\\lambda^*$-calculus with reachability types and a simple effect system) by a series of type-preserving translations into a calculus in monadic normalform (MNF). Static reachability types and effects entirely inform $\\lambda^*_{\\mathsf{G}}$'s dependency synthesis. We argue for its adequacy by proving its functional properties along with dependency safety via progress and preservation lemmas with respect to a notion of call-by-value (CBV) reduction that checks the observed order of effects. Our second concern is establishing the correctness of $\\lambda^*_{\\mathsf{G}}$'s equational rules that drive compiler optimizations (e.g., DCE, $\\lambda$-hoisting, etc.), by proving contextual equivalence using logical relations. A key insight is that the functional properties of dependency synthesis permit a logical relation on $\\lambda^*_{\\mathsf{G}}$ in MNF in terms of previously developed logical relations for the direct-style $\\lambda^*$-calculus. Finally, we also include a longer version of the conference paper's section on code generation and code motion for $\\lambda^*_{\\mathsf{G}}$ as implemented in Scala~LMS. ",
    "url": "https://arxiv.org/abs/2309.08118",
    "authors": [
      "Oliver Bra\u010devac",
      "Guannan Wei",
      "Songlin Jia",
      "Supun Abeysinghe",
      "Yuxuan Jiang",
      "Yuyan Bao",
      "Tiark Rompf"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2309.08136",
    "title": "Let's Roll: Synthetic Dataset Analysis for Pedestrian Detection Across  Different Shutter Types",
    "abstract": "Computer vision (CV) pipelines are typically evaluated on datasets processed by image signal processing (ISP) pipelines even though, for resource-constrained applications, an important research goal is to avoid as many ISP steps as possible. In particular, most CV datasets consist of global shutter (GS) images even though most cameras today use a rolling shutter (RS). This paper studies the impact of different shutter mechanisms on machine learning (ML) object detection models on a synthetic dataset that we generate using the advanced simulation capabilities of Unreal Engine 5 (UE5). In particular, we train and evaluate mainstream detection models with our synthetically-generated paired GS and RS datasets to ascertain whether there exists a significant difference in detection accuracy between these two shutter modalities, especially when capturing low-speed objects (e.g., pedestrians). The results of this emulation framework indicate the performance between them are remarkably congruent for coarse-grained detection (mean average precision (mAP) for IOU=0.5), but have significant differences for fine-grained measures of detection accuracy (mAP for IOU=0.5:0.95). This implies that ML pipelines might not need explicit correction for RS for many object detection applications, but mitigating RS effects in ISP-less ML pipelines that target fine-grained location of the objects may need additional research. ",
    "url": "https://arxiv.org/abs/2309.08136",
    "authors": [
      "Yue Hu",
      "Gourav Datta",
      "Kira Beerel",
      "Peter Beerel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08152",
    "title": "DA-RAW: Domain Adaptive Object Detection for Real-World Adverse Weather  Conditions",
    "abstract": "Despite the success of deep learning-based object detection methods in recent years, it is still challenging to make the object detector reliable in adverse weather conditions such as rain and snow. For the robust performance of object detectors, unsupervised domain adaptation has been utilized to adapt the detection network trained on clear weather images to adverse weather images. While previous methods do not explicitly address weather corruption during adaptation, the domain gap between clear and adverse weather can be decomposed into two factors with distinct characteristics: a style gap and a weather gap. In this paper, we present an unsupervised domain adaptation framework for object detection that can more effectively adapt to real-world environments with adverse weather conditions by addressing these two gaps separately. Our method resolves the style gap by concentrating on style-related information of high-level features using an attention module. Using self-supervised contrastive learning, our framework then reduces the weather gap and acquires instance features that are robust to weather corruption. Extensive experiments demonstrate that our method outperforms other methods for object detection in adverse weather conditions. ",
    "url": "https://arxiv.org/abs/2309.08152",
    "authors": [
      "Minsik Jeon",
      "Junwon Seo",
      "Jihong Min"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08154",
    "title": "Uncertainty-Aware Multi-View Visual Semantic Embedding",
    "abstract": "The key challenge in image-text retrieval is effectively leveraging semantic information to measure the similarity between vision and language data. However, using instance-level binary labels, where each image is paired with a single text, fails to capture multiple correspondences between different semantic units, leading to uncertainty in multi-modal semantic understanding. Although recent research has captured fine-grained information through more complex model structures or pre-training techniques, few studies have directly modeled uncertainty of correspondence to fully exploit binary labels. To address this issue, we propose an Uncertainty-Aware Multi-View Visual Semantic Embedding (UAMVSE)} framework that decomposes the overall image-text matching into multiple view-text matchings. Our framework introduce an uncertainty-aware loss function (UALoss) to compute the weighting of each view-text loss by adaptively modeling the uncertainty in each view-text correspondence. Different weightings guide the model to focus on different semantic information, enhancing the model's ability to comprehend the correspondence of images and texts. We also design an optimized image-text matching strategy by normalizing the similarity matrix to improve model performance. Experimental results on the Flicker30k and MS-COCO datasets demonstrate that UAMVSE outperforms state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2309.08154",
    "authors": [
      "Wenzhang Wei",
      "Zhipeng Gui",
      "Changguang Wu",
      "Anqi Zhao",
      "Xingguang Wang",
      "Huayi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.08165",
    "title": "To Predict or to Reject: Causal Effect Estimation with Uncertainty on  Networked Data",
    "abstract": "Due to the imbalanced nature of networked observational data, the causal effect predictions for some individuals can severely violate the positivity/overlap assumption, rendering unreliable estimations. Nevertheless, this potential risk of individual-level treatment effect estimation on networked data has been largely under-explored. To create a more trustworthy causal effect estimator, we propose the uncertainty-aware graph deep kernel learning (GraphDKL) framework with Lipschitz constraint to model the prediction uncertainty with Gaussian process and identify unreliable estimations. To the best of our knowledge, GraphDKL is the first framework to tackle the violation of positivity assumption when performing causal effect estimation with graphs. With extensive experiments, we demonstrate the superiority of our proposed method in uncertainty-aware causal effect estimation on networked data. ",
    "url": "https://arxiv.org/abs/2309.08165",
    "authors": [
      "Hechuan Wen",
      "Tong Chen",
      "Li Kheng Chai",
      "Shazia Sadiq",
      "Kai Zheng",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.08166",
    "title": "Controllable Residual Speaker Representation for Voice Conversion",
    "abstract": "Recently, there have been significant advancements in voice conversion, resulting in high-quality performance. However, there are still two critical challenges in this field. Firstly, current voice conversion methods have limited robustness when encountering unseen speakers. Secondly, they also have limited ability to control timbre representation. To address these challenges, this paper presents a novel approach leverages tokens of multi-layer residual approximations to enhance robustness when dealing with unseen speakers, called the residual speaker module. The introduction of multi-layer approximations facilitates the separation of information from the timbre, enabling effective control over timbre in voice conversion. The proposed method outperforms baselines in both subjective and objective evaluations, demonstrating superior performance and increased robustness. Our demo page is publicly available. ",
    "url": "https://arxiv.org/abs/2309.08166",
    "authors": [
      "Le Xu",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Tao Wang",
      "Yong Ren",
      "Rongxiu Zhong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08171",
    "title": "Unveiling Invariances via Neural Network Pruning",
    "abstract": "Invariance describes transformations that do not alter data's underlying semantics. Neural networks that preserve natural invariance capture good inductive biases and achieve superior performance. Hence, modern networks are handcrafted to handle well-known invariances (ex. translations). We propose a framework to learn novel network architectures that capture data-dependent invariances via pruning. Our learned architectures consistently outperform dense neural networks on both vision and tabular datasets in both efficiency and effectiveness. We demonstrate our framework on multiple deep learning models across 3 vision and 40 tabular datasets. ",
    "url": "https://arxiv.org/abs/2309.08171",
    "authors": [
      "Derek Xu",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08177",
    "title": "Message Passing-Based Joint Channel Estimation and Signal Detection for  OTFS with Superimposed Pilots",
    "abstract": "Receivers with joint channel estimation and signal detection using superimposed pilots (SP) can achieve high transmission efficiency in orthogonal time frequency space (OTFS) systems. However, existing receivers have high computational complexity, hindering their practical applications. In this work, with SP in the delay-Doppler (DD) domain and the generalized complex exponential (GCE) basis expansion modeling (BEM) for channels, a message passing-based SP-DD iterative receiver is proposed, which drastically reduces the computational complexity while with marginal performance loss, compared to existing ones. To facilitate channel estimation (CE) in the proposed receiver, we design pilot signal to achieve pilot power concentration in the frequency domain, thereby developing an SP-DD-D receiver that can effectively reduce the power of the pilot signal and almost no loss of CE accuracy. Extensive simulation results are provided to demonstrate the superiority of the proposed SP-DD-D receiver. ",
    "url": "https://arxiv.org/abs/2309.08177",
    "authors": [
      "Fupeng Huang",
      "Qinghua Guo",
      "Youwen Zhang",
      "Yuriy Zakharov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.08179",
    "title": "STDG: Semi-Teacher-Student Training Paradigram for Depth-guided  One-stage Scene Graph Generation",
    "abstract": "Scene Graph Generation is a critical enabler of environmental comprehension for autonomous robotic systems. Most of existing methods, however, are often thwarted by the intricate dynamics of background complexity, which limits their ability to fully decode the inherent topological information of the environment. Additionally, the wealth of contextual information encapsulated within depth cues is often left untapped, rendering existing approaches less effective. To address these shortcomings, we present STDG, an avant-garde Depth-Guided One-Stage Scene Graph Generation methodology. The innovative architecture of STDG is a triad of custom-built modules: The Depth Guided HHA Representation Generation Module, the Depth Guided Semi-Teaching Network Learning Module, and the Depth Guided Scene Graph Generation Module. This trifecta of modules synergistically harnesses depth information, covering all aspects from depth signal generation and depth feature utilization, to the final scene graph prediction. Importantly, this is achieved without imposing additional computational burden during the inference phase. Experimental results confirm that our method significantly enhances the performance of one-stage scene graph generation baselines. ",
    "url": "https://arxiv.org/abs/2309.08179",
    "authors": [
      "Xukun Zhou",
      "Zhenbo Song",
      "Jun He",
      "Hongyan Liu",
      "Zhaoxin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08196",
    "title": "ECEA: Extensible Co-Existing Attention for Few-Shot Object Detection",
    "abstract": "Few-shot object detection (FSOD) identifies objects from extremely few annotated samples. Most existing FSOD methods, recently, apply the two-stage learning paradigm, which transfers the knowledge learned from abundant base classes to assist the few-shot detectors by learning the global features. However, such existing FSOD approaches seldom consider the localization of objects from local to global. Limited by the scarce training data in FSOD, the training samples of novel classes typically capture part of objects, resulting in such FSOD methods cannot detect the completely unseen object during testing. To tackle this problem, we propose an Extensible Co-Existing Attention (ECEA) module to enable the model to infer the global object according to the local parts. Essentially, the proposed module continuously learns the extensible ability on the base stage with abundant samples and transfers it to the novel stage, which can assist the few-shot model to quickly adapt in extending local regions to co-existing regions. Specifically, we first devise an extensible attention mechanism that starts with a local region and extends attention to co-existing regions that are similar and adjacent to the given local region. We then implement the extensible attention mechanism in different feature scales to progressively discover the full object in various receptive fields. Extensive experiments on the PASCAL VOC and COCO datasets show that our ECEA module can assist the few-shot detector to completely predict the object despite some regions failing to appear in the training samples and achieve the new state of the art compared with existing FSOD methods. ",
    "url": "https://arxiv.org/abs/2309.08196",
    "authors": [
      "Zhimeng Xin",
      "Tianxu Wu",
      "Shiming Chen",
      "Yixiong Zou",
      "Ling Shao",
      "Xinge You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08206",
    "title": "Salient Object Detection in Optical Remote Sensing Images Driven by  Transformer",
    "abstract": "Existing methods for Salient Object Detection in Optical Remote Sensing Images (ORSI-SOD) mainly adopt Convolutional Neural Networks (CNNs) as the backbone, such as VGG and ResNet. Since CNNs can only extract features within certain receptive fields, most ORSI-SOD methods generally follow the local-to-contextual paradigm. In this paper, we propose a novel Global Extraction Local Exploration Network (GeleNet) for ORSI-SOD following the global-to-local paradigm. Specifically, GeleNet first adopts a transformer backbone to generate four-level feature embeddings with global long-range dependencies. Then, GeleNet employs a Direction-aware Shuffle Weighted Spatial Attention Module (D-SWSAM) and its simplified version (SWSAM) to enhance local interactions, and a Knowledge Transfer Module (KTM) to further enhance cross-level contextual interactions. D-SWSAM comprehensively perceives the orientation information in the lowest-level features through directional convolutions to adapt to various orientations of salient objects in ORSIs, and effectively enhances the details of salient objects with an improved attention mechanism. SWSAM discards the direction-aware part of D-SWSAM to focus on localizing salient objects in the highest-level features. KTM models the contextual correlation knowledge of two middle-level features of different scales based on the self-attention mechanism, and transfers the knowledge to the raw features to generate more discriminative features. Finally, a saliency predictor is used to generate the saliency map based on the outputs of the above three modules. Extensive experiments on three public datasets demonstrate that the proposed GeleNet outperforms relevant state-of-the-art methods. The code and results of our method are available at https://github.com/MathLee/GeleNet. ",
    "url": "https://arxiv.org/abs/2309.08206",
    "authors": [
      "Gongyang Li",
      "Zhen Bai",
      "Zhi Liu",
      "Xinpeng Zhang",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08208",
    "title": "HM-Conformer: A Conformer-based audio deepfake detection system with  hierarchical pooling and multi-level classification token aggregation methods",
    "abstract": "Audio deepfake detection (ADD) is the task of detecting spoofing attacks generated by text-to-speech or voice conversion systems. Spoofing evidence, which helps to distinguish between spoofed and bona-fide utterances, might exist either locally or globally in the input features. To capture these, the Conformer, which consists of Transformers and CNN, possesses a suitable structure. However, since the Conformer was designed for sequence-to-sequence tasks, its direct application to ADD tasks may be sub-optimal. To tackle this limitation, we propose HM-Conformer by adopting two components: (1) Hierarchical pooling method progressively reducing the sequence length to eliminate duplicated information (2) Multi-level classification token aggregation method utilizing classification tokens to gather information from different blocks. Owing to these components, HM-Conformer can efficiently detect spoofing evidence by processing various sequence lengths and aggregating them. In experimental results on the ASVspoof 2021 Deepfake dataset, HM-Conformer achieved a 15.71% EER, showing competitive performance compared to recent systems. ",
    "url": "https://arxiv.org/abs/2309.08208",
    "authors": [
      "Hyun-seo Shin",
      "Jungwoo Heo",
      "Ju-ho Kim",
      "Chan-yeong Lim",
      "Wonbin Kim",
      "Ha-Jin Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08220",
    "title": "UniST: Towards Unifying Saliency Transformer for Video Saliency  Prediction and Detection",
    "abstract": "Video saliency prediction and detection are thriving research domains that enable computers to simulate the distribution of visual attention akin to how humans perceiving dynamic scenes. While many approaches have crafted task-specific training paradigms for either video saliency prediction or video salient object detection tasks, few attention has been devoted to devising a generalized saliency modeling framework that seamlessly bridges both these distinct tasks. In this study, we introduce the Unified Saliency Transformer (UniST) framework, which comprehensively utilizes the essential attributes of video saliency prediction and video salient object detection. In addition to extracting representations of frame sequences, a saliency-aware transformer is designed to learn the spatio-temporal representations at progressively increased resolutions, while incorporating effective cross-scale saliency information to produce a robust representation. Furthermore, a task-specific decoder is proposed to perform the final prediction for each task. To the best of our knowledge, this is the first work that explores designing a transformer structure for both saliency modeling tasks. Convincible experiments demonstrate that the proposed UniST achieves superior performance across seven challenging benchmarks for two tasks, and significantly outperforms the other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2309.08220",
    "authors": [
      "Junwen Xiong",
      "Peng Zhang",
      "Chuanyue Li",
      "Wei Huang",
      "Yufei Zha",
      "Tao You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08221",
    "title": "Exploring the Potential of ChatGPT in Automated Code Refinement: An  Empirical Study",
    "abstract": "Code review is an essential activity for ensuring the quality and maintainability of software projects. However, it is a time-consuming and often error-prone task that can significantly impact the development process. Recently, ChatGPT, a cutting-edge language model, has demonstrated impressive performance in various natural language processing tasks, suggesting its potential to automate code review processes. However, it is still unclear how well ChatGPT performs in code review tasks. To fill this gap, in this paper, we conduct the first empirical study to understand the capabilities of ChatGPT in code review tasks, specifically focusing on automated code refinement based on given code reviews. To conduct the study, we select the existing benchmark CodeReview and construct a new code review dataset with high quality. We use CodeReviewer, a state-of-the-art code review tool, as a baseline for comparison with ChatGPT. Our results show that ChatGPT outperforms CodeReviewer in code refinement tasks. Specifically, our results show that ChatGPT achieves higher EM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art method achieves only 15.50 and 62.88 on a high-quality code review dataset. We further identify the root causes for ChatGPT's underperformance and propose several strategies to mitigate these challenges. Our study provides insights into the potential of ChatGPT in automating the code review process, and highlights the potential research directions. ",
    "url": "https://arxiv.org/abs/2309.08221",
    "authors": [
      "Qi Guo",
      "Junming Cao",
      "Xiaofei Xie",
      "Shangqing Liu",
      "Xiaohong Li",
      "Bihuan Chen",
      "Xin Peng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.08225",
    "title": "Silent Vulnerability-fixing Commit Identification Based on Graph Neural  Networks",
    "abstract": "The growing dependence of software projects on external libraries has generated apprehensions regarding the security of these libraries because of concealed vulnerabilities. Handling these vulnerabilities presents difficulties due to the temporal delay between remediation and public exposure. Furthermore, a substantial fraction of open-source projects covertly address vulnerabilities without any formal notification, influencing vulnerability management. Established solutions like OWASP predominantly hinge on public announcements, limiting their efficacy in uncovering undisclosed vulnerabilities. To address this challenge, the automated identification of vulnerability-fixing commits has come to the forefront. In this paper, we present VFFINDER, a novel graph-based approach for automated silent vulnerability fix identification. VFFINDER captures structural changes using Abstract Syntax Trees (ASTs) and represents them in annotated ASTs. To precisely capture the meaning of code changes, the changed code is represented in connection with the related unchanged code. In VFFINDER, the structure of the changed code and related unchanged code are captured and the structural changes are represented in annotated Abstract Syntax Trees (aAST). VFFINDER distinguishes vulnerability-fixing commits from non-fixing ones using attention-based graph neural network models to extract structural features expressed in aASTs. We conducted experiments to evaluate VFFINDER on a dataset of 11K+ vulnerability fixing commits in 507 real-world C/C++ projects. Our results show that VFFINDER significantly improves the state-of-the-art methods by 272-420% in Precision, 22-70% in Recall, and 3.2X-8.2X in F1. Especially, VFFINDER speeds up the silent fix identification process by up to 121% with the same effort reviewing 50K LOC compared to the existing approaches. ",
    "url": "https://arxiv.org/abs/2309.08225",
    "authors": [
      "Hieu Dinh Vo",
      "Thanh Trong Vu",
      "Son Nguyen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.08232",
    "title": "Astrocyte-Integrated Dynamic Function Exchange in Spiking Neural  Networks",
    "abstract": "This paper presents an innovative methodology for improving the robustness and computational efficiency of Spiking Neural Networks (SNNs), a critical component in neuromorphic computing. The proposed approach integrates astrocytes, a type of glial cell prevalent in the human brain, into SNNs, creating astrocyte-augmented networks. To achieve this, we designed and implemented an astrocyte model in two distinct platforms: CPU/GPU and FPGA. Our FPGA implementation notably utilizes Dynamic Function Exchange (DFX) technology, enabling real-time hardware reconfiguration and adaptive model creation based on current operating conditions. The novel approach of leveraging astrocytes significantly improves the fault tolerance of SNNs, thereby enhancing their robustness. Notably, our astrocyte-augmented SNN displays near-zero latency and theoretically infinite throughput, implying exceptional computational efficiency. Through comprehensive comparative analysis with prior works, it's established that our model surpasses others in terms of neuron and synapse count while maintaining an efficient power consumption profile. These results underscore the potential of our methodology in shaping the future of neuromorphic computing, by providing robust and energy-efficient systems. ",
    "url": "https://arxiv.org/abs/2309.08232",
    "authors": [
      "Murat Isik",
      "Kayode Inadagbo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.08253",
    "title": "Distributed Behavior Trees for Heterogeneous Robot Teams",
    "abstract": "Heterogeneous Robot Teams can provide a wide range of capabilities and therefore significant benefits when handling a mission. However, they also require new approaches to capability and mission definition that are not only suitable to handle heterogeneous capabilities but furthermore allow a combination or distribution of them with a coherent representation that is not limiting the individual robot. Behavior Trees offer many of the required properties, are growing in popularity for robot control and have been proposed for multirobot coordination, but always as separate behavior tree, defined in advance and without consideration for a changing team. In this paper, we propose a new behavior tree approach that is capable to handle complex real world robotic missions and is geared towards a distributed execution by providing built in functionalities for cost calculation, subtree distribution and data wiring. We present a formal definition, its open source implementation as ros_bt_py library and experimental verification of its capabilities. ",
    "url": "https://arxiv.org/abs/2309.08253",
    "authors": [
      "Georg Heppner",
      "Nils Berg",
      "David Oberacker",
      "Niklas Spielbauer",
      "Arne Roennau",
      "R\u00fcdiger Dillmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08264",
    "title": "Leveraging the Power of Data Augmentation for Transformer-based Tracking",
    "abstract": "Due to long-distance correlation and powerful pretrained models, transformer-based methods have initiated a breakthrough in visual object tracking performance. Previous works focus on designing effective architectures suited for tracking, but ignore that data augmentation is equally crucial for training a well-performing model. In this paper, we first explore the impact of general data augmentations on transformer-based trackers via systematic experiments, and reveal the limited effectiveness of these common strategies. Motivated by experimental observations, we then propose two data augmentation methods customized for tracking. First, we optimize existing random cropping via a dynamic search radius mechanism and simulation for boundary samples. Second, we propose a token-level feature mixing augmentation strategy, which enables the model against challenges like background interference. Extensive experiments on two transformer-based trackers and six benchmarks demonstrate the effectiveness and data efficiency of our methods, especially under challenging settings, like one-shot tracking and small image resolutions. ",
    "url": "https://arxiv.org/abs/2309.08264",
    "authors": [
      "Jie Zhao",
      "Johan Edstedt",
      "Michael Felsberg",
      "Dong Wang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08265",
    "title": "Edge Based Oriented Object Detection",
    "abstract": "In the field of remote sensing, we often utilize oriented bounding boxes (OBB) to bound the objects. This approach significantly reduces the overlap among dense detection boxes and minimizes the inclusion of background content within the bounding boxes. To enhance the detection accuracy of oriented objects, we propose a unique loss function based on edge gradients, inspired by the similarity measurement function used in template matching task. During this process, we address the issues of non-differentiability of the function and the semantic alignment between gradient vectors in ground truth (GT) boxes and predicted boxes (PB). Experimental results show that our proposed loss function achieves $0.6\\%$ mAP improvement compared to the commonly used Smooth L1 loss in the baseline algorithm. Additionally, we design an edge-based self-attention module to encourage the detection network to focus more on the object edges. Leveraging these two innovations, we achieve a mAP increase of 1.3% on the DOTA dataset. ",
    "url": "https://arxiv.org/abs/2309.08265",
    "authors": [
      "Jianghu Shen",
      "Xiaojun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08271",
    "title": "Greedy Optimization of Resistance-based Graph Robustness with Global and  Local Edge Insertions",
    "abstract": "The total effective resistance, also called the Kirchhoff index, provides a robustness measure for a graph $G$. We consider two optimization problems of adding $k$ new edges to $G$ such that the resulting graph has minimal total effective resistance (i.e., is most robust) -- one where the new edges can be anywhere in the graph and one where the new edges need to be incident to a specified focus node. The total effective resistance and effective resistances between nodes can be computed using the pseudoinverse of the graph Laplacian. The pseudoinverse may be computed explicitly via pseudoinversion; yet, this takes cubic time in practice and quadratic space. We instead exploit combinatorial and algebraic connections to speed up gain computations in an established generic greedy heuristic. Moreover, we leverage existing randomized techniques to boost the performance of our approaches by introducing a sub-sampling step. Our different graph- and matrix-based approaches are indeed significantly faster than the state-of-the-art greedy algorithm, while their quality remains reasonably high and is often quite close. Our experiments show that we can now process larger graphs for which the application of the state-of-the-art greedy approach was impractical before. ",
    "url": "https://arxiv.org/abs/2309.08271",
    "authors": [
      "Maria Predari",
      "Lukas Berner",
      "Robert Kooij",
      "Henning Meyerhenke"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.08272",
    "title": "Structural Self-Supervised Objectives for Transformers",
    "abstract": "This thesis focuses on improving the pre-training of natural language models using unsupervised raw data to make them more efficient and aligned with downstream applications. In the first part, we introduce three alternative pre-training objectives to BERT's Masked Language Modeling (MLM), namely Random Token Substitution (RTS), Cluster-based Random Token Substitution (C-RTS), and Swapped Language Modeling (SLM). These objectives involve token swapping instead of masking, with RTS and C-RTS aiming to predict token originality and SLM predicting the original token values. Results show that RTS and C-RTS require less pre-training time while maintaining performance comparable to MLM. Surprisingly, SLM outperforms MLM on certain tasks despite using the same computational budget. In the second part, we proposes self-supervised pre-training tasks that align structurally with downstream applications, reducing the need for labeled data. We use large corpora like Wikipedia and CC-News to train models to recognize if text spans originate from the same paragraph or document in several ways. By doing continuous pre-training, starting from existing models like RoBERTa, ELECTRA, DeBERTa, BART, and T5, we demonstrate significant performance improvements in tasks like Fact Verification, Answer Sentence Selection, and Summarization. These improvements are especially pronounced when limited annotation data is available. The proposed objectives also achieve state-of-the-art results on various benchmark datasets, including FEVER (dev set), ASNQ, WikiQA, and TREC-QA, as well as enhancing the quality of summaries. Importantly, these techniques can be easily integrated with other methods without altering the internal structure of Transformer models, making them versatile for various NLP applications. ",
    "url": "https://arxiv.org/abs/2309.08272",
    "authors": [
      "Luca Di Liello"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.08275",
    "title": "User Power Measurement Based IRS Channel Estimation via Single-Layer  Neural Network",
    "abstract": "One main challenge for implementing intelligent reflecting surface (IRS) aided communications lies in the difficulty to obtain the channel knowledge for the base station (BS)-IRS-user cascaded links, which is needed to design high-performance IRS reflection in practice. Traditional methods for estimating IRS cascaded channels are usually based on the additional pilot signals received at the BS/users, which increase the system training overhead and also may not be compatible with the current communication protocols. To tackle this challenge, we propose in this paper a new single-layer neural network (NN)-enabled IRS channel estimation method based on only the knowledge of users' individual received signal power measurements corresponding to different IRS random training reflections, which are easily accessible in current wireless systems. To evaluate the effectiveness of the proposed channel estimation method, we design the IRS reflection for data transmission based on the estimated cascaded channels in an IRS-aided multiuser communication system. Numerical results show that the proposed IRS channel estimation and reflection design can significantly improve the minimum received signal-to-noise ratio (SNR) among all users, as compared to existing power measurement based designs. ",
    "url": "https://arxiv.org/abs/2309.08275",
    "authors": [
      "He Sun",
      "Weidong Mei",
      "Lipeng Zhu",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.08297",
    "title": "Optimal Mobility and Communication Strategy to Maximize the Value of  Information in IoT Networks",
    "abstract": "The Internet of Things (IoT) is an emerging next-generation technology in the fourth industrial revolution. In industrial IoT networks, sensing devices are largely deployed to monitor various types of physical processes. They are required to transmit the collected data in a timely manner to support real-time monitoring, control and automation. The timeliness of information is very important in such systems. Recently, an information-theoretic metric named the \"value of information\" (VoI) has been proposed to measure the usefulness of information. In this work, we consider an industrial IoT network with a set of heterogeneous sensing devices and an intelligent mobile entity. The concept of the value of information is applied to study a joint path planning and user scheduling optimisation problem. We aim to maximise the network-level VoI under mobility and communication constraints. We formulate this problem as a Markov decision process (MDP), and an efficient algorithm based on reinforcement learning is proposed to solve this problem. Through numerical results, we show that the proposed method is able to capture the usefulness of data from both time and space dimensions. By exploiting the correlation property of the data source, the proposed method is suitable for applications in resource-limited networks. ",
    "url": "https://arxiv.org/abs/2309.08297",
    "authors": [
      "Zijing Wang",
      "Mihai-Alin Badiu",
      "Justin P. Coon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.08304",
    "title": "Lattice attack on group ring NTRU: The case of the dihedral group",
    "abstract": "Group ring NTRU (GR-NTRU) provides a general structure to design different variants of NTRU-like schemes by employing different groups. Although, most of the schemes in literature are built over cyclic groups, nonabelian groups can also be used. Coppersmith and Shamir in 1997 have suggested that noncommutativity may result in better security against some lattice attacks for some groups. Lattice attacks on the public key of NTRU-like cryptosystems try to retrieve the private key by solving the shortest vector problem (SVP) or its approximation in a lattice of a certain dimension, assuming the knowledge of the public key only. This paper shows that dihedral groups do not guarantee better security against this class of attacks. We prove that retrieving the private key is possible by solving the SVP in two lattices with half the dimension of the original lattice generated for GR-NTRU based on dihedral groups. The possibility of such an attack was mentioned by Yasuda et al.(IACR/2015/1170). In contrast to their proposed approach, we explicitly provide the lattice reduction without any structure theorem from the representation theory for finite groups. Furthermore, we demonstrate the effectiveness of our technique with experimental results. ",
    "url": "https://arxiv.org/abs/2309.08304",
    "authors": [
      "Vikas Kumar",
      "Ali Raya",
      "Sugata Gangopadhyay",
      "Aditi Kar Gangopadhyay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.08365",
    "title": "M$^3$Net: Multilevel, Mixed and Multistage Attention Network for Salient  Object Detection",
    "abstract": "Most existing salient object detection methods mostly use U-Net or feature pyramid structure, which simply aggregates feature maps of different scales, ignoring the uniqueness and interdependence of them and their respective contributions to the final prediction. To overcome these, we propose the M$^3$Net, i.e., the Multilevel, Mixed and Multistage attention network for Salient Object Detection (SOD). Firstly, we propose Multiscale Interaction Block which innovatively introduces the cross-attention approach to achieve the interaction between multilevel features, allowing high-level features to guide low-level feature learning and thus enhancing salient regions. Secondly, considering the fact that previous Transformer based SOD methods locate salient regions only using global self-attention while inevitably overlooking the details of complex objects, we propose the Mixed Attention Block. This block combines global self-attention and window self-attention, aiming at modeling context at both global and local levels to further improve the accuracy of the prediction map. Finally, we proposed a multilevel supervision strategy to optimize the aggregated feature stage-by-stage. Experiments on six challenging datasets demonstrate that the proposed M$^3$Net surpasses recent CNN and Transformer-based SOD arts in terms of four metrics. Codes are available at https://github.com/I2-Multimedia-Lab/M3Net. ",
    "url": "https://arxiv.org/abs/2309.08365",
    "authors": [
      "Yao Yuan",
      "Pan Gao",
      "XiaoYang Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08368",
    "title": "Robust Burned Area Delineation through Multitask Learning",
    "abstract": "In recent years, wildfires have posed a significant challenge due to their increasing frequency and severity. For this reason, accurate delineation of burned areas is crucial for environmental monitoring and post-fire assessment. However, traditional approaches relying on binary segmentation models often struggle to achieve robust and accurate results, especially when trained from scratch, due to limited resources and the inherent imbalance of this segmentation task. We propose to address these limitations in two ways: first, we construct an ad-hoc dataset to cope with the limited resources, combining information from Sentinel-2 feeds with Copernicus activations and other data sources. In this dataset, we provide annotations for multiple tasks, including burned area delineation and land cover segmentation. Second, we propose a multitask learning framework that incorporates land cover classification as an auxiliary task to enhance the robustness and performance of the burned area segmentation models. We compare the performance of different models, including UPerNet and SegFormer, demonstrating the effectiveness of our approach in comparison to standard binary segmentation. ",
    "url": "https://arxiv.org/abs/2309.08368",
    "authors": [
      "Edoardo Arnaudo",
      "Luca Barco",
      "Matteo Merlo",
      "Claudio Rossi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08369",
    "title": "An Efficient Wide-Range Pseudo-3D Vehicle Detection Using A Single  Camera",
    "abstract": "Wide-range and fine-grained vehicle detection plays a critical role in enabling active safety features in intelligent driving systems. However, existing vehicle detection methods based on rectangular bounding boxes (BBox) often struggle with perceiving wide-range objects, especially small objects at long distances. And BBox expression cannot provide detailed geometric shape and pose information of vehicles. This paper proposes a novel wide-range Pseudo-3D Vehicle Detection method based on images from a single camera and incorporates efficient learning methods. This model takes a spliced image as input, which is obtained by combining two sub-window images from a high-resolution image. This image format maximizes the utilization of limited image resolution to retain essential information about wide-range vehicle objects. To detect pseudo-3D objects, our model adopts specifically designed detection heads. These heads simultaneously output extended BBox and Side Projection Line (SPL) representations, which capture vehicle shapes and poses, enabling high-precision detection. To further enhance the performance of detection, a joint constraint loss combining both the object box and SPL is designed during model training, improving the efficiency, stability, and prediction accuracy of the model. Experimental results on our self-built dataset demonstrate that our model achieves favorable performance in wide-range pseudo-3D vehicle detection across multiple evaluation metrics. Our demo video has been placed at https://www.youtube.com/watch?v=1gk1PmsQ5Q8. ",
    "url": "https://arxiv.org/abs/2309.08369",
    "authors": [
      "Zhupeng Ye",
      "Yinqi Li",
      "Zejian Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08374",
    "title": "Understanding the limitations of self-supervised learning for tabular  anomaly detection",
    "abstract": "While self-supervised learning has improved anomaly detection in computer vision and natural language processing, it is unclear whether tabular data can benefit from it. This paper explores the limitations of self-supervision for tabular anomaly detection. We conduct several experiments spanning various pretext tasks on 26 benchmark datasets to understand why this is the case. Our results confirm representations derived from self-supervision do not improve tabular anomaly detection performance compared to using the raw representations of the data. We show this is due to neural networks introducing irrelevant features, which reduces the effectiveness of anomaly detectors. However, we demonstrate that using a subspace of the neural network's representation can recover performance. ",
    "url": "https://arxiv.org/abs/2309.08374",
    "authors": [
      "Kimberly T. Mai",
      "Toby Davies",
      "Lewis D. Griffin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08385",
    "title": "A Unified View Between Tensor Hypergraph Neural Networks And Signal  Denoising",
    "abstract": "Hypergraph Neural networks (HyperGNNs) and hypergraph signal denoising (HyperGSD) are two fundamental topics in higher-order network modeling. Understanding the connection between these two domains is particularly useful for designing novel HyperGNNs from a HyperGSD perspective, and vice versa. In particular, the tensor-hypergraph convolutional network (T-HGCN) has emerged as a powerful architecture for preserving higher-order interactions on hypergraphs, and this work shows an equivalence relation between a HyperGSD problem and the T-HGCN. Inspired by this intriguing result, we further design a tensor-hypergraph iterative network (T-HGIN) based on the HyperGSD problem, which takes advantage of a multi-step updating scheme in every single layer. Numerical experiments are conducted to show the promising applications of the proposed T-HGIN approach. ",
    "url": "https://arxiv.org/abs/2309.08385",
    "authors": [
      "Fuli Wang",
      "Karelia Pena-Pena",
      "Wei Qian",
      "Gonzalo R. Arce"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.08387",
    "title": "Efficient Graphics Representation with Differentiable Indirection",
    "abstract": "We introduce differentiable indirection -- a novel learned primitive that employs differentiable multi-scale lookup tables as an effective substitute for traditional compute and data operations across the graphics pipeline. We demonstrate its flexibility on a number of graphics tasks, i.e., geometric and image representation, texture mapping, shading, and radiance field representation. In all cases, differentiable indirection seamlessly integrates into existing architectures, trains rapidly, and yields both versatile and efficient results. ",
    "url": "https://arxiv.org/abs/2309.08387",
    "authors": [
      "Sayantan Datta",
      "Carl Marshall",
      "Zhao Dong",
      "Zhengqin Li",
      "Derek Nowrouzezahrai"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08396",
    "title": "Resource Optimization Using A Step-by-step Scheme in Wireless Sensing  and Localization Networks",
    "abstract": "Due to the lack of wireless spectrum resources, people are focusing on the versatile wireless networks. Wireless localization and target sensing both rely on precise extraction of parameters such as signal amplitude, propagation delay and Doppler shift from the received signals. Due to the high multi-path resolution and strong penetration of UWB signals, both localization and sensing can be achieved through the same UWB waveform. Practical networks are often resource-constrained, in order to improve the accuracy of integrated networks, we need to optimize the allocation of resources in the networks. Considering the complexity of the multi-slot networks, this paper derives the Fisher Information Matrix (FIM) expressions for single-slot and dual-slot integrated sensing and localization (ISAL) networks respectively, and proposes two resource optimization schemes, namely step-by-step scheme and integrated scheme. The numerical results show that: (i) for the sensing-resource-deficient networks with relatively uniform node distribution, the energy allocated to each step in the step-by-step scheme satisfies the relationship: energy for clock offset < energy for radar localization < energy for target sensing. (ii) In the multi-slot ISAL networks, the system will allocate more energy to the time slots where the networks are relatively sensing-resource-deficient. (iii) The step-by-step scheme is more suitable for the sensing-resource-abundant networks, while the integrated scheme is more suitable for the sensing-resource-deficient networks. ",
    "url": "https://arxiv.org/abs/2309.08396",
    "authors": [
      "Ruihang Zhang",
      "Jiayan Yang",
      "Mu Jia",
      "Tingting Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.08414",
    "title": "Make Deep Networks Shallow Again",
    "abstract": "Deep neural networks have a good success record and are thus viewed as the best architecture choice for complex applications. Their main shortcoming has been, for a long time, the vanishing gradient which prevented the numerical optimization algorithms from acceptable convergence. A breakthrough has been achieved by the concept of residual connections -- an identity mapping parallel to a conventional layer. This concept is applicable to stacks of layers of the same dimension and substantially alleviates the vanishing gradient problem. A stack of residual connection layers can be expressed as an expansion of terms similar to the Taylor expansion. This expansion suggests the possibility of truncating the higher-order terms and receiving an architecture consisting of a single broad layer composed of all initially stacked layers in parallel. In other words, a sequential deep architecture is substituted by a parallel shallow one. Prompted by this theory, we investigated the performance capabilities of the parallel architecture in comparison to the sequential one. The computer vision datasets MNIST and CIFAR10 were used to train both architectures for a total of 6912 combinations of varying numbers of convolutional layers, numbers of filters, kernel sizes, and other meta parameters. Our findings demonstrate a surprising equivalence between the deep (sequential) and shallow (parallel) architectures. Both layouts produced similar results in terms of training and validation set loss. This discovery implies that a wide, shallow architecture can potentially replace a deep network without sacrificing performance. Such substitution has the potential to simplify network architectures, improve optimization efficiency, and accelerate the training process. ",
    "url": "https://arxiv.org/abs/2309.08414",
    "authors": [
      "Bernhard Bermeitinger",
      "Tomas Hrycej",
      "Siegfried Handschuh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08416",
    "title": "Deformable Neural Radiance Fields using RGB and Event Cameras",
    "abstract": "Modeling Neural Radiance Fields for fast-moving deformable objects from visual data alone is a challenging problem. A major issue arises due to the high deformation and low acquisition rates. To address this problem, we propose to use event cameras that offer very fast acquisition of visual change in an asynchronous manner. In this work, we develop a novel method to model the deformable neural radiance fields using RGB and event cameras. The proposed method uses the asynchronous stream of events and calibrated sparse RGB frames. In our setup, the camera pose at the individual events required to integrate them into the radiance fields remains unknown. Our method jointly optimizes these poses and the radiance field. This happens efficiently by leveraging the collection of events at once and actively sampling the events during learning. Experiments conducted on both realistically rendered graphics and real-world datasets demonstrate a significant benefit of the proposed method over the state-of-the-art and the compared baseline. This shows a promising direction for modeling deformable neural radiance fields in real-world dynamic scenes. ",
    "url": "https://arxiv.org/abs/2309.08416",
    "authors": [
      "Qi Ma",
      "Danda Pani Paudel",
      "Ajad Chhatkuli",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08420",
    "title": "FedDCSR: Federated Cross-domain Sequential Recommendation via  Disentangled Representation Learning",
    "abstract": "Cross-domain Sequential Recommendation (CSR) which leverages user sequence data from multiple domains has received extensive attention in recent years. However, the existing CSR methods require sharing origin user data across domains, which violates the General Data Protection Regulation (GDPR). Thus, it is necessary to combine federated learning (FL) and CSR to fully utilize knowledge from different domains while preserving data privacy. Nonetheless, the sequence feature heterogeneity across different domains significantly impacts the overall performance of FL. In this paper, we propose FedDCSR, a novel federated cross-domain sequential recommendation framework via disentangled representation learning. Specifically, to address the sequence feature heterogeneity across domains, we introduce an approach called inter-intra domain sequence representation disentanglement (SRD) to disentangle the user sequence features into domain-shared and domain-exclusive features. In addition, we design an intra domain contrastive infomax (CIM) strategy to learn richer domain-exclusive features of users by performing data augmentation on user sequences. Extensive experiments on three real-world scenarios demonstrate that FedDCSR achieves significant improvements over existing baselines. ",
    "url": "https://arxiv.org/abs/2309.08420",
    "authors": [
      "Hongyu Zhang",
      "Dongyi Zheng",
      "Xu Yang",
      "Jiyuan Feng",
      "Qing Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.08428",
    "title": "Virtual Harassment, Real Understanding: Using a Serious Game and  Bayesian Networks to Study Cyberbullying",
    "abstract": "Cyberbullying among minors is a pressing concern in our digital society, necessitating effective prevention and intervention strategies. Traditional data collection methods often intrude on privacy and yield limited insights. This study explores an innovative approach, employing a serious game - designed with purposes beyond entertainment - as a non-intrusive tool for data collection and education. In contrast to traditional correlation-based analyses, we propose a causality-based approach using Bayesian Networks to unravel complex relationships in the collected data and quantify result uncertainties. This robust analytical tool yields interpretable outcomes, enhances transparency in assumptions, and fosters open scientific discourse. Preliminary pilot studies with the serious game show promising results, surpassing the informative capacity of traditional demographic and psychological questionnaires, suggesting its potential as an alternative methodology. Additionally, we demonstrate how our approach facilitates the examination of risk profiles and the identification of intervention strategies to mitigate this cybercrime. We also address research limitations and potential enhancements, considering the noise and variability of data in social studies and video games. This research advances our understanding of cyberbullying and showcase the potential of serious games and causality-based approaches in studying complex social issues. ",
    "url": "https://arxiv.org/abs/2309.08428",
    "authors": [
      "Jaime P\u00e9rez",
      "Mario Castro",
      "Edmond Awad",
      "Gregorio L\u00f3pez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.08444",
    "title": "Neural Network Exemplar Parallelization with Go",
    "abstract": "This paper presents a case for exemplar parallelism of neural networks using Go as parallelization framework. Further it is shown that also limited multi-core hardware systems are feasible for these parallelization tasks, as notebooks and single board computer systems. The main question was how much speedup can be generated when using concurrent Go goroutines specifically. A simple concurrent feedforward network for MNIST digit recognition with the programming language Go was created to find the answer. The first findings when using a notebook (Lenovo Yoga 2) showed a speedup of 252% when utilizing 4 goroutines. Testing a single board computer (Banana Pi M3) delivered more convincing results: 320% with 4 goroutines, and 432% with 8 goroutines. ",
    "url": "https://arxiv.org/abs/2309.08444",
    "authors": [
      "Georg Wiesinger",
      "Erich Schikuta"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.08452",
    "title": "MBAPPE: MCTS-Built-Around Prediction for Planning Explicitly",
    "abstract": "We present MBAPPE, a novel approach to motion planning for autonomous driving combining tree search with a partially-learned model of the environment. Leveraging the inherent explainable exploration and optimization capabilities of the Monte-Carlo Search Tree (MCTS), our method addresses complex decision-making in a dynamic environment. We propose a framework that combines MCTS with supervised learning, enabling the autonomous vehicle to effectively navigate through diverse scenarios. Experimental results demonstrate the effectiveness and adaptability of our approach, showcasing improved real-time decision-making and collision avoidance. This paper contributes to the field by providing a robust solution for motion planning in autonomous driving systems, enhancing their explainability and reliability. ",
    "url": "https://arxiv.org/abs/2309.08452",
    "authors": [
      "Raphael Chekroun",
      "Thomas Gilles",
      "Marin Toromanoff",
      "Sascha Hornauer",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08469",
    "title": "SilverRetriever: Advancing Neural Passage Retrieval for Polish Question  Answering",
    "abstract": "Modern open-domain question answering systems often rely on accurate and efficient retrieval components to find passages containing the facts necessary to answer the question. Recently, neural retrievers have gained popularity over lexical alternatives due to their superior performance. However, most of the work concerns popular languages such as English or Chinese. For others, such as Polish, few models are available. In this work, we present SilverRetriever, a neural retriever for Polish trained on a diverse collection of manually or weakly labeled datasets. SilverRetriever achieves much better results than other Polish models and is competitive with larger multilingual models. Together with the model, we open-source five new passage retrieval datasets. ",
    "url": "https://arxiv.org/abs/2309.08469",
    "authors": [
      "Piotr Rybak",
      "Maciej Ogrodniczuk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.08474",
    "title": "VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts  by Multimodal Learning with Graph Neural Network and Language Model",
    "abstract": "This paper presents VulnSense framework, a comprehensive approach to efficiently detect vulnerabilities in Ethereum smart contracts using a multimodal learning approach on graph-based and natural language processing (NLP) models. Our proposed framework combines three types of features from smart contracts comprising source code, opcode sequences, and control flow graph (CFG) extracted from bytecode. We employ Bidirectional Encoder Representations from Transformers (BERT), Bidirectional Long Short-Term Memory (BiLSTM) and Graph Neural Network (GNN) models to extract and analyze these features. The final layer of our multimodal approach consists of a fully connected layer used to predict vulnerabilities in Ethereum smart contracts. Addressing limitations of existing vulnerability detection methods relying on single-feature or single-model deep learning techniques, our method surpasses accuracy and effectiveness constraints. We assess VulnSense using a collection of 1.769 smart contracts derived from the combination of three datasets: Curated, SolidiFI-Benchmark, and Smartbugs Wild. We then make a comparison with various unimodal and multimodal learning techniques contributed by GNN, BiLSTM and BERT architectures. The experimental outcomes demonstrate the superior performance of our proposed approach, achieving an average accuracy of 77.96\\% across all three categories of vulnerable smart contracts. ",
    "url": "https://arxiv.org/abs/2309.08474",
    "authors": [
      "Phan The Duy",
      "Nghi Hoang Khoa",
      "Nguyen Huu Quyen",
      "Le Cong Trinh",
      "Vu Trung Kien",
      "Trinh Minh Hoang",
      "Van-Hau Pham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08476",
    "title": "A Spiking Binary Neuron -- Detector of Causal Links",
    "abstract": "Causal relationship recognition is a fundamental operation in neural networks aimed at learning behavior, action planning, and inferring external world dynamics. This operation is particularly crucial for reinforcement learning (RL). In the context of spiking neural networks (SNNs), events are represented as spikes emitted by network neurons or input nodes. Detecting causal relationships within these events is essential for effective RL implementation. This research paper presents a novel approach to realize causal relationship recognition using a simple spiking binary neuron. The proposed method leverages specially designed synaptic plasticity rules, which are both straightforward and efficient. Notably, our approach accounts for the temporal aspects of detected causal links and accommodates the representation of spiking signals as single spikes or tight spike sequences (bursts), as observed in biological brains. Furthermore, this study places a strong emphasis on the hardware-friendliness of the proposed models, ensuring their efficient implementation on modern and future neuroprocessors. Being compared with precise machine learning techniques, such as decision tree algorithms and convolutional neural networks, our neuron demonstrates satisfactory accuracy despite its simplicity. In conclusion, we introduce a multi-neuron structure capable of operating in more complex environments with enhanced accuracy, making it a promising candidate for the advancement of RL applications in SNNs. ",
    "url": "https://arxiv.org/abs/2309.08476",
    "authors": [
      "Mikhail Kiselev",
      "Denis Larionov",
      "Andrey Urusov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2309.08485",
    "title": "XFedHunter: An Explainable Federated Learning Framework for Advanced  Persistent Threat Detection in SDN",
    "abstract": "Advanced Persistent Threat (APT) attacks are highly sophisticated and employ a multitude of advanced methods and techniques to target organizations and steal sensitive and confidential information. APT attacks consist of multiple stages and have a defined strategy, utilizing new and innovative techniques and technologies developed by hackers to evade security software monitoring. To effectively protect against APTs, detecting and predicting APT indicators with an explanation from Machine Learning (ML) prediction is crucial to reveal the characteristics of attackers lurking in the network system. Meanwhile, Federated Learning (FL) has emerged as a promising approach for building intelligent applications without compromising privacy. This is particularly important in cybersecurity, where sensitive data and high-quality labeling play a critical role in constructing effective machine learning models for detecting cyber threats. Therefore, this work proposes XFedHunter, an explainable federated learning framework for APT detection in Software-Defined Networking (SDN) leveraging local cyber threat knowledge from many training collaborators. In XFedHunter, Graph Neural Network (GNN) and Deep Learning model are utilized to reveal the malicious events effectively in the large number of normal ones in the network system. The experimental results on NF-ToN-IoT and DARPA TCE3 datasets indicate that our framework can enhance the trust and accountability of ML-based systems utilized for cybersecurity purposes without privacy leakage. ",
    "url": "https://arxiv.org/abs/2309.08485",
    "authors": [
      "Huynh Thai Thi",
      "Ngo Duc Hoang Son",
      "Phan The Duy",
      "Nghi Hoang Khoa",
      "Khoa Ngo-Khanh",
      "Van-Hau Pham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08504",
    "title": "OccupancyDETR: Making Semantic Scene Completion as Straightforward as  Object Detection",
    "abstract": "Visual-based 3D semantic occupancy perception (also known as 3D semantic scene completion) is a new perception paradigm for robotic applications like autonomous driving. Compared with Bird's Eye View (BEV) perception, it extends the vertical dimension, significantly enhancing the ability of robots to understand their surroundings. However, due to this very reason, the computational demand for current 3D semantic occupancy perception methods generally surpasses that of BEV perception methods and 2D perception methods. We propose a novel 3D semantic occupancy perception method, OccupancyDETR, which consists of a DETR-like object detection module and a 3D occupancy decoder module. The integration of object detection simplifies our method structurally - instead of predicting the semantics of each voxels, it identifies objects in the scene and their respective 3D occupancy grids. This speeds up our method, reduces required resources, and leverages object detection algorithm, giving our approach notable performance on small objects. We demonstrate the effectiveness of our proposed method on the SemanticKITTI dataset, showcasing an mIoU of 23 and a processing speed of 6 frames per second, thereby presenting a promising solution for real-time 3D semantic scene completion. ",
    "url": "https://arxiv.org/abs/2309.08504",
    "authors": [
      "Yupeng Jia",
      "Jie He",
      "Runze Chen",
      "Fang Zhao",
      "Haiyong Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08532",
    "title": "Connecting Large Language Models with Evolutionary Algorithms Yields  Powerful Prompt Optimizers",
    "abstract": "Large Language Models (LLMs) excel in various tasks, but they rely on carefully crafted prompts that often demand substantial human effort. To automate this process, in this paper, we propose a novel framework for discrete prompt optimization, called EvoPrompt, which borrows the idea of evolutionary algorithms (EAs) as they exhibit good performance and fast convergence. To enable EAs to work on discrete prompts, which are natural language expressions that need to be coherent and human-readable, we connect LLMs with EAs. This approach allows us to simultaneously leverage the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs. Specifically, abstaining from any gradients or parameters, EvoPrompt starts from a population of prompts and iteratively generates new prompts with LLMs based on the evolutionary operators, improving the population based on the development set. We optimize prompts for both closed- and open-source LLMs including GPT-3.5 and Alpaca, on 9 datasets spanning language understanding and generation tasks. EvoPrompt significantly outperforms human-engineered prompts and existing methods for automatic prompt generation by up to 25% and 14% respectively. Furthermore, EvoPrompt demonstrates that connecting LLMs with EAs creates synergies, which could inspire further research on the combination of LLMs and conventional algorithms. ",
    "url": "https://arxiv.org/abs/2309.08532",
    "authors": [
      "Qingyan Guo",
      "Rui Wang",
      "Junliang Guo",
      "Bei Li",
      "Kaitao Song",
      "Xu Tan",
      "Guoqing Liu",
      "Jiang Bian",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.08533",
    "title": "Automated dermatoscopic pattern discovery by clustering neural network  output for human-computer interaction",
    "abstract": "Background: As available medical image datasets increase in size, it becomes infeasible for clinicians to review content manually for knowledge extraction. The objective of this study was to create an automated clustering resulting in human-interpretable pattern discovery. Methods: Images from the public HAM10000 dataset, including 7 common pigmented skin lesion diagnoses, were tiled into 29420 tiles and clustered via k-means using neural network-extracted image features. The final number of clusters per diagnosis was chosen by either the elbow method or a compactness metric balancing intra-lesion variance and cluster numbers. The amount of resulting non-informative clusters, defined as those containing less than six image tiles, was compared between the two methods. Results: Applying k-means, the optimal elbow cutoff resulted in a mean of 24.7 (95%-CI: 16.4-33) clusters for every included diagnosis, including 14.9% (95% CI: 0.8-29.0) non-informative clusters. The optimal cutoff, as estimated by the compactness metric, resulted in significantly fewer clusters (13.4; 95%-CI 11.8-15.1; p=0.03) and less non-informative ones (7.5%; 95% CI: 0-19.5; p=0.017). The majority of clusters (93.6%) from the compactness metric could be manually mapped to previously described dermatoscopic diagnostic patterns. Conclusions: Automatically constraining unsupervised clustering can produce an automated extraction of diagnostically relevant and human-interpretable clusters of visual patterns from a large image dataset. ",
    "url": "https://arxiv.org/abs/2309.08533",
    "authors": [
      "Lidia Talavera-Martinez",
      "Philipp Tschandl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.08534",
    "title": "Towards Last-layer Retraining for Group Robustness with Fewer  Annotations",
    "abstract": "Empirical risk minimization (ERM) of neural networks is prone to over-reliance on spurious correlations and poor generalization on minority groups. The recent deep feature reweighting (DFR) technique achieves state-of-the-art group robustness via simple last-layer retraining, but it requires held-out group and class annotations to construct a group-balanced reweighting dataset. In this work, we examine this impractical requirement and find that last-layer retraining can be surprisingly effective with no group annotations (other than for model selection) and only a handful of class annotations. We first show that last-layer retraining can greatly improve worst-group accuracy even when the reweighting dataset has only a small proportion of worst-group data. This implies a \"free lunch\" where holding out a subset of training data to retrain the last layer can substantially outperform ERM on the entire dataset with no additional data or annotations. To further improve group robustness, we introduce a lightweight method called selective last-layer finetuning (SELF), which constructs the reweighting dataset using misclassifications or disagreements. Our empirical and theoretical results present the first evidence that model disagreement upsamples worst-group data, enabling SELF to nearly match DFR on four well-established benchmarks across vision and language tasks with no group annotations and less than 3% of the held-out class annotations. Our code is available at https://github.com/tmlabonte/last-layer-retraining. ",
    "url": "https://arxiv.org/abs/2309.08534",
    "authors": [
      "Tyler LaBonte",
      "Vidya Muthukumar",
      "Abhishek Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08544",
    "title": "Quadcopter Trajectory Time Minimization and Robust Collision Avoidance  via Optimal Time Allocation",
    "abstract": "Autonomous navigation requires robots to generate trajectories for collision avoidance efficiently. Although plenty of previous works have proven successful in generating smooth and spatially collision-free trajectories, their solutions often suffer from suboptimal time efficiency and potential unsafety, particularly when accounting for uncertainties in robot perception and control. To address this issue, this paper presents the Robust Optimal Time Allocation (ROTA) framework. This framework is designed to optimize the time progress of the trajectories temporally, serving as a post-processing tool to enhance trajectory time efficiency and safety under uncertainties. In this study, we begin by formulating a non-convex optimization problem aimed at minimizing trajectory execution time while incorporating constraints on collision probability as the robot approaches obstacles. Subsequently, we introduce the concept of the trajectory braking zone and adopt the chance-constrained formulation for robust collision avoidance in the braking zones. Finally, the non-convex optimization problem is reformulated into a second-order cone programming problem to achieve real-time performance. Through simulations and physical flight experiments, we demonstrate that the proposed approach effectively reduces trajectory execution time while enabling robust collision avoidance in complex environments. ",
    "url": "https://arxiv.org/abs/2309.08544",
    "authors": [
      "Zhefan Xu",
      "Kenji Shimada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08545",
    "title": "Efficient and robust Sensor Placement in Complex Environments",
    "abstract": "We address the problem of efficient and unobstructed surveillance or communication in complex environments. On one hand, one wishes to use a minimal number of sensors to cover the environment. On the other hand, it is often important to consider solutions that are robust against sensor failure or adversarial attacks. This paper addresses these challenges of designing minimal sensor sets that achieve multi-coverage constraints -- every point in the environment is covered by a prescribed number of sensors. We propose a greedy algorithm to achieve the objective. Further, we explore deep learning techniques to accelerate the evaluation of the objective function formulated in the greedy algorithm. The training of the neural network reveals that the geometric properties of the data significantly impact the network's performance, particularly at the end stage. By taking into account these properties, we discuss the differences in using greedy and $\\epsilon$-greedy algorithms to generate data and their impact on the robustness of the network. ",
    "url": "https://arxiv.org/abs/2309.08545",
    "authors": [
      "Lukas Taus",
      "Yen-Hsi Richard Tsai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.08546",
    "title": "Towards Robust Continual Learning with Bayesian Adaptive Moment  Regularization",
    "abstract": "The pursuit of long-term autonomy mandates that robotic agents must continuously adapt to their changing environments and learn to solve new tasks. Continual learning seeks to overcome the challenge of catastrophic forgetting, where learning to solve new tasks causes a model to forget previously learnt information. Prior-based continual learning methods are appealing for robotic applications as they are space efficient and typically do not increase in computational complexity as the number of tasks grows. Despite these desirable properties, prior-based approaches typically fail on important benchmarks and consequently are limited in their potential applications compared to their memory-based counterparts. We introduce Bayesian adaptive moment regularization (BAdam), a novel prior-based method that better constrains parameter growth, leading to lower catastrophic forgetting. Our method boasts a range of desirable properties for robotic applications such as being lightweight and task label-free, converging quickly, and offering calibrated uncertainty that is important for safe real-world deployment. Results show that BAdam achieves state-of-the-art performance for prior-based methods on challenging single-headed class-incremental experiments such as Split MNIST and Split FashionMNIST, and does so without relying on task labels or discrete task boundaries. ",
    "url": "https://arxiv.org/abs/2309.08546",
    "authors": [
      "Jack Foster",
      "Alexandra Brintrup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08549",
    "title": "HINT: Healthy Influential-Noise based Training to Defend against Data  Poisoning Attacks",
    "abstract": "While numerous defense methods have been proposed to prohibit potential poisoning attacks from untrusted data sources, most research works only defend against specific attacks, which leaves many avenues for an adversary to exploit. In this work, we propose an efficient and robust training approach to defend against data poisoning attacks based on influence functions, named Healthy Influential-Noise based Training. Using influence functions, we craft healthy noise that helps to harden the classification model against poisoning attacks without significantly affecting the generalization ability on test data. In addition, our method can perform effectively when only a subset of the training data is modified, instead of the current method of adding noise to all examples that has been used in several previous works. We conduct comprehensive evaluations over two image datasets with state-of-the-art poisoning attacks under different realistic attack scenarios. Our empirical results show that HINT can efficiently protect deep learning models against the effect of both untargeted and targeted poisoning attacks. ",
    "url": "https://arxiv.org/abs/2309.08549",
    "authors": [
      "Minh-Hao Van",
      "Alycia N. Carey",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.08569",
    "title": "Local Differential Privacy in Graph Neural Networks: a Reconstruction  Approach",
    "abstract": "Graph Neural Networks have achieved tremendous success in modeling complex graph data in a variety of applications. However, there are limited studies investigating privacy protection in GNNs. In this work, we propose a learning framework that can provide node privacy at the user level, while incurring low utility loss. We focus on a decentralized notion of Differential Privacy, namely Local Differential Privacy, and apply randomization mechanisms to perturb both feature and label data at the node level before the data is collected by a central server for model training. Specifically, we investigate the application of randomization mechanisms in high-dimensional feature settings and propose an LDP protocol with strict privacy guarantees. Based on frequency estimation in statistical analysis of randomized data, we develop reconstruction methods to approximate features and labels from perturbed data. We also formulate this learning framework to utilize frequency estimates of graph clusters to supervise the training procedure at a sub-graph level. Extensive experiments on real-world and semi-synthetic datasets demonstrate the validity of our proposed model. ",
    "url": "https://arxiv.org/abs/2309.08569",
    "authors": [
      "Karuna Bhaila",
      "Wen Huang",
      "Yongkai Wu",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.08571",
    "title": "A Bayesian Approach to Robust Inverse Reinforcement Learning",
    "abstract": "We consider a Bayesian approach to offline model-based inverse reinforcement learning (IRL). The proposed framework differs from existing offline model-based IRL approaches by performing simultaneous estimation of the expert's reward function and subjective model of environment dynamics. We make use of a class of prior distributions which parameterizes how accurate the expert's model of the environment is to develop efficient algorithms to estimate the expert's reward and subjective dynamics in high-dimensional settings. Our analysis reveals a novel insight that the estimated policy exhibits robust performance when the expert is believed (a priori) to have a highly accurate model of the environment. We verify this observation in the MuJoCo environments and show that our algorithms outperform state-of-the-art offline IRL algorithms. ",
    "url": "https://arxiv.org/abs/2309.08571",
    "authors": [
      "Ran Wei",
      "Siliang Zeng",
      "Chenliang Li",
      "Alfredo Garcia",
      "Anthony McDonald",
      "Mingyi Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08588",
    "title": "Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes",
    "abstract": "We present an approach to estimating camera rotation in crowded, real-world scenes from handheld monocular video. While camera rotation estimation is a well-studied problem, no previous methods exhibit both high accuracy and acceptable speed in this setting. Because the setting is not addressed well by other datasets, we provide a new dataset and benchmark, with high-accuracy, rigorously verified ground truth, on 17 video sequences. Methods developed for wide baseline stereo (e.g., 5-point methods) perform poorly on monocular video. On the other hand, methods used in autonomous driving (e.g., SLAM) leverage specific sensor setups, specific motion models, or local optimization strategies (lagging batch processing) and do not generalize well to handheld video. Finally, for dynamic scenes, commonly used robustification techniques like RANSAC require large numbers of iterations, and become prohibitively slow. We introduce a novel generalization of the Hough transform on SO(3) to efficiently and robustly find the camera rotation most compatible with optical flow. Among comparably fast methods, ours reduces error by almost 50\\% over the next best, and is more accurate than any method, irrespective of speed. This represents a strong new performance point for crowded scenes, an important setting for computer vision. The code and the dataset are available at https://fabiendelattre.com/robust-rotation-estimation. ",
    "url": "https://arxiv.org/abs/2309.08588",
    "authors": [
      "Fabien Delattre",
      "David Dirnfeld",
      "Phat Nguyen",
      "Stephen Scarano",
      "Michael J. Jones",
      "Pedro Miraldo",
      "Erik Learned-Miller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08590",
    "title": "Neural Machine Translation Models Can Learn to be Few-shot Learners",
    "abstract": "The emergent ability of Large Language Models to use a small number of examples to learn to perform in novel domains and tasks, also called in-context learning (ICL). In this work, we show that a much smaller model can be trained to perform ICL by fine-tuning towards a specialized training objective, exemplified on the task of domain adaptation for neural machine translation. With this capacity for ICL, the model can take advantage of relevant few-shot examples to adapt its output towards the domain. We compare the quality of this domain adaptation to traditional supervised techniques and ICL with a 40B-parameter Large Language Model. Our approach allows efficient batch inference on a mix of domains and outperforms state-of-the-art baselines in terms of both translation quality and immediate adaptation rate, i.e. the ability to reproduce a specific term after being shown a single example. ",
    "url": "https://arxiv.org/abs/2309.08590",
    "authors": [
      "Raphael Reinauer",
      "Patrick Simianer",
      "Kaden Uhlig",
      "Johannes E. M. Mosig",
      "Joern Wuebker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08594",
    "title": "\"Merge Conflicts!\" Exploring the Impacts of External Distractors to  Parametric Knowledge Graphs",
    "abstract": "Large language models (LLMs) acquire extensive knowledge during pre-training, known as their parametric knowledge. However, in order to remain up-to-date and align with human instructions, LLMs inevitably require external knowledge during their interactions with users. This raises a crucial question: How will LLMs respond when external knowledge interferes with their parametric knowledge? To investigate this question, we propose a framework that systematically elicits LLM parametric knowledge and introduces external knowledge. Specifically, we uncover the impacts by constructing a parametric knowledge graph to reveal the different knowledge structures of LLMs, and introduce external knowledge through distractors of varying degrees, methods, positions, and formats. Our experiments on both black-box and open-source models demonstrate that LLMs tend to produce responses that deviate from their parametric knowledge, particularly when they encounter direct conflicts or confounding changes of information within detailed contexts. We also find that while LLMs are sensitive to the veracity of external knowledge, they can still be distracted by unrelated information. These findings highlight the risk of hallucination when integrating external knowledge, even indirectly, during interactions with current LLMs. All the data and results are publicly available. ",
    "url": "https://arxiv.org/abs/2309.08594",
    "authors": [
      "Cheng Qian",
      "Xinran Zhao",
      "Sherry Tongshuang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.08596",
    "title": "Robust e-NeRF: NeRF from Sparse & Noisy Events under Non-Uniform Motion",
    "abstract": "Event cameras offer many advantages over standard cameras due to their distinctive principle of operation: low power, low latency, high temporal resolution and high dynamic range. Nonetheless, the success of many downstream visual applications also hinges on an efficient and effective scene representation, where Neural Radiance Field (NeRF) is seen as the leading candidate. Such promise and potential of event cameras and NeRF inspired recent works to investigate on the reconstruction of NeRF from moving event cameras. However, these works are mainly limited in terms of the dependence on dense and low-noise event streams, as well as generalization to arbitrary contrast threshold values and camera speed profiles. In this work, we propose Robust e-NeRF, a novel method to directly and robustly reconstruct NeRFs from moving event cameras under various real-world conditions, especially from sparse and noisy events generated under non-uniform motion. It consists of two key components: a realistic event generation model that accounts for various intrinsic parameters (e.g. time-independent, asymmetric threshold and refractory period) and non-idealities (e.g. pixel-to-pixel threshold variation), as well as a complementary pair of normalized reconstruction losses that can effectively generalize to arbitrary speed profiles and intrinsic parameter values without such prior knowledge. Experiments on real and novel realistically simulated sequences verify our effectiveness. Our code, synthetic dataset and improved event simulator are public. ",
    "url": "https://arxiv.org/abs/2309.08596",
    "authors": [
      "Weng Fei Low",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.07948",
    "title": "Complex-Valued Neural Networks for Data-Driven Signal Processing and  Signal Understanding",
    "abstract": "Complex-valued neural networks have emerged boasting superior modeling performance for many tasks across the signal processing, sensing, and communications arenas. However, developing complex-valued models currently demands development of basic deep learning operations, such as linear or convolution layers, as modern deep learning frameworks like PyTorch and Tensor flow do not adequately support complex-valued neural networks. This paper overviews a package built on PyTorch with the intention of implementing light-weight interfaces for common complex-valued neural network operations and architectures. Similar to natural language understanding (NLU), which as recently made tremendous leaps towards text-based intelligence, RF Signal Understanding (RFSU) is a promising field extending conventional signal processing algorithms using a hybrid approach of signal mechanics-based insight with data-driven modeling power. Notably, we include efficient implementations for linear, convolution, and attention modules in addition to activation functions and normalization layers such as batchnorm and layernorm. Additionally, we include efficient implementations of manifold-based complex-valued neural network layers that have shown tremendous promise but remain relatively unexplored in many research contexts. Although there is an emphasis on 1-D data tensors, due to a focus on signal processing, communications, and radar data, many of the routines are implemented for 2-D and 3-D data as well. Specifically, the proposed approach offers a useful set of tools and documentation for data-driven signal processing research and practical implementation. ",
    "url": "https://arxiv.org/abs/2309.07948",
    "authors": [
      "Josiah W. Smith"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08005",
    "title": "Efficient Face Detection with Audio-Based Region Proposals",
    "abstract": "Robot vision often involves a large computational load due to large images to process in a short amount of time. Existing solutions often involve reducing image quality which can negatively impact processing. Another approach is to generate regions of interest with expensive vision algorithms. In this paper, we evaluate how audio can be used to generate regions of interest in optical images. To achieve this, we propose a unique attention mechanism to localize speech sources and evaluate its impact on a face detection algorithm. Our results show that the attention mechanism reduces the computational load. The proposed pipeline is flexible and can be easily adapted for human-robot interactions, robot surveillance, video-conferences or smart glasses. ",
    "url": "https://arxiv.org/abs/2309.08005",
    "authors": [
      "William Aris",
      "Fran\u00e7ois Grondin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.08023",
    "title": "USM-SCD: Multilingual Speaker Change Detection Based on Large Pretrained  Foundation Models",
    "abstract": "We introduce a multilingual speaker change detection model (USM-SCD) that can simultaneously detect speaker turns and perform ASR for 96 languages. This model is adapted from a speech foundation model trained on a large quantity of supervised and unsupervised data, demonstrating the utility of fine-tuning from a large generic foundation model for a downstream task. We analyze the performance of this multilingual speaker change detection model through a series of ablation studies. We show that the USM-SCD model can achieve more than 75% average speaker change detection F1 score across a test set that consists of data from 96 languages. On American English, the USM-SCD model can achieve an 85.8% speaker change detection F1 score across various public and internal test sets, beating the previous monolingual baseline model by 21% relative. We also show that we only need to fine-tune one-quarter of the trainable model parameters to achieve the best model performance. The USM-SCD model exhibits state-of-the-art ASR quality compared with a strong public ASR baseline, making it suitable to handle both tasks with negligible additional computational cost. ",
    "url": "https://arxiv.org/abs/2309.08023",
    "authors": [
      "Guanlong Zhao",
      "Yongqiang Wang",
      "Jason Pelecanos",
      "Yu Zhang",
      "Hank Liao",
      "Yiling Huang",
      "Han Lu",
      "Quan Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.08030",
    "title": "AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised  Features for Audio-Visual Speech Enhancement",
    "abstract": "Speech enhancement systems are typically trained using pairs of clean and noisy speech. In audio-visual speech enhancement (AVSE), there is not as much ground-truth clean data available; most audio-visual datasets are collected in real-world environments with background noise and reverberation, hampering the development of AVSE. In this work, we introduce AV2Wav, a resynthesis-based audio-visual speech enhancement approach that can generate clean speech despite the challenges of real-world training data. We obtain a subset of nearly clean speech from an audio-visual corpus using a neural quality estimator, and then train a diffusion model on this subset to generate waveforms conditioned on continuous speech representations from AV-HuBERT with noise-robust training. We use continuous rather than discrete representations to retain prosody and speaker information. With this vocoding task alone, the model can perform speech enhancement better than a masking-based baseline. We further fine-tune the diffusion model on clean/noisy utterance pairs to improve the performance. Our approach outperforms a masking-based baseline in terms of both automatic metrics and a human listening test and is close in quality to the target speech in the listening test. Audio samples can be found at https://home.ttic.edu/~jcchou/demo/avse/avse_demo.html. ",
    "url": "https://arxiv.org/abs/2309.08030",
    "authors": [
      "Ju-Chieh Chou",
      "Chung-Ming Chien",
      "Karen Livescu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.08044",
    "title": "How many Neurons do we need? A refined Analysis for Shallow Networks  trained with Gradient Descent",
    "abstract": "We analyze the generalization properties of two-layer neural networks in the neural tangent kernel (NTK) regime, trained with gradient descent (GD). For early stopped GD we derive fast rates of convergence that are known to be minimax optimal in the framework of non-parametric regression in reproducing kernel Hilbert spaces. On our way, we precisely keep track of the number of hidden neurons required for generalization and improve over existing results. We further show that the weights during training remain in a vicinity around initialization, the radius being dependent on structural assumptions such as degree of smoothness of the regression function and eigenvalue decay of the integral operator associated to the NTK. ",
    "url": "https://arxiv.org/abs/2309.08044",
    "authors": [
      "Mike Nguyen",
      "Nicole M\u00fccke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08153",
    "title": "Fine-tune the pretrained ATST model for sound event detection",
    "abstract": "Sound event detection (SED) often suffers from the data deficiency problem. The recent baseline system in the DCASE2023 challenge task 4 leverages the large pretrained self-supervised learning (SelfSL) models to mitigate such restriction, where the pretrained models help to produce more discriminative features for SED. However, the pretrained models are regarded as a frozen feature extractor in the challenge baseline system and most of the challenge submissions, and fine-tuning of the pretrained models has been rarely studied. In this work, we study the fine-tuning method of the pretrained models for SED. We first introduce ATST-Frame, our newly proposed SelfSL model, to the SED system. ATST-Frame was especially designed for learning frame-level representations of audio signals and obtained state-of-the-art (SOTA) performances on a series of downstream tasks. We then propose a fine-tuning method for ATST-Frame using both (in-domain) unlabelled and labelled SED data. Our experiments show that, the proposed method overcomes the overfitting problem when fine-tuning the large pretrained network, and our SED system obtains new SOTA results of 0.587/0.812 PSDS1/PSDS2 scores on the DCASE challenge task 4 dataset. ",
    "url": "https://arxiv.org/abs/2309.08153",
    "authors": [
      "Nian Shao",
      "Xian Li",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.08160",
    "title": "Cross-Modal Synthesis of Structural MRI and Functional Connectivity  Networks via Conditional ViT-GANs",
    "abstract": "The cross-modal synthesis between structural magnetic resonance imaging (sMRI) and functional network connectivity (FNC) is a relatively unexplored area in medical imaging, especially with respect to schizophrenia. This study employs conditional Vision Transformer Generative Adversarial Networks (cViT-GANs) to generate FNC data based on sMRI inputs. After training on a comprehensive dataset that included both individuals with schizophrenia and healthy control subjects, our cViT-GAN model effectively synthesized the FNC matrix for each subject, and then formed a group difference FNC matrix, obtaining a Pearson correlation of 0.73 with the actual FNC matrix. In addition, our FNC visualization results demonstrate significant correlations in particular subcortical brain regions, highlighting the model's capability of capturing detailed structural-functional associations. This performance distinguishes our model from conditional CNN-based GAN alternatives such as Pix2Pix. Our research is one of the first attempts to link sMRI and FNC synthesis, setting it apart from other cross-modal studies that concentrate on T1- and T2-weighted MR images or the fusion of MRI and CT scans. ",
    "url": "https://arxiv.org/abs/2309.08160",
    "authors": [
      "Yuda Bi",
      "Anees Abrol",
      "Jing Sui",
      "Vince Calhoun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08169",
    "title": "On Induced Versions of Menger's Theorem on Sparse Graphs",
    "abstract": "Let $A$ and $B$ be sets of vertices in a graph $G$. Menger's theorem states that for every positive integer $k$, either there exists a collection of $k$ vertex-disjoint paths between $A$ and $B$, or $A$ can be separated from $B$ by a set of at most $k-1$ vertices. Let $\\Delta$ be the maximum degree of $G$. We show that there exists a function $f(\\Delta) = (\\Delta+1)^{\\Delta^2+1}$, so that for every positive integer $k$, either there exists a collection of $k$ vertex-disjoint and pairwise anticomplete paths between $A$ and $B$, or $A$ can be separated from $B$ by a set of at most $k \\cdot f(\\Delta)$ vertices. We also show that the result can be generalized from bounded-degree graphs to graphs excluding a topological minor. On the negative side, we show that no such relation holds on graphs that have degeneracy 2 and arbitrarily large girth, even when $k = 2$. Similar results were obtained independently and concurrently by Hendrey, Norin, Steiner, and Turcotte [arXiv:2309.07905]. ",
    "url": "https://arxiv.org/abs/2309.08169",
    "authors": [
      "Peter Gartland",
      "Tuukka Korhonen",
      "Daniel Lokshtanov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.08197",
    "title": "Hyperspectral Image Denoising via Self-Modulating Convolutional Neural  Networks",
    "abstract": "Compared to natural images, hyperspectral images (HSIs) consist of a large number of bands, with each band capturing different spectral information from a certain wavelength, even some beyond the visible spectrum. These characteristics of HSIs make them highly effective for remote sensing applications. That said, the existing hyperspectral imaging devices introduce severe degradation in HSIs. Hence, hyperspectral image denoising has attracted lots of attention by the community lately. While recent deep HSI denoising methods have provided effective solutions, their performance under real-life complex noise remains suboptimal, as they lack adaptability to new data. To overcome these limitations, in our work, we introduce a self-modulating convolutional neural network which we refer to as SM-CNN, which utilizes correlated spectral and spatial information. At the core of the model lies a novel block, which we call spectral self-modulating residual block (SSMRB), that allows the network to transform the features in an adaptive manner based on the adjacent spectral data, enhancing the network's ability to handle complex noise. In particular, the introduction of SSMRB transforms our denoising network into a dynamic network that adapts its predicted features while denoising every input HSI with respect to its spatio-spectral characteristics. Experimental analysis on both synthetic and real data shows that the proposed SM-CNN outperforms other state-of-the-art HSI denoising methods both quantitatively and qualitatively on public benchmark datasets. ",
    "url": "https://arxiv.org/abs/2309.08197",
    "authors": [
      "Orhan Torun",
      "Seniha Esen Yuksel",
      "Erkut Erdem",
      "Nevrez Imamoglu",
      "Aykut Erdem"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08241",
    "title": "Topological Node2vec: Enhanced Graph Embedding via Persistent Homology",
    "abstract": "Node2vec is a graph embedding method that learns a vector representation for each node of a weighted graph while seeking to preserve relative proximity and global structure. Numerical experiments suggest Node2vec struggles to recreate the topology of the input graph. To resolve this we introduce a topological loss term to be added to the training loss of Node2vec which tries to align the persistence diagram (PD) of the resulting embedding as closely as possible to that of the input graph. Following results in computational optimal transport, we carefully adapt entropic regularization to PD metrics, allowing us to measure the discrepancy between PDs in a differentiable way. Our modified loss function can then be minimized through gradient descent to reconstruct both the geometry and the topology of the input graph. We showcase the benefits of this approach using demonstrative synthetic examples. ",
    "url": "https://arxiv.org/abs/2309.08241",
    "authors": [
      "Yasuaki Hiraoka",
      "Yusuke Imoto",
      "Killian Meehan",
      "Th\u00e9o Lacombe",
      "Toshiaki Yachimura"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.08255",
    "title": "Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for  Robust Polyglot Text-To-Speech",
    "abstract": "In this work, we introduce a framework for cross-lingual speech synthesis, which involves an upstream Voice Conversion (VC) model and a downstream Text-To-Speech (TTS) model. The proposed framework consists of 4 stages. In the first two stages, we use a VC model to convert utterances in the target locale to the voice of the target speaker. In the third stage, the converted data is combined with the linguistic features and durations from recordings in the target language, which are then used to train a single-speaker acoustic model. Finally, the last stage entails the training of a locale-independent vocoder. Our evaluations show that the proposed paradigm outperforms state-of-the-art approaches which are based on training a large multilingual TTS model. In addition, our experiments demonstrate the robustness of our approach with different model architectures, languages, speakers and amounts of data. Moreover, our solution is especially beneficial in low-resource settings. ",
    "url": "https://arxiv.org/abs/2309.08255",
    "authors": [
      "Dariusz Piotrowski",
      "Renard Korzeniowski",
      "Alessio Falai",
      "Sebastian Cygert",
      "Kamil Pokora",
      "Georgi Tinchev",
      "Ziyao Zhang",
      "Kayoko Yanagisawa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.08285",
    "title": "One-Class Knowledge Distillation for Spoofing Speech Detection",
    "abstract": "The detection of spoofing speech generated by unseen algorithms remains an unresolved challenge. One reason for the lack of generalization ability is traditional detecting systems follow the binary classification paradigm, which inherently assumes the possession of prior knowledge of spoofing speech. One-class methods attempt to learn the distribution of bonafide speech and are inherently suited to the task where spoofing speech exhibits significant differences. However, training a one-class system using only bonafide speech is challenging. In this paper, we introduce a teacher-student framework to provide guidance for the training of a one-class model. The proposed one-class knowledge distillation method outperforms other state-of-the-art methods on the ASVspoof 21DF dataset and InTheWild dataset, which demonstrates its superior generalization ability. ",
    "url": "https://arxiv.org/abs/2309.08285",
    "authors": [
      "Jingze Lu",
      "Yuxiang Zhang",
      "Wenchao Wang",
      "Zengqiang Shang",
      "Pengyuan Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.08295",
    "title": "A Real-Time Active Speaker Detection System Integrating an Audio-Visual  Signal with a Spatial Querying Mechanism",
    "abstract": "We introduce a distinctive real-time, causal, neural network-based active speaker detection system optimized for low-power edge computing. This system drives a virtual cinematography module and is deployed on a commercial device. The system uses data originating from a microphone array and a 360-degree camera. Our network requires only 127 MFLOPs per participant, for a meeting with 14 participants. Unlike previous work, we examine the error rate of our network when the computational budget is exhausted, and find that it exhibits graceful degradation, allowing the system to operate reasonably well even in this case. Departing from conventional DOA estimation approaches, our network learns to query the available acoustic data, considering the detected head locations. We train and evaluate our algorithm on a realistic meetings dataset featuring up to 14 participants in the same meeting, overlapped speech, and other challenging scenarios. ",
    "url": "https://arxiv.org/abs/2309.08295",
    "authors": [
      "Ilya Gurvich",
      "Ido Leichter",
      "Dharmendar Reddy Palle",
      "Yossi Asher",
      "Alon Vinnikov",
      "Igor Abramovski",
      "Vishak Gopal",
      "Ross Cutler",
      "Eyal Krupka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.08355",
    "title": "Semi-supervised Sound Event Detection with Local and Global Consistency  Regularization",
    "abstract": "Learning meaningful frame-wise features on a partially labeled dataset is crucial to semi-supervised sound event detection. Prior works either maintain consistency on frame-level predictions or seek feature-level similarity among neighboring frames, which cannot exploit the potential of unlabeled data. In this work, we design a Local and Global Consistency (LGC) regularization scheme to enhance the model on both label- and feature-level. The audio CutMix is introduced to change the contextual information of clips. Then, the local consistency is adopted to encourage the model to leverage local features for frame-level predictions, and the global consistency is applied to force features to align with global prototypes through a specially designed contrastive loss. Experiments on the DESED dataset indicate the superiority of LGC, surpassing its respective competitors largely with the same settings as the baseline system. Besides, combining LGC with existing methods can obtain further improvements. The code will be released soon. ",
    "url": "https://arxiv.org/abs/2309.08355",
    "authors": [
      "Yiming Li",
      "Xiangdong Wang",
      "Hong Liu",
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.08376",
    "title": "The monotonicity method for inclusion detection and the time harmonic  elastic wave equation",
    "abstract": "We consider the problem of reconstructing inhomogeneities in an isotropic elastic body using time harmonic waves. Here we extend the so called monotonicity method for inclusion detection and show how to determine certain types of inhomogeneities in the Lam\\'e parameters and the density. We also included some numerical tests of the method. ",
    "url": "https://arxiv.org/abs/2309.08376",
    "authors": [
      "Sarah Eberle-Blick",
      "Valter Pohjola"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2309.08381",
    "title": "Reconsidering evaluation practices in modular systems: On the  propagation of errors in MRI prostate cancer detection",
    "abstract": "Magnetic resonance imaging has evolved as a key component for prostate cancer (PCa) detection, substantially increasing the radiologist workload. Artificial intelligence (AI) systems can support radiological assessment by segmenting and classifying lesions in clinically significant (csPCa) and non-clinically significant (ncsPCa). Commonly, AI systems for PCa detection involve an automatic prostate segmentation followed by the lesion detection using the extracted prostate. However, evaluation reports are typically presented in terms of detection under the assumption of the availability of a highly accurate segmentation and an idealistic scenario, omitting the propagation of errors between modules. For that purpose, we evaluate the effect of two different segmentation networks (s1 and s2) with heterogeneous performances in the detection stage and compare it with an idealistic setting (s1:89.90+-2.23 vs 88.97+-3.06 ncsPCa, P<.001, 89.30+-4.07 and 88.12+-2.71 csPCa, P<.001). Our results depict the relevance of a holistic evaluation, accounting for all the sub-modules involved in the system. ",
    "url": "https://arxiv.org/abs/2309.08381",
    "authors": [
      "Erlend Sortland Rolfsnes",
      "Philip Thangngat",
      "Trygve Eftest\u00f8l",
      "Tobias Nordstr\u00f6m",
      "Fredrik J\u00e4derling",
      "Martin Eklund",
      "Alvaro Fernandez-Quilez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2309.08489",
    "title": "Towards Word-Level End-to-End Neural Speaker Diarization with Auxiliary  Network",
    "abstract": "While standard speaker diarization attempts to answer the question \"who spoken when\", most of relevant applications in reality are more interested in determining \"who spoken what\". Whether it is the conventional modularized approach or the more recent end-to-end neural diarization (EEND), an additional automatic speech recognition (ASR) model and an orchestration algorithm are required to associate the speaker labels with recognized words. In this paper, we propose Word-level End-to-End Neural Diarization (WEEND) with auxiliary network, a multi-task learning algorithm that performs end-to-end ASR and speaker diarization in the same neural architecture. That is, while speech is being recognized, speaker labels are predicted simultaneously for each recognized word. Experimental results demonstrate that WEEND outperforms the turn-based diarization baseline system on all 2-speaker short-form scenarios and has the capability to generalize to audio lengths of 5 minutes. Although 3+speaker conversations are harder, we find that with enough in-domain training data, WEEND has the potential to deliver high quality diarized text. ",
    "url": "https://arxiv.org/abs/2309.08489",
    "authors": [
      "Yiling Huang",
      "Weiran Wang",
      "Guanlong Zhao",
      "Hank Liao",
      "Wei Xia",
      "Quan Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.08526",
    "title": "Robust IRS-Element Activation for Energy Efficiency Optimization in  IRS-Assisted Communication Systems With Imperfect CSI",
    "abstract": "In this paper, we study an intelligent reflecting surface (IRS)-aided communication system with single-antenna transmitter and receiver, under imperfect channel state information (CSI). More specifically, we deal with the robust selection of binary (on/off) states of the IRS elements in order to maximize the worst-case energy efficiency (EE), given a bounded CSI uncertainty, while satisfying a minimum signal-to-noise ratio (SNR). In addition, we consider not only continuous but also discrete IRS phase shifts. First, we derive closed-form expressions of the worst-case SNRs, and then formulate the robust (discrete) optimization problems for each case. In the case of continuous phase shifts, we design a dynamic programming (DP) algorithm that is theoretically guaranteed to achieve the global maximum with polynomial complexity $O(L\\,{\\log L})$, where $L$ is the number of IRS elements. In the case of discrete phase shifts, we develop a convex-relaxation-based method (CRBM) to obtain a feasible (sub-optimal) solution in polynomial time $O(L^{3.5})$, with a posteriori performance guarantee. Furthermore, numerical simulations provide useful insights and confirm the theoretical results. In particular, the proposed algorithms are several orders of magnitude faster than the exhaustive search when $L$ is large, thus being highly scalable and suitable for practical applications. Moreover, both algorithms outperform a baseline scheme, namely, the activation of all IRS elements. ",
    "url": "https://arxiv.org/abs/2309.08526",
    "authors": [
      "Christos N. Efrem",
      "Ioannis Krikidis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.08558",
    "title": "A modern approach to transition analysis and process mining with Markov  models: A tutorial with R",
    "abstract": "This chapter presents an introduction to Markovian modeling for the analysis of sequence data. Contrary to the deterministic approach seen in the previous sequence analysis chapters, Markovian models are probabilistic models, focusing on the transitions between states instead of studying sequences as a whole. The chapter provides an introduction to this method and differentiates between its most common variations: first-order Markov models, hidden Markov models, mixture Markov models, and mixture hidden Markov models. In addition to a thorough explanation and contextualization within the existing literature, the chapter provides a step-by-step tutorial on how to implement each type of Markovian model using the R package seqHMM. The chaper also provides a complete guide to performing stochastic process mining with Markovian models as well as plotting, comparing and clustering different process models. ",
    "url": "https://arxiv.org/abs/2309.08558",
    "authors": [
      "Jouni Helske",
      "Satu Helske",
      "Mohammed Saqr",
      "Sonsoles L\u00f3pez-Pernas",
      "Keefe Murphy"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.08570",
    "title": "Neural Network Driven, Interactive Design for Nonlinear Optical  Molecules Based on Group Contribution Method",
    "abstract": "A Lewis-mode group contribution method (LGC) -- multi-stage Bayesian neural network (msBNN) -- evolutionary algorithm (EA) framework is reported for rational design of D-Pi-A type organic small-molecule nonlinear optical materials is presented. Upon combination of msBNN and corrected Lewis-mode group contribution method (cLGC), different optical properties of molecules are afforded accurately and efficiently - by using only a small data set for training. Moreover, by employing the EA model designed specifically for LGC, structural search is well achievable. The logical origins of the well performance of the framework are discussed in detail. Considering that such a theory guided, machine learning framework combines chemical principles and data-driven tools, most likely, it will be proven efficient to solve molecular design related problems in wider fields. ",
    "url": "https://arxiv.org/abs/2309.08570",
    "authors": [
      "Jinming Fan",
      "Chao Qian",
      "Shaodong Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2005.00610",
    "title": "Constraint-Based Causal Discovery using Partial Ancestral Graphs in the  presence of Cycles",
    "abstract": " Comments: This version corrects some typos in the published version (Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI), PMLR volume 124, 2020); it also provides proofs inline instead of in a supplement for improved readability ",
    "url": "https://arxiv.org/abs/2005.00610",
    "authors": [
      "Joris M. Mooij",
      "Tom Claassen"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2009.07140",
    "title": "HGCN-GJS: Hierarchical Graph Convolutional Network with Groupwise Joint  Sampling for Trajectory Prediction",
    "abstract": " Comments: 6 pages, 8 figures, accepted by IROS 2022 ",
    "url": "https://arxiv.org/abs/2009.07140",
    "authors": [
      "Yuying Chen",
      "Congcong Liu",
      "Xiaodong Mei",
      "Bertram E. Shi",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.08800",
    "title": "Design and Analysis of High Performance Heterogeneous Block-based  Approximate Adders",
    "abstract": " Comments: Accepted for publication in ACM Transactions on Embedded Computing Systems (TECS) ",
    "url": "https://arxiv.org/abs/2106.08800",
    "authors": [
      "Ebrahim Farahmand",
      "Ali Mahani",
      "Muhammad Abdullah Hanif",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2107.02053",
    "title": "MixStyle Neural Networks for Domain Generalization and Adaptation",
    "abstract": " Comments: Extension of this https URL Code available at this https URL To appear in IJCV ",
    "url": "https://arxiv.org/abs/2107.02053",
    "authors": [
      "Kaiyang Zhou",
      "Yongxin Yang",
      "Yu Qiao",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11501",
    "title": "VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks  for Visual Question Answering",
    "abstract": " Comments: Accepted at ICCV 2023 ",
    "url": "https://arxiv.org/abs/2205.11501",
    "authors": [
      "Yanan Wang",
      "Michihiro Yasunaga",
      "Hongyu Ren",
      "Shinya Wada",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.12447",
    "title": "XMD: An Expansive Hardware-telemetry based Mobile Malware Detector to  enhance Endpoint Detection",
    "abstract": " Comments: Revised version based on peer review feedback. Manuscript to appear in IEEE Transactions on Information Forensics and Security ",
    "url": "https://arxiv.org/abs/2206.12447",
    "authors": [
      "Harshit Kumar",
      "Biswadeep Chakraborty",
      "Sudarshan Sharma",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.04643",
    "title": "Critical Learning Periods for Multisensory Integration in Deep Networks",
    "abstract": " Comments: CVPR 2023 (Highlighted Paper) ",
    "url": "https://arxiv.org/abs/2210.04643",
    "authors": [
      "Michael Kleinman",
      "Alessandro Achille",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.04688",
    "title": "BAFFLE: Backdoor Attack in Offline Reinforcement Learning",
    "abstract": " Comments: 18 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2210.04688",
    "authors": [
      "Chen Gong",
      "Zhou Yang",
      "Yunpeng Bai",
      "Junda He",
      "Jieke Shi",
      "Kecen Li",
      "Arunesh Sinha",
      "Bowen Xu",
      "Xinwen Hou",
      "David Lo",
      "Tianhao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.02483",
    "title": "TIDE: Time Derivative Diffusion for Deep Learning on Graphs",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2212.02483",
    "authors": [
      "Maysam Behmanesh",
      "Maximilian Krahn",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.07771",
    "title": "Temporal Saliency Detection Towards Explainable Transformer-based  Timeseries Forecasting",
    "abstract": " Comments: Published at the International Workshop on Explainable and Interpretable Machine Learning (XI-ML), 26th European Conference on Artificial Intelligence (ECAI 2023) ",
    "url": "https://arxiv.org/abs/2212.07771",
    "authors": [
      "Nghia Duong-Trung",
      "Duc-Manh Nguyen",
      "Danh Le-Phuoc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.09201",
    "title": "SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis",
    "abstract": " Title: SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis ",
    "url": "https://arxiv.org/abs/2301.09201",
    "authors": [
      "Imtiaz Karim",
      "Kazi Samin Mubasshir",
      "Mirza Masfiqur Rahman",
      "Elisa Bertino"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12351",
    "title": "Emerging Synergies in Causality and Deep Generative Models: A Survey",
    "abstract": " Title: Emerging Synergies in Causality and Deep Generative Models: A Survey ",
    "url": "https://arxiv.org/abs/2301.12351",
    "authors": [
      "Guanglin Zhou",
      "Shaoan Xie",
      "Guangyuan Hao",
      "Shiming Chen",
      "Biwei Huang",
      "Xiwei Xu",
      "Chen Wang",
      "Liming Zhu",
      "Lina Yao",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.13221",
    "title": "Beyond Discrete Selection: Continuous Embedding Space Optimization for  Generative Feature Selection",
    "abstract": " Comments: keywords: Automated Feature Selection, Continuous Space Optimization, Deep Sequential Learning, 10 pages ",
    "url": "https://arxiv.org/abs/2302.13221",
    "authors": [
      "Meng Xiao",
      "Dongjie Wang",
      "Min Wu",
      "Pengfei Wang",
      "Yuanchun Zhou",
      "Yanjie Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.06335",
    "title": "Just Flip: Flipped Observation Generation and Optimization for Neural  Radiance Fields to Cover Unobserved View",
    "abstract": " Title: Just Flip: Flipped Observation Generation and Optimization for Neural  Radiance Fields to Cover Unobserved View ",
    "url": "https://arxiv.org/abs/2303.06335",
    "authors": [
      "Minjae Lee",
      "Kyeongsu Kang",
      "Hyeonwoo Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.17086",
    "title": "Modularized Control Synthesis for Complex Signal Temporal Logic  Specifications",
    "abstract": " Title: Modularized Control Synthesis for Complex Signal Temporal Logic  Specifications ",
    "url": "https://arxiv.org/abs/2303.17086",
    "authors": [
      "Zengjie Zhang",
      "Sofie Haesaert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.02976",
    "title": "Unconstrained Parametrization of Dissipative and Contracting Neural  Ordinary Differential Equations",
    "abstract": " Comments: Accepted for CDC 2023 ",
    "url": "https://arxiv.org/abs/2304.02976",
    "authors": [
      "Daniele Martinelli",
      "Clara Luc\u00eda Galimberti",
      "Ian R. Manchester",
      "Luca Furieri",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.10136",
    "title": "Diversifying the High-level Features for better Adversarial  Transferability",
    "abstract": " Comments: Accepted by BMVC 2023 (Oral) ",
    "url": "https://arxiv.org/abs/2304.10136",
    "authors": [
      "Zhiyuan Wang",
      "Zeliang Zhang",
      "Siyuan Liang",
      "Xiaosen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.14633",
    "title": "CVRecon: Rethinking 3D Geometric Feature Learning For Neural  Reconstruction",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2304.14633",
    "authors": [
      "Ziyue Feng",
      "Liang Yang",
      "Pengsheng Guo",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.06630",
    "title": "Predictive change point detection for heterogeneous data",
    "abstract": " Title: Predictive change point detection for heterogeneous data ",
    "url": "https://arxiv.org/abs/2305.06630",
    "authors": [
      "Anna-Christina Glock",
      "Florian Sobieczky",
      "Johannes F\u00fcrnkranz",
      "Peter Filzmoser",
      "Martin Jech"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05554",
    "title": "Simulation and Prediction of Countercurrent Spontaneous Imbibition at  Early and Late Times Using Physics-Informed Neural Networks",
    "abstract": " Title: Simulation and Prediction of Countercurrent Spontaneous Imbibition at  Early and Late Times Using Physics-Informed Neural Networks ",
    "url": "https://arxiv.org/abs/2306.05554",
    "authors": [
      "Jassem Abbasi",
      "P\u00e5l \u00d8steb\u00f8 Andersen"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.08960",
    "title": "Neural Network Compression using Binarization and Few Full-Precision  Weights",
    "abstract": " Comments: 15 pages, 6 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2306.08960",
    "authors": [
      "Franco Maria Nardini",
      "Cosimo Rulli",
      "Salvatore Trani",
      "Rossano Venturini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.12111",
    "title": "A Comprehensive Study on the Robustness of Image Classification and  Object Detection in Remote Sensing: Surveying and Benchmarking",
    "abstract": " Title: A Comprehensive Study on the Robustness of Image Classification and  Object Detection in Remote Sensing: Surveying and Benchmarking ",
    "url": "https://arxiv.org/abs/2306.12111",
    "authors": [
      "Shaohui Mei",
      "Jiawei Lian",
      "Xiaofei Wang",
      "Yuru Su",
      "Mingyang Ma",
      "Lap-Pui Chau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.17137",
    "title": "Nonlinear Data-Driven Control Part I: Trajectory Representation under  quasi-Linear Parameter Varying Embeddings",
    "abstract": " Comments: Many changes are being performed on the manuscript. A revised version will be available soon ",
    "url": "https://arxiv.org/abs/2306.17137",
    "authors": [
      "Marcelo Menezes Morato",
      "Julio Elias Normey-Rico",
      "Olivier Sename"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2307.04513",
    "title": "CoactSeg: Learning from Heterogeneous Data for New Multiple Sclerosis  Lesion Segmentation",
    "abstract": " Comments: Accepted by MICCAI 2023 (Early Acceptance) ",
    "url": "https://arxiv.org/abs/2307.04513",
    "authors": [
      "Yicheng Wu",
      "Zhonghua Wu",
      "Hengcan Shi",
      "Bjoern Picker",
      "Winston Chong",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07577",
    "title": "Decomposition Based Refinement for the Network Interdiction Problem",
    "abstract": " Title: Decomposition Based Refinement for the Network Interdiction Problem ",
    "url": "https://arxiv.org/abs/2307.07577",
    "authors": [
      "Krish Matta",
      "Xiaoyuan Liu",
      "Ilya Safro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.09039",
    "title": "PottsMGNet: A Mathematical Explanation of Encoder-Decoder Based Neural  Networks",
    "abstract": " Title: PottsMGNet: A Mathematical Explanation of Encoder-Decoder Based Neural  Networks ",
    "url": "https://arxiv.org/abs/2307.09039",
    "authors": [
      "Xue-Cheng Tai",
      "Hao Liu",
      "Raymond Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.13149",
    "title": "Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions",
    "abstract": " Title: Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions ",
    "url": "https://arxiv.org/abs/2307.13149",
    "authors": [
      "Bahador Bahmani",
      "Hyoung Suk Suh",
      "WaiChing Sun"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.16387",
    "title": "Relation-Oriented: Toward Knowledge-Aligned Causal AI",
    "abstract": " Title: Relation-Oriented: Toward Knowledge-Aligned Causal AI ",
    "url": "https://arxiv.org/abs/2307.16387",
    "authors": [
      "Jia Li",
      "Xiang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.16440",
    "title": "Towards Head Computed Tomography Image Reconstruction Standardization  with Deep Learning Assisted Automatic Detection",
    "abstract": " Title: Towards Head Computed Tomography Image Reconstruction Standardization  with Deep Learning Assisted Automatic Detection ",
    "url": "https://arxiv.org/abs/2307.16440",
    "authors": [
      "Bowen Zheng",
      "Chenxi Huang",
      "Yuemei Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2308.01921",
    "title": "Transferable Graph Neural Fingerprint Models for Quick Response to  Future Bio-Threats",
    "abstract": " Comments: 8 pages, 5 figures, 2 tables, accepted by ICLMA2023 ",
    "url": "https://arxiv.org/abs/2308.01921",
    "authors": [
      "Wei Chen",
      "Yihui Ren",
      "Ai Kagawa",
      "Matthew R. Carbone",
      "Samuel Yen-Chi Chen",
      "Xiaohui Qu",
      "Shinjae Yoo",
      "Austin Clyde",
      "Arvind Ramanathan",
      "Rick L. Stevens",
      "Hubertus J. J. van Dam",
      "Deyu Lu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05394",
    "title": "Robust Localization with Visual-Inertial Odometry Constraints for  Markerless Mobile AR",
    "abstract": " Title: Robust Localization with Visual-Inertial Odometry Constraints for  Markerless Mobile AR ",
    "url": "https://arxiv.org/abs/2308.05394",
    "authors": [
      "Changkun Liu",
      "Yukun Zhao",
      "Tristan Braud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06378",
    "title": "DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System",
    "abstract": " Title: DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System ",
    "url": "https://arxiv.org/abs/2308.06378",
    "authors": [
      "Mojtaba Yeganejou",
      "Kimia Honari",
      "Ryan Kluzinski",
      "Scott Dick",
      "Michael Lipsett",
      "James Miller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.06889",
    "title": "Robustness Stress Testing in Medical Image Classification",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2308.06889",
    "authors": [
      "Mobarakol Islam",
      "Zeju Li",
      "Ben Glocker"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09308",
    "title": "Differentiable Retrieval Augmentation via Generative Language Modeling  for E-commerce Query Intent Classification",
    "abstract": " Comments: 5 pages, 2 figures; accepted by CIKM2023 ",
    "url": "https://arxiv.org/abs/2308.09308",
    "authors": [
      "Chenyu Zhao",
      "Yunjiang Jiang",
      "Yiming Qiu",
      "Han Zhang",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.09729",
    "title": "MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large  Language Models",
    "abstract": " Comments: 7 pages, 8 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2308.09729",
    "authors": [
      "Yilin Wen",
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.00655",
    "title": "RigNet++: Efficient Repetitive Image Guided Network for Depth Completion",
    "abstract": " Comments: 15 pages. arXiv admin note: text overlap with arXiv:2107.13802 ",
    "url": "https://arxiv.org/abs/2309.00655",
    "authors": [
      "Zhiqiang Yan",
      "Xiang Li",
      "Zhenyu Zhang",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01167",
    "title": "Symbolically integrating tensor networks over various random tensors by  the second version of Python RTNI",
    "abstract": " Comments: The title was slitely changed, typos were fixed. PyRTNI2 is available at this https URL ",
    "url": "https://arxiv.org/abs/2309.01167",
    "authors": [
      "Motohisa Fukuda"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2309.01632",
    "title": "Representing Edge Flows on Graphs via Sparse Cell Complexes",
    "abstract": " Comments: 9 pages, 6 figures (plus appendix). For evaluation code, see this https URL ",
    "url": "https://arxiv.org/abs/2309.01632",
    "authors": [
      "Josef Hoppe",
      "Michael T. Schaub"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.02852",
    "title": "CelticGraph: Drawing Graphs as Celtic Knots and Links",
    "abstract": " Comments: Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023) ",
    "url": "https://arxiv.org/abs/2309.02852",
    "authors": [
      "Peter Eades",
      "Niklas Gr\u00f6ne",
      "Karsten Klein",
      "Patrick Eades",
      "Leo Schreiber",
      "Ulf Hailer",
      "Falk Schreiber"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2309.04723",
    "title": "Frequency-Aware Self-Supervised Long-Tailed Learning",
    "abstract": " Comments: ICCV Workshop 2023 (Oral) ",
    "url": "https://arxiv.org/abs/2309.04723",
    "authors": [
      "Ci-Siang Lin",
      "Min-Hung Chen",
      "Yu-Chiang Frank Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.05499",
    "title": "Zero-Shot Co-salient Object Detection Framework",
    "abstract": " Title: Zero-Shot Co-salient Object Detection Framework ",
    "url": "https://arxiv.org/abs/2309.05499",
    "authors": [
      "Haoke Xiao",
      "Lv Tang",
      "Bo Li",
      "Zhiming Luo",
      "Shaozi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.05955",
    "title": "Trust-Region Neural Moving Horizon Estimation for Robots",
    "abstract": " Title: Trust-Region Neural Moving Horizon Estimation for Robots ",
    "url": "https://arxiv.org/abs/2309.05955",
    "authors": [
      "Bingheng Wang",
      "Xuyang Chen",
      "Lin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.06584",
    "title": "Explainable Graph Neural Network for Alzheimer's Disease And Related  Dementias Risk Prediction",
    "abstract": " Title: Explainable Graph Neural Network for Alzheimer's Disease And Related  Dementias Risk Prediction ",
    "url": "https://arxiv.org/abs/2309.06584",
    "authors": [
      "Xinyue Hu",
      "Zenan Sun",
      "Yi Nian",
      "Yifang Dang",
      "Fang Li",
      "Jingna Feng",
      "Evan Yu",
      "Cui Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.06800",
    "title": "Uncertainty-aware Traffic Prediction under Missing Data",
    "abstract": " Comments: 11 pages, 3 figures, Accepted as a short paper of IEEE International Conference on Data Mining (ICDM) 2023 ",
    "url": "https://arxiv.org/abs/2309.06800",
    "authors": [
      "Hao Mei",
      "Junxian Li",
      "Zhiming Liang",
      "Guanjie Zheng",
      "Bin Shi",
      "Hua Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07075",
    "title": "Chained-DP: Can We Recycle Privacy Budget?",
    "abstract": " Comments: The paper was accepted by IEEE/ACM IWQoS 2023 ",
    "url": "https://arxiv.org/abs/2309.07075",
    "authors": [
      "Jingyi Li",
      "Guangjing Huang",
      "Liekang Zeng",
      "Lin Chen",
      "Xu Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  }
]