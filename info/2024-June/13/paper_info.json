[
  {
    "id": "arXiv:2406.07556",
    "title": "Community Driven Approaches to Research in Technology & Society CCC Workshop Report",
    "abstract": "           Based on our workshop activities, we outlined three ways in which research can support community needs: (1) Mapping the ecosystem of both the players and ecosystem and harm landscapes, (2) Counter-Programming, which entails using the same surveillance tools that communities are subjected to observe the entities doing the surveilling, effectively protecting people from surveillance, and conducting ethical data collection to measure the impact of these technologies, and (3) Engaging in positive visions and tools for empowerment so that technology can bring good instead of harm. In order to effectively collaborate on the aforementioned directions, we outlined seven important mechanisms for effective collaboration: (1) Never expect free labor of community members, (2) Ensure goals are aligned between all collaborators, (3) Elevate community members to leadership positions, (4) Understand no group is a monolith, (5) Establish a common language, (6) Discuss organization roles and goals of the project transparently from the start, and (7) Enable a recourse for harm. We recommend that anyone engaging in community-based research (1) starts with community-defined solutions, (2) provides alternatives to digital services/information collecting mechanisms, (3) prohibits harmful automated systems, (4) transparently states any systems impact, (5) minimizes and protects data, (6) proactively demonstrates a system is safe and beneficial prior to deployment, and (7) provides resources directly to community partners. Throughout the recommendation section of the report, we also provide specific recommendations for funding agencies, academic institutions, and individual researchers.         ",
    "url": "https://arxiv.org/abs/2406.07556",
    "authors": [
      "Suresh Venkatasubramanian",
      "Timnit Gebru",
      "Ufuk Topcu",
      "Haley Griffin",
      "Leah Namisa Rosenbloom",
      "Nasim Sonboli"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2406.07566",
    "title": "Detection of Moving Objects in Earth Observation Satellite Images",
    "abstract": "           Moving objects have characteristic signatures in multi-spectral images made by Earth observation satellites that use push broom scanning. While the general concept is applicable to all satellites of this type, each satellite design has its own unique imaging system and requires unique methods to analyze the characteristic signatures. We assess the feasibility of detecting moving objects and measuring their velocities in one particular archive of satellite images made by Planet Labs Corporation with their constellation of SuperDove satellites. Planet Labs data presents a particular challenge in that the images in the archive are mosaics of individual exposures and therefore do not have unique time stamps. We explain how the timing information can be restored indirectly. Our results indicate that the movement of common transportation vehicles, airplanes, cars, and boats, can be detected and measured.         ",
    "url": "https://arxiv.org/abs/2406.07566",
    "authors": [
      "Eric Keto",
      "Wesley Andres Watters"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ]
  },
  {
    "id": "arXiv:2406.07574",
    "title": "Biharmonic Distance of Graphs and its Higher-Order Variants: Theoretical Properties with Applications to Centrality and Clustering",
    "abstract": "           Effective resistance is a distance between vertices of a graph that is both theoretically interesting and useful in applications. We study a variant of effective resistance called the biharmonic distance. While the effective resistance measures how well-connected two vertices are, we prove several theoretical results supporting the idea that the biharmonic distance measures how important an edge is to the global topology of the graph. Our theoretical results connect the biharmonic distance to well-known measures of connectivity of a graph like its total resistance and sparsity. Based on these results, we introduce two clustering algorithms using the biharmonic distance. Finally, we introduce a further generalization of the biharmonic distance that we call the $k$-harmonic distance. We empirically study the utility of biharmonic and $k$-harmonic distance for edge centrality and graph clustering.         ",
    "url": "https://arxiv.org/abs/2406.07574",
    "authors": [
      "Mitchell Black",
      "Lucy Lin",
      "Amir Nayyeri",
      "Weng-Keen Wong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07578",
    "title": "Individual Packet Features are a Risk to Model Generalisation in ML-Based Intrusion Detection",
    "abstract": "           Machine learning is increasingly used for intrusion detection in IoT networks. This paper explores the effectiveness of using individual packet features (IPF), which are attributes extracted from a single network packet, such as timing, size, and source-destination information. Through literature review and experiments, we identify the limitations of IPF, showing they can produce misleadingly high detection rates. Our findings emphasize the need for approaches that consider packet interactions for robust intrusion detection. Additionally, we demonstrate that models based on IPF often fail to generalize across datasets, compromising their reliability in diverse IoT environments.         ",
    "url": "https://arxiv.org/abs/2406.07578",
    "authors": [
      "Kahraman Kostas",
      "Mike Just",
      "Michael A. Lones"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2406.07580",
    "title": "DMS: Addressing Information Loss with More Steps for Pragmatic Adversarial Attacks",
    "abstract": "           Despite the exceptional performance of deep neural networks (DNNs) across different domains, they are vulnerable to adversarial samples, in particular for tasks related to computer vision. Such vulnerability is further influenced by the digital container formats used in computers, where the discrete numerical values are commonly used for storing the pixel values. This paper examines how information loss in file formats impacts the effectiveness of adversarial attacks. Notably, we observe a pronounced hindrance to the adversarial attack performance due to the information loss of the non-integer pixel values. To address this issue, we explore to leverage the gradient information of the attack samples within the model to mitigate the information loss. We introduce the Do More Steps (DMS) algorithm, which hinges on two core techniques: gradient ascent-based \\textit{adversarial integerization} (DMS-AI) and integrated gradients-based \\textit{attribution selection} (DMS-AS). Our goal is to alleviate such lossy process to retain the attack performance when storing these adversarial samples digitally. In particular, DMS-AI integerizes the non-integer pixel values according to the gradient direction, and DMS-AS selects the non-integer pixels by comparing attribution results. We conduct thorough experiments to assess the effectiveness of our approach, including the implementations of the DMS-AI and DMS-AS on two large-scale datasets with various latest gradient-based attack methods. Our empirical findings conclusively demonstrate the superiority of our proposed DMS-AI and DMS-AS pixel integerization methods over the standardised methods, such as rounding, truncating and upper approaches, in maintaining attack integrity.         ",
    "url": "https://arxiv.org/abs/2406.07580",
    "authors": [
      "Zhiyu Zhu",
      "Jiayu Zhang",
      "Xinyi Wang",
      "Zhibo Jin",
      "Huaming Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07595",
    "title": "VulDetectBench: Evaluating the Deep Capability of Vulnerability Detection with Large Language Models",
    "abstract": "           Large Language Models (LLMs) have training corpora containing large amounts of program code, greatly improving the model's code comprehension and generation capabilities. However, sound comprehensive research on detecting program vulnerabilities, a more specific task related to code, and evaluating the performance of LLMs in this more specialized scenario is still lacking. To address common challenges in vulnerability analysis, our study introduces a new benchmark, VulDetectBench, specifically designed to assess the vulnerability detection capabilities of LLMs. The benchmark comprehensively evaluates LLM's ability to identify, classify, and locate vulnerabilities through five tasks of increasing difficulty. We evaluate the performance of 17 models (both open- and closed-source) and find that while existing models can achieve over 80% accuracy on tasks related to vulnerability identification and classification, they still fall short on specific, more detailed vulnerability analysis tasks, with less than 30% accuracy, making it difficult to provide valuable auxiliary information for professional vulnerability mining. Our benchmark effectively evaluates the capabilities of various LLMs at different levels in the specific task of vulnerability detection, providing a foundation for future research and improvements in this critical area of code security. VulDetectBench is publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.07595",
    "authors": [
      "Yu Liu",
      "Mingxin Yang",
      "Yu Xie",
      "Ping Chen",
      "Xiaojin Zhang",
      "Wei Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2406.07596",
    "title": "Transforming Object-Centric Event Logs to Temporal Event Knowledge Graphs (Extended Version)",
    "abstract": "           Event logs play a fundamental role in enabling data-driven business process analysis. Traditionally, these logs track events related to a single object, known as the case, limiting the scope of analysis. Recent advancements, such as Object-Centric Event Logs (OCEL) and Event Knowledge Graphs (EKG), capture better how events relate to multiple objects. However, attributes of objects can change over time, which was not initially considered in OCEL or EKG. While OCEL 2.0 has addressed some of these limitations, there remains a research gap concerning how attribute changes should be accommodated in EKG and how OCEL 2.0 logs can be transformed into EKG. This paper fills this gap by introducing Temporal Event Knowledge Graphs (tEKG) and defining an algorithm to convert an OCEL 2.0 log to a tEKG.         ",
    "url": "https://arxiv.org/abs/2406.07596",
    "authors": [
      "Shahrzad Khayatbashi",
      "Olaf Hartig",
      "Amin Jalali"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2406.07640",
    "title": "When is an Embedding Model More Promising than Another?",
    "abstract": "           Embedders play a central role in machine learning, projecting any object into numerical representations that can, in turn, be leveraged to perform various downstream tasks. The evaluation of embedding models typically depends on domain-specific empirical approaches utilizing downstream tasks, primarily because of the lack of a standardized framework for comparison. However, acquiring adequately large and representative datasets for conducting these assessments is not always viable and can prove to be prohibitively expensive and time-consuming. In this paper, we present a unified approach to evaluate embedders. First, we establish theoretical foundations for comparing embedding models, drawing upon the concepts of sufficiency and informativeness. We then leverage these concepts to devise a tractable comparison criterion (information sufficiency), leading to a task-agnostic and self-supervised ranking procedure. We demonstrate experimentally that our approach aligns closely with the capability of embedding models to facilitate various downstream tasks in both natural language processing and molecular biology. This effectively offers practitioners a valuable tool for prioritizing model trials.         ",
    "url": "https://arxiv.org/abs/2406.07640",
    "authors": [
      "Maxime Darrin",
      "Philippe Formont",
      "Ismail Ben Ayed",
      "Jackie CK Cheung",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.07645",
    "title": "SSNVC: Single Stream Neural Video Compression with Implicit Temporal Information",
    "abstract": "           Recently, Neural Video Compression (NVC) techniques have achieved remarkable performance, even surpassing the best traditional lossy video codec. However, most existing NVC methods heavily rely on transmitting Motion Vector (MV) to generate accurate contextual features, which has the following drawbacks. (1) Compressing and transmitting MV requires specialized MV encoder and decoder, which makes modules redundant. (2) Due to the existence of MV Encoder-Decoder, the training strategy is complex. In this paper, we present a noval Single Stream NVC framework (SSNVC), which removes complex MV Encoder-Decoder structure and uses a one-stage training strategy. SSNVC implicitly use temporal information by adding previous entropy model feature to current entropy model and using previous two frame to generate predicted motion information at the decoder side. Besides, we enhance the frame generator to generate higher quality reconstructed frame. Experiments demonstrate that SSNVC can achieve state-of-the-art performance on multiple benchmarks, and can greatly simplify compression process as well as training process.         ",
    "url": "https://arxiv.org/abs/2406.07645",
    "authors": [
      "Feng Wang",
      "Haihang Ruan",
      "Zhihuang Xie",
      "Ronggang Wang",
      "Xiangyu Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2406.07666",
    "title": "A Unified Framework for Integer Programming Formulation of Graph Matching Problems",
    "abstract": "           Graph theory has been a powerful tool in solving difficult and complex problems arising in all disciplines. In particular, graph matching is a classical problem in pattern analysis with enormous applications. Many graph problems have been formulated as a mathematical program and then solved using exact, heuristic, and/or approximated-guaranteed procedures. On the other hand, graph theory has been a powerful tool in visualizing and understanding complex mathematical programming problems, especially integer programs. Formulating a graph problem as a natural integer program (IP) is often a challenging task. However, an IP formulation of the problem has many advantages. Several researchers have noted the need for natural IP formulation of graph theoretic problems. The present study aims to provide a unified framework for IP formulation of graph-matching problems. Although there are many surveys on graph matching problems, none is concerned with IP formulation. This paper is the first to provide a comprehensive IP formulation for such problems. The framework includes a variety of graph optimization problems in the literature. While these problems have been studied by different research communities, however, the framework presented here helps to bring efforts from different disciplines to tackle such diverse and complex problems. We hope the present study can significantly help to simplify some of the difficult problems arising in practice, especially in pattern analysis.         ",
    "url": "https://arxiv.org/abs/2406.07666",
    "authors": [
      "Bahram Alidaee",
      "Haibo Wang",
      "Hugh Sloan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2406.07674",
    "title": "Automated Pavement Cracks Detection and Classification Using Deep Learning",
    "abstract": "           Monitoring asset conditions is a crucial factor in building efficient transportation asset management. Because of substantial advances in image processing, traditional manual classification has been largely replaced by semi-automatic/automatic techniques. As a result, automated asset detection and classification techniques are required. This paper proposes a methodology to detect and classify roadway pavement cracks using the well-known You Only Look Once (YOLO) version five (YOLOv5) and version 8 (YOLOv8) algorithms. Experimental results indicated that the precision of pavement crack detection reaches up to 67.3% under different illumination conditions and image sizes. The findings of this study can assist highway agencies in accurately detecting and classifying asset conditions under different illumination conditions. This will reduce the cost and time that are associated with manual inspection, which can greatly reduce the cost of highway asset maintenance.         ",
    "url": "https://arxiv.org/abs/2406.07674",
    "authors": [
      "Selvia Nafaa",
      "Hafsa Essam",
      "Karim Ashour",
      "Doaa Emad",
      "Rana Mohamed",
      "Mohammed Elhenawy",
      "Huthaifa I. Ashqar",
      "Abdallah A. Hassan",
      "Taqwa I. Alhadidi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2406.07685",
    "title": "Out-Of-Context Prompting Boosts Fairness and Robustness in Large Language Model Predictions",
    "abstract": "           Frontier Large Language Models (LLMs) are increasingly being deployed for high-stakes decision-making. On the other hand, these models are still consistently making predictions that contradict users' or society's expectations, e.g., hallucinating, or discriminating. Thus, it is important that we develop test-time strategies to improve their trustworthiness. Inspired by prior work, we leverage causality as a tool to formally encode two aspects of trustworthiness in LLMs: fairness and robustness. Under this perspective, existing test-time solutions explicitly instructing the model to be fair or robust implicitly depend on the LLM's causal reasoning capabilities. In this work, we explore the opposite approach. Instead of explicitly asking the LLM for trustworthiness, we design prompts to encode the underlying causal inference algorithm that will, by construction, result in more trustworthy predictions. Concretely, we propose out-of-context prompting as a test-time solution to encourage fairness and robustness in LLMs. Out-of-context prompting leverages the user's prior knowledge of the task's causal model to apply (random) counterfactual transformations and improve the model's trustworthiness. Empirically, we show that out-of-context prompting consistently improves the fairness and robustness of frontier LLMs across five different benchmark datasets without requiring additional data, finetuning or pre-training.         ",
    "url": "https://arxiv.org/abs/2406.07685",
    "authors": [
      "Leonardo Cotta",
      "Chris J. Maddison"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.07687",
    "title": "Adversarial Machine Unlearning",
    "abstract": "           This paper focuses on the challenge of machine unlearning, aiming to remove the influence of specific training data on machine learning models. Traditionally, the development of unlearning algorithms runs parallel with that of membership inference attacks (MIA), a type of privacy threat to determine whether a data instance was used for training. However, the two strands are intimately connected: one can view machine unlearning through the lens of MIA success with respect to removed data. Recognizing this connection, we propose a game-theoretic framework that integrates MIAs into the design of unlearning algorithms. Specifically, we model the unlearning problem as a Stackelberg game in which an unlearner strives to unlearn specific training data from a model, while an auditor employs MIAs to detect the traces of the ostensibly removed data. Adopting this adversarial perspective allows the utilization of new attack advancements, facilitating the design of unlearning algorithms. Our framework stands out in two ways. First, it takes an adversarial approach and proactively incorporates the attacks into the design of unlearning algorithms. Secondly, it uses implicit differentiation to obtain the gradients that limit the attacker's success, thus benefiting the process of unlearning. We present empirical results to demonstrate the effectiveness of the proposed approach for machine unlearning.         ",
    "url": "https://arxiv.org/abs/2406.07687",
    "authors": [
      "Zonglin Di",
      "Sixie Yu",
      "Yevgeniy Vorobeychik",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2406.07688",
    "title": "AI Radiologist: Revolutionizing Liver Tissue Segmentation with Convolutional Neural Networks and a Clinician-Friendly GUI",
    "abstract": "           Artificial Intelligence (AI) is a pervasive research topic, permeating various sectors and applications. In this study, we harness the power of AI, specifically convolutional neural networks (ConvNets), for segmenting liver tissues. It also focuses on developing a user-friendly graphical user interface (GUI) tool, \"AI Radiologist\", enabling clinicians to effectively delineate different liver tissues (parenchyma, tumors, and vessels), thereby saving lives. This endeavor bridges the gap between academic research and practical, industrial applications. The GUI is a single-page application and is designed using the PyQt5 Python framework. The offline-available AI Radiologist resorts to three ConvNet models trained to segment all liver tissues. With respect to the Dice metric, the best liver ConvNet scores 98.16%, the best tumor ConvNet scores 65.95%, and the best vessel ConvNet scores 51.94%. It outputs 2D slices of the liver, tumors, and vessels, along with 3D interpolations in .obj and .mtl formats, which can be visualized/printed using any 3D-compatible software. Thus, the AI Radiologist offers a convenient tool for clinicians to perform liver tissue segmentation and 3D interpolation employing state-of-the-art models for tissues segmentation. With the provided capacity to select the volumes and pre-trained models, the clinicians can leave the rest to the AI Radiologist.         ",
    "url": "https://arxiv.org/abs/2406.07688",
    "authors": [
      "Ayman Al-Kababji",
      "Faycal Bensaali",
      "Sarada Prasad Dakua",
      "Yassine Himeur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07694",
    "title": "A PRISMA Driven Systematic Review of Publicly Available Datasets for Benchmark and Model Developments for Industrial Defect Detection",
    "abstract": "           Recent advancements in quality control across various industries have increasingly utilized the integration of video cameras and image processing for effective defect detection. A critical barrier to progress is the scarcity of comprehensive datasets featuring annotated defects, which are essential for developing and refining automated defect detection models. This systematic review, spanning from 2015 to 2023, identifies 15 publicly available datasets and critically examines them to assess their effectiveness and applicability for benchmarking and model development. Our findings reveal a diverse landscape of datasets, such as NEU-CLS, NEU-DET, DAGM, KolektorSDD, PCB Defect Dataset, and the Hollow Cylindrical Defect Detection Dataset, each with unique strengths and limitations in terms of image quality, defect type representation, and real-world applicability. The goal of this systematic review is to consolidate these datasets in a single location, providing researchers who seek such publicly available resources with a comprehensive reference.         ",
    "url": "https://arxiv.org/abs/2406.07694",
    "authors": [
      "Can Akbas",
      "Irem Su Arin",
      "Sinan Onal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07696",
    "title": "Sustainable self-supervised learning for speech representations",
    "abstract": "           Sustainable artificial intelligence focuses on data, hardware, and algorithms to make machine learning models more environmentally responsible. In particular, machine learning models for speech representations are computationally expensive, generating environmental concerns because of their high energy consumption. Thus, we propose a sustainable self-supervised model to learn speech representation, combining optimizations in neural layers and training to reduce computing costs. The proposed model improves over a resource-efficient baseline, reducing both memory usage and computing cost estimations. It pretrains using a single GPU in less than a day. On top of that, it improves the error rate performance of the baseline in downstream task evaluations. When comparing it to large speech representation approaches, there is an order of magnitude reduction in memory usage, while computing cost reductions represent almost three orders of magnitude improvement.         ",
    "url": "https://arxiv.org/abs/2406.07696",
    "authors": [
      "Luis Lugo",
      "Valentin Vielzeuf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2406.07710",
    "title": "Vehicle Speed Detection System Utilizing YOLOv8: Enhancing Road Safety and Traffic Management for Metropolitan Areas",
    "abstract": "           In order to ensure traffic safety through a reduction in fatalities and accidents, vehicle speed detection is essential. Relentless driving practices are discouraged by the enforcement of speed restrictions, which are made possible by accurate monitoring of vehicle speeds. Road accidents remain one of the leading causes of death in Bangladesh. The Bangladesh Passenger Welfare Association stated in 2023 that 7,902 individuals lost their lives in traffic accidents during the course of the year. Efficient vehicle speed detection is essential to maintaining traffic safety. Reliable speed detection can also help gather important traffic data, which makes it easier to optimize traffic flow and provide safer road infrastructure. The YOLOv8 model can recognize and track cars in videos with greater speed and accuracy when trained under close supervision. By providing insights into the application of supervised learning in object identification for vehicle speed estimation and concentrating on the particular traffic conditions and safety concerns in Bangladesh, this work represents a noteworthy contribution to the area. The MAE was 3.5 and RMSE was 4.22 between the predicted speed of our model and the actual speed or the ground truth measured by the speedometer Promising increased efficiency and wider applicability in a variety of traffic conditions, the suggested solution offers a financially viable substitute for conventional approaches.         ",
    "url": "https://arxiv.org/abs/2406.07710",
    "authors": [
      "SM Shaqib",
      "Alaya Parvin Alo",
      "Shahriar Sultan Ramit",
      "Afraz Ul Haque Rupak",
      "Sadman Sadik Khan",
      "Mr. Md. Sadekur Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.07727",
    "title": "Efficient Parallel Multi-Hop Reasoning: A Scalable Approach for Knowledge Graph Analysis",
    "abstract": "           Multi-hop reasoning (MHR) is a process in artificial intelligence and natural language processing where a system needs to make multiple inferential steps to arrive at a conclusion or answer. In the context of knowledge graphs or databases, it involves traversing multiple linked entities and relationships to understand complex queries or perform tasks requiring a deeper understanding. Multi-hop reasoning is a critical function in various applications, including question answering, knowledge base completion, and link prediction. It has garnered significant interest in artificial intelligence, machine learning, and graph analytics. This paper focuses on optimizing MHR for time efficiency on large-scale graphs, diverging from the traditional emphasis on accuracy which is an orthogonal goal. We introduce a novel parallel algorithm that harnesses domain-specific learned embeddings to efficiently identify the top K paths between vertices in a knowledge graph to find the best answers to a three-hop query. Our contributions are: (1) We present a new parallel algorithm to enhance MHR performance, scalability and efficiency. (2) We demonstrate the algorithm's superior performance on leading-edge Intel and AMD architectures through empirical results. We showcase the algorithm's practicality through a case study on identifying academic affiliations of potential Turing Award laureates in Deep Learning, highlighting its capability to handle intricate entity relationships. This demonstrates the potential of our approach to enabling high-performance MHR, useful to navigate the growing complexity of modern knowledge graphs.         ",
    "url": "https://arxiv.org/abs/2406.07727",
    "authors": [
      "Jesmin Jahan Tithi",
      "Fabio Checconi",
      "Fabrizio Petrini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2406.07730",
    "title": "\"It answers questions that I didn't know I had\": Ph.D. Students' Evaluation of an Information Sharing Knowledge Graph",
    "abstract": "           Interdisciplinary PhD programs can be challenging as the vital information needed by students may not be readily available, it is scattered across university's websites, while tacit knowledge can be obtained only by interacting with people. Hence, there is a need to develop a knowledge management model to create, query, and maintain a knowledge repository for interdisciplinary students. We propose a knowledge graph containing information on critical categories and their relationships, extracted from multiple sources, essential for interdisciplinary PhD students. This study evaluates the usability of a participatory designed knowledge graph intended to facilitate information exchange and decision-making. The usability findings demonstrate that interaction with this knowledge graph benefits PhD students by notably reducing uncertainty and academic stress, particularly among newcomers. Knowledge graph supported them in decision making, especially when choosing collaborators in an interdisciplinary setting. Key helpful features are related to exploring student faculty networks, milestones tracking, rapid access to aggregated data, and insights into crowdsourced fellow students' activities. The knowledge graph provides a solution to meet the personalized needs of doctoral researchers and has the potential to improve the information discovery and decision-making process substantially. It also includes the tacit knowledge exchange support missing from most current approaches, which is critical for this population and establishing interdisciplinary collaborations. This approach can be applied to other interdisciplinary programs and domains globally.         ",
    "url": "https://arxiv.org/abs/2406.07730",
    "authors": [
      "Stanislava Gardasevic",
      "Manika Lamba"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2406.07739",
    "title": "UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback",
    "abstract": "           Large language models (LLMs) struggle to consistently generate UI code that compiles and produces visually relevant designs. Existing approaches to improve generation rely on expensive human feedback or distilling a proprietary model. In this paper, we explore the use of automated feedback (compilers and multi-modal models) to guide LLMs to generate high-quality UI code. Our method starts with an existing LLM and iteratively produces improved models by self-generating a large synthetic dataset using an original model, applying automated tools to aggressively filter, score, and de-duplicate the data into a refined higher quality dataset. The original LLM is improved by finetuning on this refined dataset. We applied our approach to several open-source LLMs and compared the resulting performance to baseline models with both automated metrics and human preferences. Our evaluation shows the resulting models outperform all other downloadable baselines and approach the performance of larger proprietary models.         ",
    "url": "https://arxiv.org/abs/2406.07739",
    "authors": [
      "Jason Wu",
      "Eldon Schoop",
      "Alan Leung",
      "Titus Barik",
      "Jeffrey P. Bigham",
      "Jeffrey Nichols"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2406.07753",
    "title": "The MuSe 2024 Multimodal Sentiment Analysis Challenge: Social Perception and Humor Recognition",
    "abstract": "           The Multimodal Sentiment Analysis Challenge (MuSe) 2024 addresses two contemporary multimodal affect and sentiment analysis problems: In the Social Perception Sub-Challenge (MuSe-Perception), participants will predict 16 different social attributes of individuals such as assertiveness, dominance, likability, and sincerity based on the provided audio-visual data. The Cross-Cultural Humor Detection Sub-Challenge (MuSe-Humor) dataset expands upon the Passau Spontaneous Football Coach Humor (Passau-SFCH) dataset, focusing on the detection of spontaneous humor in a cross-lingual and cross-cultural setting. The main objective of MuSe 2024 is to unite a broad audience from various research domains, including multimodal sentiment analysis, audio-visual affective computing, continuous signal processing, and natural language processing. By fostering collaboration and exchange among experts in these fields, the MuSe 2024 endeavors to advance the understanding and application of sentiment analysis and affective computing across multiple modalities. This baseline paper provides details on each sub-challenge and its corresponding dataset, extracted features from each data modality, and discusses challenge baselines. For our baseline system, we make use of a range of Transformers and expert-designed features and train Gated Recurrent Unit (GRU)-Recurrent Neural Network (RNN) models on them, resulting in a competitive baseline system. On the unseen test datasets of the respective sub-challenges, it achieves a mean Pearson's Correlation Coefficient ($\\rho$) of 0.3573 for MuSe-Perception and an Area Under the Curve (AUC) value of 0.8682 for MuSe-Humor.         ",
    "url": "https://arxiv.org/abs/2406.07753",
    "authors": [
      "Shahin Amiriparian",
      "Lukas Christ",
      "Alexander Kathan",
      "Maurice Gerczuk",
      "Niklas M\u00fcller",
      "Steffen Klug",
      "Lukas Stappen",
      "Andreas K\u00f6nig",
      "Erik Cambria",
      "Bj\u00f6rn Schuller",
      "Simone Eulitz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2406.07770",
    "title": "DualBind: A Dual-Loss Framework for Protein-Ligand Binding Affinity Prediction",
    "abstract": "           Accurate prediction of protein-ligand binding affinities is crucial for drug development. Recent advances in machine learning show promising results on this task. However, these methods typically rely heavily on labeled data, which can be scarce or unreliable, or they rely on assumptions like Boltzmann-distributed data that may not hold true in practice. Here, we present DualBind, a novel framework that integrates supervised mean squared error (MSE) with unsupervised denoising score matching (DSM) to accurately learn the binding energy function. DualBind not only addresses the limitations of DSM-only models by providing more accurate absolute affinity predictions but also improves generalizability and reduces reliance on labeled data compared to MSE-only models. Our experimental results demonstrate that DualBind excels in predicting binding affinities and can effectively utilize both labeled and unlabeled data to enhance performance.         ",
    "url": "https://arxiv.org/abs/2406.07770",
    "authors": [
      "Meng Liu",
      "Saee Gopal Paliwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2406.07777",
    "title": "Unifying Interpretability and Explainability for Alzheimer's Disease Progression Prediction",
    "abstract": "           Reinforcement learning (RL) has recently shown promise in predicting Alzheimer's disease (AD) progression due to its unique ability to model domain knowledge. However, it is not clear which RL algorithms are well-suited for this task. Furthermore, these methods are not inherently explainable, limiting their applicability in real-world clinical scenarios. Our work addresses these two important questions. Using a causal, interpretable model of AD, we first compare the performance of four contemporary RL algorithms in predicting brain cognition over 10 years using only baseline (year 0) data. We then apply SHAP (SHapley Additive exPlanations) to explain the decisions made by each algorithm in the model. Our approach combines interpretability with explainability to provide insights into the key factors influencing AD progression, offering both global and individual, patient-level analysis. Our findings show that only one of the RL methods is able to satisfactorily model disease progression, but the post-hoc explanations indicate that all methods fail to properly capture the importance of amyloid accumulation, one of the pathological hallmarks of Alzheimer's disease. Our work aims to merge predictive accuracy with transparency, assisting clinicians and researchers in enhancing disease progression modeling for informed healthcare decisions. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.07777",
    "authors": [
      "Raja Farrukh Ali",
      "Stephanie Milani",
      "John Woods",
      "Emmanuel Adenij",
      "Ayesha Farooq",
      "Clayton Mansel",
      "Jeffrey Burns",
      "William Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07790",
    "title": "Hierarchical Neural Networks, p-Adic PDEs, and Applications to Image Processing",
    "abstract": "           The first goal of this article is to introduce a new type of p-adic reaction-diffusion cellular neural network with delay. We study the stability of these networks and provide numerical simulations of their responses. The second goal is to provide a quick review of the state of the art of p-adic cellular neural networks and their applications to image processing.         ",
    "url": "https://arxiv.org/abs/2406.07790",
    "authors": [
      "W. A. Z\u00fa\u00f1iga-Galindo",
      "B. A. Zambrano-Luna",
      "Baboucarr Dibba"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2406.07811",
    "title": "Evolutionary Computation and Explainable AI: A Roadmap to Transparent Intelligent Systems",
    "abstract": "           AI methods are finding an increasing number of applications, but their often black-box nature has raised concerns about accountability and trust. The field of explainable artificial intelligence (XAI) has emerged in response to the need for human understanding of AI models. Evolutionary computation (EC), as a family of powerful optimization and learning tools, has significant potential to contribute to XAI. In this paper, we provide an introduction to XAI and review various techniques in current use for explaining machine learning (ML) models. We then focus on how EC can be used in XAI, and review some XAI approaches which incorporate EC techniques. Additionally, we discuss the application of XAI principles within EC itself, examining how these principles can shed some light on the behavior and outcomes of EC algorithms in general, on the (automatic) configuration of these algorithms, and on the underlying problem landscapes that these algorithms optimize. Finally, we discuss some open challenges in XAI and opportunities for future research in this field using EC. Our aim is to demonstrate that EC is well-suited for addressing current problems in explainability and to encourage further exploration of these methods to contribute to the development of more transparent and trustworthy ML models and EC algorithms.         ",
    "url": "https://arxiv.org/abs/2406.07811",
    "authors": [
      "Ryan Zhou",
      "Jaume Bacardit",
      "Alexander Brownlee",
      "Stefano Cagnoni",
      "Martin Fyvie",
      "Giovanni Iacca",
      "John McCall",
      "Niki van Stein",
      "David Walker",
      "Ting Hu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07820",
    "title": "Are Objective Explanatory Evaluation metrics Trustworthy? An Adversarial Analysis",
    "abstract": "           Explainable AI (XAI) has revolutionized the field of deep learning by empowering users to have more trust in neural network models. The field of XAI allows users to probe the inner workings of these algorithms to elucidate their decision-making processes. The rise in popularity of XAI has led to the advent of different strategies to produce explanations, all of which only occasionally agree. Thus several objective evaluation metrics have been devised to decide which of these modules give the best explanation for specific scenarios. The goal of the paper is twofold: (i) we employ the notions of necessity and sufficiency from causal literature to come up with a novel explanatory technique called SHifted Adversaries using Pixel Elimination(SHAPE) which satisfies all the theoretical and mathematical criteria of being a valid explanation, (ii) we show that SHAPE is, infact, an adversarial explanation that fools causal metrics that are employed to measure the robustness and reliability of popular importance based visual XAI methods. Our analysis shows that SHAPE outperforms popular explanatory techniques like GradCAM and GradCAM++ in these tests and is comparable to RISE, raising questions about the sanity of these metrics and the need for human involvement for an overall better evaluation.         ",
    "url": "https://arxiv.org/abs/2406.07820",
    "authors": [
      "Prithwijit Chowdhury",
      "Mohit Prabhushankar",
      "Ghassan AlRegib",
      "Mohamed Deriche"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07823",
    "title": "PRoDeliberation: Parallel Robust Deliberation for End-to-End Spoken Language Understanding",
    "abstract": "           Spoken Language Understanding (SLU) is a critical component of voice assistants; it consists of converting speech to semantic parses for task execution. Previous works have explored end-to-end models to improve the quality and robustness of SLU models with Deliberation, however these models have remained autoregressive, resulting in higher latencies. In this work we introduce PRoDeliberation, a novel method leveraging a Connectionist Temporal Classification-based decoding strategy as well as a denoising objective to train robust non-autoregressive deliberation models. We show that PRoDeliberation achieves the latency reduction of parallel decoding (2-10x improvement over autoregressive models) while retaining the ability to correct Automatic Speech Recognition (ASR) mistranscriptions of autoregressive deliberation systems. We further show that the design of the denoising training allows PRoDeliberation to overcome the limitations of small ASR devices, and we provide analysis on the necessity of each component of the system.         ",
    "url": "https://arxiv.org/abs/2406.07823",
    "authors": [
      "Trang Le",
      "Daniel Lazar",
      "Suyoun Kim",
      "Shan Jiang",
      "Duc Le",
      "Adithya Sagar",
      "Aleksandr Livshits",
      "Ahmed Aly",
      "Akshat Shrivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.07828",
    "title": "Spatial Annealing Smoothing for Efficient Few-shot Neural Rendering",
    "abstract": "           Neural Radiance Fields (NeRF) with hybrid representations have shown impressive capabilities in reconstructing scenes for view synthesis, delivering high efficiency. Nonetheless, their performance significantly drops with sparse view inputs, due to the issue of overfitting. While various regularization strategies have been devised to address these challenges, they often depend on inefficient assumptions or are not compatible with hybrid models. There is a clear need for a method that maintains efficiency and improves resilience to sparse views within a hybrid framework. In this paper, we introduce an accurate and efficient few-shot neural rendering method named Spatial Annealing smoothing regularized NeRF (SANeRF), which is specifically designed for a pre-filtering-driven hybrid representation architecture. We implement an exponential reduction of the sample space size from an initially large value. This methodology is crucial for stabilizing the early stages of the training phase and significantly contributes to the enhancement of the subsequent process of detail refinement. Our extensive experiments reveal that, by adding merely one line of code, SANeRF delivers superior rendering quality and much faster reconstruction speed compared to current few-shot NeRF methods. Notably, SANeRF outperforms FreeNeRF by 0.3 dB in PSNR on the Blender dataset, while achieving 700x faster reconstruction speed.         ",
    "url": "https://arxiv.org/abs/2406.07828",
    "authors": [
      "Yuru Xiao",
      "Xianming Liu",
      "Deming Zhai",
      "Kui Jiang",
      "Junjun Jiang",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.07837",
    "title": "Scaling Manipulation Learning with Visual Kinematic Chain Prediction",
    "abstract": "           Learning general-purpose models from diverse datasets has achieved great success in machine learning. In robotics, however, existing methods in multi-task learning are typically constrained to a single robot and workspace, while recent work such as RT-X requires a non-trivial action normalization procedure to manually bridge the gap between different action spaces in diverse environments. In this paper, we propose the visual kinematics chain as a precise and universal representation of quasi-static actions for robot learning over diverse environments, which requires no manual adjustment since the visual kinematic chains can be automatically obtained from the robot's model and camera parameters. We propose the Visual Kinematics Transformer (VKT), a convolution-free architecture that supports an arbitrary number of camera viewpoints, and that is trained with a single objective of forecasting kinematic structures through optimal point-set matching. We demonstrate the superior performance of VKT over BC transformers as a general agent on Calvin, RLBench, Open-X, and real robot manipulation tasks. Video demonstrations can be found at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.07837",
    "authors": [
      "Xinyu Zhang",
      "Yuhan Liu",
      "Haonan Chang",
      "Abdeslam Boularias"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.07843",
    "title": "Incremental Learning and Self-Attention Mechanisms Improve Neural System Identification",
    "abstract": "           Convolutional neural networks (CNNs) have been shown to be the state-of-the-art approach for modeling the transfer functions of visual cortical neurons. Cortical neurons in the primary visual cortex are are sensitive to contextual information mediated by extensive horizontal and feedback connections. Standard CNNs can integrate global spatial image information to model such contextual modulation via two mechanisms: successive rounds of convolutions and a fully connected readout layer. In this paper, we find that non-local networks or self-attention (SA) mechanisms, theoretically related to context-dependent flexible gating mechanisms observed in the primary visual cortex, improve neural response predictions over parameter-matched CNNs in two key metrics: tuning curve correlation and tuning peak. We factorize networks to determine the relative contribution of each context mechanism. This reveals that information in the local receptive field is most important for modeling the overall tuning curve, but surround information is critically necessary for characterizing the tuning peak. We find that self-attention can replace subsequent spatial-integration convolutions when learned in an incremental manner, and is further enhanced in the presence of a fully connected readout layer, suggesting that the two context mechanisms are complementary. Finally, we find that learning a receptive-field-centric model with self-attention, before incrementally learning a fully connected readout, yields a more biologically realistic model in terms of center-surround contributions.         ",
    "url": "https://arxiv.org/abs/2406.07843",
    "authors": [
      "Isaac Lin",
      "Tianye Wang",
      "Shang Gao",
      "Shiming Tang",
      "Tai Sing Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2406.07848",
    "title": "Multi-agent Reinforcement Learning with Deep Networks for Diverse Q-Vectors",
    "abstract": "           Multi-agent reinforcement learning (MARL) has become a significant research topic due to its ability to facilitate learning in complex environments. In multi-agent tasks, the state-action value, commonly referred to as the Q-value, can vary among agents because of their individual rewards, resulting in a Q-vector. Determining an optimal policy is challenging, as it involves more than just maximizing a single Q-value. Various optimal policies, such as a Nash equilibrium, have been studied in this context. Algorithms like Nash Q-learning and Nash Actor-Critic have shown effectiveness in these scenarios. This paper extends this research by proposing a deep Q-networks (DQN) algorithm capable of learning various Q-vectors using Max, Nash, and Maximin strategies. The effectiveness of this approach is demonstrated in an environment where dual robotic arms collaborate to lift a pot.         ",
    "url": "https://arxiv.org/abs/2406.07848",
    "authors": [
      "Zhenglong Luo",
      "Zhiyong Chen",
      "James Welsh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2406.07854",
    "title": "Zero-Shot Fake Video Detection by Audio-Visual Consistency",
    "abstract": "           Recent studies have advocated the detection of fake videos as a one-class detection task, predicated on the hypothesis that the consistency between audio and visual modalities of genuine data is more significant than that of fake data. This methodology, which solely relies on genuine audio-visual data while negating the need for forged counterparts, is thus delineated as a `zero-shot' detection paradigm. This paper introduces a novel zero-shot detection approach anchored in content consistency across audio and video. By employing pre-trained ASR and VSR models, we recognize the audio and video content sequences, respectively. Then, the edit distance between the two sequences is computed to assess whether the claimed video is genuine. Experimental results indicate that, compared to two mainstream approaches based on semantic consistency and temporal consistency, our approach achieves superior generalizability across various deepfake techniques and demonstrates strong robustness against audio-visual perturbations. Finally, state-of-the-art performance gains can be achieved by simply integrating the decision scores of these three systems.         ",
    "url": "https://arxiv.org/abs/2406.07854",
    "authors": [
      "Xiaolou Li",
      "Zehua Liu",
      "Chen Chen",
      "Lantian Li",
      "Li Guo",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.07855",
    "title": "VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment",
    "abstract": "           With the help of discrete neural audio codecs, large language models (LLM) have increasingly been recognized as a promising methodology for zero-shot Text-to-Speech (TTS) synthesis. However, sampling based decoding strategies bring astonishing diversity to generation, but also pose robustness issues such as typos, omissions and repetition. In addition, the high sampling rate of audio also brings huge computational overhead to the inference process of autoregression. To address these issues, we propose VALL-E R, a robust and efficient zero-shot TTS system, building upon the foundation of VALL-E. Specifically, we introduce a phoneme monotonic alignment strategy to strengthen the connection between phonemes and acoustic sequence, ensuring a more precise alignment by constraining the acoustic tokens to match their associated phonemes. Furthermore, we employ a codec-merging approach to downsample the discrete codes in shallow quantization layer, thereby accelerating the decoding speed while preserving the high quality of speech output. Benefiting from these strategies, VALL-E R obtains controllablity over phonemes and demonstrates its strong robustness by approaching the WER of ground truth. In addition, it requires fewer autoregressive steps, with over 60% time reduction during inference. This research has the potential to be applied to meaningful projects, including the creation of speech for those affected by aphasia. Audio samples will be available at: this https URL.         ",
    "url": "https://arxiv.org/abs/2406.07855",
    "authors": [
      "Bing Han",
      "Long Zhou",
      "Shujie Liu",
      "Sanyuan Chen",
      "Lingwei Meng",
      "Yanming Qian",
      "Yanqing Liu",
      "Sheng Zhao",
      "Jinyu Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.07862",
    "title": "Self-Distillation Learning Based on Temporal-Spatial Consistency for Spiking Neural Networks",
    "abstract": "           Spiking neural networks (SNNs) have attracted considerable attention for their event-driven, low-power characteristics and high biological interpretability. Inspired by knowledge distillation (KD), recent research has improved the performance of the SNN model with a pre-trained teacher model. However, additional teacher models require significant computational resources, and it is tedious to manually define the appropriate teacher network architecture. In this paper, we explore cost-effective self-distillation learning of SNNs to circumvent these concerns. Without an explicit defined teacher, the SNN generates pseudo-labels and learns consistency during training. On the one hand, we extend the timestep of the SNN during training to create an implicit temporal ``teacher\" that guides the learning of the original ``student\", i.e., the temporal self-distillation. On the other hand, we guide the output of the weak classifier at the intermediate stage by the final output of the SNN, i.e., the spatial self-distillation. Our temporal-spatial self-distillation (TSSD) learning method does not introduce any inference overhead and has excellent generalization ability. Extensive experiments on the static image datasets CIFAR10/100 and ImageNet as well as the neuromorphic datasets CIFAR10-DVS and DVS-Gesture validate the superior performance of the TSSD method. This paper presents a novel manner of fusing SNNs with KD, providing insights into high-performance SNN learning methods.         ",
    "url": "https://arxiv.org/abs/2406.07862",
    "authors": [
      "Lin Zuo",
      "Yongqi Ding",
      "Mengmeng Jing",
      "Kunshan Yang",
      "Yunqian Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2406.07869",
    "title": "Unveiling the Power of Wavelets: A Wavelet-based Kolmogorov-Arnold Network for Hyperspectral Image Classification",
    "abstract": "           Hyperspectral image classification is a crucial but challenging task due to the high dimensionality and complex spatial-spectral correlations inherent in hyperspectral data. This paper employs Wavelet-based Kolmogorov-Arnold Network (wav-kan) architecture tailored for efficient modeling of these intricate dependencies. Inspired by the Kolmogorov-Arnold representation theorem, Wav-KAN incorporates wavelet functions as learnable activation functions, enabling non-linear mapping of the input spectral signatures. The wavelet-based activation allows Wav-KAN to effectively capture multi-scale spatial and spectral patterns through dilations and translations. Experimental evaluation on three benchmark hyperspectral datasets (Salinas, Pavia, Indian Pines) demonstrates the superior performance of Wav-KAN compared to traditional multilayer perceptrons (MLPs) and the recently proposed Spline-based KAN (Spline-KAN) model. In this work we are: (1) conducting more experiments on additional hyperspectral datasets (Pavia University, WHU-Hi, and Urban Hyperspectral Image) to further validate the generalizability of Wav-KAN; (2) developing a multiresolution Wav-KAN architecture to capture scale-invariant features; (3) analyzing the effect of dimensional reduction techniques on classification performance; (4) exploring optimization methods for tuning the hyperparameters of KAN models; and (5) comparing Wav-KAN with other state-of-the-art models in hyperspectral image classification.         ",
    "url": "https://arxiv.org/abs/2406.07869",
    "authors": [
      "Seyd Teymoor Seydi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.07873",
    "title": "Robust 3D Face Alignment with Multi-Path Neural Architecture Search",
    "abstract": "           3D face alignment is a very challenging and fundamental problem in computer vision. Existing deep learning-based methods manually design different networks to regress either parameters of a 3D face model or 3D positions of face vertices. However, designing such networks relies on expert knowledge, and these methods often struggle to produce consistent results across various face poses. To address this limitation, we employ Neural Architecture Search (NAS) to automatically discover the optimal architecture for 3D face alignment. We propose a novel Multi-path One-shot Neural Architecture Search (MONAS) framework that leverages multi-scale features and contextual information to enhance face alignment across various poses. The MONAS comprises two key algorithms: Multi-path Networks Unbiased Sampling Based Training and Simulated Annealing based Multi-path One-shot Search. Experimental results on three popular benchmarks demonstrate the superior performance of the MONAS for both sparse alignment and dense alignment.         ",
    "url": "https://arxiv.org/abs/2406.07873",
    "authors": [
      "Zhichao Jiang",
      "Hongsong Wang",
      "Xi Teng",
      "Baopu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.07886",
    "title": "Label-aware Hard Negative Sampling Strategies with Momentum Contrastive Learning for Implicit Hate Speech Detection",
    "abstract": "           Detecting implicit hate speech that is not directly hateful remains a challenge. Recent research has attempted to detect implicit hate speech by applying contrastive learning to pre-trained language models such as BERT and RoBERTa, but the proposed models still do not have a significant advantage over cross-entropy loss-based learning. We found that contrastive learning based on randomly sampled batch data does not encourage the model to learn hard negative samples. In this work, we propose Label-aware Hard Negative sampling strategies (LAHN) that encourage the model to learn detailed features from hard negative samples, instead of naive negative samples in random batch, using momentum-integrated contrastive learning. LAHN outperforms the existing models for implicit hate speech detection both in- and cross-datasets. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2406.07886",
    "authors": [
      "Jaehoon Kim",
      "Seungwan Jin",
      "Sohyun Park",
      "Someen Park",
      "Kyungsik Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2406.07900",
    "title": "Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations",
    "abstract": "           Recent advancements in Deep and Self-Supervised Learning (SSL) have led to substantial improvements in Speech Emotion Recognition (SER) performance, reaching unprecedented levels. However, obtaining sufficient amounts of accurately labeled data for training or fine-tuning the models remains a costly and challenging task. In this paper, we propose a multi-view SSL pre-training technique that can be applied to various representations of speech, including the ones generated by large speech models, to improve SER performance in scenarios where annotations are limited. Our experiments, based on wav2vec 2.0, spectral and paralinguistic features, demonstrate that the proposed framework boosts the SER performance, by up to 10% in Unweighted Average Recall, in settings with extremely sparse data annotations.         ",
    "url": "https://arxiv.org/abs/2406.07900",
    "authors": [
      "Bulat Khaertdinov",
      "Pedro Jeuris",
      "Annanda Sousa",
      "Enrique Hortal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.07915",
    "title": "Aggregation Design for Personalized Federated Multi-Modal Learning over Wireless Networks",
    "abstract": "           Federated Multi-Modal Learning (FMML) is an emerging field that integrates information from different modalities in federated learning to improve the learning performance. In this letter, we develop a parameter scheduling scheme to improve personalized performance and communication efficiency in personalized FMML, considering the non-independent and nonidentically distributed (non-IID) data along with the modality heterogeneity. Specifically, a learning-based approach is utilized to obtain the aggregation coefficients for parameters of different modalities on distinct devices. Based on the aggregation coefficients and channel state, a subset of parameters is scheduled to be uploaded to a server for each modality. Experimental results show that the proposed algorithm can effectively improve the personalized performance of FMML.         ",
    "url": "https://arxiv.org/abs/2406.07915",
    "authors": [
      "Benshun Yin",
      "Zhiyong Chen",
      "Meixia Tao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2406.07917",
    "title": "Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks",
    "abstract": "           Graph neural networks (GNNs) have become instrumental in diverse real-world applications, offering powerful graph learning capabilities for tasks such as social networks and medical data analysis. Despite their successes, GNNs are vulnerable to adversarial attacks, including membership inference attacks (MIA), which threaten privacy by identifying whether a record was part of the model's training data. While existing research has explored MIA in GNNs under graph inductive learning settings, the more common and challenging graph transductive learning setting remains understudied in this context. This paper addresses this gap and proposes an effective two-stage defense, Graph Transductive Defense (GTD), tailored to graph transductive learning characteristics. The gist of our approach is a combination of a train-test alternate training schedule and flattening strategy, which successfully reduces the difference between the training and testing loss distributions. Extensive empirical results demonstrate the superior performance of our method (a decrease in attack AUROC by $9.42\\%$ and an increase in utility performance by $18.08\\%$ on average compared to LBP), highlighting its potential for seamless integration into various classification models with minimal overhead.         ",
    "url": "https://arxiv.org/abs/2406.07917",
    "authors": [
      "Peizhi Niu",
      "Chao Pan",
      "Siheng Chen",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.07923",
    "title": "CTC-aligned Audio-Text Embedding for Streaming Open-vocabulary Keyword Spotting",
    "abstract": "           This paper introduces a novel approach for streaming openvocabulary keyword spotting (KWS) with text-based keyword enrollment. For every input frame, the proposed method finds the optimal alignment ending at the frame using connectionist temporal classification (CTC) and aggregates the frame-level acoustic embedding (AE) to obtain higher-level (i.e., character, word, or phrase) AE that aligns with the text embedding (TE) of the target keyword text. After that, we calculate the similarity of the aggregated AE and the TE. To the best of our knowledge, this is the first attempt to dynamically align the audio and the keyword text on-the-fly to attain the joint audio-text embedding for KWS. Despite operating in a streaming fashion, our approach achieves competitive performance on the LibriPhrase dataset compared to the non-streaming methods with a mere 155K model parameters and a decoding algorithm with time complexity O(U), where U is the length of the target keyword at inference time.         ",
    "url": "https://arxiv.org/abs/2406.07923",
    "authors": [
      "Sichen Jin",
      "Youngmoon Jung",
      "Seungjin Lee",
      "Jaeyoung Roh",
      "Changwoo Han",
      "Hoonyoung Cho"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.07926",
    "title": "Efficient Neural Common Neighbor for Temporal Graph Link Prediction",
    "abstract": "           Temporal graphs are ubiquitous in real-world scenarios, such as social network, trade and transportation. Predicting dynamic links between nodes in a temporal graph is of vital importance. Traditional methods usually leverage the temporal neighborhood of interaction history to generate node embeddings first and then aggregate the source and target node embeddings to predict the link. However, such methods focus on learning individual node representations, but overlook the pairwise representation learning nature of link prediction and fail to capture the important pairwise features of links such as common neighbors (CN). Motivated by the success of Neural Common Neighbor (NCN) for static graph link prediction, we propose TNCN, a temporal version of NCN for link prediction in temporal graphs. TNCN dynamically updates a temporal neighbor dictionary for each node, and utilizes multi-hop common neighbors between the source and target node to learn a more effective pairwise representation. We validate our model on five large-scale real-world datasets from the Temporal Graph Benchmark (TGB), and find that it achieves new state-of-the-art performance on three of them. Additionally, TNCN demonstrates excellent scalability on large datasets, outperforming popular GNN baselines by up to 6.4 times in speed. Our code is available at https: //github.com/GraphPKU/TNCN.         ",
    "url": "https://arxiv.org/abs/2406.07926",
    "authors": [
      "Xiaohui Zhang",
      "Yanbo Wang",
      "Xiyuan Wang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2406.07935",
    "title": "Defining and Detecting Vulnerability in Human Evaluation Guidelines: A Preliminary Study Towards Reliable NLG Evaluation",
    "abstract": "           Human evaluation serves as the gold standard for assessing the quality of Natural Language Generation (NLG) systems. Nevertheless, the evaluation guideline, as a pivotal element ensuring reliable and reproducible human assessment, has received limited attention.Our investigation revealed that only 29.84% of recent papers involving human evaluation at top conferences release their evaluation guidelines, with vulnerabilities identified in 77.09% of these guidelines. Unreliable evaluation guidelines can yield inaccurate assessment outcomes, potentially impeding the advancement of NLG in the right direction. To address these challenges, we take an initial step towards reliable evaluation guidelines and propose the first human evaluation guideline dataset by collecting annotations of guidelines extracted from existing papers as well as generated via Large Language Models (LLMs). We then introduce a taxonomy of eight vulnerabilities and formulate a principle for composing evaluation guidelines. Furthermore, a method for detecting guideline vulnerabilities has been explored using LLMs, and we offer a set of recommendations to enhance reliability in human evaluation. The annotated human evaluation guideline dataset and code for the vulnerability detection method are publicly available online.         ",
    "url": "https://arxiv.org/abs/2406.07935",
    "authors": [
      "Jie Ruan",
      "Wenqing Wang",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07936",
    "title": "Characterizing Unsafe Code Encapsulation In Real-world Rust Systems",
    "abstract": "           Interior unsafe is an essential design paradigm advocated by the Rust community in system software development. However, there is little official guidance or few best practices regarding how to encapsulate unsafe code and achieve interior unsafe. The problem is critical because the Rust compiler is incapable of verifying the soundness of a safe function containing unsafe code. Falsely declaring an interior unsafe function as safe may undermine the fundamental memory-safety guarantee of Rust. To address this issue, this paper studies how interior unsafe is achieved in practice, aiming to identify best practices to guide Rust code design concerning unsafe code encapsulation. Specifically, we propose a novel unsafety isolation graph to model the essential usage and encapsulation of unsafe code. Based on the graph, we further propose four major isolation types and nine structural patterns to split a graph into several small self-contained subgraphs. These subgraphs can serve as useful audit units for examining the soundness of unsafe code encapsulation. We applied our approach to four real-world Rust projects. The experimental results demonstrate that our method is effective in characterizing their encapsulation code. Additionally, we identified two common issues in these projects that could complicate soundness verification or incur unsoundness issues.         ",
    "url": "https://arxiv.org/abs/2406.07936",
    "authors": [
      "Zihao Rao",
      "Yiran Yang",
      "Hui Xu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2406.07937",
    "title": "IFTD: Image Feature Triangle Descriptor for Loop Detection in Driving Scenes",
    "abstract": "           In this work, we propose a fast and robust Image Feature Triangle Descriptor (IFTD) based on the STD method, aimed at improving the efficiency and accuracy of place recognition in driving scenarios. We extract keypoints from BEV projection image of point cloud and construct these keypoints into triangle descriptors. By matching these feature triangles, we achieved precise place recognition and calculated the 4-DOF pose estimation between two keyframes. Furthermore, we employ image similarity inspection to perform the final place recognition. Experimental results on three public datasets demonstrate that our IFTD can achieve greater robustness and accuracy than state-of-the-art methods with low computational overhead.         ",
    "url": "https://arxiv.org/abs/2406.07937",
    "authors": [
      "Fengtian Lang",
      "Ruiye Ming",
      "Zikang Yuan",
      "Xin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2406.07946",
    "title": "Elevator: Self-* and Persistent Hub Sampling Service in Unstructured Peer-to-Peer Networks",
    "abstract": "           We present Elevator, a novel algorithm for hub samplingin peer-to-peer networks, enabling the construction of overlays with atopology between a random graph and a star network, and networksthat have both hubs and are resilient to failures. Our approach emergesfrom principles of preferential attachment, forming hubs spontaneously,offering an innovative solution for decentralized networks that can benefituse cases requiring a network with both low diameter and resilience tofailures.         ",
    "url": "https://arxiv.org/abs/2406.07946",
    "authors": [
      "Mohamed Amine Legheraba",
      "Maria Potop-Butucaru",
      "S\u00e9bastien Tixeuil"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2406.07951",
    "title": "DemosaicFormer: Coarse-to-Fine Demosaicing Network for HybridEVS Camera",
    "abstract": "           Hybrid Event-Based Vision Sensor (HybridEVS) is a novel sensor integrating traditional frame-based and event-based sensors, offering substantial benefits for applications requiring low-light, high dynamic range, and low-latency environments, such as smartphones and wearable devices. Despite its potential, the lack of Image signal processing (ISP) pipeline specifically designed for HybridEVS poses a significant challenge. To address this challenge, in this study, we propose a coarse-to-fine framework named DemosaicFormer which comprises coarse demosaicing and pixel correction. Coarse demosaicing network is designed to produce a preliminary high-quality estimate of the RGB image from the HybridEVS raw data while the pixel correction network enhances the performance of image restoration and mitigates the impact of defective pixels. Our key innovation is the design of a Multi-Scale Gating Module (MSGM) applying the integration of cross-scale features, which allows feature information to flow between different scales. Additionally, the adoption of progressive training and data augmentation strategies further improves model's robustness and effectiveness. Experimental results show superior performance against the existing methods both qualitatively and visually, and our DemosaicFormer achieves the best performance in terms of all the evaluation metrics in the MIPI 2024 challenge on Demosaic for Hybridevs Camera. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.07951",
    "authors": [
      "Senyan Xu",
      "Zhijing Sun",
      "Jiaying Zhu",
      "Yurui Zhu",
      "Xueyang Fu",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.07955",
    "title": "How Interpretable Are Interpretable Graph Neural Networks?",
    "abstract": "           Interpretable graph neural networks (XGNNs ) are widely adopted in various scientific applications involving graph-structured data. Existing XGNNs predominantly adopt the attention-based mechanism to learn edge or node importance for extracting and making predictions with the interpretable subgraph. However, the representational properties and limitations of these methods remain inadequately explored. In this work, we present a theoretical framework that formulates interpretable subgraph learning with the multilinear extension of the subgraph distribution, coined as subgraph multilinear extension (SubMT). Extracting the desired interpretable subgraph requires an accurate approximation of SubMT, yet we find that the existing XGNNs can have a huge gap in fitting SubMT. Consequently, the SubMT approximation failure will lead to the degenerated interpretability of the extracted subgraphs. To mitigate the issue, we design a new XGNN architecture called Graph Multilinear neT (GMT), which is provably more powerful in approximating SubMT. We empirically validate our theoretical findings on a number of graph classification benchmarks. The results demonstrate that GMT outperforms the state-of-the-art up to 10% in terms of both interpretability and generalizability across 12 regular and geometric graph benchmarks.         ",
    "url": "https://arxiv.org/abs/2406.07955",
    "authors": [
      "Yongqiang Chen",
      "Yatao Bian",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2406.07961",
    "title": "Accurate Explanation Model for Image Classifiers using Class Association Embedding",
    "abstract": "           Image classification is a primary task in data analysis where explainable models are crucially demanded in various applications. Although amounts of methods have been proposed to obtain explainable knowledge from the black-box classifiers, these approaches lack the efficiency of extracting global knowledge regarding the classification task, thus is vulnerable to local traps and often leads to poor accuracy. In this study, we propose a generative explanation model that combines the advantages of global and local knowledge for explaining image classifiers. We develop a representation learning method called class association embedding (CAE), which encodes each sample into a pair of separated class-associated and individual codes. Recombining the individual code of a given sample with altered class-associated code leads to a synthetic real-looking sample with preserved individual characters but modified class-associated features and possibly flipped class assignments. A building-block coherency feature extraction algorithm is proposed that efficiently separates class-associated features from individual ones. The extracted feature space forms a low-dimensional manifold that visualizes the classification decision patterns. Explanation on each individual sample can be then achieved in a counter-factual generation manner which continuously modifies the sample in one direction, by shifting its class-associated code along a guided path, until its classification outcome is changed. We compare our method with state-of-the-art ones on explaining image classification tasks in the form of saliency maps, demonstrating that our method achieves higher accuracies. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.07961",
    "authors": [
      "Ruitao Xie",
      "Jingbang Chen",
      "Limai Jiang",
      "Rui Xiao",
      "Yi Pan",
      "Yunpeng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.07966",
    "title": "Real-world Image Dehazing with Coherence-based Label Generator and Cooperative Unfolding Network",
    "abstract": "           Real-world Image Dehazing (RID) aims to alleviate haze-induced degradation in real-world settings. This task remains challenging due to the complexities in accurately modeling real haze distributions and the scarcity of paired real-world data. To address these challenges, we first introduce a cooperative unfolding network that jointly models atmospheric scattering and image scenes, effectively integrating physical knowledge into deep networks to restore haze-contaminated details. Additionally, we propose the first RID-oriented iterative mean-teacher framework, termed the Coherence-based Label Generator, to generate high-quality pseudo labels for network training. Specifically, we provide an optimal label pool to store the best pseudo-labels during network training, leveraging both global and local coherence to select high-quality candidates and assign weights to prioritize haze-free regions. We verify the effectiveness of our method, with experiments demonstrating that it achieves state-of-the-art performance on RID tasks. Code will be available at \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2406.07966",
    "authors": [
      "Chengyu Fang",
      "Chunming He",
      "Fengyang Xiao",
      "Yulun Zhang",
      "Longxiang Tang",
      "Yuelin Zhang",
      "Kai Li",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.07973",
    "title": "Unique Security and Privacy Threats of Large Language Model: A Comprehensive Survey",
    "abstract": "           With the rapid development of artificial intelligence, large language models (LLMs) have made remarkable progress in natural language processing. These models are trained on large amounts of data to demonstrate powerful language understanding and generation capabilities for various applications, from machine translation and chatbots to agents. However, LLMs have exposed a variety of privacy and security issues during their life cycle, which have become the focus of academic and industrial attention. Moreover, these risks LLMs face are pretty different from previous traditional language models. Since current surveys lack a clear taxonomy of unique threat models based on diverse scenarios, we highlight unique privacy and security issues based on five scenarios: pre-training, fine-tuning, RAG system, deploying, and LLM-based agent. Concerning the characteristics of each risk, this survey provides potential threats and countermeasures. The research on attack and defense situations LLMs face can provide feasible research directions, making more areas reap LLMs' benefits.         ",
    "url": "https://arxiv.org/abs/2406.07973",
    "authors": [
      "Shang Wang",
      "Tianqing Zhu",
      "Bo Liu",
      "Ding Ming",
      "Xu Guo",
      "Dayong Ye",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2406.07976",
    "title": "Multivariate Log-based Anomaly Detection for Distributed Database",
    "abstract": "           Distributed databases are fundamental infrastructures of today's large-scale software systems such as cloud systems. Detecting anomalies in distributed databases is essential for maintaining software availability. Existing approaches, predominantly developed using Loghub-a comprehensive collection of log datasets from various systems-lack datasets specifically tailored to distributed databases, which exhibit unique anomalies. Additionally, there's a notable absence of datasets encompassing multi-anomaly, multi-node logs. Consequently, models built upon these datasets, primarily designed for standalone systems, are inadequate for distributed databases, and the prevalent method of deeming an entire cluster anomalous based on irregularities in a single node leads to a high false-positive rate. This paper addresses the unique anomalies and multivariate nature of logs in distributed databases. We expose the first open-sourced, comprehensive dataset with multivariate logs from distributed databases. Utilizing this dataset, we conduct an extensive study to identify multiple database anomalies and to assess the effectiveness of state-of-the-art anomaly detection using multivariate log data. Our findings reveal that relying solely on logs from a single node is insufficient for accurate anomaly detection on distributed database. Leveraging these insights, we propose MultiLog, an innovative multivariate log-based anomaly detection approach tailored for distributed databases. Our experiments, based on this novel dataset, demonstrate MultiLog's superiority, outperforming existing state-of-the-art methods by approximately 12%.         ",
    "url": "https://arxiv.org/abs/2406.07976",
    "authors": [
      "Lingzhe Zhang",
      "Tong Jia",
      "Mengxi Jia",
      "Ying Li",
      "Yong Yang",
      "Zhonghai Wu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2406.07979",
    "title": "Heuristic Learning with Graph Neural Networks: A Unified Framework for Link Prediction",
    "abstract": "           Link prediction is a fundamental task in graph learning, inherently shaped by the topology of the graph. While traditional heuristics are grounded in graph topology, they encounter challenges in generalizing across diverse graphs. Recent research efforts have aimed to leverage the potential of heuristics, yet a unified formulation accommodating both local and global heuristics remains undiscovered. Drawing insights from the fact that both local and global heuristics can be represented by adjacency matrix multiplications, we propose a unified matrix formulation to accommodate and generalize various heuristics. We further propose the Heuristic Learning Graph Neural Network (HL-GNN) to efficiently implement the formulation. HL-GNN adopts intra-layer propagation and inter-layer connections, allowing it to reach a depth of around 20 layers with lower time complexity than GCN. HL-GNN is proven to be more expressive than heuristics and conventional GNNs, and it can adaptively trade-off between node features and topological information. Extensive experiments on the Planetoid, Amazon, and OGB datasets underscore the effectiveness and efficiency of HL-GNN. It outperforms existing methods by a large margin in prediction performance. Additionally, HL-GNN is several orders of magnitude faster than heuristic-inspired methods while requiring only a few trainable parameters. The case study further demonstrates that the generalized heuristics and learned weights are highly interpretable.         ",
    "url": "https://arxiv.org/abs/2406.07979",
    "authors": [
      "Juzhen Zhang",
      "Lanning Wei",
      "Zhen Xu",
      "Quanming Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07980",
    "title": "Reinforcement Learning for High-Level Strategic Control in Tower Defense Games",
    "abstract": "           In strategy games, one of the most important aspects of game design is maintaining a sense of challenge for players. Many mobile titles feature quick gameplay loops that allow players to progress steadily, requiring an abundance of levels and puzzles to prevent them from reaching the end too quickly. As with any content creation, testing and validation are essential to ensure engaging gameplay mechanics, enjoyable game assets, and playable levels. In this paper, we propose an automated approach that can be leveraged for gameplay testing and validation that combines traditional scripted methods with reinforcement learning, reaping the benefits of both approaches while adapting to new situations similarly to how a human player would. We test our solution on a popular tower defense game, Plants vs. Zombies. The results show that combining a learned approach, such as reinforcement learning, with a scripted AI produces a higher-performing and more robust agent than using only heuristic AI, achieving a 57.12% success rate compared to 47.95% in a set of 40 levels. Moreover, the results demonstrate the difficulty of training a general agent for this type of puzzle-like game.         ",
    "url": "https://arxiv.org/abs/2406.07980",
    "authors": [
      "Joakim Bergdahl",
      "Alessandro Sestini",
      "Linus Gissl\u00e9n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07983",
    "title": "Meta-Learning Neural Procedural Biases",
    "abstract": "           The goal of few-shot learning is to generalize and achieve high performance on new unseen learning tasks, where each task has only a limited number of examples available. Gradient-based meta-learning attempts to address this challenging task by learning how to learn new tasks by embedding inductive biases informed by prior learning experiences into the components of the learning algorithm. In this work, we build upon prior research and propose Neural Procedural Bias Meta-Learning (NPBML), a novel framework designed to meta-learn task-adaptive procedural biases. Our approach aims to consolidate recent advancements in meta-learned initializations, optimizers, and loss functions by learning them simultaneously and making them adapt to each individual task to maximize the strength of the learned inductive biases. This imbues each learning task with a unique set of procedural biases which is specifically designed and selected to attain strong learning performance in only a few gradient steps. The experimental results show that by meta-learning the procedural biases of a neural network, we can induce strong inductive biases towards a distribution of learning tasks, enabling robust learning performance across many well-established few-shot learning benchmarks.         ",
    "url": "https://arxiv.org/abs/2406.07983",
    "authors": [
      "Christian Raymond",
      "Qi Chen",
      "Bing Xue",
      "Mengjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08009",
    "title": "OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding",
    "abstract": "           In recent years, there has been a surge of interest in open-vocabulary 3D scene reconstruction facilitated by visual language models (VLMs), which showcase remarkable capabilities in open-set retrieval. However, existing methods face some limitations: they either focus on learning point-wise features, resulting in blurry semantic understanding, or solely tackle object-level reconstruction, thereby overlooking the intricate details of the object's interior. To address these challenges, we introduce OpenObj, an innovative approach to build open-vocabulary object-level Neural Radiance Fields (NeRF) with fine-grained understanding. In essence, OpenObj establishes a robust framework for efficient and watertight scene modeling and comprehension at the object-level. Moreover, we incorporate part-level features into the neural fields, enabling a nuanced representation of object interiors. This approach captures object-level instances while maintaining a fine-grained understanding. The results on multiple datasets demonstrate that OpenObj achieves superior performance in zero-shot semantic segmentation and retrieval tasks. Additionally, OpenObj supports real-world robotics tasks at multiple scales, including global movement and local manipulation.         ",
    "url": "https://arxiv.org/abs/2406.08009",
    "authors": [
      "Yinan Deng",
      "Jiahui Wang",
      "Jingyu Zhao",
      "Jianyu Dou",
      "Yi Yang",
      "Yufeng Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2406.08020",
    "title": "Generalizable Disaster Damage Assessment via Change Detection with Vision Foundation Model",
    "abstract": "           The increasing frequency and intensity of natural disasters demand more sophisticated approaches for rapid and precise damage assessment. To tackle this issue, researchers have developed various methods on disaster benchmark datasets from satellite imagery to aid in detecting disaster damage. However, the diverse nature of geographical landscapes and disasters makes it challenging to apply existing methods to regions unseen during training. We present DAVI (Disaster Assessment with VIsion foundation model), which overcomes domain disparities and detects structural damage (e.g., building) without requiring ground-truth labels of the target region. DAVI integrates task-specific knowledge from a model trained on source regions with an image segmentation foundation model to generate pseudo labels of possible damage in the target region. It then employs a two-stage refinement process, targeting both the pixel and overall image, to more accurately pinpoint changes in disaster-struck areas based on before-and-after images. Comprehensive evaluations demonstrate that DAVI achieves exceptional performance across diverse terrains (e.g., USA and Mexico) and disaster types (e.g., wildfires, hurricanes, and earthquakes). This confirms its robustness in assessing disaster impact without dependence on ground-truth labels.         ",
    "url": "https://arxiv.org/abs/2406.08020",
    "authors": [
      "Kyeongjin Ahn",
      "Sungwon Han",
      "Sungwon Park",
      "Jihee Kim",
      "Sangyoon Park",
      "Meeyoung Cha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08042",
    "title": "Efficient Network Traffic Feature Sets for IoT Intrusion Detection",
    "abstract": "           The use of Machine Learning (ML) models in cybersecurity solutions requires high-quality data that is stripped of redundant, missing, and noisy information. By selecting the most relevant features, data integrity and model efficiency can be significantly improved. This work evaluates the feature sets provided by a combination of different feature selection methods, namely Information Gain, Chi-Squared Test, Recursive Feature Elimination, Mean Absolute Deviation, and Dispersion Ratio, in multiple IoT network datasets. The influence of the smaller feature sets on both the classification performance and the training time of ML models is compared, with the aim of increasing the computational efficiency of IoT intrusion detection. Overall, the most impactful features of each dataset were identified, and the ML models obtained higher computational efficiency while preserving a good generalization, showing little to no difference between the sets.         ",
    "url": "https://arxiv.org/abs/2406.08042",
    "authors": [
      "Miguel Silva",
      "Jo\u00e3o Vitorino",
      "Eva Maia",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2406.08045",
    "title": "A novel approach to graph distinction through GENEOs and permutants",
    "abstract": "           The theory of Group Equivariant Non-Expansive Operators (GENEOs) was initially developed in Topological Data Analysis for the geometric approximation of data observers, including their invariances and symmetries. This paper departs from that line of research and explores the use of GENEOs for distinguishing $r$-regular graphs up to isomorphisms. In doing so, we aim to test the capabilities and flexibility of these operators. Our experiments show that GENEOs offer a good compromise between efficiency and computational cost in comparing $r$-regular graphs, while their actions on data are easily interpretable. This supports the idea that GENEOs could be a general-purpose approach to discriminative problems in Machine Learning when some structural information about data and observers is explicitly given.         ",
    "url": "https://arxiv.org/abs/2406.08045",
    "authors": [
      "Giovanni Bocchi",
      "Massimo Ferri",
      "Patrizio Frosini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Group Theory (math.GR)"
    ]
  },
  {
    "id": "arXiv:2406.08046",
    "title": "A Robust Pipeline for Classification and Detection of Bleeding Frames in Wireless Capsule Endoscopy using Swin Transformer and RT-DETR",
    "abstract": "           In this paper, we present our approach to the Auto WCEBleedGen Challenge V2 2024. Our solution combines the Swin Transformer for the initial classification of bleeding frames and RT-DETR for further detection of bleeding in Wireless Capsule Endoscopy (WCE), enhanced by a series of image preprocessing steps. These steps include converting images to Lab colour space, applying Contrast Limited Adaptive Histogram Equalization (CLAHE) for better contrast, and using Gaussian blur to suppress artefacts. The Swin Transformer utilizes a tiered architecture with shifted windows to efficiently manage self-attention calculations, focusing on local windows while enabling cross-window interactions. RT-DETR features an efficient hybrid encoder for fast processing of multi-scale features and an uncertainty-minimal query selection for enhanced accuracy. The class activation maps by Ablation-CAM are plausible to the model's decisions. On the validation set, this approach achieves a classification accuracy of 98.5% (best among the other state-of-the-art models) compared to 91.7% without any pre-processing and an $\\text{AP}_{50}$ of 66.7% compared to 65.0% with state-of-the-art YOLOv8. On the test set, this approach achieves a classification accuracy and F1 score of 87.0% and 89.0% respectively.         ",
    "url": "https://arxiv.org/abs/2406.08046",
    "authors": [
      "Sasidhar Alavala",
      "Anil Kumar Vadde",
      "Aparnamala Kancheti",
      "Subrahmanyam Gorthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2406.08050",
    "title": "Adversarial Evasion Attack Efficiency against Large Language Models",
    "abstract": "           Large Language Models (LLMs) are valuable for text classification, but their vulnerabilities must not be disregarded. They lack robustness against adversarial examples, so it is pertinent to understand the impacts of different types of perturbations, and assess if those attacks could be replicated by common users with a small amount of perturbations and a small number of queries to a deployed LLM. This work presents an analysis of the effectiveness, efficiency, and practicality of three different types of adversarial attacks against five different LLMs in a sentiment classification task. The obtained results demonstrated the very distinct impacts of the word-level and character-level attacks. The word attacks were more effective, but the character and more constrained attacks were more practical and required a reduced number of perturbations and queries. These differences need to be considered during the development of adversarial defense strategies to train more robust LLMs for intelligent text classification applications.         ",
    "url": "https://arxiv.org/abs/2406.08050",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Eva Maia",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08052",
    "title": "FakeSound: Deepfake General Audio Detection",
    "abstract": "           With the advancement of audio generation, generative models can produce highly realistic audios. However, the proliferation of deepfake general audio can pose negative consequences. Therefore, we propose a new task, deepfake general audio detection, which aims to identify whether audio content is manipulated and to locate deepfake regions. Leveraging an automated manipulation pipeline, a dataset named FakeSound for deepfake general audio detection is proposed, and samples can be viewed on website this https URL. The average binary accuracy of humans on all test sets is consistently below 0.6, which indicates the difficulty humans face in discerning deepfake audio and affirms the efficacy of the FakeSound dataset. A deepfake detection model utilizing a general audio pre-trained model is proposed as a benchmark system. Experimental results demonstrate that the performance of the proposed model surpasses the state-of-the-art in deepfake speech detection and human testers.         ",
    "url": "https://arxiv.org/abs/2406.08052",
    "authors": [
      "Zeyu Xie",
      "Baihan Li",
      "Xuenan Xu",
      "Zheng Liang",
      "Kai Yu",
      "Mengyue Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.08055",
    "title": "Learning Job Title Representation from Job Description Aggregation Network",
    "abstract": "           Learning job title representation is a vital process for developing automatic human resource tools. To do so, existing methods primarily rely on learning the title representation through skills extracted from the job description, neglecting the rich and diverse content within. Thus, we propose an alternative framework for learning job titles through their respective job description (JD) and utilize a Job Description Aggregator component to handle the lengthy description and bidirectional contrastive loss to account for the bidirectional relationship between the job title and its description. We evaluated the performance of our method on both in-domain and out-of-domain settings, achieving a superior performance over the skill-based approach.         ",
    "url": "https://arxiv.org/abs/2406.08055",
    "authors": [
      "Napat Laosaengpha",
      "Thanit Tativannarat",
      "Chawan Piansaddhayanon",
      "Attapol Rutherford",
      "Ekapol Chuangsuwanich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2406.08063",
    "title": "MWIRSTD: A MWIR Small Target Detection Dataset",
    "abstract": "           This paper presents a novel mid-wave infrared (MWIR) small target detection dataset (MWIRSTD) comprising 14 video sequences containing approximately 1053 images with annotated targets of three distinct classes of small objects. Captured using cooled MWIR imagers, the dataset offers a unique opportunity for researchers to develop and evaluate state-of-the-art methods for small object detection in realistic MWIR scenes. Unlike existing datasets, which primarily consist of uncooled thermal images or synthetic data with targets superimposed onto the background or vice versa, MWIRSTD provides authentic MWIR data with diverse targets and environments. Extensive experiments on various traditional methods and deep learning-based techniques for small target detection are performed on the proposed dataset, providing valuable insights into their efficacy. The dataset and code are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08063",
    "authors": [
      "Nikhil Kumar",
      "Avinash Upadhyay",
      "Shreya Sharma",
      "Manoj Sharma",
      "Pravendra Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08071",
    "title": "US College Net Price Prediction Comparing ML Regression Models",
    "abstract": "           This paper will illustrate the usage of Machine Learning algorithms on US College Scorecard datasets. For this paper, we will use our knowledge, research, and development of a predictive model to compare the results of all the models and predict the public and private net prices. This paper focuses on analyzing US College Scorecard data from data published on government websites. Our goal is to use four machine learning regression models to develop a predictive model to forecast the equitable net cost for every college, encompassing both public institutions and private, whether for-profit or nonprofit.         ",
    "url": "https://arxiv.org/abs/2406.08071",
    "authors": [
      "Zalak Patel",
      "Ayushi Porwal",
      "Kajal Bhandare",
      "Jongwook Woo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2406.08075",
    "title": "Balancing Molecular Information and Empirical Data in the Prediction of Physico-Chemical Properties",
    "abstract": "           Predicting the physico-chemical properties of pure substances and mixtures is a central task in thermodynamics. Established prediction methods range from fully physics-based ab-initio calculations, which are only feasible for very simple systems, over descriptor-based methods that use some information on the molecules to be modeled together with fitted model parameters (e.g., quantitative-structure-property relationship methods or classical group contribution methods), to representation-learning methods, which may, in extreme cases, completely ignore molecular descriptors and extrapolate only from existing data on the property to be modeled (e.g., matrix completion methods). In this work, we propose a general method for combining molecular descriptors with representation learning using the so-called expectation maximization algorithm from the probabilistic machine learning literature, which uses uncertainty estimates to trade off between the two approaches. The proposed hybrid model exploits chemical structure information using graph neural networks, but it automatically detects cases where structure-based predictions are unreliable, in which case it corrects them by representation-learning based predictions that can better specialize to unusual cases. The effectiveness of the proposed method is demonstrated using the prediction of activity coefficients in binary mixtures as an example. The results are compelling, as the method significantly improves predictive accuracy over the current state of the art, showcasing its potential to advance the prediction of physico-chemical properties in general.         ",
    "url": "https://arxiv.org/abs/2406.08075",
    "authors": [
      "Johannes Zenn",
      "Dominik Gond",
      "Fabian Jirasek",
      "Robert Bamler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08080",
    "title": "AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection",
    "abstract": "           Model interpretability in toxicity detection greatly profits from token-level annotations. However, currently such annotations are only available in English. We introduce a dataset annotated for offensive language detection sourced from a news forum, notable for its incorporation of the Austrian German dialect, comprising 4,562 user comments. In addition to binary offensiveness classification, we identify spans within each comment constituting vulgar language or representing targets of offensive statements. We evaluate fine-tuned language models as well as large language models in a zero- and few-shot fashion. The results indicate that while fine-tuned models excel in detecting linguistic peculiarities such as vulgar dialect, large language models demonstrate superior performance in detecting offensiveness in AustroTox. We publish the data and code.         ",
    "url": "https://arxiv.org/abs/2406.08080",
    "authors": [
      "Pia Pachinger",
      "Janis Goldzycher",
      "Anna Maria Planitzer",
      "Wojciech Kusa",
      "Allan Hanbury",
      "Julia Neidhardt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2406.08092",
    "title": "Languages Transferred Within the Encoder: On Representation Transfer in Zero-Shot Multilingual Translation",
    "abstract": "           Understanding representation transfer in multilingual neural machine translation can reveal the representational issue causing the zero-shot translation deficiency. In this work, we introduce the identity pair, a sentence translated into itself, to address the lack of the base measure in multilingual investigations, as the identity pair represents the optimal state of representation among any language transfers. In our analysis, we demonstrate that the encoder transfers the source language to the representational subspace of the target language instead of the language-agnostic state. Thus, the zero-shot translation deficiency arises because representations are entangled with other languages and are not transferred effectively to the target language. Based on our findings, we propose two methods: 1) low-rank language-specific embedding at the encoder, and 2) language-specific contrastive learning of the representation at the decoder. The experimental results on Europarl-15, TED-19, and OPUS-100 datasets show that our methods substantially enhance the performance of zero-shot translations by improving language transfer capacity, thereby providing practical evidence to support our conclusions.         ",
    "url": "https://arxiv.org/abs/2406.08092",
    "authors": [
      "Zhi Qu",
      "Chenchen Ding",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2406.08098",
    "title": "Scalable Defect Detection via Traversal on Code Graph",
    "abstract": "           Detecting defects and vulnerabilities in the early stage has long been a challenge in software engineering. Static analysis, a technique that inspects code without execution, has emerged as a key strategy to address this challenge. Among recent advancements, the use of graph-based representations, particularly Code Property Graph (CPG), has gained traction due to its comprehensive depiction of code structure and semantics. Despite the progress, existing graph-based analysis tools still face performance and scalability issues. The main bottleneck lies in the size and complexity of CPG, which makes analyzing large codebases inefficient and memory-consuming. Also, query rules used by the current tools can be over-specific. Hence, we introduce QVoG, a graph-based static analysis platform for detecting defects and vulnerabilities. It employs a compressed CPG representation to maintain a reasonable graph size, thereby enhancing the overall query efficiency. Based on the CPG, it also offers a declarative query language to simplify the queries. Furthermore, it takes a step forward to integrate machine learning to enhance the generality of vulnerability detection. For projects consisting of 1,000,000+ lines of code, QVoG can complete analysis in approximately 15 minutes, as opposed to 19 minutes with CodeQL.         ",
    "url": "https://arxiv.org/abs/2406.08098",
    "authors": [
      "Zhengyao Liu",
      "Xitong Zhong",
      "Xingjing Deng",
      "Shuo Hong",
      "Xiang Gao",
      "Hailong Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2406.08102",
    "title": "Adversarial Patch for 3D Local Feature Extractor",
    "abstract": "           Local feature extractors are the cornerstone of many computer vision tasks. However, their vulnerability to adversarial attacks can significantly compromise their effectiveness. This paper discusses approaches to attack sophisticated local feature extraction algorithms and models to achieve two distinct goals: (1) forcing a match between originally non-matching image regions, and (2) preventing a match between originally matching regions. At the end of the paper, we discuss the performance and drawbacks of different patch generation methods.         ",
    "url": "https://arxiv.org/abs/2406.08102",
    "authors": [
      "Yu Wen Pao",
      "Li Chang Lai",
      "Hong-Yi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08105",
    "title": "Prediction of the Realisation of an Information Need: An EEG Study",
    "abstract": "           One of the foundational goals of Information Retrieval (IR) is to satisfy searchers' Information Needs (IN). Understanding how INs physically manifest has long been a complex and elusive process. However, recent studies utilising Electroencephalography (EEG) data have provided real-time insights into the neural processes associated with INs. Unfortunately, they have yet to demonstrate how this insight can practically benefit the search experience. As such, within this study, we explore the ability to predict the realisation of IN within EEG data across 14 subjects whilst partaking in a Question-Answering (Q/A) task. Furthermore, we investigate the combinations of EEG features that yield optimal predictive performance, as well as identify regions within the Q/A queries where a subject's realisation of IN is more pronounced. The findings from this work demonstrate that EEG data is sufficient for the real-time prediction of the realisation of an IN across all subjects with an accuracy of 73.5% (SD 2.6%) and on a per-subject basis with an accuracy of 90.1% (SD 22.1%). This work helps to close the gap by bridging theoretical neuroscientific advancements with tangible improvements in information retrieval practices, paving the way for real-time prediction of the realisation of IN.         ",
    "url": "https://arxiv.org/abs/2406.08105",
    "authors": [
      "Niall McGuire",
      "Dr Yashar Moshfeghi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2406.08124",
    "title": "Legend: Leveraging Representation Engineering to Annotate Safety Margin for Preference Datasets",
    "abstract": "           The success of the reward model in distinguishing between responses with subtle safety differences depends critically on the high-quality preference dataset, which should capture the fine-grained nuances of harmful and harmless responses. This motivates the need to develop a dataset involving preference margins, which accurately quantify how harmless one response is compared to another. In this paper, we take the first step to propose an effective and cost-efficient framework to promote the margin-enhanced preference dataset development. Our framework, Legend, Leverages representation engineering to annotate preference datasets. It constructs the specific direction within the LLM's embedding space that represents safety. By leveraging this safety direction, Legend can then leverage the semantic distances of paired responses along this direction to annotate margins automatically. We experimentally demonstrate our effectiveness in both reward modeling and harmless alignment for LLMs. Legend also stands out for its efficiency, requiring only the inference time rather than additional training. This efficiency allows for easier implementation and scalability, making Legend particularly valuable for practical applications in aligning LLMs with safe conversations.         ",
    "url": "https://arxiv.org/abs/2406.08124",
    "authors": [
      "Duanyu Feng",
      "Bowen Qin",
      "Chen Huang",
      "Youcheng Huang",
      "Zheng Zhang",
      "Wenqiang Lei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.08152",
    "title": "CT3D++: Improving 3D Object Detection with Keypoint-induced Channel-wise Transformer",
    "abstract": "           The field of 3D object detection from point clouds is rapidly advancing in computer vision, aiming to accurately and efficiently detect and localize objects in three-dimensional space. Current 3D detectors commonly fall short in terms of flexibility and scalability, with ample room for advancements in performance. In this paper, our objective is to address these limitations by introducing two frameworks for 3D object detection with minimal hand-crafted design. Firstly, we propose CT3D, which sequentially performs raw-point-based embedding, a standard Transformer encoder, and a channel-wise decoder for point features within each proposal. Secondly, we present an enhanced network called CT3D++, which incorporates geometric and semantic fusion-based embedding to extract more valuable and comprehensive proposal-aware information. Additionally, CT3D ++ utilizes a point-to-key bidirectional encoder for more efficient feature encoding with reduced computational cost. By replacing the corresponding components of CT3D with these novel modules, CT3D++ achieves state-of-the-art performance on both the KITTI dataset and the large-scale Way\\-mo Open Dataset. The source code for our frameworks will be made accessible at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08152",
    "authors": [
      "Hualian Sheng",
      "Sijia Cai",
      "Na Zhao",
      "Bing Deng",
      "Qiao Liang",
      "Min-Jian Zhao",
      "Jieping Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08176",
    "title": "Category-level Neural Field for Reconstruction of Partially Observed Objects in Indoor Environment",
    "abstract": "           Neural implicit representation has attracted attention in 3D reconstruction through various success cases. For further applications such as scene understanding or editing, several works have shown progress towards object compositional reconstruction. Despite their superior performance in observed regions, their performance is still limited in reconstructing objects that are partially observed. To better treat this problem, we introduce category-level neural fields that learn meaningful common 3D information among objects belonging to the same category present in the scene. Our key idea is to subcategorize objects based on their observed shape for better training of the category-level model. Then we take advantage of the neural field to conduct the challenging task of registering partially observed objects by selecting and aligning against representative objects selected by ray-based uncertainty. Experiments on both simulation and real-world datasets demonstrate that our method improves the reconstruction of unobserved parts for several categories.         ",
    "url": "https://arxiv.org/abs/2406.08176",
    "authors": [
      "Taekbeom Lee",
      "Youngseok Jang",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2406.08183",
    "title": "Underneath the Numbers: Quantitative and Qualitative Gender Fairness in LLMs for Depression Prediction",
    "abstract": "           Recent studies show bias in many machine learning models for depression detection, but bias in LLMs for this task remains unexplored. This work presents the first attempt to investigate the degree of gender bias present in existing LLMs (ChatGPT, LLaMA 2, and Bard) using both quantitative and qualitative approaches. From our quantitative evaluation, we found that ChatGPT performs the best across various performance metrics and LLaMA 2 outperforms other LLMs in terms of group fairness metrics. As qualitative fairness evaluation remains an open research question we propose several strategies (e.g., word count, thematic analysis) to investigate whether and how a qualitative evaluation can provide valuable insights for bias analysis beyond what is possible with quantitative evaluation. We found that ChatGPT consistently provides a more comprehensive, well-reasoned explanation for its prediction compared to LLaMA 2. We have also identified several themes adopted by LLMs to qualitatively evaluate gender fairness. We hope our results can be used as a stepping stone towards future attempts at improving qualitative evaluation of fairness for LLMs especially for high-stakes tasks such as depression detection.         ",
    "url": "https://arxiv.org/abs/2406.08183",
    "authors": [
      "Micol Spitale",
      "Jiaee Cheong",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2406.08192",
    "title": "2nd Place Solution for MOSE Track in CVPR 2024 PVUW workshop: Complex Video Object Segmentation",
    "abstract": "           Complex video object segmentation serves as a fundamental task for a wide range of downstream applications such as video editing and automatic data annotation. Here we present the 2nd place solution in the MOSE track of PVUW 2024. To mitigate problems caused by tiny objects, similar objects and fast movements in MOSE. We use instance segmentation to generate extra pretraining data from the valid and test set of MOSE. The segmented instances are combined with objects extracted from COCO to augment the training data and enhance semantic representation of the baseline model. Besides, motion blur is added during training to increase robustness against image blur induced by motion. Finally, we apply test time augmentation (TTA) and memory strategy to the inference stage. Our method ranked 2nd in the MOSE track of PVUW 2024, with a $\\mathcal{J}$ of 0.8007, a $\\mathcal{F}$ of 0.8683 and a $\\mathcal{J}$\\&$\\mathcal{F}$ of 0.8345.         ",
    "url": "https://arxiv.org/abs/2406.08192",
    "authors": [
      "Zhensong Xu",
      "Jiangtao Yao",
      "Chengjing Wu",
      "Ting Liu",
      "Luoqi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08200",
    "title": "Asynchronous Voice Anonymization Using Adversarial Perturbation On Speaker Embedding",
    "abstract": "           Voice anonymization has been developed as a technique for preserving privacy by replacing the speaker's voice in a speech signal with that of a pseudo-speaker, thereby obscuring the original voice attributes from machine recognition and human perception. In this paper, we focus on altering the voice attributes against machine recognition while retaining human perception. We referred to this as the asynchronous voice anonymization. To this end, a speech generation framework incorporating a speaker disentanglement mechanism is employed to generate the anonymized speech. The speaker attributes are altered through adversarial perturbation applied on the speaker embedding, while human perception is preserved by controlling the intensity of perturbation. Experiments conducted on the LibriSpeech dataset showed that the speaker attributes were obscured with their human perception preserved for 60.71% of the processed utterances.         ",
    "url": "https://arxiv.org/abs/2406.08200",
    "authors": [
      "Rui Wang",
      "Liping Chen",
      "Kong AiK Lee",
      "Zhen-Hua Ling"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.08201",
    "title": "HTIM: Hybrid Text-Interaction Modeling for Broadening Political Leaning Inference in Social Media",
    "abstract": "           Political leaning can be defined as the inclination of an individual towards certain political orientations that align with their personal beliefs. Political leaning inference has traditionally been framed as a binary classification problem, namely, to distinguish between left vs. right or conservative vs liberal. Furthermore, although some recent work considers political leaning inference in a multi-party multi-region framework, their study is limited to the application of social interaction data. In order to address these shortcomings, in this study we propose Hybrid Text-Interaction Modeling (HTIM), a framework that enables hybrid modeling fusioning text and interactions from Social Media to accurately identify the political leaning of users in a multi-party multi-region framework. Access to textual and interaction-based data not only allows us to compare these data sources but also avoids reliance on specific data types. We show that, while state-of-the-art text-based representations on their own are not able to improve over interaction-based representations, a combination of text-based and interaction-based modeling using HTIM considerably improves the performance across the three regions, an improvement that is more prominent when we focus on the most challenging cases involving users who are less engaged in politics.         ",
    "url": "https://arxiv.org/abs/2406.08201",
    "authors": [
      "Joseba Fernandez de Landa",
      "Arkaitz Zubiaga",
      "Rodrigo Agerri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2406.08214",
    "title": "Graph Bottlenecked Social Recommendation",
    "abstract": "           With the emergence of social networks, social recommendation has become an essential technique for personalized services. Recently, graph-based social recommendations have shown promising results by capturing the high-order social influence. Most empirical studies of graph-based social recommendations directly take the observed social networks into formulation, and produce user preferences based on social homogeneity. Despite the effectiveness, we argue that social networks in the real-world are inevitably noisy~(existing redundant social relations), which may obstruct precise user preference characterization. Nevertheless, identifying and removing redundant social relations is challenging due to a lack of labels. In this paper, we focus on learning the denoised social structure to facilitate recommendation tasks from an information bottleneck perspective. Specifically, we propose a novel Graph Bottlenecked Social Recommendation (GBSR) framework to tackle the social noise issue.GBSR is a model-agnostic social denoising framework, that aims to maximize the mutual information between the denoised social graph and recommendation labels, meanwhile minimizing it between the denoised social graph and the original one. This enables GBSR to learn the minimal yet sufficient social structure, effectively reducing redundant social relations and enhancing social recommendations. Technically, GBSR consists of two elaborate components, preference-guided social graph refinement, and HSIC-based bottleneck learning. Extensive experimental results demonstrate the superiority of the proposed GBSR, including high performances and good generality combined with various backbones. Our code is available at: this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08214",
    "authors": [
      "Yonghui Yang",
      "Le Wu",
      "Zihan Wang",
      "Zhuangzhuang He",
      "Richang Hong",
      "Meng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2406.08223",
    "title": "Research Trends for the Interplay between Large Language Models and Knowledge Graphs",
    "abstract": "           This survey investigates the synergistic relationship between Large Language Models (LLMs) and Knowledge Graphs (KGs), which is crucial for advancing AI's capabilities in understanding, reasoning, and language processing. It aims to address gaps in current research by exploring areas such as KG Question Answering, ontology generation, KG validation, and the enhancement of KG accuracy and consistency through LLMs. The paper further examines the roles of LLMs in generating descriptive texts and natural language queries for KGs. Through a structured analysis that includes categorizing LLM-KG interactions, examining methodologies, and investigating collaborative uses and potential biases, this study seeks to provide new insights into the combined potential of LLMs and KGs. It highlights the importance of their interaction for improving AI applications and outlines future research directions.         ",
    "url": "https://arxiv.org/abs/2406.08223",
    "authors": [
      "Hanieh Khorashadizadeh",
      "Fatima Zahra Amara",
      "Morteza Ezzabady",
      "Fr\u00e9d\u00e9ric Ieng",
      "Sanju Tiwari",
      "Nandana Mihindukulasooriya",
      "Jinghua Groppe",
      "Soror Sahri",
      "Farah Benamara",
      "Sven Groppe"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2406.08229",
    "title": "GPT4Rec: Graph Prompt Tuning for Streaming Recommendation",
    "abstract": "           In the realm of personalized recommender systems, the challenge of adapting to evolving user preferences and the continuous influx of new users and items is paramount. Conventional models, typically reliant on a static training-test approach, struggle to keep pace with these dynamic demands. Streaming recommendation, particularly through continual graph learning, has emerged as a novel solution. However, existing methods in this area either rely on historical data replay, which is increasingly impractical due to stringent data privacy regulations; or are inability to effectively address the over-stability issue; or depend on model-isolation and expansion strategies. To tackle these difficulties, we present GPT4Rec, a Graph Prompt Tuning method for streaming Recommendation. Given the evolving user-item interaction graph, GPT4Rec first disentangles the graph patterns into multiple views. After isolating specific interaction patterns and relationships in different views, GPT4Rec utilizes lightweight graph prompts to efficiently guide the model across varying interaction patterns within the user-item graph. Firstly, node-level prompts are employed to instruct the model to adapt to changes in the attributes or properties of individual nodes within the graph. Secondly, structure-level prompts guide the model in adapting to broader patterns of connectivity and relationships within the graph. Finally, view-level prompts are innovatively designed to facilitate the aggregation of information from multiple disentangled views. These prompt designs allow GPT4Rec to synthesize a comprehensive understanding of the graph, ensuring that all vital aspects of the user-item interactions are considered and effectively integrated. Experiments on four diverse real-world datasets demonstrate the effectiveness and efficiency of our proposal.         ",
    "url": "https://arxiv.org/abs/2406.08229",
    "authors": [
      "Peiyan Zhang",
      "Yuchen Yan",
      "Xi Zhang",
      "Liying Kang",
      "Chaozhuo Li",
      "Feiran Huang",
      "Senzhang Wang",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08231",
    "title": "Using Deep Convolutional Neural Networks to Detect Rendered Glitches in Video Games",
    "abstract": "           In this paper, we present a method using Deep Convolutional Neural Networks (DCNNs) to detect common glitches in video games. The problem setting consists of an image (800x800 RGB) as input to be classified into one of five defined classes, normal image, or one of four different kinds of glitches (stretched, low resolution, missing and placeholder textures). Using a supervised approach, we train a ShuffleNetV2 using generated data. This work focuses on detecting texture graphical anomalies achieving arguably good performance with an accuracy of 86.8\\%, detecting 88\\% of the glitches with a false positive rate of 8.7\\%, and with the models being able to generalize and detect glitches even in unseen objects. We apply a confidence measure as well to tackle the issue with false positives as well as an effective way of aggregating images to achieve better detection in production. The main use of this work is the partial automatization of graphical testing in the final stages of video game development.         ",
    "url": "https://arxiv.org/abs/2406.08231",
    "authors": [
      "Carlos Garcia Ling",
      "Konrad Tollmar",
      "Linus Gisslen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.08267",
    "title": "A deep cut into Split Federated Self-supervised Learning",
    "abstract": "           Collaborative self-supervised learning has recently become feasible in highly distributed environments by dividing the network layers between client devices and a central server. However, state-of-the-art methods, such as MocoSFL, are optimized for network division at the initial layers, which decreases the protection of the client data and increases communication overhead. In this paper, we demonstrate that splitting depth is crucial for maintaining privacy and communication efficiency in distributed training. We also show that MocoSFL suffers from a catastrophic quality deterioration for the minimal communication overhead. As a remedy, we introduce Momentum-Aligned contrastive Split Federated Learning (MonAcoSFL), which aligns online and momentum client models during training procedure. Consequently, we achieve state-of-the-art accuracy while significantly reducing the communication overhead, making MonAcoSFL more practical in real-world scenarios.         ",
    "url": "https://arxiv.org/abs/2406.08267",
    "authors": [
      "Marcin Przewi\u0119\u017alikowski",
      "Marcin Osial",
      "Bartosz Zieli\u0144ski",
      "Marek \u015amieja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2406.08281",
    "title": "Conformal Load Prediction with Transductive Graph Autoencoders",
    "abstract": "           Predicting edge weights on graphs has various applications, from transportation systems to social networks. This paper describes a Graph Neural Network (GNN) approach for edge weight prediction with guaranteed coverage. We leverage conformal prediction to calibrate the GNN outputs and produce valid prediction intervals. We handle data heteroscedasticity through error reweighting and Conformalized Quantile Regression (CQR). We compare the performance of our method against baseline techniques on real-world transportation datasets. Our approach has better coverage and efficiency than all baselines and showcases robustness and adaptability.         ",
    "url": "https://arxiv.org/abs/2406.08281",
    "authors": [
      "Rui Luo",
      "Nicolo Colombo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2406.08285",
    "title": "A New Class Biorthogonal Spline Wavelet for Image Edge Detection",
    "abstract": "           Spline wavelets have shown favorable characteristics for localizing in both time and frequency. In this paper, we propose a new biorthogonal cubic special spline wavelet (BCSSW), based on the Cohen-Daubechies-Feauveau wavelet construction method and the cubic special spline algorithm. BCSSW has better properties in compact support, symmetry, and frequency domain characteristics. However, current mainstream detection operators usually ignore the uncertain representation of regional pixels and global structures. To solve these problems, we propose a structural uncertainty-aware and multi-structure operator fusion detection algorithm (EDBSW) based on a new BCSSW spline wavelet. By constructing a spline wavelet that efficiently handles edge effects, we utilize structural uncertainty-aware modulus maxima to detect highly uncertain edge samples. The proposed wavelet detection operator utilizes the multi-structure morphological operator and fusion reconstruction strategy to effectively address anti-noise processing and edge information of different frequencies. Numerous experiments have demonstrated its excellent performance in reducing noise and capturing edge structure details.         ",
    "url": "https://arxiv.org/abs/2406.08285",
    "authors": [
      "Dujuan Zhou",
      "Zizhao Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08287",
    "title": "Pre-Training Identification of Graph Winning Tickets in Adaptive Spatial-Temporal Graph Neural Networks",
    "abstract": "           In this paper, we present a novel method to significantly enhance the computational efficiency of Adaptive Spatial-Temporal Graph Neural Networks (ASTGNNs) by introducing the concept of the Graph Winning Ticket (GWT), derived from the Lottery Ticket Hypothesis (LTH). By adopting a pre-determined star topology as a GWT prior to training, we balance edge reduction with efficient information propagation, reducing computational demands while maintaining high model performance. Both the time and memory computational complexity of generating adaptive spatial-temporal graphs is significantly reduced from $\\mathcal{O}(N^2)$ to $\\mathcal{O}(N)$. Our approach streamlines the ASTGNN deployment by eliminating the need for exhaustive training, pruning, and retraining cycles, and demonstrates empirically across various datasets that it is possible to achieve comparable performance to full models with substantially lower computational costs. Specifically, our approach enables training ASTGNNs on the largest scale spatial-temporal dataset using a single A6000 equipped with 48 GB of memory, overcoming the out-of-memory issue encountered during original training and even achieving state-of-the-art performance. {Furthermore, we delve into the effectiveness of the GWT from the perspective of spectral graph theory, providing substantial theoretical support.} This advancement not only proves the existence of efficient sub-networks within ASTGNNs but also broadens the applicability of the LTH in resource-constrained settings, marking a significant step forward in the field of graph neural networks. Code is available at https://anonymous.4open.science/r/paper-1430.         ",
    "url": "https://arxiv.org/abs/2406.08287",
    "authors": [
      "Wenying Duan",
      "Tianxiang Fang",
      "Hong Rao",
      "Xiaoxi He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08294",
    "title": "Vessel Re-identification and Activity Detection in Thermal Domain for Maritime Surveillance",
    "abstract": "           Maritime surveillance is vital to mitigate illegal activities such as drug smuggling, illegal fishing, and human trafficking. Vision-based maritime surveillance is challenging mainly due to visibility issues at night, which results in failures in re-identifying vessels and detecting suspicious activities. In this paper, we introduce a thermal, vision-based approach for maritime surveillance with object tracking, vessel re-identification, and suspicious activity detection capabilities. For vessel re-identification, we propose a novel viewpoint-independent algorithm which compares features of the sides of the vessel separately (separate side-spaces) leveraging shape information in the absence of color features. We propose techniques to adapt tracking and activity detection algorithms for the thermal domain and train them using a thermal dataset we created. This dataset will be the first publicly available benchmark dataset for thermal maritime surveillance. Our system is capable of re-identifying vessels with an 81.8% Top1 score and identifying suspicious activities with a 72.4\\% frame mAP score; a new benchmark for each task in the thermal domain.         ",
    "url": "https://arxiv.org/abs/2406.08294",
    "authors": [
      "Yasod Ginige",
      "Ransika Gunasekara",
      "Darsha Hewavitharana",
      "Manjula Ariyarathne",
      "Ranga Rodrigo",
      "Peshala Jayasekara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08298",
    "title": "AdaNCA: Neural Cellular Automata As Adaptors For More Robust Vision Transformer",
    "abstract": "           Vision Transformers (ViTs) have demonstrated remarkable performance in image classification tasks, particularly when equipped with local information via region attention or convolutions. While such architectures improve the feature aggregation from different granularities, they often fail to contribute to the robustness of the networks. Neural Cellular Automata (NCA) enables the modeling of global cell representations through local interactions, with its training strategies and architecture design conferring strong generalization ability and robustness against noisy inputs. In this paper, we propose Adaptor Neural Cellular Automata (AdaNCA) for Vision Transformer that uses NCA as plug-in-play adaptors between ViT layers, enhancing ViT's performance and robustness against adversarial samples as well as out-of-distribution inputs. To overcome the large computational overhead of standard NCAs, we propose Dynamic Interaction for more efficient interaction learning. Furthermore, we develop an algorithm for identifying the most effective insertion points for AdaNCA based on our analysis of AdaNCA placement and robustness improvement. With less than a 3% increase in parameters, AdaNCA contributes to more than 10% absolute improvement in accuracy under adversarial attacks on the ImageNet1K benchmark. Moreover, we demonstrate with extensive evaluations across 8 robustness benchmarks and 4 ViT architectures that AdaNCA, as a plug-in-play module, consistently improves the robustness of ViTs.         ",
    "url": "https://arxiv.org/abs/2406.08298",
    "authors": [
      "Yitao Xu",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08299",
    "title": "Dynamical evolution of social network polarization and its impact on the propagation of a virus",
    "abstract": "           The COVID-19 pandemic that emerged in 2020 has highlighted the complex interplay between vaccine hesitancy and societal polarization. In this study, we analyse the dynamical polarization within a social network as well as the network properties before and after a vaccine was made available. Our results show that as the network evolves from a less structured state to one with more clustered communities. Then using an agent-based modeling approach, we simulate the propagation of a virus in a polarized society by assigning vaccines to pro-vaccine individuals and none to the anti-vaccine individuals. We compare this propagation to the case where the same number of vaccines is distributed homogeneously across the population. In polarized networks, we observe a significantly more widespread diffusion of the virus, highlighting the importance of considering polarization for epidemic forecasting.         ",
    "url": "https://arxiv.org/abs/2406.08299",
    "authors": [
      "Ixandra Achitouv",
      "David Chavalarias"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2406.08305",
    "title": "Large Language Model(LLM) assisted End-to-End Network Health Management based on Multi-Scale Semanticization",
    "abstract": "           Network device and system health management is the foundation of modern network operations and maintenance. Traditional health management methods, relying on expert identification or simple rule-based algorithms, struggle to cope with the dynamic heterogeneous networks (DHNs) environment. Moreover, current state-of-the-art distributed anomaly detection methods, which utilize specific machine learning techniques, lack multi-scale adaptivity for heterogeneous device information, resulting in unsatisfactory diagnostic accuracy for DHNs. In this paper, we develop an LLM-assisted end-to-end intelligent network health management framework. The framework first proposes a Multi-Scale Semanticized Anomaly Detection Model (MSADM), incorporating semantic rule trees with an attention mechanism to address the multi-scale anomaly detection problem in DHNs. Secondly, a chain-of-thought-based large language model is embedded in downstream to adaptively analyze the fault detection results and produce an analysis report with detailed fault information and optimization strategies. Experimental results show that the accuracy of our proposed MSADM for heterogeneous network entity anomaly detection is as high as 91.31\\%.         ",
    "url": "https://arxiv.org/abs/2406.08305",
    "authors": [
      "Fengxiao Tang",
      "Xiaonan Wang",
      "Xun Yuan",
      "Linfeng Luo",
      "Ming Zhao",
      "Nei Kato"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2406.08308",
    "title": "FSH: 3D Representation via Fibonacci Spherical Harmonics",
    "abstract": "           Spherical harmonics are a favorable technique for 3D representation, employing a frequency-based approach through the spherical harmonic transform (SHT). Typically, SHT is performed using equiangular sampling grids. However, these grids are non-uniform on spherical surfaces and exhibit local anisotropy, a common limitation in existing spherical harmonic decomposition methods. This paper proposes a 3D representation method using Fibonacci Spherical Harmonics (FSH). We introduce a spherical Fibonacci grid (SFG), which is more uniform than equiangular grids for SHT in the frequency domain. Our method employs analytical weights for SHT on SFG, effectively assigning sampling errors to spherical harmonic degrees higher than the recovered band-limited function. This provides a novel solution for spherical harmonic transformation on non-equiangular grids. The key advantages of our FSH method include: 1) With the same number of sampling points, SFG captures more features without bias compared to equiangular grids; 2) The root mean square error of 32-degree spherical harmonic coefficients is reduced by approximately 34.6\\% for SFG compared to equiangular grids; and 3) FSH offers more stable frequency domain representations, especially for rotating functions. FSH enhances the stability of frequency domain representations under rotational transformations. Its application in 3D shape reconstruction and 3D shape classification results in more accurate and robust representations.         ",
    "url": "https://arxiv.org/abs/2406.08308",
    "authors": [
      "Zikuan Li",
      "Anyi Huang",
      "Wenru Jia",
      "Qiaoyun Wu",
      "Mingqiang Wei",
      "Jun Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2406.08310",
    "title": "GraphFM: A Comprehensive Benchmark for Graph Foundation Model",
    "abstract": "           Foundation Models (FMs) serve as a general class for the development of artificial intelligence systems, offering broad potential for generalization across a spectrum of downstream tasks. Despite extensive research into self-supervised learning as the cornerstone of FMs, several outstanding issues persist in Graph Foundation Models that rely on graph self-supervised learning, namely: 1) Homogenization. The extent of generalization capability on downstream tasks remains unclear. 2) Scalability. It is unknown how effectively these models can scale to large datasets. 3) Efficiency. The training time and memory usage of these models require evaluation. 4) Training Stop Criteria. Determining the optimal stopping strategy for pre-training across multiple tasks to maximize performance on downstream tasks. To address these questions, we have constructed a rigorous benchmark that thoroughly analyzes and studies the generalization and scalability of self-supervised Graph Neural Network (GNN) models. Regarding generalization, we have implemented and compared the performance of various self-supervised GNN models, trained to generate node representations, across tasks such as node classification, link prediction, and node clustering. For scalability, we have compared the performance of various models after training using full-batch and mini-batch strategies. Additionally, we have assessed the training efficiency of these models by conducting experiments to test their GPU memory usage and throughput. Through these experiments, we aim to provide insights to motivate future research. The code for this benchmark is publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08310",
    "authors": [
      "Yuhao Xu",
      "Xinqi Liu",
      "Keyu Duan",
      "Yi Fang",
      "Yu-Neng Chuang",
      "Daochen Zha",
      "Qiaoyu Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08311",
    "title": "Causality for Tabular Data Synthesis: A High-Order Structure Causal Benchmark Framework",
    "abstract": "           Tabular synthesis models remain ineffective at capturing complex dependencies, and the quality of synthetic data is still insufficient for comprehensive downstream tasks, such as prediction under distribution shifts, automated decision-making, and cross-table understanding. A major challenge is the lack of prior knowledge about underlying structures and high-order relationships in tabular data. We argue that a systematic evaluation on high-order structural information for tabular data synthesis is the first step towards solving the problem. In this paper, we introduce high-order structural causal information as natural prior knowledge and provide a benchmark framework for the evaluation of tabular synthesis models. The framework allows us to generate benchmark datasets with a flexible range of data generation processes and to train tabular synthesis models using these datasets for further evaluation. We propose multiple benchmark tasks, high-order metrics, and causal inference tasks as downstream tasks for evaluating the quality of synthetic data generated by the trained models. Our experiments demonstrate to leverage the benchmark framework for evaluating the model capability of capturing high-order structural causal information. Furthermore, our benchmarking results provide an initial assessment of state-of-the-art tabular synthesis models. They have clearly revealed significant gaps between ideal and actual performance and how baseline methods differ. Our benchmark framework is available at URL this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08311",
    "authors": [
      "Ruibo Tu",
      "Zineb Senane",
      "Lele Cao",
      "Cheng Zhang",
      "Hedvig Kjellstr\u00f6m",
      "Gustav Eje Henter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.08329",
    "title": "Highly Connected Graph Partitioning: Exact Formulation and Solution Methods",
    "abstract": "           Graph partitioning (GP) and vertex connectivity have traditionally been two distinct fields of study. This paper introduces the highly connected graph partitioning (HCGP) problem, which partitions a graph into compact, size balanced, and $Q$-(vertex) connected parts for any $Q\\geq 1$. This problem is valuable in applications that seek cohesion and fault-tolerance within their parts, such as community detection in social networks and resiliency-focused partitioning of power networks. Existing research in this fundamental interconnection primarily focuses on providing theoretical existence guarantees of highly connected partitions for a limited set of dense graphs, and do not include canonical GP considerations such as size balance and compactness. This paper's key contribution is providing a general modeling and algorithmic approach for HCGP, inspired by recent work in the political districting problem, a special case of HCGP with $Q=1$. This approach models $Q$-connectivity constraints as mixed integer programs for any $Q\\geq 1$ and provides an efficient branch-and-cut method to solve HCGP. When solution time is a priority over optimality, this paper provides a heuristic method specifically designed for HCGP with $Q=2$. A computational analysis evaluates these methods using a test bed of instances from various real-world graphs. In this analysis, the branch-and-cut method finds an optimal solution within one hour in $82.8\\%$ of the instances solved. For $Q=2$, small and sparse instances are challenging for the heuristic, whereas large and sparse instances are challenging for the exact method. Furthermore, this study quantifies the computational cost of ensuring higher connectivity using the branch-and-cut approach, compared to a baseline of ensuring $1$-connectivity. Overall, this work serves as an effective tool to partition a graph into resilient and cohesive parts.         ",
    "url": "https://arxiv.org/abs/2406.08329",
    "authors": [
      "Rahul Swamy",
      "Douglas M. King",
      "Sheldon H. Jacobson"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2406.08331",
    "title": "Genetic Column Generation for Computing Lower Bounds for Adversarial Classification",
    "abstract": "           Recent theoretical results on adversarial multi-class classification showed a similarity to the multi-marginal formulation of Wasserstein-barycenter in optimal transport. Unfortunately, both problems suffer from the curse of dimension, making it hard to exploit the nice linear program structure of the problems for numerical calculations. We investigate how ideas from Genetic Column Generation for multi-marginal optimal transport can be used to overcome the curse of dimension in computing the minimal adversarial risk in multi-class classification.         ",
    "url": "https://arxiv.org/abs/2406.08331",
    "authors": [
      "Maximilian Penka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08336",
    "title": "CoLM-DSR: Leveraging Neural Codec Language Modeling for Multi-Modal Dysarthric Speech Reconstruction",
    "abstract": "           Dysarthric speech reconstruction (DSR) aims to transform dysarthric speech into normal speech. It still suffers from low speaker similarity and poor prosody naturalness. In this paper, we propose a multi-modal DSR model by leveraging neural codec language modeling to improve the reconstruction results, especially for the speaker similarity and prosody naturalness. Our proposed model consists of: (i) a multi-modal content encoder to extract robust phoneme embeddings from dysarthric speech with auxiliary visual inputs; (ii) a speaker codec encoder to extract and normalize the speaker-aware codecs from the dysarthric speech, in order to provide original timbre and normal prosody; (iii) a codec language model based speech decoder to reconstruct the speech based on the extracted phoneme embeddings and normalized codecs. Evaluations on the commonly used UASpeech corpus show that our proposed model can achieve significant improvements in terms of speaker similarity and prosody naturalness.         ",
    "url": "https://arxiv.org/abs/2406.08336",
    "authors": [
      "Xueyuan Chen",
      "Dongchao Yang",
      "Dingdong Wang",
      "Xixin Wu",
      "Zhiyong Wu",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.08343",
    "title": "Continuous-Time Digital Twin with Analogue Memristive Neural Ordinary Differential Equation Solver",
    "abstract": "           Digital twins, the cornerstone of Industry 4.0, replicate real-world entities through computer models, revolutionising fields such as manufacturing management and industrial automation. Recent advances in machine learning provide data-driven methods for developing digital twins using discrete-time data and finite-depth models on digital computers. However, this approach fails to capture the underlying continuous dynamics and struggles with modelling complex system behaviour. Additionally, the architecture of digital computers, with separate storage and processing units, necessitates frequent data transfers and Analogue-Digital (A/D) conversion, thereby significantly increasing both time and energy costs. Here, we introduce a memristive neural ordinary differential equation (ODE) solver for digital twins, which is capable of capturing continuous-time dynamics and facilitates the modelling of complex systems using an infinite-depth model. By integrating storage and computation within analogue memristor arrays, we circumvent the von Neumann bottleneck, thus enhancing both speed and energy efficiency. We experimentally validate our approach by developing a digital twin of the HP memristor, which accurately extrapolates its nonlinear dynamics, achieving a 4.2-fold projected speedup and a 41.4-fold projected decrease in energy consumption compared to state-of-the-art digital hardware, while maintaining an acceptable error margin. Additionally, we demonstrate scalability through experimentally grounded simulations of Lorenz96 dynamics, exhibiting projected performance improvements of 12.6-fold in speed and 189.7-fold in energy efficiency relative to traditional digital approaches. By harnessing the capabilities of fully analogue computing, our breakthrough accelerates the development of digital twins, offering an efficient and rapid solution to meet the demands of Industry 4.0.         ",
    "url": "https://arxiv.org/abs/2406.08343",
    "authors": [
      "Hegan Chen",
      "Jichang Yang",
      "Jia Chen",
      "Songqi Wang",
      "Shaocong Wang",
      "Dingchen Wang",
      "Xinyu Tian",
      "Yifei Yu",
      "Xi Chen",
      "Yinan Lin",
      "Yangu He",
      "Xiaoshan Wu",
      "Yi Li",
      "Xinyuan Zhang",
      "Ning Lin",
      "Meng Xu",
      "Yi Li",
      "Xumeng Zhang",
      "Zhongrui Wang",
      "Han Wang",
      "Dashan Shang",
      "Qi Liu",
      "Kwang-Ting Cheng",
      "Ming Liu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2406.08358",
    "title": "From a Social Cognitive Perspective: Context-aware Visual Social Relationship Recognition",
    "abstract": "           People's social relationships are often manifested through their surroundings, with certain objects or interactions acting as symbols for specific relationships, e.g., wedding rings, roses, hugs, or holding hands. This brings unique challenges to recognizing social relationships, requiring understanding and capturing the essence of these contexts from visual appearances. However, current methods of social relationship understanding rely on the basic classification paradigm of detected persons and objects, which fails to understand the comprehensive context and often overlooks decisive social factors, especially subtle visual cues. To highlight the social-aware context and intricate details, we propose a novel approach that recognizes \\textbf{Con}textual \\textbf{So}cial \\textbf{R}elationships (\\textbf{ConSoR}) from a social cognitive perspective. Specifically, to incorporate social-aware semantics, we build a lightweight adapter upon the frozen CLIP to learn social concepts via our novel multi-modal side adapter tuning mechanism. Further, we construct social-aware descriptive language prompts (e.g., scene, activity, objects, emotions) with social relationships for each image, and then compel ConSoR to concentrate more intensively on the decisive visual social factors via visual-linguistic contrasting. Impressively, ConSoR outperforms previous methods with a 12.2\\% gain on the People-in-Social-Context (PISC) dataset and a 9.8\\% increase on the People-in-Photo-Album (PIPA) benchmark. Furthermore, we observe that ConSoR excels at finding critical visual evidence to reveal social relationships.         ",
    "url": "https://arxiv.org/abs/2406.08358",
    "authors": [
      "Shiwei Wu",
      "Chao Zhang",
      "Joya Chen",
      "Tong Xu",
      "Likang Wu",
      "Yao Hu",
      "Enhong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.08372",
    "title": "APSeg: Auto-Prompt Network for Cross-Domain Few-Shot Semantic Segmentation",
    "abstract": "           Few-shot semantic segmentation (FSS) endeavors to segment unseen classes with only a few labeled samples. Current FSS methods are commonly built on the assumption that their training and application scenarios share similar domains, and their performances degrade significantly while applied to a distinct domain. To this end, we propose to leverage the cutting-edge foundation model, the Segment Anything Model (SAM), for generalization enhancement. The SAM however performs unsatisfactorily on domains that are distinct from its training data, which primarily comprise natural scene images, and it does not support automatic segmentation of specific semantics due to its interactive prompting mechanism. In our work, we introduce APSeg, a novel auto-prompt network for cross-domain few-shot semantic segmentation (CD-FSS), which is designed to be auto-prompted for guiding cross-domain segmentation. Specifically, we propose a Dual Prototype Anchor Transformation (DPAT) module that fuses pseudo query prototypes extracted based on cycle-consistency with support prototypes, allowing features to be transformed into a more stable domain-agnostic space. Additionally, a Meta Prompt Generator (MPG) module is introduced to automatically generate prompt embeddings, eliminating the need for manual visual prompts. We build an efficient model which can be applied directly to target domains without fine-tuning. Extensive experiments on four cross-domain datasets show that our model outperforms the state-of-the-art CD-FSS method by 5.24% and 3.10% in average accuracy on 1-shot and 5-shot settings, respectively.         ",
    "url": "https://arxiv.org/abs/2406.08372",
    "authors": [
      "Weizhao He",
      "Yang Zhang",
      "Wei Zhuo",
      "Linlin Shen",
      "Jiaqi Yang",
      "Songhe Deng",
      "Liang Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08379",
    "title": "Eyes Wide Unshut: Unsupervised Mistake Detection in Egocentric Video by Detecting Unpredictable Gaze",
    "abstract": "           In this paper, we address the challenge of unsupervised mistake detection in egocentric video through the analysis of gaze signals, a critical component for advancing user assistance in smart glasses. Traditional supervised methods, reliant on manually labeled mistakes, suffer from domain-dependence and scalability issues. This research introduces an unsupervised method for detecting mistakes in videos of human activities, overcoming the challenges of domain-specific requirements and the necessity for annotated data. By analyzing unusual gaze patterns that signal user disorientation during tasks, we propose a gaze completion model that forecasts eye gaze trajectories from incomplete inputs. The difference between the anticipated and observed gaze paths acts as an indicator for identifying errors. Our method is validated on the EPIC-Tent dataset, showing its superiority compared to current one-class supervised and unsupervised techniques.         ",
    "url": "https://arxiv.org/abs/2406.08379",
    "authors": [
      "Michele Mazzamuto",
      "Antonino Furnari",
      "Giovanni Maria Farinella"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08381",
    "title": "LaneCPP: Continuous 3D Lane Detection using Physical Priors",
    "abstract": "           Monocular 3D lane detection has become a fundamental problem in the context of autonomous driving, which comprises the tasks of finding the road surface and locating lane markings. One major challenge lies in a flexible but robust line representation capable of modeling complex lane structures, while still avoiding unpredictable behavior. While previous methods rely on fully data-driven approaches, we instead introduce a novel approach LaneCPP that uses a continuous 3D lane detection model leveraging physical prior knowledge about the lane structure and road geometry. While our sophisticated lane model is capable of modeling complex road structures, it also shows robust behavior since physical constraints are incorporated by means of a regularization scheme that can be analytically applied to our parametric representation. Moreover, we incorporate prior knowledge about the road geometry into the 3D feature space by modeling geometry-aware spatial features, guiding the network to learn an internal road surface representation. In our experiments, we show the benefits of our contributions and prove the meaningfulness of using priors to make 3D lane detection more robust. The results show that LaneCPP achieves state-of-the-art performance in terms of F-Score and geometric errors.         ",
    "url": "https://arxiv.org/abs/2406.08381",
    "authors": [
      "Maximilian Pittner",
      "Joel Janai",
      "Alexandru P. Condurache"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08395",
    "title": "Time-Constrained Robust MDPs",
    "abstract": "           Robust reinforcement learning is essential for deploying reinforcement learning algorithms in real-world scenarios where environmental uncertainty predominates. Traditional robust reinforcement learning often depends on rectangularity assumptions, where adverse probability measures of outcome states are assumed to be independent across different states and actions. This assumption, rarely fulfilled in practice, leads to overly conservative policies. To address this problem, we introduce a new time-constrained robust MDP (TC-RMDP) formulation that considers multifactorial, correlated, and time-dependent disturbances, thus more accurately reflecting real-world dynamics. This formulation goes beyond the conventional rectangularity paradigm, offering new perspectives and expanding the analytical framework for robust RL. We propose three distinct algorithms, each using varying levels of environmental information, and evaluate them extensively on continuous control benchmarks. Our results demonstrate that these algorithms yield an efficient tradeoff between performance and robustness, outperforming traditional deep robust RL methods in time-constrained environments while preserving robustness in classical benchmarks. This study revisits the prevailing assumptions in robust RL and opens new avenues for developing more practical and realistic RL applications.         ",
    "url": "https://arxiv.org/abs/2406.08395",
    "authors": [
      "Adil Zouitine",
      "David Bertoin",
      "Pierre Clavier",
      "Matthieu Geist",
      "Emmanuel Rachelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08404",
    "title": "Scaling Value Iteration Networks to 5000 Layers for Extreme Long-Term Planning",
    "abstract": "           The Value Iteration Network (VIN) is an end-to-end differentiable architecture that performs value iteration on a latent MDP for planning in reinforcement learning (RL). However, VINs struggle to scale to long-term and large-scale planning tasks, such as navigating a $100\\times 100$ maze -- a task which typically requires thousands of planning steps to solve. We observe that this deficiency is due to two issues: the representation capacity of the latent MDP and the planning module's depth. We address these by augmenting the latent MDP with a dynamic transition kernel, dramatically improving its representational capacity, and, to mitigate the vanishing gradient problem, introducing an \"adaptive highway loss\" that constructs skip connections to improve gradient flow. We evaluate our method on both 2D maze navigation environments and the ViZDoom 3D navigation benchmark. We find that our new method, named Dynamic Transition VIN (DT-VIN), easily scales to 5000 layers and casually solves challenging versions of the above tasks. Altogether, we believe that DT-VIN represents a concrete step forward in performing long-term large-scale planning in RL environments.         ",
    "url": "https://arxiv.org/abs/2406.08404",
    "authors": [
      "Yuhui Wang",
      "Qingyuan Wu",
      "Weida Li",
      "Dylan R. Ashley",
      "Francesco Faccio",
      "Chao Huang",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.08406",
    "title": "RRLS : Robust Reinforcement Learning Suite",
    "abstract": "           Robust reinforcement learning is the problem of learning control policies that provide optimal worst-case performance against a span of adversarial environments. It is a crucial ingredient for deploying algorithms in real-world scenarios with prevalent environmental uncertainties and has been a long-standing object of attention in the community, without a standardized set of benchmarks. This contribution endeavors to fill this gap. We introduce the Robust Reinforcement Learning Suite (RRLS), a benchmark suite based on Mujoco environments. RRLS provides six continuous control tasks with two types of uncertainty sets for training and evaluation. Our benchmark aims to standardize robust reinforcement learning tasks, facilitating reproducible and comparable experiments, in particular those from recent state-of-the-art contributions, for which we demonstrate the use of RRLS. It is also designed to be easily expandable to new environments. The source code is available at \\href{this https URL}{this https URL}.         ",
    "url": "https://arxiv.org/abs/2406.08406",
    "authors": [
      "Adil Zouitine",
      "David Bertoin",
      "Pierre Clavier",
      "Matthieu Geist",
      "Emmanuel Rachelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08428",
    "title": "Improving Noise Robustness through Abstractions and its Impact on Machine Learning",
    "abstract": "           Noise is a fundamental problem in learning theory with huge effects in the application of Machine Learning (ML) methods, due to real world data tendency to be noisy. Additionally, introduction of malicious noise can make ML methods fail critically, as is the case with adversarial attacks. Thus, finding and developing alternatives to improve robustness to noise is a fundamental problem in ML. In this paper, we propose a method to deal with noise: mitigating its effect through the use of data abstractions. The goal is to reduce the effect of noise over the model's performance through the loss of information produced by the abstraction. However, this information loss comes with a cost: it can result in an accuracy reduction due to the missing information. First, we explored multiple methodologies to create abstractions, using the training dataset, for the specific case of numerical data and binary classification tasks. We also tested how these abstractions can affect robustness to noise with several experiments that explore the robustness of an Artificial Neural Network to noise when trained using raw data \\emph{vs} when trained using abstracted data. The results clearly show that using abstractions is a viable approach for developing noise robust ML methods.         ",
    "url": "https://arxiv.org/abs/2406.08428",
    "authors": [
      "Alfredo Ibias",
      "Karol Capala",
      "Varun Ravi Varma",
      "Anna Drozdz",
      "Jose Sousa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.08443",
    "title": "Transformation-Dependent Adversarial Attacks",
    "abstract": "           We introduce transformation-dependent adversarial attacks, a new class of threats where a single additive perturbation can trigger diverse, controllable mis-predictions by systematically transforming the input (e.g., scaling, blurring, compression). Unlike traditional attacks with static effects, our perturbations embed metamorphic properties to enable different adversarial attacks as a function of the transformation parameters. We demonstrate the transformation-dependent vulnerability across models (e.g., convolutional networks and vision transformers) and vision tasks (e.g., image classification and object detection). Our proposed geometric and photometric transformations enable a range of targeted errors from one crafted input (e.g., higher than 90% attack success rate for classifiers). We analyze effects of model architecture and type/variety of transformations on attack effectiveness. This work forces a paradigm shift by redefining adversarial inputs as dynamic, controllable threats. We highlight the need for robust defenses against such multifaceted, chameleon-like perturbations that current techniques are ill-prepared for.         ",
    "url": "https://arxiv.org/abs/2406.08443",
    "authors": [
      "Yaoteng Tan",
      "Zikui Cai",
      "M. Salman Asif"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08463",
    "title": "Self-supervised Learning of Neural Implicit Feature Fields for Camera Pose Refinement",
    "abstract": "           Visual localization techniques rely upon some underlying scene representation to localize against. These representations can be explicit such as 3D SFM map or implicit, such as a neural network that learns to encode the scene. The former requires sparse feature extractors and matchers to build the scene representation. The latter might lack geometric grounding not capturing the 3D structure of the scene well enough. This paper proposes to jointly learn the scene representation along with a 3D dense feature field and a 2D feature extractor whose outputs are embedded in the same metric space. Through a contrastive framework we align this volumetric field with the image-based extractor and regularize the latter with a ranking loss from learned surface information. We learn the underlying geometry of the scene with an implicit field through volumetric rendering and design our feature field to leverage intermediate geometric information encoded in the implicit field. The resulting features are discriminative and robust to viewpoint change while maintaining rich encoded information. Visual localization is then achieved by aligning the image-based features and the rendered volumetric features. We show the effectiveness of our approach on real-world scenes, demonstrating that our approach outperforms prior and concurrent work on leveraging implicit scene representations for localization.         ",
    "url": "https://arxiv.org/abs/2406.08463",
    "authors": [
      "Maxime Pietrantoni",
      "Gabriela Csurka",
      "Martin Humenberger",
      "Torsten Sattler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08465",
    "title": "Nonconvex Federated Learning on Compact Smooth Submanifolds With Heterogeneous Data",
    "abstract": "           Many machine learning tasks, such as principal component analysis and low-rank matrix completion, give rise to manifold optimization problems. Although there is a large body of work studying the design and analysis of algorithms for manifold optimization in the centralized setting, there are currently very few works addressing the federated setting. In this paper, we consider nonconvex federated learning over a compact smooth submanifold in the setting of heterogeneous client data. We propose an algorithm that leverages stochastic Riemannian gradients and a manifold projection operator to improve computational efficiency, uses local updates to improve communication efficiency, and avoids client drift. Theoretically, we show that our proposed algorithm converges sub-linearly to a neighborhood of a first-order optimal solution by using a novel analysis that jointly exploits the manifold structure and properties of the loss functions. Numerical experiments demonstrate that our algorithm has significantly smaller computational and communication overhead than existing methods.         ",
    "url": "https://arxiv.org/abs/2406.08465",
    "authors": [
      "Jiaojiao Zhang",
      "Jiang Hu",
      "Anthony Man-Cho So",
      "Mikael Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2406.08469",
    "title": "PAL: Pluralistic Alignment Framework for Learning from Heterogeneous Preferences",
    "abstract": "           Large foundation models pretrained on raw web-scale data are not readily deployable without additional step of extensive alignment to human preferences. Such alignment is typically done by collecting large amounts of pairwise comparisons from humans (\"Do you prefer output A or B?\") and learning a reward model or a policy with the Bradley-Terry-Luce (BTL) model as a proxy for a human's underlying implicit preferences. These methods generally suffer from assuming a universal preference shared by all humans, which lacks the flexibility of adapting to plurality of opinions and preferences. In this work, we propose PAL, a framework to model human preference complementary to existing pretraining strategies, which incorporates plurality from the ground up. We propose using the ideal point model as a lens to view alignment using preference comparisons. Together with our novel reformulation and using mixture modeling, our framework captures the plurality of population preferences while simultaneously learning a common preference latent space across different preferences, which can few-shot generalize to new, unseen users. Our approach enables us to use the penultimate-layer representation of large foundation models and simple MLP layers to learn reward functions that are on-par with the existing large state-of-the-art reward models, thereby enhancing efficiency of reward modeling significantly. We show that PAL achieves competitive reward model accuracy compared to strong baselines on 1) Language models with Summary dataset ; 2) Image Generative models with Pick-a-Pic dataset ; 3) A new semisynthetic heterogeneous dataset generated using Anthropic Personas. Finally, our experiments also highlight the shortcoming of current preference datasets that are created using rigid rubrics which wash away heterogeneity, and call for more nuanced data collection approaches.         ",
    "url": "https://arxiv.org/abs/2406.08469",
    "authors": [
      "Daiwei Chen",
      "Yi Chen",
      "Aniket Rege",
      "Ramya Korlakai Vinayak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08473",
    "title": "Strategies for Pretraining Neural Operators",
    "abstract": "           Pretraining for partial differential equation (PDE) modeling has recently shown promise in scaling neural operators across datasets to improve generalizability and performance. Despite these advances, our understanding of how pretraining affects neural operators is still limited; studies generally propose tailored architectures and datasets that make it challenging to compare or examine different pretraining frameworks. To address this, we compare various pretraining methods without optimizing architecture choices to characterize pretraining dynamics on different models and datasets as well as to understand its scaling and generalization behavior. We find that pretraining is highly dependent on model and dataset choices, but in general transfer learning or physics-based pretraining strategies work best. In addition, pretraining performance can be further improved by using data augmentations. Lastly, pretraining is additionally beneficial when fine-tuning in scarce data regimes or when generalizing to downstream data similar to the pretraining distribution. Through providing insights into pretraining neural operators for physics prediction, we hope to motivate future work in developing and evaluating pretraining methods for PDEs.         ",
    "url": "https://arxiv.org/abs/2406.08473",
    "authors": [
      "Anthony Zhou",
      "Cooper Lorsung",
      "AmirPouya Hemmasian",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08474",
    "title": "Real2Code: Reconstruct Articulated Objects via Code Generation",
    "abstract": "           We present Real2Code, a novel approach to reconstructing articulated objects via code generation. Given visual observations of an object, we first reconstruct its part geometry using an image segmentation model and a shape completion model. We then represent the object parts with oriented bounding boxes, which are input to a fine-tuned large language model (LLM) to predict joint articulation as code. By leveraging pre-trained vision and language models, our approach scales elegantly with the number of articulated parts, and generalizes from synthetic training data to real world objects in unstructured environments. Experimental results demonstrate that Real2Code significantly outperforms previous state-of-the-art in reconstruction accuracy, and is the first approach to extrapolate beyond objects' structural complexity in the training set, and reconstructs objects with up to 10 articulated parts. When incorporated with a stereo reconstruction model, Real2Code also generalizes to real world objects from a handful of multi-view RGB images, without the need for depth or camera information.         ",
    "url": "https://arxiv.org/abs/2406.08474",
    "authors": [
      "Zhao Mandi",
      "Yijia Weng",
      "Dominik Bauer",
      "Shuran Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.07763",
    "title": "Gene-Level Representation Learning via Interventional Style Transfer in Optical Pooled Screening",
    "abstract": "           Optical pooled screening (OPS) combines automated microscopy and genetic perturbations to systematically study gene function in a scalable and cost-effective way. Leveraging the resulting data requires extracting biologically informative representations of cellular perturbation phenotypes from images. We employ a style-transfer approach to learn gene-level feature representations from images of genetically perturbed cells obtained via OPS. Our method outperforms widely used engineered features in clustering gene representations according to gene function, demonstrating its utility for uncovering latent biological relationships. This approach offers a promising alternative to investigate the role of genes in health and disease.         ",
    "url": "https://arxiv.org/abs/2406.07763",
    "authors": [
      "Mahtab Bigverdi",
      "Burkhard Hockendorf",
      "Heming Yao",
      "Phil Hanslovsky",
      "Romain Lopez",
      "David Richmond"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.07888",
    "title": "Classification Modeling with RNN-Based, Random Forest, and XGBoost for Imbalanced Data: A Case of Early Crash Detection in ASEAN-5 Stock Markets",
    "abstract": "           This research aims to evaluate the performance of several Recurrent Neural Network (RNN) architectures including Simple RNN, Gated Recurrent Units (GRU), and Long Short-Term Memory (LSTM), compared to classic algorithms such as Random Forest and XGBoost in building classification models for early crash detection in ASEAN-5 stock markets. The study is examined using imbalanced data, which is common due to the rarity of market crashes. The study analyzes daily data from 2010 to 2023 across the major stock markets of the ASEAN-5 countries, including Indonesia, Malaysia, Singapore, Thailand, and Philippines. Market crash is identified as the target variable when the major stock price indices fall below the Value at Risk (VaR) thresholds of 5%, 2.5% and 1%. predictors involving technical indicators of major local and global markets as well as commodity markets. This study includes 213 predictors with their respective lags (5, 10, 15, 22, 50, 200) and uses a time step of 7, expanding the total number of predictors to 1491. The challenge of data imbalance is addressed with SMOTE-ENN. The results show that all RNN-Based architectures outperform Random Forest and XGBoost. Among the various RNN architectures, Simple RNN stands out as the most superior, mainly due to the data characteristics that are not overly complex and focus more on short-term information. This study enhances and extends the range of phenomena observed in previous studies by incorporating variables like different geographical zones and time periods, as well as methodological adjustments.         ",
    "url": "https://arxiv.org/abs/2406.07888",
    "authors": [
      "Deri Siswara",
      "Agus M. Soleh",
      "Aji Hamim Wigena"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.07893",
    "title": "Parameter Estimation in Quantum Metrology Technique for Time Series Prediction",
    "abstract": "           The paper investigates the techniques of quantum computation in metrological predictions, with a particular emphasis on enhancing prediction potential through variational parameter estimation. The applicability of quantum simulations and quantum metrology techniques for modelling complex physical systems and achieving high-resolution measurements are proposed. The impacts of various parameter distributions and learning rates on predictive accuracy are investigated. Modelling the time evolution of physical systems Hamiltonian simulation and the product formula procedure are adopted. The time block method is analyzed in order to reduce simulation errors, while the Schatten-infinite norm is used to evaluate the simulation precision. Methodology requires estimation of optimized parameters by minimizing loss functions and resource needs. For this purpose, the mathematical formulations of Cramer Rao Bound and Fischer Information are indispensable requirements. The impact of learning rates on regulating the loss function for various parameter values. Using parameterized quantum circuits, the article outlines a four-step procedure for extracting information. This method involves the preparation of input states, the evolution of parameterized quantum states, the measurement of outputs, and the estimation of parameters based on multiple measurements. The study analyses variational unitary circuits with optimized parameter estimation for more precise predictions. The findings shed light on the effects of normal parameter distributions and learning rates on attaining the most optimal state and comparison with classical Long Short Term Memory (LSTM) predictions, providing valuable insights for the development of more appropriate approaches in quantum computing.         ",
    "url": "https://arxiv.org/abs/2406.07893",
    "authors": [
      "Vaidik A Sharma",
      "N.Madurai Meenachi",
      "B.Venkatraman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2406.07952",
    "title": "Spatial-Frequency Dual Progressive Attention Network For Medical Image Segmentation",
    "abstract": "           In medical images, various types of lesions often manifest significant differences in their shape and texture. Accurate medical image segmentation demands deep learning models with robust capabilities in multi-scale and boundary feature learning. However, previous networks still have limitations in addressing the above issues. Firstly, previous networks simultaneously fuse multi-level features or employ deep supervision to enhance multi-scale learning. However, this may lead to feature redundancy and excessive computational overhead, which is not conducive to network training and clinical deployment. Secondly, the majority of medical image segmentation networks exclusively learn features in the spatial domain, disregarding the abundant global information in the frequency domain. This results in a bias towards low-frequency components, neglecting crucial high-frequency information. To address these problems, we introduce SF-UNet, a spatial-frequency dual-domain attention network. It comprises two main components: the Multi-scale Progressive Channel Attention (MPCA) block, which progressively extract multi-scale features across adjacent encoder layers, and the lightweight Frequency-Spatial Attention (FSA) block, with only 0.05M parameters, enabling concurrent learning of texture and boundary features from both spatial and frequency domains. We validate the effectiveness of the proposed SF-UNet on three public datasets. Experimental results show that compared to previous state-of-the-art (SOTA) medical image segmentation networks, SF-UNet achieves the best performance, and achieves up to 9.4\\% and 10.78\\% improvement in DSC and IOU. Codes will be released at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.07952",
    "authors": [
      "Zhenhuan Zhou",
      "Along He",
      "Yanlin Wu",
      "Rui Yao",
      "Xueshuo Xie",
      "Tao Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08003",
    "title": "Neural Data-Enabled Predictive Control",
    "abstract": "           Data-enabled predictive control (DeePC) for linear systems utilizes data matrices of recorded trajectories to directly predict new system trajectories, which is very appealing for real-life applications. In this paper we leverage the universal approximation properties of neural networks (NNs) to develop neural DeePC algorithms for nonlinear systems. Firstly, we point out that the outputs of the last hidden layer of a deep NN implicitly construct a basis in a so-called neural (feature) space, while the output linear layer performs affine interpolation in the neural space. As such, we can train off-line a deep NN using large data sets of trajectories to learn the neural basis and compute on-line a suitable affine interpolation using DeePC. Secondly, methods for guaranteeing consistency of neural DeePC and for reducing computational complexity are developed. Several neural DeePC formulations are illustrated on a nonlinear pendulum example.         ",
    "url": "https://arxiv.org/abs/2406.08003",
    "authors": [
      "Mircea Lazar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2406.08030",
    "title": "Fault detection in propulsion motors in the presence of concept drift",
    "abstract": "           Machine learning and statistical methods can be used to enhance monitoring and fault prediction in marine systems. These methods rely on a dataset with records of historical system behaviour, potentially containing periods of both fault-free and faulty operation. An unexpected change in the underlying system, called a concept drift, may impact the performance of these methods, triggering the need for model retraining or other adaptations. In this article, we present an approach for detecting overheating in stator windings of marine propulsion motors that is able to successfully operate during concept drift without the need for full model retraining. Two distinct approaches are presented and tested. All models are trained and verified using a dataset from operational propulsion motors, with known, sudden concept drifts.         ",
    "url": "https://arxiv.org/abs/2406.08030",
    "authors": [
      "Martin Tveten",
      "Morten Stakkeland"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2406.08034",
    "title": "Strong and Weak Random Walks on Signed Networks",
    "abstract": "           Random walks play an important role in probing the structure of complex networks. On traditional networks, they can be used to extract community structure, understand node centrality, perform link prediction, or capture the similarity between nodes. On signed networks, where the edge weights can be either positive or negative, it is non-trivial to design a random walk which can be used to extract information about the signed structure of the network, in particular the ability to partition the graph into communities with positive edges inside and negative edges in between. Prior works on signed network random walks focus on the case where there are only two such communities (strong balance), which is rarely the case in empirical networks. In this paper, we propose a signed network random walk which can capture the structure of a network with more than two such communities (weak balance). The walk results in a similarity matrix which can be used to cluster the nodes into antagonistic communities. We compare the characteristics of the so-called strong and weak random walks, in terms of walk length and stationarity. We show through a series of experiments on synthetic and empirical networks that the similarity matrix based on weak walks can be used for both unsupervised and semi-supervised clustering, outperforming the same similarity matrix based on strong walks when the graph has more than two communities, or exhibits asymmetry in the density of links. These results suggest that other random-walk based algorithms for signed networks could be improved simply by running them with weak walks instead of strong walks.         ",
    "url": "https://arxiv.org/abs/2406.08034",
    "authors": [
      "Shazia'Ayn Babul",
      "Yu Tian",
      "Renaud Lambiotte"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2406.08056",
    "title": "DCASE 2024 Task 4: Sound Event Detection with Heterogeneous Data and Missing Labels",
    "abstract": "           The Detection and Classification of Acoustic Scenes and Events Challenge Task 4 aims to advance sound event detection (SED) systems in domestic environments by leveraging training data with different supervision uncertainty. Participants are challenged in exploring how to best use training data from different domains and with varying annotation granularity (strong/weak temporal resolution, soft/hard labels), to obtain a robust SED system that can generalize across different scenarios. Crucially, annotation across available training datasets can be inconsistent and hence sound labels of one dataset may be present but not annotated in the other one and vice-versa. As such, systems will have to cope with potentially missing target labels during training. Moreover, as an additional novelty, systems will also be evaluated on labels with different granularity in order to assess their robustness for different applications. To lower the entry barrier for participants, we developed an updated baseline system with several caveats to address these aforementioned problems. Results with our baseline system indicate that this research direction is promising and is possible to obtain a stronger SED system by using diverse domain training data with missing labels compared to training a SED system for each domain separately.         ",
    "url": "https://arxiv.org/abs/2406.08056",
    "authors": [
      "Samuele Cornell",
      "Janek Ebbers",
      "Constance Douwes",
      "Irene Mart\u00edn-Morat\u00f3",
      "Manu Harju",
      "Annamaria Mesaros",
      "Romain Serizel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2406.08117",
    "title": "Algorithmic methods of finite discrete structures. Isomorphism of Nonseparable Graphs",
    "abstract": "           In this monography, it is proposed to consider the concepts of spectra of edge cuts and edge cycles of a graph as a basic mathematical structure for solving the problem of graph isomorphism. An edge cut is defined by an edge and the vertices incident to it. In contrast to the generation of iterated edge graphs, we consider an iterated chain of qualicuts of the original graph, generated by edge cuts and determined by a recurrence relation. An edge cycle is defined by the set of isometric cycles of a graph. The monography examines the issues of constructing the spectrum of edge cuts Ws and the spectrum of edge cycles Tc of a graph G. It is shown that the formation of spectra is based on the incidence matrix of the graph. The independence of the construction of the graph structure from the numbering of vertices and edges is shown. The necessity and sufficiency of the spectra of edge cuts and the spectrum of edge cycles for determining the isomorphism of graph structures is shown. The relation between the internal structures of the graph and Whitney's theorem is considered.         ",
    "url": "https://arxiv.org/abs/2406.08117",
    "authors": [
      "Sergey Kurapov",
      "Maxim Davidovsky"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2406.08119",
    "title": "Low-Complexity Acoustic Scene Classification Using Parallel Attention-Convolution Network",
    "abstract": "           This work is an improved system that we submitted to task 1 of DCASE2023 challenge. We propose a method of low-complexity acoustic scene classification by a parallel attention-convolution network which consists of four modules, including pre-processing, fusion, global and local contextual information extraction. The proposed network is computationally efficient to capture global and local contextual information from each audio clip. In addition, we integrate other techniques into our method, such as knowledge distillation, data augmentation, and adaptive residual normalization. When evaluated on the official dataset of DCASE2023 challenge, our method obtains the highest accuracy of 56.10% with parameter number of 5.21 kilo and multiply-accumulate operations of 1.44 million. It exceeds the top two systems of DCASE2023 challenge in accuracy and complexity, and obtains state-of-the-art result. Code is at: this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08119",
    "authors": [
      "Yanxiong Li",
      "Jiaxin Tan",
      "Guoqing Chen",
      "Jialong Li",
      "Yongjie Si",
      "Qianhua He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2406.08177",
    "title": "One-Step Effective Diffusion Network for Real-World Image Super-Resolution",
    "abstract": "           The pre-trained text-to-image diffusion models have been increasingly employed to tackle the real-world image super-resolution (Real-ISR) problem due to their powerful generative image priors. Most of the existing methods start from random noise to reconstruct the high-quality (HQ) image under the guidance of the given low-quality (LQ) image. While promising results have been achieved, such Real- ISR methods require multiple diffusion steps to reproduce the HQ image, increasing the computational cost. Meanwhile, the random noise introduces uncertainty in the output, which is unfriendly to image restoration tasks. To address these issues, we propose a one-step effective diffusion network, namely OSEDiff, for the Real- ISR problem. We argue that the LQ image contains rich information to restore its HQ counterpart, and hence the given LQ image can be directly taken as the starting point for diffusion, eliminating the uncertainty introduced by random noise sampling. We finetune the pre-trained diffusion network with trainable layers to adapt it to complex image degradations. To ensure that the one-step diffusion model could yield HQ Real-ISR output, we apply variational score distillation in the latent space to conduct KL-divergence regularization. As a result, our OSEDiff model can efficiently and effectively generate HQ images in just one diffusion step. Our experiments demonstrate that OSEDiff achieves comparable or even better Real-ISR results, in terms of both objective metrics and subjective evaluations, than previous diffusion model based Real-ISR methods that require dozens or hundreds of steps. The source codes will be released at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08177",
    "authors": [
      "Rongyuan Wu",
      "Lingchen Sun",
      "Zhiyuan Ma",
      "Lei Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08186",
    "title": "Hiperwalk: Simulation of Quantum Walks with Heterogeneous High-Performance Computing",
    "abstract": "           The Hiperwalk package is designed to facilitate the simulation of quantum walks using heterogeneous high-performance computing, taking advantage of the parallel processing power of diverse processors such as CPUs, GPUs, and acceleration cards. This package enables the simulation of both the continuous-time and discrete-time quantum walk models, effectively modeling the behavior of quantum systems on large graphs. Hiperwalk features a user-friendly Python package frontend with comprehensive documentation, as well as a high-performance C-based inner core that leverages parallel computing for efficient linear algebra calculations. This versatile tool empowers researchers to better understand quantum walk behavior, optimize implementation, and explore a wide range of potential applications, including spatial search algorithms.         ",
    "url": "https://arxiv.org/abs/2406.08186",
    "authors": [
      "Paulo Motta",
      "Gustavo A. Bezerra",
      "Anderson F. P. Santos",
      "Renato Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2406.08266",
    "title": "Refining Self-Supervised Learnt Speech Representation using Brain Activations",
    "abstract": "           It was shown in literature that speech representations extracted by self-supervised pre-trained models exhibit similarities with brain activations of human for speech perception and fine-tuning speech representation models on downstream tasks can further improve the similarity. However, it still remains unclear if this similarity can be used to optimize the pre-trained speech models. In this work, we therefore propose to use the brain activations recorded by fMRI to refine the often-used wav2vec2.0 model by aligning model representations toward human neural responses. Experimental results on SUPERB reveal that this operation is beneficial for several downstream tasks, e.g., speaker verification, automatic speech recognition, intent classification.One can then consider the proposed method as a new alternative to improve self-supervised speech models.         ",
    "url": "https://arxiv.org/abs/2406.08266",
    "authors": [
      "Hengyu Li",
      "Kangdi Mei",
      "Zhaoci Liu",
      "Yang Ai",
      "Liping Chen",
      "Jie Zhang",
      "Zhenhua Ling"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2406.08282",
    "title": "Interpretable Representation Learning of Cardiac MRI via Attribute Regularization",
    "abstract": "           Interpretability is essential in medical imaging to ensure that clinicians can comprehend and trust artificial intelligence models. Several approaches have been recently considered to encode attributes in the latent space to enhance its interpretability. Notably, attribute regularization aims to encode a set of attributes along the dimensions of a latent representation. However, this approach is based on Variational AutoEncoder and suffers from blurry reconstruction. In this paper, we propose an Attributed-regularized Soft Introspective Variational Autoencoder that combines attribute regularization of the latent space within the framework of an adversarially trained variational autoencoder. We demonstrate on short-axis cardiac Magnetic Resonance images of the UK Biobank the ability of the proposed method to address blurry reconstruction issues of variational autoencoder methods while preserving the latent space interpretability.         ",
    "url": "https://arxiv.org/abs/2406.08282",
    "authors": [
      "Maxime Di Folco",
      "Cosmin I. Bercea",
      "Julia A. Schnabel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.08307",
    "title": "Measuring model variability using robust non-parametric testing",
    "abstract": "           Training a deep neural network often involves stochastic optimization, meaning each run will produce a different model. The seed used to initialize random elements of the optimization procedure heavily influences the quality of a trained model, which may be obscure from many commonly reported summary statistics, like accuracy. However, random seed is often not included in hyper-parameter optimization, perhaps because the relationship between seed and model quality is hard to describe. This work attempts to describe the relationship between deep net models trained with different random seeds and the behavior of the expected model. We adopt robust hypothesis testing to propose a novel summary statistic for network similarity, referred to as the $\\alpha$-trimming level. We use the $\\alpha$-trimming level to show that the empirical cumulative distribution function of an ensemble model created from a collection of trained models with different random seeds approximates the average of these functions as the number of models in the collection grows large. This insight provides guidance for how many random seeds should be sampled to ensure that an ensemble of these trained models is a reliable representative. We also show that the $\\alpha$-trimming level is more expressive than different performance metrics like validation accuracy, churn, or expected calibration error when taken alone and may help with random seed selection in a more principled fashion. We demonstrate the value of the proposed statistic in real experiments and illustrate the advantage of fine-tuning over random seed with an experiment in transfer learning.         ",
    "url": "https://arxiv.org/abs/2406.08307",
    "authors": [
      "Sinjini Banerjee",
      "Tim Marrinan",
      "Reilly Cannon",
      "Tony Chiang",
      "Anand D. Sarwate"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08318",
    "title": "Invariant multiscale neural networks for data-scarce scientific applications",
    "abstract": "           Success of machine learning (ML) in the modern world is largely determined by abundance of data. However at many industrial and scientific problems, amount of data is limited. Application of ML methods to data-scarce scientific problems can be made more effective via several routes, one of them is equivariant neural networks possessing knowledge of symmetries. Here we suggest that combination of symmetry-aware invariant architectures and stacks of dilated convolutions is a very effective and easy to implement receipt allowing sizable improvements in accuracy over standard approaches. We apply it to representative physical problems from different realms: prediction of bandgaps of photonic crystals, and network approximations of magnetic ground states. The suggested invariant multiscale architectures increase expressibility of networks, which allow them to perform better in all considered cases.         ",
    "url": "https://arxiv.org/abs/2406.08318",
    "authors": [
      "I. Schurov",
      "D. Alforov",
      "M. Katsnelson",
      "A. Bagrov",
      "A. Itin"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2406.08393",
    "title": "SCDNet: Self-supervised Learning Feature-based Speaker Change Detection",
    "abstract": "           Speaker Change Detection (SCD) is to identify boundaries among speakers in a conversation. Motivated by the success of fine-tuning wav2vec 2.0 models for the SCD task, a further investigation of self-supervised learning (SSL) features for SCD is conducted in this work. Specifically, an SCD model, named SCDNet, is proposed. With this model, various state-of-the-art SSL models, including Hubert, wav2vec 2.0, and WavLm are investigated. To discern the most potent layer of SSL models for SCD, a learnable weighting method is employed to analyze the effectiveness of intermediate representations. Additionally, a fine-tuning-based approach is also implemented to further compare the characteristics of SSL models in the SCD task. Furthermore, a contrastive learning method is proposed to mitigate the overfitting tendencies in the training of both the fine-tuning-based method and SCDNet. Experiments showcase the superiority of WavLm in the SCD task and also demonstrate the good design of SCDNet.         ",
    "url": "https://arxiv.org/abs/2406.08393",
    "authors": [
      "Yue Li",
      "Xinsheng Wang",
      "Li Zhang",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2406.08396",
    "title": "Neural Blind Source Separation and Diarization for Distant Speech Recognition",
    "abstract": "           This paper presents a neural method for distant speech recognition (DSR) that jointly separates and diarizes speech mixtures without supervision by isolated signals. A standard separation method for multi-talker DSR is a statistical multichannel method called guided source separation (GSS). While GSS does not require signal-level supervision, it relies on speaker diarization results to handle unknown numbers of active speakers. To overcome this limitation, we introduce and train a neural inference model in a weakly-supervised manner, employing the objective function of a statistical separation method. This training requires only multichannel mixtures and their temporal annotations of speaker activities. In contrast to GSS, the trained model can jointly separate and diarize speech mixtures without any auxiliary information. The experiments with the AMI corpus show that our method outperforms GSS with oracle diarization results regarding word error rates. The code is available online.         ",
    "url": "https://arxiv.org/abs/2406.08396",
    "authors": [
      "Yoshiaki Bando",
      "Tomohiko Nakamura",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.08486",
    "title": "On Evaluating Adversarial Robustness of Volumetric Medical Segmentation Models",
    "abstract": "           Volumetric medical segmentation models have achieved significant success on organ and tumor-based segmentation tasks in recent years. However, their vulnerability to adversarial attacks remains largely unexplored, raising serious concerns regarding the real-world deployment of tools employing such models in the healthcare sector. This underscores the importance of investigating the robustness of existing models. In this context, our work aims to empirically examine the adversarial robustness across current volumetric segmentation architectures, encompassing Convolutional, Transformer, and Mamba-based models. We extend this investigation across four volumetric segmentation datasets, evaluating robustness under both white box and black box adversarial attacks. Overall, we observe that while both pixel and frequency-based attacks perform reasonably well under white box setting, the latter performs significantly better under transfer-based black box attacks. Across our experiments, we observe transformer-based models show higher robustness than convolution-based models with Mamba-based models being the most vulnerable. Additionally, we show that large-scale training of volumetric segmentation models improves the model's robustness against adversarial attacks. The code and pretrained models will be made available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08486",
    "authors": [
      "Hashmat Shadab Malik",
      "Numan Saeed",
      "Asif Hanif",
      "Muzammal Naseer",
      "Mohammad Yaqub",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2002.07756",
    "title": "Hierarchical Correlation Clustering and Tree Preserving Embedding",
    "abstract": "           We propose a hierarchical correlation clustering method that extends the well-known correlation clustering to produce hierarchical clusters applicable to both positive and negative pairwise dissimilarities. Then, in the following, we study unsupervised representation learning with such hierarchical correlation clustering. For this purpose, we first investigate embedding the respective hierarchy to be used for tree preserving embedding and feature extraction. Thereafter, we study the extension of minimax distance measures to correlation clustering, as another representation learning paradigm. Finally, we demonstrate the performance of our methods on several datasets.         ",
    "url": "https://arxiv.org/abs/2002.07756",
    "authors": [
      "Morteza Haghir Chehreghani",
      "Mostafa Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.15549",
    "title": "Multi-Constitutive Neural Network for Large Deformation Poromechanics Problem",
    "abstract": "           In this paper, we study the problem of large-strain consolidation in poromechanics with deep neural networks (DNN). Given different material properties and different loading conditions, the goal is to predict pore pressure and settlement. We propose a novel method \"multi-constitutive neural network\" (MCNN) such that one model can solve several different constitutive laws. We introduce a one-hot encoding vector as an additional input vector, which is used to label the constitutive law we wish to solve. Then we build a DNN which takes $(\\hat{X}, \\hat{t})$ as input along with a constitutive law label and outputs the corresponding solution. It is the first time, to our knowledge, that we can evaluate multi-constitutive laws through only one training process while still obtaining good accuracies. We found that MCNN trained to solve multiple PDEs outperforms individual neural network solvers trained with PDE in some cases.         ",
    "url": "https://arxiv.org/abs/2010.15549",
    "authors": [
      "Qi Zhang",
      "Yilin Chen",
      "Ziyi Yang",
      "Eric Darve"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2104.08433",
    "title": "Are Word Embedding Methods Stable and Should We Care About It?",
    "abstract": "           A representation learning method is considered stable if it consistently generates similar representation of the given data across multiple runs. Word Embedding Methods (WEMs) are a class of representation learning methods that generate dense vector representation for each word in the given text data. The central idea of this paper is to explore the stability measurement of WEMs using intrinsic evaluation based on word similarity. We experiment with three popular WEMs: Word2Vec, GloVe, and fastText. For stability measurement, we investigate the effect of five parameters involved in training these models. We perform experiments using four real-world datasets from different domains: Wikipedia, News, Song lyrics, and European parliament proceedings. We also observe the effect of WEM stability on three downstream tasks: Clustering, POS tagging, and Fairness evaluation. Our experiments indicate that amongst the three WEMs, fastText is the most stable, followed by GloVe and Word2Vec.         ",
    "url": "https://arxiv.org/abs/2104.08433",
    "authors": [
      "Angana Borah",
      "Manash Pratim Barman",
      "Amit Awekar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2108.06025",
    "title": "Interference Mitigation using Optimized Angle Diversity Receiver in LiFi Cellular Network",
    "abstract": "           Light-fidelity (LiFi) is an emerging technology for high-speed short-range mobile communications. Inter-cell interference (ICI) is an important issue that limits the system performance in an optical attocell network. Angle diversity receivers (ADRs) have been proposed to mitigate ICI. In this paper, the structure of pyramid receivers (PRs) and truncated pyramid receivers (TPRs) are studied. The coverage problems of PRs and TPRs are defined and investigated, and the lower bound of field of view (FOV) for each PD is given analytically. The impact of random device orientation and diffuse link signal propagation are taken into consideration. The performances of PRs and TPRs are compared and then optimized ADR structures are proposed. The performance comparison between the select best combining (SBC) and maximum ratio combining (MRC) is given under different noise levels. It is shown that SBC will outperform MRC in an interference limited system, otherwise, MRC is a preferred scheme. In addition, the double source system, where each LiFi AP consists of two sources transmitting the same information signals but with opposite polarity, is proved to outperform the single source (SS) system under certain conditions.         ",
    "url": "https://arxiv.org/abs/2108.06025",
    "authors": [
      "Zhihong Zeng",
      "Chen Chen",
      "Svetislav Savovi",
      "Mohammad Dehghani Soltani",
      "Cheng Chen",
      "Majid Safari",
      "Harald Haas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.12478",
    "title": "GAME-ON: Graph Attention Network based Multimodal Fusion for Fake News Detection",
    "abstract": "           Social media in present times has a significant and growing influence. Fake news being spread on these platforms have a disruptive and damaging impact on our lives. Furthermore, as multimedia content improves the visibility of posts more than text data, it has been observed that often multimedia is being used for creating fake content. A plethora of previous multimodal-based work has tried to address the problem of modeling heterogeneous modalities in identifying fake content. However, these works have the following limitations: (1) inefficient encoding of inter-modal relations by utilizing a simple concatenation operator on the modalities at a later stage in a model, which might result in information loss; (2) training very deep neural networks with a disproportionate number of parameters on small but complex real-life multimodal datasets result in higher chances of overfitting. To address these limitations, we propose GAME-ON, a Graph Neural Network based end-to-end trainable framework that allows granular interactions within and across different modalities to learn more robust data representations for multimodal fake news detection. We use two publicly available fake news datasets, Twitter and Weibo, for evaluations. Our model outperforms on Twitter by an average of 11% and keeps competitive performance on Weibo, within a 2.6% margin, while using 65% fewer parameters than the best comparable state-of-the-art baseline.         ",
    "url": "https://arxiv.org/abs/2202.12478",
    "authors": [
      "Mudit Dhawan",
      "Shakshi Sharma",
      "Aditya Kadam",
      "Rajesh Sharma",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01290",
    "title": "Points2NeRF: Generating Neural Radiance Fields from 3D point cloud",
    "abstract": "           Contemporary registration devices for 3D visual information, such as LIDARs and various depth cameras, capture data as 3D point clouds. In turn, such clouds are challenging to be processed due to their size and complexity. Existing methods address this problem by fitting a mesh to the point cloud and rendering it instead. This approach, however, leads to the reduced fidelity of the resulting visualization and misses color information of the objects crucial in computer graphics applications. In this work, we propose to mitigate this challenge by representing 3D objects as Neural Radiance Fields (NeRFs). We leverage a hypernetwork paradigm and train the model to take a 3D point cloud with the associated color values and return a NeRF network's weights that reconstruct 3D objects from input 2D images. Our method provides efficient 3D object representation and offers several advantages over the existing approaches, including the ability to condition NeRFs and improved generalization beyond objects seen in training. The latter we also confirmed in the results of our empirical evaluation.         ",
    "url": "https://arxiv.org/abs/2206.01290",
    "authors": [
      "Dominik Zimny",
      "Joanna Waczy\u0144ska",
      "Tomasz Trzci\u0144ski",
      "Przemys\u0142aw Spurek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02001",
    "title": "A PDE-based Explanation of Extreme Numerical Sensitivities and Edge of Stability in Training Neural Networks",
    "abstract": "           We discover restrained numerical instabilities in current training practices of deep networks with stochastic gradient descent (SGD), and its variants. We show numerical error (on the order of the smallest floating point bit and thus the most extreme or limiting numerical perturbations induced from floating point arithmetic in training deep nets can be amplified significantly and result in significant test accuracy variance (sensitivities), comparable to the test accuracy variance due to stochasticity in SGD. We show how this is likely traced to instabilities of the optimization dynamics that are restrained, i.e., localized over iterations and regions of the weight tensor space. We do this by presenting a theoretical framework using numerical analysis of partial differential equations (PDE), and analyzing the gradient descent PDE of convolutional neural networks (CNNs). We show that it is stable only under certain conditions on the learning rate and weight decay. We show that rather than blowing up when the conditions are violated, the instability can be restrained. We show this is a consequence of the non-linear PDE associated with the gradient descent of the CNN, whose local linearization changes when over-driving the step size of the discretization, resulting in a stabilizing effect. We link restrained instabilities to the recently discovered Edge of Stability (EoS) phenomena, in which the stable step size predicted by classical theory is exceeded while continuing to optimize the loss and still converging. Because restrained instabilities occur at the EoS, our theory provides new insights and predictions about the EoS, in particular, the role of regularization and the dependence on the network complexity.         ",
    "url": "https://arxiv.org/abs/2206.02001",
    "authors": [
      "Yuxin Sun",
      "Dong Lao",
      "Ganesh Sundaramoorthi",
      "Anthony Yezzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2208.09116",
    "title": "Effective, Platform-Independent GUI Testing via Image Embedding and Reinforcement Learning",
    "abstract": "           Software applications have been playing an increasingly important role in various aspects of society. In particular, mobile apps and web apps are the most prevalent among all applications and are widely used in various industries as well as in people's daily lives. To help ensure mobile and web app quality, many approaches have been introduced to improve app GUI testing via automated exploration. Despite the extensive effort, existing approaches are still limited in reaching high code coverage, constructing high-quality models, and being generally applicable. Reinforcement learning-based approaches are faced with difficult challenges, including effective app state abstraction, reward function design, etc. Moreover, they heavily depend on the specific execution platforms, thus leading to poor generalizability and being unable to adapt to different platforms. We propose PIRLTest, an effective platform-independent approach for app testing. It utilizes computer vision and reinforcement learning techniques in a novel, synergistic manner for automated testing. It extracts the GUI widgets from GUI pages and characterizes the corresponding GUI layouts, embedding the GUI pages as states. The app GUI state combines the macroscopic perspective and the microscopic perspective, and attaches the critical semantic information from GUI images. This enables PIRLTest to be platform-independent and makes the testing approach generally applicable on different platforms. PIRLTest explores apps with the guidance of a curiosity-driven strategy, which uses a Q-network to estimate the values of specific state-action pairs to encourage more exploration in uncovered pages without platform dependency. The exploration will be assigned with rewards for all actions, which are designed considering both the app GUI states and the concrete widgets, to help the framework explore more uncovered pages.         ",
    "url": "https://arxiv.org/abs/2208.09116",
    "authors": [
      "Shengcheng Yu",
      "Chunrong Fang",
      "Xin Li",
      "Yuchen Ling",
      "Zhenyu Chen",
      "Zhendong Su"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2209.10414",
    "title": "Statement-Level Vulnerability Detection: Learning Vulnerability Patterns Through Information Theory and Contrastive Learning",
    "abstract": "           Software vulnerabilities are a serious and crucial concern. Typically, in a program or function consisting of hundreds or thousands of source code statements, there are only a few statements causing the corresponding vulnerabilities. Most current approaches to vulnerability labelling are done on a function or program level by experts with the assistance of machine learning tools. Extending this approach to the code statement level is much more costly and time-consuming and remains an open problem. In this paper, we propose a novel end-to-end deep learning-based approach to identify the vulnerability-relevant code statements of a specific function. Inspired by the specific structures observed in real-world vulnerable code, we first leverage mutual information for learning a set of latent variables representing the relevance of the source code statements to the corresponding function's vulnerability. We then propose novel clustered spatial contrastive learning in order to further improve the representation learning and the robust selection process of vulnerability-relevant code statements. Experimental results on real-world datasets of 200k+ C/C++ functions show the superiority of our method over other state-of-the-art baselines. In general, our method obtains a higher performance in VCP, VCA, and Top-10 ACC measures of between 3% to 14% over the baselines when running on real-world datasets in an unsupervised setting. Our released source code samples are publicly available at \\href{this https URL}{this https URL.}         ",
    "url": "https://arxiv.org/abs/2209.10414",
    "authors": [
      "Van Nguyen",
      "Trung Le",
      "Chakkrit Tantithamthavorn",
      "Michael Fu",
      "John Grundy",
      "Hung Nguyen",
      "Seyit Camtepe",
      "Paul Quirk",
      "Dinh Phung"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12956",
    "title": "Learning Provably Stable Local Volt/Var Controllers for Efficient Network Operation",
    "abstract": "           This paper develops a data-driven framework to synthesize local Volt/Var control strategies for distributed energy resources (DERs) in power distribution networks (DNs). Aiming to improve DN operational efficiency, as quantified by a generic optimal reactive power flow (ORPF) problem, we propose a two-stage approach. The first stage involves learning the manifold of optimal operating points determined by an ORPF instance. To synthesize local Volt/Var controllers, the learning task is partitioned into learning local surrogates (one per DER) of the optimal manifold with voltage input and reactive power output. Since these surrogates characterize efficient DN operating points, in the second stage, we develop local control schemes that steer the DN to these operating points. We identify the conditions on the surrogates and control parameters to ensure that the locally acting controllers collectively converge, in a global asymptotic sense, to a DN operating point agreeing with the local surrogates. We use neural networks to model the surrogates and enforce the identified conditions in the training phase. AC power flow simulations on the IEEE 37-bus network empirically bolster the theoretical stability guarantees obtained under linearized power flow assumptions. The tests further highlight the optimality improvement compared to prevalent benchmark methods.         ",
    "url": "https://arxiv.org/abs/2209.12956",
    "authors": [
      "Zhenyi Yuan",
      "Guido Cavraro",
      "Manish K. Singh",
      "Jorge Cort\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.02435",
    "title": "IRJIT: A Simple, Online, Information Retrieval Approach for Just-In-Time Software Defect Prediction",
    "abstract": "           Just-in-Time software defect prediction (JIT-SDP) prevents the introduction of defects into the software by identifying them at commit check-in time. Current software defect prediction approaches rely on manually crafted features such as change metrics and involve expensive to train machine learning or deep learning models. These models typically involve extensive training processes that may require significant computational resources and time. These characteristics can pose challenges when attempting to update the models in real-time as new examples become available, potentially impacting their suitability for fast online defect prediction. Furthermore, the reliance on a complex underlying model makes these approaches often less explainable, which means the developers cannot understand the reasons behind models' predictions. An approach that is not explainable might not be adopted in real-life development environments because of developers' lack of trust in its results. To address these limitations, we propose an approach called IRJIT that employs information retrieval on source code and labels new commits as buggy or clean based on their similarity to past buggy or clean commits. IRJIT approach is online and explainable as it can learn from new data without expensive retraining, and developers can see the documents that support a prediction, providing additional context. By evaluating 10 open-source datasets in a within project setting, we show that our approach is up to 112 times faster than the state-of-the-art ML and DL approaches, offers explainability at the commit and line level, and has comparable performance to the state-of-the-art.         ",
    "url": "https://arxiv.org/abs/2210.02435",
    "authors": [
      "Hareem Sahar",
      "Abdul Ali Bangash",
      "Abram Hindle",
      "Denilson Barbosa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.12117",
    "title": "Storage codes on coset graphs with asymptotically unit rate",
    "abstract": "           A storage code on a graph $G$ is a set of assignments of symbols to the vertices such that every vertex can recover its value by looking at its neighbors. We consider the question of constructing large-size storage codes on triangle-free graphs constructed as coset graphs of binary linear codes. Previously it was shown that there are infinite families of binary storage codes on coset graphs with rate converging to 3/4. Here we show that codes on such graphs can attain rate asymptotically approaching 1. Equivalently, this question can be phrased as a version of hat-guessing games on graphs (e.g., P.J. Cameron e.a., \\emph{Electronic J. Comb.} 2016). In this language, we construct triangle-free graphs with success probability of the players approaching one as the number of vertices tends to infinity. Furthermore, finding linear index codes of rate approaching zero is also an equivalent problem. Another family of storage codes on triangle-free graphs of rate approaching 1 was constructed earlier by A. Golovnev and I. Haviv (36th Computational Complexity Conf., 2021) relying on a different family of graphs.         ",
    "url": "https://arxiv.org/abs/2212.12117",
    "authors": [
      "Alexander Barg",
      "Moshe Schwartz",
      "Lev Yohananov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2302.04379",
    "title": "Et Tu Certifications: Robustness Certificates Yield Better Adversarial Examples",
    "abstract": "           In guaranteeing the absence of adversarial examples in an instance's neighbourhood, certification mechanisms play an important role in demonstrating neural net robustness. In this paper, we ask if these certifications can compromise the very models they help to protect? Our new \\emph{Certification Aware Attack} exploits certifications to produce computationally efficient norm-minimising adversarial examples $74 \\%$ more often than comparable attacks, while reducing the median perturbation norm by more than $10\\%$. While these attacks can be used to assess the tightness of certification bounds, they also highlight that releasing certifications can paradoxically reduce security.         ",
    "url": "https://arxiv.org/abs/2302.04379",
    "authors": [
      "Andrew C. Cullen",
      "Shijie Liu",
      "Paul Montague",
      "Sarah M. Erfani",
      "Benjamin I.P. Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.03996",
    "title": "A Unified Characterization of Private Learnability via Graph Theory",
    "abstract": "           We provide a unified framework for characterizing pure and approximate differentially private (DP) learnability. The framework uses the language of graph theory: for a concept class $\\mathcal{H}$, we define the contradiction graph $G$ of $\\mathcal{H}$. Its vertices are realizable datasets, and two datasets $S,S'$ are connected by an edge if they contradict each other (i.e., there is a point $x$ that is labeled differently in $S$ and $S'$). Our main finding is that the combinatorial structure of $G$ is deeply related to learning $\\mathcal{H}$ under DP. Learning $\\mathcal{H}$ under pure DP is captured by the fractional clique number of $G$. Learning $\\mathcal{H}$ under approximate DP is captured by the clique number of $G$. Consequently, we identify graph-theoretic dimensions that characterize DP learnability: the clique dimension and fractional clique dimension. Along the way, we reveal properties of the contradiction graph which may be of independent interest. We also suggest several open questions and directions for future research.         ",
    "url": "https://arxiv.org/abs/2304.03996",
    "authors": [
      "Noga Alon",
      "Shay Moran",
      "Hilla Schefler",
      "Amir Yehudayoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.07647",
    "title": "LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene Graphs with Weak Supervision",
    "abstract": "           We propose LASER, a neuro-symbolic approach to learn semantic video representations that capture rich spatial and temporal properties in video data by leveraging high-level logic specifications. In particular, we formulate the problem in terms of alignment between raw videos and spatio-temporal logic specifications. The alignment algorithm leverages a differentiable symbolic reasoner and a combination of contrastive, temporal, and semantics losses. It effectively and efficiently trains low-level perception models to extract a fine-grained video representation in the form of a spatio-temporal scene graph that conforms to the desired high-level specification. To practically reduce the manual effort of obtaining ground truth labels, we derive logic specifications from captions by employing a large language model with a generic prompting template. In doing so, we explore a novel methodology that weakly supervises the learning of spatio-temporal scene graphs with widely accessible video-caption data. We evaluate our method on three datasets with rich spatial and temporal specifications: 20BN-Something-Something, MUGEN, and OpenPVSG. We demonstrate that our method learns better fine-grained video semantics than existing baselines.         ",
    "url": "https://arxiv.org/abs/2304.07647",
    "authors": [
      "Jiani Huang",
      "Ziyang Li",
      "Mayur Naik",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2304.10268",
    "title": "BackCache: Mitigating Contention-Based Cache Timing Attacks by Hiding Cache Line Evictions",
    "abstract": "           Caches are used to reduce the speed differential between the CPU and memory to improve the performance of modern processors. However, attackers can use contention-based cache timing attacks to steal sensitive information from victim processes through carefully designed cache eviction sets. And L1 data cache attacks are widely exploited and pose a significant privacy and confidentiality threat. Existing hardware-based countermeasures mainly focus on cache partitioning, randomization, and cache line flushing, which unfortunately either incur high overhead or can be circumvented by sophisticated attacks. In this paper, we propose a novel hardware-software co-design called BackCache with the idea of always achieving cache hits instead of cache misses to mitigate contention-based cache timing attacks on the L1 data cache. BackCache places the evicted cache lines from the L1 data cache into a fully-associative backup cache to hide the evictions. To improve the security of BackCache, we introduce a randomly used replacement policy (RURP) and a dynamic backup cache resizing mechanism. We also present a theoretical security analysis to demonstrate the effectiveness of BackCache. Our evaluation on the gem5 simulator shows that BackCache can degrade the performance by 2.61%, 2.66%, and 3.36% For OS kernel, single-thread, and multi-thread benchmarks.         ",
    "url": "https://arxiv.org/abs/2304.10268",
    "authors": [
      "Quancheng Wang",
      "Xige Zhang",
      "Han Wang",
      "Yuzhe Gu",
      "Ming Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.12519",
    "title": "DPIC: Decoupling Prompt and Intrinsic Characteristics for LLM Generated Text Detection",
    "abstract": "           Large language models (LLMs) have the potential to generate texts that pose risks of misuse, such as plagiarism, planting fake reviews on e-commerce platforms, or creating inflammatory false tweets. Consequently, detecting whether a text is generated by LLMs has become increasingly important. Existing high-quality detection methods usually require access to the interior of the model to extract the intrinsic characteristics. However, since we do not have access to the interior of the black-box model, we must resort to surrogate models, which impacts detection quality. In order to achieve high-quality detection of black-box models, we would like to extract deep intrinsic characteristics of the black-box model generated texts. We view the generation process as a coupled process of prompt and intrinsic characteristics of the generative model. Based on this insight, we propose to decouple prompt and intrinsic characteristics (DPIC) for LLM-generated text detection method. Specifically, given a candidate text, DPIC employs an auxiliary LLM to reconstruct the prompt corresponding to the candidate text, then uses the prompt to regenerate text by the auxiliary LLM, which makes the candidate text and the regenerated text align with their prompts, respectively. Then, the similarity between the candidate text and the regenerated text is used as a detection feature, thus eliminating the prompt in the detection process, which allows the detector to focus on the intrinsic characteristics of the generative model. Compared to the baselines, DPIC has achieved an average improvement of 6.76\\% and 2.91\\% in detecting texts from different domains generated by GPT4 and Claude3, respectively.         ",
    "url": "https://arxiv.org/abs/2305.12519",
    "authors": [
      "Xiao Yu",
      "Yuang Qi",
      "Kejiang Chen",
      "Guoqiang Chen",
      "Xi Yang",
      "Pengyuan Zhu",
      "Xiuwei Shang",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14225",
    "title": "ManiTweet: A New Benchmark for Identifying Manipulation of News on Social Media",
    "abstract": "           Considerable advancements have been made to tackle the misrepresentation of information derived from reference articles in the domains of fact-checking and faithful summarization. However, an unaddressed aspect remains - the identification of social media posts that manipulate information within associated news articles. This task presents a significant challenge, primarily due to the prevalence of personal opinions in such posts. We present a novel task, identifying manipulation of news on social media, which aims to detect manipulation in social media posts and identify manipulated or inserted information. To study this task, we have proposed a data collection schema and curated a dataset called ManiTweet, consisting of 3.6K pairs of tweets and corresponding articles. Our analysis demonstrates that this task is highly challenging, with large language models (LLMs) yielding unsatisfactory performance. Additionally, we have developed a simple yet effective basic model that outperforms LLMs significantly on the ManiTweet dataset. Finally, we have conducted an exploratory analysis of human-written tweets, unveiling intriguing connections between manipulation and the domain and factuality of news articles, as well as revealing that manipulated sentences are more likely to encapsulate the main story or consequences of a news outlet.         ",
    "url": "https://arxiv.org/abs/2305.14225",
    "authors": [
      "Kung-Hsiang Huang",
      "Hou Pong Chan",
      "Kathleen McKeown",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.08201",
    "title": "Graph Laplacian Learning with Exponential Family Noise",
    "abstract": "           Graph signal processing (GSP) is a prominent framework for analyzing signals on non-Euclidean domains. The graph Fourier transform (GFT) uses the combinatorial graph Laplacian matrix to reveal the spectral decomposition of signals in the graph frequency domain. However, a common challenge in applying GSP methods is that in many scenarios the underlying graph of a system is unknown. A solution in such cases is to construct the unobserved graph from available data, which is commonly referred to as graph or network inference. Although different graph inference methods exist, these are restricted to learning from either smooth graph signals or simple additive Gaussian noise. Other types of noisy data, such as discrete counts or binary digits, are rather common in real-world applications, yet are underexplored in graph inference. In this paper, we propose a versatile graph inference framework for learning from graph signals corrupted by exponential family noise. Our framework generalizes previous methods from continuous smooth graph signals to various data types. We propose an alternating algorithm that jointly estimates the graph Laplacian and the unobserved smooth representation from the noisy signals. We also extend our approach to a variational form to account for the inherent stochasticity of the latent smooth representation. Finally, since real-world graph signals are frequently non-independent and temporally correlated, we further adapt our original setting to a time-vertex formulation. We demonstrate on synthetic and real-world data that our new algorithms outperform competing Laplacian estimation methods that suffer from noise model mismatch.         ",
    "url": "https://arxiv.org/abs/2306.08201",
    "authors": [
      "Changhao Shi",
      "Gal Mishne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.13083",
    "title": "Improved Energy-Based Signal Detection for Ambient Backscatter Communications",
    "abstract": "           In ambient backscatter communication (AmBC) systems, passive tags connect to a reader by reflecting an ambient radio frequency (RF) signal. However, the reader may not know the channel states and RF source parameters. The traditional energy detector (TED) appears to be an ideal solution. However, it performs poorly under these conditions. To address this, we propose two new detectors: (1) A joint correlation-energy detector (JCED) based on the first-order correlation of the received samples and (2) An improved energy detector (IED) based on the p-th norm of the received signal vector. We compare the performance of IED and TED under the generalized noise model using McLeish distribution and derive a general analytical formula for the area under the receiver operating characteristic (ROC) curves. Based on our results, both detectors outperform TED. For example, the probability of detection with a false alarm rate of 1\\% for JCED and IED is 22.97\\% and 5.41\\% higher, respectively, compared to TED for a single-antenna reader. Using the direct interference cancellation (DIC) technique, these gains are 34.92\\% and 3.7\\%, respectively. With a four-antenna array at the reader and a 5\\% false alarm rate, the JCED shows a significant BER improvement of 28.68\\% without DIC and 48.21\\% with DIC.         ",
    "url": "https://arxiv.org/abs/2306.13083",
    "authors": [
      "S. Zargari",
      "C. Tellambura",
      "A. Maaref"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.07429",
    "title": "Semantic Similarity Loss for Neural Source Code Summarization",
    "abstract": "           This paper presents a procedure for and evaluation of using a semantic similarity metric as a loss function for neural source code summarization. Code summarization is the task of writing natural language descriptions of source code. Neural code summarization refers to automated techniques for generating these descriptions using neural networks. Almost all current approaches involve neural networks as either standalone models or as part of a pretrained large language models e.g., GPT, Codex, LLaMA. Yet almost all also use a categorical cross-entropy (CCE) loss function for network optimization. Two problems with CCE are that 1) it computes loss over each word prediction one-at-a-time, rather than evaluating a whole sentence, and 2) it requires a perfect prediction, leaving no room for partial credit for synonyms. In this paper, we extend our previous work on semantic similarity metrics to show a procedure for using semantic similarity as a loss function to alleviate this problem, and we evaluate this procedure in several settings in both metrics-driven and human studies. In essence, we propose to use a semantic similarity metric to calculate loss over the whole output sentence prediction per training batch, rather than just loss for each word. We also propose to combine our loss with CCE for each word, which streamlines the training process compared to baselines. We evaluate our approach over several baselines and report improvement in the vast majority of conditions.         ",
    "url": "https://arxiv.org/abs/2308.07429",
    "authors": [
      "Chia-Yi Su",
      "Collin McMillan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.14348",
    "title": "Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM",
    "abstract": "           Recently, Large Language Models (LLMs) have made significant advancements and are now widely used across various domains. Unfortunately, there has been a rising concern that LLMs can be misused to generate harmful or malicious content. Though a line of research has focused on aligning LLMs with human values and preventing them from producing inappropriate content, such alignments are usually vulnerable and can be bypassed by alignment-breaking attacks via adversarially optimized or handcrafted jailbreaking prompts. In this work, we introduce a Robustly Aligned LLM (RA-LLM) to defend against potential alignment-breaking attacks. RA-LLM can be directly constructed upon an existing aligned LLM with a robust alignment checking function, without requiring any expensive retraining or fine-tuning process of the original LLM. Furthermore, we also provide a theoretical analysis for RA-LLM to verify its effectiveness in defending against alignment-breaking attacks. Through real-world experiments on open-source large language models, we demonstrate that RA-LLM can successfully defend against both state-of-the-art adversarial prompts and popular handcrafted jailbreaking prompts by reducing their attack success rates from nearly 100% to around 10% or less.         ",
    "url": "https://arxiv.org/abs/2309.14348",
    "authors": [
      "Bochuan Cao",
      "Yuanpu Cao",
      "Lu Lin",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.15375",
    "title": "PPG-to-ECG Signal Translation for Continuous Atrial Fibrillation Detection via Attention-based Deep State-Space Modeling",
    "abstract": "           Photoplethysmography (PPG) is a cost-effective and non-invasive technique that utilizes optical methods to measure cardiac physiology. PPG has become increasingly popular in health monitoring and is used in various commercial and clinical wearable devices. Compared to electrocardiography (ECG), PPG does not provide substantial clinical diagnostic value, despite the strong correlation between the two. Here, we propose a subject-independent attention-based deep state-space model (ADSSM) to translate PPG signals to corresponding ECG waveforms. The model is not only robust to noise but also data-efficient by incorporating probabilistic prior knowledge. To evaluate our approach, 55 subjects' data from the MIMIC-III database were used in their original form, and then modified with noise, mimicking real-world scenarios. Our approach was proven effective as evidenced by the PR-AUC of 0.986 achieved when inputting the translated ECG signals into an existing atrial fibrillation (AFib) detector. ADSSM enables the integration of ECG's extensive knowledge base and PPG's continuous measurement for early diagnosis of cardiovascular disease.         ",
    "url": "https://arxiv.org/abs/2309.15375",
    "authors": [
      "Khuong Vo",
      "Mostafa El-Khamy",
      "Yoojin Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01770",
    "title": "A simple connection from loss flatness to compressed representations in neural networks",
    "abstract": "           The generalization capacity of deep neural networks has been studied in a variety of ways, including at least two distinct categories of approaches: one based on the shape of the loss landscape in parameter space, and the other based on the structure of the representation manifold in feature space (that is, in the space of unit activities). Although these two approaches are related, they are rarely studied together explicitly. Here, we present an analysis that bridges this gap. We show that in the final phase of learning in deep neural networks, the compression of the manifold of neural representations correlates with the flatness of the loss around the minima explored by SGD. This correlation is predicted by a relatively simple mathematical relationship: a flatter loss corresponds to a lower upper bound on the compression metrics of neural representations. Our work builds upon the linear stability insight by Ma and Ying, deriving inequalities between various compression metrics and quantities involving sharpness. Empirically, our derived inequality predicts a consistently positive correlation between representation compression and loss sharpness in multiple experimental settings. Overall, we advance a dual perspective on generalization in neural networks in both parameter and feature space.         ",
    "url": "https://arxiv.org/abs/2310.01770",
    "authors": [
      "Shirui Chen",
      "Stefano Recanatesi",
      "Eric Shea-Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07765",
    "title": "Feature Learning and Generalization in Deep Networks with Orthogonal Weights",
    "abstract": "           Fully-connected deep neural networks with weights initialized from independent Gaussian distributions can be tuned to criticality, which prevents the exponential growth or decay of signals propagating through the network. However, such networks still exhibit fluctuations that grow linearly with the depth of the network, which may impair the training of networks with width comparable to depth. We show analytically that rectangular networks with tanh activations and weights initialized from the ensemble of orthogonal matrices have corresponding preactivation fluctuations which are independent of depth, to leading order in inverse width. Moreover, we demonstrate numerically that, at initialization, all correlators involving the neural tangent kernel (NTK) and its descendants at leading order in inverse width -- which govern the evolution of observables during training -- saturate at a depth of $\\sim 20$, rather than growing without bound as in the case of Gaussian initializations. We speculate that this structure preserves finite-width feature learning while reducing overall noise, thus improving both generalization and training speed in deep networks with depth comparable to width. We provide some experimental justification by relating empirical measurements of the NTK to the superior performance of deep nonlinear orthogonal networks trained under full-batch gradient descent on the MNIST and CIFAR-10 classification tasks.         ",
    "url": "https://arxiv.org/abs/2310.07765",
    "authors": [
      "Hannah Day",
      "Yonatan Kahn",
      "Daniel A. Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.14552",
    "title": "Knowledge-Induced Medicine Prescribing Network for Medication Recommendation",
    "abstract": "           Extensive adoption of electronic health records (EHRs) offers opportunities for their use in various downstream clinical analyses. To accomplish this purpose, enriching an EHR cohort with external knowledge (e.g., standardized medical ontology and wealthy semantics) could help us reveal more comprehensive insights via a spectrum of informative relations among medical codes. Nevertheless, harnessing those beneficial interconnections was scarcely exercised, especially in the medication recommendation task. This study proposes a novel Knowledge-Induced Medicine Prescribing Network (KindMed) to recommend medicines by inducing knowledge from myriad medical-related external sources upon the EHR cohort and rendering interconnected medical codes as medical knowledge graphs (KGs). On top of relation-aware graph representation learning to obtain an adequate embedding over such KGs, we leverage hierarchical sequence learning to discover and fuse temporal dynamics of clinical (i.e., diagnosis and procedures) and medicine streams across patients' historical admissions to foster personalized recommendations. Eventually, we employ attentive prescribing that accounts for three essential patient representations, i.e., a summary of joint historical medical records, clinical progression, and the current clinical state of patients. We validated the effectiveness of our KindMed on the augmented real-world EHR cohorts, achieving improved recommendation performances against a handful of graph-driven baselines.         ",
    "url": "https://arxiv.org/abs/2310.14552",
    "authors": [
      "Ahmad Wisnu Mulyadi",
      "Heung-Il Suk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16560",
    "title": "Resurrecting Label Propagation for Graphs with Heterophily and Label Noise",
    "abstract": "           Label noise is a common challenge in large datasets, as it can significantly degrade the generalization ability of deep neural networks. Most existing studies focus on noisy labels in computer vision; however, graph models encompass both node features and graph topology as input, and become more susceptible to label noise through message-passing mechanisms. Recently, only a few works have been proposed to tackle the label noise on graphs. One significant limitation is that they operate under the assumption that the graph exhibits homophily and that the labels are distributed smoothly. However, real-world graphs can exhibit varying degrees of heterophily, or even be dominated by heterophily, which results in the inadequacy of the current methods. In this paper, we study graph label noise in the context of arbitrary heterophily, with the aim of rectifying noisy labels and assigning labels to previously unlabeled nodes. We begin by conducting two empirical analyses to explore the impact of graph homophily on graph label noise. Following observations, we propose a efficient algorithm, denoted as $R^{2}LP$. Specifically, $R^{2}LP$ is an iterative algorithm with three steps: (1) reconstruct the graph to recover the homophily property, (2) utilize label propagation to rectify the noisy labels, (3) select high-confidence labels to retain for the next iteration. By iterating these steps, we obtain a set of correct labels, ultimately achieving high accuracy in the node classification task. The theoretical analysis is also provided to demonstrate its remarkable denoising effect. Finally, we perform experiments on ten benchmark datasets with different levels of graph heterophily and various types of noise. In these experiments, we compare the performance of $R^{2}LP$ against ten typical baseline methods. Our results illustrate the superior performance of the proposed $R^{2}LP$.         ",
    "url": "https://arxiv.org/abs/2310.16560",
    "authors": [
      "Yao Cheng",
      "Caihua Shan",
      "Yifei Shen",
      "Xiang Li",
      "Siqiang Luo",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08369",
    "title": "How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection",
    "abstract": "           To combat the misuse of Large Language Models (LLMs), many recent studies have presented LLM-generated-text detectors with promising performance. When users instruct LLMs to generate texts, the instruction can include different constraints depending on the user's need. However, most recent studies do not cover such diverse instruction patterns when creating datasets for LLM detection. In this paper, we reveal that even task-oriented constraints -- constraints that would naturally be included in an instruction and are not related to detection-evasion -- cause existing powerful detectors to have a large variance in detection performance. We focus on student essay writing as a realistic domain and manually create task-oriented constraints based on several factors for essay quality. Our experiments show that the standard deviation (SD) of current detector performance on texts generated by an instruction with such a constraint is significantly larger (up to an SD of 14.4 F1-score) than that by generating texts multiple times or paraphrasing the instruction. We also observe an overall trend where the constraints can make LLM detection more challenging than without them. Finally, our analysis indicates that the high instruction-following ability of LLMs fosters the large impact of such constraints on detection performance.         ",
    "url": "https://arxiv.org/abs/2311.08369",
    "authors": [
      "Ryuto Koike",
      "Masahiro Kaneko",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09096",
    "title": "Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization",
    "abstract": "           While significant attention has been dedicated to exploiting weaknesses in LLMs through jailbreaking attacks, there remains a paucity of effort in defending against these attacks. We point out a pivotal factor contributing to the success of jailbreaks: the intrinsic conflict between the goals of being helpful and ensuring safety. Accordingly, we propose to integrate goal prioritization at both training and inference stages to counteract. Implementing goal prioritization during inference substantially diminishes the Attack Success Rate (ASR) of jailbreaking from 66.4% to 3.6% for ChatGPT. And integrating goal prioritization into model training reduces the ASR from 71.0% to 6.6% for Llama2-13B. Remarkably, even in scenarios where no jailbreaking samples are included during training, our approach slashes the ASR by half. Additionally, our findings reveal that while stronger LLMs face greater safety risks, they also possess a greater capacity to be steered towards defending against such attacks, both because of their stronger ability in instruction following. Our work thus contributes to the comprehension of jailbreaking attacks and defenses, and sheds light on the relationship between LLMs' capability and safety. Our code is available at \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2311.09096",
    "authors": [
      "Zhexin Zhang",
      "Junxiao Yang",
      "Pei Ke",
      "Fei Mi",
      "Hongning Wang",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09835",
    "title": "ML-Bench: Evaluating Large Language Models and Agents for Machine Learning Tasks on Repository-Level Code",
    "abstract": "           Despite Large Language Models (LLMs) like GPT-4 achieving impressive results in function-level code generation, they struggle with repository-scale code understanding (e.g., coming up with the right arguments for calling routines), requiring a deeper comprehension of complex file interactions. Also, recently, people have developed LLM agents that attempt to interact with repository code (e.g., compiling and evaluating its execution), prompting the need to evaluate their performance. These gaps have motivated our development of ML-Bench, a benchmark rooted in real-world programming applications that leverage existing code repositories to perform tasks. Addressing the need for LLMs to interpret long code contexts and translate instructions into precise, executable scripts, ML-Bench encompasses annotated 9,641 examples across 18 GitHub repositories, challenging LLMs to accommodate user-specified arguments and documentation intricacies effectively. To evaluate both LLMs and AI agents, two setups are employed: ML-LLM-Bench for assessing LLMs' text-to-code conversion within a predefined deployment environment, and ML-Agent-Bench for testing autonomous agents in an end-to-end task execution within a Linux sandbox environment. Our findings indicate that while GPT-4o leads with a Pass@5 rate surpassing 50%, there remains significant scope for improvement, highlighted by issues such as hallucinated outputs and difficulties with bash script generation. Notably, in the more demanding ML-Agent-Bench, GPT-4o achieves a 76.47% success rate, reflecting the efficacy of iterative action and feedback in complex task resolution.         ",
    "url": "https://arxiv.org/abs/2311.09835",
    "authors": [
      "Xiangru Tang",
      "Yuliang Liu",
      "Zefan Cai",
      "Yanjun Shao",
      "Junjie Lu",
      "Yichi Zhang",
      "Zexuan Deng",
      "Helan Hu",
      "Kaikai An",
      "Ruijun Huang",
      "Shuzheng Si",
      "Sheng Chen",
      "Haozhe Zhao",
      "Liang Chen",
      "Yan Wang",
      "Tianyu Liu",
      "Zhiwei Jiang",
      "Baobao Chang",
      "Yin Fang",
      "Yujia Qin",
      "Wangchunshu Zhou",
      "Yilun Zhao",
      "Arman Cohan",
      "Mark Gerstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.07042",
    "title": "Rectified deep neural networks overcome the curse of dimensionality when approximating solutions of McKean--Vlasov stochastic differential equations",
    "abstract": "           In this paper we prove that rectified deep neural networks do not suffer from the curse of dimensionality when approximating McKean--Vlasov SDEs in the sense that the number of parameters in the deep neural networks only grows polynomially in the space dimension $d$ of the SDE and the reciprocal of the accuracy $\\epsilon$.         ",
    "url": "https://arxiv.org/abs/2312.07042",
    "authors": [
      "Ariel Neufeld",
      "Tuan Anh Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2312.12186",
    "title": "Social Learning in Community Structured Graphs",
    "abstract": "           Traditional social learning frameworks consider environments with a homogeneous state, where each agent receives observations conditioned on that true state of nature. In this work, we relax this assumption and study the distributed hypothesis testing problem in a heterogeneous environment, where each agent can receive observations conditioned on their own personalized state of nature (or truth). We particularly focus on community structured networks, where each community admits their own true hypothesis. This scenario is common in various contexts, such as when sensors are spatially distributed, or when individuals in a social network have differing views or opinions. We show that the adaptive social learning strategy is a preferred choice for nonstationary environments, and allows each cluster to discover its own truth.         ",
    "url": "https://arxiv.org/abs/2312.12186",
    "authors": [
      "Valentina Shumovskaia",
      "Mert Kayaalp",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2401.00137",
    "title": "SSL-OTA: Unveiling Backdoor Threats in Self-Supervised Learning for Object Detection",
    "abstract": "           The extensive adoption of Self-supervised learning(SSL) has led to an increased security threat from backdoor attacks. While existing research has mainly focused on backdoor attacks in image classification, there has been limited exploration of their implications for object detection. Object detection plays a critical role in security-sensitive applications, such as autonomous driving, where backdoor attacks seriously threaten human life and property. In this work, we propose the first backdoor attack designed for object detection tasks in SSL scenarios, called Object Transform Attack (SSL-OTA). SSL-OTA employs a trigger capable of altering predictions of the target object to the desired category, encompassing two attacks: Naive Attack(NA) and Dual-Source Blending Attack (DSBA). NA conducts data poisoning during downstream fine-tuning of the object detector, while DSBA additionally injects backdoors into the pre-trained encoder. We establish appropriate metrics and conduct extensive experiments on benchmark datasets, demonstrating the effectiveness of our proposed attack and its resistance to potential defenses. Notably, both NA and DSBA achieve high attack success rates (ASR) at extremely low poisoning rates (0.5%). The results underscore the importance of considering backdoor threats in SSL-based object detection and contribute a novel perspective to the field.         ",
    "url": "https://arxiv.org/abs/2401.00137",
    "authors": [
      "Qiannan Wang",
      "Changchun Yin",
      "Lu Zhou",
      "Liming Fang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.09074",
    "title": "Code Simulation Challenges for Large Language Models",
    "abstract": "           Many reasoning, planning, and problem-solving tasks share an intrinsic algorithmic nature: correctly simulating each step is a sufficient condition to solve them correctly. This work studies to what extent Large Language Models (LLMs) can simulate coding and algorithmic tasks to provide insights into general capabilities in such algorithmic reasoning tasks. We introduce benchmarks for straight-line programs, code that contains critical paths, and approximate and redundant instructions. We further assess the simulation capabilities of LLMs with sorting algorithms and nested loops and show that a routine's computational complexity directly affects an LLM's ability to simulate its execution. While the most powerful LLMs exhibit relatively strong simulation capabilities, the process is fragile, seems to rely heavily on pattern recognition, and is affected by memorisation. We propose a novel off-the-shelf prompting method, Chain of Simulation (CoSm), which instructs LLMs to simulate code execution line by line/follow the computation pattern of compilers. CoSm efficiently helps LLMs reduce memorisation and shallow pattern recognition while improving simulation performance. We consider the success of CoSm in code simulation to be inspirational for other general routine simulation reasoning tasks.         ",
    "url": "https://arxiv.org/abs/2401.09074",
    "authors": [
      "Emanuele La Malfa",
      "Christoph Weinhuber",
      "Orazio Torre",
      "Fangru Lin",
      "Samuele Marro",
      "Anthony Cohn",
      "Nigel Shadbolt",
      "Michael Wooldridge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2401.09520",
    "title": "Port-Hamiltonian Neural ODE Networks on Lie Groups For Robot Dynamics Learning and Control",
    "abstract": "           Accurate models of robot dynamics are critical for safe and stable control and generalization to novel operational conditions. Hand-designed models, however, may be insufficiently accurate, even after careful parameter tuning. This motivates the use of machine learning techniques to approximate the robot dynamics over a training set of state-control trajectories. The dynamics of many robots are described in terms of their generalized coordinates on a matrix Lie group, e.g. on $SE(3)$ for ground, aerial, and underwater vehicles, and generalized velocity, and satisfy conservation of energy principles. This paper proposes a port-Hamiltonian formulation over a Lie group of the structure of a neural ordinary differential equation (ODE) network to approximate the robot dynamics. In contrast to a black-box ODE network, our formulation embeds energy conservation principle and Lie group's constraints in the dynamics model and explicitly accounts for energy-dissipation effect such as friction and drag forces in the dynamics model. We develop energy shaping and damping injection control for the learned, potentially under-actuated Hamiltonian dynamics to enable a unified approach for stabilization and trajectory tracking with various robot platforms.         ",
    "url": "https://arxiv.org/abs/2401.09520",
    "authors": [
      "Thai Duong",
      "Abdullah Altawaitan",
      "Jason Stanley",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.12732",
    "title": "CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process",
    "abstract": "           Cross-domain recommendation (CDR) has been proven as a promising way to tackle the user cold-start problem, which aims to make recommendations for users in the target domain by transferring the user preference derived from the source domain. Traditional CDR studies follow the embedding and mapping (EMCDR) paradigm, which transfers user representations from the source to target domain by learning a user-shared mapping function, neglecting the user-specific preference. Recent CDR studies attempt to learn user-specific mapping functions in meta-learning paradigm, which regards each user's CDR as an individual task, but neglects the preference correlations among users, limiting the beneficial information for user representations. Moreover, both of the paradigms neglect the explicit user-item interactions from both domains during the mapping process. To address the above issues, this paper proposes a novel CDR framework with neural process (NP), termed as CDRNP. Particularly, it develops the meta-learning paradigm to leverage user-specific preference, and further introduces a stochastic process by NP to capture the preference correlations among the overlapping and cold-start users, thus generating more powerful mapping functions by mapping the user-specific preference and common preference correlations to a predictive probability distribution. In addition, we also introduce a preference remainer to enhance the common preference from the overlapping users, and finally devises an adaptive conditional decoder with preference modulation to make prediction for cold-start users with items in the target domain. Experimental results demonstrate that CDRNP outperforms previous SOTA methods in three real-world CDR scenarios.         ",
    "url": "https://arxiv.org/abs/2401.12732",
    "authors": [
      "Xiaodong Li",
      "Jiawei Sheng",
      "Jiangxia Cao",
      "Wenyuan Zhang",
      "Quangang Li",
      "Tingwen Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.14580",
    "title": "Design Your Own Universe: A Physics-Informed Agnostic Method for Enhancing Graph Neural Networks",
    "abstract": "           Physics-informed Graph Neural Networks have achieved remarkable performance in learning through graph-structured data by mitigating common GNN challenges such as over-smoothing, over-squashing, and heterophily adaption. Despite these advancements, the development of a simple yet effective paradigm that appropriately integrates previous methods for handling all these challenges is still underway. In this paper, we draw an analogy between the propagation of GNNs and particle systems in physics, proposing a model-agnostic enhancement framework. This framework enriches the graph structure by introducing additional nodes and rewiring connections with both positive and negative weights, guided by node labeling information. We theoretically verify that GNNs enhanced through our approach can effectively circumvent the over-smoothing issue and exhibit robustness against over-squashing. Moreover, we conduct a spectral analysis on the rewired graph to demonstrate that the corresponding GNNs can fit both homophilic and heterophilic graphs. Empirical validations on benchmarks for homophilic, heterophilic graphs, and long-term graph datasets show that GNNs enhanced by our method significantly outperform their original counterparts.         ",
    "url": "https://arxiv.org/abs/2401.14580",
    "authors": [
      "Dai Shi",
      "Andi Han",
      "Lequan Lin",
      "Yi Guo",
      "Zhiyong Wang",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.05626",
    "title": "Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle Escaping, and Network Embedding",
    "abstract": "           In this paper, we investigate the loss landscape of one-hidden-layer neural networks with ReLU-like activation functions trained with the empirical squared loss. As the activation function is non-differentiable, it is so far unclear how to completely characterize the stationary points. We propose the conditions for stationarity that apply to both non-differentiable and differentiable cases. Additionally, we show that, if a stationary point does not contain \"escape neurons\", which are defined with first-order conditions, then it must be a local minimum. Moreover, for the scalar-output case, the presence of an escape neuron guarantees that the stationary point is not a local minimum. Our results refine the description of the saddle-to-saddle training process starting from infinitesimally small (vanishing) initialization for shallow ReLU-like networks, linking saddle escaping directly with the parameter changes of escape neurons. Moreover, we are also able to fully discuss how network embedding, which is to instantiate a narrower network within a wider network, reshapes the stationary points.         ",
    "url": "https://arxiv.org/abs/2402.05626",
    "authors": [
      "Zhengqing Wu",
      "Berfin Simsek",
      "Francois Ged"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.06674",
    "title": "On the Impact of Dataset Properties on Membership Privacy of Deep Learning",
    "abstract": "           We apply a state-of-the-art membership inference attack (MIA) to systematically test the practical privacy vulnerability of fine-tuning large image classification models. We focus on understanding the properties of data sets and samples that make them vulnerable to membership inference. In terms of data set properties, we find a strong power law dependence between the number of examples per class in the data and the MIA vulnerability, as measured by true positive rate of the attack at a low false positive rate. We train a linear model to predict true positive rate based on data set properties and observe good fit for MIA vulnerability on unseen data. To analyse the phenomenon theoretically, we reproduce the result on a simplified model of membership inference that behaves similarly to our experimental data. We prove that in this model, the logarithm of the difference of true and false positive rates depends linearly on the logarithm of the number of examples per class.For an individual sample, the gradient norm is predictive of its vulnerability.         ",
    "url": "https://arxiv.org/abs/2402.06674",
    "authors": [
      "Marlon Tobaben",
      "Joonas J\u00e4lk\u00f6",
      "Gauri Pradhan",
      "Yuan He",
      "Antti Honkela"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.09151",
    "title": "Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for Chinese Mental Health Text Analysis",
    "abstract": "           In the current environment, psychological issues are prevalent and widespread, with social media serving as a key outlet for individuals to share their feelings. This results in the generation of vast quantities of data daily, where negative emotions have the potential to precipitate crisis situations. There is a recognized need for models capable of efficient analysis. While pre-trained language models have demonstrated their effectiveness broadly, there's a noticeable gap in pre-trained models tailored for specialized domains like psychology. To address this, we have collected a huge dataset from Chinese social media platforms and enriched it with publicly available datasets to create a comprehensive database encompassing 3.36 million text entries. To enhance the model's applicability to psychological text analysis, we integrated psychological lexicons into the pre-training masking mechanism. Building on an existing Chinese language model, we performed adaptive training to develop a model specialized for the psychological domain. We evaluated our model's performance across six public datasets, where it demonstrated improvements compared to eight other models. Additionally, in the qualitative comparison experiment, our model provided psychologically relevant predictions given the masked sentences. Due to concerns regarding data privacy, the dataset will not be made publicly available. However, we have made the pre-trained models and codes publicly accessible to the community via: this https URL.         ",
    "url": "https://arxiv.org/abs/2402.09151",
    "authors": [
      "Wei Zhai",
      "Hongzhi Qi",
      "Qing Zhao",
      "Jianqiang Li",
      "Ziqi Wang",
      "Han Wang",
      "Bing Xiang Yang",
      "Guanghui Fu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.00278",
    "title": "Shifted Interpolation for Differential Privacy",
    "abstract": "           Noisy gradient descent and its variants are the predominant algorithms for differentially private machine learning. It is a fundamental question to quantify their privacy leakage, yet tight characterizations remain open even in the foundational setting of convex losses. This paper improves over previous analyses by establishing (and refining) the \"privacy amplification by iteration\" phenomenon in the unifying framework of $f$-differential privacy--which tightly captures all aspects of the privacy loss and immediately implies tighter privacy accounting in other notions of differential privacy, e.g., $(\\varepsilon,\\delta)$-DP and R\u00e9nyi DP. Our key technical insight is the construction of shifted interpolated processes that unravel the popular shifted-divergences argument, enabling generalizations beyond divergence-based relaxations of DP. Notably, this leads to the first exact privacy analysis in the foundational setting of strongly convex optimization. Our techniques extend to many settings: convex/strongly convex, constrained/unconstrained, full/cyclic/stochastic batches, and all combinations thereof. As an immediate corollary, we recover the $f$-DP characterization of the exponential mechanism for strongly convex optimization in Gopi et al. (2022), and moreover extend this result to more general settings.         ",
    "url": "https://arxiv.org/abs/2403.00278",
    "authors": [
      "Jinho Bok",
      "Weijie Su",
      "Jason M. Altschuler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.02567",
    "title": "Eliciting Better Multilingual Structured Reasoning from LLMs through Code",
    "abstract": "           The development of large language models (LLM) has shown progress on reasoning, though studies have largely considered either English or simple reasoning tasks. To address this, we introduce a multilingual structured reasoning and explanation dataset, termed xSTREET, that covers four tasks across six languages. xSTREET exposes a gap in base LLM performance between English and non-English reasoning tasks. We then propose two methods to remedy this gap, building on the insight that LLMs trained on code are better reasoners. First, at training time, we augment a code dataset with multilingual comments using machine translation while keeping program code as-is. Second, at inference time, we bridge the gap between training and inference by employing a prompt structure that incorporates step-by-step code primitives to derive new facts and find a solution. Our methods show improved multilingual performance on xSTREET, most notably on the scientific commonsense reasoning subtask. Furthermore, the models show no regression on non-reasoning tasks, thus demonstrating our techniques maintain general-purpose abilities.         ",
    "url": "https://arxiv.org/abs/2403.02567",
    "authors": [
      "Bryan Li",
      "Tamer Alkhouli",
      "Daniele Bonadiman",
      "Nikolaos Pappas",
      "Saab Mansour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.04694",
    "title": "On $[1,2]$-Domination in Interval and Circle Graphs",
    "abstract": "           A subset $S$ of vertices in a graph $G=(V, E)$ is Dominating Set if each vertex in $V(G)\\setminus S$ is adjacent to at least one vertex in $S$. Chellali et al. in 2013, by restricting the number of neighbors in $S$ of a vertex outside $S$, introduced the concept of $[1,j]$-dominating set. A set $D \\subseteq V$ of a graph $G = (V, E)$ is called $[1,j]$-Dominating Set of $G$ if every vertex not in $D$ has at least one neighbor and at most $j$ neighbors in $D$. The Minimum $[1,j]$-Domination problem is the problem of finding the minimum set $D$. Given a positive integer $k$ and a graph $G = (V, E)$, the $[1,j]$-Domination Decision problem is to decide whether $G$ has $[1,j]$-dominating set of cardinality at most $k$. A polynomial-time algorithm was obtained in split graphs for a constant $j$ in contrast to the classic Dominating Set problem which is NP-hard in split graphs. This result motivates us to investigate the effect of restriction $j$ on the complexity of $[1,j]$-domination problem on various classes of graphs. Although for $j\\geq 3$, it has been proved that the minimum of classical domination is equal to minimum $[1,j]$-domination in interval graphs, the complexity of finding the minimum $[1,2]$-domination in interval graphs is still outstanding. In this paper, we propose a polynomial-time algorithm for computing a minimum $[1,2]$ on non-proper interval graphs by a dynamic programming technique. Next, on the negative side, we show that the minimum $[1,2]$-dominating set problem on circle graphs is $NP$-complete.         ",
    "url": "https://arxiv.org/abs/2403.04694",
    "authors": [
      "Mohsen Alambardar Meybodi",
      "Abolfazl Poureidi"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2403.08337",
    "title": "LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments",
    "abstract": "           Traffic congestion in metropolitan areas presents a formidable challenge with far-reaching economic, environmental, and societal ramifications. Therefore, effective congestion management is imperative, with traffic signal control (TSC) systems being pivotal in this endeavor. Conventional TSC systems, designed upon rule-based algorithms or reinforcement learning (RL), frequently exhibit deficiencies in managing the complexities and variabilities of urban traffic flows, constrained by their limited capacity for adaptation to unfamiliar scenarios. In response to these limitations, this work introduces an innovative approach that integrates Large Language Models (LLMs) into TSC, harnessing their advanced reasoning and decision-making faculties. Specifically, a hybrid framework that augments LLMs with a suite of perception and decision-making tools is proposed, facilitating the interrogation of both the static and dynamic traffic information. This design places the LLM at the center of the decision-making process, combining external traffic data with established TSC methods. Moreover, a simulation platform is developed to corroborate the efficacy of the proposed framework. The findings from our simulations attest to the system's adeptness in adjusting to a multiplicity of traffic environments without the need for additional training. Notably, in cases of Sensor Outage (SO), our approach surpasses conventional RL-based systems by reducing the average waiting time by $20.4\\%$. This research signifies a notable advance in TSC strategies and paves the way for the integration of LLMs into real-world, dynamic scenarios, highlighting their potential to revolutionize traffic management. The related code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2403.08337",
    "authors": [
      "Maonan Wang",
      "Aoyu Pang",
      "Yuheng Kan",
      "Man-On Pun",
      "Chung Shue Chen",
      "Bo Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11827",
    "title": "Sound Event Detection and Localization with Distance Estimation",
    "abstract": "           Sound Event Detection and Localization (SELD) is a combined task of identifying sound events and their corresponding direction-of-arrival (DOA). While this task has numerous applications and has been extensively researched in recent years, it fails to provide full information about the sound source position. In this paper, we overcome this problem by extending the task to Sound Event Detection, Localization with Distance Estimation (3D SELD). We study two ways of integrating distance estimation within the SELD core - a multi-task approach, in which the problem is tackled by a separate model output, and a single-task approach obtained by extending the multi-ACCDOA method to include distance information. We investigate both methods for the Ambisonic and binaural versions of STARSS23: Sony-TAU Realistic Spatial Soundscapes 2023. Moreover, our study involves experiments on the loss function related to the distance estimation part. Our results show that it is possible to perform 3D SELD without any degradation of performance in sound event detection and DOA estimation.         ",
    "url": "https://arxiv.org/abs/2403.11827",
    "authors": [
      "Daniel Aleksander Krause",
      "Archontis Politis",
      "Annamaria Mesaros"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.12619",
    "title": "Detection of Malicious Agents in Social Learning",
    "abstract": "           Non-Bayesian social learning is a framework for distributed hypothesis testing aimed at learning the true state of the environment. Traditionally, the agents are assumed to receive observations conditioned on the same true state, although it is also possible to examine the case of heterogeneous models across the graph. One important special case is when heterogeneity is caused by the presence of malicious agents whose goal is to move the agents toward a wrong hypothesis. In this work, we propose an algorithm that allows to discover the true state of every individual agent based on the sequence of their beliefs. In so doing, the methodology is also able to locate malicious behavior.         ",
    "url": "https://arxiv.org/abs/2403.12619",
    "authors": [
      "Valentina Shumovskaia",
      "Mert Kayaalp",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.13215",
    "title": "Leveraging advances in machine learning for the robust classification and interpretation of networks",
    "abstract": "           The ability to simulate realistic networks based on empirical data is an important task across scientific disciplines, from epidemiology to computer science. Often simulation approaches involve selecting a suitable network generative model such as Erd\u00f6s-R\u00e9nyi or small-world. However, few tools are available to quantify if a particular generative model is suitable for capturing a given network structure or organization. We utilize advances in interpretable machine learning to classify simulated networks by our generative models based on various network attributes, using both primary features and their interactions. Our study underscores the significance of specific network features and their interactions in distinguishing generative models, comprehending complex network structures, and the formation of real-world networks.         ",
    "url": "https://arxiv.org/abs/2403.13215",
    "authors": [
      "Raima Carol Appaw",
      "Nicholas Fountain-Jones",
      "Michael A. Charleston"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Spectral Theory (math.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.15180",
    "title": "Self-Improvement for Neural Combinatorial Optimization: Sample without Replacement, but Improvement",
    "abstract": "           Current methods for end-to-end constructive neural combinatorial optimization usually train a policy using behavior cloning from expert solutions or policy gradient methods from reinforcement learning. While behavior cloning is straightforward, it requires expensive expert solutions, and policy gradient methods are often computationally demanding and complex to fine-tune. In this work, we bridge the two and simplify the training process by sampling multiple solutions for random instances using the current model in each epoch and then selecting the best solution as an expert trajectory for supervised imitation learning. To achieve progressively improving solutions with minimal sampling, we introduce a method that combines round-wise Stochastic Beam Search with an update strategy derived from a provable policy improvement. This strategy refines the policy between rounds by utilizing the advantage of the sampled sequences with almost no computational overhead. We evaluate our approach on the Traveling Salesman Problem and the Capacitated Vehicle Routing Problem. The models trained with our method achieve comparable performance and generalization to those trained with expert data. Additionally, we apply our method to the Job Shop Scheduling Problem using a transformer-based architecture and outperform existing state-of-the-art methods by a wide margin.         ",
    "url": "https://arxiv.org/abs/2403.15180",
    "authors": [
      "Jonathan Pirnay",
      "Dominik G. Grimm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.17633",
    "title": "UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object Detection with Sparse LiDAR and Large Domain Gaps",
    "abstract": "           In this study, we address a gap in existing unsupervised domain adaptation approaches on LiDAR-based 3D object detection, which have predominantly concentrated on adapting between established, high-density autonomous driving datasets. We focus on sparser point clouds, capturing scenarios from different perspectives: not just from vehicles on the road but also from mobile robots on sidewalks, which encounter significantly different environmental conditions and sensor configurations. We introduce Unsupervised Adversarial Domain Adaptation for 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source models or teacher-student architectures. Instead, it uses an adversarial approach to directly learn domain-invariant features. We demonstrate its efficacy in various adaptation scenarios, showing significant improvements in both self-driving car and mobile robot domains. Our code is open-source and will be available soon.         ",
    "url": "https://arxiv.org/abs/2403.17633",
    "authors": [
      "Maciej K Wozniak",
      "Mattias Hansson",
      "Marko Thiel",
      "Patric Jensfelt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.17780",
    "title": "CaseLink: Inductive Graph Learning for Legal Case Retrieval",
    "abstract": "           In case law, the precedents are the relevant cases that are used to support the decisions made by the judges and the opinions of lawyers towards a given case. This relevance is referred to as the case-to-case reference relation. To efficiently find relevant cases from a large case pool, retrieval tools are widely used by legal practitioners. Existing legal case retrieval models mainly work by comparing the text representations of individual cases. Although they obtain a decent retrieval accuracy, the intrinsic case connectivity relationships among cases have not been well exploited for case encoding, therefore limiting the further improvement of retrieval performance. In a case pool, there are three types of case connectivity relationships: the case reference relationship, the case semantic relationship, and the case legal charge relationship. Due to the inductive manner in the task of legal case retrieval, using case reference as input is not applicable for testing. Thus, in this paper, a CaseLink model based on inductive graph learning is proposed to utilise the intrinsic case connectivity for legal case retrieval, a novel Global Case Graph is incorporated to represent both the case semantic relationship and the case legal charge relationship. A novel contrastive objective with a regularisation on the degree of case nodes is proposed to leverage the information carried by the case reference relationship to optimise the model. Extensive experiments have been conducted on two benchmark datasets, which demonstrate the state-of-the-art performance of CaseLink. The code has been released on this https URL.         ",
    "url": "https://arxiv.org/abs/2403.17780",
    "authors": [
      "Yanran Tang",
      "Ruihong Qiu",
      "Hongzhi Yin",
      "Xue Li",
      "Zi Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.18910",
    "title": "A Geometric Explanation of the Likelihood OOD Detection Paradox",
    "abstract": "           Likelihood-based deep generative models (DGMs) commonly exhibit a puzzling behaviour: when trained on a relatively complex dataset, they assign higher likelihood values to out-of-distribution (OOD) data from simpler sources. Adding to the mystery, OOD samples are never generated by these DGMs despite having higher likelihoods. This two-pronged paradox has yet to be conclusively explained, making likelihood-based OOD detection unreliable. Our primary observation is that high-likelihood regions will not be generated if they contain minimal probability mass. We demonstrate how this seeming contradiction of large densities yet low probability mass can occur around data confined to low-dimensional manifolds. We also show that this scenario can be identified through local intrinsic dimension (LID) estimation, and propose a method for OOD detection which pairs the likelihoods and LID estimates obtained from a pre-trained DGM. Our method can be applied to normalizing flows and score-based diffusion models, and obtains results which match or surpass state-of-the-art OOD detection benchmarks using the same DGM backbones. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2403.18910",
    "authors": [
      "Hamidreza Kamkari",
      "Brendan Leigh Ross",
      "Jesse C. Cresswell",
      "Anthony L. Caterini",
      "Rahul G. Krishnan",
      "Gabriel Loaiza-Ganem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.03812",
    "title": "Additive approximation algorithm for geodesic centers in $\\delta$-hyperbolic graphs",
    "abstract": "           For an integer $k\\geq 1$, the objective of \\textsc{$k$-Geodesic Center} is to find a set $\\mathcal{C}$ of $k$ isometric paths such that the maximum distance between any vertex $v$ and $\\mathcal{C}$ is minimised. Introduced by Gromov, \\emph{$\\delta$-hyperbolicity} measures how treelike a graph is from a metric point of view. Our main contribution in this paper is to provide an additive $O(\\delta)$-approximation algorithm for \\textsc{$k$-Geodesic Center} on $\\delta$-hyperbolic graphs. On the way, we define a coarse version of the pairing property introduced by Gerstel \\& Zaks (Networks, 1994) and show it holds for $\\delta$-hyperbolic graphs. This result allows to reduce the \\textsc{$k$-Geodesic Center} problem to its rooted counterpart, a main idea behind our algorithm. We also adapt a technique of Dragan \\& Leitert, (TCS, 2017) to show that for every $k\\geq 1$, $k$-\\textsc{Geodesic Center} is NP-hard even on partial grids.         ",
    "url": "https://arxiv.org/abs/2404.03812",
    "authors": [
      "Dibyayan Chakraborty",
      "Yann Vax\u00e8s"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2404.04662",
    "title": "Learning Minimal NAP Specifications for Neural Network Verification",
    "abstract": "           Specifications play a crucial role in neural network verification. They define the precise input regions we aim to verify, typically represented as L-infinity norm balls. While recent research suggests using neural activation patterns (NAPs) as specifications for verifying unseen test set data, it focuses on computing the most refined NAPs, often limited to very small regions in the input space. In this paper, we study the following problem: Given a neural network, find a minimal (coarsest) NAP that is sufficient for formal verification of the network's robustness. Finding the minimal NAP specification not only expands verifiable bounds but also provides insights into which neurons contribute to the model's robustness. To address this problem, we propose several exact and approximate approaches. Our exact approaches leverage the verification tool to find minimal NAP specifications in either a deterministic or statistical manner. Whereas the approximate methods efficiently estimate minimal NAPs using adversarial examples and local gradients, without making calls to the verification tool. This allows us to inspect potential causal links between neurons and the robustness of state-of-the-art neural networks, a task for which existing verification frameworks fail to scale. Our experimental results suggest that minimal NAP specifications require much smaller fractions of neurons compared to the most refined NAP specifications, yet they can significantly expand the verifiable boundaries to several orders of magnitude larger.         ",
    "url": "https://arxiv.org/abs/2404.04662",
    "authors": [
      "Chuqin Geng",
      "Zhaoyue Wang",
      "Haolin Ye",
      "Saifei Liao",
      "Xujie Si"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2404.14027",
    "title": "OccFeat: Self-supervised Occupancy Feature Prediction for Pretraining BEV Segmentation Networks",
    "abstract": "           We introduce a self-supervised pretraining method, called OccFeat, for camera-only Bird's-Eye-View (BEV) segmentation networks. With OccFeat, we pretrain a BEV network via occupancy prediction and feature distillation tasks. Occupancy prediction provides a 3D geometric understanding of the scene to the model. However, the geometry learned is class-agnostic. Hence, we add semantic information to the model in the 3D space through distillation from a self-supervised pretrained image foundation model. Models pretrained with our method exhibit improved BEV semantic segmentation performance, particularly in low-data scenarios. Moreover, empirical results affirm the efficacy of integrating feature distillation with 3D occupancy prediction in our pretraining approach. Repository: this https URL ",
    "url": "https://arxiv.org/abs/2404.14027",
    "authors": [
      "Sophia Sirko-Galouchenko",
      "Alexandre Boulch",
      "Spyros Gidaris",
      "Andrei Bursuc",
      "Antonin Vobecky",
      "Patrick P\u00e9rez",
      "Renaud Marlet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01741",
    "title": "PVF (Parameter Vulnerability Factor): A Scalable Metric for Understanding AI Vulnerability Against SDCs in Model Parameters",
    "abstract": "           Reliability of AI systems is a fundamental concern for the successful deployment and widespread adoption of AI technologies. Unfortunately, the escalating complexity and heterogeneity of AI hardware systems make them increasingly susceptible to hardware faults, e.g., silent data corruptions (SDC), that can potentially corrupt model parameters. When this occurs during AI inference/servicing, it can potentially lead to incorrect or degraded model output for users, ultimately affecting the quality and reliability of AI services. In light of the escalating threat, it is crucial to address key questions: How vulnerable are AI models to parameter corruptions, and how do different components (such as modules, layers) of the models exhibit varying vulnerabilities to parameter corruptions? To systematically address this question, we propose a novel quantitative metric, Parameter Vulnerability Factor (PVF), inspired by architectural vulnerability factor (AVF) in computer architecture community, aiming to standardize the quantification of AI model vulnerability against parameter corruptions. We define a model parameter's PVF as the probability that a corruption in that particular model parameter will result in an incorrect output. In this paper, we present several use cases on applying PVF to three types of tasks/models during inference -- recommendation (DLRM), vision classification (CNN), and text classification (BERT), while presenting an in-depth vulnerability analysis on DLRM. PVF can provide pivotal insights to AI hardware designers in balancing the tradeoff between fault protection and performance/efficiency such as mapping vulnerable AI parameter components to well-protected hardware modules. PVF metric is applicable to any AI model and has a potential to help unify and standardize AI vulnerability/resilience evaluation practice.         ",
    "url": "https://arxiv.org/abs/2405.01741",
    "authors": [
      "Xun Jiao",
      "Fred Lin",
      "Harish D. Dixit",
      "Joel Coburn",
      "Abhinav Pandey",
      "Han Wang",
      "Venkat Ramesh",
      "Jianyu Huang",
      "Wang Xu",
      "Daniel Moore",
      "Sriram Sankar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02782",
    "title": "A self-supervised text-vision framework for automated brain abnormality detection",
    "abstract": "           Artificial neural networks trained on large, expert-labelled datasets are considered state-of-the-art for a range of medical image recognition tasks. However, categorically labelled datasets are time-consuming to generate and constrain classification to a pre-defined, fixed set of classes. For neuroradiological applications in particular, this represents a barrier to clinical adoption. To address these challenges, we present a self-supervised text-vision framework that learns to detect clinically relevant abnormalities in brain MRI scans by directly leveraging the rich information contained in accompanying free-text neuroradiology reports. Our training approach consisted of two-steps. First, a dedicated neuroradiological language model - NeuroBERT - was trained to generate fixed-dimensional vector representations of neuroradiology reports (N = 50,523) via domain-specific self-supervised learning tasks. Next, convolutional neural networks (one per MRI sequence) learnt to map individual brain scans to their corresponding text vector representations by optimising a mean square error loss. Once trained, our text-vision framework can be used to detect abnormalities in unreported brain MRI examinations by scoring scans against suitable query sentences (e.g., 'there is an acute stroke', 'there is hydrocephalus' etc.), enabling a range of classification-based applications including automated triage. Potentially, our framework could also serve as a clinical decision support tool, not only by suggesting findings to radiologists and detecting errors in provisional reports, but also by retrieving and displaying examples of pathologies from historical examinations that could be relevant to the current case based on textual descriptors.         ",
    "url": "https://arxiv.org/abs/2405.02782",
    "authors": [
      "David A. Wood",
      "Emily Guilhem",
      "Sina Kafiabadi",
      "Ayisha Al Busaidi",
      "Kishan Dissanayake",
      "Ahmed Hammam",
      "Nina Mansoor",
      "Matthew Townend",
      "Siddharth Agarwal",
      "Yiran Wei",
      "Asif Mazumder",
      "Gareth J. Barker",
      "Peter Sasieni",
      "Sebastien Ourselin",
      "James H. Cole",
      "Thomas C. Booth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.08969",
    "title": "Wearable Sensor-Based Few-Shot Continual Learning on Hand Gestures for Motor-Impaired Individuals via Latent Embedding Exploitation",
    "abstract": "           Hand gestures can provide a natural means of human-computer interaction and enable people who cannot speak to communicate efficiently. Existing hand gesture recognition methods heavily depend on pre-defined gestures, however, motor-impaired individuals require new gestures tailored to each individual's gesture motion and style. Gesture samples collected from different persons have distribution shifts due to their health conditions, the severity of the disability, motion patterns of the arms, etc. In this paper, we introduce the Latent Embedding Exploitation (LEE) mechanism in our replay-based Few-Shot Continual Learning (FSCL) framework that significantly improves the performance of fine-tuning a model for out-of-distribution data. Our method produces a diversified latent feature space by leveraging a preserved latent embedding known as gesture prior knowledge, along with intra-gesture divergence derived from two additional embeddings. Thus, the model can capture latent statistical structure in highly variable gestures with limited samples. We conduct an experimental evaluation using the SmartWatch Gesture and the Motion Gesture datasets. The proposed method results in an average test accuracy of 57.0%, 64.6%, and 69.3% by using one, three, and five samples for six different gestures. Our method helps motor-impaired persons leverage wearable devices, and their unique styles of movement can be learned and applied in human-computer interaction and social communication. Code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2405.08969",
    "authors": [
      "Riyad Bin Rafiq",
      "Weishi Shi",
      "Mark V. Albert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.11966",
    "title": "Multiple-Choice Questions are Efficient and Robust LLM Evaluators",
    "abstract": "           We present GSM-MC and MATH-MC, two multiple-choice (MC) datasets constructed by collecting answers and incorrect predictions on GSM8K and MATH from 60 open-source models. Through extensive experiments, we show that LLMs' performance on the MC versions of these two popular benchmarks is strongly correlated with their performance on the original versions and is quite robust to distractor choices and option orders, while the evaluation time is reduced by a factor of up to 30. Following a similar procedure, we introduce PythonIO, a new program output prediction MC dataset constructed from two other popular LLM evaluation benchmarks, HumanEval and MBPP. Our data and code are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2405.11966",
    "authors": [
      "Ziyin Zhang",
      "Lizhen Xu",
      "Zhaokun Jiang",
      "Hongkun Hao",
      "Rui Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2405.16907",
    "title": "GTA: Generative Trajectory Augmentation with Guidance for Offline Reinforcement Learning",
    "abstract": "           Offline Reinforcement Learning (Offline RL) presents challenges of learning effective decision-making policies from static datasets without any online interactions. Data augmentation techniques, such as noise injection and data synthesizing, aim to improve Q-function approximation by smoothing the learned state-action region. However, these methods often fall short of directly improving the quality of offline datasets, leading to suboptimal results. In response, we introduce \\textbf{GTA}, Generative Trajectory Augmentation, a novel generative data augmentation approach designed to enrich offline data by augmenting trajectories to be both high-rewarding and dynamically plausible. GTA applies a diffusion model within the data augmentation framework. GTA partially noises original trajectories and then denoises them with classifier-free guidance via conditioning on amplified return value. Our results show that GTA, as a general data augmentation strategy, enhances the performance of widely used offline RL algorithms in both dense and sparse reward settings. Furthermore, we conduct a quality analysis of data augmented by GTA and demonstrate that GTA improves the quality of the data. Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2405.16907",
    "authors": [
      "Jaewoo Lee",
      "Sujin Yun",
      "Taeyoung Yun",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.17003",
    "title": "Graph Condensation for Open-World Graph Learning",
    "abstract": "           The burgeoning volume of graph data presents significant computational challenges in training graph neural networks (GNNs), critically impeding their efficiency in various applications. To tackle this challenge, graph condensation (GC) has emerged as a promising acceleration solution, focusing on the synthesis of a compact yet representative graph for efficiently training GNNs while retaining performance. Despite the potential to promote scalable use of GNNs, existing GC methods are limited to aligning the condensed graph with merely the observed static graph distribution. This limitation significantly restricts the generalization capacity of condensed graphs, particularly in adapting to dynamic distribution changes. In real-world scenarios, however, graphs are dynamic and constantly evolving, with new nodes and edges being continually integrated. Consequently, due to the limited generalization capacity of condensed graphs, applications that employ GC for efficient GNN training end up with sub-optimal GNNs when confronted with evolving graph structures and distributions in dynamic real-world situations. To overcome this issue, we propose open-world graph condensation (OpenGC), a robust GC framework that integrates structure-aware distribution shift to simulate evolving graph patterns and exploit the temporal environments for invariance condensation. This approach is designed to extract temporal invariant patterns from the original graph, thereby enhancing the generalization capabilities of the condensed graph and, subsequently, the GNNs trained on it. Extensive experiments on both real-world and synthetic evolving graphs demonstrate that OpenGC outperforms state-of-the-art (SOTA) GC methods in adapting to dynamic changes in open-world graph environments.         ",
    "url": "https://arxiv.org/abs/2405.17003",
    "authors": [
      "Xinyi Gao",
      "Tong Chen",
      "Wentao Zhang",
      "Yayong Li",
      "Xiangguo Sun",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.20773",
    "title": "Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character",
    "abstract": "           With the advent and widespread deployment of Multimodal Large Language Models (MLLMs), ensuring their safety has become increasingly critical. To achieve this objective, it requires us to proactively discover the vulnerability of MLLMs by exploring the attack methods. Thus, structure-based jailbreak attacks, where harmful semantic content is embedded within images, have been proposed to mislead the models. However, previous structure-based jailbreak methods mainly focus on transforming the format of malicious queries, such as converting harmful content into images through typography, which lacks sufficient jailbreak effectiveness and generalizability. To address these limitations, we first introduce the concept of \"Role-play\" into MLLM jailbreak attacks and propose a novel and effective method called Visual Role-play (VRP). Specifically, VRP leverages Large Language Models to generate detailed descriptions of high-risk characters and create corresponding images based on the descriptions. When paired with benign role-play instruction texts, these high-risk character images effectively mislead MLLMs into generating malicious responses by enacting characters with negative attributes. We further extend our VRP method into a universal setup to demonstrate its generalizability. Extensive experiments on popular benchmarks show that VRP outperforms the strongest baseline, Query relevant and FigStep, by an average Attack Success Rate (ASR) margin of 14.3% across all models.         ",
    "url": "https://arxiv.org/abs/2405.20773",
    "authors": [
      "Siyuan Ma",
      "Weidi Luo",
      "Yu Wang",
      "Xiaogeng Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.03229",
    "title": "Global Clipper: Enhancing Safety and Reliability of Transformer-based Object Detection Models",
    "abstract": "           As transformer-based object detection models progress, their impact in critical sectors like autonomous vehicles and aviation is expected to grow. Soft errors causing bit flips during inference have significantly impacted DNN performance, altering predictions. Traditional range restriction solutions for CNNs fall short for transformers. This study introduces the Global Clipper and Global Hybrid Clipper, effective mitigation strategies specifically designed for transformer-based models. It significantly enhances their resilience to soft errors and reduces faulty inferences to ~ 0\\%. We also detail extensive testing across over 64 scenarios involving two transformer models (DINO-DETR and Lite-DETR) and two CNN models (YOLOv3 and SSD) using three datasets, totalling approximately 3.3 million inferences, to assess model robustness comprehensively. Moreover, the paper explores unique aspects of attention blocks in transformers and their operational differences from CNNs.         ",
    "url": "https://arxiv.org/abs/2406.03229",
    "authors": [
      "Qutub Syed Sha",
      "Michael Paulitsch",
      "Karthik Pattabiraman",
      "Korbinian Hagn",
      "Fabian Oboril",
      "Cornelius Buerkle",
      "Kay-Ulrich Scholl",
      "Gereon Hinz",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.03512",
    "title": "Harder or Different? Understanding Generalization of Audio Deepfake Detection",
    "abstract": "           Recent research has highlighted a key issue in speech deepfake detection: models trained on one set of deepfakes perform poorly on others. The question arises: is this due to the continuously improving quality of Text-to-Speech (TTS) models, i.e., are newer DeepFakes just 'harder' to detect? Or, is it because deepfakes generated with one model are fundamentally different to those generated using another model? We answer this question by decomposing the performance gap between in-domain and out-of-domain test data into 'hardness' and 'difference' components. Experiments performed using ASVspoof databases indicate that the hardness component is practically negligible, with the performance gap being attributed primarily to the difference component. This has direct implications for real-world deepfake detection, highlighting that merely increasing model capacity, the currently-dominant research trend, may not effectively address the generalization challenge.         ",
    "url": "https://arxiv.org/abs/2406.03512",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Nicholas Evans",
      "Hemlata Tak",
      "Philip Sperl",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.04596",
    "title": "Federated Representation Learning in the Under-Parameterized Regime",
    "abstract": "           Federated representation learning (FRL) is a popular personalized federated learning (FL) framework where clients work together to train a common representation while retaining their personalized heads. Existing studies, however, largely focus on the over-parameterized regime. In this paper, we make the initial efforts to investigate FRL in the under-parameterized regime, where the FL model is insufficient to express the variations in all ground-truth models. We propose a novel FRL algorithm FLUTE, and theoretically characterize its sample complexity and convergence rate for linear models in the under-parameterized regime. To the best of our knowledge, this is the first FRL algorithm with provable performance guarantees in this regime. FLUTE features a data-independent random initialization and a carefully designed objective function that aids the distillation of subspace spanned by the global optimal representation from the misaligned local representations. On the technical side, we bridge low-rank matrix approximation techniques with the FL analysis, which may be of broad interest. We also extend FLUTE beyond linear representations. Experimental results demonstrate that FLUTE outperforms state-of-the-art FRL solutions in both synthetic and real-world tasks.         ",
    "url": "https://arxiv.org/abs/2406.04596",
    "authors": [
      "Renpu Liu",
      "Cong Shen",
      "Jing Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.04601",
    "title": "Enhancing Size Generalization in Graph Neural Networks through Disentangled Representation Learning",
    "abstract": "           Although most graph neural networks (GNNs) can operate on graphs of any size, their classification performance often declines on graphs larger than those encountered during training. Existing methods insufficiently address the removal of size information from graph representations, resulting in sub-optimal performance and reliance on backbone models. In response, we propose DISGEN, a novel and model-agnostic framework designed to disentangle size factors from graph representations. DISGEN employs size- and task-invariant augmentations and introduces a decoupling loss that minimizes shared information in hidden representations, with theoretical guarantees for its effectiveness. Our empirical results show that DISGEN outperforms the state-of-the-art models by up to 6% on real-world datasets, underscoring its effectiveness in enhancing the size generalizability of GNNs. Our codes are available at: this https URL.         ",
    "url": "https://arxiv.org/abs/2406.04601",
    "authors": [
      "Zheng Huang",
      "Qihui Yang",
      "Dawei Zhou",
      "Yujun Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.04962",
    "title": "Mapping the Global Election Landscape on Social Media in 2024",
    "abstract": "           In 2024, half of the global population is expected to participate in elections, offering researchers a unique opportunity to study online information diffusion and user behavior. This study investigates the media landscape on social media by analyzing Facebook posts from national political parties and major news agencies across Europe, Mexico, and India. Our methodology identifies key topics and evaluates public interaction, reflecting broader trends in political engagement. Using Principal Component Analysis, we distil these topics to uncover patterns of correlation and differentiation. This approach reveals dominant themes that engage global audiences, providing critical insights into the interplay between public opinion and digital narratives during a major electoral cycle. Our findings highlight how different topics resonate across political spectrums, shaping political debate and offering a comprehensive view of the interaction between media content, political ideology, and audience engagement.         ",
    "url": "https://arxiv.org/abs/2406.04962",
    "authors": [
      "Giulio Pecile",
      "Niccol\u00f2 Di Marco",
      "Matteo Cinelli",
      "Walter Quattrociocchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2406.04995",
    "title": "Data2Neo - A Tool for Complex Neo4j Data Integration",
    "abstract": "           This paper introduces Data2Neo, an open-source Python library for converting relational data into knowledge graphs stored in Neo4j databases. With extensive customization options and support for continuous online data integration from various data sources, Data2Neo is designed to be user-friendly, efficient, and scalable to large datasets. The tool significantly lowers the barrier to entry for creating and using knowledge graphs, making this increasingly popular form of data representation accessible to a wider audience. The code is available at this https URL .         ",
    "url": "https://arxiv.org/abs/2406.04995",
    "authors": [
      "Julian Minder",
      "Laurence Brandenberger",
      "Luis Salamanca",
      "Frank Schweitzer"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2406.04998",
    "title": "ADBA:Approximation Decision Boundary Approach for Black-Box Adversarial Attacks",
    "abstract": "           Many machine learning models are susceptible to adversarial attacks, with decision-based black-box attacks representing the most critical threat in real-world applications. These attacks are extremely stealthy, generating adversarial examples using hard labels obtained from the target machine learning model. This is typically realized by optimizing perturbation directions, guided by decision boundaries identified through query-intensive exact search, significantly limiting the attack success rate. This paper introduces a novel approach using the Approximation Decision Boundary (ADB) to efficiently and accurately compare perturbation directions without precisely determining decision boundaries. The effectiveness of our ADB approach (ADBA) hinges on promptly identifying suitable ADB, ensuring reliable differentiation of all perturbation directions. For this purpose, we analyze the probability distribution of decision boundaries, confirming that using the distribution's median value as ADB can effectively distinguish different perturbation directions, giving rise to the development of the ADBA-md algorithm. ADBA-md only requires four queries on average to differentiate any pair of perturbation directions, which is highly query-efficient. Extensive experiments on six well-known image classifiers clearly demonstrate the superiority of ADBA and ADBA-md over multiple state-of-the-art black-box attacks. The source code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.04998",
    "authors": [
      "Feiyang Wang",
      "Xingquan Zuo",
      "Hai Huang",
      "Gang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.05954",
    "title": "Aligning Large Language Models with Representation Editing: A Control Perspective",
    "abstract": "           Aligning large language models (LLMs) with human objectives is crucial for real-world applications. However, fine-tuning LLMs for alignment often suffers from unstable training and requires substantial computing resources. Test-time alignment techniques, such as prompting and guided decoding, do not modify the underlying model, and their performance remains dependent on the original model's capabilities. To address these challenges, we propose aligning LLMs through representation editing. The core of our method is to view a pre-trained autoregressive LLM as a discrete-time stochastic dynamical system. To achieve alignment for specific objectives, we introduce external control signals into the state space of this language dynamical system. We train a value function directly on the hidden states according to the Bellman equation, enabling gradient-based optimization to obtain the optimal control signals at test time. Our experiments demonstrate that our method outperforms existing test-time alignment techniques while requiring significantly fewer resources compared to fine-tuning methods.         ",
    "url": "https://arxiv.org/abs/2406.05954",
    "authors": [
      "Lingkai Kong",
      "Haorui Wang",
      "Wenhao Mu",
      "Yuanqi Du",
      "Yuchen Zhuang",
      "Yifei Zhou",
      "Yue Song",
      "Rongzhi Zhang",
      "Kai Wang",
      "Chao Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2406.06400",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "abstract": "           The integration of Large Language Models (LLMs) in social robotics presents a unique set of ethical challenges and social impacts. This research is set out to identify ethical considerations that arise in the design and development of these two technologies in combination. Using LLMs for social robotics may provide benefits, such as enabling natural language open-domain dialogues. However, the intersection of these two technologies also gives rise to ethical concerns related to misinformation, non-verbal cues, emotional disruption, and biases. The robot's physical social embodiment adds complexity, as ethical hazards associated with LLM-based Social AI, such as hallucinations and misinformation, can be exacerbated due to the effects of physical embodiment on social perception and communication. To address these challenges, this study employs an empirical design justice-based methodology, focusing on identifying socio-technical ethical considerations through a qualitative co-design and interaction study. The purpose of the study is to identify ethical considerations relevant to the process of co-design of, and interaction with a humanoid social robot as the interface of a LLM, and to evaluate how a design justice methodology can be used in the context of designing LLMs-based social robotics. The findings reveal a mapping of ethical considerations arising in four conceptual dimensions: interaction, co-design, terms of service and relationship and evaluates how a design justice approach can be used empirically in the intersection of LLMs and social robotics.         ",
    "url": "https://arxiv.org/abs/2406.06400",
    "authors": [
      "Alva Markelius"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.07023",
    "title": "LiSD: An Efficient Multi-Task Learning Framework for LiDAR Segmentation and Detection",
    "abstract": "           With the rapid proliferation of autonomous driving, there has been a heightened focus on the research of lidar-based 3D semantic segmentation and object detection methodologies, aiming to ensure the safety of traffic participants. In recent decades, learning-based approaches have emerged, demonstrating remarkable performance gains in comparison to conventional algorithms. However, the segmentation and detection tasks have traditionally been examined in isolation to achieve the best precision. To this end, we propose an efficient multi-task learning framework named LiSD which can address both segmentation and detection tasks, aiming to optimize the overall performance. Our proposed LiSD is a voxel-based encoder-decoder framework that contains a hierarchical feature collaboration module and a holistic information aggregation module. Different integration methods are adopted to keep sparsity in segmentation while densifying features for query initialization in detection. Besides, cross-task information is utilized in an instance-aware refinement module to obtain more accurate predictions. Experimental results on the nuScenes dataset and Waymo Open Dataset demonstrate the effectiveness of our proposed model. It is worth noting that LiSD achieves the state-of-the-art performance of 83.3% mIoU on the nuScenes segmentation benchmark for lidar-only methods.         ",
    "url": "https://arxiv.org/abs/2406.07023",
    "authors": [
      "Jiahua Xu",
      "Si Zuo",
      "Chenfeng Wei",
      "Wei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.07349",
    "title": "Erasing Radio Frequency Fingerprints via Active Adversarial Perturbation",
    "abstract": "           Radio Frequency (RF) fingerprinting is to identify a wireless device from its uniqueness of the analog circuitry or hardware imperfections. However, unlike the MAC address which can be modified, such hardware feature is inevitable for the signal emitted to air, which can possibly reveal device whereabouts, e.g., a sniffer can use a pre-trained model to identify a nearby device when receiving its signal. Such fingerprint may expose critical private information, e.g., the associated upper-layer applications or the end-user. In this paper, we propose to erase such RF feature for wireless devices, which can prevent fingerprinting by actively perturbation from the signal perspective. Specifically, we consider a common RF fingerprinting scenario, where machine learning models are trained from pilot signal data for identification. A novel adversarial attack solution is designed to generate proper perturbations, whereby the perturbed pilot signal can hide the hardware feature and misclassify the model. We theoretically show that the perturbation would not affect the communication function within a tolerable perturbation threshold. We also implement the pilot signal fingerprinting and the proposed perturbation process in a practical LTE system. Extensive experiment results demonstrate that the RF fingerprints can be effectively erased to protect the user privacy.         ",
    "url": "https://arxiv.org/abs/2406.07349",
    "authors": [
      "Zhaoyi Lu",
      "Wenchao Xu",
      "Ming Tu",
      "Xin Xie",
      "Cunqing Hua",
      "Nan Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.03660",
    "title": "ECG Classification System for Arrhythmia Detection Using Convolutional Neural Networks",
    "abstract": "           Arrhythmia is just one of the many cardiovascular illnesses that have been extensively studied throughout the years. Using multi-lead ECG data, this research describes a deep learning (DL) pipeline technique based on convolutional neural network (CNN) algorithms to detect cardiovascular lar arrhythmia in patients. The suggested model architecture has hidden layers with a residual block in addition to the input and output layers. In this study, the classification of the ECG signals into five main groups, namely: Left Bundle Branch Block (LBBB), Right Bundle Branch Block (RBBB), Atrial Premature Contraction (APC), Premature Ventricular Contraction (PVC), and Normal Beat (N), are performed. Using the MIT-BIH arrhythmia dataset, we assessed the suggested technique. The findings show that our suggested strategy classified 15,000 cases with a high accuracy of 98.2%         ",
    "url": "https://arxiv.org/abs/2303.03660",
    "authors": [
      "Aryan Odugoudar",
      "Jaskaran Singh Walia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2303.05723",
    "title": "New Results on Edge-coloring and Total-coloring of Split Graphs",
    "abstract": "           A split graph is a graph whose vertex set can be partitioned into a clique and an independent set. A connected graph $G$ is said to be $t$-admissible if admits a special spanning tree in which the distance between any two adjacent vertices is at most $t$. Given a graph $G$, determining the smallest $t$ for which $G$ is $t$-admissible, i.e. the stretch index of $G$ denoted by $\\sigma(G)$, is the goal of the $t$-admissibility problem. Split graphs are $3$-admissible and can be partitioned into three subclasses: split graphs with $\\sigma=1, 2 $ or $3$. In this work we consider such a partition while dealing with the problem of coloring a split graph. Vizing proved that any graph can have its edges colored with $\\Delta$ or $\\Delta+1$ colors, and thus can be classified as Class 1 or Class 2, respectively. When both, edges and vertices, are simultaneously colored, i.e., a total coloring of $G$, it is conjectured that any graph can be total colored with $\\Delta+1$ or $\\Delta+2$ colors, and thus can be classified as Type 1 or Type 2. These both variants are still open for split graphs. In this paper, using the partition of split graphs presented above, we consider the edge coloring problem and the total coloring problem for split graphs with $\\sigma=2$. For this class, we characterize Class 2 and Type 2 graphs and we provide polynomial-time algorithms to color any Class 1 or Type 1 graph.         ",
    "url": "https://arxiv.org/abs/2303.05723",
    "authors": [
      "Fernanda Couto",
      "Diego Amaro Ferraz",
      "Sulamita Klein"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.12516",
    "title": "On the detection of the presence of malicious components in cyber-physical systems in the almost sure sense",
    "abstract": "           This article studies a fundamental problem of security of cyber-physical systems (CPSs): that of detecting, almost surely, the presence of malicious components in the CPS. We assume that some of the actuators may be malicious while all sensors are honest. We introduce a novel idea of separability of state trajectories generated by CPSs in two situations: those under the nominal no-attack situation and those under the influence of an attacker. We establish its connection to security of CPSs in the context of detecting the presence of malicious actuators (if any) in them. As primary contributions we establish necessary and sufficient conditions for the aforementioned detection in CPSs modeled as Markov decision processes (MDPs). Moreover, we focus on the mechanism of perturbing the pre-determined control policies of the honest agents in CPSs modeled as stochastic linear systems, by injecting a certain class of random process called private excitation; sufficient conditions for detectability and non-detectability of the presence of malicious actuators assuming that the policies are randomized history dependent and randomized Markovian, are established. Several technical aspects of our results are discussed extensively.         ",
    "url": "https://arxiv.org/abs/2306.12516",
    "authors": [
      "Souvik Das",
      "Priyanka Dey",
      "Debasish Chatterjee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.03262",
    "title": "Low-Cost High-Power Membership Inference Attacks",
    "abstract": "           Membership inference attacks aim to detect if a particular data point was used in training a model. We design a novel statistical test to perform robust membership inference attacks (RMIA) with low computational overhead. We achieve this by a fine-grained modeling of the null hypothesis in our likelihood ratio tests, and effectively leveraging both reference models and reference population data samples. RMIA has superior test power compared with prior methods, throughout the TPR-FPR curve (even at extremely low FPR, as low as 0). Under computational constraints, where only a limited number of pre-trained reference models (as few as 1) are available, and also when we vary other elements of the attack (e.g., data distribution), our method performs exceptionally well, unlike prior attacks that approach random guessing. RMIA lays the groundwork for practical yet accurate data privacy risk assessment in machine learning.         ",
    "url": "https://arxiv.org/abs/2312.03262",
    "authors": [
      "Sajjad Zarifzadeh",
      "Philippe Liu",
      "Reza Shokri"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.18984",
    "title": "Graph Burning: Bounds and Hardness",
    "abstract": "           Graph burning models the propagation of information within a network as a stepwise process where at each step, one node becomes informed, and this information also spreads to all neighbors of previously informed nodes. Formally, graph burning is defined as follows: For an undirected graph $G$, at step $t=0$ all vertices in $G$ are unburned. At each step $t\\ge 1$, one new unburned vertex is selected to burn if such a vertex exists. If a vertex is burned at step $t$, then all its unburned neighbors are burned in step $t+1$, and the process continues until there are no unburned vertices in $G$. The burning number of a graph $G$, denoted by $b(G)$, is the minimum number of steps required to burn all the vertices of $G$. The burning number problem asks whether the burning number of an input graph $G$ is at most $k$ or not. In this paper, we study the burning number problem both from an algorithmic and a structural point of view. The burning number problem is known to be NP-complete for trees with maximum degree at most three and interval graphs. Here, we prove that this problem is NP-complete even when restricted to connected cubic graphs and connected proper interval graphs. The well-known burning number conjecture asserts that all the vertices of a graph of order $n$ can be burned in $\\lceil\\sqrt{n}~\\rceil$ steps. In line with this conjecture, upper and lower bounds of $b(G)$ are well-studied for various graph classes. Here, we provide an improved upper bound for the burning number of connected $P_k$-free graphs and show that the bound is tight up to an additive constant $1$. Finally, we study two variants of the problem, namely edge burning (only edges are burned) and total burning (both vertices and edges are burned). In particular, we establish their relationship with the burning number problem and evaluate the algorithmic complexity of these variants.         ",
    "url": "https://arxiv.org/abs/2402.18984",
    "authors": [
      "Dhanyamol Antony",
      "Anita Das",
      "Shirish Gosavi",
      "Dalu Jacob",
      "Shashanka Kulamarva"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2403.05704",
    "title": "Non-robustness of diffusion estimates on networks with measurement error",
    "abstract": "           Network diffusion models are used to study things like disease transmission, information spread, and technology adoption. However, small amounts of mismeasurement are extremely likely in the networks constructed to operationalize these models. We show that estimates of diffusions are highly non-robust to this measurement error. First, we show that even when measurement error is vanishingly small, such that the share of missed links is close to zero, forecasts about the extent of diffusion will greatly underestimate the truth. Second, a small mismeasurement in the identity of the initial seed generates a large shift in the locations of expected diffusion path. We show that both of these results still hold when the vanishing measurement error is only local in nature. Such non-robustness in forecasting exists even under conditions where the basic reproductive number is consistently estimable. Possible solutions, such as estimating the measurement error or implementing widespread detection efforts, still face difficulties because the number of missed links are so small. Finally, we conduct Monte Carlo simulations on simulated networks, and real networks from three settings: travel data from the COVID-19 pandemic in the western US, a mobile phone marketing campaign in rural India, and in an insurance experiment in China.         ",
    "url": "https://arxiv.org/abs/2403.05704",
    "authors": [
      "Arun G. Chandrasekhar",
      "Paul Goldsmith-Pinkham",
      "Tyler H. McCormick",
      "Samuel Thau",
      "Jerry Wei"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.17042",
    "title": "Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction",
    "abstract": "           In a great number of tasks in science and engineering, the goal is to infer an unknown image from a small number of measurements collected from a known forward model describing certain sensing or imaging modality. Due to resource constraints, this task is often extremely ill-posed, which necessitates the adoption of expressive prior information to regularize the solution space. Score-based diffusion models, due to its impressive empirical success, have emerged as an appealing candidate of an expressive prior in image reconstruction. In order to accommodate diverse tasks at once, it is of great interest to develop efficient, consistent and robust algorithms that incorporate unconditional score functions of an image prior distribution in conjunction with flexible choices of forward models. This work develops an algorithmic framework for employing score-based diffusion models as an expressive data prior in general nonlinear inverse problems. Motivated by the plug-and-play framework in the imaging community, we introduce a diffusion plug-and-play method (DPnP) that alternatively calls two samplers, a proximal consistency sampler based solely on the likelihood function of the forward model, and a denoising diffusion sampler based solely on the score functions of the image prior. The key insight is that denoising under white Gaussian noise can be solved rigorously via both stochastic (i.e., DDPM-type) and deterministic (i.e., DDIM-type) samplers using the unconditional score functions. We establish both asymptotic and non-asymptotic performance guarantees of DPnP, and provide numerical experiments to illustrate its promise in solving both linear and nonlinear image reconstruction tasks. To the best of our knowledge, DPnP is the first provably-robust posterior sampling method for nonlinear inverse problems using unconditional diffusion priors.         ",
    "url": "https://arxiv.org/abs/2403.17042",
    "authors": [
      "Xingyu Xu",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2404.19557",
    "title": "Neural Dynamic Data Valuation",
    "abstract": "           Data constitute the foundational component of the data economy and its marketplaces. Efficient and fair data valuation has emerged as a topic of significant interest.\\ Many approaches based on marginal contribution have shown promising results in various downstream tasks. However, they are well known to be computationally expensive as they require training a large number of utility functions, which are used to evaluate the usefulness or value of a given dataset for a specific purpose. As a result, it has been recognized as infeasible to apply these methods to a data marketplace involving large-scale datasets. Consequently, a critical issue arises: how can the re-training of the utility function be avoided? To address this issue, we propose a novel data valuation method from the perspective of optimal control, named the neural dynamic data valuation (NDDV). Our method has solid theoretical interpretations to accurately identify the data valuation via the sensitivity of the data optimal control state. In addition, we implement a data re-weighting strategy to capture the unique features of data points, ensuring fairness through the interaction between data points and the mean-field states. Notably, our method requires only training once to estimate the value of all data points, significantly improving the computational efficiency. We conduct comprehensive experiments using different datasets and tasks. The results demonstrate that the proposed NDDV method outperforms the existing state-of-the-art data valuation methods in accurately identifying data points with either high or low values and is more computationally efficient.         ",
    "url": "https://arxiv.org/abs/2404.19557",
    "authors": [
      "Zhangyong Liang",
      "Huanhuan Gao",
      "Ji Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.09556",
    "title": "Co-learning-aided Multi-modal-deep-learning Framework of Passive DOA Estimators for a Heterogeneous Hybrid Massive MIMO Receiver",
    "abstract": "           Due to its excellent performance in rate and resolution, fully-digital (FD) massive multiple-input multiple-output (MIMO) antenna arrays has been widely applied in data transmission and direction of arrival (DOA) measurements, etc. But it confronts with two main challenges: high computational complexity and circuit cost. The two problems may be addressed well by hybrid analog-digital (HAD) structure. But there exists the problem of phase ambiguity for HAD, which leads to its low-efficiency or high-latency. Does exist there such a MIMO structure of owning low-cost, low-complexity and high time efficiency at the same time. To satisfy the three properties, a novel heterogeneous hybrid MIMO receiver structure of integrating FD and heterogeneous HAD ($\\rm{H}^2$AD-FD) is proposed and corresponding multi-modal (MD)-learning framework is developed. The framework includes three major stages: 1) generate the candidate sets via root multiple signal classification (Root-MUSIC) or deep learning (DL); 2) infer the class of true solutions from candidate sets using machine learning (ML) methods; 3) fuse the two-part true solutions to achieve a better DOA estimation. The above process form two methods named MD-Root-MUSIC and MDDL. To improve DOA estimation accuracy and reduce the clustering complexity, a co-learning-aided MD framework is proposed to form two enhanced methods named CoMDDL and CoMD-RootMUSIC. Moreover, the Cramer-Rao lower bound (CRLB) for the proposed $\\rm{H}^2$AD-FD structure is also derived. Experimental results demonstrate that our proposed four methods could approach the CRLB for signal-to-noise ratio (SNR) > 0 dB and the proposed CoMDDL and MDDL perform better than CoMD-RootMUSIC and MD-RootMUSIC, particularly in the extremely low SNR region.         ",
    "url": "https://arxiv.org/abs/2405.09556",
    "authors": [
      "Jiatong Bai",
      "Feng Shu",
      "Qinghe Zheng",
      "Bo Xu",
      "Baihua Shi",
      "Yiwen Chen",
      "Weibin Zhang",
      "Xianpeng Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2406.02313",
    "title": "Neural Thermodynamic Integration: Free Energies from Energy-based Diffusion Models",
    "abstract": "           Thermodynamic integration (TI) offers a rigorous method for estimating free-energy differences by integrating over a sequence of interpolating conformational ensembles. However, TI calculations are computationally expensive and typically limited to coupling a small number of degrees of freedom due to the need to sample numerous intermediate ensembles with sufficient conformational-space overlap. In this work, we propose to perform TI along an alchemical pathway represented by a trainable neural network, which we term Neural TI. Critically, we parametrize a time-dependent Hamiltonian interpolating between the interacting and non-interacting systems, and optimize its gradient using a denoising-diffusion objective. The ability of the resulting energy-based diffusion model to sample all intermediate ensembles allows us to perform TI from a single reference calculation. We apply our method to Lennard-Jones fluids, where we report accurate calculations of the excess chemical potential, demonstrating that Neural TI is capable of coupling hundreds of degrees of freedom at once.         ",
    "url": "https://arxiv.org/abs/2406.02313",
    "authors": [
      "B\u00e1lint M\u00e1t\u00e9",
      "Fran\u00e7ois Fleuret",
      "Tristan Bereau"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  }
]