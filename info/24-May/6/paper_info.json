[
  {
    "id": "arXiv:2405.01553",
    "title": "Empirical Studies of Parameter Efficient Methods for Large Language  Models of Code and Knowledge Transfer to R",
    "abstract": "Recently, Large Langauge Models (LLMs) have gained a lot of attention in the Software Engineering (SE) community. LLMs or their variants pre-trained on code are used for many SE tasks. A main approach for adapting LLMs to the downstream task is to fine-tune the models. However, with having billions-parameters-LLMs, fine-tuning the models is not practical. An alternative approach is using Parameter Efficient Fine Tuning (PEFT), in which the model parameters are frozen and only a few added parameters are trained. Though the LLMs are used for programming languages such as Python and Java widely, their capability for low-resource languages is limited. In this work, we empirically study PEFT methods, LoRA and Compacter, on CodeT5 and CodeLlama. We will assess their performance compared to fully fine-tuned models, whether they can be used for knowledge transfer from natural language models to code (using T5 and Llama models), and their ability to adapt the learned knowledge to an unseen language. For the unseen language, we aim to study R, as it has a wide community. The adaptability with less computational costs makes LLMs accessible in scenarios where heavy computational resources are not available. Moreover, studying R opens new opportunities for using LLMs for other languages. We anticipate our findings to showcase the capabilities of PEFT for code LLMs for R and reveal the improvement areas. ",
    "url": "https://arxiv.org/abs/2405.01553",
    "authors": [
      "Amirreza Esmaeili",
      "Iman Saberi",
      "Fatemeh H. Fard"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01554",
    "title": "Early-stage detection of cognitive impairment by hybrid  quantum-classical algorithm using resting-state functional MRI time-series",
    "abstract": "Following the recent development of quantum machine learning techniques, the literature has reported several quantum machine learning algorithms for disease detection. This study explores the application of a hybrid quantum-classical algorithm for classifying region-of-interest time-series data obtained from resting-state functional magnetic resonance imaging in patients with early-stage cognitive impairment based on the importance of cognitive decline for dementia or aging. Classical one-dimensional convolutional layers are used together with quantum convolutional neural networks in our hybrid algorithm. In the classical simulation, the proposed hybrid algorithms showed higher balanced accuracies than classical convolutional neural networks under the similar training conditions. Moreover, a total of nine brain regions (left precentral gyrus, right superior temporal gyrus, left rolandic operculum, right rolandic operculum, left parahippocampus, right hippocampus, left medial frontal gyrus, right cerebellum crus, and cerebellar vermis) among 116 brain regions were found to be relatively effective brain regions for the classification based on the model performances. The associations of the selected nine regions with cognitive decline, as found in previous studies, were additionally validated through seed-based functional connectivity analysis. We confirmed both the improvement of model performance with the quantum convolutional neural network and neuroscientific validities of brain regions from our hybrid quantum-classical model. ",
    "url": "https://arxiv.org/abs/2405.01554",
    "authors": [
      "Junggu Choi",
      "Tak Hur",
      "Daniel K. Park",
      "Na-Young Shin",
      "Seung-Koo Lee",
      "Hakbae Lee",
      "Sanghoon Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2405.01556",
    "title": "Semantically Aligned Question and Code Generation for Automated Insight  Generation",
    "abstract": "Automated insight generation is a common tactic for helping knowledge workers, such as data scientists, to quickly understand the potential value of new and unfamiliar data. Unfortunately, automated insights produced by large-language models can generate code that does not correctly correspond (or align) to the insight. In this paper, we leverage the semantic knowledge of large language models to generate targeted and insightful questions about data and the corresponding code to answer those questions. Then through an empirical study on data from Open-WikiTable, we show that embeddings can be effectively used for filtering out semantically unaligned pairs of question and code. Additionally, we found that generating questions and code together yields more diverse questions. ",
    "url": "https://arxiv.org/abs/2405.01556",
    "authors": [
      "Ananya Singha",
      "Bhavya Chopra",
      "Anirudh Khatry",
      "Sumit Gulwani",
      "Austin Z. Henley",
      "Vu Le",
      "Chris Parnin",
      "Mukul Singh",
      "Gust Verbruggen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2405.01565",
    "title": "The Role of Code Proficiency in the Era of Generative AI",
    "abstract": "At the current pace of technological advancements, Generative AI models, including both Large Language Models and Large Multi-modal Models, are becoming integral to the developer workspace. However, challenges emerge due to the 'black box' nature of many of these models, where the processes behind their outputs are not transparent. This position paper advocates for a 'white box' approach to these generative models, emphasizing the necessity of transparency and understanding in AI-generated code to match the proficiency levels of human developers and better enable software maintenance and evolution. We outline a research agenda aimed at investigating the alignment between AI-generated code and developer skills, highlighting the importance of responsibility, security, legal compliance, creativity, and social value in software development. The proposed research questions explore the potential of white-box methodologies to ensure that software remains an inspectable, adaptable, and trustworthy asset in the face of rapid AI integration, setting a course for research that could shape the role of code proficiency into 2030 and beyond. ",
    "url": "https://arxiv.org/abs/2405.01565",
    "authors": [
      "Gregorio Robles",
      "Christoph Treude",
      "Jesus M. Gonzalez-Barahona",
      "Raula Gaikovina Kula"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2405.01567",
    "title": "CodeFort: Robust Training for Code Generation Models",
    "abstract": "Code generation models are not robust to small perturbations, which often lead to inconsistent and incorrect generations and significantly degrade the performance of these models. Improving the robustness of code generation models is crucial to better user experience when these models are deployed in real-world applications. However, existing efforts have not addressed this issue for code generation models. To fill this gap, we propose CodeFort, a framework to improve the robustness of code generation models, generalizing a large variety of code perturbations to enrich the training data and enabling various robust training strategies, mixing data augmentation, batch augmentation, adversarial logits pairing, and contrastive learning, all carefully designed to support high-throughput training. Extensive evaluations show that we improve the average robust pass rates of baseline CodeGen models from 14.79 to 21.74. Notably, the improvement in robustness against code-syntax perturbations is evidenced by a significant decrease in pass rate drop from 95.04% to 53.35% ",
    "url": "https://arxiv.org/abs/2405.01567",
    "authors": [
      "Yuhao Zhang",
      "Shiqi Wang",
      "Haifeng Qian",
      "Zijian Wang",
      "Mingyue Shang",
      "Linbo Liu",
      "Sanjay Krishna Gouda",
      "Baishakhi Ray",
      "Murali Krishna Ramanathan",
      "Xiaofei Ma",
      "Anoop Deoras"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01573",
    "title": "Class-Level Code Generation from Natural Language Using Iterative,  Tool-Enhanced Reasoning over Repository",
    "abstract": "LLMs have demonstrated significant potential in code generation tasks, achieving promising results at the function or statement level in various benchmarks. However, the complexities associated with creating code artifacts like classes, particularly within the context of real-world software repositories, remain underexplored. Existing research often treats class-level generation as an isolated task, neglecting the intricate dependencies and interactions that characterize real-world software development environments. To address this gap, we introduce RepoClassBench, a benchmark designed to rigorously evaluate LLMs in generating complex, class-level code within real-world repositories. RepoClassBench includes natural language to class generation tasks across Java and Python, from a selection of public repositories. We ensure that each class in our dataset not only has cross-file dependencies within the repository but also includes corresponding test cases to verify its functionality. We find that current models struggle with the realistic challenges posed by our benchmark, primarily due to their limited exposure to relevant repository contexts. To address this shortcoming, we introduce Retrieve-Repotools-Reflect (RRR), a novel approach that equips LLMs with static analysis tools to iteratively navigate & reason about repository-level context in an agent-based framework. Our experiments demonstrate that RRR significantly outperforms existing baselines on RepoClassBench, showcasing its effectiveness across programming languages and in various settings. Our findings emphasize the need for benchmarks that incorporate repository-level dependencies to more accurately reflect the complexities of software development. Our work illustrates the benefits of leveraging specialized tools to enhance LLMs understanding of repository context. We plan to make our dataset and evaluation harness public. ",
    "url": "https://arxiv.org/abs/2405.01573",
    "authors": [
      "Ajinkya Deshpande",
      "Anmol Agarwal",
      "Shashank Shet",
      "Arun Iyer",
      "Aditya Kanade",
      "Ramakrishna Bairi",
      "Suresh Parthasarathy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01577",
    "title": "HateTinyLLM : Hate Speech Detection Using Tiny Large Language Models",
    "abstract": "Hate speech encompasses verbal, written, or behavioral communication that targets derogatory or discriminatory language against individuals or groups based on sensitive characteristics. Automated hate speech detection plays a crucial role in curbing its propagation, especially across social media platforms. Various methods, including recent advancements in deep learning, have been devised to address this challenge. In this study, we introduce HateTinyLLM, a novel framework based on fine-tuned decoder-only tiny large language models (tinyLLMs) for efficient hate speech detection. Our experimental findings demonstrate that the fine-tuned HateTinyLLM outperforms the pretrained mixtral-7b model by a significant margin. We explored various tiny LLMs, including PY007/TinyLlama-1.1B-step-50K-105b, Microsoft/phi-2, and facebook/opt-1.3b, and fine-tuned them using LoRA and adapter methods. Our observations indicate that all LoRA-based fine-tuned models achieved over 80\\% accuracy. ",
    "url": "https://arxiv.org/abs/2405.01577",
    "authors": [
      "Tanmay Sen",
      "Ansuman Das",
      "Mrinmay Sen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01579",
    "title": "Mining patterns in syntax trees to automate code reviews of student  solutions for programming exercises",
    "abstract": "In programming education, providing manual feedback is essential but labour-intensive, posing challenges in consistency and timeliness. We introduce ECHO, a machine learning method to automate the reuse of feedback in educational code reviews by analysing patterns in abstract syntax trees. This study investigates two primary questions: whether ECHO can predict feedback annotations to specific lines of student code based on previously added annotations by human reviewers (RQ1), and whether its training and prediction speeds are suitable for using ECHO for real-time feedback during live code reviews by human reviewers (RQ2). Our results, based on annotations from both automated linting tools and human reviewers, show that ECHO can accurately and quickly predict appropriate feedback annotations. Its efficiency in processing and its flexibility in adapting to feedback patterns can significantly reduce the time and effort required for manual feedback provisioning in educational settings. ",
    "url": "https://arxiv.org/abs/2405.01579",
    "authors": [
      "Charlotte Van Petegem",
      "Kasper Demeyere",
      "Rien Maertens",
      "Niko Strijbol",
      "Bram De Wever",
      "Bart Mesuere",
      "Peter Dawyndt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01580",
    "title": "On the Limitations of Embedding Based Methods for Measuring Functional  Correctness for Code Generation",
    "abstract": "The task of code generation from natural language (NL2Code) has become extremely popular, especially with the advent of Large Language Models (LLMs). However, efforts to quantify and track this progress have suffered due to a lack of reliable metrics for functional correctness. While popular benchmarks like HumanEval have test cases to enable reliable evaluation of correctness, it is time-consuming and requires human effort to collect test cases. As an alternative several reference-based evaluation metrics have been proposed, with embedding-based metrics like CodeBERTScore being touted as having a high correlation with human preferences and functional correctness. In our work, we analyze the ability of embedding-based metrics like CodeBERTScore to measure functional correctness and other helpful constructs like editing effort by analyzing outputs of ten models over two popular code generation benchmarks. Our results show that while they have a weak correlation with functional correctness (0.16), they are strongly correlated (0.72) with editing effort. ",
    "url": "https://arxiv.org/abs/2405.01580",
    "authors": [
      "Atharva Naik"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01585",
    "title": "Tabular Embedding Model (TEM): Finetuning Embedding Models For Tabular  RAG Applications",
    "abstract": "In recent times Large Language Models have exhibited tremendous capabilities, especially in the areas of mathematics, code generation and general-purpose reasoning. However for specialized domains especially in applications that require parsing and analyzing large chunks of numeric or tabular data even state-of-the-art (SOTA) models struggle. In this paper, we introduce a new approach to solving domain-specific tabular data analysis tasks by presenting a unique RAG workflow that mitigates the scalability issues of existing tabular LLM solutions. Specifically, we present Tabular Embedding Model (TEM), a novel approach to fine-tune embedding models for tabular Retrieval-Augmentation Generation (RAG) applications. Embedding models form a crucial component in the RAG workflow and even current SOTA embedding models struggle as they are predominantly trained on textual datasets and thus underperform in scenarios involving complex tabular data. The evaluation results showcase that our approach not only outperforms current SOTA embedding models in this domain but also does so with a notably smaller and more efficient model structure. ",
    "url": "https://arxiv.org/abs/2405.01585",
    "authors": [
      "Sujit Khanna",
      "Shishir Subedi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2405.01593",
    "title": "Large Language Model Agent for Fake News Detection",
    "abstract": "In the current digital era, the rapid spread of misinformation on online platforms presents significant challenges to societal well-being, public trust, and democratic processes, influencing critical decision making and public opinion. To address these challenges, there is a growing need for automated fake news detection mechanisms. Pre-trained large language models (LLMs) have demonstrated exceptional capabilities across various natural language processing (NLP) tasks, prompting exploration into their potential for verifying news claims. Instead of employing LLMs in a non-agentic way, where LLMs generate responses based on direct prompts in a single shot, our work introduces FactAgent, an agentic approach of utilizing LLMs for fake news detection. FactAgent enables LLMs to emulate human expert behavior in verifying news claims without any model training, following a structured workflow. This workflow breaks down the complex task of news veracity checking into multiple sub-steps, where LLMs complete simple tasks using their internal knowledge or external tools. At the final step of the workflow, LLMs integrate all findings throughout the workflow to determine the news claim's veracity. Compared to manual human verification, FactAgent offers enhanced efficiency. Experimental studies demonstrate the effectiveness of FactAgent in verifying claims without the need for any training process. Moreover, FactAgent provides transparent explanations at each step of the workflow and during final decision-making, offering insights into the reasoning process of fake news detection for end users. FactAgent is highly adaptable, allowing for straightforward updates to its tools that LLMs can leverage within the workflow, as well as updates to the workflow itself using domain knowledge. This adaptability enables FactAgent's application to news verification across various domains. ",
    "url": "https://arxiv.org/abs/2405.01593",
    "authors": [
      "Xinyi Li",
      "Yongfeng Zhang",
      "Edward C. Malthouse"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2405.01597",
    "title": "Improving Disease Detection from Social Media Text via Self-Augmentation  and Contrastive Learning",
    "abstract": "Detecting diseases from social media has diverse applications, such as public health monitoring and disease spread detection. While language models (LMs) have shown promising performance in this domain, there remains ongoing research aimed at refining their discriminating representations. In this paper, we propose a novel method that integrates Contrastive Learning (CL) with language modeling to address this challenge. Our approach introduces a self-augmentation method, wherein hidden representations of the model are augmented with their own representations. This method comprises two branches: the first branch, a traditional LM, learns features specific to the given data, while the second branch incorporates augmented representations from the first branch to encourage generalization. CL further refines these representations by pulling pairs of original and augmented versions closer while pushing other samples away. We evaluate our method on three NLP datasets encompassing binary, multi-label, and multi-class classification tasks involving social media posts related to various diseases. Our approach demonstrates notable improvements over traditional fine-tuning methods, achieving up to a 2.48% increase in F1-score compared to baseline approaches and a 2.1% enhancement over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2405.01597",
    "authors": [
      "Pervaiz Iqbal Khan",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2405.01646",
    "title": "Explaining models relating objects and privacy",
    "abstract": "Accurately predicting whether an image is private before sharing it online is difficult due to the vast variety of content and the subjective nature of privacy itself. In this paper, we evaluate privacy models that use objects extracted from an image to determine why the image is predicted as private. To explain the decision of these models, we use feature-attribution to identify and quantify which objects (and which of their features) are more relevant to privacy classification with respect to a reference input (i.e., no objects localised in an image) predicted as public. We show that the presence of the person category and its cardinality is the main factor for the privacy decision. Therefore, these models mostly fail to identify private images depicting documents with sensitive data, vehicle ownership, and internet activity, or public images with people (e.g., an outdoor concert or people walking in a public space next to a famous landmark). As baselines for future benchmarks, we also devise two strategies that are based on the person presence and cardinality and achieve comparable classification performance of the privacy models. ",
    "url": "https://arxiv.org/abs/2405.01646",
    "authors": [
      "Alessio Xompero",
      "Myriam Bontonou",
      "Jean-Michel Arbona",
      "Emmanouil Benetos",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.01649",
    "title": "Improving Complex Reasoning over Knowledge Graph with Logic-Aware  Curriculum Tuning",
    "abstract": "Answering complex logical queries over incomplete knowledge graphs (KGs) is challenging. Most previous works have focused on learning entity/relation embeddings and simulating first-order logic operators with various neural networks. However, they are bottlenecked by the inability to share world knowledge to improve logical reasoning, thus resulting in suboptimal performance. In this paper, we propose a complex logical reasoning schema over knowledge graphs upon large language models (LLMs), containing a curriculum-based logical-aware instruction tuning framework, named LACT. Specifically, we augment the arbitrary first-order logical queries via binary tree decomposition, to stimulate the reasoning capability of LLMs. To address the difficulty gap among different types of complex queries, we design a simple and flexible logic-aware curriculum learning framework. Experiments across widely used datasets demonstrate that LACT has substantial improvements~(brings an average +5.5% MRR score) over advanced methods, achieving the new state-of-the-art. Our code and model will be released at GitHub and huggingface soon. ",
    "url": "https://arxiv.org/abs/2405.01649",
    "authors": [
      "Tianle Xia",
      "Liang Ding",
      "Guojia Wan",
      "Yibing Zhan",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2405.01654",
    "title": "Key Patches Are All You Need: A Multiple Instance Learning Framework For  Robust Medical Diagnosis",
    "abstract": "Deep learning models have revolutionized the field of medical image analysis, due to their outstanding performances. However, they are sensitive to spurious correlations, often taking advantage of dataset bias to improve results for in-domain data, but jeopardizing their generalization capabilities. In this paper, we propose to limit the amount of information these models use to reach the final classification, by using a multiple instance learning (MIL) framework. MIL forces the model to use only a (small) subset of patches in the image, identifying discriminative regions. This mimics the clinical procedures, where medical decisions are based on localized findings. We evaluate our framework on two medical applications: skin cancer diagnosis using dermoscopy and breast cancer diagnosis using mammography. Our results show that using only a subset of the patches does not compromise diagnostic performance for in-domain data, compared to the baseline approaches. However, our approach is more robust to shifts in patient demographics, while also providing more detailed explanations about which regions contributed to the decision. Code is available at: https://github.com/diogojpa99/MedicalMultiple-Instance-Learning. ",
    "url": "https://arxiv.org/abs/2405.01654",
    "authors": [
      "Diogo J. Ara\u00fajo",
      "M. Rita Verdelho",
      "Alceu Bissoto",
      "Jacinto C. Nascimento",
      "Carlos Santiago",
      "Catarina Barata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.01656",
    "title": "S4: Self-Supervised Sensing Across the Spectrum",
    "abstract": "Satellite image time series (SITS) segmentation is crucial for many applications like environmental monitoring, land cover mapping and agricultural crop type classification. However, training models for SITS segmentation remains a challenging task due to the lack of abundant training data, which requires fine grained annotation. We propose S4 a new self-supervised pre-training approach that significantly reduces the requirement for labeled training data by utilizing two new insights: (a) Satellites capture images in different parts of the spectrum such as radio frequencies, and visible frequencies. (b) Satellite imagery is geo-registered allowing for fine-grained spatial alignment. We use these insights to formulate pre-training tasks in S4. We also curate m2s2-SITS, a large-scale dataset of unlabeled, spatially-aligned, multi-modal and geographic specific SITS that serves as representative pre-training data for S4. Finally, we evaluate S4 on multiple SITS segmentation datasets and demonstrate its efficacy against competing baselines while using limited labeled data. ",
    "url": "https://arxiv.org/abs/2405.01656",
    "authors": [
      "Jayanth Shenoy",
      "Xinjian Davis Zhang",
      "Shlok Mehrotra",
      "Bill Tao",
      "Rem Yang",
      "Han Zhao",
      "Deepak Vasisht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01662",
    "title": "Out-of-distribution detection based on subspace projection of  high-dimensional features output by the last convolutional layer",
    "abstract": "Out-of-distribution (OOD) detection, crucial for reliable pattern classification, discerns whether a sample originates outside the training distribution. This paper concentrates on the high-dimensional features output by the final convolutional layer, which contain rich image features. Our key idea is to project these high-dimensional features into two specific feature subspaces, leveraging the dimensionality reduction capacity of the network's linear layers, trained with Predefined Evenly-Distribution Class Centroids (PEDCC)-Loss. This involves calculating the cosines of three projection angles and the norm values of features, thereby identifying distinctive information for in-distribution (ID) and OOD data, which assists in OOD detection. Building upon this, we have modified the batch normalization (BN) and ReLU layer preceding the fully connected layer, diminishing their impact on the output feature distributions and thereby widening the distribution gap between ID and OOD data features. Our method requires only the training of the classification network model, eschewing any need for input pre-processing or specific OOD data pre-tuning. Extensive experiments on several benchmark datasets demonstrates that our approach delivers state-of-the-art performance. Our code is available at https://github.com/Hewell0/ProjOOD. ",
    "url": "https://arxiv.org/abs/2405.01662",
    "authors": [
      "Qiuyu Zhu",
      "Yiwei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.01663",
    "title": "ATNPA: A Unified View of Oversmoothing Alleviation in Graph Neural  Networks",
    "abstract": "Oversmoothing is a commonly observed challenge in graph neural network (GNN) learning, where, as layers increase, embedding features learned from GNNs quickly become similar/indistinguishable, making them incapable of differentiating network proximity. A GNN with shallow layer architectures can only learn short-term relation or localized structure information, limiting its power of learning long-term connection, evidenced by their inferior learning performance on heterophilous graphs. Tackling oversmoothing is crucial to harness deep-layer architectures for GNNs. To date, many methods have been proposed to alleviate oversmoothing. The vast difference behind their design principles, combined with graph complications, make it difficult to understand and even compare their difference in tackling the oversmoothing. In this paper, we propose ATNPA, a unified view with five key steps: Augmentation, Transformation, Normalization, Propagation, and Aggregation, to summarize GNN oversmoothing alleviation approaches. We first outline three themes to tackle oversmoothing, and then separate all methods into six categories, followed by detailed reviews of representative methods, including their relation to the ATNPA, and discussion about their niche, strength, and weakness. The review not only draws in-depth understanding of existing methods in the field, but also shows a clear road map for future study. ",
    "url": "https://arxiv.org/abs/2405.01663",
    "authors": [
      "Yufei Jin",
      "Xingquan Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01678",
    "title": "1-Diffractor: Efficient and Utility-Preserving Text Obfuscation  Leveraging Word-Level Metric Differential Privacy",
    "abstract": "The study of privacy-preserving Natural Language Processing (NLP) has gained rising attention in recent years. One promising avenue studies the integration of Differential Privacy in NLP, which has brought about innovative methods in a variety of application settings. Of particular note are $\\textit{word-level Metric Local Differential Privacy (MLDP)}$ mechanisms, which work to obfuscate potentially sensitive input text by performing word-by-word $\\textit{perturbations}$. Although these methods have shown promising results in empirical tests, there are two major drawbacks: (1) the inevitable loss of utility due to addition of noise, and (2) the computational expensiveness of running these mechanisms on high-dimensional word embeddings. In this work, we aim to address these challenges by proposing $\\texttt{1-Diffractor}$, a new mechanism that boasts high speedups in comparison to previous mechanisms, while still demonstrating strong utility- and privacy-preserving capabilities. We evaluate $\\texttt{1-Diffractor}$ for utility on several NLP tasks, for theoretical and task-based privacy, and for efficiency in terms of speed and memory. $\\texttt{1-Diffractor}$ shows significant improvements in efficiency, while still maintaining competitive utility and privacy scores across all conducted comparative tests against previous MLDP mechanisms. Our code is made available at: https://github.com/sjmeis/Diffractor. ",
    "url": "https://arxiv.org/abs/2405.01678",
    "authors": [
      "Stephen Meisenbacher",
      "Maulik Chevli",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2405.01680",
    "title": "Physics-Informed Neural Networks: Minimizing Residual Loss with Wide  Networks and Effective Activations",
    "abstract": "The residual loss in Physics-Informed Neural Networks (PINNs) alters the simple recursive relation of layers in a feed-forward neural network by applying a differential operator, resulting in a loss landscape that is inherently different from those of common supervised problems. Therefore, relying on the existing theory leads to unjustified design choices and suboptimal performance. In this work, we analyze the residual loss by studying its characteristics at critical points to find the conditions that result in effective training of PINNs. Specifically, we first show that under certain conditions, the residual loss of PINNs can be globally minimized by a wide neural network. Furthermore, our analysis also reveals that an activation function with well-behaved high-order derivatives plays a crucial role in minimizing the residual loss. In particular, to solve a $k$-th order PDE, the $k$-th derivative of the activation function should be bijective. The established theory paves the way for designing and choosing effective activation functions for PINNs and explains why periodic activations have shown promising performance in certain cases. Finally, we verify our findings by conducting a set of experiments on several PDEs. Our code is publicly available at https://github.com/nimahsn/pinns_tf2. ",
    "url": "https://arxiv.org/abs/2405.01680",
    "authors": [
      "Nima Hosseini Dashtbayaz",
      "Ghazal Farhani",
      "Boyu Wang",
      "Charles X. Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01688",
    "title": "Adapting Self-Supervised Learning for Computational Pathology",
    "abstract": "Self-supervised learning (SSL) has emerged as a key technique for training networks that can generalize well to diverse tasks without task-specific supervision. This property makes SSL desirable for computational pathology, the study of digitized images of tissues, as there are many target applications and often limited labeled training samples. However, SSL algorithms and models have been primarily developed in the field of natural images and whether their performance can be improved by adaptation to particular domains remains an open question. In this work, we present an investigation of modifications to SSL for pathology data, specifically focusing on the DINOv2 algorithm. We propose alternative augmentations, regularization functions, and position encodings motivated by the characteristics of pathology images. We evaluate the impact of these changes on several benchmarks to demonstrate the value of tailored approaches. ",
    "url": "https://arxiv.org/abs/2405.01688",
    "authors": [
      "Eric Zimmermann",
      "Neil Tenenholtz",
      "James Hall",
      "George Shaikovski",
      "Michal Zelechowski",
      "Adam Casson",
      "Fausto Milletari",
      "Julian Viret",
      "Eugene Vorontsov",
      "Siqi Liu",
      "Kristen Severson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.01690",
    "title": "Addressing the Load Estimation Problem: Cell Switching in HAPS-Assisted  Sustainable 6G Networks",
    "abstract": "This study aims to introduce and address the problem of traffic load estimation in the cell switching concept within the evolving landscape of vertical heterogeneous networks (vHetNets). The problem is that the practice of cell switching faces a significant challenge due to the lack of accurate data on the traffic load of sleeping small base stations (SBSs). This problem makes the majority of the studies in the literature, particularly those employing load-dependent approaches, impractical due to their basic assumption of perfect knowledge of the traffic loads of sleeping SBSs for the next time slot. Rather than developing another advanced cell switching algorithm, this study investigates the impacts of estimation errors and explores possible solutions through established methodologies in a novel vHetNet environment that includes the integration of a high altitude platform (HAPS) as a super macro base station (SMBS) into the terrestrial network. In other words, this study adopts a more foundational perspective, focusing on eliminating a significant obstacle for the application of advanced cell switching algorithms. To this end, we explore the potential of three distinct spatial interpolation-based estimation schemes: random neighboring selection, distance-based selection, and clustering-based selection. Utilizing a real dataset for empirical validations, we evaluate the efficacy of our proposed traffic load estimation schemes. Our results demonstrate that the multi-level clustering (MLC) algorithm performs exceptionally well, with an insignificant difference (i.e., 0.8%) observed between its estimated and actual network power consumption, highlighting its potential to significantly improve energy efficiency in vHetNets. ",
    "url": "https://arxiv.org/abs/2405.01690",
    "authors": [
      "Maryam Salamatmoghadasi",
      "Metin Ozturk",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2405.01691",
    "title": "Language-Enhanced Latent Representations for Out-of-Distribution  Detection in Autonomous Driving",
    "abstract": "Out-of-distribution (OOD) detection is essential in autonomous driving, to determine when learning-based components encounter unexpected inputs. Traditional detectors typically use encoder models with fixed settings, thus lacking effective human interaction capabilities. With the rise of large foundation models, multimodal inputs offer the possibility of taking human language as a latent representation, thus enabling language-defined OOD detection. In this paper, we use the cosine similarity of image and text representations encoded by the multimodal model CLIP as a new representation to improve the transparency and controllability of latent encodings used for visual anomaly detection. We compare our approach with existing pre-trained encoders that can only produce latent representations that are meaningless from the user's standpoint. Our experiments on realistic driving data show that the language-based latent representation performs better than the traditional representation of the vision encoder and helps improve the detection performance when combined with standard representations. ",
    "url": "https://arxiv.org/abs/2405.01691",
    "authors": [
      "Zhenjiang Mao",
      "Dong-You Jhong",
      "Ao Wang",
      "Ivan Ruchkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2405.01693",
    "title": "Adversarial Attacks on Reinforcement Learning Agents for Command and  Control",
    "abstract": "Given the recent impact of Deep Reinforcement Learning in training agents to win complex games like StarCraft and DoTA(Defense Of The Ancients) - there has been a surge in research for exploiting learning based techniques for professional wargaming, battlefield simulation and modeling. Real time strategy games and simulators have become a valuable resource for operational planning and military research. However, recent work has shown that such learning based approaches are highly susceptible to adversarial perturbations. In this paper, we investigate the robustness of an agent trained for a Command and Control task in an environment that is controlled by an active adversary. The C2 agent is trained on custom StarCraft II maps using the state of the art RL algorithms - A3C and PPO. We empirically show that an agent trained using these algorithms is highly susceptible to noise injected by the adversary and investigate the effects these perturbations have on the performance of the trained agent. Our work highlights the urgent need to develop more robust training algorithms especially for critical arenas like the battlefield. ",
    "url": "https://arxiv.org/abs/2405.01693",
    "authors": [
      "Ahaan Dabholkar",
      "James Z. Hare",
      "Mark Mittrick",
      "John Richardson",
      "Nicholas Waytowich",
      "Priya Narayanan",
      "Saurabh Bagchi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2405.01699",
    "title": "SOAR: Advancements in Small Body Object Detection for Aerial Imagery  Using State Space Models and Programmable Gradients",
    "abstract": "Small object detection in aerial imagery presents significant challenges in computer vision due to the minimal data inherent in small-sized objects and their propensity to be obscured by larger objects and background noise. Traditional methods using transformer-based models often face limitations stemming from the lack of specialized databases, which adversely affect their performance with objects of varying orientations and scales. This underscores the need for more adaptable, lightweight models. In response, this paper introduces two innovative approaches that significantly enhance detection and segmentation capabilities for small aerial objects. Firstly, we explore the use of the SAHI framework on the newly introduced lightweight YOLO v9 architecture, which utilizes Programmable Gradient Information (PGI) to reduce the substantial information loss typically encountered in sequential feature extraction processes. The paper employs the Vision Mamba model, which incorporates position embeddings to facilitate precise location-aware visual understanding, combined with a novel bidirectional State Space Model (SSM) for effective visual context modeling. This State Space Model adeptly harnesses the linear complexity of CNNs and the global receptive field of Transformers, making it particularly effective in remote sensing image classification. Our experimental results demonstrate substantial improvements in detection accuracy and processing efficiency, validating the applicability of these approaches for real-time small object detection across diverse aerial scenarios. This paper also discusses how these methodologies could serve as foundational models for future advancements in aerial object recognition technologies. The source code will be made accessible here. ",
    "url": "https://arxiv.org/abs/2405.01699",
    "authors": [
      "Tushar Verma",
      "Jyotsna Singh",
      "Yash Bhartari",
      "Rishi Jarwal",
      "Suraj Singh",
      "Shubhkarman Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01705",
    "title": "Long Tail Image Generation Through Feature Space Augmentation and  Iterated Learning",
    "abstract": "Image and multimodal machine learning tasks are very challenging to solve in the case of poorly distributed data. In particular, data availability and privacy restrictions exacerbate these hurdles in the medical domain. The state of the art in image generation quality is held by Latent Diffusion models, making them prime candidates for tackling this problem. However, a few key issues still need to be solved, such as the difficulty in generating data from under-represented classes and a slow inference process. To mitigate these issues, we propose a new method for image augmentation in long-tailed data based on leveraging the rich latent space of pre-trained Stable Diffusion Models. We create a modified separable latent space to mix head and tail class examples. We build this space via Iterated Learning of underlying sparsified embeddings, which we apply to task-specific saliency maps via a K-NN approach. Code is available at https://github.com/SugarFreeManatee/Feature-Space-Augmentation-and-Iterated-Learning ",
    "url": "https://arxiv.org/abs/2405.01705",
    "authors": [
      "Rafael Elberg",
      "Denis Parra",
      "Mircea Petrache"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01708",
    "title": "A deep causal inference model for fully-interpretable travel behaviour  analysis",
    "abstract": "Transport policy assessment often involves causal questions, yet the causal inference capabilities of traditional travel behavioural models are at best limited. We present the deep CAusal infeRence mOdel for traveL behavIour aNAlysis (CAROLINA), a framework that explicitly models causality in travel behaviour, enhances predictive accuracy, and maintains interpretability by leveraging causal inference, deep learning, and traditional discrete choice modelling. Within this framework, we introduce a Generative Counterfactual model for forecasting human behaviour by adapting the Normalizing Flow method. Through the case studies of virtual reality-based pedestrian crossing behaviour, revealed preference travel behaviour from London, and synthetic data, we demonstrate the effectiveness of our proposed models in uncovering causal relationships, prediction accuracy, and assessing policy interventions. Our results show that intervention mechanisms that can reduce pedestrian stress levels lead to a 38.5% increase in individuals experiencing shorter waiting times. Reducing the travel distances in London results in a 47% increase in sustainable travel modes. ",
    "url": "https://arxiv.org/abs/2405.01708",
    "authors": [
      "Kimia Kamal",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01716",
    "title": "ATTAXONOMY: Unpacking Differential Privacy Guarantees Against Practical  Adversaries",
    "abstract": "Differential Privacy (DP) is a mathematical framework that is increasingly deployed to mitigate privacy risks associated with machine learning and statistical analyses. Despite the growing adoption of DP, its technical privacy parameters do not lend themselves to an intelligible description of the real-world privacy risks associated with that deployment: the guarantee that most naturally follows from the DP definition is protection against membership inference by an adversary who knows all but one data record and has unlimited auxiliary knowledge. In many settings, this adversary is far too strong to inform how to set real-world privacy parameters. One approach for contextualizing privacy parameters is via defining and measuring the success of technical attacks, but doing so requires a systematic categorization of the relevant attack space. In this work, we offer a detailed taxonomy of attacks, showing the various dimensions of attacks and highlighting that many real-world settings have been understudied. Our taxonomy provides a roadmap for analyzing real-world deployments and developing theoretical bounds for more informative privacy attacks. We operationalize our taxonomy by using it to analyze a real-world case study, the Israeli Ministry of Health's recent release of a birth dataset using DP, showing how the taxonomy enables fine-grained threat modeling and provides insight towards making informed privacy parameter choices. Finally, we leverage the taxonomy towards defining a more realistic attack than previously considered in the literature, namely a distributional reconstruction attack: we generalize Balle et al.'s notion of reconstruction robustness to a less-informed adversary with distributional uncertainty, and extend the worst-case guarantees of DP to this average-case setting. ",
    "url": "https://arxiv.org/abs/2405.01716",
    "authors": [
      "Rachel Cummings",
      "Shlomi Hod",
      "Jayshree Sarathy",
      "Marika Swanberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2405.01718",
    "title": "Robust Risk-Sensitive Reinforcement Learning with Conditional  Value-at-Risk",
    "abstract": "Robust Markov Decision Processes (RMDPs) have received significant research interest, offering an alternative to standard Markov Decision Processes (MDPs) that often assume fixed transition probabilities. RMDPs address this by optimizing for the worst-case scenarios within ambiguity sets. While earlier studies on RMDPs have largely centered on risk-neutral reinforcement learning (RL), with the goal of minimizing expected total discounted costs, in this paper, we analyze the robustness of CVaR-based risk-sensitive RL under RMDP. Firstly, we consider predetermined ambiguity sets. Based on the coherency of CVaR, we establish a connection between robustness and risk sensitivity, thus, techniques in risk-sensitive RL can be adopted to solve the proposed problem. Furthermore, motivated by the existence of decision-dependent uncertainty in real-world problems, we study problems with state-action-dependent ambiguity sets. To solve this, we define a new risk measure named NCVaR and build the equivalence of NCVaR optimization and robust CVaR optimization. We further propose value iteration algorithms and validate our approach in simulation experiments. ",
    "url": "https://arxiv.org/abs/2405.01718",
    "authors": [
      "Xinyi Ni",
      "Lifeng Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2405.01728",
    "title": "Explainability Guided Adversarial Evasion Attacks on Malware Detectors",
    "abstract": "As the focus on security of Artificial Intelligence (AI) is becoming paramount, research on crafting and inserting optimal adversarial perturbations has become increasingly critical. In the malware domain, this adversarial sample generation relies heavily on the accuracy and placement of crafted perturbation with the goal of evading a trained classifier. This work focuses on applying explainability techniques to enhance the adversarial evasion attack on a machine-learning-based Windows PE malware detector. The explainable tool identifies the regions of PE malware files that have the most significant impact on the decision-making process of a given malware detector, and therefore, the same regions can be leveraged to inject the adversarial perturbation for maximum efficiency. Profiling all the PE malware file regions based on their impact on the malware detector's decision enables the derivation of an efficient strategy for identifying the optimal location for perturbation injection. The strategy should incorporate the region's significance in influencing the malware detector's decision and the sensitivity of the PE malware file's integrity towards modifying that region. To assess the utility of explainable AI in crafting an adversarial sample of Windows PE malware, we utilize the DeepExplainer module of SHAP for determining the contribution of each region of PE malware to its detection by a CNN-based malware detector, MalConv. Furthermore, we analyzed the significance of SHAP values at a more granular level by subdividing each section of Windows PE into small subsections. We then performed an adversarial evasion attack on the subsections based on the corresponding SHAP values of the byte sequences. ",
    "url": "https://arxiv.org/abs/2405.01728",
    "authors": [
      "Kshitiz Aryal",
      "Maanak Gupta",
      "Mahmoud Abdelsalam",
      "Moustafa Saleh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2405.01734",
    "title": "Diabetic Retinopathy Detection Using Quantum Transfer Learning",
    "abstract": "Diabetic Retinopathy (DR), a prevalent complication in diabetes patients, can lead to vision impairment due to lesions formed on the retina. Detecting DR at an advanced stage often results in irreversible blindness. The traditional process of diagnosing DR through retina fundus images by ophthalmologists is not only time-intensive but also expensive. While classical transfer learning models have been widely adopted for computer-aided detection of DR, their high maintenance costs can hinder their detection efficiency. In contrast, Quantum Transfer Learning offers a more effective solution to this challenge. This approach is notably advantageous because it operates on heuristic principles, making it highly optimized for the task. Our proposed methodology leverages this hybrid quantum transfer learning technique to detect DR. To construct our model, we utilize the APTOS 2019 Blindness Detection dataset, available on Kaggle. We employ the ResNet-18, ResNet34, ResNet50, ResNet101, ResNet152 and Inception V3, pre-trained classical neural networks, for the initial feature extraction. For the classification stage, we use a Variational Quantum Classifier. Our hybrid quantum model has shown remarkable results, achieving an accuracy of 97% for ResNet-18. This demonstrates that quantum computing, when integrated with quantum machine learning, can perform tasks with a level of power and efficiency unattainable by classical computers alone. By harnessing these advanced technologies, we can significantly improve the detection and diagnosis of Diabetic Retinopathy, potentially saving many from the risk of blindness. Keywords: Diabetic Retinopathy, Quantum Transfer Learning, Deep Learning ",
    "url": "https://arxiv.org/abs/2405.01734",
    "authors": [
      "Ankush Jain",
      "Rinav Gupta",
      "Jai Singhal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01741",
    "title": "PVF (Parameter Vulnerability Factor): A Quantitative Metric Measuring AI  Vulnerability and Resilience Against Parameter Corruptions",
    "abstract": "Reliability of AI systems is a fundamental concern for the successful deployment and widespread adoption of AI technologies. Unfortunately, the escalating complexity and heterogeneity of AI hardware systems make them inevitably and increasingly susceptible to hardware faults (e.g., bit flips) that can potentially corrupt model parameters. Given this challenge, this paper aims to answer a critical question: How likely is a parameter corruption to result in an incorrect model output? To systematically answer this question, we propose a novel quantitative metric, Parameter Vulnerability Factor (PVF), inspired by architectural vulnerability factor (AVF) in computer architecture community, aiming to standardize the quantification of AI model resilience/vulnerability against parameter corruptions. We define a model parameter's PVF as the probability that a corruption in that particular model parameter will result in an incorrect output. Similar to AVF, this statistical concept can be derived from statistically extensive and meaningful fault injection (FI) experiments. In this paper, we present several use cases on applying PVF to three types of tasks/models during inference -- recommendation (DLRM), vision classification (CNN), and text classification (BERT). PVF can provide pivotal insights to AI hardware designers in balancing the tradeoff between fault protection and performance/efficiency such as mapping vulnerable AI parameter components to well-protected hardware modules. PVF metric is applicable to any AI model and has a potential to help unify and standardize AI vulnerability/resilience evaluation practice. ",
    "url": "https://arxiv.org/abs/2405.01741",
    "authors": [
      "Xun Jiao",
      "Fred Lin",
      "Harish D. Dixit",
      "Joel Coburn",
      "Abhinav Pandey",
      "Han Wang",
      "Jianyu Huang",
      "Venkat Ramesh",
      "Wang Xu",
      "Daniel Moore",
      "Sriram Sankar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01742",
    "title": "Addressing Privacy Concerns in Joint Communication and Sensing for 6G  Networks: Challenges and Prospects",
    "abstract": "The vision for 6G extends beyond mere communication, incorporating sensing capabilities to facilitate a diverse array of novel applications and services. However, the advent of joint communication and sensing (JCAS) technology introduces concerns regarding the handling of sensitive personally identifiable information (PII) pertaining to individuals and objects, along with external third-party data and disclosure. Consequently, JCAS-based applications are susceptible to privacy breaches, including location tracking, identity disclosure, profiling, and misuse of sensor data, raising significant implications under the European Union's General Data Protection Regulation (GDPR) as well as other applicable standards. This paper critically examines emergent JCAS architectures and underscores the necessity for network functions to enable privacy-specific features in the 6G systems. We propose an enhanced JCAS architecture with additional network functions and interfaces, facilitating the management of sensing policies, consent information, and transparency guidelines, alongside the integration of sensing-specific functions and storage for sensing processing sessions. Furthermore, we conduct a comprehensive threat analysis for all interfaces, employing security threat model STRIDE and privacy threat model LINDDUN. We also summarise the identified threats using standard Common Weakness Enumerations (CWEs). Finally, we suggest the security and privacy controls as the mitigating strategies to counter the identified threats stemming from the JCAS architecture. ",
    "url": "https://arxiv.org/abs/2405.01742",
    "authors": [
      "Prajnamaya Dass",
      "Sonika Ujjwal",
      "Jiri Novotny",
      "Yevhen Zolotavkin",
      "Zakaria Laaroussi",
      "Stefan K\u00f6psell"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2405.01744",
    "title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
    "abstract": "To perform effective causal inference in high-dimensional datasets, initiating the process with causal discovery is imperative, wherein a causal graph is generated based on observational data. However, obtaining a complete and accurate causal graph poses a formidable challenge, recognized as an NP-hard problem. Recently, the advent of Large Language Models (LLMs) has ushered in a new era, indicating their emergent capabilities and widespread applicability in facilitating causal reasoning across diverse domains, such as medicine, finance, and science. The expansive knowledge base of LLMs holds the potential to elevate the field of causal reasoning by offering interpretability, making inferences, generalizability, and uncovering novel causal structures. In this paper, we introduce a new framework, named Autonomous LLM-Augmented Causal Discovery Framework (ALCM), to synergize data-driven causal discovery algorithms and LLMs, automating the generation of a more resilient, accurate, and explicable causal graph. The ALCM consists of three integral components: causal structure learning, causal wrapper, and LLM-driven causal refiner. These components autonomously collaborate within a dynamic environment to address causal discovery questions and deliver plausible causal graphs. We evaluate the ALCM framework by implementing two demonstrations on seven well-known datasets. Experimental results demonstrate that ALCM outperforms existing LLM methods and conventional data-driven causal reasoning mechanisms. This study not only shows the effectiveness of the ALCM but also underscores new research directions in leveraging the causal reasoning capabilities of LLMs. ",
    "url": "https://arxiv.org/abs/2405.01744",
    "authors": [
      "Elahe Khatibi",
      "Mahyar Abbasian",
      "Zhongqi Yang",
      "Iman Azimi",
      "Amir M. Rahmani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2405.01754",
    "title": "A Peer-to-Peer Energy Management Solution for Maximum Social Welfare",
    "abstract": "In smart energy communities, prosumers who both generate and consume energy play a crucial role in shaping energy management strategies. These communities use advanced platforms that enable prosumers to actively engage in the local electricity markets by setting and adjusting their own energy prices. Through peer to peer (P2P) energy trading systems, members can directly exchange energy derived from sources such as solar photovoltaic panels, electric vehicle battery storage, and demand response (DR) programs. This direct exchange not only enhances the efficiency of the network but also fosters a dynamic energy market within the community. In this article, parking-sharing services for EVs and the mechanisms of P2P energy scheduling, which facilitates the transfer and communication of power among different energy communities (ECs) are addressed. It focuses on integrating solar power, responsive electrical loads, and electric vehicles (EVs) to optimize both economic returns and social benefits for all participants. The system is designed to ensure that all energy transactions are transparent and beneficial to the proactive consumers involved. Moreover, due to urban traffic conditions and the challenges of finding suitable locations for EV charging and parking, houses in these communities provide parking-sharing services for EVs. This integration of energy management and urban scheduling illustrates a holistic approach to addressing both energy and transportation challenges, ultimately leading to more sustainable urban environments. ",
    "url": "https://arxiv.org/abs/2405.01754",
    "authors": [
      "Atefeh Alirezazadeh",
      "Vahid Disfani"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2405.01762",
    "title": "EiG-Search: Generating Edge-Induced Subgraphs for GNN Explanation in  Linear Time",
    "abstract": "Understanding and explaining the predictions of Graph Neural Networks (GNNs), is crucial for enhancing their safety and trustworthiness. Subgraph-level explanations are gaining attention for their intuitive appeal. However, most existing subgraph-level explainers face efficiency challenges in explaining GNNs due to complex search processes. The key challenge is to find a balance between intuitiveness and efficiency while ensuring transparency. Additionally, these explainers usually induce subgraphs by nodes, which may introduce less-intuitive disconnected nodes in the subgraph-level explanations or omit many important subgraph structures. In this paper, we reveal that inducing subgraph explanations by edges is more comprehensive than other subgraph inducing techniques. We also emphasize the need of determining the subgraph explanation size for each data instance, as different data instances may involve different important substructures. Building upon these considerations, we introduce a training-free approach, named EiG-Search. We employ an efficient linear-time search algorithm over the edge-induced subgraphs, where the edges are ranked by an enhanced gradient-based importance. We conduct extensive experiments on a total of seven datasets, demonstrating its superior performance and efficiency both quantitatively and qualitatively over the leading baselines. ",
    "url": "https://arxiv.org/abs/2405.01762",
    "authors": [
      "Shengyao Lu",
      "Bang Liu",
      "Keith G. Mills",
      "Jiao He",
      "Di Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01775",
    "title": "Torch2Chip: An End-to-end Customizable Deep Neural Network Compression  and Deployment Toolkit for Prototype Hardware Accelerator Design",
    "abstract": "The development of model compression is continuously motivated by the evolution of various neural network accelerators with ASIC or FPGA. On the algorithm side, the ultimate goal of quantization or pruning is accelerating the expensive DNN computations on low-power hardware. However, such a \"design-and-deploy\" workflow faces under-explored challenges in the current hardware-algorithm co-design community. First, although the state-of-the-art quantization algorithm can achieve low precision with negligible degradation of accuracy, the latest deep learning framework (e.g., PyTorch) can only support non-customizable 8-bit precision, data format, and parameter extraction. Secondly, the objective of quantization is to enable the computation with low-precision data. However, the current SoTA algorithm treats the quantized integer as an intermediate result, while the final output of the quantizer is the \"discretized\" floating-point values, ignoring the practical needs and adding additional workload to hardware designers for integer parameter extraction and layer fusion. Finally, the compression toolkits designed by the industry are constrained to their in-house product or a handful of algorithms. The limited degree of freedom in the current toolkit and the under-explored customization hinder the prototype ASIC or FPGA-based accelerator design. To resolve these challenges, we propose Torch2Chip, an open-sourced, fully customizable, and high-performance toolkit that supports user-designed compression followed by automatic model fusion and parameter extraction. Torch2Chip incorporates the hierarchical design workflow, and the user-customized compression algorithm will be directly packed into the deployment-ready format for prototype chip verification with either CNN or vision transformer (ViT). The code is available at https://github.com/SeoLabCornell/torch2chip. ",
    "url": "https://arxiv.org/abs/2405.01775",
    "authors": [
      "Jian Meng",
      "Yuan Liao",
      "Anupreetham Anupreetham",
      "Ahmed Hasssan",
      "Shixing Yu",
      "Han-sok Suh",
      "Xiaofeng Hu",
      "Jae-sun Seo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01787",
    "title": "Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming",
    "abstract": "Proof-oriented programs mix computational content with proofs of program correctness. However, the human effort involved in programming and proving is still substantial, despite the use of Satisfiability Modulo Theories (SMT) solvers to automate proofs in languages such as F*. Seeking to spur research on using AI to automate the construction of proof-oriented programs, we curate a dataset of 600K lines of open-source F* programs and proofs, including software used in production systems ranging from Windows and Linux, to Python and Firefox. Our dataset includes around 32K top-level F* definitions, each representing a type-directed program and proof synthesis problem -- producing a definition given a formal specification expressed as an F* type. We provide a program-fragment checker that queries F* to check the correctness of candidate solutions. We believe this is the largest corpus of SMT-assisted program proofs coupled with a reproducible program-fragment checker. Grounded in this dataset, we investigate the use of AI to synthesize programs and their proofs in F*, with promising results. Our main finding in that the performance of fine-tuned smaller language models (such as Phi-2 or StarCoder) compare favorably with large language models (such as GPT-4), at a much lower computational cost. We also identify various type-based retrieval augmentation techniques and find that they boost performance significantly. With detailed error analysis and case studies, we identify potential strengths and weaknesses of models and techniques and suggest directions for future improvements. ",
    "url": "https://arxiv.org/abs/2405.01787",
    "authors": [
      "Saikat Chakraborty",
      "Gabriel Ebner",
      "Siddharth Bhat",
      "Sarah Fakhoury",
      "Sakina Fatima",
      "Shuvendu Lahiri",
      "Nikhil Swamy"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2405.01790",
    "title": "Understanding Position Bias Effects on Fairness in Social Multi-Document  Summarization",
    "abstract": "Text summarization models have typically focused on optimizing aspects of quality such as fluency, relevance, and coherence, particularly in the context of news articles. However, summarization models are increasingly being used to summarize diverse sources of text, such as social media data, that encompass a wide demographic user base. It is thus crucial to assess not only the quality of the generated summaries, but also the extent to which they can fairly represent the opinions of diverse social groups. Position bias, a long-known issue in news summarization, has received limited attention in the context of social multi-document summarization. We deeply investigate this phenomenon by analyzing the effect of group ordering in input documents when summarizing tweets from three distinct linguistic communities: African-American English, Hispanic-aligned Language, and White-aligned Language. Our empirical analysis shows that although the textual quality of the summaries remains consistent regardless of the input document order, in terms of fairness, the results vary significantly depending on how the dialect groups are presented in the input data. Our results suggest that position bias manifests differently in social multi-document summarization, severely impacting the fairness of summarization models. ",
    "url": "https://arxiv.org/abs/2405.01790",
    "authors": [
      "Olubusayo Olabisi",
      "Ameeta Agrawal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01792",
    "title": "Learning Robust Autonomous Navigation and Locomotion for Wheeled-Legged  Robots",
    "abstract": "Autonomous wheeled-legged robots have the potential to transform logistics systems, improving operational efficiency and adaptability in urban environments. Navigating urban environments, however, poses unique challenges for robots, necessitating innovative solutions for locomotion and navigation. These challenges include the need for adaptive locomotion across varied terrains and the ability to navigate efficiently around complex dynamic obstacles. This work introduces a fully integrated system comprising adaptive locomotion control, mobility-aware local navigation planning, and large-scale path planning within the city. Using model-free reinforcement learning (RL) techniques and privileged learning, we develop a versatile locomotion controller. This controller achieves efficient and robust locomotion over various rough terrains, facilitated by smooth transitions between walking and driving modes. It is tightly integrated with a learned navigation controller through a hierarchical RL framework, enabling effective navigation through challenging terrain and various obstacles at high speed. Our controllers are integrated into a large-scale urban navigation system and validated by autonomous, kilometer-scale navigation missions conducted in Zurich, Switzerland, and Seville, Spain. These missions demonstrate the system's robustness and adaptability, underscoring the importance of integrated control systems in achieving seamless navigation in complex environments. Our findings support the feasibility of wheeled-legged robots and hierarchical RL for autonomous navigation, with implications for last-mile delivery and beyond. ",
    "url": "https://arxiv.org/abs/2405.01792",
    "authors": [
      "Joonho Lee",
      "Marko Bjelonic",
      "Alexander Reske",
      "Lorenz Wellhausen",
      "Takahiro Miki",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2405.01815",
    "title": "Toward end-to-end interpretable convolutional neural networks for  waveform signals",
    "abstract": "This paper introduces a novel convolutional neural networks (CNN) framework tailored for end-to-end audio deep learning models, presenting advancements in efficiency and explainability. By benchmarking experiments on three standard speech emotion recognition datasets with five-fold cross-validation, our framework outperforms Mel spectrogram features by up to seven percent. It can potentially replace the Mel-Frequency Cepstral Coefficients (MFCC) while remaining lightweight. Furthermore, we demonstrate the efficiency and interpretability of the front-end layer using the PhysioNet Heart Sound Database, illustrating its ability to handle and capture intricate long waveform patterns. Our contributions offer a portable solution for building efficient and interpretable models for raw waveform data. ",
    "url": "https://arxiv.org/abs/2405.01815",
    "authors": [
      "Linh Vu",
      "Thu Tran",
      "Wern-Han Lim",
      "Raphael Phan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2405.01817",
    "title": "Uniformly Stable Algorithms for Adversarial Training and Beyond",
    "abstract": "In adversarial machine learning, neural networks suffer from a significant issue known as robust overfitting, where the robust test accuracy decreases over epochs (Rice et al., 2020). Recent research conducted by Xing et al.,2021; Xiao et al., 2022 has focused on studying the uniform stability of adversarial training. Their investigations revealed that SGD-based adversarial training fails to exhibit uniform stability, and the derived stability bounds align with the observed phenomenon of robust overfitting in experiments. This motivates us to develop uniformly stable algorithms specifically tailored for adversarial training. To this aim, we introduce Moreau envelope-$\\mathcal{A}$, a variant of the Moreau Envelope-type algorithm. We employ a Moreau envelope function to reframe the original problem as a min-min problem, separating the non-strong convexity and non-smoothness of the adversarial loss. Then, this approach alternates between solving the inner and outer minimization problems to achieve uniform stability without incurring additional computational overhead. In practical scenarios, we show the efficacy of ME-$\\mathcal{A}$ in mitigating the issue of robust overfitting. Beyond its application in adversarial training, this represents a fundamental result in uniform stability analysis, as ME-$\\mathcal{A}$ is the first algorithm to exhibit uniform stability for weakly-convex, non-smooth problems. ",
    "url": "https://arxiv.org/abs/2405.01817",
    "authors": [
      "Jiancong Xiao",
      "Jiawei Zhang",
      "Zhi-Quan Luo",
      "Asuman Ozdaglar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01828",
    "title": "FER-YOLO-Mamba: Facial Expression Detection and Classification Based on  Selective State Space",
    "abstract": "Facial Expression Recognition (FER) plays a pivotal role in understanding human emotional cues. However, traditional FER methods based on visual information have some limitations, such as preprocessing, feature extraction, and multi-stage classification procedures. These not only increase computational complexity but also require a significant amount of computing resources. Considering Convolutional Neural Network (CNN)-based FER schemes frequently prove inadequate in identifying the deep, long-distance dependencies embedded within facial expression images, and the Transformer's inherent quadratic computational complexity, this paper presents the FER-YOLO-Mamba model, which integrates the principles of Mamba and YOLO technologies to facilitate efficient coordination in facial expression image recognition and localization. Within the FER-YOLO-Mamba model, we further devise a FER-YOLO-VSS dual-branch module, which combines the inherent strengths of convolutional layers in local feature extraction with the exceptional capability of State Space Models (SSMs) in revealing long-distance dependencies. To the best of our knowledge, this is the first Vision Mamba model designed for facial expression detection and classification. To evaluate the performance of the proposed FER-YOLO-Mamba model, we conducted experiments on two benchmark datasets, RAF-DB and SFEW. The experimental results indicate that the FER-YOLO-Mamba model achieved better results compared to other models. The code is available from https://github.com/SwjtuMa/FER-YOLO-Mamba. ",
    "url": "https://arxiv.org/abs/2405.01828",
    "authors": [
      "Hui Ma",
      "Sen Lei",
      "Turgay Celik",
      "Heng-Chao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.01838",
    "title": "A Novel Approach to Guard from Adversarial Attacks using Stable  Diffusion",
    "abstract": "Recent developments in adversarial machine learning have highlighted the importance of building robust AI systems to protect against increasingly sophisticated attacks. While frameworks like AI Guardian are designed to defend against these threats, they often rely on assumptions that can limit their effectiveness. For example, they may assume attacks only come from one direction or include adversarial images in their training data. Our proposal suggests a different approach to the AI Guardian framework. Instead of including adversarial examples in the training process, we propose training the AI system without them. This aims to create a system that is inherently resilient to a wider range of attacks. Our method focuses on a dynamic defense strategy using stable diffusion that learns continuously and models threats comprehensively. We believe this approach can lead to a more generalized and robust defense against adversarial attacks. In this paper, we outline our proposed approach, including the theoretical basis, experimental design, and expected impact on improving AI security against adversarial threats. ",
    "url": "https://arxiv.org/abs/2405.01838",
    "authors": [
      "Trinath Sai Subhash Reddy Pittala",
      "Uma Maheswara Rao Meleti",
      "Geethakrishna Puligundla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01839",
    "title": "SocialGFs: Learning Social Gradient Fields for Multi-Agent Reinforcement  Learning",
    "abstract": "Multi-agent systems (MAS) need to adaptively cope with dynamic environments, changing agent populations, and diverse tasks. However, most of the multi-agent systems cannot easily handle them, due to the complexity of the state and task space. The social impact theory regards the complex influencing factors as forces acting on an agent, emanating from the environment, other agents, and the agent's intrinsic motivation, referring to the social force. Inspired by this concept, we propose a novel gradient-based state representation for multi-agent reinforcement learning. To non-trivially model the social forces, we further introduce a data-driven method, where we employ denoising score matching to learn the social gradient fields (SocialGFs) from offline samples, e.g., the attractive or repulsive outcomes of each force. During interactions, the agents take actions based on the multi-dimensional gradients to maximize their own rewards. In practice, we integrate SocialGFs into the widely used multi-agent reinforcement learning algorithms, e.g., MAPPO. The empirical results reveal that SocialGFs offer four advantages for multi-agent systems: 1) they can be learned without requiring online interaction, 2) they demonstrate transferability across diverse tasks, 3) they facilitate credit assignment in challenging reward settings, and 4) they are scalable with the increasing number of agents. ",
    "url": "https://arxiv.org/abs/2405.01839",
    "authors": [
      "Qian Long",
      "Fangwei Zhong",
      "Mingdong Wu",
      "Yizhou Wang",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2405.01843",
    "title": "Closing the Gap: Achieving Global Convergence (Last Iterate) of  Actor-Critic under Markovian Sampling with Neural Network Parametrization",
    "abstract": "The current state-of-the-art theoretical analysis of Actor-Critic (AC) algorithms significantly lags in addressing the practical aspects of AC implementations. This crucial gap needs bridging to bring the analysis in line with practical implementations of AC. To address this, we advocate for considering the MMCLG criteria: \\textbf{M}ulti-layer neural network parametrization for actor/critic, \\textbf{M}arkovian sampling, \\textbf{C}ontinuous state-action spaces, the performance of the \\textbf{L}ast iterate, and \\textbf{G}lobal optimality. These aspects are practically significant and have been largely overlooked in existing theoretical analyses of AC algorithms. In this work, we address these gaps by providing the first comprehensive theoretical analysis of AC algorithms that encompasses all five crucial practical aspects (covers MMCLG criteria). We establish global convergence sample complexity bounds of $\\tilde{\\mathcal{O}}\\left({\\epsilon^{-3}}\\right)$. We achieve this result through our novel use of the weak gradient domination property of MDP's and our unique analysis of the error in critic estimation. ",
    "url": "https://arxiv.org/abs/2405.01843",
    "authors": [
      "Mudit Gaur",
      "Vaneet Aggarwal",
      "Amrit Singh Bedi",
      "Di Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01844",
    "title": "A Survey on Privacy-Preserving Caching at Network Edge: Classification,  Solutions, and Challenges",
    "abstract": "Caching content at the network edge is a popular and effective technique widely deployed to alleviate the burden of network backhaul, shorten service delay and improve service quality. However, there has been some controversy over privacy violations in caching content at the network edge. On the one hand, the multi-access open edge network provides an ideal surface for external attackers to obtain private data from the edge cache by extracting sensitive information. On the other hand, privacy can be infringed by curious edge caching providers through caching trace analysis targeting to achieve better caching performance or higher profits. Therefore, an in-depth understanding of privacy issues in edge caching networks is vital and indispensable for creating a privacy-preserving caching service at the network edge. In this article, we are among the first to fill in this gap by examining privacy-preserving techniques for caching content at the network edge. Firstly, we provide an introduction to the background of Privacy-Preserving Edge Caching (PPEC). Next, we summarize the key privacy issues and present a taxonomy for caching at the network edge from the perspective of private data. Additionally, we conduct a retrospective review of the state-of-the-art countermeasures against privacy leakage from content caching at the network edge. Finally, we conclude the survey and envision challenges for future research. ",
    "url": "https://arxiv.org/abs/2405.01844",
    "authors": [
      "Xianzhi Zhang",
      "Yipeng Zhou",
      "Di Wu",
      "Shazia Riaz",
      "Quan Z. Sheng",
      "Miao Hu",
      "Linchang Xiao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2405.01851",
    "title": "Deep Learning Inference on Heterogeneous Mobile Processors: Potentials  and Pitfalls",
    "abstract": "There is a growing demand to deploy computation-intensive deep learning (DL) models on resource-constrained mobile devices for real-time intelligent applications. Equipped with a variety of processing units such as CPUs, GPUs, and NPUs, the mobile devices hold potential to accelerate DL inference via parallel execution across heterogeneous processors. Various efficient parallel methods have been explored to optimize computation distribution, achieve load balance, and minimize communication cost across processors. Yet their practical effectiveness in the dynamic and diverse real-world mobile environment is less explored. This paper presents a holistic empirical study to assess the capabilities and challenges associated with parallel DL inference on heterogeneous mobile processors. Through carefully designed experiments covering various DL models, mobile software/hardware environments, workload patterns, and resource availability, we identify limitations of existing techniques and highlight opportunities for cross-level optimization. ",
    "url": "https://arxiv.org/abs/2405.01851",
    "authors": [
      "Sicong Liu",
      "Wentao Zhou",
      "Zimu Zhou",
      "Bin Guo",
      "Minfan Wang",
      "Cheng Fang",
      "Zheng Lin",
      "Zhiwen Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01855",
    "title": "Robust Explainable Recommendation",
    "abstract": "Explainable Recommender Systems is an important field of study which provides reasons behind the suggested recommendations. Explanations with recommender systems are useful for developers while debugging anomalies within the system and for consumers while interpreting the model's effectiveness in capturing their true preferences towards items. However, most of the existing state-of-the-art (SOTA) explainable recommenders could not retain their explanation capability under noisy circumstances and moreover are not generalizable across different datasets. The robustness of the explanations must be ensured so that certain malicious attackers do not manipulate any high-stake decision scenarios to their advantage, which could cause severe consequences affecting large groups of interest. In this work, we present a general framework for feature-aware explainable recommenders that can withstand external attacks and provide robust and generalized explanations. This paper presents a novel framework which could be utilized as an additional defense tool, preserving the global explainability when subject to model-based white box attacks. Our framework is simple to implement and supports different methods regardless of the internal model structure and intrinsic utility within any model. We experimented our framework on two architecturally different feature-based SOTA explainable algorithms by training them on three popular e-commerce datasets of increasing scales. We noticed that both the algorithms displayed an overall improvement in the quality and robustness of the global explainability under normal as well as noisy environments across all the datasets, indicating the flexibility and mutability of our framework. ",
    "url": "https://arxiv.org/abs/2405.01855",
    "authors": [
      "Sairamvinay Vijayaraghavan",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01873",
    "title": "Enhancing Bangla Language Next Word Prediction and Sentence Completion  through Extended RNN with Bi-LSTM Model On N-gram Language",
    "abstract": "Texting stands out as the most prominent form of communication worldwide. Individual spend significant amount of time writing whole texts to send emails or write something on social media, which is time consuming in this modern era. Word prediction and sentence completion will be suitable and appropriate in the Bangla language to make textual information easier and more convenient. This paper expands the scope of Bangla language processing by introducing a Bi-LSTM model that effectively handles Bangla next-word prediction and Bangla sentence generation, demonstrating its versatility and potential impact. We proposed a new Bi-LSTM model to predict a following word and complete a sentence. We constructed a corpus dataset from various news portals, including bdnews24, BBC News Bangla, and Prothom Alo. The proposed approach achieved superior results in word prediction, reaching 99\\% accuracy for both 4-gram and 5-gram word predictions. Moreover, it demonstrated significant improvement over existing methods, achieving 35\\%, 75\\%, and 95\\% accuracy for uni-gram, bi-gram, and tri-gram word prediction, respectively ",
    "url": "https://arxiv.org/abs/2405.01873",
    "authors": [
      "Md Robiul Islam",
      "Al Amin",
      "Aniqua Nusrat Zereen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01904",
    "title": "Which Identities Are Mobilized: Towards an automated detection of social  group appeals in political texts",
    "abstract": "This paper proposes a computational text classification strategy to identify references to social groups in European party manifestos and beyond. Our methodology uses machine learning techniques, including BERT and large language models, to capture group-based appeals in texts. We propose to combine automated identification of social groups using the Mistral-7B-v0.1 Large Language Model with Embedding Space-based filtering to extend a sample of core social groups to all social groups mentioned in party manifestos. By applying this approach to RRP's and mainstream parties' group images in manifestos, we explore whether electoral dynamics explain similarities in group appeals and potential convergence or divergence in party strategies. Contrary to expectations, increasing RRP support or mainstream parties' vote loss does not necessarily lead to convergence in group appeals. Nonetheless, our methodology enables mapping similarities in group appeals across time and space in 15 European countries from 1980 to 2021 and can be transferred to other use cases as well. ",
    "url": "https://arxiv.org/abs/2405.01904",
    "authors": [
      "Felicia Riethm\u00fcller",
      "Julian Dehne",
      "Denise Al-Gaddooa"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Other Statistics (stat.OT)"
    ]
  },
  {
    "id": "arXiv:2405.01906",
    "title": "Instance-Conditioned Adaptation for Large-scale Generalization of Neural  Combinatorial Optimization",
    "abstract": "The neural combinatorial optimization (NCO) approach has shown great potential for solving routing problems without the requirement of expert knowledge. However, existing constructive NCO methods cannot directly solve large-scale instances, which significantly limits their application prospects. To address these crucial shortcomings, this work proposes a novel Instance-Conditioned Adaptation Model (ICAM) for better large-scale generalization of neural combinatorial optimization. In particular, we design a powerful yet lightweight instance-conditioned adaptation module for the NCO model to generate better solutions for instances across different scales. In addition, we develop an efficient three-stage reinforcement learning-based training scheme that enables the model to learn cross-scale features without any labeled optimal solution. Experimental results show that our proposed method is capable of obtaining excellent results with a very fast inference time in solving Traveling Salesman Problems (TSPs) and Capacitated Vehicle Routing Problems (CVRPs) across different scales. To the best of our knowledge, our model achieves state-of-the-art performance among all RL-based constructive methods for TSP and CVRP with up to 1,000 nodes. ",
    "url": "https://arxiv.org/abs/2405.01906",
    "authors": [
      "Changliang Zhou",
      "Xi Lin",
      "Zhenkun Wang",
      "Xialiang Tong",
      "Mingxuan Yuan",
      "Qingfu Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01920",
    "title": "Lightweight Change Detection in Heterogeneous Remote Sensing Images with  Online All-Integer Pruning Training",
    "abstract": "Detection of changes in heterogeneous remote sensing images is vital, especially in response to emergencies like earthquakes and floods. Current homogenous transformation-based change detection (CD) methods often suffer from high computation and memory costs, which are not friendly to edge-computation devices like onboard CD devices at satellites. To address this issue, this paper proposes a new lightweight CD method for heterogeneous remote sensing images that employs the online all-integer pruning (OAIP) training strategy to efficiently fine-tune the CD network using the current test data. The proposed CD network consists of two visual geometry group (VGG) subnetworks as the backbone architecture. In the OAIP-based training process, all the weights, gradients, and intermediate data are quantized to integers to speed up training and reduce memory usage, where the per-layer block exponentiation scaling scheme is utilized to reduce the computation errors of network parameters caused by quantization. Second, an adaptive filter-level pruning method based on the L1-norm criterion is employed to further lighten the fine-tuning process of the CD network. Experimental results show that the proposed OAIP-based method attains similar detection performance (but with significantly reduced computation complexity and memory usage) in comparison with state-of-the-art CD methods. ",
    "url": "https://arxiv.org/abs/2405.01920",
    "authors": [
      "Chengyang Zhang",
      "Weiming Li",
      "Gang Li",
      "Huina Song",
      "Zhaohui Song",
      "Xueqian Wang",
      "Antonio Plaza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.01927",
    "title": "SlotGAT: Slot-based Message Passing for Heterogeneous Graph Neural  Network",
    "abstract": "Heterogeneous graphs are ubiquitous to model complex data. There are urgent needs on powerful heterogeneous graph neural networks to effectively support important applications. We identify a potential semantic mixing issue in existing message passing processes, where the representations of the neighbors of a node $v$ are forced to be transformed to the feature space of $v$ for aggregation, though the neighbors are in different types. That is, the semantics in different node types are entangled together into node $v$'s representation. To address the issue, we propose SlotGAT with separate message passing processes in slots, one for each node type, to maintain the representations in their own node-type feature spaces. Moreover, in a slot-based message passing layer, we design an attention mechanism for effective slot-wise message aggregation. Further, we develop a slot attention technique after the last layer of SlotGAT, to learn the importance of different slots in downstream tasks. Our analysis indicates that the slots in SlotGAT can preserve different semantics in various feature spaces. The superiority of SlotGAT is evaluated against 13 baselines on 6 datasets for node classification and link prediction. Our code is at https://github.com/scottjiao/SlotGAT_ICML23/. ",
    "url": "https://arxiv.org/abs/2405.01927",
    "authors": [
      "Ziang Zhou",
      "Jieming Shi",
      "Renchi Yang",
      "Yuanhang Zou",
      "Qing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01934",
    "title": "Impact of Architectural Modifications on Deep Learning Adversarial  Robustness",
    "abstract": "Rapid advancements of deep learning are accelerating adoption in a wide variety of applications, including safety-critical applications such as self-driving vehicles, drones, robots, and surveillance systems. These advancements include applying variations of sophisticated techniques that improve the performance of models. However, such models are not immune to adversarial manipulations, which can cause the system to misbehave and remain unnoticed by experts. The frequency of modifications to existing deep learning models necessitates thorough analysis to determine the impact on models' robustness. In this work, we present an experimental evaluation of the effects of model modifications on deep learning model robustness using adversarial attacks. Our methodology involves examining the robustness of variations of models against various adversarial attacks. By conducting our experiments, we aim to shed light on the critical issue of maintaining the reliability and safety of deep learning models in safety- and security-critical applications. Our results indicate the pressing demand for an in-depth assessment of the effects of model changes on the robustness of models. ",
    "url": "https://arxiv.org/abs/2405.01934",
    "authors": [
      "Firuz Juraev",
      "Mohammed Abuhamad",
      "Simon S. Woo",
      "George K Thiruvathukal",
      "Tamer Abuhmed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01938",
    "title": "Conservative semi-lagrangian finite difference scheme for transport  simulations using graph neural networks",
    "abstract": "Semi-Lagrangian (SL) schemes are highly efficient for simulating transport equations and are widely used across various applications. Despite their success, designing genuinely multi-dimensional and conservative SL schemes remains a significant challenge. Building on our previous work [Chen et al., J. Comput. Phys., V490 112329, (2023)], we introduce a conservative machine-learning-based SL finite difference (FD) method that allows for extra-large time step evolution. At the core of our approach is a novel dynamical graph neural network designed to handle the complexities associated with tracking accurately upstream points along characteristics. This proposed neural transport solver learns the conservative SL FD discretization directly from data, improving accuracy and efficiency compared to traditional numerical schemes, while significantly simplifying algorithm implementation. We validate the method' s effectiveness and efficiency through numerical tests on benchmark transport equations in both one and two dimensions, as well as the nonlinear Vlasov-Poisson system. ",
    "url": "https://arxiv.org/abs/2405.01938",
    "authors": [
      "Yongsheng Chen",
      "Wei Guo",
      "Xinghui Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2405.01963",
    "title": "From Attack to Defense: Insights into Deep Learning Security Measures in  Black-Box Settings",
    "abstract": "Deep Learning (DL) is rapidly maturing to the point that it can be used in safety- and security-crucial applications. However, adversarial samples, which are undetectable to the human eye, pose a serious threat that can cause the model to misbehave and compromise the performance of such applications. Addressing the robustness of DL models has become crucial to understanding and defending against adversarial attacks. In this study, we perform comprehensive experiments to examine the effect of adversarial attacks and defenses on various model architectures across well-known datasets. Our research focuses on black-box attacks such as SimBA, HopSkipJump, MGAAttack, and boundary attacks, as well as preprocessor-based defensive mechanisms, including bits squeezing, median smoothing, and JPEG filter. Experimenting with various models, our results demonstrate that the level of noise needed for the attack increases as the number of layers increases. Moreover, the attack success rate decreases as the number of layers increases. This indicates that model complexity and robustness have a significant relationship. Investigating the diversity and robustness relationship, our experiments with diverse models show that having a large number of parameters does not imply higher robustness. Our experiments extend to show the effects of the training dataset on model robustness. Using various datasets such as ImageNet-1000, CIFAR-100, and CIFAR-10 are used to evaluate the black-box attacks. Considering the multiple dimensions of our analysis, e.g., model complexity and training dataset, we examined the behavior of black-box attacks when models apply defenses. Our results show that applying defense strategies can significantly reduce attack effectiveness. This research provides in-depth analysis and insight into the robustness of DL models against various attacks, and defenses. ",
    "url": "https://arxiv.org/abs/2405.01963",
    "authors": [
      "Firuz Juraev",
      "Mohammed Abuhamad",
      "Eric Chan-Tin",
      "George K. Thiruvathukal",
      "Tamer Abuhmed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01976",
    "title": "Conformal Prediction for Natural Language Processing: A Survey",
    "abstract": "The rapid proliferation of large language models and natural language processing (NLP) applications creates a crucial need for uncertainty quantification to mitigate risks such as hallucinations and to enhance decision-making reliability in critical applications. Conformal prediction is emerging as a theoretically sound and practically useful framework, combining flexibility with strong statistical guarantees. Its model-agnostic and distribution-free nature makes it particularly promising to address the current shortcomings of NLP systems that stem from the absence of uncertainty quantification. This paper provides a comprehensive survey of conformal prediction techniques, their guarantees, and existing applications in NLP, pointing to directions for future research and open challenges. ",
    "url": "https://arxiv.org/abs/2405.01976",
    "authors": [
      "Margarida M. Campos",
      "Ant\u00f3nio Farinhas",
      "Chrysoula Zerva",
      "M\u00e1rio A.T. Figueiredo",
      "Andr\u00e9 F.T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01978",
    "title": "Quantifying Distribution Shifts and Uncertainties for Enhanced Model  Robustness in Machine Learning Applications",
    "abstract": "Distribution shifts, where statistical properties differ between training and test datasets, present a significant challenge in real-world machine learning applications where they directly impact model generalization and robustness. In this study, we explore model adaptation and generalization by utilizing synthetic data to systematically address distributional disparities. Our investigation aims to identify the prerequisites for successful model adaptation across diverse data distributions, while quantifying the associated uncertainties. Specifically, we generate synthetic data using the Van der Waals equation for gases and employ quantitative measures such as Kullback-Leibler divergence, Jensen-Shannon distance, and Mahalanobis distance to assess data similarity. These metrics en able us to evaluate both model accuracy and quantify the associated uncertainty in predictions arising from data distribution shifts. Our findings suggest that utilizing statistical measures, such as the Mahalanobis distance, to determine whether model predictions fall within the low-error \"interpolation regime\" or the high-error \"extrapolation regime\" provides a complementary method for assessing distribution shift and model uncertainty. These insights hold significant value for enhancing model robustness and generalization, essential for the successful deployment of machine learning applications in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2405.01978",
    "authors": [
      "Vegard Flovik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2405.01979",
    "title": "Graph Neural Network based Active and Passive Beamforming for  Distributed STAR-RIS-Assisted Multi-User MISO Systems",
    "abstract": "This paper investigates a joint active and passive beamforming design for distributed simultaneous transmitting and reflecting (STAR) reconfigurable intelligent surface (RIS) assisted multi-user (MU)- mutiple input single output (MISO) systems, where the energy splitting (ES) mode is considered for the STAR-RIS. We aim to design the active beamforming vectors at the base station (BS) and the passive beamforming at the STAR-RIS to maximize the user sum rate under transmitting power constraints. The formulated problem is non-convex and nontrivial to obtain the global optimum due to the coupling between active beamforming vectors and STAR-RIS phase shifts. To efficiently solve the problem, we propose a novel graph neural network (GNN)-based framework. Specifically, we first model the interactions among users and network entities are using a heterogeneous graph representation. A heterogeneous graph neural network (HGNN) implementation is then introduced to directly optimizes beamforming vectors and STAR-RIS coefficients with the system objective. Numerical results show that the proposed approach yields efficient performance compared to the previous benchmarks. Furthermore, the proposed GNN is scalable with various system configurations. ",
    "url": "https://arxiv.org/abs/2405.01979",
    "authors": [
      "Ha An Le",
      "Trinh Van Chien",
      "Wan Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2405.01992",
    "title": "SFFNet: A Wavelet-Based Spatial and Frequency Domain Fusion Network for  Remote Sensing Segmentation",
    "abstract": "In order to fully utilize spatial information for segmentation and address the challenge of handling areas with significant grayscale variations in remote sensing segmentation, we propose the SFFNet (Spatial and Frequency Domain Fusion Network) framework. This framework employs a two-stage network design: the first stage extracts features using spatial methods to obtain features with sufficient spatial details and semantic information; the second stage maps these features in both spatial and frequency domains. In the frequency domain mapping, we introduce the Wavelet Transform Feature Decomposer (WTFD) structure, which decomposes features into low-frequency and high-frequency components using the Haar wavelet transform and integrates them with spatial features. To bridge the semantic gap between frequency and spatial features, and facilitate significant feature selection to promote the combination of features from different representation domains, we design the Multiscale Dual-Representation Alignment Filter (MDAF). This structure utilizes multiscale convolutions and dual-cross attentions. Comprehensive experimental results demonstrate that, compared to existing methods, SFFNet achieves superior performance in terms of mIoU, reaching 84.80% and 87.73% respectively.The code is located at https://github.com/yysdck/SFFNet. ",
    "url": "https://arxiv.org/abs/2405.01992",
    "authors": [
      "Yunsong Yang",
      "Genji Yuan",
      "Jinjiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.02004",
    "title": "M${^2}$Depth: Self-supervised Two-Frame Multi-camera Metric Depth  Estimation",
    "abstract": "This paper presents a novel self-supervised two-frame multi-camera metric depth estimation network, termed M${^2}$Depth, which is designed to predict reliable scale-aware surrounding depth in autonomous driving. Unlike the previous works that use multi-view images from a single time-step or multiple time-step images from a single camera, M${^2}$Depth takes temporally adjacent two-frame images from multiple cameras as inputs and produces high-quality surrounding depth. We first construct cost volumes in spatial and temporal domains individually and propose a spatial-temporal fusion module that integrates the spatial-temporal information to yield a strong volume presentation. We additionally combine the neural prior from SAM features with internal features to reduce the ambiguity between foreground and background and strengthen the depth edges. Extensive experimental results on nuScenes and DDAD benchmarks show M${^2}$Depth achieves state-of-the-art performance. More results can be found in https://heiheishuang.xyz/M2Depth . ",
    "url": "https://arxiv.org/abs/2405.02004",
    "authors": [
      "Yingshuang Zou",
      "Yikang Ding",
      "Xi Qiu",
      "Haoqian Wang",
      "Haotian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.02016",
    "title": "Adversarial Botometer: Adversarial Analysis for Social Bot Detection",
    "abstract": "Social bots play a significant role in many online social networks (OSN) as they imitate human behavior. This fact raises difficult questions about their capabilities and potential risks. Given the recent advances in Generative AI (GenAI), social bots are capable of producing highly realistic and complex content that mimics human creativity. As the malicious social bots emerge to deceive people with their unrealistic content, identifying them and distinguishing the content they produce has become an actual challenge for numerous social platforms. Several approaches to this problem have already been proposed in the literature, but the proposed solutions have not been widely evaluated. To address this issue, we evaluate the behavior of a text-based bot detector in a competitive environment where some scenarios are proposed: \\textit{First}, the tug-of-war between a bot and a bot detector is examined. It is interesting to analyze which party is more likely to prevail and which circumstances influence these expectations. In this regard, we model the problem as a synthetic adversarial game in which a conversational bot and a bot detector are engaged in strategic online interactions. \\textit{Second}, the bot detection model is evaluated under attack examples generated by a social bot; to this end, we poison the dataset with attack examples and evaluate the model performance under this condition. \\textit{Finally}, to investigate the impact of the dataset, a cross-domain analysis is performed. Through our comprehensive evaluation of different categories of social bots using two benchmark datasets, we were able to demonstrate some achivement that could be utilized in future works. ",
    "url": "https://arxiv.org/abs/2405.02016",
    "authors": [
      "Shaghayegh Najari",
      "Davood Rafiee",
      "Mostafa Salehi",
      "Reza Farahbakhsh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2405.02019",
    "title": "Fast Algorithms for Spiking Neural Network Simulation with FPGAs",
    "abstract": "Using OpenCL-based high-level synthesis, we create a number of spiking neural network (SNN) simulators for the Potjans-Diesmann cortical microcircuit for a high-end Field-Programmable Gate Array (FPGA). Our best simulators simulate the circuit 25\\% faster than real-time, require less than 21 nJ per synaptic event, and are bottle-necked by the device's on-chip memory. Speed-wise they compare favorably to the state-of-the-art GPU-based simulators and their energy usage is lower than any other published result. This result is the first for simulating the circuit on a single hardware accelerator. We also extensively analyze the techniques and algorithms we implement our simulators with, many of which can be realized on other types of hardware. Thus, this article is of interest to any researcher or practitioner interested in efficient SNN simulation, whether they target FPGAs or not. ",
    "url": "https://arxiv.org/abs/2405.02019",
    "authors": [
      "Bj\u00f6rn A. Lindqvist",
      "Artur Podobas"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2405.02022",
    "title": "STX-Vote: Improving Reliability with Bit Voting in Synchronous  Transmission-based IoT Networks",
    "abstract": "Industrial Internet of Things (IIoT) networks must meet strict reliability, latency, and low energy consumption requirements. However, traditional low-power wireless protocols are ineffective in finding a sweet spot for balancing these performance metrics. Recently, network flooding protocols based on Synchronous Transmissions (STX) have been proposed for better performance in reliability-critical IIoT, where simultaneous transmissions are possible without packet collisions. STX-based protocols can offer a competitive edge over routing-based protocols, particularly in dependability. However, they notably suffer from the beating effect, a physical layer phenomenon that results in sinusoidal interference across a packet and, consequently, packet loss. Thus, we introduce STX-Vote, an error correction scheme that can handle errors caused by beating effects. Importantly, we utilize transmission redundancy already inherent within STX protocols so do not incur additional on-air overhead. Through simulation, we demonstrate STX-Vote can provide a 40% increase in reliability. We subsequently implement STX-Vote on nRF52840-DK devices and perform extensive experiments. The results confirm that STX-Vote improves reliability by 25-28% for BLE 5 PHYs and 8% for IEEE 802.15.4; thus, it can complement existing error correction schemes. ",
    "url": "https://arxiv.org/abs/2405.02022",
    "authors": [
      "Burhanuddin Rangwala",
      "Ava Powelson",
      "Michael Baddeley",
      "Israat Haque"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2405.02041",
    "title": "Stabilizing Backpropagation Through Time to Learn Complex Physics",
    "abstract": "Of all the vector fields surrounding the minima of recurrent learning setups, the gradient field with its exploding and vanishing updates appears a poor choice for optimization, offering little beyond efficient computability. We seek to improve this suboptimal practice in the context of physics simulations, where backpropagating feedback through many unrolled time steps is considered crucial to acquiring temporally coherent behavior. The alternative vector field we propose follows from two principles: physics simulators, unlike neural networks, have a balanced gradient flow, and certain modifications to the backpropagation pass leave the positions of the original minima unchanged. As any modification of backpropagation decouples forward and backward pass, the rotation-free character of the gradient field is lost. Therefore, we discuss the negative implications of using such a rotational vector field for optimization and how to counteract them. Our final procedure is easily implementable via a sequence of gradient stopping and component-wise comparison operations, which do not negatively affect scalability. Our experiments on three control problems show that especially as we increase the complexity of each task, the unbalanced updates from the gradient can no longer provide the precise control signals necessary while our method still solves the tasks. Our code can be found at https://github.com/tum-pbs/StableBPTT. ",
    "url": "https://arxiv.org/abs/2405.02041",
    "authors": [
      "Patrick Schnell",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2405.02044",
    "title": "Zero-Sum Positional Differential Games as a Framework for Robust  Reinforcement Learning: Deep Q-Learning Approach",
    "abstract": "Robust Reinforcement Learning (RRL) is a promising Reinforcement Learning (RL) paradigm aimed at training robust to uncertainty or disturbances models, making them more efficient for real-world applications. Following this paradigm, uncertainty or disturbances are interpreted as actions of a second adversarial agent, and thus, the problem is reduced to seeking the agents' policies robust to any opponent's actions. This paper is the first to propose considering the RRL problems within the positional differential game theory, which helps us to obtain theoretically justified intuition to develop a centralized Q-learning approach. Namely, we prove that under Isaacs's condition (sufficiently general for real-world dynamical systems), the same Q-function can be utilized as an approximate solution of both minimax and maximin Bellman equations. Based on these results, we present the Isaacs Deep Q-Network algorithms and demonstrate their superiority compared to other baseline RRL and Multi-Agent RL algorithms in various environments. ",
    "url": "https://arxiv.org/abs/2405.02044",
    "authors": [
      "Anton Plaksin",
      "Vitaly Kalev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2405.02063",
    "title": "Few-sample Variational Inference of Bayesian Neural Networks with  Arbitrary Nonlinearities",
    "abstract": "Bayesian Neural Networks (BNNs) extend traditional neural networks to provide uncertainties associated with their outputs. On the forward pass through a BNN, predictions (and their uncertainties) are made either by Monte Carlo sampling network weights from the learned posterior or by analytically propagating statistical moments through the network. Though flexible, Monte Carlo sampling is computationally expensive and can be infeasible or impractical under resource constraints or for large networks. While moment propagation can ameliorate the computational costs of BNN inference, it can be difficult or impossible for networks with arbitrary nonlinearities, thereby restricting the possible set of network layers permitted with such a scheme. In this work, we demonstrate a simple yet effective approach for propagating statistical moments through arbitrary nonlinearities with only 3 deterministic samples, enabling few-sample variational inference of BNNs without restricting the set of network layers used. Furthermore, we leverage this approach to demonstrate a novel nonlinear activation function that we use to inject physics-informed prior information into output nodes of a BNN. ",
    "url": "https://arxiv.org/abs/2405.02063",
    "authors": [
      "David J. Schodt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02066",
    "title": "WateRF: Robust Watermarks in Radiance Fields for Protection of  Copyrights",
    "abstract": "The advances in the Neural Radiance Fields (NeRF) research offer extensive applications in diverse domains, but protecting their copyrights has not yet been researched in depth. Recently, NeRF watermarking has been considered one of the pivotal solutions for safely deploying NeRF-based 3D representations. However, existing methods are designed to apply only to implicit or explicit NeRF representations. In this work, we introduce an innovative watermarking method that can be employed in both representations of NeRF. This is achieved by fine-tuning NeRF to embed binary messages in the rendering process. In detail, we propose utilizing the discrete wavelet transform in the NeRF space for watermarking. Furthermore, we adopt a deferred back-propagation technique and introduce a combination with the patch-wise loss to improve rendering quality and bit accuracy with minimum trade-offs. We evaluate our method in three different aspects: capacity, invisibility, and robustness of the embedded watermarks in the 2D-rendered images. Our method achieves state-of-the-art performance with faster training speed over the compared state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2405.02066",
    "authors": [
      "Youngdong Jang",
      "Dong In Lee",
      "MinHyuk Jang",
      "Jong Wook Kim",
      "Feng Yang",
      "Sangpil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2405.02068",
    "title": "Advancing Pre-trained Teacher: Towards Robust Feature Discrepancy for  Anomaly Detection",
    "abstract": "With the wide application of knowledge distillation between an ImageNet pre-trained teacher model and a learnable student model, industrial anomaly detection has witnessed a significant achievement in the past few years. The success of knowledge distillation mainly relies on how to keep the feature discrepancy between the teacher and student model, in which it assumes that: (1) the teacher model can jointly represent two different distributions for the normal and abnormal patterns, while (2) the student model can only reconstruct the normal distribution. However, it still remains a challenging issue to maintain these ideal assumptions in practice. In this paper, we propose a simple yet effective two-stage industrial anomaly detection framework, termed as AAND, which sequentially performs Anomaly Amplification and Normality Distillation to obtain robust feature discrepancy. In the first anomaly amplification stage, we propose a novel Residual Anomaly Amplification (RAA) module to advance the pre-trained teacher encoder. With the exposure of synthetic anomalies, it amplifies anomalies via residual generation while maintaining the integrity of pre-trained model. It mainly comprises a Matching-guided Residual Gate and an Attribute-scaling Residual Generator, which can determine the residuals' proportion and characteristic, respectively. In the second normality distillation stage, we further employ a reverse distillation paradigm to train a student decoder, in which a novel Hard Knowledge Distillation (HKD) loss is built to better facilitate the reconstruction of normal patterns. Comprehensive experiments on the MvTecAD, VisA, and MvTec3D-RGB datasets show that our method achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2405.02068",
    "authors": [
      "Canhui Tang",
      "Sanping Zhou",
      "Yizhe Li",
      "Yonghao Dong",
      "Le Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.02074",
    "title": "A Federated Learning Benchmark on Tabular Data: Comparing Tree-Based  Models and Neural Networks",
    "abstract": "Federated Learning (FL) has lately gained traction as it addresses how machine learning models train on distributed datasets. FL was designed for parametric models, namely Deep Neural Networks (DNNs).Thus, it has shown promise on image and text tasks. However, FL for tabular data has received little attention. Tree-Based Models (TBMs) have been considered to perform better on tabular data and they are starting to see FL integrations. In this study, we benchmark federated TBMs and DNNs for horizontal FL, with varying data partitions, on 10 well-known tabular datasets. Our novel benchmark results indicates that current federated boosted TBMs perform better than federated DNNs in different data partitions. Furthermore, a federated XGBoost outperforms all other models. Lastly, we find that federated TBMs perform better than federated parametric models, even when increasing the number of clients significantly. ",
    "url": "https://arxiv.org/abs/2405.02074",
    "authors": [
      "William Lindskog",
      "Christian Prehofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02086",
    "title": "Multi-level projection with exponential parallel speedup; Application to  sparse auto-encoders neural networks",
    "abstract": "The $\\ell_{1,\\infty}$ norm is an efficient structured projection but the complexity of the best algorithm is unfortunately $\\mathcal{O}\\big(n m \\log(n m)\\big)$ for a matrix in $\\mathbb{R}^{n\\times m}$. In this paper, we propose a new bi-level projection method for which we show that the time complexity for the $\\ell_{1,\\infty}$ norm is only $\\mathcal{O}\\big(n m \\big)$ for a matrix in $\\mathbb{R}^{n\\times m}$, and $\\mathcal{O}\\big(n + m \\big)$ with full parallel power. We generalize our method to tensors and we propose a new multi-level projection, having an induced decomposition that yields a linear parallel speedup up to an exponential speedup factor, resulting in a time complexity lower-bounded by the sum of the dimensions. Experiments show that our bi-level $\\ell_{1,\\infty}$ projection is $2.5$ times faster than the actual fastest algorithm provided by \\textit{Chu et. al.} while providing same accuracy and better sparsity in neural networks applications. ",
    "url": "https://arxiv.org/abs/2405.02086",
    "authors": [
      "Guillaume Perez",
      "Michel Barlaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02094",
    "title": "Numerical validation of an adaptive model for the determination of  nonlinear-flow regions in highly heterogeneous porous media",
    "abstract": "An adaptive model for the description of flows in highly heterogeneous porous media is developed in~\\cite{FP21,FP23}. There, depending on the magnitude of the fluid's velocity, the constitutive law linking velocity and pressure gradient is selected between two possible options, one better adapted to slow motion and the other to fast motion. We propose here to validate further this adaptive approach by means of more extensive numerical experiments, including a three-dimensional case, as well as to use such approach to determine a partition of the domain into slow- and fast-flow regions. ",
    "url": "https://arxiv.org/abs/2405.02094",
    "authors": [
      "Alessio Fumagalli",
      "Francesco S. Patacchini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2405.02095",
    "title": "Advanced Detection of Source Code Clones via an Ensemble of Unsupervised  Similarity Measures",
    "abstract": "The capability of accurately determining code similarity is crucial in many tasks related to software development. For example, it might be essential to identify code duplicates for performing software maintenance. This research introduces a novel ensemble learning approach for code similarity assessment, combining the strengths of multiple unsupervised similarity measures. The key idea is that the strengths of a diverse set of similarity measures can complement each other and mitigate individual weaknesses, leading to improved performance. Preliminary results show that while Transformers-based CodeBERT and its variant GraphCodeBERT are undoubtedly the best option in the presence of abundant training data, in the case of specific small datasets (up to 500 samples), our ensemble achieves similar results, without prejudice to the interpretability of the resulting solution, and with a much lower associated carbon footprint due to training. The source code of this novel approach can be downloaded from https://github.com/jorge-martinez-gil/ensemble-codesim. ",
    "url": "https://arxiv.org/abs/2405.02095",
    "authors": [
      "Jorge Martinez-Gil"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.02098",
    "title": "Forecasting Ferry Passenger Flow Using Long-Short Term Memory Neural  Networks",
    "abstract": "With recent studies related to Neural Networks being used on different forecasting and time series investigations, this study aims to expand these contexts to ferry passenger traffic. The primary objective of the study is to investigate and evaluate an LSTM-based Neural Networks' capability to forecast ferry passengers of two ports in the Philippines. The proposed model's fitting and evaluation of the passenger flow forecasting of the two ports is based on monthly passenger traffic from 2016 to 2022 data that was acquired from the Philippine Ports Authority (PPA). This work uses Mean Absolute Percentage Error (MAPE) as its primary metric to evaluate the model's forecasting capability. The proposed LSTM-based Neural Networks model achieved 72% forecasting accuracy to the Batangas port ferry passenger data and 74% forecasting accuracy to the Mindoro port ferry passenger data. Using Keras and Scikit-learn Python libraries, this work concludes a reasonable forecasting performance of the presented LSTM model. Aside from these notable findings, this study also recommends further investigation and studies on employing other statistical, machine learning, and deep learning methods on forecasting ferry passenger flows. ",
    "url": "https://arxiv.org/abs/2405.02098",
    "authors": [
      "Daniel Fesalbon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02105",
    "title": "Evaluating Large Language Models for Structured Science Summarization in  the Open Research Knowledge Graph",
    "abstract": "Structured science summaries or research contributions using properties or dimensions beyond traditional keywords enhances science findability. Current methods, such as those used by the Open Research Knowledge Graph (ORKG), involve manually curating properties to describe research papers' contributions in a structured manner, but this is labor-intensive and inconsistent between the domain expert human curators. We propose using Large Language Models (LLMs) to automatically suggest these properties. However, it's essential to assess the readiness of LLMs like GPT-3.5, Llama 2, and Mistral for this task before application. Our study performs a comprehensive comparative analysis between ORKG's manually curated properties and those generated by the aforementioned state-of-the-art LLMs. We evaluate LLM performance through four unique perspectives: semantic alignment and deviation with ORKG properties, fine-grained properties mapping accuracy, SciNCL embeddings-based cosine similarity, and expert surveys comparing manual annotations with LLM outputs. These evaluations occur within a multidisciplinary science setting. Overall, LLMs show potential as recommendation systems for structuring science, but further finetuning is recommended to improve their alignment with scientific tasks and mimicry of human expertise. ",
    "url": "https://arxiv.org/abs/2405.02105",
    "authors": [
      "Vladyslav Nechakhin",
      "Jennifer D'Souza",
      "Steffen Eger"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2405.02121",
    "title": "Accurate Pose Prediction on Signed Distance Fields for Mobile Ground  Robots in Rough Terrain",
    "abstract": "Autonomous locomotion for mobile ground robots in unstructured environments such as waypoint navigation or flipper control requires a sufficiently accurate prediction of the robot-terrain interaction. Heuristics like occupancy grids or traversability maps are widely used but limit actions available to robots with active flippers as joint positions are not taken into account. We present a novel iterative geometric method to predict the 3D pose of mobile ground robots with active flippers on uneven ground with high accuracy and online planning capabilities. This is achieved by utilizing the ability of signed distance fields to represent surfaces with sub-voxel accuracy. The effectiveness of the presented approach is demonstrated on two different tracked robots in simulation and on a real platform. Compared to a tracking system as ground truth, our method predicts the robot position and orientation with an average accuracy of 3.11 cm and 3.91{\\deg}, outperforming a recent heightmap-based approach. The implementation is made available as an open-source ROS package. ",
    "url": "https://arxiv.org/abs/2405.02121",
    "authors": [
      "Martin Oehler",
      "Oskar von Stryk"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2405.02133",
    "title": "Learning from Evolution: Improving Collective Decision-Making Mechanisms  using Insights from Evolutionary Robotics",
    "abstract": "Collective decision-making enables multi-robot systems to act autonomously in real-world environments. Existing collective decision-making mechanisms suffer from the so-called speed versus accuracy trade-off or rely on high complexity, e.g., by including global communication. Recent work has shown that more efficient collective decision-making mechanisms based on artificial neural networks can be generated using methods from evolutionary computation. A major drawback of these decision-making neural networks is their limited interpretability. Analyzing evolved decision-making mechanisms can help us improve the efficiency of hand-coded decision-making mechanisms while maintaining a higher interpretability. In this paper, we analyze evolved collective decision-making mechanisms in detail and hand-code two new decision-making mechanisms based on the insights gained. In benchmark experiments, we show that the newly implemented collective decision-making mechanisms are more efficient than the state-of-the-art collective decision-making mechanisms voter model and majority rule. ",
    "url": "https://arxiv.org/abs/2405.02133",
    "authors": [
      "Tanja Katharina Kaiser"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2405.02140",
    "title": "An Information Theoretic Perspective on Conformal Prediction",
    "abstract": "Conformal Prediction (CP) is a distribution-free uncertainty estimation framework that constructs prediction sets guaranteed to contain the true answer with a user-specified probability. Intuitively, the size of the prediction set encodes a general notion of uncertainty, with larger sets associated with higher degrees of uncertainty. In this work, we leverage information theory to connect conformal prediction to other notions of uncertainty. More precisely, we prove three different ways to upper bound the intrinsic uncertainty, as described by the conditional entropy of the target variable given the inputs, by combining CP with information theoretical inequalities. Moreover, we demonstrate two direct and useful applications of such connection between conformal prediction and information theory: (i) more principled and effective conformal training objectives that generalize previous approaches and enable end-to-end training of machine learning models from scratch, and (ii) a natural mechanism to incorporate side information into conformal prediction. We empirically validate both applications in centralized and federated learning settings, showing our theoretical results translate to lower inefficiency (average prediction set size) for popular CP methods. ",
    "url": "https://arxiv.org/abs/2405.02140",
    "authors": [
      "Alvaro H.C. Correia",
      "Fabio Valerio Massoli",
      "Christos Louizos",
      "Arash Behboodi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2405.02145",
    "title": "Characterized Diffusion and Spatial-Temporal Interaction Network for  Trajectory Prediction in Autonomous Driving",
    "abstract": "Trajectory prediction is a cornerstone in autonomous driving (AD), playing a critical role in enabling vehicles to navigate safely and efficiently in dynamic environments. To address this task, this paper presents a novel trajectory prediction model tailored for accuracy in the face of heterogeneous and uncertain traffic scenarios. At the heart of this model lies the Characterized Diffusion Module, an innovative module designed to simulate traffic scenarios with inherent uncertainty. This module enriches the predictive process by infusing it with detailed semantic information, thereby enhancing trajectory prediction accuracy. Complementing this, our Spatio-Temporal (ST) Interaction Module captures the nuanced effects of traffic scenarios on vehicle dynamics across both spatial and temporal dimensions with remarkable effectiveness. Demonstrated through exhaustive evaluations, our model sets a new standard in trajectory prediction, achieving state-of-the-art (SOTA) results on the Next Generation Simulation (NGSIM), Highway Drone (HighD), and Macao Connected Autonomous Driving (MoCAD) datasets across both short and extended temporal spans. This performance underscores the model's unparalleled adaptability and efficacy in navigating complex traffic scenarios, including highways, urban streets, and intersections. ",
    "url": "https://arxiv.org/abs/2405.02145",
    "authors": [
      "Haicheng Liao",
      "Xuelin Li",
      "Yongkang Li",
      "Hanlin Kong",
      "Chengyue Wang",
      "Bonan Wang",
      "Yanchen Guan",
      "KaHou Tam",
      "Zhenning Li",
      "Chengzhong Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2405.02147",
    "title": "Payout Races and Congested Channels: A Formal Analysis of Security in  the Lightning Network",
    "abstract": "The Lightning Network, a payment channel network with a market cap of over 192M USD, is designed to resolve Bitcoin's scalability issues through fast off-chain transactions. There are multiple Lightning Network client implementations, all of which conform to the same textual specifications known as BOLTs. Several vulnerabilities have been manually discovered, but to-date there have been few works systematically analyzing the security of the Lightning Network. In this work, we take a foundational approach to analyzing the security of the Lightning Network with the help of formal methods. Based on the BOLTs' specifications, we build a detailed formal model of the Lightning Network's single-hop payment protocol and verify it using the Spin model checker. Our model captures both concurrency and error semantics of the payment protocol. We then define several security properties which capture the correct intermediate operation of the protocol, ensuring that the outcome is always certain to both channel peers, and using them we re-discover a known attack previously reported in the literature along with a novel attack, referred to as a Payout Race. A Payout Race consists of a particular sequence of events that can lead to an ambiguity in the protocol in which innocent users can unwittingly lose funds. We confirm the practicality of this attack by reproducing it in a local testbed environment. ",
    "url": "https://arxiv.org/abs/2405.02147",
    "authors": [
      "Ben Weintraub",
      "Satwik Prabhu Kumble",
      "Cristina Nita-Rotaru",
      "Stefanie Roos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2405.02154",
    "title": "Neural Context Flows for Learning Generalizable Dynamical Systems",
    "abstract": "Neural Ordinary Differential Equations typically struggle to generalize to new dynamical behaviors created by parameter changes in the underlying system, even when the dynamics are close to previously seen behaviors. The issue gets worse when the changing parameters are unobserved, i.e., their value or influence is not directly measurable when collecting data. We introduce Neural Context Flow (NCF), a framework that encodes said unobserved parameters in a latent context vector as input to a vector field. NCFs leverage differentiability of the vector field with respect to the parameters, along with first-order Taylor expansion to allow any context vector to influence trajectories from other parameters. We validate our method and compare it to established Multi-Task and Meta-Learning alternatives, showing competitive performance in mean squared error for in-domain and out-of-distribution evaluation on the Lotka-Volterra, Glycolytic Oscillator, and Gray-Scott problems. This study holds practical implications for foundational models in science and related areas that benefit from conditional neural ODEs. Our code is openly available at https://github.com/ddrous/ncflow. ",
    "url": "https://arxiv.org/abs/2405.02154",
    "authors": [
      "Roussel Desmond Nzoyem",
      "David A.W. Barton",
      "Tom Deakin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2405.02171",
    "title": "Self-Supervised Learning for Real-World Super-Resolution from Dual and  Multiple Zoomed Observations",
    "abstract": "In this paper, we consider two challenging issues in reference-based super-resolution (RefSR) for smartphone, (i) how to choose a proper reference image, and (ii) how to learn RefSR in a self-supervised manner. Particularly, we propose a novel self-supervised learning approach for real-world RefSR from observations at dual and multiple camera zooms. Firstly, considering the popularity of multiple cameras in modern smartphones, the more zoomed (telephoto) image can be naturally leveraged as the reference to guide the super-resolution (SR) of the lesser zoomed (ultra-wide) image, which gives us a chance to learn a deep network that performs SR from the dual zoomed observations (DZSR). Secondly, for self-supervised learning of DZSR, we take the telephoto image instead of an additional high-resolution image as the supervision information, and select a center patch from it as the reference to super-resolve the corresponding ultra-wide image patch. To mitigate the effect of the misalignment between ultra-wide low-resolution (LR) patch and telephoto ground-truth (GT) image during training, we first adopt patch-based optical flow alignment and then design an auxiliary-LR to guide the deforming of the warped LR features. To generate visually pleasing results, we present local overlapped sliced Wasserstein loss to better represent the perceptual difference between GT and output in the feature space. During testing, DZSR can be directly deployed to super-solve the whole ultra-wide image with the reference of the telephoto image. In addition, we further take multiple zoomed observations to explore self-supervised RefSR, and present a progressive fusion scheme for the effective utilization of reference images. Experiments show that our methods achieve better quantitative and qualitative performance against state-of-the-arts. Codes are available at https://github.com/cszhilu1998/SelfDZSR_PlusPlus. ",
    "url": "https://arxiv.org/abs/2405.02171",
    "authors": [
      "Zhilu Zhang",
      "Ruohao Wang",
      "Hongzhi Zhang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.02180",
    "title": "A Flow-Based Model for Conditional and Probabilistic Electricity  Consumption Profile Generation and Prediction",
    "abstract": "Residential Load Profile (RLP) generation and prediction are critical for the operation and planning of distribution networks, particularly as diverse low-carbon technologies are increasingly integrated. This paper introduces a novel flow-based generative model, termed Full Convolutional Profile Flow (FCPFlow), which is uniquely designed for both conditional and unconditional RLP generation, and for probabilistic load forecasting. By introducing two new layers--the invertible linear layer and the invertible normalization layer--the proposed FCPFlow architecture shows three main advantages compared to traditional statistical and contemporary deep generative models: 1) it is well-suited for RLP generation under continuous conditions, such as varying weather and annual electricity consumption, 2) it shows superior scalability in different datasets compared to traditional statistical, and 3) it also demonstrates better modeling capabilities in capturing the complex correlation of RLPs compared with deep generative models. ",
    "url": "https://arxiv.org/abs/2405.02180",
    "authors": [
      "Weijie Xia",
      "Chenguang Wang",
      "Peter Palensky",
      "Pedro P. Vergara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2405.02195",
    "title": "Impact of emoji exclusion on the performance of Arabic sarcasm detection  models",
    "abstract": "The complex challenge of detecting sarcasm in Arabic speech on social media is increased by the language diversity and the nature of sarcastic expressions. There is a significant gap in the capability of existing models to effectively interpret sarcasm in Arabic, which mandates the necessity for more sophisticated and precise detection methods. In this paper, we investigate the impact of a fundamental preprocessing component on sarcasm speech detection. While emojis play a crucial role in mitigating the absence effect of body language and facial expressions in modern communication, their impact on automated text analysis, particularly in sarcasm detection, remains underexplored. We investigate the impact of emoji exclusion from datasets on the performance of sarcasm detection models in social media content for Arabic as a vocabulary-super rich language. This investigation includes the adaptation and enhancement of AraBERT pre-training models, specifically by excluding emojis, to improve sarcasm detection capabilities. We use AraBERT pre-training to refine the specified models, demonstrating that the removal of emojis can significantly boost the accuracy of sarcasm detection. This approach facilitates a more refined interpretation of language, eliminating the potential confusion introduced by non-textual elements. The evaluated AraBERT models, through the focused strategy of emoji removal, adeptly navigate the complexities of Arabic sarcasm. This study establishes new benchmarks in Arabic natural language processing and presents valuable insights for social media platforms. ",
    "url": "https://arxiv.org/abs/2405.02195",
    "authors": [
      "Ghalyah H. Aleryani",
      "Wael Deabes",
      "Khaled Albishre",
      "Alaa E. Abdel-Hakim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02203",
    "title": "Convergence of a Finite Volume Scheme for Compactly Heterogeneous Scalar  Conservation Laws",
    "abstract": "We build a finite volume scheme for the scalar conservation law $\\partial_t u + \\partial_x (H(x, u)) = 0$ with bounded initial condition for a wide class of flux function $H$, convex with respect to the second variable. The main idea for the construction of the scheme is to use the theory of discontinuous flux. We prove that the resulting approximating sequence converges boundedly almost everywhere on $\\mathopen]0, +\\infty\\mathclose[$ to the entropy solution. ",
    "url": "https://arxiv.org/abs/2405.02203",
    "authors": [
      "Abraham Sylla"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2405.02220",
    "title": "Designed Dithering Sign Activation for Binary Neural Networks",
    "abstract": "Binary Neural Networks emerged as a cost-effective and energy-efficient solution for computer vision tasks by binarizing either network weights or activations. However, common binary activations, such as the Sign activation function, abruptly binarize the values with a single threshold, losing fine-grained details in the feature outputs. This work proposes an activation that applies multiple thresholds following dithering principles, shifting the Sign activation function for each pixel according to a spatially periodic threshold kernel. Unlike literature methods, the shifting is defined jointly for a set of adjacent pixels, taking advantage of spatial correlations. Experiments over the classification task demonstrate the effectiveness of the designed dithering Sign activation function as an alternative activation for binary neural networks, without increasing the computational cost. Further, DeSign balances the preservation of details with the efficiency of binary operations. ",
    "url": "https://arxiv.org/abs/2405.02220",
    "authors": [
      "Brayan Monroy",
      "Juan Estupi\u00f1an",
      "Tatiana Gelvez-Barrera",
      "Jorge Bacca",
      "Henry Arguello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02221",
    "title": "Discretization Error of Fourier Neural Operators",
    "abstract": "Operator learning is a variant of machine learning that is designed to approximate maps between function spaces from data. The Fourier Neural Operator (FNO) is a common model architecture used for operator learning. The FNO combines pointwise linear and nonlinear operations in physical space with pointwise linear operations in Fourier space, leading to a parameterized map acting between function spaces. Although FNOs formally involve convolutions of functions on a continuum, in practice the computations are performed on a discretized grid, allowing efficient implementation via the FFT. In this paper, the aliasing error that results from such a discretization is quantified and algebraic rates of convergence in terms of the grid resolution are obtained as a function of the regularity of the input. Numerical experiments that validate the theory and describe model stability are performed. ",
    "url": "https://arxiv.org/abs/2405.02221",
    "authors": [
      "Samuel Lanthaler",
      "Andrew M. Stuart",
      "Margaret Trautner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02240",
    "title": "Subgraph2vec: A random walk-based algorithm for embedding knowledge  graphs",
    "abstract": "Graph is an important data representation which occurs naturally in the real world applications \\cite{goyal2018graph}. Therefore, analyzing graphs provides users with better insights in different areas such as anomaly detection \\cite{ma2021comprehensive}, decision making \\cite{fan2023graph}, clustering \\cite{tsitsulin2023graph}, classification \\cite{wang2021mixup} and etc. However, most of these methods require high levels of computational time and space. We can use other ways like embedding to reduce these costs. Knowledge graph (KG) embedding is a technique that aims to achieve the vector representation of a KG. It represents entities and relations of a KG in a low-dimensional space while maintaining the semantic meanings of them. There are different methods for embedding graphs including random walk-based methods such as node2vec, metapath2vec and regpattern2vec. However, most of these methods bias the walks based on a rigid pattern usually hard-coded in the algorithm. In this work, we introduce \\textit{subgraph2vec} for embedding KGs where walks are run inside a user-defined subgraph. We use this embedding for link prediction and prove our method has better performance in most cases in comparison with the previous ones. ",
    "url": "https://arxiv.org/abs/2405.02240",
    "authors": [
      "Elika Bozorgi",
      "Saber Soleimani",
      "Sakher Khalil Alqaiidi",
      "Hamid Reza Arabnia",
      "Krzysztof Kochut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02261",
    "title": "Comparing Personalized Relevance Algorithms for Directed Graphs",
    "abstract": "We present an interactive Web platform that, given a directed graph, allows identifying the most relevant nodes related to a given query node. Besides well-established algorithms such as PageRank and Personalized PageRank, the demo includes Cyclerank, a novel algorithm that addresses some of their limitations by leveraging cyclic paths to compute personalized relevance scores. Our demo design enables two use cases: (a) algorithm comparison, comparing the results obtained with different algorithms, and (b) dataset comparison, for exploring and gaining insights into a dataset and comparing it with others. We provide 50 pre-loaded datasets from Wikipedia, Twitter, and Amazon and seven algorithms. Users can upload new datasets, and new algorithms can be easily added. By showcasing efficient algorithms to compute relevance scores in directed graphs, our tool helps to uncover hidden relationships within the data, which makes of it a valuable addition to the repertoire of graph analysis algorithms. ",
    "url": "https://arxiv.org/abs/2405.02261",
    "authors": [
      "Luca Cavalcanti",
      "Cristian Consonni",
      "Martin Brugnara",
      "David Laniado",
      "Alberto Montresor"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2405.02267",
    "title": "Structural Pruning of Pre-trained Language Models via Neural  Architecture Search",
    "abstract": "Pre-trained language models (PLM), for example BERT or RoBERTa, mark the state-of-the-art for natural language understanding task when fine-tuned on labeled data. However, their large size poses challenges in deploying them for inference in real-world applications, due to significant GPU memory requirements and high inference latency. This paper explores neural architecture search (NAS) for structural pruning to find sub-parts of the fine-tuned network that optimally trade-off efficiency, for example in terms of model size or latency, and generalization performance. We also show how we can utilize more recently developed two-stage weight-sharing NAS approaches in this setting to accelerate the search process. Unlike traditional pruning methods with fixed thresholds, we propose to adopt a multi-objective approach that identifies the Pareto optimal set of sub-networks, allowing for a more flexible and automated compression process. ",
    "url": "https://arxiv.org/abs/2405.02267",
    "authors": [
      "Aaron Klein",
      "Jacek Golebiowski",
      "Xingchen Ma",
      "Valerio Perrone",
      "Cedric Archambeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2405.01596",
    "title": "Analyzing Player Involvement in the Indian Pro Kabaddi League: A Network  Analysis Approach",
    "abstract": "This paper aims to apply network analysis to all players who have participated in the Indian Pro Kabaddi League since its inception. The Kabaddi network has been constructed based on the number of teams and players they have played with. The players have been ranked with the help of the degree and PageRank algorithm. Small-world phenomenon is observed in the Kabaddi network. The significance of the player performance has been compared with the player rank received by the network analysis. ",
    "url": "https://arxiv.org/abs/2405.01596",
    "authors": [
      "Arjab Sengupta",
      "Subhadip Layek",
      "Krishanu Deyasi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2405.01725",
    "title": "Development of Skip Connection in Deep Neural Networks for Computer  Vision and Medical Image Analysis: A Survey",
    "abstract": "Deep learning has made significant progress in computer vision, specifically in image classification, object detection, and semantic segmentation. The skip connection has played an essential role in the architecture of deep neural networks,enabling easier optimization through residual learning during the training stage and improving accuracy during testing. Many neural networks have inherited the idea of residual learning with skip connections for various tasks, and it has been the standard choice for designing neural networks. This survey provides a comprehensive summary and outlook on the development of skip connections in deep neural networks. The short history of skip connections is outlined, and the development of residual learning in deep neural networks is surveyed. The effectiveness of skip connections in the training and testing stages is summarized, and future directions for using skip connections in residual learning are discussed. Finally, we summarize seminal papers, source code, models, and datasets that utilize skip connections in computer vision, including image classification, object detection, semantic segmentation, and image reconstruction. We hope this survey could inspire peer researchers in the community to develop further skip connections in various forms and tasks and the theory of residual learning in deep neural networks. The project page can be found at https://github.com/apple1986/Residual_Learning_For_Images ",
    "url": "https://arxiv.org/abs/2405.01725",
    "authors": [
      "Guoping Xu",
      "Xiaxia Wang",
      "Xinglong Wu",
      "Xuesong Leng",
      "Yongchao Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01737",
    "title": "Sample-efficient neural likelihood-free Bayesian inference of implicit  HMMs",
    "abstract": "Likelihood-free inference methods based on neural conditional density estimation were shown to drastically reduce the simulation burden in comparison to classical methods such as ABC. When applied in the context of any latent variable model, such as a Hidden Markov model (HMM), these methods are designed to only estimate the parameters, rather than the joint distribution of the parameters and the hidden states. Naive application of these methods to a HMM, ignoring the inference of this joint posterior distribution, will thus produce an inaccurate estimate of the posterior predictive distribution, in turn hampering the assessment of goodness-of-fit. To rectify this problem, we propose a novel, sample-efficient likelihood-free method for estimating the high-dimensional hidden states of an implicit HMM. Our approach relies on learning directly the intractable posterior distribution of the hidden states, using an autoregressive-flow, by exploiting the Markov property. Upon evaluating our approach on some implicit HMMs, we found that the quality of the estimates retrieved using our method is comparable to what can be achieved using a much more computationally expensive SMC algorithm. ",
    "url": "https://arxiv.org/abs/2405.01737",
    "authors": [
      "Sanmitra Ghosh",
      "Paul J. Birrell",
      "Daniela De Angelis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2405.01756",
    "title": "Segmentation-Free Outcome Prediction in Head and Neck Cancer: Deep  Learning-based Feature Extraction from Multi-Angle Maximum Intensity  Projections (MA-MIPs) of PET Images",
    "abstract": "We introduce an innovative, simple, effective segmentation-free approach for outcome prediction in head \\& neck cancer (HNC) patients. By harnessing deep learning-based feature extraction techniques and multi-angle maximum intensity projections (MA-MIPs) applied to Fluorodeoxyglucose Positron Emission Tomography (FDG-PET) volumes, our proposed method eliminates the need for manual segmentations of regions-of-interest (ROIs) such as primary tumors and involved lymph nodes. Instead, a state-of-the-art object detection model is trained to perform automatic cropping of the head and neck region on the PET volumes. A pre-trained deep convolutional neural network backbone is then utilized to extract deep features from MA-MIPs obtained from 72 multi-angel axial rotations of the cropped PET volumes. These deep features extracted from multiple projection views of the PET volumes are then aggregated and fused, and employed to perform recurrence-free survival analysis on a cohort of 489 HNC patients. The proposed approach outperforms the best performing method on the target dataset for the task of recurrence-free survival analysis. By circumventing the manual delineation of the malignancies on the FDG PET-CT images, our approach eliminates the dependency on subjective interpretations and highly enhances the reproducibility of the proposed survival analysis method. ",
    "url": "https://arxiv.org/abs/2405.01756",
    "authors": [
      "Amirhosein Toosi",
      "Isaac Shiri",
      "Habib Zaidi",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.01770",
    "title": "Bike network planning in limited urban space",
    "abstract": "The lack of cycling infrastructure in urban environments hinders the adoption of cycling as a viable mode for commuting, despite the evident benefits of (e-)bikes as sustainable, efficient, and health-promoting transportation modes. Bike network planning is a tedious process, relying on heuristic computational methods that frequently overlook the broader implications of introducing new cycling infrastructure, in particular the necessity to repurpose car lanes. In this work, we call for optimizing the trade-off between bike and car networks, effectively pushing for Pareto optimality. This shift in perspective gives rise to a novel linear programming formulation towards optimal bike network allocation. Our experiments, conducted using both real-world and synthetic data, testify the effectiveness and superiority of this optimization approach compared to heuristic methods. In particular, the framework provides stakeholders with a range of lane reallocation scenarios, illustrating potential bike network enhancements and their implications for car infrastructure. Crucially, our approach is adaptable to various bikeability and car accessibility evaluation criteria, making our tool a highly flexible and scalable resource for urban planning. This paper presents an advanced decision-support framework that can significantly aid urban planners in making informed decisions on cycling infrastructure development. ",
    "url": "https://arxiv.org/abs/2405.01770",
    "authors": [
      "Nina Wiedemann",
      "Christian N\u00f6bel",
      "Henry Martin",
      "Lukas Ballo",
      "Martin Raubal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2405.01879",
    "title": "Unavoidable induced subgraphs in graphs with complete bipartite induced  minors",
    "abstract": "We prove that if a graph contains the complete bipartite graph $K_{134, 12}$ as an induced minor, then it contains a cycle of length at most~12 or a theta as an induced subgraph. With a longer and more technical proof, we prove that if a graph contains $K_{3, 4}$ as an induced minor, then it contains a triangle or a theta as an induced subgraph. Here, a \\emph{theta} is a graph made of three internally vertex-disjoint chordless paths $P_1 = a \\dots b$, $P_2 = a \\dots b$, $P_3 = a \\dots b$, each of length at least two, such that no edges exist between the paths except the three edges incident to $a$ and the three edges incident to $b$. A consequence is that excluding a grid and a complete bipartite graph as induced minors is not enough to guarantee a bounded tree-independence number, or even that the treewidth is bounded by a function of the size of the maximum clique, because the existence of graphs with large treewidth that contain no triangles or thetas as induced subgraphs is already known (the so-called layered wheels). ",
    "url": "https://arxiv.org/abs/2405.01879",
    "authors": [
      "Maria Chudnovsky",
      "Meike Hatzel",
      "Tuukka Korhonen",
      "Nicolas Trotignon",
      "Sebastian Wiederrecht"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2405.01952",
    "title": "Three Quantization Regimes for ReLU Networks",
    "abstract": "We establish the fundamental limits in the approximation of Lipschitz functions by deep ReLU neural networks with finite-precision weights. Specifically, three regimes, namely under-, over-, and proper quantization, in terms of minimax approximation error behavior as a function of network weight precision, are identified. This is accomplished by deriving nonasymptotic tight lower and upper bounds on the minimax approximation error. Notably, in the proper-quantization regime, neural networks exhibit memory-optimality in the approximation of Lipschitz functions. Deep networks have an inherent advantage over shallow networks in achieving memory-optimality. We also develop the notion of depth-precision tradeoff, showing that networks with high-precision weights can be converted into functionally equivalent deeper networks with low-precision weights, while preserving memory-optimality. This idea is reminiscent of sigma-delta analog-to-digital conversion, where oversampling rate is traded for resolution in the quantization of signal samples. We improve upon the best-known ReLU network approximation results for Lipschitz functions and describe a refinement of the bit extraction technique which could be of independent general interest. ",
    "url": "https://arxiv.org/abs/2405.01952",
    "authors": [
      "Weigutian Ou",
      "Philipp Schenkel",
      "Helmut B\u00f6lcskei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.01967",
    "title": "Real-time multichannel deep speech enhancement in hearing aids:  Comparing monaural and binaural processing in complex acoustic scenarios",
    "abstract": "Deep learning has the potential to enhance speech signals and increase their intelligibility for users of hearing aids. Deep models suited for real-world application should feature a low computational complexity and low processing delay of only a few milliseconds. In this paper, we explore deep speech enhancement that matches these requirements and contrast monaural and binaural processing algorithms in two complex acoustic scenes. Both algorithms are evaluated with objective metrics and in experiments with hearing-impaired listeners performing a speech-in-noise test. Results are compared to two traditional enhancement strategies, i.e., adaptive differential microphone processing and binaural beamforming. While in diffuse noise, all algorithms perform similarly, the binaural deep learning approach performs best in the presence of spatial interferers. Through a post-analysis, this can be attributed to improvements at low SNRs and to precise spatial filtering. ",
    "url": "https://arxiv.org/abs/2405.01967",
    "authors": [
      "Nils L. Westhausen",
      "Hendrik Kayser",
      "Theresa Jansen",
      "Bernd T. Meyer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2405.02082",
    "title": "A comparative study of conformal prediction methods for valid  uncertainty quantification in machine learning",
    "abstract": "In the past decades, most work in the area of data analysis and machine learning was focused on optimizing predictive models and getting better results than what was possible with existing models. To what extent the metrics with which such improvements were measured were accurately capturing the intended goal, whether the numerical differences in the resulting values were significant, or whether uncertainty played a role in this study and if it should have been taken into account, was of secondary importance. Whereas probability theory, be it frequentist or Bayesian, used to be the gold standard in science before the advent of the supercomputer, it was quickly replaced in favor of black box models and sheer computing power because of their ability to handle large data sets. This evolution sadly happened at the expense of interpretability and trustworthiness. However, while people are still trying to improve the predictive power of their models, the community is starting to realize that for many applications it is not so much the exact prediction that is of importance, but rather the variability or uncertainty. The work in this dissertation tries to further the quest for a world where everyone is aware of uncertainty, of how important it is and how to embrace it instead of fearing it. A specific, though general, framework that allows anyone to obtain accurate uncertainty estimates is singled out and analysed. Certain aspects and applications of the framework -- dubbed `conformal prediction' -- are studied in detail. Whereas many approaches to uncertainty quantification make strong assumptions about the data, conformal prediction is, at the time of writing, the only framework that deserves the title `distribution-free'. No parametric assumptions have to be made and the nonparametric results also hold without having to resort to the law of large numbers in the asymptotic regime. ",
    "url": "https://arxiv.org/abs/2405.02082",
    "authors": [
      "Nicolas Dewolf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2405.02109",
    "title": "Three-Dimensional Amyloid-Beta PET Synthesis from Structural MRI with  Conditional Generative Adversarial Networks",
    "abstract": "Motivation: Alzheimer's Disease hallmarks include amyloid-beta deposits and brain atrophy, detectable via PET and MRI scans, respectively. PET is expensive, invasive and exposes patients to ionizing radiation. MRI is cheaper, non-invasive, and free from ionizing radiation but limited to measuring brain atrophy. Goal: To develop an 3D image translation model that synthesizes amyloid-beta PET images from T1-weighted MRI, exploiting the known relationship between amyloid-beta and brain atrophy. Approach: The model was trained on 616 PET/MRI pairs and validated with 264 pairs. Results: The model synthesized amyloid-beta PET images from T1-weighted MRI with high-degree of similarity showing high SSIM and PSNR metrics (SSIM>0.95&PSNR=28). Impact: Our model proves the feasibility of synthesizing amyloid-beta PET images from structural MRI ones, significantly enhancing accessibility for large-cohort studies and early dementia detection, while also reducing cost, invasiveness, and radiation exposure. ",
    "url": "https://arxiv.org/abs/2405.02109",
    "authors": [
      "Fernando Vega",
      "Abdoljalil Addeh",
      "M. Ethan MacDonald"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.02124",
    "title": "TIPAA-SSL: Text Independent Phone-to-Audio Alignment based on  Self-Supervised Learning and Knowledge Transfer",
    "abstract": "In this paper, we present a novel approach for text independent phone-to-audio alignment based on phoneme recognition, representation learning and knowledge transfer. Our method leverages a self-supervised model (wav2vec2) fine-tuned for phoneme recognition using a Connectionist Temporal Classification (CTC) loss, a dimension reduction model and a frame-level phoneme classifier trained thanks to forced-alignment labels (using Montreal Forced Aligner) to produce multi-lingual phonetic representations, thus requiring minimal additional training. We evaluate our model using synthetic native data from the TIMIT dataset and the SCRIBE dataset for American and British English, respectively. Our proposed model outperforms the state-of-the-art (charsiu) in statistical metrics and has applications in language learning and speech processing systems. We leave experiments on other languages for future work but the design of the system makes it easily adaptable to other languages. ",
    "url": "https://arxiv.org/abs/2405.02124",
    "authors": [
      "No\u00e9 Tits",
      "Prernna Bhatnagar",
      "Thierry Dutoit"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02131",
    "title": "Physics-informed generative neural networks for RF propagation  prediction with application to indoor body perception",
    "abstract": "Electromagnetic (EM) body models designed to predict Radio-Frequency (RF) propagation are time-consuming methods which prevent their adoption in strict real-time computational imaging problems, such as human body localization and sensing. Physics-informed Generative Neural Network (GNN) models have been recently proposed to reproduce EM effects, namely to simulate or reconstruct missing data or samples by incorporating relevant EM principles and constraints. The paper discusses a Variational Auto-Encoder (VAE) model which is trained to reproduce the effects of human motions on the EM field and incorporate EM body diffraction principles. Proposed physics-informed generative neural network models are verified against both classical diffraction-based EM tools and full-wave EM body simulations. ",
    "url": "https://arxiv.org/abs/2405.02131",
    "authors": [
      "Federica Fieramosca",
      "Vittorio Rampa",
      "Michele D'Amico",
      "Stefano Savazzi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2405.02188",
    "title": "Optimistic Regret Bounds for Online Learning in Adversarial Markov  Decision Processes",
    "abstract": "The Adversarial Markov Decision Process (AMDP) is a learning framework that deals with unknown and varying tasks in decision-making applications like robotics and recommendation systems. A major limitation of the AMDP formalism, however, is pessimistic regret analysis results in the sense that although the cost function can change from one episode to the next, the evolution in many settings is not adversarial. To address this, we introduce and study a new variant of AMDP, which aims to minimize regret while utilizing a set of cost predictors. For this setting, we develop a new policy search method that achieves a sublinear optimistic regret with high probability, that is a regret bound which gracefully degrades with the estimation power of the cost predictors. Establishing such optimistic regret bounds is nontrivial given that (i) as we demonstrate, the existing importance-weighted cost estimators cannot establish optimistic bounds, and (ii) the feedback model of AMDP is different (and more realistic) than the existing optimistic online learning works. Our result, in particular, hinges upon developing a novel optimistically biased cost estimator that leverages cost predictors and enables a high-probability regret analysis without imposing restrictive assumptions. We further discuss practical extensions of the proposed scheme and demonstrate its efficacy numerically. ",
    "url": "https://arxiv.org/abs/2405.02188",
    "authors": [
      "Sang Bin Moon",
      "Abolfazl Hashemi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02201",
    "title": "Regularized Q-learning through Robust Averaging",
    "abstract": "We propose a new Q-learning variant, called 2RA Q-learning, that addresses some weaknesses of existing Q-learning methods in a principled manner. One such weakness is an underlying estimation bias which cannot be controlled and often results in poor performance. We propose a distributionally robust estimator for the maximum expected value term, which allows us to precisely control the level of estimation bias introduced. The distributionally robust estimator admits a closed-form solution such that the proposed algorithm has a computational cost per iteration comparable to Watkins' Q-learning. For the tabular case, we show that 2RA Q-learning converges to the optimal policy and analyze its asymptotic mean-squared error. Lastly, we conduct numerical experiments for various settings, which corroborate our theoretical findings and indicate that 2RA Q-learning often performs better than existing methods. ",
    "url": "https://arxiv.org/abs/2405.02201",
    "authors": [
      "Peter Schmitt-F\u00f6rster",
      "Tobias Sutter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.02231",
    "title": "Efficient spline orthogonal basis for representation of density  functions",
    "abstract": "Probability density functions form a specific class of functional data objects with intrinsic properties of scale invariance and relative scale characterized by the unit integral constraint. The Bayes spaces methodology respects their specific nature, and the centred log-ratio transformation enables processing such functional data in the standard Lebesgue space of square-integrable functions. As the data representing densities are frequently observed in their discrete form, the focus has been on their spline representation. Therefore, the crucial step in the approximation is to construct a proper spline basis reflecting their specific properties. Since the centred log-ratio transformation forms a subspace of functions with a zero integral constraint, the standard $B$-spline basis is no longer suitable. Recently, a new spline basis incorporating this zero integral property, called $Z\\!B$-splines, was developed. However, this basis does not possess the orthogonal property which is beneficial from computational and application point of view. As a result of this paper, we describe an efficient method for constructing an orthogonal $Z\\!B$-splines basis, called $Z\\!B$-splinets. The advantages of the $Z\\!B$-splinet approach are foremost a computational efficiency and locality of basis supports that is desirable for data interpretability, e.g. in the context of functional principal component analysis. The proposed approach is demonstrated on an empirical demographic dataset. ",
    "url": "https://arxiv.org/abs/2405.02231",
    "authors": [
      "Jana Burkotov\u00e1",
      "Ivana Pavl\u016f",
      "Hiba Nassar",
      "Jitka Machalov\u00e1",
      "Karel Hron"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2102.10156",
    "title": "Learning to Persuade on the Fly: Robustness Against Ignorance",
    "abstract": " Comments: Accepted at Operations Research. Preliminary version appeared as an extended abstract in EC 2021 ",
    "url": "https://arxiv.org/abs/2102.10156",
    "authors": [
      "You Zu",
      "Krishnamurthy Iyer",
      "Haifeng Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2110.00744",
    "title": "Random Subgraph Detection Using Queries",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2110.00744",
    "authors": [
      "Wasim Huleihel",
      "Arya Mazumdar",
      "Soumyabrata Pal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2201.01288",
    "title": "Automated Graph Machine Learning: Approaches, Libraries, Benchmarks and  Directions",
    "abstract": " Comments: 20 pages, 4 figures. arXiv admin note: text overlap with arXiv:2103.00742 ",
    "url": "https://arxiv.org/abs/2201.01288",
    "authors": [
      "Xin Wang",
      "Ziwei Zhang",
      "Haoyang Li",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.14682",
    "title": "Towards Unconstrained Audio Splicing Detection and Localization with  Neural Networks",
    "abstract": " Comments: Published at MMFORWILD 2022, ICPR Workshops - Code: this https URL . International Conference on Pattern Recognition. Cham: Springer Nature Switzerland, 2022 ",
    "url": "https://arxiv.org/abs/2207.14682",
    "authors": [
      "Denise Moussa",
      "Germans Hirsch",
      "Christian Riess"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.03990",
    "title": "Weisfeiler-Lehman goes Dynamic: An Analysis of the Expressive Power of  Graph Neural Networks for Attributed and Dynamic Graphs",
    "abstract": " Title: Weisfeiler-Lehman goes Dynamic: An Analysis of the Expressive Power of  Graph Neural Networks for Attributed and Dynamic Graphs ",
    "url": "https://arxiv.org/abs/2210.03990",
    "authors": [
      "Silvia Beddar-Wiesing",
      "Giuseppe Alessio D'Inverno",
      "Caterina Graziani",
      "Veronica Lachi",
      "Alice Moallemy-Oureh",
      "Franco Scarselli",
      "Josephine Maria Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.03865",
    "title": "Contact graphs of boxes with unidirectional contacts",
    "abstract": " Comments: Minor change ",
    "url": "https://arxiv.org/abs/2301.03865",
    "authors": [
      "Daniel Gon\u00e7alves",
      "Vincent Limouzy",
      "Pascal Ochem"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2301.07281",
    "title": "Detecting and Ranking Causal Anomalies in End-to-End Complex System",
    "abstract": " Title: Detecting and Ranking Causal Anomalies in End-to-End Complex System ",
    "url": "https://arxiv.org/abs/2301.07281",
    "authors": [
      "Ching Chang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12809",
    "title": "The Hidden Power of Pure 16-bit Floating-Point Neural Networks",
    "abstract": " Title: The Hidden Power of Pure 16-bit Floating-Point Neural Networks ",
    "url": "https://arxiv.org/abs/2301.12809",
    "authors": [
      "Juyoung Yun",
      "Byungkon Kang",
      "Zhoulai Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2302.00890",
    "title": "Neural Common Neighbor with Completion for Link Prediction",
    "abstract": " Comments: ICLR 2024 ",
    "url": "https://arxiv.org/abs/2302.00890",
    "authors": [
      "Xiyuan Wang",
      "Haotong Yang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.10396",
    "title": "Towards Diverse Binary Segmentation via A Simple yet General Gated  Network",
    "abstract": " Comments: Accepted by IJCV 2024 ",
    "url": "https://arxiv.org/abs/2303.10396",
    "authors": [
      "Xiaoqi Zhao",
      "Youwei Pang",
      "Lihe Zhang",
      "Huchuan Lu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03688",
    "title": "Graph Parameters, Universal Obstructions, and WQO",
    "abstract": " Title: Graph Parameters, Universal Obstructions, and WQO ",
    "url": "https://arxiv.org/abs/2304.03688",
    "authors": [
      "Christophe Paul",
      "Evangelos Protopapas",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.06058",
    "title": "Compressing neural network by tensor network with exponentially fewer  variational parameters",
    "abstract": " Comments: 6 pages, 3 figures for the main text and 3 pages for the appendices ",
    "url": "https://arxiv.org/abs/2305.06058",
    "authors": [
      "Yong Qing",
      "Ke Li",
      "Peng-Fei Zhou",
      "Shi-Ju Ran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.06630",
    "title": "Predictive change point detection for heterogeneous data",
    "abstract": " Title: Predictive change point detection for heterogeneous data ",
    "url": "https://arxiv.org/abs/2305.06630",
    "authors": [
      "Anna-Christina Glock",
      "Florian Sobieczky",
      "Johannes F\u00fcrnkranz",
      "Peter Filzmoser",
      "Martin Jech"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06999",
    "title": "Temporal Reachability Dominating Sets: contagion in temporal graphs",
    "abstract": " Comments: 38 pages, 17 figures ",
    "url": "https://arxiv.org/abs/2306.06999",
    "authors": [
      "David C. Kutner",
      "Laura Larios-Jones"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2310.05336",
    "title": "GReAT: A Graph Regularized Adversarial Training Method",
    "abstract": " Comments: 25 pages including references. 7 figures and 6 tables ",
    "url": "https://arxiv.org/abs/2310.05336",
    "authors": [
      "Samet Bayram",
      "Kenneth Barner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.11884",
    "title": "From Neural Activations to Concepts: A Survey on Explaining Concepts in  Neural Networks",
    "abstract": " Comments: Accepted in Neurosymbolic Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2310.11884",
    "authors": [
      "Jae Hee Lee",
      "Sergio Lanza",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.04037",
    "title": "Causal Discovery Under Local Privacy",
    "abstract": " Title: Causal Discovery Under Local Privacy ",
    "url": "https://arxiv.org/abs/2311.04037",
    "authors": [
      "R\u016bta Binkyt\u0117",
      "Carlos Pinz\u00f3n",
      "Szilvia Lesty\u00e1n",
      "Kangsoo Jung",
      "H\u00e9ber H. Arcolezi",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.09047",
    "title": "6G Non-Terrestrial Networks Enabled Low-Altitude Economy: Opportunities  and Challenges",
    "abstract": " Comments: This paper has been submitted to IEEE for possible publication ",
    "url": "https://arxiv.org/abs/2311.09047",
    "authors": [
      "Yihang Jiang",
      "Xiaoyang Li",
      "Guangxu Zhu",
      "Hang Li",
      "Jing Deng",
      "Kaifeng Han",
      "Chao Shen",
      "Qingjiang Shi",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.11871",
    "title": "Training robust and generalizable quantum models",
    "abstract": " Title: Training robust and generalizable quantum models ",
    "url": "https://arxiv.org/abs/2311.11871",
    "authors": [
      "Julian Berberich",
      "Daniel Fink",
      "Daniel Pranji\u0107",
      "Christian Tutschku",
      "Christian Holm"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.16834",
    "title": "FocusLearn: Fully-Interpretable, High-Performance Modular Neural  Networks for Time Series",
    "abstract": " Title: FocusLearn: Fully-Interpretable, High-Performance Modular Neural  Networks for Time Series ",
    "url": "https://arxiv.org/abs/2311.16834",
    "authors": [
      "Qiqi Su",
      "Christos Kloukinas",
      "Artur d'Avila Garcez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.03682",
    "title": "What Planning Problems Can A Relational Neural Network Solve?",
    "abstract": " Comments: NeurIPS 2023 (Spotlight). Project page: this https URL ",
    "url": "https://arxiv.org/abs/2312.03682",
    "authors": [
      "Jiayuan Mao",
      "Tom\u00e1s Lozano-P\u00e9rez",
      "Joshua B. Tenenbaum",
      "Leslie Pack Kaelbling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.10314",
    "title": "LangProp: A code optimization framework using Large Language Models  applied to driving",
    "abstract": " Title: LangProp: A code optimization framework using Large Language Models  applied to driving ",
    "url": "https://arxiv.org/abs/2401.10314",
    "authors": [
      "Shu Ishida",
      "Gianluca Corrado",
      "George Fedoseev",
      "Hudson Yeo",
      "Lloyd Russell",
      "Jamie Shotton",
      "Jo\u00e3o F. Henriques",
      "Anthony Hu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.03015",
    "title": "Open-separating dominating codes in graphs",
    "abstract": " Title: Open-separating dominating codes in graphs ",
    "url": "https://arxiv.org/abs/2402.03015",
    "authors": [
      "Dipayan Chakraborty",
      "Annegret K. Wagler"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2402.09330",
    "title": "3D-based RNA function prediction tools in rnaglib",
    "abstract": " Title: 3D-based RNA function prediction tools in rnaglib ",
    "url": "https://arxiv.org/abs/2402.09330",
    "authors": [
      "Carlos Oliver",
      "Vincent Mallet",
      "J\u00e9r\u00f4me Waldisp\u00fchl"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11319",
    "title": "Hysteresis Compensation of Flexible Continuum Manipulator using RGBD  Sensing and Temporal Convolutional Network",
    "abstract": " Comments: 8 pages, 11 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2402.11319",
    "authors": [
      "Junhyun Park",
      "Seonghyeok Jang",
      "Hyojae Park",
      "Seongjun Bae",
      "Minho Hwang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.19379",
    "title": "Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Rival  Human Crowd Accuracy",
    "abstract": " Comments: 20 pages; 13 visualizations (nine figures, four tables) ",
    "url": "https://arxiv.org/abs/2402.19379",
    "authors": [
      "Philipp Schoenegger",
      "Indre Tuminauskaite",
      "Peter S. Park",
      "Philip E. Tetlock"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.00462",
    "title": "LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues",
    "abstract": " Comments: Accepted at NAACL SRW 2024 ",
    "url": "https://arxiv.org/abs/2403.00462",
    "authors": [
      "Joe Stacey",
      "Jianpeng Cheng",
      "John Torr",
      "Tristan Guigue",
      "Joris Driesen",
      "Alexandru Coca",
      "Mark Gaynor",
      "Anders Johannsen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.07507",
    "title": "Reconstructions of Jupiter's magnetic field using physics informed  neural networks",
    "abstract": " Title: Reconstructions of Jupiter's magnetic field using physics informed  neural networks ",
    "url": "https://arxiv.org/abs/2403.07507",
    "authors": [
      "Philip W. Livermore",
      "Leyuan Wu",
      "Longwei Chen",
      "Sjoerd A.L. de Ridder"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10659",
    "title": "Towards Practical Fabrication Stage Attacks Using Interrupt-Resilient  Hardware Trojans",
    "abstract": " Title: Towards Practical Fabrication Stage Attacks Using Interrupt-Resilient  Hardware Trojans ",
    "url": "https://arxiv.org/abs/2403.10659",
    "authors": [
      "Athanasios Moschos",
      "Fabian Monrose",
      "Angelos D. Keromytis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.12619",
    "title": "Detection of Malicious Agents in Social Learning",
    "abstract": " Title: Detection of Malicious Agents in Social Learning ",
    "url": "https://arxiv.org/abs/2403.12619",
    "authors": [
      "Valentina Shumovskaia",
      "Mert Kayaalp",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2404.00462",
    "title": "Zero-shot Safety Prediction for Autonomous Robots with Foundation World  Models",
    "abstract": " Comments: Presented at the Back to the Future-Robot Learning Going Probabilistic Workshop, co-located with ICRA 2024. this https URL ",
    "url": "https://arxiv.org/abs/2404.00462",
    "authors": [
      "Zhenjiang Mao",
      "Siqi Dai",
      "Yuang Geng",
      "Ivan Ruchkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.05688",
    "title": "David and Goliath: An Empirical Evaluation of Attacks and Defenses for  QNNs at the Deep Edge",
    "abstract": " Title: David and Goliath: An Empirical Evaluation of Attacks and Defenses for  QNNs at the Deep Edge ",
    "url": "https://arxiv.org/abs/2404.05688",
    "authors": [
      "Miguel Costa",
      "Sandro Pinto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2404.16051",
    "title": "TimeFlows: Visualizing Process Chronologies from Vast Collections of  Heterogeneous Information Objects",
    "abstract": " Comments: 16 pages, accepted at RCIS 2024 ",
    "url": "https://arxiv.org/abs/2404.16051",
    "authors": [
      "Max Lonysa Muller",
      "Erik Saaman",
      "Jan Martijn E. M. van der Werf",
      "Charles Jeurgens",
      "Hajo A. Reijers"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2404.16549",
    "title": "Application of Long-Short Term Memory and Convolutional Neural Networks  for Real-Time Bridge Scour Prediction",
    "abstract": " Title: Application of Long-Short Term Memory and Convolutional Neural Networks  for Real-Time Bridge Scour Prediction ",
    "url": "https://arxiv.org/abs/2404.16549",
    "authors": [
      "Tahrima Hashem",
      "Negin Yousefpour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2404.17129",
    "title": "Process Mining Embeddings: Learning Vector Representations for Petri  Nets",
    "abstract": " Title: Process Mining Embeddings: Learning Vector Representations for Petri  Nets ",
    "url": "https://arxiv.org/abs/2404.17129",
    "authors": [
      "Juan G. Colonna",
      "Ahmed A. Fares",
      "M\u00e1rcio Duarte",
      "Ricardo Sousa"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.17699",
    "title": "Deep Learning for Melt Pool Depth Contour Prediction From Surface  Thermal Images via Vision Transformers",
    "abstract": " Title: Deep Learning for Melt Pool Depth Contour Prediction From Surface  Thermal Images via Vision Transformers ",
    "url": "https://arxiv.org/abs/2404.17699",
    "authors": [
      "Francis Ogoke",
      "Peter Myung-Won Pak",
      "Alexander Myers",
      "Guadalupe Quirarte",
      "Jack Beuth",
      "Jonathan Malen",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.17862",
    "title": "Revisiting Multimodal Emotion Recognition in Conversation from the  Perspective of Graph Spectrum",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2404.17862",
    "authors": [
      "Tao Meng",
      "Fuchen Zhang",
      "Yuntao Shou",
      "Wei Ai",
      "Nan Yin",
      "Keqin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2404.18381",
    "title": "Object Registration in Neural Fields",
    "abstract": " Comments: Accepted to ICRA 2024 RoboNeRF workshop. 5 pages, 10 figures. arXiv admin note: substantial text overlap with arXiv:2402.09722 ",
    "url": "https://arxiv.org/abs/2404.18381",
    "authors": [
      "David Hall",
      "Stephen Hausler",
      "Sutharsan Mahendren",
      "Peyman Moghadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.00711",
    "title": "Fake Artificial Intelligence Generated Contents (FAIGC): A Survey of  Theories, Detection Methods, and Opportunities",
    "abstract": " Title: Fake Artificial Intelligence Generated Contents (FAIGC): A Survey of  Theories, Detection Methods, and Opportunities ",
    "url": "https://arxiv.org/abs/2405.00711",
    "authors": [
      "Xiaomin Yu",
      "Yezhaohui Wang",
      "Yanfang Chen",
      "Zhen Tao",
      "Dinghao Xi",
      "Shichao Song",
      "Simin Niu",
      "Zhiyu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2405.01031",
    "title": "The Privacy Power of Correlated Noise in Decentralized Learning",
    "abstract": " Comments: Accepted as conference paper at ICML 2024 ",
    "url": "https://arxiv.org/abs/2405.01031",
    "authors": [
      "Youssef Allouah",
      "Anastasia Koloskova",
      "Aymane El Firdoussi",
      "Martin Jaggi",
      "Rachid Guerraoui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2405.01196",
    "title": "Decoupling Feature Extraction and Classification Layers for Calibrated  Neural Networks",
    "abstract": " Title: Decoupling Feature Extraction and Classification Layers for Calibrated  Neural Networks ",
    "url": "https://arxiv.org/abs/2405.01196",
    "authors": [
      "Mikkel Jordahn",
      "Pablo M. Olmos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  }
]