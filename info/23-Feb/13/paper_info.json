[
  {
    "id": "arXiv:2302.04907",
    "title": "Binarized Neural Machine Translation",
    "abstract": "The rapid scaling of language models is motivating research using low-bitwidth quantization. In this work, we propose a novel binarization technique for Transformers applied to machine translation (BMT), the first of its kind. We identify and address the problem of inflated dot-product variance when using one-bit weights and activations. Specifically, BMT leverages additional LayerNorms and residual connections to improve binarization quality. Experiments on the WMT dataset show that a one-bit weight-only Transformer can achieve the same quality as a float one, while being 16x smaller in size. One-bit activations incur varying degrees of quality drop, but mitigated by the proposed architectural changes. We further conduct a scaling law study using production-scale translation datasets, which shows that one-bit weight Transformers scale and generalize well in both in-domain and out-of-domain settings. Implementation in JAX/Flax will be open sourced. ",
    "url": "https://arxiv.org/abs/2302.04907",
    "authors": [
      "Yichi Zhang",
      "Ankush Garg",
      "Yuan Cao",
      "\u0141ukasz Lew",
      "Behrooz Ghorbani",
      "Zhiru Zhang",
      "Orhan Firat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04915",
    "title": "Experimental Demonstration of Network Convergence with Coherent and  AnalogRadio-over-Fibre signals For Densified 5.5G/6G Small Cell Networks",
    "abstract": "In this work we analyse and demonstrate the coexistence of digital coherent and analogue radio over fibre signals over an access-metro transmission network and field fibre. We analyse how the spectral proximity of the two signals and the non-ideal filter alignment of typical telecomms-grade ROADMs affect the signal performance. Our results show that coexistence is indeed possible, although performance deteriorates with the increase in number of ROADMs in the network topology. Thus, while todays access-metro networks will be able to support future 5.5 and 6G cell densification operating at mmWave and THz frequency, using spectral efficient analogue radio over fibre transmission, there will be trade-offs to be considered. In our experiment setup, we show that the limit for ARoF accessible performance is reached after transmission over 3 ROADMs and a total of 49 km of fibre. ",
    "url": "https://arxiv.org/abs/2302.04915",
    "authors": [
      "Frank Slyne",
      "Colm Browning",
      "Amol Delmade",
      "Liam P. Barry",
      "Marco Ruffini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2302.04917",
    "title": "ChemVise: Maximizing Out-of-Distribution Chemical Detection with the  Novel Application of Zero-Shot Learning",
    "abstract": "Accurate chemical sensors are vital in medical, military, and home safety applications. Training machine learning models to be accurate on real world chemical sensor data requires performing many diverse, costly experiments in controlled laboratory settings to create a data set. In practice even expensive, large data sets may be insufficient for generalization of a trained model to a real-world testing distribution. Rather than perform greater numbers of experiments requiring exhaustive mixtures of chemical analytes, this research proposes learning approximations of complex exposures from training sets of simple ones by using single-analyte exposure signals as building blocks of a multiple-analyte space. We demonstrate this approach to synthetic sensor responses surprisingly improves the detection of out-of-distribution obscured chemical analytes. Further, we pair these synthetic signals to targets in an information-dense representation space utilizing a large corpus of chemistry knowledge. Through utilization of a semantically meaningful analyte representation spaces along with synthetic targets we achieve rapid analyte classification in the presence of obscurants without corresponding obscured-analyte training data. Transfer learning for supervised learning with molecular representations makes assumptions about the input data. Instead, we borrow from the natural language and natural image processing literature for a novel approach to chemical sensor signal classification using molecular semantics for arbitrary chemical sensor hardware designs. ",
    "url": "https://arxiv.org/abs/2302.04917",
    "authors": [
      "Alexander M. Moore",
      "Randy C. Paffenroth",
      "Ken T. Ngo",
      "Joshua R. Uzarski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04944",
    "title": "Learning Complex Teamwork Tasks using a Sub-task Curriculum",
    "abstract": "Training a team to complete a complex task via multi-agent reinforcement learning can be difficult due to challenges such as policy search in a large policy space, and non-stationarity caused by mutually adapting agents. To facilitate efficient learning of complex multi-agent tasks, we propose an approach which uses an expert-provided curriculum of simpler multi-agent sub-tasks. In each sub-task of the curriculum, a subset of the entire team is trained to acquire sub-task-specific policies. The sub-teams are then merged and transferred to the target task, where their policies are collectively fined tuned to solve the more complex target task. We present MEDoE, a flexible method which identifies situations in the target task where each agent can use its sub-task-specific skills, and uses this information to modulate hyperparameters for learning and exploration during the fine-tuning process. We compare MEDoE to multi-agent reinforcement learning baselines that train from scratch in the full task, and with na\\\"ive applications of standard multi-agent reinforcement learning techniques for fine-tuning. We show that MEDoE outperforms baselines which train from scratch or use na\\\"ive fine-tuning approaches, requiring significantly fewer total training timesteps to solve a range of complex teamwork tasks. ",
    "url": "https://arxiv.org/abs/2302.04944",
    "authors": [
      "Elliot Fosong",
      "Arrasy Rahman",
      "Ignacio Carlucho",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04954",
    "title": "Mixed formulation of physics-informed neural networks for  thermo-mechanically coupled systems and heterogeneous domains",
    "abstract": "Deep learning methods find a solution to a boundary value problem by defining loss functions of neural networks based on governing equations, boundary conditions, and initial conditions. Furthermore, the authors show that when it comes to many engineering problems, designing the loss functions based on first-order derivatives results in much better accuracy, especially when there is heterogeneity and variable jumps in the domain \\cite{REZAEI2022PINN}. The so-called mixed formulation for PINN is applied to basic engineering problems such as the balance of linear momentum and diffusion problems. In this work, the proposed mixed formulation is further extended to solve multi-physical problems. In particular, we focus on a stationary thermo-mechanically coupled system of equations that can be utilized in designing the microstructure of advanced materials. First, sequential unsupervised training, and second, fully coupled unsupervised learning are discussed. The results of each approach are compared in terms of accuracy and corresponding computational cost. Finally, the idea of transfer learning is employed by combining data and physics to address the capability of the network to predict the response of the system for unseen cases. The outcome of this work will be useful for many other engineering applications where DL is employed on multiple coupled systems of equations. ",
    "url": "https://arxiv.org/abs/2302.04954",
    "authors": [
      "Ali Harandi",
      "Ahmad Moeineddin",
      "Michael Kaliske",
      "Stefanie Reese",
      "Shahed Rezaei"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04959",
    "title": "Hypernetworks build Implicit Neural Representations of Sounds",
    "abstract": "Implicit Neural Representations (INRs) are nowadays used to represent multimedia signals across various real-life applications, including image super-resolution, image compression, or 3D rendering. Existing methods that leverage INRs are predominantly focused on visual data, as their application to other modalities, such as audio, is nontrivial due to the inductive biases present in architectural attributes of image-based INR models. To address this limitation, we introduce HyperSound, the first meta-learning approach to produce INRs for audio samples that leverages hypernetworks to generalize beyond samples observed in training. Our approach reconstructs audio samples with quality comparable to other state-of-the-art models and provides a viable alternative to contemporary sound representations used in deep neural networks for audio processing, such as spectrograms. ",
    "url": "https://arxiv.org/abs/2302.04959",
    "authors": [
      "Filip Szatkowski",
      "Karol J. Piczak",
      "Przemts\u0142aw Spurek",
      "Jacek Tabor",
      "Tomasz Trzci\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.04977",
    "title": "Hyperparameter Search Is All You Need For Training-Agnostic Backdoor  Robustness",
    "abstract": "Commoditization and broad adoption of machine learning (ML) technologies expose users of these technologies to new security risks. Many models today are based on neural networks. Training and deploying these models for real-world applications involves complex hardware and software pipelines applied to training data from many sources. Models trained on untrusted data are vulnerable to poisoning attacks that introduce \"backdoor\" functionality. Compromising a fraction of the training data requires few resources from the attacker, but defending against these attacks is a challenge. Although there have been dozens of defenses proposed in the research literature, most of them are expensive to integrate or incompatible with the existing training pipelines. In this paper, we take a pragmatic, developer-centric view and show how practitioners can answer two actionable questions: (1) how robust is my model to backdoor poisoning attacks?, and (2) how can I make it more robust without changing the training pipeline? We focus on the size of the compromised subset of the training data as a universal metric. We propose an easy-to-learn primitive sub-task to estimate this metric, thus providing a baseline on backdoor poisoning. Next, we show how to leverage hyperparameter search - a tool that ML developers already extensively use - to balance the model's accuracy and robustness to poisoning, without changes to the training pipeline. We demonstrate how to use our metric to estimate the robustness of models to backdoor attacks. We then design, implement, and evaluate a multi-stage hyperparameter search method we call Mithridates that strengthens robustness by 3-5x with only a slight impact on the model's accuracy. We show that the hyperparameters found by our method increase robustness against multiple types of backdoor attacks and extend our method to AutoML and federated learning. ",
    "url": "https://arxiv.org/abs/2302.04977",
    "authors": [
      "Eugene Bagdasaryan",
      "Vitaly Shmatikov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04989",
    "title": "Causal Inference out of Control: Estimating the Steerability of  Consumption",
    "abstract": "Regulators and academics are increasingly interested in the causal effect that algorithmic actions of a digital platform have on consumption. We introduce a general causal inference problem we call the steerability of consumption that abstracts many settings of interest. Focusing on observational designs and exploiting the structure of the problem, we exhibit a set of assumptions for causal identifiability that significantly weaken the often unrealistic overlap assumptions of standard designs. The key novelty of our approach is to explicitly model the dynamics of consumption over time, viewing the platform as a controller acting on a dynamical system. From this dynamical systems perspective, we are able to show that exogenous variation in consumption and appropriately responsive algorithmic control actions are sufficient for identifying steerability of consumption. Our results illustrate the fruitful interplay of control theory and causal inference, which we illustrate with examples from econometrics, macroeconomics, and machine learning. ",
    "url": "https://arxiv.org/abs/2302.04989",
    "authors": [
      "Gary Cheng",
      "Moritz Hardt",
      "Celestine Mendler-D\u00fcnner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.04998",
    "title": "Neural Networks vs. Splines: Advances in Numerical Extruder Design",
    "abstract": "We present a novel application of neural networks to design improved mixing elements for single-screw extruders. Specifically, we propose to use neural networks in numerical shape optimization to parameterize geometries. Geometry parameterization is crucial in enabling efficient shape optimization as it allows for optimizing complex shapes using only a few design variables. Recent approaches often utilize CAD data in conjunction with spline-based methods where the spline's control points serve as design variables. Consequently, these approaches rely on the same design variables as specified by the human designer. While this choice is convenient, it either restricts the design to small modifications of given, initial design features - effectively prohibiting topological changes - or yields undesirably many design variables. In this work, we step away from CAD and spline-based approaches and construct an artificial, feature-dense yet low-dimensional optimization space using a generative neural network. Using the neural network for the geometry parameterization extends state-of-the-art methods in that the resulting design space is not restricted to user-prescribed modifications of certain basis shapes. Instead, within the same optimization space, we can interpolate between and explore seemingly unrelated designs. To show the performance of this new approach, we integrate the developed shape parameterization into our numerical design framework for dynamic mixing elements in plastics extrusion. Finally, we challenge the novel method in a competitive setting against current free-form deformation-based approaches and demonstrate the method's performance even at this early stage. ",
    "url": "https://arxiv.org/abs/2302.04998",
    "authors": [
      "Jaewook Lee",
      "Sebastian Hube",
      "Stefanie Elgeti"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2302.05008",
    "title": "Language-Aware Multilingual Machine Translation with Self-Supervised  Learning",
    "abstract": "Multilingual machine translation (MMT) benefits from cross-lingual transfer but is a challenging multitask optimization problem. This is partly because there is no clear framework to systematically learn language-specific parameters. Self-supervised learning (SSL) approaches that leverage large quantities of monolingual data (where parallel data is unavailable) have shown promise by improving translation performance as complementary tasks to the MMT task. However, jointly optimizing SSL and MMT tasks is even more challenging. In this work, we first investigate how to utilize intra-distillation to learn more *language-specific* parameters and then show the importance of these language-specific parameters. Next, we propose a novel but simple SSL task, concurrent denoising, that co-trains with the MMT task by concurrently denoising monolingual data on both the encoder and decoder. Finally, we apply intra-distillation to this co-training approach. Combining these two approaches significantly improves MMT performance, outperforming three state-of-the-art SSL methods by a large margin, e.g., 11.3\\% and 3.7\\% improvement on an 8-language and a 15-language benchmark compared with MASS, respectively ",
    "url": "https://arxiv.org/abs/2302.05008",
    "authors": [
      "Haoran Xu",
      "Jean Maillard",
      "Vedanuj Goswami"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.05009",
    "title": "Network Inspection Using Heterogeneous Sensors for Detecting Strategic  Attacks",
    "abstract": "We consider a two-player network inspection game, in which a defender allocates sensors with potentially heterogeneous detection capabilities in order to detect multiple attacks caused by a strategic attacker. The objective of the defender (resp. attacker) is to minimize (resp. maximize) the expected number of undetected attacks by selecting a potentially randomized inspection (resp. attack) strategy. We analytically characterize Nash equilibria of this large-scale zero-sum game when every vulnerable network component can be monitored from a unique sensor location. We then leverage our equilibrium analysis to design a heuristic solution approach based on minimum set covers for computing inspection strategies in general. Our computational results on a benchmark cyber-physical distribution network illustrate the performance and computational tractability of our solution approach. ",
    "url": "https://arxiv.org/abs/2302.05009",
    "authors": [
      "Bobak McCann",
      "Mathieu Dahan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.05015",
    "title": "Graph-Theoretic Analyses and Model Reduction for an Open Jackson  Queueing Network",
    "abstract": "A graph-theoretic analysis of the steady-state behavior of an open Jackson queueing network is developed. In particular, a number of queueing-network performance metrics are shown to exhibit a spatial dependence on local drivers (e.g. increments to local exogenous arrival rates), wherein the impacts fall off across graph cutsets away from a target queue. This graph-theoretic analysis is also used to motivate a structure-preserving model reduction algorithm, and an algorithm that exactly matches performance statistics of the original model is proposed. The graph-theoretic results and model-reduction method are evaluated via simulations of an example queueing-network model. ",
    "url": "https://arxiv.org/abs/2302.05015",
    "authors": [
      "Chenyan Zhu",
      "Sandip Roy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.05019",
    "title": "A Comprehensive Survey on Automatic Knowledge Graph Construction",
    "abstract": "Automatic knowledge graph construction aims to manufacture structured human knowledge. To this end, much effort has historically been spent extracting informative fact patterns from different data sources. However, more recently, research interest has shifted to acquiring conceptualized structured knowledge beyond informative data. In addition, researchers have also been exploring new ways of handling sophisticated construction tasks in diversified scenarios. Thus, there is a demand for a systematic review of paradigms to organize knowledge structures beyond data-level mentions. To meet this demand, we comprehensively survey more than 300 methods to summarize the latest developments in knowledge graph construction. A knowledge graph is built in three steps: knowledge acquisition, knowledge refinement, and knowledge evolution. The processes of knowledge acquisition are reviewed in detail, including obtaining entities with fine-grained types and their conceptual linkages to knowledge graphs; resolving coreferences; and extracting entity relationships in complex scenarios. The survey covers models for knowledge refinement, including knowledge graph completion, and knowledge fusion. Methods to handle knowledge evolution are also systematically presented, including condition knowledge acquisition, condition knowledge graph completion, and knowledge dynamic. We present the paradigms to compare the distinction among these methods along the axis of the data environment, motivation, and architecture. Additionally, we also provide briefs on accessible resources that can help readers to develop practical knowledge graph systems. The survey concludes with discussions on the challenges and possible directions for future exploration. ",
    "url": "https://arxiv.org/abs/2302.05019",
    "authors": [
      "Lingfeng Zhong",
      "Jia Wu",
      "Qian Li",
      "Hao Peng",
      "Xindong Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.05020",
    "title": "Impact of Code Language Models on Automated Program Repair",
    "abstract": "Automated program repair (APR) aims to help developers improve software reliability by generating patches for buggy programs. Although many code language models (CLM) are developed and effective in many software tasks such as code completion, there has been little comprehensive, in-depth work to evaluate CLMs' fixing capabilities and to fine-tune CLMs for the APR task. Firstly, this work is the first to evaluate ten CLMs on four APR benchmarks, which shows that surprisingly, the best CLM, as is, fixes 72% more bugs than the state-of-the-art deep-learning (DL)-based APR techniques. Secondly, one of the four APR benchmarks was created by us in this paper to avoid data leaking for a fair evaluation. Thirdly, it is the first work to fine-tune CLMs with APR training data, which shows that fine-tuning brings 31%-1,267% improvement to CLMs and enables them to fix 46%-164% more bugs than existing DL-based APR techniques. Fourthly, this work studies the impact of buggy lines, showing that CLMs, as is, cannot make good use of the buggy lines to fix bugs, yet fine-tuned CLMs could potentially over-rely on buggy lines. Lastly, this work analyzes the size, time, and memory efficiency of different CLMs. This work shows promising directions for the APR domain, such as fine-tuning CLMs with APR-specific designs, and also raises awareness of fair and comprehensive evaluations of CLMs and calls for more transparent reporting of open-source repositories used in the pre-training data to address the data leaking problem. ",
    "url": "https://arxiv.org/abs/2302.05020",
    "authors": [
      "Nan Jiang",
      "Kevin Liu",
      "Thibaud Lutellier",
      "Lin Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.05021",
    "title": "ShapeWordNet: An Interpretable Shapelet Neural Network for Physiological  Signal Classification",
    "abstract": "Physiological signals are high-dimensional time series of great practical values in medical and healthcare applications. However, previous works on its classification fail to obtain promising results due to the intractable data characteristics and the severe label sparsity issues. In this paper, we try to address these challenges by proposing a more effective and interpretable scheme tailored for the physiological signal classification task. Specifically, we exploit the time series shapelets to extract prominent local patterns and perform interpretable sequence discretization to distill the whole-series information. By doing so, the long and continuous raw signals are compressed into short and discrete token sequences, where both local patterns and global contexts are well preserved. Moreover, to alleviate the label sparsity issue, a multi-scale transformation strategy is adaptively designed to augment data and a cross-scale contrastive learning mechanism is accordingly devised to guide the model training. We name our method as ShapeWordNet and conduct extensive experiments on three real-world datasets to investigate its effectiveness. Comparative results show that our proposed scheme remarkably outperforms four categories of cutting-edge approaches. Visualization analysis further witnesses the good interpretability of the sequence discretization idea based on shapelets. ",
    "url": "https://arxiv.org/abs/2302.05021",
    "authors": [
      "Wenqiang He",
      "Mingyue Cheng",
      "Qi Liu",
      "Zhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05027",
    "title": "Deep Seam Prediction for Image Stitching Based on Selection Consistency  Loss",
    "abstract": "Image stitching is to construct panoramic images with wider field of vision (FOV) from some images captured from different viewing positions. To solve the problem of fusion ghosting in the stitched image, seam-driven methods avoid the misalignment area to fuse images by predicting the best seam. Currently, as standard tools of the OpenCV library, dynamic programming (DP) and GraphCut (GC) are still the only commonly used seam prediction methods despite the fact that they were both proposed two decades ago. However, GC can get excellent seam quality but poor real-time performance while DP method has good efficiency but poor seam quality. In this paper, we propose a deep learning based seam prediction method (DSeam) for the sake of high seam quality with high efficiency. To overcome the difficulty of the seam description in network and no GroundTruth for training we design a selective consistency loss combining the seam shape constraint and seam quality constraint to supervise the network learning. By the constraint of the selection of consistency loss, we implicitly defined the mask boundaries as seams and transform seam prediction into mask prediction. To our knowledge, the proposed DSeam is the first deep learning based seam prediction method for image stitching. Extensive experimental results well demonstrate the superior performance of our proposed Dseam method which is 15 times faster than the classic GC seam prediction method in OpenCV 2.4.9 with similar seam quality. ",
    "url": "https://arxiv.org/abs/2302.05027",
    "authors": [
      "Senmao Cheng",
      "Fan Yang",
      "Zhi Chen",
      "Nanjun Yuan",
      "Wenbin Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05043",
    "title": "A Review of Predictive and Contrastive Self-supervised Learning for  Medical Images",
    "abstract": "Over the last decade, supervised deep learning on manually annotated big data has been progressing significantly on computer vision tasks. But the application of deep learning in medical image analysis was limited by the scarcity of high-quality annotated medical imaging data. An emerging solution is self-supervised learning (SSL), among which contrastive SSL is the most successful approach to rivalling or outperforming supervised learning. This review investigates several state-of-the-art contrastive SSL algorithms originally on natural images as well as their adaptations for medical images, and concludes by discussing recent advances, current limitations, and future directions in applying contrastive SSL in the medical domain. ",
    "url": "https://arxiv.org/abs/2302.05043",
    "authors": [
      "Wei-Chien Wang",
      "Euijoon Ahn",
      "Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05044",
    "title": "Toward Degree Bias in Embedding-Based Knowledge Graph Completion",
    "abstract": "A fundamental task for knowledge graphs (KGs) is knowledge graph completion (KGC). It aims to predict unseen edges by learning representations for all the entities and relations in a KG. A common concern when learning representations on traditional graphs is degree bias. It can affect graph algorithms by learning poor representations for lower-degree nodes, often leading to low performance on such nodes. However, there has been limited research on whether there exists degree bias for embedding-based KGC and how such bias affects the performance of KGC. In this paper, we validate the existence of degree bias in embedding-based KGC and identify the key factor to degree bias. We then introduce a novel data augmentation method, KG-Mixup, to generate synthetic triples to mitigate such bias. Extensive experiments have demonstrated that our method can improve various embedding-based KGC methods and outperform other methods tackling the bias problem on multiple benchmark datasets. ",
    "url": "https://arxiv.org/abs/2302.05044",
    "authors": [
      "Harry Shomer",
      "Wei Jin",
      "Wentao Wang",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05045",
    "title": "Exploiting Sparsity in Pruned Neural Networks to Optimize Large Model  Training",
    "abstract": "Parallel training of neural networks at scale is challenging due to significant overheads arising from communication. Recently, deep learning researchers have developed a variety of pruning algorithms that are capable of pruning (i.e. setting to zero) 80-90% of the parameters in a neural network to yield sparse subnetworks that equal the accuracy of the unpruned parent network. In this work, we propose a novel approach that exploits these sparse subnetworks to optimize the memory utilization and communication in two popular algorithms for parallel deep learning namely -- data and inter-layer parallelism. We integrate our approach into AxoNN, a highly scalable framework for parallel deep learning that relies on data and inter-layer parallelism, and demonstrate the reduction in communication times and memory utilization. On 512 NVIDIA V100 GPUs, our optimizations reduce the memory consumption of a 2.7 billion parameter model by 74%, and the total communication times by 40%, thus providing an overall speedup of 34% over AxoNN, 32% over DeepSpeed-3D and 46% over Sputnik, a sparse matrix computation baseline. ",
    "url": "https://arxiv.org/abs/2302.05045",
    "authors": [
      "Siddharth Singh",
      "Abhinav Bhatele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2302.05083",
    "title": "DRGCN: Dynamic Evolving Initial Residual for Deep Graph Convolutional  Networks",
    "abstract": "Graph convolutional networks (GCNs) have been proved to be very practical to handle various graph-related tasks. It has attracted considerable research interest to study deep GCNs, due to their potential superior performance compared with shallow ones. However, simply increasing network depth will, on the contrary, hurt the performance due to the over-smoothing problem. Adding residual connection is proved to be effective for learning deep convolutional neural networks (deep CNNs), it is not trivial when applied to deep GCNs. Recent works proposed an initial residual mechanism that did alleviate the over-smoothing problem in deep GCNs. However, according to our study, their algorithms are quite sensitive to different datasets. In their setting, the personalization (dynamic) and correlation (evolving) of how residual applies are ignored. To this end, we propose a novel model called Dynamic evolving initial Residual Graph Convolutional Network (DRGCN). Firstly, we use a dynamic block for each node to adaptively fetch information from the initial representation. Secondly, we use an evolving block to model the residual evolving pattern between layers. Our experimental results show that our model effectively relieves the problem of over-smoothing in deep GCNs and outperforms the state-of-the-art (SOTA) methods on various benchmark datasets. Moreover, we develop a mini-batch version of DRGCN which can be applied to large-scale data. Coupling with several fair training techniques, our model reaches new SOTA results on the large-scale ogbn-arxiv dataset of Open Graph Benchmark (OGB). Our reproducible code is available on GitHub. ",
    "url": "https://arxiv.org/abs/2302.05083",
    "authors": [
      "Lei Zhang",
      "Xiaodong Yan",
      "Jianshan He",
      "Ruopeng Li",
      "Wei Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05086",
    "title": "Making Substitute Models More Bayesian Can Enhance Transferability of  Adversarial Examples",
    "abstract": "The transferability of adversarial examples across deep neural networks (DNNs) is the crux of many black-box attacks. Many prior efforts have been devoted to improving the transferability via increasing the diversity in inputs of some substitute models. In this paper, by contrast, we opt for the diversity in substitute models and advocate to attack a Bayesian model for achieving desirable transferability. Deriving from the Bayesian formulation, we develop a principled strategy for possible finetuning, which can be combined with many off-the-shelf Gaussian posterior approximations over DNN parameters. Extensive experiments have been conducted to verify the effectiveness of our method, on common benchmark datasets, and the results demonstrate that our method outperforms recent state-of-the-arts by large margins (roughly 19% absolute increase in average attack success rate on ImageNet), and, by combining with these recent methods, further performance gain can be obtained. Our code: https://github.com/qizhangli/MoreBayesian-attack. ",
    "url": "https://arxiv.org/abs/2302.05086",
    "authors": [
      "Qizhang Li",
      "Yiwen Guo",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05093",
    "title": "Unified Vision-Language Representation Modeling for E-Commerce  Same-Style Products Retrieval",
    "abstract": "Same-style products retrieval plays an important role in e-commerce platforms, aiming to identify the same products which may have different text descriptions or images. It can be used for similar products retrieval from different suppliers or duplicate products detection of one supplier. Common methods use the image as the detected object, but they only consider the visual features and overlook the attribute information contained in the textual descriptions, and perform weakly for products in image less important industries like machinery, hardware tools and electronic component, even if an additional text matching module is added. In this paper, we propose a unified vision-language modeling method for e-commerce same-style products retrieval, which is designed to represent one product with its textual descriptions and visual contents. It contains one sampling skill to collect positive pairs from user click log with category and relevance constrained, and a novel contrastive loss unit to model the image, text, and image+text representations into one joint embedding space. It is capable of cross-modal product-to-product retrieval, as well as style transfer and user-interactive search. Offline evaluations on annotated data demonstrate its superior retrieval performance, and online testings show it can attract more clicks and conversions. Moreover, this model has already been deployed online for similar products retrieval in alibaba.com, the largest B2B e-commerce platform in the world. ",
    "url": "https://arxiv.org/abs/2302.05093",
    "authors": [
      "Ben Chen",
      "Linbo Jin",
      "Xinxin Wang",
      "Dehong Gao",
      "Wen Jiang",
      "Wei Ning"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.05096",
    "title": "Selective In-Context Data Augmentation for Intent Detection using  Pointwise V-Information",
    "abstract": "This work focuses on in-context data augmentation for intent detection. Having found that augmentation via in-context prompting of large pre-trained language models (PLMs) alone does not improve performance, we introduce a novel approach based on PLMs and pointwise V-information (PVI), a metric that can measure the usefulness of a datapoint for training a model. Our method first fine-tunes a PLM on a small seed of training data and then synthesizes new datapoints - utterances that correspond to given intents. It then employs intent-aware filtering, based on PVI, to remove datapoints that are not helpful to the downstream intent classifier. Our method is thus able to leverage the expressive power of large language models to produce diverse training data. Empirical results demonstrate that our method can produce synthetic training data that achieve state-of-the-art performance on three challenging intent detection datasets under few-shot settings (1.28% absolute improvement in 5-shot and 1.18% absolute in 10-shot, on average) and perform on par with the state-of-the-art in full-shot settings (within 0.01% absolute, on average). ",
    "url": "https://arxiv.org/abs/2302.05096",
    "authors": [
      "Yen-Ting Lin",
      "Alexandros Papangelis",
      "Seokhwan Kim",
      "Sungjin Lee",
      "Devamanyu Hazarika",
      "Mahdi Namazifar",
      "Di Jin",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.05097",
    "title": "CCDN: Checkerboard Corner Detection Network for Robust Camera  Calibration",
    "abstract": "Aiming to improve the checkerboard corner detection robustness against the images with poor quality, such as lens distortion, extreme poses, and noise, we propose a novel detection algorithm which can maintain high accuracy on inputs under multiply scenarios without any prior knowledge of the checkerboard pattern. This whole algorithm includes a checkerboard corner detection network and some post-processing techniques. The network model is a fully convolutional network with improvements of loss function and learning rate, which can deal with the images of arbitrary size and produce correspondingly-sized output with a corner score on each pixel by efficient inference and learning. Besides, in order to remove the false positives, we employ three post-processing techniques including threshold related to maximum response, non-maximum suppression, and clustering. Evaluations on two different datasets show its superior robustness, accuracy and wide applicability in quantitative comparisons with the state-of-the-art methods, like MATE, ChESS, ROCHADE and OCamCalib. ",
    "url": "https://arxiv.org/abs/2302.05097",
    "authors": [
      "Ben Chen",
      "Caihua Xiong",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.05104",
    "title": "Monte Carlo Neural Operator for Learning PDEs via Probabilistic  Representation",
    "abstract": "Neural operators, which use deep neural networks to approximate the solution mappings of partial differential equation (PDE) systems, are emerging as a new paradigm for PDE simulation. The neural operators could be trained in supervised or unsupervised ways, i.e., by using the generated data or the PDE information. The unsupervised training approach is essential when data generation is costly or the data is less qualified (e.g., insufficient and noisy). However, its performance and efficiency have plenty of room for improvement. To this end, we design a new loss function based on the Feynman-Kac formula and call the developed neural operator Monte-Carlo Neural Operator (MCNO), which can allow larger temporal steps and efficiently handle fractional diffusion operators. Our analyses show that MCNO has advantages in handling complex spatial conditions and larger temporal steps compared with other unsupervised methods. Furthermore, MCNO is more robust with the perturbation raised by the numerical scheme and operator approximation. Numerical experiments on the diffusion equation and Navier-Stokes equation show significant accuracy improvement compared with other unsupervised baselines, especially for the vibrated initial condition and long-time simulation settings. ",
    "url": "https://arxiv.org/abs/2302.05104",
    "authors": [
      "Rui Zhang",
      "Qi Meng",
      "Rongchan Zhu",
      "Yue Wang",
      "Wenlei Shi",
      "Shihua Zhang",
      "Zhi-Ming Ma",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2302.05109",
    "title": "Adjacent-level Feature Cross-Fusion with 3D CNN for Remote Sensing Image  Change Detection",
    "abstract": "Deep learning-based change detection using remote sensing images has received increasing attention in recent years. However, how to effectively extract and fuse the deep features of bi-temporal images to improve the accuracy of change detection is still a challenge. To address that, a novel adjacent-level feature fusion network with 3D convolution (named AFCF3D-Net) is proposed in this article. First, through the inner fusion property of 3D convolution, we design a new feature fusion way that can simultaneously extract and fuse the feature information from bi-temporal images. Then, in order to bridge the semantic gap between low-level features and high-level features, we propose an adjacent-level feature cross-fusion (AFCF) module to aggregate complementary feature information between the adjacent-levels. Furthermore, the densely skip connection strategy is introduced to improve the capability of pixel-wise prediction and compactness of changed objects in the results. Finally, the proposed AFCF3D-Net has been validated on the three challenging remote sensing change detection datasets: Wuhan building dataset (WHU-CD), LEVIR building dataset (LEVIR-CD), and Sun Yat-Sen University (SYSU-CD). The results of quantitative analysis and qualitative comparison demonstrate that the proposed AFCF3D-Net achieves better performance compared to the other state-of-the-art change detection methods. ",
    "url": "https://arxiv.org/abs/2302.05109",
    "authors": [
      "Yuanxin Ye",
      "Mengmeng Wang",
      "Liang Zhou",
      "Guangyang Lei",
      "Jianwei Fan",
      "Yao Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05114",
    "title": "Exploiting Neighborhood Structural Features for Change Detection",
    "abstract": "In this letter, a novel method for change detection is proposed using neighborhood structure correlation. Because structure features are insensitive to the intensity differences between bi-temporal images, we perform the correlation analysis on structure features rather than intensity information. First, we extract the structure feature maps by using multi-orientated gradient information. Then, the structure feature maps are used to obtain the Neighborhood Structural Correlation Image (NSCI), which can represent the context structure information. In addition, we introduce a measure named matching error which can be used to improve neighborhood information. Subsequently, a change detection model based on the random forest is constructed. The NSCI feature and matching error are used as the model inputs for training and prediction. Finally, the decision tree voting is used to produce the change detection result. To evaluate the performance of the proposed method, it was compared with three state-of-the-art change detection methods. The experimental results on two datasets demonstrated the effectiveness and robustness of the proposed method. ",
    "url": "https://arxiv.org/abs/2302.05114",
    "authors": [
      "Mengmeng Wang",
      "Zhiqiang Han",
      "Peizhen Yang",
      "Bai Zhu",
      "Ming Hao",
      "Jianwei Fan",
      "Yuanxin Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05118",
    "title": "Beyond In-Domain Scenarios: Robust Density-Aware Calibration",
    "abstract": "Calibrating deep learning models to yield uncertainty-aware predictions is crucial as deep neural networks get increasingly deployed in safety-critical applications. While existing post-hoc calibration methods achieve impressive results on in-domain test datasets, they are limited by their inability to yield reliable uncertainty estimates in domain-shift and out-of-domain (OOD) scenarios. We aim to bridge this gap by proposing DAC, an accuracy-preserving as well as Density-Aware Calibration method based on k-nearest-neighbors (KNN). In contrast to existing post-hoc methods, we utilize hidden layers of classifiers as a source for uncertainty-related information and study their importance. We show that DAC is a generic method that can readily be combined with state-of-the-art post-hoc methods. DAC boosts the robustness of calibration performance in domain-shift and OOD, while maintaining excellent in-domain predictive uncertainty estimates. We demonstrate that DAC leads to consistently better calibration across a large number of model architectures, datasets, and metrics. Additionally, we show that DAC improves calibration substantially on recent large-scale neural networks pre-trained on vast amounts of data. ",
    "url": "https://arxiv.org/abs/2302.05118",
    "authors": [
      "Christian Tomani",
      "Futa Waseda",
      "Yuesong Shen",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.05120",
    "title": "Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial  Text Attacks",
    "abstract": "We propose a novel gradient-based attack against transformer-based language models that searches for an adversarial example in a continuous space of token probabilities. Our algorithm mitigates the gap between adversarial loss for continuous and discrete text representations by performing multi-step quantization in a quantization-compensation loop. Experiments show that our method significantly outperforms other approaches on various natural language processing (NLP) tasks. ",
    "url": "https://arxiv.org/abs/2302.05120",
    "authors": [
      "Piotr Gai\u0144ski",
      "Klaudia Ba\u0142azy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.05132",
    "title": "GCNet: Probing Self-Similarity Learning for Generalized Counting Network",
    "abstract": "The class-agnostic counting (CAC) problem has caught increasing attention recently due to its wide societal applications and arduous challenges. To count objects of different categories, existing approaches rely on user-provided exemplars, which is hard-to-obtain and limits their generality. In this paper, we aim to empower the framework to recognize adaptive exemplars within the whole images. A zero-shot Generalized Counting Network (GCNet) is developed, which uses a pseudo-Siamese structure to automatically and effectively learn pseudo exemplar clues from inherent repetition patterns. In addition, a weakly-supervised scheme is presented to reduce the burden of laborious density maps required by all contemporary CAC models, allowing GCNet to be trained using count-level supervisory signals in an end-to-end manner. Without providing any spatial location hints, GCNet is capable of adaptively capturing them through a carefully-designed self-similarity learning strategy. Extensive experiments and ablation studies on the prevailing benchmark FSC147 for zero-shot CAC demonstrate the superiority of our GCNet. It performs on par with existing exemplar-dependent methods and shows stunning cross-dataset generality on crowd-specific datasets, e.g., ShanghaiTech Part A, Part B and UCF_QNRF. ",
    "url": "https://arxiv.org/abs/2302.05132",
    "authors": [
      "Mingjie Wang",
      "Yande Li",
      "Jun Zhou",
      "Graham W. Taylor",
      "Minglun Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05134",
    "title": "Neural Capacitated Clustering",
    "abstract": "Recent work on deep clustering has found new promising methods also for constrained clustering problems. Their typically pairwise constraints often can be used to guide the partitioning of the data. Many problems however, feature cluster-level constraints, e.g. the Capacitated Clustering Problem (CCP), where each point has a weight and the total weight sum of all points in each cluster is bounded by a prescribed capacity. In this paper we propose a new method for the CCP, Neural Capacited Clustering, that learns a neural network to predict the assignment probabilities of points to cluster centers from a data set of optimal or near optimal past solutions of other problem instances. During inference, the resulting scores are then used in an iterative k-means like procedure to refine the assignment under capacity constraints. In our experiments on artificial data and two real world datasets our approach outperforms several state-of-the-art mathematical and heuristic solvers from the literature. Moreover, we apply our method in the context of a cluster-first-route-second approach to the Capacitated Vehicle Routing Problem (CVRP) and show competitive results on the well-known Uchoa benchmark. ",
    "url": "https://arxiv.org/abs/2302.05134",
    "authors": [
      "Jonas K. Falkner",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05151",
    "title": "Binomial Line Cox Processes: Statistical Characterization and  Applications in Wireless Network Analysis",
    "abstract": "The current analysis of wireless networks whose transceivers are confined to streets is largely based on Poissonian models, such as Poisson line processes and Poisson line Cox processes. We demonstrate important scenarios where a model with a finite and deterministic number of streets, termed binomial line process, is more accurate. We characterize the statistical properties of the BLP and the corresponding binomial line Cox process and apply them to analyze the performance of a network whose access points are deployed along the streets of a city. Such a deployment scenario will be typical for 5G and future wireless networks. In order to obtain a fine-grained insight into the network performance, we derive the meta distribution of the signal-to-interference and noise ratio. Accordingly, we investigate the mean local delay in transmission and the density of successful transmission. These metrics, respectively, characterize the latency and coverage performance of the network and are key performance indicators of next-generation wireless systems. ",
    "url": "https://arxiv.org/abs/2302.05151",
    "authors": [
      "Mohammad Taha Shah",
      "Gourab Ghatak",
      "Souradip Sanyal",
      "Martin Haenggi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2302.05154",
    "title": "Industrial and Medical Anomaly Detection Through Cycle-Consistent  Adversarial Networks",
    "abstract": "In this study, a new Anomaly Detection (AD) approach for real-world images is proposed. This method leverages the theoretical strengths of unsupervised learning and the data availability of both normal and abnormal classes. The AD is often formulated as an unsupervised task motivated by the frequent imbalanced nature of the datasets, as well as the challenge of capturing the entirety of the abnormal class. Such methods only rely on normal images during training, which are devoted to be reconstructed through an autoencoder architecture for instance. However, the information contained in the abnormal data is also valuable for this reconstruction. Indeed, the model would be able to identify its weaknesses by better learning how to transform an abnormal (or normal) image into a normal (or abnormal) image. Each of these tasks could help the entire model to learn with higher precision than a single normal to normal reconstruction. To address this challenge, the proposed method utilizes Cycle-Generative Adversarial Networks (Cycle-GANs) for abnormal-to-normal translation. To the best of our knowledge, this is the first time that Cycle-GANs have been studied for this purpose. After an input image has been reconstructed by the normal generator, an anomaly score describes the differences between the input and reconstructed images. Based on a threshold set with a business quality constraint, the input image is then flagged as normal or not. The proposed method is evaluated on industrial and medical images, including cases with balanced datasets and others with as few as 30 abnormal images. The results demonstrate accurate performance and good generalization for all kinds of anomalies, specifically for texture-shaped images where the method reaches an average accuracy of 97.2% (85.4% with an additional zero false negative constraint). ",
    "url": "https://arxiv.org/abs/2302.05154",
    "authors": [
      "Arnaud Bougaham",
      "Valentin Delchevalerie",
      "Mohammed El Adoui",
      "Beno\u00eet Fr\u00e9nay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.05160",
    "title": "Dual Memory Units with Uncertainty Regulation for Weakly Supervised  Video Anomaly Detection",
    "abstract": "Learning discriminative features for effectively separating abnormal events from normality is crucial for weakly supervised video anomaly detection (WS-VAD) tasks. Existing approaches, both video and segment-level label oriented, mainly focus on extracting representations for anomaly data while neglecting the implication of normal data. We observe that such a scheme is sub-optimal, i.e., for better distinguishing anomaly one needs to understand what is a normal state, and may yield a higher false alarm rate. To address this issue, we propose an Uncertainty Regulated Dual Memory Units (UR-DMU) model to learn both the representations of normal data and discriminative features of abnormal data. To be specific, inspired by the traditional global and local structure on graph convolutional networks, we introduce a Global and Local Multi-Head Self Attention (GL-MHSA) module for the Transformer network to obtain more expressive embeddings for capturing associations in videos. Then, we use two memory banks, one additional abnormal memory for tackling hard samples, to store and separate abnormal and normal prototypes and maximize the margins between the two representations. Finally, we propose an uncertainty learning scheme to learn the normal data latent space, that is robust to noise from camera switching, object changing, scene transforming, etc. Extensive experiments on XD-Violence and UCF-Crime datasets demonstrate that our method outperforms the state-of-the-art methods by a sizable margin. ",
    "url": "https://arxiv.org/abs/2302.05160",
    "authors": [
      "Hang Zhou",
      "Junqing Yu",
      "Wei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05172",
    "title": "Social Virtual Reality Avatar Biosignal Animations as Availability  Status Indicators",
    "abstract": "In this position paper, we outline our research challenges in Affective Interactive Systems, and present recent work on visualizing avatar biosignals for social VR entertainment. We highlight considerations for how biosignals animations in social VR spaces can (falsely) indicate users' availability status. ",
    "url": "https://arxiv.org/abs/2302.05172",
    "authors": [
      "Abdallah El Ali",
      "Sueyoon Lee",
      "Pablo Cesar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.05200",
    "title": "End-to-end Semantic Object Detection with Cross-Modal Alignment",
    "abstract": "Traditional semantic image search methods aim to retrieve images that match the meaning of the text query. However, these methods typically search for objects on the whole image, without considering the localization of objects within the image. This paper presents an extension of existing object detection models for semantic image search that considers the semantic alignment between object proposals and text queries, with a focus on searching for objects within images. The proposed model uses a single feature extractor, a pre-trained Convolutional Neural Network, and a transformer encoder to encode the text query. Proposal-text alignment is performed using contrastive learning, producing a score for each proposal that reflects its semantic alignment with the text query. The Region Proposal Network (RPN) is used to generate object proposals, and the end-to-end training process allows for an efficient and effective solution for semantic image search. The proposed model was trained end-to-end, providing a promising solution for semantic image search that retrieves images that match the meaning of the text query and generates semantically relevant object proposals. ",
    "url": "https://arxiv.org/abs/2302.05200",
    "authors": [
      "Silvan Ferreira",
      "Allan Martins",
      "Ivanovitch Silva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05209",
    "title": "A Survey on Causal Reinforcement Learning",
    "abstract": "While Reinforcement Learning (RL) achieves tremendous success in sequential decision-making problems of many domains, it still faces key challenges of data inefficiency and the lack of interpretability. Interestingly, many researchers have leveraged insights from the causality literature recently, bringing forth flourishing works to unify the merits of causality and address well the challenges from RL. As such, it is of great necessity and significance to collate these Causal Reinforcement Learning (CRL) works, offer a review of CRL methods, and investigate the potential functionality from causality toward RL. In particular, we divide existing CRL approaches into two categories according to whether their causality-based information is given in advance or not. We further analyze each category in terms of the formalization of different models, ranging from the Markov Decision Process (MDP), Partially Observed Markov Decision Process (POMDP), Multi-Arm Bandits (MAB), and Dynamic Treatment Regime (DTR). Moreover, we summarize the evaluation matrices and open sources while we discuss emerging applications, along with promising prospects for the future development of CRL. ",
    "url": "https://arxiv.org/abs/2302.05209",
    "authors": [
      "Yan Zeng",
      "Ruichu Cai",
      "Fuchun Sun",
      "Libo Huang",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05213",
    "title": "CEN-HDR: Computationally Efficient neural Network for real-time High  Dynamic Range imaging",
    "abstract": "High dynamic range (HDR) imaging is still a challenging task in modern digital photography. Recent research proposes solutions that provide high-quality acquisition but at the cost of a very large number of operations and a slow inference time that prevent the implementation of these solutions on lightweight real-time systems. In this paper, we propose CEN-HDR, a new computationally efficient neural network by providing a novel architecture based on a light attention mechanism and sub-pixel convolution operations for real-time HDR imaging. We also provide an efficient training scheme by applying network compression using knowledge distillation. We performed extensive qualitative and quantitative comparisons to show that our approach produces competitive results in image quality while being faster than state-of-the-art solutions, allowing it to be practically deployed under real-time constraints. Experimental results show our method obtains a score of 43.04 mu-PSNR on the Kalantari2017 dataset with a framerate of 33 FPS using a Macbook M1 NPU. ",
    "url": "https://arxiv.org/abs/2302.05213",
    "authors": [
      "Steven Tel",
      "Barth\u00e9l\u00e9my Heyrman",
      "Dominique Ginhac"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.05262",
    "title": "Evaluation of Data Augmentation and Loss Functions in Semantic Image  Segmentation for Drilling Tool Wear Detection",
    "abstract": "Tool wear monitoring is crucial for quality control and cost reduction in manufacturing processes, of which drilling applications are one example. In this paper, we present a U-Net based semantic image segmentation pipeline, deployed on microscopy images of cutting inserts, for the purpose of wear detection. The wear area is differentiated in two different types, resulting in a multiclass classification problem. Joining the two wear types in one general wear class, on the other hand, allows the problem to be formulated as a binary classification task. Apart from the comparison of the binary and multiclass problem, also different loss functions, i. e., Cross Entropy, Focal Cross Entropy, and a loss based on the Intersection over Union (IoU), are investigated. Furthermore, models are trained on image tiles of different sizes, and augmentation techniques of varying intensities are deployed. We find, that the best performing models are binary models, trained on data with moderate augmentation and an IoU-based loss function. ",
    "url": "https://arxiv.org/abs/2302.05262",
    "authors": [
      "Elke Schlager",
      "Andreas Windisch",
      "Lukas Hanna",
      "Thomas Kl\u00fcnsner",
      "Elias Jan Hagendorfer",
      "Tamara Teppernegg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05282",
    "title": "Graph Neural Networks Go Forward-Forward",
    "abstract": "We present the Graph Forward-Forward (GFF) algorithm, an extension of the Forward-Forward procedure to graphs, able to handle features distributed over a graph's nodes. This allows training graph neural networks with forward passes only, without backpropagation. Our method is agnostic to the message-passing scheme, and provides a more biologically plausible learning scheme than backpropagation, while also carrying computational advantages. With GFF, graph neural networks are trained greedily layer by layer, using both positive and negative samples. We run experiments on 11 standard graph property prediction tasks, showing how GFF provides an effective alternative to backpropagation for training graph neural networks. This shows in particular that this procedure is remarkably efficient in spite of combining the per-layer training with the locality of the processing in a GNN. ",
    "url": "https://arxiv.org/abs/2302.05282",
    "authors": [
      "Daniele Paliotta",
      "Mathieu Alain",
      "B\u00e1lint M\u00e1t\u00e9",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.05286",
    "title": "Archaeological Sites Detection with a Human-AI Collaboration Workflow",
    "abstract": "This paper illustrates the results obtained by using pre-trained semantic segmentation deep learning models for the detection of archaeological sites within the Mesopotamian floodplains environment. The models were fine-tuned using openly available satellite imagery and vector shapes coming from a large corpus of annotations (i.e., surveyed sites). A randomized test showed that the best model reaches a detection accuracy in the neighborhood of 80%. Integrating domain expertise was crucial to define how to build the dataset and how to evaluate the predictions, since defining if a proposed mask counts as a prediction is very subjective. Furthermore, even an inaccurate prediction can be useful when put into context and interpreted by a trained archaeologist. Coming from these considerations we close the paper with a vision for a Human-AI collaboration workflow. Starting with an annotated dataset that is refined by the human expert we obtain a model whose predictions can either be combined to create a heatmap, to be overlaid on satellite and/or aerial imagery, or alternatively can be vectorized to make further analysis in a GIS software easier and automatic. In turn, the archaeologists can analyze the predictions, organize their onsite surveys, and refine the dataset with new, corrected, annotation ",
    "url": "https://arxiv.org/abs/2302.05286",
    "authors": [
      "Luca Casini",
      "Valentina Orr\u00f9",
      "Andrea Montanucci",
      "Nicol\u00f2 Marchetti",
      "Marco Roccetti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05293",
    "title": "A Novel Improved Mask RCNN for Multiple Targets Detection in the Indoor  Complex Scenes",
    "abstract": "With the expansive aging of global population, service robot with living assistance applied in indoor scenes will serve as a crucial role in the field of elderly care and health in the future. Service robots need to detect multiple targets when completing auxiliary tasks. However, indoor scenes are usually complex and there are many types of interference factors, leading to great challenges in the multiple targets detection. To overcome this technical difficulty, a novel improved Mask RCNN method for multiple targets detection in the indoor complex scenes is proposed in this paper. The improved model utilizes Mask RCNN as the network framework. On this basis, Convolutional Block Attention Module (CBAM) with channel mechanism and space mechanism is integrated, and the influence of different background, distance, angle and interference factors are comprehensively considered. Meanwhile, in order to evaluate the detection and identification effects of the established model, a comprehensive evaluation system based on loss function and Mean Average Precision (mAP) is established. For verification, experiments on the detection and identification effects under different distances, backgrounds, angles and interference factors were conducted. The results show that designed model improves the accuracy to a higher level and has a better anti-interference ability than other methods when the detection speed was nearly the same. ",
    "url": "https://arxiv.org/abs/2302.05293",
    "authors": [
      "Zongmin Liu",
      "Jirui Wang",
      "Jie Li",
      "Pengda Liu",
      "Kai Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.05294",
    "title": "MoreauGrad: Sparse and Robust Interpretation of Neural Networks via  Moreau Envelope",
    "abstract": "Explaining the predictions of deep neural nets has been a topic of great interest in the computer vision literature. While several gradient-based interpretation schemes have been proposed to reveal the influential variables in a neural net's prediction, standard gradient-based interpretation frameworks have been commonly observed to lack robustness to input perturbations and flexibility for incorporating prior knowledge of sparsity and group-sparsity structures. In this work, we propose MoreauGrad as an interpretation scheme based on the classifier neural net's Moreau envelope. We demonstrate that MoreauGrad results in a smooth and robust interpretation of a multi-layer neural network and can be efficiently computed through first-order optimization methods. Furthermore, we show that MoreauGrad can be naturally combined with $L_1$-norm regularization techniques to output a sparse or group-sparse explanation which are prior conditions applicable to a wide range of deep learning applications. We empirically evaluate the proposed MoreauGrad scheme on standard computer vision datasets, showing the qualitative and quantitative success of the MoreauGrad approach in comparison to standard gradient-based interpretation methods. ",
    "url": "https://arxiv.org/abs/2302.05294",
    "authors": [
      "Jingwei Zhang",
      "Farzan Farnia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.05300",
    "title": "Reinforcement Learning for Protocol Synthesis in Resource-Constrained  Wireless Sensor and IoT Networks",
    "abstract": "This article explores the concepts of online protocol synthesis using Reinforcement Learning (RL). The study is performed in the context of sensor and IoT networks with ultra low complexity wireless transceivers. The paper introduces the use of RL and Multi Armed Bandit (MAB), a specific type of RL, for Medium Access Control (MAC) under different network and traffic conditions. It then introduces a novel learning based protocol synthesis framework that addresses specific difficulties and limitations in medium access for both random access and time slotted networks. The mechanism does not rely on carrier sensing, network time-synchronization, collision detection, and other low level complex operations, thus making it ideal for ultra simple transceiver hardware used in resource constrained sensor and IoT networks. Additionally, the ability of independent protocol learning by the nodes makes the system robust and adaptive to the changes in network and traffic conditions. It is shown that the nodes can be trained to learn to avoid collisions, and to achieve network throughputs that are comparable to ALOHA based access protocols in sensor and IoT networks with simplest transceiver hardware. It is also shown that using RL, it is feasible to synthesize access protocols that can sustain network throughput at high traffic loads, which is not feasible in the ALOHA-based systems. The ability of the system to provide throughput fairness under network and traffic heterogeneities are also experimentally demonstrated. ",
    "url": "https://arxiv.org/abs/2302.05300",
    "authors": [
      "Hrishikesh Dutta",
      "Amit Kumar Bhuyan",
      "Subir Biswas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05312",
    "title": "Trauma-Informed Social Media: Towards Solutions for Reducing and Healing  Online Harm",
    "abstract": "Social media platforms exacerbate trauma, and many users experience various forms of trauma unique to them (e.g., doxxing and swatting). Trauma is the psychological and physical response to experiencing a deeply disturbing event. Platforms' failures to address trauma threaten users' well-being globally, especially amongst minoritized groups. Platform policies also expose moderators and designers to trauma through content they must engage with as part of their jobs (e.g., child sexual abuse). We consider how a trauma-informed approach might help address or decrease the likelihood of (re)experiencing trauma online. A trauma-informed approach to social media recognizes that everyone likely has a trauma history and that trauma is experienced at the individual, secondary, collective, and cultural levels. This paper proceeds by detailing trauma and its impacts. We then describe how the six trauma-informed principles can be applied to social media design, content moderation, and companies. We conclude by offering recommendations that balance platform responsibility and accountability with well-being and healing for all. ",
    "url": "https://arxiv.org/abs/2302.05312",
    "authors": [
      "Carol F. Scott",
      "Gabriela Marcu",
      "Riana Elyse Anderson",
      "Mark W. Newman",
      "Sarita Schoenebeck"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.05319",
    "title": "Controlling Large Language Models to Generate Secure and Vulnerable Code",
    "abstract": "Large language models (LMs) are increasingly pretrained on massive corpora of open-source programs and applied to solve program synthesis tasks. However, a fundamental limitation of LMs is their unawareness of security and vulnerability during pretraining and inference. As a result, LMs produce secure or vulnerable programs with high uncertainty (e.g., around 60%/40% chances for GitHub Copilot according to a recent study). This greatly impairs LMs' usability, especially in security-sensitive scenarios. To address this limitation, this work formulates a new problem called controlled code generation, which allows users to input a boolean property into an LM to control if the LM generates secure or vulnerable code. We propose svGen, an effective and lightweight learning approach for solving controlled code generation. svGen leverages property-specific continuous vectors to steer program generation toward the given property, without altering the weights of the LM. svGen's training optimizes those continuous vectors by carefully applying specialized loss terms on different regions of code. Our extensive evaluation shows that svGen achieves strong control capability across various software vulnerabilities and LMs of different parameter sizes. For example, on 9 dangerous vulnerabilities, a state-of-the-art CodeGen LM with 2.7B parameters generates secure programs with a 57% chance. When we use svGen to control the LM to generate secure (resp., vulnerable) programs, the chance is significantly increased to 82% (resp., decreased to 35%). ",
    "url": "https://arxiv.org/abs/2302.05319",
    "authors": [
      "Jingxuan He",
      "Martin Vechev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.05322",
    "title": "Numerical Methods For PDEs Over Manifolds Using Spectral Physics  Informed Neural Networks",
    "abstract": "We introduce an approach for solving PDEs over manifolds using physics informed neural networks whose architecture aligns with spectral methods. The networks are trained to take in as input samples of an initial condition, a time stamp and point(s) on the manifold and then output the solution's value at the given time and point(s). We provide proofs of our method for the heat equation on the interval and examples of unique network architectures that are adapted to nonlinear equations on the sphere and the torus. We also show that our spectral-inspired neural network architectures outperform the standard physics informed architectures. Our extensive experimental results include generalization studies where the testing dataset of initial conditions is randomly sampled from a significantly larger space than the training set. ",
    "url": "https://arxiv.org/abs/2302.05322",
    "authors": [
      "Yuval Zelig",
      "Shai Dekel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.05330",
    "title": "Action Dynamics Task Graphs for Learning Plannable Representations of  Procedural Tasks",
    "abstract": "Given video demonstrations and paired narrations of an at-home procedural task such as changing a tire, we present an approach to extract the underlying task structure -- relevant actions and their temporal dependencies -- via action-centric task graphs. Learnt structured representations from our method, Action Dynamics Task Graphs (ADTG), can then be used for understanding such tasks in unseen videos of humans performing them. Furthermore, ADTG can enable providing user-centric guidance to humans in these tasks, either for performing them better or for learning new tasks. Specifically, we show how ADTG can be used for: (1) tracking an ongoing task, (2) recommending next actions, and (3) planning a sequence of actions to accomplish a procedural task. We compare against state-of-the-art Neural Task Graph method and demonstrate substantial gains on 18 procedural tasks from the CrossTask dataset, including 30.1% improvement in task tracking accuracy and 20.3% accuracy gain in next action prediction. ",
    "url": "https://arxiv.org/abs/2302.05330",
    "authors": [
      "Weichao Mao",
      "Ruta Desai",
      "Michael Louis Iuzzolino",
      "Nitin Kamra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05336",
    "title": "Intelligent Proactive Fault Tolerance at the Edge through Resource Usage  Prediction",
    "abstract": "The proliferation of demanding applications and edge computing establishes the need for an efficient management of the underlying computing infrastructures, urging the providers to rethink their operational methods. In this paper, we propose an Intelligent Proactive Fault Tolerance (IPFT) method that leverages the edge resource usage predictions through Recurrent Neural Networks (RNN). More specifically, we focus on the process-faults, which are related with the inability of the infrastructure to provide Quality of Service (QoS) in acceptable ranges due to the lack of processing power. In order to tackle this challenge we propose a composite deep learning architecture that predicts the resource usage metrics of the edge nodes and triggers proactive node replications and task migration. Taking also into consideration that the edge computing infrastructure is also highly dynamic and heterogeneous, we propose an innovative Hybrid Bayesian Evolution Strategy (HBES) algorithm for automated adaptation of the resource usage models. The proposed resource usage prediction mechanism has been experimentally evaluated and compared with other state of the art methods with significant improvements in terms of Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). Additionally, the IPFT mechanism that leverages the resource usage predictions has been evaluated in an extensive simulation in CloudSim Plus and the results show significant improvement compared to the reactive fault tolerance method in terms of reliability and maintainability. ",
    "url": "https://arxiv.org/abs/2302.05336",
    "authors": [
      "Theodoros Theodoropoulos",
      "John Violos",
      "Stylianos Tsanakas",
      "Aris Leivadeas",
      "Konstantinos Tserpes",
      "Theodora Varvarigou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.05348",
    "title": "Computing a Best Response against a Maximum Disruption Attack",
    "abstract": "Inspired by scenarios where the strategic network design and defense or immunisation are of the central importance, Goyal et al. [3] defined a new Network Formation Game with Attack and Immunisation. The authors showed that despite the presence of attacks, the game has high social welfare properties and even though the equilibrium networks can contain cycles, the number of edges is strongly bounded. Subsequently, Friedrich et al. [10] provided a polynomial time algorithm for computing a best response strategy for the maximum carnage adversary which tries to kill as many nodes as possible, and for the random attack adversary, but they left open the problem for the case of maximum disruption adversary. This adversary attacks the vulnerable region that minimises the post-attack social welfare. In this paper we address our efforts to this question. We can show that computing a best response strategy given a player u and the strategies of all players but u, is polynomial time solvable when the initial network resulting from the given strategies is connected. Our algorithm is based on a dynamic programming and has some reminiscence to the knapsack-problem, although is considerably more complex and involved. ",
    "url": "https://arxiv.org/abs/2302.05348",
    "authors": [
      "Carme \u00c0lvarez",
      "Arnau Messegu\u00e9"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.05355",
    "title": "Building cross-language corpora for human understanding of privacy  policies",
    "abstract": "Making sure that users understand privacy policies that impact them is a key challenge for a real GDPR deployment. Research studies are mostly carried in English, but in Europe and elsewhere, users speak a language that is not English. Replicating studies in different languages requires the availability of comparable cross-language privacy policies corpora. This work provides a methodology for building comparable cross-language in a national language and a reference study language. We provide an application example of our methodology comparing English and Italian extending the corpus of one of the first studies about users understanding of technical terms in privacy policies. We also investigate other open issues that can make replication harder. ",
    "url": "https://arxiv.org/abs/2302.05355",
    "authors": [
      "Francesco Ciclosi",
      "Silvia Vidor",
      "Fabio Massacci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2302.05356",
    "title": "Approximation and Structured Prediction with Sparse Wasserstein  Barycenters",
    "abstract": "We develop a general theoretical and algorithmic framework for sparse approximation and structured prediction in $\\mathcal{P}_2(\\Omega)$ with Wasserstein barycenters. The barycenters are sparse in the sense that they are computed from an available dictionary of measures but the approximations only involve a reduced number of atoms. We show that the best reconstruction from the class of sparse barycenters is characterized by a notion of best $n$-term barycenter which we introduce, and which can be understood as a natural extension of the classical concept of best $n$-term approximation in Banach spaces. We show that the best $n$-term barycenter is the minimizer of a highly non-convex, bi-level optimization problem, and we develop algorithmic strategies for practical numerical computation. We next leverage this approximation tool to build interpolation strategies that involve a reduced computational cost, and that can be used for structured prediction, and metamodelling of parametrized families of measures. We illustrate the potential of the method through the specific problem of Model Order Reduction (MOR) of parametrized PDEs. Since our approach is sparse, adaptive and preserves mass by construction, it has potential to overcome known bottlenecks of classical linear methods in hyperbolic conservation laws transporting discontinuities. It also paves the way towards MOR for measure-valued PDE problems such as gradient flows. ",
    "url": "https://arxiv.org/abs/2302.05356",
    "authors": [
      "Minh-Hieu Do",
      "Jean Feydy",
      "Olga Mula"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.05372",
    "title": "Towards Minimax Optimality of Model-based Robust Reinforcement Learning",
    "abstract": "We study the sample complexity of obtaining an $\\epsilon$-optimal policy in \\emph{Robust} discounted Markov Decision Processes (RMDPs), given only access to a generative model of the nominal kernel. This problem is widely studied in the non-robust case, and it is known that any planning approach applied to an empirical MDP estimated with $\\tilde{\\mathcal{O}}(\\frac{H^3 \\mid S \\mid\\mid A \\mid}{\\epsilon^2})$ samples provides an $\\epsilon$-optimal policy, which is minimax optimal. Results in the robust case are much more scarce. For $sa$- (resp $s$-)rectangular uncertainty sets, the best known sample complexity is $\\tilde{\\mathcal{O}}(\\frac{H^4 \\mid S \\mid^2\\mid A \\mid}{\\epsilon^2})$ (resp. $\\tilde{\\mathcal{O}}(\\frac{H^4 \\mid S \\mid^2\\mid A \\mid^2}{\\epsilon^2})$), for specific algorithms and when the uncertainty set is based on the total variation (TV), the KL or the Chi-square divergences. In this paper, we consider uncertainty sets defined with an $L_p$-ball (recovering the TV case), and study the sample complexity of \\emph{any} planning algorithm (with high accuracy guarantee on the solution) applied to an empirical RMDP estimated using the generative model. In the general case, we prove a sample complexity of $\\tilde{\\mathcal{O}}(\\frac{H^4 \\mid S \\mid\\mid A \\mid}{\\epsilon^2})$ for both the $sa$- and $s$-rectangular cases (improvements of $\\mid S \\mid$ and $\\mid S \\mid\\mid A \\mid$ respectively). When the size of the uncertainty is small enough, we improve the sample complexity to $\\tilde{\\mathcal{O}}(\\frac{H^3 \\mid S \\mid\\mid A \\mid }{\\epsilon^2})$, recovering the lower-bound for the non-robust case for the first time and a robust lower-bound when the size of the uncertainty is small enough. ",
    "url": "https://arxiv.org/abs/2302.05372",
    "authors": [
      "Pierre Clavier",
      "Erwan Le Pennec",
      "Matthieu Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.05400",
    "title": "DNArch: Learning Convolutional Neural Architectures by Backpropagation",
    "abstract": "We present Differentiable Neural Architectures (DNArch), a method that jointly learns the weights and the architecture of Convolutional Neural Networks (CNNs) by backpropagation. In particular, DNArch allows learning (i) the size of convolutional kernels at each layer, (ii) the number of channels at each layer, (iii) the position and values of downsampling layers, and (iv) the depth of the network. To this end, DNArch views neural architectures as continuous multidimensional entities, and uses learnable differentiable masks along each dimension to control their size. Unlike existing methods, DNArch is not limited to a predefined set of possible neural components, but instead it is able to discover entire CNN architectures across all combinations of kernel sizes, widths, depths and downsampling. Empirically, DNArch finds performant CNN architectures for several classification and dense prediction tasks on both sequential and image data. When combined with a loss term that considers the network complexity, DNArch finds powerful architectures that respect a predefined computational budget. ",
    "url": "https://arxiv.org/abs/2302.05400",
    "authors": [
      "David W. Romero",
      "Neil Zeghidour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.05406",
    "title": "Adversarial Transformer Language Models for Contextual Commonsense  Inference",
    "abstract": "Contextualized or discourse aware commonsense inference is the task of generating coherent commonsense assertions (i.e., facts) from a given story, and a particular sentence from that story. Some problems with the task are: lack of controllability for topics of the inferred facts; lack of commonsense knowledge during training; and, possibly, hallucinated or false facts. In this work, we utilize a transformer model for this task and develop techniques to address the aforementioned problems in the task. We control the inference by introducing a new technique we call \"hinting\". Hinting is a kind of language model prompting, that utilizes both hard prompts (specific words) and soft prompts (virtual learnable templates). This serves as a control signal to advise the language model \"what to talk about\". Next, we establish a methodology for performing joint inference with multiple commonsense knowledge bases. Joint inference of commonsense requires care, because it is imprecise and the level of generality is more flexible. You want to be sure that the results \"still make sense\" for the context. To this end, we align the textual version of assertions from three knowledge graphs (ConceptNet, ATOMIC2020, and GLUCOSE) with a story and a target sentence. This combination allows us to train a single model to perform joint inference with multiple knowledge graphs. We show experimental results for the three knowledge graphs on joint inference. Our final contribution is exploring a GAN architecture that generates the contextualized commonsense assertions and scores them as to their plausibility through a discriminator. The result is an integrated system for contextual commonsense inference in stories, that can controllably generate plausible commonsense assertions, and takes advantage of joint inference between multiple commonsense knowledge bases. ",
    "url": "https://arxiv.org/abs/2302.05406",
    "authors": [
      "Pedro Colon-Hernandez",
      "Henry Lieberman",
      "Yida Xin",
      "Claire Yin",
      "Cynthia Breazeal",
      "Peter Chin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.05411",
    "title": "The Impact of Network Design Interventions on the Security of  Interdependent Systems",
    "abstract": "We study the problem of defending a Cyber-Physical System (CPS) consisting of interdependent components with heterogeneous sensitivity to investments. In addition to the optimal allocation of limited security resources, we analyze the impact of an orthogonal set of defense strategies in the form of network design interventions in the CPS to protect it against the attacker. We first propose an algorithm to simplify the CPS attack graph to an equivalent form which reduces the computational requirements for characterizing the defender's optimal security investments. We then evaluate four types of design interventions in the network in the form of adding nodes in the attack graph, interpreted as introducing additional safeguards, introducing structural redundancies, introducing functional redundancies, and introducing new functionalities. We identify scenarios in which interventions that strengthen internal components of the CPS may be more beneficial than traditional approaches such as perimeter defense. We showcase our proposed approach in two practical use cases: a remote attack on an industrial CPS and a remote attack on an automotive system. We highlight how our results closely match recommendations made by security organizations and discuss the implications of our findings for CPS design. ",
    "url": "https://arxiv.org/abs/2302.05411",
    "authors": [
      "Pradeep Sharma Oruganti",
      "Parinaz Naghizadeh",
      "Qadeer Ahmed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.05428",
    "title": "STERLING: Synergistic Representation Learning on Bipartite Graphs",
    "abstract": "The bipartite graph is a powerful data structure for modeling interactions between two types of nodes, of which a fundamental challenge is how to extract informative node embeddings. Self-Supervised Learning (SSL) is a promising paradigm to address this challenge. Most recent bipartite graph SSL methods are based on contrastive learning which learns embeddings by discriminating positive and negative node pairs. Contrastive learning usually requires a large number of negative node pairs, which could lead to computational burden and semantic errors. In this paper, we introduce a novel synergistic representation learning model (STERLING) to learn node embeddings without negative node pairs. STERLING preserves the unique synergies in bipartite graphs. The local and global synergies are captured by maximizing the similarity of the inter-type and intra-type positive node pairs, and maximizing the mutual information of co-clusters respectively. Theoretical analysis demonstrates that STERLING could preserve the synergies in the embedding space. Extensive empirical evaluation on various benchmark datasets and tasks demonstrates the effectiveness of STERLING for extracting node embeddings. ",
    "url": "https://arxiv.org/abs/2302.05428",
    "authors": [
      "Baoyu Jing",
      "Yuchen Yan",
      "Kaize Ding",
      "Chanyoung Park",
      "Yada Zhu",
      "Huan Liu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05435",
    "title": "A deep convolutional neural network for salt-and-pepper noise removal  using selective convolutional blocks",
    "abstract": "In recent years, there has been an unprecedented upsurge in applying deep learning approaches, specifically convolutional neural networks (CNNs), to solve image denoising problems, owing to their superior performance. However, CNNs mostly rely on Gaussian noise, and there is a conspicuous lack of exploiting CNNs for salt-and-pepper (SAP) noise reduction. In this paper, we proposed a deep CNN model, namely SeConvNet, to suppress SAP noise in gray-scale and color images. To meet this objective, we introduce a new selective convolutional (SeConv) block. SeConvNet is compared to state-of-the-art SAP denoising methods using extensive experiments on various common datasets. The results illustrate that the proposed SeConvNet model effectively restores images corrupted by SAP noise and surpasses all its counterparts at both quantitative criteria and visual effects, especially at high and very high noise densities. ",
    "url": "https://arxiv.org/abs/2302.05435",
    "authors": [
      "Ahmad Ali Rafiee",
      "Mahmoud Farhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.05438",
    "title": "Deep Learning on Implicit Neural Representations of Shapes",
    "abstract": "Implicit Neural Representations (INRs) have emerged in the last few years as a powerful tool to encode continuously a variety of different signals like images, videos, audio and 3D shapes. When applied to 3D shapes, INRs allow to overcome the fragmentation and shortcomings of the popular discrete representations used so far. Yet, considering that INRs consist in neural networks, it is not clear whether and how it may be possible to feed them into deep learning pipelines aimed at solving a downstream task. In this paper, we put forward this research problem and propose inr2vec, a framework that can compute a compact latent representation for an input INR in a single inference pass. We verify that inr2vec can embed effectively the 3D shapes represented by the input INRs and show how the produced embeddings can be fed into deep learning pipelines to solve several tasks by processing exclusively INRs. ",
    "url": "https://arxiv.org/abs/2302.05438",
    "authors": [
      "Luca De Luigi",
      "Adriano Cardace",
      "Riccardo Spezialetti",
      "Pierluigi Zama Ramirez",
      "Samuele Salti",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05443",
    "title": "Believability and Harmfulness Shape the Virality of Misleading Social  Media Posts",
    "abstract": "Misinformation on social media presents a major threat to modern societies. While previous research has analyzed the virality across true and false social media posts, not every misleading post is necessarily equally viral. Rather, misinformation has different characteristics and varies in terms of its believability and harmfulness - which might influence its spread. In this work, we study how the perceived believability and harmfulness of misleading posts are associated with their virality on social media. Specifically, we analyze (and validate) a large sample of crowd-annotated social media posts from Twitter's Birdwatch platform, on which users can rate the believability and harmfulness of misleading tweets. To address our research questions, we implement an explanatory regression model and link the crowd ratings for believability and harmfulness to the virality of misleading posts on Twitter. Our findings imply that misinformation that is (i) easily believable and (ii) not particularly harmful is associated with more viral resharing cascades. These results offer insights into how different kinds of crowd fact-checked misinformation spreads and suggest that the most viral misleading posts are often not the ones that are particularly concerning from the perspective of public safety. From a practical view, our findings may help platforms to develop more effective strategies to curb the proliferation of misleading posts on social media. ",
    "url": "https://arxiv.org/abs/2302.05443",
    "authors": [
      "Chiara Drolsbach",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.05444",
    "title": "Q-Match: Self-supervised Learning by Matching Distributions Induced by a  Queue",
    "abstract": "In semi-supervised learning, student-teacher distribution matching has been successful in improving performance of models using unlabeled data in conjunction with few labeled samples. In this paper, we aim to replicate that success in the self-supervised setup where we do not have access to any labeled data during pre-training. We introduce our algorithm, Q-Match, and show it is possible to induce the student-teacher distributions without any knowledge of downstream classes by using a queue of embeddings of samples from the unlabeled dataset. We focus our study on tabular datasets and show that Q-Match outperforms previous self-supervised learning techniques when measuring downstream classification performance. Furthermore, we show that our method is sample efficient--in terms of both the labels required for downstream training and the amount of unlabeled data required for pre-training--and scales well to the sizes of both the labeled and unlabeled data. ",
    "url": "https://arxiv.org/abs/2302.05444",
    "authors": [
      "Thomas Mulc",
      "Debidatta Dwibedi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04933",
    "title": "Optimal Routing of Modular Agents on a Graph",
    "abstract": "Motivated by an emerging framework of Autonomous Modular Vehicles, we consider the abstract problem of optimally routing two modules, i.e., vehicles that can attach to or detach from each other in motion on a graph. The modules' objective is to reach a preset set of nodes while incurring minimum resource costs. We assume that the resource cost incurred by an agent formed by joining two modules is the same as that of a single module. Such a cost formulation simplistically models the benefits of joining two modules, such as passenger redistribution between the modules, less traffic congestion, and higher fuel efficiency. To find an optimal plan, we propose a heuristic algorithm that uses the notion of graph centrality to determine when and where to join the modules. Additionally, we use the nearest neighbor approach to estimate the cost routing for joined or separated modules. Based on this estimated cost, the algorithm determines the subsequent nodes for both modules. The proposed algorithm is polynomial time: the worst-case number of calculations scale as the eighth power of the number of the total nodes in the graph. To validate its benefits, we simulate the proposed algorithm on a large number of pseudo-random graphs, motivated by real transportation scenario where it performs better than the most relevant benchmark, an adapted nearest neighbor algorithm for two separate agents, more than 85 percent of the time. ",
    "url": "https://arxiv.org/abs/2302.04933",
    "authors": [
      "Karan Jagdale",
      "Melkior Ornik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.05059",
    "title": "Effects of noise on the overparametrization of quantum neural networks",
    "abstract": "Overparametrization is one of the most surprising and notorious phenomena in machine learning. Recently, there have been several efforts to study if, and how, Quantum Neural Networks (QNNs) acting in the absence of hardware noise can be overparametrized. In particular, it has been proposed that a QNN can be defined as overparametrized if it has enough parameters to explore all available directions in state space. That is, if the rank of the Quantum Fisher Information Matrix (QFIM) for the QNN's output state is saturated. Here, we explore how the presence of noise affects the overparametrization phenomenon. Our results show that noise can \"turn on\" previously-zero eigenvalues of the QFIM. This enables the parametrized state to explore directions that were otherwise inaccessible, thus potentially turning an overparametrized QNN into an underparametrized one. For small noise levels, the QNN is quasi-overparametrized, as large eigenvalues coexists with small ones. Then, we prove that as the magnitude of noise increases all the eigenvalues of the QFIM become exponentially suppressed, indicating that the state becomes insensitive to any change in the parameters. As such, there is a pull-and-tug effect where noise can enable new directions, but also suppress the sensitivity to parameter updates. Finally, our results imply that current QNN capacity measures are ill-defined when hardware noise is present. ",
    "url": "https://arxiv.org/abs/2302.05059",
    "authors": [
      "Diego Garc\u00eda-Mart\u00edn",
      "Martin Larocca",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.05071",
    "title": "EVC: Towards Real-Time Neural Image Compression with Mask Decay",
    "abstract": "Neural image compression has surpassed state-of-the-art traditional codecs (H.266/VVC) for rate-distortion (RD) performance, but suffers from large complexity and separate models for different rate-distortion trade-offs. In this paper, we propose an Efficient single-model Variable-bit-rate Codec (EVC), which is able to run at 30 FPS with 768x512 input images and still outperforms VVC for the RD performance. By further reducing both encoder and decoder complexities, our small model even achieves 30 FPS with 1920x1080 input images. To bridge the performance gap between our different capacities models, we meticulously design the mask decay, which transforms the large model's parameters into the small model automatically. And a novel sparsity regularization loss is proposed to mitigate shortcomings of $L_p$ regularization. Our algorithm significantly narrows the performance gap by 50% and 30% for our medium and small models, respectively. At last, we advocate the scalable encoder for neural image compression. The encoding complexity is dynamic to meet different latency requirements. We propose decaying the large encoder multiple times to reduce the residual representation progressively. Both mask decay and residual representation learning greatly improve the RD performance of our scalable encoder. Our code is at https://github.com/microsoft/DCVC. ",
    "url": "https://arxiv.org/abs/2302.05071",
    "authors": [
      "Guo-Hua Wang",
      "Jiahao Li",
      "Bin Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.05195",
    "title": "Self-Supervised Learning-Based Cervical Cytology Diagnostics in Low-Data  Regime and Low-Resource Setting",
    "abstract": "Screening Papanicolaou test samples effectively reduces cervical cancer-related mortality, but the lack of trained cytopathologists prevents its widespread adoption in low-resource settings. Developing AI algorithms, e.g., deep learning to analyze the digitized cytology images suited to resource-constrained countries is appealing. Albeit successful, it comes at the price of collecting large annotated training datasets, which is both costly and time-consuming. Our study shows that the large number of unlabeled images that can be sampled from digitized cytology slides make for a ripe ground where self-supervised learning methods can thrive and even outperform off-the-shelf deep learning models on various downstream tasks. Along the same line, we report improved performance and data efficiency using modern augmentation strategies. ",
    "url": "https://arxiv.org/abs/2302.05195",
    "authors": [
      "Thomas Stegm\u00fcller",
      "Christian Abbet",
      "Behzad Bozorgtabar",
      "Holly Clarke",
      "Patrick Petignat",
      "Pierre Vassilakos",
      "Jean-Philippe Thiran"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05265",
    "title": "Spoken language change detection inspired by speaker change detection",
    "abstract": "Spoken language change detection (LCD) refers to identifying the language transitions in a code-switched utterance. Similarly, identifying the speaker transitions in a multispeaker utterance is known as speaker change detection (SCD). Since tasks-wise both are similar, the architecture/framework developed for the SCD task may be suitable for the LCD task. Hence, the aim of the present work is to develop LCD systems inspired by SCD. Initially, both LCD and SCD are performed by humans. The study suggests humans require (a) a larger duration around the change point and (b) language-specific prior exposure, for performing LCD as compared to SCD. The larger duration requirement is incorporated by increasing the analysis window length of the unsupervised distance-based approach. This leads to a relative performance improvement of 29.1% and 2.4%, and a priori language knowledge provides a relative improvement of 31.63% and 14.27% on the synthetic and practical codeswitched datasets, respectively. The performance difference between the practical and synthetic datasets is mostly due to differences in the distribution of the monolingual segment duration. ",
    "url": "https://arxiv.org/abs/2302.05265",
    "authors": [
      "Jagabandhu Mishra",
      "S. R. Mahadeva Prasanna"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2302.05407",
    "title": "Matching Correlated Inhomogeneous Random Graphs using the $k$-core  Estimator",
    "abstract": "We consider the task of estimating the latent vertex correspondence between two edge-correlated random graphs with generic, inhomogeneous structure. We study the so-called \\emph{$k$-core estimator}, which outputs a vertex correspondence that induces a large, common subgraph of both graphs which has minimum degree at least $k$. We derive sufficient conditions under which the $k$-core estimator exactly or partially recovers the latent vertex correspondence. Finally, we specialize our general framework to derive new results on exact and partial recovery in correlated stochastic block models, correlated Chung-Lu graphs, and correlated random geometric graphs. ",
    "url": "https://arxiv.org/abs/2302.05407",
    "authors": [
      "Mikl\u00f3s Z. R\u00e1cz",
      "Anirudh Sridhar"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2302.05418",
    "title": "Quickest Inference of Susceptible-Infected Cascades in Sparse Networks",
    "abstract": "We consider the task of estimating a network cascade as fast as possible. The cascade is assumed to spread according to a general Susceptible-Infected process with heterogeneous transmission rates from an unknown source in the network. While the propagation is not directly observable, noisy information about its spread can be gathered through multiple rounds of error-prone diagnostic testing. We propose a novel adaptive procedure which quickly outputs an estimate for the cascade source and the full spread under this observation model. Remarkably, under mild conditions on the network topology, our procedure is able to estimate the full spread of the cascade in an $n$-vertex network, before $\\mathrm{poly log}(n)$ vertices are affected by the cascade. We complement our theoretical analysis with simulation results illustrating the effectiveness of our methods. ",
    "url": "https://arxiv.org/abs/2302.05418",
    "authors": [
      "Anirudh Sridhar",
      "Tirza Routtenberg",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2302.05419",
    "title": "Gauge-equivariant neural networks as preconditioners in lattice QCD",
    "abstract": "We demonstrate that a state-of-the art multi-grid preconditioner can be learned efficiently by gauge-equivariant neural networks. We show that the models require minimal re-training on different gauge configurations of the same gauge ensemble and to a large extent remain efficient under modest modifications of ensemble parameters. We also demonstrate that important paradigms such as communication avoidance are straightforward to implement in this framework. ",
    "url": "https://arxiv.org/abs/2302.05419",
    "authors": [
      "Christoph Lehner",
      "Tilo Wettig"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:1811.07130",
    "title": "Batch DropBlock Network for Person Re-identification and Beyond",
    "abstract": " Comments: Accepted by ICCV 2019 ",
    "url": "https://arxiv.org/abs/1811.07130",
    "authors": [
      "Zuozhuo Dai",
      "Mingqiang Chen",
      "Xiaodong Gu",
      "Siyu Zhu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1902.09040",
    "title": "Factoring Perfect Reconstruction Filter Banks into Causal Lifting  Matrices: A Diophantine Approach",
    "abstract": " Comments: 34 pages, 3 figures. Version 2: exposition expanded and corrected ",
    "url": "https://arxiv.org/abs/1902.09040",
    "authors": [
      "Christopher M. Brislawn"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2001.05670",
    "title": "Optimization of Convolutional Neural Network Using the Linearly  Decreasing Weight Particle Swarm Optimization",
    "abstract": " Comments: This paper is presented at the 36th Annual Conference of the Japanese Society for Artificial In-telligence ",
    "url": "https://arxiv.org/abs/2001.05670",
    "authors": [
      "T. Serizawa",
      "H. Fujita"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2008.13305",
    "title": "An Integrated Approach to Produce Robust Models with High Efficiency",
    "abstract": " Title: An Integrated Approach to Produce Robust Models with High Efficiency ",
    "url": "https://arxiv.org/abs/2008.13305",
    "authors": [
      "Zhijian Li",
      "Bao Wang",
      "Jack Xin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2012.11035",
    "title": "Contraction of $E_\u03b3$-Divergence and Its Applications to Privacy",
    "abstract": " Comments: Submitted ",
    "url": "https://arxiv.org/abs/2012.11035",
    "authors": [
      "Shahab Asoodeh",
      "Mario Diaz",
      "Flavio P. Calmon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2101.05509",
    "title": "Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake  News Detection",
    "abstract": " Comments: AAAI 2021 Workshop Best Paper. 9 pages, 1 figures ",
    "url": "https://arxiv.org/abs/2101.05509",
    "authors": [
      "Ben Chen",
      "Bin Chen",
      "Dehong Gao",
      "Qijin Chen",
      "Chengfu Huo",
      "Xiaonan Meng",
      "Weijun Ren",
      "Yang Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.05003",
    "title": "CondLaneNet: a Top-to-down Lane Detection Framework Based on Conditional  Convolution",
    "abstract": " Title: CondLaneNet: a Top-to-down Lane Detection Framework Based on Conditional  Convolution ",
    "url": "https://arxiv.org/abs/2105.05003",
    "authors": [
      "Lizhe Liu",
      "Xiaohao Chen",
      "Siyu Zhu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.04639",
    "title": "GenCAT: Generating Attributed Graphs with Controlled Relationships  between Classes, Attributes, and Topology",
    "abstract": " Comments: Accepted to Information Systems ",
    "url": "https://arxiv.org/abs/2109.04639",
    "authors": [
      "Seiji Maekawa",
      "Yuya Sasaki",
      "George Fletcher",
      "Makoto Onizuka"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2109.12390",
    "title": "Model reduction for the material point method via an implicit neural  representation of the deformation map",
    "abstract": " Title: Model reduction for the material point method via an implicit neural  representation of the deformation map ",
    "url": "https://arxiv.org/abs/2109.12390",
    "authors": [
      "Peter Yichen Chen",
      "Maurizio M. Chiaramonte",
      "Eitan Grinspun",
      "Kevin Carlberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.13997",
    "title": "On Privacy Weaknesses and Vulnerabilities in Software Systems",
    "abstract": " Title: On Privacy Weaknesses and Vulnerabilities in Software Systems ",
    "url": "https://arxiv.org/abs/2112.13997",
    "authors": [
      "Pattaraporn Sangaroonsilp",
      "Hoa Khanh Dam",
      "Aditya Ghose"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.02323",
    "title": "Distributed Nash Equilibrium Seeking over Time-Varying Directed  Communication Networks",
    "abstract": " Title: Distributed Nash Equilibrium Seeking over Time-Varying Directed  Communication Networks ",
    "url": "https://arxiv.org/abs/2201.02323",
    "authors": [
      "Duong Thuy Anh Nguyen",
      "Duong Tung Nguyen",
      "Angelia Nedi\u0107"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2202.03574",
    "title": "Structured Prediction Problem Archive",
    "abstract": " Comments: Added complete factorized multicat section ",
    "url": "https://arxiv.org/abs/2202.03574",
    "authors": [
      "Paul Swoboda",
      "Andrea Hornakova",
      "Paul Roetzer",
      "Bogdan Savchynskyy",
      "Ahmed Abbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.02719",
    "title": "DroidRL: Reinforcement Learning Driven Feature Selection for Android  Malware Detection",
    "abstract": " Title: DroidRL: Reinforcement Learning Driven Feature Selection for Android  Malware Detection ",
    "url": "https://arxiv.org/abs/2203.02719",
    "authors": [
      "Yinwei Wu",
      "Meijin Li",
      "Junfeng Wang",
      "Zhiyang Fang",
      "Qi Zeng",
      "Tao Yang",
      "Luyu Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.02394",
    "title": "SE(3)-Equivariant Attention Networks for Shape Reconstruction in  Function Space",
    "abstract": " Title: SE(3)-Equivariant Attention Networks for Shape Reconstruction in  Function Space ",
    "url": "https://arxiv.org/abs/2204.02394",
    "authors": [
      "Evangelos Chatzipantazis",
      "Stefanos Pertigkiozoglou",
      "Edgar Dobriban",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09056",
    "title": "Slowly Changing Adversarial Bandit Algorithms are Efficient for  Discounted MDPs",
    "abstract": " Title: Slowly Changing Adversarial Bandit Algorithms are Efficient for  Discounted MDPs ",
    "url": "https://arxiv.org/abs/2205.09056",
    "authors": [
      "Ian A. Kash",
      "Lev Reyzin",
      "Zishun Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10664",
    "title": "Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks",
    "abstract": " Comments: Published in ICLR 2023 (Oral) ",
    "url": "https://arxiv.org/abs/2205.10664",
    "authors": [
      "Guangji Bai",
      "Chen Ling",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11156",
    "title": "Squeeze Training for Adversarial Robustness",
    "abstract": " Comments: Accepted by ICLR 2023 ",
    "url": "https://arxiv.org/abs/2205.11156",
    "authors": [
      "Qizhang Li",
      "Yiwen Guo",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12379",
    "title": "Gaussian Pre-Activations in Neural Networks: Myth or Reality?",
    "abstract": " Title: Gaussian Pre-Activations in Neural Networks: Myth or Reality? ",
    "url": "https://arxiv.org/abs/2205.12379",
    "authors": [
      "Pierre Wolinski",
      "Julyan Arbel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.01041",
    "title": "End-to-End Security for Distributed Event-Driven Enclave Applications on  Heterogeneous TEEs",
    "abstract": " Comments: 40 pages main text + 4 pages appendix, submitted to ACM Transactions on Privacy and Security, first co-authorship between Gianluca Scopelliti and Sepideh Pouyanrad, source code available at this https URL ",
    "url": "https://arxiv.org/abs/2206.01041",
    "authors": [
      "Gianluca Scopelliti",
      "Sepideh Pouyanrad",
      "Job Noorman",
      "Fritz Alder",
      "Christoph Baumann",
      "Frank Piessens",
      "Jan Tobias M\u00fchlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.02094",
    "title": "Using Connectome Features to Constrain Echo State Networks",
    "abstract": " Comments: 8 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2206.02094",
    "authors": [
      "Jacob Morra",
      "Mark Daley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.07742",
    "title": "Human keypoint detection for close proximity human-robot interaction",
    "abstract": " Comments: 8 pages 8 figures ",
    "url": "https://arxiv.org/abs/2207.07742",
    "authors": [
      "Jan Docekal",
      "Jakub Rozlivek",
      "Jiri Matas",
      "Matej Hoffmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.09957",
    "title": "Heterogeneous Graph Masked Autoencoders",
    "abstract": " Comments: Accepted by AAAI 2023 (Oral) ",
    "url": "https://arxiv.org/abs/2208.09957",
    "authors": [
      "Yijun Tian",
      "Kaiwen Dong",
      "Chunhui Zhang",
      "Chuxu Zhang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.04265",
    "title": "Route Planning for Last-Mile Deliveries Using Mobile Parcel Lockers: A  Hybrid Q-Learning Network Approach",
    "abstract": " Comments: 54 pages, 18 figures. This paper has been submitted to Transportation Research Part E: Logistics and Transportation Review (Manuscript Number: TRE-D-23-00202) ",
    "url": "https://arxiv.org/abs/2209.04265",
    "authors": [
      "Yubin Liu",
      "Qiming Ye",
      "Jose Escribano-Macias",
      "Yuxiang Feng",
      "Eduardo Candela",
      "Panagiotis Angeloudis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.06177",
    "title": "Characterizing Graph Datasets for Node Classification:  Homophily-Heterophily Dichotomy and Beyond",
    "abstract": " Title: Characterizing Graph Datasets for Node Classification:  Homophily-Heterophily Dichotomy and Beyond ",
    "url": "https://arxiv.org/abs/2209.06177",
    "authors": [
      "Oleg Platonov",
      "Denis Kuznedelev",
      "Artem Babenko",
      "Liudmila Prokhorenkova"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2209.07027",
    "title": "Out-of-Distribution Representation Learning for Time Series  Classification",
    "abstract": " Comments: ICLR 2023; code is at: this https URL ",
    "url": "https://arxiv.org/abs/2209.07027",
    "authors": [
      "Wang Lu",
      "Jindong Wang",
      "Xinwei Sun",
      "Yiqiang Chen",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.07263",
    "title": "Robustness in deep learning: The good (width), the bad (depth), and the  ugly (initialization)",
    "abstract": " Comments: Accepted in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2209.07263",
    "authors": [
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11924",
    "title": "Interventional Causal Representation Learning",
    "abstract": " Title: Interventional Causal Representation Learning ",
    "url": "https://arxiv.org/abs/2209.11924",
    "authors": [
      "Kartik Ahuja",
      "Divyat Mahajan",
      "Yixin Wang",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04590",
    "title": "The Small Solution Hypothesis for MAPF on Strongly Connected Directed  Graphs Is True",
    "abstract": " Comments: Conference version, to be published at: The 33rd International Conference on Automated Planning and Scheduling (ICAPS-2023) ",
    "url": "https://arxiv.org/abs/2210.04590",
    "authors": [
      "Bernhard Nebel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.05794",
    "title": "Designing Robust Transformers using Robust Kernel Density Estimation",
    "abstract": " Comments: 21 pages, 2 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2210.05794",
    "authors": [
      "Xing Han",
      "Tongzheng Ren",
      "Tan Minh Nguyen",
      "Khai Nguyen",
      "Joydeep Ghosh",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16114",
    "title": "Towards Reliable Neural Specifications",
    "abstract": " Comments: 19 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2210.16114",
    "authors": [
      "Chuqin Geng",
      "Nham Le",
      "Xiaojie Xu",
      "Zhaoyue Wang",
      "Arie Gurfinkel",
      "Xujie Si"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.02489",
    "title": "Sampling Rate Offset Estimation and Compensation for Distributed  Adaptive Node-Specific Signal Estimation in Wireless Acoustic Sensor Networks",
    "abstract": " Comments: 9 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2211.02489",
    "authors": [
      "Paul Didier",
      "Toon van Waterschoot",
      "Simon Doclo",
      "Marc Moonen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.04154",
    "title": "Russian propaganda on social media during the 2022 invasion of Ukraine",
    "abstract": " Title: Russian propaganda on social media during the 2022 invasion of Ukraine ",
    "url": "https://arxiv.org/abs/2211.04154",
    "authors": [
      "Dominique Geissler",
      "Dominik B\u00e4r",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.09916",
    "title": "Online Distribution Shift Detection via Recency Prediction",
    "abstract": " Title: Online Distribution Shift Detection via Recency Prediction ",
    "url": "https://arxiv.org/abs/2211.09916",
    "authors": [
      "Rachel Luo",
      "Rohan Sinha",
      "Ali Hindy",
      "Shengjia Zhao",
      "Silvio Savarese",
      "Edward Schmerling",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10581",
    "title": "Sparse4D: Multi-view 3D Object Detection with Sparse Spatial-Temporal  Fusion",
    "abstract": " Title: Sparse4D: Multi-view 3D Object Detection with Sparse Spatial-Temporal  Fusion ",
    "url": "https://arxiv.org/abs/2211.10581",
    "authors": [
      "Xuewu Lin",
      "Tianwei Lin",
      "Zixiang Pei",
      "Lichao Huang",
      "Zhizhong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11711",
    "title": "CLAWSAT: Towards Both Robust and Accurate Code Models",
    "abstract": " Comments: Accepted by SANER2023 ",
    "url": "https://arxiv.org/abs/2211.11711",
    "authors": [
      "Jinghan Jia",
      "Shashank Srikant",
      "Tamara Mitrovska",
      "Chuang Gan",
      "Shiyu Chang",
      "Sijia Liu",
      "Una-May O'Reilly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.15223",
    "title": "Gamma-convergence of a nonlocal perimeter arising in adversarial machine  learning",
    "abstract": " Comments: More general asymptotics for adversarial training ",
    "url": "https://arxiv.org/abs/2211.15223",
    "authors": [
      "Leon Bungert",
      "Kerrek Stinson"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.10355",
    "title": "Optimizing Serially Concatenated Neural Codes with Classical Decoders",
    "abstract": " Comments: WSA/SCC 23, 6 pages ",
    "url": "https://arxiv.org/abs/2212.10355",
    "authors": [
      "Jannis Clausius",
      "Marvin Geiselhart",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.14266",
    "title": "Sequence Generation with Label Augmentation for Relation Extraction",
    "abstract": " Comments: AAAI2023 Regular Paper (oral) ",
    "url": "https://arxiv.org/abs/2212.14266",
    "authors": [
      "Bo Li",
      "Dingyao Yu",
      "Wei Ye",
      "Jinglei Zhang",
      "Shikun Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.01732",
    "title": "UNAEN: Unsupervised Abnormality Extraction Network for MRI Motion  Artifact Reduction",
    "abstract": " Title: UNAEN: Unsupervised Abnormality Extraction Network for MRI Motion  Artifact Reduction ",
    "url": "https://arxiv.org/abs/2301.01732",
    "authors": [
      "Yusheng Zhou",
      "Hao Li",
      "Jianan Liu",
      "Zhengmin Kong",
      "Tao Huang",
      "Euijoon Ahn",
      "Zhihan Lv"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2301.13538",
    "title": "AMD: Adaptive Masked Distillation for Object Detection",
    "abstract": " Title: AMD: Adaptive Masked Distillation for Object Detection ",
    "url": "https://arxiv.org/abs/2301.13538",
    "authors": [
      "Guang Yang",
      "Yin Tang",
      "Jun Li",
      "Jianhua Xu",
      "Xili Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.01478",
    "title": "Clustered Embedding Learning for Recommender Systems",
    "abstract": " Title: Clustered Embedding Learning for Recommender Systems ",
    "url": "https://arxiv.org/abs/2302.01478",
    "authors": [
      "Yizhou Chen",
      "Guangda Huzhang",
      "Anxiang Zeng",
      "Qingtao Yu",
      "Hui Sun",
      "Heng-yi Li",
      "Jingyi Li",
      "Yabo Ni",
      "Han Yu",
      "Zhiming Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01738",
    "title": "AIROGS: Artificial Intelligence for RObust Glaucoma Screening Challenge",
    "abstract": " Comments: 19 pages, 8 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2302.01738",
    "authors": [
      "Coen de Vente",
      "Koenraad A. Vermeer",
      "Nicolas Jaccard",
      "He Wang",
      "Hongyi Sun",
      "Firas Khader",
      "Daniel Truhn",
      "Temirgali Aimyshev",
      "Yerkebulan Zhanibekuly",
      "Tien-Dung Le",
      "Adrian Galdran",
      "Miguel \u00c1ngel Gonz\u00e1lez Ballester",
      "Gustavo Carneiro",
      "Devika R G",
      "Hrishikesh P S",
      "Densen Puthussery",
      "Hong Liu",
      "Zekang Yang",
      "Satoshi Kondo",
      "Satoshi Kasai",
      "Edward Wang",
      "Ashritha Durvasula",
      "J\u00f3nathan Heras",
      "Miguel \u00c1ngel Zapata",
      "Teresa Ara\u00fajo",
      "Guilherme Aresta",
      "Hrvoje Bogunovi\u0107",
      "Mustafa Arikan",
      "Yeong Chan Lee",
      "Hyun Bin Cho",
      "Yoon Ho Choi",
      "Abdul Qayyum",
      "Imran Razzak",
      "Bram van Ginneken",
      "Hans G. Lemij",
      "Clara I. S\u00e1nchez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03198",
    "title": "Scaling Self-Supervised End-to-End Driving with Multi-View Attention  Learning",
    "abstract": " Title: Scaling Self-Supervised End-to-End Driving with Multi-View Attention  Learning ",
    "url": "https://arxiv.org/abs/2302.03198",
    "authors": [
      "Yi Xiao",
      "Felipe Codevilla",
      "Diego Porres",
      "Antonio M. Lopez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.03376",
    "title": "System-Level Metrics for Non-Terrestrial Networks Under Stochastic  Geometry Framework",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2302.03376",
    "authors": [
      "Qi Huang",
      "Baha Eddine Youcef Belmekki",
      "Ahmed M. Eltawil",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.03566",
    "title": "Look around and learn: self-improving object detection by exploration",
    "abstract": " Title: Look around and learn: self-improving object detection by exploration ",
    "url": "https://arxiv.org/abs/2302.03566",
    "authors": [
      "Gianluca Scarpellini",
      "Stefano Rosa",
      "Pietro Morerio",
      "Lorenzo Natale",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04030",
    "title": "CrossCodeBench: Benchmarking Cross-Task Generalization of Source Code  Models",
    "abstract": " Comments: ICSE 2023 ",
    "url": "https://arxiv.org/abs/2302.04030",
    "authors": [
      "Changan Niu",
      "Chuanyi Li",
      "Vincent Ng",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04463",
    "title": "Practical Privacy Preservation in a Mobile Cloud Environment",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2302.04463",
    "authors": [
      "Dimitrios Tomaras",
      "Michail Tsenos",
      "Vana Kalogeraki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.04626",
    "title": "Self-Supervised Node Representation Learning via Node-to-Neighbourhood  Alignment",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2203.12265 ",
    "url": "https://arxiv.org/abs/2302.04626",
    "authors": [
      "Wei Dong",
      "Dawei Yan",
      "Peng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]