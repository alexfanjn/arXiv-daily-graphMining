[
  {
    "id": "arXiv:2302.04332",
    "title": "Continuous Learning for Android Malware Detection",
    "abstract": "Machine learning methods can detect Android malware with very high accuracy. However, these classifiers have an Achilles heel, concept drift: they rapidly become out of date and ineffective, due to the evolution of malware apps and benign apps. Our research finds that, after training an Android malware classifier on one year's worth of data, the F1 score quickly dropped from 0.99 to 0.76 after 6 months of deployment on new test samples. In this paper, we propose new methods to combat the concept drift problem of Android malware classifiers. Since machine learning technique needs to be continuously deployed, we use active learning: we select new samples for analysts to label, and then add the labeled samples to the training set to retrain the classifier. Our key idea is, similarity-based uncertainty is more robust against concept drift. Therefore, we combine contrastive learning with active learning. We propose a new hierarchical contrastive learning scheme, and a new sample selection technique to continuously train the Android malware classifier. Our evaluation shows that this leads to significant improvements, compared to previously published methods for active learning. Our approach reduces the false negative rate from 16% (for the best baseline) to 10%, while maintaining the same false positive rate (0.6%). Also, our approach maintains more consistent performance across a seven-year time period than past methods. ",
    "url": "https://arxiv.org/abs/2302.04332",
    "authors": [
      "Yizheng Chen",
      "Zhoujie Ding",
      "David Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04334",
    "title": "Asking for Help: Failure Prediction in Behavioral Cloning through Value  Approximation",
    "abstract": "Recent progress in end-to-end Imitation Learning approaches has shown promising results and generalization capabilities on mobile manipulation tasks. Such models are seeing increasing deployment in real-world settings, where scaling up requires robots to be able to operate with high autonomy, i.e. requiring as little human supervision as possible. In order to avoid the need for one-on-one human supervision, robots need to be able to detect and prevent policy failures ahead of time, and ask for help, allowing a remote operator to supervise multiple robots and help when needed. However, the black-box nature of end-to-end Imitation Learning models such as Behavioral Cloning, as well as the lack of an explicit state-value representation, make it difficult to predict failures. To this end, we introduce Behavioral Cloning Value Approximation (BCVA), an approach to learning a state value function based on and trained jointly with a Behavioral Cloning policy that can be used to predict failures. We demonstrate the effectiveness of BCVA by applying it to the challenging mobile manipulation task of latched-door opening, showing that we can identify failure scenarios with with 86% precision and 81% recall, evaluated on over 2000 real world runs, improving upon the baseline of simple failure classification by 10 percentage-points. ",
    "url": "https://arxiv.org/abs/2302.04334",
    "authors": [
      "Cem Gokmen",
      "Daniel Ho",
      "Mohi Khansari"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04335",
    "title": "Will ChatGPT get you caught? Rethinking of Plagiarism Detection",
    "abstract": "The rise of Artificial Intelligence (AI) technology and its impact on education has been a topic of growing concern in recent years. The new generation AI systems such as chatbots have become more accessible on the Internet and stronger in terms of capabilities. The use of chatbots, particularly ChatGPT, for generating academic essays at schools and colleges has sparked fears among scholars. This study aims to explore the originality of contents produced by one of the most popular AI chatbots, ChatGPT. To this end, two popular plagiarism detection tools were used to evaluate the originality of 50 essays generated by ChatGPT on various topics. Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software. In other words, ChatGPT can create content on many topics with high originality as if they were written by someone. These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort. Moreover, ChatGPT was asked to verify if the essays were generated by itself, as an additional measure of plagiarism check, and it showed superior performance compared to the traditional plagiarism-detection tools. The paper discusses the need for institutions to consider appropriate measures to mitigate potential plagiarism issues and advise on the ongoing debate surrounding the impact of AI technology on education. Further implications are discussed in the paper. ",
    "url": "https://arxiv.org/abs/2302.04335",
    "authors": [
      "Mohammad Khalil",
      "Erkan Er"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04343",
    "title": "CRL+: A Novel Semi-Supervised Deep Active Contrastive Representation  Learning-Based Text Classification Model for Insurance Data",
    "abstract": "Financial sector and especially the insurance industry collect vast volumes of text on a daily basis and through multiple channels (their agents, customer care centers, emails, social networks, and web in general). The information collected includes policies, expert and health reports, claims and complaints, results of surveys, and relevant social media posts. It is difficult to effectively extract label, classify, and interpret the essential information from such varied and unstructured material. Therefore, the Insurance Industry is among the ones that can benefit from applying technologies for the intelligent analysis of free text through Natural Language Processing (NLP). In this paper, CRL+, a novel text classification model combining Contrastive Representation Learning (CRL) and Active Learning is proposed to handle the challenge of using semi-supervised learning for text classification. In this method, supervised (CRL) is used to train a RoBERTa transformer model to encode the textual data into a contrastive representation space and then classify using a classification layer. This (CRL)-based transformer model is used as the base model in the proposed Active Learning mechanism to classify all the data in an iterative manner. The proposed model is evaluated using unstructured obituary data with objective to determine the cause of the death from the data. This model is compared with the CRL model and an Active Learning model with the RoBERTa base model. The experiment shows that the proposed method can outperform both methods for this specific task. ",
    "url": "https://arxiv.org/abs/2302.04343",
    "authors": [
      "Amir Namavar Jahromi",
      "Ebrahim Pourjafari",
      "Hadis Karimipour",
      "Amit Satpathy",
      "Lovell Hodge"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04359",
    "title": "Sentiment analysis and opinion mining on educational data: A survey",
    "abstract": "Sentiment analysis AKA opinion mining is one of the most widely used NLP applications to identify human intentions from their reviews. In the education sector, opinion mining is used to listen to student opinions and enhance their learning-teaching practices pedagogically. With advancements in sentiment annotation techniques and AI methodologies, student comments can be labelled with their sentiment orientation without much human intervention. In this review article, (1) we consider the role of emotional analysis in education from four levels: document level, sentence level, entity level, and aspect level, (2) sentiment annotation techniques including lexicon-based and corpus-based approaches for unsupervised annotations are explored, (3) the role of AI in sentiment analysis with methodologies like machine learning, deep learning, and transformers are discussed, (4) the impact of sentiment analysis on educational procedures to enhance pedagogy, decision-making, and evaluation are presented. Educational institutions have been widely invested to build sentiment analysis tools and process their student feedback to draw their opinions and insights. Applications built on sentiment analysis of student feedback are reviewed in this study. Challenges in sentiment analysis like multi-polarity, polysemous, negation words, and opinion spam detection are explored and their trends in the research space are discussed. The future directions of sentiment analysis in education are discussed. ",
    "url": "https://arxiv.org/abs/2302.04359",
    "authors": [
      "Thanveer Shaik",
      "Xiaohui Tao",
      "Christopher Dann",
      "Haoran Xie",
      "Yan Li",
      "Linda Galligan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.04363",
    "title": "Towards Model-Agnostic Federated Learning over Networks",
    "abstract": "We present a model-agnostic federated learning method for decentralized data with an intrinsic network structure. The network structure reflects similarities between the (statistics of) local datasets and, in turn, their associated local models. Our method is an instance of empirical risk minimization, using a regularization term that is constructed from the network structure of data. In particular, we require well-connected local models, forming clusters, to yield similar predictions on a common test set. In principle our method can be applied to any collection of local models. The only restriction put on these local models is that they allow for efficient implementation of regularized empirical risk minimization (training). Such implementations might be available in the form of high-level programming frameworks such as \\texttt{scikit-learn}, \\texttt{Keras} or \\texttt{PyTorch}. ",
    "url": "https://arxiv.org/abs/2302.04363",
    "authors": [
      "A. Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04369",
    "title": "Unsupervised Learning of Initialization in Deep Neural Networks via  Maximum Mean Discrepancy",
    "abstract": "Despite the recent success of stochastic gradient descent in deep learning, it is often difficult to train a deep neural network with an inappropriate choice of its initial parameters. Even if training is successful, it has been known that the initial parameter configuration may negatively impact generalization. In this paper, we propose an unsupervised algorithm to find good initialization for input data, given that a downstream task is d-way classification. We first notice that each parameter configuration in the parameter space corresponds to one particular downstream task of d-way classification. We then conjecture that the success of learning is directly related to how diverse downstream tasks are in the vicinity of the initial parameters. We thus design an algorithm that encourages small perturbation to the initial parameter configuration leads to a diverse set of d-way classification tasks. In other words, the proposed algorithm ensures a solution to any downstream task to be near the initial parameter configuration. We empirically evaluate the proposed algorithm on various tasks derived from MNIST with a fully connected network. In these experiments, we observe that our algorithm improves average test accuracy across most of these tasks, and that such improvement is greater when the number of labelled examples is small. ",
    "url": "https://arxiv.org/abs/2302.04369",
    "authors": [
      "Cheolhyoung Lee",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04373",
    "title": "Measuring the Privacy Leakage via Graph Reconstruction Attacks on  Simplicial Neural Networks (Student Abstract)",
    "abstract": "In this paper, we measure the privacy leakage via studying whether graph representations can be inverted to recover the graph used to generate them via graph reconstruction attack (GRA). We propose a GRA that recovers a graph's adjacency matrix from the representations via a graph decoder that minimizes the reconstruction loss between the partial graph and the reconstructed graph. We study three types of representations that are trained on the graph, i.e., representations output from graph convolutional network (GCN), graph attention network (GAT), and our proposed simplicial neural network (SNN) via a higher-order combinatorial Laplacian. Unlike the first two types of representations that only encode pairwise relationships, the third type of representation, i.e., SNN outputs, encodes higher-order interactions (e.g., homological features) between nodes. We find that the SNN outputs reveal the lowest privacy-preserving ability to defend the GRA, followed by those of GATs and GCNs, which indicates the importance of building more private representations with higher-order node information that could defend the potential threats, such as GRAs. ",
    "url": "https://arxiv.org/abs/2302.04373",
    "authors": [
      "Huixin Zhan",
      "Kun Zhang",
      "Keyi Lu",
      "Victor S. Sheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.04374",
    "title": "Near-Optimal Adversarial Reinforcement Learning with Switching Costs",
    "abstract": "Switching costs, which capture the costs for changing policies, are regarded as a critical metric in reinforcement learning (RL), in addition to the standard metric of losses (or rewards). However, existing studies on switching costs (with a coefficient $\\beta$ that is strictly positive and is independent of $T$) have mainly focused on static RL, where the loss distribution is assumed to be fixed during the learning process, and thus practical scenarios where the loss distribution could be non-stationary or even adversarial are not considered. While adversarial RL better models this type of practical scenarios, an open problem remains: how to develop a provably efficient algorithm for adversarial RL with switching costs? This paper makes the first effort towards solving this problem. First, we provide a regret lower-bound that shows that the regret of any algorithm must be larger than $\\tilde{\\Omega}( ( H S A )^{1/3} T^{2/3} )$, where $T$, $S$, $A$ and $H$ are the number of episodes, states, actions and layers in each episode, respectively. Our lower bound indicates that, due to the fundamental challenge of switching costs in adversarial RL, the best achieved regret (whose dependency on $T$ is $\\tilde{O}(\\sqrt{T})$) in static RL with switching costs (as well as adversarial RL without switching costs) is no longer achievable. Moreover, we propose two novel switching-reduced algorithms with regrets that match our lower bound when the transition function is known, and match our lower bound within a small factor of $\\tilde{O}( H^{1/3} )$ when the transition function is unknown. Our regret analysis demonstrates the near-optimal performance of them. ",
    "url": "https://arxiv.org/abs/2302.04374",
    "authors": [
      "Ming Shi",
      "Yingbin Liang",
      "Ness Shroff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.04379",
    "title": "Exploiting Certified Defences to Attack Randomised Smoothing",
    "abstract": "In guaranteeing that no adversarial examples exist within a bounded region, certification mechanisms play an important role in neural network robustness. Concerningly, this work demonstrates that the certification mechanisms themselves introduce a new, heretofore undiscovered attack surface, that can be exploited by attackers to construct smaller adversarial perturbations. While these attacks exist outside the certification region in no way invalidate certifications, minimising a perturbation's norm significantly increases the level of difficulty associated with attack detection. In comparison to baseline attacks, our new framework yields smaller perturbations more than twice as frequently as any other approach, resulting in an up to $34 \\%$ reduction in the median perturbation norm. That this approach also requires $90 \\%$ less computational time than approaches like PGD. That these reductions are possible suggests that exploiting this new attack vector would allow attackers to more frequently construct hard to detect adversarial attacks, by exploiting the very systems designed to defend deployed models. ",
    "url": "https://arxiv.org/abs/2302.04379",
    "authors": [
      "Andrew C. Cullen",
      "Paul Montague",
      "Shijie Liu",
      "Sarah M. Erfani",
      "Benjamin I.P. Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.04383",
    "title": "Privacy-Preserving Representation Learning for Text-Attributed Networks  with Simplicial Complexes",
    "abstract": "Although recent network representation learning (NRL) works in text-attributed networks demonstrated superior performance for various graph inference tasks, learning network representations could always raise privacy concerns when nodes represent people or human-related variables. Moreover, standard NRLs that leverage structural information from a graph proceed by first encoding pairwise relationships into learned representations and then analysing its properties. This approach is fundamentally misaligned with problems where the relationships involve multiple points, and topological structure must be encoded beyond pairwise interactions. Fortunately, the machinery of topological data analysis (TDA) and, in particular, simplicial neural networks (SNNs) offer a mathematically rigorous framework to learn higher-order interactions between nodes. It is critical to investigate if the representation outputs from SNNs are more vulnerable compared to regular representation outputs from graph neural networks (GNNs) via pairwise interactions. In my dissertation, I will first study learning the representations with text attributes for simplicial complexes (RT4SC) via SNNs. Then, I will conduct research on two potential attacks on the representation outputs from SNNs: (1) membership inference attack, which infers whether a certain node of a graph is inside the training data of the GNN model; and (2) graph reconstruction attacks, which infer the confidential edges of a text-attributed network. Finally, I will study a privacy-preserving deterministic differentially private alternating direction method of multiplier to learn secure representation outputs from SNNs that capture multi-scale relationships and facilitate the passage from local structure to global invariant features on text-attributed networks. ",
    "url": "https://arxiv.org/abs/2302.04383",
    "authors": [
      "Huixin Zhan",
      "Victor S. Sheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.04384",
    "title": "SF-SGL: Solver-Free Spectral Graph Learning from Linear Measurements",
    "abstract": "This work introduces a highly-scalable spectral graph densification framework (SGL) for learning resistor networks with linear measurements, such as node voltages and currents. We show that the proposed graph learning approach is equivalent to solving the classical graphical Lasso problems with Laplacian-like precision matrices. We prove that given $O(\\log N)$ pairs of voltage and current measurements, it is possible to recover sparse $N$-node resistor networks that can well preserve the effective resistance distances on the original graph. In addition, the learned graphs also preserve the structural (spectral) properties of the original graph, which can potentially be leveraged in many circuit design and optimization tasks. To achieve more scalable performance, we also introduce a solver-free method (SF-SGL) that exploits multilevel spectral approximation of the graphs and allows for a scalable and flexible decomposition of the entire graph spectrum (to be learned) into multiple different eigenvalue clusters (frequency bands). Such a solver-free approach allows us to more efficiently identify the most spectrally-critical edges for reducing various ranges of spectral embedding distortions. Through extensive experiments for a variety of real-world test cases, we show that the proposed approach is highly scalable for learning sparse resistor networks without sacrificing solution quality. We also introduce a data-driven EDA algorithm for vectorless power/thermal integrity verifications to allow estimating worst-case voltage/temperature (gradient) distributions across the entire chip by leveraging a few voltage/temperature measurements. ",
    "url": "https://arxiv.org/abs/2302.04384",
    "authors": [
      "Ying Zhang",
      "Zhiqiang Zhao",
      "Zhuo Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.04406",
    "title": "Light and Accurate: Neural Architecture Search via Two Constant Shared  Weights Initialisations",
    "abstract": "In recent years, zero-cost proxies are gaining ground in neural architecture search (NAS). These methods allow finding the optimal neural network for a given task faster and with a lesser computational load than conventional NAS methods. Equally important is the fact that they also shed some light on the internal workings of neural architectures. This paper presents a zero-cost metric that highly correlates with the train set accuracy across the NAS-Bench-101, NAS-Bench-201 and NAS-Bench-NLP benchmark datasets. Architectures are initialised with two distinct constant shared weights, one at a time. Then, a fixed random mini-batch of data is passed forward through each initialisation. We observe that the dispersion of the outputs between two initialisations positively correlates with trained accuracy. The correlation further improves when we normalise dispersion by average output magnitude. Our metric, epsilon, does not require gradients computation or labels. It thus unbinds the NAS procedure from training hyperparameters, loss metrics and human-labelled data. Our method is easy to integrate within existing NAS algorithms and takes a fraction of a second to evaluate a single network. ",
    "url": "https://arxiv.org/abs/2302.04406",
    "authors": [
      "Ekaterina Gracheva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04441",
    "title": "Multi-task Representation Learning for Pure Exploration in Linear  Bandits",
    "abstract": "Despite the recent success of representation learning in sequential decision making, the study of the pure exploration scenario (i.e., identify the best option and minimize the sample complexity) is still limited. In this paper, we study multi-task representation learning for best arm identification in linear bandits (RepBAI-LB) and best policy identification in contextual linear bandits (RepBPI-CLB), two popular pure exploration settings with wide applications, e.g., clinical trials and web content optimization. In these two problems, all tasks share a common low-dimensional linear representation, and our goal is to leverage this feature to accelerate the best arm (policy) identification process for all tasks. For these problems, we design computationally and sample efficient algorithms DouExpDes and C-DouExpDes, which perform double experimental designs to plan optimal sample allocations for learning the global representation. We show that by learning the common representation among tasks, our sample complexity is significantly better than that of the native approach which solves tasks independently. To the best of our knowledge, this is the first work to demonstrate the benefits of representation learning for multi-task pure exploration. ",
    "url": "https://arxiv.org/abs/2302.04441",
    "authors": [
      "Yihan Du",
      "Longbo Huang",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04445",
    "title": "Quantum Multi-Agent Actor-Critic Networks for Cooperative Mobile Access  in Multi-UAV Systems",
    "abstract": "This paper proposes a novel quantum multi-agent actor-critic networks (QMACN) algorithm for autonomously constructing a robust mobile access system using multiple unmanned aerial vehicles (UAVs). For the cooperation of multiple UAVs for autonomous mobile access, multi-agent reinforcement learning (MARL) methods are considered. In addition, we also adopt the concept of quantum computing (QC) to improve the training and inference performances. By utilizing QC, scalability and physical issues can happen. However, our proposed QMACN algorithm builds quantum critic and multiple actor networks in order to handle such problems. Thus, our proposed QMACN algorithm verifies the advantage of quantum MARL with remarkable performance improvements in terms of training speed and wireless service quality in various data-intensive evaluations. Furthermore, we validate that a noise injection scheme can be used for handling environmental uncertainties in order to realize robust mobile access. Our data-intensive simulation results verify that our proposed QMACN algorithm outperforms the other existing algorithms. ",
    "url": "https://arxiv.org/abs/2302.04445",
    "authors": [
      "Chanyoung Park",
      "Won Joon Yun",
      "Jae Pyoung Kim",
      "Tiago Koketsu Rodrigues",
      "Soohyun Park",
      "Soyi Jung",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04450",
    "title": "Tracking Fringe and Coordinated Activity on Twitter Leading Up To the US  Capitol Attack",
    "abstract": "The aftermath of the 2020 US Presidential Election witnessed an unprecedented attack on the democratic values of the country through the violent insurrection at Capitol Hill on January 6th, 2021. The attack was fueled by the proliferation of conspiracy theories and misleading claims about the integrity of the election pushed by political elites and fringe communities on social media. In this study, we explore the evolution of fringe content and conspiracy theories on Twitter in the seven months leading up to the Capitol attack. We examine the suspicious coordinated activity carried out by users sharing fringe content, finding evidence of common adversarial manipulation techniques ranging from targeted amplification to manufactured consensus. Further, we map out the temporal evolution of, and the relationship between, fringe and conspiracy theories, which eventually coalesced into the rhetoric of a stolen election, with the hashtag #stopthesteal, alongside QAnon-related narratives. Our findings further highlight how social media platforms offer fertile ground for the widespread proliferation of conspiracies during major societal events, which can potentially lead to offline coordinated actions and organized violence. ",
    "url": "https://arxiv.org/abs/2302.04450",
    "authors": [
      "Vishnuprasad Padinjaredath Suresh",
      "Gianluca Nogara",
      "Felipe Cardoso",
      "Stefano Cresci",
      "Silvia Giordano",
      "Luca Luceri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.04451",
    "title": "Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on  Graph Diffusion",
    "abstract": "Graph neural networks are widely used tools for graph prediction tasks. Motivated by their empirical performance, prior works have developed generalization bounds for graph neural networks, which scale with graph structures in terms of the maximum degree. In this paper, we present generalization bounds that instead scale with the largest singular value of the graph neural network's feature diffusion matrix. These bounds are numerically much smaller than prior bounds for real-world graphs. We also construct a lower bound of the generalization gap that matches our upper bound asymptotically. To achieve these results, we analyze a unified model that includes prior works' settings (i.e., convolutional and message-passing networks) and new settings (i.e., graph isomorphism networks). Our key idea is to measure the stability of graph neural networks against noise perturbations using Hessians. Empirically, we find that Hessian-based measurements correlate with the observed generalization gaps of graph neural networks accurately; Optimizing noise stability properties for fine-tuning pretrained graph neural networks also improves test performance on several graph-level classification tasks. ",
    "url": "https://arxiv.org/abs/2302.04451",
    "authors": [
      "Haotian Ju",
      "Dongyue Li",
      "Aneesh Sharma",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.04457",
    "title": "Imperceptible Sample-Specific Backdoor to DNN with Denoising Autoencoder",
    "abstract": "The backdoor attack poses a new security threat to deep neural networks. Existing backdoor often relies on visible universal trigger to make the backdoored model malfunction, which are not only usually visually suspicious to human but also catchable by mainstream countermeasures. We propose an imperceptible sample-specific backdoor that the trigger varies from sample to sample and invisible. Our trigger generation is automated through a desnoising autoencoder that is fed with delicate but pervasive features (i.e., edge patterns per images). We extensively experiment our backdoor attack on ImageNet and MS-Celeb-1M, which demonstrates stable and nearly 100% (i.e., 99.8%) attack success rate with negligible impact on the clean data accuracy of the infected model. The denoising autoeconder based trigger generator is reusable or transferable across tasks (e.g., from ImageNet to MS-Celeb-1M), whilst the trigger has high exclusiveness (i.e., a trigger generated for one sample is not applicable to another sample). Besides, our proposed backdoored model has achieved high evasiveness against mainstream backdoor defenses such as Neural Cleanse, STRIP, SentiNet and Fine-Pruning. ",
    "url": "https://arxiv.org/abs/2302.04457",
    "authors": [
      "Jiliang Zhang",
      "Jing Xu",
      "Zhi Zhang",
      "Yansong Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.04461",
    "title": "Hubbard-Stratonovich Detector for Simple Trainable MIMO Signal Detection",
    "abstract": "Massive multiple-input multiple-output (MIMO) is a key technology used in fifth-generation wireless communication networks and beyond. Recently, various MIMO signal detectors based on deep learning have been proposed. Especially, deep unfolding (DU), which involves unrolling of an existing iterative algorithm and embedding of trainable parameters, has been applied with remarkable detection performance. Although DU has a lesser number of trainable parameters than conventional deep neural networks, the computational complexities related to training and execution have been problematic because DU-based MIMO detectors usually utilize matrix inversion to improve their detection performance. In this study, we attempted to construct a DU-based trainable MIMO detector with the simplest structure. The proposed detector based on the Hubbard--Stratonovich (HS) transformation and DU is called the trainable HS (THS) detector. It requires only $O(1)$ trainable parameters and its training and execution cost is $O(n^2)$ per iteration, where $n$ is the number of transmitting antennas. Numerical results show that the detection performance of the THS detector is better than that of existing algorithms of the same complexity and close to that of a DU-based detector, which has higher training and execution costs than the THS detector. ",
    "url": "https://arxiv.org/abs/2302.04461",
    "authors": [
      "Satoshi Takabe",
      "Takashi Abe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.04463",
    "title": "Practical Privacy Preservation in a Mobile Cloud Environment",
    "abstract": "The proliferation of smartphone devices has led to the emergence of powerful user services from enabling interactions with friends and business associates to mapping, finding nearby businesses and alerting users in real-time. Moreover, users do not realize that continuously sharing their trajectory data with online systems may end up revealing a great amount of information in terms of their behavior, mobility patterns and social relationships. Thus, addressing these privacy risks is a fundamental challenge. In this work, we present $TP^3$, a Privacy Protection system for Trajectory analytics. Our contributions are the following: (1) we model a new type of attack, namely 'social link exploitation attack', (2) we utilize the coresets theory, a fast and accurate technique which approximates well the original data using a small data set, and running queries on the coreset produces similar results to the original data, and (3) we employ the Serverless computing paradigm to accommodate a set of privacy operations for achieving high system performance with minimized provisioning costs, while preserving the users' privacy. We have developed these techniques in our $TP^3$ system that works with state-of-the-art trajectory analytics apps and applies different types of privacy operations. Our detailed experimental evaluation illustrates that our approach is both efficient and practical. ",
    "url": "https://arxiv.org/abs/2302.04463",
    "authors": [
      "Dimitrios Tomaras",
      "Michail Tsenos",
      "Vana Kalogeraki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.04497",
    "title": "Scale-aware neural calibration for wide swath altimetry observations",
    "abstract": "Sea surface height (SSH) is a key geophysical parameter for monitoring and studying meso-scale surface ocean dynamics. For several decades, the mapping of SSH products at regional and global scales has relied on nadir satellite altimeters, which provide one-dimensional-only along-track satellite observations of the SSH. The Surface Water and Ocean Topography (SWOT) mission deploys a new sensor that acquires for the first time wide-swath two-dimensional observations of the SSH. This provides new means to observe the ocean at previously unresolved spatial scales. A critical challenge for the exploiting of SWOT data is the separation of the SSH from other signals present in the observations. In this paper, we propose a novel learning-based approach for this SWOT calibration problem. It benefits from calibrated nadir altimetry products and a scale-space decomposition adapted to SWOT swath geometry and the structure of the different processes in play. In a supervised setting, our method reaches the state-of-the-art residual error of ~1.4cm while proposing a correction on the entire spectral from 10km to 1000k ",
    "url": "https://arxiv.org/abs/2302.04497",
    "authors": [
      "Febvre Quentin",
      "Ubelmann Cl\u00e9ment",
      "Le Sommer Julien",
      "Fablet Ronan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2302.04519",
    "title": "RayNet: A Simulation Platform for Developing Reinforcement  Learning-Driven Network Protocols",
    "abstract": "Reinforcement Learning has gained significant momentum in the development of network protocols. However, learning-based protocols are still in their infancy, and substantial research is required to build deployable solutions. Developing a protocol based on reinforcement learning is a complex and challenging process that involves several model design decisions and requires significant training and evaluation in real or realistic network topologies. Network simulators offer RL-based protocols a highly effective training environment, because simulations are deterministic and can run in parallel. In this paper, we introduce RayNet, a scalable and adaptable simulation framework for the development of learning-based network protocols. RayNet integrates OMNeT++, a fully programmable network simulator, with Ray/RLlib, a scalable training platform for distributed reinforcement learning. RayNet facilitates the methodical development of RL-based network protocols with minimal overhead. We have developed a congestion control use case and present evidence that RayNet can be a valuable framework for the computer networks research community. ",
    "url": "https://arxiv.org/abs/2302.04519",
    "authors": [
      "Luca Giacomoni",
      "Basil Benny",
      "George Parisis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.04521",
    "title": "IH-ViT: Vision Transformer-based Integrated Circuit Appear-ance Defect  Detection",
    "abstract": "For the problems of low recognition rate and slow recognition speed of traditional detection methods in IC appearance defect detection, we propose an IC appearance defect detection algo-rithm IH-ViT. Our proposed model takes advantage of the respective strengths of CNN and ViT to acquire image features from both local and global aspects, and finally fuses the two features for decision making to determine the class of defects, thus obtaining better accuracy of IC defect recognition. To address the problem that IC appearance defects are mainly reflected in the dif-ferences in details, which are difficult to identify by traditional algorithms, we improved the tra-ditional ViT by performing an additional convolution operation inside the batch. For the problem of information imbalance of samples due to diverse sources of data sets, we adopt a dual-channel image segmentation technique to further improve the accuracy of IC appearance defects. Finally, after testing, our proposed hybrid IH-ViT model achieved 72.51% accuracy, which is 2.8% and 6.06% higher than ResNet50 and ViT models alone. The proposed algorithm can quickly and accurately detect the defect status of IC appearance and effectively improve the productivity of IC packaging and testing companies. ",
    "url": "https://arxiv.org/abs/2302.04521",
    "authors": [
      "Xiaoibin Wang",
      "Shuang Gao",
      "Yuntao Zou",
      "Jianlan Guo",
      "Chu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04522",
    "title": "Hardness of monadic second-order formulae over succinct graphs",
    "abstract": "Our main result is a succinct counterpoint to Courcelle's meta-theorem as follows: every arborescent monadic second-order (MSO) property is either NP-hard or coNP-hard over graphs given by succinct representations. Succint representations are Boolean circuits computing the adjacency relation. Arborescent properties are those which have infinitely many models and countermodels with bounded treewidth. We actually prove this result in the terminology of automata network, which is a generalization of finite cellular automata over arbitrary graphs. This model arose from the biological modelization of neural networks and gene regulation networks. Our result states that every arborescent MSO property on the transition graph of automata networks is either NP-hard or coNP-hard. Moreover, we explore what happens when the arborescence condition is dropped and show that, under a reasonable complexity assumption, the previous dichotomy fails, even for questions expressible in first-order logic. ",
    "url": "https://arxiv.org/abs/2302.04522",
    "authors": [
      "Guilhem Gamard",
      "Pierre Guillon",
      "K\u00e9vin Perrot",
      "Guillaume Theyssier"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2302.04527",
    "title": "Toward Extremely Lightweight Distracted Driver Recognition With  Distillation-Based Neural Architecture Search and Knowledge Transfer",
    "abstract": "The number of traffic accidents has been continuously increasing in recent years worldwide. Many accidents are caused by distracted drivers, who take their attention away from driving. Motivated by the success of Convolutional Neural Networks (CNNs) in computer vision, many researchers developed CNN-based algorithms to recognize distracted driving from a dashcam and warn the driver against unsafe behaviors. However, current models have too many parameters, which is unfeasible for vehicle-mounted computing. This work proposes a novel knowledge-distillation-based framework to solve this problem. The proposed framework first constructs a high-performance teacher network by progressively strengthening the robustness to illumination changes from shallow to deep layers of a CNN. Then, the teacher network is used to guide the architecture searching process of a student network through knowledge distillation. After that, we use the teacher network again to transfer knowledge to the student network by knowledge distillation. Experimental results on the Statefarm Distracted Driver Detection Dataset and AUC Distracted Driver Dataset show that the proposed approach is highly effective for recognizing distracted driving behaviors from photos: (1) the teacher network's accuracy surpasses the previous best accuracy; (2) the student network achieves very high accuracy with only 0.42M parameters (around 55% of the previous most lightweight model). Furthermore, the student network architecture can be extended to a spatial-temporal 3D CNN for recognizing distracted driving from video clips. The 3D student network largely surpasses the previous best accuracy with only 2.03M parameters on the Drive&Act Dataset. The source code is available at https://github.com/Dichao-Liu/Lightweight_Distracted_Driver_Recognition_with_Distillation-Based_NAS_and_Knowledge_Transfer. ",
    "url": "https://arxiv.org/abs/2302.04527",
    "authors": [
      "Dichao Liu",
      "Toshihiko Yamasaki",
      "Yu Wang",
      "Kenji Mase",
      "Jien Kato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04541",
    "title": "Forensic Log Based Detection For Keystroke Injection \"BadUsb\" Attacks",
    "abstract": "This document describes an experiment with main purpose to detect BadUSB attacks that utilize external Human Interaction Device hardware gadgets to inject keystrokes and acquire remote code execution. One of the main goals, is to detect such activity based on behavioral factors and allow everyone with a basic set of cognitive capabilities ,regardless of the user being a human or a computer, to identify anomalous speed related indicators but also correlate such speed changes with other elements such as commonly malicious processes like powershell processes being called in close proximity timing-wise, PnP device events occurring correlated with driver images loaded. ",
    "url": "https://arxiv.org/abs/2302.04541",
    "authors": [
      "George Karantzas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.04544",
    "title": "Gaussian Mask Convolution for Convolutional Neural Networks",
    "abstract": "Square convolution is a default unit in convolutional neural networks as it fits well on the tensor computation for convolution operation, which usually has a fixed N x N receptive field (RF). However, what matters most to the network is the effective receptive field (ERF), which indicates the extent each pixel contributes to the output. ERF shows a Gaussian distribution and can not be modeled by simply sampling pixels with offsets. To simulate ERF, we propose a Gaussian Mask convolutional kernel (GMConv) in this work. Specifically, GMConv utilizes the Gaussian function to generate a concentric symmetry mask and put the mask over the kernel to refine the RF. Our GMConv can directly replace the standard convolutions in existing CNNs and can be easily trained end-to-end by standard backpropagation. Extensive experiments on multiple image classification benchmark datasets show that our method is comparable to, and outperforms in many cases, the standard convolution. For instance, using GMConv for AlexNet and ResNet-50, the top-1 accuracy on ImageNet classification is boosted by 0.98% and 0.85%, respectively. ",
    "url": "https://arxiv.org/abs/2302.04544",
    "authors": [
      "Qi Chen",
      "Chao Li",
      "Jia Ning",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04552",
    "title": "Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial  Online Convex Optimization",
    "abstract": "Stochastically Extended Adversarial (SEA) model is introduced by Sachs et al. [2022] as an interpolation between stochastic and adversarial online convex optimization. Under the smoothness condition, they demonstrate that the expected regret of optimistic follow-the-regularized-leader (FTRL) depends on the cumulative stochastic variance $\\sigma_{1:T}^2$ and the cumulative adversarial variation $\\Sigma_{1:T}^2$ for convex functions. They also provide a slightly weaker bound based on the maximal stochastic variance $\\sigma_{\\max}^2$ and the maximal adversarial variation $\\Sigma_{\\max}^2$ for strongly convex functions. Inspired by their work, we investigate the theoretical guarantees of optimistic online mirror descent (OMD) for the SEA model. For convex and smooth functions, we obtain the same $\\mathcal{O}(\\sqrt{\\sigma_{1:T}^2}+\\sqrt{\\Sigma_{1:T}^2})$ regret bound, without the convexity requirement of individual functions. For strongly convex and smooth functions, we establish an $\\mathcal{O}(\\min\\{\\log (\\sigma_{1:T}^2+\\Sigma_{1:T}^2), (\\sigma_{\\max}^2 + \\Sigma_{\\max}^2) \\log T\\})$ bound, better than their $\\mathcal{O}((\\sigma_{\\max}^2 + \\Sigma_{\\max}^2) \\log T)$ bound. For \\mbox{exp-concave} and smooth functions, we achieve a new $\\mathcal{O}(d\\log(\\sigma_{1:T}^2+\\Sigma_{1:T}^2))$ bound. Owing to the OMD framework, we can further extend our result to obtain dynamic regret guarantees, which are more favorable in non-stationary online scenarios. The attained results allow us to recover excess risk bounds of the stochastic setting and regret bounds of the adversarial setting, and derive new guarantees for many intermediate scenarios. ",
    "url": "https://arxiv.org/abs/2302.04552",
    "authors": [
      "Sijia Chen",
      "Wei-Wei Tu",
      "Peng Zhao",
      "Lijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.04555",
    "title": "Data Augmentation for Robust Character Detection in Fantasy Novels",
    "abstract": "Named Entity Recognition (NER) is a low-level task often used as a foundation for solving higher level NLP problems. In the context of character detection in novels, NER false negatives can be an issue as they possibly imply missing certain characters or relationships completely. In this article, we demonstrate that applying a straightforward data augmentation technique allows training a model achieving higher recall, at the cost of a certain amount of precision regarding ambiguous entities. We show that this decrease in precision can be mitigated by giving the model more local context, which resolves some of the ambiguities. ",
    "url": "https://arxiv.org/abs/2302.04555",
    "authors": [
      "Arthur Amalvy",
      "Vincent Labatut",
      "Richard Dufour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.04578",
    "title": "Adversarial Example Does Good: Preventing Painting Imitation from  Diffusion Models via Adversarial Examples",
    "abstract": "Diffusion Models (DMs) achieve state-of-the-art performance in generative tasks, boosting a wave in AI for Art. Despite the success of commercialization, DMs meanwhile provide tools for copyright violations, where infringers benefit from illegally using paintings created by human artists to train DMs and generate novel paintings in a similar style. In this paper, we show that it is possible to create an image $x'$ that is similar to an image $x$ for human vision but unrecognizable for DMs. We build a framework to define and evaluate this adversarial example for diffusion models. Based on the framework, we further propose AdvDM, an algorithm to generate adversarial examples for DMs. By optimizing upon different latent variables sampled from the reverse process of DMs, AdvDM conducts a Monte-Carlo estimation of adversarial examples for DMs. Extensive experiments show that the estimated adversarial examples can effectively hinder DMs from extracting their features. Our method can be a powerful tool for human artists to protect their copyright against infringers with DM-based AI-for-Art applications. ",
    "url": "https://arxiv.org/abs/2302.04578",
    "authors": [
      "Chumeng Liang",
      "Xiaoyu Wu",
      "Yang Hua",
      "Jiaru Zhang",
      "Yiming Xue",
      "Tao Song",
      "Zhengui Xue",
      "Ruhui Ma",
      "Haibing Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04584",
    "title": "Complex Network for Complex Problems: A comparative study of CNN and  Complex-valued CNN",
    "abstract": "Neural networks, especially convolutional neural networks (CNN), are one of the most common tools these days used in computer vision. Most of these networks work with real-valued data using real-valued features. Complex-valued convolutional neural networks (CV-CNN) can preserve the algebraic structure of complex-valued input data and have the potential to learn more complex relationships between the input and the ground-truth. Although some comparisons of CNNs and CV-CNNs for different tasks have been performed in the past, a large-scale investigation comparing different models operating on different tasks has not been conducted. Furthermore, because complex features contain both real and imaginary components, CV-CNNs have double the number of trainable parameters as real-valued CNNs in terms of the actual number of trainable parameters. Whether or not the improvements in performance with CV-CNN observed in the past have been because of the complex features or just because of having double the number of trainable parameters has not yet been explored. This paper presents a comparative study of CNN, CNNx2 (CNN with double the number of trainable parameters as the CNN), and CV-CNN. The experiments were performed using seven models for two different tasks - brain tumour classification and segmentation in brain MRIs. The results have revealed that the CV-CNN models outperformed the CNN and CNNx2 models. ",
    "url": "https://arxiv.org/abs/2302.04584",
    "authors": [
      "Soumick Chatterjee",
      "Pavan Tummala",
      "Oliver Speck",
      "Andreas N\u00fcrnberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.04589",
    "title": "MAPS: A Noise-Robust Progressive Learning Approach for Source-Free  Domain Adaptive Keypoint Detection",
    "abstract": "Existing cross-domain keypoint detection methods always require accessing the source data during adaptation, which may violate the data privacy law and pose serious security concerns. Instead, this paper considers a realistic problem setting called source-free domain adaptive keypoint detection, where only the well-trained source model is provided to the target domain. For the challenging problem, we first construct a teacher-student learning baseline by stabilizing the predictions under data augmentation and network ensembles. Built on this, we further propose a unified approach, Mixup Augmentation and Progressive Selection (MAPS), to fully exploit the noisy pseudo labels of unlabeled target data during training. On the one hand, MAPS regularizes the model to favor simple linear behavior in-between the target samples via self-mixup augmentation, preventing the model from over-fitting to noisy predictions. On the other hand, MAPS employs the self-paced learning paradigm and progressively selects pseudo-labeled samples from `easy' to `hard' into the training process to reduce noise accumulation. Results on four keypoint detection datasets show that MAPS outperforms the baseline and achieves comparable or even better results in comparison to previous non-source-free counterparts. ",
    "url": "https://arxiv.org/abs/2302.04589",
    "authors": [
      "Yuhe Ding",
      "Jian Liang",
      "Bo Jiang",
      "Aihua Zheng",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04608",
    "title": "Differentially Private Deep Q-Learning for Pattern Privacy Preservation  in MEC Offloading",
    "abstract": "Mobile edge computing (MEC) is a promising paradigm to meet the quality of service (QoS) requirements of latency-sensitive IoT applications. However, attackers may eavesdrop on the offloading decisions to infer the edge server's (ES's) queue information and users' usage patterns, thereby incurring the pattern privacy (PP) issue. Therefore, we propose an offloading strategy which jointly minimizes the latency, ES's energy consumption, and task dropping rate, while preserving PP. Firstly, we formulate the dynamic computation offloading procedure as a Markov decision process (MDP). Next, we develop a Differential Privacy Deep Q-learning based Offloading (DP-DQO) algorithm to solve this problem while addressing the PP issue by injecting noise into the generated offloading decisions. This is achieved by modifying the deep Q-network (DQN) with a Function-output Gaussian process mechanism. We provide a theoretical privacy guarantee and a utility guarantee (learning error bound) for the DP-DQO algorithm and finally, conduct simulations to evaluate the performance of our proposed algorithm by comparing it with greedy and DQN-based algorithms. ",
    "url": "https://arxiv.org/abs/2302.04608",
    "authors": [
      "Shuying Gan",
      "Marie Siew",
      "Chao Xu",
      "Tony Q.S. Quek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04610",
    "title": "Outlier-Robust Gromov Wasserstein for Graph Data",
    "abstract": "Gromov Wasserstein (GW) distance is a powerful tool for comparing and aligning probability distributions supported on different metric spaces. It has become the main modeling technique for aligning heterogeneous data for a wide range of graph learning tasks. However, the GW distance is known to be highly sensitive to outliers, which can result in large inaccuracies if the outliers are given the same weight as other samples in the objective function. To mitigate this issue, we introduce a new and robust version of the GW distance called RGW. RGW features optimistically perturbed marginal constraints within a $\\varphi$-divergence based ambiguity set. To make the benefits of RGW more accessible in practice, we develop a computationally efficient algorithm, Bregman proximal alternating linearization minimization, with a theoretical convergence guarantee. Through extensive experimentation, we validate our theoretical results and demonstrate the effectiveness of RGW on real-world graph learning tasks, such as subgraph matching and partial shape correspondence. ",
    "url": "https://arxiv.org/abs/2302.04610",
    "authors": [
      "Lemin Kong",
      "Jiajin Li",
      "Anthony Man-Cho So"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.04614",
    "title": "SoK: A Data-driven View on Methods to Detect Reflective Amplification  DDoS Attacks Using Honeypots",
    "abstract": "In this paper, we revisit the use of honeypots for detecting reflective amplification attacks. These measurement tools require careful design of both data collection and data analysis including cautious threshold inference. We survey common amplification honeypot platforms as well as the underlying methods to infer attack detection thresholds and to extract knowledge from the data. By systematically exploring the threshold space, we find most honeypot platforms produce comparable results despite their different configurations. Moreover, by applying data from a large-scale honeypot deployment, network telescopes, and a real-world baseline obtained from a leading DDoS mitigation provider, we question the fundamental assumption of honeypot research that convergence of observations can imply their completeness. Conclusively we derive guidance on precise, reproducible honeypot research, and present open challenges. ",
    "url": "https://arxiv.org/abs/2302.04614",
    "authors": [
      "Marcin Nawrocki",
      "John Kristoff",
      "Raphael Hiesgen",
      "Chris Kanich",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.04618",
    "title": "Robust Question Answering against Distribution Shifts with Test-Time  Adaptation: An Empirical Study",
    "abstract": "A deployed question answering (QA) model can easily fail when the test data has a distribution shift compared to the training data. Robustness tuning (RT) methods have been widely studied to enhance model robustness against distribution shifts before model deployment. However, can we improve a model after deployment? To answer this question, we evaluate test-time adaptation (TTA) to improve a model after deployment. We first introduce COLDQA, a unified evaluation benchmark for robust QA against text corruption and changes in language and domain. We then evaluate previous TTA methods on COLDQA and compare them to RT methods. We also propose a novel TTA method called online imitation learning (OIL). Through extensive experiments, we find that TTA is comparable to RT methods, and applying TTA after RT can significantly boost the performance on COLDQA. Our proposed OIL improves TTA to be more robust to variation in hyper-parameters and test distributions over time. ",
    "url": "https://arxiv.org/abs/2302.04618",
    "authors": [
      "Hai Ye",
      "Yuyang Ding",
      "Juntao Li",
      "Hwee Tou Ng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.04624",
    "title": "A new width parameter of graphs based on edge cuts:  $\u03b1$-edge-crossing width",
    "abstract": "We introduce graph width parameters, called $\\alpha$-edge-crossing width and edge-crossing width. These are defined in terms of the number of edges crossing a bag of a tree-cut decomposition. They are motivated by edge-cut width, recently introduced by Brand et al. (WG 2022). We show that edge-crossing width is equivalent to the known parameter tree-partition-width. On the other hand, $\\alpha$-edge-crossing width is a new parameter; tree-cut width and $\\alpha$-edge-crossing width are incomparable, and they both lie between tree-partition-width and edge-cut width. We provide an algorithm that, for a given $n$-vertex graph $G$ and integers $k$ and $\\alpha$, in time $2^{O((\\alpha+k)\\log (\\alpha+k))}n^2$ either outputs a tree-cut decomposition certifying that the $\\alpha$-edge-crossing width of $G$ is at most $2\\alpha^2+5k$ or confirms that the $\\alpha$-edge-crossing width of $G$ is more than $k$. As applications, for every fixed $\\alpha$, we obtain FPT algorithms for the List Coloring and Precoloring Extension problems parameterized by $\\alpha$-edge-crossing width. They were known to be W[1]-hard parameterized by tree-partition-width, and FPT parameterized by edge-cut width, and we close the complexity gap between these two parameters. ",
    "url": "https://arxiv.org/abs/2302.04624",
    "authors": [
      "Yeonsu Chang",
      "O-joung Kwon",
      "Myounghwan Lee"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2302.04626",
    "title": "Self-Supervised Node Representation Learning via Node-to-Neighbourhood  Alignment",
    "abstract": "Self-supervised node representation learning aims to learn node representations from unlabelled graphs that rival the supervised counterparts. The key towards learning informative node representations lies in how to effectively gain contextual information from the graph structure. In this work, we present simple-yet-effective self-supervised node representation learning via aligning the hidden representations of nodes and their neighbourhood. Our first idea achieves such node-to-neighbourhood alignment by directly maximizing the mutual information between their representations, which, we prove theoretically, plays the role of graph smoothing. Our framework is optimized via a surrogate contrastive loss and a Topology-Aware Positive Sampling (TAPS) strategy is proposed to sample positives by considering the structural dependencies between nodes, which enables offline positive selection. Considering the excessive memory overheads of contrastive learning, we further propose a negative-free solution, where the main contribution is a Graph Signal Decorrelation (GSD) constraint to avoid representation collapse and over-smoothing. The GSD constraint unifies some of the existing constraints and can be used to derive new implementations to combat representation collapse. By applying our methods on top of simple MLP-based node representation encoders, we learn node representations that achieve promising node classification performance on a set of graph-structured datasets from small- to large-scale. ",
    "url": "https://arxiv.org/abs/2302.04626",
    "authors": [
      "Wei Dong",
      "Dawei Yan",
      "Peng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04638",
    "title": "Better Diffusion Models Further Improve Adversarial Training",
    "abstract": "It has been recognized that the data generated by the denoising diffusion probabilistic model (DDPM) improves adversarial training. After two years of rapid development in diffusion models, a question naturally arises: can better diffusion models further improve adversarial training? This paper gives an affirmative answer by employing the most recent diffusion model which has higher efficiency ($\\sim 20$ sampling steps) and image quality (lower FID score) compared with DDPM. Our adversarially trained models achieve state-of-the-art performance on RobustBench using only generated data (no external datasets). Under the $\\ell_\\infty$-norm threat model with $\\epsilon=8/255$, our models achieve $70.69\\%$ and $42.67\\%$ robust accuracy on CIFAR-10 and CIFAR-100, respectively, i.e. improving upon previous state-of-the-art models by $+4.58\\%$ and $+8.03\\%$. Under the $\\ell_2$-norm threat model with $\\epsilon=128/255$, our models achieve $84.86\\%$ on CIFAR-10 ($+4.44\\%$). These results also beat previous works that use external data. Our code is available at https://github.com/wzekai99/DM-Improves-AT. ",
    "url": "https://arxiv.org/abs/2302.04638",
    "authors": [
      "Zekai Wang",
      "Tianyu Pang",
      "Chao Du",
      "Min Lin",
      "Weiwei Liu",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04666",
    "title": "Understand Code Style: Efficient CNN-based Compiler Optimization  Recognition System",
    "abstract": "Compiler optimization level recognition can be applied to vulnerability discovery and binary analysis. Due to the exists of many different compilation optimization options, the difference in the contents of the binary file is very complicated. There are thousands of compiler optimization algorithms and multiple different processor architectures, so it is very difficult to manually analyze binary files and recognize its compiler optimization level with rules. This paper first proposes a CNN-based compiler optimization level recognition model: BinEye. The system extracts semantic and structural differences and automatically recognize the compiler optimization levels. The model is designed to be very suitable for binary file processing and is easy to understand. We built a dataset containing 80,028 binary files for the model training and testing. Our proposed model achieves an accuracy of over 97%. At the same time, BinEye is a fully CNN-based system and it has a faster forward calculation speed, at least 8 times faster than the normal RNN-based model. Through our analysis of the model output, we successfully found the difference in assembly codes caused by the different compiler optimization level. This means that the model we proposed is interpretable. Based on our model, we propose a method to analyze the code differences caused by different compiler optimization levels, which has great guiding significance for analyzing closed source compilers and binary security analysis. ",
    "url": "https://arxiv.org/abs/2302.04666",
    "authors": [
      "Shouguo Yang",
      "Zhiqiang Shi",
      "Guodong Zhang",
      "Mingxuan Li",
      "Yuan Ma",
      "Limin Sun"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2302.04675",
    "title": "Vulnerability Detection with Graph Simplification and Enhanced Graph  Representation Learning",
    "abstract": "Prior studies have demonstrated the effectiveness of Deep Learning (DL) in automated software vulnerability detection. Graph Neural Networks (GNNs) have proven effective in learning the graph representations of source code and are commonly adopted by existing DL-based vulnerability detection methods. However, the existing methods are still limited by the fact that GNNs are essentially difficult to handle the connections between long-distance nodes in a code structure graph. Besides, they do not well exploit the multiple types of edges in a code structure graph (such as edges representing data flow and control flow). Consequently, despite achieving state-of-the-art performance, the existing GNN-based methods tend to fail to capture global information (i.e., long-range dependencies among nodes) of code graphs. To mitigate these issues, in this paper, we propose a novel vulnerability detection framework with grAph siMplification and enhanced graph rePresentation LEarning, named AMPLE. AMPLE mainly contains two parts: 1) graph simplification, which aims at reducing the distances between nodes by shrinking the node sizes of code structure graphs; 2) enhanced graph representation learning, which involves one edge-aware graph convolutional network module for fusing heterogeneous edge information into node representations and one kernel-scaled representation module for well capturing the relations between distant graph nodes. Experiments on three public benchmark datasets show that AMPLE outperforms the state-of-the-art methods by 0.39%-35.32% and 7.64%-199.81% with respect to the accuracy and F1 score metrics, respectively. The results demonstrate the effectiveness of AMPLE in learning global information of code graphs for vulnerability detection. ",
    "url": "https://arxiv.org/abs/2302.04675",
    "authors": [
      "Xin-Cheng Wen",
      "Yupan Chen",
      "Cuiyun Gao",
      "Hongyu Zhang",
      "Jie M.Zhang",
      "Qing Liao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.04676",
    "title": "Stacked Cross-modal Feature Consolidation Attention Networks for Image  Captioning",
    "abstract": "Recently, the attention-enriched encoder-decoder framework has aroused great interest in image captioning due to its overwhelming progress. Many visual attention models directly leverage meaningful regions to generate image descriptions. However, seeking a direct transition from visual space to text is not enough to generate fine-grained captions. This paper exploits a feature-compounding approach to bring together high-level semantic concepts and visual information regarding the contextual environment fully end-to-end. Thus, we propose a stacked cross-modal feature consolidation (SCFC) attention network for image captioning in which we simultaneously consolidate cross-modal features through a novel compounding function in a multi-step reasoning fashion. Besides, we jointly employ spatial information and context-aware attributes (CAA) as the principal components in our proposed compounding function, where our CAA provides a concise context-sensitive semantic representation. To make better use of consolidated features potential, we further propose an SCFC-LSTM as the caption generator, which can leverage discriminative semantic information through the caption generation process. The experimental results indicate that our proposed SCFC can outperform various state-of-the-art image captioning benchmarks in terms of popular metrics on the MSCOCO and Flickr30K datasets. ",
    "url": "https://arxiv.org/abs/2302.04676",
    "authors": [
      "Mozhgan Pourkeshavarz",
      "Shahabedin Nabavi",
      "Mohsen Ebrahimi Moghaddam",
      "Mehrnoush Shamsfard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.04677",
    "title": "Mixed-order self-paced curriculum learning for universal lesion  detection",
    "abstract": "Self-paced curriculum learning (SCL) has demonstrated its great potential in computer vision, natural language processing, etc. During training, it implements easy-to-hard sampling based on online estimation of data difficulty. Most SCL methods commonly adopt a loss-based strategy of estimating data difficulty and deweighting the `hard' samples in the early training stage. While achieving success in a variety of applications, SCL stills confront two challenges in a medical image analysis task, such as universal lesion detection, featuring insufficient and highly class-imbalanced data: (i) the loss-based difficulty measurer is inaccurate; ii) the hard samples are under-utilized from a deweighting mechanism. To overcome these challenges, in this paper we propose a novel mixed-order self-paced curriculum learning (Mo-SCL) method. We integrate both uncertainty and loss to better estimate difficulty online and mix both hard and easy samples in the same mini-batch to appropriately alleviate the problem of under-utilization of hard samples. We provide a theoretical investigation of our method in the context of stochastic gradient descent optimization and extensive experiments based on the DeepLesion benchmark dataset for universal lesion detection (ULD). When applied to two state-of-the-art ULD methods, the proposed mixed-order SCL method can provide a free boost to lesion detection accuracy without extra special network designs. ",
    "url": "https://arxiv.org/abs/2302.04677",
    "authors": [
      "Han Li",
      "Hu Han",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04712",
    "title": "DeepCAM: A Fully CAM-based Inference Accelerator with Variable Hash  Lengths for Energy-efficient Deep Neural Networks",
    "abstract": "With ever increasing depth and width in deep neural networks to achieve state-of-the-art performance, deep learning computation has significantly grown, and dot-products remain dominant in overall computation time. Most prior works are built on conventional dot-product where weighted input summation is used to represent the neuron operation. However, another implementation of dot-product based on the notion of angles and magnitudes in the Euclidean space has attracted limited attention. This paper proposes DeepCAM, an inference accelerator built on two critical innovations to alleviate the computation time bottleneck of convolutional neural networks. The first innovation is an approximate dot-product built on computations in the Euclidean space that can replace addition and multiplication with simple bit-wise operations. The second innovation is a dynamic size content addressable memory-based (CAM-based) accelerator to perform bit-wise operations and accelerate the CNNs with a lower computation time. Our experiments on benchmark image recognition datasets demonstrate that DeepCAM is up to 523x and 3498x faster than Eyeriss and traditional CPUs like Intel Skylake, respectively. Furthermore, the energy consumed by our DeepCAM approach is 2.16x to 109x less compared to Eyeriss. ",
    "url": "https://arxiv.org/abs/2302.04712",
    "authors": [
      "Duy-Thanh Nguyen",
      "Abhiroop Bhattacharjee",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2302.04720",
    "title": "Computers as Bad Social Actors: Dark Patterns and Anti-Patterns in  Interfaces that Act Socially",
    "abstract": "The Computers Are Social Actors (CASA) paradigm suggests people exhibit social/anthropomorphic biases in their treatment of technology. Such insights have encouraged interaction designers to make automated systems act in more social (chatty or even friend-like) ways. However, like typical dark patterns, social-emotional responses to systems as (seemingly sentient) agents can be harnessed to manipulate user behaviour. An increasingly common example is app notifications that assume person-like tones to persuade or pressure users into compliance. Even without manipulative intent, difficulties meeting contextual social expectations can make automated social acting seem rude, invasive, tactless, and even disrespectful -- constituting social `anti-patterns'. This paper explores ways to improve how automated systems treat people in interactions. We mixed four qualitative methods to elicit user experiences and preferences regarding how interfaces ``talk'' to/at them. We identify an emerging `social' class of dark and anti-patterns, and propose guidelines for helping (`social') interfaces treat users in more respectful, tactful, and autonomy-supportive ways. ",
    "url": "https://arxiv.org/abs/2302.04720",
    "authors": [
      "Lize Alberts",
      "Max Van Kleek"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.04737",
    "title": "A Biomedical Knowledge Graph for Biomarker Discovery in Cancer",
    "abstract": "Structured and unstructured data and facts about drugs, genes, protein, viruses, and their mechanism are spread across a huge number of scientific articles. These articles are a large-scale knowledge source and can have a huge impact on disseminating knowledge about the mechanisms of certain biological processes. A domain-specific knowledge graph~(KG) is an explicit conceptualization of a specific subject-matter domain represented w.r.t semantically interrelated entities and relations. A KG can be constructed by integrating such facts and data and be used for data integration, exploration, and federated queries. However, exploration and querying large-scale KGs is tedious for certain groups of users due to a lack of knowledge about underlying data assets or semantic technologies. Such a KG will not only allow deducing new knowledge and question answering(QA) but also allows domain experts to explore. Since cross-disciplinary explanations are important for accurate diagnosis, it is important to query the KG to provide interactive explanations about learned biomarkers. Inspired by these, we construct a domain-specific KG, particularly for cancer-specific biomarker discovery. The KG is constructed by integrating cancer-related knowledge and facts from multiple sources. First, we construct a domain-specific ontology, which we call OncoNet Ontology (ONO). The ONO ontology is developed to enable semantic reasoning for verification of the predictions for relations between diseases and genes. The KG is then developed and enriched by harmonizing the ONO, additional metadata schemas, ontologies, controlled vocabularies, and additional concepts from external sources using a BERT-based information extraction method. BioBERT and SciBERT are finetuned with the selected articles crawled from PubMed. We listed down some queries and some examples of QA and deducing knowledge based on the KG. ",
    "url": "https://arxiv.org/abs/2302.04737",
    "authors": [
      "Md. Rezaul Karim",
      "Lina Comet",
      "Oya Beyan",
      "Michael Cochez",
      "Dietrich Rebholz-Schuhmann",
      "Stefan Decker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04747",
    "title": "An $O(\\log k)$-Approximation for Directed Steiner Tree in Planar Graphs",
    "abstract": "We present an $O(\\log k)$-approximation for both the edge-weighted and node-weighted versions of \\DST in planar graphs where $k$ is the number of terminals. We extend our approach to \\MDST (in general graphs \\MDST and \\DST are easily seen to be equivalent but in planar graphs this is not the case necessarily) in which we get a $O(R+\\log k)$-approximation for planar graphs for where $R$ is the number of roots. ",
    "url": "https://arxiv.org/abs/2302.04747",
    "authors": [
      "Zachary Friggstad",
      "Ramin Mousavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.04751",
    "title": "Mission Planning and Execution in Heterogeneous Teams of Aerial Robots  supporting Power Line Inspection Operations",
    "abstract": "A software architecture aimed at coordinating a team of heterogeneous aerial vehicles for inspection and maintenance operations in high-voltage power line scenarios is presented in this paper. A hierarchical approach deals with high-level tasks by planning and executing complex missions requiring vehicles to support human operators. A resource-constrained problem allows distributing tasks among the team taking into account vehicles' capabilities and battery constraints. Besides, Behavior Trees (BTs) are in charge of mission execution, triggering replanning operations in case of unforeseen events, such as vehicle faults or communication drop-outs. The feasibility and validity of the approach are showcased through realistic simulations achieved in Gazebo. ",
    "url": "https://arxiv.org/abs/2302.04751",
    "authors": [
      "Alvaro Calvo",
      "Giuseppe Silano",
      "Jesus Capitan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.04775",
    "title": "Adap-tau: Adaptively Modulating Embedding Magnitude for Recommendation",
    "abstract": "Recent years have witnessed the great successes of embedding-based methods in recommender systems. Despite their decent performance, we argue one potential limitation of these methods -- the embedding magnitude has not been explicitly modulated, which may aggravate popularity bias and training instability, hindering the model from making a good recommendation. It motivates us to leverage the embedding normalization in recommendation. By normalizing user/item embeddings to a specific value, we empirically observe impressive performance gains (9\\% on average) on four real-world datasets. Although encouraging, we also reveal a serious limitation when applying normalization in recommendation -- the performance is highly sensitive to the choice of the temperature $\\tau$ which controls the scale of the normalized embeddings. To fully foster the merits of the normalization while circumvent its limitation, this work studied on how to adaptively set the proper $\\tau$. Towards this end, we first make a comprehensive analyses of $\\tau$ to fully understand its role on recommendation. We then accordingly develop an adaptive fine-grained strategy Adap-$\\tau$ for the temperature with satisfying four desirable properties including adaptivity, personalized, efficiency and model-agnostic. Extensive experiments have been conducted to validate the effectiveness of the proposal. The code is available at \\url{https://github.com/junkangwu/Adap_tau}. ",
    "url": "https://arxiv.org/abs/2302.04775",
    "authors": [
      "Jiawei Chen",
      "Junkang Wu",
      "Jiancan Wu",
      "Sheng Zhou",
      "Xuezhi Cao",
      "Xiangnan He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04785",
    "title": "Analysis of business process automation as linear time-invariant system  network",
    "abstract": "In this work, we examined Business Process (BP) production as a signal; this novel approach explores a BP workflow as a linear time-invariant (LTI) system. We analysed BP productivity in the frequency domain; this standpoint examines how labour and capital act as BP input signals and how their fundamental frequencies affect BP production. Our research also proposes a simulation framework of a BP in the frequency domain for estimating productivity gains due to the introduction of automation steps. Our ultimate goal was to supply evidence to address Solow's Paradox. ",
    "url": "https://arxiv.org/abs/2302.04785",
    "authors": [
      "Mauricio Jacobo-Romero",
      "Danilo S. Carvalho",
      "Andre Freitas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2302.04787",
    "title": "Distributed Learning with Curious and Adversarial Machines",
    "abstract": "The ubiquity of distributed machine learning (ML) in sensitive public domain applications calls for algorithms that protect data privacy, while being robust to faults and adversarial behaviors. Although privacy and robustness have been extensively studied independently in distributed ML, their synthesis remains poorly understood. We present the first tight analysis of the error incurred by any algorithm ensuring robustness against a fraction of adversarial machines, as well as differential privacy (DP) for honest machines' data against any other curious entity. Our analysis exhibits a fundamental trade-off between privacy, robustness, and utility. Surprisingly, we show that the cost of this trade-off is marginal compared to that of the classical privacy-utility trade-off. To prove our lower bound, we consider the case of mean estimation, subject to distributed DP and robustness constraints, and devise reductions to centralized estimation of one-way marginals. We prove our matching upper bound by presenting a new distributed ML algorithm using a high-dimensional robust aggregation rule. The latter amortizes the dependence on the dimension in the error (caused by adversarial workers and DP), while being agnostic to the statistical properties of the data. ",
    "url": "https://arxiv.org/abs/2302.04787",
    "authors": [
      "Youssef Allouah",
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "Rafael Pinot",
      "John Stephan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.04815",
    "title": "To Perceive or Not to Perceive: Lightweight Stacked Hourglass Network",
    "abstract": "Human pose estimation (HPE) is a classical task in computer vision that focuses on representing the orientation of a person by identifying the positions of their joints. We design a lighterversion of the stacked hourglass network with minimal loss in performance of the model. The lightweight 2-stacked hourglass has a reduced number of channels with depthwise separable convolutions, residual connections with concatenation, and residual connections between the necks of the hourglasses. The final model has a marginal drop in performance with 79% reduction in the number of parameters and a similar drop in MAdds ",
    "url": "https://arxiv.org/abs/2302.04815",
    "authors": [
      "Jameel Hassan Abdul Samadh",
      "Salwa K. Al Khatib"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.04823",
    "title": "Hierarchical Generative Adversarial Imitation Learning with Mid-level  Input Generation for Autonomous Driving on Urban Environments",
    "abstract": "Deriving robust control policies for realistic urban navigation scenarios is not a trivial task. In an end-to-end approach, these policies must map high-dimensional images from the vehicle's cameras to low-level actions such as steering and throttle. While pure Reinforcement Learning (RL) approaches are based exclusively on rewards,Generative Adversarial Imitation Learning (GAIL) agents learn from expert demonstrations while interacting with the environment, which favors GAIL on tasks for which a reward signal is difficult to derive. In this work, the hGAIL architecture was proposed to solve the autonomous navigation of a vehicle in an end-to-end approach, mapping sensory perceptions directly to low-level actions, while simultaneously learning mid-level input representations of the agent's environment. The proposed hGAIL consists of an hierarchical Adversarial Imitation Learning architecture composed of two main modules: the GAN (Generative Adversarial Nets) which generates the Bird's-Eye View (BEV) representation mainly from the images of three frontal cameras of the vehicle, and the GAIL which learns to control the vehicle based mainly on the BEV predictions from the GAN as input.Our experiments have shown that GAIL exclusively from cameras (without BEV) fails to even learn the task, while hGAIL, after training, was able to autonomously navigate successfully in all intersections of the city. ",
    "url": "https://arxiv.org/abs/2302.04823",
    "authors": [
      "Gustavo Claudio Karl Couto",
      "Eric Aislan Antonelo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.04832",
    "title": "Bridging the Sim2Real gap with CARE: Supervised Detection Adaptation  with Conditional Alignment and Reweighting",
    "abstract": "Sim2Real domain adaptation (DA) research focuses on the constrained setting of adapting from a labeled synthetic source domain to an unlabeled or sparsely labeled real target domain. However, for high-stakes applications (e.g. autonomous driving), it is common to have a modest amount of human-labeled real data in addition to plentiful auto-labeled source data (e.g. from a driving simulator). We study this setting of supervised sim2real DA applied to 2D object detection. We propose Domain Translation via Conditional Alignment and Reweighting (CARE) a novel algorithm that systematically exploits target labels to explicitly close the sim2real appearance and content gaps. We present an analytical justification of our algorithm and demonstrate strong gains over competing methods on standard benchmarks. ",
    "url": "https://arxiv.org/abs/2302.04832",
    "authors": [
      "Viraj Prabhu",
      "David Acuna",
      "Andrew Liao",
      "Rafid Mahmood",
      "Marc T. Law",
      "Judy Hoffman",
      "Sanja Fidler",
      "James Lucas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04834",
    "title": "FrameBERT: Conceptual Metaphor Detection with Frame Embedding Learning",
    "abstract": "In this paper, we propose FrameBERT, a RoBERTa-based model that can explicitly learn and incorporate FrameNet Embeddings for concept-level metaphor detection. FrameBERT not only achieves better or comparable performance to the state-of-the-art, but also is more explainable and interpretable compared to existing models, attributing to its ability of accounting for external knowledge of FrameNet. ",
    "url": "https://arxiv.org/abs/2302.04834",
    "authors": [
      "Yucheng Li",
      "Shun Wang",
      "Chenghua Lin",
      "Frank Guerin",
      "Lo\u00efc Barrault"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.04852",
    "title": "SparseProp: Efficient Sparse Backpropagation for Faster Training of  Neural Networks",
    "abstract": "We provide a new efficient version of the backpropagation algorithm, specialized to the case where the weights of the neural network being trained are sparse. Our algorithm is general, as it applies to arbitrary (unstructured) sparsity and common layer types (e.g., convolutional or linear). We provide a fast vectorized implementation on commodity CPUs, and show that it can yield speedups in end-to-end runtime experiments, both in transfer learning using already-sparsified networks, and in training sparse networks from scratch. Thus, our results provide the first support for sparse training on commodity hardware. ",
    "url": "https://arxiv.org/abs/2302.04852",
    "authors": [
      "Mahdi Nikdan",
      "Tommaso Pegolotti",
      "Eugenia Iofinova",
      "Eldar Kurtic",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04856",
    "title": "One-shot Visual Imitation via Attributed Waypoints and Demonstration  Augmentation",
    "abstract": "In this paper, we analyze the behavior of existing techniques and design new solutions for the problem of one-shot visual imitation. In this setting, an agent must solve a novel instance of a novel task given just a single visual demonstration. Our analysis reveals that current methods fall short because of three errors: the DAgger problem arising from purely offline training, last centimeter errors in interacting with objects, and mis-fitting to the task context rather than to the actual task. This motivates the design of our modular approach where we a) separate out task inference (what to do) from task execution (how to do it), and b) develop data augmentation and generation techniques to mitigate mis-fitting. The former allows us to leverage hand-crafted motor primitives for task execution which side-steps the DAgger problem and last centimeter errors, while the latter gets the model to focus on the task rather than the task context. Our model gets 100% and 48% success rates on two recent benchmarks, improving upon the current state-of-the-art by absolute 90% and 20% respectively. ",
    "url": "https://arxiv.org/abs/2302.04856",
    "authors": [
      "Matthew Chang",
      "Saurabh Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04860",
    "title": "Diverse Human Motion Prediction Guided by Multi-Level Spatial-Temporal  Anchors",
    "abstract": "Predicting diverse human motions given a sequence of historical poses has received increasing attention. Despite rapid progress, existing work captures the multi-modal nature of human motions primarily through likelihood-based sampling, where the mode collapse has been widely observed. In this paper, we propose a simple yet effective approach that disentangles randomly sampled codes with a deterministic learnable component named anchors to promote sample precision and diversity. Anchors are further factorized into spatial anchors and temporal anchors, which provide attractively interpretable control over spatial-temporal disparity. In principle, our spatial-temporal anchor-based sampling (STARS) can be applied to different motion predictors. Here we propose an interaction-enhanced spatial-temporal graph convolutional network (IE-STGCN) that encodes prior knowledge of human motions (e.g., spatial locality), and incorporate the anchors into it. Extensive experiments demonstrate that our approach outperforms state of the art in both stochastic and deterministic prediction, suggesting it as a unified framework for modeling human motions. Our code and pretrained models are available at https://github.com/Sirui-Xu/STARS. ",
    "url": "https://arxiv.org/abs/2302.04860",
    "authors": [
      "Sirui Xu",
      "Yu-Xiong Wang",
      "Liang-Yan Gui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04862",
    "title": "Polynomial Neural Fields for Subband Decomposition and Manipulation",
    "abstract": "Neural fields have emerged as a new paradigm for representing signals, thanks to their ability to do it compactly while being easy to optimize. In most applications, however, neural fields are treated like black boxes, which precludes many signal manipulation tasks. In this paper, we propose a new class of neural fields called polynomial neural fields (PNFs). The key advantage of a PNF is that it can represent a signal as a composition of a number of manipulable and interpretable components without losing the merits of neural fields representation. We develop a general theoretical framework to analyze and design PNFs. We use this framework to design Fourier PNFs, which match state-of-the-art performance in signal representation tasks that use neural fields. In addition, we empirically demonstrate that Fourier PNFs enable signal manipulation applications such as texture transfer and scale-space interpolation. Code is available at https://github.com/stevenygd/PNF. ",
    "url": "https://arxiv.org/abs/2302.04862",
    "authors": [
      "Guandao Yang",
      "Sagie Benaim",
      "Varun Jampani",
      "Kyle Genova",
      "Jonathan T. Barron",
      "Thomas Funkhouser",
      "Bharath Hariharan",
      "Serge Belongie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04866",
    "title": "RelightableHands: Efficient Neural Relighting of Articulated Hand Models",
    "abstract": "We present the first neural relighting approach for rendering high-fidelity personalized hands that can be animated in real-time under novel illumination. Our approach adopts a teacher-student framework, where the teacher learns appearance under a single point light from images captured in a light-stage, allowing us to synthesize hands in arbitrary illuminations but with heavy compute. Using images rendered by the teacher model as training data, an efficient student model directly predicts appearance under natural illuminations in real-time. To achieve generalization, we condition the student model with physics-inspired illumination features such as visibility, diffuse shading, and specular reflections computed on a coarse proxy geometry, maintaining a small computational overhead. Our key insight is that these features have strong correlation with subsequent global light transport effects, which proves sufficient as conditioning data for the neural relighting network. Moreover, in contrast to bottleneck illumination conditioning, these features are spatially aligned based on underlying geometry, leading to better generalization to unseen illuminations and poses. In our experiments, we demonstrate the efficacy of our illumination feature representations, outperforming baseline approaches. We also show that our approach can photorealistically relight two interacting hands at real-time speeds. https://sh8.io/#/relightable_hands ",
    "url": "https://arxiv.org/abs/2302.04866",
    "authors": [
      "Shun Iwase",
      "Shunsuke Saito",
      "Tomas Simon",
      "Stephen Lombardi",
      "Timur Bagautdinov",
      "Rohan Joshi",
      "Fabian Prada",
      "Takaaki Shiratori",
      "Yaser Sheikh",
      "Jason Saragih"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2302.04868",
    "title": "MEGANE: Morphable Eyeglass and Avatar Network",
    "abstract": "Eyeglasses play an important role in the perception of identity. Authentic virtual representations of faces can benefit greatly from their inclusion. However, modeling the geometric and appearance interactions of glasses and the face of virtual representations of humans is challenging. Glasses and faces affect each other's geometry at their contact points, and also induce appearance changes due to light transport. Most existing approaches do not capture these physical interactions since they model eyeglasses and faces independently. Others attempt to resolve interactions as a 2D image synthesis problem and suffer from view and temporal inconsistencies. In this work, we propose a 3D compositional morphable model of eyeglasses that accurately incorporates high-fidelity geometric and photometric interaction effects. To support the large variation in eyeglass topology efficiently, we employ a hybrid representation that combines surface geometry and a volumetric representation. Unlike volumetric approaches, our model naturally retains correspondences across glasses, and hence explicit modification of geometry, such as lens insertion and frame deformation, is greatly simplified. In addition, our model is relightable under point lights and natural illumination, supporting high-fidelity rendering of various frame materials, including translucent plastic and metal within a single morphable model. Importantly, our approach models global light transport effects, such as casting shadows between faces and glasses. Our morphable model for eyeglasses can also be fit to novel glasses via inverse rendering. We compare our approach to state-of-the-art methods and demonstrate significant quality improvements. ",
    "url": "https://arxiv.org/abs/2302.04868",
    "authors": [
      "Junxuan Li",
      "Shunsuke Saito",
      "Tomas Simon",
      "Stephen Lombardi",
      "Hongdong Li",
      "Jason Saragih"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2302.04341",
    "title": "Neonatal Face and Facial Landmark Detection from Video Recordings",
    "abstract": "This paper explores automated face and facial landmark detection of neonates, which is an important first step in many video-based neonatal health applications, such as vital sign estimation, pain assessment, sleep-wake classification, and jaundice detection. Utilising three publicly available datasets of neonates in the clinical environment, 366 images (258 subjects) and 89 (66 subjects) were annotated for training and testing, respectively. Transfer learning was applied to two YOLO-based models, with input training images augmented with random horizontal flipping, photo-metric colour distortion, translation and scaling during each training epoch. Additionally, the re-orientation of input images and fusion of trained deep learning models was explored. Our proposed model based on YOLOv7Face outperformed existing methods with a mean average precision of 84.8% for face detection, and a normalised mean error of 0.072 for facial landmark detection. Overall, this will assist in the development of fully automated neonatal health assessment algorithms. ",
    "url": "https://arxiv.org/abs/2302.04341",
    "authors": [
      "Ethan Grooby",
      "Chiranjibi Sitaula",
      "Soodeh Ahani",
      "Liisa Holsti",
      "Atul Malhotra",
      "Guy A. Dumont",
      "Faezeh Marzbanrad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04361",
    "title": "Robust trajectory optimisation for transitions of tiltwing VTOL aircraft",
    "abstract": "We propose a method to generate robust and optimal trajectories for the transition of a tiltwing Vertical Take-Off and Landing (VTOL) aircraft leveraging concepts from convex optimisation, tube-based nonlinear Model Predictive Control (MPC) and Difference of Convex (DC) functions decomposition. The approach relies on computing DC decompositions of dynamic models in order to exploit convexity properties and develop a tractable robust optimisation that solves a sequence of convex programs converging to a local optimum of the trajectory generation problem. The algorithm developed is applied to an Urban Air Mobility case study. The resulting solutions are robust to approximation errors in dynamic models and provide safe trajectories for aggressive transition manoeuvres at constant altitude. ",
    "url": "https://arxiv.org/abs/2302.04361",
    "authors": [
      "Martin Doff-Sotta",
      "Mark Cannon",
      "Marko Bacic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.04368",
    "title": "Channelformer: Attention based Neural Solution for Wireless Channel  Estimation and Effective Online Training",
    "abstract": "In this paper, we propose an encoder-decoder neural architecture (called Channelformer) to achieve improved channel estimation for orthogonal frequency-division multiplexing (OFDM) waveforms in downlink scenarios. The self-attention mechanism is employed to achieve input precoding for the input features before processing them in the decoder. In particular, we implement multi-head attention in the encoder and a residual convolutional neural architecture as the decoder, respectively. We also employ a customized weight-level pruning to slim the trained neural network with a fine-tuning process, which reduces the computational complexity significantly to realize a low complexity and low latency solution. This enables reductions of up to 70\\% in the parameters, while maintaining an almost identical performance compared with the complete Channelformer. We also propose an effective online training method based on the fifth generation (5G) new radio (NR) configuration for the modern communication systems, which only needs the available information at the receiver for online training. Using industrial standard channel models, the simulations of attention-based solutions show superior estimation performance compared with other candidate neural network methods for channel estimation. ",
    "url": "https://arxiv.org/abs/2302.04368",
    "authors": [
      "Dianxin Luan",
      "John Thompson"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04437",
    "title": "rMultiNet: An R Package For Multilayer Networks Analysis",
    "abstract": "This paper develops an R package rMultiNet to analyze multilayer network data. We provide two general frameworks from recent literature, e.g. mixture multilayer stochastic block model(MMSBM) and mixture multilayer latent space model(MMLSM) to generate the multilayer network. We also provide several methods to reveal the embedding of both nodes and layers followed by further data analysis methods, such as clustering. Three real data examples are processed in the package. The source code of rMultiNet is available at https://github.com/ChenyuzZZ73/rMultiNet. ",
    "url": "https://arxiv.org/abs/2302.04437",
    "authors": [
      "Ting Li",
      "Zhongyuan Lyu",
      "Chenyu Ren",
      "Dong Xia"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2302.04438",
    "title": "A data variation robust learning model based on importance sampling",
    "abstract": "A crucial assumption underlying the most current theory of machine learning is that the training distribution is identical to the testing distribution. However, this assumption may not hold in some real-world applications. In this paper, we propose an importance sampling based data variation robust loss (ISloss) for learning problems which minimizes the worst case of loss under the constraint of distribution deviation. The distribution deviation constraint can be converted to the constraint over a set of weight distributions centered on the uniform distribution derived from the importance sampling method. Furthermore, we reveal that there is a relationship between ISloss under the logarithmic transformation (LogISloss) and the p-norm loss. We apply the proposed LogISloss to the face verification problem on Racial Faces in the Wild dataset and show that the proposed method is robust under large distribution deviations. ",
    "url": "https://arxiv.org/abs/2302.04438",
    "authors": [
      "Jiangshe Zhang",
      "Lizhen Ji",
      "Fei Gao",
      "Mengyao Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04759",
    "title": "Robust and Scalable Bayesian Online Changepoint Detection",
    "abstract": "This paper proposes an online, provably robust, and scalable Bayesian approach for changepoint detection. The resulting algorithm has key advantages over previous work: it provides provable robustness by leveraging the generalised Bayesian perspective, and also addresses the scalability issues of previous attempts. Specifically, the proposed generalised Bayesian formalism leads to conjugate posteriors whose parameters are available in closed form by leveraging diffusion score matching. The resulting algorithm is exact, can be updated through simple algebra, and is more than 10 times faster than its closest competitor. ",
    "url": "https://arxiv.org/abs/2302.04759",
    "authors": [
      "Matias Altamirano",
      "Fran\u00e7ois-Xavier Briol",
      "Jeremias Knoblauch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1905.09803",
    "title": "How degenerate is the parametrization of neural networks with the ReLU  activation function?",
    "abstract": " Comments: Accepted at NeurIPS 2019 ",
    "url": "https://arxiv.org/abs/1905.09803",
    "authors": [
      "Julius Berner",
      "Dennis Elbr\u00e4chter",
      "Philipp Grohs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2004.13135",
    "title": "Local Lipschitz Bounds of Deep Neural Networks",
    "abstract": " Title: Local Lipschitz Bounds of Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2004.13135",
    "authors": [
      "Calypso Herrera",
      "Florian Krach",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ]
  },
  {
    "id": "arXiv:2106.00720",
    "title": "Fair-Net: A Network Architecture For Reducing Performance Disparity  Between Identifiable Sub-Populations",
    "abstract": " Title: Fair-Net: A Network Architecture For Reducing Performance Disparity  Between Identifiable Sub-Populations ",
    "url": "https://arxiv.org/abs/2106.00720",
    "authors": [
      "Arghya Datta",
      "S. Joshua Swamidass"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2106.06921",
    "title": "Heterogeneous Federated Learning using Dynamic Model Pruning and  Adaptive Gradient",
    "abstract": " Comments: Preprint of the CCGrid 2023 Submission ",
    "url": "https://arxiv.org/abs/2106.06921",
    "authors": [
      "Sixing Yu",
      "Phuong Nguyen",
      "Ali Anwar",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.08448",
    "title": "Improved Robustness and Safety for Pre-Adaptation of Meta Reinforcement  Learning with Prior Regularization",
    "abstract": " Title: Improved Robustness and Safety for Pre-Adaptation of Meta Reinforcement  Learning with Prior Regularization ",
    "url": "https://arxiv.org/abs/2108.08448",
    "authors": [
      "Lu Wen",
      "Songan Zhang",
      "H. Eric Tseng",
      "Baljeet Singh",
      "Dimitar Filev",
      "Huei Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08683",
    "title": "Inferring halo masses with Graph Neural Networks",
    "abstract": " Comments: 20 pages, 8 figures, code publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2111.08683",
    "authors": [
      "Pablo Villanueva-Domingo",
      "Francisco Villaescusa-Navarro",
      "Daniel Angl\u00e9s-Alc\u00e1zar",
      "Shy Genel",
      "Federico Marinacci",
      "David N. Spergel",
      "Lars Hernquist",
      "Mark Vogelsberger",
      "Romeel Dave",
      "Desika Narayanan"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.06854",
    "title": "Convergence of a robust deep FBSDE method for stochastic control",
    "abstract": " Comments: 27 pages, 5 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2201.06854",
    "authors": [
      "Kristoffer Andersson",
      "Adam Andersson",
      "Cornelis W. Oosterlee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.05101",
    "title": "Characterizations of Adjoint Sobolev Embedding Operators with  Applications in Inverse Problems",
    "abstract": " Comments: 33 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2202.05101",
    "authors": [
      "Simon Hubmer",
      "Ekaterina Sherina",
      "Ronny Ramlau"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2202.07135",
    "title": "Compositional Scene Representation Learning via Reconstruction: A Survey",
    "abstract": " Title: Compositional Scene Representation Learning via Reconstruction: A Survey ",
    "url": "https://arxiv.org/abs/2202.07135",
    "authors": [
      "Jinyang Yuan",
      "Tonglin Chen",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.07170",
    "title": "Fairness Amidst Non-IID Graph Data: Current Achievements and Future  Directions",
    "abstract": " Title: Fairness Amidst Non-IID Graph Data: Current Achievements and Future  Directions ",
    "url": "https://arxiv.org/abs/2202.07170",
    "authors": [
      "Wenbin Zhang",
      "Shimei Pan",
      "Shuigeng Zhou",
      "Toby Walsh",
      "Jeremy C. Weiss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.10046",
    "title": "Testing robustness of predictions of trained classifiers against  naturally occurring perturbations",
    "abstract": " Comments: 25 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2204.10046",
    "authors": [
      "Sebastian Scher",
      "Andreas Tr\u00fcgler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.11307",
    "title": "A Comprehensive Test Pattern Generation Approach Exploiting SAT Attack  for Logic Locking",
    "abstract": " Comments: 12 pages, 7 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2204.11307",
    "authors": [
      "Yadi Zhong",
      "Ujjwal Guin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.13713",
    "title": "Learning cosmology and clustering with cosmic graphs",
    "abstract": " Comments: 21 pages, 8 figures, code publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2204.13713",
    "authors": [
      "Pablo Villanueva-Domingo",
      "Francisco Villaescusa-Navarro"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12718",
    "title": "DPSNN: A Differentially Private Spiking Neural Network",
    "abstract": " Comments: We find a mistake in our experiment. This leads us to the wrong conclusion ",
    "url": "https://arxiv.org/abs/2205.12718",
    "authors": [
      "Jihang Wang",
      "Dongcheng Zhao",
      "Guobin Shen",
      "Qian Zhang",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15619",
    "title": "Meta-ticket: Finding optimal subnetworks for few-shot learning within  randomly initialized neural networks",
    "abstract": " Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2205.15619",
    "authors": [
      "Daiki Chijiwa",
      "Shin'ya Yamaguchi",
      "Atsutoshi Kumagai",
      "Yasutoshi Ida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.06711",
    "title": "Conformal Off-policy Prediction",
    "abstract": " Comments: This paper is accepted at the 26th International Conference on Artificial Intelligence and Statistics (AISTATS 2023) ",
    "url": "https://arxiv.org/abs/2206.06711",
    "authors": [
      "Yingying Zhang",
      "Chengchun Shi",
      "Shikai Luo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02760",
    "title": "Decision Trees with Dynamic Graph Features",
    "abstract": " Title: Decision Trees with Dynamic Graph Features ",
    "url": "https://arxiv.org/abs/2207.02760",
    "authors": [
      "Maya Bechler-Speicher",
      "Amir Globerson",
      "Ran Gilad-Bachrach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.06819",
    "title": "Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks",
    "abstract": " Comments: Accepted by Knowledge-Based Systems ",
    "url": "https://arxiv.org/abs/2207.06819",
    "authors": [
      "Evan Caville",
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.00884",
    "title": "PulseDL-II: A System-on-Chip Neural Network Accelerator for Timing and  Energy Extraction of Nuclear Detector Signals",
    "abstract": " Comments: Accepted by IEEE Transactions on Nuclear Science ",
    "url": "https://arxiv.org/abs/2209.00884",
    "authors": [
      "Pengcheng Ai",
      "Zhi Deng",
      "Yi Wang",
      "Hui Gong",
      "Xinchi Ran",
      "Zijian Lang"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.01335",
    "title": "Neural Approaches to Multilingual Information Retrieval",
    "abstract": " Comments: 17 pages, 3 figures, accepted at ECIR 2023 ",
    "url": "https://arxiv.org/abs/2209.01335",
    "authors": [
      "Dawn Lawrie",
      "Eugene Yang",
      "Douglas W. Oard",
      "James Mayfield"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.10900",
    "title": "A Capability and Skill Model for Heterogeneous Autonomous Robots",
    "abstract": " Title: A Capability and Skill Model for Heterogeneous Autonomous Robots ",
    "url": "https://arxiv.org/abs/2209.10900",
    "authors": [
      "Luis Miguel Vieira da Silva",
      "Aljosha K\u00f6cher",
      "Alexander Fay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.11366",
    "title": "Jensen-Shannon Divergence Based Novel Loss Functions for Bayesian Neural  Networks",
    "abstract": " Comments: Submitted to IEEE for peer review ",
    "url": "https://arxiv.org/abs/2209.11366",
    "authors": [
      "Ponkrshnan Thiagarajan",
      "Susanta Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15328",
    "title": "Sparse Random Networks for Communication-Efficient Federated Learning",
    "abstract": " Comments: Published at the International Conference on Learning Representations (ICLR) 2023 ",
    "url": "https://arxiv.org/abs/2209.15328",
    "authors": [
      "Berivan Isik",
      "Francesco Pase",
      "Deniz Gunduz",
      "Tsachy Weissman",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01963",
    "title": "COMPS: Conceptual Minimal Pair Sentences for testing Robust Property  Knowledge and its Inheritance in Pre-trained Language Models",
    "abstract": " Comments: EACL 2023 Camera Ready version. Code can be found at this https URL ",
    "url": "https://arxiv.org/abs/2210.01963",
    "authors": [
      "Kanishka Misra",
      "Julia Taylor Rayz",
      "Allyson Ettinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04246",
    "title": "Better Pre-Training by Reducing Representation Confusion",
    "abstract": " Comments: EACL 2023(Findings) ",
    "url": "https://arxiv.org/abs/2210.04246",
    "authors": [
      "Haojie Zhang",
      "Mingfei Liang",
      "Ruobing Xie",
      "Zhenlong Sun",
      "Bo Zhang",
      "Leyu Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12538",
    "title": "Compressing multidimensional weather and climate data into neural  networks",
    "abstract": " Title: Compressing multidimensional weather and climate data into neural  networks ",
    "url": "https://arxiv.org/abs/2210.12538",
    "authors": [
      "Langwen Huang",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2210.13915",
    "title": "Towards Formal XAI: Formally Approximate Minimal Explanations of Neural  Networks",
    "abstract": " Comments: To appear in Proc. 29th Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems (TACAS) ",
    "url": "https://arxiv.org/abs/2210.13915",
    "authors": [
      "Shahaf Bassan",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2211.07211",
    "title": "Joint Jammer Mitigation and Data Detection for Smart, Distributed, and  Multi-Antenna Jammers",
    "abstract": " Comments: To be presented at the 2023 IEEE International Conference on Communications (ICC) ",
    "url": "https://arxiv.org/abs/2211.07211",
    "authors": [
      "Gian Marti",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.08771",
    "title": "On the symmetries in the dynamics of wide two-layer neural networks",
    "abstract": " Title: On the symmetries in the dynamics of wide two-layer neural networks ",
    "url": "https://arxiv.org/abs/2211.08771",
    "authors": [
      "Karl Hajjar",
      "Lenaic Chizat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.11191",
    "title": "Correlative Preference Transfer with Hierarchical Hypergraph Network for  Multi-Domain Recommendation",
    "abstract": " Comments: Accepted by WWW 2023 research track. The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2211.11191",
    "authors": [
      "Zixuan Xu",
      "Penghui Wei",
      "Shaoguo Liu",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.05925",
    "title": "CausalEGM: a general causal inference framework by encoding generative  modeling",
    "abstract": " Comments: Corrected typos ",
    "url": "https://arxiv.org/abs/2212.05925",
    "authors": [
      "Qiao Liu",
      "Zhongren Chen",
      "Wing Hung Wong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05970",
    "title": "Decomposing a Recurrent Neural Network into Modules for Enabling  Reusability and Replacement",
    "abstract": " Comments: Accepted at 45th international conference on software engineering (ICSE'2023) ",
    "url": "https://arxiv.org/abs/2212.05970",
    "authors": [
      "Sayem Mohammad Imtiaz",
      "Fraol Batole",
      "Astha Singh",
      "Rangeet Pan",
      "Breno Dantas Cruz",
      "Hridesh Rajan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01026",
    "title": "Continual Causal Effect Estimation: Challenges and Opportunities",
    "abstract": " Comments: The 37th AAAI conference on artificial intelligence Continual Causality Bridge Program ",
    "url": "https://arxiv.org/abs/2301.01026",
    "authors": [
      "Zhixuan Chu",
      "Sheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.01732",
    "title": "UNAEN: Unsupervised Abnomality Extraction Network for MRI Motion  Artifact Reduction",
    "abstract": " Title: UNAEN: Unsupervised Abnomality Extraction Network for MRI Motion  Artifact Reduction ",
    "url": "https://arxiv.org/abs/2301.01732",
    "authors": [
      "Yusheng Zhou",
      "Hao Li",
      "Jianan Liu",
      "Zhengmin Kong",
      "Tao Huang",
      "Euijoon Ah",
      "Zhihan Lv"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2301.05549",
    "title": "On the explainability of quantum neural networks based on variational  quantum circuits",
    "abstract": " Comments: 4 pages, a short letter version ",
    "url": "https://arxiv.org/abs/2301.05549",
    "authors": [
      "Ammar Daskin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11524",
    "title": "RAPTOR: Advanced Persistent Threat Detection in Industrial IoT via  Attack Stage Correlation",
    "abstract": " Comments: To be submitted to journal ",
    "url": "https://arxiv.org/abs/2301.11524",
    "authors": [
      "Ayush Kumar",
      "Vrizlynn L.L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12097",
    "title": "Enhancing Dyadic Relations with Homogeneous Graphs for Multimodal  Recommendation",
    "abstract": " Comments: 17 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2301.12097",
    "authors": [
      "Hongyu Zhou",
      "Xin Zhou",
      "Lingzi Zhang",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.00236",
    "title": "Generative Adversarial Symmetry Discovery",
    "abstract": " Title: Generative Adversarial Symmetry Discovery ",
    "url": "https://arxiv.org/abs/2302.00236",
    "authors": [
      "Jianke Yang",
      "Robin Walters",
      "Nima Dehmamy",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00735",
    "title": "MTP-GO: Graph-Based Probabilistic Multi-Agent Trajectory Prediction with  Neural ODEs",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2302.00735",
    "authors": [
      "Theodor Westny",
      "Joel Oskarsson",
      "Bj\u00f6rn Olofsson",
      "Erik Frisk"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01707",
    "title": "Parfum: Detection and Automatic Repair of Dockerfile Smells",
    "abstract": " Title: Parfum: Detection and Automatic Repair of Dockerfile Smells ",
    "url": "https://arxiv.org/abs/2302.01707",
    "authors": [
      "Thomas Durieux"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.02001",
    "title": "Spatial Network Calculus and Performance Guarantees in Wireless Networks",
    "abstract": " Comments: Submitted to IEEE Transactions on Wireless Communications ",
    "url": "https://arxiv.org/abs/2302.02001",
    "authors": [
      "Ke Feng",
      "Fran\u00e7ois Baccelli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.02713",
    "title": "Flat Seeking Bayesian Neural Networks",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2302.02713",
    "authors": [
      "Van-Anh Nguyen",
      "Tung-Long Vuong",
      "Hoang Phan",
      "Thanh-Toan Do",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2302.03232",
    "title": "Linear Optimal Partial Transport Embedding",
    "abstract": " Title: Linear Optimal Partial Transport Embedding ",
    "url": "https://arxiv.org/abs/2302.03232",
    "authors": [
      "Yikun Bai",
      "Ivan Medri",
      "Rocio Diaz Martin",
      "Rana Muhammad Shahroz Khan",
      "Soheil Kolouri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.03731",
    "title": "MMA-RNN: A Multi-level Multi-task Attention-based Recurrent Neural  Network for Discrimination and Localization of Atrial Fibrillation",
    "abstract": " Comments: 9 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2302.03731",
    "authors": [
      "Yifan Sun",
      "Jingyan Shen",
      "Yunfan Jiang",
      "Zhaohui Huang",
      "Minsheng Hao",
      "Xuegong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.03807",
    "title": "A Prototype-Oriented Clustering for Domain Shift with Source Privacy",
    "abstract": " Title: A Prototype-Oriented Clustering for Domain Shift with Source Privacy ",
    "url": "https://arxiv.org/abs/2302.03807",
    "authors": [
      "Korawat Tanwisuth",
      "Shujian Zhang",
      "Pengcheng He",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.03896",
    "title": "Auto-Learning: An Adversarial Process of Two Pre-trained Models for  Natural Language Generation",
    "abstract": " Comments: 12 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2302.03896",
    "authors": [
      "Zhengqing Yuan",
      "Huiwen Xue",
      "Chao Zhang",
      "Yuelin Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.04129",
    "title": "Hyperspectral Image Compression Using Implicit Neural Representation",
    "abstract": " Title: Hyperspectral Image Compression Using Implicit Neural Representation ",
    "url": "https://arxiv.org/abs/2302.04129",
    "authors": [
      "Shima Rezasoltani",
      "Faisal Z. Qureshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  }
]