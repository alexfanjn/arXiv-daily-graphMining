[
  {
    "id": "arXiv:2302.10184",
    "title": "On Robust Numerical Solver for ODE via Self-Attention Mechanism",
    "abstract": "With the development of deep learning techniques, AI-enhanced numerical solvers are expected to become a new paradigm for solving differential equations due to their versatility and effectiveness in alleviating the accuracy-speed trade-off in traditional numerical solvers. However, this paradigm still inevitably requires a large amount of high-quality data, whose acquisition is often very expensive in natural science and engineering problems. Therefore, in this paper, we explore training efficient and robust AI-enhanced numerical solvers with a small data size by mitigating intrinsic noise disturbances. We first analyze the ability of the self-attention mechanism to regulate noise in supervised learning and then propose a simple-yet-effective numerical solver, AttSolver, which introduces an additive self-attention mechanism to the numerical solution of differential equations based on the dynamical system perspective of the residual neural network. Our results on benchmarks, ranging from high-dimensional problems to chaotic systems, demonstrate the effectiveness of AttSolver in generally improving the performance of existing traditional numerical solvers without any elaborated model crafting. Finally, we analyze the convergence, generalization, and robustness of the proposed method experimentally and theoretically. ",
    "url": "https://arxiv.org/abs/2302.10184",
    "authors": [
      "Zhongzhan Huang",
      "Mingfu Liang",
      "Liang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.10195",
    "title": "Uncertainty-Aware Reward-based Deep Reinforcement Learning for Intent  Analysis of Social Media Information",
    "abstract": "Due to various and serious adverse impacts of spreading fake news, it is often known that only people with malicious intent would propagate fake news. However, it is not necessarily true based on social science studies. Distinguishing the types of fake news spreaders based on their intent is critical because it will effectively guide how to intervene to mitigate the spread of fake news with different approaches. To this end, we propose an intent classification framework that can best identify the correct intent of fake news. We will leverage deep reinforcement learning (DRL) that can optimize the structural representation of each tweet by removing noisy words from the input sequence when appending an actor to the long short-term memory (LSTM) intent classifier. Policy gradient DRL model (e.g., REINFORCE) can lead the actor to a higher delayed reward. We also devise a new uncertainty-aware immediate reward using a subjective opinion that can explicitly deal with multidimensional uncertainty for effective decision-making. Via 600K training episodes from a fake news tweets dataset with an annotated intent class, we evaluate the performance of uncertainty-aware reward in DRL. Evaluation results demonstrate that our proposed framework efficiently reduces the number of selected words to maintain a high 95\\% multi-class accuracy. ",
    "url": "https://arxiv.org/abs/2302.10195",
    "authors": [
      "Zhen Guo",
      "Qi Zhang",
      "Xinwei An",
      "Qisheng Zhang",
      "Audun J\u00f8sang",
      "Lance M. Kaplan",
      "Feng Chen",
      "Dong H. Jeong",
      "Jin-Hee Cho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10197",
    "title": "Growing Steerable Neural Cellular Automata",
    "abstract": "Neural Cellular Automata (NCA) models have shown remarkable capacity for pattern formation and complex global behaviors stemming from local coordination. However, in the original implementation of NCA, cells are incapable of adjusting their own orientation, and it is the responsibility of the model designer to orient them externally. A recent isotropic variant of NCA (Growing Isotropic Neural Cellular Automata) makes the model orientation-independent - cells can no longer tell up from down, nor left from right - by removing its dependency on perceiving the gradient of spatial states in its neighborhood. In this work, we revisit NCA with a different approach: we make each cell responsible for its own orientation by allowing it to \"turn\" as determined by an adjustable internal state. The resulting Steerable NCA contains cells of varying orientation embedded in the same pattern. We observe how, while Isotropic NCA are orientation-agnostic, Steerable NCA have chirality: they have a predetermined left-right symmetry. We therefore show that we can train Steerable NCA in similar but simpler ways than their Isotropic variant by: (1) breaking symmetries using only two seeds, or (2) introducing a rotation-invariant training objective and relying on asynchronous cell updates to break the up-down symmetry of the system. ",
    "url": "https://arxiv.org/abs/2302.10197",
    "authors": [
      "Ettore Randazzo",
      "Alexander Mordvintsev",
      "Craig Fouts"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10203",
    "title": "Nonlinear response of Silicon Photonics microresonators for reservoir  computing neural network",
    "abstract": "Nowadays, Information Photonics is extensively studied and sees applications in many fields. The interest in this breakthrough technology is mainly stimulated by the possibility of achieving real-time data processing for high-bandwidth applications, still implemented through small-footprint devices that would allow for breaking the limit imposed by Moore's law. One potential breakthrough implementation of information photonics is via integrated photonic circuits. Within this approach, the most suitable computational scheme is achieved by integrated photonic neural networks. In this chapter, we provide a review of one possible way to implement a neural network by using silicon photonics. Specifically, we review the work we performed at the Nanoscience Laboratory of the University of Trento. We present methodologies, results, and future challenges about a delayed complex perceptron for fast data processing, a microring resonator exploiting nonlinear dynamics for a reservoir computing approach, and a microring resonator with the addition of a feedback delay loop for time series processing. ",
    "url": "https://arxiv.org/abs/2302.10203",
    "authors": [
      "Emiliano Staffoli",
      "Davide Bazzanella",
      "Stefano Biasi",
      "Giovanni Donati",
      "Mattia Mancinelli",
      "Paolo Bettotti",
      "Lorenzo Pavesi"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2302.10237",
    "title": "SceneHGN: Hierarchical Graph Networks for 3D Indoor Scene Generation  with Fine-Grained Geometry",
    "abstract": "3D indoor scenes are widely used in computer graphics, with applications ranging from interior design to gaming to virtual and augmented reality. They also contain rich information, including room layout, as well as furniture type, geometry, and placement. High-quality 3D indoor scenes are highly demanded while it requires expertise and is time-consuming to design high-quality 3D indoor scenes manually. Existing research only addresses partial problems: some works learn to generate room layout, and other works focus on generating detailed structure and geometry of individual furniture objects. However, these partial steps are related and should be addressed together for optimal synthesis. We propose SCENEHGN, a hierarchical graph network for 3D indoor scenes that takes into account the full hierarchy from the room level to the object level, then finally to the object part level. Therefore for the first time, our method is able to directly generate plausible 3D room content, including furniture objects with fine-grained geometry, and their layout. To address the challenge, we introduce functional regions as intermediate proxies between the room and object levels to make learning more manageable. To ensure plausibility, our graph-based representation incorporates both vertical edges connecting child nodes with parent nodes from different levels, and horizontal edges encoding relationships between nodes at the same level. Extensive experiments demonstrate that our method produces superior generation results, even when comparing results of partial steps with alternative methods that can only achieve these. We also demonstrate that our method is effective for various applications such as part-level room editing, room interpolation, and room generation by arbitrary room boundaries. ",
    "url": "https://arxiv.org/abs/2302.10237",
    "authors": [
      "Lin Gao",
      "Jia-Mu Sun",
      "Kaichun Mo",
      "Yu-Kun Lai",
      "Leonidas J. Guibas",
      "Jie Yang"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10253",
    "title": "Multiobjective Evolutionary Pruning of Deep Neural Networks with  Transfer Learning for improving their Performance and Robustness",
    "abstract": "Evolutionary Computation algorithms have been used to solve optimization problems in relation with architectural, hyper-parameter or training configuration, forging the field known today as Neural Architecture Search. These algorithms have been combined with other techniques such as the pruning of Neural Networks, which reduces the complexity of the network, and the Transfer Learning, which lets the import of knowledge from another problem related to the one at hand. The usage of several criteria to evaluate the quality of the evolutionary proposals is also a common case, in which the performance and complexity of the network are the most used criteria. This work proposes MO-EvoPruneDeepTL, a multi-objective evolutionary pruning algorithm. \\proposal uses Transfer Learning to adapt the last layers of Deep Neural Networks, by replacing them with sparse layers evolved by a genetic algorithm, which guides the evolution based in the performance, complexity and robustness of the network, being the robustness a great quality indicator for the evolved models. We carry out different experiments with several datasets to assess the benefits of our proposal. Results show that our proposal achieves promising results in all the objectives, and direct relation are presented among them. The experiments also show that the most influential neurons help us explain which parts of the input images are the most relevant for the prediction of the pruned neural network. Lastly, by virtue of the diversity within the Pareto front of pruning patterns produced by the proposal, it is shown that an ensemble of differently pruned models improves the overall performance and robustness of the trained networks. ",
    "url": "https://arxiv.org/abs/2302.10253",
    "authors": [
      "Javier Poyatos",
      "Daniel Molina",
      "Aitor Mart\u00ednez",
      "Javier Del Ser",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10255",
    "title": "NeuralStagger: accelerating physics-constrained neural PDE solver with  spatial-temporal decomposition",
    "abstract": "Neural networks have shown great potential in accelerating the solution of partial differential equations (PDEs). Recently, there has been a growing interest in introducing physics constraints into training neural PDE solvers to reduce the use of costly data and improve the generalization ability. However, these physics constraints, based on certain finite dimensional approximations over the function space, must resolve the smallest scaled physics to ensure the accuracy and stability of the simulation, resulting in high computational costs from large input, output, and neural networks. This paper proposes a general acceleration methodology called NeuralStagger by spatially and temporally decomposing the original learning tasks into several coarser-resolution subtasks. We define a coarse-resolution neural solver for each subtask, which requires fewer computational resources, and jointly train them with the vanilla physics-constrained loss by simply arranging their outputs to reconstruct the original solution. Due to the perfect parallelism between them, the solution is achieved as fast as a coarse-resolution neural solver. In addition, the trained solvers bring the flexibility of simulating with multiple levels of resolution. We demonstrate the successful application of NeuralStagger on 2D and 3D fluid dynamics simulations, which leads to an additional $10\\sim100\\times$ speed-up. Moreover, the experiment also shows that the learned model could be well used for optimal control. ",
    "url": "https://arxiv.org/abs/2302.10255",
    "authors": [
      "Xinquan Huang",
      "Wenlei Shi",
      "Qi Meng",
      "Yue Wang",
      "Xiaotian Gao",
      "Jia Zhang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2302.10257",
    "title": "Secrecy Outage Analysis of Energy Harvesting Relay-based Mixed UOWC-RF  Network with Multiple Eavesdroppers",
    "abstract": "This work deals with the physical layer security performance of a dual-hop underwater optical communication (UOWC)-radio frequency (RF) network under the intruding attempts of multiple eavesdroppers via RF links. The intermediate decode and forward relay node between the underwater source and the destination transforms the optical signal into electrical form and re-transmits it to the destination node with the help of harvested energy by the relay from an integrated power beacon within the system. The source-to-relay link (UOWC) follows a mixture exponential generalized Gamma turbulence with pointing error impairments whereas all the remaining links (RF) undergo $\\kappa-\\mu$ shadowed fading. With regards to the types of intruders, herein two scenarios are considered, i.e., colluding (\\textit{Scenario-I}) and non-colluding (\\textit{Scenario-II}) eavesdroppers and the analytical expressions of secure outage probability, probability of strictly positive secrecy capacity, and effective secrecy throughput are derived in closed form for each scenario. Furthermore, the impacts of UOWC and RF channel parameters as well as detection techniques on secrecy capacity are demonstrated, and following this a comparison between the two considered scenarios is demonstrated that reveals the collusion between the eavesdroppers imposes the most harmful threat on secrecy throughput but a better secrecy level can be attained adopting diversity at the destination and power beacon nodes along with heterodyne detection rather than intensity modulation and direct detection technique. Finally, all the derived expressions are corroborated via Monte Carlo simulations. ",
    "url": "https://arxiv.org/abs/2302.10257",
    "authors": [
      "Moloy Kumar Ghosh",
      "Milton Kumar Kundu",
      "Md Ibrahim",
      "A. S. M. Badrudduza",
      "Md. Shamim Anower",
      "Imran Shafique Ansari",
      "Ali A. Shaikhi",
      "Mohammed A. Mohandes"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.10258",
    "title": "Neural Algorithmic Reasoning with Causal Regularisation",
    "abstract": "Recent work on neural algorithmic reasoning has investigated the reasoning capabilities of neural networks, effectively demonstrating they can learn to execute classical algorithms on unseen data coming from the train distribution. However, the performance of existing neural reasoners significantly degrades on out-of-distribution (OOD) test data, where inputs have larger sizes. In this work, we make an important observation: there are many \\emph{different} inputs for which an algorithm will perform certain intermediate computations \\emph{identically}. This insight allows us to develop data augmentation procedures that, given an algorithm's intermediate trajectory, produce inputs for which the target algorithm would have \\emph{exactly} the same next trajectory step. Then, we employ a causal framework to design a corresponding self-supervised objective, and we prove that it improves the OOD generalisation capabilities of the reasoner. We evaluate our method on the CLRS algorithmic reasoning benchmark, where we show up to 3$\\times$ improvements on the OOD test data. ",
    "url": "https://arxiv.org/abs/2302.10258",
    "authors": [
      "Beatrice Bevilacqua",
      "Kyriacos Nikiforou",
      "Borja Ibarz",
      "Ioana Bica",
      "Michela Paganini",
      "Charles Blundell",
      "Jovana Mitrovic",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.10266",
    "title": "Kernel function impact on convolutional neural networks",
    "abstract": "This paper investigates the usage of kernel functions at the different layers in a convolutional neural network. We carry out extensive studies of their impact on convolutional, pooling and fully-connected layers. We notice that the linear kernel may not be sufficiently effective to fit the input data distributions, whereas high order kernels prone to over-fitting. This leads to conclude that a trade-off between complexity and performance should be reached. We show how one can effectively leverage kernel functions, by introducing a more distortion aware pooling layers which reduces over-fitting while keeping track of the majority of the information fed into subsequent layers. We further propose Kernelized Dense Layers (KDL), which replace fully-connected layers, and capture higher order feature interactions. The experiments on conventional classification datasets i.e. MNIST, FASHION-MNIST and CIFAR-10, show that the proposed techniques improve the performance of the network compared to classical convolution, pooling and fully connected layers. Moreover, experiments on fine-grained classification i.e. facial expression databases, namely RAF-DB, FER2013 and ExpW demonstrate that the discriminative power of the network is boosted, since the proposed techniques improve the awareness to slight visual details and allows the network reaching state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2302.10266",
    "authors": [
      "M.Amine Mahmoudi",
      "Aladine Chetouani",
      "Fatma Boufera",
      "Hedi Tabia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10271",
    "title": "Thermal Analysis of Malignant Brain Tumors by Employing a Morphological  Differentiation-Based Method in Conjunction with Artificial Neural Network",
    "abstract": "In this study, a morphological differentiation-based method has been introduced which employs temperature distribution on the tissue surface to detect brain tumor's malignancy. According to the common tumor CT scans, two different scenarios have been implemented to describe irregular shape of the malignant tumor. In the first scenario, tumor has been considered as a polygon base prism and in the second one, it has been considered as a star-shaped base prism. By increasing the number of sides of the polygon or wings of the star, degree of the malignancy has been increased. Constant heat generation has been considered for the tumor and finite element analysis has been conducted by the ABAQUS software linked with a PYTHON script on both tumor models to study temperature variations on the top tissue surface. This temperature distribution has been characterized by 10 parameters. In each scenario, 98 sets of these parameters has been used as inputs of a radial basis function neural network (RBFNN) and number of sides or wings has been selected to be the output. The RBFNN has been trained to identify malignancy of tumor based on its morphology. According to the RBFNN results, the proposed method has been capable of differentiating between benign and malignant tumors and estimating the degree of malignancy with high accuracy ",
    "url": "https://arxiv.org/abs/2302.10271",
    "authors": [
      "Hamed Hani",
      "Afsaneh Mojra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10273",
    "title": "ViGU: Vision GNN U-Net for Fast MRI",
    "abstract": "Deep learning models have been widely applied for fast MRI. The majority of existing deep learning models, e.g., convolutional neural networks, work on data with Euclidean or regular grids structures. However, high-dimensional features extracted from MR data could be encapsulated in non-Euclidean manifolds. This disparity between the go-to assumption of existing models and data requirements limits the flexibility to capture irregular anatomical features in MR data. In this work, we introduce a novel Vision GNN type network for fast MRI called Vision GNN U-Net (ViGU). More precisely, the pixel array is first embedded into patches and then converted into a graph. Secondly, a U-shape network is developed using several graph blocks in symmetrical encoder and decoder paths. Moreover, we show that the proposed ViGU can also benefit from Generative Adversarial Networks yielding to its variant ViGU-GAN. We demonstrate, through numerical and visual experiments, that the proposed ViGU and GAN variant outperform existing CNN and GAN-based methods. Moreover, we show that the proposed network readily competes with approaches based on Transformers while requiring a fraction of the computational cost. More importantly, the graph structure of the network reveals how the network extracts features from MR images, providing intuitive explainability. ",
    "url": "https://arxiv.org/abs/2302.10273",
    "authors": [
      "Jiahao Huang",
      "Angelica Aviles-Rivero",
      "Carola-Bibiane Schonlieb",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10274",
    "title": "A Generative Adversarial Network for Climate Tipping Point Discovery  (TIP-GAN)",
    "abstract": "We propose a new Tipping Point Generative Adversarial Network (TIP-GAN) for better characterizing potential climate tipping points in Earth system models. We describe an adversarial game to explore the parameter space of these models, detect upcoming tipping points, and discover the drivers of tipping points. In this setup, a set of generators learn to construct model configurations that will invoke a climate tipping point. The discriminator learns to identify which generators are generating each model configuration and whether a given configuration will lead to a tipping point. The discriminator is trained using an oracle (a surrogate climate model) to test if a generated model configuration leads to a tipping point or not. We demonstrate the application of this GAN to invoke the collapse of the Atlantic Meridional Overturning Circulation (AMOC). We share experimental results of modifying the loss functions and the number of generators to exploit the area of uncertainty in model state space near a climate tipping point. In addition, we show that our trained discriminator can predict AMOC collapse with a high degree of accuracy without the use of the oracle. This approach could generalize to other tipping points, and could augment climate modeling research by directing users interested in studying tipping points to parameter sets likely to induce said tipping points in their computationally intensive climate models. ",
    "url": "https://arxiv.org/abs/2302.10274",
    "authors": [
      "Jennifer Sleeman",
      "David Chung",
      "Anand Gnanadesikan",
      "Jay Brett",
      "Yannis Kevrekidis",
      "Marisa Hughes",
      "Thomas Haine",
      "Marie-Aude Pradal",
      "Renske Gelderloos",
      "Chace Ashcraft",
      "Caroline Tang",
      "Anshu Saksena",
      "Larry White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10275",
    "title": "Semantic Feature Integration network for Fine-grained Visual  Classification",
    "abstract": "Fine-Grained Visual Classification (FGVC) is known as a challenging task due to subtle differences among subordinate categories. Many current FGVC approaches focus on identifying and locating discriminative regions by using the attention mechanism, but neglect the presence of unnecessary features that hinder the understanding of object structure. These unnecessary features, including 1) ambiguous parts resulting from the visual similarity in object appearances and 2) noninformative parts (e.g., background noise), can have a significant adverse impact on classification results. In this paper, we propose the Semantic Feature Integration network (SFI-Net) to address the above difficulties. By eliminating unnecessary features and reconstructing the semantic relations among discriminative features, our SFI-Net has achieved satisfying performance. The network consists of two modules: 1) the multi-level feature filter (MFF) module is proposed to remove unnecessary features with different receptive field, and then concatenate the preserved features on pixel level for subsequent disposal; 2) the semantic information reconstitution (SIR) module is presented to further establish semantic relations among discriminative features obtained from the MFF module. These two modules are carefully designed to be light-weighted and can be trained end-to-end in a weakly-supervised way. Extensive experiments on four challenging fine-grained benchmarks demonstrate that our proposed SFI-Net achieves the state-of-the-arts performance. Especially, the classification accuracy of our model on CUB-200-2011 and Stanford Dogs reaches 92.64% and 93.03%, respectively. ",
    "url": "https://arxiv.org/abs/2302.10275",
    "authors": [
      "Hui Wang",
      "Yueyang li",
      "Haichi Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10277",
    "title": "A Comparative Analysis of CNN-Based Pretrained Models for the Detection  and Prediction of Monkeypox",
    "abstract": "Monkeypox is a rare disease that raised concern among medical specialists following the convi-19 pandemic. It's concerning since monkeypox is difficult to diagnose early on because of symptoms that are similar to chickenpox and measles. Furthermore, because this is a rare condition, there is a knowledge gap among healthcare professionals. As a result, there is an urgent need for a novel technique to combat and anticipate the disease in the early phases of individual virus infection. Multiple CNN-based pre-trained models, including VGG-16, VGG-19, Restnet50, Inception-V3, Densnet, Xception, MobileNetV2, Alexnet, Lenet, and majority Voting, were employed in classification in this study. For this study, multiple data sets were combined, such as monkeypox vs chickenpox, monkeypox versus measles, monkeypox versus normal, and monkeypox versus all diseases. Majority voting performed 97% in monkeypox vs chickenpox, Xception achieved 79% in monkeypox against measles, MobileNetV2 scored 96% in monkeypox vs normal, and Lenet performed 80% in monkeypox versus all. ",
    "url": "https://arxiv.org/abs/2302.10277",
    "authors": [
      "Sourav Saha",
      "Trina Chakraborty",
      "Rejwan Bin Sulaiman",
      "Tithi Paul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10280",
    "title": "Deepfake Detection Analyzing Hybrid Dataset Utilizing CNN and SVM",
    "abstract": "Social media is currently being used by many individuals online as a major source of information. However, not all information shared online is true, even photos and videos can be doctored. Deepfakes have recently risen with the rise of technological advancement and have allowed nefarious online users to replace one face with a computer generated face of anyone they would like, including important political and cultural figures. Deepfakes are now a tool to be able to spread mass misinformation. There is now an immense need to create models that are able to detect deepfakes and keep them from being spread as seemingly real images or videos. In this paper, we propose a new deepfake detection schema using two popular machine learning algorithms. ",
    "url": "https://arxiv.org/abs/2302.10280",
    "authors": [
      "Jacob mallet",
      "Laura Pryor",
      "Rushit Dave",
      "Mounika Vanamala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10281",
    "title": "LiT Tuned Models for Efficient Species Detection",
    "abstract": "Recent advances in training vision-language models have demonstrated unprecedented robustness and transfer learning effectiveness; however, standard computer vision datasets are image-only, and therefore not well adapted to such training methods. Our paper introduces a simple methodology for adapting any fine-grained image classification dataset for distributed vision-language pretraining. We implement this methodology on the challenging iNaturalist-2021 dataset, comprised of approximately 2.7 million images of macro-organisms across 10,000 classes, and achieve a new state-of-the art model in terms of zero-shot classification accuracy. Somewhat surprisingly, our model (trained using a new method called locked-image text tuning) uses a pre-trained, frozen vision representation, proving that language alignment alone can attain strong transfer learning performance, even on fractious, long-tailed datasets. Our approach opens the door for utilizing high quality vision-language pretrained models in agriculturally relevant applications involving species detection. ",
    "url": "https://arxiv.org/abs/2302.10281",
    "authors": [
      "Andre Nakkab",
      "Benjamin Feuer",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.10283",
    "title": "Self-supervised learning of Split Invariant Equivariant representations",
    "abstract": "Recent progress has been made towards learning invariant or equivariant representations with self-supervised learning. While invariant methods are evaluated on large scale datasets, equivariant ones are evaluated in smaller, more controlled, settings. We aim at bridging the gap between the two in order to learn more diverse representations that are suitable for a wide range of tasks. We start by introducing a dataset called 3DIEBench, consisting of renderings from 3D models over 55 classes and more than 2.5 million images where we have full control on the transformations applied to the objects. We further introduce a predictor architecture based on hypernetworks to learn equivariant representations with no possible collapse to invariance. We introduce SIE (Split Invariant-Equivariant) which combines the hypernetwork-based predictor with representations split in two parts, one invariant, the other equivariant, to learn richer representations. We demonstrate significant performance gains over existing methods on equivariance related tasks from both a qualitative and quantitative point of view. We further analyze our introduced predictor and show how it steers the learned latent space. We hope that both our introduced dataset and approach will enable learning richer representations without supervision in more complex scenarios. ",
    "url": "https://arxiv.org/abs/2302.10283",
    "authors": [
      "Quentin Garrido",
      "Laurent Najman",
      "Yann Lecun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10287",
    "title": "CertViT: Certified Robustness of Pre-Trained Vision Transformers",
    "abstract": "Lipschitz bounded neural networks are certifiably robust and have a good trade-off between clean and certified accuracy. Existing Lipschitz bounding methods train from scratch and are limited to moderately sized networks (< 6M parameters). They require a fair amount of hyper-parameter tuning and are computationally prohibitive for large networks like Vision Transformers (5M to 660M parameters). Obtaining certified robustness of transformers is not feasible due to the non-scalability and inflexibility of the current methods. This work presents CertViT, a two-step proximal-projection method to achieve certified robustness from pre-trained weights. The proximal step tries to lower the Lipschitz bound and the projection step tries to maintain the clean accuracy of pre-trained weights. We show that CertViT networks have better certified accuracy than state-of-the-art Lipschitz trained networks. We apply CertViT on several variants of pre-trained vision transformers and show adversarial robustness using standard attacks. Code : https://github.com/sagarverma/transformer-lipschitz ",
    "url": "https://arxiv.org/abs/2302.10287",
    "authors": [
      "Kavya Gupta",
      "Sagar Verma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10296",
    "title": "On Function-Coupled Watermarks for Deep Neural Networks",
    "abstract": "Well-performed deep neural networks (DNNs) generally require massive labelled data and computational resources for training. Various watermarking techniques are proposed to protect such intellectual properties (IPs), wherein the DNN providers implant secret information into the model so that they can later claim IP ownership by retrieving their embedded watermarks with some dedicated trigger inputs. While promising results are reported in the literature, existing solutions suffer from watermark removal attacks, such as model fine-tuning and model pruning. In this paper, we propose a novel DNN watermarking solution that can effectively defend against the above attacks. Our key insight is to enhance the coupling of the watermark and model functionalities such that removing the watermark would inevitably degrade the model's performance on normal inputs. To this end, unlike previous methods relying on secret features learnt from out-of-distribution data, our method only uses features learnt from in-distribution data. Specifically, on the one hand, we propose to sample inputs from the original training dataset and fuse them as watermark triggers. On the other hand, we randomly mask model weights during training so that the information of our embedded watermarks spreads in the network. By doing so, model fine-tuning/pruning would not forget our function-coupled watermarks. Evaluation results on various image classification tasks show a 100\\% watermark authentication success rate under aggressive watermark removal attacks, significantly outperforming existing solutions. Code is available: https://github.com/cure-lab/Function-Coupled-Watermark. ",
    "url": "https://arxiv.org/abs/2302.10296",
    "authors": [
      "Xiangyu Wen",
      "Yu Li",
      "Wei Jiang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10301",
    "title": "Artificial Intelligence System for Detection and Screening of Cardiac  Abnormalities using Electrocardiogram Images",
    "abstract": "The artificial intelligence (AI) system has achieved expert-level performance in electrocardiogram (ECG) signal analysis. However, in underdeveloped countries or regions where the healthcare information system is imperfect, only paper ECGs can be provided. Analysis of real-world ECG images (photos or scans of paper ECGs) remains challenging due to complex environments or interference. In this study, we present an AI system developed to detect and screen cardiac abnormalities (CAs) from real-world ECG images. The system was evaluated on a large dataset of 52,357 patients from multiple regions and populations across the world. On the detection task, the AI system obtained area under the receiver operating curve (AUC) of 0.996 (hold-out test), 0.994 (external test 1), 0.984 (external test 2), and 0.979 (external test 3), respectively. Meanwhile, the detection results of AI system showed a strong correlation with the diagnosis of cardiologists (cardiologist 1 (R=0.794, p<1e-3), cardiologist 2 (R=0.812, p<1e-3)). On the screening task, the AI system achieved AUCs of 0.894 (hold-out test) and 0.850 (external test). The screening performance of the AI system was better than that of the cardiologists (AI system (0.846) vs. cardiologist 1 (0.520) vs. cardiologist 2 (0.480)). Our study demonstrates the feasibility of an accurate, objective, easy-to-use, fast, and low-cost AI system for CA detection and screening. The system has the potential to be used by healthcare professionals, caregivers, and general users to assess CAs based on real-world ECG images. ",
    "url": "https://arxiv.org/abs/2302.10301",
    "authors": [
      "Deyun Zhang",
      "Shijia Geng",
      "Yang Zhou",
      "Weilun Xu",
      "Guodong Wei",
      "Kai Wang",
      "Jie Yu",
      "Qiang Zhu",
      "Yongkui Li",
      "Yonghong Zhao",
      "Xingyue Chen",
      "Rui Zhang",
      "Zhaoji Fu",
      "Rongbo Zhou",
      "Yanqi E",
      "Sumei Fan",
      "Qinghao Zhao",
      "Chuandong Cheng",
      "Nan Peng",
      "Liang Zhang",
      "Linlin Zheng",
      "Jianjun Chu",
      "Hongbin Xu",
      "Chen Tan",
      "Jian Liu",
      "Huayue Tao",
      "Tong Liu",
      "Kangyin Chen",
      "Chenyang Jiang",
      "Xingpeng Liu",
      "Shenda Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10303",
    "title": "Interpretable Out-Of-Distribution Detection Using Pattern Identification",
    "abstract": "Out-of-distribution (OoD) detection for data-based programs is a goal of paramount importance. Common approaches in the literature tend to train detectors requiring inside-of-distribution (in-distribution, or IoD) and OoD validation samples, and/or implement confidence metrics that are often abstract and therefore difficult to interpret. In this work, we propose to use existing work from the field of explainable AI, namely the PARTICUL pattern identification algorithm, in order to build more interpretable and robust OoD detectors for visual classifiers. Crucially, this approach does not require to retrain the classifier and is tuned directly to the IoD dataset, making it applicable to domains where OoD does not have a clear definition. Moreover, pattern identification allows us to provide images from the IoD dataset as reference points to better explain the confidence scores. We demonstrates that the detection capabilities of this approach are on par with existing methods through an extensive benchmark across four datasets and two definitions of OoD. In particular, we introduce a new benchmark based on perturbations of the IoD dataset which provides a known and quantifiable evaluation of the discrepancy between the IoD and OoD datasets that serves as a reference value for the comparison between various OoD detection methods. Our experiments show that the robustness of all metrics under test does not solely depend on the nature of the IoD dataset or the OoD definition, but also on the architecture of the classifier, which stresses the need for thorough experimentations for future work on OoD detection. ",
    "url": "https://arxiv.org/abs/2302.10303",
    "authors": [
      "Romain Xu-Darme",
      "Julien Girard-Satabin",
      "Darryl Hond",
      "Gabriele Incorvaia",
      "Zakaria Chihani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10306",
    "title": "Deep Convolutional Framelet Denoising for Panoramic by Mixed Wavelet  Integration",
    "abstract": "Enhancing quality and removing noise during preprocessing is one of the most critical steps in image processing. X-ray images are created by photons colliding with atoms and the variation in scattered noise absorption. This noise causes the graph's quality of medical to decline and, occasionally, causes it to repeat itself, causing an elevation in the patient's effective dose. One of the most critical challenges in this area has consistently been lowering the image noise. Techniques like BM3d, low-pass filters, and Autoencoder have taken this step. Due to the algorithm's structure and high repetition rate, neural networks using various architectures have reduced noise with acceptable results over the past ten years compared to the traditional BM3D and low-pass filters. The Hankel matrix combined with neural networks is one of these configurations. The Hankel matrix seeks a local circle by splitting up individual values into local and non-local components using a non-local matrix. A non-local matrix can be created using the wave or DCT. This paper proposes combining the waveform with the Daubechies (D4) wavelength because it has more energy and uses the u-Net neural network structure, which uses the waveform alone at each stage. The outcomes were evaluated using the PSNR and SSIM criteria, and the outcomes were verified by using various waves. The effectiveness of a one-wave network has increased from 0.5% to 1.2%, according to studies done on other datasets. ",
    "url": "https://arxiv.org/abs/2302.10306",
    "authors": [
      "Masoud Shahraki Mohammadi",
      "Seyed Javad Seyed Mahdavi Chabok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.10309",
    "title": "Hierarchical Perception Adversarial Learning Framework for Compressed  Sensing MRI",
    "abstract": "The long acquisition time has limited the accessibility of magnetic resonance imaging (MRI) because it leads to patient discomfort and motion artifacts. Although several MRI techniques have been proposed to reduce the acquisition time, compressed sensing in magnetic resonance imaging (CS-MRI) enables fast acquisition without compromising SNR and resolution. However, existing CS-MRI methods suffer from the challenge of aliasing artifacts. This challenge results in the noise-like textures and missing the fine details, thus leading to unsatisfactory reconstruction performance. To tackle this challenge, we propose a hierarchical perception adversarial learning framework (HP-ALF). HP-ALF can perceive the image information in the hierarchical mechanism: image-level perception and patch-level perception. The former can reduce the visual perception difference in the entire image, and thus achieve aliasing artifact removal. The latter can reduce this difference in the regions of the image, and thus recover fine details. Specifically, HP-ALF achieves the hierarchical mechanism by utilizing multilevel perspective discrimination. This discrimination can provide the information from two perspectives (overall and regional) for adversarial learning. It also utilizes a global and local coherent discriminator to provide structure information to the generator during training. In addition, HP-ALF contains a context-aware learning block to effectively exploit the slice information between individual images for better reconstruction performance. The experiments validated on three datasets demonstrate the effectiveness of HP-ALF and its superiority to the comparative methods. ",
    "url": "https://arxiv.org/abs/2302.10309",
    "authors": [
      "Zhifan Gao",
      "Yifeng Guo",
      "Jiajing Zhang",
      "Tieyong Zeng",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10315",
    "title": "Generalization algorithm of multimodal pre-training model based on  graph-text self-supervised training",
    "abstract": "Recently, a large number of studies have shown that the introduction of visual information can effectively improve the effect of neural machine translation (NMT). Its effectiveness largely depends on the availability of a large number of bilingual parallel sentence pairs and manual image annotation. The lack of images and the effectiveness of images have been difficult to solve. In this paper, a multimodal pre-training generalization algorithm for self-supervised training is proposed, which overcomes the lack of visual information and inaccuracy, and thus extends the applicability of images on NMT. Specifically, we will search for many pictures from the existing sentences through the search engine, and then through the relationship between visual information and text, do the self-supervised training task of graphics and text to obtain more effective visual information for text. We show that when the filtered information is used as multimodal machine translation for fine-tuning, the effect of translation in the global voice dataset is 0.5 BLEU higher than the baseline. ",
    "url": "https://arxiv.org/abs/2302.10315",
    "authors": [
      "Zhangxiaobing",
      "Tangzhenhao",
      "Longzi",
      "Fuxianghua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10320",
    "title": "Meta-World Conditional Neural Processes",
    "abstract": "We propose Meta-World Conditional Neural Processes (MW-CNP), a conditional world model generator that leverages sample efficiency and scalability of Conditional Neural Processes to enable an agent to sample from its own \"hallucination\". We intend to reduce the agent's interaction with the target environment at test time as much as possible. To reduce the number of samples required at test time, we first obtain a latent representation of the transition dynamics from a single rollout from the test environment with hidden parameters. Then, we obtain rollouts for few-shot learning by interacting with the \"hallucination\" generated by the meta-world model. Using the world model representation from MW-CNP, the meta-RL agent can adapt to an unseen target environment with significantly fewer samples collected from the target environment compared to the baselines. We emphasize that the agent does not have access to the task parameters throughout training and testing, and MW-CNP is trained on offline interaction data logged during meta-training. ",
    "url": "https://arxiv.org/abs/2302.10320",
    "authors": [
      "Suzan Ece Ada",
      "Emre Ugur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.10326",
    "title": "Unsupervised Out-of-Distribution Detection with Diffusion Inpainting",
    "abstract": "Unsupervised out-of-distribution detection (OOD) seeks to identify out-of-domain data by learning only from unlabeled in-domain data. We present a novel approach for this task - Lift, Map, Detect (LMD) - that leverages recent advancement in diffusion models. Diffusion models are one type of generative models. At their core, they learn an iterative denoising process that gradually maps a noisy image closer to their training manifolds. LMD leverages this intuition for OOD detection. Specifically, LMD lifts an image off its original manifold by corrupting it, and maps it towards the in-domain manifold with a diffusion model. For an out-of-domain image, the mapped image would have a large distance away from its original manifold, and LMD would identify it as OOD accordingly. We show through extensive experiments that LMD achieves competitive performance across a broad variety of datasets. ",
    "url": "https://arxiv.org/abs/2302.10326",
    "authors": [
      "Zhenzhen Liu",
      "Jin Peng Zhou",
      "Yufan Wang",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10328",
    "title": "Hello Me, Meet the Real Me: Audio Deepfake Attacks on Voice Assistants",
    "abstract": "The radical advances in telecommunications and computer science have enabled a myriad of applications and novel seamless interaction with computing interfaces. Voice Assistants (VAs) have become a norm for smartphones, and millions of VAs incorporated in smart devices are used to control these devices in the smart home context. Previous research has shown that they are prone to attacks, leading vendors to countermeasures. One of these measures is to allow only a specific individual, the device's owner, to perform possibly dangerous tasks, that is, tasks that may disclose personal information, involve monetary transactions etc. To understand the extent to which VAs provide the necessary protection to their users, we experimented with two of the most widely used VAs, which the participants trained. We then utilised voice synthesis using samples provided by participants to synthesise commands that were used to trigger the corresponding VA and perform a dangerous task. Our extensive results showed that more than 30\\% of our deepfake attacks were successful and that there was at least one successful attack for more than half of the participants. Moreover, they illustrate statistically significant variation among vendors and, in one case, even gender bias. The outcomes are rather alarming and require the deployment of further countermeasures to prevent exploitation, as the number of VAs in use is currently comparable to the world population. ",
    "url": "https://arxiv.org/abs/2302.10328",
    "authors": [
      "Domna Bilika",
      "Nikoletta Michopoulou",
      "Efthimios Alepis",
      "Constantinos Patsakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.10331",
    "title": "Causal Razors",
    "abstract": "When performing causal discovery, assumptions have to be made on how the true causal mechanism corresponds to the underlying joint probability distribution. These assumptions are labeled as causal razors in this work. We review numerous causal razors that appeared in the literature, and offer a comprehensive logical comparison of them. In particular, we scrutinize an unpopular causal razor, namely parameter minimality, in multinomial causal models and its logical relations with other well-studied causal razors. Our logical result poses a dilemma in selecting a reasonable scoring criterion for score-based casual search algorithms. ",
    "url": "https://arxiv.org/abs/2302.10331",
    "authors": [
      "Wai-yin Lam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.10343",
    "title": "Non-rigid Medical Image Registration using Physics-informed Neural  Networks",
    "abstract": "Biomechanical modelling of soft tissue provides a non-data-driven method for constraining medical image registration, such that the estimated spatial transformation is considered biophysically plausible. This has not only been adopted in real-world clinical applications, such as the MR-to-ultrasound registration for prostate intervention of interest in this work, but also provides an explainable means of understanding the organ motion and spatial correspondence establishment. This work instantiates the recently-proposed physics-informed neural networks (PINNs) to a 3D linear elastic model for modelling prostate motion commonly encountered during transrectal ultrasound guided procedures. To overcome a widely-recognised challenge in generalising PINNs to different subjects, we propose to use PointNet as the nodal-permutation-invariant feature extractor, together with a registration algorithm that aligns point sets and simultaneously takes into account the PINN-imposed biomechanics. The proposed method has been both developed and validated in both patient-specific and multi-patient manner. ",
    "url": "https://arxiv.org/abs/2302.10343",
    "authors": [
      "Zhe Min",
      "Zachary M. C. Baum",
      "Shaheer U. Saeed",
      "Mark Emberton",
      "Dean C. Barratt",
      "Zeike A. Taylor",
      "Yipeng Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2302.10347",
    "title": "Online Evolutionary Neural Architecture Search for Multivariate  Non-Stationary Time Series Forecasting",
    "abstract": "Time series forecasting (TSF) is one of the most important tasks in data science given the fact that accurate time series (TS) predictive models play a major role across a wide variety of domains including finance, transportation, health care, and power systems. Real-world utilization of machine learning (ML) typically involves (pre-)training models on collected, historical data and then applying them to unseen data points. However, in real-world applications, time series data streams are usually non-stationary and trained ML models usually, over time, face the problem of data or concept drift. To address this issue, models must be periodically retrained or redesigned, which takes significant human and computational resources. Additionally, historical data may not even exist to re-train or re-design model with. As a result, it is highly desirable that models are designed and trained in an online fashion. This work presents the Online NeuroEvolution-based Neural Architecture Search (ONE-NAS) algorithm, which is a novel neural architecture search method capable of automatically designing and dynamically training recurrent neural networks (RNNs) for online forecasting tasks. Without any pre-training, ONE-NAS utilizes populations of RNNs that are continuously updated with new network structures and weights in response to new multivariate input data. ONE-NAS is tested on real-world, large-scale multivariate wind turbine data as well as the univariate Dow Jones Industrial Average (DJIA) dataset. Results demonstrate that ONE-NAS outperforms traditional statistical time series forecasting methods, including online linear regression, fixed long short-term memory (LSTM) and gated recurrent unit (GRU) models trained online, as well as state-of-the-art, online ARIMA strategies. ",
    "url": "https://arxiv.org/abs/2302.10347",
    "authors": [
      "Zimeng Lyu",
      "Alexander Ororbia",
      "Travis Desell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.10351",
    "title": "Variational Autoencoding Neural Operators",
    "abstract": "Unsupervised learning with functional data is an emerging paradigm of machine learning research with applications to computer vision, climate modeling and physical systems. A natural way of modeling functional data is by learning operators between infinite dimensional spaces, leading to discretization invariant representations that scale independently of the sample grid resolution. Here we present Variational Autoencoding Neural Operators (VANO), a general strategy for making a large class of operator learning architectures act as variational autoencoders. For this purpose, we provide a novel rigorous mathematical formulation of the variational objective in function spaces for training. VANO first maps an input function to a distribution over a latent space using a parametric encoder and then decodes a sample from the latent distribution to reconstruct the input, as in classic variational autoencoders. We test VANO with different model set-ups and architecture choices for a variety of benchmarks. We start from a simple Gaussian random field where we can analytically track what the model learns and progressively transition to more challenging benchmarks including modeling phase separation in Cahn-Hilliard systems and real world satellite data for measuring Earth surface deformation. ",
    "url": "https://arxiv.org/abs/2302.10351",
    "authors": [
      "Jacob H. Seidman",
      "Georgios Kissas",
      "George J. Pappas",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.10362",
    "title": "Heterogeneous Social Event Detection via Hyperbolic Graph  Representations",
    "abstract": "Social events reflect the dynamics of society and, here, natural disasters and emergencies receive significant attention. The timely detection of these events can provide organisations and individuals with valuable information to reduce or avoid losses. However, due to the complex heterogeneities of the content and structure of social media, existing models can only learn limited information; large amounts of semantic and structural information are ignored. In addition, due to high labour costs, it is rare for social media datasets to include high-quality labels, which also makes it challenging for models to learn information from social media. In this study, we propose two hyperbolic graph representation-based methods for detecting social events from heterogeneous social media environments. For cases where a dataset has labels, we designed a Hyperbolic Social Event Detection (HSED) model that converts complex social information into a unified social message graph. This model addresses the heterogeneity of social media, and, with this graph, the information in social media can be used to capture structural information based on the properties of hyperbolic space. For cases where the dataset is unlabelled, we designed an Unsupervised Hyperbolic Social Event Detection (UHSED). This model is based on the HSED model but includes graph contrastive learning to make it work in unlabelled scenarios. Extensive experiments demonstrate the superiority of the proposed approaches. ",
    "url": "https://arxiv.org/abs/2302.10362",
    "authors": [
      "Zitai Qiu",
      "Jia Wu",
      "Jian Yang",
      "Xing Su",
      "Charu C. Aggarwal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10390",
    "title": "DrasCLR: A Self-supervised Framework of Learning Disease-related and  Anatomy-specific Representation for 3D Medical Images",
    "abstract": "Large-scale volumetric medical images with annotation are rare, costly, and time prohibitive to acquire. Self-supervised learning (SSL) offers a promising pre-training and feature extraction solution for many downstream tasks, as it only uses unlabeled data. Recently, SSL methods based on instance discrimination have gained popularity in the medical imaging domain. However, SSL pre-trained encoders may use many clues in the image to discriminate an instance that are not necessarily disease-related. Moreover, pathological patterns are often subtle and heterogeneous, requiring the ability of the desired method to represent anatomy-specific features that are sensitive to abnormal changes in different body parts. In this work, we present a novel SSL framework, named DrasCLR, for 3D medical imaging to overcome these challenges. We propose two domain-specific contrastive learning strategies: one aims to capture subtle disease patterns inside a local anatomical region, and the other aims to represent severe disease patterns that span larger regions. We formulate the encoder using conditional hyper-parameterized network, in which the parameters are dependant on the anatomical location, to extract anatomically sensitive features. Extensive experiments on large-scale computer tomography (CT) datasets of lung images show that our method improves the performance of many downstream prediction and segmentation tasks. The patient-level representation improves the performance of the patient survival prediction task. We show how our method can detect emphysema subtypes via dense prediction. We demonstrate that fine-tuning the pre-trained model can significantly reduce annotation efforts without sacrificing emphysema detection accuracy. Our ablation study highlights the importance of incorporating anatomical context into the SSL framework. ",
    "url": "https://arxiv.org/abs/2302.10390",
    "authors": [
      "Ke Yu",
      "Li Sun",
      "Junxiang Chen",
      "Max Reynolds",
      "Tigmanshu Chaudhary",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10393",
    "title": "Epistemic Prediction and Planning with Implicit Coordination for  Multi-Robot Teams in Communication Restricted Environments",
    "abstract": "In communication restricted environments, a multi-robot system can be deployed to either: i) maintain constant communication but potentially sacrifice operational efficiency due to proximity constraints or ii) allow disconnections to increase environmental coverage efficiency, challenges on how, when, and where to reconnect (rendezvous problem). In this work we tackle the latter problem and notice that most state-of-the-art methods assume that robots will be able to execute a predetermined plan; however system failures and changes in environmental conditions can cause the robots to deviate from the plan with cascading effects across the multi-robot system. This paper proposes a coordinated epistemic prediction and planning framework to achieve consensus without communicating for exploration and coverage, task discovery and completion, and rendezvous applications. Dynamic epistemic logic is the principal component implemented to allow robots to propagate belief states and empathize with other agents. Propagation of belief states and subsequent coverage of the environment is achieved via a frontier-based method within an artificial physics-based framework. The proposed framework is validated with both simulations and experiments with unmanned ground vehicles in various cluttered environments. ",
    "url": "https://arxiv.org/abs/2302.10393",
    "authors": [
      "Lauren Bramblett",
      "Shijie Gao",
      "Nicola Bezzo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10396",
    "title": "Assessing Domain Gap for Continual Domain Adaptation in Object Detection",
    "abstract": "To ensure reliable object detection in autonomous systems, the detector must be able to adapt to changes in appearance caused by environmental factors such as time of day, weather, and seasons. Continually adapting the detector to incorporate these changes is a promising solution, but it can be computationally costly. Our proposed approach is to selectively adapt the detector only when necessary, using new data that does not have the same distribution as the current training data. To this end, we investigate three popular metrics for domain gap evaluation and find that there is a correlation between the domain gap and detection accuracy. Therefore, we apply the domain gap as a criterion to decide when to adapt the detector. Our experiments show that our approach has the potential to improve the efficiency of the detector's operation in real-world scenarios, where environmental conditions change in a cyclical manner, without sacrificing the overall performance of the detector. Our code is publicly available at https://github.com/dadung/DGE-CDA. ",
    "url": "https://arxiv.org/abs/2302.10396",
    "authors": [
      "Anh-Dzung Doan",
      "Bach Long Nguyen",
      "Surabhi Gupta",
      "Ian Reid",
      "Markus Wagner",
      "Tat-Jun Chin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10406",
    "title": "Time to Embrace Natural Language Processing (NLP)-based Digital  Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep  Learning Pipelines",
    "abstract": "NLP-based computer vision models, particularly vision transformers, have been shown to outperform CNN models in many imaging tasks. However, most digital pathology artificial-intelligence models are based on CNN architectures, probably owing to a lack of data regarding NLP models for pathology images. In this study, we developed digital pathology pipelines to benchmark the five most recently proposed NLP models (vision transformer (ViT), Swin Transformer, MobileViT, CMT, and Sequencer2D) and four popular CNN models (ResNet18, ResNet50, MobileNetV2, and EfficientNet) to predict biomarkers in colorectal cancer (microsatellite instability, CpG island methylator phenotype, and BRAF mutation). Hematoxylin and eosin-stained whole-slide images from Molecular and Cellular Oncology and The Cancer Genome Atlas were used as training and external validation datasets, respectively. Cross-study external validations revealed that the NLP-based models significantly outperformed the CNN-based models in biomarker prediction tasks, improving the overall prediction and precision up to approximately 10% and 26%, respectively. Notably, compared with existing models in the current literature using large training datasets, our NLP models achieved state-of-the-art predictions for all three biomarkers using a relatively small training dataset, suggesting that large training datasets are not a prerequisite for NLP models or transformers, and NLP may be more suitable for clinical studies in which small training datasets are commonly collected. The superior performance of Sequencer2D suggests that further research and innovation on both transformer and bidirectional long short-term memory architectures are warranted in the field of digital pathology. NLP models can replace classic CNN architectures and become the new workhorse backbone in the field of digital pathology. ",
    "url": "https://arxiv.org/abs/2302.10406",
    "authors": [
      "Min Cen",
      "Xingyu Li",
      "Bangwei Guo",
      "Jitendra Jonnagaddala",
      "Hong Zhang",
      "Xu Steven Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2302.10407",
    "title": "Label Information Enhanced Fraud Detection against Low Homophily in  Graphs",
    "abstract": "Node classification is a substantial problem in graph-based fraud detection. Many existing works adopt Graph Neural Networks (GNNs) to enhance fraud detectors. While promising, currently most GNN-based fraud detectors fail to generalize to the low homophily setting. Besides, label utilization has been proved to be significant factor for node classification problem. But we find they are less effective in fraud detection tasks due to the low homophily in graphs. In this work, we propose GAGA, a novel Group AGgregation enhanced TrAnsformer, to tackle the above challenges. Specifically, the group aggregation provides a portable method to cope with the low homophily issue. Such an aggregation explicitly integrates the label information to generate distinguishable neighborhood information. Along with group aggregation, an attempt towards end-to-end trainable group encoding is proposed which augments the original feature space with the class labels. Meanwhile, we devise two additional learnable encodings to recognize the structural and relational context. Then, we combine the group aggregation and the learnable encodings into a Transformer encoder to capture the semantic information. Experimental results clearly show that GAGA outperforms other competitive graph-based fraud detectors by up to 24.39% on two trending public datasets and a real-world industrial dataset from Anonymous. Even more, the group aggregation is demonstrated to outperform other label utilization methods (e.g., C&S, BoT/UniMP) in the low homophily setting. ",
    "url": "https://arxiv.org/abs/2302.10407",
    "authors": [
      "Yuchen Wang",
      "Jinghui Zhang",
      "Zhengjie Huang",
      "Weibin Li",
      "Shikun Feng",
      "Ziheng Ma",
      "Yu Sun",
      "Dianhai Yu",
      "Fang Dong",
      "Jiahui Jin",
      "Beilun Wang",
      "Junzhou Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10412",
    "title": "Non-pooling Network for medical image segmentation",
    "abstract": "Existing studies tend tofocus onmodel modifications and integration with higher accuracy, which improve performance but also carry huge computational costs, resulting in longer detection times. Inmedical imaging, the use of time is extremely sensitive. And at present most of the semantic segmentation models have encoder-decoder structure or double branch structure. Their several times of the pooling use with high-level semantic information extraction operation cause information loss although there si a reverse pooling or other similar action to restore information loss of pooling operation. In addition, we notice that visual attention mechanism has superior performance on a variety of tasks. Given this, this paper proposes non-pooling network(NPNet), non-pooling commendably reduces the loss of information and attention enhancement m o d u l e ( A M ) effectively increases the weight of useful information. The method greatly reduces the number of parametersand computation costs by the shallow neural network structure. We evaluate the semantic segmentation model of our NPNet on three benchmark datasets comparing w i t h multiple current state-of-the-art(SOTA) models, and the implementation results show thatour NPNetachieves SOTA performance, with an excellent balance between accuracyand speed. ",
    "url": "https://arxiv.org/abs/2302.10412",
    "authors": [
      "Weihu Song",
      "Heng Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10414",
    "title": "Improving Scene Text Image Super-Resolution via Dual Prior Modulation  Network",
    "abstract": "Scene text image super-resolution (STISR) aims to simultaneously increase the resolution and legibility of the text images, and the resulting images will significantly affect the performance of downstream tasks. Although numerous progress has been made, existing approaches raise two crucial issues: (1) They neglect the global structure of the text, which bounds the semantic determinism of the scene text. (2) The priors, e.g., text prior or stroke prior, employed in existing works, are extracted from pre-trained text recognizers. That said, such priors suffer from the domain gap including low resolution and blurriness caused by poor imaging conditions, leading to incorrect guidance. Our work addresses these gaps and proposes a plug-and-play module dubbed Dual Prior Modulation Network (DPMN), which leverages dual image-level priors to bring performance gain over existing approaches. Specifically, two types of prior-guided refinement modules, each using the text mask or graphic recognition result of the low-quality SR image from the preceding layer, are designed to improve the structural clarity and semantic accuracy of the text, respectively. The following attention mechanism hence modulates two quality-enhanced images to attain a superior SR result. Extensive experiments validate that our method improves the image quality and boosts the performance of downstream tasks over five typical approaches on the benchmark. Substantial visualizations and ablation studies demonstrate the advantages of the proposed DPMN. Code is available at: https://github.com/jdfxzzy/DPMN. ",
    "url": "https://arxiv.org/abs/2302.10414",
    "authors": [
      "Shipeng Zhu",
      "Zuoyan Zhao",
      "Pengfei Fang",
      "Hui Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10420",
    "title": "HCGMNET: A Hierarchical Change Guiding Map Network For Change Detection",
    "abstract": "Very-high-resolution (VHR) remote sensing (RS) image change detection (CD) has been a challenging task for its very rich spatial information and sample imbalance problem. In this paper, we have proposed a hierarchical change guiding map network (HCGMNet) for change detection. The model uses hierarchical convolution operations to extract multiscale features, continuously merges multi-scale features layer by layer to improve the expression of global and local information, and guides the model to gradually refine edge features and comprehensive performance by a change guide module (CGM), which is a self-attention with changing guide map. Extensive experiments on two CD datasets show that the proposed HCGMNet architecture achieves better CD performance than existing state-of-the-art (SOTA) CD methods. ",
    "url": "https://arxiv.org/abs/2302.10420",
    "authors": [
      "Chengxi Han",
      "Chen Wu",
      "Bo Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.10423",
    "title": "Criminal Investigation Tracker with Suspect Prediction using Machine  Learning",
    "abstract": "An automated approach to identifying offenders in Sri Lanka would be better than the current system. Obtaining information from eyewitnesses is one of the less reliable approaches and procedures still in use today. Automated criminal identification has the ability to save lives, notwithstanding Sri Lankan culture's lack of awareness of the issue. Using cutting-edge technology like biometrics to finish this task would be the most accurate strategy. The most notable outcomes will be obtained by applying fingerprint and face recognition as biometric techniques. The main responsibilities will be image optimization and criminality. CCTV footage may be used to identify a person's fingerprint, identify a person's face, and identify crimes involving weapons. Additionally, we unveil a notification system and condense the police report to Additionally, to make it simpler for police officers to understand the essential points of the crime, we develop a notification system and condense the police report. Additionally, if an incident involving a weapon is detected, an automated notice of the crime with all the relevant facts is sent to the closest police station. The summarization of the police report is what makes this the most original. In order to improve the efficacy of the overall image, the system will quickly and precisely identify the full crime scene, identify, and recognize the suspects using their faces and fingerprints, and detect firearms. This study provides a novel approach for crime prediction based on real-world data, and criminality incorporation. A crime or occurrence should be reported to the appropriate agencies, and the suggested web application should be improved further to offer a workable channel of communication. ",
    "url": "https://arxiv.org/abs/2302.10423",
    "authors": [
      "S. J. Dilmini",
      "R. A. T. M. Rajapaksha",
      "Erandika Lakmali",
      "S. P. S. Mandula",
      "D. D. G. Delgasdeniya",
      "Pradeepa Bandara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2302.10424",
    "title": "Deep Learning via Neural Energy Descent",
    "abstract": "This paper proposes the Nerual Energy Descent (NED) via neural network evolution equations for a wide class of deep learning problems. We show that deep learning can be reformulated as the evolution of network parameters in an evolution equation and the steady state solution of the partial differential equation (PDE) provides a solution to deep learning. This equation corresponds to a gradient descent flow of a variational problem and hence the proposed time-dependent PDE solves an energy minimization problem to obtain a global minimizer of deep learning. This gives a novel interpretation and solution to deep learning optimization. The computational complexity of the proposed energy descent method can be enhanced by randomly sampling the spatial domain of the PDE leading to an efficient NED. Numerical examples are provided to demonstrate the numerical advantage of NED over stochastic gradient descent (SGD). ",
    "url": "https://arxiv.org/abs/2302.10424",
    "authors": [
      "Wenrui Hao",
      "Chunmei Wang",
      "Xingjian Xu",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.10425",
    "title": "Instance-incremental Scene Graph Generation from Real-world Point Clouds  via Normalizing Flows",
    "abstract": "This work introduces a new task of instance-incremental scene graph generation: Given an empty room of the point cloud, representing it as a graph and automatically increasing novel instances. A graph denoting the object layout of the scene is finally generated. It is an important task since it helps to guide the insertion of novel 3D objects into a real-world scene in vision-based applications like augmented reality. It is also challenging because the complexity of the real-world point cloud brings difficulties in learning object layout experiences from the observation data (non-empty rooms with labeled semantics). We model this task as a conditional generation problem and propose a 3D autoregressive framework based on normalizing flows (3D-ANF) to address it. We first represent the point cloud as a graph by extracting the containing label semantics and contextual relationships. Next, a model based on normalizing flows is introduced to map the conditional generation of graphic elements into the Gaussian process. The mapping is invertible. Thus, the real-world experiences represented in the observation data can be modeled in the training phase, and novel instances can be sequentially generated based on the Gaussian process in the testing phase. We implement this new task on the dataset of 3D point-based scenes (3DSSG and 3RScan) and evaluate the performance of our method. Experiments show that our method generates reliable novel graphs from the real-world point cloud and achieves state-of-the-art performance on the benchmark dataset. ",
    "url": "https://arxiv.org/abs/2302.10425",
    "authors": [
      "Chao Qi",
      "Jianqin Yin",
      "Jinghang Xu",
      "Pengxiang Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10428",
    "title": "A Dynamic Temporal Self-attention Graph Convolutional Network for  Traffic Prediction",
    "abstract": "Accurate traffic prediction in real time plays an important role in Intelligent Transportation System (ITS) and travel navigation guidance. There have been many attempts to predict short-term traffic status which consider the spatial and temporal dependencies of traffic information such as temporal graph convolutional network (T-GCN) model and convolutional long short-term memory (Conv-LSTM) model. However, most existing methods use simple adjacent matrix consisting of 0 and 1 to capture the spatial dependence which can not meticulously describe the urban road network topological structure and the law of dynamic change with time. In order to tackle the problem, this paper proposes a dynamic temporal self-attention graph convolutional network (DT-SGN) model which considers the adjacent matrix as a trainable attention score matrix and adapts network parameters to different inputs. Specially, self-attention graph convolutional network (SGN) is chosen to capture the spatial dependence and the dynamic gated recurrent unit (Dynamic-GRU) is chosen to capture temporal dependence and learn dynamic changes of input data. Experiments demonstrate the superiority of our method over state-of-art model-driven model and data-driven models on real-world traffic datasets. ",
    "url": "https://arxiv.org/abs/2302.10428",
    "authors": [
      "Ruiyuan Jiang",
      "Shangbo Wang",
      "Yuli Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10430",
    "title": "Interval Type-2 Fuzzy Neural Networks for Multi-Label Classification",
    "abstract": "Prediction of multi-dimensional labels plays an important role in machine learning problems. We found that the classical binary labels could not reflect the contents and their relationships in an instance. Hence, we propose a multi-label classification model based on interval type-2 fuzzy logic. In the proposed model, we use a deep neural network to predict the type-1 fuzzy membership of an instance and another one to predict the fuzzifiers of the membership to generate interval type-2 fuzzy memberships. We also propose a loss function to measure the similarities between binary labels in datasets and interval type-2 fuzzy memberships generated by our model. The experiments validate that our approach outperforms baselines on multi-label classification benchmarks. ",
    "url": "https://arxiv.org/abs/2302.10430",
    "authors": [
      "Dayong Tian",
      "Feifei Li",
      "Yiwen Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10432",
    "title": "Link Prediction on Latent Heterogeneous Graphs",
    "abstract": "On graph data, the multitude of node or edge types gives rise to heterogeneous information networks (HINs). To preserve the heterogeneous semantics on HINs, the rich node/edge types become a cornerstone of HIN representation learning. However, in real-world scenarios, type information is often noisy, missing or inaccessible. Assuming no type information is given, we define a so-called latent heterogeneous graph (LHG), which carries latent heterogeneous semantics as the node/edge types cannot be observed. In this paper, we study the challenging and unexplored problem of link prediction on an LHG. As existing approaches depend heavily on type-based information, they are suboptimal or even inapplicable on LHGs. To address the absence of type information, we propose a model named LHGNN, based on the novel idea of semantic embedding at node and path levels, to capture latent semantics on and between nodes. We further design a personalization function to modulate the heterogeneous contexts conditioned on their latent semantics w.r.t. the target node, to enable finer-grained aggregation. Finally, we conduct extensive experiments on four benchmark datasets, and demonstrate the superior performance of LHGNN. ",
    "url": "https://arxiv.org/abs/2302.10432",
    "authors": [
      "Trung-Kien Nguyen",
      "Zemin Liu",
      "Yuan Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10437",
    "title": "Two-in-one Knowledge Distillation for Efficient Facial Forgery Detection",
    "abstract": "Facial forgery detection is a crucial but extremely challenging topic, with the fast development of forgery techniques making the synthetic artefact highly indistinguishable. Prior works show that by mining both spatial and frequency information the forgery detection performance of deep learning models can be vastly improved. However, leveraging multiple types of information usually requires more than one branch in the neural network, which makes the model heavy and cumbersome. Knowledge distillation, as an important technique for efficient modelling, could be a possible remedy. We find that existing knowledge distillation methods have difficulties distilling a dual-branch model into a single-branch model. More specifically, knowledge distillation on both the spatial and frequency branches has degraded performance than distillation only on the spatial branch. To handle such problem, we propose a novel two-in-one knowledge distillation framework which can smoothly merge the information from a large dual-branch network into a small single-branch network, with the help of different dedicated feature projectors and the gradient homogenization technique. Experimental analysis on two datasets, FaceForensics++ and Celeb-DF, shows that our proposed framework achieves superior performance for facial forgery detection with much fewer parameters. ",
    "url": "https://arxiv.org/abs/2302.10437",
    "authors": [
      "Chuyang Zhou",
      "Jiajun Huang",
      "Daochang Liu",
      "Chengbin Du",
      "Siqi Ma",
      "Surya Nepal",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10441",
    "title": "Speech Privacy Leakage from Shared Gradients in Distributed Learning",
    "abstract": "Distributed machine learning paradigms, such as federated learning, have been recently adopted in many privacy-critical applications for speech analysis. However, such frameworks are vulnerable to privacy leakage attacks from shared gradients. Despite extensive efforts in the image domain, the exploration of speech privacy leakage from gradients is quite limited. In this paper, we explore methods for recovering private speech/speaker information from the shared gradients in distributed learning settings. We conduct experiments on a keyword spotting model with two different types of speech features to quantify the amount of leaked information by measuring the similarity between the original and recovered speech signals. We further demonstrate the feasibility of inferring various levels of side-channel information, including speech content and speaker identity, under the distributed learning framework without accessing the user's data. ",
    "url": "https://arxiv.org/abs/2302.10441",
    "authors": [
      "Zhuohang Li",
      "Jiaxin Zhang",
      "Jian Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.10446",
    "title": "Deep Reinforcement Learning Based on Local GNN for Goal-conditioned  Deformable Object Rearranging",
    "abstract": "Object rearranging is one of the most common deformable manipulation tasks, where the robot needs to rearrange a deformable object into a goal configuration. Previous studies focus on designing an expert system for each specific task by model-based or data-driven approaches and the application scenarios are therefore limited. Some research has been attempting to design a general framework to obtain more advanced manipulation capabilities for deformable rearranging tasks, with lots of progress achieved in simulation. However, transferring from simulation to reality is difficult due to the limitation of the end-to-end CNN architecture. To address these challenges, we design a local GNN (Graph Neural Network) based learning method, which utilizes two representation graphs to encode keypoints detected from images. Self-attention is applied for graph updating and cross-attention is applied for generating manipulation actions. Extensive experiments have been conducted to demonstrate that our framework is effective in multiple 1-D (rope, rope ring) and 2-D (cloth) rearranging tasks in simulation and can be easily transferred to a real robot by fine-tuning a keypoint detector. ",
    "url": "https://arxiv.org/abs/2302.10446",
    "authors": [
      "Yuhong Deng",
      "Chongkun Xia",
      "Xueqian Wang",
      "Lipeng Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10448",
    "title": "Variational inference in neural functional prior using normalizing  flows: Application to differential equation and operator learning problems",
    "abstract": "Physics-informed deep learning have recently emerged as an effective tool for leveraging both observational data and available physical laws. Physics-informed neural networks (PINNs) and deep operator networks (DeepONets) are two such models. The former encodes the physical laws via the automatic differentiation, while the latter learns the hidden physics from data. Generally, the noisy and limited observational data as well as the overparameterization in neural networks (NNs) result in uncertainty in predictions from deep learning models. In [1], a Bayesian framework based on the {{Generative Adversarial Networks}} (GAN) has been proposed as a unified model to quantify uncertainties in predictions of PINNs as well as DeepONets. Specifically, the proposed approach in [1] has two stages: (1) prior learning, and (2) posterior estimation. At the first stage, the GANs are employed to learn a functional prior either from a prescribed function distribution, e.g., Gaussian process, or from historical data and available physics. At the second stage, the Hamiltonian Monte Carlo (HMC) method is utilized to estimate the posterior in the latent space of GANs. However, the vanilla HMC does not support the mini-batch training, which limits its applications in problems with big data. In the present work, we propose to use the normalizing flow (NF) models in the context of variational inference, which naturally enables the minibatch training, as the alternative to HMC for posterior estimation in the latent space of GANs. A series of numerical experiments, including a nonlinear differential equation problem and a 100-dimensional Darcy problem, are conducted to demonstrate that NF with full-/mini-batch training are able to achieve similar accuracy as the ``gold rule'' HMC. ",
    "url": "https://arxiv.org/abs/2302.10448",
    "authors": [
      "Xuhui Meng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2302.10450",
    "title": "Automotive RADAR sub-sampling via object detection networks: Leveraging  prior signal information",
    "abstract": "Automotive radar has increasingly attracted attention due to growing interest in autonomous driving technologies. Acquiring situational awareness using multimodal data collected at high sampling rates by various sensing devices including cameras, LiDAR, and radar requires considerable power, memory and compute resources which are often limited at an edge device. In this paper, we present a novel adaptive radar sub-sampling algorithm designed to identify regions that require more detailed/accurate reconstruction based on prior environmental conditions' knowledge, enabling near-optimal performance at considerably lower effective sampling rates. Designed to robustly perform under variable weather conditions, the algorithm was shown on the Oxford raw radar and RADIATE dataset to achieve accurate reconstruction utilizing only 10% of the original samples in good weather and 20% in extreme (snow, fog) weather conditions. A further modification of the algorithm incorporates object motion to enable reliable identification of important regions. This includes monitoring possible future occlusions caused by objects detected in the present frame. Finally, we train a YOLO network on the RADIATE dataset to perform object detection directly on RADAR data and obtain a 6.6% AP50 improvement over the baseline Faster R-CNN network. ",
    "url": "https://arxiv.org/abs/2302.10450",
    "authors": [
      "Madhumitha Sakthi",
      "Ahmed Tewfik",
      "Marius Arvinte",
      "Haris Vikalo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.10454",
    "title": "KG-ECO: Knowledge Graph Enhanced Entity Correction for Query Rewriting",
    "abstract": "Query Rewriting (QR) plays a critical role in large-scale dialogue systems for reducing frictions. When there is an entity error, it imposes extra challenges for a dialogue system to produce satisfactory responses. In this work, we propose KG-ECO: Knowledge Graph enhanced Entity COrrection for query rewriting, an entity correction system with corrupt entity span detection and entity retrieval/re-ranking functionalities.To boost the model performance, we incorporate Knowledge Graph (KG) to provide entity structural information (neighboring entities encoded by graph neural networks) and textual information (KG entity descriptions encoded by RoBERTa). Experimental results show that our approach yields a clear performance gain over two baselines: utterance level QR and entity correction without utilizing KG information. The proposed system is particularly effective for few-shot learning cases where target entities are rarely seen in training or there is a KG relation between the target entity and other contextual entities in the query. ",
    "url": "https://arxiv.org/abs/2302.10454",
    "authors": [
      "Jinglun Cai",
      "Mingda Li",
      "Ziyan Jiang",
      "Eunah Cho",
      "Zheng Chen",
      "Yang Liu",
      "Xing Fan",
      "Chenlei Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10473",
    "title": "Oriented Object Detection in Optical Remote Sensing Images: A Survey",
    "abstract": "Oriented object detection is one of the most fundamental and challenging tasks in remote sensing, aiming at locating the oriented objects of numerous predefined object categories. Recently, deep learning based methods have achieved remarkable performance in detecting oriented objects in remote sensing imagery. However, a thorough review of the literature in remote sensing has not yet emerged. Therefore, we give a comprehensive survey of recent advances and cover many aspects of oriented object detection, including problem definition, commonly used datasets, evaluation protocols, detection frameworks, oriented object representations, and feature representations. Besides, we analyze and discuss state-of-the-art methods. We finally discuss future research directions to put forward some useful research guidance. We believe that this survey shall be valuable to researchers across academia and industry. ",
    "url": "https://arxiv.org/abs/2302.10473",
    "authors": [
      "Kun Wang",
      "Zhang Li",
      "Ang Su",
      "Zi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10483",
    "title": "Structured Bayesian Compression for Deep Neural Networks Based on The  Turbo-VBI Approach",
    "abstract": "With the growth of neural network size, model compression has attracted increasing interest in recent research. As one of the most common techniques, pruning has been studied for a long time. By exploiting the structured sparsity of the neural network, existing methods can prune neurons instead of individual weights. However, in most existing pruning methods, surviving neurons are randomly connected in the neural network without any structure, and the non-zero weights within each neuron are also randomly distributed. Such irregular sparse structure can cause very high control overhead and irregular memory access for the hardware and even increase the neural network computational complexity. In this paper, we propose a three-layer hierarchical prior to promote a more regular sparse structure during pruning. The proposed three-layer hierarchical prior can achieve per-neuron weight-level structured sparsity and neuron-level structured sparsity. We derive an efficient Turbo-variational Bayesian inferencing (Turbo-VBI) algorithm to solve the resulting model compression problem with the proposed prior. The proposed Turbo-VBI algorithm has low complexity and can support more general priors than existing model compression algorithms. Simulation results show that our proposed algorithm can promote a more regular structure in the pruned neural networks while achieving even better performance in terms of compression rate and inferencing accuracy compared with the baselines. ",
    "url": "https://arxiv.org/abs/2302.10483",
    "authors": [
      "Chengyu Xia",
      "Danny H.K. Tsang",
      "Vincent K.N. Lau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10484",
    "title": "Lightweight Real-time Semantic Segmentation Network with Efficient  Transformer and CNN",
    "abstract": "In the past decade, convolutional neural networks (CNNs) have shown prominence for semantic segmentation. Although CNN models have very impressive performance, the ability to capture global representation is still insufficient, which results in suboptimal results. Recently, Transformer achieved huge success in NLP tasks, demonstrating its advantages in modeling long-range dependency. Recently, Transformer has also attracted tremendous attention from computer vision researchers who reformulate the image processing tasks as a sequence-to-sequence prediction but resulted in deteriorating local feature details. In this work, we propose a lightweight real-time semantic segmentation network called LETNet. LETNet combines a U-shaped CNN with Transformer effectively in a capsule embedding style to compensate for respective deficiencies. Meanwhile, the elaborately designed Lightweight Dilated Bottleneck (LDB) module and Feature Enhancement (FE) module cultivate a positive impact on training from scratch simultaneously. Extensive experiments performed on challenging datasets demonstrate that LETNet achieves superior performances in accuracy and efficiency balance. Specifically, It only contains 0.95M parameters and 13.6G FLOPs but yields 72.8\\% mIoU at 120 FPS on the Cityscapes test set and 70.5\\% mIoU at 250 FPS on the CamVid test dataset using a single RTX 3090 GPU. The source code will be available at https://github.com/IVIPLab/LETNet. ",
    "url": "https://arxiv.org/abs/2302.10484",
    "authors": [
      "Guoan Xu",
      "Juncheng Li",
      "Guangwei Gao",
      "Huimin Lu",
      "Jian Yang",
      "Dong Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10505",
    "title": "Higher-order Sparse Convolutions in Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have been applied to many problems in computer sciences. Capturing higher-order relationships between nodes is crucial to increase the expressive power of GNNs. However, existing methods to capture these relationships could be infeasible for large-scale graphs. In this work, we introduce a new higher-order sparse convolution based on the Sobolev norm of graph signals. Our Sparse Sobolev GNN (S-SobGNN) computes a cascade of filters on each layer with increasing Hadamard powers to get a more diverse set of functions, and then a linear combination layer weights the embeddings of each filter. We evaluate S-SobGNN in several applications of semi-supervised learning. S-SobGNN shows competitive performance in all applications as compared to several state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2302.10505",
    "authors": [
      "Jhony H. Giraldo",
      "Sajid Javed",
      "Arif Mahmood",
      "Fragkiskos D. Malliaros",
      "Thierry Bouwmans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.10506",
    "title": "Diffusion Probabilistic Models for Graph-Structured Prediction",
    "abstract": "This paper studies graph-structured prediction for supervised learning on graphs with node-wise or edge-wise target dependencies. To solve this problem, recent works investigated combining graph neural networks (GNNs) with conventional structured prediction algorithms like conditional random fields. However, in this work, we pursue an alternative direction building on the recent successes of diffusion probabilistic models (DPMs). That is, we propose a new framework using DPMs to make graph-structured predictions. In the fully supervised setting, our DPM captures the target dependencies by iteratively updating each target estimate based on the estimates of nearby targets. We also propose a variational expectation maximization algorithm to train our DPM in the semi-supervised setting. Extensive experiments verify that our framework consistently outperforms existing neural structured prediction models on inductive and transductive node classification. We also demonstrate the competitive performance of our framework for algorithmic reasoning tasks. ",
    "url": "https://arxiv.org/abs/2302.10506",
    "authors": [
      "Hyosoon Jang",
      "Sangwoo Mo",
      "Sungsoo Ahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10511",
    "title": "MVFusion: Multi-View 3D Object Detection with Semantic-aligned Radar and  Camera Fusion",
    "abstract": "Multi-view radar-camera fused 3D object detection provides a farther detection range and more helpful features for autonomous driving, especially under adverse weather. The current radar-camera fusion methods deliver kinds of designs to fuse radar information with camera data. However, these fusion approaches usually adopt the straightforward concatenation operation between multi-modal features, which ignores the semantic alignment with radar features and sufficient correlations across modals. In this paper, we present MVFusion, a novel Multi-View radar-camera Fusion method to achieve semantic-aligned radar features and enhance the cross-modal information interaction. To achieve so, we inject the semantic alignment into the radar features via the semantic-aligned radar encoder (SARE) to produce image-guided radar features. Then, we propose the radar-guided fusion transformer (RGFT) to fuse our radar and image features to strengthen the two modals' correlation from the global scope via the cross-attention mechanism. Extensive experiments show that MVFusion achieves state-of-the-art performance (51.7% NDS and 45.3% mAP) on the nuScenes dataset. We shall release our code and trained networks upon publication. ",
    "url": "https://arxiv.org/abs/2302.10511",
    "authors": [
      "Zizhang Wu",
      "Guilian Chen",
      "Yuanzhu Gan",
      "Lei Wang",
      "Jian Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10512",
    "title": "Robust Failure Diagnosis of Microservice System through Multimodal Data",
    "abstract": "Automatic failure diagnosis is crucial for large microservice systems. Currently, most failure diagnosis methods rely solely on single-modal data (i.e., using either metrics, logs, or traces). In this study, we conduct an empirical study using real-world failure cases to show that combining these sources of data (multimodal data) leads to a more accurate diagnosis. However, effectively representing this data and addressing imbalanced failures remain a challenge. To tackle these issues, we introduce DiagFusion, a robust failure diagnosis approach that uses multimodal data. It leverages embedding techniques and data augmentation to represent the multimodal data of service instances, combines deployment data and traces to build a dependency graph, and uses a graph neural network to localize the root cause instance and determine the failure type. Our evaluations using real-world datasets show that DiagFusion outperforms existing methods in terms of root cause instance localization and failure type determination. ",
    "url": "https://arxiv.org/abs/2302.10512",
    "authors": [
      "Shenglin Zhang",
      "Pengxiang Jin",
      "Zihan Lin",
      "Yongqian Sun",
      "Bicheng Zhang",
      "Sibo Xia",
      "Zhengdan Li",
      "Zhenyu Zhong",
      "Minghua Ma",
      "Wa Jin",
      "Dai Zhang",
      "Zhenyu Zhu",
      "Dan Pei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.10523",
    "title": "I2V: Towards Texture-Aware Self-Supervised Blind Denoising using  Self-Residual Learning for Real-World Images",
    "abstract": "Although the advances of self-supervised blind denoising are significantly superior to conventional approaches without clean supervision in synthetic noise scenarios, it shows poor quality in real-world images due to spatially correlated noise corruption. Recently, pixel-shuffle downsampling (PD) has been proposed to eliminate the spatial correlation of noise. A study combining a blind spot network (BSN) and asymmetric PD (AP) successfully demonstrated that self-supervised blind denoising is applicable to real-world noisy images. However, PD-based inference may degrade texture details in the testing phase because high-frequency details (e.g., edges) are destroyed in the downsampled images. To avoid such an issue, we propose self-residual learning without the PD process to maintain texture information. We also propose an order-variant PD constraint, noise prior loss, and an efficient inference scheme (progressive random-replacing refinement ($\\text{PR}^3$)) to boost overall performance. The results of extensive experiments show that the proposed method outperforms state-of-the-art self-supervised blind denoising approaches, including several supervised learning methods, in terms of PSNR, SSIM, LPIPS, and DISTS in real-world sRGB images. ",
    "url": "https://arxiv.org/abs/2302.10523",
    "authors": [
      "Kanggeun Lee",
      "Kyungryun Lee",
      "Won-Ki Jeong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.10524",
    "title": "LU-Net: Invertible Neural Networks Based on Matrix Factorization",
    "abstract": "LU-Net is a simple and fast architecture for invertible neural networks (INN) that is based on the factorization of quadratic weight matrices $\\mathsf{A=LU}$, where $\\mathsf{L}$ is a lower triangular matrix with ones on the diagonal and $\\mathsf{U}$ an upper triangular matrix. Instead of learning a fully occupied matrix $\\mathsf{A}$, we learn $\\mathsf{L}$ and $\\mathsf{U}$ separately. If combined with an invertible activation function, such layers can easily be inverted whenever the diagonal entries of $\\mathsf{U}$ are different from zero. Also, the computation of the determinant of the Jacobian matrix of such layers is cheap. Consequently, the LU architecture allows for cheap computation of the likelihood via the change of variables formula and can be trained according to the maximum likelihood principle. In our numerical experiments, we test the LU-net architecture as generative model on several academic datasets. We also provide a detailed comparison with conventional invertible neural networks in terms of performance, training as well as run time. ",
    "url": "https://arxiv.org/abs/2302.10524",
    "authors": [
      "Robin Chan",
      "Sarina Penquitt",
      "Hanno Gottschalk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.10536",
    "title": "Nonparallel Emotional Voice Conversion For Unseen Speaker-Emotion Pairs  Using Dual Domain Adversarial Network & Virtual Domain Pairing",
    "abstract": "Primary goal of an emotional voice conversion (EVC) system is to convert the emotion of a given speech signal from one style to another style without modifying the linguistic content of the signal. Most of the state-of-the-art approaches convert emotions for seen speaker-emotion combinations only. In this paper, we tackle the problem of converting the emotion of speakers whose only neutral data are present during the time of training and testing (i.e., unseen speaker-emotion combinations). To this end, we extend a recently proposed StartGANv2-VC architecture by utilizing dual encoders for learning the speaker and emotion style embeddings separately along with dual domain source classifiers. For achieving the conversion to unseen speaker-emotion combinations, we propose a Virtual Domain Pairing (VDP) training strategy, which virtually incorporates the speaker-emotion pairs that are not present in the real data without compromising the min-max game of a discriminator and generator in adversarial training. We evaluate the proposed method using a Hindi emotional database. ",
    "url": "https://arxiv.org/abs/2302.10536",
    "authors": [
      "Nirmesh Shah",
      "Mayank Kumar Singh",
      "Naoya Takahashi",
      "Naoyuki Onoe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.10549",
    "title": "MonoPGC: Monocular 3D Object Detection with Pixel Geometry Contexts",
    "abstract": "Monocular 3D object detection reveals an economical but challenging task in autonomous driving. Recently center-based monocular methods have developed rapidly with a great trade-off between speed and accuracy, where they usually depend on the object center's depth estimation via 2D features. However, the visual semantic features without sufficient pixel geometry information, may affect the performance of clues for spatial 3D detection tasks. To alleviate this, we propose MonoPGC, a novel end-to-end Monocular 3D object detection framework with rich Pixel Geometry Contexts. We introduce the pixel depth estimation as our auxiliary task and design depth cross-attention pyramid module (DCPM) to inject local and global depth geometry knowledge into visual features. In addition, we present the depth-space-aware transformer (DSAT) to integrate 3D space position and depth-aware features efficiently. Besides, we design a novel depth-gradient positional encoding (DGPE) to bring more distinct pixel geometry contexts into the transformer for better object detection. Extensive experiments demonstrate that our method achieves the state-of-the-art performance on the KITTI dataset. ",
    "url": "https://arxiv.org/abs/2302.10549",
    "authors": [
      "Zizhang Wu",
      "Yuanzhu Gan",
      "Lei Wang",
      "Guilian Chen",
      "Jian Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10567",
    "title": "Dual Policy Learning for Aggregation Optimization in Graph Neural  Network-based Recommender Systems",
    "abstract": "Graph Neural Networks (GNNs) provide powerful representations for recommendation tasks. GNN-based recommendation systems capture the complex high-order connectivity between users and items by aggregating information from distant neighbors and can improve the performance of recommender systems. Recently, Knowledge Graphs (KGs) have also been incorporated into the user-item interaction graph to provide more abundant contextual information; they are exploited to address cold-start problems and enable more explainable aggregation in GNN-based recommender systems (GNN-Rs). However, due to the heterogeneous nature of users and items, developing an effective aggregation strategy that works across multiple GNN-Rs, such as LightGCN and KGAT, remains a challenge. In this paper, we propose a novel reinforcement learning-based message passing framework for recommender systems, which we call DPAO (Dual Policy framework for Aggregation Optimization). This framework adaptively determines high-order connectivity to aggregate users and items using dual policy learning. Dual policy learning leverages two Deep-Q-Network models to exploit the user- and item-aware feedback from a GNN-R and boost the performance of the target GNN-R. Our proposed framework was evaluated with both non-KG-based and KG-based GNN-R models on six real-world datasets, and their results show that our proposed framework significantly enhances the recent base model, improving nDCG and Recall by up to 63.7% and 42.9%, respectively. Our implementation code is available at https://github.com/steve30572/DPAO/. ",
    "url": "https://arxiv.org/abs/2302.10567",
    "authors": [
      "Heesoo Jung",
      "Sangpil Kim",
      "Hogun Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10593",
    "title": "Connecting Humanities and Social Sciences: Applying Language and Speech  Technology to Online Panel Surveys",
    "abstract": "In this paper, we explore the application of language and speech technology to open-ended questions in a Dutch panel survey. In an experimental wave respondents could choose to answer open questions via speech or keyboard. Automatic speech recognition (ASR) was used to process spoken responses. We evaluated answers from these input modalities to investigate differences between spoken and typed answers.We report the errors the ASR system produces and investigate the impact of these errors on downstream analyses. Open-ended questions give more freedom to answer for respondents, but entail a non-trivial amount of work to analyse. We evaluated the feasibility of using transformer-based models (e.g. BERT) to apply sentiment analysis and topic modelling on the answers of open questions. A big advantage of transformer-based models is that they are trained on a large amount of language materials and do not necessarily need training on the target materials. This is especially advantageous for survey data, which does not contain a lot of text materials. We tested the quality of automatic sentiment analysis by comparing automatic labeling with three human raters and tested the robustness of topic modelling by comparing the generated models based on automatic and manually transcribed spoken answers. ",
    "url": "https://arxiv.org/abs/2302.10593",
    "authors": [
      "Henk van den Heuvel",
      "Martijn Bentum",
      "Simone Wills",
      "Judith C. Koops"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.10601",
    "title": "Few-shot Detection of Anomalies in Industrial Cyber-Physical System via  Prototypical Network and Contrastive Learning",
    "abstract": "The rapid development of Industry 4.0 has amplified the scope and destructiveness of industrial Cyber-Physical System (CPS) by network attacks. Anomaly detection techniques are employed to identify these attacks and guarantee the normal operation of industrial CPS. However, it is still a challenging problem to cope with scenarios with few labeled samples. In this paper, we propose a few-shot anomaly detection model (FSL-PN) based on prototypical network and contrastive learning for identifying anomalies with limited labeled data from industrial CPS. Specifically, we design a contrastive loss to assist the training process of the feature extractor and learn more fine-grained features to improve the discriminative performance. Subsequently, to tackle the overfitting issue during classifying, we construct a robust cost function with a specific regularizer to enhance the generalization capability. Experimental results based on two public imbalanced datasets with few-shot settings show that the FSL-PN model can significantly improve F1 score and reduce false alarm rate (FAR) for identifying anomalous signals to guarantee the security of industrial CPS. ",
    "url": "https://arxiv.org/abs/2302.10601",
    "authors": [
      "Haili Sun",
      "Yan Huang",
      "Lansheng Han",
      "Chunjie Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.10602",
    "title": "SU-Net: Pose estimation network for non-cooperative spacecraft on-orbit",
    "abstract": "Spacecraft pose estimation plays a vital role in many on-orbit space missions, such as rendezvous and docking, debris removal, and on-orbit maintenance. At present, space images contain widely varying lighting conditions, high contrast and low resolution, pose estimation of space objects is more challenging than that of objects on earth. In this paper, we analyzing the radar image characteristics of spacecraft on-orbit, then propose a new deep learning neural Network structure named Dense Residual U-shaped Network (DR-U-Net) to extract image features. We further introduce a novel neural network based on DR-U-Net, namely Spacecraft U-shaped Network (SU-Net) to achieve end-to-end pose estimation for non-cooperative spacecraft. Specifically, the SU-Net first preprocess the image of non-cooperative spacecraft, then transfer learning was used for pre-training. Subsequently, in order to solve the problem of radar image blur and low ability of spacecraft contour recognition, we add residual connection and dense connection to the backbone network U-Net, and we named it DR-U-Net. In this way, the feature loss and the complexity of the model is reduced, and the degradation of deep neural network during training is avoided. Finally, a layer of feedforward neural network is used for pose estimation of non-cooperative spacecraft on-orbit. Experiments prove that the proposed method does not rely on the hand-made object specific features, and the model has robust robustness, and the calculation accuracy outperforms the state-of-the-art pose estimation methods. The absolute error is 0.1557 to 0.4491 , the mean error is about 0.302 , and the standard deviation is about 0.065 . ",
    "url": "https://arxiv.org/abs/2302.10602",
    "authors": [
      "Hu Gao",
      "Zhihui Li",
      "Depeng Dang",
      "Ning Wang",
      "Jingfan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10607",
    "title": "Differentiable Multi-Target Causal Bayesian Experimental Design",
    "abstract": "We introduce a gradient-based approach for the problem of Bayesian optimal experimental design to learn causal models in a batch setting -- a critical component for causal discovery from finite data where interventions can be costly or risky. Existing methods rely on greedy approximations to construct a batch of experiments while using black-box methods to optimize over a single target-state pair to intervene with. In this work, we completely dispose of the black-box optimization techniques and greedy heuristics and instead propose a conceptually simple end-to-end gradient-based optimization procedure to acquire a set of optimal intervention target-state pairs. Such a procedure enables parameterization of the design space to efficiently optimize over a batch of multi-target-state interventions, a setting which has hitherto not been explored due to its complexity. We demonstrate that our proposed method outperforms baselines and existing acquisition strategies in both single-target and multi-target settings across a number of synthetic datasets. ",
    "url": "https://arxiv.org/abs/2302.10607",
    "authors": [
      "Yashas Annadani",
      "Panagiotis Tigas",
      "Desi R. Ivanova",
      "Andrew Jesson",
      "Yarin Gal",
      "Adam Foster",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.10612",
    "title": "Tree-Based Machine Learning Methods For Vehicle Insurance Claims Size  Prediction",
    "abstract": "Vehicle insurance claims size prediction needs methods to efficiently handle these claims. Machine learning (ML) is one of the methods that solve this problem. Tree-based ensemble learning algorithms are highly effective and widely used ML methods. This study considers how vehicle insurance providers incorporate ML methods in their companies and explores how the models can be applied to insurance big data. We utilize various tree-based ML methods, such as bagging, random forest, and gradient boosting, to determine the relative importance of predictors in predicting claims size and to explore the relationships between claims size and predictors. Furthermore, we evaluate and compare these models' performances. The results show that tree-based ensemble methods are better than the classical least square method. Keywords: claims size prediction; machine learning; tree-based ensemble methods; vehicle insurance. ",
    "url": "https://arxiv.org/abs/2302.10612",
    "authors": [
      "Edossa Merga Terefe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2302.10613",
    "title": "Approximating Bin Packing with Conflict Graphs via Maximization  Techniques",
    "abstract": "We give a comprehensive study of bin packing with conflicts (BPC). The input is a set $I$ of items, sizes $s:I \\rightarrow [0,1]$, and a conflict graph $G = (I,E)$. The goal is to find a partition of $I$ into a minimum number of independent sets, each of total size at most $1$. Being a generalization of the notoriously hard graph coloring problem, BPC has been studied mostly on polynomially colorable conflict graphs. An intriguing open question is whether BPC on such graphs admits the same best known approximation guarantees as classic bin packing. We answer this question negatively, by showing that (in contrast to bin packing) there is no asymptotic polynomial-time approximation scheme (APTAS) for BPC already on seemingly easy graph classes, such as bipartite and split graphs. We complement this result with improved approximation guarantees for BPC on several prominent graph classes. Most notably, we derive an asymptotic $1.391$-approximation for bipartite graphs, a $2.445$-approximation for perfect graphs, and a $\\left(1+\\frac{2}{e}\\right)$-approximation for split graphs. To this end, we introduce a generic framework relying on a novel interpretation of BPC allowing us to solve the problem via maximization techniques. Our framework may find use in tackling BPC on other graph classes arising in applications. ",
    "url": "https://arxiv.org/abs/2302.10613",
    "authors": [
      "Ilan Doron-Arad",
      "Hadas Shachnai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.10624",
    "title": "Self-improving object detection via disagreement reconciliation",
    "abstract": "Object detectors often experience a drop in performance when new environmental conditions are insufficiently represented in the training data. This paper studies how to automatically fine-tune a pre-existing object detector while exploring and acquiring images in a new environment without relying on human intervention, i.e., in a self-supervised fashion. In our setting, an agent initially explores the environment using a pre-trained off-the-shelf detector to locate objects and associate pseudo-labels. By assuming that pseudo-labels for the same object must be consistent across different views, we devise a novel mechanism for producing refined predictions from the consensus among observations. Our approach improves the off-the-shelf object detector by 2.66% in terms of mAP and outperforms the current state of the art without relying on ground-truth annotations. ",
    "url": "https://arxiv.org/abs/2302.10624",
    "authors": [
      "Gianluca Scarpellini",
      "Stefano Rosa",
      "Pietro Morerio",
      "Lorenzo Natale",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10632",
    "title": "Multi-Modal Self-Supervised Learning for Recommendation",
    "abstract": "The online emergence of multi-modal sharing platforms (eg, TikTok, Youtube) is powering personalized recommender systems to incorporate various modalities (eg, visual, textual and acoustic) into the latent user representations. While existing works on multi-modal recommendation exploit multimedia content features in enhancing item embeddings, their model representation capability is limited by heavy label reliance and weak robustness on sparse user behavior data. Inspired by the recent progress of self-supervised learning in alleviating label scarcity issue, we explore deriving self-supervision signals with effectively learning of modality-aware user preference and cross-modal dependencies. To this end, we propose a new Multi-Modal Self-Supervised Learning (MMSSL) method which tackles two key challenges. Specifically, to characterize the inter-dependency between the user-item collaborative view and item multi-modal semantic view, we design a modality-aware interactive structure learning paradigm via adversarial perturbations for data augmentation. In addition, to capture the effects that user's modality-aware interaction pattern would interweave with each other, a cross-modal contrastive learning approach is introduced to jointly preserve the inter-modal semantic commonality and user preference diversity. Experiments on real-world datasets verify the superiority of our method in offering great potential for multimedia recommendation over various state-of-the-art baselines. The implementation is released at: https://github.com/HKUDS/MMSSL. ",
    "url": "https://arxiv.org/abs/2302.10632",
    "authors": [
      "Wei Wei",
      "Chao Huang",
      "Lianghao Xia",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.10633",
    "title": "Generalization Bounds for Adversarial Contrastive Learning",
    "abstract": "Deep networks are well-known to be fragile to adversarial attacks, and adversarial training is one of the most popular methods used to train a robust model. To take advantage of unlabeled data, recent works have applied adversarial training to contrastive learning (Adversarial Contrastive Learning; ACL for short) and obtain promising robust performance. However, the theory of ACL is not well understood. To fill this gap, we leverage the Rademacher complexity to analyze the generalization performance of ACL, with a particular focus on linear models and multi-layer neural networks under $\\ell_p$ attack ($p \\ge 1$). Our theory shows that the average adversarial risk of the downstream tasks can be upper bounded by the adversarial unsupervised risk of the upstream task. The experimental results validate our theory. ",
    "url": "https://arxiv.org/abs/2302.10633",
    "authors": [
      "Xin Zou",
      "Weiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.10637",
    "title": "A Survey of Trustworthy Federated Learning with Perspectives on  Security, Robustness, and Privacy",
    "abstract": "Trustworthy artificial intelligence (AI) technology has revolutionized daily life and greatly benefited human society. Among various AI technologies, Federated Learning (FL) stands out as a promising solution for diverse real-world scenarios, ranging from risk evaluation systems in finance to cutting-edge technologies like drug discovery in life sciences. However, challenges around data isolation and privacy threaten the trustworthiness of FL systems. Adversarial attacks against data privacy, learning algorithm stability, and system confidentiality are particularly concerning in the context of distributed training in federated learning. Therefore, it is crucial to develop FL in a trustworthy manner, with a focus on security, robustness, and privacy. In this survey, we propose a comprehensive roadmap for developing trustworthy FL systems and summarize existing efforts from three key aspects: security, robustness, and privacy. We outline the threats that pose vulnerabilities to trustworthy federated learning across different stages of development, including data processing, model training, and deployment. To guide the selection of the most appropriate defense methods, we discuss specific technical solutions for realizing each aspect of Trustworthy FL (TFL). Our approach differs from previous work that primarily discusses TFL from a legal perspective or presents FL from a high-level, non-technical viewpoint. ",
    "url": "https://arxiv.org/abs/2302.10637",
    "authors": [
      "Yifei Zhang",
      "Dun Zeng",
      "Jinglong Luo",
      "Zenglin Xu",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.10641",
    "title": "A3S: Adversarial learning of semantic representations for Scene-Text  Spotting",
    "abstract": "Scene-text spotting is a task that predicts a text area on natural scene images and recognizes its text characters simultaneously. It has attracted much attention in recent years due to its wide applications. Existing research has mainly focused on improving text region detection, not text recognition. Thus, while detection accuracy is improved, the end-to-end accuracy is insufficient. Texts in natural scene images tend to not be a random string of characters but a meaningful string of characters, a word. Therefore, we propose adversarial learning of semantic representations for scene text spotting (A3S) to improve end-to-end accuracy, including text recognition. A3S simultaneously predicts semantic features in the detected text area instead of only performing text recognition based on existing visual features. Experimental results on publicly available datasets show that the proposed method achieves better accuracy than other methods. ",
    "url": "https://arxiv.org/abs/2302.10641",
    "authors": [
      "Masato Fujitake"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10650",
    "title": "Predicting Privacy Preferences for Smart Devices as Norms",
    "abstract": "Smart devices, such as smart speakers, are becoming ubiquitous, and users expect these devices to act in accordance with their preferences. In particular, since these devices gather and manage personal data, users expect them to adhere to their privacy preferences. However, the current approach of gathering these preferences consists in asking the users directly, which usually triggers automatic responses failing to capture their true preferences. In response, in this paper we present a collaborative filtering approach to predict user preferences as norms. These preference predictions can be readily adopted or can serve to assist users in determining their own preferences. Using a dataset of privacy preferences of smart assistant users, we test the accuracy of our predictions. ",
    "url": "https://arxiv.org/abs/2302.10650",
    "authors": [
      "Marc Serramia",
      "William Seymour",
      "Natalia Criado",
      "Michael Luck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10672",
    "title": "Importance of methodological choices in data manipulation for validating  epileptic seizure detection models",
    "abstract": "Epilepsy is a chronic neurological disorder that affects a significant portion of the human population and imposes serious risks in the daily life of patients. Despite advances in machine learning and IoT, small, nonstigmatizing wearable devices for continuous monitoring and detection in outpatient environments are not yet available. Part of the reason is the complexity of epilepsy itself, including highly imbalanced data, multimodal nature, and very subject-specific signatures. However, another problem is the heterogeneity of methodological approaches in research, leading to slower progress, difficulty comparing results, and low reproducibility. Therefore, this article identifies a wide range of methodological decisions that must be made and reported when training and evaluating the performance of epilepsy detection systems. We characterize the influence of individual choices using a typical ensemble random-forest model and the publicly available CHB-MIT database, providing a broader picture of each decision and giving good-practice recommendations, based on our experience, where possible. ",
    "url": "https://arxiv.org/abs/2302.10672",
    "authors": [
      "Una Pale",
      "Tomas Teijeiro",
      "David Atienza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10679",
    "title": "Evaluating the effect of data augmentation and BALD heuristics on  distillation of Semantic-KITTI dataset",
    "abstract": "Active Learning (AL) has remained relatively unexplored for LiDAR perception tasks in autonomous driving datasets. In this study we evaluate Bayesian active learning methods applied to the task of dataset distillation or core subset selection (subset with near equivalent performance as full dataset). We also study the effect of application of data augmentation (DA) within Bayesian AL based dataset distillation. We perform these experiments on the full Semantic-KITTI dataset. We extend our study over our existing work only on 1/4th of the same dataset. Addition of DA and BALD have a negative impact over the labeling efficiency and thus the capacity to distill datasets. We demonstrate key issues in designing a functional AL framework and finally conclude with a review of challenges in real world active learning. ",
    "url": "https://arxiv.org/abs/2302.10679",
    "authors": [
      "Anh Duong",
      "Alexandre Almin",
      "L\u00e9o Lemari\u00e9",
      "B Ravi Kiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10686",
    "title": "Interpretable Spectrum Transformation Attacks to Speaker Recognition",
    "abstract": "The success of adversarial attacks to speaker recognition is mainly in white-box scenarios. When applying the adversarial voices that are generated by attacking white-box surrogate models to black-box victim models, i.e. \\textit{transfer-based} black-box attacks, the transferability of the adversarial voices is not only far from satisfactory, but also lacks interpretable basis. To address these issues, in this paper, we propose a general framework, named spectral transformation attack based on modified discrete cosine transform (STA-MDCT), to improve the transferability of the adversarial voices to a black-box victim model. Specifically, we first apply MDCT to the input voice. Then, we slightly modify the energy of different frequency bands for capturing the salient regions of the adversarial noise in the time-frequency domain that are critical to a successful attack. Unlike existing approaches that operate voices in the time domain, the proposed framework operates voices in the time-frequency domain, which improves the interpretability, transferability, and imperceptibility of the attack. Moreover, it can be implemented with any gradient-based attackers. To utilize the advantage of model ensembling, we not only implement STA-MDCT with a single white-box surrogate model, but also with an ensemble of surrogate models. Finally, we visualize the saliency maps of adversarial voices by the class activation maps (CAM), which offers an interpretable basis to transfer-based attacks in speaker recognition for the first time. Extensive comparison results with five representative attackers show that the CAM visualization clearly explains the effectiveness of STA-MDCT, and the weaknesses of the comparison methods; the proposed method outperforms the comparison methods by a large margin. ",
    "url": "https://arxiv.org/abs/2302.10686",
    "authors": [
      "Jiadi Yao",
      "Hong Luo",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.10697",
    "title": "A General Visual Representation Guided Framework with Global Affinity  for Weakly Supervised Salient Object Detection",
    "abstract": "Fully supervised salient object detection (SOD) methods have made considerable progress in performance, yet these models rely heavily on expensive pixel-wise labels. Recently, to achieve a trade-off between labeling burden and performance, scribble-based SOD methods have attracted increasing attention. Previous models directly implement the SOD task only based on small-scale SOD training data. Due to the limited information provided by the weakly scribble tags and such small-scale training data, it is extremely difficult for them to understand the image and further achieve a superior SOD task. In this paper, we propose a simple yet effective framework guided by general visual representations that simulate the general cognition of humans for scribble-based SOD. It consists of a task-related encoder, a general visual module, and an information integration module to combine efficiently the general visual representations learned from large-scale unlabeled datasets with task-related features to perform the SOD task based on understanding the contextual connections of images. Meanwhile, we propose a novel global semantic affinity loss to guide the model to perceive the global structure of the salient objects. Experimental results on five public benchmark datasets demonstrate that our method that only utilizes scribble annotations without introducing any extra label outperforms the state-of-the-art weakly supervised SOD methods and is comparable or even superior to the state-of-the-art fully supervised models. ",
    "url": "https://arxiv.org/abs/2302.10697",
    "authors": [
      "Binwei Xu",
      "Haoran Liang",
      "Weihua Gong",
      "Ronghua Liang",
      "Peng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10702",
    "title": "CoPracTter: Toward Integrating Personalized Practice Scenarios, Timely  Feedback and Social Support into An Online Support Tool for Coping with  Stuttering in China",
    "abstract": "Stuttering is a speech disorder influencing over 70 million people worldwide, including 13 million in China. It causes low self-esteem among other detrimental effects on people who stutter (PwS). Although prior work has explored approaches to assist PwS, they primarily focused on western contexts. In our formative study, we found unique practices and challenges among Chinese PwS. We then iteratively designed an online tool, CoPracTter, to support Chinese PwS practicing speaking fluency with 1) targeted stress-inducing practice scenarios, 2) real-time speech indicators, and 3) personalized timely feedback from the community. We further conducted a seven-day deployment study (N=11) to understand how participants utilized these key features. To our knowledge, it is the first time such a prototype was designed and tested for a long time with multiple PwS participants online simultaneously. Results indicate that personalized practice with targeted scenarios and timely feedback from a supportive community assisted PwS in speaking fluently, staying positive, and facing similar real-life circumstances. ",
    "url": "https://arxiv.org/abs/2302.10702",
    "authors": [
      "Feng Li",
      "Zeyu Xiong",
      "Xinyi Li",
      "Mingming Fan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.10719",
    "title": "Memory-augmented Online Video Anomaly Detection",
    "abstract": "The ability to understand the surrounding scene is of paramount importance for Autonomous Vehicles (AVs). This paper presents a system capable to work in a real time guaranteed response times and online fashion, giving an immediate response to the arise of anomalies surrounding the AV, exploiting only the videos captured by a dash-mounted camera. Our architecture, called MOVAD, relies on two main modules: a short-term memory to extract information related to the ongoing action, implemented by a Video Swin Transformer adapted to work in an online scenario, and a long-term memory module that considers also remote past information thanks to the use of a Long-Short Term Memory (LSTM) network. We evaluated the performance of our method on Detection of Traffic Anomaly (DoTA) dataset, a challenging collection of dash-mounted camera videos of accidents. After an extensive ablation study, MOVAD is able to reach an AUC score of 82.11%, surpassing the current state-of-the-art by +2.81 AUC. Our code will be available on https://github.com/IMPLabUniPr/movad/tree/icip ",
    "url": "https://arxiv.org/abs/2302.10719",
    "authors": [
      "Leonardo Rossi",
      "Vittorio Bernuzzi",
      "Tomaso Fontanini",
      "Massimo Bertozzi",
      "Andrea Prati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.10739",
    "title": "MalProtect: Stateful Defense Against Adversarial Query Attacks in  ML-based Malware Detection",
    "abstract": "ML models are known to be vulnerable to adversarial query attacks. In these attacks, queries are iteratively perturbed towards a particular class without any knowledge of the target model besides its output. The prevalence of remotely-hosted ML classification models and Machine-Learning-as-a-Service platforms means that query attacks pose a real threat to the security of these systems. To deal with this, stateful defenses have been proposed to detect query attacks and prevent the generation of adversarial examples by monitoring and analyzing the sequence of queries received by the system. Several stateful defenses have been proposed in recent years. However, these defenses rely solely on similarity or out-of-distribution detection methods that may be effective in other domains. In the malware detection domain, the methods to generate adversarial examples are inherently different, and therefore we find that such detection mechanisms are significantly less effective. Hence, in this paper, we present MalProtect, which is a stateful defense against query attacks in the malware detection domain. MalProtect uses several threat indicators to detect attacks. Our results show that it reduces the evasion rate of adversarial query attacks by 80+\\% in Android and Windows malware, across a range of attacker scenarios. In the first evaluation of its kind, we show that MalProtect outperforms prior stateful defenses, especially under the peak adversarial threat. ",
    "url": "https://arxiv.org/abs/2302.10739",
    "authors": [
      "Aqib Rashid",
      "Jose Such"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.10747",
    "title": "Clustered Data Sharing for Non-IID Federated Learning over Wireless  Networks",
    "abstract": "Federated Learning (FL) is a novel distributed machine learning approach to leverage data from Internet of Things (IoT) devices while maintaining data privacy. However, the current FL algorithms face the challenges of non-independent and identically distributed (non-IID) data, which causes high communication costs and model accuracy declines. To address the statistical imbalances in FL, we propose a clustered data sharing framework which spares the partial data from cluster heads to credible associates through device-to-device (D2D) communication. Moreover, aiming at diluting the data skew on nodes, we formulate the joint clustering and data sharing problem based on the privacy-preserving constrained graph. To tackle the serious coupling of decisions on the graph, we devise a distribution-based adaptive clustering algorithm (DACA) basing on three deductive cluster-forming conditions, which ensures the maximum yield of data sharing. The experiments show that the proposed framework facilitates FL on non-IID datasets with better convergence and model accuracy under a limited communication environment. ",
    "url": "https://arxiv.org/abs/2302.10747",
    "authors": [
      "Gang Hu",
      "Yinglei Teng",
      "Nan Wang",
      "F. Richard Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.10753",
    "title": "DTAAD: Dual Tcn-Attention Networks for Anomaly Detection in Multivariate  Time Series Data",
    "abstract": "Anomaly detection techniques enable effective anomaly detection and diagnosis in multi-variate time series data, which are of major significance for today's industrial applications. However, establishing an anomaly detection system that can be rapidly and accurately located is a challenging problem due to the lack of outlier tags, the high dimensional complexity of the data, memory bottlenecks in the actual hardware, and the need for fast reasoning. We have proposed an anomaly detection and diagnosis model--DTAAD in this paper, based on Transformer and Dual TCN. Our overall model will be an integrated design in which AR combines AE structures, introducing scaling methods and feedback mechanisms to improve prediction accuracy and expand correlation differences. The Dual TCN-Attention Network(DTA) constructed by us only uses a single layer of Transformer encoder in our baseline experiment, which belongs to an ultra-lightweight model. Our extensive experiments on six publicly datasets validate that DTAAD exceeds current most advanced baseline methods in both detection and diagnostic performance. Specifically, DTAAD improved F1 scores by $8.38\\%$, and reduced training time by $99\\%$ compared to baseline. The code and training scripts are publicly on GitHub at https://github.com/Yu-Lingrui/DTAAD. ",
    "url": "https://arxiv.org/abs/2302.10753",
    "authors": [
      "Lingrui Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10757",
    "title": "Distributed Learning in Heterogeneous Environment: federated learning  with adaptive aggregation and computation reduction",
    "abstract": "Although federated learning has achieved many breakthroughs recently, the heterogeneous nature of the learning environment greatly limits its performance and hinders its real-world applications. The heterogeneous data, time-varying wireless conditions and computing-limited devices are three main challenges, which often result in an unstable training process and degraded accuracy. Herein, we propose strategies to address these challenges. Targeting the heterogeneous data distribution, we propose a novel adaptive mixing aggregation (AMA) scheme that mixes the model updates from previous rounds with current rounds to avoid large model shifts and thus, maintain training stability. We further propose a novel staleness-based weighting scheme for the asynchronous model updates caused by the dynamic wireless environment. Lastly, we propose a novel CPU-friendly computation-reduction scheme based on transfer learning by sharing the feature extractor (FES) and letting the computing-limited devices update only the classifier. The simulation results show that the proposed framework outperforms existing state-of-the-art solutions and increases the test accuracy, and training stability by up to 2.38%, 93.10% respectively. Additionally, the proposed framework can tolerate communication delay of up to 15 rounds under a moderate delay environment without significant accuracy degradation. ",
    "url": "https://arxiv.org/abs/2302.10757",
    "authors": [
      "Jingxin Li",
      "Toktam Mahmoodi",
      "Hak-Keung Lam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.10771",
    "title": "Data-driven prognostics based on time-frequency analysis and symbolic  recurrent neural network for fuel cells under dynamic load",
    "abstract": "Data-centric prognostics is beneficial to improve the reliability and safety of proton exchange membrane fuel cell (PEMFC). For the prognostics of PEMFC operating under dynamic load, the challenges come from extracting degradation features, improving prediction accuracy, expanding the prognostics horizon, and reducing computational cost. To address these issues, this work proposes a data-driven PEMFC prognostics approach, in which Hilbert-Huang transform is used to extract health indicator in dynamic operating conditions and symbolic-based gated recurrent unit model is used to enhance the accuracy of life prediction. Comparing with other state-of-the-art methods, the proposed data-driven prognostics approach provides a competitive prognostics horizon with lower computational cost. The prognostics performance shows consistency and generalizability under different failure threshold settings. ",
    "url": "https://arxiv.org/abs/2302.10771",
    "authors": [
      "Chu Wang",
      "Manfeng Dou",
      "Zhongliang Li",
      "Rachid Outbib",
      "Dongdong Zhao",
      "Jian Zuo",
      "Yuanlin Wang",
      "Bin Liang",
      "Peng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.10781",
    "title": "Learning 3D Photography Videos via Self-supervised Diffusion on Single  Images",
    "abstract": "3D photography renders a static image into a video with appealing 3D visual effects. Existing approaches typically first conduct monocular depth estimation, then render the input frame to subsequent frames with various viewpoints, and finally use an inpainting model to fill those missing/occluded regions. The inpainting model plays a crucial role in rendering quality, but it is normally trained on out-of-domain data. To reduce the training and inference gap, we propose a novel self-supervised diffusion model as the inpainting module. Given a single input image, we automatically construct a training pair of the masked occluded image and the ground-truth image with random cycle-rendering. The constructed training samples are closely aligned to the testing instances, without the need of data annotation. To make full use of the masked images, we design a Masked Enhanced Block (MEB), which can be easily plugged into the UNet and enhance the semantic conditions. Towards real-world animation, we present a novel task: out-animation, which extends the space and time of input objects. Extensive experiments on real datasets show that our method achieves competitive results with existing SOTA methods. ",
    "url": "https://arxiv.org/abs/2302.10781",
    "authors": [
      "Xiaodong Wang",
      "Chenfei Wu",
      "Shengming Yin",
      "Minheng Ni",
      "Jianfeng Wang",
      "Linjie Li",
      "Zhengyuan Yang",
      "Fan Yang",
      "Lijuan Wang",
      "Zicheng Liu",
      "Yuejian Fang",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10784",
    "title": "Utilizing Domain Knowledge: Robust Machine Learning for Building Energy  Prediction with Small, Inconsistent Datasets",
    "abstract": "The demand for a huge amount of data for machine learning (ML) applications is currently a bottleneck in an empirically dominated field. We propose a method to combine prior knowledge with data-driven methods to significantly reduce their data dependency. In this study, component-based machine learning (CBML) as the knowledge-encoded data-driven method is examined in the context of energy-efficient building engineering. It encodes the abstraction of building structural knowledge as semantic information in the model organization. We design a case experiment to understand the efficacy of knowledge-encoded ML in sparse data input (1% - 0.0125% sampling rate). The result reveals its three advanced features compared with pure ML methods: 1. Significant improvement in the robustness of ML to extremely small-size and inconsistent datasets; 2. Efficient data utilization from different entities' record collections; 3. Characteristics of accepting incomplete data with high interpretability and reduced training time. All these features provide a promising path to alleviating the deployment bottleneck of data-intensive methods and contribute to efficient real-world data usage. Moreover, four necessary prerequisites are summarized in this study that ensures the target scenario benefits by combining prior knowledge and ML generalization. ",
    "url": "https://arxiv.org/abs/2302.10784",
    "authors": [
      "Xia Chen",
      "Manav Mahan Sing",
      "Philipp Geyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10788",
    "title": "Exact Performance Analysis of THz Link Under Transceiver Hardware  Impairments",
    "abstract": "Transceiver hardware impairment (THI) is inevitable for high-date rate terahertz (THz) communication. Existing statistical analysis either neglects THI's effect or provides approximate results when analyzing the performance of the THz system combined with channel fading and antenna misalignment. In this paper, we develop exact analytical expressions for the average signal-to-noise ratio (SNR), ergodic capacity, and average bit-error-rate (BER) performance of a THz wireless link under the combined effect of $\\alpha$-$\\mu$ fading channel, zero-boresight pointing errors, and the Gaussian distributed THI. We also derive asymptotic expressions for the outage probability and average BER, which shows that the diversity order of the THz link is independent of THI's parameters. Simulations validate the derived analytical results and demonstrate the impact of the THI parameters on the THz performance. ",
    "url": "https://arxiv.org/abs/2302.10788",
    "authors": [
      "Pranay Bhardwaj",
      "S.M. Zafaruddin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.10801",
    "title": "Deep Generative Neural Embeddings for High Dimensional Data  Visualization",
    "abstract": "We propose a visualization technique that utilizes neural network embeddings and a generative network to reconstruct original data. This method allows for independent manipulation of individual image embeddings through its non-parametric structure, providing more flexibility than traditional autoencoder approaches. We have evaluated the effectiveness of this technique in data visualization and compared it to t-SNE and VAE methods. Furthermore, we have demonstrated the scalability of our method through visualizations on the ImageNet dataset. Our technique has potential applications in human-in-the-loop training, as it allows for independent editing of embedding locations without affecting the optimization process. ",
    "url": "https://arxiv.org/abs/2302.10801",
    "authors": [
      "Halid Ziya Yerebakan",
      "Gerardo Hermosillo Valadez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.10802",
    "title": "A Novel Noise Injection-based Training Scheme for Better Model  Robustness",
    "abstract": "Noise injection-based method has been shown to be able to improve the robustness of artificial neural networks in previous work. In this work, we propose a novel noise injection-based training scheme for better model robustness. Specifically, we first develop a likelihood ratio method to estimate the gradient with respect to both synaptic weights and noise levels for stochastic gradient descent training. Then, we design an approximation for the vanilla noise injection-based training method to reduce memory and improve computational efficiency. Next, we apply our proposed scheme to spiking neural networks and evaluate the performance of classification accuracy and robustness on MNIST and Fashion-MNIST datasets. Experiment results show that our proposed method achieves a much better performance on adversarial robustness and slightly better performance on original accuracy, compared with the conventional gradient-based training method. ",
    "url": "https://arxiv.org/abs/2302.10802",
    "authors": [
      "Zeliang Zhang",
      "Jinyang Jiang",
      "Minjie Chen",
      "Zhiyuan Wang",
      "Yijie Peng",
      "Zhaofei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10804",
    "title": "GDBN: a Graph Neural Network Approach to Dynamic Bayesian Network",
    "abstract": "Identifying causal relations among multi-variate time series is one of the most important elements towards understanding the complex mechanisms underlying the dynamic system. It provides critical tools for forecasting, simulations and interventions in science and business analytics. In this paper, we proposed a graph neural network approach with score-based method aiming at learning a sparse DAG that captures the causal dependencies in a discretized time temporal graph. We demonstrate methods with graph neural network significantly outperformed other state-of-the-art methods with dynamic bayesian networking inference. In addition, from the experiments, the structural causal model can be more accurate than a linear SCM discovered by the methods such as Notears. ",
    "url": "https://arxiv.org/abs/2302.10804",
    "authors": [
      "Yang Sun",
      "Yifan Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.10808",
    "title": "Bokeh Rendering Based on Adaptive Depth Calibration Network",
    "abstract": "Bokeh rendering is a popular and effective technique used in photography to create an aesthetically pleasing effect. It is widely used to blur the background and highlight the subject in the foreground, thereby drawing the viewer's attention to the main focus of the image. In traditional digital single-lens reflex cameras (DSLRs), this effect is achieved through the use of a large aperture lens. This allows the camera to capture images with shallow depth-of-field, in which only a small area of the image is in sharp focus, while the rest of the image is blurred. However, the hardware embedded in mobile phones is typically much smaller and more limited than that found in DSLRs. Consequently, mobile phones are not able to capture natural shallow depth-of-field photos, which can be a significant limitation for mobile photography. To address this challenge, in this paper, we propose a novel method for bokeh rendering using the Vision Transformer, a recent and powerful deep learning architecture. Our approach employs an adaptive depth calibration network that acts as a confidence level to compensate for errors in monocular depth estimation. This network is used to supervise the rendering process in conjunction with depth information, allowing for the generation of high-quality bokeh images at high resolutions. Our experiments demonstrate that our proposed method outperforms state-of-the-art methods, achieving about 24.7% improvements on LPIPS and obtaining higher PSNR scores. ",
    "url": "https://arxiv.org/abs/2302.10808",
    "authors": [
      "Lu Liu",
      "Lei Zhou",
      "Yuhan Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10809",
    "title": "Causal Social Explanations for Stochastic Sequential Multi-Agent  Decision-Making",
    "abstract": "We present a novel framework to generate causal explanations for the decisions of agents in stochastic sequential multi-agent environments. Explanations are given via natural language conversations answering a wide range of user queries and requiring associative, interventionist, or counterfactual causal reasoning. Instead of assuming any specific causal graph, our method relies on a generative model of interactions to simulate counterfactual worlds which are used to identify the salient causes behind decisions. We implement our method for motion planning for autonomous driving and test it in simulated scenarios with coupled interactions. Our method correctly identifies and ranks the relevant causes and delivers concise explanations to the users' queries. ",
    "url": "https://arxiv.org/abs/2302.10809",
    "authors": [
      "Balint Gyevnar",
      "Cheng Wang",
      "Christopher G. Lucas",
      "Shay B. Cohen",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.10817",
    "title": "Inferring Implicit Trait Preferences for Task Allocation in  Heterogeneous Teams",
    "abstract": "Task allocation in heterogeneous multi-agent teams often requires reasoning about multi-dimensional agent traits (i.e., capabilities) and the demands placed on them by tasks. However, existing methods tend to ignore the fact that not all traits equally contribute to a given task. Ignoring such inherent preferences or relative importance can lead to unintended sub-optimal allocations of limited agent resources that do not necessarily contribute to task success. Further, reasoning over a large number of traits can incur a hefty computational burden. To alleviate these concerns, we propose an algorithm to infer task-specific trait preferences implicit in expert demonstrations. We leverage the insight that the consistency with which an expert allocates a trait to a task across demonstrations reflects the trait's importance to that task. Inspired by findings in psychology, we account for the fact that the inherent diversity of a trait in the dataset influences the dataset's informativeness and, thereby, the extent of the inferred preference or the lack thereof. Through detailed numerical simulations and evaluations of a publicly-available soccer dataset (FIFA 20), we demonstrate that we can successfully infer implicit trait preferences and that accounting for the inferred preferences leads to more computationally efficient and effective task allocation, compared to a baseline approach that treats all traits equally. ",
    "url": "https://arxiv.org/abs/2302.10817",
    "authors": [
      "Vivek Mallampati",
      "Harish Ravichandar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2302.10834",
    "title": "Weakly Supervised Temporal Convolutional Networks for Fine-grained  Surgical Activity Recognition",
    "abstract": "Automatic recognition of fine-grained surgical activities, called steps, is a challenging but crucial task for intelligent intra-operative computer assistance. The development of current vision-based activity recognition methods relies heavily on a high volume of manually annotated data. This data is difficult and time-consuming to generate and requires domain-specific knowledge. In this work, we propose to use coarser and easier-to-annotate activity labels, namely phases, as weak supervision to learn step recognition with fewer step annotated videos. We introduce a step-phase dependency loss to exploit the weak supervision signal. We then employ a Single-Stage Temporal Convolutional Network (SS-TCN) with a ResNet-50 backbone, trained in an end-to-end fashion from weakly annotated videos, for temporal activity segmentation and recognition. We extensively evaluate and show the effectiveness of the proposed method on a large video dataset consisting of 40 laparoscopic gastric bypass procedures and the public benchmark CATARACTS containing 50 cataract surgeries. ",
    "url": "https://arxiv.org/abs/2302.10834",
    "authors": [
      "Sanat Ramesh",
      "Diego Dall'Alba",
      "Cristians Gonzalez",
      "Tong Yu",
      "Pietro Mascagni",
      "Didier Mutter",
      "Jacques Marescaux",
      "Paolo Fiorini",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.10835",
    "title": "A General-Purpose Transferable Predictor for Neural Architecture Search",
    "abstract": "Understanding and modelling the performance of neural architectures is key to Neural Architecture Search (NAS). Performance predictors have seen widespread use in low-cost NAS and achieve high ranking correlations between predicted and ground truth performance in several NAS benchmarks. However, existing predictors are often designed based on network encodings specific to a predefined search space and are therefore not generalizable to other search spaces or new architecture families. In this paper, we propose a general-purpose neural predictor for NAS that can transfer across search spaces, by representing any given candidate Convolutional Neural Network (CNN) with a Computation Graph (CG) that consists of primitive operators. We further combine our CG network representation with Contrastive Learning (CL) and propose a graph representation learning procedure that leverages the structural information of unlabeled architectures from multiple families to train CG embeddings for our performance predictor. Experimental results on NAS-Bench-101, 201 and 301 demonstrate the efficacy of our scheme as we achieve strong positive Spearman Rank Correlation Coefficient (SRCC) on every search space, outperforming several Zero-Cost Proxies, including Synflow and Jacov, which are also generalizable predictors across search spaces. Moreover, when using our proposed general-purpose predictor in an evolutionary neural architecture search algorithm, we can find high-performance architectures on NAS-Bench-101 and find a MobileNetV3 architecture that attains 79.2% top-1 accuracy on ImageNet. ",
    "url": "https://arxiv.org/abs/2302.10835",
    "authors": [
      "Fred X. Han",
      "Keith G. Mills",
      "Fabian Chudak",
      "Parsa Riahi",
      "Mohammad Salameh",
      "Jialin Zhang",
      "Wei Lu",
      "Shangling Jui",
      "Di Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10842",
    "title": "DSL-Assembly: A Robust and Safe Assembly Strategy",
    "abstract": "A reinforcement learning (RL) based method that enables the robot to accomplish the assembly-type task with safety regulations is proposed. The overall strategy consists of grasping and assembly, and this paper mainly considers the assembly strategy. Force feedback is used instead of visual feedback to perceive the shape and direction of the hole in this paper. Furthermore, multiple models based on different sensors are trained for different environments due to environmental perturbations and equipment failures (failures of cameras and other sensors) in the real world. Then, since the emergency stop is triggered when the force output by the robot is too large, a force-based dynamic safety lock (DSL) is proposed to limit the pressing force of the robot. Finally, we train and test the robot model with a simulator and build ablation experiments to illustrate the effectiveness of our method. The models are independently tested 500 times in the simulator, giving a 58.91% success rate with a 4mm gap. These models are transferred to the real world and deployed on a real robot. Simulation environments: https://github.com/0707yiliu/peg-in-hole-with-RL. ",
    "url": "https://arxiv.org/abs/2302.10842",
    "authors": [
      "Yi Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.10844",
    "title": "Robust Mean Estimation Without a Mean: Dimension-Independent Error in  Polynomial Time for Symmetric Distributions",
    "abstract": "In this work, we study the problem of robustly estimating the mean/location parameter of distributions without moment bounds. For a large class of distributions satisfying natural symmetry constraints we give a sequence of algorithms that can efficiently estimate its location without incurring dimension-dependent factors in the error. Concretely, suppose an adversary can arbitrarily corrupt an $\\varepsilon$-fraction of the observed samples. For every $k \\in \\mathbb{N}$, we design an estimator using time and samples $\\tilde{O}({d^k})$ such that the dependence of the error on the corruption level $\\varepsilon$ is an additive factor of $O(\\varepsilon^{1-\\frac{1}{2k}})$. The dependence on other problem parameters is also nearly optimal. Our class contains products of arbitrary symmetric one-dimensional distributions as well as elliptical distributions, a vast generalization of the Gaussian distribution. Examples include product Cauchy distributions and multi-variate $t$-distributions. In particular, even the first moment might not exist. We provide the first efficient algorithms for this class of distributions. Previously, such results where only known under boundedness assumptions on the moments of the distribution and in particular, are provably impossible in the absence of symmetry [KSS18, CTBJ22]. For the class of distributions we consider, all previous estimators either require exponential time or incur error depending on the dimension. Our algorithms are based on a generalization of the filtering technique [DK22]. We show how this machinery can be combined with Huber-loss-based approach to work with projections of the noise. Moreover, we show how sum-of-squares proofs can be used to obtain algorithmic guarantees even for distributions without first moment. We believe that this approach may find other application in future works. ",
    "url": "https://arxiv.org/abs/2302.10844",
    "authors": [
      "Gleb Novikov",
      "David Steurer",
      "Stefan Tiegel"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.10860",
    "title": "Spatio-Temporal Denoising Graph Autoencoders with Data Augmentation for  Photovoltaic Timeseries Data Imputation",
    "abstract": "The integration of the global Photovoltaic (PV) market with real time data-loggers has enabled large scale PV data analytical pipelines for power forecasting and long-term reliability assessment of PV fleets. Nevertheless, the performance of PV data analysis heavily depends on the quality of PV timeseries data. This paper proposes a novel Spatio-Temporal Denoising Graph Autoencoder (STD-GAE) framework to impute missing PV Power Data. STD-GAE exploits temporal correlation, spatial coherence, and value dependencies from domain knowledge to recover missing data. Experimental results show that STD-GAE can achieve a gain of 43.14% in imputation accuracy and remains less sensitive to missing rate, different seasons, and missing scenarios, compared with state-of-the-art data imputation methods such as MIDA and LRTC-TNN. ",
    "url": "https://arxiv.org/abs/2302.10860",
    "authors": [
      "Yangxin Fan",
      "Xuanji Yu",
      "Raymond Wieser",
      "David Meakin",
      "Avishai Shaton",
      "Jean-Nicolas Jaubert",
      "Robert Flottemesch",
      "Michael Howell",
      "Jennifer Braid",
      "Laura S.Bruckman",
      "Roger French",
      "Yinghui Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2302.10866",
    "title": "Hyena Hierarchy: Towards Larger Convolutional Language Models",
    "abstract": "Recent advances in deep learning have relied heavily on the use of large Transformers due to their ability to learn at scale. However, the core building block of Transformers, the attention operator, exhibits quadratic cost in sequence length, limiting the amount of context accessible. Existing subquadratic methods based on low-rank and sparse approximations need to be combined with dense attention layers to match Transformers, indicating a gap in capability. In this work, we propose Hyena, a subquadratic drop-in replacement for attention constructed by interleaving implicitly parametrized long convolutions and data-controlled gating. In recall and reasoning tasks on sequences of thousands to hundreds of thousands of tokens, Hyena improves accuracy by more than 50 points over operators relying on state-spaces and other implicit and explicit methods, matching attention-based models. We set a new state-of-the-art for dense-attention-free architectures on language modeling in standard datasets (WikiText103 and The Pile), reaching Transformer quality with a 20% reduction in training compute required at sequence length 2K. Hyena operators are twice as fast as highly optimized attention at sequence length 8K, and 100x faster at sequence length 64K. ",
    "url": "https://arxiv.org/abs/2302.10866",
    "authors": [
      "Michael Poli",
      "Stefano Massaroli",
      "Eric Nguyen",
      "Daniel Y. Fu",
      "Tri Dao",
      "Stephen Baccus",
      "Yoshua Bengio",
      "Stefano Ermon",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.10873",
    "title": "Context-Aware Timewise VAEs for Real-Time Vehicle Trajectory Prediction",
    "abstract": "Real-time, accurate prediction of human steering behaviors has wide applications, from developing intelligent traffic systems to deploying autonomous driving systems in both real and simulated worlds. In this paper, we present ContextVAE, a context-aware approach for multi-modal vehicle trajectory prediction. Built upon the backbone architecture of a timewise variational autoencoder, ContextVAE employs a dual attention mechanism for observation encoding that accounts for the environmental context information and the dynamic agents' states in a unified way. By utilizing features extracted from semantic maps during agent state encoding, our approach takes into account both the social features exhibited by agents on the scene and the physical environment constraints to generate map-compliant and socially-aware trajectories. We perform extensive testing on the nuScenes prediction challenge, Lyft Level 5 dataset and Waymo Open Motion Dataset to show the effectiveness of our approach and its state-of-the-art performance. In all tested datasets, ContextVAE models are fast to train and provide high-quality multi-modal predictions in real-time. ",
    "url": "https://arxiv.org/abs/2302.10873",
    "authors": [
      "Pei Xu",
      "Jean-Bernard Hayet",
      "Ioannis Karamouzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10876",
    "title": "Effects of Co-channel Interference on RIS Empowered Wireless Networks  amid Multiple Eavesdropping Attempts",
    "abstract": "This letter is concerned with the secrecy performance of reconfigurable intelligent surfaces (RIS)-aided wireless networks in the existence of multiple interferers towards the destination. To be more precise, we analyze three critical issues in the design of secure RIS-assisted networks: 1) How do interferers affect the performance of secure wireless networks? 2) Which of the two groups of eavesdroppers (i.e., colluding and non-colluding) is more severe? 3) How can RIS improve network confidentiality? To do so, we develop the analytical expression of secrecy outage probability in closed-form, along with asymptotic analysis at high signal-to-noise ratio regime to better understand the impacts of different system parameters on secrecy performance. Finally, we validate our analytical results using a computer based Monte-Carlo simulation. ",
    "url": "https://arxiv.org/abs/2302.10876",
    "authors": [
      "Md. Roisul Ajom Ruku",
      "Md. Ibrahim",
      "A. S. M. Badrudduza",
      "Imran Shafique Ansari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2302.10886",
    "title": "Some Fundamental Aspects about Lipschitz Continuity of Neural Network  Functions",
    "abstract": "Lipschitz continuity is a simple yet pivotal functional property of any predictive model that lies at the core of its robustness, generalisation, and adversarial vulnerability. Our aim is to thoroughly investigate and characterise the Lipschitz behaviour of the functions learned via neural networks. Despite the significant tightening of the bounds in the recent years, precisely estimating the Lipschitz constant continues to be a practical challenge and tight theoretical analyses, similarly, remain intractable. Therefore, we shift our perspective and instead attempt to uncover insights about the nature of Lipschitz constant of neural networks functions -- by relying on the simplest and most general upper and lower bounds. We carry out an empirical investigation in a range of different settings (architectures, losses, optimisers, label noise, etc.), which reveals several fundamental and intriguing traits of the Lipschitz continuity of neural networks functions, In particular, we identify a remarkable double descent trend in both upper and lower bounds to the Lipschitz constant which tightly aligns with the typical double descent trend in the test loss. ",
    "url": "https://arxiv.org/abs/2302.10886",
    "authors": [
      "Grigory Khromov",
      "Sidak Pal Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.10344",
    "title": "Model-based feature selection for neural networks: A mixed-integer  programming approach",
    "abstract": "In this work, we develop a novel input feature selection framework for ReLU-based deep neural networks (DNNs), which builds upon a mixed-integer optimization approach. While the method is generally applicable to various classification tasks, we focus on finding input features for image classification for clarity of presentation. The idea is to use a trained DNN, or an ensemble of trained DNNs, to identify the salient input features. The input feature selection is formulated as a sequence of mixed-integer linear programming (MILP) problems that find sets of sparse inputs that maximize the classification confidence of each category. These ''inverse'' problems are regularized by the number of inputs selected for each category and by distribution constraints. Numerical results on the well-known MNIST and FashionMNIST datasets show that the proposed input feature selection allows us to drastically reduce the size of the input to $\\sim$15\\% while maintaining a good classification accuracy. This allows us to design DNNs with significantly fewer connections, reducing computational effort and producing DNNs that are more robust towards adversarial attacks. ",
    "url": "https://arxiv.org/abs/2302.10344",
    "authors": [
      "Shudian Zhao",
      "Calvin Tsay",
      "Jan Kronqvist"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10411",
    "title": "Regret Analysis of Online LQR Control via Trajectory Prediction and  Tracking: Extended Version",
    "abstract": "In this paper, we propose and analyze a new method for online linear quadratic regulator (LQR) control with a priori unknown time-varying cost matrices. The cost matrices are revealed sequentially with the potential for future values to be previewed over a short window. Our novel method involves using the available cost matrices to predict the optimal trajectory, and a tracking controller to drive the system towards it. We adopted the notion of dynamic regret to measure the performance of this proposed online LQR control method, with our main result being that the (dynamic) regret of our method is upper bounded by a constant. Moreover, the regret upper bound decays exponentially with the preview window length, and is extendable to systems with disturbances. We show in simulations that our proposed method offers improved performance compared to other previously proposed online LQR methods. ",
    "url": "https://arxiv.org/abs/2302.10411",
    "authors": [
      "Yitian Chen",
      "Timothy L. Molloy",
      "Tyler Summers",
      "Iman Shames"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.10467",
    "title": "On the Behaviour of Pulsed Qubits and their Application to Feed Forward  Networks",
    "abstract": "In the last two decades, the combination of machine learning and quantum computing has been an ever-growing topic of interest but, to this date, the limitations of quantum computing hardware have somewhat restricted the use of complex multi-qubit operations for machine learning. In this paper, we capitalize on the cyclical nature of quantum state probabilities observed on pulsed qubits to propose a single-qubit feed forward block whose architecture allows for classical parameters to be used in a way similar to classical neural networks. To do this, we modulate the pulses exciting qubits to induce superimposed rotations around the Bloch Sphere. The approach presented here has the advantage of employing a single qubit per block. Thus, it is linear with respect to the number of blocks, not polynomial with respect to the number of neurons as opposed to the majority of methods elsewhere. Further, since it employs classical parameters, a large number of iterations and updates at training can be effected without dwelling on coherence times and the gradients can be reused and stored if necessary. We also show how an analogy can be drawn to neural networks using sine-squared activation functions and illustrate how the feed-forward block presented here may be used and implemented on pulse-enabled quantum computers. ",
    "url": "https://arxiv.org/abs/2302.10467",
    "authors": [
      "Matheus Moraes Hammes",
      "Antonio Robles-Kelly"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10538",
    "title": "Lasserre Hierarchy for Graph Isomorphism and Homomorphism  Indistinguishability",
    "abstract": "We show that feasibility of the $t^\\text{th}$ level of the Lasserre semidefinite programming hierarchy for graph isomorphism can be expressed as a homomorphism indistinguishability relation. In other words, we define a class $\\mathcal{L}_t$ of graphs such that graphs $G$ and $H$ are not distinguished by the $t^\\text{th}$ level of the Lasserre hierarchy if and only if they admit the same number of homomorphisms from any graph in $\\mathcal{L}_t$. By analysing the treewidth of graphs in $\\mathcal{L}_t$ we prove that the $3t^\\text{th}$ level of Sherali--Adams linear programming hierarchy is as strong as the $t^\\text{th}$ level of Lasserre. Moreover, we show that this is best possible in the sense that $3t$ cannot be lowered to $3t-1$ for any $t$. The same result holds for the Lasserre hierarchy with non-negativity constraints, which we similarly characterise in terms of homomorphism indistinguishability over a family $\\mathcal{L}_t^+$ of graphs. Additionally, we give characterisations of level-$t$ Lasserre with non-negativity constraints in terms of logical equivalence and via a graph colouring algorithm akin to the Weisfeiler--Leman algorithm. This provides a polynomial time algorithm for determining if two given graphs are distinguished by the $t^\\text{th}$ level of the Lasserre hierarchy with non-negativity constraints. ",
    "url": "https://arxiv.org/abs/2302.10538",
    "authors": [
      "David E. Roberson",
      "Tim Seppelt"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.10625",
    "title": "Estimating long-term causal effects from short-term experiments and  long-term observational data with unobserved confounding",
    "abstract": "Understanding and quantifying cause and effect is an important problem in many domains. The generally-agreed solution to this problem is to perform a randomised controlled trial. However, even when randomised controlled trials can be performed, they usually have relatively short duration's due to cost considerations. This makes learning long-term causal effects a very challenging task in practice, since the long-term outcome is only observed after a long delay. In this paper, we study the identification and estimation of long-term treatment effects when both experimental and observational data are available. Previous work provided an estimation strategy to determine long-term causal effects from such data regimes. However, this strategy only works if one assumes there are no unobserved confounders in the observational data. In this paper, we specifically address the challenging case where unmeasured confounders are present in the observational data. Our long-term causal effect estimator is obtained by combining regression residuals with short-term experimental outcomes in a specific manner to create an instrumental variable, which is then used to quantify the long-term causal effect through instrumental variable regression. We prove this estimator is unbiased, and analytically study its variance. In the context of the front-door causal structure, this provides a new causal estimator, which may be of independent interest. Finally, we empirically test our approach on synthetic-data, as well as real-data from the International Stroke Trial. ",
    "url": "https://arxiv.org/abs/2302.10625",
    "authors": [
      "Graham Van Goffrier",
      "Lucas Maystre",
      "Ciar\u00e1n Gilligan-Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10681",
    "title": "FrankenSplit: Saliency Guided Neural Feature Compression with Shallow  Variational Bottleneck Injection",
    "abstract": "Lightweight neural networks exchange fast inference for predictive strength. Conversely, large deep neural networks have low prediction error but incur prolonged inference times and high energy consumption on resource-constrained devices. This trade-off is unacceptable for latency-sensitive and performance-critical applications. Offloading inference tasks to a server is unsatisfactory due to the inevitable network congestion by high-dimensional data competing for limited bandwidth and leaving valuable client-side resources idle. This work demonstrates why existing methods cannot adequately address the need for high-performance inference in mobile edge computing. Then, we show how to overcome current limitations by introducing a novel training method to reduce bandwidth consumption in Machine-to-Machine communication and a generalizable design heuristic for resource-conscious compression models. We extensively evaluate our proposed method against a wide range of baselines for latency and compressive strength in an environment with asymmetric resource distribution between edge devices and servers. Despite our edge-oriented lightweight encoder, our method achieves considerably better compression rates. ",
    "url": "https://arxiv.org/abs/2302.10681",
    "authors": [
      "Alireza Furutanpey",
      "Philipp Raith",
      "Schahram Dustdar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10800",
    "title": "KG-Hub -- Building and Exchanging Biological Knowledge Graphs",
    "abstract": "Knowledge graphs (KGs) are a powerful approach for integrating heterogeneous data and making inferences in biology and many other domains, but a coherent solution for constructing, exchanging, and facilitating the downstream use of knowledge graphs is lacking. Here we present KG-Hub, a platform that enables standardized construction, exchange, and reuse of knowledge graphs. Features include a simple, modular extract-transform-load (ETL) pattern for producing graphs compliant with Biolink Model (a high-level data model for standardizing biological data), easy integration of any OBO (Open Biological and Biomedical Ontologies) ontology, cached downloads of upstream data sources, versioned and automatically updated builds with stable URLs, web-browsable storage of KG artifacts on cloud infrastructure, and easy reuse of transformed subgraphs across projects. Current KG-Hub projects span use cases including COVID-19 research, drug repurposing, microbial-environmental interactions, and rare disease research. KG-Hub is equipped with tooling to easily analyze and manipulate knowledge graphs. KG-Hub is also tightly integrated with graph machine learning (ML) tools which allow automated graph machine learning, including node embeddings and training of models for link prediction and node classification. ",
    "url": "https://arxiv.org/abs/2302.10800",
    "authors": [
      "J Harry Caufield",
      "Tim Putman",
      "Kevin Schaper",
      "Deepak R Unni",
      "Harshad Hegde",
      "Tiffany J Callahan",
      "Luca Cappelletti",
      "Sierra AT Moxon",
      "Vida Ravanmehr",
      "Seth Carbon",
      "Lauren E Chan",
      "Katherina Cortes",
      "Kent A Shefchek",
      "Glass Elsarboukh",
      "James P Balhoff",
      "Tommaso Fontana",
      "Nicolas Matentzoglu",
      "Richard M Bruskiewich",
      "Anne E Thessen",
      "Nomi L Harris",
      "Monica C Munoz-Torres",
      "Melissa A Haendel",
      "Peter N Robinson",
      "Marcin P Joachimiak",
      "Christopher J Mungall",
      "Justin T Reese"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10824",
    "title": "Localizing the Origin of Idiopathic Ventricular Arrhythmia from ECG  Using an Attention-Based Recurrent Convolutional Neural Network",
    "abstract": "Idiopathic ventricular arrhythmia (IVAs) is extra abnormal heartbeats disturbing the regular heart rhythm that can become fatal if left untreated. Cardiac catheter ablation is the standard approach to treat IVAs, however, a crucial prerequisite for the ablation is the localization of IVAs' origin. The current IVA localization techniques are invasive, rely on expert interpretation, or are inaccurate. In this study, we developed a new deep-learning algorithm that can automatically identify the origin of IVAs from ECG signals without the need for expert manual analysis. Our developed deep learning algorithm was comprised of a spatial fusion to extract the most informative features from multichannel ECG data, temporal modeling to capture the evolving pattern of the ECG time series, and an attention mechanism to weigh the most important temporal features and improve the model interpretability. The algorithm was validated on a 12-lead ECG dataset collected from 334 patients (230 females) who experienced IVA and successfully underwent a catheter ablation procedure that determined IVA's exact origins. The proposed method achieved an area under the curve of 93%, an accuracy of 94%, a sensitivity of 97%, a precision of 95%, and an F1 score of 96% in locating the origin of IVAs and outperformed existing automatic and semi-automatic algorithms. The proposed method shows promise toward automatic and noninvasive evaluation of IVA patients before cardiac catheter ablation. ",
    "url": "https://arxiv.org/abs/2302.10824",
    "authors": [
      "Mohammadreza Shahsavari",
      "Niloufar Delfan",
      "Mohamad Forouzanfar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.07598",
    "title": "Internal Wasserstein Distance for Adversarial Attack and Defense",
    "abstract": " Title: Internal Wasserstein Distance for Adversarial Attack and Defense ",
    "url": "https://arxiv.org/abs/2103.07598",
    "authors": [
      "Qicheng Wang",
      "Shuhai Zhang",
      "Jiezhang Cao",
      "Jincheng Li",
      "Mingkui Tan",
      "Yang Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2105.05987",
    "title": "Two Influence Maximization Games on Graphs Made Temporal",
    "abstract": " Comments: Accepted to IJCAI 2021 ",
    "url": "https://arxiv.org/abs/2105.05987",
    "authors": [
      "Niclas Boehmer",
      "Vincent Froese",
      "Julia Henkel",
      "Yvonne Lasars",
      "Rolf Niedermeier",
      "Malte Renken"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2109.02722",
    "title": "Automatic Landmarks Correspondence Detection in Medical Images with an  Application to Deformable Image Registration",
    "abstract": " Comments: accepted paper in the Journal of Medical Imaging ",
    "url": "https://arxiv.org/abs/2109.02722",
    "authors": [
      "Monika Grewal",
      "Jan Wiersma",
      "Henrike Westerveld",
      "Peter A. N. Bosman",
      "Tanja Alderliesten"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12769",
    "title": "Heterogeneous Treatment Effect Estimation using machine learning for  Healthcare application: tutorial and benchmark",
    "abstract": " Comments: 52 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2109.12769",
    "authors": [
      "Yaobin Ling",
      "Pulakesh Upadhyaya",
      "Luyao Chen",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2111.05410",
    "title": "Leveraging the Graph Structure of Neural Network Training Dynamics",
    "abstract": " Title: Leveraging the Graph Structure of Neural Network Training Dynamics ",
    "url": "https://arxiv.org/abs/2111.05410",
    "authors": [
      "Fatemeh Vahedian",
      "Ruiyu Li",
      "Puja Trivedi",
      "Di Jin",
      "Danai Koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11937",
    "title": "Adversarial Deep Reinforcement Learning for Improving the Robustness of  Multi-agent Autonomous Driving Policies",
    "abstract": " Title: Adversarial Deep Reinforcement Learning for Improving the Robustness of  Multi-agent Autonomous Driving Policies ",
    "url": "https://arxiv.org/abs/2112.11937",
    "authors": [
      "Aizaz Sharif",
      "Dusica Marijan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.13064",
    "title": "CatchBackdoor: Backdoor Testing by Critical Trojan Neural Path  Identification via Differential Fuzzing",
    "abstract": " Comments: There are some problems in the experiment so we need to withdraw this paper. We will upload the new version after revision ",
    "url": "https://arxiv.org/abs/2112.13064",
    "authors": [
      "Haibo Jin",
      "Ruoxi Chen",
      "Jinyin Chen",
      "Yao Cheng",
      "Chong Fu",
      "Ting Wang",
      "Yue Yu",
      "Zhaoyan Ming"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14495",
    "title": "Conjugate Gradient Method for Generative Adversarial Networks",
    "abstract": " Comments: Accepted to AISTATS 2023 ",
    "url": "https://arxiv.org/abs/2203.14495",
    "authors": [
      "Hiroki Naganuma",
      "Hideaki Iiduka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.08735",
    "title": "Neural Collapse Inspired Attraction-Repulsion-Balanced Loss for  Imbalanced Learning",
    "abstract": " Comments: 25 pages, 5 figures, accepted by Neurocomputing ",
    "url": "https://arxiv.org/abs/2204.08735",
    "authors": [
      "Liang Xie",
      "Yibo Yang",
      "Deng Cai",
      "Xiaofei He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11551",
    "title": "Learning to Ignore Adversarial Attacks",
    "abstract": " Comments: EACL 2023, code is available at this https URL ",
    "url": "https://arxiv.org/abs/2205.11551",
    "authors": [
      "Yiming Zhang",
      "Yangqiaoyu Zhou",
      "Samuel Carton",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13076",
    "title": "On Bridging the Gap between Mean Field and Finite Width in Deep Random  Neural Networks with Batch Normalization",
    "abstract": " Title: On Bridging the Gap between Mean Field and Finite Width in Deep Random  Neural Networks with Batch Normalization ",
    "url": "https://arxiv.org/abs/2205.13076",
    "authors": [
      "Amir Joudaki",
      "Hadi Daneshmand",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.07340",
    "title": "On the Design and Training Strategies for RNN-based Online Neural Speech  Separation Systems",
    "abstract": " Comments: Accepted by ICASSP2023 ",
    "url": "https://arxiv.org/abs/2206.07340",
    "authors": [
      "Kai Li",
      "Yi Luo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.04248",
    "title": "A Statistically-Based Approach to Feedforward Neural Network Model  Selection",
    "abstract": " Title: A Statistically-Based Approach to Feedforward Neural Network Model  Selection ",
    "url": "https://arxiv.org/abs/2207.04248",
    "authors": [
      "Andrew McInerney",
      "Kevin Burke"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08457",
    "title": "A Meta-Reinforcement Learning Algorithm for Causal Discovery",
    "abstract": " Comments: Camera-ready version for CLEAR23 ",
    "url": "https://arxiv.org/abs/2207.08457",
    "authors": [
      "Andreas Sauter",
      "Erman Acar",
      "Vincent Fran\u00e7ois-Lavet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2208.10583",
    "title": "Improving Sample Efficiency in Evolutionary RL Using Off-Policy Ranking",
    "abstract": " Title: Improving Sample Efficiency in Evolutionary RL Using Off-Policy Ranking ",
    "url": "https://arxiv.org/abs/2208.10583",
    "authors": [
      "Eshwar S R",
      "Shishir Kolathaya",
      "Gugan Thoppe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.14450",
    "title": "Dual Representation Learning for One-Step Clustering of Multi-View Data",
    "abstract": " Comments: This paper has been submitted to a journal ",
    "url": "https://arxiv.org/abs/2208.14450",
    "authors": [
      "Wei Zhang",
      "Zhaohong Deng",
      "Kup-Sze Choi",
      "Jun Wang",
      "Shitong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.05980",
    "title": "Certified Defences Against Adversarial Patch Attacks on Semantic  Segmentation",
    "abstract": " Comments: accepted at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2209.05980",
    "authors": [
      "Maksym Yatsura",
      "Kaspar Sakmann",
      "N. Grace Hua",
      "Matthias Hein",
      "Jan Hendrik Metzen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14887",
    "title": "Learning Low-Frequency Motion Control for Robust and Dynamic Robot  Locomotion",
    "abstract": " Comments: 7 pages, 9 figures and 2 tables ",
    "url": "https://arxiv.org/abs/2209.14887",
    "authors": [
      "Siddhant Gangapurwala",
      "Luigi Campanaro",
      "Ioannis Havoutis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00262",
    "title": "Frequency Estimation of Evolving Data Under Local Differential Privacy",
    "abstract": " Comments: Accepted at EDBT 2023. Updated structure and correcting privacy loss of dBitFlipPM ",
    "url": "https://arxiv.org/abs/2210.00262",
    "authors": [
      "H\u00e9ber H. Arcolezi",
      "Carlos Pinz\u00f3n",
      "Catuscia Palamidessi",
      "S\u00e9bastien Gambs"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.01953",
    "title": "Robust Fair Clustering: A Novel Fairness Attack and Defense Framework",
    "abstract": " Comments: Accepted to the 11th International Conference on Learning Representations (ICLR 2023) ",
    "url": "https://arxiv.org/abs/2210.01953",
    "authors": [
      "Anshuman Chhabra",
      "Peizhao Li",
      "Prasant Mohapatra",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.03115",
    "title": "SimPer: Simple Self-Supervised Learning of Periodic Targets",
    "abstract": " Comments: ICLR 2023 Oral (notable top 5%) ",
    "url": "https://arxiv.org/abs/2210.03115",
    "authors": [
      "Yuzhe Yang",
      "Xin Liu",
      "Jiang Wu",
      "Silviu Borac",
      "Dina Katabi",
      "Ming-Zher Poh",
      "Daniel McDuff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04227",
    "title": "Dual-distribution discrepancy with self-supervised refinement for  anomaly detection in medical images",
    "abstract": " Comments: Under consideration. arXiv admin note: text overlap with arXiv:2206.03935 ",
    "url": "https://arxiv.org/abs/2210.04227",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Xin Yang",
      "Yu Zhou",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04371",
    "title": "A Detailed Study of Interpretability of Deep Neural Network based Top  Taggers",
    "abstract": " Comments: Repository: this https URL Major revisions with respect to previous version ",
    "url": "https://arxiv.org/abs/2210.04371",
    "authors": [
      "Ayush Khot",
      "Mark S. Neubauer",
      "Avik Roy"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.07321",
    "title": "MT4SSL: Boosting Self-Supervised Speech Representation Learning by  Integrating Multiple Targets",
    "abstract": " Title: MT4SSL: Boosting Self-Supervised Speech Representation Learning by  Integrating Multiple Targets ",
    "url": "https://arxiv.org/abs/2211.07321",
    "authors": [
      "Ziyang Ma",
      "Zhisheng Zhen",
      "Changli Tang",
      "Yujin Wang",
      "Xie Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2301.08883",
    "title": "Versatile Neural Processes for Learning Implicit Neural Representations",
    "abstract": " Comments: Camera-ready version for ICLR2023 ",
    "url": "https://arxiv.org/abs/2301.08883",
    "authors": [
      "Zongyu Guo",
      "Cuiling Lan",
      "Zhizheng Zhang",
      "Yan Lu",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.08941",
    "title": "On the Algebraic Properties of Flame Graphs",
    "abstract": " Comments: 11 pages, 4 figures; added clarifications ",
    "url": "https://arxiv.org/abs/2301.08941",
    "authors": [
      "Gabriele N. Tornetta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2301.12166",
    "title": "Heterogeneous Datasets for Federated Survival Analysis Simulation",
    "abstract": " Title: Heterogeneous Datasets for Federated Survival Analysis Simulation ",
    "url": "https://arxiv.org/abs/2301.12166",
    "authors": [
      "Alberto Archetti",
      "Eugenio Lomurno",
      "Francesco Lattari",
      "Andr\u00e9 Martin",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12698",
    "title": "Robust Meta Learning for Image based tasks",
    "abstract": " Comments: IEEE International Conference on Robotics and Automation SRLworkshop 2022 ",
    "url": "https://arxiv.org/abs/2301.12698",
    "authors": [
      "Penghao Jiang",
      "Xin Ke",
      "ZiFeng Wang",
      "Chunxi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.05451",
    "title": "Brain Effective Connectome based on fMRI and DTI Data: Bayesian Causal  Learning and Assessment",
    "abstract": " Title: Brain Effective Connectome based on fMRI and DTI Data: Bayesian Causal  Learning and Assessment ",
    "url": "https://arxiv.org/abs/2302.05451",
    "authors": [
      "Abdolmahdi Bagheri",
      "Mahdi Dehshiri",
      "Yamin Bagheri",
      "Alireza Akhondi-Asl",
      "Babak Nadjar Araabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2302.06333",
    "title": "Improving Recommendation Fairness via Data Augmentation",
    "abstract": " Comments: The paper is accepted by WWW 2023 ",
    "url": "https://arxiv.org/abs/2302.06333",
    "authors": [
      "Lei Chen",
      "Le Wu",
      "Kun Zhang",
      "Richang Hong",
      "Defu Lian",
      "Zhiqiang Zhang",
      "Jun Zhou",
      "Meng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06804",
    "title": "Discovering Optimal Scoring Mechanisms in Causal Strategic Prediction",
    "abstract": " Title: Discovering Optimal Scoring Mechanisms in Causal Strategic Prediction ",
    "url": "https://arxiv.org/abs/2302.06804",
    "authors": [
      "Tom Yan",
      "Shantanu Gupta",
      "Zachary Lipton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.07427",
    "title": "Studying the effect of AI Code Generators on Supporting Novice Learners  in Introductory Programming",
    "abstract": " Comments: To be published in Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23), April 23--28, 2023, Hamburg, Germany 17 pages with 11 Figures, 2 Tables, 6 Page Appendix ",
    "url": "https://arxiv.org/abs/2302.07427",
    "authors": [
      "Majeed Kazemitabaar",
      "Justin Chow",
      "Carl Ka To Ma",
      "Barbara J. Ericson",
      "David Weintrop",
      "Tovi Grossman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.07867",
    "title": "Learning Performance-Improving Code Edits",
    "abstract": " Comments: Project website: this https URL This version extends the related work and acknowledgements ",
    "url": "https://arxiv.org/abs/2302.07867",
    "authors": [
      "Aman Madaan",
      "Alexander Shypula",
      "Uri Alon",
      "Milad Hashemi",
      "Parthasarathy Ranganathan",
      "Yiming Yang",
      "Graham Neubig",
      "Amir Yazdanbakhsh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2302.08043",
    "title": "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural  Networks",
    "abstract": " Comments: accepted by WWW23 ",
    "url": "https://arxiv.org/abs/2302.08043",
    "authors": [
      "Zemin Liu",
      "Xingtong Yu",
      "Yuan Fang",
      "Xinming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.09119",
    "title": "A Review on Generative Adversarial Networks for Data Augmentation in  Person Re-Identification Systems",
    "abstract": " Title: A Review on Generative Adversarial Networks for Data Augmentation in  Person Re-Identification Systems ",
    "url": "https://arxiv.org/abs/2302.09119",
    "authors": [
      "Victor Uc-Cetina",
      "Laura Alvarez-Gonzalez",
      "Anabel Martin-Gonzalez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.09256",
    "title": "Multi-dimensional frequency dynamic convolution with confident mean  teacher for sound event detection",
    "abstract": " Comments: accepted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2302.09256",
    "authors": [
      "Shengchang Xiao",
      "Xueshuai Zhang",
      "Pengyuan Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2302.09298",
    "title": "Improving Fairness in Adaptive Social Exergames via Shapley Bandits",
    "abstract": " Title: Improving Fairness in Adaptive Social Exergames via Shapley Bandits ",
    "url": "https://arxiv.org/abs/2302.09298",
    "authors": [
      "Robert C. Gray",
      "Jennifer Villareale",
      "Thomas B. Fox",
      "Diane H. Dallal",
      "Santiago Onta\u00f1\u00f3n",
      "Danielle Arigo",
      "Shahin Jabbari",
      "Jichen Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.09360",
    "title": "Backdoor Attacks to Pre-trained Unified Foundation Models",
    "abstract": " Comments: This paper is accepted as a poster for NDSS 2023 ",
    "url": "https://arxiv.org/abs/2302.09360",
    "authors": [
      "Zenghui Yuan",
      "Yixin Liu",
      "Kai Zhang",
      "Pan Zhou",
      "Lichao Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.09484",
    "title": "Gradient-based Wang-Landau Algorithm: A Novel Sampler for Output  Distribution of Neural Networks over the Input Space",
    "abstract": " Title: Gradient-based Wang-Landau Algorithm: A Novel Sampler for Output  Distribution of Neural Networks over the Input Space ",
    "url": "https://arxiv.org/abs/2302.09484",
    "authors": [
      "Weitang Liu",
      "Ying-Wai Li",
      "Yi-Zhuang You",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.09554",
    "title": "Mixed Hierarchy Network for Image Restoration",
    "abstract": " Title: Mixed Hierarchy Network for Image Restoration ",
    "url": "https://arxiv.org/abs/2302.09554",
    "authors": [
      "Hu Gao",
      "Depeng Dang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.09582",
    "title": "Human Emotion Knowledge Representation Emerges in Large Language Model  and Supports Discrete Emotion Inference",
    "abstract": " Comments: 35 pages, 11 figures, correct typos and update references ",
    "url": "https://arxiv.org/abs/2302.09582",
    "authors": [
      "Ming Li",
      "Yusheng Su",
      "Hsiu-Yuan Huang",
      "Jiali Cheng",
      "Xin Hu",
      "Xinmiao Zhang",
      "Huadong Wang",
      "Yujia Qin",
      "Xiaozhi Wang",
      "Zhiyuan Liu",
      "Dan Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.10126",
    "title": "iQPP: A Benchmark for Image Query Performance Prediction",
    "abstract": " Title: iQPP: A Benchmark for Image Query Performance Prediction ",
    "url": "https://arxiv.org/abs/2302.10126",
    "authors": [
      "Eduard Poesina",
      "Radu Tudor Ionescu",
      "Josiane Mothe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  }
]